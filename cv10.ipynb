{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number=\"10-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'monitor/isolation/2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step3_gcnsm.path_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "# step3_gcnsm.load_env(ds_name=\"monitor\",ns=2,st=\"isolation\",sp=False,we=\"MONITOR_SIMPLE_SHORT\")\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "#             loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# train(training_object,207)\n",
    "\n",
    "training_object.best.epochs_run = training_object.epochs_run\n",
    "training_object.lr = 1e-2\n",
    "training_object.best.lr = 1e-2\n",
    "training_object.save_state(step3_gcnsm.path_setup)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14632, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.057, tt:32.057\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14586, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.080, tt:64.161\n",
      "Ep:2, loss:0.00014, loss_test:0.14505, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.923, tt:95.768\n",
      "Ep:3, loss:0.00014, loss_test:0.14370, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.852, tt:127.407\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00013, loss_test:0.14152, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:32.166, tt:160.832\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00013, loss_test:0.13813, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:32.093, tt:192.559\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00012, loss_test:0.13474, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:32.118, tt:224.829\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00011, loss_test:0.13534, lr:1.00e-02, fs:0.60488 (r=0.626,p=0.585),  time:32.170, tt:257.359\n",
      "Ep:8, loss:0.00011, loss_test:0.13693, lr:1.00e-02, fs:0.46243 (r=0.404,p=0.541),  time:32.088, tt:288.790\n",
      "Ep:9, loss:0.00011, loss_test:0.13392, lr:1.00e-02, fs:0.51648 (r=0.475,p=0.566),  time:32.039, tt:320.386\n",
      "Ep:10, loss:0.00011, loss_test:0.13183, lr:1.00e-02, fs:0.61165 (r=0.636,p=0.589),  time:31.964, tt:351.609\n",
      "Ep:11, loss:0.00010, loss_test:0.13120, lr:1.00e-02, fs:0.59000 (r=0.596,p=0.584),  time:32.125, tt:385.496\n",
      "Ep:12, loss:0.00010, loss_test:0.13132, lr:1.00e-02, fs:0.57754 (r=0.545,p=0.614),  time:32.282, tt:419.667\n",
      "Ep:13, loss:0.00010, loss_test:0.13000, lr:1.00e-02, fs:0.57459 (r=0.525,p=0.634),  time:32.273, tt:451.827\n",
      "Ep:14, loss:0.00009, loss_test:0.12799, lr:1.00e-02, fs:0.62032 (r=0.586,p=0.659),  time:32.323, tt:484.846\n",
      "Ep:15, loss:0.00009, loss_test:0.12666, lr:1.00e-02, fs:0.65979 (r=0.646,p=0.674),  time:32.333, tt:517.321\n",
      "Ep:16, loss:0.00009, loss_test:0.12637, lr:1.00e-02, fs:0.68085 (r=0.646,p=0.719),  time:32.540, tt:553.172\n",
      "Ep:17, loss:0.00008, loss_test:0.12657, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:32.520, tt:585.363\n",
      "Ep:18, loss:0.00008, loss_test:0.12507, lr:9.90e-03, fs:0.66667 (r=0.626,p=0.713),  time:32.608, tt:619.550\n",
      "Ep:19, loss:0.00008, loss_test:0.12398, lr:9.80e-03, fs:0.68817 (r=0.646,p=0.736),  time:32.546, tt:650.917\n",
      "Ep:20, loss:0.00008, loss_test:0.12332, lr:9.70e-03, fs:0.70270 (r=0.657,p=0.756),  time:32.573, tt:684.030\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.12191, lr:9.70e-03, fs:0.71277 (r=0.677,p=0.753),  time:32.622, tt:717.685\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00007, loss_test:0.12077, lr:9.70e-03, fs:0.70213 (r=0.667,p=0.742),  time:32.627, tt:750.411\n",
      "Ep:23, loss:0.00007, loss_test:0.11940, lr:9.70e-03, fs:0.70526 (r=0.677,p=0.736),  time:32.648, tt:783.553\n",
      "Ep:24, loss:0.00007, loss_test:0.11948, lr:9.70e-03, fs:0.71658 (r=0.677,p=0.761),  time:32.688, tt:817.207\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.11885, lr:9.70e-03, fs:0.70899 (r=0.677,p=0.744),  time:32.665, tt:849.288\n",
      "Ep:26, loss:0.00007, loss_test:0.11879, lr:9.70e-03, fs:0.70213 (r=0.667,p=0.742),  time:32.675, tt:882.222\n",
      "Ep:27, loss:0.00006, loss_test:0.11792, lr:9.70e-03, fs:0.70968 (r=0.667,p=0.759),  time:32.654, tt:914.311\n",
      "Ep:28, loss:0.00006, loss_test:0.11728, lr:9.70e-03, fs:0.71277 (r=0.677,p=0.753),  time:32.671, tt:947.446\n",
      "Ep:29, loss:0.00006, loss_test:0.11707, lr:9.70e-03, fs:0.72340 (r=0.687,p=0.764),  time:32.689, tt:980.682\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.11651, lr:9.70e-03, fs:0.72043 (r=0.677,p=0.770),  time:32.659, tt:1012.419\n",
      "Ep:31, loss:0.00006, loss_test:0.11507, lr:9.70e-03, fs:0.72727 (r=0.687,p=0.773),  time:32.697, tt:1046.295\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.11517, lr:9.70e-03, fs:0.73118 (r=0.687,p=0.782),  time:32.696, tt:1078.972\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.11499, lr:9.70e-03, fs:0.73118 (r=0.687,p=0.782),  time:32.714, tt:1112.281\n",
      "Ep:34, loss:0.00006, loss_test:0.11343, lr:9.70e-03, fs:0.73118 (r=0.687,p=0.782),  time:32.702, tt:1144.552\n",
      "Ep:35, loss:0.00005, loss_test:0.11438, lr:9.70e-03, fs:0.72826 (r=0.677,p=0.788),  time:32.741, tt:1178.661\n",
      "Ep:36, loss:0.00005, loss_test:0.11215, lr:9.70e-03, fs:0.74074 (r=0.707,p=0.778),  time:32.729, tt:1210.983\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00005, loss_test:0.11277, lr:9.70e-03, fs:0.73404 (r=0.697,p=0.775),  time:32.773, tt:1245.378\n",
      "Ep:38, loss:0.00005, loss_test:0.11287, lr:9.70e-03, fs:0.73797 (r=0.697,p=0.784),  time:32.797, tt:1279.074\n",
      "Ep:39, loss:0.00005, loss_test:0.11019, lr:9.70e-03, fs:0.74468 (r=0.707,p=0.787),  time:32.833, tt:1313.305\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.11266, lr:9.70e-03, fs:0.75410 (r=0.697,p=0.821),  time:32.839, tt:1346.402\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.11006, lr:9.70e-03, fs:0.74468 (r=0.707,p=0.787),  time:32.844, tt:1379.441\n",
      "Ep:42, loss:0.00005, loss_test:0.10949, lr:9.70e-03, fs:0.76087 (r=0.707,p=0.824),  time:32.908, tt:1415.056\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00004, loss_test:0.11209, lr:9.70e-03, fs:0.75556 (r=0.687,p=0.840),  time:32.945, tt:1449.577\n",
      "Ep:44, loss:0.00004, loss_test:0.10846, lr:9.70e-03, fs:0.74074 (r=0.707,p=0.778),  time:32.923, tt:1481.557\n",
      "Ep:45, loss:0.00004, loss_test:0.10911, lr:9.70e-03, fs:0.75824 (r=0.697,p=0.831),  time:32.940, tt:1515.240\n",
      "Ep:46, loss:0.00004, loss_test:0.10871, lr:9.70e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.940, tt:1548.200\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.10783, lr:9.70e-03, fs:0.76087 (r=0.707,p=0.824),  time:32.934, tt:1580.823\n",
      "Ep:48, loss:0.00004, loss_test:0.10754, lr:9.70e-03, fs:0.77095 (r=0.697,p=0.863),  time:32.951, tt:1614.605\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.10810, lr:9.70e-03, fs:0.77095 (r=0.697,p=0.863),  time:32.968, tt:1648.399\n",
      "Ep:50, loss:0.00004, loss_test:0.10719, lr:9.70e-03, fs:0.76503 (r=0.707,p=0.833),  time:32.971, tt:1681.522\n",
      "Ep:51, loss:0.00004, loss_test:0.10743, lr:9.70e-03, fs:0.75429 (r=0.667,p=0.868),  time:32.975, tt:1714.703\n",
      "Ep:52, loss:0.00004, loss_test:0.10659, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:32.967, tt:1747.262\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.10677, lr:9.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:32.970, tt:1780.386\n",
      "Ep:54, loss:0.00004, loss_test:0.10679, lr:9.70e-03, fs:0.76836 (r=0.687,p=0.872),  time:32.983, tt:1814.091\n",
      "Ep:55, loss:0.00003, loss_test:0.10632, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:33.003, tt:1848.143\n",
      "Ep:56, loss:0.00003, loss_test:0.10530, lr:9.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:33.000, tt:1881.001\n",
      "Ep:57, loss:0.00003, loss_test:0.10623, lr:9.70e-03, fs:0.76136 (r=0.677,p=0.870),  time:33.023, tt:1915.317\n",
      "Ep:58, loss:0.00003, loss_test:0.10485, lr:9.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.998, tt:1946.888\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00003, loss_test:0.10633, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.982, tt:1978.938\n",
      "Ep:60, loss:0.00003, loss_test:0.10447, lr:9.70e-03, fs:0.76136 (r=0.677,p=0.870),  time:32.936, tt:2009.093\n",
      "Ep:61, loss:0.00003, loss_test:0.10501, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.936, tt:2042.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.10497, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.912, tt:2073.432\n",
      "Ep:63, loss:0.00003, loss_test:0.10482, lr:9.70e-03, fs:0.76836 (r=0.687,p=0.872),  time:32.878, tt:2104.211\n",
      "Ep:64, loss:0.00003, loss_test:0.10391, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.865, tt:2136.242\n",
      "Ep:65, loss:0.00003, loss_test:0.10593, lr:9.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.855, tt:2168.457\n",
      "Ep:66, loss:0.00003, loss_test:0.10466, lr:9.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:32.834, tt:2199.911\n",
      "Ep:67, loss:0.00003, loss_test:0.10375, lr:9.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:32.824, tt:2232.045\n",
      "Ep:68, loss:0.00003, loss_test:0.10574, lr:9.70e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.803, tt:2263.407\n",
      "Ep:69, loss:0.00003, loss_test:0.10541, lr:9.70e-03, fs:0.76301 (r=0.667,p=0.892),  time:32.782, tt:2294.723\n",
      "Ep:70, loss:0.00003, loss_test:0.10424, lr:9.61e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.761, tt:2326.038\n",
      "Ep:71, loss:0.00003, loss_test:0.10676, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:32.718, tt:2355.728\n",
      "Ep:72, loss:0.00003, loss_test:0.10305, lr:9.41e-03, fs:0.77011 (r=0.677,p=0.893),  time:32.699, tt:2387.049\n",
      "Ep:73, loss:0.00002, loss_test:0.10500, lr:9.32e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.703, tt:2420.024\n",
      "Ep:74, loss:0.00002, loss_test:0.10606, lr:9.23e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.704, tt:2452.804\n",
      "Ep:75, loss:0.00002, loss_test:0.10489, lr:9.14e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.678, tt:2483.510\n",
      "Ep:76, loss:0.00002, loss_test:0.10633, lr:9.04e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.679, tt:2516.277\n",
      "Ep:77, loss:0.00002, loss_test:0.10520, lr:8.95e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.647, tt:2546.500\n",
      "Ep:78, loss:0.00002, loss_test:0.10577, lr:8.86e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.634, tt:2578.082\n",
      "Ep:79, loss:0.00002, loss_test:0.10620, lr:8.78e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.621, tt:2609.669\n",
      "Ep:80, loss:0.00002, loss_test:0.10584, lr:8.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.609, tt:2641.304\n",
      "Ep:81, loss:0.00002, loss_test:0.10697, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.612, tt:2674.203\n",
      "Ep:82, loss:0.00002, loss_test:0.10529, lr:8.51e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.608, tt:2706.434\n",
      "Ep:83, loss:0.00002, loss_test:0.10662, lr:8.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.591, tt:2737.606\n",
      "Ep:84, loss:0.00002, loss_test:0.10645, lr:8.35e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.559, tt:2767.514\n",
      "Ep:85, loss:0.00002, loss_test:0.10666, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.550, tt:2799.282\n",
      "Ep:86, loss:0.00002, loss_test:0.10649, lr:8.18e-03, fs:0.76744 (r=0.667,p=0.904),  time:32.538, tt:2830.794\n",
      "Ep:87, loss:0.00002, loss_test:0.10777, lr:8.10e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.526, tt:2862.329\n",
      "Ep:88, loss:0.00002, loss_test:0.10695, lr:8.02e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.512, tt:2893.541\n",
      "Ep:89, loss:0.00002, loss_test:0.10683, lr:7.94e-03, fs:0.77907 (r=0.677,p=0.918),  time:32.499, tt:2924.904\n",
      "Ep:90, loss:0.00002, loss_test:0.10893, lr:7.86e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.498, tt:2957.284\n",
      "Ep:91, loss:0.00002, loss_test:0.10633, lr:7.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:32.484, tt:2988.547\n",
      "Ep:92, loss:0.00002, loss_test:0.10818, lr:7.70e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.481, tt:3020.774\n",
      "Ep:93, loss:0.00002, loss_test:0.10936, lr:7.62e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.475, tt:3052.689\n",
      "Ep:94, loss:0.00002, loss_test:0.10658, lr:7.55e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.476, tt:3085.234\n",
      "Ep:95, loss:0.00002, loss_test:0.10970, lr:7.47e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.460, tt:3116.185\n",
      "Ep:96, loss:0.00002, loss_test:0.11092, lr:7.40e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.462, tt:3148.848\n",
      "Ep:97, loss:0.00002, loss_test:0.10704, lr:7.32e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.454, tt:3180.539\n",
      "Ep:98, loss:0.00002, loss_test:0.10980, lr:7.25e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.447, tt:3212.277\n",
      "Ep:99, loss:0.00002, loss_test:0.11043, lr:7.18e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.430, tt:3242.996\n",
      "Ep:100, loss:0.00002, loss_test:0.10850, lr:7.11e-03, fs:0.77193 (r=0.667,p=0.917),  time:32.424, tt:3274.807\n",
      "Ep:101, loss:0.00002, loss_test:0.10923, lr:7.03e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.408, tt:3305.645\n",
      "Ep:102, loss:0.00002, loss_test:0.11058, lr:6.96e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.387, tt:3335.859\n",
      "Ep:103, loss:0.00002, loss_test:0.10898, lr:6.89e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.378, tt:3367.327\n",
      "Ep:104, loss:0.00002, loss_test:0.11116, lr:6.83e-03, fs:0.72840 (r=0.596,p=0.937),  time:32.359, tt:3397.690\n",
      "Ep:105, loss:0.00002, loss_test:0.10990, lr:6.76e-03, fs:0.77381 (r=0.657,p=0.942),  time:32.353, tt:3429.457\n",
      "Ep:106, loss:0.00002, loss_test:0.10943, lr:6.69e-03, fs:0.73171 (r=0.606,p=0.923),  time:32.357, tt:3462.241\n",
      "Ep:107, loss:0.00001, loss_test:0.11065, lr:6.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.353, tt:3494.136\n",
      "Ep:108, loss:0.00001, loss_test:0.10896, lr:6.56e-03, fs:0.77647 (r=0.667,p=0.930),  time:32.356, tt:3526.763\n",
      "Ep:109, loss:0.00001, loss_test:0.11049, lr:6.49e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.351, tt:3558.606\n",
      "Ep:110, loss:0.00001, loss_test:0.10976, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:32.361, tt:3592.113\n",
      "Ep:111, loss:0.00001, loss_test:0.11083, lr:6.36e-03, fs:0.74699 (r=0.626,p=0.925),  time:32.369, tt:3625.369\n",
      "Ep:112, loss:0.00001, loss_test:0.11128, lr:6.30e-03, fs:0.71250 (r=0.576,p=0.934),  time:32.366, tt:3657.385\n",
      "Ep:113, loss:0.00001, loss_test:0.11006, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:32.356, tt:3688.587\n",
      "Ep:114, loss:0.00001, loss_test:0.11075, lr:6.17e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.358, tt:3721.214\n",
      "Ep:115, loss:0.00001, loss_test:0.11192, lr:6.11e-03, fs:0.70000 (r=0.566,p=0.918),  time:32.353, tt:3752.945\n",
      "Ep:116, loss:0.00001, loss_test:0.11108, lr:6.05e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.347, tt:3784.628\n",
      "Ep:117, loss:0.00001, loss_test:0.11126, lr:5.99e-03, fs:0.69565 (r=0.566,p=0.903),  time:32.356, tt:3817.997\n",
      "Ep:118, loss:0.00001, loss_test:0.11154, lr:5.93e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.349, tt:3849.492\n",
      "Ep:119, loss:0.00001, loss_test:0.11185, lr:5.87e-03, fs:0.70807 (r=0.576,p=0.919),  time:32.357, tt:3882.830\n",
      "Ep:120, loss:0.00001, loss_test:0.11098, lr:5.81e-03, fs:0.71605 (r=0.586,p=0.921),  time:32.354, tt:3914.842\n",
      "Ep:121, loss:0.00001, loss_test:0.11106, lr:5.75e-03, fs:0.72393 (r=0.596,p=0.922),  time:32.365, tt:3948.575\n",
      "Ep:122, loss:0.00001, loss_test:0.11174, lr:5.70e-03, fs:0.70000 (r=0.566,p=0.918),  time:32.364, tt:3980.802\n",
      "Ep:123, loss:0.00001, loss_test:0.11153, lr:5.64e-03, fs:0.73939 (r=0.616,p=0.924),  time:32.352, tt:4011.659\n",
      "Ep:124, loss:0.00001, loss_test:0.11157, lr:5.58e-03, fs:0.70000 (r=0.566,p=0.918),  time:32.334, tt:4041.714\n",
      "Ep:125, loss:0.00001, loss_test:0.11126, lr:5.53e-03, fs:0.70807 (r=0.576,p=0.919),  time:32.331, tt:4073.717\n",
      "Ep:126, loss:0.00001, loss_test:0.11156, lr:5.47e-03, fs:0.70807 (r=0.576,p=0.919),  time:32.342, tt:4107.370\n",
      "Ep:127, loss:0.00001, loss_test:0.11298, lr:5.42e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.334, tt:4138.794\n",
      "Ep:128, loss:0.00001, loss_test:0.11126, lr:5.36e-03, fs:0.70000 (r=0.566,p=0.918),  time:32.340, tt:4171.881\n",
      "Ep:129, loss:0.00001, loss_test:0.11165, lr:5.31e-03, fs:0.70000 (r=0.566,p=0.918),  time:32.343, tt:4204.556\n",
      "Ep:130, loss:0.00001, loss_test:0.11258, lr:5.26e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.343, tt:4236.995\n",
      "Ep:131, loss:0.00001, loss_test:0.11216, lr:5.20e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.350, tt:4270.141\n",
      "Ep:132, loss:0.00001, loss_test:0.11192, lr:5.15e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.357, tt:4303.516\n",
      "Ep:133, loss:0.00001, loss_test:0.11224, lr:5.10e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.368, tt:4337.283\n",
      "Ep:134, loss:0.00001, loss_test:0.11234, lr:5.05e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.369, tt:4369.826\n",
      "Ep:135, loss:0.00001, loss_test:0.11205, lr:5.00e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.377, tt:4403.217\n",
      "Ep:136, loss:0.00001, loss_test:0.11253, lr:4.95e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.361, tt:4433.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.11299, lr:4.90e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.364, tt:4466.267\n",
      "Ep:138, loss:0.00001, loss_test:0.11235, lr:4.85e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.372, tt:4499.774\n",
      "Ep:139, loss:0.00001, loss_test:0.11185, lr:4.80e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.368, tt:4531.553\n",
      "Ep:140, loss:0.00001, loss_test:0.11403, lr:4.75e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.366, tt:4563.589\n",
      "Ep:141, loss:0.00001, loss_test:0.11274, lr:4.71e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.369, tt:4596.424\n",
      "Ep:142, loss:0.00001, loss_test:0.11184, lr:4.66e-03, fs:0.68354 (r=0.545,p=0.915),  time:32.374, tt:4629.475\n",
      "Ep:143, loss:0.00001, loss_test:0.11392, lr:4.61e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.373, tt:4661.725\n",
      "Ep:144, loss:0.00001, loss_test:0.11215, lr:4.57e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.371, tt:4693.821\n",
      "Ep:145, loss:0.00001, loss_test:0.11213, lr:4.52e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.371, tt:4726.133\n",
      "Ep:146, loss:0.00001, loss_test:0.11329, lr:4.48e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.376, tt:4759.292\n",
      "Ep:147, loss:0.00001, loss_test:0.11295, lr:4.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.373, tt:4791.236\n",
      "Ep:148, loss:0.00001, loss_test:0.11192, lr:4.39e-03, fs:0.67516 (r=0.535,p=0.914),  time:32.375, tt:4823.864\n",
      "Ep:149, loss:0.00001, loss_test:0.11466, lr:4.34e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.383, tt:4857.428\n",
      "Ep:150, loss:0.00001, loss_test:0.11301, lr:4.30e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.385, tt:4890.143\n",
      "Ep:151, loss:0.00001, loss_test:0.11217, lr:4.26e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.388, tt:4922.900\n",
      "Ep:152, loss:0.00001, loss_test:0.11422, lr:4.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.393, tt:4956.194\n",
      "Ep:153, loss:0.00001, loss_test:0.11313, lr:4.17e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.401, tt:4989.813\n",
      "Ep:154, loss:0.00001, loss_test:0.11223, lr:4.13e-03, fs:0.66667 (r=0.525,p=0.912),  time:32.405, tt:5022.840\n",
      "Ep:155, loss:0.00001, loss_test:0.11332, lr:4.09e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.405, tt:5055.169\n",
      "Ep:156, loss:0.00001, loss_test:0.11405, lr:4.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.402, tt:5087.074\n",
      "Ep:157, loss:0.00001, loss_test:0.11266, lr:4.01e-03, fs:0.65806 (r=0.515,p=0.911),  time:32.405, tt:5120.028\n",
      "Ep:158, loss:0.00001, loss_test:0.11338, lr:3.97e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.405, tt:5152.419\n",
      "Ep:159, loss:0.00001, loss_test:0.11311, lr:3.93e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.407, tt:5185.070\n",
      "Ep:160, loss:0.00001, loss_test:0.11351, lr:3.89e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.411, tt:5218.237\n",
      "Ep:161, loss:0.00001, loss_test:0.11299, lr:3.85e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.413, tt:5250.916\n",
      "Ep:162, loss:0.00001, loss_test:0.11306, lr:3.81e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.417, tt:5284.011\n",
      "Ep:163, loss:0.00001, loss_test:0.11479, lr:3.77e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.419, tt:5316.674\n",
      "Ep:164, loss:0.00001, loss_test:0.11332, lr:3.73e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.420, tt:5349.245\n",
      "Ep:165, loss:0.00001, loss_test:0.11352, lr:3.70e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.424, tt:5382.460\n",
      "Ep:166, loss:0.00001, loss_test:0.11420, lr:3.66e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.427, tt:5415.385\n",
      "Ep:167, loss:0.00001, loss_test:0.11310, lr:3.62e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.434, tt:5448.899\n",
      "Ep:168, loss:0.00001, loss_test:0.11313, lr:3.59e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.443, tt:5482.890\n",
      "Ep:169, loss:0.00001, loss_test:0.11434, lr:3.55e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.450, tt:5516.569\n",
      "Ep:170, loss:0.00001, loss_test:0.11354, lr:3.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.447, tt:5548.508\n",
      "Ep:171, loss:0.00001, loss_test:0.11303, lr:3.48e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.467, tt:5584.295\n",
      "Ep:172, loss:0.00001, loss_test:0.11481, lr:3.45e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.479, tt:5618.942\n",
      "Ep:173, loss:0.00001, loss_test:0.11354, lr:3.41e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.481, tt:5651.764\n",
      "Ep:174, loss:0.00001, loss_test:0.11301, lr:3.38e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.482, tt:5684.315\n",
      "Ep:175, loss:0.00001, loss_test:0.11438, lr:3.34e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.489, tt:5718.014\n",
      "Ep:176, loss:0.00001, loss_test:0.11350, lr:3.31e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.489, tt:5750.598\n",
      "Ep:177, loss:0.00001, loss_test:0.11340, lr:3.28e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.498, tt:5784.645\n",
      "Ep:178, loss:0.00001, loss_test:0.11433, lr:3.24e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.497, tt:5817.021\n",
      "Ep:179, loss:0.00001, loss_test:0.11338, lr:3.21e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.503, tt:5850.500\n",
      "Ep:180, loss:0.00001, loss_test:0.11325, lr:3.18e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.511, tt:5884.549\n",
      "Ep:181, loss:0.00001, loss_test:0.11370, lr:3.15e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.514, tt:5917.637\n",
      "Ep:182, loss:0.00001, loss_test:0.11411, lr:3.12e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.516, tt:5950.475\n",
      "Ep:183, loss:0.00001, loss_test:0.11322, lr:3.09e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.524, tt:5984.345\n",
      "Ep:184, loss:0.00001, loss_test:0.11358, lr:3.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.528, tt:6017.638\n",
      "Ep:185, loss:0.00001, loss_test:0.11412, lr:3.02e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.525, tt:6049.685\n",
      "Ep:186, loss:0.00001, loss_test:0.11333, lr:2.99e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.533, tt:6083.588\n",
      "Ep:187, loss:0.00001, loss_test:0.11354, lr:2.96e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.539, tt:6117.275\n",
      "Ep:188, loss:0.00001, loss_test:0.11342, lr:2.93e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.539, tt:6149.849\n",
      "Ep:189, loss:0.00001, loss_test:0.11504, lr:2.90e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.536, tt:6181.928\n",
      "Ep:190, loss:0.00001, loss_test:0.11358, lr:2.88e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.536, tt:6214.363\n",
      "Ep:191, loss:0.00001, loss_test:0.11301, lr:2.85e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.534, tt:6246.570\n",
      "Ep:192, loss:0.00001, loss_test:0.11455, lr:2.82e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.562, tt:6284.421\n",
      "Ep:193, loss:0.00001, loss_test:0.11475, lr:2.79e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.569, tt:6318.484\n",
      "Ep:194, loss:0.00001, loss_test:0.11313, lr:2.76e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.566, tt:6350.344\n",
      "Ep:195, loss:0.00001, loss_test:0.11396, lr:2.73e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.567, tt:6383.063\n",
      "Ep:196, loss:0.00001, loss_test:0.11426, lr:2.71e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.565, tt:6415.271\n",
      "Ep:197, loss:0.00001, loss_test:0.11357, lr:2.68e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.569, tt:6448.678\n",
      "Ep:198, loss:0.00001, loss_test:0.11372, lr:2.65e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.561, tt:6479.718\n",
      "Ep:199, loss:0.00001, loss_test:0.11384, lr:2.63e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.558, tt:6511.639\n",
      "Ep:200, loss:0.00001, loss_test:0.11405, lr:2.60e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.547, tt:6541.894\n",
      "Ep:201, loss:0.00001, loss_test:0.11347, lr:2.57e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.528, tt:6570.653\n",
      "Ep:202, loss:0.00001, loss_test:0.11393, lr:2.55e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.503, tt:6598.208\n",
      "Ep:203, loss:0.00001, loss_test:0.11460, lr:2.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.492, tt:6628.393\n",
      "Ep:204, loss:0.00001, loss_test:0.11314, lr:2.50e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.439, tt:6650.080\n",
      "Ep:205, loss:0.00001, loss_test:0.11435, lr:2.47e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.352, tt:6664.564\n",
      "Ep:206, loss:0.00001, loss_test:0.11429, lr:2.45e-03, fs:0.64935 (r=0.505,p=0.909),  time:32.245, tt:6674.728\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14186, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.167, tt:33.167\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14079, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.050, tt:66.099\n",
      "Ep:2, loss:0.00014, loss_test:0.13908, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.787, tt:98.362\n",
      "Ep:3, loss:0.00014, loss_test:0.13656, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:32.275, tt:129.101\n",
      "Ep:4, loss:0.00013, loss_test:0.13330, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:32.379, tt:161.896\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00013, loss_test:0.12861, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:32.491, tt:194.944\n",
      "Ep:6, loss:0.00012, loss_test:0.12293, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:32.589, tt:228.123\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00012, loss_test:0.11928, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:32.506, tt:260.044\n",
      "Ep:8, loss:0.00011, loss_test:0.11776, lr:1.00e-02, fs:0.67299 (r=0.717,p=0.634),  time:32.477, tt:292.292\n",
      "Ep:9, loss:0.00011, loss_test:0.11641, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:32.511, tt:325.109\n",
      "Ep:10, loss:0.00011, loss_test:0.11442, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:32.471, tt:357.176\n",
      "Ep:11, loss:0.00010, loss_test:0.11196, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:32.477, tt:389.723\n",
      "Ep:12, loss:0.00010, loss_test:0.11019, lr:1.00e-02, fs:0.65049 (r=0.677,p=0.626),  time:32.497, tt:422.457\n",
      "Ep:13, loss:0.00010, loss_test:0.10849, lr:1.00e-02, fs:0.66038 (r=0.707,p=0.619),  time:32.440, tt:454.164\n",
      "Ep:14, loss:0.00010, loss_test:0.10664, lr:1.00e-02, fs:0.66029 (r=0.697,p=0.627),  time:32.393, tt:485.890\n",
      "Ep:15, loss:0.00009, loss_test:0.10500, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:32.347, tt:517.544\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.10361, lr:1.00e-02, fs:0.68108 (r=0.636,p=0.733),  time:32.377, tt:550.408\n",
      "Ep:17, loss:0.00009, loss_test:0.10180, lr:1.00e-02, fs:0.70769 (r=0.697,p=0.719),  time:32.404, tt:583.268\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.10057, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:32.393, tt:615.469\n",
      "Ep:19, loss:0.00008, loss_test:0.09967, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:32.378, tt:647.556\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.09883, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:32.385, tt:680.079\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.09801, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:32.401, tt:712.815\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.09690, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:32.470, tt:746.820\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00008, loss_test:0.09594, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:32.528, tt:780.678\n",
      "Ep:24, loss:0.00007, loss_test:0.09510, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:32.556, tt:813.912\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.09428, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:32.599, tt:847.576\n",
      "Ep:26, loss:0.00007, loss_test:0.09390, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:32.641, tt:881.306\n",
      "Ep:27, loss:0.00007, loss_test:0.09303, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:32.657, tt:914.385\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.09241, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:32.622, tt:946.034\n",
      "Ep:29, loss:0.00007, loss_test:0.09192, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:32.626, tt:978.780\n",
      "Ep:30, loss:0.00006, loss_test:0.09133, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:32.597, tt:1010.521\n",
      "Ep:31, loss:0.00006, loss_test:0.09106, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:32.627, tt:1044.065\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.09049, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:32.691, tt:1078.790\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.08996, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:32.722, tt:1112.543\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.08959, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:32.737, tt:1145.792\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.08976, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:32.770, tt:1179.732\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.08948, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:32.757, tt:1212.017\n",
      "Ep:37, loss:0.00005, loss_test:0.08873, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:32.744, tt:1244.256\n",
      "Ep:38, loss:0.00005, loss_test:0.08925, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:32.755, tt:1277.447\n",
      "Ep:39, loss:0.00005, loss_test:0.08875, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:32.740, tt:1309.594\n",
      "Ep:40, loss:0.00005, loss_test:0.08831, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:32.707, tt:1340.971\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.08888, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:32.730, tt:1374.675\n",
      "Ep:42, loss:0.00005, loss_test:0.08776, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.708, tt:1406.437\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.08898, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:32.664, tt:1437.234\n",
      "Ep:44, loss:0.00005, loss_test:0.08841, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.632, tt:1468.446\n",
      "Ep:45, loss:0.00005, loss_test:0.08939, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:32.648, tt:1501.821\n",
      "Ep:46, loss:0.00004, loss_test:0.08916, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.649, tt:1534.517\n",
      "Ep:47, loss:0.00004, loss_test:0.08858, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.621, tt:1565.788\n",
      "Ep:48, loss:0.00004, loss_test:0.08986, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:32.638, tt:1599.264\n",
      "Ep:49, loss:0.00004, loss_test:0.08876, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.640, tt:1631.995\n",
      "Ep:50, loss:0.00004, loss_test:0.09005, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:32.651, tt:1665.194\n",
      "Ep:51, loss:0.00004, loss_test:0.08822, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.661, tt:1698.375\n",
      "Ep:52, loss:0.00004, loss_test:0.09025, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:32.696, tt:1732.871\n",
      "Ep:53, loss:0.00004, loss_test:0.08894, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:32.690, tt:1765.274\n",
      "Ep:54, loss:0.00004, loss_test:0.09040, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.689, tt:1797.877\n",
      "Ep:55, loss:0.00004, loss_test:0.08905, lr:9.80e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.688, tt:1830.533\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00004, loss_test:0.08955, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.710, tt:1864.472\n",
      "Ep:57, loss:0.00004, loss_test:0.09049, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.730, tt:1898.356\n",
      "Ep:58, loss:0.00003, loss_test:0.08926, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.734, tt:1931.284\n",
      "Ep:59, loss:0.00003, loss_test:0.09021, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.742, tt:1964.527\n",
      "Ep:60, loss:0.00003, loss_test:0.08880, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.762, tt:1998.495\n",
      "Ep:61, loss:0.00003, loss_test:0.09182, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.796, tt:2033.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.08936, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.797, tt:2066.242\n",
      "Ep:63, loss:0.00003, loss_test:0.09086, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.808, tt:2099.727\n",
      "Ep:64, loss:0.00003, loss_test:0.08970, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.810, tt:2132.646\n",
      "Ep:65, loss:0.00003, loss_test:0.09169, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.811, tt:2165.505\n",
      "Ep:66, loss:0.00003, loss_test:0.09056, lr:9.80e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.808, tt:2198.140\n",
      "Ep:67, loss:0.00003, loss_test:0.09082, lr:9.70e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.818, tt:2231.591\n",
      "Ep:68, loss:0.00003, loss_test:0.09216, lr:9.61e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.821, tt:2264.658\n",
      "Ep:69, loss:0.00003, loss_test:0.09226, lr:9.51e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.830, tt:2298.069\n",
      "Ep:70, loss:0.00003, loss_test:0.09137, lr:9.41e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.840, tt:2331.608\n",
      "Ep:71, loss:0.00003, loss_test:0.09349, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:32.859, tt:2365.853\n",
      "Ep:72, loss:0.00003, loss_test:0.09217, lr:9.23e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.844, tt:2397.585\n",
      "Ep:73, loss:0.00003, loss_test:0.09439, lr:9.14e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.832, tt:2429.536\n",
      "Ep:74, loss:0.00003, loss_test:0.09494, lr:9.04e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.830, tt:2462.261\n",
      "Ep:75, loss:0.00002, loss_test:0.09340, lr:8.95e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.829, tt:2495.012\n",
      "Ep:76, loss:0.00002, loss_test:0.09625, lr:8.86e-03, fs:0.77381 (r=0.657,p=0.942),  time:32.839, tt:2528.599\n",
      "Ep:77, loss:0.00002, loss_test:0.09511, lr:8.78e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.836, tt:2561.224\n",
      "Ep:78, loss:0.00002, loss_test:0.09451, lr:8.69e-03, fs:0.78824 (r=0.677,p=0.944),  time:32.841, tt:2594.426\n",
      "Ep:79, loss:0.00002, loss_test:0.09822, lr:8.60e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.851, tt:2628.062\n",
      "Ep:80, loss:0.00002, loss_test:0.09522, lr:8.51e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.854, tt:2661.213\n",
      "Ep:81, loss:0.00002, loss_test:0.09516, lr:8.43e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.848, tt:2693.516\n",
      "Ep:82, loss:0.00002, loss_test:0.09874, lr:8.35e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.858, tt:2727.255\n",
      "Ep:83, loss:0.00002, loss_test:0.09484, lr:8.26e-03, fs:0.78107 (r=0.667,p=0.943),  time:32.863, tt:2760.465\n",
      "Ep:84, loss:0.00002, loss_test:0.09783, lr:8.18e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.872, tt:2794.104\n",
      "Ep:85, loss:0.00002, loss_test:0.09538, lr:8.10e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.889, tt:2828.487\n",
      "Ep:86, loss:0.00002, loss_test:0.09975, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.893, tt:2861.716\n",
      "Ep:87, loss:0.00002, loss_test:0.09636, lr:7.94e-03, fs:0.75152 (r=0.626,p=0.939),  time:32.879, tt:2893.355\n",
      "Ep:88, loss:0.00002, loss_test:0.09740, lr:7.86e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.883, tt:2926.602\n",
      "Ep:89, loss:0.00002, loss_test:0.09868, lr:7.78e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.871, tt:2958.368\n",
      "Ep:90, loss:0.00002, loss_test:0.09757, lr:7.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.873, tt:2991.480\n",
      "Ep:91, loss:0.00002, loss_test:0.09998, lr:7.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.876, tt:3024.631\n",
      "Ep:92, loss:0.00002, loss_test:0.09821, lr:7.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.862, tt:3056.165\n",
      "Ep:93, loss:0.00002, loss_test:0.10024, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.860, tt:3088.794\n",
      "Ep:94, loss:0.00002, loss_test:0.09868, lr:7.40e-03, fs:0.74390 (r=0.616,p=0.938),  time:32.858, tt:3121.477\n",
      "Ep:95, loss:0.00002, loss_test:0.09913, lr:7.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.870, tt:3155.503\n",
      "Ep:96, loss:0.00002, loss_test:0.10048, lr:7.25e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.870, tt:3188.406\n",
      "Ep:97, loss:0.00002, loss_test:0.09923, lr:7.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.857, tt:3219.953\n",
      "Ep:98, loss:0.00002, loss_test:0.09934, lr:7.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.869, tt:3254.071\n",
      "Ep:99, loss:0.00002, loss_test:0.10027, lr:7.03e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.860, tt:3286.042\n",
      "Ep:100, loss:0.00002, loss_test:0.10064, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.857, tt:3318.581\n",
      "Ep:101, loss:0.00002, loss_test:0.10039, lr:6.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.852, tt:3350.880\n",
      "Ep:102, loss:0.00002, loss_test:0.10179, lr:6.83e-03, fs:0.70440 (r=0.566,p=0.933),  time:32.858, tt:3384.333\n",
      "Ep:103, loss:0.00002, loss_test:0.10128, lr:6.76e-03, fs:0.68790 (r=0.545,p=0.931),  time:32.856, tt:3417.048\n",
      "Ep:104, loss:0.00002, loss_test:0.10046, lr:6.69e-03, fs:0.73620 (r=0.606,p=0.938),  time:32.841, tt:3448.275\n",
      "Ep:105, loss:0.00002, loss_test:0.10209, lr:6.62e-03, fs:0.68790 (r=0.545,p=0.931),  time:32.840, tt:3481.001\n",
      "Ep:106, loss:0.00002, loss_test:0.10119, lr:6.56e-03, fs:0.69620 (r=0.556,p=0.932),  time:32.841, tt:3514.002\n",
      "Ep:107, loss:0.00001, loss_test:0.10155, lr:6.49e-03, fs:0.68790 (r=0.545,p=0.931),  time:32.865, tt:3549.413\n",
      "Ep:108, loss:0.00001, loss_test:0.10121, lr:6.43e-03, fs:0.71250 (r=0.576,p=0.934),  time:32.858, tt:3581.521\n",
      "Ep:109, loss:0.00001, loss_test:0.10143, lr:6.36e-03, fs:0.67949 (r=0.535,p=0.930),  time:32.864, tt:3615.087\n",
      "Ep:110, loss:0.00001, loss_test:0.10126, lr:6.30e-03, fs:0.67097 (r=0.525,p=0.929),  time:32.850, tt:3646.358\n",
      "Ep:111, loss:0.00001, loss_test:0.10258, lr:6.24e-03, fs:0.66234 (r=0.515,p=0.927),  time:32.839, tt:3678.006\n",
      "Ep:112, loss:0.00001, loss_test:0.10134, lr:6.17e-03, fs:0.67949 (r=0.535,p=0.930),  time:32.836, tt:3710.449\n",
      "Ep:113, loss:0.00001, loss_test:0.10299, lr:6.11e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.832, tt:3742.804\n",
      "Ep:114, loss:0.00001, loss_test:0.10223, lr:6.05e-03, fs:0.66667 (r=0.515,p=0.944),  time:32.833, tt:3775.786\n",
      "Ep:115, loss:0.00001, loss_test:0.10155, lr:5.99e-03, fs:0.68387 (r=0.535,p=0.946),  time:32.835, tt:3808.889\n",
      "Ep:116, loss:0.00001, loss_test:0.10272, lr:5.93e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.821, tt:3840.021\n",
      "Ep:117, loss:0.00001, loss_test:0.10165, lr:5.87e-03, fs:0.67532 (r=0.525,p=0.945),  time:32.819, tt:3872.668\n",
      "Ep:118, loss:0.00001, loss_test:0.10255, lr:5.81e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.829, tt:3906.628\n",
      "Ep:119, loss:0.00001, loss_test:0.10225, lr:5.75e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.820, tt:3938.423\n",
      "Ep:120, loss:0.00001, loss_test:0.10232, lr:5.70e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.819, tt:3971.114\n",
      "Ep:121, loss:0.00001, loss_test:0.10216, lr:5.64e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.832, tt:4005.557\n",
      "Ep:122, loss:0.00001, loss_test:0.10220, lr:5.58e-03, fs:0.66667 (r=0.515,p=0.944),  time:32.836, tt:4038.832\n",
      "Ep:123, loss:0.00001, loss_test:0.10201, lr:5.53e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.820, tt:4069.619\n",
      "Ep:124, loss:0.00001, loss_test:0.10314, lr:5.47e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.806, tt:4100.740\n",
      "Ep:125, loss:0.00001, loss_test:0.10248, lr:5.42e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.809, tt:4133.931\n",
      "Ep:126, loss:0.00001, loss_test:0.10241, lr:5.36e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.820, tt:4168.154\n",
      "Ep:127, loss:0.00001, loss_test:0.10313, lr:5.31e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.821, tt:4201.061\n",
      "Ep:128, loss:0.00001, loss_test:0.10189, lr:5.26e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.824, tt:4234.252\n",
      "Ep:129, loss:0.00001, loss_test:0.10344, lr:5.20e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.835, tt:4268.601\n",
      "Ep:130, loss:0.00001, loss_test:0.10305, lr:5.15e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.833, tt:4301.081\n",
      "Ep:131, loss:0.00001, loss_test:0.10178, lr:5.10e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.828, tt:4333.277\n",
      "Ep:132, loss:0.00001, loss_test:0.10357, lr:5.05e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.829, tt:4366.254\n",
      "Ep:133, loss:0.00001, loss_test:0.10228, lr:5.00e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.846, tt:4401.349\n",
      "Ep:134, loss:0.00001, loss_test:0.10320, lr:4.95e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.848, tt:4434.496\n",
      "Ep:135, loss:0.00001, loss_test:0.10412, lr:4.90e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.855, tt:4468.259\n",
      "Ep:136, loss:0.00001, loss_test:0.10290, lr:4.85e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.858, tt:4501.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.10337, lr:4.80e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.856, tt:4534.079\n",
      "Ep:138, loss:0.00001, loss_test:0.10354, lr:4.75e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.851, tt:4566.298\n",
      "Ep:139, loss:0.00001, loss_test:0.10325, lr:4.71e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.860, tt:4600.360\n",
      "Ep:140, loss:0.00001, loss_test:0.10371, lr:4.66e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.872, tt:4635.012\n",
      "Ep:141, loss:0.00001, loss_test:0.10357, lr:4.61e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.874, tt:4668.148\n",
      "Ep:142, loss:0.00001, loss_test:0.10366, lr:4.57e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.875, tt:4701.173\n",
      "Ep:143, loss:0.00001, loss_test:0.10342, lr:4.52e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.881, tt:4734.839\n",
      "Ep:144, loss:0.00001, loss_test:0.10474, lr:4.48e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.886, tt:4768.415\n",
      "Ep:145, loss:0.00001, loss_test:0.10323, lr:4.43e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.891, tt:4802.101\n",
      "Ep:146, loss:0.00001, loss_test:0.10411, lr:4.39e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.895, tt:4835.607\n",
      "Ep:147, loss:0.00001, loss_test:0.10480, lr:4.34e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.895, tt:4868.482\n",
      "Ep:148, loss:0.00001, loss_test:0.10312, lr:4.30e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.897, tt:4901.581\n",
      "Ep:149, loss:0.00001, loss_test:0.10458, lr:4.26e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.903, tt:4935.384\n",
      "Ep:150, loss:0.00001, loss_test:0.10510, lr:4.21e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.927, tt:4972.043\n",
      "Ep:151, loss:0.00001, loss_test:0.10334, lr:4.17e-03, fs:0.65789 (r=0.505,p=0.943),  time:32.923, tt:5004.339\n",
      "Ep:152, loss:0.00001, loss_test:0.10500, lr:4.13e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.928, tt:5037.917\n",
      "Ep:153, loss:0.00001, loss_test:0.10464, lr:4.09e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.932, tt:5071.511\n",
      "Ep:154, loss:0.00001, loss_test:0.10400, lr:4.05e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.934, tt:5104.778\n",
      "Ep:155, loss:0.00001, loss_test:0.10459, lr:4.01e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.929, tt:5136.993\n",
      "Ep:156, loss:0.00001, loss_test:0.10470, lr:3.97e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.931, tt:5170.245\n",
      "Ep:157, loss:0.00001, loss_test:0.10470, lr:3.93e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.932, tt:5203.279\n",
      "Ep:158, loss:0.00001, loss_test:0.10433, lr:3.89e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.933, tt:5236.414\n",
      "Ep:159, loss:0.00001, loss_test:0.10536, lr:3.85e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.936, tt:5269.704\n",
      "Ep:160, loss:0.00001, loss_test:0.10503, lr:3.81e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.928, tt:5301.447\n",
      "Ep:161, loss:0.00001, loss_test:0.10500, lr:3.77e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.923, tt:5333.587\n",
      "Ep:162, loss:0.00001, loss_test:0.10536, lr:3.73e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.925, tt:5366.770\n",
      "Ep:163, loss:0.00001, loss_test:0.10574, lr:3.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.924, tt:5399.542\n",
      "Ep:164, loss:0.00001, loss_test:0.10497, lr:3.66e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.926, tt:5432.815\n",
      "Ep:165, loss:0.00001, loss_test:0.10521, lr:3.62e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.922, tt:5464.975\n",
      "Ep:166, loss:0.00001, loss_test:0.10623, lr:3.59e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.923, tt:5498.127\n",
      "Ep:167, loss:0.00001, loss_test:0.10490, lr:3.55e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.920, tt:5530.494\n",
      "Ep:168, loss:0.00001, loss_test:0.10531, lr:3.52e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.913, tt:5562.329\n",
      "Ep:169, loss:0.00001, loss_test:0.10567, lr:3.48e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.912, tt:5595.027\n",
      "Ep:170, loss:0.00001, loss_test:0.10639, lr:3.45e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.914, tt:5628.263\n",
      "Ep:171, loss:0.00001, loss_test:0.10544, lr:3.41e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.906, tt:5659.873\n",
      "Ep:172, loss:0.00001, loss_test:0.10612, lr:3.38e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.912, tt:5693.745\n",
      "Ep:173, loss:0.00001, loss_test:0.10598, lr:3.34e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.910, tt:5726.272\n",
      "Ep:174, loss:0.00001, loss_test:0.10575, lr:3.31e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.909, tt:5759.083\n",
      "Ep:175, loss:0.00001, loss_test:0.10625, lr:3.28e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.913, tt:5792.615\n",
      "Ep:176, loss:0.00001, loss_test:0.10620, lr:3.24e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.912, tt:5825.429\n",
      "Ep:177, loss:0.00001, loss_test:0.10596, lr:3.21e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.908, tt:5857.708\n",
      "Ep:178, loss:0.00001, loss_test:0.10597, lr:3.18e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.909, tt:5890.744\n",
      "Ep:179, loss:0.00001, loss_test:0.10584, lr:3.15e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.907, tt:5923.259\n",
      "Ep:180, loss:0.00001, loss_test:0.10617, lr:3.12e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.906, tt:5955.963\n",
      "Ep:181, loss:0.00001, loss_test:0.10591, lr:3.09e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.911, tt:5989.858\n",
      "Ep:182, loss:0.00001, loss_test:0.10626, lr:3.05e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.909, tt:6022.405\n",
      "Ep:183, loss:0.00001, loss_test:0.10599, lr:3.02e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.907, tt:6054.917\n",
      "Ep:184, loss:0.00001, loss_test:0.10638, lr:2.99e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.903, tt:6086.988\n",
      "Ep:185, loss:0.00001, loss_test:0.10622, lr:2.96e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.899, tt:6119.267\n",
      "Ep:186, loss:0.00001, loss_test:0.10608, lr:2.93e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.898, tt:6151.950\n",
      "Ep:187, loss:0.00001, loss_test:0.10643, lr:2.90e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.896, tt:6184.505\n",
      "Ep:188, loss:0.00001, loss_test:0.10630, lr:2.88e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.901, tt:6218.336\n",
      "Ep:189, loss:0.00001, loss_test:0.10588, lr:2.85e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.908, tt:6252.464\n",
      "Ep:190, loss:0.00001, loss_test:0.10746, lr:2.82e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.912, tt:6286.159\n",
      "Ep:191, loss:0.00001, loss_test:0.10601, lr:2.79e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.946, tt:6325.539\n",
      "Ep:192, loss:0.00001, loss_test:0.10591, lr:2.76e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.931, tt:6355.725\n",
      "Ep:193, loss:0.00001, loss_test:0.10716, lr:2.73e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.930, tt:6388.379\n",
      "Ep:194, loss:0.00001, loss_test:0.10636, lr:2.71e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.931, tt:6421.460\n",
      "Ep:195, loss:0.00001, loss_test:0.10599, lr:2.68e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.928, tt:6453.976\n",
      "Ep:196, loss:0.00001, loss_test:0.10668, lr:2.65e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.938, tt:6488.729\n",
      "Ep:197, loss:0.00001, loss_test:0.10652, lr:2.63e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.931, tt:6520.254\n",
      "Ep:198, loss:0.00001, loss_test:0.10603, lr:2.60e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.924, tt:6551.941\n",
      "Ep:199, loss:0.00001, loss_test:0.10654, lr:2.57e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.927, tt:6585.312\n",
      "Ep:200, loss:0.00001, loss_test:0.10654, lr:2.55e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.920, tt:6616.976\n",
      "Ep:201, loss:0.00001, loss_test:0.10627, lr:2.52e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.914, tt:6648.648\n",
      "Ep:202, loss:0.00001, loss_test:0.10681, lr:2.50e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.916, tt:6681.983\n",
      "Ep:203, loss:0.00001, loss_test:0.10644, lr:2.47e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.919, tt:6715.542\n",
      "Ep:204, loss:0.00001, loss_test:0.10618, lr:2.45e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.898, tt:6743.994\n",
      "Ep:205, loss:0.00001, loss_test:0.10688, lr:2.42e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.854, tt:6767.957\n",
      "Ep:206, loss:0.00001, loss_test:0.10653, lr:2.40e-03, fs:0.66225 (r=0.505,p=0.962),  time:32.752, tt:6779.583\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14274, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:63.575, tt:63.575\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13783, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:65.251, tt:130.502\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.12837, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:65.509, tt:196.526\n",
      "Ep:3, loss:0.00046, loss_test:0.12539, lr:1.00e-02, fs:0.62857 (r=0.667,p=0.595),  time:65.662, tt:262.649\n",
      "Ep:4, loss:0.00044, loss_test:0.11921, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:65.645, tt:328.223\n",
      "Ep:5, loss:0.00042, loss_test:0.11505, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:65.903, tt:395.418\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00039, loss_test:0.10929, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:65.640, tt:459.480\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00037, loss_test:0.10588, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:65.814, tt:526.515\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00035, loss_test:0.10384, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:65.725, tt:591.522\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00033, loss_test:0.10144, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:65.685, tt:656.853\n",
      "Ep:10, loss:0.00031, loss_test:0.09916, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:65.777, tt:723.551\n",
      "Ep:11, loss:0.00030, loss_test:0.09650, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:65.921, tt:791.055\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00028, loss_test:0.09375, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:65.897, tt:856.663\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00027, loss_test:0.09155, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:65.844, tt:921.821\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00025, loss_test:0.08982, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:65.873, tt:988.094\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.08761, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:66.015, tt:1056.244\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.08705, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:65.892, tt:1120.171\n",
      "Ep:17, loss:0.00022, loss_test:0.08439, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:65.869, tt:1185.635\n",
      "Ep:18, loss:0.00021, loss_test:0.08451, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:65.904, tt:1252.175\n",
      "Ep:19, loss:0.00020, loss_test:0.08410, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:65.814, tt:1316.282\n",
      "Ep:20, loss:0.00019, loss_test:0.08336, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:65.905, tt:1384.013\n",
      "Ep:21, loss:0.00018, loss_test:0.08138, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:65.778, tt:1447.116\n",
      "Ep:22, loss:0.00017, loss_test:0.08059, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:65.684, tt:1510.727\n",
      "Ep:23, loss:0.00017, loss_test:0.07977, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:65.676, tt:1576.228\n",
      "Ep:24, loss:0.00016, loss_test:0.08227, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:65.647, tt:1641.176\n",
      "Ep:25, loss:0.00016, loss_test:0.07845, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:65.703, tt:1708.287\n",
      "Ep:26, loss:0.00015, loss_test:0.07674, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:65.712, tt:1774.234\n",
      "Ep:27, loss:0.00014, loss_test:0.08164, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:65.719, tt:1840.124\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08768, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:65.744, tt:1906.568\n",
      "Ep:29, loss:0.00013, loss_test:0.08879, lr:9.90e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.733, tt:1971.995\n",
      "Ep:30, loss:0.00013, loss_test:0.09138, lr:9.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:65.712, tt:2037.059\n",
      "Ep:31, loss:0.00012, loss_test:0.08647, lr:9.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:65.678, tt:2101.697\n",
      "Ep:32, loss:0.00011, loss_test:0.08000, lr:9.90e-03, fs:0.86631 (r=0.818,p=0.920),  time:65.666, tt:2166.981\n",
      "Ep:33, loss:0.00011, loss_test:0.08010, lr:9.90e-03, fs:0.87234 (r=0.828,p=0.921),  time:65.660, tt:2232.432\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08172, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:65.635, tt:2297.217\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08335, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:65.603, tt:2361.692\n",
      "Ep:36, loss:0.00009, loss_test:0.08595, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.633, tt:2428.424\n",
      "Ep:37, loss:0.00009, loss_test:0.08623, lr:9.90e-03, fs:0.78363 (r=0.677,p=0.931),  time:65.626, tt:2493.775\n",
      "Ep:38, loss:0.00008, loss_test:0.08814, lr:9.90e-03, fs:0.74699 (r=0.626,p=0.925),  time:65.640, tt:2559.977\n",
      "Ep:39, loss:0.00008, loss_test:0.08961, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:65.670, tt:2626.792\n",
      "Ep:40, loss:0.00008, loss_test:0.09394, lr:9.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:65.674, tt:2692.631\n",
      "Ep:41, loss:0.00008, loss_test:0.09094, lr:9.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:65.621, tt:2756.074\n",
      "Ep:42, loss:0.00007, loss_test:0.08551, lr:9.90e-03, fs:0.77647 (r=0.667,p=0.930),  time:65.624, tt:2821.852\n",
      "Ep:43, loss:0.00007, loss_test:0.09016, lr:9.90e-03, fs:0.72050 (r=0.586,p=0.935),  time:65.594, tt:2886.123\n",
      "Ep:44, loss:0.00007, loss_test:0.09212, lr:9.90e-03, fs:0.67532 (r=0.525,p=0.945),  time:65.586, tt:2951.350\n",
      "Ep:45, loss:0.00006, loss_test:0.08980, lr:9.90e-03, fs:0.70064 (r=0.556,p=0.948),  time:65.580, tt:3016.669\n",
      "Ep:46, loss:0.00006, loss_test:0.09020, lr:9.80e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.641, tt:3085.125\n",
      "Ep:47, loss:0.00006, loss_test:0.09369, lr:9.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.637, tt:3150.599\n",
      "Ep:48, loss:0.00006, loss_test:0.09145, lr:9.61e-03, fs:0.67532 (r=0.525,p=0.945),  time:65.609, tt:3214.858\n",
      "Ep:49, loss:0.00005, loss_test:0.09346, lr:9.51e-03, fs:0.67974 (r=0.525,p=0.963),  time:65.592, tt:3279.613\n",
      "Ep:50, loss:0.00005, loss_test:0.09268, lr:9.41e-03, fs:0.67532 (r=0.525,p=0.945),  time:65.615, tt:3346.353\n",
      "Ep:51, loss:0.00005, loss_test:0.09305, lr:9.32e-03, fs:0.68387 (r=0.535,p=0.946),  time:65.584, tt:3410.369\n",
      "Ep:52, loss:0.00004, loss_test:0.09638, lr:9.23e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.545, tt:3473.882\n",
      "Ep:53, loss:0.00004, loss_test:0.09873, lr:9.14e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.567, tt:3540.633\n",
      "Ep:54, loss:0.00004, loss_test:0.10057, lr:9.04e-03, fs:0.67105 (r=0.515,p=0.962),  time:65.551, tt:3605.282\n",
      "Ep:55, loss:0.00004, loss_test:0.10289, lr:8.95e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.534, tt:3669.910\n",
      "Ep:56, loss:0.00004, loss_test:0.10114, lr:8.86e-03, fs:0.66667 (r=0.515,p=0.944),  time:65.532, tt:3735.301\n",
      "Ep:57, loss:0.00004, loss_test:0.09643, lr:8.78e-03, fs:0.68387 (r=0.535,p=0.946),  time:65.540, tt:3801.319\n",
      "Ep:58, loss:0.00003, loss_test:0.09926, lr:8.69e-03, fs:0.69231 (r=0.545,p=0.947),  time:65.630, tt:3872.174\n",
      "Ep:59, loss:0.00003, loss_test:0.10074, lr:8.60e-03, fs:0.69231 (r=0.545,p=0.947),  time:65.612, tt:3936.746\n",
      "Ep:60, loss:0.00003, loss_test:0.10057, lr:8.51e-03, fs:0.69231 (r=0.545,p=0.947),  time:65.635, tt:4003.753\n",
      "Ep:61, loss:0.00003, loss_test:0.09839, lr:8.43e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.625, tt:4068.739\n",
      "Ep:62, loss:0.00003, loss_test:0.09819, lr:8.35e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.614, tt:4133.694\n",
      "Ep:63, loss:0.00003, loss_test:0.10290, lr:8.26e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.584, tt:4197.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00003, loss_test:0.09949, lr:8.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:65.575, tt:4262.383\n",
      "Ep:65, loss:0.00003, loss_test:0.09844, lr:8.10e-03, fs:0.69677 (r=0.545,p=0.964),  time:65.596, tt:4329.362\n",
      "Ep:66, loss:0.00003, loss_test:0.10338, lr:8.02e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.601, tt:4395.279\n",
      "Ep:67, loss:0.00003, loss_test:0.10381, lr:7.94e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.574, tt:4459.062\n",
      "Ep:68, loss:0.00002, loss_test:0.10276, lr:7.86e-03, fs:0.68831 (r=0.535,p=0.964),  time:65.588, tt:4525.551\n",
      "Ep:69, loss:0.00002, loss_test:0.10242, lr:7.78e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.608, tt:4592.562\n",
      "Ep:70, loss:0.00002, loss_test:0.10090, lr:7.70e-03, fs:0.66225 (r=0.505,p=0.962),  time:65.617, tt:4658.835\n",
      "Ep:71, loss:0.00002, loss_test:0.10012, lr:7.62e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.612, tt:4724.029\n",
      "Ep:72, loss:0.00002, loss_test:0.09954, lr:7.55e-03, fs:0.70130 (r=0.545,p=0.982),  time:65.614, tt:4789.853\n",
      "Ep:73, loss:0.00002, loss_test:0.10206, lr:7.47e-03, fs:0.67105 (r=0.515,p=0.962),  time:65.632, tt:4856.756\n",
      "Ep:74, loss:0.00002, loss_test:0.10579, lr:7.40e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.640, tt:4923.008\n",
      "Ep:75, loss:0.00002, loss_test:0.10327, lr:7.32e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.612, tt:4986.523\n",
      "Ep:76, loss:0.00002, loss_test:0.10090, lr:7.25e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.610, tt:5051.990\n",
      "Ep:77, loss:0.00002, loss_test:0.10290, lr:7.18e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.577, tt:5115.021\n",
      "Ep:78, loss:0.00002, loss_test:0.10453, lr:7.11e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.611, tt:5183.297\n",
      "Ep:79, loss:0.00002, loss_test:0.10224, lr:7.03e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.582, tt:5246.563\n",
      "Ep:80, loss:0.00002, loss_test:0.10426, lr:6.96e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.566, tt:5310.814\n",
      "Ep:81, loss:0.00002, loss_test:0.10551, lr:6.89e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.544, tt:5374.642\n",
      "Ep:82, loss:0.00002, loss_test:0.10291, lr:6.83e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.578, tt:5442.989\n",
      "Ep:83, loss:0.00002, loss_test:0.10543, lr:6.76e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.609, tt:5511.148\n",
      "Ep:84, loss:0.00002, loss_test:0.10562, lr:6.69e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.624, tt:5578.008\n",
      "Ep:85, loss:0.00002, loss_test:0.10477, lr:6.62e-03, fs:0.67550 (r=0.515,p=0.981),  time:65.634, tt:5644.538\n",
      "Ep:86, loss:0.00002, loss_test:0.10547, lr:6.56e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.623, tt:5709.209\n",
      "Ep:87, loss:0.00001, loss_test:0.10733, lr:6.49e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.630, tt:5775.448\n",
      "Ep:88, loss:0.00001, loss_test:0.10330, lr:6.43e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.635, tt:5841.537\n",
      "Ep:89, loss:0.00001, loss_test:0.10541, lr:6.36e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.645, tt:5908.049\n",
      "Ep:90, loss:0.00001, loss_test:0.10869, lr:6.30e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.661, tt:5975.171\n",
      "Ep:91, loss:0.00001, loss_test:0.10484, lr:6.24e-03, fs:0.66667 (r=0.505,p=0.980),  time:65.667, tt:6041.349\n",
      "Ep:92, loss:0.00001, loss_test:0.10912, lr:6.17e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.661, tt:6106.448\n",
      "Ep:93, loss:0.00001, loss_test:0.10814, lr:6.11e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.679, tt:6173.799\n",
      "Ep:94, loss:0.00001, loss_test:0.10587, lr:6.05e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.656, tt:6237.277\n",
      "Ep:95, loss:0.00001, loss_test:0.10505, lr:5.99e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.657, tt:6303.056\n",
      "Ep:96, loss:0.00001, loss_test:0.10835, lr:5.93e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.646, tt:6367.651\n",
      "Ep:97, loss:0.00001, loss_test:0.10828, lr:5.87e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.682, tt:6436.812\n",
      "Ep:98, loss:0.00001, loss_test:0.10427, lr:5.81e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.680, tt:6502.359\n",
      "Ep:99, loss:0.00001, loss_test:0.10973, lr:5.75e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.674, tt:6567.351\n",
      "Ep:100, loss:0.00001, loss_test:0.10503, lr:5.70e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.675, tt:6633.174\n",
      "Ep:101, loss:0.00001, loss_test:0.10823, lr:5.64e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.682, tt:6699.587\n",
      "Ep:102, loss:0.00001, loss_test:0.10966, lr:5.58e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.668, tt:6763.755\n",
      "Ep:103, loss:0.00001, loss_test:0.10643, lr:5.53e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.664, tt:6829.084\n",
      "Ep:104, loss:0.00001, loss_test:0.10799, lr:5.47e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.654, tt:6893.686\n",
      "Ep:105, loss:0.00001, loss_test:0.10846, lr:5.42e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.652, tt:6959.141\n",
      "Ep:106, loss:0.00001, loss_test:0.10899, lr:5.36e-03, fs:0.67114 (r=0.505,p=1.000),  time:65.298, tt:6986.858\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14580, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.459, tt:13.459\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14563, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.325, tt:28.650\n",
      "Ep:2, loss:0.00014, loss_test:0.14537, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.480, tt:43.440\n",
      "Ep:3, loss:0.00014, loss_test:0.14501, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.654, tt:58.615\n",
      "Ep:4, loss:0.00014, loss_test:0.14455, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.930, tt:74.650\n",
      "Ep:5, loss:0.00014, loss_test:0.14398, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.893, tt:89.361\n",
      "Ep:6, loss:0.00014, loss_test:0.14326, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.006, tt:105.039\n",
      "Ep:7, loss:0.00014, loss_test:0.14236, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.014, tt:120.114\n",
      "Ep:8, loss:0.00014, loss_test:0.14128, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.981, tt:134.826\n",
      "Ep:9, loss:0.00013, loss_test:0.13992, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:15.003, tt:150.033\n",
      "Ep:10, loss:0.00013, loss_test:0.13825, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:15.035, tt:165.384\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00013, loss_test:0.13623, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:15.024, tt:180.293\n",
      "Ep:12, loss:0.00013, loss_test:0.13390, lr:1.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:15.004, tt:195.056\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00012, loss_test:0.13146, lr:1.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:15.048, tt:210.669\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00012, loss_test:0.12938, lr:1.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:15.038, tt:225.574\n",
      "Ep:15, loss:0.00012, loss_test:0.12790, lr:1.00e-02, fs:0.62712 (r=0.747,p=0.540),  time:15.073, tt:241.166\n",
      "Ep:16, loss:0.00011, loss_test:0.12724, lr:1.00e-02, fs:0.64220 (r=0.707,p=0.588),  time:15.077, tt:256.302\n",
      "Ep:17, loss:0.00011, loss_test:0.12701, lr:1.00e-02, fs:0.64455 (r=0.687,p=0.607),  time:15.000, tt:270.000\n",
      "Ep:18, loss:0.00011, loss_test:0.12657, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:14.970, tt:284.420\n",
      "Ep:19, loss:0.00011, loss_test:0.12535, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:14.983, tt:299.652\n",
      "Ep:20, loss:0.00011, loss_test:0.12363, lr:1.00e-02, fs:0.65385 (r=0.687,p=0.624),  time:14.995, tt:314.903\n",
      "Ep:21, loss:0.00010, loss_test:0.12201, lr:1.00e-02, fs:0.66351 (r=0.707,p=0.625),  time:14.965, tt:329.222\n",
      "Ep:22, loss:0.00010, loss_test:0.12080, lr:1.00e-02, fs:0.66047 (r=0.717,p=0.612),  time:14.965, tt:344.195\n",
      "Ep:23, loss:0.00010, loss_test:0.11986, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:14.899, tt:357.582\n",
      "Ep:24, loss:0.00010, loss_test:0.11879, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:14.854, tt:371.349\n",
      "Ep:25, loss:0.00010, loss_test:0.11808, lr:9.90e-03, fs:0.63107 (r=0.657,p=0.607),  time:14.823, tt:385.401\n",
      "Ep:26, loss:0.00009, loss_test:0.11811, lr:9.80e-03, fs:0.61000 (r=0.616,p=0.604),  time:14.803, tt:399.693\n",
      "Ep:27, loss:0.00009, loss_test:0.11803, lr:9.70e-03, fs:0.59898 (r=0.596,p=0.602),  time:14.789, tt:414.079\n",
      "Ep:28, loss:0.00009, loss_test:0.11740, lr:9.61e-03, fs:0.60606 (r=0.606,p=0.606),  time:14.793, tt:428.995\n",
      "Ep:29, loss:0.00009, loss_test:0.11666, lr:9.51e-03, fs:0.60302 (r=0.606,p=0.600),  time:14.806, tt:444.166\n",
      "Ep:30, loss:0.00009, loss_test:0.11580, lr:9.41e-03, fs:0.60302 (r=0.606,p=0.600),  time:14.787, tt:458.389\n",
      "Ep:31, loss:0.00009, loss_test:0.11512, lr:9.32e-03, fs:0.61692 (r=0.626,p=0.608),  time:14.808, tt:473.869\n",
      "Ep:32, loss:0.00009, loss_test:0.11489, lr:9.23e-03, fs:0.62312 (r=0.626,p=0.620),  time:14.777, tt:487.636\n",
      "Ep:33, loss:0.00008, loss_test:0.11520, lr:9.14e-03, fs:0.60204 (r=0.596,p=0.608),  time:14.778, tt:502.463\n",
      "Ep:34, loss:0.00008, loss_test:0.11551, lr:9.04e-03, fs:0.59487 (r=0.586,p=0.604),  time:14.791, tt:517.672\n",
      "Ep:35, loss:0.00008, loss_test:0.11545, lr:8.95e-03, fs:0.61616 (r=0.616,p=0.616),  time:14.786, tt:532.279\n",
      "Ep:36, loss:0.00008, loss_test:0.11521, lr:8.86e-03, fs:0.62312 (r=0.626,p=0.620),  time:14.807, tt:547.858\n",
      "Ep:37, loss:0.00008, loss_test:0.11491, lr:8.78e-03, fs:0.62000 (r=0.626,p=0.614),  time:14.814, tt:562.918\n",
      "Ep:38, loss:0.00008, loss_test:0.11460, lr:8.69e-03, fs:0.62687 (r=0.636,p=0.618),  time:14.800, tt:577.181\n",
      "Ep:39, loss:0.00008, loss_test:0.11422, lr:8.60e-03, fs:0.63317 (r=0.636,p=0.630),  time:14.824, tt:592.957\n",
      "Ep:40, loss:0.00008, loss_test:0.11375, lr:8.51e-03, fs:0.64000 (r=0.646,p=0.634),  time:14.827, tt:607.903\n",
      "Ep:41, loss:0.00008, loss_test:0.11333, lr:8.43e-03, fs:0.65347 (r=0.667,p=0.641),  time:14.863, tt:624.262\n",
      "Ep:42, loss:0.00007, loss_test:0.11292, lr:8.35e-03, fs:0.66010 (r=0.677,p=0.644),  time:14.884, tt:640.026\n",
      "Ep:43, loss:0.00007, loss_test:0.11258, lr:8.26e-03, fs:0.66995 (r=0.687,p=0.654),  time:14.888, tt:655.093\n",
      "Ep:44, loss:0.00007, loss_test:0.11238, lr:8.18e-03, fs:0.66995 (r=0.687,p=0.654),  time:14.941, tt:672.352\n",
      "Ep:45, loss:0.00007, loss_test:0.11233, lr:8.10e-03, fs:0.66995 (r=0.687,p=0.654),  time:14.931, tt:686.813\n",
      "Ep:46, loss:0.00007, loss_test:0.11234, lr:8.02e-03, fs:0.67647 (r=0.697,p=0.657),  time:14.937, tt:702.032\n",
      "Ep:47, loss:0.00007, loss_test:0.11224, lr:7.94e-03, fs:0.67647 (r=0.697,p=0.657),  time:14.925, tt:716.384\n",
      "Ep:48, loss:0.00007, loss_test:0.11203, lr:7.86e-03, fs:0.67327 (r=0.687,p=0.660),  time:14.926, tt:731.381\n",
      "Ep:49, loss:0.00007, loss_test:0.11186, lr:7.78e-03, fs:0.67327 (r=0.687,p=0.660),  time:14.924, tt:746.193\n",
      "Ep:50, loss:0.00007, loss_test:0.11176, lr:7.70e-03, fs:0.67662 (r=0.687,p=0.667),  time:14.936, tt:761.752\n",
      "Ep:51, loss:0.00007, loss_test:0.11164, lr:7.62e-03, fs:0.67677 (r=0.677,p=0.677),  time:14.940, tt:776.892\n",
      "Ep:52, loss:0.00007, loss_test:0.11146, lr:7.55e-03, fs:0.67677 (r=0.677,p=0.677),  time:14.944, tt:792.012\n",
      "Ep:53, loss:0.00007, loss_test:0.11120, lr:7.47e-03, fs:0.68342 (r=0.687,p=0.680),  time:14.949, tt:807.227\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.11098, lr:7.47e-03, fs:0.68342 (r=0.687,p=0.680),  time:14.948, tt:822.117\n",
      "Ep:55, loss:0.00007, loss_test:0.11078, lr:7.47e-03, fs:0.68342 (r=0.687,p=0.680),  time:14.973, tt:838.488\n",
      "Ep:56, loss:0.00006, loss_test:0.11064, lr:7.47e-03, fs:0.68342 (r=0.687,p=0.680),  time:14.988, tt:854.320\n",
      "Ep:57, loss:0.00006, loss_test:0.11051, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:15.008, tt:870.472\n",
      "Ep:58, loss:0.00006, loss_test:0.11017, lr:7.47e-03, fs:0.67677 (r=0.677,p=0.677),  time:15.020, tt:886.208\n",
      "Ep:59, loss:0.00006, loss_test:0.10984, lr:7.47e-03, fs:0.69000 (r=0.697,p=0.683),  time:15.044, tt:902.660\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.10968, lr:7.47e-03, fs:0.69000 (r=0.697,p=0.683),  time:15.045, tt:917.740\n",
      "Ep:61, loss:0.00006, loss_test:0.10958, lr:7.47e-03, fs:0.68687 (r=0.687,p=0.687),  time:15.041, tt:932.568\n",
      "Ep:62, loss:0.00006, loss_test:0.10932, lr:7.47e-03, fs:0.69347 (r=0.697,p=0.690),  time:15.022, tt:946.366\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.10908, lr:7.47e-03, fs:0.69347 (r=0.697,p=0.690),  time:15.027, tt:961.698\n",
      "Ep:64, loss:0.00006, loss_test:0.10890, lr:7.47e-03, fs:0.68687 (r=0.687,p=0.687),  time:15.015, tt:975.957\n",
      "Ep:65, loss:0.00006, loss_test:0.10870, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:15.008, tt:990.525\n",
      "Ep:66, loss:0.00006, loss_test:0.10834, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:15.008, tt:1005.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00006, loss_test:0.10805, lr:7.47e-03, fs:0.68687 (r=0.687,p=0.687),  time:15.002, tt:1020.115\n",
      "Ep:68, loss:0.00006, loss_test:0.10800, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:14.996, tt:1034.731\n",
      "Ep:69, loss:0.00006, loss_test:0.10783, lr:7.47e-03, fs:0.68020 (r=0.677,p=0.684),  time:14.996, tt:1049.722\n",
      "Ep:70, loss:0.00006, loss_test:0.10754, lr:7.47e-03, fs:0.68687 (r=0.687,p=0.687),  time:14.992, tt:1064.419\n",
      "Ep:71, loss:0.00006, loss_test:0.10726, lr:7.47e-03, fs:0.68687 (r=0.687,p=0.687),  time:14.988, tt:1079.158\n",
      "Ep:72, loss:0.00006, loss_test:0.10711, lr:7.47e-03, fs:0.68367 (r=0.677,p=0.691),  time:15.005, tt:1095.345\n",
      "Ep:73, loss:0.00005, loss_test:0.10693, lr:7.47e-03, fs:0.68367 (r=0.677,p=0.691),  time:14.996, tt:1109.689\n",
      "Ep:74, loss:0.00005, loss_test:0.10676, lr:7.40e-03, fs:0.69036 (r=0.687,p=0.694),  time:14.996, tt:1124.716\n",
      "Ep:75, loss:0.00005, loss_test:0.10676, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.009, tt:1140.717\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00005, loss_test:0.10670, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.004, tt:1155.276\n",
      "Ep:77, loss:0.00005, loss_test:0.10652, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.013, tt:1171.051\n",
      "Ep:78, loss:0.00005, loss_test:0.10644, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.017, tt:1186.366\n",
      "Ep:79, loss:0.00005, loss_test:0.10636, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.034, tt:1202.742\n",
      "Ep:80, loss:0.00005, loss_test:0.10622, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.029, tt:1217.362\n",
      "Ep:81, loss:0.00005, loss_test:0.10608, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.023, tt:1231.873\n",
      "Ep:82, loss:0.00005, loss_test:0.10594, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.030, tt:1247.461\n",
      "Ep:83, loss:0.00005, loss_test:0.10587, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.034, tt:1262.873\n",
      "Ep:84, loss:0.00005, loss_test:0.10575, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.029, tt:1277.471\n",
      "Ep:85, loss:0.00005, loss_test:0.10559, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.040, tt:1293.434\n",
      "Ep:86, loss:0.00005, loss_test:0.10556, lr:7.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.045, tt:1308.896\n",
      "Ep:87, loss:0.00005, loss_test:0.10540, lr:7.25e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.054, tt:1324.787\n",
      "Ep:88, loss:0.00005, loss_test:0.10515, lr:7.18e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.065, tt:1340.818\n",
      "Ep:89, loss:0.00005, loss_test:0.10501, lr:7.11e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.081, tt:1357.333\n",
      "Ep:90, loss:0.00005, loss_test:0.10494, lr:7.03e-03, fs:0.69388 (r=0.687,p=0.701),  time:15.091, tt:1373.276\n",
      "Ep:91, loss:0.00005, loss_test:0.10485, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:15.105, tt:1389.644\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00005, loss_test:0.10479, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:15.131, tt:1407.144\n",
      "Ep:93, loss:0.00005, loss_test:0.10471, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:15.141, tt:1423.211\n",
      "Ep:94, loss:0.00005, loss_test:0.10462, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:15.136, tt:1437.914\n",
      "Ep:95, loss:0.00005, loss_test:0.10447, lr:6.96e-03, fs:0.70408 (r=0.697,p=0.711),  time:15.132, tt:1452.677\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00004, loss_test:0.10438, lr:6.96e-03, fs:0.69430 (r=0.677,p=0.713),  time:15.141, tt:1468.640\n",
      "Ep:97, loss:0.00004, loss_test:0.10413, lr:6.96e-03, fs:0.69744 (r=0.687,p=0.708),  time:15.139, tt:1483.647\n",
      "Ep:98, loss:0.00004, loss_test:0.10419, lr:6.96e-03, fs:0.69792 (r=0.677,p=0.720),  time:15.146, tt:1499.458\n",
      "Ep:99, loss:0.00004, loss_test:0.10399, lr:6.96e-03, fs:0.69430 (r=0.677,p=0.713),  time:15.143, tt:1514.320\n",
      "Ep:100, loss:0.00004, loss_test:0.10374, lr:6.96e-03, fs:0.70051 (r=0.697,p=0.704),  time:15.148, tt:1529.928\n",
      "Ep:101, loss:0.00004, loss_test:0.10390, lr:6.96e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.162, tt:1546.543\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00004, loss_test:0.10387, lr:6.96e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.161, tt:1561.557\n",
      "Ep:103, loss:0.00004, loss_test:0.10364, lr:6.96e-03, fs:0.70157 (r=0.677,p=0.728),  time:15.175, tt:1578.168\n",
      "Ep:104, loss:0.00004, loss_test:0.10353, lr:6.96e-03, fs:0.70833 (r=0.687,p=0.731),  time:15.182, tt:1594.135\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.10376, lr:6.96e-03, fs:0.70526 (r=0.677,p=0.736),  time:15.184, tt:1609.502\n",
      "Ep:106, loss:0.00004, loss_test:0.10373, lr:6.96e-03, fs:0.70899 (r=0.677,p=0.744),  time:15.191, tt:1625.445\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00004, loss_test:0.10338, lr:6.96e-03, fs:0.70833 (r=0.687,p=0.731),  time:15.183, tt:1639.716\n",
      "Ep:108, loss:0.00004, loss_test:0.10325, lr:6.96e-03, fs:0.70833 (r=0.687,p=0.731),  time:15.185, tt:1655.124\n",
      "Ep:109, loss:0.00004, loss_test:0.10339, lr:6.96e-03, fs:0.70899 (r=0.677,p=0.744),  time:15.184, tt:1670.203\n",
      "Ep:110, loss:0.00004, loss_test:0.10327, lr:6.96e-03, fs:0.70899 (r=0.677,p=0.744),  time:15.189, tt:1686.004\n",
      "Ep:111, loss:0.00004, loss_test:0.10292, lr:6.96e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.190, tt:1701.283\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00004, loss_test:0.10284, lr:6.96e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.192, tt:1716.741\n",
      "Ep:113, loss:0.00004, loss_test:0.10295, lr:6.96e-03, fs:0.70899 (r=0.677,p=0.744),  time:15.188, tt:1731.485\n",
      "Ep:114, loss:0.00004, loss_test:0.10275, lr:6.96e-03, fs:0.71579 (r=0.687,p=0.747),  time:15.189, tt:1746.708\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00004, loss_test:0.10237, lr:6.96e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.180, tt:1760.927\n",
      "Ep:116, loss:0.00004, loss_test:0.10246, lr:6.96e-03, fs:0.71958 (r=0.687,p=0.756),  time:15.177, tt:1775.702\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00004, loss_test:0.10249, lr:6.96e-03, fs:0.72340 (r=0.687,p=0.764),  time:15.186, tt:1792.006\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00004, loss_test:0.10215, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.184, tt:1806.900\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00004, loss_test:0.10210, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.177, tt:1821.265\n",
      "Ep:120, loss:0.00004, loss_test:0.10209, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.173, tt:1835.949\n",
      "Ep:121, loss:0.00004, loss_test:0.10185, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.175, tt:1851.348\n",
      "Ep:122, loss:0.00004, loss_test:0.10182, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.177, tt:1866.767\n",
      "Ep:123, loss:0.00004, loss_test:0.10121, lr:6.96e-03, fs:0.72251 (r=0.697,p=0.750),  time:15.185, tt:1883.002\n",
      "Ep:124, loss:0.00003, loss_test:0.10132, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.191, tt:1898.906\n",
      "Ep:125, loss:0.00003, loss_test:0.10145, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.196, tt:1914.676\n",
      "Ep:126, loss:0.00003, loss_test:0.10100, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.196, tt:1929.847\n",
      "Ep:127, loss:0.00003, loss_test:0.10157, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.196, tt:1945.122\n",
      "Ep:128, loss:0.00003, loss_test:0.10109, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.196, tt:1960.277\n",
      "Ep:129, loss:0.00003, loss_test:0.10078, lr:6.96e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.197, tt:1975.550\n",
      "Ep:130, loss:0.00003, loss_test:0.10139, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.200, tt:1991.206\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00003, loss_test:0.10102, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.208, tt:2007.400\n",
      "Ep:132, loss:0.00003, loss_test:0.10053, lr:6.89e-03, fs:0.72632 (r=0.697,p=0.758),  time:15.214, tt:2023.452\n",
      "Ep:133, loss:0.00003, loss_test:0.10159, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.228, tt:2040.535\n",
      "Ep:134, loss:0.00003, loss_test:0.10126, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.232, tt:2056.386\n",
      "Ep:135, loss:0.00003, loss_test:0.10010, lr:6.89e-03, fs:0.73298 (r=0.707,p=0.761),  time:15.235, tt:2071.975\n",
      "Ep:136, loss:0.00003, loss_test:0.10079, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.241, tt:2087.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00003, loss_test:0.10144, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.240, tt:2103.129\n",
      "Ep:138, loss:0.00003, loss_test:0.10082, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.238, tt:2118.025\n",
      "Ep:139, loss:0.00003, loss_test:0.10003, lr:6.89e-03, fs:0.73684 (r=0.707,p=0.769),  time:15.243, tt:2134.040\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00003, loss_test:0.10059, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.250, tt:2150.237\n",
      "Ep:141, loss:0.00003, loss_test:0.10065, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.255, tt:2166.184\n",
      "Ep:142, loss:0.00003, loss_test:0.09987, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.265, tt:2182.864\n",
      "Ep:143, loss:0.00003, loss_test:0.09947, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.267, tt:2198.403\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00003, loss_test:0.10007, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.273, tt:2214.589\n",
      "Ep:145, loss:0.00003, loss_test:0.10013, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.278, tt:2230.593\n",
      "Ep:146, loss:0.00003, loss_test:0.09920, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.275, tt:2245.448\n",
      "Ep:147, loss:0.00003, loss_test:0.09896, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.273, tt:2260.383\n",
      "Ep:148, loss:0.00003, loss_test:0.09971, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.265, tt:2274.468\n",
      "Ep:149, loss:0.00003, loss_test:0.09940, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.256, tt:2288.419\n",
      "Ep:150, loss:0.00003, loss_test:0.09863, lr:6.89e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.247, tt:2302.263\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00003, loss_test:0.09947, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.236, tt:2315.913\n",
      "Ep:152, loss:0.00003, loss_test:0.09928, lr:6.89e-03, fs:0.73404 (r=0.697,p=0.775),  time:15.234, tt:2330.811\n",
      "Ep:153, loss:0.00003, loss_test:0.09828, lr:6.89e-03, fs:0.74737 (r=0.717,p=0.780),  time:15.229, tt:2345.331\n",
      "Ep:154, loss:0.00003, loss_test:0.09879, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.215, tt:2358.342\n",
      "Ep:155, loss:0.00003, loss_test:0.09901, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.210, tt:2372.697\n",
      "Ep:156, loss:0.00003, loss_test:0.09817, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.205, tt:2387.168\n",
      "Ep:157, loss:0.00003, loss_test:0.09807, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.198, tt:2401.230\n",
      "Ep:158, loss:0.00003, loss_test:0.09884, lr:6.89e-03, fs:0.74468 (r=0.707,p=0.787),  time:15.195, tt:2415.953\n",
      "Ep:159, loss:0.00003, loss_test:0.09822, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.191, tt:2430.509\n",
      "Ep:160, loss:0.00003, loss_test:0.09751, lr:6.89e-03, fs:0.75393 (r=0.727,p=0.783),  time:15.185, tt:2444.856\n",
      "##########Best model found so far##########\n",
      "Ep:161, loss:0.00003, loss_test:0.09890, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.181, tt:2459.340\n",
      "Ep:162, loss:0.00003, loss_test:0.09881, lr:6.89e-03, fs:0.74468 (r=0.707,p=0.787),  time:15.177, tt:2473.926\n",
      "Ep:163, loss:0.00003, loss_test:0.09743, lr:6.89e-03, fs:0.74346 (r=0.717,p=0.772),  time:15.170, tt:2487.831\n",
      "Ep:164, loss:0.00003, loss_test:0.09797, lr:6.89e-03, fs:0.74074 (r=0.707,p=0.778),  time:15.156, tt:2500.795\n",
      "Ep:165, loss:0.00002, loss_test:0.09832, lr:6.89e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.146, tt:2514.238\n",
      "Ep:166, loss:0.00002, loss_test:0.09771, lr:6.89e-03, fs:0.74194 (r=0.697,p=0.793),  time:15.141, tt:2528.593\n",
      "Ep:167, loss:0.00002, loss_test:0.09724, lr:6.89e-03, fs:0.74468 (r=0.707,p=0.787),  time:15.135, tt:2542.660\n",
      "Ep:168, loss:0.00002, loss_test:0.09810, lr:6.89e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.127, tt:2556.456\n",
      "Ep:169, loss:0.00002, loss_test:0.09798, lr:6.89e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.121, tt:2570.571\n",
      "Ep:170, loss:0.00002, loss_test:0.09701, lr:6.89e-03, fs:0.74468 (r=0.707,p=0.787),  time:15.114, tt:2584.417\n",
      "Ep:171, loss:0.00002, loss_test:0.09721, lr:6.89e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.111, tt:2599.025\n",
      "Ep:172, loss:0.00002, loss_test:0.09741, lr:6.83e-03, fs:0.75676 (r=0.707,p=0.814),  time:15.106, tt:2613.403\n",
      "##########Best model found so far##########\n",
      "Ep:173, loss:0.00002, loss_test:0.09675, lr:6.83e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.099, tt:2627.293\n",
      "Ep:174, loss:0.00002, loss_test:0.09655, lr:6.83e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.090, tt:2640.805\n",
      "Ep:175, loss:0.00002, loss_test:0.09706, lr:6.83e-03, fs:0.74595 (r=0.697,p=0.802),  time:15.086, tt:2655.113\n",
      "Ep:176, loss:0.00002, loss_test:0.09688, lr:6.83e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.081, tt:2669.308\n",
      "Ep:177, loss:0.00002, loss_test:0.09639, lr:6.83e-03, fs:0.74866 (r=0.707,p=0.795),  time:15.072, tt:2682.835\n",
      "Ep:178, loss:0.00002, loss_test:0.09666, lr:6.83e-03, fs:0.75676 (r=0.707,p=0.814),  time:15.061, tt:2695.954\n",
      "Ep:179, loss:0.00002, loss_test:0.09651, lr:6.83e-03, fs:0.75676 (r=0.707,p=0.814),  time:15.057, tt:2710.252\n",
      "Ep:180, loss:0.00002, loss_test:0.09583, lr:6.83e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.051, tt:2724.259\n",
      "Ep:181, loss:0.00002, loss_test:0.09635, lr:6.83e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.046, tt:2738.338\n",
      "Ep:182, loss:0.00002, loss_test:0.09610, lr:6.83e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.041, tt:2752.473\n",
      "Ep:183, loss:0.00002, loss_test:0.09552, lr:6.83e-03, fs:0.75269 (r=0.707,p=0.805),  time:15.038, tt:2766.920\n",
      "Ep:184, loss:0.00002, loss_test:0.09662, lr:6.76e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.031, tt:2780.713\n",
      "Ep:185, loss:0.00002, loss_test:0.09626, lr:6.69e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.026, tt:2794.908\n",
      "Ep:186, loss:0.00002, loss_test:0.09511, lr:6.62e-03, fs:0.74595 (r=0.697,p=0.802),  time:15.020, tt:2808.659\n",
      "Ep:187, loss:0.00002, loss_test:0.09672, lr:6.56e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.015, tt:2822.731\n",
      "Ep:188, loss:0.00002, loss_test:0.09683, lr:6.49e-03, fs:0.75410 (r=0.697,p=0.821),  time:15.011, tt:2837.083\n",
      "Ep:189, loss:0.00002, loss_test:0.09539, lr:6.43e-03, fs:0.75000 (r=0.697,p=0.812),  time:14.994, tt:2848.813\n",
      "Ep:190, loss:0.00002, loss_test:0.09507, lr:6.36e-03, fs:0.75000 (r=0.697,p=0.812),  time:14.990, tt:2863.080\n",
      "Ep:191, loss:0.00002, loss_test:0.09692, lr:6.30e-03, fs:0.75824 (r=0.697,p=0.831),  time:14.975, tt:2875.181\n",
      "##########Best model found so far##########\n",
      "Ep:192, loss:0.00002, loss_test:0.09718, lr:6.30e-03, fs:0.76243 (r=0.697,p=0.841),  time:14.960, tt:2887.211\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00002, loss_test:0.09552, lr:6.30e-03, fs:0.75824 (r=0.697,p=0.831),  time:14.952, tt:2900.655\n",
      "Ep:194, loss:0.00002, loss_test:0.09452, lr:6.30e-03, fs:0.75000 (r=0.697,p=0.812),  time:14.943, tt:2913.894\n",
      "Ep:195, loss:0.00002, loss_test:0.09636, lr:6.30e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.939, tt:2928.109\n",
      "Ep:196, loss:0.00002, loss_test:0.09672, lr:6.30e-03, fs:0.76243 (r=0.697,p=0.841),  time:14.933, tt:2941.760\n",
      "Ep:197, loss:0.00002, loss_test:0.09503, lr:6.30e-03, fs:0.75824 (r=0.697,p=0.831),  time:14.926, tt:2955.336\n",
      "Ep:198, loss:0.00002, loss_test:0.09374, lr:6.30e-03, fs:0.75000 (r=0.697,p=0.812),  time:14.919, tt:2968.814\n",
      "Ep:199, loss:0.00002, loss_test:0.09577, lr:6.30e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.915, tt:2983.056\n",
      "Ep:200, loss:0.00002, loss_test:0.09707, lr:6.30e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.912, tt:2997.307\n",
      "Ep:201, loss:0.00002, loss_test:0.09576, lr:6.30e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.897, tt:3009.181\n",
      "Ep:202, loss:0.00002, loss_test:0.09378, lr:6.30e-03, fs:0.75676 (r=0.707,p=0.814),  time:14.877, tt:3020.131\n",
      "Ep:203, loss:0.00002, loss_test:0.09488, lr:6.30e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.856, tt:3030.574\n",
      "Ep:204, loss:0.00002, loss_test:0.09618, lr:6.24e-03, fs:0.75978 (r=0.687,p=0.850),  time:14.819, tt:3037.965\n",
      "Ep:205, loss:0.00002, loss_test:0.09559, lr:6.17e-03, fs:0.75556 (r=0.687,p=0.840),  time:14.774, tt:3043.452\n",
      "Ep:206, loss:0.00002, loss_test:0.09405, lr:6.11e-03, fs:0.75138 (r=0.687,p=0.829),  time:14.724, tt:3047.788\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13550, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.555, tt:31.555\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13360, lr:1.00e-02, fs:0.67500 (r=1.000,p=0.509),  time:31.851, tt:63.701\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13026, lr:1.00e-02, fs:0.68354 (r=1.000,p=0.519),  time:31.337, tt:94.011\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12485, lr:1.00e-02, fs:0.67114 (r=0.926,p=0.526),  time:31.081, tt:124.325\n",
      "Ep:4, loss:0.00026, loss_test:0.11868, lr:1.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:31.266, tt:156.328\n",
      "Ep:5, loss:0.00024, loss_test:0.11494, lr:1.00e-02, fs:0.65600 (r=0.759,p=0.577),  time:31.400, tt:188.403\n",
      "Ep:6, loss:0.00023, loss_test:0.11180, lr:1.00e-02, fs:0.63636 (r=0.648,p=0.625),  time:31.233, tt:218.629\n",
      "Ep:7, loss:0.00023, loss_test:0.10962, lr:1.00e-02, fs:0.66667 (r=0.648,p=0.686),  time:31.249, tt:249.993\n",
      "Ep:8, loss:0.00022, loss_test:0.10714, lr:1.00e-02, fs:0.67826 (r=0.722,p=0.639),  time:31.325, tt:281.929\n",
      "Ep:9, loss:0.00022, loss_test:0.10537, lr:1.00e-02, fs:0.68333 (r=0.759,p=0.621),  time:31.332, tt:313.320\n",
      "Ep:10, loss:0.00021, loss_test:0.10146, lr:1.00e-02, fs:0.71304 (r=0.759,p=0.672),  time:31.391, tt:345.296\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09887, lr:1.00e-02, fs:0.69725 (r=0.704,p=0.691),  time:31.522, tt:378.262\n",
      "Ep:12, loss:0.00020, loss_test:0.09682, lr:1.00e-02, fs:0.69725 (r=0.704,p=0.691),  time:31.609, tt:410.921\n",
      "Ep:13, loss:0.00019, loss_test:0.09549, lr:1.00e-02, fs:0.73504 (r=0.796,p=0.683),  time:31.577, tt:442.072\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09354, lr:1.00e-02, fs:0.76033 (r=0.852,p=0.687),  time:31.677, tt:475.149\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09065, lr:1.00e-02, fs:0.77193 (r=0.815,p=0.733),  time:31.683, tt:506.930\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08853, lr:1.00e-02, fs:0.77876 (r=0.815,p=0.746),  time:31.582, tt:536.887\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08753, lr:1.00e-02, fs:0.77966 (r=0.852,p=0.719),  time:31.533, tt:567.591\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08662, lr:1.00e-02, fs:0.76923 (r=0.833,p=0.714),  time:31.486, tt:598.226\n",
      "Ep:19, loss:0.00016, loss_test:0.08450, lr:1.00e-02, fs:0.78947 (r=0.833,p=0.750),  time:31.532, tt:630.637\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08358, lr:1.00e-02, fs:0.79310 (r=0.852,p=0.742),  time:31.606, tt:663.718\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08221, lr:1.00e-02, fs:0.80000 (r=0.852,p=0.754),  time:31.562, tt:694.355\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08080, lr:1.00e-02, fs:0.80357 (r=0.833,p=0.776),  time:31.620, tt:727.264\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08018, lr:1.00e-02, fs:0.81081 (r=0.833,p=0.789),  time:31.634, tt:759.214\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07886, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:31.607, tt:790.168\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07682, lr:1.00e-02, fs:0.82883 (r=0.852,p=0.807),  time:31.642, tt:822.702\n",
      "Ep:26, loss:0.00014, loss_test:0.07633, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:31.645, tt:854.416\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07549, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:31.689, tt:887.297\n",
      "Ep:28, loss:0.00013, loss_test:0.07364, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:31.676, tt:918.604\n",
      "Ep:29, loss:0.00013, loss_test:0.07261, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:31.675, tt:950.251\n",
      "Ep:30, loss:0.00012, loss_test:0.07198, lr:1.00e-02, fs:0.83929 (r=0.870,p=0.810),  time:31.662, tt:981.535\n",
      "Ep:31, loss:0.00012, loss_test:0.07078, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:31.711, tt:1014.750\n",
      "Ep:32, loss:0.00012, loss_test:0.06981, lr:1.00e-02, fs:0.84685 (r=0.870,p=0.825),  time:31.665, tt:1044.956\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06925, lr:1.00e-02, fs:0.83186 (r=0.870,p=0.797),  time:31.682, tt:1077.184\n",
      "Ep:34, loss:0.00011, loss_test:0.06830, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:31.695, tt:1109.319\n",
      "Ep:35, loss:0.00011, loss_test:0.06721, lr:1.00e-02, fs:0.85714 (r=0.889,p=0.828),  time:31.687, tt:1140.718\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.06642, lr:1.00e-02, fs:0.85965 (r=0.907,p=0.817),  time:31.666, tt:1171.627\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06620, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:31.674, tt:1203.625\n",
      "Ep:38, loss:0.00010, loss_test:0.06481, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.707, tt:1236.564\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.06405, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.699, tt:1267.969\n",
      "Ep:40, loss:0.00010, loss_test:0.06408, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:31.689, tt:1299.244\n",
      "Ep:41, loss:0.00010, loss_test:0.06315, lr:1.00e-02, fs:0.85965 (r=0.907,p=0.817),  time:31.700, tt:1331.420\n",
      "Ep:42, loss:0.00010, loss_test:0.06225, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:31.731, tt:1364.439\n",
      "Ep:43, loss:0.00009, loss_test:0.06161, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.752, tt:1397.098\n",
      "Ep:44, loss:0.00009, loss_test:0.06134, lr:1.00e-02, fs:0.84483 (r=0.907,p=0.790),  time:31.740, tt:1428.309\n",
      "Ep:45, loss:0.00009, loss_test:0.05990, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.754, tt:1460.685\n",
      "Ep:46, loss:0.00009, loss_test:0.05935, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.752, tt:1492.348\n",
      "Ep:47, loss:0.00009, loss_test:0.05942, lr:1.00e-02, fs:0.84483 (r=0.907,p=0.790),  time:31.755, tt:1524.256\n",
      "Ep:48, loss:0.00009, loss_test:0.05813, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:31.820, tt:1559.175\n",
      "Ep:49, loss:0.00008, loss_test:0.05752, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:31.814, tt:1590.711\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.05691, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.805, tt:1622.075\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.05658, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:31.809, tt:1654.046\n",
      "Ep:52, loss:0.00008, loss_test:0.05567, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:31.819, tt:1686.409\n",
      "Ep:53, loss:0.00008, loss_test:0.05514, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:31.825, tt:1718.568\n",
      "Ep:54, loss:0.00008, loss_test:0.05459, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.837, tt:1751.008\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.05395, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.840, tt:1783.049\n",
      "Ep:56, loss:0.00007, loss_test:0.05362, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.837, tt:1814.712\n",
      "Ep:57, loss:0.00007, loss_test:0.05235, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.824, tt:1845.800\n",
      "Ep:58, loss:0.00007, loss_test:0.05239, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:31.828, tt:1877.863\n",
      "Ep:59, loss:0.00007, loss_test:0.05166, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.823, tt:1909.360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00007, loss_test:0.05117, lr:1.00e-02, fs:0.88496 (r=0.926,p=0.847),  time:31.789, tt:1939.139\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.05093, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.802, tt:1971.715\n",
      "Ep:62, loss:0.00007, loss_test:0.04921, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.794, tt:2003.041\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00007, loss_test:0.04945, lr:1.00e-02, fs:0.87931 (r=0.944,p=0.823),  time:31.791, tt:2034.613\n",
      "Ep:64, loss:0.00006, loss_test:0.04836, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.800, tt:2066.992\n",
      "Ep:65, loss:0.00006, loss_test:0.04766, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.803, tt:2099.019\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.04742, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.800, tt:2130.587\n",
      "Ep:67, loss:0.00006, loss_test:0.04646, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.821, tt:2163.826\n",
      "Ep:68, loss:0.00006, loss_test:0.04705, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:31.811, tt:2194.953\n",
      "Ep:69, loss:0.00006, loss_test:0.04524, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.817, tt:2227.221\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.04542, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.803, tt:2258.038\n",
      "Ep:71, loss:0.00006, loss_test:0.04440, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.794, tt:2289.165\n",
      "Ep:72, loss:0.00006, loss_test:0.04365, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.789, tt:2320.580\n",
      "Ep:73, loss:0.00005, loss_test:0.04383, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:31.801, tt:2353.300\n",
      "Ep:74, loss:0.00005, loss_test:0.04261, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.832, tt:2387.371\n",
      "Ep:75, loss:0.00005, loss_test:0.04280, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.838, tt:2419.653\n",
      "Ep:76, loss:0.00005, loss_test:0.04168, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.829, tt:2450.833\n",
      "Ep:77, loss:0.00005, loss_test:0.04137, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.819, tt:2481.844\n",
      "Ep:78, loss:0.00005, loss_test:0.04167, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.839, tt:2515.248\n",
      "Ep:79, loss:0.00005, loss_test:0.03997, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.840, tt:2547.239\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00005, loss_test:0.03993, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:31.847, tt:2579.634\n",
      "Ep:81, loss:0.00005, loss_test:0.03935, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.843, tt:2611.101\n",
      "Ep:82, loss:0.00005, loss_test:0.03886, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.867, tt:2644.936\n",
      "Ep:83, loss:0.00004, loss_test:0.03890, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.860, tt:2676.204\n",
      "Ep:84, loss:0.00004, loss_test:0.03773, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.878, tt:2709.623\n",
      "Ep:85, loss:0.00004, loss_test:0.03787, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.899, tt:2743.341\n",
      "Ep:86, loss:0.00004, loss_test:0.03701, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.934, tt:2778.242\n",
      "Ep:87, loss:0.00004, loss_test:0.03648, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.948, tt:2811.385\n",
      "Ep:88, loss:0.00004, loss_test:0.03680, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:31.959, tt:2844.316\n",
      "Ep:89, loss:0.00004, loss_test:0.03558, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:31.993, tt:2879.351\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00004, loss_test:0.03627, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:32.007, tt:2912.632\n",
      "Ep:91, loss:0.00004, loss_test:0.03468, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.026, tt:2946.402\n",
      "Ep:92, loss:0.00004, loss_test:0.03446, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.048, tt:2980.476\n",
      "Ep:93, loss:0.00004, loss_test:0.03473, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.053, tt:3012.960\n",
      "Ep:94, loss:0.00004, loss_test:0.03344, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.071, tt:3046.727\n",
      "Ep:95, loss:0.00004, loss_test:0.03401, lr:1.00e-02, fs:0.92035 (r=0.963,p=0.881),  time:32.095, tt:3081.127\n",
      "Ep:96, loss:0.00004, loss_test:0.03330, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.102, tt:3113.902\n",
      "Ep:97, loss:0.00003, loss_test:0.03209, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.110, tt:3146.781\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00003, loss_test:0.03251, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.121, tt:3179.933\n",
      "Ep:99, loss:0.00003, loss_test:0.03214, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.139, tt:3213.880\n",
      "Ep:100, loss:0.00003, loss_test:0.03125, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.134, tt:3245.575\n",
      "Ep:101, loss:0.00003, loss_test:0.03095, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.145, tt:3278.794\n",
      "Ep:102, loss:0.00003, loss_test:0.03057, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.142, tt:3310.654\n",
      "Ep:103, loss:0.00003, loss_test:0.02992, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.148, tt:3343.393\n",
      "Ep:104, loss:0.00003, loss_test:0.02988, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.154, tt:3376.128\n",
      "Ep:105, loss:0.00003, loss_test:0.02939, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.145, tt:3407.402\n",
      "Ep:106, loss:0.00003, loss_test:0.02900, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.150, tt:3440.017\n",
      "Ep:107, loss:0.00003, loss_test:0.02899, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.154, tt:3472.600\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00003, loss_test:0.02865, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.125, tt:3501.617\n",
      "Ep:109, loss:0.00003, loss_test:0.02829, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.125, tt:3533.715\n",
      "Ep:110, loss:0.00003, loss_test:0.02796, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.114, tt:3564.632\n",
      "Ep:111, loss:0.00003, loss_test:0.02757, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.105, tt:3595.708\n",
      "Ep:112, loss:0.00003, loss_test:0.02753, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.107, tt:3628.064\n",
      "Ep:113, loss:0.00003, loss_test:0.02678, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.088, tt:3658.011\n",
      "Ep:114, loss:0.00002, loss_test:0.02688, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.091, tt:3690.506\n",
      "Ep:115, loss:0.00002, loss_test:0.02619, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.095, tt:3723.077\n",
      "Ep:116, loss:0.00002, loss_test:0.02622, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.093, tt:3754.924\n",
      "Ep:117, loss:0.00002, loss_test:0.02566, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.084, tt:3785.944\n",
      "Ep:118, loss:0.00002, loss_test:0.02552, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:32.088, tt:3818.452\n",
      "Ep:119, loss:0.00002, loss_test:0.02516, lr:9.90e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.096, tt:3851.476\n",
      "Ep:120, loss:0.00002, loss_test:0.02511, lr:9.80e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.130, tt:3887.675\n",
      "Ep:121, loss:0.00002, loss_test:0.02507, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.127, tt:3919.522\n",
      "Ep:122, loss:0.00002, loss_test:0.02478, lr:9.61e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.130, tt:3951.955\n",
      "Ep:123, loss:0.00002, loss_test:0.02513, lr:9.51e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.129, tt:3984.018\n",
      "Ep:124, loss:0.00002, loss_test:0.02440, lr:9.41e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.140, tt:4017.529\n",
      "Ep:125, loss:0.00002, loss_test:0.02509, lr:9.32e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.156, tt:4051.624\n",
      "Ep:126, loss:0.00002, loss_test:0.02419, lr:9.23e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.141, tt:4081.844\n",
      "Ep:127, loss:0.00002, loss_test:0.02401, lr:9.14e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.136, tt:4113.434\n",
      "Ep:128, loss:0.00002, loss_test:0.02375, lr:9.04e-03, fs:0.93694 (r=0.963,p=0.912),  time:32.142, tt:4146.278\n",
      "Ep:129, loss:0.00002, loss_test:0.02365, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.153, tt:4179.826\n",
      "Ep:130, loss:0.00002, loss_test:0.02309, lr:8.86e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.164, tt:4213.525\n",
      "Ep:131, loss:0.00002, loss_test:0.02360, lr:8.78e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.165, tt:4245.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.02309, lr:8.69e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:4278.766\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00002, loss_test:0.02265, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.167, tt:4310.371\n",
      "Ep:134, loss:0.00002, loss_test:0.02311, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.162, tt:4341.828\n",
      "Ep:135, loss:0.00002, loss_test:0.02266, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.167, tt:4374.726\n",
      "Ep:136, loss:0.00002, loss_test:0.02240, lr:8.69e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.163, tt:4406.302\n",
      "Ep:137, loss:0.00002, loss_test:0.02234, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.168, tt:4439.187\n",
      "Ep:138, loss:0.00002, loss_test:0.02235, lr:8.69e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.167, tt:4471.206\n",
      "Ep:139, loss:0.00002, loss_test:0.02198, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.169, tt:4503.730\n",
      "Ep:140, loss:0.00002, loss_test:0.02191, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.177, tt:4536.961\n",
      "Ep:141, loss:0.00002, loss_test:0.02164, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.196, tt:4571.877\n",
      "Ep:142, loss:0.00002, loss_test:0.02172, lr:8.69e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.197, tt:4604.124\n",
      "Ep:143, loss:0.00002, loss_test:0.02150, lr:8.69e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.210, tt:4638.280\n",
      "Ep:144, loss:0.00002, loss_test:0.02130, lr:8.60e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.220, tt:4671.931\n",
      "Ep:145, loss:0.00002, loss_test:0.02124, lr:8.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.221, tt:4704.219\n",
      "Ep:146, loss:0.00002, loss_test:0.02104, lr:8.43e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.214, tt:4735.503\n",
      "Ep:147, loss:0.00001, loss_test:0.02103, lr:8.35e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.208, tt:4766.791\n",
      "Ep:148, loss:0.00001, loss_test:0.02090, lr:8.26e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.203, tt:4798.183\n",
      "Ep:149, loss:0.00001, loss_test:0.02071, lr:8.18e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.203, tt:4830.471\n",
      "Ep:150, loss:0.00001, loss_test:0.02078, lr:8.10e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.203, tt:4862.645\n",
      "Ep:151, loss:0.00001, loss_test:0.02040, lr:8.02e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.191, tt:4893.084\n",
      "Ep:152, loss:0.00001, loss_test:0.02055, lr:7.94e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.184, tt:4924.191\n",
      "Ep:153, loss:0.00001, loss_test:0.02029, lr:7.86e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.176, tt:4955.082\n",
      "Ep:154, loss:0.00001, loss_test:0.02028, lr:7.78e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.175, tt:4987.116\n",
      "Ep:155, loss:0.00001, loss_test:0.02026, lr:7.70e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.169, tt:5018.397\n",
      "Ep:156, loss:0.00001, loss_test:0.02025, lr:7.62e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.177, tt:5051.763\n",
      "Ep:157, loss:0.00001, loss_test:0.01983, lr:7.55e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.180, tt:5084.421\n",
      "Ep:158, loss:0.00001, loss_test:0.01999, lr:7.47e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:5115.151\n",
      "Ep:159, loss:0.00001, loss_test:0.01991, lr:7.40e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:5147.370\n",
      "Ep:160, loss:0.00001, loss_test:0.01970, lr:7.32e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.175, tt:5180.174\n",
      "Ep:161, loss:0.00001, loss_test:0.01978, lr:7.25e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:5211.706\n",
      "Ep:162, loss:0.00001, loss_test:0.01961, lr:7.18e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.174, tt:5244.417\n",
      "Ep:163, loss:0.00001, loss_test:0.01950, lr:7.11e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.170, tt:5275.820\n",
      "Ep:164, loss:0.00001, loss_test:0.01941, lr:7.03e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:5308.279\n",
      "Ep:165, loss:0.00001, loss_test:0.01947, lr:6.96e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.171, tt:5340.367\n",
      "Ep:166, loss:0.00001, loss_test:0.01934, lr:6.89e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.170, tt:5372.385\n",
      "Ep:167, loss:0.00001, loss_test:0.01911, lr:6.83e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.179, tt:5406.101\n",
      "Ep:168, loss:0.00001, loss_test:0.01933, lr:6.76e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.182, tt:5438.780\n",
      "Ep:169, loss:0.00001, loss_test:0.01917, lr:6.69e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.187, tt:5471.859\n",
      "Ep:170, loss:0.00001, loss_test:0.01916, lr:6.62e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.192, tt:5504.864\n",
      "Ep:171, loss:0.00001, loss_test:0.01901, lr:6.56e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.198, tt:5537.983\n",
      "Ep:172, loss:0.00001, loss_test:0.01892, lr:6.49e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.198, tt:5570.206\n",
      "Ep:173, loss:0.00001, loss_test:0.01894, lr:6.43e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.203, tt:5603.368\n",
      "Ep:174, loss:0.00001, loss_test:0.01885, lr:6.36e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.208, tt:5636.479\n",
      "Ep:175, loss:0.00001, loss_test:0.01878, lr:6.30e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.203, tt:5667.738\n",
      "Ep:176, loss:0.00001, loss_test:0.01869, lr:6.24e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.212, tt:5701.509\n",
      "Ep:177, loss:0.00001, loss_test:0.01873, lr:6.17e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.215, tt:5734.196\n",
      "Ep:178, loss:0.00001, loss_test:0.01865, lr:6.11e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.211, tt:5765.783\n",
      "Ep:179, loss:0.00001, loss_test:0.01854, lr:6.05e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.217, tt:5799.038\n",
      "Ep:180, loss:0.00001, loss_test:0.01856, lr:5.99e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.217, tt:5831.205\n",
      "Ep:181, loss:0.00001, loss_test:0.01853, lr:5.93e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.222, tt:5864.458\n",
      "Ep:182, loss:0.00001, loss_test:0.01843, lr:5.87e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.226, tt:5897.326\n",
      "Ep:183, loss:0.00001, loss_test:0.01847, lr:5.81e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.234, tt:5931.096\n",
      "Ep:184, loss:0.00001, loss_test:0.01827, lr:5.75e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.238, tt:5964.011\n",
      "Ep:185, loss:0.00001, loss_test:0.01831, lr:5.70e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.238, tt:5996.187\n",
      "Ep:186, loss:0.00001, loss_test:0.01831, lr:5.64e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.237, tt:6028.325\n",
      "Ep:187, loss:0.00001, loss_test:0.01829, lr:5.58e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.238, tt:6060.820\n",
      "Ep:188, loss:0.00001, loss_test:0.01824, lr:5.53e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.242, tt:6093.807\n",
      "Ep:189, loss:0.00001, loss_test:0.01817, lr:5.47e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.245, tt:6126.522\n",
      "Ep:190, loss:0.00001, loss_test:0.01816, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.249, tt:6159.546\n",
      "##########Best model found so far##########\n",
      "Ep:191, loss:0.00001, loss_test:0.01821, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.257, tt:6193.303\n",
      "Ep:192, loss:0.00001, loss_test:0.01794, lr:5.42e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.255, tt:6225.274\n",
      "Ep:193, loss:0.00001, loss_test:0.01800, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.261, tt:6258.690\n",
      "Ep:194, loss:0.00001, loss_test:0.01819, lr:5.42e-03, fs:0.95413 (r=0.963,p=0.945),  time:32.266, tt:6291.855\n",
      "Ep:195, loss:0.00001, loss_test:0.01786, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.258, tt:6322.475\n",
      "Ep:196, loss:0.00001, loss_test:0.01783, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.259, tt:6355.014\n",
      "Ep:197, loss:0.00001, loss_test:0.01805, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.261, tt:6387.629\n",
      "Ep:198, loss:0.00001, loss_test:0.01780, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.252, tt:6418.053\n",
      "Ep:199, loss:0.00001, loss_test:0.01770, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.257, tt:6451.480\n",
      "Ep:200, loss:0.00001, loss_test:0.01779, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.261, tt:6484.389\n",
      "Ep:201, loss:0.00001, loss_test:0.01777, lr:5.42e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.267, tt:6517.836\n",
      "Ep:202, loss:0.00001, loss_test:0.01773, lr:5.36e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.278, tt:6552.504\n",
      "Ep:203, loss:0.00001, loss_test:0.01766, lr:5.31e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.281, tt:6585.312\n",
      "Ep:204, loss:0.00001, loss_test:0.01767, lr:5.26e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.283, tt:6618.044\n",
      "Ep:205, loss:0.00001, loss_test:0.01762, lr:5.20e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.253, tt:6644.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00001, loss_test:0.01759, lr:5.15e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.148, tt:6654.636\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.12941, lr:1.00e-02, fs:0.68421 (r=0.963,p=0.531),  time:36.672, tt:36.672\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12734, lr:1.00e-02, fs:0.68966 (r=0.926,p=0.549),  time:36.103, tt:72.207\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12422, lr:1.00e-02, fs:0.67606 (r=0.889,p=0.545),  time:36.573, tt:109.719\n",
      "Ep:3, loss:0.00026, loss_test:0.12211, lr:1.00e-02, fs:0.66667 (r=0.852,p=0.548),  time:36.491, tt:145.965\n",
      "Ep:4, loss:0.00026, loss_test:0.12063, lr:1.00e-02, fs:0.67153 (r=0.852,p=0.554),  time:36.716, tt:183.582\n",
      "Ep:5, loss:0.00025, loss_test:0.11925, lr:1.00e-02, fs:0.68182 (r=0.833,p=0.577),  time:36.564, tt:219.381\n",
      "Ep:6, loss:0.00025, loss_test:0.11788, lr:1.00e-02, fs:0.68182 (r=0.833,p=0.577),  time:36.352, tt:254.461\n",
      "Ep:7, loss:0.00024, loss_test:0.11596, lr:1.00e-02, fs:0.68182 (r=0.833,p=0.577),  time:36.526, tt:292.208\n",
      "Ep:8, loss:0.00023, loss_test:0.11284, lr:1.00e-02, fs:0.69231 (r=0.833,p=0.592),  time:36.500, tt:328.497\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11020, lr:1.00e-02, fs:0.70769 (r=0.852,p=0.605),  time:36.597, tt:365.966\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10761, lr:1.00e-02, fs:0.70400 (r=0.815,p=0.620),  time:36.520, tt:401.719\n",
      "Ep:11, loss:0.00021, loss_test:0.10506, lr:1.00e-02, fs:0.68852 (r=0.778,p=0.618),  time:36.528, tt:438.342\n",
      "Ep:12, loss:0.00021, loss_test:0.10161, lr:1.00e-02, fs:0.72269 (r=0.796,p=0.662),  time:36.602, tt:475.822\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09848, lr:1.00e-02, fs:0.73950 (r=0.815,p=0.677),  time:36.674, tt:513.429\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09675, lr:1.00e-02, fs:0.74797 (r=0.852,p=0.667),  time:36.599, tt:548.980\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09420, lr:1.00e-02, fs:0.76667 (r=0.852,p=0.697),  time:36.619, tt:585.904\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09253, lr:1.00e-02, fs:0.77311 (r=0.852,p=0.708),  time:36.615, tt:622.462\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.08994, lr:1.00e-02, fs:0.77966 (r=0.852,p=0.719),  time:36.652, tt:659.730\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08749, lr:1.00e-02, fs:0.79661 (r=0.870,p=0.734),  time:36.641, tt:696.171\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08558, lr:1.00e-02, fs:0.81034 (r=0.870,p=0.758),  time:36.630, tt:732.603\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08419, lr:1.00e-02, fs:0.80342 (r=0.870,p=0.746),  time:36.573, tt:768.036\n",
      "Ep:21, loss:0.00016, loss_test:0.08233, lr:1.00e-02, fs:0.80000 (r=0.852,p=0.754),  time:36.571, tt:804.554\n",
      "Ep:22, loss:0.00015, loss_test:0.08094, lr:1.00e-02, fs:0.79310 (r=0.852,p=0.742),  time:36.517, tt:839.889\n",
      "Ep:23, loss:0.00015, loss_test:0.07901, lr:1.00e-02, fs:0.81739 (r=0.870,p=0.770),  time:36.625, tt:878.988\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07711, lr:1.00e-02, fs:0.81739 (r=0.870,p=0.770),  time:36.673, tt:916.828\n",
      "Ep:25, loss:0.00014, loss_test:0.07599, lr:1.00e-02, fs:0.81739 (r=0.870,p=0.770),  time:36.778, tt:956.231\n",
      "Ep:26, loss:0.00014, loss_test:0.07400, lr:1.00e-02, fs:0.82456 (r=0.870,p=0.783),  time:36.842, tt:994.725\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07206, lr:1.00e-02, fs:0.82456 (r=0.870,p=0.783),  time:36.822, tt:1031.016\n",
      "Ep:28, loss:0.00013, loss_test:0.07118, lr:1.00e-02, fs:0.83478 (r=0.889,p=0.787),  time:36.812, tt:1067.541\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.06978, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:36.803, tt:1104.101\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.06861, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:36.862, tt:1142.717\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.06736, lr:1.00e-02, fs:0.85470 (r=0.926,p=0.794),  time:36.870, tt:1179.846\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.06694, lr:1.00e-02, fs:0.85217 (r=0.907,p=0.803),  time:36.870, tt:1216.726\n",
      "Ep:33, loss:0.00011, loss_test:0.06566, lr:1.00e-02, fs:0.86207 (r=0.926,p=0.806),  time:36.861, tt:1253.274\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06466, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.900, tt:1291.513\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.06344, lr:1.00e-02, fs:0.86207 (r=0.926,p=0.806),  time:36.894, tt:1328.174\n",
      "Ep:36, loss:0.00010, loss_test:0.06274, lr:1.00e-02, fs:0.86207 (r=0.926,p=0.806),  time:36.856, tt:1363.658\n",
      "Ep:37, loss:0.00010, loss_test:0.06127, lr:1.00e-02, fs:0.85470 (r=0.926,p=0.794),  time:36.851, tt:1400.321\n",
      "Ep:38, loss:0.00009, loss_test:0.06071, lr:1.00e-02, fs:0.85470 (r=0.926,p=0.794),  time:36.843, tt:1436.872\n",
      "Ep:39, loss:0.00009, loss_test:0.05904, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.814, tt:1472.568\n",
      "Ep:40, loss:0.00009, loss_test:0.05925, lr:1.00e-02, fs:0.86207 (r=0.926,p=0.806),  time:36.851, tt:1510.879\n",
      "Ep:41, loss:0.00008, loss_test:0.05674, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.826, tt:1546.690\n",
      "Ep:42, loss:0.00008, loss_test:0.05605, lr:1.00e-02, fs:0.86207 (r=0.926,p=0.806),  time:36.826, tt:1583.502\n",
      "Ep:43, loss:0.00008, loss_test:0.05685, lr:1.00e-02, fs:0.85470 (r=0.926,p=0.794),  time:36.860, tt:1621.844\n",
      "Ep:44, loss:0.00008, loss_test:0.05483, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.829, tt:1657.287\n",
      "Ep:45, loss:0.00007, loss_test:0.05337, lr:1.00e-02, fs:0.86957 (r=0.926,p=0.820),  time:36.831, tt:1694.206\n",
      "Ep:46, loss:0.00007, loss_test:0.05393, lr:9.90e-03, fs:0.85470 (r=0.926,p=0.794),  time:36.803, tt:1729.750\n",
      "Ep:47, loss:0.00007, loss_test:0.05150, lr:9.80e-03, fs:0.86957 (r=0.926,p=0.820),  time:36.797, tt:1766.270\n",
      "Ep:48, loss:0.00007, loss_test:0.05038, lr:9.70e-03, fs:0.87719 (r=0.926,p=0.833),  time:36.806, tt:1803.505\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.05141, lr:9.70e-03, fs:0.86957 (r=0.926,p=0.820),  time:36.794, tt:1839.694\n",
      "Ep:50, loss:0.00007, loss_test:0.04953, lr:9.70e-03, fs:0.88496 (r=0.926,p=0.847),  time:36.794, tt:1876.514\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.04913, lr:9.70e-03, fs:0.89474 (r=0.944,p=0.850),  time:36.786, tt:1912.877\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.05046, lr:9.70e-03, fs:0.86207 (r=0.926,p=0.806),  time:36.776, tt:1949.111\n",
      "Ep:53, loss:0.00006, loss_test:0.04661, lr:9.70e-03, fs:0.89286 (r=0.926,p=0.862),  time:36.808, tt:1987.618\n",
      "Ep:54, loss:0.00006, loss_test:0.04666, lr:9.70e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.834, tt:2025.851\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.04727, lr:9.70e-03, fs:0.90265 (r=0.944,p=0.864),  time:36.812, tt:2061.479\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.04585, lr:9.70e-03, fs:0.89655 (r=0.963,p=0.839),  time:36.822, tt:2098.827\n",
      "Ep:59, loss:0.00005, loss_test:0.04304, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.798, tt:2207.859\n",
      "Ep:60, loss:0.00005, loss_test:0.04367, lr:9.70e-03, fs:0.90435 (r=0.963,p=0.852),  time:36.800, tt:2244.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00005, loss_test:0.04114, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.771, tt:2279.803\n",
      "Ep:62, loss:0.00005, loss_test:0.04085, lr:9.70e-03, fs:0.90435 (r=0.963,p=0.852),  time:36.754, tt:2315.523\n",
      "Ep:63, loss:0.00005, loss_test:0.04103, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.746, tt:2351.714\n",
      "Ep:64, loss:0.00005, loss_test:0.04051, lr:9.70e-03, fs:0.90435 (r=0.963,p=0.852),  time:36.719, tt:2386.717\n",
      "Ep:65, loss:0.00005, loss_test:0.04218, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.737, tt:2424.626\n",
      "Ep:66, loss:0.00005, loss_test:0.03835, lr:9.70e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.736, tt:2461.324\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.03825, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.721, tt:2497.015\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.03700, lr:9.70e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.703, tt:2532.521\n",
      "Ep:69, loss:0.00004, loss_test:0.03948, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.705, tt:2569.340\n",
      "Ep:70, loss:0.00004, loss_test:0.03567, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.688, tt:2604.873\n",
      "Ep:71, loss:0.00004, loss_test:0.03835, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.736, tt:2644.985\n",
      "Ep:72, loss:0.00004, loss_test:0.03427, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.716, tt:2680.246\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00004, loss_test:0.03574, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.713, tt:2716.765\n",
      "Ep:74, loss:0.00004, loss_test:0.03488, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.710, tt:2753.232\n",
      "Ep:75, loss:0.00004, loss_test:0.03539, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.701, tt:2789.294\n",
      "Ep:76, loss:0.00005, loss_test:0.03470, lr:9.70e-03, fs:0.91228 (r=0.963,p=0.867),  time:36.677, tt:2824.161\n",
      "Ep:77, loss:0.00004, loss_test:0.03373, lr:9.70e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.695, tt:2862.184\n",
      "Ep:78, loss:0.00004, loss_test:0.03155, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.701, tt:2899.395\n",
      "Ep:79, loss:0.00004, loss_test:0.03320, lr:9.70e-03, fs:0.92035 (r=0.963,p=0.881),  time:36.718, tt:2937.442\n",
      "Ep:80, loss:0.00004, loss_test:0.03164, lr:9.70e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.718, tt:2974.133\n",
      "Ep:81, loss:0.00004, loss_test:0.02999, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.749, tt:3013.392\n",
      "Ep:82, loss:0.00003, loss_test:0.03204, lr:9.70e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.774, tt:3052.226\n",
      "Ep:83, loss:0.00003, loss_test:0.02933, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.773, tt:3088.901\n",
      "Ep:84, loss:0.00004, loss_test:0.03002, lr:9.61e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.755, tt:3124.160\n",
      "Ep:85, loss:0.00003, loss_test:0.03034, lr:9.51e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.776, tt:3162.708\n",
      "Ep:86, loss:0.00003, loss_test:0.02850, lr:9.41e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.779, tt:3199.789\n",
      "Ep:87, loss:0.00003, loss_test:0.02956, lr:9.32e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.777, tt:3236.368\n",
      "Ep:88, loss:0.00003, loss_test:0.02993, lr:9.23e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.766, tt:3272.155\n",
      "Ep:89, loss:0.00003, loss_test:0.02674, lr:9.14e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.772, tt:3309.447\n",
      "Ep:90, loss:0.00003, loss_test:0.02879, lr:9.04e-03, fs:0.92857 (r=0.963,p=0.897),  time:36.774, tt:3346.456\n",
      "Ep:91, loss:0.00003, loss_test:0.02531, lr:8.95e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.775, tt:3383.296\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00003, loss_test:0.02643, lr:8.95e-03, fs:0.93694 (r=0.963,p=0.912),  time:36.784, tt:3420.883\n",
      "Ep:93, loss:0.00003, loss_test:0.02599, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.789, tt:3458.206\n",
      "Ep:94, loss:0.00003, loss_test:0.02493, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.782, tt:3494.310\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00003, loss_test:0.02570, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.774, tt:3530.279\n",
      "Ep:96, loss:0.00003, loss_test:0.02412, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.790, tt:3568.640\n",
      "Ep:97, loss:0.00003, loss_test:0.02490, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.799, tt:3606.300\n",
      "Ep:98, loss:0.00002, loss_test:0.02332, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.812, tt:3644.396\n",
      "Ep:99, loss:0.00002, loss_test:0.02472, lr:8.95e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.801, tt:3680.091\n",
      "Ep:100, loss:0.00002, loss_test:0.02295, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.805, tt:3717.346\n",
      "Ep:101, loss:0.00002, loss_test:0.02353, lr:8.95e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.810, tt:3754.582\n",
      "Ep:102, loss:0.00002, loss_test:0.02246, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.812, tt:3791.625\n",
      "Ep:103, loss:0.00002, loss_test:0.02246, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.801, tt:3827.257\n",
      "Ep:104, loss:0.00002, loss_test:0.02166, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.811, tt:3865.104\n",
      "Ep:105, loss:0.00002, loss_test:0.02158, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.808, tt:3901.695\n",
      "Ep:106, loss:0.00002, loss_test:0.02140, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.810, tt:3938.706\n",
      "Ep:107, loss:0.00002, loss_test:0.02136, lr:8.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.817, tt:3976.189\n",
      "Ep:108, loss:0.00002, loss_test:0.02325, lr:8.69e-03, fs:0.95495 (r=0.981,p=0.930),  time:36.790, tt:4010.084\n",
      "Ep:109, loss:0.00002, loss_test:0.02228, lr:8.60e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.762, tt:4043.788\n",
      "Ep:110, loss:0.00002, loss_test:0.02164, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.758, tt:4080.144\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.02106, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.759, tt:4116.991\n",
      "Ep:112, loss:0.00002, loss_test:0.02123, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.764, tt:4154.383\n",
      "Ep:113, loss:0.00002, loss_test:0.02058, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.762, tt:4190.822\n",
      "Ep:114, loss:0.00002, loss_test:0.02098, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.763, tt:4227.697\n",
      "Ep:115, loss:0.00002, loss_test:0.01978, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.758, tt:4263.920\n",
      "Ep:116, loss:0.00002, loss_test:0.02032, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.770, tt:4302.059\n",
      "Ep:117, loss:0.00002, loss_test:0.02003, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.773, tt:4339.255\n",
      "Ep:118, loss:0.00002, loss_test:0.01982, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.816, tt:4381.114\n",
      "Ep:119, loss:0.00002, loss_test:0.01947, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.822, tt:4418.634\n",
      "Ep:120, loss:0.00002, loss_test:0.01947, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.810, tt:4453.989\n",
      "Ep:121, loss:0.00002, loss_test:0.02018, lr:8.51e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.802, tt:4489.871\n",
      "Ep:122, loss:0.00002, loss_test:0.01969, lr:8.43e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.791, tt:4525.243\n",
      "Ep:123, loss:0.00002, loss_test:0.01990, lr:8.35e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.782, tt:4561.022\n",
      "Ep:124, loss:0.00002, loss_test:0.02020, lr:8.26e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.784, tt:4597.961\n",
      "Ep:125, loss:0.00002, loss_test:0.01934, lr:8.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.786, tt:4635.056\n",
      "Ep:126, loss:0.00002, loss_test:0.01952, lr:8.10e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.783, tt:4671.411\n",
      "Ep:127, loss:0.00002, loss_test:0.01973, lr:8.02e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.775, tt:4707.167\n",
      "Ep:128, loss:0.00002, loss_test:0.01973, lr:7.94e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.773, tt:4743.665\n",
      "Ep:129, loss:0.00002, loss_test:0.01962, lr:7.86e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.779, tt:4781.268\n",
      "Ep:130, loss:0.00002, loss_test:0.01900, lr:7.78e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.769, tt:4816.792\n",
      "Ep:131, loss:0.00002, loss_test:0.01925, lr:7.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.777, tt:4854.509\n",
      "Ep:132, loss:0.00002, loss_test:0.01895, lr:7.62e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.776, tt:4891.216\n",
      "Ep:133, loss:0.00002, loss_test:0.01837, lr:7.55e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.778, tt:4928.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.01863, lr:7.47e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.777, tt:4964.834\n",
      "Ep:135, loss:0.00001, loss_test:0.01860, lr:7.40e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.783, tt:5002.479\n",
      "Ep:136, loss:0.00001, loss_test:0.01836, lr:7.32e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.791, tt:5040.346\n",
      "Ep:137, loss:0.00001, loss_test:0.01781, lr:7.25e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.775, tt:5074.881\n",
      "Ep:138, loss:0.00001, loss_test:0.01826, lr:7.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.768, tt:5110.735\n",
      "Ep:139, loss:0.00001, loss_test:0.01801, lr:7.11e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.760, tt:5146.412\n",
      "Ep:140, loss:0.00001, loss_test:0.01796, lr:7.03e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.757, tt:5182.735\n",
      "Ep:141, loss:0.00001, loss_test:0.01782, lr:6.96e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.749, tt:5218.302\n",
      "Ep:142, loss:0.00001, loss_test:0.01781, lr:6.89e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.739, tt:5253.668\n",
      "Ep:143, loss:0.00001, loss_test:0.01755, lr:6.83e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.742, tt:5290.796\n",
      "Ep:144, loss:0.00001, loss_test:0.01745, lr:6.76e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.736, tt:5326.772\n",
      "Ep:145, loss:0.00001, loss_test:0.01732, lr:6.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.736, tt:5363.507\n",
      "Ep:146, loss:0.00001, loss_test:0.01732, lr:6.62e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.718, tt:5397.514\n",
      "Ep:147, loss:0.00001, loss_test:0.01738, lr:6.56e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.696, tt:5430.993\n",
      "Ep:148, loss:0.00001, loss_test:0.01732, lr:6.49e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.682, tt:5465.575\n",
      "Ep:149, loss:0.00001, loss_test:0.01726, lr:6.43e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.691, tt:5503.627\n",
      "Ep:150, loss:0.00001, loss_test:0.01715, lr:6.36e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.689, tt:5540.098\n",
      "Ep:151, loss:0.00001, loss_test:0.01723, lr:6.30e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.680, tt:5575.322\n",
      "Ep:152, loss:0.00001, loss_test:0.01695, lr:6.24e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.680, tt:5611.966\n",
      "Ep:153, loss:0.00001, loss_test:0.01758, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.677, tt:5648.272\n",
      "Ep:154, loss:0.00001, loss_test:0.01704, lr:6.11e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.682, tt:5685.784\n",
      "Ep:155, loss:0.00001, loss_test:0.01704, lr:6.05e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.718, tt:5728.007\n",
      "Ep:156, loss:0.00001, loss_test:0.01700, lr:5.99e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.724, tt:5765.695\n",
      "Ep:157, loss:0.00001, loss_test:0.01716, lr:5.93e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.715, tt:5801.015\n",
      "Ep:158, loss:0.00001, loss_test:0.01725, lr:5.87e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.715, tt:5837.610\n",
      "Ep:159, loss:0.00001, loss_test:0.01702, lr:5.81e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.710, tt:5873.566\n",
      "Ep:160, loss:0.00001, loss_test:0.01716, lr:5.75e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.704, tt:5909.299\n",
      "Ep:161, loss:0.00001, loss_test:0.01697, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.704, tt:5945.979\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00001, loss_test:0.01685, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.709, tt:5983.516\n",
      "Ep:163, loss:0.00001, loss_test:0.01670, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.712, tt:6020.828\n",
      "Ep:164, loss:0.00001, loss_test:0.01654, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.708, tt:6056.863\n",
      "Ep:165, loss:0.00001, loss_test:0.01675, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.711, tt:6094.042\n",
      "Ep:166, loss:0.00001, loss_test:0.01648, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.704, tt:6129.501\n",
      "Ep:167, loss:0.00001, loss_test:0.01672, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.697, tt:6165.016\n",
      "Ep:168, loss:0.00001, loss_test:0.01634, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.693, tt:6201.135\n",
      "Ep:169, loss:0.00001, loss_test:0.01648, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.702, tt:6239.378\n",
      "Ep:170, loss:0.00001, loss_test:0.01643, lr:5.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.708, tt:6277.100\n",
      "Ep:171, loss:0.00001, loss_test:0.01658, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.713, tt:6314.643\n",
      "Ep:172, loss:0.00001, loss_test:0.01644, lr:5.70e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.711, tt:6351.079\n",
      "Ep:173, loss:0.00001, loss_test:0.01639, lr:5.64e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.709, tt:6387.448\n",
      "Ep:174, loss:0.00001, loss_test:0.01635, lr:5.58e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.710, tt:6424.295\n",
      "Ep:175, loss:0.00001, loss_test:0.01626, lr:5.53e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.711, tt:6461.194\n",
      "Ep:176, loss:0.00001, loss_test:0.01622, lr:5.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.715, tt:6498.513\n",
      "Ep:177, loss:0.00001, loss_test:0.01627, lr:5.42e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.709, tt:6534.136\n",
      "Ep:178, loss:0.00001, loss_test:0.01606, lr:5.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.707, tt:6570.495\n",
      "Ep:179, loss:0.00001, loss_test:0.01610, lr:5.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.711, tt:6608.049\n",
      "Ep:180, loss:0.00001, loss_test:0.01613, lr:5.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.713, tt:6644.988\n",
      "Ep:181, loss:0.00001, loss_test:0.01612, lr:5.20e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.719, tt:6682.841\n",
      "Ep:182, loss:0.00001, loss_test:0.01621, lr:5.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.725, tt:6720.600\n",
      "Ep:183, loss:0.00001, loss_test:0.01613, lr:5.10e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.742, tt:6760.511\n",
      "Ep:184, loss:0.00001, loss_test:0.01591, lr:5.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.742, tt:6797.235\n",
      "Ep:185, loss:0.00001, loss_test:0.01598, lr:5.00e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.744, tt:6834.293\n",
      "Ep:186, loss:0.00001, loss_test:0.01567, lr:4.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.750, tt:6872.163\n",
      "Ep:187, loss:0.00001, loss_test:0.01584, lr:4.90e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.751, tt:6909.210\n",
      "Ep:188, loss:0.00001, loss_test:0.01594, lr:4.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.756, tt:6946.848\n",
      "Ep:189, loss:0.00001, loss_test:0.01590, lr:4.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.758, tt:6984.068\n",
      "Ep:190, loss:0.00001, loss_test:0.01610, lr:4.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.758, tt:7020.750\n",
      "Ep:191, loss:0.00001, loss_test:0.01577, lr:4.71e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.751, tt:7056.173\n",
      "Ep:192, loss:0.00001, loss_test:0.01581, lr:4.66e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.757, tt:7094.108\n",
      "Ep:193, loss:0.00001, loss_test:0.01591, lr:4.61e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.751, tt:7129.732\n",
      "Ep:194, loss:0.00001, loss_test:0.01630, lr:4.57e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.748, tt:7165.775\n",
      "Ep:195, loss:0.00001, loss_test:0.01634, lr:4.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.755, tt:7203.944\n",
      "Ep:196, loss:0.00001, loss_test:0.01596, lr:4.48e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.751, tt:7239.912\n",
      "Ep:197, loss:0.00001, loss_test:0.01575, lr:4.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.754, tt:7277.371\n",
      "Ep:198, loss:0.00001, loss_test:0.01582, lr:4.39e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.759, tt:7315.007\n",
      "Ep:199, loss:0.00001, loss_test:0.01612, lr:4.34e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.760, tt:7352.006\n",
      "Ep:200, loss:0.00001, loss_test:0.01598, lr:4.30e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.763, tt:7389.357\n",
      "Ep:201, loss:0.00001, loss_test:0.01549, lr:4.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.761, tt:7425.800\n",
      "Ep:202, loss:0.00001, loss_test:0.01569, lr:4.21e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.761, tt:7462.445\n",
      "Ep:203, loss:0.00001, loss_test:0.01578, lr:4.17e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.745, tt:7496.000\n",
      "Ep:204, loss:0.00001, loss_test:0.01556, lr:4.13e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.693, tt:7521.975\n",
      "Ep:205, loss:0.00001, loss_test:0.01554, lr:4.09e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.601, tt:7539.818\n",
      "Ep:206, loss:0.00001, loss_test:0.01536, lr:4.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.500, tt:7555.414\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1956 Test samples: 108\n",
      "Train positive samples: 978 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02329, lr:6.00e-02, fs:0.66667 (r=0.796,p=0.573),  time:28.888, tt:28.888\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02301, lr:6.00e-02, fs:0.68000 (r=0.944,p=0.531),  time:27.122, tt:54.244\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02520, lr:6.00e-02, fs:0.67925 (r=1.000,p=0.514),  time:27.954, tt:83.863\n",
      "Ep:3, loss:0.00005, loss_test:0.02526, lr:6.00e-02, fs:0.66667 (r=0.963,p=0.510),  time:29.006, tt:116.025\n",
      "Ep:4, loss:0.00005, loss_test:0.02518, lr:6.00e-02, fs:0.67105 (r=0.944,p=0.520),  time:29.510, tt:147.551\n",
      "Ep:5, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.67568 (r=0.926,p=0.532),  time:30.544, tt:183.265\n",
      "Ep:6, loss:0.00005, loss_test:0.02473, lr:6.00e-02, fs:0.68493 (r=0.926,p=0.543),  time:30.894, tt:216.260\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02428, lr:6.00e-02, fs:0.65217 (r=0.833,p=0.536),  time:31.117, tt:248.939\n",
      "Ep:8, loss:0.00005, loss_test:0.02387, lr:6.00e-02, fs:0.65217 (r=0.833,p=0.536),  time:31.140, tt:280.257\n",
      "Ep:9, loss:0.00005, loss_test:0.02323, lr:6.00e-02, fs:0.65714 (r=0.852,p=0.535),  time:31.005, tt:310.054\n",
      "Ep:10, loss:0.00005, loss_test:0.02259, lr:6.00e-02, fs:0.65714 (r=0.852,p=0.535),  time:31.100, tt:342.102\n",
      "Ep:11, loss:0.00005, loss_test:0.02221, lr:6.00e-02, fs:0.67568 (r=0.926,p=0.532),  time:31.219, tt:374.626\n",
      "Ep:12, loss:0.00005, loss_test:0.02145, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:31.540, tt:410.026\n",
      "Ep:13, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.67133 (r=0.889,p=0.539),  time:31.706, tt:443.889\n",
      "Ep:14, loss:0.00004, loss_test:0.02017, lr:6.00e-02, fs:0.67143 (r=0.870,p=0.547),  time:31.871, tt:478.060\n",
      "Ep:15, loss:0.00004, loss_test:0.01987, lr:6.00e-02, fs:0.68571 (r=0.889,p=0.558),  time:32.115, tt:513.838\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01976, lr:6.00e-02, fs:0.67143 (r=0.870,p=0.547),  time:32.288, tt:548.889\n",
      "Ep:17, loss:0.00004, loss_test:0.01952, lr:6.00e-02, fs:0.67606 (r=0.889,p=0.545),  time:32.383, tt:582.896\n",
      "Ep:18, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.68085 (r=0.889,p=0.552),  time:32.485, tt:617.221\n",
      "Ep:19, loss:0.00004, loss_test:0.01861, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:32.560, tt:651.201\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01845, lr:6.00e-02, fs:0.70000 (r=0.907,p=0.570),  time:32.668, tt:686.037\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01833, lr:6.00e-02, fs:0.70423 (r=0.926,p=0.568),  time:32.779, tt:721.146\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01802, lr:6.00e-02, fs:0.71831 (r=0.944,p=0.580),  time:32.840, tt:755.310\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.72340 (r=0.944,p=0.586),  time:32.845, tt:788.268\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.71429 (r=0.926,p=0.581),  time:32.937, tt:823.424\n",
      "Ep:25, loss:0.00003, loss_test:0.01712, lr:6.00e-02, fs:0.72340 (r=0.944,p=0.586),  time:32.970, tt:857.230\n",
      "Ep:26, loss:0.00003, loss_test:0.01687, lr:6.00e-02, fs:0.72857 (r=0.944,p=0.593),  time:33.081, tt:893.197\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.75556 (r=0.944,p=0.630),  time:33.190, tt:929.315\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.76119 (r=0.944,p=0.637),  time:33.223, tt:963.477\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01561, lr:6.00e-02, fs:0.75362 (r=0.963,p=0.619),  time:33.282, tt:998.464\n",
      "Ep:30, loss:0.00003, loss_test:0.01519, lr:6.00e-02, fs:0.77037 (r=0.963,p=0.642),  time:33.330, tt:1033.226\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01475, lr:6.00e-02, fs:0.78195 (r=0.963,p=0.658),  time:33.389, tt:1068.439\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01434, lr:6.00e-02, fs:0.80303 (r=0.981,p=0.679),  time:33.384, tt:1101.688\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01399, lr:6.00e-02, fs:0.78519 (r=0.981,p=0.654),  time:33.435, tt:1136.799\n",
      "Ep:34, loss:0.00003, loss_test:0.01359, lr:6.00e-02, fs:0.79389 (r=0.963,p=0.675),  time:33.494, tt:1172.296\n",
      "Ep:35, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.79389 (r=0.963,p=0.675),  time:33.513, tt:1206.484\n",
      "Ep:36, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.78788 (r=0.963,p=0.667),  time:33.591, tt:1242.860\n",
      "Ep:37, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.81890 (r=0.963,p=0.712),  time:33.623, tt:1277.684\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.80000 (r=0.963,p=0.684),  time:33.664, tt:1312.893\n",
      "Ep:39, loss:0.00002, loss_test:0.01240, lr:6.00e-02, fs:0.80620 (r=0.963,p=0.693),  time:33.730, tt:1349.197\n",
      "Ep:40, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.81250 (r=0.963,p=0.703),  time:33.741, tt:1383.372\n",
      "Ep:41, loss:0.00002, loss_test:0.01184, lr:6.00e-02, fs:0.81250 (r=0.963,p=0.703),  time:33.724, tt:1416.398\n",
      "Ep:42, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.80952 (r=0.944,p=0.708),  time:33.742, tt:1450.922\n",
      "Ep:43, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.81890 (r=0.963,p=0.712),  time:33.777, tt:1486.206\n",
      "Ep:44, loss:0.00002, loss_test:0.01134, lr:6.00e-02, fs:0.82540 (r=0.963,p=0.722),  time:33.815, tt:1521.686\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.82540 (r=0.963,p=0.722),  time:33.844, tt:1556.820\n",
      "Ep:46, loss:0.00002, loss_test:0.01118, lr:6.00e-02, fs:0.80952 (r=0.944,p=0.708),  time:33.875, tt:1592.108\n",
      "Ep:47, loss:0.00002, loss_test:0.01080, lr:6.00e-02, fs:0.84553 (r=0.963,p=0.754),  time:33.927, tt:1628.487\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01055, lr:6.00e-02, fs:0.84298 (r=0.944,p=0.761),  time:33.941, tt:1663.099\n",
      "Ep:49, loss:0.00002, loss_test:0.01083, lr:6.00e-02, fs:0.84553 (r=0.963,p=0.754),  time:33.997, tt:1699.839\n",
      "Ep:50, loss:0.00002, loss_test:0.01017, lr:6.00e-02, fs:0.83607 (r=0.944,p=0.750),  time:33.997, tt:1733.854\n",
      "Ep:51, loss:0.00002, loss_test:0.01009, lr:6.00e-02, fs:0.85246 (r=0.963,p=0.765),  time:34.041, tt:1770.154\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.85246 (r=0.963,p=0.765),  time:34.076, tt:1806.019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02245, lr:6.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:31.202, tt:31.202\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02266, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:31.224, tt:62.447\n",
      "Ep:2, loss:0.00005, loss_test:0.02388, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.281, tt:93.842\n",
      "Ep:3, loss:0.00005, loss_test:0.02264, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:31.336, tt:125.345\n",
      "Ep:4, loss:0.00005, loss_test:0.02249, lr:6.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:31.326, tt:156.630\n",
      "Ep:5, loss:0.00005, loss_test:0.02236, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:31.263, tt:187.575\n",
      "Ep:6, loss:0.00005, loss_test:0.02195, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:31.308, tt:219.156\n",
      "Ep:7, loss:0.00005, loss_test:0.02145, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:31.501, tt:252.006\n",
      "Ep:8, loss:0.00004, loss_test:0.02096, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:31.493, tt:283.441\n",
      "Ep:9, loss:0.00004, loss_test:0.02015, lr:6.00e-02, fs:0.67883 (r=0.939,p=0.531),  time:31.535, tt:315.353\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01928, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:31.475, tt:346.221\n",
      "Ep:11, loss:0.00004, loss_test:0.01842, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:31.456, tt:377.475\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01798, lr:6.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:31.470, tt:409.107\n",
      "Ep:13, loss:0.00004, loss_test:0.01794, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:31.594, tt:442.323\n",
      "Ep:14, loss:0.00004, loss_test:0.01775, lr:6.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:31.546, tt:473.189\n",
      "Ep:15, loss:0.00004, loss_test:0.01725, lr:6.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:31.415, tt:502.634\n",
      "Ep:16, loss:0.00003, loss_test:0.01666, lr:6.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:31.380, tt:533.454\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:31.373, tt:564.714\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:31.353, tt:595.706\n",
      "Ep:19, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:31.347, tt:626.950\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:31.304, tt:657.386\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01530, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:31.339, tt:689.465\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:31.336, tt:720.737\n",
      "Ep:23, loss:0.00003, loss_test:0.01496, lr:6.00e-02, fs:0.74894 (r=0.889,p=0.647),  time:31.353, tt:752.469\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01467, lr:6.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:31.353, tt:783.820\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01440, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:31.375, tt:815.757\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:31.402, tt:847.863\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:31.353, tt:877.880\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01412, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:31.353, tt:909.245\n",
      "Ep:29, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:31.307, tt:939.218\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:31.324, tt:971.050\n",
      "Ep:31, loss:0.00002, loss_test:0.01380, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:31.291, tt:1001.321\n",
      "Ep:32, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:31.232, tt:1030.652\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:31.202, tt:1060.866\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01366, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:31.176, tt:1091.162\n",
      "Ep:35, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:31.185, tt:1122.666\n",
      "Ep:36, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:31.237, tt:1155.768\n",
      "Ep:37, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:31.234, tt:1186.885\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:31.234, tt:1218.133\n",
      "Ep:39, loss:0.00001, loss_test:0.01391, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:31.225, tt:1249.018\n",
      "Ep:40, loss:0.00001, loss_test:0.01351, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.191, tt:1278.832\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01405, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.179, tt:1309.508\n",
      "Ep:42, loss:0.00001, loss_test:0.01387, lr:6.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.179, tt:1340.713\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01432, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.131, tt:1369.749\n",
      "Ep:44, loss:0.00001, loss_test:0.01388, lr:6.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.131, tt:1400.900\n",
      "Ep:45, loss:0.00001, loss_test:0.01457, lr:6.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:31.125, tt:1431.768\n",
      "Ep:46, loss:0.00001, loss_test:0.01376, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.132, tt:1463.203\n",
      "Ep:47, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:31.118, tt:1493.658\n",
      "Ep:48, loss:0.00001, loss_test:0.01386, lr:6.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:31.104, tt:1524.084\n",
      "Ep:49, loss:0.00001, loss_test:0.01465, lr:6.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:31.105, tt:1555.236\n",
      "Ep:50, loss:0.00001, loss_test:0.01418, lr:6.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:31.104, tt:1586.282\n",
      "Ep:51, loss:0.00001, loss_test:0.01440, lr:6.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.100, tt:1617.195\n",
      "Ep:52, loss:0.00001, loss_test:0.01476, lr:6.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:31.099, tt:1648.260\n",
      "Ep:53, loss:0.00001, loss_test:0.01444, lr:6.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:31.104, tt:1679.628\n",
      "Ep:54, loss:0.00001, loss_test:0.01445, lr:5.94e-02, fs:0.81319 (r=0.747,p=0.892),  time:31.106, tt:1710.828\n",
      "Ep:55, loss:0.00001, loss_test:0.01460, lr:5.88e-02, fs:0.79558 (r=0.727,p=0.878),  time:31.105, tt:1741.895\n",
      "Ep:56, loss:0.00001, loss_test:0.01432, lr:5.82e-02, fs:0.80663 (r=0.737,p=0.890),  time:31.115, tt:1773.528\n",
      "Ep:57, loss:0.00001, loss_test:0.01475, lr:5.76e-02, fs:0.79330 (r=0.717,p=0.887),  time:31.122, tt:1805.100\n",
      "Ep:58, loss:0.00001, loss_test:0.01426, lr:5.71e-02, fs:0.80220 (r=0.737,p=0.880),  time:31.130, tt:1836.684\n",
      "Ep:59, loss:0.00001, loss_test:0.01509, lr:5.65e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.098, tt:1865.904\n",
      "Ep:60, loss:0.00001, loss_test:0.01465, lr:5.59e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.104, tt:1897.356\n",
      "Ep:61, loss:0.00001, loss_test:0.01476, lr:5.54e-02, fs:0.78453 (r=0.717,p=0.866),  time:31.100, tt:1928.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01506, lr:5.48e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.089, tt:1958.637\n",
      "Ep:63, loss:0.00001, loss_test:0.01541, lr:5.43e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.100, tt:1990.399\n",
      "Ep:64, loss:0.00001, loss_test:0.01463, lr:5.37e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.125, tt:2023.127\n",
      "Ep:65, loss:0.00001, loss_test:0.01547, lr:5.32e-02, fs:0.77966 (r=0.697,p=0.885),  time:31.123, tt:2054.124\n",
      "Ep:66, loss:0.00001, loss_test:0.01514, lr:5.27e-02, fs:0.77714 (r=0.687,p=0.895),  time:31.125, tt:2085.376\n",
      "Ep:67, loss:0.00001, loss_test:0.01525, lr:5.21e-02, fs:0.78613 (r=0.687,p=0.919),  time:31.155, tt:2118.574\n",
      "Ep:68, loss:0.00001, loss_test:0.01551, lr:5.16e-02, fs:0.77011 (r=0.677,p=0.893),  time:31.158, tt:2149.921\n",
      "Ep:69, loss:0.00001, loss_test:0.01592, lr:5.11e-02, fs:0.77457 (r=0.677,p=0.905),  time:31.182, tt:2182.754\n",
      "Ep:70, loss:0.00001, loss_test:0.01545, lr:5.06e-02, fs:0.77457 (r=0.677,p=0.905),  time:31.193, tt:2214.684\n",
      "Ep:71, loss:0.00001, loss_test:0.01609, lr:5.01e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.219, tt:2247.736\n",
      "Ep:72, loss:0.00001, loss_test:0.01558, lr:4.96e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.227, tt:2279.572\n",
      "Ep:73, loss:0.00000, loss_test:0.01611, lr:4.91e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.243, tt:2312.012\n",
      "Ep:74, loss:0.00000, loss_test:0.01625, lr:4.86e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.266, tt:2344.983\n",
      "Ep:75, loss:0.00000, loss_test:0.01645, lr:4.81e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.271, tt:2376.631\n",
      "Ep:76, loss:0.00000, loss_test:0.01634, lr:4.76e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.267, tt:2407.592\n",
      "Ep:77, loss:0.00000, loss_test:0.01649, lr:4.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.274, tt:2439.367\n",
      "Ep:78, loss:0.00000, loss_test:0.01689, lr:4.67e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.287, tt:2471.687\n",
      "Ep:79, loss:0.00000, loss_test:0.01645, lr:4.62e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.288, tt:2503.005\n",
      "Ep:80, loss:0.00000, loss_test:0.01697, lr:4.57e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.279, tt:2533.599\n",
      "Ep:81, loss:0.00000, loss_test:0.01698, lr:4.53e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.265, tt:2563.725\n",
      "Ep:82, loss:0.00000, loss_test:0.01784, lr:4.48e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.248, tt:2593.578\n",
      "Ep:83, loss:0.00000, loss_test:0.01701, lr:4.44e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.250, tt:2625.019\n",
      "Ep:84, loss:0.00000, loss_test:0.01753, lr:4.39e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.239, tt:2655.278\n",
      "Ep:85, loss:0.00000, loss_test:0.01781, lr:4.35e-02, fs:0.77907 (r=0.677,p=0.918),  time:31.227, tt:2685.556\n",
      "Ep:86, loss:0.00000, loss_test:0.01735, lr:4.31e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.217, tt:2715.852\n",
      "Ep:87, loss:0.00000, loss_test:0.01769, lr:4.26e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.216, tt:2746.984\n",
      "Ep:88, loss:0.00000, loss_test:0.01809, lr:4.22e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.206, tt:2777.329\n",
      "Ep:89, loss:0.00000, loss_test:0.01743, lr:4.18e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.206, tt:2808.568\n",
      "Ep:90, loss:0.00000, loss_test:0.01814, lr:4.14e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.198, tt:2839.051\n",
      "Ep:91, loss:0.00000, loss_test:0.01800, lr:4.10e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.188, tt:2869.340\n",
      "Ep:92, loss:0.00000, loss_test:0.01838, lr:4.05e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.174, tt:2899.195\n",
      "Ep:93, loss:0.00000, loss_test:0.01844, lr:4.01e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.170, tt:2929.966\n",
      "Ep:94, loss:0.00000, loss_test:0.01817, lr:3.97e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.175, tt:2961.587\n",
      "Ep:95, loss:0.00000, loss_test:0.01888, lr:3.93e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.157, tt:2991.093\n",
      "Ep:96, loss:0.00000, loss_test:0.01850, lr:3.89e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.141, tt:3020.673\n",
      "Ep:97, loss:0.00000, loss_test:0.01872, lr:3.86e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.130, tt:3050.749\n",
      "Ep:98, loss:0.00000, loss_test:0.01893, lr:3.82e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.142, tt:3083.010\n",
      "Ep:99, loss:0.00000, loss_test:0.01926, lr:3.78e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.115, tt:3111.510\n",
      "Ep:100, loss:0.00000, loss_test:0.01916, lr:3.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.087, tt:3139.825\n",
      "Ep:101, loss:0.00000, loss_test:0.01945, lr:3.70e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.084, tt:3170.608\n",
      "Ep:102, loss:0.00000, loss_test:0.01924, lr:3.67e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.089, tt:3202.139\n",
      "Ep:103, loss:0.00000, loss_test:0.02013, lr:3.63e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.073, tt:3231.567\n",
      "Ep:104, loss:0.00000, loss_test:0.01961, lr:3.59e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.065, tt:3261.860\n",
      "Ep:105, loss:0.00000, loss_test:0.02005, lr:3.56e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.082, tt:3294.719\n",
      "Ep:106, loss:0.00000, loss_test:0.01976, lr:3.52e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.069, tt:3324.431\n",
      "Ep:107, loss:0.00000, loss_test:0.02031, lr:3.49e-02, fs:0.77193 (r=0.667,p=0.917),  time:31.063, tt:3354.810\n",
      "Ep:108, loss:0.00000, loss_test:0.01994, lr:3.45e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.052, tt:3384.675\n",
      "Ep:109, loss:0.00000, loss_test:0.02076, lr:3.42e-02, fs:0.77647 (r=0.667,p=0.930),  time:31.021, tt:3412.268\n",
      "Ep:110, loss:0.00000, loss_test:0.02019, lr:3.38e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.997, tt:3440.708\n",
      "Ep:111, loss:0.00000, loss_test:0.02082, lr:3.35e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.982, tt:3470.011\n",
      "Ep:112, loss:0.00000, loss_test:0.02042, lr:3.32e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.962, tt:3498.738\n",
      "Ep:113, loss:0.00000, loss_test:0.02100, lr:3.28e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.963, tt:3529.758\n",
      "Ep:114, loss:0.00000, loss_test:0.02053, lr:3.25e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.959, tt:3560.331\n",
      "Ep:115, loss:0.00000, loss_test:0.02085, lr:3.22e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.952, tt:3590.406\n",
      "Ep:116, loss:0.00000, loss_test:0.02102, lr:3.19e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.955, tt:3621.696\n",
      "Ep:117, loss:0.00000, loss_test:0.02111, lr:3.15e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.950, tt:3652.120\n",
      "Ep:118, loss:0.00000, loss_test:0.02107, lr:3.12e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.938, tt:3681.629\n",
      "Ep:119, loss:0.00000, loss_test:0.02149, lr:3.09e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.927, tt:3711.230\n",
      "Ep:120, loss:0.00000, loss_test:0.02107, lr:3.06e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.930, tt:3742.506\n",
      "Ep:121, loss:0.00000, loss_test:0.02163, lr:3.03e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.929, tt:3773.358\n",
      "Ep:122, loss:0.00000, loss_test:0.02136, lr:3.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.935, tt:3804.950\n",
      "Ep:123, loss:0.00000, loss_test:0.02154, lr:2.97e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.949, tt:3837.630\n",
      "Ep:124, loss:0.00000, loss_test:0.02165, lr:2.94e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.960, tt:3869.960\n",
      "Ep:125, loss:0.00000, loss_test:0.02159, lr:2.91e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.965, tt:3901.556\n",
      "Ep:126, loss:0.00000, loss_test:0.02201, lr:2.88e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.970, tt:3933.139\n",
      "Ep:127, loss:0.00000, loss_test:0.02167, lr:2.85e-02, fs:0.78571 (r=0.667,p=0.957),  time:30.978, tt:3965.203\n",
      "Ep:128, loss:0.00000, loss_test:0.02207, lr:2.82e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.983, tt:3996.848\n",
      "Ep:129, loss:0.00000, loss_test:0.02190, lr:2.80e-02, fs:0.78571 (r=0.667,p=0.957),  time:30.989, tt:4028.512\n",
      "Ep:130, loss:0.00000, loss_test:0.02217, lr:2.77e-02, fs:0.78571 (r=0.667,p=0.957),  time:30.997, tt:4060.550\n",
      "Ep:131, loss:0.00000, loss_test:0.02220, lr:2.74e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.004, tt:4092.512\n",
      "Ep:132, loss:0.00000, loss_test:0.02227, lr:2.71e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.016, tt:4125.142\n",
      "Ep:133, loss:0.00000, loss_test:0.02242, lr:2.69e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.022, tt:4156.893\n",
      "Ep:134, loss:0.00000, loss_test:0.02252, lr:2.66e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.024, tt:4188.210\n",
      "Ep:135, loss:0.00000, loss_test:0.02238, lr:2.63e-02, fs:0.79042 (r=0.667,p=0.971),  time:31.032, tt:4220.287\n",
      "Ep:136, loss:0.00000, loss_test:0.02273, lr:2.61e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.042, tt:4252.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02263, lr:2.58e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.049, tt:4284.711\n",
      "Ep:138, loss:0.00000, loss_test:0.02252, lr:2.55e-02, fs:0.78571 (r=0.667,p=0.957),  time:31.061, tt:4317.422\n",
      "Ep:139, loss:0.00000, loss_test:0.02306, lr:2.53e-02, fs:0.77844 (r=0.657,p=0.956),  time:31.067, tt:4349.425\n",
      "Ep:140, loss:0.00000, loss_test:0.02266, lr:2.50e-02, fs:0.77576 (r=0.646,p=0.970),  time:31.075, tt:4381.507\n",
      "Ep:141, loss:0.00000, loss_test:0.02321, lr:2.48e-02, fs:0.78313 (r=0.657,p=0.970),  time:31.070, tt:4411.953\n",
      "Ep:142, loss:0.00000, loss_test:0.02274, lr:2.45e-02, fs:0.77576 (r=0.646,p=0.970),  time:31.072, tt:4443.297\n",
      "Ep:143, loss:0.00000, loss_test:0.02310, lr:2.43e-02, fs:0.78313 (r=0.657,p=0.970),  time:31.062, tt:4472.870\n",
      "Ep:144, loss:0.00000, loss_test:0.02319, lr:2.40e-02, fs:0.76829 (r=0.636,p=0.969),  time:31.067, tt:4504.679\n",
      "Ep:145, loss:0.00000, loss_test:0.02316, lr:2.38e-02, fs:0.77576 (r=0.646,p=0.970),  time:31.059, tt:4534.623\n",
      "Ep:146, loss:0.00000, loss_test:0.02343, lr:2.36e-02, fs:0.78313 (r=0.657,p=0.970),  time:31.064, tt:4566.370\n",
      "Ep:147, loss:0.00000, loss_test:0.02314, lr:2.33e-02, fs:0.75309 (r=0.616,p=0.968),  time:31.058, tt:4596.555\n",
      "Ep:148, loss:0.00000, loss_test:0.02354, lr:2.31e-02, fs:0.78313 (r=0.657,p=0.970),  time:31.066, tt:4628.856\n",
      "Ep:149, loss:0.00000, loss_test:0.02326, lr:2.29e-02, fs:0.75309 (r=0.616,p=0.968),  time:31.062, tt:4659.337\n",
      "Ep:150, loss:0.00000, loss_test:0.02372, lr:2.26e-02, fs:0.77576 (r=0.646,p=0.970),  time:31.058, tt:4689.726\n",
      "Ep:151, loss:0.00000, loss_test:0.02340, lr:2.24e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.047, tt:4719.219\n",
      "Ep:152, loss:0.00000, loss_test:0.02377, lr:2.22e-02, fs:0.76829 (r=0.636,p=0.969),  time:31.041, tt:4749.338\n",
      "Ep:153, loss:0.00000, loss_test:0.02367, lr:2.20e-02, fs:0.76074 (r=0.626,p=0.969),  time:31.036, tt:4779.594\n",
      "Ep:154, loss:0.00000, loss_test:0.02366, lr:2.17e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.044, tt:4811.828\n",
      "Ep:155, loss:0.00000, loss_test:0.02398, lr:2.15e-02, fs:0.76074 (r=0.626,p=0.969),  time:31.038, tt:4841.853\n",
      "Ep:156, loss:0.00000, loss_test:0.02390, lr:2.13e-02, fs:0.74534 (r=0.606,p=0.968),  time:31.030, tt:4871.741\n",
      "Ep:157, loss:0.00000, loss_test:0.02399, lr:2.11e-02, fs:0.76074 (r=0.626,p=0.969),  time:31.027, tt:4902.311\n",
      "Ep:158, loss:0.00000, loss_test:0.02391, lr:2.09e-02, fs:0.74534 (r=0.606,p=0.968),  time:31.030, tt:4933.816\n",
      "Ep:159, loss:0.00000, loss_test:0.02407, lr:2.07e-02, fs:0.75309 (r=0.616,p=0.968),  time:31.032, tt:4965.047\n",
      "Ep:160, loss:0.00000, loss_test:0.02395, lr:2.05e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.030, tt:4995.827\n",
      "Ep:161, loss:0.00000, loss_test:0.02430, lr:2.03e-02, fs:0.75309 (r=0.616,p=0.968),  time:31.031, tt:5027.083\n",
      "Ep:162, loss:0.00000, loss_test:0.02422, lr:2.01e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.035, tt:5058.657\n",
      "Ep:163, loss:0.00000, loss_test:0.02444, lr:1.99e-02, fs:0.75309 (r=0.616,p=0.968),  time:31.025, tt:5088.121\n",
      "Ep:164, loss:0.00000, loss_test:0.02425, lr:1.97e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.012, tt:5117.011\n",
      "Ep:165, loss:0.00000, loss_test:0.02442, lr:1.95e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.008, tt:5147.282\n",
      "Ep:166, loss:0.00000, loss_test:0.02447, lr:1.93e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.002, tt:5177.385\n",
      "Ep:167, loss:0.00000, loss_test:0.02444, lr:1.91e-02, fs:0.72956 (r=0.586,p=0.967),  time:30.997, tt:5207.458\n",
      "Ep:168, loss:0.00000, loss_test:0.02473, lr:1.89e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.991, tt:5237.548\n",
      "Ep:169, loss:0.00000, loss_test:0.02456, lr:1.87e-02, fs:0.72956 (r=0.586,p=0.967),  time:30.991, tt:5268.488\n",
      "Ep:170, loss:0.00000, loss_test:0.02463, lr:1.85e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.005, tt:5301.773\n",
      "Ep:171, loss:0.00000, loss_test:0.02464, lr:1.83e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.004, tt:5332.670\n",
      "Ep:172, loss:0.00000, loss_test:0.02480, lr:1.81e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.005, tt:5363.900\n",
      "Ep:173, loss:0.00000, loss_test:0.02470, lr:1.80e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.005, tt:5394.814\n",
      "Ep:174, loss:0.00000, loss_test:0.02496, lr:1.78e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.015, tt:5427.665\n",
      "Ep:175, loss:0.00000, loss_test:0.02492, lr:1.76e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.013, tt:5458.353\n",
      "Ep:176, loss:0.00000, loss_test:0.02493, lr:1.74e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.011, tt:5488.995\n",
      "Ep:177, loss:0.00000, loss_test:0.02516, lr:1.73e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.006, tt:5519.026\n",
      "Ep:178, loss:0.00000, loss_test:0.02495, lr:1.71e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.002, tt:5549.427\n",
      "Ep:179, loss:0.00000, loss_test:0.02516, lr:1.69e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.008, tt:5581.406\n",
      "Ep:180, loss:0.00000, loss_test:0.02528, lr:1.67e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.013, tt:5613.428\n",
      "Ep:181, loss:0.00000, loss_test:0.02507, lr:1.66e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.012, tt:5644.173\n",
      "Ep:182, loss:0.00000, loss_test:0.02530, lr:1.64e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.016, tt:5675.918\n",
      "Ep:183, loss:0.00000, loss_test:0.02530, lr:1.62e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.026, tt:5708.760\n",
      "Ep:184, loss:0.00000, loss_test:0.02516, lr:1.61e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.027, tt:5739.911\n",
      "Ep:185, loss:0.00000, loss_test:0.02557, lr:1.59e-02, fs:0.73750 (r=0.596,p=0.967),  time:31.023, tt:5770.266\n",
      "Ep:186, loss:0.00000, loss_test:0.02533, lr:1.58e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.024, tt:5801.399\n",
      "Ep:187, loss:0.00000, loss_test:0.02540, lr:1.56e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.025, tt:5832.719\n",
      "Ep:188, loss:0.00000, loss_test:0.02554, lr:1.54e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.031, tt:5864.845\n",
      "Ep:189, loss:0.00000, loss_test:0.02546, lr:1.53e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.024, tt:5894.622\n",
      "Ep:190, loss:0.00000, loss_test:0.02548, lr:1.51e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.027, tt:5926.234\n",
      "Ep:191, loss:0.00000, loss_test:0.02557, lr:1.50e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.027, tt:5957.276\n",
      "Ep:192, loss:0.00000, loss_test:0.02561, lr:1.48e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.029, tt:5988.620\n",
      "Ep:193, loss:0.00000, loss_test:0.02568, lr:1.47e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.037, tt:6021.210\n",
      "Ep:194, loss:0.00000, loss_test:0.02573, lr:1.45e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.045, tt:6053.850\n",
      "Ep:195, loss:0.00000, loss_test:0.02567, lr:1.44e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.048, tt:6085.494\n",
      "Ep:196, loss:0.00000, loss_test:0.02573, lr:1.43e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.051, tt:6117.103\n",
      "Ep:197, loss:0.00000, loss_test:0.02584, lr:1.41e-02, fs:0.72956 (r=0.586,p=0.967),  time:31.049, tt:6147.787\n",
      "Ep:198, loss:0.00000, loss_test:0.02585, lr:1.40e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.050, tt:6179.040\n",
      "Ep:199, loss:0.00000, loss_test:0.02574, lr:1.38e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.046, tt:6209.249\n",
      "Ep:200, loss:0.00000, loss_test:0.02593, lr:1.37e-02, fs:0.72152 (r=0.576,p=0.966),  time:31.041, tt:6239.201\n",
      "Ep:201, loss:0.00000, loss_test:0.02590, lr:1.36e-02, fs:0.71338 (r=0.566,p=0.966),  time:31.001, tt:6262.156\n",
      "Ep:202, loss:0.00000, loss_test:0.02595, lr:1.34e-02, fs:0.72152 (r=0.576,p=0.966),  time:30.967, tt:6286.394\n",
      "Ep:203, loss:0.00000, loss_test:0.02598, lr:1.33e-02, fs:0.71338 (r=0.566,p=0.966),  time:30.952, tt:6314.206\n",
      "Ep:204, loss:0.00000, loss_test:0.02609, lr:1.32e-02, fs:0.72152 (r=0.576,p=0.966),  time:30.922, tt:6338.952\n",
      "Ep:205, loss:0.00000, loss_test:0.02602, lr:1.30e-02, fs:0.71338 (r=0.566,p=0.966),  time:30.879, tt:6361.097\n",
      "Ep:206, loss:0.00000, loss_test:0.02599, lr:1.29e-02, fs:0.71338 (r=0.566,p=0.966),  time:30.880, tt:6392.216\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.11807, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:30.980, tt:30.980\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00027, loss_test:0.11831, lr:1.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:30.202, tt:60.404\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11878, lr:1.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:30.680, tt:92.041\n",
      "Ep:3, loss:0.00026, loss_test:0.11861, lr:1.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:31.088, tt:124.352\n",
      "Ep:4, loss:0.00026, loss_test:0.11727, lr:1.00e-02, fs:0.70498 (r=0.929,p=0.568),  time:30.759, tt:153.797\n",
      "Ep:5, loss:0.00026, loss_test:0.11544, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:30.830, tt:184.983\n",
      "Ep:6, loss:0.00025, loss_test:0.11356, lr:1.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:30.856, tt:215.991\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11168, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:30.751, tt:246.009\n",
      "Ep:8, loss:0.00025, loss_test:0.10982, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:30.618, tt:275.562\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.10883, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:30.616, tt:306.160\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.10861, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:30.715, tt:337.868\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10868, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:30.782, tt:369.379\n",
      "Ep:12, loss:0.00023, loss_test:0.10720, lr:1.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:30.840, tt:400.924\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10597, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:30.989, tt:433.845\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.10534, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:31.033, tt:465.491\n",
      "Ep:15, loss:0.00021, loss_test:0.10337, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:31.163, tt:498.602\n",
      "Ep:16, loss:0.00021, loss_test:0.10132, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.268, tt:531.554\n",
      "Ep:17, loss:0.00020, loss_test:0.10049, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:31.261, tt:562.702\n",
      "Ep:18, loss:0.00020, loss_test:0.09952, lr:1.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:31.360, tt:595.842\n",
      "Ep:19, loss:0.00019, loss_test:0.09761, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:31.398, tt:627.969\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.09534, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:31.414, tt:659.693\n",
      "Ep:21, loss:0.00018, loss_test:0.09337, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:31.483, tt:692.629\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.09322, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:31.442, tt:723.155\n",
      "Ep:23, loss:0.00017, loss_test:0.09144, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:31.462, tt:755.085\n",
      "Ep:24, loss:0.00017, loss_test:0.09126, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:31.431, tt:785.768\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08856, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:31.386, tt:816.026\n",
      "Ep:26, loss:0.00016, loss_test:0.08754, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:31.385, tt:847.398\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.08464, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:31.328, tt:877.181\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.08292, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:31.269, tt:906.795\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.07896, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:31.223, tt:936.681\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.07825, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:31.244, tt:968.559\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.10001, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:31.243, tt:999.764\n",
      "Ep:32, loss:0.00014, loss_test:0.07494, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:31.165, tt:1028.460\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08859, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:31.126, tt:1058.278\n",
      "Ep:34, loss:0.00012, loss_test:0.07397, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:31.114, tt:1089.007\n",
      "Ep:35, loss:0.00012, loss_test:0.08258, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.079, tt:1118.833\n",
      "Ep:36, loss:0.00011, loss_test:0.08253, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:31.110, tt:1151.084\n",
      "Ep:37, loss:0.00011, loss_test:0.07446, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:31.124, tt:1182.705\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.07852, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:31.134, tt:1214.223\n",
      "Ep:39, loss:0.00009, loss_test:0.09751, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:31.119, tt:1244.770\n",
      "Ep:40, loss:0.00009, loss_test:0.07125, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:31.098, tt:1275.009\n",
      "Ep:41, loss:0.00011, loss_test:0.09760, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:31.116, tt:1306.863\n",
      "Ep:42, loss:0.00010, loss_test:0.09857, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:31.140, tt:1339.039\n",
      "Ep:43, loss:0.00009, loss_test:0.08128, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.121, tt:1369.334\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.08755, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:31.141, tt:1401.326\n",
      "Ep:45, loss:0.00008, loss_test:0.08035, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:31.161, tt:1433.388\n",
      "Ep:46, loss:0.00007, loss_test:0.08101, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:31.172, tt:1465.086\n",
      "Ep:47, loss:0.00007, loss_test:0.07340, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.173, tt:1496.298\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08802, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:31.137, tt:1525.725\n",
      "Ep:49, loss:0.00006, loss_test:0.07449, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:31.144, tt:1557.198\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07875, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.154, tt:1588.837\n",
      "Ep:51, loss:0.00006, loss_test:0.08338, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.185, tt:1621.623\n",
      "Ep:52, loss:0.00006, loss_test:0.07582, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.231, tt:1655.254\n",
      "Ep:53, loss:0.00006, loss_test:0.07334, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.242, tt:1687.090\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.07846, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.272, tt:1719.980\n",
      "Ep:55, loss:0.00005, loss_test:0.08429, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:31.295, tt:1752.540\n",
      "Ep:56, loss:0.00005, loss_test:0.07837, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.314, tt:1784.904\n",
      "Ep:57, loss:0.00005, loss_test:0.08819, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:31.315, tt:1816.293\n",
      "Ep:58, loss:0.00005, loss_test:0.06875, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.317, tt:1847.677\n",
      "Ep:59, loss:0.00005, loss_test:0.07769, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:31.337, tt:1880.207\n",
      "Ep:60, loss:0.00004, loss_test:0.08159, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:31.335, tt:1911.427\n",
      "Ep:61, loss:0.00004, loss_test:0.07301, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.350, tt:1943.677\n",
      "Ep:62, loss:0.00004, loss_test:0.07980, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:31.356, tt:1975.403\n",
      "Ep:63, loss:0.00004, loss_test:0.07731, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:31.353, tt:2006.569\n",
      "Ep:64, loss:0.00004, loss_test:0.08270, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.357, tt:2038.173\n",
      "Ep:65, loss:0.00004, loss_test:0.07199, lr:9.90e-03, fs:0.80447 (r=0.727,p=0.900),  time:31.365, tt:2070.112\n",
      "Ep:66, loss:0.00005, loss_test:0.08742, lr:9.80e-03, fs:0.77528 (r=0.697,p=0.873),  time:31.375, tt:2102.124\n",
      "Ep:67, loss:0.00005, loss_test:0.08654, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.374, tt:2133.465\n",
      "Ep:68, loss:0.00004, loss_test:0.07418, lr:9.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.361, tt:2163.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00004, loss_test:0.08720, lr:9.51e-03, fs:0.81081 (r=0.758,p=0.872),  time:31.376, tt:2196.306\n",
      "Ep:70, loss:0.00004, loss_test:0.07556, lr:9.41e-03, fs:0.82162 (r=0.768,p=0.884),  time:31.380, tt:2227.997\n",
      "Ep:71, loss:0.00004, loss_test:0.08827, lr:9.32e-03, fs:0.78161 (r=0.687,p=0.907),  time:31.392, tt:2260.189\n",
      "Ep:72, loss:0.00004, loss_test:0.08465, lr:9.23e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.393, tt:2291.715\n",
      "Ep:73, loss:0.00003, loss_test:0.08097, lr:9.14e-03, fs:0.81319 (r=0.747,p=0.892),  time:31.372, tt:2321.533\n",
      "Ep:74, loss:0.00004, loss_test:0.07679, lr:9.04e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.383, tt:2353.741\n",
      "Ep:75, loss:0.00003, loss_test:0.09142, lr:8.95e-03, fs:0.79775 (r=0.717,p=0.899),  time:31.376, tt:2384.579\n",
      "Ep:76, loss:0.00003, loss_test:0.07075, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.394, tt:2417.364\n",
      "Ep:77, loss:0.00003, loss_test:0.09124, lr:8.78e-03, fs:0.82081 (r=0.717,p=0.959),  time:31.402, tt:2449.337\n",
      "Ep:78, loss:0.00003, loss_test:0.07875, lr:8.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.411, tt:2481.487\n",
      "Ep:79, loss:0.00003, loss_test:0.07370, lr:8.60e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.413, tt:2513.008\n",
      "Ep:80, loss:0.00003, loss_test:0.09017, lr:8.51e-03, fs:0.76364 (r=0.636,p=0.955),  time:31.422, tt:2545.143\n",
      "Ep:81, loss:0.00003, loss_test:0.07862, lr:8.43e-03, fs:0.82486 (r=0.737,p=0.936),  time:31.432, tt:2577.390\n",
      "Ep:82, loss:0.00003, loss_test:0.07743, lr:8.35e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.434, tt:2609.010\n",
      "Ep:83, loss:0.00002, loss_test:0.09435, lr:8.26e-03, fs:0.78571 (r=0.667,p=0.957),  time:31.453, tt:2642.069\n",
      "Ep:84, loss:0.00002, loss_test:0.07931, lr:8.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.471, tt:2675.036\n",
      "Ep:85, loss:0.00002, loss_test:0.07755, lr:8.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.500, tt:2708.978\n",
      "Ep:86, loss:0.00002, loss_test:0.08121, lr:8.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.522, tt:2742.407\n",
      "Ep:87, loss:0.00002, loss_test:0.07744, lr:7.94e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.550, tt:2776.430\n",
      "Ep:88, loss:0.00002, loss_test:0.08020, lr:7.86e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.607, tt:2812.995\n",
      "Ep:89, loss:0.00002, loss_test:0.08192, lr:7.78e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.652, tt:2848.720\n",
      "Ep:90, loss:0.00002, loss_test:0.08537, lr:7.70e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.693, tt:2884.071\n",
      "Ep:91, loss:0.00002, loss_test:0.07777, lr:7.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.767, tt:2922.561\n",
      "Ep:92, loss:0.00002, loss_test:0.08440, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.825, tt:2959.770\n",
      "Ep:93, loss:0.00002, loss_test:0.08437, lr:7.47e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.862, tt:2994.984\n",
      "Ep:94, loss:0.00002, loss_test:0.08173, lr:7.40e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.904, tt:3030.865\n",
      "Ep:95, loss:0.00001, loss_test:0.08682, lr:7.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.939, tt:3066.134\n",
      "Ep:96, loss:0.00001, loss_test:0.08209, lr:7.25e-03, fs:0.86034 (r=0.778,p=0.963),  time:31.984, tt:3102.422\n",
      "Ep:97, loss:0.00001, loss_test:0.08237, lr:7.18e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.026, tt:3138.521\n",
      "Ep:98, loss:0.00001, loss_test:0.09062, lr:7.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:32.064, tt:3174.371\n",
      "Ep:99, loss:0.00001, loss_test:0.08162, lr:7.03e-03, fs:0.86667 (r=0.788,p=0.963),  time:32.116, tt:3211.596\n",
      "Ep:100, loss:0.00001, loss_test:0.08660, lr:6.96e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.170, tt:3249.200\n",
      "Ep:101, loss:0.00001, loss_test:0.08370, lr:6.89e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.192, tt:3283.633\n",
      "Ep:102, loss:0.00001, loss_test:0.08791, lr:6.83e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.220, tt:3318.615\n",
      "Ep:103, loss:0.00001, loss_test:0.08540, lr:6.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.251, tt:3354.124\n",
      "Ep:104, loss:0.00001, loss_test:0.08081, lr:6.69e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.291, tt:3390.594\n",
      "Ep:105, loss:0.00001, loss_test:0.09202, lr:6.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:32.330, tt:3426.970\n",
      "Ep:106, loss:0.00001, loss_test:0.08126, lr:6.56e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.338, tt:3460.204\n",
      "Ep:107, loss:0.00001, loss_test:0.08863, lr:6.49e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.337, tt:3492.421\n",
      "Ep:108, loss:0.00001, loss_test:0.08775, lr:6.43e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.368, tt:3528.102\n",
      "Ep:109, loss:0.00001, loss_test:0.08443, lr:6.36e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.396, tt:3563.533\n",
      "Ep:110, loss:0.00001, loss_test:0.09083, lr:6.30e-03, fs:0.74074 (r=0.606,p=0.952),  time:32.408, tt:3597.244\n",
      "Ep:111, loss:0.00001, loss_test:0.08207, lr:6.24e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.433, tt:3632.526\n",
      "Ep:112, loss:0.00001, loss_test:0.09006, lr:6.17e-03, fs:0.75610 (r=0.626,p=0.954),  time:32.457, tt:3667.613\n",
      "Ep:113, loss:0.00001, loss_test:0.08332, lr:6.11e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.479, tt:3702.553\n",
      "Ep:114, loss:0.00001, loss_test:0.08682, lr:6.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.496, tt:3737.049\n",
      "Ep:115, loss:0.00001, loss_test:0.08740, lr:5.99e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.520, tt:3772.340\n",
      "Ep:116, loss:0.00001, loss_test:0.08427, lr:5.93e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.534, tt:3806.477\n",
      "Ep:117, loss:0.00001, loss_test:0.08648, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.557, tt:3841.718\n",
      "Ep:118, loss:0.00001, loss_test:0.08557, lr:5.81e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.573, tt:3876.139\n",
      "Ep:119, loss:0.00001, loss_test:0.08702, lr:5.75e-03, fs:0.79290 (r=0.677,p=0.957),  time:32.588, tt:3910.606\n",
      "Ep:120, loss:0.00001, loss_test:0.08648, lr:5.70e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.605, tt:3945.178\n",
      "Ep:121, loss:0.00001, loss_test:0.08532, lr:5.64e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.630, tt:3980.909\n",
      "Ep:122, loss:0.00001, loss_test:0.09126, lr:5.58e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.648, tt:4015.658\n",
      "Ep:123, loss:0.00001, loss_test:0.08245, lr:5.53e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.668, tt:4050.806\n",
      "Ep:124, loss:0.00001, loss_test:0.09032, lr:5.47e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.677, tt:4084.617\n",
      "Ep:125, loss:0.00001, loss_test:0.08445, lr:5.42e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.682, tt:4117.879\n",
      "Ep:126, loss:0.00001, loss_test:0.08691, lr:5.36e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.702, tt:4153.113\n",
      "Ep:127, loss:0.00001, loss_test:0.09007, lr:5.31e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.710, tt:4186.834\n",
      "Ep:128, loss:0.00001, loss_test:0.08424, lr:5.26e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.716, tt:4220.371\n",
      "Ep:129, loss:0.00001, loss_test:0.08623, lr:5.20e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.722, tt:4253.920\n",
      "Ep:130, loss:0.00001, loss_test:0.08451, lr:5.15e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.742, tt:4289.153\n",
      "Ep:131, loss:0.00001, loss_test:0.08623, lr:5.10e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.753, tt:4323.381\n",
      "Ep:132, loss:0.00001, loss_test:0.08444, lr:5.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.764, tt:4357.675\n",
      "Ep:133, loss:0.00001, loss_test:0.08579, lr:5.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.772, tt:4391.463\n",
      "Ep:134, loss:0.00001, loss_test:0.08472, lr:4.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.781, tt:4425.444\n",
      "Ep:135, loss:0.00001, loss_test:0.08690, lr:4.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.787, tt:4459.018\n",
      "Ep:136, loss:0.00001, loss_test:0.08494, lr:4.85e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.801, tt:4493.757\n",
      "Ep:137, loss:0.00001, loss_test:0.08500, lr:4.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.824, tt:4529.663\n",
      "Ep:138, loss:0.00001, loss_test:0.08555, lr:4.75e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.852, tt:4566.451\n",
      "Ep:139, loss:0.00001, loss_test:0.08199, lr:4.71e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.862, tt:4600.622\n",
      "Ep:140, loss:0.00001, loss_test:0.08471, lr:4.66e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.897, tt:4638.536\n",
      "Ep:141, loss:0.00001, loss_test:0.08432, lr:4.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.922, tt:4674.868\n",
      "Ep:142, loss:0.00001, loss_test:0.08446, lr:4.57e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.942, tt:4710.760\n",
      "Ep:143, loss:0.00001, loss_test:0.08610, lr:4.52e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.951, tt:4744.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.08220, lr:4.48e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.974, tt:4781.189\n",
      "Ep:145, loss:0.00001, loss_test:0.08606, lr:4.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.993, tt:4816.964\n",
      "Ep:146, loss:0.00001, loss_test:0.08469, lr:4.39e-03, fs:0.85393 (r=0.768,p=0.962),  time:33.015, tt:4853.244\n",
      "Ep:147, loss:0.00001, loss_test:0.08341, lr:4.34e-03, fs:0.84746 (r=0.758,p=0.962),  time:33.039, tt:4889.722\n",
      "Ep:148, loss:0.00001, loss_test:0.08787, lr:4.30e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.064, tt:4926.524\n",
      "Ep:149, loss:0.00001, loss_test:0.08517, lr:4.26e-03, fs:0.84746 (r=0.758,p=0.962),  time:33.073, tt:4960.990\n",
      "Ep:150, loss:0.00001, loss_test:0.08504, lr:4.21e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.096, tt:4997.479\n",
      "Ep:151, loss:0.00001, loss_test:0.08598, lr:4.17e-03, fs:0.85393 (r=0.768,p=0.962),  time:33.117, tt:5033.805\n",
      "Ep:152, loss:0.00001, loss_test:0.08337, lr:4.13e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.131, tt:5069.097\n",
      "Ep:153, loss:0.00001, loss_test:0.08324, lr:4.09e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.144, tt:5104.139\n",
      "Ep:154, loss:0.00001, loss_test:0.08511, lr:4.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.164, tt:5140.466\n",
      "Ep:155, loss:0.00001, loss_test:0.08499, lr:4.01e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.189, tt:5177.530\n",
      "Ep:156, loss:0.00001, loss_test:0.08407, lr:3.97e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.206, tt:5213.385\n",
      "Ep:157, loss:0.00001, loss_test:0.08632, lr:3.93e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.225, tt:5249.532\n",
      "Ep:158, loss:0.00001, loss_test:0.08354, lr:3.89e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.248, tt:5286.422\n",
      "Ep:159, loss:0.00001, loss_test:0.08514, lr:3.85e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.270, tt:5323.226\n",
      "Ep:160, loss:0.00001, loss_test:0.08496, lr:3.81e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.295, tt:5360.558\n",
      "Ep:161, loss:0.00001, loss_test:0.08534, lr:3.77e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.311, tt:5396.308\n",
      "Ep:162, loss:0.00001, loss_test:0.08669, lr:3.73e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.335, tt:5433.569\n",
      "Ep:163, loss:0.00001, loss_test:0.08403, lr:3.70e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.356, tt:5470.331\n",
      "Ep:164, loss:0.00001, loss_test:0.08495, lr:3.66e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.368, tt:5505.677\n",
      "Ep:165, loss:0.00001, loss_test:0.08615, lr:3.62e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.383, tt:5541.625\n",
      "Ep:166, loss:0.00001, loss_test:0.08257, lr:3.59e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.402, tt:5578.162\n",
      "Ep:167, loss:0.00001, loss_test:0.08430, lr:3.55e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.429, tt:5616.095\n",
      "Ep:168, loss:0.00001, loss_test:0.08535, lr:3.52e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.442, tt:5651.740\n",
      "Ep:169, loss:0.00001, loss_test:0.08387, lr:3.48e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.463, tt:5688.704\n",
      "Ep:170, loss:0.00001, loss_test:0.08426, lr:3.45e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.488, tt:5726.512\n",
      "Ep:171, loss:0.00001, loss_test:0.08424, lr:3.41e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.508, tt:5763.441\n",
      "Ep:172, loss:0.00001, loss_test:0.08399, lr:3.38e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.527, tt:5800.242\n",
      "Ep:173, loss:0.00001, loss_test:0.08380, lr:3.34e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.558, tt:5839.098\n",
      "Ep:174, loss:0.00001, loss_test:0.08456, lr:3.31e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.567, tt:5874.150\n",
      "Ep:175, loss:0.00001, loss_test:0.08387, lr:3.28e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.582, tt:5910.366\n",
      "Ep:176, loss:0.00001, loss_test:0.08351, lr:3.24e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.590, tt:5945.394\n",
      "Ep:177, loss:0.00001, loss_test:0.08418, lr:3.21e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.602, tt:5981.162\n",
      "Ep:178, loss:0.00001, loss_test:0.08395, lr:3.18e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.614, tt:6016.987\n",
      "Ep:179, loss:0.00001, loss_test:0.08404, lr:3.15e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.636, tt:6054.484\n",
      "Ep:180, loss:0.00001, loss_test:0.08451, lr:3.12e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.652, tt:6090.990\n",
      "Ep:181, loss:0.00001, loss_test:0.08392, lr:3.09e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.663, tt:6126.734\n",
      "Ep:182, loss:0.00001, loss_test:0.08419, lr:3.05e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.679, tt:6163.282\n",
      "Ep:183, loss:0.00001, loss_test:0.08434, lr:3.02e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.697, tt:6200.262\n",
      "Ep:184, loss:0.00001, loss_test:0.08336, lr:2.99e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.713, tt:6236.932\n",
      "Ep:185, loss:0.00001, loss_test:0.08443, lr:2.96e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.728, tt:6273.457\n",
      "Ep:186, loss:0.00001, loss_test:0.08420, lr:2.93e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.745, tt:6310.293\n",
      "Ep:187, loss:0.00000, loss_test:0.08351, lr:2.90e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.758, tt:6346.502\n",
      "Ep:188, loss:0.00000, loss_test:0.08422, lr:2.88e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.776, tt:6383.749\n",
      "Ep:189, loss:0.00000, loss_test:0.08375, lr:2.85e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.793, tt:6420.601\n",
      "Ep:190, loss:0.00000, loss_test:0.08392, lr:2.82e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.805, tt:6456.777\n",
      "Ep:191, loss:0.00001, loss_test:0.08393, lr:2.79e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.827, tt:6494.783\n",
      "Ep:192, loss:0.00000, loss_test:0.08464, lr:2.76e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.837, tt:6530.515\n",
      "Ep:193, loss:0.00000, loss_test:0.08437, lr:2.73e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.856, tt:6567.973\n",
      "Ep:194, loss:0.00000, loss_test:0.08399, lr:2.71e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.873, tt:6605.248\n",
      "Ep:195, loss:0.00000, loss_test:0.08473, lr:2.68e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.887, tt:6641.760\n",
      "Ep:196, loss:0.00000, loss_test:0.08420, lr:2.65e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.907, tt:6679.748\n",
      "Ep:197, loss:0.00000, loss_test:0.08383, lr:2.63e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.929, tt:6717.945\n",
      "Ep:198, loss:0.00000, loss_test:0.08452, lr:2.60e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.939, tt:6753.951\n",
      "Ep:199, loss:0.00000, loss_test:0.08456, lr:2.57e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.955, tt:6790.938\n",
      "Ep:200, loss:0.00000, loss_test:0.08369, lr:2.55e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.970, tt:6827.920\n",
      "Ep:201, loss:0.00000, loss_test:0.08441, lr:2.52e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.986, tt:6865.145\n",
      "Ep:202, loss:0.00000, loss_test:0.08579, lr:2.50e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.982, tt:6898.347\n",
      "Ep:203, loss:0.00000, loss_test:0.08481, lr:2.47e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.943, tt:6924.376\n",
      "Ep:204, loss:0.00000, loss_test:0.08434, lr:2.45e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.923, tt:6954.200\n",
      "Ep:205, loss:0.00000, loss_test:0.08446, lr:2.42e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.892, tt:6981.697\n",
      "Ep:206, loss:0.00000, loss_test:0.08470, lr:2.40e-03, fs:0.86034 (r=0.778,p=0.963),  time:33.840, tt:7004.815\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02455, lr:6.00e-02, fs:0.67532 (r=0.788,p=0.591),  time:35.969, tt:35.969\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02370, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:35.888, tt:71.775\n",
      "Ep:2, loss:0.00005, loss_test:0.02617, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:35.506, tt:106.517\n",
      "Ep:3, loss:0.00005, loss_test:0.02606, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:35.496, tt:141.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00005, loss_test:0.02526, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:35.775, tt:178.877\n",
      "Ep:5, loss:0.00005, loss_test:0.02485, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:35.845, tt:215.069\n",
      "Ep:6, loss:0.00005, loss_test:0.02447, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:35.808, tt:250.657\n",
      "Ep:7, loss:0.00005, loss_test:0.02412, lr:6.00e-02, fs:0.64419 (r=0.869,p=0.512),  time:35.752, tt:286.016\n",
      "Ep:8, loss:0.00005, loss_test:0.02344, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:35.826, tt:322.435\n",
      "Ep:9, loss:0.00005, loss_test:0.02276, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:35.655, tt:356.545\n",
      "Ep:10, loss:0.00005, loss_test:0.02262, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:35.535, tt:390.888\n",
      "Ep:11, loss:0.00005, loss_test:0.02227, lr:6.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:35.480, tt:425.763\n",
      "Ep:12, loss:0.00005, loss_test:0.02154, lr:5.94e-02, fs:0.65693 (r=0.909,p=0.514),  time:35.449, tt:460.831\n",
      "Ep:13, loss:0.00005, loss_test:0.02052, lr:5.88e-02, fs:0.66667 (r=0.899,p=0.530),  time:35.466, tt:496.520\n",
      "Ep:14, loss:0.00004, loss_test:0.01977, lr:5.82e-02, fs:0.66923 (r=0.879,p=0.540),  time:35.600, tt:534.006\n",
      "Ep:15, loss:0.00004, loss_test:0.01939, lr:5.76e-02, fs:0.67442 (r=0.879,p=0.547),  time:35.643, tt:570.288\n",
      "Ep:16, loss:0.00004, loss_test:0.01926, lr:5.71e-02, fs:0.68702 (r=0.909,p=0.552),  time:35.660, tt:606.228\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01922, lr:5.71e-02, fs:0.69173 (r=0.929,p=0.551),  time:35.587, tt:640.567\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01911, lr:5.71e-02, fs:0.69173 (r=0.929,p=0.551),  time:35.594, tt:676.288\n",
      "Ep:19, loss:0.00004, loss_test:0.01894, lr:5.71e-02, fs:0.69173 (r=0.929,p=0.551),  time:35.573, tt:711.452\n",
      "Ep:20, loss:0.00004, loss_test:0.01880, lr:5.71e-02, fs:0.68679 (r=0.919,p=0.548),  time:35.528, tt:746.085\n",
      "Ep:21, loss:0.00004, loss_test:0.01870, lr:5.71e-02, fs:0.68421 (r=0.919,p=0.545),  time:35.489, tt:780.752\n",
      "Ep:22, loss:0.00004, loss_test:0.01854, lr:5.71e-02, fs:0.67910 (r=0.919,p=0.538),  time:35.563, tt:817.955\n",
      "Ep:23, loss:0.00004, loss_test:0.01837, lr:5.71e-02, fs:0.68165 (r=0.919,p=0.542),  time:35.550, tt:853.196\n",
      "Ep:24, loss:0.00004, loss_test:0.01817, lr:5.71e-02, fs:0.68914 (r=0.929,p=0.548),  time:35.556, tt:888.892\n",
      "Ep:25, loss:0.00004, loss_test:0.01794, lr:5.71e-02, fs:0.69173 (r=0.929,p=0.551),  time:35.547, tt:924.226\n",
      "Ep:26, loss:0.00004, loss_test:0.01782, lr:5.71e-02, fs:0.69925 (r=0.939,p=0.557),  time:35.524, tt:959.154\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01760, lr:5.71e-02, fs:0.70722 (r=0.939,p=0.567),  time:35.500, tt:993.993\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01735, lr:5.71e-02, fs:0.70543 (r=0.919,p=0.572),  time:35.450, tt:1028.060\n",
      "Ep:29, loss:0.00004, loss_test:0.01735, lr:5.71e-02, fs:0.70588 (r=0.909,p=0.577),  time:35.438, tt:1063.141\n",
      "Ep:30, loss:0.00003, loss_test:0.01741, lr:5.71e-02, fs:0.70039 (r=0.909,p=0.570),  time:35.417, tt:1097.925\n",
      "Ep:31, loss:0.00003, loss_test:0.01735, lr:5.71e-02, fs:0.70866 (r=0.909,p=0.581),  time:35.388, tt:1132.430\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01733, lr:5.71e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.392, tt:1167.942\n",
      "Ep:33, loss:0.00003, loss_test:0.01724, lr:5.71e-02, fs:0.70400 (r=0.889,p=0.583),  time:35.356, tt:1202.112\n",
      "Ep:34, loss:0.00003, loss_test:0.01718, lr:5.71e-02, fs:0.71774 (r=0.899,p=0.597),  time:35.343, tt:1237.021\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01727, lr:5.71e-02, fs:0.72428 (r=0.889,p=0.611),  time:35.287, tt:1270.331\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01725, lr:5.71e-02, fs:0.72574 (r=0.869,p=0.623),  time:35.244, tt:1304.021\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01720, lr:5.71e-02, fs:0.72574 (r=0.869,p=0.623),  time:35.257, tt:1339.772\n",
      "Ep:38, loss:0.00003, loss_test:0.01766, lr:5.71e-02, fs:0.72881 (r=0.869,p=0.628),  time:35.249, tt:1374.696\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01719, lr:5.71e-02, fs:0.72881 (r=0.869,p=0.628),  time:35.248, tt:1409.902\n",
      "Ep:40, loss:0.00003, loss_test:0.01700, lr:5.71e-02, fs:0.72727 (r=0.848,p=0.636),  time:35.259, tt:1445.637\n",
      "Ep:41, loss:0.00003, loss_test:0.01714, lr:5.71e-02, fs:0.73362 (r=0.848,p=0.646),  time:35.200, tt:1478.409\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01715, lr:5.71e-02, fs:0.73362 (r=0.848,p=0.646),  time:35.189, tt:1513.108\n",
      "Ep:43, loss:0.00003, loss_test:0.01689, lr:5.71e-02, fs:0.72807 (r=0.838,p=0.643),  time:35.157, tt:1546.928\n",
      "Ep:44, loss:0.00003, loss_test:0.01711, lr:5.71e-02, fs:0.73362 (r=0.848,p=0.646),  time:35.146, tt:1581.557\n",
      "Ep:45, loss:0.00002, loss_test:0.01686, lr:5.71e-02, fs:0.73778 (r=0.838,p=0.659),  time:35.137, tt:1616.299\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01691, lr:5.71e-02, fs:0.72646 (r=0.818,p=0.653),  time:35.095, tt:1649.451\n",
      "Ep:47, loss:0.00002, loss_test:0.01664, lr:5.71e-02, fs:0.73303 (r=0.818,p=0.664),  time:35.053, tt:1682.547\n",
      "Ep:48, loss:0.00002, loss_test:0.01693, lr:5.71e-02, fs:0.74654 (r=0.818,p=0.686),  time:35.046, tt:1717.264\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01647, lr:5.71e-02, fs:0.74654 (r=0.818,p=0.686),  time:35.054, tt:1752.687\n",
      "Ep:50, loss:0.00002, loss_test:0.01659, lr:5.71e-02, fs:0.75701 (r=0.818,p=0.704),  time:35.025, tt:1786.261\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01662, lr:5.71e-02, fs:0.77143 (r=0.818,p=0.730),  time:34.988, tt:1819.402\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01638, lr:5.71e-02, fs:0.77725 (r=0.828,p=0.732),  time:34.983, tt:1854.075\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01663, lr:5.71e-02, fs:0.77725 (r=0.828,p=0.732),  time:34.970, tt:1888.362\n",
      "Ep:54, loss:0.00002, loss_test:0.01627, lr:5.71e-02, fs:0.77143 (r=0.818,p=0.730),  time:34.968, tt:1923.227\n",
      "Ep:55, loss:0.00002, loss_test:0.01634, lr:5.71e-02, fs:0.78469 (r=0.828,p=0.745),  time:34.956, tt:1957.522\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01612, lr:5.71e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.950, tt:1992.165\n",
      "Ep:57, loss:0.00002, loss_test:0.01678, lr:5.71e-02, fs:0.80000 (r=0.828,p=0.774),  time:34.934, tt:2026.153\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01583, lr:5.71e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.930, tt:2060.875\n",
      "Ep:59, loss:0.00002, loss_test:0.01645, lr:5.71e-02, fs:0.79612 (r=0.828,p=0.766),  time:34.925, tt:2095.506\n",
      "Ep:60, loss:0.00002, loss_test:0.01573, lr:5.71e-02, fs:0.77512 (r=0.818,p=0.736),  time:34.932, tt:2130.858\n",
      "Ep:61, loss:0.00002, loss_test:0.01661, lr:5.71e-02, fs:0.80392 (r=0.828,p=0.781),  time:34.913, tt:2164.612\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01565, lr:5.71e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.898, tt:2198.566\n",
      "Ep:63, loss:0.00001, loss_test:0.01724, lr:5.71e-02, fs:0.80788 (r=0.828,p=0.788),  time:34.896, tt:2233.346\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01555, lr:5.71e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.887, tt:2267.677\n",
      "Ep:65, loss:0.00001, loss_test:0.01720, lr:5.71e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.872, tt:2301.583\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01537, lr:5.71e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.864, tt:2335.900\n",
      "Ep:67, loss:0.00001, loss_test:0.01684, lr:5.71e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.846, tt:2369.533\n",
      "Ep:68, loss:0.00001, loss_test:0.01557, lr:5.71e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.837, tt:2403.783\n",
      "Ep:69, loss:0.00001, loss_test:0.01587, lr:5.71e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.858, tt:2440.084\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01727, lr:5.71e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.858, tt:2474.952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00001, loss_test:0.01553, lr:5.71e-02, fs:0.80829 (r=0.788,p=0.830),  time:34.844, tt:2508.779\n",
      "Ep:72, loss:0.00001, loss_test:0.01618, lr:5.71e-02, fs:0.82292 (r=0.798,p=0.849),  time:34.842, tt:2543.439\n",
      "Ep:73, loss:0.00001, loss_test:0.01711, lr:5.71e-02, fs:0.80000 (r=0.768,p=0.835),  time:34.858, tt:2579.517\n",
      "Ep:74, loss:0.00001, loss_test:0.01628, lr:5.71e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.848, tt:2613.580\n",
      "Ep:75, loss:0.00001, loss_test:0.01662, lr:5.71e-02, fs:0.78075 (r=0.737,p=0.830),  time:34.835, tt:2647.468\n",
      "Ep:76, loss:0.00001, loss_test:0.01683, lr:5.71e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.835, tt:2682.321\n",
      "Ep:77, loss:0.00001, loss_test:0.01680, lr:5.71e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.842, tt:2717.669\n",
      "Ep:78, loss:0.00001, loss_test:0.01645, lr:5.71e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.839, tt:2752.290\n",
      "Ep:79, loss:0.00001, loss_test:0.01649, lr:5.71e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.819, tt:2785.517\n",
      "Ep:80, loss:0.00001, loss_test:0.01750, lr:5.71e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.833, tt:2821.462\n",
      "Ep:81, loss:0.00001, loss_test:0.01873, lr:5.65e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.806, tt:2854.053\n",
      "Ep:82, loss:0.00001, loss_test:0.01924, lr:5.59e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.787, tt:2887.301\n",
      "Ep:83, loss:0.00001, loss_test:0.01739, lr:5.54e-02, fs:0.76571 (r=0.677,p=0.882),  time:34.810, tt:2924.080\n",
      "Ep:84, loss:0.00001, loss_test:0.01839, lr:5.48e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.812, tt:2959.045\n",
      "Ep:85, loss:0.00001, loss_test:0.01812, lr:5.43e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.818, tt:2994.343\n",
      "Ep:86, loss:0.00001, loss_test:0.01886, lr:5.37e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.817, tt:3029.074\n",
      "Ep:87, loss:0.00001, loss_test:0.02043, lr:5.32e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.837, tt:3065.684\n",
      "Ep:88, loss:0.00001, loss_test:0.02034, lr:5.27e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.825, tt:3099.400\n",
      "Ep:89, loss:0.00001, loss_test:0.01884, lr:5.21e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.812, tt:3133.070\n",
      "Ep:90, loss:0.00001, loss_test:0.01573, lr:5.16e-02, fs:0.74866 (r=0.707,p=0.795),  time:34.800, tt:3166.815\n",
      "Ep:91, loss:0.00001, loss_test:0.02239, lr:5.11e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.776, tt:3199.394\n",
      "Ep:92, loss:0.00001, loss_test:0.01686, lr:5.06e-02, fs:0.75824 (r=0.697,p=0.831),  time:34.772, tt:3233.763\n",
      "Ep:93, loss:0.00001, loss_test:0.01906, lr:5.01e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.776, tt:3268.978\n",
      "Ep:94, loss:0.00001, loss_test:0.01788, lr:4.96e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.784, tt:3304.465\n",
      "Ep:95, loss:0.00001, loss_test:0.01837, lr:4.91e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.780, tt:3338.900\n",
      "Ep:96, loss:0.00001, loss_test:0.01887, lr:4.86e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.774, tt:3373.057\n",
      "Ep:97, loss:0.00001, loss_test:0.02030, lr:4.81e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.765, tt:3406.995\n",
      "Ep:98, loss:0.00001, loss_test:0.01995, lr:4.76e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.758, tt:3441.059\n",
      "Ep:99, loss:0.00001, loss_test:0.02198, lr:4.71e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.745, tt:3474.467\n",
      "Ep:100, loss:0.00000, loss_test:0.02133, lr:4.67e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.740, tt:3508.716\n",
      "Ep:101, loss:0.00001, loss_test:0.02328, lr:4.62e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.734, tt:3542.919\n",
      "Ep:102, loss:0.00000, loss_test:0.02283, lr:4.57e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.741, tt:3578.345\n",
      "Ep:103, loss:0.00000, loss_test:0.02234, lr:4.53e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.743, tt:3613.266\n",
      "Ep:104, loss:0.00000, loss_test:0.02482, lr:4.48e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.725, tt:3646.164\n",
      "Ep:105, loss:0.00000, loss_test:0.02344, lr:4.44e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.712, tt:3679.500\n",
      "Ep:106, loss:0.00000, loss_test:0.02236, lr:4.39e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.711, tt:3714.081\n",
      "Ep:107, loss:0.00000, loss_test:0.02541, lr:4.35e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.699, tt:3747.441\n",
      "Ep:108, loss:0.00000, loss_test:0.02393, lr:4.31e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.687, tt:3780.879\n",
      "Ep:109, loss:0.00000, loss_test:0.02491, lr:4.26e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.674, tt:3814.093\n",
      "Ep:110, loss:0.00000, loss_test:0.02427, lr:4.22e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.663, tt:3847.621\n",
      "Ep:111, loss:0.00000, loss_test:0.02595, lr:4.18e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.645, tt:3880.279\n",
      "Ep:112, loss:0.00000, loss_test:0.02561, lr:4.14e-02, fs:0.76744 (r=0.667,p=0.904),  time:34.624, tt:3912.506\n",
      "Ep:113, loss:0.00000, loss_test:0.02588, lr:4.10e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.624, tt:3947.147\n",
      "Ep:114, loss:0.00000, loss_test:0.02754, lr:4.05e-02, fs:0.76744 (r=0.667,p=0.904),  time:34.618, tt:3981.064\n",
      "Ep:115, loss:0.00000, loss_test:0.02517, lr:4.01e-02, fs:0.76471 (r=0.657,p=0.915),  time:34.596, tt:4013.125\n",
      "Ep:116, loss:0.00000, loss_test:0.02902, lr:3.97e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.586, tt:4046.553\n",
      "Ep:117, loss:0.00000, loss_test:0.02708, lr:3.93e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.577, tt:4080.125\n",
      "Ep:118, loss:0.00000, loss_test:0.02475, lr:3.89e-02, fs:0.77381 (r=0.657,p=0.942),  time:34.590, tt:4116.176\n",
      "Ep:119, loss:0.00000, loss_test:0.03122, lr:3.86e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.593, tt:4151.132\n",
      "Ep:120, loss:0.00000, loss_test:0.02477, lr:3.82e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.583, tt:4184.501\n",
      "Ep:121, loss:0.00000, loss_test:0.02825, lr:3.78e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.581, tt:4218.877\n",
      "Ep:122, loss:0.00000, loss_test:0.02805, lr:3.74e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.574, tt:4252.597\n",
      "Ep:123, loss:0.00000, loss_test:0.02691, lr:3.70e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.563, tt:4285.801\n",
      "Ep:124, loss:0.00000, loss_test:0.02744, lr:3.67e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.549, tt:4318.685\n",
      "Ep:125, loss:0.00000, loss_test:0.02815, lr:3.63e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.544, tt:4352.501\n",
      "Ep:126, loss:0.00000, loss_test:0.02914, lr:3.59e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.540, tt:4386.555\n",
      "Ep:127, loss:0.00000, loss_test:0.02960, lr:3.56e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.536, tt:4420.555\n",
      "Ep:128, loss:0.00000, loss_test:0.02819, lr:3.52e-02, fs:0.77193 (r=0.667,p=0.917),  time:34.527, tt:4454.030\n",
      "Ep:129, loss:0.00000, loss_test:0.02917, lr:3.49e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.540, tt:4490.155\n",
      "Ep:130, loss:0.00000, loss_test:0.03182, lr:3.45e-02, fs:0.77647 (r=0.667,p=0.930),  time:34.526, tt:4522.861\n",
      "Ep:131, loss:0.00000, loss_test:0.02805, lr:3.42e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.528, tt:4557.693\n",
      "Ep:132, loss:0.00000, loss_test:0.03188, lr:3.38e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.517, tt:4590.781\n",
      "Ep:133, loss:0.00000, loss_test:0.02987, lr:3.35e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.524, tt:4626.193\n",
      "Ep:134, loss:0.00000, loss_test:0.03097, lr:3.32e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.529, tt:4661.463\n",
      "Ep:135, loss:0.00000, loss_test:0.03129, lr:3.28e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.524, tt:4695.258\n",
      "Ep:136, loss:0.00000, loss_test:0.03032, lr:3.25e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.524, tt:4729.847\n",
      "Ep:137, loss:0.00000, loss_test:0.03205, lr:3.22e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.529, tt:4764.937\n",
      "Ep:138, loss:0.00000, loss_test:0.03151, lr:3.19e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.536, tt:4800.511\n",
      "Ep:139, loss:0.00000, loss_test:0.03208, lr:3.15e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.544, tt:4836.224\n",
      "Ep:140, loss:0.00000, loss_test:0.03194, lr:3.12e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.555, tt:4872.196\n",
      "Ep:141, loss:0.00000, loss_test:0.03282, lr:3.09e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.562, tt:4907.832\n",
      "Ep:142, loss:0.00000, loss_test:0.03307, lr:3.06e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.566, tt:4942.963\n",
      "Ep:143, loss:0.00000, loss_test:0.03218, lr:3.03e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.570, tt:4978.097\n",
      "Ep:144, loss:0.00000, loss_test:0.03313, lr:3.00e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.574, tt:5013.241\n",
      "Ep:145, loss:0.00000, loss_test:0.03424, lr:2.97e-02, fs:0.77108 (r=0.646,p=0.955),  time:34.572, tt:5047.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.03227, lr:2.94e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.566, tt:5081.244\n",
      "Ep:147, loss:0.00000, loss_test:0.03290, lr:2.91e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.569, tt:5116.260\n",
      "Ep:148, loss:0.00000, loss_test:0.03510, lr:2.88e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.567, tt:5150.530\n",
      "Ep:149, loss:0.00000, loss_test:0.03378, lr:2.85e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.560, tt:5184.041\n",
      "Ep:150, loss:0.00000, loss_test:0.03428, lr:2.82e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.564, tt:5219.159\n",
      "Ep:151, loss:0.00000, loss_test:0.03490, lr:2.80e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.563, tt:5253.640\n",
      "Ep:152, loss:0.00000, loss_test:0.03403, lr:2.77e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.570, tt:5289.261\n",
      "Ep:153, loss:0.00000, loss_test:0.03536, lr:2.74e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.570, tt:5323.769\n",
      "Ep:154, loss:0.00000, loss_test:0.03505, lr:2.71e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.579, tt:5359.669\n",
      "Ep:155, loss:0.00000, loss_test:0.03452, lr:2.69e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.580, tt:5394.538\n",
      "Ep:156, loss:0.00000, loss_test:0.03650, lr:2.66e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.589, tt:5430.414\n",
      "Ep:157, loss:0.00000, loss_test:0.03433, lr:2.63e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.594, tt:5465.874\n",
      "Ep:158, loss:0.00000, loss_test:0.03599, lr:2.61e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.605, tt:5502.270\n",
      "Ep:159, loss:0.00000, loss_test:0.03614, lr:2.58e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.605, tt:5536.783\n",
      "Ep:160, loss:0.00000, loss_test:0.03472, lr:2.55e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.613, tt:5572.701\n",
      "Ep:161, loss:0.00000, loss_test:0.03705, lr:2.53e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.612, tt:5607.086\n",
      "Ep:162, loss:0.00000, loss_test:0.03478, lr:2.50e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.619, tt:5642.974\n",
      "Ep:163, loss:0.00000, loss_test:0.03646, lr:2.48e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.629, tt:5679.113\n",
      "Ep:164, loss:0.00000, loss_test:0.03632, lr:2.45e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.626, tt:5713.328\n",
      "Ep:165, loss:0.00000, loss_test:0.03570, lr:2.43e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.629, tt:5748.419\n",
      "Ep:166, loss:0.00000, loss_test:0.03736, lr:2.40e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.627, tt:5782.636\n",
      "Ep:167, loss:0.00000, loss_test:0.03590, lr:2.38e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.628, tt:5817.573\n",
      "Ep:168, loss:0.00000, loss_test:0.03665, lr:2.36e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.630, tt:5852.405\n",
      "Ep:169, loss:0.00000, loss_test:0.03670, lr:2.33e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.634, tt:5887.712\n",
      "Ep:170, loss:0.00000, loss_test:0.03628, lr:2.31e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.637, tt:5922.994\n",
      "Ep:171, loss:0.00000, loss_test:0.03793, lr:2.29e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.636, tt:5957.338\n",
      "Ep:172, loss:0.00000, loss_test:0.03629, lr:2.26e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.637, tt:5992.133\n",
      "Ep:173, loss:0.00000, loss_test:0.03808, lr:2.24e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.641, tt:6027.508\n",
      "Ep:174, loss:0.00000, loss_test:0.03632, lr:2.22e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.646, tt:6063.128\n",
      "Ep:175, loss:0.00000, loss_test:0.03821, lr:2.20e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.643, tt:6097.084\n",
      "Ep:176, loss:0.00000, loss_test:0.03712, lr:2.17e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.653, tt:6133.588\n",
      "Ep:177, loss:0.00000, loss_test:0.03796, lr:2.15e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.650, tt:6167.724\n",
      "Ep:178, loss:0.00000, loss_test:0.03729, lr:2.13e-02, fs:0.78049 (r=0.646,p=0.985),  time:34.650, tt:6202.325\n",
      "Ep:179, loss:0.00000, loss_test:0.03813, lr:2.11e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.660, tt:6238.818\n",
      "Ep:180, loss:0.00000, loss_test:0.03750, lr:2.09e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.662, tt:6273.846\n",
      "Ep:181, loss:0.00000, loss_test:0.03789, lr:2.07e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.664, tt:6308.929\n",
      "Ep:182, loss:0.00000, loss_test:0.03826, lr:2.05e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.668, tt:6344.315\n",
      "Ep:183, loss:0.00000, loss_test:0.03819, lr:2.03e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.666, tt:6378.589\n",
      "Ep:184, loss:0.00000, loss_test:0.03800, lr:2.01e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.660, tt:6412.193\n",
      "Ep:185, loss:0.00000, loss_test:0.03838, lr:1.99e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.658, tt:6446.333\n",
      "Ep:186, loss:0.00000, loss_test:0.03807, lr:1.97e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.651, tt:6479.673\n",
      "Ep:187, loss:0.00000, loss_test:0.03869, lr:1.95e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.649, tt:6514.075\n",
      "Ep:188, loss:0.00000, loss_test:0.03837, lr:1.93e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.646, tt:6548.139\n",
      "Ep:189, loss:0.00000, loss_test:0.03845, lr:1.91e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.649, tt:6583.282\n",
      "Ep:190, loss:0.00000, loss_test:0.03850, lr:1.89e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.652, tt:6618.541\n",
      "Ep:191, loss:0.00000, loss_test:0.03870, lr:1.87e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.648, tt:6652.366\n",
      "Ep:192, loss:0.00000, loss_test:0.03873, lr:1.85e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.641, tt:6685.723\n",
      "Ep:193, loss:0.00000, loss_test:0.03875, lr:1.83e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.645, tt:6721.041\n",
      "Ep:194, loss:0.00000, loss_test:0.03905, lr:1.81e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.639, tt:6754.635\n",
      "Ep:195, loss:0.00000, loss_test:0.03877, lr:1.80e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.645, tt:6790.484\n",
      "Ep:196, loss:0.00000, loss_test:0.03891, lr:1.78e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.651, tt:6826.333\n",
      "Ep:197, loss:0.00000, loss_test:0.03888, lr:1.76e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.651, tt:6860.844\n",
      "Ep:198, loss:0.00000, loss_test:0.03895, lr:1.74e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.645, tt:6894.278\n",
      "Ep:199, loss:0.00000, loss_test:0.03895, lr:1.73e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.646, tt:6929.238\n",
      "Ep:200, loss:0.00000, loss_test:0.03913, lr:1.71e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.647, tt:6964.132\n",
      "Ep:201, loss:0.00000, loss_test:0.03942, lr:1.69e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.641, tt:6997.512\n",
      "Ep:202, loss:0.00000, loss_test:0.03922, lr:1.67e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.644, tt:7032.728\n",
      "Ep:203, loss:0.00000, loss_test:0.03941, lr:1.66e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.644, tt:7067.275\n",
      "Ep:204, loss:0.00000, loss_test:0.03930, lr:1.64e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.641, tt:7101.370\n",
      "Ep:205, loss:0.00000, loss_test:0.03945, lr:1.62e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.636, tt:7135.107\n",
      "Ep:206, loss:0.00000, loss_test:0.03963, lr:1.61e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.636, tt:7169.681\n",
      "Ep:207, loss:0.00000, loss_test:0.03935, lr:1.59e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.614, tt:7199.717\n",
      "Ep:208, loss:0.00000, loss_test:0.03994, lr:1.58e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.578, tt:7226.906\n",
      "Ep:209, loss:0.00000, loss_test:0.03949, lr:1.56e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.539, tt:7253.251\n",
      "Ep:210, loss:0.00000, loss_test:0.04014, lr:1.54e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.529, tt:7285.535\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.11919, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:36.067, tt:36.067\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12040, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:35.899, tt:71.799\n",
      "Ep:2, loss:0.00027, loss_test:0.12053, lr:1.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:36.204, tt:108.611\n",
      "Ep:3, loss:0.00026, loss_test:0.11958, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:36.049, tt:144.196\n",
      "Ep:4, loss:0.00026, loss_test:0.11765, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:36.001, tt:180.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00026, loss_test:0.11542, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:36.601, tt:219.605\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11411, lr:1.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:36.376, tt:254.630\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.11297, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:36.358, tt:290.867\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11238, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:36.475, tt:328.276\n",
      "Ep:9, loss:0.00025, loss_test:0.11162, lr:1.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:36.340, tt:363.402\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.10983, lr:1.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:36.365, tt:400.016\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.10688, lr:1.00e-02, fs:0.72800 (r=0.919,p=0.603),  time:36.348, tt:436.175\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10487, lr:1.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:36.322, tt:472.192\n",
      "Ep:13, loss:0.00024, loss_test:0.10387, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:36.236, tt:507.303\n",
      "Ep:14, loss:0.00023, loss_test:0.10282, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:36.302, tt:544.533\n",
      "Ep:15, loss:0.00023, loss_test:0.10151, lr:1.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:36.272, tt:580.352\n",
      "Ep:16, loss:0.00022, loss_test:0.09906, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:36.248, tt:616.221\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.09693, lr:1.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:36.224, tt:652.024\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.09573, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:36.282, tt:689.365\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.09522, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:36.320, tt:726.400\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09389, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:36.305, tt:762.409\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09395, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:36.315, tt:798.919\n",
      "Ep:22, loss:0.00019, loss_test:0.09271, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:36.269, tt:834.179\n",
      "Ep:23, loss:0.00018, loss_test:0.09217, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:36.298, tt:871.155\n",
      "Ep:24, loss:0.00017, loss_test:0.09201, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:36.293, tt:907.323\n",
      "Ep:25, loss:0.00017, loss_test:0.08843, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:36.347, tt:945.016\n",
      "Ep:26, loss:0.00016, loss_test:0.09460, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:36.318, tt:980.588\n",
      "Ep:27, loss:0.00015, loss_test:0.08718, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:36.336, tt:1017.417\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.08637, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:36.339, tt:1053.826\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09249, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:36.372, tt:1091.160\n",
      "Ep:30, loss:0.00014, loss_test:0.08209, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:36.400, tt:1128.415\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09020, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:36.435, tt:1165.915\n",
      "Ep:32, loss:0.00013, loss_test:0.09212, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:36.499, tt:1204.478\n",
      "Ep:33, loss:0.00012, loss_test:0.08337, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:36.516, tt:1241.542\n",
      "Ep:34, loss:0.00012, loss_test:0.08598, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:36.533, tt:1278.653\n",
      "Ep:35, loss:0.00011, loss_test:0.07960, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.569, tt:1316.467\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08579, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:36.563, tt:1352.813\n",
      "Ep:37, loss:0.00010, loss_test:0.08600, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:36.584, tt:1390.203\n",
      "Ep:38, loss:0.00010, loss_test:0.10075, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:36.579, tt:1426.576\n",
      "Ep:39, loss:0.00010, loss_test:0.09293, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:36.621, tt:1464.843\n",
      "Ep:40, loss:0.00009, loss_test:0.08225, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:36.598, tt:1500.511\n",
      "Ep:41, loss:0.00009, loss_test:0.08391, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:36.595, tt:1536.991\n",
      "Ep:42, loss:0.00008, loss_test:0.07524, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:36.575, tt:1572.733\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.09152, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:36.573, tt:1609.205\n",
      "Ep:44, loss:0.00008, loss_test:0.08002, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:36.588, tt:1646.467\n",
      "Ep:45, loss:0.00008, loss_test:0.09827, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:36.563, tt:1681.887\n",
      "Ep:46, loss:0.00008, loss_test:0.07221, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:36.562, tt:1718.430\n",
      "Ep:47, loss:0.00007, loss_test:0.07635, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:36.554, tt:1754.594\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07975, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:36.510, tt:1789.013\n",
      "Ep:49, loss:0.00006, loss_test:0.07727, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.512, tt:1825.613\n",
      "Ep:50, loss:0.00006, loss_test:0.07855, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:36.513, tt:1862.187\n",
      "Ep:51, loss:0.00006, loss_test:0.07051, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.516, tt:1898.829\n",
      "Ep:52, loss:0.00005, loss_test:0.07710, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:36.517, tt:1935.407\n",
      "Ep:53, loss:0.00005, loss_test:0.07537, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:36.493, tt:1970.603\n",
      "Ep:54, loss:0.00005, loss_test:0.08170, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.501, tt:2007.559\n",
      "Ep:55, loss:0.00006, loss_test:0.06789, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:36.492, tt:2043.539\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.11125, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:36.468, tt:2078.679\n",
      "Ep:57, loss:0.00006, loss_test:0.06609, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:36.492, tt:2116.508\n",
      "Ep:58, loss:0.00006, loss_test:0.08607, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.498, tt:2153.404\n",
      "Ep:59, loss:0.00005, loss_test:0.08214, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.492, tt:2189.515\n",
      "Ep:60, loss:0.00006, loss_test:0.06548, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:36.470, tt:2224.649\n",
      "Ep:61, loss:0.00007, loss_test:0.08803, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.451, tt:2259.951\n",
      "Ep:62, loss:0.00006, loss_test:0.07528, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.452, tt:2296.458\n",
      "Ep:63, loss:0.00005, loss_test:0.07586, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:36.471, tt:2334.159\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.07718, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:36.496, tt:2372.250\n",
      "Ep:65, loss:0.00006, loss_test:0.07295, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:36.489, tt:2408.307\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.08143, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:36.478, tt:2444.021\n",
      "Ep:67, loss:0.00005, loss_test:0.07122, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:36.452, tt:2478.713\n",
      "Ep:68, loss:0.00005, loss_test:0.07567, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.441, tt:2514.396\n",
      "Ep:69, loss:0.00004, loss_test:0.07601, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.420, tt:2549.412\n",
      "Ep:70, loss:0.00004, loss_test:0.07923, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.389, tt:2583.654\n",
      "Ep:71, loss:0.00004, loss_test:0.07453, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.374, tt:2618.938\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00004, loss_test:0.07371, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.350, tt:2653.519\n",
      "Ep:73, loss:0.00004, loss_test:0.08441, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:36.323, tt:2687.894\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00003, loss_test:0.07879, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.308, tt:2723.127\n",
      "Ep:75, loss:0.00004, loss_test:0.08307, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:36.288, tt:2757.915\n",
      "Ep:76, loss:0.00003, loss_test:0.07770, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.248, tt:2791.058\n",
      "Ep:77, loss:0.00003, loss_test:0.08058, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:36.219, tt:2825.109\n",
      "Ep:78, loss:0.00003, loss_test:0.07278, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:36.246, tt:2863.446\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.08870, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:36.247, tt:2899.749\n",
      "Ep:80, loss:0.00003, loss_test:0.07331, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.243, tt:2935.715\n",
      "Ep:81, loss:0.00003, loss_test:0.09163, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:36.216, tt:2969.719\n",
      "Ep:82, loss:0.00003, loss_test:0.07693, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.220, tt:3006.252\n",
      "Ep:83, loss:0.00002, loss_test:0.08371, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.207, tt:3041.354\n",
      "Ep:84, loss:0.00002, loss_test:0.07693, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.193, tt:3076.402\n",
      "Ep:85, loss:0.00002, loss_test:0.10963, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:36.154, tt:3109.251\n",
      "Ep:86, loss:0.00005, loss_test:0.07517, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:36.112, tt:3141.714\n",
      "Ep:87, loss:0.00007, loss_test:0.10505, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:36.081, tt:3175.110\n",
      "Ep:88, loss:0.00005, loss_test:0.09632, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:36.071, tt:3210.318\n",
      "Ep:89, loss:0.00005, loss_test:0.08319, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:36.054, tt:3244.848\n",
      "Ep:90, loss:0.00004, loss_test:0.07904, lr:9.90e-03, fs:0.83770 (r=0.808,p=0.870),  time:36.033, tt:3278.960\n",
      "Ep:91, loss:0.00004, loss_test:0.07322, lr:9.80e-03, fs:0.85106 (r=0.808,p=0.899),  time:36.036, tt:3315.309\n",
      "Ep:92, loss:0.00003, loss_test:0.08290, lr:9.70e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.043, tt:3352.043\n",
      "Ep:93, loss:0.00003, loss_test:0.08101, lr:9.61e-03, fs:0.83770 (r=0.808,p=0.870),  time:36.042, tt:3387.994\n",
      "Ep:94, loss:0.00003, loss_test:0.08532, lr:9.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.045, tt:3424.263\n",
      "Ep:95, loss:0.00003, loss_test:0.08193, lr:9.41e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.020, tt:3457.885\n",
      "Ep:96, loss:0.00003, loss_test:0.08613, lr:9.32e-03, fs:0.78212 (r=0.707,p=0.875),  time:36.016, tt:3493.594\n",
      "Ep:97, loss:0.00003, loss_test:0.07611, lr:9.23e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.026, tt:3530.514\n",
      "Ep:98, loss:0.00003, loss_test:0.08477, lr:9.14e-03, fs:0.85417 (r=0.828,p=0.882),  time:36.009, tt:3564.900\n",
      "Ep:99, loss:0.00002, loss_test:0.07904, lr:9.04e-03, fs:0.83696 (r=0.778,p=0.906),  time:35.997, tt:3599.659\n",
      "Ep:100, loss:0.00002, loss_test:0.09471, lr:8.95e-03, fs:0.82418 (r=0.758,p=0.904),  time:35.991, tt:3635.079\n",
      "Ep:101, loss:0.00002, loss_test:0.08295, lr:8.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:35.981, tt:3670.021\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.08224, lr:8.86e-03, fs:0.82540 (r=0.788,p=0.867),  time:35.976, tt:3705.499\n",
      "Ep:103, loss:0.00002, loss_test:0.08630, lr:8.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.958, tt:3739.644\n",
      "Ep:104, loss:0.00002, loss_test:0.09186, lr:8.86e-03, fs:0.79096 (r=0.707,p=0.897),  time:35.969, tt:3776.721\n",
      "Ep:105, loss:0.00002, loss_test:0.07322, lr:8.86e-03, fs:0.86911 (r=0.838,p=0.902),  time:35.969, tt:3812.698\n",
      "Ep:106, loss:0.00002, loss_test:0.09297, lr:8.86e-03, fs:0.81111 (r=0.737,p=0.901),  time:35.970, tt:3848.762\n",
      "Ep:107, loss:0.00002, loss_test:0.08074, lr:8.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.963, tt:3884.045\n",
      "Ep:108, loss:0.00002, loss_test:0.08638, lr:8.86e-03, fs:0.83696 (r=0.778,p=0.906),  time:35.954, tt:3919.033\n",
      "Ep:109, loss:0.00002, loss_test:0.08324, lr:8.86e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.945, tt:3953.919\n",
      "Ep:110, loss:0.00001, loss_test:0.08220, lr:8.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:35.935, tt:3988.810\n",
      "Ep:111, loss:0.00001, loss_test:0.09008, lr:8.86e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.931, tt:4024.228\n",
      "Ep:112, loss:0.00001, loss_test:0.08431, lr:8.86e-03, fs:0.85405 (r=0.798,p=0.919),  time:35.924, tt:4059.394\n",
      "Ep:113, loss:0.00001, loss_test:0.09020, lr:8.78e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.907, tt:4093.354\n",
      "Ep:114, loss:0.00001, loss_test:0.08753, lr:8.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.896, tt:4128.013\n",
      "Ep:115, loss:0.00001, loss_test:0.10051, lr:8.60e-03, fs:0.80460 (r=0.707,p=0.933),  time:35.881, tt:4162.219\n",
      "Ep:116, loss:0.00002, loss_test:0.09127, lr:8.51e-03, fs:0.84324 (r=0.788,p=0.907),  time:35.908, tt:4201.286\n",
      "Ep:117, loss:0.00001, loss_test:0.09595, lr:8.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:35.892, tt:4235.255\n",
      "Ep:118, loss:0.00001, loss_test:0.07819, lr:8.35e-03, fs:0.88172 (r=0.828,p=0.943),  time:35.894, tt:4271.389\n",
      "Ep:119, loss:0.00001, loss_test:0.10096, lr:8.26e-03, fs:0.72189 (r=0.616,p=0.871),  time:35.878, tt:4305.367\n",
      "Ep:120, loss:0.00001, loss_test:0.08302, lr:8.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.858, tt:4338.879\n",
      "Ep:121, loss:0.00001, loss_test:0.09297, lr:8.10e-03, fs:0.76404 (r=0.687,p=0.861),  time:35.867, tt:4375.738\n",
      "Ep:122, loss:0.00001, loss_test:0.08723, lr:8.02e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.857, tt:4410.371\n",
      "Ep:123, loss:0.00001, loss_test:0.09185, lr:7.94e-03, fs:0.78409 (r=0.697,p=0.896),  time:35.840, tt:4444.167\n",
      "Ep:124, loss:0.00001, loss_test:0.09312, lr:7.86e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.825, tt:4478.102\n",
      "Ep:125, loss:0.00001, loss_test:0.08791, lr:7.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.819, tt:4513.212\n",
      "Ep:126, loss:0.00001, loss_test:0.08698, lr:7.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.824, tt:4549.707\n",
      "Ep:127, loss:0.00001, loss_test:0.09498, lr:7.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:35.819, tt:4584.769\n",
      "Ep:128, loss:0.00001, loss_test:0.09803, lr:7.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.802, tt:4618.492\n",
      "Ep:129, loss:0.00001, loss_test:0.09596, lr:7.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.800, tt:4654.029\n",
      "Ep:130, loss:0.00001, loss_test:0.08964, lr:7.40e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.790, tt:4688.447\n",
      "Ep:131, loss:0.00001, loss_test:0.09085, lr:7.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.778, tt:4722.645\n",
      "Ep:132, loss:0.00001, loss_test:0.09601, lr:7.25e-03, fs:0.79310 (r=0.697,p=0.920),  time:35.772, tt:4757.713\n",
      "Ep:133, loss:0.00001, loss_test:0.09107, lr:7.18e-03, fs:0.84324 (r=0.788,p=0.907),  time:35.774, tt:4793.767\n",
      "Ep:134, loss:0.00001, loss_test:0.09314, lr:7.11e-03, fs:0.78161 (r=0.687,p=0.907),  time:35.773, tt:4829.325\n",
      "Ep:135, loss:0.00001, loss_test:0.09915, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:35.774, tt:4865.310\n",
      "Ep:136, loss:0.00001, loss_test:0.09020, lr:6.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:35.761, tt:4899.265\n",
      "Ep:137, loss:0.00001, loss_test:0.09172, lr:6.89e-03, fs:0.85246 (r=0.788,p=0.929),  time:35.754, tt:4934.062\n",
      "Ep:138, loss:0.00001, loss_test:0.09317, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.751, tt:4969.428\n",
      "Ep:139, loss:0.00001, loss_test:0.09356, lr:6.76e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.755, tt:5005.691\n",
      "Ep:140, loss:0.00001, loss_test:0.09424, lr:6.69e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.759, tt:5042.002\n",
      "Ep:141, loss:0.00001, loss_test:0.09008, lr:6.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:35.774, tt:5079.923\n",
      "Ep:142, loss:0.00001, loss_test:0.09742, lr:6.56e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.777, tt:5116.117\n",
      "Ep:143, loss:0.00001, loss_test:0.09370, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:35.775, tt:5151.638\n",
      "Ep:144, loss:0.00001, loss_test:0.09531, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.774, tt:5187.207\n",
      "Ep:145, loss:0.00001, loss_test:0.09049, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:35.793, tt:5225.793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.08993, lr:6.30e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.796, tt:5262.081\n",
      "Ep:147, loss:0.00000, loss_test:0.09609, lr:6.24e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.807, tt:5299.384\n",
      "Ep:148, loss:0.00000, loss_test:0.09141, lr:6.17e-03, fs:0.83429 (r=0.737,p=0.961),  time:35.812, tt:5335.963\n",
      "Ep:149, loss:0.00000, loss_test:0.09301, lr:6.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:35.817, tt:5372.496\n",
      "Ep:150, loss:0.00000, loss_test:0.09574, lr:6.05e-03, fs:0.82955 (r=0.737,p=0.948),  time:35.824, tt:5409.422\n",
      "Ep:151, loss:0.00000, loss_test:0.09254, lr:5.99e-03, fs:0.82955 (r=0.737,p=0.948),  time:35.840, tt:5447.706\n",
      "Ep:152, loss:0.00000, loss_test:0.09506, lr:5.93e-03, fs:0.78824 (r=0.677,p=0.944),  time:35.855, tt:5485.796\n",
      "Ep:153, loss:0.00000, loss_test:0.09673, lr:5.87e-03, fs:0.77108 (r=0.646,p=0.955),  time:35.865, tt:5523.194\n",
      "Ep:154, loss:0.00000, loss_test:0.09674, lr:5.81e-03, fs:0.74847 (r=0.616,p=0.953),  time:35.865, tt:5559.131\n",
      "Ep:155, loss:0.00000, loss_test:0.09494, lr:5.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.861, tt:5594.374\n",
      "Ep:156, loss:0.00000, loss_test:0.09444, lr:5.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.862, tt:5630.284\n",
      "Ep:157, loss:0.00000, loss_test:0.09797, lr:5.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:35.862, tt:5666.209\n",
      "Ep:158, loss:0.00000, loss_test:0.09588, lr:5.58e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.866, tt:5702.748\n",
      "Ep:159, loss:0.00000, loss_test:0.09500, lr:5.53e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.875, tt:5739.972\n",
      "Ep:160, loss:0.00000, loss_test:0.09562, lr:5.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.874, tt:5775.669\n",
      "Ep:161, loss:0.00000, loss_test:0.09276, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.880, tt:5812.639\n",
      "Ep:162, loss:0.00000, loss_test:0.09847, lr:5.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.885, tt:5849.296\n",
      "Ep:163, loss:0.00000, loss_test:0.09501, lr:5.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.884, tt:5885.055\n",
      "Ep:164, loss:0.00000, loss_test:0.09690, lr:5.26e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.888, tt:5921.519\n",
      "Ep:165, loss:0.00000, loss_test:0.09602, lr:5.20e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.895, tt:5958.495\n",
      "Ep:166, loss:0.00000, loss_test:0.09478, lr:5.15e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.904, tt:5996.000\n",
      "Ep:167, loss:0.00000, loss_test:0.09723, lr:5.10e-03, fs:0.73939 (r=0.616,p=0.924),  time:35.906, tt:6032.181\n",
      "Ep:168, loss:0.00000, loss_test:0.09624, lr:5.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.911, tt:6068.992\n",
      "Ep:169, loss:0.00000, loss_test:0.10180, lr:5.00e-03, fs:0.74847 (r=0.616,p=0.953),  time:35.908, tt:6104.412\n",
      "Ep:170, loss:0.00000, loss_test:0.09954, lr:4.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.908, tt:6140.217\n",
      "Ep:171, loss:0.00000, loss_test:0.09605, lr:4.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.912, tt:6176.803\n",
      "Ep:172, loss:0.00000, loss_test:0.09783, lr:4.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:35.916, tt:6213.467\n",
      "Ep:173, loss:0.00000, loss_test:0.09484, lr:4.80e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.916, tt:6249.412\n",
      "Ep:174, loss:0.00000, loss_test:0.09454, lr:4.75e-03, fs:0.79042 (r=0.667,p=0.971),  time:35.915, tt:6285.039\n",
      "Ep:175, loss:0.00000, loss_test:0.09668, lr:4.71e-03, fs:0.74390 (r=0.616,p=0.938),  time:35.926, tt:6322.892\n",
      "Ep:176, loss:0.00000, loss_test:0.09590, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.928, tt:6359.323\n",
      "Ep:177, loss:0.00000, loss_test:0.09821, lr:4.61e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.931, tt:6395.643\n",
      "Ep:178, loss:0.00000, loss_test:0.09776, lr:4.57e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.938, tt:6432.830\n",
      "Ep:179, loss:0.00000, loss_test:0.09419, lr:4.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.939, tt:6468.938\n",
      "Ep:180, loss:0.00000, loss_test:0.09731, lr:4.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:35.945, tt:6506.129\n",
      "Ep:181, loss:0.00000, loss_test:0.09669, lr:4.43e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.947, tt:6542.302\n",
      "Ep:182, loss:0.00000, loss_test:0.09511, lr:4.39e-03, fs:0.80473 (r=0.687,p=0.971),  time:35.958, tt:6580.373\n",
      "Ep:183, loss:0.00000, loss_test:0.09633, lr:4.34e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.975, tt:6619.481\n",
      "Ep:184, loss:0.00000, loss_test:0.09471, lr:4.30e-03, fs:0.80240 (r=0.677,p=0.985),  time:35.979, tt:6656.181\n",
      "Ep:185, loss:0.00000, loss_test:0.09322, lr:4.26e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.982, tt:6692.689\n",
      "Ep:186, loss:0.00000, loss_test:0.09672, lr:4.21e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.985, tt:6729.183\n",
      "Ep:187, loss:0.00000, loss_test:0.09960, lr:4.17e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.985, tt:6765.100\n",
      "Ep:188, loss:0.00000, loss_test:0.09672, lr:4.13e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.985, tt:6801.210\n",
      "Ep:189, loss:0.00000, loss_test:0.09474, lr:4.09e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.986, tt:6837.388\n",
      "Ep:190, loss:0.00000, loss_test:0.09561, lr:4.05e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.986, tt:6873.346\n",
      "Ep:191, loss:0.00000, loss_test:0.09340, lr:4.01e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.988, tt:6909.696\n",
      "Ep:192, loss:0.00000, loss_test:0.09370, lr:3.97e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.998, tt:6947.682\n",
      "Ep:193, loss:0.00000, loss_test:0.09528, lr:3.93e-03, fs:0.76074 (r=0.626,p=0.969),  time:36.005, tt:6985.028\n",
      "Ep:194, loss:0.00000, loss_test:0.09530, lr:3.89e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.004, tt:7020.770\n",
      "Ep:195, loss:0.00000, loss_test:0.09454, lr:3.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.999, tt:7055.826\n",
      "Ep:196, loss:0.00000, loss_test:0.09439, lr:3.81e-03, fs:0.79762 (r=0.677,p=0.971),  time:36.001, tt:7092.283\n",
      "Ep:197, loss:0.00000, loss_test:0.09472, lr:3.77e-03, fs:0.79290 (r=0.677,p=0.957),  time:36.007, tt:7129.377\n",
      "Ep:198, loss:0.00000, loss_test:0.09419, lr:3.73e-03, fs:0.79290 (r=0.677,p=0.957),  time:36.007, tt:7165.462\n",
      "Ep:199, loss:0.00000, loss_test:0.09419, lr:3.70e-03, fs:0.75309 (r=0.616,p=0.968),  time:36.010, tt:7202.010\n",
      "Ep:200, loss:0.00000, loss_test:0.09292, lr:3.66e-03, fs:0.79042 (r=0.667,p=0.971),  time:36.017, tt:7239.418\n",
      "Ep:201, loss:0.00000, loss_test:0.09252, lr:3.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:36.017, tt:7275.375\n",
      "Ep:202, loss:0.00000, loss_test:0.09389, lr:3.59e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.011, tt:7310.270\n",
      "Ep:203, loss:0.00000, loss_test:0.09424, lr:3.55e-03, fs:0.74847 (r=0.616,p=0.953),  time:36.010, tt:7346.132\n",
      "Ep:204, loss:0.00000, loss_test:0.09395, lr:3.52e-03, fs:0.79290 (r=0.677,p=0.957),  time:36.019, tt:7383.995\n",
      "Ep:205, loss:0.00000, loss_test:0.09378, lr:3.48e-03, fs:0.79290 (r=0.677,p=0.957),  time:36.020, tt:7420.171\n",
      "Ep:206, loss:0.00000, loss_test:0.09431, lr:3.45e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.994, tt:7450.729\n",
      "Ep:207, loss:0.00000, loss_test:0.09419, lr:3.41e-03, fs:0.78571 (r=0.667,p=0.957),  time:35.940, tt:7475.594\n",
      "Ep:208, loss:0.00000, loss_test:0.09308, lr:3.38e-03, fs:0.76364 (r=0.636,p=0.955),  time:35.880, tt:7498.939\n",
      "Ep:209, loss:0.00000, loss_test:0.09256, lr:3.34e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.822, tt:7522.667\n",
      "Ep:210, loss:0.00000, loss_test:0.09272, lr:3.31e-03, fs:0.79290 (r=0.677,p=0.957),  time:35.783, tt:7550.212\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02639, lr:6.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:34.394, tt:34.394\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:35.260, tt:70.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00005, loss_test:0.02657, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:35.554, tt:106.662\n",
      "Ep:3, loss:0.00005, loss_test:0.02656, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:35.482, tt:141.926\n",
      "Ep:4, loss:0.00005, loss_test:0.02636, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:35.601, tt:178.004\n",
      "Ep:5, loss:0.00005, loss_test:0.02605, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:35.447, tt:212.680\n",
      "Ep:6, loss:0.00005, loss_test:0.02585, lr:6.00e-02, fs:0.63433 (r=0.859,p=0.503),  time:35.302, tt:247.116\n",
      "Ep:7, loss:0.00005, loss_test:0.02576, lr:6.00e-02, fs:0.63602 (r=0.838,p=0.512),  time:35.194, tt:281.551\n",
      "Ep:8, loss:0.00005, loss_test:0.02532, lr:6.00e-02, fs:0.64093 (r=0.838,p=0.519),  time:34.944, tt:314.500\n",
      "Ep:9, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:34.878, tt:348.780\n",
      "Ep:10, loss:0.00005, loss_test:0.02439, lr:6.00e-02, fs:0.64394 (r=0.859,p=0.515),  time:34.866, tt:383.521\n",
      "Ep:11, loss:0.00005, loss_test:0.02412, lr:6.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:34.784, tt:417.409\n",
      "Ep:12, loss:0.00005, loss_test:0.02365, lr:5.94e-02, fs:0.64925 (r=0.879,p=0.515),  time:34.670, tt:450.704\n",
      "Ep:13, loss:0.00005, loss_test:0.02301, lr:5.88e-02, fs:0.65169 (r=0.879,p=0.518),  time:34.545, tt:483.635\n",
      "Ep:14, loss:0.00005, loss_test:0.02232, lr:5.82e-02, fs:0.65909 (r=0.879,p=0.527),  time:34.438, tt:516.574\n",
      "Ep:15, loss:0.00005, loss_test:0.02176, lr:5.76e-02, fs:0.66412 (r=0.879,p=0.534),  time:34.434, tt:550.937\n",
      "Ep:16, loss:0.00004, loss_test:0.02127, lr:5.71e-02, fs:0.67176 (r=0.889,p=0.540),  time:34.384, tt:584.524\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02084, lr:5.71e-02, fs:0.67176 (r=0.889,p=0.540),  time:34.344, tt:618.193\n",
      "Ep:18, loss:0.00004, loss_test:0.02055, lr:5.71e-02, fs:0.66412 (r=0.879,p=0.534),  time:34.335, tt:652.372\n",
      "Ep:19, loss:0.00004, loss_test:0.02028, lr:5.71e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.370, tt:687.400\n",
      "Ep:20, loss:0.00004, loss_test:0.02006, lr:5.71e-02, fs:0.66920 (r=0.889,p=0.537),  time:34.518, tt:724.881\n",
      "Ep:21, loss:0.00004, loss_test:0.01992, lr:5.71e-02, fs:0.67692 (r=0.889,p=0.547),  time:34.463, tt:758.194\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01986, lr:5.71e-02, fs:0.67939 (r=0.899,p=0.546),  time:34.511, tt:793.753\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01974, lr:5.71e-02, fs:0.68462 (r=0.899,p=0.553),  time:34.488, tt:827.717\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01958, lr:5.71e-02, fs:0.68966 (r=0.909,p=0.556),  time:34.468, tt:861.702\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01933, lr:5.71e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.493, tt:896.820\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01910, lr:5.71e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.435, tt:929.753\n",
      "Ep:27, loss:0.00004, loss_test:0.01897, lr:5.71e-02, fs:0.69498 (r=0.909,p=0.562),  time:34.430, tt:964.032\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01882, lr:5.71e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.415, tt:998.041\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01875, lr:5.71e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.407, tt:1032.201\n",
      "Ep:30, loss:0.00003, loss_test:0.01862, lr:5.71e-02, fs:0.69231 (r=0.909,p=0.559),  time:34.394, tt:1066.198\n",
      "Ep:31, loss:0.00003, loss_test:0.01840, lr:5.71e-02, fs:0.69767 (r=0.909,p=0.566),  time:34.391, tt:1100.516\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01806, lr:5.71e-02, fs:0.70039 (r=0.909,p=0.570),  time:34.418, tt:1135.796\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01778, lr:5.71e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.440, tt:1170.967\n",
      "Ep:34, loss:0.00003, loss_test:0.01748, lr:5.71e-02, fs:0.71200 (r=0.899,p=0.589),  time:34.449, tt:1205.727\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01707, lr:5.71e-02, fs:0.70683 (r=0.889,p=0.587),  time:34.508, tt:1242.303\n",
      "Ep:36, loss:0.00003, loss_test:0.01672, lr:5.71e-02, fs:0.72358 (r=0.899,p=0.605),  time:34.529, tt:1277.556\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01636, lr:5.71e-02, fs:0.72951 (r=0.899,p=0.614),  time:34.541, tt:1312.576\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01600, lr:5.71e-02, fs:0.73770 (r=0.909,p=0.621),  time:34.527, tt:1346.544\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01581, lr:5.71e-02, fs:0.75314 (r=0.909,p=0.643),  time:34.563, tt:1382.506\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01560, lr:5.71e-02, fs:0.75630 (r=0.909,p=0.647),  time:34.548, tt:1416.466\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01535, lr:5.71e-02, fs:0.76151 (r=0.919,p=0.650),  time:34.549, tt:1451.054\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01532, lr:5.71e-02, fs:0.76923 (r=0.909,p=0.667),  time:34.537, tt:1485.106\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01496, lr:5.71e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.516, tt:1518.691\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01464, lr:5.71e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.513, tt:1553.076\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01452, lr:5.71e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.522, tt:1588.026\n",
      "Ep:46, loss:0.00002, loss_test:0.01416, lr:5.71e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.529, tt:1622.855\n",
      "Ep:47, loss:0.00002, loss_test:0.01387, lr:5.71e-02, fs:0.78070 (r=0.899,p=0.690),  time:34.492, tt:1655.625\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01369, lr:5.71e-02, fs:0.78761 (r=0.899,p=0.701),  time:34.504, tt:1690.695\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01336, lr:5.71e-02, fs:0.79295 (r=0.909,p=0.703),  time:34.493, tt:1724.667\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01316, lr:5.71e-02, fs:0.81448 (r=0.909,p=0.738),  time:34.504, tt:1759.728\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01274, lr:5.71e-02, fs:0.81818 (r=0.909,p=0.744),  time:34.502, tt:1794.094\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01256, lr:5.71e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.496, tt:1828.273\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01242, lr:5.71e-02, fs:0.81651 (r=0.899,p=0.748),  time:34.463, tt:1861.017\n",
      "Ep:54, loss:0.00002, loss_test:0.01217, lr:5.71e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.458, tt:1895.207\n",
      "Ep:55, loss:0.00002, loss_test:0.01206, lr:5.71e-02, fs:0.82407 (r=0.899,p=0.761),  time:34.468, tt:1930.194\n",
      "Ep:56, loss:0.00002, loss_test:0.01172, lr:5.71e-02, fs:0.83178 (r=0.899,p=0.774),  time:34.458, tt:1964.078\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01174, lr:5.71e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.478, tt:1999.706\n",
      "Ep:58, loss:0.00002, loss_test:0.01109, lr:5.71e-02, fs:0.83568 (r=0.899,p=0.781),  time:34.487, tt:2034.723\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01157, lr:5.71e-02, fs:0.83495 (r=0.869,p=0.804),  time:34.478, tt:2068.674\n",
      "Ep:60, loss:0.00001, loss_test:0.01081, lr:5.71e-02, fs:0.84906 (r=0.909,p=0.796),  time:34.482, tt:2103.394\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01102, lr:5.71e-02, fs:0.84466 (r=0.879,p=0.813),  time:34.493, tt:2138.538\n",
      "Ep:62, loss:0.00001, loss_test:0.01093, lr:5.71e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.480, tt:2172.241\n",
      "Ep:63, loss:0.00001, loss_test:0.01081, lr:5.71e-02, fs:0.84314 (r=0.869,p=0.819),  time:34.497, tt:2207.813\n",
      "Ep:64, loss:0.00001, loss_test:0.01099, lr:5.71e-02, fs:0.84466 (r=0.879,p=0.813),  time:34.505, tt:2242.856\n",
      "Ep:65, loss:0.00001, loss_test:0.01109, lr:5.71e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.509, tt:2277.569\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00001, loss_test:0.01095, lr:5.71e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.494, tt:2311.072\n",
      "Ep:67, loss:0.00001, loss_test:0.01041, lr:5.71e-02, fs:0.85854 (r=0.889,p=0.830),  time:34.522, tt:2347.477\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01229, lr:5.71e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.539, tt:2383.177\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01029, lr:5.71e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.529, tt:2416.996\n",
      "Ep:70, loss:0.00001, loss_test:0.01030, lr:5.71e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.501, tt:2449.568\n",
      "Ep:71, loss:0.00001, loss_test:0.01038, lr:5.71e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.487, tt:2483.041\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01125, lr:5.71e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.489, tt:2517.670\n",
      "Ep:73, loss:0.00001, loss_test:0.01121, lr:5.71e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.472, tt:2550.946\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01046, lr:5.71e-02, fs:0.86735 (r=0.859,p=0.876),  time:34.464, tt:2584.784\n",
      "Ep:75, loss:0.00001, loss_test:0.01030, lr:5.71e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.462, tt:2619.134\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01015, lr:5.71e-02, fs:0.87755 (r=0.869,p=0.887),  time:34.460, tt:2653.439\n",
      "Ep:77, loss:0.00001, loss_test:0.01113, lr:5.71e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.450, tt:2687.073\n",
      "Ep:78, loss:0.00001, loss_test:0.01122, lr:5.71e-02, fs:0.88660 (r=0.869,p=0.905),  time:34.438, tt:2720.623\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01009, lr:5.71e-02, fs:0.88205 (r=0.869,p=0.896),  time:34.430, tt:2754.361\n",
      "Ep:80, loss:0.00001, loss_test:0.01041, lr:5.71e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.418, tt:2787.864\n",
      "Ep:81, loss:0.00001, loss_test:0.01083, lr:5.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.418, tt:2822.314\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01078, lr:5.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.369, tt:2852.642\n",
      "Ep:83, loss:0.00001, loss_test:0.01100, lr:5.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.337, tt:2884.295\n",
      "Ep:84, loss:0.00001, loss_test:0.01171, lr:5.71e-02, fs:0.88542 (r=0.859,p=0.914),  time:34.336, tt:2918.551\n",
      "Ep:85, loss:0.00001, loss_test:0.01012, lr:5.71e-02, fs:0.92462 (r=0.929,p=0.920),  time:34.333, tt:2952.670\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01066, lr:5.71e-02, fs:0.89119 (r=0.869,p=0.915),  time:34.339, tt:2987.531\n",
      "Ep:87, loss:0.00001, loss_test:0.01231, lr:5.71e-02, fs:0.89005 (r=0.859,p=0.924),  time:34.336, tt:3021.573\n",
      "Ep:88, loss:0.00001, loss_test:0.01133, lr:5.71e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.340, tt:3056.262\n",
      "Ep:89, loss:0.00001, loss_test:0.01118, lr:5.71e-02, fs:0.89583 (r=0.869,p=0.925),  time:34.326, tt:3089.310\n",
      "Ep:90, loss:0.00001, loss_test:0.01191, lr:5.71e-02, fs:0.90526 (r=0.869,p=0.945),  time:34.330, tt:3124.017\n",
      "Ep:91, loss:0.00001, loss_test:0.01267, lr:5.71e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.332, tt:3158.563\n",
      "Ep:92, loss:0.00001, loss_test:0.01182, lr:5.71e-02, fs:0.90526 (r=0.869,p=0.945),  time:34.325, tt:3192.191\n",
      "Ep:93, loss:0.00001, loss_test:0.01216, lr:5.71e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.323, tt:3226.377\n",
      "Ep:94, loss:0.00001, loss_test:0.01270, lr:5.71e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.338, tt:3262.081\n",
      "Ep:95, loss:0.00001, loss_test:0.01165, lr:5.71e-02, fs:0.89474 (r=0.859,p=0.934),  time:34.346, tt:3297.246\n",
      "Ep:96, loss:0.00001, loss_test:0.01100, lr:5.71e-02, fs:0.92308 (r=0.909,p=0.938),  time:34.371, tt:3333.954\n",
      "Ep:97, loss:0.00001, loss_test:0.01030, lr:5.65e-02, fs:0.93532 (r=0.949,p=0.922),  time:34.383, tt:3369.501\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01457, lr:5.65e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.398, tt:3405.392\n",
      "Ep:99, loss:0.00001, loss_test:0.01048, lr:5.65e-02, fs:0.89691 (r=0.879,p=0.916),  time:34.404, tt:3440.433\n",
      "Ep:100, loss:0.00001, loss_test:0.01036, lr:5.65e-02, fs:0.92929 (r=0.929,p=0.929),  time:34.411, tt:3475.555\n",
      "Ep:101, loss:0.00001, loss_test:0.01225, lr:5.65e-02, fs:0.91005 (r=0.869,p=0.956),  time:34.434, tt:3512.288\n",
      "Ep:102, loss:0.00001, loss_test:0.01116, lr:5.65e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.442, tt:3547.558\n",
      "Ep:103, loss:0.00001, loss_test:0.01357, lr:5.65e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.451, tt:3582.935\n",
      "Ep:104, loss:0.00001, loss_test:0.01218, lr:5.65e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.452, tt:3617.455\n",
      "Ep:105, loss:0.00001, loss_test:0.01250, lr:5.65e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.460, tt:3652.734\n",
      "Ep:106, loss:0.00001, loss_test:0.01177, lr:5.65e-02, fs:0.90052 (r=0.869,p=0.935),  time:34.468, tt:3688.052\n",
      "Ep:107, loss:0.00000, loss_test:0.01311, lr:5.65e-02, fs:0.90426 (r=0.859,p=0.955),  time:34.470, tt:3722.774\n",
      "Ep:108, loss:0.00000, loss_test:0.01384, lr:5.65e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.474, tt:3757.683\n",
      "Ep:109, loss:0.00000, loss_test:0.01298, lr:5.59e-02, fs:0.90426 (r=0.859,p=0.955),  time:34.481, tt:3792.911\n",
      "Ep:110, loss:0.00000, loss_test:0.01318, lr:5.54e-02, fs:0.89947 (r=0.859,p=0.944),  time:34.504, tt:3829.894\n",
      "Ep:111, loss:0.00000, loss_test:0.01454, lr:5.48e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.512, tt:3865.397\n",
      "Ep:112, loss:0.00000, loss_test:0.01438, lr:5.43e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.521, tt:3900.832\n",
      "Ep:113, loss:0.00000, loss_test:0.01382, lr:5.37e-02, fs:0.88398 (r=0.808,p=0.976),  time:34.525, tt:3935.905\n",
      "Ep:114, loss:0.00000, loss_test:0.01320, lr:5.32e-02, fs:0.85227 (r=0.758,p=0.974),  time:34.525, tt:3970.373\n",
      "Ep:115, loss:0.00000, loss_test:0.01531, lr:5.27e-02, fs:0.80000 (r=0.687,p=0.958),  time:34.536, tt:4006.221\n",
      "Ep:116, loss:0.00000, loss_test:0.01517, lr:5.21e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.535, tt:4040.612\n",
      "Ep:117, loss:0.00000, loss_test:0.01323, lr:5.16e-02, fs:0.85227 (r=0.758,p=0.974),  time:34.535, tt:4075.154\n",
      "Ep:118, loss:0.00000, loss_test:0.01391, lr:5.11e-02, fs:0.84571 (r=0.747,p=0.974),  time:34.580, tt:4115.001\n",
      "Ep:119, loss:0.00000, loss_test:0.01474, lr:5.06e-02, fs:0.83237 (r=0.727,p=0.973),  time:34.583, tt:4149.938\n",
      "Ep:120, loss:0.00000, loss_test:0.01575, lr:5.01e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.601, tt:4186.766\n",
      "Ep:121, loss:0.00000, loss_test:0.01577, lr:4.96e-02, fs:0.76074 (r=0.626,p=0.969),  time:34.613, tt:4222.747\n",
      "Ep:122, loss:0.00000, loss_test:0.01438, lr:4.91e-02, fs:0.82558 (r=0.717,p=0.973),  time:34.639, tt:4260.567\n",
      "Ep:123, loss:0.00000, loss_test:0.01464, lr:4.86e-02, fs:0.82558 (r=0.717,p=0.973),  time:34.648, tt:4296.297\n",
      "Ep:124, loss:0.00000, loss_test:0.01551, lr:4.81e-02, fs:0.78313 (r=0.657,p=0.970),  time:34.647, tt:4330.854\n",
      "Ep:125, loss:0.00000, loss_test:0.01539, lr:4.76e-02, fs:0.76074 (r=0.626,p=0.969),  time:34.664, tt:4367.720\n",
      "Ep:126, loss:0.00000, loss_test:0.01567, lr:4.71e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.677, tt:4404.038\n",
      "Ep:127, loss:0.00000, loss_test:0.01576, lr:4.67e-02, fs:0.76074 (r=0.626,p=0.969),  time:34.685, tt:4439.705\n",
      "Ep:128, loss:0.00000, loss_test:0.01612, lr:4.62e-02, fs:0.73750 (r=0.596,p=0.967),  time:34.698, tt:4475.981\n",
      "Ep:129, loss:0.00000, loss_test:0.01637, lr:4.57e-02, fs:0.73750 (r=0.596,p=0.967),  time:34.714, tt:4512.826\n",
      "Ep:130, loss:0.00000, loss_test:0.01472, lr:4.53e-02, fs:0.79042 (r=0.667,p=0.971),  time:34.725, tt:4548.993\n",
      "Ep:131, loss:0.00000, loss_test:0.01420, lr:4.48e-02, fs:0.80473 (r=0.687,p=0.971),  time:34.731, tt:4584.449\n",
      "Ep:132, loss:0.00000, loss_test:0.01594, lr:4.44e-02, fs:0.75309 (r=0.616,p=0.968),  time:34.747, tt:4621.380\n",
      "Ep:133, loss:0.00000, loss_test:0.01647, lr:4.39e-02, fs:0.70513 (r=0.556,p=0.965),  time:34.764, tt:4658.412\n",
      "Ep:134, loss:0.00000, loss_test:0.01508, lr:4.35e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.776, tt:4694.786\n",
      "Ep:135, loss:0.00000, loss_test:0.01541, lr:4.31e-02, fs:0.76074 (r=0.626,p=0.969),  time:34.793, tt:4731.911\n",
      "Ep:136, loss:0.00000, loss_test:0.01601, lr:4.26e-02, fs:0.72956 (r=0.586,p=0.967),  time:34.800, tt:4767.638\n",
      "Ep:137, loss:0.00000, loss_test:0.01669, lr:4.22e-02, fs:0.72956 (r=0.586,p=0.967),  time:34.814, tt:4804.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.01606, lr:4.18e-02, fs:0.71338 (r=0.566,p=0.966),  time:34.834, tt:4841.947\n",
      "Ep:139, loss:0.00000, loss_test:0.01692, lr:4.14e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.836, tt:4877.022\n",
      "Ep:140, loss:0.00000, loss_test:0.01729, lr:4.10e-02, fs:0.71338 (r=0.566,p=0.966),  time:34.832, tt:4911.277\n",
      "Ep:141, loss:0.00000, loss_test:0.01635, lr:4.05e-02, fs:0.72152 (r=0.576,p=0.966),  time:34.845, tt:4947.923\n",
      "Ep:142, loss:0.00000, loss_test:0.01709, lr:4.01e-02, fs:0.70513 (r=0.556,p=0.965),  time:34.849, tt:4983.442\n",
      "Ep:143, loss:0.00000, loss_test:0.01697, lr:3.97e-02, fs:0.69677 (r=0.545,p=0.964),  time:34.853, tt:5018.841\n",
      "Ep:144, loss:0.00000, loss_test:0.01686, lr:3.93e-02, fs:0.68831 (r=0.535,p=0.964),  time:34.859, tt:5054.585\n",
      "Ep:145, loss:0.00000, loss_test:0.01745, lr:3.89e-02, fs:0.71338 (r=0.566,p=0.966),  time:34.876, tt:5091.909\n",
      "Ep:146, loss:0.00000, loss_test:0.01735, lr:3.86e-02, fs:0.69677 (r=0.545,p=0.964),  time:34.878, tt:5127.072\n",
      "Ep:147, loss:0.00000, loss_test:0.01719, lr:3.82e-02, fs:0.66225 (r=0.505,p=0.962),  time:34.879, tt:5162.131\n",
      "Ep:148, loss:0.00000, loss_test:0.01787, lr:3.78e-02, fs:0.70513 (r=0.556,p=0.965),  time:34.885, tt:5197.794\n",
      "Ep:149, loss:0.00000, loss_test:0.01731, lr:3.74e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.894, tt:5234.090\n",
      "Ep:150, loss:0.00000, loss_test:0.01727, lr:3.70e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.897, tt:5269.490\n",
      "Ep:151, loss:0.00000, loss_test:0.01799, lr:3.67e-02, fs:0.69677 (r=0.545,p=0.964),  time:34.913, tt:5306.830\n",
      "Ep:152, loss:0.00000, loss_test:0.01766, lr:3.63e-02, fs:0.67550 (r=0.515,p=0.981),  time:34.933, tt:5344.722\n",
      "Ep:153, loss:0.00000, loss_test:0.01797, lr:3.59e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.942, tt:5381.098\n",
      "Ep:154, loss:0.00000, loss_test:0.01727, lr:3.56e-02, fs:0.67974 (r=0.525,p=0.963),  time:34.951, tt:5417.329\n",
      "Ep:155, loss:0.00000, loss_test:0.01769, lr:3.52e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.954, tt:5452.899\n",
      "Ep:156, loss:0.00000, loss_test:0.01815, lr:3.49e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.955, tt:5488.006\n",
      "Ep:157, loss:0.00000, loss_test:0.01772, lr:3.45e-02, fs:0.65333 (r=0.495,p=0.961),  time:34.957, tt:5523.194\n",
      "Ep:158, loss:0.00000, loss_test:0.01756, lr:3.42e-02, fs:0.67105 (r=0.515,p=0.962),  time:34.962, tt:5558.942\n",
      "Ep:159, loss:0.00000, loss_test:0.01826, lr:3.38e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.963, tt:5594.152\n",
      "Ep:160, loss:0.00000, loss_test:0.01855, lr:3.35e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.961, tt:5628.729\n",
      "Ep:161, loss:0.00000, loss_test:0.01825, lr:3.32e-02, fs:0.67974 (r=0.525,p=0.963),  time:34.961, tt:5663.644\n",
      "Ep:162, loss:0.00000, loss_test:0.01777, lr:3.28e-02, fs:0.64430 (r=0.485,p=0.960),  time:34.972, tt:5700.486\n",
      "Ep:163, loss:0.00000, loss_test:0.01808, lr:3.25e-02, fs:0.65333 (r=0.495,p=0.961),  time:34.979, tt:5736.582\n",
      "Ep:164, loss:0.00000, loss_test:0.01848, lr:3.22e-02, fs:0.66225 (r=0.505,p=0.962),  time:34.980, tt:5771.697\n",
      "Ep:165, loss:0.00000, loss_test:0.01847, lr:3.19e-02, fs:0.66667 (r=0.505,p=0.980),  time:34.977, tt:5806.203\n",
      "Ep:166, loss:0.00000, loss_test:0.01872, lr:3.15e-02, fs:0.67550 (r=0.515,p=0.981),  time:34.976, tt:5841.004\n",
      "Ep:167, loss:0.00000, loss_test:0.01872, lr:3.12e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.974, tt:5875.625\n",
      "Ep:168, loss:0.00000, loss_test:0.01867, lr:3.09e-02, fs:0.66667 (r=0.505,p=0.980),  time:34.973, tt:5910.507\n",
      "Ep:169, loss:0.00000, loss_test:0.01834, lr:3.06e-02, fs:0.65333 (r=0.495,p=0.961),  time:34.970, tt:5944.940\n",
      "Ep:170, loss:0.00000, loss_test:0.01869, lr:3.03e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.972, tt:5980.144\n",
      "Ep:171, loss:0.00000, loss_test:0.01866, lr:3.00e-02, fs:0.64430 (r=0.485,p=0.960),  time:34.969, tt:6014.662\n",
      "Ep:172, loss:0.00000, loss_test:0.01837, lr:2.97e-02, fs:0.65333 (r=0.495,p=0.961),  time:34.974, tt:6050.552\n",
      "Ep:173, loss:0.00000, loss_test:0.01888, lr:2.94e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.976, tt:6085.816\n",
      "Ep:174, loss:0.00000, loss_test:0.01924, lr:2.91e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.983, tt:6121.941\n",
      "Ep:175, loss:0.00000, loss_test:0.01876, lr:2.88e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.987, tt:6157.646\n",
      "Ep:176, loss:0.00000, loss_test:0.01904, lr:2.85e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.984, tt:6192.142\n",
      "Ep:177, loss:0.00000, loss_test:0.01886, lr:2.82e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.988, tt:6227.921\n",
      "Ep:178, loss:0.00000, loss_test:0.01910, lr:2.80e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.993, tt:6263.824\n",
      "Ep:179, loss:0.00000, loss_test:0.01893, lr:2.77e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.997, tt:6299.396\n",
      "Ep:180, loss:0.00000, loss_test:0.01908, lr:2.74e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.997, tt:6334.491\n",
      "Ep:181, loss:0.00000, loss_test:0.01907, lr:2.71e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.996, tt:6369.268\n",
      "Ep:182, loss:0.00000, loss_test:0.01925, lr:2.69e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.998, tt:6404.674\n",
      "Ep:183, loss:0.00000, loss_test:0.01941, lr:2.66e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.995, tt:6439.010\n",
      "Ep:184, loss:0.00000, loss_test:0.01929, lr:2.63e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.996, tt:6474.219\n",
      "Ep:185, loss:0.00000, loss_test:0.01902, lr:2.61e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.002, tt:6510.424\n",
      "Ep:186, loss:0.00000, loss_test:0.01921, lr:2.58e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.998, tt:6544.694\n",
      "Ep:187, loss:0.00000, loss_test:0.01976, lr:2.55e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.007, tt:6581.281\n",
      "Ep:188, loss:0.00000, loss_test:0.01934, lr:2.53e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.009, tt:6616.789\n",
      "Ep:189, loss:0.00000, loss_test:0.01942, lr:2.50e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.010, tt:6651.929\n",
      "Ep:190, loss:0.00000, loss_test:0.01976, lr:2.48e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.017, tt:6688.232\n",
      "Ep:191, loss:0.00000, loss_test:0.01983, lr:2.45e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.012, tt:6722.233\n",
      "Ep:192, loss:0.00000, loss_test:0.01924, lr:2.43e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.010, tt:6756.845\n",
      "Ep:193, loss:0.00000, loss_test:0.01977, lr:2.40e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.022, tt:6794.175\n",
      "Ep:194, loss:0.00000, loss_test:0.01966, lr:2.38e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.023, tt:6829.523\n",
      "Ep:195, loss:0.00000, loss_test:0.01954, lr:2.36e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.028, tt:6865.481\n",
      "Ep:196, loss:0.00000, loss_test:0.01996, lr:2.33e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.028, tt:6900.418\n",
      "Ep:197, loss:0.00000, loss_test:0.01959, lr:2.31e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.033, tt:6936.626\n",
      "Ep:198, loss:0.00000, loss_test:0.01993, lr:2.29e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.036, tt:6972.131\n",
      "Ep:199, loss:0.00000, loss_test:0.01973, lr:2.26e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.040, tt:7008.030\n",
      "Ep:200, loss:0.00000, loss_test:0.01979, lr:2.24e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.041, tt:7043.182\n",
      "Ep:201, loss:0.00000, loss_test:0.01998, lr:2.22e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.047, tt:7079.505\n",
      "Ep:202, loss:0.00000, loss_test:0.01978, lr:2.20e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.051, tt:7115.393\n",
      "Ep:203, loss:0.00000, loss_test:0.01987, lr:2.17e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.051, tt:7150.335\n",
      "Ep:204, loss:0.00000, loss_test:0.02003, lr:2.15e-02, fs:0.65772 (r=0.495,p=0.980),  time:35.054, tt:7186.059\n",
      "Ep:205, loss:0.00000, loss_test:0.01979, lr:2.13e-02, fs:0.66667 (r=0.505,p=0.980),  time:35.053, tt:7220.962\n",
      "Ep:206, loss:0.00000, loss_test:0.02028, lr:2.11e-02, fs:0.66667 (r=0.505,p=0.980),  time:35.029, tt:7251.011\n",
      "Ep:207, loss:0.00000, loss_test:0.01985, lr:2.09e-02, fs:0.66667 (r=0.505,p=0.980),  time:35.012, tt:7282.592\n",
      "Ep:208, loss:0.00000, loss_test:0.02020, lr:2.07e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.990, tt:7312.903\n",
      "Ep:209, loss:0.00000, loss_test:0.02022, lr:2.05e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.971, tt:7343.856\n",
      "Ep:210, loss:0.00000, loss_test:0.02003, lr:2.03e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.937, tt:7371.636\n",
      "Ep:211, loss:0.00000, loss_test:0.02031, lr:2.01e-02, fs:0.65772 (r=0.495,p=0.980),  time:34.911, tt:7401.050\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12219, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:35.991, tt:35.991\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12040, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:35.885, tt:71.770\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11817, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:35.944, tt:107.832\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11604, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.833, tt:143.332\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11472, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:36.066, tt:180.329\n",
      "Ep:5, loss:0.00026, loss_test:0.11426, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:35.819, tt:214.913\n",
      "Ep:6, loss:0.00025, loss_test:0.11437, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:35.758, tt:250.306\n",
      "Ep:7, loss:0.00025, loss_test:0.11392, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:35.672, tt:285.373\n",
      "Ep:8, loss:0.00025, loss_test:0.11335, lr:1.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:35.571, tt:320.143\n",
      "Ep:9, loss:0.00025, loss_test:0.11217, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:35.276, tt:352.757\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11035, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:35.090, tt:385.994\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.10885, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:35.053, tt:420.634\n",
      "Ep:12, loss:0.00024, loss_test:0.10850, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:35.004, tt:455.057\n",
      "Ep:13, loss:0.00023, loss_test:0.10708, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:34.906, tt:488.677\n",
      "Ep:14, loss:0.00023, loss_test:0.10543, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:34.797, tt:521.957\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.10384, lr:1.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:34.844, tt:557.499\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.10204, lr:1.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:34.774, tt:591.166\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10257, lr:1.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:34.806, tt:626.509\n",
      "Ep:18, loss:0.00021, loss_test:0.09954, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:34.744, tt:660.137\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.09882, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:34.662, tt:693.246\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.09629, lr:1.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:34.639, tt:727.415\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09633, lr:1.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:34.565, tt:760.426\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.09522, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:34.509, tt:793.716\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.09499, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:34.623, tt:830.943\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09269, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:34.535, tt:863.374\n",
      "Ep:25, loss:0.00016, loss_test:0.09249, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:34.534, tt:897.875\n",
      "Ep:26, loss:0.00015, loss_test:0.09087, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.547, tt:932.772\n",
      "Ep:27, loss:0.00014, loss_test:0.08940, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:34.547, tt:967.304\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08509, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:34.548, tt:1001.882\n",
      "Ep:29, loss:0.00013, loss_test:0.08635, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.546, tt:1036.371\n",
      "Ep:30, loss:0.00012, loss_test:0.08304, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.592, tt:1072.359\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08485, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.612, tt:1107.590\n",
      "Ep:32, loss:0.00011, loss_test:0.08173, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.576, tt:1141.015\n",
      "Ep:33, loss:0.00011, loss_test:0.09294, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:34.549, tt:1174.674\n",
      "Ep:34, loss:0.00012, loss_test:0.08258, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.564, tt:1209.746\n",
      "Ep:35, loss:0.00011, loss_test:0.08534, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:34.572, tt:1244.574\n",
      "Ep:36, loss:0.00010, loss_test:0.07503, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:34.592, tt:1279.915\n",
      "Ep:37, loss:0.00009, loss_test:0.07903, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.566, tt:1313.490\n",
      "Ep:38, loss:0.00009, loss_test:0.07615, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.580, tt:1348.632\n",
      "Ep:39, loss:0.00009, loss_test:0.08748, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.594, tt:1383.747\n",
      "Ep:40, loss:0.00009, loss_test:0.07049, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.566, tt:1417.195\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07580, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:34.553, tt:1451.205\n",
      "Ep:42, loss:0.00009, loss_test:0.07807, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.540, tt:1485.234\n",
      "Ep:43, loss:0.00008, loss_test:0.07212, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.519, tt:1518.815\n",
      "Ep:44, loss:0.00008, loss_test:0.07961, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.520, tt:1553.414\n",
      "Ep:45, loss:0.00007, loss_test:0.06880, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.543, tt:1588.987\n",
      "Ep:46, loss:0.00007, loss_test:0.09324, lr:1.00e-02, fs:0.71739 (r=0.667,p=0.776),  time:34.528, tt:1622.825\n",
      "Ep:47, loss:0.00010, loss_test:0.07515, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.515, tt:1656.698\n",
      "Ep:48, loss:0.00009, loss_test:0.08935, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:34.540, tt:1692.463\n",
      "Ep:49, loss:0.00008, loss_test:0.07041, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:34.516, tt:1725.787\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.08236, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.496, tt:1759.281\n",
      "Ep:51, loss:0.00007, loss_test:0.07036, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:34.480, tt:1792.952\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.07931, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.468, tt:1826.808\n",
      "Ep:53, loss:0.00008, loss_test:0.06895, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.464, tt:1861.069\n",
      "Ep:54, loss:0.00006, loss_test:0.09550, lr:1.00e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.456, tt:1895.062\n",
      "Ep:55, loss:0.00007, loss_test:0.06842, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.451, tt:1929.242\n",
      "Ep:56, loss:0.00006, loss_test:0.07896, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.453, tt:1963.841\n",
      "Ep:57, loss:0.00006, loss_test:0.07128, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.449, tt:1998.059\n",
      "Ep:58, loss:0.00005, loss_test:0.07234, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:34.448, tt:2032.429\n",
      "Ep:59, loss:0.00005, loss_test:0.07232, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:34.470, tt:2068.194\n",
      "Ep:60, loss:0.00005, loss_test:0.07144, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.480, tt:2103.298\n",
      "Ep:61, loss:0.00005, loss_test:0.07044, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.478, tt:2137.653\n",
      "Ep:62, loss:0.00004, loss_test:0.07065, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.509, tt:2174.089\n",
      "Ep:63, loss:0.00004, loss_test:0.07691, lr:9.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:34.524, tt:2209.528\n",
      "Ep:64, loss:0.00004, loss_test:0.07724, lr:9.80e-03, fs:0.75581 (r=0.657,p=0.890),  time:34.501, tt:2242.546\n",
      "Ep:65, loss:0.00004, loss_test:0.07531, lr:9.70e-03, fs:0.74854 (r=0.646,p=0.889),  time:34.492, tt:2276.449\n",
      "Ep:66, loss:0.00003, loss_test:0.07644, lr:9.61e-03, fs:0.76301 (r=0.667,p=0.892),  time:34.498, tt:2311.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00003, loss_test:0.07643, lr:9.51e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.478, tt:2344.520\n",
      "Ep:68, loss:0.00003, loss_test:0.07924, lr:9.41e-03, fs:0.75145 (r=0.657,p=0.878),  time:34.488, tt:2379.652\n",
      "Ep:69, loss:0.00003, loss_test:0.08198, lr:9.32e-03, fs:0.73373 (r=0.626,p=0.886),  time:34.466, tt:2412.651\n",
      "Ep:70, loss:0.00003, loss_test:0.07925, lr:9.23e-03, fs:0.76023 (r=0.657,p=0.903),  time:34.465, tt:2447.026\n",
      "Ep:71, loss:0.00003, loss_test:0.08387, lr:9.14e-03, fs:0.74419 (r=0.646,p=0.877),  time:34.458, tt:2480.960\n",
      "Ep:72, loss:0.00003, loss_test:0.07859, lr:9.04e-03, fs:0.75429 (r=0.667,p=0.868),  time:34.447, tt:2514.628\n",
      "Ep:73, loss:0.00003, loss_test:0.08516, lr:8.95e-03, fs:0.69091 (r=0.576,p=0.864),  time:34.445, tt:2548.939\n",
      "Ep:74, loss:0.00003, loss_test:0.07696, lr:8.86e-03, fs:0.74854 (r=0.646,p=0.889),  time:34.422, tt:2581.635\n",
      "Ep:75, loss:0.00003, loss_test:0.07936, lr:8.78e-03, fs:0.81111 (r=0.737,p=0.901),  time:34.417, tt:2615.723\n",
      "Ep:76, loss:0.00003, loss_test:0.09666, lr:8.69e-03, fs:0.66667 (r=0.545,p=0.857),  time:34.434, tt:2651.380\n",
      "Ep:77, loss:0.00003, loss_test:0.07596, lr:8.60e-03, fs:0.81319 (r=0.747,p=0.892),  time:34.430, tt:2685.564\n",
      "Ep:78, loss:0.00003, loss_test:0.08770, lr:8.51e-03, fs:0.73054 (r=0.616,p=0.897),  time:34.419, tt:2719.072\n",
      "Ep:79, loss:0.00002, loss_test:0.08890, lr:8.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.408, tt:2752.656\n",
      "Ep:80, loss:0.00002, loss_test:0.08584, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:34.404, tt:2786.737\n",
      "Ep:81, loss:0.00002, loss_test:0.08974, lr:8.26e-03, fs:0.74419 (r=0.646,p=0.877),  time:34.396, tt:2820.493\n",
      "Ep:82, loss:0.00002, loss_test:0.08617, lr:8.18e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.394, tt:2854.685\n",
      "Ep:83, loss:0.00002, loss_test:0.09212, lr:8.10e-03, fs:0.74854 (r=0.646,p=0.889),  time:34.387, tt:2888.490\n",
      "Ep:84, loss:0.00002, loss_test:0.09318, lr:8.02e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.382, tt:2922.439\n",
      "Ep:85, loss:0.00002, loss_test:0.08774, lr:7.94e-03, fs:0.68323 (r=0.556,p=0.887),  time:34.343, tt:2953.498\n",
      "Ep:86, loss:0.00002, loss_test:0.09289, lr:7.86e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.335, tt:2987.106\n",
      "Ep:87, loss:0.00002, loss_test:0.08920, lr:7.78e-03, fs:0.68323 (r=0.556,p=0.887),  time:34.313, tt:3019.522\n",
      "Ep:88, loss:0.00002, loss_test:0.08753, lr:7.70e-03, fs:0.81111 (r=0.737,p=0.901),  time:34.317, tt:3054.198\n",
      "Ep:89, loss:0.00002, loss_test:0.10234, lr:7.62e-03, fs:0.67081 (r=0.545,p=0.871),  time:34.308, tt:3087.682\n",
      "Ep:90, loss:0.00002, loss_test:0.09226, lr:7.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:34.313, tt:3122.451\n",
      "Ep:91, loss:0.00002, loss_test:0.09344, lr:7.47e-03, fs:0.67081 (r=0.545,p=0.871),  time:34.314, tt:3156.865\n",
      "Ep:92, loss:0.00002, loss_test:0.09777, lr:7.40e-03, fs:0.73988 (r=0.646,p=0.865),  time:34.300, tt:3189.900\n",
      "Ep:93, loss:0.00002, loss_test:0.10300, lr:7.32e-03, fs:0.67081 (r=0.545,p=0.871),  time:34.305, tt:3224.643\n",
      "Ep:94, loss:0.00002, loss_test:0.09392, lr:7.25e-03, fs:0.74854 (r=0.646,p=0.889),  time:34.285, tt:3257.106\n",
      "Ep:95, loss:0.00002, loss_test:0.09099, lr:7.18e-03, fs:0.68323 (r=0.556,p=0.887),  time:34.286, tt:3291.410\n",
      "Ep:96, loss:0.00002, loss_test:0.09519, lr:7.11e-03, fs:0.83516 (r=0.768,p=0.916),  time:34.288, tt:3325.977\n",
      "Ep:97, loss:0.00002, loss_test:0.09816, lr:7.03e-03, fs:0.67081 (r=0.545,p=0.871),  time:34.294, tt:3360.782\n",
      "Ep:98, loss:0.00002, loss_test:0.09828, lr:6.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:34.281, tt:3393.782\n",
      "Ep:99, loss:0.00002, loss_test:0.09714, lr:6.89e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.285, tt:3428.469\n",
      "Ep:100, loss:0.00002, loss_test:0.10092, lr:6.83e-03, fs:0.65806 (r=0.515,p=0.911),  time:34.292, tt:3463.531\n",
      "Ep:101, loss:0.00002, loss_test:0.09857, lr:6.76e-03, fs:0.68712 (r=0.566,p=0.875),  time:34.294, tt:3497.993\n",
      "Ep:102, loss:0.00003, loss_test:0.08602, lr:6.69e-03, fs:0.76836 (r=0.687,p=0.872),  time:34.297, tt:3532.575\n",
      "Ep:103, loss:0.00004, loss_test:0.08239, lr:6.62e-03, fs:0.76087 (r=0.707,p=0.824),  time:34.288, tt:3566.002\n",
      "Ep:104, loss:0.00006, loss_test:0.09374, lr:6.56e-03, fs:0.82418 (r=0.758,p=0.904),  time:34.301, tt:3601.629\n",
      "Ep:105, loss:0.00004, loss_test:0.09624, lr:6.49e-03, fs:0.72316 (r=0.646,p=0.821),  time:34.298, tt:3635.569\n",
      "Ep:106, loss:0.00004, loss_test:0.08121, lr:6.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.285, tt:3668.508\n",
      "Ep:107, loss:0.00004, loss_test:0.08311, lr:6.36e-03, fs:0.78889 (r=0.717,p=0.877),  time:34.282, tt:3702.419\n",
      "Ep:108, loss:0.00003, loss_test:0.10258, lr:6.30e-03, fs:0.73446 (r=0.657,p=0.833),  time:34.292, tt:3737.836\n",
      "Ep:109, loss:0.00004, loss_test:0.08210, lr:6.24e-03, fs:0.82418 (r=0.758,p=0.904),  time:34.299, tt:3772.896\n",
      "Ep:110, loss:0.00003, loss_test:0.09970, lr:6.17e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.299, tt:3807.211\n",
      "Ep:111, loss:0.00003, loss_test:0.09705, lr:6.11e-03, fs:0.70732 (r=0.586,p=0.892),  time:34.293, tt:3840.785\n",
      "Ep:112, loss:0.00002, loss_test:0.08877, lr:6.05e-03, fs:0.76301 (r=0.667,p=0.892),  time:34.297, tt:3875.527\n",
      "Ep:113, loss:0.00002, loss_test:0.09334, lr:5.99e-03, fs:0.69512 (r=0.576,p=0.877),  time:34.287, tt:3908.692\n",
      "Ep:114, loss:0.00002, loss_test:0.09629, lr:5.93e-03, fs:0.72189 (r=0.616,p=0.871),  time:34.287, tt:3942.974\n",
      "Ep:115, loss:0.00002, loss_test:0.08889, lr:5.87e-03, fs:0.74118 (r=0.636,p=0.887),  time:34.288, tt:3977.367\n",
      "Ep:116, loss:0.00002, loss_test:0.09026, lr:5.81e-03, fs:0.70732 (r=0.586,p=0.892),  time:34.288, tt:4011.651\n",
      "Ep:117, loss:0.00002, loss_test:0.09394, lr:5.75e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.285, tt:4045.665\n",
      "Ep:118, loss:0.00002, loss_test:0.10178, lr:5.70e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.282, tt:4079.530\n",
      "Ep:119, loss:0.00002, loss_test:0.09569, lr:5.64e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.286, tt:4114.273\n",
      "Ep:120, loss:0.00001, loss_test:0.09535, lr:5.58e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.279, tt:4147.784\n",
      "Ep:121, loss:0.00001, loss_test:0.09460, lr:5.53e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.282, tt:4182.428\n",
      "Ep:122, loss:0.00001, loss_test:0.09791, lr:5.47e-03, fs:0.67925 (r=0.545,p=0.900),  time:34.276, tt:4215.892\n",
      "Ep:123, loss:0.00001, loss_test:0.10145, lr:5.42e-03, fs:0.67500 (r=0.545,p=0.885),  time:34.271, tt:4249.620\n",
      "Ep:124, loss:0.00001, loss_test:0.09442, lr:5.36e-03, fs:0.67925 (r=0.545,p=0.900),  time:34.278, tt:4284.741\n",
      "Ep:125, loss:0.00001, loss_test:0.10153, lr:5.31e-03, fs:0.67925 (r=0.545,p=0.900),  time:34.292, tt:4320.765\n",
      "Ep:126, loss:0.00001, loss_test:0.10172, lr:5.26e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.288, tt:4354.530\n",
      "Ep:127, loss:0.00001, loss_test:0.09870, lr:5.20e-03, fs:0.69182 (r=0.556,p=0.917),  time:34.292, tt:4389.432\n",
      "Ep:128, loss:0.00001, loss_test:0.09790, lr:5.15e-03, fs:0.70370 (r=0.576,p=0.905),  time:34.292, tt:4423.660\n",
      "Ep:129, loss:0.00001, loss_test:0.09831, lr:5.10e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.286, tt:4457.116\n",
      "Ep:130, loss:0.00001, loss_test:0.10403, lr:5.05e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.290, tt:4492.031\n",
      "Ep:131, loss:0.00001, loss_test:0.10118, lr:5.00e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.279, tt:4524.855\n",
      "Ep:132, loss:0.00001, loss_test:0.10169, lr:4.95e-03, fs:0.68750 (r=0.556,p=0.902),  time:34.273, tt:4558.306\n",
      "Ep:133, loss:0.00001, loss_test:0.09877, lr:4.90e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.270, tt:4592.207\n",
      "Ep:134, loss:0.00001, loss_test:0.10262, lr:4.85e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.255, tt:4624.488\n",
      "Ep:135, loss:0.00001, loss_test:0.10345, lr:4.80e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.257, tt:4658.930\n",
      "Ep:136, loss:0.00001, loss_test:0.10112, lr:4.75e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.255, tt:4692.923\n",
      "Ep:137, loss:0.00001, loss_test:0.10106, lr:4.71e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.269, tt:4729.120\n",
      "Ep:138, loss:0.00001, loss_test:0.10574, lr:4.66e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.263, tt:4762.623\n",
      "Ep:139, loss:0.00001, loss_test:0.10125, lr:4.61e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.268, tt:4797.583\n",
      "Ep:140, loss:0.00001, loss_test:0.10555, lr:4.57e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.270, tt:4832.003\n",
      "Ep:141, loss:0.00001, loss_test:0.10363, lr:4.52e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.268, tt:4866.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.10263, lr:4.48e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.270, tt:4900.629\n",
      "Ep:143, loss:0.00001, loss_test:0.10659, lr:4.43e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.273, tt:4935.312\n",
      "Ep:144, loss:0.00001, loss_test:0.10321, lr:4.39e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.262, tt:4968.000\n",
      "Ep:145, loss:0.00001, loss_test:0.10615, lr:4.34e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.260, tt:5001.916\n",
      "Ep:146, loss:0.00001, loss_test:0.10528, lr:4.30e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.268, tt:5037.445\n",
      "Ep:147, loss:0.00001, loss_test:0.10942, lr:4.26e-03, fs:0.67925 (r=0.545,p=0.900),  time:34.280, tt:5073.509\n",
      "Ep:148, loss:0.00001, loss_test:0.10078, lr:4.21e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.280, tt:5107.717\n",
      "Ep:149, loss:0.00001, loss_test:0.10641, lr:4.17e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.304, tt:5145.601\n",
      "Ep:150, loss:0.00001, loss_test:0.10837, lr:4.13e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.310, tt:5180.756\n",
      "Ep:151, loss:0.00001, loss_test:0.10281, lr:4.09e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.302, tt:5213.945\n",
      "Ep:152, loss:0.00001, loss_test:0.10576, lr:4.05e-03, fs:0.68790 (r=0.545,p=0.931),  time:34.306, tt:5248.754\n",
      "Ep:153, loss:0.00001, loss_test:0.10585, lr:4.01e-03, fs:0.68790 (r=0.545,p=0.931),  time:34.309, tt:5283.526\n",
      "Ep:154, loss:0.00001, loss_test:0.10438, lr:3.97e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.310, tt:5317.981\n",
      "Ep:155, loss:0.00001, loss_test:0.10571, lr:3.93e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.304, tt:5351.401\n",
      "Ep:156, loss:0.00001, loss_test:0.10589, lr:3.89e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.301, tt:5385.205\n",
      "Ep:157, loss:0.00001, loss_test:0.10603, lr:3.85e-03, fs:0.68354 (r=0.545,p=0.915),  time:34.299, tt:5419.237\n",
      "Ep:158, loss:0.00001, loss_test:0.10414, lr:3.81e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.295, tt:5452.929\n",
      "Ep:159, loss:0.00001, loss_test:0.10589, lr:3.77e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.298, tt:5487.624\n",
      "Ep:160, loss:0.00001, loss_test:0.10282, lr:3.73e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.295, tt:5521.431\n",
      "Ep:161, loss:0.00001, loss_test:0.10611, lr:3.70e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.302, tt:5556.956\n",
      "Ep:162, loss:0.00001, loss_test:0.10409, lr:3.66e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.308, tt:5592.165\n",
      "Ep:163, loss:0.00001, loss_test:0.10549, lr:3.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.318, tt:5628.101\n",
      "Ep:164, loss:0.00001, loss_test:0.10439, lr:3.59e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.313, tt:5661.637\n",
      "Ep:165, loss:0.00001, loss_test:0.10456, lr:3.55e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.321, tt:5697.258\n",
      "Ep:166, loss:0.00001, loss_test:0.10408, lr:3.52e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.318, tt:5731.151\n",
      "Ep:167, loss:0.00001, loss_test:0.10475, lr:3.48e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.329, tt:5767.303\n",
      "Ep:168, loss:0.00001, loss_test:0.10587, lr:3.45e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.332, tt:5802.143\n",
      "Ep:169, loss:0.00001, loss_test:0.10354, lr:3.41e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.327, tt:5835.554\n",
      "Ep:170, loss:0.00001, loss_test:0.10500, lr:3.38e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.326, tt:5869.702\n",
      "Ep:171, loss:0.00001, loss_test:0.10350, lr:3.34e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.329, tt:5904.617\n",
      "Ep:172, loss:0.00001, loss_test:0.10510, lr:3.31e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.339, tt:5940.651\n",
      "Ep:173, loss:0.00001, loss_test:0.10727, lr:3.28e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.342, tt:5975.549\n",
      "Ep:174, loss:0.00001, loss_test:0.10081, lr:3.24e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.353, tt:6011.755\n",
      "Ep:175, loss:0.00001, loss_test:0.10698, lr:3.21e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.365, tt:6048.231\n",
      "Ep:176, loss:0.00001, loss_test:0.10666, lr:3.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.378, tt:6084.826\n",
      "Ep:177, loss:0.00001, loss_test:0.10322, lr:3.15e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.387, tt:6120.902\n",
      "Ep:178, loss:0.00001, loss_test:0.10808, lr:3.12e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.394, tt:6156.466\n",
      "Ep:179, loss:0.00001, loss_test:0.10521, lr:3.09e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.403, tt:6192.548\n",
      "Ep:180, loss:0.00001, loss_test:0.10386, lr:3.05e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.412, tt:6228.631\n",
      "Ep:181, loss:0.00001, loss_test:0.10409, lr:3.02e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.417, tt:6263.974\n",
      "Ep:182, loss:0.00001, loss_test:0.10410, lr:2.99e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.432, tt:6301.008\n",
      "Ep:183, loss:0.00001, loss_test:0.10363, lr:2.96e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.449, tt:6338.552\n",
      "Ep:184, loss:0.00000, loss_test:0.10222, lr:2.93e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.454, tt:6374.052\n",
      "Ep:185, loss:0.00000, loss_test:0.10395, lr:2.90e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.462, tt:6409.993\n",
      "Ep:186, loss:0.00000, loss_test:0.10557, lr:2.88e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.472, tt:6446.333\n",
      "Ep:187, loss:0.00000, loss_test:0.10309, lr:2.85e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.482, tt:6482.667\n",
      "Ep:188, loss:0.00000, loss_test:0.10373, lr:2.82e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.492, tt:6519.034\n",
      "Ep:189, loss:0.00000, loss_test:0.10517, lr:2.79e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.504, tt:6555.800\n",
      "Ep:190, loss:0.00000, loss_test:0.10353, lr:2.76e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.516, tt:6592.476\n",
      "Ep:191, loss:0.00000, loss_test:0.10356, lr:2.73e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.524, tt:6628.632\n",
      "Ep:192, loss:0.00000, loss_test:0.10461, lr:2.71e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.531, tt:6664.485\n",
      "Ep:193, loss:0.00000, loss_test:0.10300, lr:2.68e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.534, tt:6699.669\n",
      "Ep:194, loss:0.00000, loss_test:0.10424, lr:2.65e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.546, tt:6736.548\n",
      "Ep:195, loss:0.00000, loss_test:0.10471, lr:2.63e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.561, tt:6773.995\n",
      "Ep:196, loss:0.00000, loss_test:0.10417, lr:2.60e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.570, tt:6810.365\n",
      "Ep:197, loss:0.00000, loss_test:0.10337, lr:2.57e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.578, tt:6846.363\n",
      "Ep:198, loss:0.00000, loss_test:0.10339, lr:2.55e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.588, tt:6883.088\n",
      "Ep:199, loss:0.00000, loss_test:0.10321, lr:2.52e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.591, tt:6918.286\n",
      "Ep:200, loss:0.00000, loss_test:0.10230, lr:2.50e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.592, tt:6953.019\n",
      "Ep:201, loss:0.00000, loss_test:0.10340, lr:2.47e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.598, tt:6988.725\n",
      "Ep:202, loss:0.00000, loss_test:0.10379, lr:2.45e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.600, tt:7023.829\n",
      "Ep:203, loss:0.00000, loss_test:0.10275, lr:2.42e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.604, tt:7059.136\n",
      "Ep:204, loss:0.00000, loss_test:0.10341, lr:2.40e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.618, tt:7096.773\n",
      "Ep:205, loss:0.00000, loss_test:0.10250, lr:2.38e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.622, tt:7132.105\n",
      "Ep:206, loss:0.00000, loss_test:0.10236, lr:2.35e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.609, tt:7164.065\n",
      "Ep:207, loss:0.00000, loss_test:0.10380, lr:2.33e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.580, tt:7192.639\n",
      "Ep:208, loss:0.00000, loss_test:0.10356, lr:2.31e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.545, tt:7219.866\n",
      "Ep:209, loss:0.00000, loss_test:0.10227, lr:2.28e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.522, tt:7249.578\n",
      "Ep:210, loss:0.00000, loss_test:0.10278, lr:2.26e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.473, tt:7273.904\n",
      "Ep:211, loss:0.00000, loss_test:0.10317, lr:2.24e-03, fs:0.69231 (r=0.545,p=0.947),  time:34.435, tt:7300.237\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02583, lr:6.00e-02, fs:0.65778 (r=0.747,p=0.587),  time:35.215, tt:35.215\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02266, lr:6.00e-02, fs:0.69118 (r=0.949,p=0.543),  time:34.928, tt:69.856\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02515, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.937, tt:104.812\n",
      "Ep:3, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.097, tt:140.387\n",
      "Ep:4, loss:0.00005, loss_test:0.02506, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:35.047, tt:175.233\n",
      "Ep:5, loss:0.00005, loss_test:0.02388, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:35.100, tt:210.598\n",
      "Ep:6, loss:0.00005, loss_test:0.02305, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:35.079, tt:245.556\n",
      "Ep:7, loss:0.00005, loss_test:0.02285, lr:6.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:35.055, tt:280.443\n",
      "Ep:8, loss:0.00005, loss_test:0.02291, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:34.999, tt:314.989\n",
      "Ep:9, loss:0.00005, loss_test:0.02293, lr:6.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.924, tt:349.241\n",
      "Ep:10, loss:0.00005, loss_test:0.02291, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:34.935, tt:384.285\n",
      "Ep:11, loss:0.00005, loss_test:0.02293, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:34.927, tt:419.119\n",
      "Ep:12, loss:0.00005, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:34.906, tt:453.774\n",
      "Ep:13, loss:0.00005, loss_test:0.02254, lr:5.94e-02, fs:0.66667 (r=0.909,p=0.526),  time:34.896, tt:488.550\n",
      "Ep:14, loss:0.00005, loss_test:0.02211, lr:5.88e-02, fs:0.66914 (r=0.909,p=0.529),  time:34.823, tt:522.351\n",
      "Ep:15, loss:0.00005, loss_test:0.02159, lr:5.82e-02, fs:0.67925 (r=0.909,p=0.542),  time:34.747, tt:555.945\n",
      "Ep:16, loss:0.00005, loss_test:0.02113, lr:5.76e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.787, tt:591.373\n",
      "Ep:17, loss:0.00005, loss_test:0.02074, lr:5.71e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.811, tt:626.593\n",
      "Ep:18, loss:0.00004, loss_test:0.02044, lr:5.65e-02, fs:0.69498 (r=0.909,p=0.562),  time:34.720, tt:659.674\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.02023, lr:5.65e-02, fs:0.68726 (r=0.899,p=0.556),  time:34.640, tt:692.801\n",
      "Ep:20, loss:0.00004, loss_test:0.02009, lr:5.65e-02, fs:0.66667 (r=0.859,p=0.545),  time:34.648, tt:727.616\n",
      "Ep:21, loss:0.00004, loss_test:0.01997, lr:5.65e-02, fs:0.65339 (r=0.828,p=0.539),  time:34.602, tt:761.251\n",
      "Ep:22, loss:0.00004, loss_test:0.01983, lr:5.65e-02, fs:0.65600 (r=0.828,p=0.543),  time:34.582, tt:795.380\n",
      "Ep:23, loss:0.00004, loss_test:0.01967, lr:5.65e-02, fs:0.65863 (r=0.828,p=0.547),  time:34.547, tt:829.132\n",
      "Ep:24, loss:0.00004, loss_test:0.01942, lr:5.65e-02, fs:0.66939 (r=0.828,p=0.562),  time:34.543, tt:863.577\n",
      "Ep:25, loss:0.00004, loss_test:0.01911, lr:5.65e-02, fs:0.67769 (r=0.828,p=0.573),  time:34.549, tt:898.266\n",
      "Ep:26, loss:0.00004, loss_test:0.01878, lr:5.65e-02, fs:0.68050 (r=0.828,p=0.577),  time:34.490, tt:931.241\n",
      "Ep:27, loss:0.00004, loss_test:0.01848, lr:5.65e-02, fs:0.69167 (r=0.838,p=0.589),  time:34.448, tt:964.540\n",
      "Ep:28, loss:0.00004, loss_test:0.01817, lr:5.65e-02, fs:0.69710 (r=0.848,p=0.592),  time:34.505, tt:1000.644\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01783, lr:5.65e-02, fs:0.70248 (r=0.859,p=0.594),  time:34.477, tt:1034.302\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01752, lr:5.65e-02, fs:0.72269 (r=0.869,p=0.619),  time:34.479, tt:1068.861\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01726, lr:5.65e-02, fs:0.73109 (r=0.879,p=0.626),  time:34.471, tt:1103.081\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01697, lr:5.65e-02, fs:0.73950 (r=0.889,p=0.633),  time:34.434, tt:1136.324\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01669, lr:5.65e-02, fs:0.74477 (r=0.899,p=0.636),  time:34.425, tt:1170.442\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01640, lr:5.65e-02, fs:0.75833 (r=0.919,p=0.645),  time:34.414, tt:1204.503\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01608, lr:5.65e-02, fs:0.76151 (r=0.919,p=0.650),  time:34.417, tt:1238.999\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01567, lr:5.65e-02, fs:0.76151 (r=0.919,p=0.650),  time:34.405, tt:1272.968\n",
      "Ep:37, loss:0.00003, loss_test:0.01522, lr:5.65e-02, fs:0.77447 (r=0.919,p=0.669),  time:34.395, tt:1306.996\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01480, lr:5.65e-02, fs:0.77586 (r=0.909,p=0.677),  time:34.406, tt:1341.838\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01443, lr:5.65e-02, fs:0.78261 (r=0.909,p=0.687),  time:34.394, tt:1375.761\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01404, lr:5.65e-02, fs:0.79476 (r=0.919,p=0.700),  time:34.368, tt:1409.070\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01364, lr:5.65e-02, fs:0.79476 (r=0.919,p=0.700),  time:34.349, tt:1442.661\n",
      "Ep:42, loss:0.00002, loss_test:0.01330, lr:5.65e-02, fs:0.80000 (r=0.929,p=0.702),  time:34.334, tt:1476.349\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01310, lr:5.65e-02, fs:0.80702 (r=0.929,p=0.713),  time:34.335, tt:1510.729\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01282, lr:5.65e-02, fs:0.80531 (r=0.919,p=0.717),  time:34.346, tt:1545.570\n",
      "Ep:45, loss:0.00002, loss_test:0.01252, lr:5.65e-02, fs:0.82143 (r=0.929,p=0.736),  time:34.348, tt:1580.029\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01233, lr:5.65e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.354, tt:1614.625\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01221, lr:5.65e-02, fs:0.84545 (r=0.939,p=0.769),  time:34.350, tt:1648.807\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01212, lr:5.65e-02, fs:0.85714 (r=0.939,p=0.788),  time:34.391, tt:1685.178\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01178, lr:5.65e-02, fs:0.86111 (r=0.939,p=0.795),  time:34.397, tt:1719.857\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01180, lr:5.65e-02, fs:0.86385 (r=0.929,p=0.807),  time:34.420, tt:1755.404\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01178, lr:5.65e-02, fs:0.86385 (r=0.929,p=0.807),  time:34.447, tt:1791.233\n",
      "Ep:52, loss:0.00002, loss_test:0.01179, lr:5.65e-02, fs:0.86792 (r=0.929,p=0.814),  time:34.459, tt:1826.323\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01180, lr:5.65e-02, fs:0.87324 (r=0.939,p=0.816),  time:34.464, tt:1861.048\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01188, lr:5.65e-02, fs:0.86792 (r=0.929,p=0.814),  time:34.477, tt:1896.244\n",
      "Ep:55, loss:0.00001, loss_test:0.01179, lr:5.65e-02, fs:0.87204 (r=0.929,p=0.821),  time:34.489, tt:1931.364\n",
      "Ep:56, loss:0.00001, loss_test:0.01229, lr:5.65e-02, fs:0.87204 (r=0.929,p=0.821),  time:34.488, tt:1965.843\n",
      "Ep:57, loss:0.00001, loss_test:0.01227, lr:5.65e-02, fs:0.88038 (r=0.929,p=0.836),  time:34.495, tt:2000.709\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01256, lr:5.65e-02, fs:0.88462 (r=0.929,p=0.844),  time:34.513, tt:2036.295\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01307, lr:5.65e-02, fs:0.87805 (r=0.909,p=0.849),  time:34.518, tt:2071.087\n",
      "Ep:60, loss:0.00001, loss_test:0.01291, lr:5.65e-02, fs:0.88350 (r=0.919,p=0.850),  time:34.537, tt:2106.783\n",
      "Ep:61, loss:0.00001, loss_test:0.01385, lr:5.65e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.561, tt:2142.807\n",
      "Ep:62, loss:0.00001, loss_test:0.01338, lr:5.65e-02, fs:0.88350 (r=0.919,p=0.850),  time:34.561, tt:2177.350\n",
      "Ep:63, loss:0.00001, loss_test:0.01434, lr:5.65e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.565, tt:2212.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01426, lr:5.65e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.579, tt:2247.645\n",
      "Ep:65, loss:0.00001, loss_test:0.01529, lr:5.65e-02, fs:0.81865 (r=0.798,p=0.840),  time:34.584, tt:2282.537\n",
      "Ep:66, loss:0.00001, loss_test:0.01586, lr:5.65e-02, fs:0.80000 (r=0.768,p=0.835),  time:34.601, tt:2318.271\n",
      "Ep:67, loss:0.00001, loss_test:0.01531, lr:5.65e-02, fs:0.84848 (r=0.848,p=0.848),  time:34.608, tt:2353.327\n",
      "Ep:68, loss:0.00001, loss_test:0.01631, lr:5.65e-02, fs:0.78919 (r=0.737,p=0.849),  time:34.610, tt:2388.099\n",
      "Ep:69, loss:0.00001, loss_test:0.01678, lr:5.65e-02, fs:0.76757 (r=0.717,p=0.826),  time:34.608, tt:2422.527\n",
      "Ep:70, loss:0.00001, loss_test:0.01704, lr:5.59e-02, fs:0.75978 (r=0.687,p=0.850),  time:34.597, tt:2456.367\n",
      "Ep:71, loss:0.00001, loss_test:0.01792, lr:5.54e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.597, tt:2490.968\n",
      "Ep:72, loss:0.00001, loss_test:0.01822, lr:5.48e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.611, tt:2526.617\n",
      "Ep:73, loss:0.00001, loss_test:0.01891, lr:5.43e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.619, tt:2561.782\n",
      "Ep:74, loss:0.00001, loss_test:0.01818, lr:5.37e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.595, tt:2594.632\n",
      "Ep:75, loss:0.00001, loss_test:0.02012, lr:5.32e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.596, tt:2629.326\n",
      "Ep:76, loss:0.00001, loss_test:0.01941, lr:5.27e-02, fs:0.69048 (r=0.586,p=0.841),  time:34.600, tt:2664.234\n",
      "Ep:77, loss:0.00001, loss_test:0.01963, lr:5.21e-02, fs:0.70238 (r=0.596,p=0.855),  time:34.596, tt:2698.512\n",
      "Ep:78, loss:0.00001, loss_test:0.02146, lr:5.16e-02, fs:0.67470 (r=0.566,p=0.836),  time:34.588, tt:2732.469\n",
      "Ep:79, loss:0.00001, loss_test:0.01935, lr:5.11e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.590, tt:2767.192\n",
      "Ep:80, loss:0.00001, loss_test:0.02188, lr:5.06e-02, fs:0.68263 (r=0.576,p=0.838),  time:34.599, tt:2802.535\n",
      "Ep:81, loss:0.00001, loss_test:0.02059, lr:5.01e-02, fs:0.67879 (r=0.566,p=0.848),  time:34.568, tt:2834.611\n",
      "Ep:82, loss:0.00001, loss_test:0.02208, lr:4.96e-02, fs:0.68263 (r=0.576,p=0.838),  time:34.570, tt:2869.323\n",
      "Ep:83, loss:0.00001, loss_test:0.02147, lr:4.91e-02, fs:0.66258 (r=0.545,p=0.844),  time:34.568, tt:2903.703\n",
      "Ep:84, loss:0.00000, loss_test:0.02287, lr:4.86e-02, fs:0.64198 (r=0.525,p=0.825),  time:34.547, tt:2936.537\n",
      "Ep:85, loss:0.00000, loss_test:0.02227, lr:4.81e-02, fs:0.65854 (r=0.545,p=0.831),  time:34.546, tt:2970.947\n",
      "Ep:86, loss:0.00000, loss_test:0.02220, lr:4.76e-02, fs:0.64596 (r=0.525,p=0.839),  time:34.541, tt:3005.085\n",
      "Ep:87, loss:0.00000, loss_test:0.02441, lr:4.71e-02, fs:0.66667 (r=0.556,p=0.833),  time:34.546, tt:3040.054\n",
      "Ep:88, loss:0.00000, loss_test:0.02210, lr:4.67e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.530, tt:3073.170\n",
      "Ep:89, loss:0.00000, loss_test:0.02501, lr:4.62e-02, fs:0.65854 (r=0.545,p=0.831),  time:34.526, tt:3107.312\n",
      "Ep:90, loss:0.00000, loss_test:0.02323, lr:4.57e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.529, tt:3142.120\n",
      "Ep:91, loss:0.00000, loss_test:0.02443, lr:4.53e-02, fs:0.63354 (r=0.515,p=0.823),  time:34.517, tt:3175.596\n",
      "Ep:92, loss:0.00000, loss_test:0.02430, lr:4.48e-02, fs:0.65031 (r=0.535,p=0.828),  time:34.514, tt:3209.810\n",
      "Ep:93, loss:0.00000, loss_test:0.02409, lr:4.44e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.510, tt:3243.937\n",
      "Ep:94, loss:0.00000, loss_test:0.02577, lr:4.39e-02, fs:0.65432 (r=0.535,p=0.841),  time:34.530, tt:3280.338\n",
      "Ep:95, loss:0.00000, loss_test:0.02406, lr:4.35e-02, fs:0.64596 (r=0.525,p=0.839),  time:34.532, tt:3315.096\n",
      "Ep:96, loss:0.00000, loss_test:0.02656, lr:4.31e-02, fs:0.66258 (r=0.545,p=0.844),  time:34.534, tt:3349.836\n",
      "Ep:97, loss:0.00000, loss_test:0.02450, lr:4.26e-02, fs:0.63750 (r=0.515,p=0.836),  time:34.532, tt:3384.181\n",
      "Ep:98, loss:0.00000, loss_test:0.02720, lr:4.22e-02, fs:0.66258 (r=0.545,p=0.844),  time:34.539, tt:3419.366\n",
      "Ep:99, loss:0.00000, loss_test:0.02486, lr:4.18e-02, fs:0.63750 (r=0.515,p=0.836),  time:34.520, tt:3452.031\n",
      "Ep:100, loss:0.00000, loss_test:0.02742, lr:4.14e-02, fs:0.67073 (r=0.556,p=0.846),  time:34.508, tt:3485.260\n",
      "Ep:101, loss:0.00000, loss_test:0.02553, lr:4.10e-02, fs:0.62420 (r=0.495,p=0.845),  time:34.508, tt:3519.805\n",
      "Ep:102, loss:0.00000, loss_test:0.02771, lr:4.05e-02, fs:0.66258 (r=0.545,p=0.844),  time:34.514, tt:3554.967\n",
      "Ep:103, loss:0.00000, loss_test:0.02616, lr:4.01e-02, fs:0.63291 (r=0.505,p=0.847),  time:34.529, tt:3590.987\n",
      "Ep:104, loss:0.00000, loss_test:0.02848, lr:3.97e-02, fs:0.65839 (r=0.535,p=0.855),  time:34.534, tt:3626.050\n",
      "Ep:105, loss:0.00000, loss_test:0.02600, lr:3.93e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.558, tt:3663.182\n",
      "Ep:106, loss:0.00000, loss_test:0.02908, lr:3.89e-02, fs:0.65839 (r=0.535,p=0.855),  time:34.557, tt:3697.631\n",
      "Ep:107, loss:0.00000, loss_test:0.02646, lr:3.86e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.554, tt:3731.842\n",
      "Ep:108, loss:0.00000, loss_test:0.02934, lr:3.82e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.537, tt:3764.537\n",
      "Ep:109, loss:0.00000, loss_test:0.02703, lr:3.78e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.524, tt:3797.669\n",
      "Ep:110, loss:0.00000, loss_test:0.02968, lr:3.74e-02, fs:0.65000 (r=0.525,p=0.852),  time:34.523, tt:3832.015\n",
      "Ep:111, loss:0.00000, loss_test:0.02758, lr:3.70e-02, fs:0.62821 (r=0.495,p=0.860),  time:34.533, tt:3867.699\n",
      "Ep:112, loss:0.00000, loss_test:0.02984, lr:3.67e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.537, tt:3902.661\n",
      "Ep:113, loss:0.00000, loss_test:0.02860, lr:3.63e-02, fs:0.62821 (r=0.495,p=0.860),  time:34.528, tt:3936.185\n",
      "Ep:114, loss:0.00000, loss_test:0.03007, lr:3.59e-02, fs:0.62821 (r=0.495,p=0.860),  time:34.512, tt:3968.936\n",
      "Ep:115, loss:0.00000, loss_test:0.02926, lr:3.56e-02, fs:0.62821 (r=0.495,p=0.860),  time:34.511, tt:4003.291\n",
      "Ep:116, loss:0.00000, loss_test:0.03065, lr:3.52e-02, fs:0.63226 (r=0.495,p=0.875),  time:34.504, tt:4036.991\n",
      "Ep:117, loss:0.00000, loss_test:0.02934, lr:3.49e-02, fs:0.63226 (r=0.495,p=0.875),  time:34.497, tt:4070.656\n",
      "Ep:118, loss:0.00000, loss_test:0.03110, lr:3.45e-02, fs:0.63226 (r=0.495,p=0.875),  time:34.490, tt:4104.279\n",
      "Ep:119, loss:0.00000, loss_test:0.03016, lr:3.42e-02, fs:0.63226 (r=0.495,p=0.875),  time:34.494, tt:4139.251\n",
      "Ep:120, loss:0.00000, loss_test:0.03103, lr:3.38e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.484, tt:4172.563\n",
      "Ep:121, loss:0.00000, loss_test:0.03062, lr:3.35e-02, fs:0.63226 (r=0.495,p=0.875),  time:34.475, tt:4205.907\n",
      "Ep:122, loss:0.00000, loss_test:0.03182, lr:3.32e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.483, tt:4241.461\n",
      "Ep:123, loss:0.00000, loss_test:0.03129, lr:3.28e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.487, tt:4276.429\n",
      "Ep:124, loss:0.00000, loss_test:0.03193, lr:3.25e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.502, tt:4312.701\n",
      "Ep:125, loss:0.00000, loss_test:0.03191, lr:3.22e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.504, tt:4347.489\n",
      "Ep:126, loss:0.00000, loss_test:0.03211, lr:3.19e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.499, tt:4381.430\n",
      "Ep:127, loss:0.00000, loss_test:0.03219, lr:3.15e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.512, tt:4417.522\n",
      "Ep:128, loss:0.00000, loss_test:0.03279, lr:3.12e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.524, tt:4453.645\n",
      "Ep:129, loss:0.00000, loss_test:0.03283, lr:3.09e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.532, tt:4489.173\n",
      "Ep:130, loss:0.00000, loss_test:0.03236, lr:3.06e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.536, tt:4524.181\n",
      "Ep:131, loss:0.00000, loss_test:0.03330, lr:3.03e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.541, tt:4559.387\n",
      "Ep:132, loss:0.00000, loss_test:0.03318, lr:3.00e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.544, tt:4594.415\n",
      "Ep:133, loss:0.00000, loss_test:0.03337, lr:2.97e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.545, tt:4629.048\n",
      "Ep:134, loss:0.00000, loss_test:0.03325, lr:2.94e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.545, tt:4663.608\n",
      "Ep:135, loss:0.00000, loss_test:0.03396, lr:2.91e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.555, tt:4699.436\n",
      "Ep:136, loss:0.00000, loss_test:0.03363, lr:2.88e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.562, tt:4734.982\n",
      "Ep:137, loss:0.00000, loss_test:0.03407, lr:2.85e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.570, tt:4770.598\n",
      "Ep:138, loss:0.00000, loss_test:0.03408, lr:2.82e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.583, tt:4806.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.03438, lr:2.80e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.591, tt:4842.793\n",
      "Ep:140, loss:0.00000, loss_test:0.03458, lr:2.77e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.599, tt:4878.490\n",
      "Ep:141, loss:0.00000, loss_test:0.03414, lr:2.74e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.604, tt:4913.781\n",
      "Ep:142, loss:0.00000, loss_test:0.03496, lr:2.71e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.604, tt:4948.417\n",
      "Ep:143, loss:0.00000, loss_test:0.03478, lr:2.69e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.606, tt:4983.239\n",
      "Ep:144, loss:0.00000, loss_test:0.03496, lr:2.66e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.604, tt:5017.632\n",
      "Ep:145, loss:0.00000, loss_test:0.03479, lr:2.63e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.620, tt:5054.582\n",
      "Ep:146, loss:0.00000, loss_test:0.03546, lr:2.61e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.626, tt:5090.007\n",
      "Ep:147, loss:0.00000, loss_test:0.03528, lr:2.58e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.633, tt:5125.727\n",
      "Ep:148, loss:0.00000, loss_test:0.03518, lr:2.55e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.633, tt:5160.320\n",
      "Ep:149, loss:0.00000, loss_test:0.03586, lr:2.53e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.631, tt:5194.663\n",
      "Ep:150, loss:0.00000, loss_test:0.03560, lr:2.50e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.628, tt:5228.876\n",
      "Ep:151, loss:0.00000, loss_test:0.03577, lr:2.48e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.627, tt:5263.278\n",
      "Ep:152, loss:0.00000, loss_test:0.03593, lr:2.45e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.624, tt:5297.437\n",
      "Ep:153, loss:0.00000, loss_test:0.03617, lr:2.43e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.622, tt:5331.758\n",
      "Ep:154, loss:0.00000, loss_test:0.03572, lr:2.40e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.621, tt:5366.293\n",
      "Ep:155, loss:0.00000, loss_test:0.03628, lr:2.38e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.616, tt:5400.144\n",
      "Ep:156, loss:0.00000, loss_test:0.03620, lr:2.36e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.622, tt:5435.584\n",
      "Ep:157, loss:0.00000, loss_test:0.03660, lr:2.33e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.623, tt:5470.443\n",
      "Ep:158, loss:0.00000, loss_test:0.03604, lr:2.31e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.617, tt:5504.122\n",
      "Ep:159, loss:0.00000, loss_test:0.03697, lr:2.29e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.612, tt:5537.898\n",
      "Ep:160, loss:0.00000, loss_test:0.03653, lr:2.26e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.611, tt:5572.394\n",
      "Ep:161, loss:0.00000, loss_test:0.03637, lr:2.24e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.614, tt:5607.470\n",
      "Ep:162, loss:0.00000, loss_test:0.03717, lr:2.22e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.619, tt:5642.914\n",
      "Ep:163, loss:0.00000, loss_test:0.03640, lr:2.20e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.618, tt:5677.356\n",
      "Ep:164, loss:0.00000, loss_test:0.03707, lr:2.17e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.619, tt:5712.111\n",
      "Ep:165, loss:0.00000, loss_test:0.03692, lr:2.15e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.611, tt:5745.400\n",
      "Ep:166, loss:0.00000, loss_test:0.03688, lr:2.13e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.611, tt:5780.075\n",
      "Ep:167, loss:0.00000, loss_test:0.03768, lr:2.11e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.616, tt:5815.511\n",
      "Ep:168, loss:0.00000, loss_test:0.03659, lr:2.09e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.612, tt:5849.425\n",
      "Ep:169, loss:0.00000, loss_test:0.03753, lr:2.07e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.609, tt:5883.525\n",
      "Ep:170, loss:0.00000, loss_test:0.03766, lr:2.05e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.610, tt:5918.286\n",
      "Ep:171, loss:0.00000, loss_test:0.03710, lr:2.03e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.601, tt:5951.406\n",
      "Ep:172, loss:0.00000, loss_test:0.03779, lr:2.01e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.602, tt:5986.059\n",
      "Ep:173, loss:0.00000, loss_test:0.03751, lr:1.99e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.601, tt:6020.588\n",
      "Ep:174, loss:0.00000, loss_test:0.03751, lr:1.97e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.600, tt:6054.983\n",
      "Ep:175, loss:0.00000, loss_test:0.03790, lr:1.95e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.600, tt:6089.640\n",
      "Ep:176, loss:0.00000, loss_test:0.03776, lr:1.93e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.606, tt:6125.231\n",
      "Ep:177, loss:0.00000, loss_test:0.03782, lr:1.91e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.606, tt:6159.879\n",
      "Ep:178, loss:0.00000, loss_test:0.03790, lr:1.89e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.598, tt:6193.083\n",
      "Ep:179, loss:0.00000, loss_test:0.03810, lr:1.87e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.600, tt:6227.930\n",
      "Ep:180, loss:0.00000, loss_test:0.03800, lr:1.85e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.600, tt:6262.547\n",
      "Ep:181, loss:0.00000, loss_test:0.03812, lr:1.83e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.596, tt:6296.537\n",
      "Ep:182, loss:0.00000, loss_test:0.03823, lr:1.81e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.595, tt:6330.957\n",
      "Ep:183, loss:0.00000, loss_test:0.03819, lr:1.80e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.591, tt:6364.691\n",
      "Ep:184, loss:0.00000, loss_test:0.03820, lr:1.78e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.599, tt:6400.732\n",
      "Ep:185, loss:0.00000, loss_test:0.03837, lr:1.76e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.604, tt:6436.372\n",
      "Ep:186, loss:0.00000, loss_test:0.03836, lr:1.74e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.616, tt:6473.230\n",
      "Ep:187, loss:0.00000, loss_test:0.03846, lr:1.73e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.622, tt:6508.954\n",
      "Ep:188, loss:0.00000, loss_test:0.03840, lr:1.71e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.632, tt:6545.479\n",
      "Ep:189, loss:0.00000, loss_test:0.03839, lr:1.69e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.638, tt:6581.206\n",
      "Ep:190, loss:0.00000, loss_test:0.03866, lr:1.67e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.640, tt:6616.168\n",
      "Ep:191, loss:0.00000, loss_test:0.03854, lr:1.66e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.637, tt:6650.306\n",
      "Ep:192, loss:0.00000, loss_test:0.03841, lr:1.64e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.634, tt:6684.300\n",
      "Ep:193, loss:0.00000, loss_test:0.03866, lr:1.62e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.631, tt:6718.468\n",
      "Ep:194, loss:0.00000, loss_test:0.03874, lr:1.61e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.629, tt:6752.737\n",
      "Ep:195, loss:0.00000, loss_test:0.03861, lr:1.59e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.627, tt:6786.990\n",
      "Ep:196, loss:0.00000, loss_test:0.03866, lr:1.58e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.626, tt:6821.409\n",
      "Ep:197, loss:0.00000, loss_test:0.03876, lr:1.56e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.600, tt:6850.873\n",
      "Ep:198, loss:0.00000, loss_test:0.03888, lr:1.54e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.569, tt:6879.243\n",
      "Ep:199, loss:0.00000, loss_test:0.03867, lr:1.53e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.563, tt:6912.622\n",
      "Ep:200, loss:0.00000, loss_test:0.03891, lr:1.51e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.557, tt:6946.021\n",
      "Ep:201, loss:0.00000, loss_test:0.03896, lr:1.50e-02, fs:0.63636 (r=0.495,p=0.891),  time:34.526, tt:6974.298\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.12431, lr:1.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:34.780, tt:34.780\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.12184, lr:1.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:35.126, tt:70.252\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.11911, lr:1.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:35.187, tt:105.561\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.11738, lr:1.00e-02, fs:0.70769 (r=0.929,p=0.571),  time:35.653, tt:142.613\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.11715, lr:1.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:35.405, tt:177.026\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11767, lr:1.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:35.196, tt:211.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00026, loss_test:0.11786, lr:1.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:35.264, tt:246.850\n",
      "Ep:7, loss:0.00026, loss_test:0.11712, lr:1.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:35.268, tt:282.143\n",
      "Ep:8, loss:0.00026, loss_test:0.11592, lr:1.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:34.910, tt:314.194\n",
      "Ep:9, loss:0.00026, loss_test:0.11386, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:34.851, tt:348.515\n",
      "Ep:10, loss:0.00026, loss_test:0.11186, lr:1.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:34.764, tt:382.407\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.11075, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.717, tt:416.600\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.11034, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.637, tt:450.275\n",
      "Ep:13, loss:0.00025, loss_test:0.11012, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.682, tt:485.555\n",
      "Ep:14, loss:0.00025, loss_test:0.10978, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.638, tt:519.570\n",
      "Ep:15, loss:0.00025, loss_test:0.10900, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.677, tt:554.826\n",
      "Ep:16, loss:0.00025, loss_test:0.10772, lr:1.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:34.734, tt:590.478\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.10631, lr:1.00e-02, fs:0.73228 (r=0.939,p=0.600),  time:34.639, tt:623.503\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.10492, lr:1.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:34.618, tt:657.740\n",
      "Ep:19, loss:0.00024, loss_test:0.10354, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:34.592, tt:691.834\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.10195, lr:1.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:34.628, tt:727.182\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.10041, lr:1.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:34.664, tt:762.611\n",
      "Ep:22, loss:0.00023, loss_test:0.09872, lr:1.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:34.614, tt:796.113\n",
      "Ep:23, loss:0.00023, loss_test:0.09700, lr:1.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:34.590, tt:830.161\n",
      "Ep:24, loss:0.00022, loss_test:0.09480, lr:1.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:34.588, tt:864.691\n",
      "Ep:25, loss:0.00022, loss_test:0.09307, lr:1.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:34.571, tt:898.859\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00021, loss_test:0.09147, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.564, tt:933.218\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00021, loss_test:0.08871, lr:1.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:34.582, tt:968.302\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00020, loss_test:0.08787, lr:1.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:34.590, tt:1003.103\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.08747, lr:1.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:34.609, tt:1038.278\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00019, loss_test:0.08504, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:34.642, tt:1073.917\n",
      "Ep:31, loss:0.00018, loss_test:0.08389, lr:1.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:34.683, tt:1109.859\n",
      "Ep:32, loss:0.00018, loss_test:0.08198, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.670, tt:1144.094\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.07959, lr:1.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:34.658, tt:1178.370\n",
      "Ep:34, loss:0.00016, loss_test:0.07785, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:34.712, tt:1214.913\n",
      "Ep:35, loss:0.00016, loss_test:0.07641, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:34.747, tt:1250.885\n",
      "Ep:36, loss:0.00015, loss_test:0.07635, lr:1.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:34.755, tt:1285.948\n",
      "Ep:37, loss:0.00014, loss_test:0.07478, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.778, tt:1321.546\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00014, loss_test:0.07404, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.782, tt:1356.511\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.07315, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:34.813, tt:1392.505\n",
      "Ep:40, loss:0.00013, loss_test:0.07776, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:34.752, tt:1424.814\n",
      "Ep:41, loss:0.00012, loss_test:0.07259, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:34.740, tt:1459.063\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00012, loss_test:0.07138, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.734, tt:1493.559\n",
      "Ep:43, loss:0.00011, loss_test:0.07738, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:34.742, tt:1528.662\n",
      "Ep:44, loss:0.00011, loss_test:0.06844, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.686, tt:1560.867\n",
      "Ep:45, loss:0.00010, loss_test:0.07988, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:34.701, tt:1596.267\n",
      "Ep:46, loss:0.00010, loss_test:0.07069, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:34.661, tt:1629.049\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.07811, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:34.627, tt:1662.109\n",
      "Ep:48, loss:0.00009, loss_test:0.07057, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.612, tt:1695.981\n",
      "Ep:49, loss:0.00008, loss_test:0.07722, lr:1.00e-02, fs:0.73684 (r=0.707,p=0.769),  time:34.620, tt:1731.009\n",
      "Ep:50, loss:0.00008, loss_test:0.07684, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.607, tt:1764.980\n",
      "Ep:51, loss:0.00008, loss_test:0.07094, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.579, tt:1798.108\n",
      "Ep:52, loss:0.00007, loss_test:0.08080, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:34.559, tt:1831.607\n",
      "Ep:53, loss:0.00007, loss_test:0.07205, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.555, tt:1865.981\n",
      "Ep:54, loss:0.00006, loss_test:0.07632, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.549, tt:1900.192\n",
      "Ep:55, loss:0.00006, loss_test:0.07892, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.535, tt:1933.936\n",
      "Ep:56, loss:0.00006, loss_test:0.07202, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:34.526, tt:1967.968\n",
      "Ep:57, loss:0.00005, loss_test:0.07263, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.524, tt:2002.404\n",
      "Ep:58, loss:0.00005, loss_test:0.07945, lr:9.90e-03, fs:0.76243 (r=0.697,p=0.841),  time:34.520, tt:2036.709\n",
      "Ep:59, loss:0.00005, loss_test:0.06786, lr:9.80e-03, fs:0.82759 (r=0.848,p=0.808),  time:34.499, tt:2069.926\n",
      "Ep:60, loss:0.00005, loss_test:0.08265, lr:9.70e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.518, tt:2105.622\n",
      "Ep:61, loss:0.00005, loss_test:0.07226, lr:9.61e-03, fs:0.77174 (r=0.717,p=0.835),  time:34.554, tt:2142.378\n",
      "Ep:62, loss:0.00004, loss_test:0.07747, lr:9.51e-03, fs:0.75824 (r=0.697,p=0.831),  time:34.570, tt:2177.899\n",
      "Ep:63, loss:0.00004, loss_test:0.08328, lr:9.41e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.565, tt:2212.180\n",
      "Ep:64, loss:0.00004, loss_test:0.07528, lr:9.32e-03, fs:0.76243 (r=0.697,p=0.841),  time:34.603, tt:2249.199\n",
      "Ep:65, loss:0.00004, loss_test:0.08046, lr:9.23e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.597, tt:2283.435\n",
      "Ep:66, loss:0.00003, loss_test:0.08604, lr:9.14e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.587, tt:2317.349\n",
      "Ep:67, loss:0.00003, loss_test:0.07720, lr:9.04e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.587, tt:2351.914\n",
      "Ep:68, loss:0.00003, loss_test:0.08314, lr:8.95e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.590, tt:2386.712\n",
      "Ep:69, loss:0.00003, loss_test:0.07956, lr:8.86e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.595, tt:2421.641\n",
      "Ep:70, loss:0.00003, loss_test:0.08319, lr:8.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.591, tt:2455.969\n",
      "Ep:71, loss:0.00003, loss_test:0.07921, lr:8.69e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.590, tt:2490.473\n",
      "Ep:72, loss:0.00003, loss_test:0.08095, lr:8.60e-03, fs:0.76243 (r=0.697,p=0.841),  time:34.592, tt:2525.197\n",
      "Ep:73, loss:0.00003, loss_test:0.08340, lr:8.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.591, tt:2559.725\n",
      "Ep:74, loss:0.00003, loss_test:0.08649, lr:8.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.579, tt:2593.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00002, loss_test:0.07921, lr:8.35e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.584, tt:2628.347\n",
      "Ep:76, loss:0.00002, loss_test:0.08252, lr:8.26e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.609, tt:2664.911\n",
      "Ep:77, loss:0.00002, loss_test:0.07232, lr:8.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.600, tt:2698.830\n",
      "Ep:78, loss:0.00002, loss_test:0.08839, lr:8.10e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.587, tt:2732.366\n",
      "Ep:79, loss:0.00002, loss_test:0.07974, lr:8.02e-03, fs:0.76667 (r=0.697,p=0.852),  time:34.588, tt:2767.069\n",
      "Ep:80, loss:0.00002, loss_test:0.08256, lr:7.94e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.602, tt:2802.746\n",
      "Ep:81, loss:0.00002, loss_test:0.08870, lr:7.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.617, tt:2838.582\n",
      "Ep:82, loss:0.00002, loss_test:0.07681, lr:7.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.603, tt:2872.048\n",
      "Ep:83, loss:0.00002, loss_test:0.08536, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.594, tt:2905.877\n",
      "Ep:84, loss:0.00002, loss_test:0.08083, lr:7.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.604, tt:2941.332\n",
      "Ep:85, loss:0.00002, loss_test:0.08395, lr:7.55e-03, fs:0.77528 (r=0.697,p=0.873),  time:34.594, tt:2975.061\n",
      "Ep:86, loss:0.00002, loss_test:0.08133, lr:7.47e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.582, tt:3008.645\n",
      "Ep:87, loss:0.00002, loss_test:0.08050, lr:7.40e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.578, tt:3042.835\n",
      "Ep:88, loss:0.00002, loss_test:0.08733, lr:7.32e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.592, tt:3078.693\n",
      "Ep:89, loss:0.00002, loss_test:0.08134, lr:7.25e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.619, tt:3115.743\n",
      "Ep:90, loss:0.00002, loss_test:0.07947, lr:7.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.638, tt:3152.058\n",
      "Ep:91, loss:0.00002, loss_test:0.08661, lr:7.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.646, tt:3187.450\n",
      "Ep:92, loss:0.00001, loss_test:0.08203, lr:7.03e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.687, tt:3225.909\n",
      "Ep:93, loss:0.00001, loss_test:0.08444, lr:6.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.710, tt:3262.756\n",
      "Ep:94, loss:0.00001, loss_test:0.07908, lr:6.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.697, tt:3296.262\n",
      "Ep:95, loss:0.00001, loss_test:0.08647, lr:6.83e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.697, tt:3330.946\n",
      "Ep:96, loss:0.00001, loss_test:0.08236, lr:6.76e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.723, tt:3368.174\n",
      "Ep:97, loss:0.00001, loss_test:0.08274, lr:6.69e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.747, tt:3405.246\n",
      "Ep:98, loss:0.00001, loss_test:0.08031, lr:6.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.764, tt:3441.629\n",
      "Ep:99, loss:0.00001, loss_test:0.08332, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.788, tt:3478.759\n",
      "Ep:100, loss:0.00001, loss_test:0.08543, lr:6.49e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.800, tt:3514.775\n",
      "Ep:101, loss:0.00001, loss_test:0.07986, lr:6.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.834, tt:3553.096\n",
      "Ep:102, loss:0.00001, loss_test:0.08297, lr:6.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.873, tt:3591.911\n",
      "Ep:103, loss:0.00001, loss_test:0.07993, lr:6.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.890, tt:3628.610\n",
      "Ep:104, loss:0.00001, loss_test:0.08493, lr:6.24e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.911, tt:3665.663\n",
      "Ep:105, loss:0.00001, loss_test:0.08100, lr:6.17e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.895, tt:3698.839\n",
      "Ep:106, loss:0.00001, loss_test:0.08148, lr:6.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.884, tt:3732.632\n",
      "Ep:107, loss:0.00001, loss_test:0.08004, lr:6.05e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.884, tt:3767.439\n",
      "Ep:108, loss:0.00001, loss_test:0.08545, lr:5.99e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.880, tt:3801.900\n",
      "Ep:109, loss:0.00001, loss_test:0.07968, lr:5.93e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.870, tt:3835.693\n",
      "Ep:110, loss:0.00001, loss_test:0.08142, lr:5.87e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.859, tt:3869.392\n",
      "Ep:111, loss:0.00001, loss_test:0.08085, lr:5.81e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.848, tt:3903.024\n",
      "Ep:112, loss:0.00001, loss_test:0.08103, lr:5.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.842, tt:3937.189\n",
      "Ep:113, loss:0.00001, loss_test:0.08479, lr:5.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.823, tt:3969.833\n",
      "Ep:114, loss:0.00001, loss_test:0.08063, lr:5.64e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.818, tt:4004.115\n",
      "Ep:115, loss:0.00001, loss_test:0.08126, lr:5.58e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.826, tt:4039.870\n",
      "Ep:116, loss:0.00001, loss_test:0.08416, lr:5.53e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.828, tt:4074.931\n",
      "Ep:117, loss:0.00001, loss_test:0.07895, lr:5.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.829, tt:4109.861\n",
      "Ep:118, loss:0.00001, loss_test:0.08526, lr:5.42e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.828, tt:4144.541\n",
      "Ep:119, loss:0.00001, loss_test:0.08019, lr:5.36e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.825, tt:4179.036\n",
      "Ep:120, loss:0.00001, loss_test:0.07900, lr:5.31e-03, fs:0.77966 (r=0.697,p=0.885),  time:34.818, tt:4212.988\n",
      "Ep:121, loss:0.00001, loss_test:0.08942, lr:5.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.819, tt:4247.932\n",
      "Ep:122, loss:0.00001, loss_test:0.07226, lr:5.20e-03, fs:0.81564 (r=0.737,p=0.912),  time:34.820, tt:4282.826\n",
      "Ep:123, loss:0.00001, loss_test:0.08587, lr:5.15e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.820, tt:4317.734\n",
      "Ep:124, loss:0.00001, loss_test:0.08569, lr:5.10e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.831, tt:4353.880\n",
      "Ep:125, loss:0.00001, loss_test:0.07531, lr:5.05e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.830, tt:4388.569\n",
      "Ep:126, loss:0.00001, loss_test:0.08519, lr:5.00e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.824, tt:4422.656\n",
      "Ep:127, loss:0.00001, loss_test:0.08032, lr:4.95e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.818, tt:4456.724\n",
      "Ep:128, loss:0.00001, loss_test:0.07716, lr:4.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.810, tt:4490.528\n",
      "Ep:129, loss:0.00001, loss_test:0.08572, lr:4.85e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.814, tt:4525.880\n",
      "Ep:130, loss:0.00001, loss_test:0.08111, lr:4.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.817, tt:4560.980\n",
      "Ep:131, loss:0.00001, loss_test:0.07673, lr:4.75e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.815, tt:4595.547\n",
      "Ep:132, loss:0.00001, loss_test:0.08080, lr:4.71e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.805, tt:4629.015\n",
      "Ep:133, loss:0.00001, loss_test:0.08236, lr:4.66e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.798, tt:4662.961\n",
      "Ep:134, loss:0.00001, loss_test:0.07881, lr:4.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.795, tt:4697.369\n",
      "Ep:135, loss:0.00001, loss_test:0.08002, lr:4.57e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.797, tt:4732.349\n",
      "Ep:136, loss:0.00001, loss_test:0.08159, lr:4.52e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.789, tt:4766.124\n",
      "Ep:137, loss:0.00001, loss_test:0.07894, lr:4.48e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.786, tt:4800.487\n",
      "Ep:138, loss:0.00001, loss_test:0.08040, lr:4.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.772, tt:4833.367\n",
      "Ep:139, loss:0.00001, loss_test:0.08196, lr:4.39e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.776, tt:4868.605\n",
      "Ep:140, loss:0.00001, loss_test:0.07932, lr:4.34e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.780, tt:4903.919\n",
      "Ep:141, loss:0.00001, loss_test:0.08159, lr:4.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.779, tt:4938.610\n",
      "Ep:142, loss:0.00001, loss_test:0.08311, lr:4.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.786, tt:4974.358\n",
      "Ep:143, loss:0.00001, loss_test:0.07967, lr:4.21e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.787, tt:5009.354\n",
      "Ep:144, loss:0.00001, loss_test:0.07980, lr:4.17e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.795, tt:5045.206\n",
      "Ep:145, loss:0.00001, loss_test:0.08124, lr:4.13e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.798, tt:5080.544\n",
      "Ep:146, loss:0.00001, loss_test:0.07985, lr:4.09e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.812, tt:5117.360\n",
      "Ep:147, loss:0.00001, loss_test:0.08129, lr:4.05e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.811, tt:5152.009\n",
      "Ep:150, loss:0.00001, loss_test:0.08110, lr:3.93e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.825, tt:5258.538\n",
      "Ep:151, loss:0.00001, loss_test:0.08067, lr:3.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.832, tt:5294.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00001, loss_test:0.08022, lr:3.85e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.837, tt:5330.047\n",
      "Ep:153, loss:0.00001, loss_test:0.08038, lr:3.81e-03, fs:0.78409 (r=0.697,p=0.896),  time:34.845, tt:5366.097\n",
      "Ep:154, loss:0.00001, loss_test:0.08155, lr:3.77e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.859, tt:5403.115\n",
      "Ep:155, loss:0.00001, loss_test:0.08108, lr:3.73e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.891, tt:5442.944\n",
      "Ep:156, loss:0.00001, loss_test:0.07986, lr:3.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.894, tt:5478.351\n",
      "Ep:157, loss:0.00001, loss_test:0.08073, lr:3.66e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.901, tt:5514.363\n",
      "Ep:158, loss:0.00001, loss_test:0.08085, lr:3.62e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.897, tt:5548.619\n",
      "Ep:159, loss:0.00001, loss_test:0.08070, lr:3.59e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.900, tt:5584.002\n",
      "Ep:160, loss:0.00001, loss_test:0.08081, lr:3.55e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.903, tt:5619.310\n",
      "Ep:161, loss:0.00001, loss_test:0.08077, lr:3.52e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.908, tt:5655.168\n",
      "Ep:162, loss:0.00001, loss_test:0.08128, lr:3.48e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.910, tt:5690.373\n",
      "Ep:163, loss:0.00001, loss_test:0.08163, lr:3.45e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.916, tt:5726.196\n",
      "Ep:164, loss:0.00001, loss_test:0.08100, lr:3.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.916, tt:5761.176\n",
      "Ep:165, loss:0.00001, loss_test:0.08081, lr:3.38e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.917, tt:5796.227\n",
      "Ep:166, loss:0.00001, loss_test:0.08126, lr:3.34e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.920, tt:5831.657\n",
      "Ep:167, loss:0.00001, loss_test:0.08113, lr:3.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.932, tt:5868.512\n",
      "Ep:168, loss:0.00001, loss_test:0.08077, lr:3.28e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.939, tt:5904.667\n",
      "Ep:169, loss:0.00001, loss_test:0.08188, lr:3.24e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.941, tt:5940.019\n",
      "Ep:170, loss:0.00001, loss_test:0.08093, lr:3.21e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.948, tt:5976.054\n",
      "Ep:171, loss:0.00001, loss_test:0.08091, lr:3.18e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.954, tt:6012.122\n",
      "Ep:172, loss:0.00001, loss_test:0.08175, lr:3.15e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.956, tt:6047.338\n",
      "Ep:173, loss:0.00001, loss_test:0.08150, lr:3.12e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.955, tt:6082.249\n",
      "Ep:174, loss:0.00001, loss_test:0.08139, lr:3.09e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.958, tt:6117.628\n",
      "Ep:175, loss:0.00001, loss_test:0.08182, lr:3.05e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6152.937\n",
      "Ep:176, loss:0.00001, loss_test:0.08107, lr:3.02e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.962, tt:6188.249\n",
      "Ep:177, loss:0.00001, loss_test:0.08168, lr:2.99e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.961, tt:6223.124\n",
      "Ep:178, loss:0.00001, loss_test:0.08150, lr:2.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.959, tt:6257.680\n",
      "Ep:179, loss:0.00001, loss_test:0.08123, lr:2.93e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.967, tt:6294.035\n",
      "Ep:180, loss:0.00001, loss_test:0.08153, lr:2.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.965, tt:6328.753\n",
      "Ep:181, loss:0.00001, loss_test:0.08157, lr:2.88e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.968, tt:6364.265\n",
      "Ep:182, loss:0.00001, loss_test:0.08099, lr:2.85e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.970, tt:6399.483\n",
      "Ep:183, loss:0.00001, loss_test:0.08181, lr:2.82e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.962, tt:6432.979\n",
      "Ep:184, loss:0.00001, loss_test:0.08228, lr:2.79e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.961, tt:6467.760\n",
      "Ep:185, loss:0.00001, loss_test:0.08228, lr:2.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.961, tt:6502.772\n",
      "Ep:186, loss:0.00001, loss_test:0.08106, lr:2.73e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.954, tt:6536.382\n",
      "Ep:187, loss:0.00001, loss_test:0.08125, lr:2.71e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6572.391\n",
      "Ep:188, loss:0.00001, loss_test:0.08204, lr:2.68e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.963, tt:6607.962\n",
      "Ep:189, loss:0.00001, loss_test:0.08108, lr:2.65e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.959, tt:6642.275\n",
      "Ep:190, loss:0.00001, loss_test:0.08121, lr:2.63e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6677.346\n",
      "Ep:191, loss:0.00001, loss_test:0.08196, lr:2.60e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6712.384\n",
      "Ep:192, loss:0.00001, loss_test:0.08149, lr:2.57e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6747.264\n",
      "Ep:193, loss:0.00001, loss_test:0.08122, lr:2.55e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.959, tt:6781.999\n",
      "Ep:194, loss:0.00001, loss_test:0.08181, lr:2.52e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.960, tt:6817.155\n",
      "Ep:195, loss:0.00001, loss_test:0.08153, lr:2.50e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.952, tt:6850.603\n",
      "Ep:196, loss:0.00001, loss_test:0.08178, lr:2.47e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.946, tt:6884.391\n",
      "Ep:197, loss:0.00001, loss_test:0.08106, lr:2.45e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.928, tt:6915.814\n",
      "Ep:198, loss:0.00001, loss_test:0.08219, lr:2.42e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.888, tt:6942.721\n",
      "Ep:199, loss:0.00001, loss_test:0.08336, lr:2.40e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.856, tt:6971.197\n",
      "Ep:200, loss:0.00001, loss_test:0.08319, lr:2.38e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.825, tt:6999.776\n",
      "Ep:201, loss:0.00001, loss_test:0.08139, lr:2.35e-03, fs:0.78857 (r=0.697,p=0.908),  time:34.795, tt:7028.613\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02570, lr:6.00e-02, fs:0.63927 (r=0.707,p=0.583),  time:30.784, tt:30.784\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02311, lr:6.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:30.843, tt:61.686\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02589, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.563, tt:91.690\n",
      "Ep:3, loss:0.00005, loss_test:0.02504, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:30.817, tt:123.267\n",
      "Ep:4, loss:0.00005, loss_test:0.02435, lr:6.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:30.873, tt:154.363\n",
      "Ep:5, loss:0.00005, loss_test:0.02411, lr:6.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:30.753, tt:184.519\n",
      "Ep:6, loss:0.00005, loss_test:0.02370, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:30.739, tt:215.171\n",
      "Ep:7, loss:0.00005, loss_test:0.02333, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:30.562, tt:244.499\n",
      "Ep:8, loss:0.00005, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:30.574, tt:275.163\n",
      "Ep:9, loss:0.00005, loss_test:0.02262, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:30.555, tt:305.551\n",
      "Ep:10, loss:0.00005, loss_test:0.02223, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:30.612, tt:336.734\n",
      "Ep:11, loss:0.00005, loss_test:0.02184, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:30.543, tt:366.512\n",
      "Ep:12, loss:0.00005, loss_test:0.02137, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:30.499, tt:396.489\n",
      "Ep:13, loss:0.00005, loss_test:0.02085, lr:5.94e-02, fs:0.66914 (r=0.909,p=0.529),  time:30.420, tt:425.883\n",
      "Ep:14, loss:0.00005, loss_test:0.02034, lr:5.88e-02, fs:0.68702 (r=0.909,p=0.552),  time:30.377, tt:455.653\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01998, lr:5.88e-02, fs:0.66667 (r=0.848,p=0.549),  time:30.280, tt:484.477\n",
      "Ep:16, loss:0.00004, loss_test:0.01976, lr:5.88e-02, fs:0.67490 (r=0.828,p=0.569),  time:30.291, tt:514.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00004, loss_test:0.01959, lr:5.88e-02, fs:0.68050 (r=0.828,p=0.577),  time:30.262, tt:544.720\n",
      "Ep:18, loss:0.00004, loss_test:0.01943, lr:5.88e-02, fs:0.67769 (r=0.828,p=0.573),  time:30.261, tt:574.960\n",
      "Ep:19, loss:0.00004, loss_test:0.01930, lr:5.88e-02, fs:0.67490 (r=0.828,p=0.569),  time:30.246, tt:604.920\n",
      "Ep:20, loss:0.00004, loss_test:0.01924, lr:5.88e-02, fs:0.66400 (r=0.838,p=0.550),  time:30.251, tt:635.273\n",
      "Ep:21, loss:0.00004, loss_test:0.01915, lr:5.88e-02, fs:0.66932 (r=0.848,p=0.553),  time:30.190, tt:664.180\n",
      "Ep:22, loss:0.00004, loss_test:0.01903, lr:5.88e-02, fs:0.67200 (r=0.848,p=0.556),  time:30.165, tt:693.787\n",
      "Ep:23, loss:0.00004, loss_test:0.01889, lr:5.88e-02, fs:0.67460 (r=0.859,p=0.556),  time:30.154, tt:723.706\n",
      "Ep:24, loss:0.00004, loss_test:0.01875, lr:5.88e-02, fs:0.67742 (r=0.848,p=0.564),  time:30.140, tt:753.500\n",
      "Ep:25, loss:0.00004, loss_test:0.01864, lr:5.88e-02, fs:0.68033 (r=0.838,p=0.572),  time:30.121, tt:783.148\n",
      "Ep:26, loss:0.00004, loss_test:0.01851, lr:5.82e-02, fs:0.68595 (r=0.838,p=0.580),  time:30.125, tt:813.388\n",
      "Ep:27, loss:0.00004, loss_test:0.01839, lr:5.76e-02, fs:0.68313 (r=0.838,p=0.576),  time:30.155, tt:844.335\n",
      "Ep:28, loss:0.00004, loss_test:0.01828, lr:5.71e-02, fs:0.68313 (r=0.838,p=0.576),  time:30.150, tt:874.338\n",
      "Ep:29, loss:0.00004, loss_test:0.01814, lr:5.65e-02, fs:0.68033 (r=0.838,p=0.572),  time:30.183, tt:905.484\n",
      "Ep:30, loss:0.00004, loss_test:0.01801, lr:5.59e-02, fs:0.69167 (r=0.838,p=0.589),  time:30.145, tt:934.493\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00004, loss_test:0.01788, lr:5.59e-02, fs:0.69167 (r=0.838,p=0.589),  time:30.191, tt:966.109\n",
      "Ep:32, loss:0.00004, loss_test:0.01774, lr:5.59e-02, fs:0.68619 (r=0.828,p=0.586),  time:30.183, tt:996.033\n",
      "Ep:33, loss:0.00004, loss_test:0.01759, lr:5.59e-02, fs:0.68880 (r=0.838,p=0.585),  time:30.173, tt:1025.873\n",
      "Ep:34, loss:0.00004, loss_test:0.01744, lr:5.59e-02, fs:0.69959 (r=0.859,p=0.590),  time:30.165, tt:1055.772\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00004, loss_test:0.01727, lr:5.59e-02, fs:0.70782 (r=0.869,p=0.597),  time:30.188, tt:1086.752\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00004, loss_test:0.01710, lr:5.59e-02, fs:0.71311 (r=0.879,p=0.600),  time:30.207, tt:1117.645\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01695, lr:5.59e-02, fs:0.71901 (r=0.879,p=0.608),  time:30.178, tt:1146.778\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01683, lr:5.59e-02, fs:0.72500 (r=0.879,p=0.617),  time:30.212, tt:1178.287\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01673, lr:5.59e-02, fs:0.72803 (r=0.879,p=0.621),  time:30.201, tt:1208.029\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01660, lr:5.59e-02, fs:0.72428 (r=0.889,p=0.611),  time:30.200, tt:1238.209\n",
      "Ep:41, loss:0.00003, loss_test:0.01650, lr:5.59e-02, fs:0.73029 (r=0.889,p=0.620),  time:30.214, tt:1268.987\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01638, lr:5.59e-02, fs:0.73029 (r=0.889,p=0.620),  time:30.200, tt:1298.585\n",
      "Ep:43, loss:0.00003, loss_test:0.01626, lr:5.59e-02, fs:0.73029 (r=0.889,p=0.620),  time:30.196, tt:1328.634\n",
      "Ep:44, loss:0.00003, loss_test:0.01618, lr:5.59e-02, fs:0.73640 (r=0.889,p=0.629),  time:30.194, tt:1358.722\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01613, lr:5.59e-02, fs:0.74894 (r=0.889,p=0.647),  time:30.174, tt:1388.025\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01606, lr:5.59e-02, fs:0.73820 (r=0.869,p=0.642),  time:30.164, tt:1417.721\n",
      "Ep:47, loss:0.00003, loss_test:0.01600, lr:5.59e-02, fs:0.74678 (r=0.879,p=0.649),  time:30.184, tt:1448.846\n",
      "Ep:48, loss:0.00003, loss_test:0.01597, lr:5.59e-02, fs:0.74359 (r=0.879,p=0.644),  time:30.175, tt:1478.575\n",
      "Ep:49, loss:0.00003, loss_test:0.01605, lr:5.59e-02, fs:0.73593 (r=0.859,p=0.644),  time:30.168, tt:1508.388\n",
      "Ep:50, loss:0.00003, loss_test:0.01614, lr:5.59e-02, fs:0.72000 (r=0.818,p=0.643),  time:30.161, tt:1538.226\n",
      "Ep:51, loss:0.00003, loss_test:0.01605, lr:5.59e-02, fs:0.71818 (r=0.798,p=0.653),  time:30.131, tt:1566.803\n",
      "Ep:52, loss:0.00002, loss_test:0.01579, lr:5.59e-02, fs:0.72889 (r=0.828,p=0.651),  time:30.117, tt:1596.177\n",
      "Ep:53, loss:0.00002, loss_test:0.01595, lr:5.59e-02, fs:0.71233 (r=0.788,p=0.650),  time:30.106, tt:1625.700\n",
      "Ep:54, loss:0.00002, loss_test:0.01654, lr:5.59e-02, fs:0.72222 (r=0.788,p=0.667),  time:30.123, tt:1656.741\n",
      "Ep:55, loss:0.00002, loss_test:0.01595, lr:5.59e-02, fs:0.72727 (r=0.808,p=0.661),  time:30.094, tt:1685.260\n",
      "Ep:56, loss:0.00002, loss_test:0.01615, lr:5.59e-02, fs:0.73832 (r=0.798,p=0.687),  time:30.075, tt:1714.289\n",
      "Ep:57, loss:0.00002, loss_test:0.01628, lr:5.54e-02, fs:0.74178 (r=0.798,p=0.693),  time:30.085, tt:1744.951\n",
      "Ep:58, loss:0.00002, loss_test:0.01596, lr:5.48e-02, fs:0.75229 (r=0.828,p=0.689),  time:30.066, tt:1773.906\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01627, lr:5.48e-02, fs:0.77143 (r=0.818,p=0.730),  time:30.067, tt:1804.026\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01645, lr:5.48e-02, fs:0.77512 (r=0.818,p=0.736),  time:30.060, tt:1833.688\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01621, lr:5.48e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.057, tt:1863.554\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01609, lr:5.48e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.051, tt:1893.199\n",
      "Ep:63, loss:0.00002, loss_test:0.01665, lr:5.48e-02, fs:0.79024 (r=0.818,p=0.764),  time:30.046, tt:1922.926\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.01652, lr:5.48e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.056, tt:1953.668\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01693, lr:5.48e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.059, tt:1983.901\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01700, lr:5.48e-02, fs:0.79024 (r=0.818,p=0.764),  time:30.096, tt:2016.423\n",
      "Ep:67, loss:0.00001, loss_test:0.01719, lr:5.48e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.095, tt:2046.487\n",
      "Ep:68, loss:0.00001, loss_test:0.01751, lr:5.48e-02, fs:0.79803 (r=0.818,p=0.779),  time:30.101, tt:2076.955\n",
      "Ep:69, loss:0.00001, loss_test:0.01820, lr:5.48e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.083, tt:2105.787\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01897, lr:5.48e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.092, tt:2136.565\n",
      "Ep:71, loss:0.00001, loss_test:0.01914, lr:5.48e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.087, tt:2166.275\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01949, lr:5.48e-02, fs:0.81218 (r=0.808,p=0.816),  time:30.085, tt:2196.184\n",
      "Ep:73, loss:0.00001, loss_test:0.02011, lr:5.48e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.079, tt:2225.824\n",
      "Ep:74, loss:0.00001, loss_test:0.02147, lr:5.48e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.070, tt:2255.272\n",
      "Ep:75, loss:0.00001, loss_test:0.01970, lr:5.48e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.069, tt:2285.260\n",
      "Ep:76, loss:0.00001, loss_test:0.02166, lr:5.48e-02, fs:0.81026 (r=0.798,p=0.823),  time:30.062, tt:2314.740\n",
      "Ep:77, loss:0.00001, loss_test:0.02182, lr:5.48e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.069, tt:2345.389\n",
      "Ep:78, loss:0.00001, loss_test:0.02286, lr:5.48e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.083, tt:2376.553\n",
      "Ep:79, loss:0.00001, loss_test:0.02461, lr:5.48e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.093, tt:2407.474\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.02371, lr:5.48e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.139, tt:2441.296\n",
      "Ep:81, loss:0.00001, loss_test:0.02448, lr:5.48e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.145, tt:2471.927\n",
      "Ep:82, loss:0.00001, loss_test:0.02687, lr:5.48e-02, fs:0.81481 (r=0.778,p=0.856),  time:30.156, tt:2502.939\n",
      "Ep:83, loss:0.00001, loss_test:0.02567, lr:5.48e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.152, tt:2532.759\n",
      "Ep:84, loss:0.00001, loss_test:0.01790, lr:5.48e-02, fs:0.76142 (r=0.758,p=0.765),  time:30.159, tt:2563.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:85, loss:0.00001, loss_test:0.02658, lr:5.48e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.163, tt:2593.990\n",
      "Ep:86, loss:0.00001, loss_test:0.02676, lr:5.48e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.169, tt:2624.708\n",
      "Ep:87, loss:0.00001, loss_test:0.02286, lr:5.48e-02, fs:0.76757 (r=0.717,p=0.826),  time:30.181, tt:2655.933\n",
      "Ep:88, loss:0.00001, loss_test:0.02503, lr:5.48e-02, fs:0.77174 (r=0.717,p=0.835),  time:30.187, tt:2686.605\n",
      "Ep:89, loss:0.00001, loss_test:0.02884, lr:5.48e-02, fs:0.79558 (r=0.727,p=0.878),  time:30.183, tt:2716.505\n",
      "Ep:90, loss:0.00001, loss_test:0.02804, lr:5.48e-02, fs:0.80435 (r=0.747,p=0.871),  time:30.184, tt:2746.713\n",
      "Ep:91, loss:0.00001, loss_test:0.02616, lr:5.43e-02, fs:0.78212 (r=0.707,p=0.875),  time:30.201, tt:2778.464\n",
      "Ep:92, loss:0.00001, loss_test:0.02366, lr:5.37e-02, fs:0.74725 (r=0.687,p=0.819),  time:30.194, tt:2808.006\n",
      "Ep:93, loss:0.00001, loss_test:0.03019, lr:5.32e-02, fs:0.80645 (r=0.758,p=0.862),  time:30.191, tt:2837.966\n",
      "Ep:94, loss:0.00001, loss_test:0.02876, lr:5.27e-02, fs:0.78652 (r=0.707,p=0.886),  time:30.184, tt:2867.520\n",
      "Ep:95, loss:0.00001, loss_test:0.02719, lr:5.21e-02, fs:0.77095 (r=0.697,p=0.863),  time:30.178, tt:2897.094\n",
      "Ep:96, loss:0.00001, loss_test:0.02474, lr:5.16e-02, fs:0.75978 (r=0.687,p=0.850),  time:30.169, tt:2926.400\n",
      "Ep:97, loss:0.00001, loss_test:0.02655, lr:5.11e-02, fs:0.77966 (r=0.697,p=0.885),  time:30.174, tt:2957.085\n",
      "Ep:98, loss:0.00001, loss_test:0.02913, lr:5.06e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.191, tt:2988.936\n",
      "Ep:99, loss:0.00001, loss_test:0.02639, lr:5.01e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.193, tt:3019.252\n",
      "Ep:100, loss:0.00001, loss_test:0.02487, lr:4.96e-02, fs:0.76836 (r=0.687,p=0.872),  time:30.201, tt:3050.335\n",
      "Ep:101, loss:0.00001, loss_test:0.02815, lr:4.91e-02, fs:0.78857 (r=0.697,p=0.908),  time:30.220, tt:3082.466\n",
      "Ep:102, loss:0.00001, loss_test:0.03072, lr:4.86e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.216, tt:3112.273\n",
      "Ep:103, loss:0.00000, loss_test:0.02771, lr:4.81e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.230, tt:3143.970\n",
      "Ep:104, loss:0.00001, loss_test:0.02465, lr:4.76e-02, fs:0.76404 (r=0.687,p=0.861),  time:30.245, tt:3175.711\n",
      "Ep:105, loss:0.00000, loss_test:0.03352, lr:4.71e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.252, tt:3206.708\n",
      "Ep:106, loss:0.00000, loss_test:0.02620, lr:4.67e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.262, tt:3238.073\n",
      "Ep:107, loss:0.00001, loss_test:0.02701, lr:4.62e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.269, tt:3269.033\n",
      "Ep:108, loss:0.00000, loss_test:0.03096, lr:4.57e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.270, tt:3299.474\n",
      "Ep:109, loss:0.00000, loss_test:0.03040, lr:4.53e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.256, tt:3328.204\n",
      "Ep:110, loss:0.00000, loss_test:0.02754, lr:4.48e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.277, tt:3360.768\n",
      "Ep:111, loss:0.00000, loss_test:0.03351, lr:4.44e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.288, tt:3392.281\n",
      "Ep:112, loss:0.00001, loss_test:0.03078, lr:4.39e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.302, tt:3424.094\n",
      "Ep:113, loss:0.00000, loss_test:0.02698, lr:4.35e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.314, tt:3455.795\n",
      "Ep:114, loss:0.00000, loss_test:0.03539, lr:4.31e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.317, tt:3486.505\n",
      "Ep:115, loss:0.00000, loss_test:0.02644, lr:4.26e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.328, tt:3517.999\n",
      "Ep:116, loss:0.00000, loss_test:0.03152, lr:4.22e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.329, tt:3548.509\n",
      "Ep:117, loss:0.00000, loss_test:0.02871, lr:4.18e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.328, tt:3578.758\n",
      "Ep:118, loss:0.00000, loss_test:0.03066, lr:4.14e-02, fs:0.75862 (r=0.667,p=0.880),  time:30.334, tt:3609.761\n",
      "Ep:119, loss:0.00000, loss_test:0.03239, lr:4.10e-02, fs:0.79290 (r=0.677,p=0.957),  time:30.325, tt:3638.982\n",
      "Ep:120, loss:0.00000, loss_test:0.02992, lr:4.05e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.329, tt:3669.855\n",
      "Ep:121, loss:0.00000, loss_test:0.03255, lr:4.01e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.337, tt:3701.083\n",
      "Ep:122, loss:0.00000, loss_test:0.03209, lr:3.97e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.345, tt:3732.495\n",
      "Ep:123, loss:0.00000, loss_test:0.02984, lr:3.93e-02, fs:0.78161 (r=0.687,p=0.907),  time:30.339, tt:3762.035\n",
      "Ep:124, loss:0.00000, loss_test:0.03345, lr:3.89e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.334, tt:3791.709\n",
      "Ep:125, loss:0.00000, loss_test:0.03270, lr:3.86e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.328, tt:3821.378\n",
      "Ep:126, loss:0.00000, loss_test:0.03241, lr:3.82e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.332, tt:3852.175\n",
      "Ep:127, loss:0.00000, loss_test:0.03377, lr:3.78e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.344, tt:3883.971\n",
      "Ep:128, loss:0.00000, loss_test:0.03353, lr:3.74e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.345, tt:3914.504\n",
      "Ep:129, loss:0.00000, loss_test:0.03337, lr:3.70e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.342, tt:3944.509\n",
      "Ep:130, loss:0.00000, loss_test:0.03625, lr:3.67e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.336, tt:3973.952\n",
      "Ep:131, loss:0.00000, loss_test:0.03174, lr:3.63e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.332, tt:4003.802\n",
      "Ep:132, loss:0.00000, loss_test:0.03657, lr:3.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.329, tt:4033.747\n",
      "Ep:133, loss:0.00000, loss_test:0.03306, lr:3.56e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.326, tt:4063.728\n",
      "Ep:134, loss:0.00000, loss_test:0.03569, lr:3.52e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.324, tt:4093.751\n",
      "Ep:135, loss:0.00000, loss_test:0.03520, lr:3.49e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.321, tt:4123.645\n",
      "Ep:136, loss:0.00000, loss_test:0.03516, lr:3.45e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.321, tt:4153.918\n",
      "Ep:137, loss:0.00000, loss_test:0.03375, lr:3.42e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.313, tt:4183.161\n",
      "Ep:138, loss:0.00000, loss_test:0.03689, lr:3.38e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.306, tt:4212.597\n",
      "Ep:139, loss:0.00000, loss_test:0.03418, lr:3.35e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.303, tt:4242.469\n",
      "Ep:140, loss:0.00000, loss_test:0.03564, lr:3.32e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.311, tt:4273.806\n",
      "Ep:141, loss:0.00000, loss_test:0.03645, lr:3.28e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.311, tt:4304.195\n",
      "Ep:142, loss:0.00000, loss_test:0.03508, lr:3.25e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.314, tt:4334.838\n",
      "Ep:143, loss:0.00000, loss_test:0.03718, lr:3.22e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.338, tt:4368.699\n",
      "Ep:144, loss:0.00000, loss_test:0.03581, lr:3.19e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.340, tt:4399.371\n",
      "Ep:145, loss:0.00000, loss_test:0.03825, lr:3.15e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.348, tt:4430.788\n",
      "Ep:146, loss:0.00000, loss_test:0.03567, lr:3.12e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.368, tt:4464.100\n",
      "Ep:147, loss:0.00000, loss_test:0.03714, lr:3.09e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.361, tt:4493.412\n",
      "Ep:148, loss:0.00000, loss_test:0.03794, lr:3.06e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.367, tt:4524.686\n",
      "Ep:149, loss:0.00000, loss_test:0.03670, lr:3.03e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.369, tt:4555.356\n",
      "Ep:150, loss:0.00000, loss_test:0.03833, lr:3.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.371, tt:4585.977\n",
      "Ep:151, loss:0.00000, loss_test:0.03702, lr:2.97e-02, fs:0.78613 (r=0.687,p=0.919),  time:30.367, tt:4615.749\n",
      "Ep:152, loss:0.00000, loss_test:0.03794, lr:2.94e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.362, tt:4645.395\n",
      "Ep:153, loss:0.00000, loss_test:0.03795, lr:2.91e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.363, tt:4675.923\n",
      "Ep:154, loss:0.00000, loss_test:0.03782, lr:2.88e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.368, tt:4707.012\n",
      "Ep:155, loss:0.00000, loss_test:0.03854, lr:2.85e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.370, tt:4737.664\n",
      "Ep:156, loss:0.00000, loss_test:0.03771, lr:2.82e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.376, tt:4768.964\n",
      "Ep:157, loss:0.00000, loss_test:0.03872, lr:2.80e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.371, tt:4798.675\n",
      "Ep:158, loss:0.00000, loss_test:0.03937, lr:2.77e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.367, tt:4828.361\n",
      "Ep:159, loss:0.00000, loss_test:0.03795, lr:2.74e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.362, tt:4857.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:160, loss:0.00000, loss_test:0.03938, lr:2.71e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.358, tt:4887.667\n",
      "Ep:161, loss:0.00000, loss_test:0.03883, lr:2.69e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.361, tt:4918.485\n",
      "Ep:162, loss:0.00000, loss_test:0.03953, lr:2.66e-02, fs:0.76190 (r=0.646,p=0.928),  time:30.365, tt:4949.528\n",
      "Ep:163, loss:0.00000, loss_test:0.03923, lr:2.63e-02, fs:0.79070 (r=0.687,p=0.932),  time:30.368, tt:4980.402\n",
      "Ep:164, loss:0.00000, loss_test:0.03844, lr:2.61e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.372, tt:5011.441\n",
      "Ep:165, loss:0.00000, loss_test:0.04053, lr:2.58e-02, fs:0.75449 (r=0.636,p=0.926),  time:30.375, tt:5042.220\n",
      "Ep:166, loss:0.00000, loss_test:0.03903, lr:2.55e-02, fs:0.75740 (r=0.646,p=0.914),  time:30.377, tt:5073.008\n",
      "Ep:167, loss:0.00000, loss_test:0.04056, lr:2.53e-02, fs:0.77647 (r=0.667,p=0.930),  time:30.374, tt:5102.865\n",
      "Ep:168, loss:0.00000, loss_test:0.03881, lr:2.50e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.370, tt:5132.501\n",
      "Ep:169, loss:0.00000, loss_test:0.04049, lr:2.48e-02, fs:0.74699 (r=0.626,p=0.925),  time:30.377, tt:5164.083\n",
      "Ep:170, loss:0.00000, loss_test:0.03939, lr:2.45e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.377, tt:5194.386\n",
      "Ep:171, loss:0.00000, loss_test:0.04045, lr:2.43e-02, fs:0.76190 (r=0.646,p=0.928),  time:30.378, tt:5225.043\n",
      "Ep:172, loss:0.00000, loss_test:0.03944, lr:2.40e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.391, tt:5257.602\n",
      "Ep:173, loss:0.00000, loss_test:0.04072, lr:2.38e-02, fs:0.74699 (r=0.626,p=0.925),  time:30.390, tt:5287.870\n",
      "Ep:174, loss:0.00000, loss_test:0.04017, lr:2.36e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.387, tt:5317.775\n",
      "Ep:175, loss:0.00000, loss_test:0.04119, lr:2.33e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.387, tt:5348.119\n",
      "Ep:176, loss:0.00000, loss_test:0.04051, lr:2.31e-02, fs:0.75449 (r=0.636,p=0.926),  time:30.382, tt:5377.571\n",
      "Ep:177, loss:0.00000, loss_test:0.04103, lr:2.29e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.380, tt:5407.622\n",
      "Ep:178, loss:0.00000, loss_test:0.04101, lr:2.26e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.377, tt:5437.478\n",
      "Ep:179, loss:0.00000, loss_test:0.04129, lr:2.24e-02, fs:0.72393 (r=0.596,p=0.922),  time:30.375, tt:5467.420\n",
      "Ep:180, loss:0.00000, loss_test:0.04092, lr:2.22e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.375, tt:5497.813\n",
      "Ep:181, loss:0.00000, loss_test:0.04176, lr:2.20e-02, fs:0.72393 (r=0.596,p=0.922),  time:30.373, tt:5527.961\n",
      "Ep:182, loss:0.00000, loss_test:0.04103, lr:2.17e-02, fs:0.73171 (r=0.606,p=0.923),  time:30.376, tt:5558.733\n",
      "Ep:183, loss:0.00000, loss_test:0.04196, lr:2.15e-02, fs:0.72393 (r=0.596,p=0.922),  time:30.377, tt:5589.370\n",
      "Ep:184, loss:0.00000, loss_test:0.04092, lr:2.13e-02, fs:0.73939 (r=0.616,p=0.924),  time:30.379, tt:5620.099\n",
      "Ep:185, loss:0.00000, loss_test:0.04212, lr:2.11e-02, fs:0.71605 (r=0.586,p=0.921),  time:30.376, tt:5649.854\n",
      "Ep:186, loss:0.00000, loss_test:0.04123, lr:2.09e-02, fs:0.71605 (r=0.586,p=0.921),  time:30.367, tt:5678.547\n",
      "Ep:187, loss:0.00000, loss_test:0.04217, lr:2.07e-02, fs:0.71605 (r=0.586,p=0.921),  time:30.359, tt:5707.550\n",
      "Ep:188, loss:0.00000, loss_test:0.04163, lr:2.05e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.352, tt:5736.598\n",
      "Ep:189, loss:0.00000, loss_test:0.04224, lr:2.03e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.348, tt:5766.147\n",
      "Ep:190, loss:0.00000, loss_test:0.04193, lr:2.01e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.343, tt:5795.597\n",
      "Ep:191, loss:0.00000, loss_test:0.04192, lr:1.99e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.340, tt:5825.227\n",
      "Ep:192, loss:0.00000, loss_test:0.04218, lr:1.97e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.334, tt:5854.556\n",
      "Ep:193, loss:0.00000, loss_test:0.04257, lr:1.95e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.329, tt:5883.773\n",
      "Ep:194, loss:0.00000, loss_test:0.04253, lr:1.93e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.322, tt:5912.774\n",
      "Ep:195, loss:0.00000, loss_test:0.04234, lr:1.91e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.311, tt:5940.944\n",
      "Ep:196, loss:0.00000, loss_test:0.04253, lr:1.89e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.296, tt:5968.248\n",
      "Ep:197, loss:0.00000, loss_test:0.04265, lr:1.87e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.277, tt:5994.919\n",
      "Ep:198, loss:0.00000, loss_test:0.04293, lr:1.85e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.254, tt:6020.492\n",
      "Ep:199, loss:0.00000, loss_test:0.04291, lr:1.83e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.234, tt:6046.806\n",
      "Ep:200, loss:0.00000, loss_test:0.04290, lr:1.81e-02, fs:0.70807 (r=0.576,p=0.919),  time:30.212, tt:6072.583\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.12535, lr:1.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:28.756, tt:28.756\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.12318, lr:1.00e-02, fs:0.68864 (r=0.949,p=0.540),  time:30.041, tt:60.082\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12139, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:30.300, tt:90.899\n",
      "Ep:3, loss:0.00027, loss_test:0.12036, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:30.285, tt:121.142\n",
      "Ep:4, loss:0.00027, loss_test:0.11957, lr:1.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:30.372, tt:151.862\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00027, loss_test:0.11843, lr:1.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:30.521, tt:183.129\n",
      "Ep:6, loss:0.00026, loss_test:0.11670, lr:1.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:30.598, tt:214.186\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.11464, lr:1.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:30.474, tt:243.792\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.11258, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:30.660, tt:275.937\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.11074, lr:1.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:30.581, tt:305.815\n",
      "Ep:10, loss:0.00026, loss_test:0.10958, lr:1.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:30.597, tt:336.562\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.10853, lr:1.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:30.588, tt:367.057\n",
      "Ep:12, loss:0.00025, loss_test:0.10739, lr:1.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:30.546, tt:397.098\n",
      "Ep:13, loss:0.00025, loss_test:0.10590, lr:1.00e-02, fs:0.73600 (r=0.929,p=0.609),  time:30.527, tt:427.379\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.10433, lr:1.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:30.554, tt:458.307\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00024, loss_test:0.10238, lr:1.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:30.582, tt:489.305\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.10001, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:30.620, tt:520.545\n",
      "Ep:17, loss:0.00023, loss_test:0.09803, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:30.703, tt:552.658\n",
      "Ep:18, loss:0.00023, loss_test:0.09641, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:30.654, tt:582.430\n",
      "Ep:19, loss:0.00022, loss_test:0.09552, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:30.640, tt:612.801\n",
      "Ep:20, loss:0.00022, loss_test:0.09556, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:30.684, tt:644.365\n",
      "Ep:21, loss:0.00022, loss_test:0.09550, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:30.721, tt:675.865\n",
      "Ep:22, loss:0.00021, loss_test:0.09487, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:30.801, tt:708.420\n",
      "Ep:23, loss:0.00021, loss_test:0.09390, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:30.806, tt:739.336\n",
      "Ep:24, loss:0.00021, loss_test:0.09270, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:30.802, tt:770.053\n",
      "Ep:25, loss:0.00020, loss_test:0.09156, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:30.779, tt:800.249\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00020, loss_test:0.09023, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:30.801, tt:831.628\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.08904, lr:1.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.834, tt:863.341\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.08746, lr:1.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:30.876, tt:895.398\n",
      "Ep:29, loss:0.00019, loss_test:0.08578, lr:1.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:30.877, tt:926.308\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00019, loss_test:0.08467, lr:1.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:30.875, tt:957.127\n",
      "Ep:31, loss:0.00018, loss_test:0.08396, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:30.892, tt:988.528\n",
      "Ep:32, loss:0.00018, loss_test:0.08237, lr:1.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.992, tt:1022.736\n",
      "Ep:33, loss:0.00017, loss_test:0.08052, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:30.988, tt:1053.589\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.07908, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:31.025, tt:1085.861\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00017, loss_test:0.07797, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:31.060, tt:1118.145\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00016, loss_test:0.07619, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:31.068, tt:1149.506\n",
      "Ep:37, loss:0.00016, loss_test:0.07353, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:31.103, tt:1181.933\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00015, loss_test:0.07325, lr:1.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:31.067, tt:1211.613\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00015, loss_test:0.07129, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:31.053, tt:1242.112\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00014, loss_test:0.07202, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:31.037, tt:1272.500\n",
      "Ep:41, loss:0.00014, loss_test:0.07179, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:31.042, tt:1303.782\n",
      "Ep:42, loss:0.00013, loss_test:0.06708, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:31.043, tt:1334.859\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00013, loss_test:0.06928, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:31.032, tt:1365.395\n",
      "Ep:44, loss:0.00012, loss_test:0.07235, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:31.035, tt:1396.571\n",
      "Ep:45, loss:0.00012, loss_test:0.07147, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.025, tt:1427.169\n",
      "Ep:46, loss:0.00012, loss_test:0.06538, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:30.988, tt:1456.443\n",
      "Ep:47, loss:0.00011, loss_test:0.06670, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.967, tt:1486.411\n",
      "Ep:48, loss:0.00010, loss_test:0.06924, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:30.967, tt:1517.389\n",
      "Ep:49, loss:0.00010, loss_test:0.07040, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:30.937, tt:1546.870\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.06425, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:30.926, tt:1577.217\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00009, loss_test:0.06504, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.916, tt:1607.611\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.07693, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.902, tt:1637.809\n",
      "Ep:53, loss:0.00010, loss_test:0.07385, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.907, tt:1669.000\n",
      "Ep:54, loss:0.00008, loss_test:0.06191, lr:1.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:30.907, tt:1699.898\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00009, loss_test:0.06332, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.907, tt:1730.777\n",
      "Ep:56, loss:0.00008, loss_test:0.06702, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:30.901, tt:1761.349\n",
      "Ep:57, loss:0.00008, loss_test:0.06272, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.882, tt:1791.179\n",
      "Ep:58, loss:0.00008, loss_test:0.06895, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.898, tt:1822.958\n",
      "Ep:59, loss:0.00007, loss_test:0.06128, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:30.914, tt:1854.815\n",
      "Ep:60, loss:0.00007, loss_test:0.07324, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:30.915, tt:1885.786\n",
      "Ep:61, loss:0.00007, loss_test:0.06777, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:30.917, tt:1916.882\n",
      "Ep:62, loss:0.00007, loss_test:0.06442, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.907, tt:1947.150\n",
      "Ep:63, loss:0.00007, loss_test:0.06595, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:30.925, tt:1979.184\n",
      "Ep:64, loss:0.00007, loss_test:0.06696, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:30.912, tt:2009.268\n",
      "Ep:65, loss:0.00007, loss_test:0.07233, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.913, tt:2040.269\n",
      "Ep:66, loss:0.00007, loss_test:0.06236, lr:9.90e-03, fs:0.86124 (r=0.909,p=0.818),  time:30.935, tt:2072.660\n",
      "Ep:67, loss:0.00007, loss_test:0.09016, lr:9.80e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.925, tt:2102.868\n",
      "Ep:68, loss:0.00007, loss_test:0.05829, lr:9.70e-03, fs:0.84694 (r=0.838,p=0.856),  time:30.904, tt:2132.345\n",
      "Ep:69, loss:0.00007, loss_test:0.06780, lr:9.61e-03, fs:0.80214 (r=0.758,p=0.852),  time:30.914, tt:2163.971\n",
      "Ep:70, loss:0.00006, loss_test:0.07537, lr:9.51e-03, fs:0.86567 (r=0.879,p=0.853),  time:30.918, tt:2195.163\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00006, loss_test:0.07676, lr:9.51e-03, fs:0.78689 (r=0.727,p=0.857),  time:30.919, tt:2226.179\n",
      "Ep:72, loss:0.00005, loss_test:0.06264, lr:9.51e-03, fs:0.81481 (r=0.778,p=0.856),  time:30.904, tt:2256.014\n",
      "Ep:73, loss:0.00005, loss_test:0.07215, lr:9.51e-03, fs:0.80000 (r=0.727,p=0.889),  time:30.913, tt:2287.535\n",
      "Ep:74, loss:0.00005, loss_test:0.06957, lr:9.51e-03, fs:0.80645 (r=0.758,p=0.862),  time:30.902, tt:2317.632\n",
      "Ep:75, loss:0.00005, loss_test:0.06900, lr:9.51e-03, fs:0.81522 (r=0.758,p=0.882),  time:30.906, tt:2348.844\n",
      "Ep:76, loss:0.00004, loss_test:0.06857, lr:9.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:30.887, tt:2378.283\n",
      "Ep:77, loss:0.00004, loss_test:0.06774, lr:9.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:30.884, tt:2408.913\n",
      "Ep:78, loss:0.00004, loss_test:0.08159, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.897, tt:2440.890\n",
      "Ep:79, loss:0.00004, loss_test:0.06755, lr:9.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:30.899, tt:2471.902\n",
      "Ep:80, loss:0.00004, loss_test:0.07765, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.914, tt:2504.010\n",
      "Ep:81, loss:0.00004, loss_test:0.06967, lr:9.51e-03, fs:0.80645 (r=0.758,p=0.862),  time:30.918, tt:2535.267\n",
      "Ep:82, loss:0.00004, loss_test:0.07489, lr:9.41e-03, fs:0.77348 (r=0.707,p=0.854),  time:30.933, tt:2567.415\n",
      "Ep:83, loss:0.00004, loss_test:0.07244, lr:9.32e-03, fs:0.86458 (r=0.838,p=0.892),  time:30.926, tt:2597.768\n",
      "Ep:84, loss:0.00003, loss_test:0.08509, lr:9.23e-03, fs:0.78212 (r=0.707,p=0.875),  time:30.922, tt:2628.399\n",
      "Ep:85, loss:0.00003, loss_test:0.06459, lr:9.14e-03, fs:0.86154 (r=0.848,p=0.875),  time:30.928, tt:2659.849\n",
      "Ep:86, loss:0.00003, loss_test:0.08632, lr:9.04e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.918, tt:2689.843\n",
      "Ep:87, loss:0.00003, loss_test:0.06937, lr:8.95e-03, fs:0.83871 (r=0.788,p=0.897),  time:30.924, tt:2721.311\n",
      "Ep:88, loss:0.00003, loss_test:0.06594, lr:8.86e-03, fs:0.81522 (r=0.758,p=0.882),  time:30.923, tt:2752.186\n",
      "Ep:89, loss:0.00003, loss_test:0.09017, lr:8.78e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.926, tt:2783.326\n",
      "Ep:90, loss:0.00003, loss_test:0.08891, lr:8.69e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.921, tt:2813.782\n",
      "Ep:91, loss:0.00002, loss_test:0.06912, lr:8.60e-03, fs:0.85106 (r=0.808,p=0.899),  time:30.907, tt:2843.406\n",
      "Ep:92, loss:0.00002, loss_test:0.07755, lr:8.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.913, tt:2874.934\n",
      "Ep:93, loss:0.00003, loss_test:0.06739, lr:8.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:30.917, tt:2906.155\n",
      "Ep:94, loss:0.00002, loss_test:0.07389, lr:8.35e-03, fs:0.78212 (r=0.707,p=0.875),  time:30.911, tt:2936.574\n",
      "Ep:95, loss:0.00002, loss_test:0.09125, lr:8.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.906, tt:2967.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00002, loss_test:0.08457, lr:8.18e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.906, tt:2997.860\n",
      "Ep:97, loss:0.00002, loss_test:0.07335, lr:8.10e-03, fs:0.82609 (r=0.768,p=0.894),  time:30.903, tt:3028.493\n",
      "Ep:98, loss:0.00002, loss_test:0.08832, lr:8.02e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.897, tt:3058.789\n",
      "Ep:99, loss:0.00002, loss_test:0.08097, lr:7.94e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.893, tt:3089.298\n",
      "Ep:100, loss:0.00002, loss_test:0.07741, lr:7.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.893, tt:3120.201\n",
      "Ep:101, loss:0.00002, loss_test:0.08568, lr:7.78e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.904, tt:3152.165\n",
      "Ep:102, loss:0.00002, loss_test:0.08365, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:30.905, tt:3183.209\n",
      "Ep:103, loss:0.00001, loss_test:0.08945, lr:7.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.916, tt:3215.285\n",
      "Ep:104, loss:0.00001, loss_test:0.08261, lr:7.55e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.909, tt:3245.411\n",
      "Ep:105, loss:0.00001, loss_test:0.08571, lr:7.47e-03, fs:0.79775 (r=0.717,p=0.899),  time:30.924, tt:3277.968\n",
      "Ep:106, loss:0.00001, loss_test:0.08561, lr:7.40e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.933, tt:3309.782\n",
      "Ep:107, loss:0.00001, loss_test:0.09174, lr:7.32e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.932, tt:3340.689\n",
      "Ep:108, loss:0.00001, loss_test:0.08023, lr:7.25e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.945, tt:3373.001\n",
      "Ep:109, loss:0.00001, loss_test:0.09091, lr:7.18e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.952, tt:3404.674\n",
      "Ep:110, loss:0.00001, loss_test:0.08046, lr:7.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.954, tt:3435.860\n",
      "Ep:111, loss:0.00001, loss_test:0.08993, lr:7.03e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.939, tt:3465.140\n",
      "Ep:112, loss:0.00001, loss_test:0.09044, lr:6.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.930, tt:3495.072\n",
      "Ep:113, loss:0.00001, loss_test:0.07924, lr:6.89e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.922, tt:3525.092\n",
      "Ep:114, loss:0.00001, loss_test:0.08966, lr:6.83e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.911, tt:3554.714\n",
      "Ep:115, loss:0.00001, loss_test:0.08573, lr:6.76e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.909, tt:3585.435\n",
      "Ep:116, loss:0.00001, loss_test:0.09004, lr:6.69e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.913, tt:3616.846\n",
      "Ep:117, loss:0.00001, loss_test:0.08383, lr:6.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:30.907, tt:3646.991\n",
      "Ep:118, loss:0.00001, loss_test:0.09202, lr:6.56e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.889, tt:3675.797\n",
      "Ep:119, loss:0.00001, loss_test:0.08735, lr:6.49e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.886, tt:3706.368\n",
      "Ep:120, loss:0.00001, loss_test:0.08558, lr:6.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.887, tt:3737.360\n",
      "Ep:121, loss:0.00001, loss_test:0.08841, lr:6.36e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.889, tt:3768.508\n",
      "Ep:122, loss:0.00001, loss_test:0.08992, lr:6.30e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.905, tt:3801.360\n",
      "Ep:123, loss:0.00001, loss_test:0.08678, lr:6.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.902, tt:3831.841\n",
      "Ep:124, loss:0.00001, loss_test:0.09035, lr:6.17e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.898, tt:3862.270\n",
      "Ep:125, loss:0.00001, loss_test:0.08599, lr:6.11e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.902, tt:3893.625\n",
      "Ep:126, loss:0.00001, loss_test:0.08663, lr:6.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.898, tt:3924.056\n",
      "Ep:127, loss:0.00001, loss_test:0.08938, lr:5.99e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.890, tt:3953.863\n",
      "Ep:128, loss:0.00001, loss_test:0.09262, lr:5.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.897, tt:3985.759\n",
      "Ep:129, loss:0.00001, loss_test:0.08782, lr:5.87e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.887, tt:4015.306\n",
      "Ep:130, loss:0.00001, loss_test:0.08627, lr:5.81e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.887, tt:4046.218\n",
      "Ep:131, loss:0.00001, loss_test:0.08941, lr:5.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.880, tt:4076.170\n",
      "Ep:132, loss:0.00001, loss_test:0.09006, lr:5.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.865, tt:4105.021\n",
      "Ep:133, loss:0.00001, loss_test:0.09117, lr:5.64e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.855, tt:4134.635\n",
      "Ep:134, loss:0.00001, loss_test:0.08881, lr:5.58e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.847, tt:4164.349\n",
      "Ep:135, loss:0.00001, loss_test:0.09035, lr:5.53e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.846, tt:4195.004\n",
      "Ep:136, loss:0.00001, loss_test:0.09078, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.839, tt:4224.916\n",
      "Ep:137, loss:0.00001, loss_test:0.09159, lr:5.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.829, tt:4254.369\n",
      "Ep:138, loss:0.00001, loss_test:0.08656, lr:5.36e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.825, tt:4284.688\n",
      "Ep:139, loss:0.00001, loss_test:0.09385, lr:5.31e-03, fs:0.78857 (r=0.697,p=0.908),  time:30.814, tt:4313.955\n",
      "Ep:140, loss:0.00001, loss_test:0.08894, lr:5.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.806, tt:4343.671\n",
      "Ep:141, loss:0.00001, loss_test:0.09011, lr:5.20e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.795, tt:4372.924\n",
      "Ep:142, loss:0.00001, loss_test:0.09060, lr:5.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.782, tt:4401.767\n",
      "Ep:143, loss:0.00001, loss_test:0.08839, lr:5.10e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.784, tt:4432.899\n",
      "Ep:144, loss:0.00001, loss_test:0.08763, lr:5.05e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.796, tt:4465.408\n",
      "Ep:145, loss:0.00001, loss_test:0.09187, lr:5.00e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.789, tt:4495.176\n",
      "Ep:146, loss:0.00001, loss_test:0.08782, lr:4.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.785, tt:4525.365\n",
      "Ep:147, loss:0.00001, loss_test:0.08837, lr:4.90e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.776, tt:4554.863\n",
      "Ep:148, loss:0.00001, loss_test:0.08951, lr:4.85e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.754, tt:4582.404\n",
      "Ep:149, loss:0.00001, loss_test:0.08808, lr:4.80e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.728, tt:4609.267\n",
      "Ep:150, loss:0.00001, loss_test:0.08917, lr:4.75e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.718, tt:4638.491\n",
      "Ep:151, loss:0.00001, loss_test:0.09130, lr:4.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.709, tt:4667.766\n",
      "Ep:152, loss:0.00001, loss_test:0.08770, lr:4.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.698, tt:4696.842\n",
      "Ep:153, loss:0.00001, loss_test:0.09086, lr:4.61e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.694, tt:4726.824\n",
      "Ep:154, loss:0.00001, loss_test:0.09169, lr:4.57e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.684, tt:4756.033\n",
      "Ep:155, loss:0.00001, loss_test:0.08897, lr:4.52e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.681, tt:4786.222\n",
      "Ep:156, loss:0.00001, loss_test:0.08958, lr:4.48e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.673, tt:4815.709\n",
      "Ep:157, loss:0.00001, loss_test:0.09183, lr:4.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.664, tt:4844.971\n",
      "Ep:158, loss:0.00001, loss_test:0.09211, lr:4.39e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.667, tt:4875.975\n",
      "Ep:159, loss:0.00000, loss_test:0.08920, lr:4.34e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.665, tt:4906.437\n",
      "Ep:160, loss:0.00000, loss_test:0.09234, lr:4.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.667, tt:4937.451\n",
      "Ep:161, loss:0.00000, loss_test:0.09450, lr:4.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.673, tt:4969.041\n",
      "Ep:162, loss:0.00000, loss_test:0.09199, lr:4.21e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.678, tt:5000.558\n",
      "Ep:163, loss:0.00000, loss_test:0.08598, lr:4.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.680, tt:5031.517\n",
      "Ep:164, loss:0.00000, loss_test:0.09045, lr:4.13e-03, fs:0.79310 (r=0.697,p=0.920),  time:30.685, tt:5062.978\n",
      "Ep:165, loss:0.00000, loss_test:0.09167, lr:4.09e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.685, tt:5093.705\n",
      "Ep:166, loss:0.00000, loss_test:0.09125, lr:4.05e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.684, tt:5124.193\n",
      "Ep:167, loss:0.00000, loss_test:0.09095, lr:4.01e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.697, tt:5157.137\n",
      "Ep:168, loss:0.00000, loss_test:0.09127, lr:3.97e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.695, tt:5187.427\n",
      "Ep:169, loss:0.00000, loss_test:0.09080, lr:3.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.703, tt:5219.539\n",
      "Ep:170, loss:0.00000, loss_test:0.09062, lr:3.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.700, tt:5249.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:171, loss:0.00000, loss_test:0.09240, lr:3.85e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.700, tt:5280.445\n",
      "Ep:172, loss:0.00000, loss_test:0.08874, lr:3.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.699, tt:5310.997\n",
      "Ep:173, loss:0.00000, loss_test:0.08871, lr:3.77e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.702, tt:5342.073\n",
      "Ep:174, loss:0.00000, loss_test:0.09430, lr:3.73e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.701, tt:5372.753\n",
      "Ep:175, loss:0.00000, loss_test:0.09392, lr:3.70e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.691, tt:5401.594\n",
      "Ep:176, loss:0.00000, loss_test:0.09256, lr:3.66e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.690, tt:5432.129\n",
      "Ep:177, loss:0.00000, loss_test:0.09050, lr:3.62e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.684, tt:5461.757\n",
      "Ep:178, loss:0.00000, loss_test:0.09189, lr:3.59e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.689, tt:5493.251\n",
      "Ep:179, loss:0.00000, loss_test:0.09234, lr:3.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.682, tt:5522.760\n",
      "Ep:180, loss:0.00000, loss_test:0.09141, lr:3.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.685, tt:5554.057\n",
      "Ep:181, loss:0.00000, loss_test:0.09005, lr:3.48e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.677, tt:5583.276\n",
      "Ep:182, loss:0.00000, loss_test:0.09114, lr:3.45e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.672, tt:5612.994\n",
      "Ep:183, loss:0.00000, loss_test:0.09360, lr:3.41e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.670, tt:5643.359\n",
      "Ep:184, loss:0.00000, loss_test:0.09173, lr:3.38e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.669, tt:5673.741\n",
      "Ep:185, loss:0.00000, loss_test:0.09133, lr:3.34e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.671, tt:5704.744\n",
      "Ep:186, loss:0.00000, loss_test:0.09247, lr:3.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.670, tt:5735.201\n",
      "Ep:187, loss:0.00000, loss_test:0.09167, lr:3.28e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.666, tt:5765.284\n",
      "Ep:188, loss:0.00000, loss_test:0.08990, lr:3.24e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.661, tt:5794.996\n",
      "Ep:189, loss:0.00000, loss_test:0.08836, lr:3.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.657, tt:5824.842\n",
      "Ep:190, loss:0.00000, loss_test:0.09018, lr:3.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.659, tt:5855.774\n",
      "Ep:191, loss:0.00000, loss_test:0.09402, lr:3.15e-03, fs:0.79769 (r=0.697,p=0.932),  time:30.659, tt:5886.547\n",
      "Ep:192, loss:0.00000, loss_test:0.09102, lr:3.12e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.671, tt:5919.515\n",
      "Ep:193, loss:0.00000, loss_test:0.08934, lr:3.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.670, tt:5949.900\n",
      "Ep:194, loss:0.00000, loss_test:0.09194, lr:3.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.670, tt:5980.701\n",
      "Ep:195, loss:0.00000, loss_test:0.09206, lr:3.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.679, tt:6013.048\n",
      "Ep:196, loss:0.00000, loss_test:0.09110, lr:2.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:30.659, tt:6039.913\n",
      "Ep:197, loss:0.00000, loss_test:0.08924, lr:2.96e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.640, tt:6066.692\n",
      "Ep:198, loss:0.00000, loss_test:0.08990, lr:2.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:30.604, tt:6090.239\n",
      "Ep:199, loss:0.00000, loss_test:0.09231, lr:2.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.568, tt:6113.632\n",
      "Ep:200, loss:0.00000, loss_test:0.09176, lr:2.88e-03, fs:0.81176 (r=0.697,p=0.972),  time:30.515, tt:6133.522\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02175, lr:6.00e-02, fs:0.59504 (r=0.727,p=0.503),  time:30.636, tt:30.636\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02287, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.096, tt:62.192\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02455, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.510, tt:94.530\n",
      "Ep:3, loss:0.00005, loss_test:0.02491, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.336, tt:125.344\n",
      "Ep:4, loss:0.00005, loss_test:0.02454, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.587, tt:157.935\n",
      "Ep:5, loss:0.00004, loss_test:0.02347, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.424, tt:188.542\n",
      "Ep:6, loss:0.00004, loss_test:0.02210, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:31.193, tt:218.349\n",
      "Ep:7, loss:0.00004, loss_test:0.02085, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:31.182, tt:249.455\n",
      "Ep:8, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:31.281, tt:281.526\n",
      "Ep:9, loss:0.00004, loss_test:0.01977, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:31.250, tt:312.503\n",
      "Ep:10, loss:0.00004, loss_test:0.01987, lr:6.00e-02, fs:0.64103 (r=0.758,p=0.556),  time:31.239, tt:343.629\n",
      "Ep:11, loss:0.00004, loss_test:0.01970, lr:6.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:31.403, tt:376.841\n",
      "Ep:12, loss:0.00003, loss_test:0.01935, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:31.427, tt:408.552\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01910, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:31.467, tt:440.542\n",
      "Ep:14, loss:0.00003, loss_test:0.01900, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:31.391, tt:470.860\n",
      "Ep:15, loss:0.00003, loss_test:0.01884, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:31.508, tt:504.136\n",
      "Ep:16, loss:0.00003, loss_test:0.01866, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:31.463, tt:534.867\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01852, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:31.460, tt:566.276\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01847, lr:6.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:31.478, tt:598.089\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:31.445, tt:628.897\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01840, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:31.390, tt:659.195\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01829, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:31.438, tt:691.644\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:31.416, tt:722.574\n",
      "Ep:23, loss:0.00003, loss_test:0.01805, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:31.391, tt:753.385\n",
      "Ep:24, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:31.388, tt:784.692\n",
      "Ep:25, loss:0.00003, loss_test:0.01781, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:31.361, tt:815.396\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:31.403, tt:847.873\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01776, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:31.392, tt:878.990\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01774, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:31.359, tt:909.409\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01772, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:31.377, tt:941.318\n",
      "Ep:30, loss:0.00002, loss_test:0.01771, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:31.320, tt:970.920\n",
      "Ep:31, loss:0.00002, loss_test:0.01772, lr:6.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:31.382, tt:1004.235\n",
      "Ep:32, loss:0.00002, loss_test:0.01772, lr:6.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:31.397, tt:1036.094\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00002, loss_test:0.01771, lr:6.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:31.367, tt:1066.476\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:31.344, tt:1097.028\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01770, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:31.334, tt:1128.029\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01766, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:31.346, tt:1159.814\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01763, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:31.330, tt:1190.539\n",
      "Ep:38, loss:0.00002, loss_test:0.01765, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:31.325, tt:1221.657\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:31.336, tt:1253.453\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01772, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:31.337, tt:1284.824\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01774, lr:6.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:31.347, tt:1316.580\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01773, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:31.334, tt:1347.341\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01773, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:31.346, tt:1379.207\n",
      "Ep:44, loss:0.00002, loss_test:0.01777, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:31.366, tt:1411.455\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01778, lr:6.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:31.362, tt:1442.670\n",
      "Ep:46, loss:0.00002, loss_test:0.01782, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:31.346, tt:1473.249\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01785, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:31.342, tt:1504.416\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01793, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:31.299, tt:1533.655\n",
      "Ep:49, loss:0.00002, loss_test:0.01795, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:31.292, tt:1564.583\n",
      "Ep:50, loss:0.00002, loss_test:0.01793, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:31.269, tt:1594.714\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:31.264, tt:1625.705\n",
      "Ep:52, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.245, tt:1655.973\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01787, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.302, tt:1690.329\n",
      "Ep:54, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:31.304, tt:1721.733\n",
      "Ep:55, loss:0.00002, loss_test:0.01790, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.289, tt:1752.204\n",
      "Ep:56, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:31.273, tt:1782.559\n",
      "Ep:57, loss:0.00002, loss_test:0.01793, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:31.243, tt:1812.072\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01795, lr:6.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:31.227, tt:1842.418\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01797, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:31.197, tt:1871.814\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01798, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:31.157, tt:1900.579\n",
      "Ep:61, loss:0.00001, loss_test:0.01798, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.151, tt:1931.350\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01801, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.153, tt:1962.619\n",
      "Ep:63, loss:0.00001, loss_test:0.01804, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.150, tt:1993.589\n",
      "Ep:64, loss:0.00001, loss_test:0.01805, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.150, tt:2024.762\n",
      "Ep:65, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.137, tt:2055.068\n",
      "Ep:66, loss:0.00001, loss_test:0.01811, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.116, tt:2084.756\n",
      "Ep:67, loss:0.00001, loss_test:0.01811, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:31.094, tt:2114.419\n",
      "Ep:68, loss:0.00001, loss_test:0.01809, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:31.055, tt:2142.785\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01814, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:31.069, tt:2174.835\n",
      "Ep:70, loss:0.00001, loss_test:0.01818, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:31.080, tt:2206.678\n",
      "Ep:71, loss:0.00001, loss_test:0.01816, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:31.078, tt:2237.640\n",
      "Ep:72, loss:0.00001, loss_test:0.01815, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.060, tt:2267.356\n",
      "Ep:73, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.068, tt:2299.014\n",
      "Ep:74, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.049, tt:2328.704\n",
      "Ep:75, loss:0.00001, loss_test:0.01816, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.033, tt:2358.535\n",
      "Ep:76, loss:0.00001, loss_test:0.01821, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.041, tt:2390.122\n",
      "Ep:77, loss:0.00001, loss_test:0.01822, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.030, tt:2420.376\n",
      "Ep:78, loss:0.00001, loss_test:0.01824, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.016, tt:2450.248\n",
      "Ep:79, loss:0.00001, loss_test:0.01827, lr:6.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.013, tt:2481.040\n",
      "Ep:80, loss:0.00001, loss_test:0.01824, lr:5.94e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.013, tt:2512.047\n",
      "Ep:81, loss:0.00001, loss_test:0.01827, lr:5.88e-02, fs:0.83838 (r=0.838,p=0.838),  time:31.012, tt:2542.970\n",
      "Ep:82, loss:0.00001, loss_test:0.01826, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.011, tt:2573.882\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01827, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.007, tt:2604.549\n",
      "Ep:84, loss:0.00001, loss_test:0.01829, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.001, tt:2635.116\n",
      "Ep:85, loss:0.00001, loss_test:0.01830, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.993, tt:2665.415\n",
      "Ep:86, loss:0.00001, loss_test:0.01831, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.991, tt:2696.190\n",
      "Ep:87, loss:0.00001, loss_test:0.01832, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.982, tt:2726.425\n",
      "Ep:88, loss:0.00001, loss_test:0.01834, lr:5.82e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.988, tt:2757.928\n",
      "Ep:89, loss:0.00001, loss_test:0.01832, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.993, tt:2789.394\n",
      "Ep:90, loss:0.00001, loss_test:0.01836, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.989, tt:2820.020\n",
      "Ep:91, loss:0.00001, loss_test:0.01837, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:31.038, tt:2855.495\n",
      "Ep:92, loss:0.00001, loss_test:0.01832, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.029, tt:2885.682\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01834, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.030, tt:2916.799\n",
      "Ep:94, loss:0.00001, loss_test:0.01832, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.033, tt:2948.149\n",
      "Ep:95, loss:0.00001, loss_test:0.01836, lr:5.82e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.039, tt:2979.713\n",
      "Ep:96, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.041, tt:3010.957\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.054, tt:3043.245\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01837, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.061, tt:3075.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.064, tt:3106.438\n",
      "Ep:100, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.084, tt:3139.508\n",
      "Ep:101, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.081, tt:3170.312\n",
      "Ep:102, loss:0.00001, loss_test:0.01835, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.084, tt:3201.644\n",
      "Ep:103, loss:0.00001, loss_test:0.01839, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.082, tt:3232.571\n",
      "Ep:104, loss:0.00001, loss_test:0.01840, lr:5.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.084, tt:3263.825\n",
      "Ep:105, loss:0.00001, loss_test:0.01841, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.086, tt:3295.160\n",
      "Ep:106, loss:0.00001, loss_test:0.01834, lr:5.82e-02, fs:0.86010 (r=0.838,p=0.883),  time:31.093, tt:3326.967\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01838, lr:5.82e-02, fs:0.86010 (r=0.838,p=0.883),  time:31.102, tt:3359.027\n",
      "Ep:108, loss:0.00001, loss_test:0.01845, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.110, tt:3390.987\n",
      "Ep:109, loss:0.00001, loss_test:0.01845, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.110, tt:3422.102\n",
      "Ep:110, loss:0.00001, loss_test:0.01837, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.113, tt:3453.585\n",
      "Ep:111, loss:0.00001, loss_test:0.01839, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.128, tt:3486.348\n",
      "Ep:112, loss:0.00001, loss_test:0.01843, lr:5.82e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.153, tt:3520.335\n",
      "Ep:113, loss:0.00001, loss_test:0.01847, lr:5.82e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.167, tt:3553.030\n",
      "Ep:114, loss:0.00001, loss_test:0.01844, lr:5.82e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.173, tt:3584.922\n",
      "Ep:115, loss:0.00001, loss_test:0.01846, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.171, tt:3615.794\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01851, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.172, tt:3647.144\n",
      "Ep:117, loss:0.00001, loss_test:0.01848, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.160, tt:3676.823\n",
      "Ep:118, loss:0.00001, loss_test:0.01849, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.157, tt:3707.631\n",
      "Ep:119, loss:0.00001, loss_test:0.01846, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.155, tt:3738.605\n",
      "Ep:120, loss:0.00001, loss_test:0.01852, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.161, tt:3770.465\n",
      "Ep:121, loss:0.00001, loss_test:0.01853, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.153, tt:3800.637\n",
      "Ep:122, loss:0.00001, loss_test:0.01856, lr:5.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.162, tt:3832.900\n",
      "Ep:123, loss:0.00001, loss_test:0.01862, lr:5.82e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.167, tt:3864.716\n",
      "Ep:124, loss:0.00001, loss_test:0.01863, lr:5.82e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.160, tt:3895.023\n",
      "Ep:125, loss:0.00001, loss_test:0.01867, lr:5.82e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.160, tt:3926.150\n",
      "Ep:126, loss:0.00001, loss_test:0.01872, lr:5.82e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.160, tt:3957.369\n",
      "Ep:127, loss:0.00001, loss_test:0.01872, lr:5.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.154, tt:3987.719\n",
      "Ep:128, loss:0.00001, loss_test:0.01875, lr:5.71e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.146, tt:4017.786\n",
      "Ep:129, loss:0.00001, loss_test:0.01880, lr:5.65e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.142, tt:4048.428\n",
      "Ep:130, loss:0.00001, loss_test:0.01882, lr:5.59e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.137, tt:4078.972\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.01882, lr:5.59e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.140, tt:4110.504\n",
      "Ep:132, loss:0.00001, loss_test:0.01880, lr:5.59e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.119, tt:4138.784\n",
      "Ep:133, loss:0.00001, loss_test:0.01887, lr:5.59e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.098, tt:4167.079\n",
      "Ep:134, loss:0.00001, loss_test:0.01890, lr:5.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.125, tt:4201.866\n",
      "Ep:135, loss:0.00001, loss_test:0.01896, lr:5.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.112, tt:4231.230\n",
      "Ep:136, loss:0.00001, loss_test:0.01896, lr:5.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.106, tt:4261.502\n",
      "Ep:137, loss:0.00001, loss_test:0.01896, lr:5.59e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.099, tt:4291.682\n",
      "Ep:138, loss:0.00001, loss_test:0.01898, lr:5.59e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.091, tt:4321.713\n",
      "Ep:139, loss:0.00001, loss_test:0.01902, lr:5.59e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.086, tt:4352.053\n",
      "Ep:140, loss:0.00001, loss_test:0.01907, lr:5.59e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.077, tt:4381.855\n",
      "Ep:141, loss:0.00001, loss_test:0.01905, lr:5.59e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.082, tt:4413.626\n",
      "Ep:142, loss:0.00001, loss_test:0.01905, lr:5.54e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.078, tt:4444.117\n",
      "Ep:143, loss:0.00001, loss_test:0.01906, lr:5.48e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.072, tt:4474.353\n",
      "Ep:144, loss:0.00001, loss_test:0.01915, lr:5.43e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.070, tt:4505.189\n",
      "Ep:145, loss:0.00001, loss_test:0.01918, lr:5.37e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.078, tt:4537.384\n",
      "Ep:146, loss:0.00001, loss_test:0.01921, lr:5.32e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.073, tt:4567.775\n",
      "Ep:147, loss:0.00001, loss_test:0.01920, lr:5.27e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.069, tt:4598.147\n",
      "Ep:148, loss:0.00001, loss_test:0.01919, lr:5.21e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.061, tt:4628.113\n",
      "Ep:149, loss:0.00001, loss_test:0.01928, lr:5.16e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.058, tt:4658.732\n",
      "Ep:150, loss:0.00001, loss_test:0.01935, lr:5.11e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.054, tt:4689.203\n",
      "Ep:151, loss:0.00001, loss_test:0.01935, lr:5.06e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.054, tt:4720.206\n",
      "Ep:152, loss:0.00001, loss_test:0.01934, lr:5.01e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.059, tt:4752.008\n",
      "Ep:153, loss:0.00001, loss_test:0.01942, lr:4.96e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.054, tt:4782.331\n",
      "Ep:154, loss:0.00001, loss_test:0.01941, lr:4.91e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.056, tt:4813.720\n",
      "Ep:155, loss:0.00001, loss_test:0.01942, lr:4.86e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.049, tt:4843.694\n",
      "Ep:156, loss:0.00001, loss_test:0.01941, lr:4.81e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.053, tt:4875.246\n",
      "Ep:157, loss:0.00001, loss_test:0.01942, lr:4.76e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.055, tt:4906.613\n",
      "Ep:158, loss:0.00001, loss_test:0.01946, lr:4.71e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.050, tt:4936.990\n",
      "Ep:159, loss:0.00001, loss_test:0.01945, lr:4.67e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.050, tt:4968.069\n",
      "Ep:160, loss:0.00000, loss_test:0.01951, lr:4.62e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.053, tt:4999.542\n",
      "Ep:161, loss:0.00000, loss_test:0.01953, lr:4.57e-02, fs:0.81143 (r=0.717,p=0.934),  time:31.057, tt:5031.241\n",
      "Ep:162, loss:0.00000, loss_test:0.01956, lr:4.53e-02, fs:0.80460 (r=0.707,p=0.933),  time:31.054, tt:5061.799\n",
      "Ep:163, loss:0.00000, loss_test:0.01960, lr:4.48e-02, fs:0.80000 (r=0.707,p=0.921),  time:31.054, tt:5092.854\n",
      "Ep:164, loss:0.00000, loss_test:0.01961, lr:4.44e-02, fs:0.80460 (r=0.707,p=0.933),  time:31.050, tt:5123.179\n",
      "Ep:165, loss:0.00000, loss_test:0.01957, lr:4.39e-02, fs:0.80460 (r=0.707,p=0.933),  time:31.043, tt:5153.090\n",
      "Ep:166, loss:0.00000, loss_test:0.01962, lr:4.35e-02, fs:0.80925 (r=0.707,p=0.946),  time:31.035, tt:5182.801\n",
      "Ep:167, loss:0.00000, loss_test:0.01968, lr:4.31e-02, fs:0.80925 (r=0.707,p=0.946),  time:31.025, tt:5212.265\n",
      "Ep:168, loss:0.00000, loss_test:0.01967, lr:4.26e-02, fs:0.80925 (r=0.707,p=0.946),  time:31.015, tt:5241.592\n",
      "Ep:169, loss:0.00000, loss_test:0.01969, lr:4.22e-02, fs:0.80925 (r=0.707,p=0.946),  time:31.009, tt:5271.519\n",
      "Ep:170, loss:0.00000, loss_test:0.01974, lr:4.18e-02, fs:0.80233 (r=0.697,p=0.945),  time:30.998, tt:5300.665\n",
      "Ep:171, loss:0.00000, loss_test:0.01976, lr:4.14e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.993, tt:5330.784\n",
      "Ep:172, loss:0.00000, loss_test:0.01975, lr:4.10e-02, fs:0.79532 (r=0.687,p=0.944),  time:31.010, tt:5364.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:173, loss:0.00000, loss_test:0.01977, lr:4.05e-02, fs:0.79532 (r=0.687,p=0.944),  time:31.006, tt:5395.095\n",
      "Ep:174, loss:0.00000, loss_test:0.01978, lr:4.01e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.985, tt:5422.445\n",
      "Ep:175, loss:0.00000, loss_test:0.01984, lr:3.97e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.991, tt:5454.408\n",
      "Ep:176, loss:0.00000, loss_test:0.01984, lr:3.93e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.986, tt:5484.604\n",
      "Ep:177, loss:0.00000, loss_test:0.01984, lr:3.89e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.986, tt:5515.490\n",
      "Ep:178, loss:0.00000, loss_test:0.01986, lr:3.86e-02, fs:0.79532 (r=0.687,p=0.944),  time:30.970, tt:5543.657\n",
      "Ep:179, loss:0.00000, loss_test:0.01988, lr:3.82e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.964, tt:5573.568\n",
      "Ep:180, loss:0.00000, loss_test:0.01990, lr:3.78e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.959, tt:5603.650\n",
      "Ep:181, loss:0.00000, loss_test:0.01993, lr:3.74e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.953, tt:5633.370\n",
      "Ep:182, loss:0.00000, loss_test:0.01994, lr:3.70e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.947, tt:5663.353\n",
      "Ep:183, loss:0.00000, loss_test:0.01997, lr:3.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.945, tt:5693.823\n",
      "Ep:184, loss:0.00000, loss_test:0.02000, lr:3.63e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.943, tt:5724.385\n",
      "Ep:185, loss:0.00000, loss_test:0.02000, lr:3.59e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.937, tt:5754.371\n",
      "Ep:186, loss:0.00000, loss_test:0.02001, lr:3.56e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.925, tt:5783.010\n",
      "Ep:187, loss:0.00000, loss_test:0.02006, lr:3.52e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.922, tt:5813.396\n",
      "Ep:188, loss:0.00000, loss_test:0.02007, lr:3.49e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.922, tt:5844.279\n",
      "Ep:189, loss:0.00000, loss_test:0.02010, lr:3.45e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.919, tt:5874.643\n",
      "Ep:190, loss:0.00000, loss_test:0.02013, lr:3.42e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.921, tt:5905.847\n",
      "Ep:191, loss:0.00000, loss_test:0.02013, lr:3.38e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.919, tt:5936.540\n",
      "Ep:192, loss:0.00000, loss_test:0.02009, lr:3.35e-02, fs:0.78824 (r=0.677,p=0.944),  time:30.923, tt:5968.051\n",
      "Ep:193, loss:0.00000, loss_test:0.02010, lr:3.32e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.917, tt:5997.982\n",
      "Ep:194, loss:0.00000, loss_test:0.02015, lr:3.28e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.912, tt:6027.861\n",
      "Ep:195, loss:0.00000, loss_test:0.02018, lr:3.25e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.908, tt:6057.973\n",
      "Ep:196, loss:0.00000, loss_test:0.02021, lr:3.22e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.908, tt:6088.897\n",
      "Ep:197, loss:0.00000, loss_test:0.02021, lr:3.19e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.903, tt:6118.887\n",
      "Ep:198, loss:0.00000, loss_test:0.02022, lr:3.15e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.903, tt:6149.763\n",
      "Ep:199, loss:0.00000, loss_test:0.02024, lr:3.12e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.908, tt:6181.636\n",
      "Ep:200, loss:0.00000, loss_test:0.02024, lr:3.09e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.915, tt:6213.971\n",
      "Ep:201, loss:0.00000, loss_test:0.02030, lr:3.06e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.898, tt:6241.487\n",
      "Ep:202, loss:0.00000, loss_test:0.02030, lr:3.03e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.883, tt:6269.331\n",
      "Ep:203, loss:0.00000, loss_test:0.02031, lr:3.00e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.870, tt:6297.470\n",
      "Ep:204, loss:0.00000, loss_test:0.02032, lr:2.97e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.871, tt:6328.464\n",
      "Ep:205, loss:0.00000, loss_test:0.02035, lr:2.94e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.865, tt:6358.229\n",
      "Ep:206, loss:0.00000, loss_test:0.02034, lr:2.91e-02, fs:0.78107 (r=0.667,p=0.943),  time:30.833, tt:6382.513\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14481, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.173, tt:29.173\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14373, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.862, tt:59.723\n",
      "Ep:2, loss:0.00027, loss_test:0.14182, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.281, tt:90.843\n",
      "Ep:3, loss:0.00027, loss_test:0.13877, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:30.904, tt:123.615\n",
      "Ep:4, loss:0.00026, loss_test:0.13354, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:31.208, tt:156.038\n",
      "Ep:5, loss:0.00025, loss_test:0.12671, lr:1.00e-02, fs:0.64463 (r=0.788,p=0.545),  time:31.329, tt:187.975\n",
      "Ep:6, loss:0.00023, loss_test:0.12114, lr:1.00e-02, fs:0.64815 (r=0.707,p=0.598),  time:31.507, tt:220.551\n",
      "Ep:7, loss:0.00022, loss_test:0.12129, lr:1.00e-02, fs:0.61307 (r=0.616,p=0.610),  time:31.512, tt:252.093\n",
      "Ep:8, loss:0.00022, loss_test:0.12112, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:31.656, tt:284.908\n",
      "Ep:9, loss:0.00021, loss_test:0.12308, lr:1.00e-02, fs:0.65471 (r=0.737,p=0.589),  time:31.585, tt:315.851\n",
      "Ep:10, loss:0.00021, loss_test:0.11933, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:31.721, tt:348.927\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.11680, lr:1.00e-02, fs:0.62887 (r=0.616,p=0.642),  time:31.807, tt:381.684\n",
      "Ep:12, loss:0.00020, loss_test:0.11532, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:31.820, tt:413.663\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.11293, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:31.925, tt:446.945\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10967, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:31.913, tt:478.698\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10682, lr:1.00e-02, fs:0.71429 (r=0.707,p=0.722),  time:31.903, tt:510.448\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10671, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:31.853, tt:541.506\n",
      "Ep:17, loss:0.00017, loss_test:0.10487, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:31.775, tt:571.957\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.10289, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:31.846, tt:605.066\n",
      "Ep:19, loss:0.00016, loss_test:0.10126, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:31.943, tt:638.857\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09965, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:32.044, tt:672.934\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09858, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:32.049, tt:705.075\n",
      "Ep:22, loss:0.00015, loss_test:0.09744, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:32.059, tt:737.355\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09567, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:32.039, tt:768.934\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09530, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:32.100, tt:802.493\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09464, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:32.103, tt:834.671\n",
      "Ep:26, loss:0.00013, loss_test:0.09259, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:32.088, tt:866.388\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09089, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:32.065, tt:897.820\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09091, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:32.022, tt:928.646\n",
      "Ep:29, loss:0.00012, loss_test:0.09142, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:31.978, tt:959.337\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08883, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:31.964, tt:990.881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00012, loss_test:0.08971, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:31.922, tt:1021.516\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.08744, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:31.879, tt:1051.996\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08665, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:31.912, tt:1084.993\n",
      "Ep:34, loss:0.00011, loss_test:0.08765, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:31.921, tt:1117.220\n",
      "Ep:35, loss:0.00011, loss_test:0.08450, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:31.889, tt:1148.020\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08672, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:31.887, tt:1179.824\n",
      "Ep:37, loss:0.00010, loss_test:0.08562, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.912, tt:1212.659\n",
      "Ep:40, loss:0.00010, loss_test:0.08429, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.868, tt:1306.592\n",
      "Ep:41, loss:0.00009, loss_test:0.08238, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.870, tt:1338.559\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08498, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:31.869, tt:1370.358\n",
      "Ep:43, loss:0.00009, loss_test:0.08278, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:31.884, tt:1402.875\n",
      "Ep:44, loss:0.00009, loss_test:0.08238, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.881, tt:1434.654\n",
      "Ep:45, loss:0.00008, loss_test:0.08360, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:31.871, tt:1466.065\n",
      "Ep:46, loss:0.00008, loss_test:0.08065, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.862, tt:1497.513\n",
      "Ep:47, loss:0.00008, loss_test:0.08105, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:31.856, tt:1529.112\n",
      "Ep:48, loss:0.00008, loss_test:0.08167, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.858, tt:1561.018\n",
      "Ep:49, loss:0.00008, loss_test:0.07981, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.836, tt:1591.797\n",
      "Ep:50, loss:0.00008, loss_test:0.08081, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.818, tt:1622.695\n",
      "Ep:51, loss:0.00007, loss_test:0.07939, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:31.790, tt:1653.097\n",
      "Ep:52, loss:0.00007, loss_test:0.08088, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.772, tt:1683.892\n",
      "Ep:53, loss:0.00007, loss_test:0.07854, lr:9.90e-03, fs:0.80628 (r=0.778,p=0.837),  time:31.774, tt:1715.799\n",
      "Ep:54, loss:0.00007, loss_test:0.07844, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.810, tt:1749.543\n",
      "Ep:55, loss:0.00007, loss_test:0.07896, lr:9.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:31.795, tt:1780.498\n",
      "Ep:56, loss:0.00007, loss_test:0.07803, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.820, tt:1813.713\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07855, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.863, tt:1848.040\n",
      "Ep:58, loss:0.00006, loss_test:0.07780, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.869, tt:1880.251\n",
      "Ep:59, loss:0.00006, loss_test:0.07750, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.851, tt:1911.082\n",
      "Ep:60, loss:0.00006, loss_test:0.07840, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.858, tt:1943.349\n",
      "Ep:61, loss:0.00006, loss_test:0.07634, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.866, tt:1975.664\n",
      "Ep:62, loss:0.00006, loss_test:0.07892, lr:9.61e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.858, tt:2007.059\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07570, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.875, tt:2040.003\n",
      "Ep:64, loss:0.00006, loss_test:0.07758, lr:9.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.896, tt:2073.215\n",
      "Ep:65, loss:0.00006, loss_test:0.07498, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.922, tt:2106.882\n",
      "Ep:66, loss:0.00005, loss_test:0.07684, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.909, tt:2137.877\n",
      "Ep:67, loss:0.00005, loss_test:0.07480, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.925, tt:2170.929\n",
      "Ep:68, loss:0.00005, loss_test:0.07601, lr:9.61e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.944, tt:2204.129\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.07460, lr:9.61e-03, fs:0.81915 (r=0.778,p=0.865),  time:31.963, tt:2237.437\n",
      "Ep:70, loss:0.00005, loss_test:0.07688, lr:9.61e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.985, tt:2270.915\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00005, loss_test:0.07374, lr:9.61e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.994, tt:2303.599\n",
      "Ep:72, loss:0.00005, loss_test:0.07731, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:32.002, tt:2336.166\n",
      "Ep:73, loss:0.00005, loss_test:0.07370, lr:9.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.998, tt:2367.869\n",
      "Ep:74, loss:0.00005, loss_test:0.07508, lr:9.61e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.027, tt:2402.016\n",
      "Ep:75, loss:0.00005, loss_test:0.07402, lr:9.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:32.018, tt:2433.335\n",
      "Ep:76, loss:0.00005, loss_test:0.07552, lr:9.61e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.004, tt:2464.346\n",
      "Ep:77, loss:0.00005, loss_test:0.07573, lr:9.61e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.980, tt:2494.458\n",
      "Ep:78, loss:0.00004, loss_test:0.07390, lr:9.61e-03, fs:0.83516 (r=0.768,p=0.916),  time:32.008, tt:2528.672\n",
      "Ep:79, loss:0.00004, loss_test:0.07408, lr:9.61e-03, fs:0.82796 (r=0.778,p=0.885),  time:32.010, tt:2560.803\n",
      "Ep:80, loss:0.00004, loss_test:0.07583, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:32.018, tt:2593.431\n",
      "Ep:81, loss:0.00004, loss_test:0.07310, lr:9.61e-03, fs:0.83243 (r=0.778,p=0.895),  time:32.007, tt:2624.566\n",
      "Ep:82, loss:0.00004, loss_test:0.07523, lr:9.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:32.000, tt:2655.970\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00004, loss_test:0.07377, lr:9.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.014, tt:2689.153\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.07534, lr:9.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.016, tt:2721.381\n",
      "Ep:85, loss:0.00004, loss_test:0.07547, lr:9.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:32.014, tt:2753.208\n",
      "Ep:86, loss:0.00004, loss_test:0.07289, lr:9.51e-03, fs:0.83243 (r=0.778,p=0.895),  time:32.013, tt:2785.164\n",
      "Ep:87, loss:0.00004, loss_test:0.07654, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.023, tt:2818.007\n",
      "Ep:88, loss:0.00004, loss_test:0.07405, lr:9.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:32.037, tt:2851.261\n",
      "Ep:89, loss:0.00004, loss_test:0.07484, lr:9.51e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.053, tt:2884.772\n",
      "Ep:90, loss:0.00004, loss_test:0.07612, lr:9.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:32.043, tt:2915.895\n",
      "Ep:91, loss:0.00004, loss_test:0.07254, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.061, tt:2949.595\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.07636, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:32.055, tt:2981.113\n",
      "Ep:93, loss:0.00004, loss_test:0.07484, lr:9.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.045, tt:3012.190\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00003, loss_test:0.07405, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.034, tt:3043.209\n",
      "Ep:95, loss:0.00003, loss_test:0.07660, lr:9.51e-03, fs:0.83799 (r=0.758,p=0.938),  time:32.045, tt:3076.332\n",
      "Ep:96, loss:0.00003, loss_test:0.07469, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.062, tt:3109.979\n",
      "Ep:97, loss:0.00003, loss_test:0.07572, lr:9.51e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.067, tt:3142.560\n",
      "Ep:98, loss:0.00003, loss_test:0.07412, lr:9.51e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.060, tt:3173.974\n",
      "Ep:99, loss:0.00003, loss_test:0.07522, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.062, tt:3206.217\n",
      "Ep:100, loss:0.00003, loss_test:0.07466, lr:9.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.065, tt:3238.536\n",
      "Ep:101, loss:0.00003, loss_test:0.07495, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.056, tt:3269.687\n",
      "Ep:102, loss:0.00003, loss_test:0.07545, lr:9.51e-03, fs:0.84091 (r=0.747,p=0.961),  time:32.065, tt:3302.650\n",
      "Ep:103, loss:0.00003, loss_test:0.07379, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.065, tt:3334.710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00003, loss_test:0.07615, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.061, tt:3366.437\n",
      "Ep:105, loss:0.00003, loss_test:0.07398, lr:9.41e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.106, tt:3403.196\n",
      "Ep:106, loss:0.00003, loss_test:0.07650, lr:9.32e-03, fs:0.83429 (r=0.737,p=0.961),  time:32.105, tt:3435.192\n",
      "Ep:107, loss:0.00003, loss_test:0.07423, lr:9.23e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.114, tt:3468.312\n",
      "Ep:108, loss:0.00003, loss_test:0.07422, lr:9.14e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.116, tt:3500.612\n",
      "Ep:109, loss:0.00003, loss_test:0.07723, lr:9.04e-03, fs:0.84571 (r=0.747,p=0.974),  time:32.100, tt:3530.975\n",
      "Ep:110, loss:0.00003, loss_test:0.07149, lr:8.95e-03, fs:0.86034 (r=0.778,p=0.963),  time:32.073, tt:3560.110\n",
      "Ep:111, loss:0.00003, loss_test:0.07716, lr:8.86e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.069, tt:3591.780\n",
      "Ep:112, loss:0.00003, loss_test:0.07343, lr:8.78e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.061, tt:3622.912\n",
      "Ep:113, loss:0.00002, loss_test:0.07496, lr:8.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.071, tt:3656.040\n",
      "Ep:114, loss:0.00002, loss_test:0.07557, lr:8.60e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.076, tt:3688.742\n",
      "Ep:115, loss:0.00002, loss_test:0.07306, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.081, tt:3721.422\n",
      "Ep:116, loss:0.00002, loss_test:0.07780, lr:8.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.080, tt:3753.389\n",
      "Ep:117, loss:0.00002, loss_test:0.07317, lr:8.35e-03, fs:0.81871 (r=0.707,p=0.972),  time:32.074, tt:3784.740\n",
      "Ep:118, loss:0.00002, loss_test:0.07655, lr:8.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.077, tt:3817.167\n",
      "Ep:119, loss:0.00002, loss_test:0.07663, lr:8.18e-03, fs:0.85057 (r=0.747,p=0.987),  time:32.077, tt:3849.204\n",
      "Ep:120, loss:0.00002, loss_test:0.07197, lr:8.10e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.076, tt:3881.243\n",
      "Ep:121, loss:0.00002, loss_test:0.07772, lr:8.02e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.071, tt:3912.719\n",
      "Ep:122, loss:0.00002, loss_test:0.07198, lr:7.94e-03, fs:0.85057 (r=0.747,p=0.987),  time:32.071, tt:3944.789\n",
      "Ep:123, loss:0.00002, loss_test:0.07608, lr:7.86e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.062, tt:3975.681\n",
      "Ep:124, loss:0.00002, loss_test:0.07349, lr:7.78e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.054, tt:4006.761\n",
      "Ep:125, loss:0.00002, loss_test:0.07445, lr:7.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.048, tt:4038.088\n",
      "Ep:126, loss:0.00002, loss_test:0.07607, lr:7.62e-03, fs:0.83041 (r=0.717,p=0.986),  time:32.060, tt:4071.620\n",
      "Ep:127, loss:0.00002, loss_test:0.07299, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.060, tt:4103.732\n",
      "Ep:128, loss:0.00002, loss_test:0.07505, lr:7.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.061, tt:4135.814\n",
      "Ep:129, loss:0.00002, loss_test:0.07627, lr:7.40e-03, fs:0.81657 (r=0.697,p=0.986),  time:32.053, tt:4166.873\n",
      "Ep:130, loss:0.00002, loss_test:0.07382, lr:7.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.063, tt:4200.240\n",
      "Ep:131, loss:0.00002, loss_test:0.07481, lr:7.25e-03, fs:0.85714 (r=0.758,p=0.987),  time:32.057, tt:4231.566\n",
      "Ep:132, loss:0.00002, loss_test:0.07338, lr:7.18e-03, fs:0.85714 (r=0.758,p=0.987),  time:32.058, tt:4263.693\n",
      "Ep:133, loss:0.00002, loss_test:0.07462, lr:7.11e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.069, tt:4297.239\n",
      "Ep:134, loss:0.00002, loss_test:0.07416, lr:7.03e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.076, tt:4330.306\n",
      "Ep:135, loss:0.00002, loss_test:0.07324, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:32.074, tt:4362.071\n",
      "Ep:136, loss:0.00002, loss_test:0.07536, lr:6.89e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.059, tt:4392.061\n",
      "Ep:137, loss:0.00002, loss_test:0.07263, lr:6.83e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.059, tt:4424.101\n",
      "Ep:138, loss:0.00002, loss_test:0.07681, lr:6.76e-03, fs:0.85714 (r=0.758,p=0.987),  time:32.063, tt:4456.723\n",
      "Ep:139, loss:0.00002, loss_test:0.07630, lr:6.69e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.064, tt:4489.006\n",
      "Ep:140, loss:0.00002, loss_test:0.07229, lr:6.62e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.065, tt:4521.125\n",
      "Ep:141, loss:0.00002, loss_test:0.07709, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:32.086, tt:4556.184\n",
      "Ep:142, loss:0.00002, loss_test:0.07410, lr:6.49e-03, fs:0.82353 (r=0.707,p=0.986),  time:32.081, tt:4587.515\n",
      "Ep:143, loss:0.00002, loss_test:0.07432, lr:6.43e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.085, tt:4620.269\n",
      "Ep:144, loss:0.00002, loss_test:0.07604, lr:6.36e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.085, tt:4652.316\n",
      "Ep:145, loss:0.00002, loss_test:0.07329, lr:6.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:32.085, tt:4684.419\n",
      "Ep:146, loss:0.00002, loss_test:0.07553, lr:6.24e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.077, tt:4715.353\n",
      "Ep:147, loss:0.00002, loss_test:0.07532, lr:6.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.076, tt:4747.212\n",
      "Ep:148, loss:0.00001, loss_test:0.07349, lr:6.11e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.075, tt:4779.223\n",
      "Ep:149, loss:0.00001, loss_test:0.07505, lr:6.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.081, tt:4812.151\n",
      "Ep:150, loss:0.00001, loss_test:0.07443, lr:5.99e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.087, tt:4845.130\n",
      "Ep:151, loss:0.00001, loss_test:0.07470, lr:5.93e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.082, tt:4876.411\n",
      "Ep:152, loss:0.00001, loss_test:0.07522, lr:5.87e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.090, tt:4909.750\n",
      "Ep:153, loss:0.00001, loss_test:0.07362, lr:5.81e-03, fs:0.81176 (r=0.697,p=0.972),  time:32.086, tt:4941.271\n",
      "Ep:154, loss:0.00001, loss_test:0.07582, lr:5.75e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.089, tt:4973.790\n",
      "Ep:155, loss:0.00001, loss_test:0.07497, lr:5.70e-03, fs:0.84571 (r=0.747,p=0.974),  time:32.090, tt:5005.980\n",
      "Ep:156, loss:0.00001, loss_test:0.07484, lr:5.64e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.081, tt:5036.779\n",
      "Ep:157, loss:0.00001, loss_test:0.07453, lr:5.58e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.081, tt:5068.877\n",
      "Ep:158, loss:0.00001, loss_test:0.07457, lr:5.53e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.084, tt:5101.390\n",
      "Ep:159, loss:0.00001, loss_test:0.07531, lr:5.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.086, tt:5133.817\n",
      "Ep:160, loss:0.00001, loss_test:0.07499, lr:5.42e-03, fs:0.84571 (r=0.747,p=0.974),  time:32.084, tt:5165.552\n",
      "Ep:161, loss:0.00001, loss_test:0.07579, lr:5.36e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.090, tt:5198.523\n",
      "Ep:162, loss:0.00001, loss_test:0.07488, lr:5.31e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.091, tt:5230.870\n",
      "Ep:163, loss:0.00001, loss_test:0.07506, lr:5.26e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.087, tt:5262.250\n",
      "Ep:164, loss:0.00001, loss_test:0.07466, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.090, tt:5294.873\n",
      "Ep:165, loss:0.00001, loss_test:0.07518, lr:5.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.091, tt:5327.066\n",
      "Ep:166, loss:0.00001, loss_test:0.07480, lr:5.10e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.097, tt:5360.223\n",
      "Ep:167, loss:0.00001, loss_test:0.07521, lr:5.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:32.108, tt:5394.218\n",
      "Ep:168, loss:0.00001, loss_test:0.07486, lr:5.00e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.100, tt:5424.854\n",
      "Ep:169, loss:0.00001, loss_test:0.07602, lr:4.95e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.091, tt:5455.489\n",
      "Ep:170, loss:0.00001, loss_test:0.07524, lr:4.90e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.089, tt:5487.224\n",
      "Ep:171, loss:0.00001, loss_test:0.07501, lr:4.85e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.087, tt:5518.904\n",
      "Ep:172, loss:0.00001, loss_test:0.07609, lr:4.80e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.087, tt:5551.035\n",
      "Ep:173, loss:0.00001, loss_test:0.07555, lr:4.75e-03, fs:0.84746 (r=0.758,p=0.962),  time:32.091, tt:5583.755\n",
      "Ep:174, loss:0.00001, loss_test:0.07496, lr:4.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:32.089, tt:5615.582\n",
      "Ep:175, loss:0.00001, loss_test:0.07606, lr:4.66e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.090, tt:5647.873\n",
      "Ep:176, loss:0.00001, loss_test:0.07454, lr:4.61e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.095, tt:5680.832\n",
      "Ep:177, loss:0.00001, loss_test:0.07595, lr:4.57e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.105, tt:5714.738\n",
      "Ep:178, loss:0.00001, loss_test:0.07607, lr:4.52e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.103, tt:5746.389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00001, loss_test:0.07555, lr:4.48e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.097, tt:5777.500\n",
      "Ep:180, loss:0.00001, loss_test:0.07602, lr:4.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:32.080, tt:5806.559\n",
      "Ep:181, loss:0.00001, loss_test:0.07521, lr:4.39e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.075, tt:5837.719\n",
      "Ep:182, loss:0.00001, loss_test:0.07534, lr:4.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.076, tt:5869.843\n",
      "Ep:183, loss:0.00001, loss_test:0.07550, lr:4.30e-03, fs:0.84571 (r=0.747,p=0.974),  time:32.066, tt:5900.134\n",
      "Ep:184, loss:0.00001, loss_test:0.07562, lr:4.26e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.060, tt:5931.062\n",
      "Ep:185, loss:0.00001, loss_test:0.07579, lr:4.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.055, tt:5962.216\n",
      "Ep:186, loss:0.00001, loss_test:0.07551, lr:4.17e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.048, tt:5992.891\n",
      "Ep:187, loss:0.00001, loss_test:0.07587, lr:4.13e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.046, tt:6024.681\n",
      "Ep:188, loss:0.00001, loss_test:0.07540, lr:4.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.059, tt:6059.212\n",
      "Ep:189, loss:0.00001, loss_test:0.07565, lr:4.05e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.063, tt:6091.891\n",
      "Ep:190, loss:0.00001, loss_test:0.07567, lr:4.01e-03, fs:0.83908 (r=0.737,p=0.973),  time:32.063, tt:6124.109\n",
      "Ep:191, loss:0.00001, loss_test:0.07561, lr:3.97e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.061, tt:6155.782\n",
      "Ep:192, loss:0.00001, loss_test:0.07612, lr:3.93e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.058, tt:6187.229\n",
      "Ep:193, loss:0.00001, loss_test:0.07582, lr:3.89e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.061, tt:6219.807\n",
      "Ep:194, loss:0.00001, loss_test:0.07585, lr:3.85e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.054, tt:6250.607\n",
      "Ep:195, loss:0.00001, loss_test:0.07606, lr:3.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:32.050, tt:6281.822\n",
      "Ep:196, loss:0.00001, loss_test:0.07566, lr:3.77e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.051, tt:6314.045\n",
      "Ep:197, loss:0.00001, loss_test:0.07651, lr:3.73e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.048, tt:6345.489\n",
      "Ep:198, loss:0.00001, loss_test:0.07550, lr:3.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.048, tt:6377.517\n",
      "Ep:199, loss:0.00001, loss_test:0.07587, lr:3.66e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.051, tt:6410.300\n",
      "Ep:200, loss:0.00001, loss_test:0.07646, lr:3.62e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.052, tt:6442.418\n",
      "Ep:201, loss:0.00001, loss_test:0.07565, lr:3.59e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.045, tt:6473.032\n",
      "Ep:202, loss:0.00001, loss_test:0.07552, lr:3.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:32.027, tt:6501.574\n",
      "Ep:203, loss:0.00001, loss_test:0.07660, lr:3.52e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.006, tt:6529.305\n",
      "Ep:204, loss:0.00001, loss_test:0.07640, lr:3.48e-03, fs:0.85227 (r=0.758,p=0.974),  time:32.005, tt:6560.936\n",
      "Ep:205, loss:0.00001, loss_test:0.07520, lr:3.45e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.988, tt:6589.503\n",
      "Ep:206, loss:0.00001, loss_test:0.07698, lr:3.41e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.951, tt:6613.834\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02416, lr:6.00e-02, fs:0.64198 (r=0.788,p=0.542),  time:26.202, tt:26.202\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02341, lr:6.00e-02, fs:0.62143 (r=0.879,p=0.481),  time:27.340, tt:54.681\n",
      "Ep:2, loss:0.00004, loss_test:0.02420, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:28.041, tt:84.122\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02374, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:28.654, tt:114.616\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02266, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:28.938, tt:144.689\n",
      "Ep:5, loss:0.00004, loss_test:0.02176, lr:6.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:29.158, tt:174.948\n",
      "Ep:6, loss:0.00004, loss_test:0.02136, lr:6.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:29.179, tt:204.251\n",
      "Ep:7, loss:0.00004, loss_test:0.02140, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:29.271, tt:234.170\n",
      "Ep:8, loss:0.00004, loss_test:0.02143, lr:6.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:29.241, tt:263.168\n",
      "Ep:9, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:29.124, tt:291.243\n",
      "Ep:10, loss:0.00004, loss_test:0.02027, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:29.209, tt:321.303\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01983, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:29.314, tt:351.768\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01966, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:29.403, tt:382.233\n",
      "Ep:13, loss:0.00003, loss_test:0.01953, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:29.422, tt:411.908\n",
      "Ep:14, loss:0.00003, loss_test:0.01942, lr:6.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:29.275, tt:439.125\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01938, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:29.307, tt:468.910\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01943, lr:6.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:29.274, tt:497.652\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01946, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:29.277, tt:526.978\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01940, lr:6.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:29.301, tt:556.718\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01925, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.279, tt:585.576\n",
      "Ep:20, loss:0.00003, loss_test:0.01908, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.257, tt:614.390\n",
      "Ep:21, loss:0.00003, loss_test:0.01894, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.293, tt:644.436\n",
      "Ep:22, loss:0.00003, loss_test:0.01885, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.387, tt:675.893\n",
      "Ep:23, loss:0.00003, loss_test:0.01881, lr:6.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:29.408, tt:705.784\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01876, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.370, tt:734.256\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01868, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.380, tt:763.868\n",
      "Ep:26, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:29.324, tt:791.748\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01841, lr:6.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:29.289, tt:820.096\n",
      "Ep:28, loss:0.00003, loss_test:0.01828, lr:6.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:29.252, tt:848.303\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01812, lr:6.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:29.287, tt:878.596\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01802, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:29.326, tt:909.091\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:29.348, tt:939.130\n",
      "Ep:32, loss:0.00002, loss_test:0.01776, lr:6.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:29.326, tt:967.742\n",
      "Ep:33, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:29.324, tt:997.013\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00002, loss_test:0.01765, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.349, tt:1027.230\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01757, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:29.379, tt:1057.627\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01751, lr:6.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:29.394, tt:1087.560\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:29.420, tt:1117.953\n",
      "Ep:38, loss:0.00002, loss_test:0.01739, lr:6.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:29.433, tt:1147.905\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01729, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:29.431, tt:1177.239\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01723, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:29.420, tt:1206.230\n",
      "Ep:41, loss:0.00002, loss_test:0.01719, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:29.395, tt:1234.584\n",
      "Ep:42, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:29.402, tt:1264.275\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01710, lr:6.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:29.381, tt:1292.766\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01710, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:29.355, tt:1320.955\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01707, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:29.343, tt:1349.759\n",
      "Ep:46, loss:0.00002, loss_test:0.01698, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:29.336, tt:1378.782\n",
      "Ep:47, loss:0.00002, loss_test:0.01696, lr:6.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:29.338, tt:1408.210\n",
      "Ep:48, loss:0.00002, loss_test:0.01693, lr:6.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:29.311, tt:1436.245\n",
      "Ep:49, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:29.295, tt:1464.752\n",
      "Ep:50, loss:0.00002, loss_test:0.01692, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:29.345, tt:1496.571\n",
      "Ep:51, loss:0.00002, loss_test:0.01690, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:29.353, tt:1526.370\n",
      "Ep:52, loss:0.00002, loss_test:0.01690, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:29.349, tt:1555.487\n",
      "Ep:53, loss:0.00002, loss_test:0.01685, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:29.367, tt:1585.834\n",
      "Ep:54, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:29.360, tt:1614.795\n",
      "Ep:55, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:29.362, tt:1644.274\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01683, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.383, tt:1674.835\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01686, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.382, tt:1704.143\n",
      "Ep:58, loss:0.00002, loss_test:0.01686, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.403, tt:1734.769\n",
      "Ep:59, loss:0.00002, loss_test:0.01686, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.387, tt:1763.197\n",
      "Ep:60, loss:0.00002, loss_test:0.01690, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.411, tt:1794.097\n",
      "Ep:61, loss:0.00002, loss_test:0.01688, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.419, tt:1823.992\n",
      "Ep:62, loss:0.00002, loss_test:0.01685, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.455, tt:1855.680\n",
      "Ep:63, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:29.494, tt:1887.607\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01685, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:29.508, tt:1918.047\n",
      "Ep:65, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:29.533, tt:1949.172\n",
      "Ep:66, loss:0.00001, loss_test:0.01686, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:29.554, tt:1980.122\n",
      "Ep:67, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.590, tt:2012.097\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01689, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.580, tt:2040.991\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01692, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.611, tt:2072.793\n",
      "Ep:70, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.648, tt:2105.027\n",
      "Ep:71, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:29.686, tt:2137.426\n",
      "Ep:72, loss:0.00001, loss_test:0.01688, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.714, tt:2169.097\n",
      "Ep:73, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.732, tt:2200.189\n",
      "Ep:74, loss:0.00001, loss_test:0.01688, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.750, tt:2231.284\n",
      "Ep:75, loss:0.00001, loss_test:0.01685, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.790, tt:2264.050\n",
      "Ep:76, loss:0.00001, loss_test:0.01676, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.803, tt:2294.865\n",
      "Ep:77, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.808, tt:2324.995\n",
      "Ep:78, loss:0.00001, loss_test:0.01685, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.817, tt:2355.526\n",
      "Ep:79, loss:0.00001, loss_test:0.01683, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.833, tt:2386.658\n",
      "Ep:80, loss:0.00001, loss_test:0.01686, lr:5.94e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.828, tt:2416.106\n",
      "Ep:81, loss:0.00001, loss_test:0.01684, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.829, tt:2446.013\n",
      "Ep:82, loss:0.00001, loss_test:0.01683, lr:5.82e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.842, tt:2476.872\n",
      "Ep:83, loss:0.00001, loss_test:0.01686, lr:5.76e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.858, tt:2508.048\n",
      "Ep:84, loss:0.00001, loss_test:0.01685, lr:5.71e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.877, tt:2539.550\n",
      "Ep:85, loss:0.00001, loss_test:0.01690, lr:5.65e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.891, tt:2570.645\n",
      "Ep:86, loss:0.00001, loss_test:0.01689, lr:5.59e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.900, tt:2601.272\n",
      "Ep:87, loss:0.00001, loss_test:0.01683, lr:5.54e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.923, tt:2633.207\n",
      "Ep:88, loss:0.00001, loss_test:0.01689, lr:5.48e-02, fs:0.81865 (r=0.798,p=0.840),  time:29.927, tt:2663.472\n",
      "Ep:89, loss:0.00001, loss_test:0.01691, lr:5.43e-02, fs:0.81865 (r=0.798,p=0.840),  time:29.927, tt:2693.466\n",
      "Ep:90, loss:0.00001, loss_test:0.01693, lr:5.37e-02, fs:0.81865 (r=0.798,p=0.840),  time:29.933, tt:2723.890\n",
      "Ep:91, loss:0.00001, loss_test:0.01689, lr:5.32e-02, fs:0.82292 (r=0.798,p=0.849),  time:29.944, tt:2754.805\n",
      "Ep:92, loss:0.00001, loss_test:0.01692, lr:5.27e-02, fs:0.82292 (r=0.798,p=0.849),  time:29.944, tt:2784.811\n",
      "Ep:93, loss:0.00001, loss_test:0.01688, lr:5.21e-02, fs:0.82292 (r=0.798,p=0.849),  time:29.960, tt:2816.264\n",
      "Ep:94, loss:0.00001, loss_test:0.01692, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.967, tt:2846.818\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01693, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.973, tt:2877.379\n",
      "Ep:96, loss:0.00001, loss_test:0.01691, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.980, tt:2908.030\n",
      "Ep:97, loss:0.00001, loss_test:0.01686, lr:5.16e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.986, tt:2938.677\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01688, lr:5.16e-02, fs:0.83333 (r=0.808,p=0.860),  time:29.989, tt:2968.894\n",
      "Ep:99, loss:0.00001, loss_test:0.01697, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.993, tt:2999.313\n",
      "Ep:100, loss:0.00001, loss_test:0.01696, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:29.975, tt:3027.459\n",
      "Ep:101, loss:0.00001, loss_test:0.01693, lr:5.16e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.981, tt:3058.078\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01693, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.983, tt:3088.269\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:103, loss:0.00001, loss_test:0.01696, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.991, tt:3119.095\n",
      "Ep:104, loss:0.00001, loss_test:0.01692, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.999, tt:3149.845\n",
      "Ep:105, loss:0.00001, loss_test:0.01695, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.999, tt:3179.915\n",
      "Ep:106, loss:0.00001, loss_test:0.01693, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:29.997, tt:3209.634\n",
      "Ep:107, loss:0.00001, loss_test:0.01702, lr:5.16e-02, fs:0.83598 (r=0.798,p=0.878),  time:29.979, tt:3237.725\n",
      "Ep:108, loss:0.00001, loss_test:0.01695, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.000, tt:3269.953\n",
      "Ep:109, loss:0.00001, loss_test:0.01694, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.022, tt:3302.433\n",
      "Ep:110, loss:0.00001, loss_test:0.01692, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.031, tt:3333.488\n",
      "Ep:111, loss:0.00001, loss_test:0.01696, lr:5.16e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.041, tt:3364.568\n",
      "Ep:112, loss:0.00001, loss_test:0.01700, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.037, tt:3394.228\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00001, loss_test:0.01697, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.048, tt:3425.501\n",
      "Ep:114, loss:0.00001, loss_test:0.01701, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.052, tt:3455.977\n",
      "Ep:115, loss:0.00001, loss_test:0.01706, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.049, tt:3485.640\n",
      "Ep:116, loss:0.00001, loss_test:0.01698, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.058, tt:3516.842\n",
      "Ep:117, loss:0.00001, loss_test:0.01695, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.064, tt:3547.529\n",
      "Ep:118, loss:0.00001, loss_test:0.01699, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.078, tt:3579.264\n",
      "Ep:119, loss:0.00001, loss_test:0.01706, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.090, tt:3610.804\n",
      "Ep:120, loss:0.00001, loss_test:0.01704, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.087, tt:3640.467\n",
      "Ep:121, loss:0.00001, loss_test:0.01703, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.091, tt:3671.141\n",
      "Ep:122, loss:0.00001, loss_test:0.01710, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.102, tt:3702.560\n",
      "Ep:123, loss:0.00001, loss_test:0.01713, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.102, tt:3732.695\n",
      "Ep:124, loss:0.00001, loss_test:0.01698, lr:5.11e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.119, tt:3764.900\n",
      "Ep:125, loss:0.00001, loss_test:0.01702, lr:5.06e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.127, tt:3795.994\n",
      "Ep:126, loss:0.00001, loss_test:0.01712, lr:5.01e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.144, tt:3828.250\n",
      "Ep:127, loss:0.00001, loss_test:0.01707, lr:4.96e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.153, tt:3859.629\n",
      "Ep:128, loss:0.00001, loss_test:0.01704, lr:4.91e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.157, tt:3890.256\n",
      "Ep:129, loss:0.00001, loss_test:0.01716, lr:4.86e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.156, tt:3920.216\n",
      "Ep:130, loss:0.00001, loss_test:0.01711, lr:4.81e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.164, tt:3951.487\n",
      "Ep:131, loss:0.00001, loss_test:0.01704, lr:4.76e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.159, tt:3980.994\n",
      "Ep:132, loss:0.00001, loss_test:0.01710, lr:4.71e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.157, tt:4010.913\n",
      "Ep:133, loss:0.00001, loss_test:0.01712, lr:4.67e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.165, tt:4042.088\n",
      "Ep:134, loss:0.00001, loss_test:0.01711, lr:4.62e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.172, tt:4073.187\n",
      "Ep:135, loss:0.00001, loss_test:0.01708, lr:4.57e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.175, tt:4103.755\n",
      "Ep:136, loss:0.00001, loss_test:0.01716, lr:4.53e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.176, tt:4134.154\n",
      "Ep:137, loss:0.00001, loss_test:0.01716, lr:4.48e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.197, tt:4167.241\n",
      "Ep:138, loss:0.00001, loss_test:0.01715, lr:4.44e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.205, tt:4198.484\n",
      "Ep:139, loss:0.00001, loss_test:0.01714, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.214, tt:4229.895\n",
      "Ep:140, loss:0.00001, loss_test:0.01719, lr:4.35e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.214, tt:4260.206\n",
      "Ep:141, loss:0.00001, loss_test:0.01721, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.214, tt:4290.346\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00001, loss_test:0.01720, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.217, tt:4321.097\n",
      "Ep:143, loss:0.00001, loss_test:0.01724, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.218, tt:4351.328\n",
      "Ep:144, loss:0.00001, loss_test:0.01723, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.213, tt:4380.915\n",
      "Ep:145, loss:0.00001, loss_test:0.01724, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.208, tt:4410.298\n",
      "Ep:146, loss:0.00001, loss_test:0.01724, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.205, tt:4440.159\n",
      "Ep:147, loss:0.00001, loss_test:0.01728, lr:4.31e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.205, tt:4470.390\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00001, loss_test:0.01726, lr:4.31e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.200, tt:4499.801\n",
      "Ep:149, loss:0.00001, loss_test:0.01727, lr:4.31e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.198, tt:4529.752\n",
      "Ep:150, loss:0.00001, loss_test:0.01730, lr:4.31e-02, fs:0.85870 (r=0.798,p=0.929),  time:30.194, tt:4559.356\n",
      "Ep:151, loss:0.00001, loss_test:0.01738, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.193, tt:4589.404\n",
      "Ep:152, loss:0.00001, loss_test:0.01734, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.200, tt:4620.663\n",
      "Ep:153, loss:0.00001, loss_test:0.01733, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.219, tt:4653.688\n",
      "Ep:154, loss:0.00001, loss_test:0.01739, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.209, tt:4682.331\n",
      "Ep:155, loss:0.00001, loss_test:0.01738, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.213, tt:4713.186\n",
      "Ep:156, loss:0.00001, loss_test:0.01737, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.215, tt:4743.688\n",
      "Ep:157, loss:0.00001, loss_test:0.01740, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.227, tt:4775.807\n",
      "Ep:158, loss:0.00001, loss_test:0.01742, lr:4.31e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.221, tt:4805.190\n",
      "Ep:159, loss:0.00001, loss_test:0.01745, lr:4.26e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.212, tt:4833.989\n",
      "Ep:160, loss:0.00001, loss_test:0.01743, lr:4.22e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.208, tt:4863.503\n",
      "Ep:161, loss:0.00001, loss_test:0.01743, lr:4.18e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.212, tt:4894.368\n",
      "Ep:162, loss:0.00001, loss_test:0.01739, lr:4.14e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.224, tt:4926.524\n",
      "Ep:163, loss:0.00001, loss_test:0.01743, lr:4.10e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.220, tt:4956.112\n",
      "Ep:164, loss:0.00001, loss_test:0.01746, lr:4.05e-02, fs:0.83978 (r=0.768,p=0.927),  time:30.218, tt:4986.019\n",
      "Ep:165, loss:0.00001, loss_test:0.01746, lr:4.01e-02, fs:0.83978 (r=0.768,p=0.927),  time:30.214, tt:5015.571\n",
      "Ep:166, loss:0.00001, loss_test:0.01746, lr:3.97e-02, fs:0.83978 (r=0.768,p=0.927),  time:30.203, tt:5043.891\n",
      "Ep:167, loss:0.00001, loss_test:0.01750, lr:3.93e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.197, tt:5073.041\n",
      "Ep:168, loss:0.00001, loss_test:0.01749, lr:3.89e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.195, tt:5102.933\n",
      "Ep:169, loss:0.00001, loss_test:0.01752, lr:3.86e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.192, tt:5132.604\n",
      "Ep:170, loss:0.00000, loss_test:0.01760, lr:3.82e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.190, tt:5162.503\n",
      "Ep:171, loss:0.00000, loss_test:0.01754, lr:3.78e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.195, tt:5193.599\n",
      "Ep:172, loss:0.00000, loss_test:0.01751, lr:3.74e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.199, tt:5224.481\n",
      "Ep:173, loss:0.00000, loss_test:0.01755, lr:3.70e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.197, tt:5254.340\n",
      "Ep:174, loss:0.00000, loss_test:0.01757, lr:3.67e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.198, tt:5284.656\n",
      "Ep:175, loss:0.00000, loss_test:0.01755, lr:3.63e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.203, tt:5315.755\n",
      "Ep:176, loss:0.00000, loss_test:0.01754, lr:3.59e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.199, tt:5345.201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:177, loss:0.00000, loss_test:0.01759, lr:3.56e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.198, tt:5375.289\n",
      "Ep:178, loss:0.00000, loss_test:0.01764, lr:3.52e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.201, tt:5406.000\n",
      "Ep:179, loss:0.00000, loss_test:0.01759, lr:3.49e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.200, tt:5435.930\n",
      "Ep:180, loss:0.00000, loss_test:0.01756, lr:3.45e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.197, tt:5465.736\n",
      "Ep:181, loss:0.00000, loss_test:0.01761, lr:3.42e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.200, tt:5496.390\n",
      "Ep:182, loss:0.00000, loss_test:0.01765, lr:3.38e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.204, tt:5527.388\n",
      "Ep:183, loss:0.00000, loss_test:0.01763, lr:3.35e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.198, tt:5556.344\n",
      "Ep:184, loss:0.00000, loss_test:0.01763, lr:3.32e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.198, tt:5586.554\n",
      "Ep:185, loss:0.00000, loss_test:0.01763, lr:3.28e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.195, tt:5616.358\n",
      "Ep:186, loss:0.00000, loss_test:0.01767, lr:3.25e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.199, tt:5647.193\n",
      "Ep:187, loss:0.00000, loss_test:0.01766, lr:3.22e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.201, tt:5677.745\n",
      "Ep:188, loss:0.00000, loss_test:0.01766, lr:3.19e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.204, tt:5708.464\n",
      "Ep:189, loss:0.00000, loss_test:0.01768, lr:3.15e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.203, tt:5738.650\n",
      "Ep:190, loss:0.00000, loss_test:0.01771, lr:3.12e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.210, tt:5770.134\n",
      "Ep:191, loss:0.00000, loss_test:0.01774, lr:3.09e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.217, tt:5801.662\n",
      "Ep:192, loss:0.00000, loss_test:0.01770, lr:3.06e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.218, tt:5832.159\n",
      "Ep:193, loss:0.00000, loss_test:0.01769, lr:3.03e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.215, tt:5861.807\n",
      "Ep:194, loss:0.00000, loss_test:0.01772, lr:3.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.215, tt:5892.017\n",
      "Ep:195, loss:0.00000, loss_test:0.01776, lr:2.97e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.216, tt:5922.359\n",
      "Ep:196, loss:0.00000, loss_test:0.01774, lr:2.94e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.221, tt:5953.450\n",
      "Ep:197, loss:0.00000, loss_test:0.01771, lr:2.91e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.218, tt:5983.101\n",
      "Ep:198, loss:0.00000, loss_test:0.01776, lr:2.88e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.219, tt:6013.627\n",
      "Ep:199, loss:0.00000, loss_test:0.01779, lr:2.85e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.221, tt:6044.217\n",
      "Ep:200, loss:0.00000, loss_test:0.01776, lr:2.82e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.224, tt:6075.097\n",
      "Ep:201, loss:0.00000, loss_test:0.01776, lr:2.80e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.220, tt:6104.526\n",
      "Ep:202, loss:0.00000, loss_test:0.01780, lr:2.77e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.217, tt:6134.074\n",
      "Ep:203, loss:0.00000, loss_test:0.01781, lr:2.74e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.218, tt:6164.397\n",
      "Ep:204, loss:0.00000, loss_test:0.01781, lr:2.71e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.210, tt:6193.065\n",
      "Ep:205, loss:0.00000, loss_test:0.01782, lr:2.69e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.203, tt:6221.817\n",
      "Ep:206, loss:0.00000, loss_test:0.01787, lr:2.66e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.203, tt:6252.091\n",
      "Ep:207, loss:0.00000, loss_test:0.01784, lr:2.63e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.204, tt:6282.339\n",
      "Ep:208, loss:0.00000, loss_test:0.01782, lr:2.61e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.193, tt:6310.270\n",
      "Ep:209, loss:0.00000, loss_test:0.01782, lr:2.58e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.170, tt:6335.665\n",
      "Ep:210, loss:0.00000, loss_test:0.01785, lr:2.55e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.158, tt:6363.298\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14413, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.496, tt:28.496\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14316, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.069, tt:62.138\n",
      "Ep:2, loss:0.00028, loss_test:0.14148, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.169, tt:90.506\n",
      "Ep:3, loss:0.00027, loss_test:0.13881, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:29.979, tt:119.917\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13439, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:30.171, tt:150.856\n",
      "Ep:5, loss:0.00026, loss_test:0.12763, lr:1.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:30.340, tt:182.039\n",
      "Ep:6, loss:0.00024, loss_test:0.11955, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:30.408, tt:212.858\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11426, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:30.421, tt:243.371\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11089, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:30.490, tt:274.412\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10883, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:30.519, tt:305.194\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10985, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:30.555, tt:336.100\n",
      "Ep:11, loss:0.00021, loss_test:0.10898, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:30.618, tt:367.411\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10568, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:30.830, tt:400.789\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10265, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:30.863, tt:432.084\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10152, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:30.949, tt:464.233\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10150, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:30.922, tt:494.750\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10111, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:30.926, tt:525.743\n",
      "Ep:17, loss:0.00018, loss_test:0.09901, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:31.065, tt:559.174\n",
      "Ep:18, loss:0.00017, loss_test:0.09707, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:31.187, tt:592.549\n",
      "Ep:19, loss:0.00017, loss_test:0.09465, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:31.194, tt:623.883\n",
      "Ep:20, loss:0.00016, loss_test:0.09390, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:31.289, tt:657.070\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09249, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:31.307, tt:688.747\n",
      "Ep:22, loss:0.00015, loss_test:0.09007, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:31.420, tt:722.658\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08918, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:31.473, tt:755.343\n",
      "Ep:24, loss:0.00015, loss_test:0.08896, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:31.529, tt:788.234\n",
      "Ep:25, loss:0.00014, loss_test:0.08595, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:31.549, tt:820.277\n",
      "Ep:26, loss:0.00014, loss_test:0.08431, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:31.542, tt:851.625\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08518, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:31.550, tt:883.394\n",
      "Ep:28, loss:0.00013, loss_test:0.08290, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:31.586, tt:915.993\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08120, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.637, tt:949.119\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08111, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.638, tt:980.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00012, loss_test:0.07996, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:31.643, tt:1012.574\n",
      "Ep:32, loss:0.00012, loss_test:0.07905, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:31.656, tt:1044.641\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07856, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.698, tt:1077.748\n",
      "Ep:34, loss:0.00012, loss_test:0.07748, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:31.727, tt:1110.443\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07623, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.761, tt:1143.409\n",
      "Ep:36, loss:0.00011, loss_test:0.07623, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.776, tt:1175.700\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07552, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:31.781, tt:1207.662\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.07449, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.796, tt:1240.055\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07386, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:31.822, tt:1272.871\n",
      "Ep:40, loss:0.00010, loss_test:0.07313, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:31.782, tt:1303.066\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07269, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.804, tt:1335.773\n",
      "Ep:42, loss:0.00010, loss_test:0.07270, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:31.765, tt:1365.908\n",
      "Ep:43, loss:0.00010, loss_test:0.07196, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:31.807, tt:1399.523\n",
      "Ep:44, loss:0.00009, loss_test:0.07061, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.820, tt:1431.884\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00009, loss_test:0.07016, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.822, tt:1463.804\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.06961, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.827, tt:1495.853\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.06993, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.799, tt:1526.349\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.06916, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.791, tt:1557.742\n",
      "Ep:49, loss:0.00008, loss_test:0.06935, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:31.789, tt:1589.449\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.06901, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.775, tt:1620.522\n",
      "Ep:51, loss:0.00008, loss_test:0.06757, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.772, tt:1652.163\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.06772, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.755, tt:1683.016\n",
      "Ep:53, loss:0.00008, loss_test:0.06754, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:31.742, tt:1714.091\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.06682, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.741, tt:1745.773\n",
      "Ep:55, loss:0.00007, loss_test:0.06742, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.747, tt:1777.847\n",
      "Ep:56, loss:0.00007, loss_test:0.06633, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.756, tt:1810.102\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.06629, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.763, tt:1842.257\n",
      "Ep:58, loss:0.00007, loss_test:0.06742, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.766, tt:1874.220\n",
      "Ep:59, loss:0.00007, loss_test:0.06671, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.736, tt:1904.130\n",
      "Ep:60, loss:0.00007, loss_test:0.06461, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.707, tt:1934.109\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00007, loss_test:0.06578, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:31.724, tt:1966.891\n",
      "Ep:62, loss:0.00006, loss_test:0.06403, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:31.695, tt:1996.767\n",
      "Ep:63, loss:0.00006, loss_test:0.06414, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.644, tt:2025.195\n",
      "Ep:64, loss:0.00006, loss_test:0.06386, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:31.642, tt:2056.697\n",
      "Ep:65, loss:0.00006, loss_test:0.06383, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:31.626, tt:2087.289\n",
      "Ep:66, loss:0.00006, loss_test:0.06272, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.628, tt:2119.048\n",
      "Ep:67, loss:0.00006, loss_test:0.06326, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.639, tt:2151.467\n",
      "Ep:68, loss:0.00006, loss_test:0.06213, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.645, tt:2183.506\n",
      "Ep:69, loss:0.00006, loss_test:0.06258, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.634, tt:2214.350\n",
      "Ep:70, loss:0.00006, loss_test:0.06169, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.621, tt:2245.096\n",
      "Ep:71, loss:0.00005, loss_test:0.06186, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.618, tt:2276.466\n",
      "Ep:72, loss:0.00005, loss_test:0.06156, lr:9.90e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.599, tt:2306.725\n",
      "Ep:73, loss:0.00005, loss_test:0.06087, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.576, tt:2336.605\n",
      "Ep:74, loss:0.00005, loss_test:0.06164, lr:9.70e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.561, tt:2367.100\n",
      "Ep:75, loss:0.00005, loss_test:0.06063, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.556, tt:2398.271\n",
      "Ep:76, loss:0.00005, loss_test:0.06068, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.562, tt:2430.303\n",
      "Ep:77, loss:0.00005, loss_test:0.06113, lr:9.41e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.559, tt:2461.602\n",
      "Ep:78, loss:0.00005, loss_test:0.06055, lr:9.32e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.543, tt:2491.933\n",
      "Ep:79, loss:0.00005, loss_test:0.06038, lr:9.23e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.530, tt:2522.409\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00005, loss_test:0.06139, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.515, tt:2552.739\n",
      "Ep:81, loss:0.00005, loss_test:0.06214, lr:9.23e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.515, tt:2584.230\n",
      "Ep:82, loss:0.00005, loss_test:0.05978, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.528, tt:2616.838\n",
      "Ep:83, loss:0.00005, loss_test:0.06114, lr:9.23e-03, fs:0.88770 (r=0.838,p=0.943),  time:31.517, tt:2647.392\n",
      "Ep:84, loss:0.00005, loss_test:0.06042, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.497, tt:2677.211\n",
      "Ep:85, loss:0.00004, loss_test:0.06094, lr:9.23e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.475, tt:2706.813\n",
      "Ep:86, loss:0.00004, loss_test:0.05989, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.466, tt:2737.585\n",
      "Ep:87, loss:0.00004, loss_test:0.06016, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.473, tt:2769.629\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00004, loss_test:0.05995, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.463, tt:2800.252\n",
      "Ep:89, loss:0.00004, loss_test:0.06044, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.475, tt:2832.706\n",
      "Ep:90, loss:0.00004, loss_test:0.06099, lr:9.23e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.496, tt:2866.169\n",
      "Ep:91, loss:0.00004, loss_test:0.06063, lr:9.23e-03, fs:0.89362 (r=0.848,p=0.944),  time:31.504, tt:2898.328\n",
      "Ep:92, loss:0.00004, loss_test:0.05960, lr:9.23e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.495, tt:2929.039\n",
      "Ep:93, loss:0.00004, loss_test:0.06197, lr:9.23e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.500, tt:2960.982\n",
      "Ep:94, loss:0.00004, loss_test:0.05918, lr:9.23e-03, fs:0.87831 (r=0.838,p=0.922),  time:31.504, tt:2992.873\n",
      "Ep:95, loss:0.00004, loss_test:0.05986, lr:9.23e-03, fs:0.89474 (r=0.859,p=0.934),  time:31.483, tt:3022.322\n",
      "Ep:96, loss:0.00004, loss_test:0.06007, lr:9.23e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.477, tt:3053.280\n",
      "Ep:97, loss:0.00004, loss_test:0.05968, lr:9.23e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.470, tt:3084.024\n",
      "Ep:98, loss:0.00004, loss_test:0.06009, lr:9.23e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.456, tt:3114.111\n",
      "Ep:99, loss:0.00004, loss_test:0.05992, lr:9.14e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.427, tt:3142.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00004, loss_test:0.05889, lr:9.04e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.403, tt:3171.742\n",
      "Ep:101, loss:0.00004, loss_test:0.05933, lr:8.95e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.389, tt:3201.637\n",
      "Ep:102, loss:0.00003, loss_test:0.05949, lr:8.86e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.381, tt:3232.230\n",
      "Ep:103, loss:0.00003, loss_test:0.05908, lr:8.78e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.370, tt:3262.513\n",
      "Ep:104, loss:0.00003, loss_test:0.05943, lr:8.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.366, tt:3293.412\n",
      "Ep:105, loss:0.00003, loss_test:0.05987, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.362, tt:3324.323\n",
      "Ep:106, loss:0.00003, loss_test:0.05969, lr:8.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.360, tt:3355.572\n",
      "Ep:107, loss:0.00003, loss_test:0.05954, lr:8.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.349, tt:3385.686\n",
      "Ep:108, loss:0.00003, loss_test:0.05982, lr:8.35e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.344, tt:3416.490\n",
      "Ep:109, loss:0.00003, loss_test:0.05920, lr:8.26e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.345, tt:3447.962\n",
      "Ep:110, loss:0.00003, loss_test:0.06003, lr:8.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.327, tt:3477.261\n",
      "Ep:111, loss:0.00003, loss_test:0.06068, lr:8.10e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.317, tt:3507.479\n",
      "Ep:112, loss:0.00003, loss_test:0.05863, lr:8.02e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.293, tt:3536.127\n",
      "Ep:113, loss:0.00003, loss_test:0.06110, lr:7.94e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.273, tt:3565.083\n",
      "Ep:114, loss:0.00003, loss_test:0.06002, lr:7.86e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.267, tt:3595.714\n",
      "Ep:115, loss:0.00003, loss_test:0.05966, lr:7.78e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.264, tt:3626.613\n",
      "Ep:116, loss:0.00003, loss_test:0.06053, lr:7.70e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.251, tt:3656.338\n",
      "Ep:117, loss:0.00003, loss_test:0.05972, lr:7.62e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.235, tt:3685.770\n",
      "Ep:118, loss:0.00003, loss_test:0.05995, lr:7.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.224, tt:3715.656\n",
      "Ep:119, loss:0.00003, loss_test:0.06063, lr:7.47e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.220, tt:3746.355\n",
      "Ep:120, loss:0.00003, loss_test:0.06023, lr:7.40e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.225, tt:3778.173\n",
      "Ep:121, loss:0.00003, loss_test:0.06087, lr:7.32e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.219, tt:3808.693\n",
      "Ep:122, loss:0.00003, loss_test:0.06048, lr:7.25e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.217, tt:3839.670\n",
      "Ep:123, loss:0.00003, loss_test:0.06057, lr:7.18e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.222, tt:3871.525\n",
      "Ep:124, loss:0.00003, loss_test:0.06055, lr:7.11e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.215, tt:3901.855\n",
      "Ep:125, loss:0.00003, loss_test:0.06075, lr:7.03e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.227, tt:3934.575\n",
      "Ep:126, loss:0.00003, loss_test:0.06081, lr:6.96e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.226, tt:3965.700\n",
      "Ep:127, loss:0.00003, loss_test:0.06106, lr:6.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.254, tt:4000.559\n",
      "Ep:128, loss:0.00003, loss_test:0.06082, lr:6.83e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.250, tt:4031.277\n",
      "Ep:129, loss:0.00003, loss_test:0.06053, lr:6.76e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.254, tt:4062.985\n",
      "Ep:130, loss:0.00003, loss_test:0.06036, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.257, tt:4094.671\n",
      "Ep:131, loss:0.00003, loss_test:0.06099, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.256, tt:4125.789\n",
      "Ep:132, loss:0.00002, loss_test:0.06099, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.264, tt:4158.155\n",
      "Ep:133, loss:0.00002, loss_test:0.06067, lr:6.49e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.281, tt:4191.676\n",
      "Ep:134, loss:0.00002, loss_test:0.06131, lr:6.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.290, tt:4224.194\n",
      "Ep:135, loss:0.00002, loss_test:0.06096, lr:6.36e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.302, tt:4257.021\n",
      "Ep:136, loss:0.00002, loss_test:0.06130, lr:6.30e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.310, tt:4289.507\n",
      "Ep:137, loss:0.00002, loss_test:0.06057, lr:6.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.327, tt:4323.128\n",
      "Ep:138, loss:0.00002, loss_test:0.06170, lr:6.17e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.330, tt:4354.858\n",
      "Ep:139, loss:0.00002, loss_test:0.06222, lr:6.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:31.323, tt:4385.250\n",
      "Ep:140, loss:0.00002, loss_test:0.06105, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.330, tt:4417.480\n",
      "Ep:141, loss:0.00002, loss_test:0.06149, lr:5.99e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.326, tt:4448.283\n",
      "Ep:142, loss:0.00002, loss_test:0.06192, lr:5.93e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.330, tt:4480.190\n",
      "Ep:143, loss:0.00002, loss_test:0.06187, lr:5.87e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.329, tt:4511.426\n",
      "Ep:144, loss:0.00002, loss_test:0.06154, lr:5.81e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.332, tt:4543.165\n",
      "Ep:145, loss:0.00002, loss_test:0.06256, lr:5.75e-03, fs:0.81609 (r=0.717,p=0.947),  time:31.336, tt:4575.072\n",
      "Ep:146, loss:0.00002, loss_test:0.06207, lr:5.70e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.337, tt:4606.501\n",
      "Ep:147, loss:0.00002, loss_test:0.06162, lr:5.64e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.337, tt:4637.944\n",
      "Ep:148, loss:0.00002, loss_test:0.06251, lr:5.58e-03, fs:0.81609 (r=0.717,p=0.947),  time:31.370, tt:4674.136\n",
      "Ep:149, loss:0.00002, loss_test:0.06190, lr:5.53e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.380, tt:4707.024\n",
      "Ep:150, loss:0.00002, loss_test:0.06316, lr:5.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.396, tt:4740.868\n",
      "Ep:151, loss:0.00002, loss_test:0.06180, lr:5.42e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.381, tt:4769.890\n",
      "Ep:152, loss:0.00002, loss_test:0.06221, lr:5.36e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.386, tt:4802.083\n",
      "Ep:153, loss:0.00002, loss_test:0.06341, lr:5.31e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.376, tt:4831.863\n",
      "Ep:154, loss:0.00002, loss_test:0.06336, lr:5.26e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.384, tt:4864.587\n",
      "Ep:155, loss:0.00002, loss_test:0.06335, lr:5.20e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.383, tt:4895.705\n",
      "Ep:156, loss:0.00002, loss_test:0.06381, lr:5.15e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.372, tt:4925.417\n",
      "Ep:157, loss:0.00002, loss_test:0.06308, lr:5.10e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.375, tt:4957.316\n",
      "Ep:158, loss:0.00002, loss_test:0.06362, lr:5.05e-03, fs:0.79290 (r=0.677,p=0.957),  time:31.376, tt:4988.763\n",
      "Ep:159, loss:0.00002, loss_test:0.06303, lr:5.00e-03, fs:0.81395 (r=0.707,p=0.959),  time:31.374, tt:5019.815\n",
      "Ep:160, loss:0.00002, loss_test:0.06364, lr:4.95e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.384, tt:5052.810\n",
      "Ep:161, loss:0.00002, loss_test:0.06445, lr:4.90e-03, fs:0.78824 (r=0.677,p=0.944),  time:31.374, tt:5082.552\n",
      "Ep:162, loss:0.00002, loss_test:0.06376, lr:4.85e-03, fs:0.82558 (r=0.717,p=0.973),  time:31.375, tt:5114.047\n",
      "Ep:163, loss:0.00002, loss_test:0.06414, lr:4.80e-03, fs:0.81871 (r=0.707,p=0.972),  time:31.375, tt:5145.539\n",
      "Ep:164, loss:0.00002, loss_test:0.06446, lr:4.75e-03, fs:0.79290 (r=0.677,p=0.957),  time:31.371, tt:5176.213\n",
      "Ep:165, loss:0.00002, loss_test:0.06372, lr:4.71e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.363, tt:5206.196\n",
      "Ep:166, loss:0.00002, loss_test:0.06424, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.356, tt:5236.439\n",
      "Ep:167, loss:0.00002, loss_test:0.06407, lr:4.61e-03, fs:0.79762 (r=0.677,p=0.971),  time:31.350, tt:5266.732\n",
      "Ep:168, loss:0.00002, loss_test:0.06414, lr:4.57e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.343, tt:5296.962\n",
      "Ep:169, loss:0.00002, loss_test:0.06517, lr:4.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.353, tt:5329.990\n",
      "Ep:170, loss:0.00002, loss_test:0.06420, lr:4.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.347, tt:5360.268\n",
      "Ep:171, loss:0.00002, loss_test:0.06419, lr:4.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.345, tt:5391.339\n",
      "Ep:172, loss:0.00002, loss_test:0.06473, lr:4.39e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.347, tt:5422.984\n",
      "Ep:173, loss:0.00002, loss_test:0.06485, lr:4.34e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.346, tt:5454.248\n",
      "Ep:174, loss:0.00002, loss_test:0.06481, lr:4.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.339, tt:5484.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:175, loss:0.00002, loss_test:0.06524, lr:4.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.337, tt:5515.338\n",
      "Ep:176, loss:0.00002, loss_test:0.06510, lr:4.21e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.336, tt:5546.544\n",
      "Ep:177, loss:0.00002, loss_test:0.06497, lr:4.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.333, tt:5577.267\n",
      "Ep:178, loss:0.00002, loss_test:0.06521, lr:4.13e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.334, tt:5608.830\n",
      "Ep:179, loss:0.00002, loss_test:0.06474, lr:4.09e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.347, tt:5642.521\n",
      "Ep:180, loss:0.00002, loss_test:0.06518, lr:4.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.350, tt:5674.407\n",
      "Ep:181, loss:0.00002, loss_test:0.06550, lr:4.01e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.343, tt:5704.446\n",
      "Ep:182, loss:0.00002, loss_test:0.06521, lr:3.97e-03, fs:0.82353 (r=0.707,p=0.986),  time:31.342, tt:5735.669\n",
      "Ep:183, loss:0.00002, loss_test:0.06563, lr:3.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.342, tt:5766.890\n",
      "Ep:184, loss:0.00002, loss_test:0.06491, lr:3.89e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.347, tt:5799.171\n",
      "Ep:185, loss:0.00002, loss_test:0.06553, lr:3.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.367, tt:5834.329\n",
      "Ep:186, loss:0.00002, loss_test:0.06553, lr:3.81e-03, fs:0.80952 (r=0.687,p=0.986),  time:31.368, tt:5865.805\n",
      "Ep:187, loss:0.00002, loss_test:0.06470, lr:3.77e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.361, tt:5895.852\n",
      "Ep:188, loss:0.00002, loss_test:0.06524, lr:3.73e-03, fs:0.82353 (r=0.707,p=0.986),  time:31.361, tt:5927.311\n",
      "Ep:189, loss:0.00002, loss_test:0.06565, lr:3.70e-03, fs:0.80952 (r=0.687,p=0.986),  time:31.358, tt:5957.955\n",
      "Ep:190, loss:0.00002, loss_test:0.06461, lr:3.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.350, tt:5987.897\n",
      "Ep:191, loss:0.00001, loss_test:0.06554, lr:3.62e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.356, tt:6020.300\n",
      "Ep:192, loss:0.00001, loss_test:0.06532, lr:3.59e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.357, tt:6051.965\n",
      "Ep:193, loss:0.00001, loss_test:0.06566, lr:3.55e-03, fs:0.82143 (r=0.697,p=1.000),  time:31.364, tt:6084.628\n",
      "Ep:194, loss:0.00001, loss_test:0.06526, lr:3.52e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.365, tt:6116.099\n",
      "Ep:195, loss:0.00001, loss_test:0.06470, lr:3.48e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.366, tt:6147.667\n",
      "Ep:196, loss:0.00001, loss_test:0.06620, lr:3.45e-03, fs:0.82143 (r=0.697,p=1.000),  time:31.371, tt:6180.115\n",
      "Ep:197, loss:0.00001, loss_test:0.06620, lr:3.41e-03, fs:0.80952 (r=0.687,p=0.986),  time:31.370, tt:6211.329\n",
      "Ep:198, loss:0.00001, loss_test:0.06472, lr:3.38e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.372, tt:6242.964\n",
      "Ep:199, loss:0.00001, loss_test:0.06562, lr:3.34e-03, fs:0.82143 (r=0.697,p=1.000),  time:31.373, tt:6274.516\n",
      "Ep:200, loss:0.00001, loss_test:0.06542, lr:3.31e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.377, tt:6306.779\n",
      "Ep:201, loss:0.00001, loss_test:0.06531, lr:3.28e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.377, tt:6338.070\n",
      "Ep:202, loss:0.00001, loss_test:0.06595, lr:3.24e-03, fs:0.82143 (r=0.697,p=1.000),  time:31.385, tt:6371.132\n",
      "Ep:203, loss:0.00001, loss_test:0.06515, lr:3.21e-03, fs:0.80952 (r=0.687,p=0.986),  time:31.390, tt:6403.563\n",
      "Ep:204, loss:0.00001, loss_test:0.06503, lr:3.18e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.393, tt:6435.583\n",
      "Ep:205, loss:0.00001, loss_test:0.06533, lr:3.15e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.389, tt:6466.163\n",
      "Ep:206, loss:0.00001, loss_test:0.06511, lr:3.12e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.402, tt:6500.241\n",
      "Ep:207, loss:0.00001, loss_test:0.06548, lr:3.09e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.392, tt:6529.574\n",
      "Ep:208, loss:0.00001, loss_test:0.06520, lr:3.05e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.391, tt:6560.761\n",
      "Ep:209, loss:0.00001, loss_test:0.06504, lr:3.02e-03, fs:0.81657 (r=0.697,p=0.986),  time:31.376, tt:6589.040\n",
      "Ep:210, loss:0.00001, loss_test:0.06577, lr:2.99e-03, fs:0.82143 (r=0.697,p=1.000),  time:31.359, tt:6616.743\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02395, lr:6.00e-02, fs:0.59592 (r=0.737,p=0.500),  time:27.534, tt:27.534\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02341, lr:6.00e-02, fs:0.63345 (r=0.899,p=0.489),  time:28.530, tt:57.060\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02382, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:28.979, tt:86.938\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02342, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:28.570, tt:114.281\n",
      "Ep:4, loss:0.00004, loss_test:0.02250, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:28.640, tt:143.199\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02148, lr:6.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:28.843, tt:173.057\n",
      "Ep:6, loss:0.00004, loss_test:0.02103, lr:6.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:29.047, tt:203.329\n",
      "Ep:7, loss:0.00004, loss_test:0.02134, lr:6.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:29.099, tt:232.791\n",
      "Ep:8, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.64035 (r=0.737,p=0.566),  time:29.262, tt:263.357\n",
      "Ep:9, loss:0.00003, loss_test:0.02114, lr:6.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:29.269, tt:292.688\n",
      "Ep:10, loss:0.00003, loss_test:0.02053, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:29.312, tt:322.427\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.02018, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:29.261, tt:351.129\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01998, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:29.297, tt:380.863\n",
      "Ep:13, loss:0.00003, loss_test:0.01978, lr:6.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:29.302, tt:410.229\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01970, lr:6.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:29.247, tt:438.707\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01972, lr:6.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:29.241, tt:467.848\n",
      "Ep:16, loss:0.00003, loss_test:0.01970, lr:6.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:29.299, tt:498.087\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01953, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:29.332, tt:527.980\n",
      "Ep:18, loss:0.00003, loss_test:0.01932, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:29.367, tt:557.968\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01910, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:29.379, tt:587.580\n",
      "Ep:20, loss:0.00003, loss_test:0.01892, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:29.448, tt:618.411\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01876, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:29.440, tt:647.677\n",
      "Ep:22, loss:0.00003, loss_test:0.01868, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.487, tt:678.208\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01858, lr:6.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:29.505, tt:708.123\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:29.514, tt:737.844\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01836, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.523, tt:767.605\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00002, loss_test:0.01826, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:29.623, tt:799.826\n",
      "Ep:27, loss:0.00002, loss_test:0.01818, lr:6.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:29.665, tt:830.621\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01811, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:29.640, tt:859.557\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01801, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:29.666, tt:889.986\n",
      "Ep:30, loss:0.00002, loss_test:0.01792, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:29.697, tt:920.594\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01792, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:29.723, tt:951.123\n",
      "Ep:32, loss:0.00002, loss_test:0.01795, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:29.755, tt:981.926\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01798, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.766, tt:1012.051\n",
      "Ep:34, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:29.753, tt:1041.358\n",
      "Ep:35, loss:0.00002, loss_test:0.01776, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.757, tt:1071.258\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01767, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.755, tt:1100.937\n",
      "Ep:37, loss:0.00002, loss_test:0.01763, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:29.792, tt:1132.092\n",
      "Ep:38, loss:0.00002, loss_test:0.01758, lr:6.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:29.810, tt:1162.587\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01756, lr:6.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:29.816, tt:1192.624\n",
      "Ep:40, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:29.867, tt:1224.563\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01750, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:29.900, tt:1255.791\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01745, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:29.883, tt:1284.952\n",
      "Ep:43, loss:0.00002, loss_test:0.01739, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:29.914, tt:1316.234\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01733, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.926, tt:1346.657\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01728, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.937, tt:1377.106\n",
      "Ep:46, loss:0.00002, loss_test:0.01723, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.929, tt:1406.672\n",
      "Ep:47, loss:0.00002, loss_test:0.01714, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:29.922, tt:1436.272\n",
      "Ep:48, loss:0.00002, loss_test:0.01712, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:29.942, tt:1467.136\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01712, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.960, tt:1498.007\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01704, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.955, tt:1527.712\n",
      "Ep:51, loss:0.00002, loss_test:0.01704, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.943, tt:1557.018\n",
      "Ep:52, loss:0.00002, loss_test:0.01700, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.947, tt:1587.197\n",
      "Ep:53, loss:0.00002, loss_test:0.01694, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.937, tt:1616.613\n",
      "Ep:54, loss:0.00002, loss_test:0.01688, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.929, tt:1646.115\n",
      "Ep:55, loss:0.00002, loss_test:0.01686, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:29.955, tt:1677.481\n",
      "Ep:56, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:29.975, tt:1708.589\n",
      "Ep:57, loss:0.00001, loss_test:0.01683, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.003, tt:1740.184\n",
      "Ep:58, loss:0.00001, loss_test:0.01680, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:29.989, tt:1769.350\n",
      "Ep:59, loss:0.00001, loss_test:0.01675, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:29.996, tt:1799.766\n",
      "Ep:60, loss:0.00001, loss_test:0.01674, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.011, tt:1830.670\n",
      "Ep:61, loss:0.00001, loss_test:0.01673, lr:5.94e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.034, tt:1862.117\n",
      "Ep:62, loss:0.00001, loss_test:0.01664, lr:5.88e-02, fs:0.81517 (r=0.869,p=0.768),  time:30.053, tt:1893.336\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01660, lr:5.88e-02, fs:0.81517 (r=0.869,p=0.768),  time:30.056, tt:1923.565\n",
      "Ep:64, loss:0.00001, loss_test:0.01660, lr:5.88e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.068, tt:1954.436\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01657, lr:5.88e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.070, tt:1984.638\n",
      "Ep:66, loss:0.00001, loss_test:0.01654, lr:5.88e-02, fs:0.81731 (r=0.859,p=0.780),  time:30.066, tt:2014.405\n",
      "Ep:67, loss:0.00001, loss_test:0.01652, lr:5.88e-02, fs:0.81731 (r=0.859,p=0.780),  time:30.077, tt:2045.240\n",
      "Ep:68, loss:0.00001, loss_test:0.01641, lr:5.88e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.059, tt:2074.103\n",
      "Ep:69, loss:0.00001, loss_test:0.01636, lr:5.88e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.059, tt:2104.109\n",
      "Ep:70, loss:0.00001, loss_test:0.01639, lr:5.88e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.061, tt:2134.337\n",
      "Ep:71, loss:0.00001, loss_test:0.01635, lr:5.88e-02, fs:0.83333 (r=0.859,p=0.810),  time:30.059, tt:2164.243\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01632, lr:5.88e-02, fs:0.83744 (r=0.859,p=0.817),  time:30.048, tt:2193.515\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01636, lr:5.88e-02, fs:0.84158 (r=0.859,p=0.825),  time:30.039, tt:2222.852\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01632, lr:5.88e-02, fs:0.84577 (r=0.859,p=0.833),  time:30.032, tt:2252.403\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01625, lr:5.88e-02, fs:0.84577 (r=0.859,p=0.833),  time:30.051, tt:2283.860\n",
      "Ep:76, loss:0.00001, loss_test:0.01622, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.040, tt:2313.083\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01618, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.039, tt:2343.058\n",
      "Ep:78, loss:0.00001, loss_test:0.01610, lr:5.88e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.045, tt:2373.525\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01609, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:30.042, tt:2403.388\n",
      "Ep:80, loss:0.00001, loss_test:0.01611, lr:5.88e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.061, tt:2434.928\n",
      "Ep:81, loss:0.00001, loss_test:0.01606, lr:5.88e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.059, tt:2464.823\n",
      "Ep:82, loss:0.00001, loss_test:0.01607, lr:5.88e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.064, tt:2495.337\n",
      "Ep:83, loss:0.00001, loss_test:0.01606, lr:5.88e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.061, tt:2525.107\n",
      "Ep:84, loss:0.00001, loss_test:0.01607, lr:5.88e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.051, tt:2554.302\n",
      "Ep:85, loss:0.00001, loss_test:0.01606, lr:5.88e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.083, tt:2587.113\n",
      "Ep:86, loss:0.00001, loss_test:0.01608, lr:5.88e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.085, tt:2617.400\n",
      "Ep:87, loss:0.00001, loss_test:0.01609, lr:5.88e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.068, tt:2645.999\n",
      "Ep:88, loss:0.00001, loss_test:0.01612, lr:5.88e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.058, tt:2675.157\n",
      "Ep:89, loss:0.00001, loss_test:0.01618, lr:5.88e-02, fs:0.83505 (r=0.818,p=0.853),  time:30.053, tt:2704.796\n",
      "Ep:90, loss:0.00001, loss_test:0.01609, lr:5.82e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.058, tt:2735.251\n",
      "Ep:91, loss:0.00001, loss_test:0.01612, lr:5.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.061, tt:2765.611\n",
      "Ep:92, loss:0.00001, loss_test:0.01617, lr:5.71e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.060, tt:2795.607\n",
      "Ep:93, loss:0.00001, loss_test:0.01615, lr:5.65e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.066, tt:2826.231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:94, loss:0.00001, loss_test:0.01607, lr:5.59e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.066, tt:2856.303\n",
      "Ep:95, loss:0.00001, loss_test:0.01614, lr:5.54e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.078, tt:2887.459\n",
      "Ep:96, loss:0.00001, loss_test:0.01616, lr:5.48e-02, fs:0.84375 (r=0.818,p=0.871),  time:30.063, tt:2916.124\n",
      "Ep:97, loss:0.00001, loss_test:0.01617, lr:5.43e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.062, tt:2946.117\n",
      "Ep:98, loss:0.00001, loss_test:0.01625, lr:5.37e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.063, tt:2976.284\n",
      "Ep:99, loss:0.00001, loss_test:0.01617, lr:5.32e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.069, tt:3006.906\n",
      "Ep:100, loss:0.00001, loss_test:0.01615, lr:5.27e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.080, tt:3038.125\n",
      "Ep:101, loss:0.00001, loss_test:0.01614, lr:5.21e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.088, tt:3068.950\n",
      "Ep:102, loss:0.00001, loss_test:0.01617, lr:5.16e-02, fs:0.82540 (r=0.788,p=0.867),  time:30.093, tt:3099.577\n",
      "Ep:103, loss:0.00001, loss_test:0.01617, lr:5.11e-02, fs:0.82979 (r=0.788,p=0.876),  time:30.104, tt:3130.821\n",
      "Ep:104, loss:0.00001, loss_test:0.01624, lr:5.06e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.115, tt:3162.024\n",
      "Ep:105, loss:0.00001, loss_test:0.01624, lr:5.01e-02, fs:0.81720 (r=0.768,p=0.874),  time:30.112, tt:3191.851\n",
      "Ep:106, loss:0.00001, loss_test:0.01626, lr:4.96e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.109, tt:3221.647\n",
      "Ep:107, loss:0.00001, loss_test:0.01622, lr:4.91e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.109, tt:3251.719\n",
      "Ep:108, loss:0.00001, loss_test:0.01622, lr:4.86e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.081, tt:3278.779\n",
      "Ep:109, loss:0.00001, loss_test:0.01627, lr:4.81e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.077, tt:3308.470\n",
      "Ep:110, loss:0.00001, loss_test:0.01623, lr:4.76e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.094, tt:3340.446\n",
      "Ep:111, loss:0.00001, loss_test:0.01622, lr:4.71e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.088, tt:3369.853\n",
      "Ep:112, loss:0.00001, loss_test:0.01630, lr:4.67e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.101, tt:3401.437\n",
      "Ep:113, loss:0.00001, loss_test:0.01635, lr:4.62e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.103, tt:3431.699\n",
      "Ep:114, loss:0.00001, loss_test:0.01633, lr:4.57e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.109, tt:3462.583\n",
      "Ep:115, loss:0.00001, loss_test:0.01632, lr:4.53e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.115, tt:3493.367\n",
      "Ep:116, loss:0.00001, loss_test:0.01635, lr:4.48e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.124, tt:3524.497\n",
      "Ep:117, loss:0.00001, loss_test:0.01636, lr:4.44e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.129, tt:3555.209\n",
      "Ep:118, loss:0.00001, loss_test:0.01633, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.119, tt:3584.143\n",
      "Ep:119, loss:0.00001, loss_test:0.01635, lr:4.35e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.127, tt:3615.262\n",
      "Ep:120, loss:0.00001, loss_test:0.01641, lr:4.31e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.128, tt:3645.489\n",
      "Ep:121, loss:0.00001, loss_test:0.01641, lr:4.26e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.137, tt:3676.744\n",
      "Ep:122, loss:0.00001, loss_test:0.01641, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.146, tt:3707.939\n",
      "Ep:123, loss:0.00001, loss_test:0.01643, lr:4.18e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.146, tt:3738.066\n",
      "Ep:124, loss:0.00001, loss_test:0.01645, lr:4.14e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.179, tt:3772.318\n",
      "Ep:125, loss:0.00001, loss_test:0.01644, lr:4.10e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.186, tt:3803.404\n",
      "Ep:126, loss:0.00001, loss_test:0.01648, lr:4.05e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.195, tt:3834.710\n",
      "Ep:127, loss:0.00001, loss_test:0.01650, lr:4.01e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.199, tt:3865.421\n",
      "Ep:128, loss:0.00001, loss_test:0.01650, lr:3.97e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.200, tt:3895.848\n",
      "Ep:129, loss:0.00001, loss_test:0.01650, lr:3.93e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.199, tt:3925.899\n",
      "Ep:130, loss:0.00001, loss_test:0.01654, lr:3.89e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.196, tt:3955.677\n",
      "Ep:131, loss:0.00001, loss_test:0.01654, lr:3.86e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.202, tt:3986.640\n",
      "Ep:132, loss:0.00001, loss_test:0.01653, lr:3.82e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.199, tt:4016.454\n",
      "Ep:133, loss:0.00001, loss_test:0.01655, lr:3.78e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.203, tt:4047.185\n",
      "Ep:134, loss:0.00001, loss_test:0.01656, lr:3.74e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.213, tt:4078.799\n",
      "Ep:135, loss:0.00001, loss_test:0.01652, lr:3.70e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.221, tt:4110.006\n",
      "Ep:136, loss:0.00001, loss_test:0.01657, lr:3.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.229, tt:4141.437\n",
      "Ep:137, loss:0.00001, loss_test:0.01665, lr:3.63e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.231, tt:4171.880\n",
      "Ep:138, loss:0.00001, loss_test:0.01665, lr:3.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.233, tt:4202.375\n",
      "Ep:139, loss:0.00001, loss_test:0.01666, lr:3.56e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.239, tt:4233.483\n",
      "Ep:140, loss:0.00001, loss_test:0.01667, lr:3.52e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.245, tt:4264.599\n",
      "Ep:141, loss:0.00001, loss_test:0.01665, lr:3.49e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.246, tt:4294.961\n",
      "Ep:142, loss:0.00001, loss_test:0.01671, lr:3.45e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.245, tt:4325.029\n",
      "Ep:143, loss:0.00000, loss_test:0.01670, lr:3.42e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.242, tt:4354.879\n",
      "Ep:144, loss:0.00000, loss_test:0.01666, lr:3.38e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.244, tt:4385.386\n",
      "Ep:145, loss:0.00000, loss_test:0.01667, lr:3.35e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.248, tt:4416.166\n",
      "Ep:146, loss:0.00000, loss_test:0.01670, lr:3.32e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.257, tt:4447.829\n",
      "Ep:147, loss:0.00000, loss_test:0.01670, lr:3.28e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.252, tt:4477.236\n",
      "Ep:148, loss:0.00000, loss_test:0.01671, lr:3.25e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.256, tt:4508.192\n",
      "Ep:149, loss:0.00000, loss_test:0.01670, lr:3.22e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.262, tt:4539.266\n",
      "Ep:150, loss:0.00000, loss_test:0.01670, lr:3.19e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.255, tt:4568.457\n",
      "Ep:151, loss:0.00000, loss_test:0.01674, lr:3.15e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.257, tt:4599.013\n",
      "Ep:152, loss:0.00000, loss_test:0.01674, lr:3.12e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.255, tt:4629.071\n",
      "Ep:153, loss:0.00000, loss_test:0.01675, lr:3.09e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.255, tt:4659.287\n",
      "Ep:154, loss:0.00000, loss_test:0.01673, lr:3.06e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.255, tt:4689.525\n",
      "Ep:155, loss:0.00000, loss_test:0.01671, lr:3.03e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.260, tt:4720.544\n",
      "Ep:156, loss:0.00000, loss_test:0.01677, lr:3.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.261, tt:4750.903\n",
      "Ep:157, loss:0.00000, loss_test:0.01679, lr:2.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:30.266, tt:4782.082\n",
      "Ep:158, loss:0.00000, loss_test:0.01678, lr:2.94e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.259, tt:4811.212\n",
      "Ep:159, loss:0.00000, loss_test:0.01677, lr:2.91e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.265, tt:4842.348\n",
      "Ep:160, loss:0.00000, loss_test:0.01679, lr:2.88e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.261, tt:4871.952\n",
      "Ep:161, loss:0.00000, loss_test:0.01679, lr:2.85e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.254, tt:4901.102\n",
      "Ep:162, loss:0.00000, loss_test:0.01676, lr:2.82e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.259, tt:4932.201\n",
      "Ep:163, loss:0.00000, loss_test:0.01676, lr:2.80e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.255, tt:4961.872\n",
      "Ep:164, loss:0.00000, loss_test:0.01679, lr:2.77e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.245, tt:4990.403\n",
      "Ep:165, loss:0.00000, loss_test:0.01679, lr:2.74e-02, fs:0.82486 (r=0.737,p=0.936),  time:30.243, tt:5020.410\n",
      "Ep:166, loss:0.00000, loss_test:0.01678, lr:2.71e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.244, tt:5050.777\n",
      "Ep:167, loss:0.00000, loss_test:0.01678, lr:2.69e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.249, tt:5081.904\n",
      "Ep:168, loss:0.00000, loss_test:0.01679, lr:2.66e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.271, tt:5115.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:169, loss:0.00000, loss_test:0.01681, lr:2.63e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.264, tt:5144.941\n",
      "Ep:170, loss:0.00000, loss_test:0.01679, lr:2.61e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.265, tt:5175.388\n",
      "Ep:171, loss:0.00000, loss_test:0.01681, lr:2.58e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.268, tt:5206.171\n",
      "Ep:172, loss:0.00000, loss_test:0.01683, lr:2.55e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.268, tt:5236.307\n",
      "Ep:173, loss:0.00000, loss_test:0.01682, lr:2.53e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.267, tt:5266.519\n",
      "Ep:174, loss:0.00000, loss_test:0.01681, lr:2.50e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.260, tt:5295.478\n",
      "Ep:175, loss:0.00000, loss_test:0.01682, lr:2.48e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.253, tt:5324.466\n",
      "Ep:176, loss:0.00000, loss_test:0.01681, lr:2.45e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.252, tt:5354.667\n",
      "Ep:177, loss:0.00000, loss_test:0.01682, lr:2.43e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.247, tt:5383.926\n",
      "Ep:178, loss:0.00000, loss_test:0.01684, lr:2.40e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.246, tt:5414.049\n",
      "Ep:179, loss:0.00000, loss_test:0.01684, lr:2.38e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.240, tt:5443.191\n",
      "Ep:180, loss:0.00000, loss_test:0.01686, lr:2.36e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.240, tt:5473.376\n",
      "Ep:181, loss:0.00000, loss_test:0.01686, lr:2.33e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.235, tt:5502.827\n",
      "Ep:182, loss:0.00000, loss_test:0.01687, lr:2.31e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.235, tt:5533.006\n",
      "Ep:183, loss:0.00000, loss_test:0.01688, lr:2.29e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.232, tt:5562.630\n",
      "Ep:184, loss:0.00000, loss_test:0.01687, lr:2.26e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.226, tt:5591.761\n",
      "Ep:185, loss:0.00000, loss_test:0.01686, lr:2.24e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.226, tt:5621.985\n",
      "Ep:186, loss:0.00000, loss_test:0.01687, lr:2.22e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.231, tt:5653.143\n",
      "Ep:187, loss:0.00000, loss_test:0.01687, lr:2.20e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.237, tt:5684.495\n",
      "Ep:188, loss:0.00000, loss_test:0.01690, lr:2.17e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.242, tt:5715.749\n",
      "Ep:189, loss:0.00000, loss_test:0.01693, lr:2.15e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.226, tt:5742.968\n",
      "Ep:190, loss:0.00000, loss_test:0.01693, lr:2.13e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.233, tt:5774.444\n",
      "Ep:191, loss:0.00000, loss_test:0.01690, lr:2.11e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.221, tt:5802.411\n",
      "Ep:192, loss:0.00000, loss_test:0.01691, lr:2.09e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.224, tt:5833.231\n",
      "Ep:193, loss:0.00000, loss_test:0.01694, lr:2.07e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.220, tt:5862.649\n",
      "Ep:194, loss:0.00000, loss_test:0.01696, lr:2.05e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.215, tt:5891.852\n",
      "Ep:195, loss:0.00000, loss_test:0.01693, lr:2.03e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.207, tt:5920.654\n",
      "Ep:196, loss:0.00000, loss_test:0.01693, lr:2.01e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.199, tt:5949.197\n",
      "Ep:197, loss:0.00000, loss_test:0.01695, lr:1.99e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.198, tt:5979.272\n",
      "Ep:198, loss:0.00000, loss_test:0.01698, lr:1.97e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.197, tt:6009.183\n",
      "Ep:199, loss:0.00000, loss_test:0.01698, lr:1.95e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.195, tt:6039.046\n",
      "Ep:200, loss:0.00000, loss_test:0.01697, lr:1.93e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.203, tt:6070.865\n",
      "Ep:201, loss:0.00000, loss_test:0.01697, lr:1.91e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.203, tt:6100.963\n",
      "Ep:202, loss:0.00000, loss_test:0.01699, lr:1.89e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.205, tt:6131.602\n",
      "Ep:203, loss:0.00000, loss_test:0.01701, lr:1.87e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.207, tt:6162.241\n",
      "Ep:204, loss:0.00000, loss_test:0.01702, lr:1.85e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.213, tt:6193.756\n",
      "Ep:205, loss:0.00000, loss_test:0.01701, lr:1.83e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.221, tt:6225.514\n",
      "Ep:206, loss:0.00000, loss_test:0.01703, lr:1.81e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.238, tt:6259.336\n",
      "Ep:207, loss:0.00000, loss_test:0.01704, lr:1.80e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.233, tt:6288.524\n",
      "Ep:208, loss:0.00000, loss_test:0.01704, lr:1.78e-02, fs:0.83146 (r=0.747,p=0.937),  time:30.243, tt:6320.735\n",
      "Ep:209, loss:0.00000, loss_test:0.01702, lr:1.76e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.232, tt:6348.645\n",
      "Ep:210, loss:0.00000, loss_test:0.01703, lr:1.74e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.226, tt:6377.636\n",
      "Ep:211, loss:0.00000, loss_test:0.01707, lr:1.73e-02, fs:0.83616 (r=0.747,p=0.949),  time:30.210, tt:6404.604\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14228, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.192, tt:31.192\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14071, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.950, tt:59.900\n",
      "Ep:2, loss:0.00027, loss_test:0.13789, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:30.184, tt:90.551\n",
      "Ep:3, loss:0.00027, loss_test:0.13339, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:30.495, tt:121.978\n",
      "Ep:4, loss:0.00026, loss_test:0.12702, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:30.362, tt:151.808\n",
      "Ep:5, loss:0.00025, loss_test:0.12007, lr:1.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:30.125, tt:180.751\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11002, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:30.642, tt:275.782\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10976, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:30.800, tt:308.003\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10966, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:30.791, tt:338.701\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10860, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:30.897, tt:370.759\n",
      "Ep:12, loss:0.00020, loss_test:0.10719, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:31.009, tt:403.114\n",
      "Ep:13, loss:0.00020, loss_test:0.10600, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:31.018, tt:434.246\n",
      "Ep:14, loss:0.00019, loss_test:0.10423, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:31.020, tt:465.294\n",
      "Ep:15, loss:0.00019, loss_test:0.10193, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:31.123, tt:497.962\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10093, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:31.144, tt:529.443\n",
      "Ep:17, loss:0.00018, loss_test:0.09928, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:31.186, tt:561.348\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09822, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.103, tt:590.962\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09735, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:31.010, tt:620.195\n",
      "Ep:20, loss:0.00016, loss_test:0.09557, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.988, tt:650.756\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09512, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:30.982, tt:681.613\n",
      "Ep:22, loss:0.00016, loss_test:0.09468, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:31.021, tt:713.477\n",
      "Ep:23, loss:0.00015, loss_test:0.09277, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:30.991, tt:743.795\n",
      "Ep:24, loss:0.00015, loss_test:0.09194, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:30.981, tt:774.531\n",
      "Ep:25, loss:0.00015, loss_test:0.09068, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:31.040, tt:807.045\n",
      "Ep:26, loss:0.00014, loss_test:0.08993, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:31.153, tt:841.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00014, loss_test:0.08876, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:31.218, tt:874.107\n",
      "Ep:28, loss:0.00014, loss_test:0.08750, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:31.240, tt:905.954\n",
      "Ep:29, loss:0.00013, loss_test:0.08753, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:31.281, tt:938.430\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08618, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:31.315, tt:970.766\n",
      "Ep:31, loss:0.00013, loss_test:0.08608, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:31.358, tt:1003.445\n",
      "Ep:32, loss:0.00012, loss_test:0.08482, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.367, tt:1035.105\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08498, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.466, tt:1069.861\n",
      "Ep:34, loss:0.00012, loss_test:0.08402, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:31.443, tt:1100.488\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08412, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.451, tt:1132.219\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08393, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:31.464, tt:1164.155\n",
      "Ep:37, loss:0.00011, loss_test:0.08270, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:31.424, tt:1194.098\n",
      "Ep:38, loss:0.00011, loss_test:0.08315, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:31.449, tt:1226.518\n",
      "Ep:39, loss:0.00011, loss_test:0.08157, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.465, tt:1258.609\n",
      "Ep:40, loss:0.00010, loss_test:0.08335, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:31.440, tt:1289.032\n",
      "Ep:41, loss:0.00010, loss_test:0.08153, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:31.437, tt:1320.339\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.08185, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:31.454, tt:1352.513\n",
      "Ep:43, loss:0.00010, loss_test:0.08072, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:31.454, tt:1383.980\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08218, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.431, tt:1414.413\n",
      "Ep:45, loss:0.00009, loss_test:0.08066, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:31.413, tt:1445.005\n",
      "Ep:46, loss:0.00009, loss_test:0.08210, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.364, tt:1474.102\n",
      "Ep:47, loss:0.00009, loss_test:0.07924, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.374, tt:1505.942\n",
      "Ep:48, loss:0.00009, loss_test:0.08270, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:31.367, tt:1536.967\n",
      "Ep:49, loss:0.00009, loss_test:0.07692, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:31.379, tt:1568.931\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00009, loss_test:0.08357, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:31.422, tt:1602.543\n",
      "Ep:51, loss:0.00008, loss_test:0.07851, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.476, tt:1636.739\n",
      "Ep:52, loss:0.00008, loss_test:0.08072, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:31.472, tt:1668.026\n",
      "Ep:53, loss:0.00008, loss_test:0.07891, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.509, tt:1701.496\n",
      "Ep:54, loss:0.00008, loss_test:0.08008, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.493, tt:1732.128\n",
      "Ep:55, loss:0.00008, loss_test:0.07771, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:31.494, tt:1763.675\n",
      "Ep:56, loss:0.00007, loss_test:0.08245, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:31.483, tt:1794.518\n",
      "Ep:57, loss:0.00007, loss_test:0.07578, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.471, tt:1825.305\n",
      "Ep:58, loss:0.00007, loss_test:0.08389, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:31.478, tt:1857.180\n",
      "Ep:59, loss:0.00007, loss_test:0.07795, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:31.494, tt:1889.663\n",
      "Ep:60, loss:0.00007, loss_test:0.07892, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.508, tt:1921.978\n",
      "Ep:61, loss:0.00007, loss_test:0.07913, lr:9.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.518, tt:1954.090\n",
      "Ep:62, loss:0.00006, loss_test:0.07735, lr:9.80e-03, fs:0.79365 (r=0.758,p=0.833),  time:31.537, tt:1986.853\n",
      "Ep:63, loss:0.00006, loss_test:0.07780, lr:9.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.555, tt:2019.493\n",
      "Ep:64, loss:0.00006, loss_test:0.07835, lr:9.61e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.560, tt:2051.408\n",
      "Ep:65, loss:0.00006, loss_test:0.07704, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.559, tt:2082.920\n",
      "Ep:66, loss:0.00006, loss_test:0.07734, lr:9.41e-03, fs:0.77966 (r=0.697,p=0.885),  time:31.576, tt:2115.575\n",
      "Ep:67, loss:0.00006, loss_test:0.07485, lr:9.32e-03, fs:0.81053 (r=0.778,p=0.846),  time:31.577, tt:2147.254\n",
      "Ep:68, loss:0.00006, loss_test:0.07743, lr:9.23e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.571, tt:2178.385\n",
      "Ep:69, loss:0.00006, loss_test:0.07431, lr:9.14e-03, fs:0.80645 (r=0.758,p=0.862),  time:31.578, tt:2210.440\n",
      "Ep:70, loss:0.00005, loss_test:0.08120, lr:9.04e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.570, tt:2241.468\n",
      "Ep:71, loss:0.00005, loss_test:0.07322, lr:8.95e-03, fs:0.80214 (r=0.758,p=0.852),  time:31.560, tt:2272.291\n",
      "Ep:72, loss:0.00005, loss_test:0.08057, lr:8.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.560, tt:2303.874\n",
      "Ep:73, loss:0.00005, loss_test:0.07531, lr:8.78e-03, fs:0.78889 (r=0.717,p=0.877),  time:31.580, tt:2336.921\n",
      "Ep:74, loss:0.00005, loss_test:0.07933, lr:8.69e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.584, tt:2368.835\n",
      "Ep:75, loss:0.00005, loss_test:0.07696, lr:8.60e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.611, tt:2402.474\n",
      "Ep:76, loss:0.00005, loss_test:0.07706, lr:8.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.616, tt:2434.406\n",
      "Ep:77, loss:0.00005, loss_test:0.07735, lr:8.43e-03, fs:0.82162 (r=0.768,p=0.884),  time:31.618, tt:2466.229\n",
      "Ep:78, loss:0.00005, loss_test:0.08073, lr:8.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.594, tt:2495.944\n",
      "Ep:79, loss:0.00005, loss_test:0.07416, lr:8.26e-03, fs:0.78212 (r=0.707,p=0.875),  time:31.604, tt:2528.355\n",
      "Ep:80, loss:0.00005, loss_test:0.08135, lr:8.18e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.608, tt:2560.246\n",
      "Ep:81, loss:0.00005, loss_test:0.07643, lr:8.10e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.595, tt:2590.825\n",
      "Ep:82, loss:0.00004, loss_test:0.07718, lr:8.02e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.578, tt:2621.003\n",
      "Ep:83, loss:0.00004, loss_test:0.08020, lr:7.94e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.581, tt:2652.839\n",
      "Ep:84, loss:0.00004, loss_test:0.07515, lr:7.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:31.585, tt:2684.709\n",
      "Ep:85, loss:0.00004, loss_test:0.08043, lr:7.78e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.581, tt:2715.939\n",
      "Ep:86, loss:0.00004, loss_test:0.07610, lr:7.70e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.581, tt:2747.579\n",
      "Ep:87, loss:0.00004, loss_test:0.07890, lr:7.62e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.580, tt:2779.054\n",
      "Ep:88, loss:0.00004, loss_test:0.07671, lr:7.55e-03, fs:0.81967 (r=0.758,p=0.893),  time:31.580, tt:2810.621\n",
      "Ep:89, loss:0.00004, loss_test:0.08007, lr:7.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.568, tt:2841.103\n",
      "Ep:90, loss:0.00004, loss_test:0.07628, lr:7.40e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.564, tt:2872.294\n",
      "Ep:91, loss:0.00004, loss_test:0.07956, lr:7.32e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.556, tt:2903.185\n",
      "Ep:92, loss:0.00004, loss_test:0.07799, lr:7.25e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.556, tt:2934.695\n",
      "Ep:93, loss:0.00004, loss_test:0.07677, lr:7.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.565, tt:2967.083\n",
      "Ep:94, loss:0.00004, loss_test:0.08087, lr:7.11e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.556, tt:2997.866\n",
      "Ep:95, loss:0.00004, loss_test:0.07437, lr:7.03e-03, fs:0.77966 (r=0.697,p=0.885),  time:31.551, tt:3028.849\n",
      "Ep:96, loss:0.00004, loss_test:0.08123, lr:6.96e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.530, tt:3058.432\n",
      "Ep:97, loss:0.00003, loss_test:0.07624, lr:6.89e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.511, tt:3088.095\n",
      "Ep:98, loss:0.00003, loss_test:0.07852, lr:6.83e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.525, tt:3120.927\n",
      "Ep:99, loss:0.00003, loss_test:0.07674, lr:6.76e-03, fs:0.77966 (r=0.697,p=0.885),  time:31.531, tt:3153.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00003, loss_test:0.07983, lr:6.69e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.523, tt:3183.868\n",
      "Ep:101, loss:0.00003, loss_test:0.07643, lr:6.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.518, tt:3214.811\n",
      "Ep:102, loss:0.00003, loss_test:0.07997, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.526, tt:3247.196\n",
      "Ep:103, loss:0.00003, loss_test:0.07616, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:31.519, tt:3277.961\n",
      "Ep:104, loss:0.00003, loss_test:0.07879, lr:6.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.504, tt:3307.884\n",
      "Ep:105, loss:0.00003, loss_test:0.07723, lr:6.36e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.515, tt:3340.639\n",
      "Ep:106, loss:0.00003, loss_test:0.08059, lr:6.30e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.516, tt:3372.190\n",
      "Ep:107, loss:0.00003, loss_test:0.07872, lr:6.24e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.503, tt:3402.309\n",
      "Ep:108, loss:0.00003, loss_test:0.07865, lr:6.17e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.515, tt:3435.183\n",
      "Ep:109, loss:0.00003, loss_test:0.07988, lr:6.11e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.519, tt:3467.127\n",
      "Ep:110, loss:0.00003, loss_test:0.07851, lr:6.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.511, tt:3497.755\n",
      "Ep:111, loss:0.00003, loss_test:0.07944, lr:5.99e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.497, tt:3527.617\n",
      "Ep:112, loss:0.00003, loss_test:0.07698, lr:5.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.476, tt:3556.817\n",
      "Ep:113, loss:0.00003, loss_test:0.08197, lr:5.87e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.477, tt:3588.348\n",
      "Ep:114, loss:0.00003, loss_test:0.07556, lr:5.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.477, tt:3619.873\n",
      "Ep:115, loss:0.00003, loss_test:0.08051, lr:5.75e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.480, tt:3651.710\n",
      "Ep:116, loss:0.00003, loss_test:0.07766, lr:5.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.474, tt:3682.469\n",
      "Ep:117, loss:0.00003, loss_test:0.07916, lr:5.64e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.464, tt:3712.784\n",
      "Ep:118, loss:0.00003, loss_test:0.07793, lr:5.58e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.483, tt:3746.423\n",
      "Ep:119, loss:0.00003, loss_test:0.07851, lr:5.53e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.483, tt:3777.974\n",
      "Ep:120, loss:0.00003, loss_test:0.07834, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.494, tt:3810.797\n",
      "Ep:121, loss:0.00002, loss_test:0.07933, lr:5.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.493, tt:3842.117\n",
      "Ep:122, loss:0.00002, loss_test:0.07808, lr:5.36e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.486, tt:3872.811\n",
      "Ep:123, loss:0.00002, loss_test:0.07843, lr:5.31e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.503, tt:3906.324\n",
      "Ep:124, loss:0.00002, loss_test:0.07896, lr:5.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.504, tt:3937.982\n",
      "Ep:125, loss:0.00002, loss_test:0.07899, lr:5.20e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.509, tt:3970.181\n",
      "Ep:126, loss:0.00002, loss_test:0.08005, lr:5.15e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.523, tt:4003.411\n",
      "Ep:127, loss:0.00002, loss_test:0.07700, lr:5.10e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.522, tt:4034.874\n",
      "Ep:128, loss:0.00002, loss_test:0.08054, lr:5.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.519, tt:4065.913\n",
      "Ep:129, loss:0.00002, loss_test:0.07851, lr:5.00e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.513, tt:4096.672\n",
      "Ep:130, loss:0.00002, loss_test:0.07819, lr:4.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.522, tt:4129.326\n",
      "Ep:131, loss:0.00002, loss_test:0.08035, lr:4.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.517, tt:4160.218\n",
      "Ep:132, loss:0.00002, loss_test:0.07747, lr:4.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.512, tt:4191.037\n",
      "Ep:133, loss:0.00002, loss_test:0.07946, lr:4.80e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.499, tt:4220.856\n",
      "Ep:134, loss:0.00002, loss_test:0.07790, lr:4.75e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.491, tt:4251.335\n",
      "Ep:135, loss:0.00002, loss_test:0.07892, lr:4.71e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.500, tt:4284.051\n",
      "Ep:136, loss:0.00002, loss_test:0.07926, lr:4.66e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.499, tt:4315.309\n",
      "Ep:137, loss:0.00002, loss_test:0.07839, lr:4.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.501, tt:4347.093\n",
      "Ep:138, loss:0.00002, loss_test:0.07937, lr:4.57e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.498, tt:4378.236\n",
      "Ep:139, loss:0.00002, loss_test:0.07930, lr:4.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.497, tt:4409.544\n",
      "Ep:140, loss:0.00002, loss_test:0.07932, lr:4.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.495, tt:4440.781\n",
      "Ep:141, loss:0.00002, loss_test:0.08014, lr:4.43e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.491, tt:4471.787\n",
      "Ep:142, loss:0.00002, loss_test:0.07855, lr:4.39e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.492, tt:4503.363\n",
      "Ep:143, loss:0.00002, loss_test:0.07923, lr:4.34e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.499, tt:4535.886\n",
      "Ep:144, loss:0.00002, loss_test:0.07969, lr:4.30e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.508, tt:4568.730\n",
      "Ep:145, loss:0.00002, loss_test:0.07839, lr:4.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.513, tt:4600.908\n",
      "Ep:146, loss:0.00002, loss_test:0.08040, lr:4.21e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.532, tt:4635.168\n",
      "Ep:147, loss:0.00002, loss_test:0.07933, lr:4.17e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.532, tt:4666.784\n",
      "Ep:148, loss:0.00002, loss_test:0.07873, lr:4.13e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.541, tt:4699.604\n",
      "Ep:149, loss:0.00002, loss_test:0.07977, lr:4.09e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.543, tt:4731.415\n",
      "Ep:150, loss:0.00002, loss_test:0.07932, lr:4.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.551, tt:4764.235\n",
      "Ep:151, loss:0.00002, loss_test:0.07999, lr:4.01e-03, fs:0.78857 (r=0.697,p=0.908),  time:31.560, tt:4797.061\n",
      "Ep:152, loss:0.00002, loss_test:0.07918, lr:3.97e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.557, tt:4828.276\n",
      "Ep:153, loss:0.00002, loss_test:0.07990, lr:3.93e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.564, tt:4860.864\n",
      "Ep:154, loss:0.00002, loss_test:0.07860, lr:3.89e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.563, tt:4892.266\n",
      "Ep:155, loss:0.00002, loss_test:0.08027, lr:3.85e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.568, tt:4924.617\n",
      "Ep:156, loss:0.00002, loss_test:0.07954, lr:3.81e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.569, tt:4956.348\n",
      "Ep:157, loss:0.00002, loss_test:0.07928, lr:3.77e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.582, tt:4989.929\n",
      "Ep:158, loss:0.00002, loss_test:0.07993, lr:3.73e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.588, tt:5022.475\n",
      "Ep:159, loss:0.00002, loss_test:0.07905, lr:3.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.595, tt:5055.134\n",
      "Ep:160, loss:0.00002, loss_test:0.08014, lr:3.66e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.602, tt:5087.856\n",
      "Ep:161, loss:0.00002, loss_test:0.07971, lr:3.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.613, tt:5121.279\n",
      "Ep:162, loss:0.00002, loss_test:0.07980, lr:3.59e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.623, tt:5154.598\n",
      "Ep:163, loss:0.00002, loss_test:0.07906, lr:3.55e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.624, tt:5186.316\n",
      "Ep:164, loss:0.00002, loss_test:0.07998, lr:3.52e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.634, tt:5219.659\n",
      "Ep:165, loss:0.00002, loss_test:0.07970, lr:3.48e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.640, tt:5252.320\n",
      "Ep:166, loss:0.00002, loss_test:0.07968, lr:3.45e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.665, tt:5288.045\n",
      "Ep:167, loss:0.00002, loss_test:0.08069, lr:3.41e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.665, tt:5319.708\n",
      "Ep:168, loss:0.00002, loss_test:0.07895, lr:3.38e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.672, tt:5352.594\n",
      "Ep:169, loss:0.00002, loss_test:0.08061, lr:3.34e-03, fs:0.78613 (r=0.687,p=0.919),  time:31.668, tt:5383.605\n",
      "Ep:170, loss:0.00002, loss_test:0.07907, lr:3.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.668, tt:5415.175\n",
      "Ep:171, loss:0.00002, loss_test:0.08071, lr:3.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:31.665, tt:5446.323\n",
      "Ep:172, loss:0.00002, loss_test:0.07868, lr:3.24e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.666, tt:5478.241\n",
      "Ep:173, loss:0.00002, loss_test:0.08090, lr:3.21e-03, fs:0.79070 (r=0.687,p=0.932),  time:31.663, tt:5509.376\n",
      "Ep:174, loss:0.00002, loss_test:0.08088, lr:3.18e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.665, tt:5541.360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:175, loss:0.00002, loss_test:0.08012, lr:3.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.668, tt:5573.639\n",
      "Ep:176, loss:0.00002, loss_test:0.07997, lr:3.12e-03, fs:0.79769 (r=0.697,p=0.932),  time:31.663, tt:5604.402\n",
      "Ep:177, loss:0.00002, loss_test:0.07997, lr:3.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.660, tt:5635.489\n",
      "Ep:178, loss:0.00002, loss_test:0.08049, lr:3.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.665, tt:5668.043\n",
      "Ep:179, loss:0.00001, loss_test:0.07969, lr:3.02e-03, fs:0.80233 (r=0.697,p=0.945),  time:31.661, tt:5699.015\n",
      "Ep:180, loss:0.00001, loss_test:0.08006, lr:2.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.667, tt:5731.807\n",
      "Ep:181, loss:0.00001, loss_test:0.08067, lr:2.96e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.669, tt:5763.786\n",
      "Ep:182, loss:0.00001, loss_test:0.08021, lr:2.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.666, tt:5794.806\n",
      "Ep:183, loss:0.00001, loss_test:0.07950, lr:2.90e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.672, tt:5827.633\n",
      "Ep:184, loss:0.00001, loss_test:0.08064, lr:2.88e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.667, tt:5858.365\n",
      "Ep:185, loss:0.00001, loss_test:0.07971, lr:2.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.664, tt:5889.508\n",
      "Ep:186, loss:0.00001, loss_test:0.08058, lr:2.82e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.665, tt:5921.319\n",
      "Ep:187, loss:0.00001, loss_test:0.07983, lr:2.79e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.684, tt:5956.582\n",
      "Ep:188, loss:0.00001, loss_test:0.08070, lr:2.76e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.686, tt:5988.601\n",
      "Ep:189, loss:0.00001, loss_test:0.08087, lr:2.73e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.681, tt:6019.404\n",
      "Ep:190, loss:0.00001, loss_test:0.07959, lr:2.71e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.682, tt:6051.213\n",
      "Ep:191, loss:0.00001, loss_test:0.08076, lr:2.68e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.685, tt:6083.519\n",
      "Ep:192, loss:0.00001, loss_test:0.08093, lr:2.65e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.685, tt:6115.166\n",
      "Ep:193, loss:0.00001, loss_test:0.07982, lr:2.63e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.688, tt:6147.550\n",
      "Ep:194, loss:0.00001, loss_test:0.08062, lr:2.60e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.696, tt:6180.722\n",
      "Ep:195, loss:0.00001, loss_test:0.08046, lr:2.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.700, tt:6213.105\n",
      "Ep:196, loss:0.00001, loss_test:0.08022, lr:2.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.696, tt:6244.203\n",
      "Ep:197, loss:0.00001, loss_test:0.08063, lr:2.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.684, tt:6273.490\n",
      "Ep:198, loss:0.00001, loss_test:0.08032, lr:2.50e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.679, tt:6304.160\n",
      "Ep:199, loss:0.00001, loss_test:0.08079, lr:2.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.676, tt:6335.133\n",
      "Ep:200, loss:0.00001, loss_test:0.08054, lr:2.45e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.660, tt:6363.620\n",
      "Ep:201, loss:0.00001, loss_test:0.08076, lr:2.42e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.657, tt:6394.698\n",
      "Ep:202, loss:0.00001, loss_test:0.08051, lr:2.40e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.650, tt:6424.965\n",
      "Ep:203, loss:0.00001, loss_test:0.07991, lr:2.38e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.640, tt:6454.509\n",
      "Ep:204, loss:0.00001, loss_test:0.08057, lr:2.35e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.641, tt:6486.445\n",
      "Ep:205, loss:0.00001, loss_test:0.08022, lr:2.33e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.647, tt:6519.309\n",
      "Ep:206, loss:0.00001, loss_test:0.08056, lr:2.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.642, tt:6549.932\n",
      "Ep:207, loss:0.00001, loss_test:0.08095, lr:2.28e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.632, tt:6579.459\n",
      "Ep:208, loss:0.00001, loss_test:0.08048, lr:2.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.613, tt:6607.094\n",
      "Ep:209, loss:0.00001, loss_test:0.08085, lr:2.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.600, tt:6636.004\n",
      "Ep:210, loss:0.00001, loss_test:0.08064, lr:2.21e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.590, tt:6665.543\n",
      "Ep:211, loss:0.00001, loss_test:0.08116, lr:2.19e-03, fs:0.81176 (r=0.697,p=0.972),  time:31.567, tt:6692.172\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02262, lr:6.00e-02, fs:0.60526 (r=0.697,p=0.535),  time:26.742, tt:26.742\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02184, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.768, tt:53.536\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02408, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.627, tt:82.882\n",
      "Ep:3, loss:0.00005, loss_test:0.02515, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.933, tt:111.734\n",
      "Ep:4, loss:0.00005, loss_test:0.02523, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.919, tt:139.594\n",
      "Ep:5, loss:0.00005, loss_test:0.02464, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.708, tt:166.248\n",
      "Ep:6, loss:0.00005, loss_test:0.02359, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.642, tt:193.496\n",
      "Ep:7, loss:0.00005, loss_test:0.02227, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.830, tt:222.643\n",
      "Ep:8, loss:0.00004, loss_test:0.02084, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:28.021, tt:252.185\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01956, lr:6.00e-02, fs:0.68070 (r=0.980,p=0.522),  time:28.164, tt:281.639\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01877, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:28.255, tt:310.801\n",
      "Ep:11, loss:0.00004, loss_test:0.01855, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:28.465, tt:341.580\n",
      "Ep:12, loss:0.00004, loss_test:0.01858, lr:6.00e-02, fs:0.67521 (r=0.798,p=0.585),  time:28.527, tt:370.856\n",
      "Ep:13, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.67556 (r=0.768,p=0.603),  time:28.596, tt:400.343\n",
      "Ep:14, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:28.766, tt:431.494\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.66949 (r=0.798,p=0.577),  time:28.847, tt:461.559\n",
      "Ep:16, loss:0.00003, loss_test:0.01753, lr:6.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:28.954, tt:492.217\n",
      "Ep:17, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:29.251, tt:526.512\n",
      "Ep:18, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:29.328, tt:557.240\n",
      "Ep:19, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:29.392, tt:587.839\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:29.490, tt:619.282\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:29.511, tt:649.248\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:29.548, tt:679.600\n",
      "Ep:23, loss:0.00003, loss_test:0.01653, lr:6.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:29.580, tt:709.916\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:29.588, tt:739.698\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01630, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.610, tt:769.870\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01614, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.685, tt:801.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:29.726, tt:832.333\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.738, tt:862.411\n",
      "Ep:29, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.776, tt:893.282\n",
      "Ep:30, loss:0.00002, loss_test:0.01555, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.787, tt:923.394\n",
      "Ep:31, loss:0.00002, loss_test:0.01545, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:29.815, tt:954.080\n",
      "Ep:32, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:29.840, tt:984.705\n",
      "Ep:33, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:29.792, tt:1012.945\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:29.813, tt:1043.446\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:29.810, tt:1073.175\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:29.834, tt:1103.847\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01497, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:29.859, tt:1134.649\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:29.865, tt:1164.738\n",
      "Ep:39, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:29.900, tt:1195.997\n",
      "Ep:40, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:29.891, tt:1225.511\n",
      "Ep:41, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:29.907, tt:1256.100\n",
      "Ep:42, loss:0.00002, loss_test:0.01469, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:29.950, tt:1287.840\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.972, tt:1318.755\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:29.983, tt:1349.239\n",
      "Ep:45, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:29.973, tt:1378.771\n",
      "Ep:46, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.974, tt:1408.761\n",
      "Ep:47, loss:0.00002, loss_test:0.01450, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:29.960, tt:1438.092\n",
      "Ep:48, loss:0.00002, loss_test:0.01448, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:29.979, tt:1468.987\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:29.998, tt:1499.890\n",
      "Ep:50, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.027, tt:1531.366\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01440, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.012, tt:1560.627\n",
      "Ep:52, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.005, tt:1590.259\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.975, tt:1618.655\n",
      "Ep:54, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.978, tt:1648.790\n",
      "Ep:55, loss:0.00001, loss_test:0.01435, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.979, tt:1678.805\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01435, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.975, tt:1708.593\n",
      "Ep:57, loss:0.00001, loss_test:0.01433, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.982, tt:1738.980\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01432, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:29.982, tt:1768.914\n",
      "Ep:59, loss:0.00001, loss_test:0.01428, lr:6.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.987, tt:1799.249\n",
      "Ep:60, loss:0.00001, loss_test:0.01425, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:29.993, tt:1829.551\n",
      "Ep:61, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.010, tt:1860.603\n",
      "Ep:62, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.003, tt:1890.193\n",
      "Ep:63, loss:0.00001, loss_test:0.01426, lr:6.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:30.002, tt:1920.129\n",
      "Ep:64, loss:0.00001, loss_test:0.01429, lr:6.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:29.987, tt:1949.160\n",
      "Ep:65, loss:0.00001, loss_test:0.01430, lr:6.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:30.010, tt:1980.664\n",
      "Ep:66, loss:0.00001, loss_test:0.01429, lr:6.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.044, tt:2012.972\n",
      "Ep:67, loss:0.00001, loss_test:0.01428, lr:6.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:30.060, tt:2044.079\n",
      "Ep:68, loss:0.00001, loss_test:0.01427, lr:6.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.067, tt:2074.645\n",
      "Ep:69, loss:0.00001, loss_test:0.01426, lr:5.94e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.053, tt:2103.743\n",
      "Ep:70, loss:0.00001, loss_test:0.01426, lr:5.88e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.075, tt:2135.359\n",
      "Ep:71, loss:0.00001, loss_test:0.01425, lr:5.82e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.074, tt:2165.360\n",
      "Ep:72, loss:0.00001, loss_test:0.01427, lr:5.76e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.079, tt:2195.792\n",
      "Ep:73, loss:0.00001, loss_test:0.01427, lr:5.71e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.069, tt:2225.132\n",
      "Ep:74, loss:0.00001, loss_test:0.01426, lr:5.65e-02, fs:0.81053 (r=0.778,p=0.846),  time:30.061, tt:2254.583\n",
      "Ep:75, loss:0.00001, loss_test:0.01426, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.071, tt:2285.399\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01426, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.069, tt:2315.346\n",
      "Ep:77, loss:0.00001, loss_test:0.01427, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.069, tt:2345.399\n",
      "Ep:78, loss:0.00001, loss_test:0.01430, lr:5.59e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.057, tt:2374.482\n",
      "Ep:79, loss:0.00001, loss_test:0.01431, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.056, tt:2404.468\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01433, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.056, tt:2434.511\n",
      "Ep:81, loss:0.00001, loss_test:0.01433, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.077, tt:2466.353\n",
      "Ep:82, loss:0.00001, loss_test:0.01436, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.082, tt:2496.820\n",
      "Ep:83, loss:0.00001, loss_test:0.01438, lr:5.59e-02, fs:0.82353 (r=0.778,p=0.875),  time:30.085, tt:2527.176\n",
      "Ep:84, loss:0.00001, loss_test:0.01441, lr:5.59e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.096, tt:2558.176\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01443, lr:5.59e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.079, tt:2586.826\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01445, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.086, tt:2617.461\n",
      "Ep:87, loss:0.00001, loss_test:0.01447, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.091, tt:2648.017\n",
      "Ep:88, loss:0.00001, loss_test:0.01448, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.107, tt:2679.518\n",
      "Ep:89, loss:0.00001, loss_test:0.01450, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.098, tt:2708.832\n",
      "Ep:90, loss:0.00001, loss_test:0.01452, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.092, tt:2738.363\n",
      "Ep:91, loss:0.00001, loss_test:0.01453, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.082, tt:2767.570\n",
      "Ep:92, loss:0.00001, loss_test:0.01456, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.086, tt:2798.021\n",
      "Ep:93, loss:0.00001, loss_test:0.01460, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.088, tt:2828.299\n",
      "Ep:94, loss:0.00001, loss_test:0.01462, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.087, tt:2858.286\n",
      "Ep:95, loss:0.00001, loss_test:0.01463, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.093, tt:2888.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00001, loss_test:0.01466, lr:5.59e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.099, tt:2919.613\n",
      "Ep:97, loss:0.00001, loss_test:0.01469, lr:5.54e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.100, tt:2949.801\n",
      "Ep:98, loss:0.00001, loss_test:0.01469, lr:5.48e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.102, tt:2980.127\n",
      "Ep:99, loss:0.00001, loss_test:0.01469, lr:5.43e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.108, tt:3010.768\n",
      "Ep:100, loss:0.00001, loss_test:0.01472, lr:5.37e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.119, tt:3041.987\n",
      "Ep:101, loss:0.00001, loss_test:0.01475, lr:5.32e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.122, tt:3072.421\n",
      "Ep:102, loss:0.00001, loss_test:0.01478, lr:5.27e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.126, tt:3103.024\n",
      "Ep:103, loss:0.00001, loss_test:0.01480, lr:5.21e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.116, tt:3132.114\n",
      "Ep:104, loss:0.00001, loss_test:0.01480, lr:5.16e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.130, tt:3163.622\n",
      "Ep:105, loss:0.00001, loss_test:0.01482, lr:5.11e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.127, tt:3193.435\n",
      "Ep:106, loss:0.00001, loss_test:0.01483, lr:5.06e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.139, tt:3224.906\n",
      "Ep:107, loss:0.00001, loss_test:0.01484, lr:5.01e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.110, tt:3251.847\n",
      "Ep:108, loss:0.00001, loss_test:0.01485, lr:4.96e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.103, tt:3281.249\n",
      "Ep:109, loss:0.00001, loss_test:0.01489, lr:4.91e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.110, tt:3312.088\n",
      "Ep:110, loss:0.00001, loss_test:0.01493, lr:4.86e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.113, tt:3342.556\n",
      "Ep:111, loss:0.00001, loss_test:0.01496, lr:4.81e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.105, tt:3371.796\n",
      "Ep:112, loss:0.00001, loss_test:0.01496, lr:4.76e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.107, tt:3402.038\n",
      "Ep:113, loss:0.00001, loss_test:0.01498, lr:4.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.103, tt:3431.697\n",
      "Ep:114, loss:0.00001, loss_test:0.01499, lr:4.67e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.099, tt:3461.430\n",
      "Ep:115, loss:0.00001, loss_test:0.01503, lr:4.62e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.096, tt:3491.113\n",
      "Ep:116, loss:0.00001, loss_test:0.01505, lr:4.57e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.087, tt:3520.211\n",
      "Ep:117, loss:0.00001, loss_test:0.01506, lr:4.53e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.084, tt:3549.870\n",
      "Ep:118, loss:0.00001, loss_test:0.01509, lr:4.48e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.071, tt:3578.497\n",
      "Ep:119, loss:0.00001, loss_test:0.01510, lr:4.44e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.071, tt:3608.572\n",
      "Ep:120, loss:0.00001, loss_test:0.01512, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.066, tt:3637.959\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.01514, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.095, tt:3671.560\n",
      "Ep:122, loss:0.00001, loss_test:0.01517, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.100, tt:3702.324\n",
      "Ep:123, loss:0.00001, loss_test:0.01520, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.097, tt:3732.083\n",
      "Ep:124, loss:0.00001, loss_test:0.01523, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.091, tt:3761.426\n",
      "Ep:125, loss:0.00001, loss_test:0.01525, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.097, tt:3792.198\n",
      "Ep:126, loss:0.00001, loss_test:0.01525, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.087, tt:3821.039\n",
      "Ep:127, loss:0.00001, loss_test:0.01527, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.085, tt:3850.865\n",
      "Ep:128, loss:0.00001, loss_test:0.01531, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.085, tt:3880.912\n",
      "Ep:129, loss:0.00001, loss_test:0.01531, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.088, tt:3911.505\n",
      "Ep:130, loss:0.00001, loss_test:0.01533, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.101, tt:3943.259\n",
      "Ep:131, loss:0.00001, loss_test:0.01536, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.100, tt:3973.244\n",
      "Ep:132, loss:0.00001, loss_test:0.01539, lr:4.35e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.079, tt:4000.530\n",
      "Ep:133, loss:0.00001, loss_test:0.01542, lr:4.31e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.090, tt:4032.070\n",
      "Ep:134, loss:0.00001, loss_test:0.01543, lr:4.26e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.111, tt:4064.948\n",
      "Ep:135, loss:0.00001, loss_test:0.01545, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.109, tt:4094.883\n",
      "Ep:136, loss:0.00001, loss_test:0.01547, lr:4.18e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.101, tt:4123.902\n",
      "Ep:137, loss:0.00001, loss_test:0.01548, lr:4.14e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.102, tt:4154.088\n",
      "Ep:138, loss:0.00001, loss_test:0.01549, lr:4.10e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.098, tt:4183.632\n",
      "Ep:139, loss:0.00001, loss_test:0.01550, lr:4.05e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.095, tt:4213.259\n",
      "Ep:140, loss:0.00001, loss_test:0.01552, lr:4.01e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.096, tt:4243.584\n",
      "Ep:141, loss:0.00001, loss_test:0.01554, lr:3.97e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.092, tt:4273.115\n",
      "Ep:142, loss:0.00001, loss_test:0.01557, lr:3.93e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.092, tt:4303.211\n",
      "Ep:143, loss:0.00001, loss_test:0.01559, lr:3.89e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.111, tt:4336.054\n",
      "Ep:144, loss:0.00001, loss_test:0.01562, lr:3.86e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.115, tt:4366.717\n",
      "Ep:145, loss:0.00001, loss_test:0.01564, lr:3.82e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.119, tt:4397.371\n",
      "Ep:146, loss:0.00000, loss_test:0.01566, lr:3.78e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.119, tt:4427.474\n",
      "Ep:147, loss:0.00000, loss_test:0.01567, lr:3.74e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.128, tt:4458.908\n",
      "Ep:148, loss:0.00000, loss_test:0.01569, lr:3.70e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.139, tt:4490.784\n",
      "Ep:149, loss:0.00000, loss_test:0.01571, lr:3.67e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.143, tt:4521.423\n",
      "Ep:150, loss:0.00000, loss_test:0.01572, lr:3.63e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.152, tt:4552.909\n",
      "Ep:151, loss:0.00000, loss_test:0.01572, lr:3.59e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.155, tt:4583.564\n",
      "Ep:152, loss:0.00000, loss_test:0.01574, lr:3.56e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.147, tt:4612.431\n",
      "Ep:153, loss:0.00000, loss_test:0.01575, lr:3.52e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.148, tt:4642.862\n",
      "Ep:154, loss:0.00000, loss_test:0.01576, lr:3.49e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.142, tt:4672.014\n",
      "Ep:155, loss:0.00000, loss_test:0.01578, lr:3.45e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.144, tt:4702.409\n",
      "Ep:156, loss:0.00000, loss_test:0.01580, lr:3.42e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.136, tt:4731.332\n",
      "Ep:157, loss:0.00000, loss_test:0.01581, lr:3.38e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.142, tt:4762.509\n",
      "Ep:158, loss:0.00000, loss_test:0.01582, lr:3.35e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.130, tt:4790.716\n",
      "Ep:159, loss:0.00000, loss_test:0.01583, lr:3.32e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.132, tt:4821.062\n",
      "Ep:160, loss:0.00000, loss_test:0.01586, lr:3.28e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.120, tt:4849.268\n",
      "Ep:161, loss:0.00000, loss_test:0.01587, lr:3.25e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.127, tt:4880.507\n",
      "Ep:162, loss:0.00000, loss_test:0.01589, lr:3.22e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.129, tt:4911.055\n",
      "Ep:163, loss:0.00000, loss_test:0.01590, lr:3.19e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.132, tt:4941.714\n",
      "Ep:164, loss:0.00000, loss_test:0.01591, lr:3.15e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.125, tt:4970.612\n",
      "Ep:165, loss:0.00000, loss_test:0.01593, lr:3.12e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.117, tt:4999.416\n",
      "Ep:166, loss:0.00000, loss_test:0.01594, lr:3.09e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.116, tt:5029.422\n",
      "Ep:167, loss:0.00000, loss_test:0.01595, lr:3.06e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.106, tt:5057.850\n",
      "Ep:168, loss:0.00000, loss_test:0.01597, lr:3.03e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.105, tt:5087.821\n",
      "Ep:169, loss:0.00000, loss_test:0.01599, lr:3.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.103, tt:5117.556\n",
      "Ep:170, loss:0.00000, loss_test:0.01601, lr:2.97e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.105, tt:5147.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:171, loss:0.00000, loss_test:0.01603, lr:2.94e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.111, tt:5179.074\n",
      "Ep:172, loss:0.00000, loss_test:0.01603, lr:2.91e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.112, tt:5209.377\n",
      "Ep:173, loss:0.00000, loss_test:0.01605, lr:2.88e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.116, tt:5240.260\n",
      "Ep:174, loss:0.00000, loss_test:0.01605, lr:2.85e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.129, tt:5272.580\n",
      "Ep:175, loss:0.00000, loss_test:0.01608, lr:2.82e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.132, tt:5303.256\n",
      "Ep:176, loss:0.00000, loss_test:0.01609, lr:2.80e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.134, tt:5333.786\n",
      "Ep:177, loss:0.00000, loss_test:0.01610, lr:2.77e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.133, tt:5363.654\n",
      "Ep:178, loss:0.00000, loss_test:0.01610, lr:2.74e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.138, tt:5394.676\n",
      "Ep:179, loss:0.00000, loss_test:0.01611, lr:2.71e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.147, tt:5426.432\n",
      "Ep:180, loss:0.00000, loss_test:0.01612, lr:2.69e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.146, tt:5456.407\n",
      "Ep:181, loss:0.00000, loss_test:0.01614, lr:2.66e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.165, tt:5490.028\n",
      "Ep:182, loss:0.00000, loss_test:0.01615, lr:2.63e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.163, tt:5519.843\n",
      "Ep:183, loss:0.00000, loss_test:0.01616, lr:2.61e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.165, tt:5550.420\n",
      "Ep:184, loss:0.00000, loss_test:0.01617, lr:2.58e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.156, tt:5578.939\n",
      "Ep:185, loss:0.00000, loss_test:0.01618, lr:2.55e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.153, tt:5608.427\n",
      "Ep:186, loss:0.00000, loss_test:0.01619, lr:2.53e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.152, tt:5638.446\n",
      "Ep:187, loss:0.00000, loss_test:0.01620, lr:2.50e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.151, tt:5668.405\n",
      "Ep:188, loss:0.00000, loss_test:0.01621, lr:2.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.143, tt:5696.943\n",
      "Ep:189, loss:0.00000, loss_test:0.01623, lr:2.45e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.143, tt:5727.098\n",
      "Ep:190, loss:0.00000, loss_test:0.01623, lr:2.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.140, tt:5756.680\n",
      "Ep:191, loss:0.00000, loss_test:0.01624, lr:2.40e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.144, tt:5787.563\n",
      "Ep:192, loss:0.00000, loss_test:0.01625, lr:2.38e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.139, tt:5816.816\n",
      "Ep:193, loss:0.00000, loss_test:0.01626, lr:2.36e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.141, tt:5847.439\n",
      "Ep:194, loss:0.00000, loss_test:0.01628, lr:2.33e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.140, tt:5877.226\n",
      "Ep:195, loss:0.00000, loss_test:0.01628, lr:2.31e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.142, tt:5907.847\n",
      "Ep:196, loss:0.00000, loss_test:0.01629, lr:2.29e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.137, tt:5937.000\n",
      "Ep:197, loss:0.00000, loss_test:0.01631, lr:2.26e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.132, tt:5966.087\n",
      "Ep:198, loss:0.00000, loss_test:0.01633, lr:2.24e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.120, tt:5993.930\n",
      "Ep:199, loss:0.00000, loss_test:0.01634, lr:2.22e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.129, tt:6025.773\n",
      "Ep:200, loss:0.00000, loss_test:0.01635, lr:2.20e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.111, tt:6052.404\n",
      "Ep:201, loss:0.00000, loss_test:0.01636, lr:2.17e-02, fs:0.83333 (r=0.758,p=0.926),  time:30.085, tt:6077.138\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13995, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.873, tt:25.873\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13855, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.020, tt:56.039\n",
      "Ep:2, loss:0.00027, loss_test:0.13624, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:28.738, tt:86.214\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13271, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:28.907, tt:115.627\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12746, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:29.565, tt:147.824\n",
      "Ep:5, loss:0.00025, loss_test:0.12093, lr:1.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:30.073, tt:180.435\n",
      "Ep:6, loss:0.00024, loss_test:0.11460, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:30.282, tt:211.974\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11190, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:30.020, tt:240.158\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11031, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:30.141, tt:271.267\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10986, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:30.152, tt:301.516\n",
      "Ep:10, loss:0.00021, loss_test:0.10639, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:30.340, tt:333.739\n",
      "Ep:11, loss:0.00020, loss_test:0.10191, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:30.413, tt:364.950\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09933, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:30.655, tt:398.514\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09679, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:30.637, tt:428.916\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09524, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:30.654, tt:459.817\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09362, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.714, tt:491.425\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09223, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.782, tt:523.290\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09056, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.915, tt:556.467\n",
      "Ep:18, loss:0.00016, loss_test:0.08893, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.995, tt:588.914\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08741, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:31.084, tt:621.671\n",
      "Ep:20, loss:0.00015, loss_test:0.08620, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.038, tt:651.794\n",
      "Ep:21, loss:0.00015, loss_test:0.08449, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:31.063, tt:683.389\n",
      "Ep:22, loss:0.00014, loss_test:0.08313, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.162, tt:716.721\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08239, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:31.195, tt:748.678\n",
      "Ep:24, loss:0.00013, loss_test:0.08066, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:31.142, tt:778.561\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07909, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:31.117, tt:809.052\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.07795, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.169, tt:841.574\n",
      "Ep:27, loss:0.00012, loss_test:0.07687, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.198, tt:873.549\n",
      "Ep:28, loss:0.00012, loss_test:0.07547, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.234, tt:905.779\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.07473, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:31.208, tt:936.232\n",
      "Ep:30, loss:0.00011, loss_test:0.07422, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.324, tt:971.031\n",
      "Ep:31, loss:0.00011, loss_test:0.07273, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.349, tt:1003.155\n",
      "Ep:32, loss:0.00010, loss_test:0.07239, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.373, tt:1035.311\n",
      "Ep:33, loss:0.00010, loss_test:0.07143, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.399, tt:1067.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00010, loss_test:0.07061, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.422, tt:1099.763\n",
      "Ep:35, loss:0.00009, loss_test:0.07032, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.419, tt:1131.070\n",
      "Ep:36, loss:0.00009, loss_test:0.06955, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.447, tt:1163.557\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.06886, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.455, tt:1195.288\n",
      "Ep:38, loss:0.00009, loss_test:0.06860, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:31.439, tt:1226.119\n",
      "Ep:39, loss:0.00008, loss_test:0.06778, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.454, tt:1258.170\n",
      "Ep:40, loss:0.00008, loss_test:0.06765, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.486, tt:1290.914\n",
      "Ep:41, loss:0.00008, loss_test:0.06693, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.512, tt:1323.525\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06668, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.526, tt:1355.638\n",
      "Ep:43, loss:0.00007, loss_test:0.06660, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:31.496, tt:1385.843\n",
      "Ep:44, loss:0.00007, loss_test:0.06561, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:31.533, tt:1418.990\n",
      "Ep:45, loss:0.00007, loss_test:0.06580, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.546, tt:1451.097\n",
      "Ep:46, loss:0.00007, loss_test:0.06562, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.572, tt:1483.876\n",
      "Ep:47, loss:0.00007, loss_test:0.06439, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:31.599, tt:1516.772\n",
      "Ep:48, loss:0.00007, loss_test:0.06473, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.596, tt:1548.184\n",
      "Ep:49, loss:0.00006, loss_test:0.06449, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.603, tt:1580.167\n",
      "Ep:50, loss:0.00006, loss_test:0.06379, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:31.615, tt:1612.387\n",
      "Ep:51, loss:0.00006, loss_test:0.06365, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.594, tt:1642.874\n",
      "Ep:52, loss:0.00006, loss_test:0.06361, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.616, tt:1675.669\n",
      "Ep:53, loss:0.00006, loss_test:0.06273, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.625, tt:1707.765\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.06303, lr:9.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.661, tt:1741.356\n",
      "Ep:55, loss:0.00006, loss_test:0.06251, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.667, tt:1773.374\n",
      "Ep:56, loss:0.00005, loss_test:0.06248, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.688, tt:1806.234\n",
      "Ep:57, loss:0.00005, loss_test:0.06211, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.680, tt:1837.427\n",
      "Ep:58, loss:0.00005, loss_test:0.06183, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.694, tt:1869.971\n",
      "Ep:59, loss:0.00005, loss_test:0.06177, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.702, tt:1902.135\n",
      "Ep:60, loss:0.00005, loss_test:0.06137, lr:9.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.723, tt:1935.130\n",
      "Ep:61, loss:0.00005, loss_test:0.06135, lr:9.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.729, tt:1967.197\n",
      "Ep:62, loss:0.00005, loss_test:0.06104, lr:9.90e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.740, tt:1999.608\n",
      "Ep:63, loss:0.00005, loss_test:0.06127, lr:9.90e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.719, tt:2029.996\n",
      "Ep:64, loss:0.00005, loss_test:0.06126, lr:9.90e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.683, tt:2059.423\n",
      "Ep:65, loss:0.00004, loss_test:0.06120, lr:9.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:31.709, tt:2092.784\n",
      "Ep:66, loss:0.00004, loss_test:0.06016, lr:9.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.700, tt:2123.905\n",
      "Ep:67, loss:0.00004, loss_test:0.06101, lr:9.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.701, tt:2155.692\n",
      "Ep:68, loss:0.00004, loss_test:0.06017, lr:9.51e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.699, tt:2187.219\n",
      "Ep:69, loss:0.00004, loss_test:0.06030, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.697, tt:2218.762\n",
      "Ep:70, loss:0.00004, loss_test:0.06079, lr:9.32e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.705, tt:2251.052\n",
      "Ep:71, loss:0.00004, loss_test:0.05965, lr:9.23e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.697, tt:2282.155\n",
      "Ep:72, loss:0.00004, loss_test:0.05993, lr:9.14e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.678, tt:2312.511\n",
      "Ep:73, loss:0.00004, loss_test:0.06088, lr:9.04e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.694, tt:2345.389\n",
      "Ep:74, loss:0.00004, loss_test:0.05985, lr:8.95e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.693, tt:2376.976\n",
      "Ep:75, loss:0.00004, loss_test:0.05941, lr:8.86e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.694, tt:2408.777\n",
      "Ep:76, loss:0.00004, loss_test:0.06001, lr:8.78e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.679, tt:2439.252\n",
      "Ep:77, loss:0.00003, loss_test:0.05963, lr:8.69e-03, fs:0.82022 (r=0.737,p=0.924),  time:31.685, tt:2471.451\n",
      "Ep:78, loss:0.00003, loss_test:0.05943, lr:8.60e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.685, tt:2503.094\n",
      "Ep:79, loss:0.00003, loss_test:0.05992, lr:8.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.689, tt:2535.106\n",
      "Ep:80, loss:0.00003, loss_test:0.05939, lr:8.43e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.689, tt:2566.815\n",
      "Ep:81, loss:0.00003, loss_test:0.05967, lr:8.35e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.694, tt:2598.885\n",
      "Ep:82, loss:0.00003, loss_test:0.05974, lr:8.26e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.702, tt:2631.244\n",
      "Ep:83, loss:0.00003, loss_test:0.05908, lr:8.18e-03, fs:0.80226 (r=0.717,p=0.910),  time:31.690, tt:2661.967\n",
      "Ep:84, loss:0.00003, loss_test:0.05955, lr:8.10e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.693, tt:2693.910\n",
      "Ep:85, loss:0.00003, loss_test:0.05951, lr:8.02e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.701, tt:2726.286\n",
      "Ep:86, loss:0.00003, loss_test:0.05962, lr:7.94e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.702, tt:2758.061\n",
      "Ep:87, loss:0.00003, loss_test:0.05916, lr:7.86e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.682, tt:2788.013\n",
      "Ep:88, loss:0.00003, loss_test:0.05944, lr:7.78e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.670, tt:2818.628\n",
      "Ep:89, loss:0.00003, loss_test:0.05994, lr:7.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.672, tt:2850.516\n",
      "Ep:90, loss:0.00003, loss_test:0.05902, lr:7.62e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.681, tt:2882.987\n",
      "Ep:91, loss:0.00003, loss_test:0.05974, lr:7.55e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.680, tt:2914.520\n",
      "Ep:92, loss:0.00003, loss_test:0.05946, lr:7.47e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.685, tt:2946.707\n",
      "Ep:93, loss:0.00003, loss_test:0.05939, lr:7.40e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.689, tt:2978.750\n",
      "Ep:94, loss:0.00003, loss_test:0.05963, lr:7.32e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.684, tt:3009.966\n",
      "Ep:95, loss:0.00003, loss_test:0.05920, lr:7.25e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.681, tt:3041.329\n",
      "Ep:96, loss:0.00003, loss_test:0.05948, lr:7.18e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.683, tt:3073.292\n",
      "Ep:97, loss:0.00003, loss_test:0.05939, lr:7.11e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.694, tt:3106.028\n",
      "Ep:98, loss:0.00003, loss_test:0.05921, lr:7.03e-03, fs:0.79545 (r=0.707,p=0.909),  time:31.696, tt:3137.934\n",
      "Ep:99, loss:0.00002, loss_test:0.05954, lr:6.96e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.695, tt:3169.537\n",
      "Ep:100, loss:0.00002, loss_test:0.05922, lr:6.89e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.702, tt:3201.895\n",
      "Ep:101, loss:0.00002, loss_test:0.05958, lr:6.83e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.704, tt:3233.835\n",
      "Ep:102, loss:0.00002, loss_test:0.05958, lr:6.76e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.699, tt:3264.993\n",
      "Ep:103, loss:0.00002, loss_test:0.05912, lr:6.69e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.703, tt:3297.128\n",
      "Ep:104, loss:0.00002, loss_test:0.05957, lr:6.62e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.723, tt:3330.956\n",
      "Ep:105, loss:0.00002, loss_test:0.05949, lr:6.56e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.711, tt:3361.320\n",
      "Ep:106, loss:0.00002, loss_test:0.05938, lr:6.49e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.692, tt:3391.022\n",
      "Ep:107, loss:0.00002, loss_test:0.05976, lr:6.43e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.687, tt:3422.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00002, loss_test:0.05914, lr:6.36e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.687, tt:3453.910\n",
      "Ep:109, loss:0.00002, loss_test:0.05932, lr:6.30e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.680, tt:3484.757\n",
      "Ep:110, loss:0.00002, loss_test:0.05980, lr:6.24e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.675, tt:3515.927\n",
      "Ep:111, loss:0.00002, loss_test:0.05932, lr:6.17e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.672, tt:3547.218\n",
      "Ep:112, loss:0.00002, loss_test:0.05905, lr:6.11e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.671, tt:3578.791\n",
      "Ep:113, loss:0.00002, loss_test:0.05973, lr:6.05e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.664, tt:3609.735\n",
      "Ep:114, loss:0.00002, loss_test:0.05935, lr:5.99e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.677, tt:3642.799\n",
      "Ep:115, loss:0.00002, loss_test:0.05909, lr:5.93e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.688, tt:3675.798\n",
      "Ep:116, loss:0.00002, loss_test:0.05960, lr:5.87e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.696, tt:3708.441\n",
      "Ep:117, loss:0.00002, loss_test:0.05928, lr:5.81e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.690, tt:3739.388\n",
      "Ep:118, loss:0.00002, loss_test:0.05945, lr:5.75e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.695, tt:3771.719\n",
      "Ep:119, loss:0.00002, loss_test:0.05936, lr:5.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.695, tt:3803.354\n",
      "Ep:120, loss:0.00002, loss_test:0.05925, lr:5.64e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.684, tt:3833.775\n",
      "Ep:121, loss:0.00002, loss_test:0.05951, lr:5.58e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.659, tt:3862.439\n",
      "Ep:122, loss:0.00002, loss_test:0.05947, lr:5.53e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.643, tt:3892.118\n",
      "Ep:123, loss:0.00002, loss_test:0.05923, lr:5.47e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.640, tt:3923.405\n",
      "Ep:124, loss:0.00002, loss_test:0.05953, lr:5.42e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.634, tt:3954.212\n",
      "Ep:125, loss:0.00002, loss_test:0.05922, lr:5.36e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.633, tt:3985.719\n",
      "Ep:126, loss:0.00002, loss_test:0.05971, lr:5.31e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.629, tt:4016.886\n",
      "Ep:127, loss:0.00002, loss_test:0.05949, lr:5.26e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.625, tt:4048.030\n",
      "Ep:128, loss:0.00002, loss_test:0.05912, lr:5.20e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.632, tt:4080.564\n",
      "Ep:129, loss:0.00002, loss_test:0.05960, lr:5.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.625, tt:4111.311\n",
      "Ep:130, loss:0.00002, loss_test:0.05925, lr:5.10e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.629, tt:4143.334\n",
      "Ep:131, loss:0.00002, loss_test:0.05931, lr:5.05e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.623, tt:4174.269\n",
      "Ep:132, loss:0.00002, loss_test:0.05957, lr:5.00e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.631, tt:4206.923\n",
      "Ep:133, loss:0.00002, loss_test:0.05900, lr:4.95e-03, fs:0.80000 (r=0.707,p=0.921),  time:31.631, tt:4238.556\n",
      "Ep:134, loss:0.00002, loss_test:0.05968, lr:4.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.635, tt:4270.711\n",
      "Ep:135, loss:0.00002, loss_test:0.05949, lr:4.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.644, tt:4303.583\n",
      "Ep:136, loss:0.00002, loss_test:0.05932, lr:4.80e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.655, tt:4336.690\n",
      "Ep:137, loss:0.00002, loss_test:0.05931, lr:4.75e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.650, tt:4367.716\n",
      "Ep:138, loss:0.00002, loss_test:0.05908, lr:4.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.677, tt:4403.088\n",
      "Ep:139, loss:0.00002, loss_test:0.05936, lr:4.66e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.690, tt:4436.539\n",
      "Ep:140, loss:0.00002, loss_test:0.05922, lr:4.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.698, tt:4469.442\n",
      "Ep:141, loss:0.00002, loss_test:0.05914, lr:4.57e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.696, tt:4500.865\n",
      "Ep:142, loss:0.00002, loss_test:0.05946, lr:4.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.701, tt:4533.274\n",
      "Ep:143, loss:0.00002, loss_test:0.05916, lr:4.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.700, tt:4564.870\n",
      "Ep:144, loss:0.00002, loss_test:0.05922, lr:4.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.697, tt:4596.126\n",
      "Ep:145, loss:0.00002, loss_test:0.05924, lr:4.39e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.689, tt:4626.657\n",
      "Ep:146, loss:0.00002, loss_test:0.05947, lr:4.34e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.690, tt:4658.423\n",
      "Ep:147, loss:0.00002, loss_test:0.05917, lr:4.30e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.696, tt:4691.013\n",
      "Ep:148, loss:0.00002, loss_test:0.05928, lr:4.26e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.707, tt:4724.416\n",
      "Ep:149, loss:0.00002, loss_test:0.05919, lr:4.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.711, tt:4756.642\n",
      "Ep:150, loss:0.00002, loss_test:0.05912, lr:4.17e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.711, tt:4788.422\n",
      "Ep:151, loss:0.00002, loss_test:0.05938, lr:4.13e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.724, tt:4822.082\n",
      "Ep:152, loss:0.00002, loss_test:0.05906, lr:4.09e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.735, tt:4855.417\n",
      "Ep:153, loss:0.00002, loss_test:0.05939, lr:4.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.743, tt:4888.396\n",
      "Ep:154, loss:0.00002, loss_test:0.05918, lr:4.01e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.750, tt:4921.327\n",
      "Ep:155, loss:0.00002, loss_test:0.05936, lr:3.97e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.756, tt:4953.991\n",
      "Ep:156, loss:0.00002, loss_test:0.05947, lr:3.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.773, tt:4988.379\n",
      "Ep:157, loss:0.00002, loss_test:0.05898, lr:3.89e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.788, tt:5022.430\n",
      "Ep:158, loss:0.00002, loss_test:0.05943, lr:3.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.793, tt:5055.025\n",
      "Ep:159, loss:0.00002, loss_test:0.05968, lr:3.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.790, tt:5086.320\n",
      "Ep:160, loss:0.00002, loss_test:0.05918, lr:3.77e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.798, tt:5119.431\n",
      "Ep:161, loss:0.00001, loss_test:0.05918, lr:3.73e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.790, tt:5149.926\n",
      "Ep:162, loss:0.00001, loss_test:0.05944, lr:3.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.787, tt:5181.233\n",
      "Ep:163, loss:0.00001, loss_test:0.05942, lr:3.66e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.793, tt:5214.024\n",
      "Ep:164, loss:0.00001, loss_test:0.05935, lr:3.62e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.800, tt:5246.991\n",
      "Ep:165, loss:0.00001, loss_test:0.05946, lr:3.59e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.802, tt:5279.182\n",
      "Ep:166, loss:0.00001, loss_test:0.05942, lr:3.55e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.807, tt:5311.807\n",
      "Ep:167, loss:0.00001, loss_test:0.05943, lr:3.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.806, tt:5343.440\n",
      "Ep:168, loss:0.00001, loss_test:0.05954, lr:3.48e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.809, tt:5375.660\n",
      "Ep:169, loss:0.00001, loss_test:0.05929, lr:3.45e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.809, tt:5407.496\n",
      "Ep:170, loss:0.00001, loss_test:0.05939, lr:3.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.817, tt:5440.735\n",
      "Ep:171, loss:0.00001, loss_test:0.05975, lr:3.38e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.827, tt:5474.236\n",
      "Ep:172, loss:0.00001, loss_test:0.05949, lr:3.34e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.825, tt:5505.805\n",
      "Ep:173, loss:0.00001, loss_test:0.05930, lr:3.31e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.823, tt:5537.271\n",
      "Ep:174, loss:0.00001, loss_test:0.05960, lr:3.28e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.826, tt:5569.615\n",
      "Ep:175, loss:0.00001, loss_test:0.05957, lr:3.24e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.840, tt:5603.774\n",
      "Ep:176, loss:0.00001, loss_test:0.05929, lr:3.21e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.851, tt:5637.652\n",
      "Ep:177, loss:0.00001, loss_test:0.05937, lr:3.18e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.856, tt:5670.436\n",
      "Ep:178, loss:0.00001, loss_test:0.05943, lr:3.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.861, tt:5703.088\n",
      "Ep:179, loss:0.00001, loss_test:0.05925, lr:3.12e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.861, tt:5734.940\n",
      "Ep:180, loss:0.00001, loss_test:0.05954, lr:3.09e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.866, tt:5767.824\n",
      "Ep:181, loss:0.00001, loss_test:0.05961, lr:3.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.869, tt:5800.088\n",
      "Ep:182, loss:0.00001, loss_test:0.05942, lr:3.02e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.879, tt:5833.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00001, loss_test:0.05945, lr:2.99e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.881, tt:5866.026\n",
      "Ep:184, loss:0.00001, loss_test:0.05955, lr:2.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.881, tt:5898.057\n",
      "Ep:185, loss:0.00001, loss_test:0.05944, lr:2.93e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.879, tt:5929.508\n",
      "Ep:186, loss:0.00001, loss_test:0.05948, lr:2.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.879, tt:5961.370\n",
      "Ep:187, loss:0.00001, loss_test:0.05952, lr:2.88e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.876, tt:5992.597\n",
      "Ep:188, loss:0.00001, loss_test:0.05949, lr:2.85e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.870, tt:6023.341\n",
      "Ep:189, loss:0.00001, loss_test:0.05948, lr:2.82e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.872, tt:6055.642\n",
      "Ep:190, loss:0.00001, loss_test:0.05958, lr:2.79e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.863, tt:6085.773\n",
      "Ep:191, loss:0.00001, loss_test:0.05945, lr:2.76e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.862, tt:6117.560\n",
      "Ep:192, loss:0.00001, loss_test:0.05958, lr:2.73e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.860, tt:6149.011\n",
      "Ep:193, loss:0.00001, loss_test:0.05968, lr:2.71e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.866, tt:6181.930\n",
      "Ep:194, loss:0.00001, loss_test:0.05958, lr:2.68e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.862, tt:6213.017\n",
      "Ep:195, loss:0.00001, loss_test:0.05971, lr:2.65e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.857, tt:6244.068\n",
      "Ep:196, loss:0.00001, loss_test:0.05979, lr:2.63e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.847, tt:6273.943\n",
      "Ep:197, loss:0.00001, loss_test:0.05961, lr:2.60e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.842, tt:6304.654\n",
      "Ep:198, loss:0.00001, loss_test:0.05967, lr:2.57e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.829, tt:6333.948\n",
      "Ep:199, loss:0.00001, loss_test:0.05963, lr:2.55e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.804, tt:6360.868\n",
      "Ep:200, loss:0.00001, loss_test:0.05960, lr:2.52e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.784, tt:6388.628\n",
      "Ep:201, loss:0.00001, loss_test:0.05961, lr:2.50e-03, fs:0.79310 (r=0.697,p=0.920),  time:31.756, tt:6414.775\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02120, lr:6.00e-02, fs:0.60729 (r=0.758,p=0.507),  time:21.771, tt:21.771\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02189, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.966, tt:41.932\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02312, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.652, tt:64.957\n",
      "Ep:3, loss:0.00004, loss_test:0.02304, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.085, tt:88.341\n",
      "Ep:4, loss:0.00004, loss_test:0.02221, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.917, tt:114.584\n",
      "Ep:5, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:23.410, tt:140.460\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01982, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:23.579, tt:165.051\n",
      "Ep:7, loss:0.00004, loss_test:0.01929, lr:6.00e-02, fs:0.63900 (r=0.778,p=0.542),  time:23.765, tt:190.122\n",
      "Ep:8, loss:0.00004, loss_test:0.01963, lr:6.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:23.771, tt:213.942\n",
      "Ep:9, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:23.848, tt:238.476\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01924, lr:6.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:23.978, tt:263.763\n",
      "Ep:11, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:24.133, tt:289.598\n",
      "Ep:12, loss:0.00003, loss_test:0.01833, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:24.274, tt:315.556\n",
      "Ep:13, loss:0.00003, loss_test:0.01813, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:24.374, tt:341.242\n",
      "Ep:14, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:24.402, tt:366.026\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01760, lr:6.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:24.440, tt:391.043\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01747, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:24.519, tt:416.825\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01740, lr:6.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:24.606, tt:442.911\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:24.643, tt:468.216\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:24.721, tt:494.422\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01681, lr:6.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:24.758, tt:519.918\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01664, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:24.758, tt:544.679\n",
      "Ep:22, loss:0.00003, loss_test:0.01654, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:24.763, tt:569.546\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01650, lr:6.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:24.797, tt:595.120\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01648, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:24.822, tt:620.554\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01638, lr:6.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:24.862, tt:646.416\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01621, lr:6.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:24.898, tt:672.233\n",
      "Ep:27, loss:0.00002, loss_test:0.01599, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:24.946, tt:698.487\n",
      "Ep:28, loss:0.00002, loss_test:0.01581, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:24.975, tt:724.265\n",
      "Ep:29, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:24.989, tt:749.679\n",
      "Ep:30, loss:0.00002, loss_test:0.01552, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:25.043, tt:776.342\n",
      "Ep:31, loss:0.00002, loss_test:0.01542, lr:6.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:25.083, tt:802.649\n",
      "Ep:32, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:25.106, tt:828.512\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:25.111, tt:853.775\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:25.130, tt:879.565\n",
      "Ep:35, loss:0.00002, loss_test:0.01501, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:25.167, tt:906.000\n",
      "Ep:36, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:25.206, tt:932.611\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:25.227, tt:958.616\n",
      "Ep:38, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:25.258, tt:985.043\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01471, lr:6.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:25.272, tt:1010.888\n",
      "Ep:40, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:25.293, tt:1037.023\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:25.306, tt:1062.849\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:25.321, tt:1088.809\n",
      "Ep:43, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:25.338, tt:1114.891\n",
      "Ep:44, loss:0.00002, loss_test:0.01429, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:25.363, tt:1141.322\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01423, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:25.392, tt:1168.054\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:25.400, tt:1193.798\n",
      "Ep:47, loss:0.00002, loss_test:0.01413, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:25.398, tt:1219.117\n",
      "Ep:48, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:25.380, tt:1243.629\n",
      "Ep:49, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:25.381, tt:1269.056\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:25.406, tt:1295.717\n",
      "Ep:51, loss:0.00001, loss_test:0.01389, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:25.405, tt:1321.080\n",
      "Ep:52, loss:0.00001, loss_test:0.01390, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.459, tt:1349.307\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01383, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.462, tt:1374.972\n",
      "Ep:54, loss:0.00001, loss_test:0.01373, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:25.467, tt:1400.699\n",
      "Ep:55, loss:0.00001, loss_test:0.01368, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:25.489, tt:1427.387\n",
      "Ep:56, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.514, tt:1454.273\n",
      "Ep:57, loss:0.00001, loss_test:0.01361, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.541, tt:1481.360\n",
      "Ep:58, loss:0.00001, loss_test:0.01358, lr:6.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:25.564, tt:1508.260\n",
      "Ep:59, loss:0.00001, loss_test:0.01357, lr:6.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:25.582, tt:1534.903\n",
      "Ep:60, loss:0.00001, loss_test:0.01353, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.597, tt:1561.398\n",
      "Ep:61, loss:0.00001, loss_test:0.01348, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.599, tt:1587.149\n",
      "Ep:62, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.601, tt:1612.872\n",
      "Ep:63, loss:0.00001, loss_test:0.01345, lr:6.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:25.605, tt:1638.746\n",
      "Ep:64, loss:0.00001, loss_test:0.01342, lr:5.94e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.624, tt:1665.553\n",
      "Ep:65, loss:0.00001, loss_test:0.01338, lr:5.88e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.634, tt:1691.853\n",
      "Ep:66, loss:0.00001, loss_test:0.01337, lr:5.82e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.647, tt:1718.334\n",
      "Ep:67, loss:0.00001, loss_test:0.01338, lr:5.76e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.649, tt:1744.139\n",
      "Ep:68, loss:0.00001, loss_test:0.01340, lr:5.71e-02, fs:0.80203 (r=0.798,p=0.806),  time:25.650, tt:1769.869\n",
      "Ep:69, loss:0.00001, loss_test:0.01340, lr:5.65e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.669, tt:1796.812\n",
      "Ep:70, loss:0.00001, loss_test:0.01337, lr:5.59e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.674, tt:1822.871\n",
      "Ep:71, loss:0.00001, loss_test:0.01334, lr:5.54e-02, fs:0.79592 (r=0.788,p=0.804),  time:25.676, tt:1848.651\n",
      "Ep:72, loss:0.00001, loss_test:0.01330, lr:5.48e-02, fs:0.78974 (r=0.778,p=0.802),  time:25.678, tt:1874.530\n",
      "Ep:73, loss:0.00001, loss_test:0.01332, lr:5.43e-02, fs:0.78974 (r=0.778,p=0.802),  time:25.665, tt:1899.237\n",
      "Ep:74, loss:0.00001, loss_test:0.01336, lr:5.37e-02, fs:0.78756 (r=0.768,p=0.809),  time:25.661, tt:1924.592\n",
      "Ep:75, loss:0.00001, loss_test:0.01338, lr:5.32e-02, fs:0.78756 (r=0.768,p=0.809),  time:25.679, tt:1951.578\n",
      "Ep:76, loss:0.00001, loss_test:0.01337, lr:5.27e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.689, tt:1978.049\n",
      "Ep:77, loss:0.00001, loss_test:0.01332, lr:5.21e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.706, tt:2005.057\n",
      "Ep:78, loss:0.00001, loss_test:0.01333, lr:5.16e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.725, tt:2032.309\n",
      "Ep:79, loss:0.00001, loss_test:0.01337, lr:5.11e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.721, tt:2057.684\n",
      "Ep:80, loss:0.00001, loss_test:0.01338, lr:5.06e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.716, tt:2082.979\n",
      "Ep:81, loss:0.00001, loss_test:0.01336, lr:5.01e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.704, tt:2107.702\n",
      "Ep:82, loss:0.00001, loss_test:0.01331, lr:4.96e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.698, tt:2132.973\n",
      "Ep:83, loss:0.00001, loss_test:0.01334, lr:4.91e-02, fs:0.79581 (r=0.768,p=0.826),  time:25.706, tt:2159.308\n",
      "Ep:84, loss:0.00001, loss_test:0.01335, lr:4.86e-02, fs:0.80000 (r=0.768,p=0.835),  time:25.713, tt:2185.631\n",
      "Ep:85, loss:0.00001, loss_test:0.01335, lr:4.81e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.714, tt:2211.433\n",
      "Ep:86, loss:0.00001, loss_test:0.01339, lr:4.76e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.713, tt:2237.063\n",
      "Ep:87, loss:0.00001, loss_test:0.01338, lr:4.71e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.706, tt:2262.142\n",
      "Ep:88, loss:0.00001, loss_test:0.01339, lr:4.67e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.683, tt:2285.817\n",
      "Ep:89, loss:0.00001, loss_test:0.01341, lr:4.62e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.690, tt:2312.132\n",
      "Ep:90, loss:0.00001, loss_test:0.01340, lr:4.57e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.677, tt:2336.615\n",
      "Ep:91, loss:0.00001, loss_test:0.01341, lr:4.53e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.668, tt:2361.435\n",
      "Ep:92, loss:0.00001, loss_test:0.01343, lr:4.48e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.663, tt:2386.671\n",
      "Ep:93, loss:0.00001, loss_test:0.01340, lr:4.44e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.668, tt:2412.826\n",
      "Ep:94, loss:0.00001, loss_test:0.01338, lr:4.39e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.662, tt:2437.856\n",
      "Ep:95, loss:0.00001, loss_test:0.01341, lr:4.35e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.672, tt:2464.515\n",
      "Ep:96, loss:0.00001, loss_test:0.01338, lr:4.31e-02, fs:0.80423 (r=0.768,p=0.844),  time:25.657, tt:2488.765\n",
      "Ep:97, loss:0.00001, loss_test:0.01339, lr:4.26e-02, fs:0.80851 (r=0.768,p=0.854),  time:25.658, tt:2514.456\n",
      "Ep:98, loss:0.00001, loss_test:0.01342, lr:4.22e-02, fs:0.81283 (r=0.768,p=0.864),  time:25.657, tt:2540.073\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01343, lr:4.22e-02, fs:0.81283 (r=0.768,p=0.864),  time:25.655, tt:2565.537\n",
      "Ep:100, loss:0.00001, loss_test:0.01344, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.648, tt:2590.437\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01345, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.648, tt:2616.104\n",
      "Ep:102, loss:0.00001, loss_test:0.01346, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.643, tt:2641.277\n",
      "Ep:103, loss:0.00001, loss_test:0.01345, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.649, tt:2667.461\n",
      "Ep:104, loss:0.00001, loss_test:0.01345, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.673, tt:2695.657\n",
      "Ep:105, loss:0.00001, loss_test:0.01343, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.683, tt:2722.396\n",
      "Ep:106, loss:0.00001, loss_test:0.01347, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.678, tt:2747.547\n",
      "Ep:107, loss:0.00001, loss_test:0.01350, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.673, tt:2772.670\n",
      "Ep:108, loss:0.00001, loss_test:0.01348, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.680, tt:2799.146\n",
      "Ep:109, loss:0.00001, loss_test:0.01351, lr:4.22e-02, fs:0.81720 (r=0.768,p=0.874),  time:25.677, tt:2824.513\n",
      "Ep:110, loss:0.00001, loss_test:0.01354, lr:4.22e-02, fs:0.82162 (r=0.768,p=0.884),  time:25.689, tt:2851.425\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01352, lr:4.22e-02, fs:0.82162 (r=0.768,p=0.884),  time:25.686, tt:2876.818\n",
      "Ep:112, loss:0.00001, loss_test:0.01352, lr:4.22e-02, fs:0.82162 (r=0.768,p=0.884),  time:25.698, tt:2903.920\n",
      "Ep:113, loss:0.00001, loss_test:0.01353, lr:4.22e-02, fs:0.82609 (r=0.768,p=0.894),  time:25.709, tt:2930.808\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00001, loss_test:0.01356, lr:4.22e-02, fs:0.83060 (r=0.768,p=0.905),  time:25.707, tt:2956.272\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.01363, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.705, tt:2981.819\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01360, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.714, tt:3008.596\n",
      "Ep:117, loss:0.00001, loss_test:0.01357, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.711, tt:3033.955\n",
      "Ep:118, loss:0.00001, loss_test:0.01360, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.713, tt:3059.835\n",
      "Ep:119, loss:0.00001, loss_test:0.01363, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.715, tt:3085.806\n",
      "Ep:120, loss:0.00001, loss_test:0.01364, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.714, tt:3111.412\n",
      "Ep:121, loss:0.00001, loss_test:0.01364, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:25.713, tt:3137.028\n",
      "Ep:122, loss:0.00001, loss_test:0.01364, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.709, tt:3162.167\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.01367, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.707, tt:3187.681\n",
      "Ep:124, loss:0.00001, loss_test:0.01366, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.695, tt:3211.841\n",
      "Ep:125, loss:0.00001, loss_test:0.01367, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.698, tt:3237.888\n",
      "Ep:126, loss:0.00001, loss_test:0.01373, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.706, tt:3264.643\n",
      "Ep:127, loss:0.00001, loss_test:0.01375, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.705, tt:3290.190\n",
      "Ep:128, loss:0.00001, loss_test:0.01373, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.708, tt:3316.320\n",
      "Ep:129, loss:0.00001, loss_test:0.01372, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.707, tt:3341.952\n",
      "Ep:130, loss:0.00001, loss_test:0.01375, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.728, tt:3370.342\n",
      "Ep:131, loss:0.00001, loss_test:0.01378, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.715, tt:3394.369\n",
      "Ep:132, loss:0.00001, loss_test:0.01380, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.716, tt:3420.260\n",
      "Ep:133, loss:0.00001, loss_test:0.01379, lr:4.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.715, tt:3445.839\n",
      "Ep:134, loss:0.00001, loss_test:0.01382, lr:4.18e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.710, tt:3470.866\n",
      "Ep:135, loss:0.00001, loss_test:0.01389, lr:4.14e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.701, tt:3495.354\n",
      "Ep:136, loss:0.00001, loss_test:0.01390, lr:4.10e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.695, tt:3520.160\n",
      "Ep:137, loss:0.00001, loss_test:0.01389, lr:4.05e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.694, tt:3545.782\n",
      "Ep:138, loss:0.00001, loss_test:0.01388, lr:4.01e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.680, tt:3569.570\n",
      "Ep:139, loss:0.00001, loss_test:0.01391, lr:3.97e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.656, tt:3591.905\n",
      "Ep:140, loss:0.00000, loss_test:0.01397, lr:3.93e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.655, tt:3617.413\n",
      "Ep:141, loss:0.00000, loss_test:0.01396, lr:3.89e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.653, tt:3642.685\n",
      "Ep:142, loss:0.00000, loss_test:0.01399, lr:3.86e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.658, tt:3669.038\n",
      "Ep:143, loss:0.00000, loss_test:0.01398, lr:3.82e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.653, tt:3694.098\n",
      "Ep:144, loss:0.00000, loss_test:0.01395, lr:3.78e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.646, tt:3718.651\n",
      "Ep:145, loss:0.00000, loss_test:0.01398, lr:3.74e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.649, tt:3744.695\n",
      "Ep:146, loss:0.00000, loss_test:0.01401, lr:3.70e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.649, tt:3770.398\n",
      "Ep:147, loss:0.00000, loss_test:0.01403, lr:3.67e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.653, tt:3796.625\n",
      "Ep:148, loss:0.00000, loss_test:0.01405, lr:3.63e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.648, tt:3821.560\n",
      "Ep:149, loss:0.00000, loss_test:0.01406, lr:3.59e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.652, tt:3847.859\n",
      "Ep:150, loss:0.00000, loss_test:0.01406, lr:3.56e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.645, tt:3872.427\n",
      "Ep:151, loss:0.00000, loss_test:0.01409, lr:3.52e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.650, tt:3898.828\n",
      "Ep:152, loss:0.00000, loss_test:0.01409, lr:3.49e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.653, tt:3924.867\n",
      "Ep:153, loss:0.00000, loss_test:0.01411, lr:3.45e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.652, tt:3950.368\n",
      "Ep:154, loss:0.00000, loss_test:0.01413, lr:3.42e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.649, tt:3975.594\n",
      "Ep:155, loss:0.00000, loss_test:0.01416, lr:3.38e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.645, tt:4000.561\n",
      "Ep:156, loss:0.00000, loss_test:0.01415, lr:3.35e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.668, tt:4029.800\n",
      "Ep:157, loss:0.00000, loss_test:0.01419, lr:3.32e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.671, tt:4056.016\n",
      "Ep:158, loss:0.00000, loss_test:0.01417, lr:3.28e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.677, tt:4082.686\n",
      "Ep:159, loss:0.00000, loss_test:0.01419, lr:3.25e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.675, tt:4107.979\n",
      "Ep:160, loss:0.00000, loss_test:0.01420, lr:3.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.681, tt:4134.566\n",
      "Ep:161, loss:0.00000, loss_test:0.01419, lr:3.19e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.677, tt:4159.665\n",
      "Ep:162, loss:0.00000, loss_test:0.01420, lr:3.15e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.678, tt:4185.535\n",
      "Ep:163, loss:0.00000, loss_test:0.01422, lr:3.12e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.676, tt:4210.842\n",
      "Ep:164, loss:0.00000, loss_test:0.01423, lr:3.09e-02, fs:0.84444 (r=0.768,p=0.938),  time:25.676, tt:4236.569\n",
      "Ep:165, loss:0.00000, loss_test:0.01427, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.677, tt:4262.325\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00000, loss_test:0.01427, lr:3.06e-02, fs:0.84916 (r=0.768,p=0.950),  time:25.680, tt:4288.568\n",
      "Ep:167, loss:0.00000, loss_test:0.01427, lr:3.06e-02, fs:0.84916 (r=0.768,p=0.950),  time:25.678, tt:4313.986\n",
      "Ep:168, loss:0.00000, loss_test:0.01429, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.673, tt:4338.813\n",
      "Ep:169, loss:0.00000, loss_test:0.01430, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.668, tt:4363.532\n",
      "Ep:170, loss:0.00000, loss_test:0.01432, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.666, tt:4388.891\n",
      "Ep:171, loss:0.00000, loss_test:0.01432, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.663, tt:4414.098\n",
      "Ep:172, loss:0.00000, loss_test:0.01432, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.663, tt:4439.777\n",
      "Ep:173, loss:0.00000, loss_test:0.01433, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.655, tt:4463.936\n",
      "Ep:174, loss:0.00000, loss_test:0.01436, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.656, tt:4489.739\n",
      "Ep:175, loss:0.00000, loss_test:0.01437, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.657, tt:4515.642\n",
      "Ep:176, loss:0.00000, loss_test:0.01438, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.658, tt:4541.549\n",
      "Ep:177, loss:0.00000, loss_test:0.01439, lr:3.03e-02, fs:0.85393 (r=0.768,p=0.962),  time:25.655, tt:4566.553\n",
      "Ep:178, loss:0.00000, loss_test:0.01441, lr:3.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:25.652, tt:4591.698\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00000, loss_test:0.01441, lr:3.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:25.646, tt:4616.362\n",
      "Ep:180, loss:0.00000, loss_test:0.01443, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.638, tt:4640.477\n",
      "Ep:181, loss:0.00000, loss_test:0.01446, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.633, tt:4665.271\n",
      "Ep:182, loss:0.00000, loss_test:0.01446, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.652, tt:4694.318\n",
      "Ep:183, loss:0.00000, loss_test:0.01447, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.648, tt:4719.208\n",
      "Ep:184, loss:0.00000, loss_test:0.01448, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.642, tt:4743.843\n",
      "Ep:185, loss:0.00000, loss_test:0.01452, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.643, tt:4769.538\n",
      "Ep:186, loss:0.00000, loss_test:0.01451, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.636, tt:4793.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:187, loss:0.00000, loss_test:0.01451, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.630, tt:4818.510\n",
      "Ep:188, loss:0.00000, loss_test:0.01453, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.634, tt:4844.877\n",
      "Ep:189, loss:0.00000, loss_test:0.01452, lr:3.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.633, tt:4870.301\n",
      "Ep:190, loss:0.00000, loss_test:0.01455, lr:2.97e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.626, tt:4894.609\n",
      "Ep:191, loss:0.00000, loss_test:0.01456, lr:2.94e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.620, tt:4919.107\n",
      "Ep:192, loss:0.00000, loss_test:0.01456, lr:2.91e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.619, tt:4944.538\n",
      "Ep:193, loss:0.00000, loss_test:0.01458, lr:2.88e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.619, tt:4970.137\n",
      "Ep:194, loss:0.00000, loss_test:0.01458, lr:2.85e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.613, tt:4994.455\n",
      "Ep:195, loss:0.00000, loss_test:0.01462, lr:2.82e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.596, tt:5016.790\n",
      "Ep:196, loss:0.00000, loss_test:0.01462, lr:2.80e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.590, tt:5041.293\n",
      "Ep:197, loss:0.00000, loss_test:0.01463, lr:2.77e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.580, tt:5064.902\n",
      "Ep:198, loss:0.00000, loss_test:0.01466, lr:2.74e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.563, tt:5087.124\n",
      "Ep:199, loss:0.00000, loss_test:0.01467, lr:2.71e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.553, tt:5110.590\n",
      "Ep:200, loss:0.00000, loss_test:0.01469, lr:2.69e-02, fs:0.85227 (r=0.758,p=0.974),  time:25.555, tt:5136.465\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14228, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:24.970, tt:24.970\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14047, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:23.740, tt:47.479\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13699, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:23.982, tt:71.945\n",
      "Ep:3, loss:0.00026, loss_test:0.13106, lr:1.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:24.048, tt:96.192\n",
      "Ep:4, loss:0.00025, loss_test:0.12251, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:24.217, tt:121.087\n",
      "Ep:5, loss:0.00023, loss_test:0.11586, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:24.526, tt:147.156\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11524, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:25.201, tt:176.404\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11405, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:25.267, tt:202.133\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11302, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:25.161, tt:226.448\n",
      "Ep:9, loss:0.00022, loss_test:0.11267, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:25.252, tt:252.520\n",
      "Ep:10, loss:0.00021, loss_test:0.10957, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:25.409, tt:279.502\n",
      "Ep:11, loss:0.00021, loss_test:0.10566, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:25.507, tt:306.090\n",
      "Ep:12, loss:0.00020, loss_test:0.10400, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:25.501, tt:331.511\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10447, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:25.577, tt:358.083\n",
      "Ep:14, loss:0.00019, loss_test:0.10329, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:25.687, tt:385.311\n",
      "Ep:15, loss:0.00019, loss_test:0.09995, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:25.840, tt:413.441\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09790, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:25.972, tt:441.522\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09671, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:26.009, tt:468.169\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09505, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:25.990, tt:493.801\n",
      "Ep:19, loss:0.00017, loss_test:0.09320, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:25.987, tt:519.747\n",
      "Ep:20, loss:0.00016, loss_test:0.09234, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:26.059, tt:547.247\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09144, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:26.067, tt:573.465\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09021, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:26.055, tt:599.255\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08900, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:26.106, tt:626.538\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08802, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:26.146, tt:653.641\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08734, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:26.161, tt:680.183\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08699, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:26.212, tt:707.734\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08625, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:26.233, tt:734.538\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08582, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:26.249, tt:761.231\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08462, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:26.287, tt:788.612\n",
      "Ep:30, loss:0.00012, loss_test:0.08329, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:26.294, tt:815.127\n",
      "Ep:31, loss:0.00012, loss_test:0.08306, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:26.335, tt:842.705\n",
      "Ep:32, loss:0.00011, loss_test:0.08216, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:26.322, tt:868.636\n",
      "Ep:33, loss:0.00011, loss_test:0.08056, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:26.365, tt:896.422\n",
      "Ep:34, loss:0.00011, loss_test:0.08035, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:26.430, tt:925.037\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08001, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:26.444, tt:951.973\n",
      "Ep:36, loss:0.00010, loss_test:0.07877, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:26.440, tt:978.273\n",
      "Ep:37, loss:0.00010, loss_test:0.07908, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:26.421, tt:1004.012\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07724, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:26.450, tt:1031.546\n",
      "Ep:39, loss:0.00009, loss_test:0.07681, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:26.454, tt:1058.166\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07710, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:26.405, tt:1082.586\n",
      "Ep:41, loss:0.00009, loss_test:0.07586, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:26.455, tt:1111.121\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07607, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:26.488, tt:1138.962\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.07516, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:26.519, tt:1166.840\n",
      "Ep:44, loss:0.00008, loss_test:0.07451, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:26.536, tt:1194.127\n",
      "Ep:45, loss:0.00008, loss_test:0.07480, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:26.513, tt:1219.578\n",
      "Ep:46, loss:0.00007, loss_test:0.07434, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:26.538, tt:1247.274\n",
      "Ep:47, loss:0.00007, loss_test:0.07445, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:26.526, tt:1273.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00007, loss_test:0.07314, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:26.537, tt:1300.315\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.07448, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:26.575, tt:1328.727\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.07345, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:26.557, tt:1354.391\n",
      "Ep:51, loss:0.00006, loss_test:0.07228, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:26.547, tt:1380.434\n",
      "Ep:52, loss:0.00006, loss_test:0.07398, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:26.574, tt:1408.419\n",
      "Ep:53, loss:0.00006, loss_test:0.07203, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:26.599, tt:1436.367\n",
      "Ep:54, loss:0.00006, loss_test:0.07174, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:26.637, tt:1465.027\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.07217, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:26.691, tt:1494.670\n",
      "Ep:56, loss:0.00006, loss_test:0.07153, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.687, tt:1521.185\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.07072, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:26.701, tt:1548.682\n",
      "Ep:58, loss:0.00005, loss_test:0.07137, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.702, tt:1575.425\n",
      "Ep:59, loss:0.00005, loss_test:0.06988, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:26.712, tt:1602.733\n",
      "Ep:60, loss:0.00005, loss_test:0.07025, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.687, tt:1627.924\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.07018, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.695, tt:1655.065\n",
      "Ep:62, loss:0.00005, loss_test:0.06943, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:26.705, tt:1682.393\n",
      "Ep:63, loss:0.00005, loss_test:0.06930, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:26.726, tt:1710.479\n",
      "Ep:64, loss:0.00004, loss_test:0.06988, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.719, tt:1736.706\n",
      "Ep:65, loss:0.00004, loss_test:0.06997, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.725, tt:1763.842\n",
      "Ep:66, loss:0.00004, loss_test:0.06860, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.741, tt:1791.665\n",
      "Ep:67, loss:0.00004, loss_test:0.06886, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.760, tt:1819.653\n",
      "Ep:68, loss:0.00004, loss_test:0.06872, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.787, tt:1848.292\n",
      "Ep:69, loss:0.00004, loss_test:0.06890, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.807, tt:1876.492\n",
      "Ep:70, loss:0.00004, loss_test:0.06945, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.811, tt:1903.583\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00004, loss_test:0.06798, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.809, tt:1930.219\n",
      "Ep:72, loss:0.00004, loss_test:0.06924, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.817, tt:1957.638\n",
      "Ep:73, loss:0.00004, loss_test:0.06872, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.823, tt:1984.869\n",
      "Ep:74, loss:0.00003, loss_test:0.06812, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.838, tt:2012.877\n",
      "Ep:75, loss:0.00003, loss_test:0.06947, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.846, tt:2040.268\n",
      "Ep:76, loss:0.00003, loss_test:0.06652, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.842, tt:2066.828\n",
      "Ep:77, loss:0.00003, loss_test:0.06791, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:26.867, tt:2095.632\n",
      "Ep:78, loss:0.00003, loss_test:0.06808, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.865, tt:2122.315\n",
      "Ep:79, loss:0.00003, loss_test:0.06694, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:26.866, tt:2149.306\n",
      "Ep:80, loss:0.00003, loss_test:0.06845, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.878, tt:2177.082\n",
      "Ep:81, loss:0.00003, loss_test:0.06726, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:26.895, tt:2205.429\n",
      "Ep:82, loss:0.00003, loss_test:0.06710, lr:9.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.901, tt:2232.777\n",
      "Ep:83, loss:0.00003, loss_test:0.06863, lr:9.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.894, tt:2259.112\n",
      "Ep:84, loss:0.00003, loss_test:0.06650, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:26.911, tt:2287.468\n",
      "Ep:85, loss:0.00003, loss_test:0.06746, lr:9.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.927, tt:2315.715\n",
      "Ep:86, loss:0.00003, loss_test:0.06799, lr:9.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:26.937, tt:2343.479\n",
      "Ep:87, loss:0.00003, loss_test:0.06685, lr:9.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:26.937, tt:2370.450\n",
      "Ep:88, loss:0.00003, loss_test:0.06811, lr:9.32e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.950, tt:2398.529\n",
      "Ep:89, loss:0.00002, loss_test:0.06715, lr:9.23e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.952, tt:2425.692\n",
      "Ep:90, loss:0.00002, loss_test:0.06649, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:26.947, tt:2452.163\n",
      "Ep:91, loss:0.00002, loss_test:0.06830, lr:9.04e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.951, tt:2479.523\n",
      "Ep:92, loss:0.00002, loss_test:0.06623, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:26.964, tt:2507.625\n",
      "Ep:93, loss:0.00002, loss_test:0.06786, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:26.981, tt:2536.237\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.06691, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.987, tt:2563.731\n",
      "Ep:95, loss:0.00002, loss_test:0.06691, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:26.993, tt:2591.362\n",
      "Ep:96, loss:0.00002, loss_test:0.06727, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.983, tt:2617.321\n",
      "Ep:97, loss:0.00002, loss_test:0.06695, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:26.963, tt:2642.369\n",
      "Ep:98, loss:0.00002, loss_test:0.06742, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.960, tt:2669.044\n",
      "Ep:99, loss:0.00002, loss_test:0.06875, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:26.968, tt:2696.831\n",
      "Ep:100, loss:0.00002, loss_test:0.06740, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.972, tt:2724.188\n",
      "Ep:101, loss:0.00002, loss_test:0.06923, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:26.989, tt:2752.832\n",
      "Ep:102, loss:0.00002, loss_test:0.06799, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.003, tt:2781.326\n",
      "Ep:103, loss:0.00002, loss_test:0.06780, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:26.991, tt:2807.050\n",
      "Ep:104, loss:0.00002, loss_test:0.06878, lr:8.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.008, tt:2835.850\n",
      "Ep:105, loss:0.00002, loss_test:0.06767, lr:8.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:27.017, tt:2863.787\n",
      "Ep:106, loss:0.00002, loss_test:0.06983, lr:8.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.027, tt:2891.840\n",
      "Ep:107, loss:0.00002, loss_test:0.07049, lr:8.60e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.030, tt:2919.280\n",
      "Ep:108, loss:0.00002, loss_test:0.06784, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:27.026, tt:2945.814\n",
      "Ep:109, loss:0.00002, loss_test:0.07147, lr:8.43e-03, fs:0.85057 (r=0.747,p=0.987),  time:27.046, tt:2975.061\n",
      "Ep:110, loss:0.00002, loss_test:0.07075, lr:8.35e-03, fs:0.86364 (r=0.768,p=0.987),  time:27.052, tt:3002.737\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.06751, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:27.059, tt:3030.593\n",
      "Ep:112, loss:0.00002, loss_test:0.07095, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.035, tt:3054.996\n",
      "Ep:113, loss:0.00002, loss_test:0.07061, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.035, tt:3081.938\n",
      "Ep:114, loss:0.00002, loss_test:0.06679, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:27.036, tt:3109.195\n",
      "Ep:115, loss:0.00002, loss_test:0.07020, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.041, tt:3136.806\n",
      "Ep:116, loss:0.00002, loss_test:0.07008, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.040, tt:3163.638\n",
      "Ep:117, loss:0.00002, loss_test:0.06729, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.057, tt:3192.681\n",
      "Ep:118, loss:0.00002, loss_test:0.06986, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.044, tt:3218.260\n",
      "Ep:119, loss:0.00002, loss_test:0.07003, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.047, tt:3245.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00001, loss_test:0.06849, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.053, tt:3273.434\n",
      "Ep:121, loss:0.00001, loss_test:0.06952, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.055, tt:3300.700\n",
      "Ep:122, loss:0.00001, loss_test:0.06962, lr:8.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.051, tt:3327.264\n",
      "Ep:123, loss:0.00001, loss_test:0.06916, lr:8.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.051, tt:3354.357\n",
      "Ep:124, loss:0.00001, loss_test:0.06909, lr:8.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.047, tt:3380.921\n",
      "Ep:125, loss:0.00001, loss_test:0.06975, lr:8.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.036, tt:3406.535\n",
      "Ep:126, loss:0.00001, loss_test:0.06945, lr:7.94e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.038, tt:3433.836\n",
      "Ep:127, loss:0.00001, loss_test:0.06937, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.041, tt:3461.242\n",
      "Ep:128, loss:0.00001, loss_test:0.07023, lr:7.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.041, tt:3488.276\n",
      "Ep:129, loss:0.00001, loss_test:0.06975, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.044, tt:3515.707\n",
      "Ep:130, loss:0.00001, loss_test:0.06947, lr:7.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.036, tt:3541.653\n",
      "Ep:131, loss:0.00001, loss_test:0.07013, lr:7.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.026, tt:3567.497\n",
      "Ep:132, loss:0.00001, loss_test:0.07070, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.023, tt:3594.040\n",
      "Ep:133, loss:0.00001, loss_test:0.06896, lr:7.40e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.026, tt:3621.424\n",
      "Ep:134, loss:0.00001, loss_test:0.07174, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.025, tt:3648.382\n",
      "Ep:135, loss:0.00001, loss_test:0.07072, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.029, tt:3675.914\n",
      "Ep:136, loss:0.00001, loss_test:0.06969, lr:7.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.020, tt:3701.744\n",
      "Ep:137, loss:0.00001, loss_test:0.07067, lr:7.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.021, tt:3728.900\n",
      "Ep:138, loss:0.00001, loss_test:0.07114, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.016, tt:3755.200\n",
      "Ep:139, loss:0.00001, loss_test:0.07030, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.026, tt:3783.583\n",
      "Ep:140, loss:0.00001, loss_test:0.07023, lr:6.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.032, tt:3811.573\n",
      "Ep:141, loss:0.00001, loss_test:0.07117, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.036, tt:3839.141\n",
      "Ep:142, loss:0.00001, loss_test:0.07033, lr:6.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.052, tt:3868.452\n",
      "Ep:143, loss:0.00001, loss_test:0.07089, lr:6.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.042, tt:3894.056\n",
      "Ep:144, loss:0.00001, loss_test:0.07150, lr:6.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.033, tt:3919.841\n",
      "Ep:145, loss:0.00001, loss_test:0.07118, lr:6.56e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.030, tt:3946.368\n",
      "Ep:146, loss:0.00001, loss_test:0.07075, lr:6.49e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.020, tt:3971.962\n",
      "Ep:147, loss:0.00001, loss_test:0.07172, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.015, tt:3998.266\n",
      "Ep:148, loss:0.00001, loss_test:0.07214, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.007, tt:4024.045\n",
      "Ep:149, loss:0.00001, loss_test:0.07104, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.002, tt:4050.284\n",
      "Ep:150, loss:0.00001, loss_test:0.07133, lr:6.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.006, tt:4077.855\n",
      "Ep:151, loss:0.00001, loss_test:0.07220, lr:6.17e-03, fs:0.84571 (r=0.747,p=0.974),  time:26.996, tt:4103.441\n",
      "Ep:152, loss:0.00001, loss_test:0.07172, lr:6.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.003, tt:4131.444\n",
      "Ep:153, loss:0.00001, loss_test:0.07101, lr:6.05e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.021, tt:4161.203\n",
      "Ep:154, loss:0.00001, loss_test:0.07230, lr:5.99e-03, fs:0.84571 (r=0.747,p=0.974),  time:27.032, tt:4189.905\n",
      "Ep:155, loss:0.00001, loss_test:0.07211, lr:5.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.037, tt:4217.749\n",
      "Ep:156, loss:0.00001, loss_test:0.07191, lr:5.87e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.033, tt:4244.199\n",
      "Ep:157, loss:0.00001, loss_test:0.07203, lr:5.81e-03, fs:0.85714 (r=0.758,p=0.987),  time:27.033, tt:4271.157\n",
      "Ep:158, loss:0.00001, loss_test:0.07291, lr:5.75e-03, fs:0.84571 (r=0.747,p=0.974),  time:27.029, tt:4297.617\n",
      "Ep:159, loss:0.00001, loss_test:0.07261, lr:5.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.026, tt:4324.104\n",
      "Ep:160, loss:0.00001, loss_test:0.07275, lr:5.64e-03, fs:0.85227 (r=0.758,p=0.974),  time:27.021, tt:4350.379\n",
      "Ep:161, loss:0.00001, loss_test:0.07237, lr:5.58e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.018, tt:4376.900\n",
      "Ep:162, loss:0.00001, loss_test:0.07265, lr:5.53e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.012, tt:4403.035\n",
      "Ep:163, loss:0.00001, loss_test:0.07303, lr:5.47e-03, fs:0.83721 (r=0.727,p=0.986),  time:27.011, tt:4429.788\n",
      "Ep:164, loss:0.00001, loss_test:0.07271, lr:5.42e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.009, tt:4456.532\n",
      "Ep:165, loss:0.00001, loss_test:0.07256, lr:5.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.002, tt:4482.391\n",
      "Ep:166, loss:0.00001, loss_test:0.07313, lr:5.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:27.008, tt:4510.366\n",
      "Ep:167, loss:0.00001, loss_test:0.07308, lr:5.26e-03, fs:0.84571 (r=0.747,p=0.974),  time:27.007, tt:4537.177\n",
      "Ep:168, loss:0.00001, loss_test:0.07255, lr:5.20e-03, fs:0.85876 (r=0.768,p=0.974),  time:27.011, tt:4564.777\n",
      "Ep:169, loss:0.00001, loss_test:0.07297, lr:5.15e-03, fs:0.84571 (r=0.747,p=0.974),  time:27.001, tt:4590.099\n",
      "Ep:170, loss:0.00001, loss_test:0.07365, lr:5.10e-03, fs:0.83237 (r=0.727,p=0.973),  time:26.993, tt:4615.830\n",
      "Ep:171, loss:0.00001, loss_test:0.07317, lr:5.05e-03, fs:0.84571 (r=0.747,p=0.974),  time:26.990, tt:4642.205\n",
      "Ep:172, loss:0.00001, loss_test:0.07279, lr:5.00e-03, fs:0.85227 (r=0.758,p=0.974),  time:26.995, tt:4670.088\n",
      "Ep:173, loss:0.00001, loss_test:0.07392, lr:4.95e-03, fs:0.83721 (r=0.727,p=0.986),  time:26.993, tt:4696.728\n",
      "Ep:174, loss:0.00001, loss_test:0.07331, lr:4.90e-03, fs:0.85227 (r=0.758,p=0.974),  time:26.999, tt:4724.827\n",
      "Ep:175, loss:0.00001, loss_test:0.07311, lr:4.85e-03, fs:0.84571 (r=0.747,p=0.974),  time:26.998, tt:4751.711\n",
      "Ep:176, loss:0.00001, loss_test:0.07396, lr:4.80e-03, fs:0.81871 (r=0.707,p=0.972),  time:26.988, tt:4776.869\n",
      "Ep:177, loss:0.00001, loss_test:0.07384, lr:4.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:26.982, tt:4802.856\n",
      "Ep:178, loss:0.00001, loss_test:0.07377, lr:4.71e-03, fs:0.85057 (r=0.747,p=0.987),  time:26.979, tt:4829.255\n",
      "Ep:179, loss:0.00001, loss_test:0.07369, lr:4.66e-03, fs:0.84393 (r=0.737,p=0.986),  time:26.961, tt:4852.953\n",
      "Ep:180, loss:0.00001, loss_test:0.07430, lr:4.61e-03, fs:0.82353 (r=0.707,p=0.986),  time:26.951, tt:4878.167\n",
      "Ep:181, loss:0.00001, loss_test:0.07362, lr:4.57e-03, fs:0.83237 (r=0.727,p=0.973),  time:26.944, tt:4903.721\n",
      "Ep:182, loss:0.00001, loss_test:0.07424, lr:4.52e-03, fs:0.82353 (r=0.707,p=0.986),  time:26.937, tt:4929.509\n",
      "Ep:183, loss:0.00001, loss_test:0.07443, lr:4.48e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.938, tt:4956.679\n",
      "Ep:184, loss:0.00001, loss_test:0.07353, lr:4.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:26.953, tt:4986.303\n",
      "Ep:185, loss:0.00001, loss_test:0.07438, lr:4.39e-03, fs:0.82353 (r=0.707,p=0.986),  time:26.952, tt:5013.123\n",
      "Ep:186, loss:0.00001, loss_test:0.07565, lr:4.34e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.953, tt:5040.129\n",
      "Ep:187, loss:0.00001, loss_test:0.07442, lr:4.30e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.958, tt:5068.028\n",
      "Ep:188, loss:0.00001, loss_test:0.07367, lr:4.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:26.962, tt:5095.752\n",
      "Ep:189, loss:0.00001, loss_test:0.07551, lr:4.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.960, tt:5122.425\n",
      "Ep:190, loss:0.00001, loss_test:0.07588, lr:4.17e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.967, tt:5150.625\n",
      "Ep:191, loss:0.00001, loss_test:0.07432, lr:4.13e-03, fs:0.83041 (r=0.717,p=0.986),  time:26.968, tt:5177.775\n",
      "Ep:192, loss:0.00001, loss_test:0.07432, lr:4.09e-03, fs:0.82558 (r=0.717,p=0.973),  time:26.973, tt:5205.761\n",
      "Ep:193, loss:0.00001, loss_test:0.07600, lr:4.05e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.976, tt:5233.317\n",
      "Ep:194, loss:0.00001, loss_test:0.07520, lr:4.01e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.980, tt:5261.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00001, loss_test:0.07392, lr:3.97e-03, fs:0.83041 (r=0.717,p=0.986),  time:26.973, tt:5286.675\n",
      "Ep:196, loss:0.00001, loss_test:0.07496, lr:3.93e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.973, tt:5313.722\n",
      "Ep:197, loss:0.00001, loss_test:0.07583, lr:3.89e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.960, tt:5338.137\n",
      "Ep:198, loss:0.00001, loss_test:0.07513, lr:3.85e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.942, tt:5361.424\n",
      "Ep:199, loss:0.00001, loss_test:0.07437, lr:3.81e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.917, tt:5383.425\n",
      "Ep:200, loss:0.00001, loss_test:0.07509, lr:3.77e-03, fs:0.81657 (r=0.697,p=0.986),  time:26.905, tt:5407.869\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02303, lr:6.00e-02, fs:0.61887 (r=0.828,p=0.494),  time:30.645, tt:30.645\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02489, lr:6.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:31.094, tt:62.189\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02620, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.638, tt:94.914\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02596, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.274, tt:129.094\n",
      "Ep:4, loss:0.00005, loss_test:0.02497, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:32.134, tt:160.669\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02327, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:32.097, tt:192.579\n",
      "Ep:6, loss:0.00004, loss_test:0.02139, lr:6.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:32.431, tt:227.015\n",
      "Ep:7, loss:0.00004, loss_test:0.02034, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:32.819, tt:262.550\n",
      "Ep:8, loss:0.00004, loss_test:0.02019, lr:6.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:33.055, tt:297.497\n",
      "Ep:9, loss:0.00004, loss_test:0.01988, lr:6.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:33.148, tt:331.476\n",
      "Ep:10, loss:0.00004, loss_test:0.01930, lr:6.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:33.345, tt:366.796\n",
      "Ep:11, loss:0.00003, loss_test:0.01924, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:33.475, tt:401.695\n",
      "Ep:12, loss:0.00003, loss_test:0.01888, lr:6.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:33.718, tt:438.338\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01815, lr:6.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:33.783, tt:472.964\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:33.829, tt:507.440\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01728, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:33.831, tt:541.289\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:33.897, tt:576.256\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:33.880, tt:609.844\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01670, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:33.938, tt:644.824\n",
      "Ep:19, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:34.002, tt:680.048\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01650, lr:6.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:33.961, tt:713.184\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:34.022, tt:748.475\n",
      "Ep:22, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:34.096, tt:784.200\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:34.087, tt:818.081\n",
      "Ep:24, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:34.120, tt:852.992\n",
      "Ep:25, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:34.110, tt:886.867\n",
      "Ep:26, loss:0.00002, loss_test:0.01587, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:34.132, tt:921.574\n",
      "Ep:27, loss:0.00002, loss_test:0.01577, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:34.186, tt:957.197\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:34.169, tt:990.896\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:34.200, tt:1025.996\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01584, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:34.192, tt:1059.938\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01579, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:34.203, tt:1094.501\n",
      "Ep:32, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:34.186, tt:1128.144\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01579, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.209, tt:1163.122\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.269, tt:1199.417\n",
      "Ep:35, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:34.305, tt:1234.976\n",
      "Ep:36, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:34.352, tt:1271.020\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:34.360, tt:1305.672\n",
      "Ep:38, loss:0.00002, loss_test:0.01604, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:34.367, tt:1340.312\n",
      "Ep:39, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:34.411, tt:1376.456\n",
      "Ep:40, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:34.448, tt:1412.364\n",
      "Ep:41, loss:0.00001, loss_test:0.01603, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:34.482, tt:1448.238\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01626, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.505, tt:1483.713\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01624, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.545, tt:1519.968\n",
      "Ep:44, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.594, tt:1556.730\n",
      "Ep:45, loss:0.00001, loss_test:0.01637, lr:6.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:34.617, tt:1592.388\n",
      "Ep:46, loss:0.00001, loss_test:0.01645, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.648, tt:1628.447\n",
      "Ep:47, loss:0.00001, loss_test:0.01636, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.670, tt:1664.164\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01651, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.698, tt:1700.209\n",
      "Ep:49, loss:0.00001, loss_test:0.01651, lr:6.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:34.704, tt:1735.224\n",
      "Ep:50, loss:0.00001, loss_test:0.01645, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:34.736, tt:1771.547\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01668, lr:6.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:34.759, tt:1807.453\n",
      "Ep:52, loss:0.00001, loss_test:0.01673, lr:6.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.760, tt:1842.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00001, loss_test:0.01664, lr:6.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:34.757, tt:1876.889\n",
      "Ep:54, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.761, tt:1911.847\n",
      "Ep:55, loss:0.00001, loss_test:0.01659, lr:6.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:34.803, tt:1948.963\n",
      "Ep:56, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:34.826, tt:1985.083\n",
      "Ep:57, loss:0.00001, loss_test:0.01679, lr:6.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.844, tt:2020.954\n",
      "Ep:58, loss:0.00001, loss_test:0.01683, lr:6.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.856, tt:2056.514\n",
      "Ep:59, loss:0.00001, loss_test:0.01685, lr:6.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.872, tt:2092.309\n",
      "Ep:60, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.898, tt:2128.788\n",
      "Ep:61, loss:0.00001, loss_test:0.01693, lr:6.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.907, tt:2164.255\n",
      "Ep:62, loss:0.00001, loss_test:0.01678, lr:5.94e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.921, tt:2200.039\n",
      "Ep:63, loss:0.00001, loss_test:0.01693, lr:5.88e-02, fs:0.74595 (r=0.697,p=0.802),  time:34.924, tt:2235.167\n",
      "Ep:64, loss:0.00001, loss_test:0.01682, lr:5.82e-02, fs:0.75676 (r=0.707,p=0.814),  time:34.913, tt:2269.322\n",
      "Ep:65, loss:0.00001, loss_test:0.01691, lr:5.76e-02, fs:0.75410 (r=0.697,p=0.821),  time:34.968, tt:2307.891\n",
      "Ep:66, loss:0.00001, loss_test:0.01725, lr:5.71e-02, fs:0.74860 (r=0.677,p=0.838),  time:34.963, tt:2342.550\n",
      "Ep:67, loss:0.00001, loss_test:0.01703, lr:5.65e-02, fs:0.74444 (r=0.677,p=0.827),  time:34.974, tt:2378.258\n",
      "Ep:68, loss:0.00001, loss_test:0.01715, lr:5.59e-02, fs:0.74033 (r=0.677,p=0.817),  time:35.001, tt:2415.048\n",
      "Ep:69, loss:0.00001, loss_test:0.01718, lr:5.54e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.025, tt:2451.778\n",
      "Ep:70, loss:0.00001, loss_test:0.01713, lr:5.48e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.030, tt:2487.161\n",
      "Ep:71, loss:0.00001, loss_test:0.01729, lr:5.43e-02, fs:0.73864 (r=0.657,p=0.844),  time:35.060, tt:2524.352\n",
      "Ep:72, loss:0.00001, loss_test:0.01743, lr:5.37e-02, fs:0.73864 (r=0.657,p=0.844),  time:35.062, tt:2559.521\n",
      "Ep:73, loss:0.00001, loss_test:0.01743, lr:5.32e-02, fs:0.73563 (r=0.646,p=0.853),  time:35.071, tt:2595.236\n",
      "Ep:74, loss:0.00001, loss_test:0.01746, lr:5.27e-02, fs:0.72832 (r=0.636,p=0.851),  time:35.078, tt:2630.859\n",
      "Ep:75, loss:0.00001, loss_test:0.01744, lr:5.21e-02, fs:0.72414 (r=0.636,p=0.840),  time:35.089, tt:2666.727\n",
      "Ep:76, loss:0.00001, loss_test:0.01741, lr:5.16e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.077, tt:2700.891\n",
      "Ep:77, loss:0.00001, loss_test:0.01758, lr:5.11e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.086, tt:2736.726\n",
      "Ep:78, loss:0.00001, loss_test:0.01752, lr:5.06e-02, fs:0.72515 (r=0.626,p=0.861),  time:35.093, tt:2772.345\n",
      "Ep:79, loss:0.00001, loss_test:0.01770, lr:5.01e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.101, tt:2808.073\n",
      "Ep:80, loss:0.00001, loss_test:0.01764, lr:4.96e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.098, tt:2842.941\n",
      "Ep:81, loss:0.00001, loss_test:0.01769, lr:4.91e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.103, tt:2878.417\n",
      "Ep:82, loss:0.00001, loss_test:0.01785, lr:4.86e-02, fs:0.71765 (r=0.616,p=0.859),  time:35.116, tt:2914.632\n",
      "Ep:83, loss:0.00001, loss_test:0.01782, lr:4.81e-02, fs:0.72189 (r=0.616,p=0.871),  time:35.123, tt:2950.355\n",
      "Ep:84, loss:0.00001, loss_test:0.01792, lr:4.76e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.129, tt:2985.935\n",
      "Ep:85, loss:0.00001, loss_test:0.01784, lr:4.71e-02, fs:0.71429 (r=0.606,p=0.870),  time:35.121, tt:3020.442\n",
      "Ep:86, loss:0.00001, loss_test:0.01799, lr:4.67e-02, fs:0.69880 (r=0.586,p=0.866),  time:35.135, tt:3056.780\n",
      "Ep:87, loss:0.00001, loss_test:0.01786, lr:4.62e-02, fs:0.69880 (r=0.586,p=0.866),  time:35.170, tt:3094.999\n",
      "Ep:88, loss:0.00001, loss_test:0.01809, lr:4.57e-02, fs:0.70659 (r=0.596,p=0.868),  time:35.177, tt:3130.766\n",
      "Ep:89, loss:0.00001, loss_test:0.01796, lr:4.53e-02, fs:0.69880 (r=0.586,p=0.866),  time:35.188, tt:3166.924\n",
      "Ep:90, loss:0.00001, loss_test:0.01807, lr:4.48e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.205, tt:3203.680\n",
      "Ep:91, loss:0.00001, loss_test:0.01822, lr:4.44e-02, fs:0.69880 (r=0.586,p=0.866),  time:35.219, tt:3240.156\n",
      "Ep:92, loss:0.00001, loss_test:0.01811, lr:4.39e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.229, tt:3276.290\n",
      "Ep:93, loss:0.00001, loss_test:0.01831, lr:4.35e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.246, tt:3313.091\n",
      "Ep:94, loss:0.00001, loss_test:0.01813, lr:4.31e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.252, tt:3348.953\n",
      "Ep:95, loss:0.00001, loss_test:0.01843, lr:4.26e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.260, tt:3384.944\n",
      "Ep:96, loss:0.00001, loss_test:0.01833, lr:4.22e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.286, tt:3422.715\n",
      "Ep:97, loss:0.00001, loss_test:0.01849, lr:4.18e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.292, tt:3458.582\n",
      "Ep:98, loss:0.00001, loss_test:0.01847, lr:4.14e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.299, tt:3494.629\n",
      "Ep:99, loss:0.00000, loss_test:0.01840, lr:4.10e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.309, tt:3530.895\n",
      "Ep:100, loss:0.00000, loss_test:0.01868, lr:4.05e-02, fs:0.70303 (r=0.586,p=0.879),  time:35.335, tt:3568.826\n",
      "Ep:101, loss:0.00000, loss_test:0.01857, lr:4.01e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.318, tt:3602.455\n",
      "Ep:102, loss:0.00000, loss_test:0.01862, lr:3.97e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.326, tt:3638.551\n",
      "Ep:103, loss:0.00000, loss_test:0.01875, lr:3.93e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.332, tt:3674.543\n",
      "Ep:104, loss:0.00000, loss_test:0.01867, lr:3.89e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.331, tt:3709.738\n",
      "Ep:105, loss:0.00000, loss_test:0.01881, lr:3.86e-02, fs:0.70732 (r=0.586,p=0.892),  time:35.319, tt:3743.793\n",
      "Ep:106, loss:0.00000, loss_test:0.01892, lr:3.82e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.347, tt:3782.167\n",
      "Ep:107, loss:0.00000, loss_test:0.01881, lr:3.78e-02, fs:0.69939 (r=0.576,p=0.891),  time:35.361, tt:3818.970\n",
      "Ep:108, loss:0.00000, loss_test:0.01895, lr:3.74e-02, fs:0.69136 (r=0.566,p=0.889),  time:35.360, tt:3854.260\n",
      "Ep:109, loss:0.00000, loss_test:0.01905, lr:3.70e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.360, tt:3889.645\n",
      "Ep:110, loss:0.00000, loss_test:0.01898, lr:3.67e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.369, tt:3925.964\n",
      "Ep:111, loss:0.00000, loss_test:0.01911, lr:3.63e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.372, tt:3961.614\n",
      "Ep:112, loss:0.00000, loss_test:0.01914, lr:3.59e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.369, tt:3996.746\n",
      "Ep:113, loss:0.00000, loss_test:0.01902, lr:3.56e-02, fs:0.69136 (r=0.566,p=0.889),  time:35.360, tt:4031.046\n",
      "Ep:114, loss:0.00000, loss_test:0.01925, lr:3.52e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.372, tt:4067.744\n",
      "Ep:115, loss:0.00000, loss_test:0.01919, lr:3.49e-02, fs:0.69136 (r=0.566,p=0.889),  time:35.368, tt:4102.743\n",
      "Ep:116, loss:0.00000, loss_test:0.01929, lr:3.45e-02, fs:0.69136 (r=0.566,p=0.889),  time:35.365, tt:4137.723\n",
      "Ep:117, loss:0.00000, loss_test:0.01927, lr:3.42e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.362, tt:4172.747\n",
      "Ep:118, loss:0.00000, loss_test:0.01943, lr:3.38e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.368, tt:4208.846\n",
      "Ep:119, loss:0.00000, loss_test:0.01934, lr:3.35e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.375, tt:4245.048\n",
      "Ep:120, loss:0.00000, loss_test:0.01946, lr:3.32e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.370, tt:4279.779\n",
      "Ep:121, loss:0.00000, loss_test:0.01948, lr:3.28e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.363, tt:4314.232\n",
      "Ep:122, loss:0.00000, loss_test:0.01947, lr:3.25e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.354, tt:4348.590\n",
      "Ep:123, loss:0.00000, loss_test:0.01972, lr:3.22e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.360, tt:4384.690\n",
      "Ep:124, loss:0.00000, loss_test:0.01941, lr:3.19e-02, fs:0.69565 (r=0.566,p=0.903),  time:35.365, tt:4420.676\n",
      "Ep:125, loss:0.00000, loss_test:0.01972, lr:3.15e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.368, tt:4456.399\n",
      "Ep:126, loss:0.00000, loss_test:0.01965, lr:3.12e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.364, tt:4491.198\n",
      "Ep:127, loss:0.00000, loss_test:0.01969, lr:3.09e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.361, tt:4526.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.01977, lr:3.06e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.368, tt:4562.537\n",
      "Ep:129, loss:0.00000, loss_test:0.01969, lr:3.03e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.366, tt:4597.604\n",
      "Ep:130, loss:0.00000, loss_test:0.01989, lr:3.00e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.399, tt:4637.243\n",
      "Ep:131, loss:0.00000, loss_test:0.01977, lr:2.97e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.400, tt:4672.770\n",
      "Ep:132, loss:0.00000, loss_test:0.01998, lr:2.94e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.412, tt:4709.736\n",
      "Ep:133, loss:0.00000, loss_test:0.01991, lr:2.91e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.406, tt:4744.443\n",
      "Ep:134, loss:0.00000, loss_test:0.02002, lr:2.88e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.413, tt:4780.750\n",
      "Ep:135, loss:0.00000, loss_test:0.01997, lr:2.85e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.412, tt:4816.093\n",
      "Ep:136, loss:0.00000, loss_test:0.02002, lr:2.82e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.381, tt:4847.240\n",
      "Ep:137, loss:0.00000, loss_test:0.02008, lr:2.80e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.397, tt:4884.718\n",
      "Ep:138, loss:0.00000, loss_test:0.02010, lr:2.77e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.407, tt:4921.632\n",
      "Ep:139, loss:0.00000, loss_test:0.02010, lr:2.74e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.422, tt:4959.070\n",
      "Ep:140, loss:0.00000, loss_test:0.02020, lr:2.71e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.426, tt:4995.034\n",
      "Ep:141, loss:0.00000, loss_test:0.02015, lr:2.69e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.428, tt:5030.822\n",
      "Ep:142, loss:0.00000, loss_test:0.02018, lr:2.66e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.429, tt:5066.340\n",
      "Ep:143, loss:0.00000, loss_test:0.02030, lr:2.63e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.421, tt:5100.680\n",
      "Ep:144, loss:0.00000, loss_test:0.02031, lr:2.61e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.428, tt:5137.107\n",
      "Ep:145, loss:0.00000, loss_test:0.02029, lr:2.58e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.437, tt:5173.846\n",
      "Ep:146, loss:0.00000, loss_test:0.02040, lr:2.55e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.439, tt:5209.601\n",
      "Ep:147, loss:0.00000, loss_test:0.02034, lr:2.53e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.432, tt:5243.940\n",
      "Ep:148, loss:0.00000, loss_test:0.02055, lr:2.50e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.443, tt:5281.066\n",
      "Ep:149, loss:0.00000, loss_test:0.02040, lr:2.48e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.441, tt:5316.138\n",
      "Ep:150, loss:0.00000, loss_test:0.02029, lr:2.45e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.441, tt:5351.590\n",
      "Ep:151, loss:0.00000, loss_test:0.02064, lr:2.43e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.451, tt:5388.481\n",
      "Ep:152, loss:0.00000, loss_test:0.02054, lr:2.40e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.443, tt:5422.836\n",
      "Ep:153, loss:0.00000, loss_test:0.02041, lr:2.38e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.447, tt:5458.893\n",
      "Ep:154, loss:0.00000, loss_test:0.02073, lr:2.36e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.442, tt:5493.564\n",
      "Ep:155, loss:0.00000, loss_test:0.02061, lr:2.33e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.431, tt:5527.226\n",
      "Ep:156, loss:0.00000, loss_test:0.02053, lr:2.31e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.439, tt:5563.876\n",
      "Ep:157, loss:0.00000, loss_test:0.02087, lr:2.29e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.438, tt:5599.179\n",
      "Ep:158, loss:0.00000, loss_test:0.02073, lr:2.26e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.436, tt:5634.335\n",
      "Ep:159, loss:0.00000, loss_test:0.02068, lr:2.24e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.450, tt:5671.954\n",
      "Ep:160, loss:0.00000, loss_test:0.02087, lr:2.22e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.443, tt:5706.365\n",
      "Ep:161, loss:0.00000, loss_test:0.02071, lr:2.20e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.440, tt:5741.216\n",
      "Ep:162, loss:0.00000, loss_test:0.02076, lr:2.17e-02, fs:0.68323 (r=0.556,p=0.887),  time:35.439, tt:5776.594\n",
      "Ep:163, loss:0.00000, loss_test:0.02097, lr:2.15e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.446, tt:5813.077\n",
      "Ep:164, loss:0.00000, loss_test:0.02092, lr:2.13e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.442, tt:5847.880\n",
      "Ep:165, loss:0.00000, loss_test:0.02082, lr:2.11e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.450, tt:5884.628\n",
      "Ep:166, loss:0.00000, loss_test:0.02091, lr:2.09e-02, fs:0.68750 (r=0.556,p=0.902),  time:35.449, tt:5920.003\n",
      "Ep:167, loss:0.00000, loss_test:0.02099, lr:2.07e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.450, tt:5955.626\n",
      "Ep:168, loss:0.00000, loss_test:0.02092, lr:2.05e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.447, tt:5990.612\n",
      "Ep:169, loss:0.00000, loss_test:0.02096, lr:2.03e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.453, tt:6027.084\n",
      "Ep:170, loss:0.00000, loss_test:0.02105, lr:2.01e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.446, tt:6061.260\n",
      "Ep:171, loss:0.00000, loss_test:0.02101, lr:1.99e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.442, tt:6095.992\n",
      "Ep:172, loss:0.00000, loss_test:0.02105, lr:1.97e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.438, tt:6130.734\n",
      "Ep:173, loss:0.00000, loss_test:0.02108, lr:1.95e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.432, tt:6165.177\n",
      "Ep:174, loss:0.00000, loss_test:0.02112, lr:1.93e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.431, tt:6200.400\n",
      "Ep:175, loss:0.00000, loss_test:0.02114, lr:1.91e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.426, tt:6234.940\n",
      "Ep:176, loss:0.00000, loss_test:0.02120, lr:1.89e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.429, tt:6270.994\n",
      "Ep:177, loss:0.00000, loss_test:0.02117, lr:1.87e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.425, tt:6305.710\n",
      "Ep:178, loss:0.00000, loss_test:0.02123, lr:1.85e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.423, tt:6340.747\n",
      "Ep:179, loss:0.00000, loss_test:0.02123, lr:1.83e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.420, tt:6375.679\n",
      "Ep:180, loss:0.00000, loss_test:0.02124, lr:1.81e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.416, tt:6410.249\n",
      "Ep:181, loss:0.00000, loss_test:0.02128, lr:1.80e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.414, tt:6445.353\n",
      "Ep:182, loss:0.00000, loss_test:0.02133, lr:1.78e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.399, tt:6478.044\n",
      "Ep:183, loss:0.00000, loss_test:0.02127, lr:1.76e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.414, tt:6516.232\n",
      "Ep:184, loss:0.00000, loss_test:0.02135, lr:1.74e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.409, tt:6550.693\n",
      "Ep:185, loss:0.00000, loss_test:0.02138, lr:1.73e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.409, tt:6586.155\n",
      "Ep:186, loss:0.00000, loss_test:0.02140, lr:1.71e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.408, tt:6621.328\n",
      "Ep:187, loss:0.00000, loss_test:0.02139, lr:1.69e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.404, tt:6655.913\n",
      "Ep:188, loss:0.00000, loss_test:0.02142, lr:1.67e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.398, tt:6690.291\n",
      "Ep:189, loss:0.00000, loss_test:0.02145, lr:1.66e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.402, tt:6726.356\n",
      "Ep:190, loss:0.00000, loss_test:0.02139, lr:1.64e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.405, tt:6762.402\n",
      "Ep:191, loss:0.00000, loss_test:0.02152, lr:1.62e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.399, tt:6796.557\n",
      "Ep:192, loss:0.00000, loss_test:0.02154, lr:1.61e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.399, tt:6831.973\n",
      "Ep:193, loss:0.00000, loss_test:0.02148, lr:1.59e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.399, tt:6867.364\n",
      "Ep:194, loss:0.00000, loss_test:0.02158, lr:1.58e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.400, tt:6903.022\n",
      "Ep:195, loss:0.00000, loss_test:0.02154, lr:1.56e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.400, tt:6938.492\n",
      "Ep:196, loss:0.00000, loss_test:0.02155, lr:1.54e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.403, tt:6974.299\n",
      "Ep:197, loss:0.00000, loss_test:0.02162, lr:1.53e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.403, tt:7009.843\n",
      "Ep:198, loss:0.00000, loss_test:0.02157, lr:1.51e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.408, tt:7046.267\n",
      "Ep:199, loss:0.00000, loss_test:0.02164, lr:1.50e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.412, tt:7082.449\n",
      "Ep:200, loss:0.00000, loss_test:0.02162, lr:1.48e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.414, tt:7118.129\n",
      "Ep:201, loss:0.00000, loss_test:0.02166, lr:1.47e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.412, tt:7153.249\n",
      "Ep:202, loss:0.00000, loss_test:0.02172, lr:1.45e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.400, tt:7186.130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.02164, lr:1.44e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.387, tt:7218.869\n",
      "Ep:204, loss:0.00000, loss_test:0.02170, lr:1.43e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.387, tt:7254.290\n",
      "Ep:205, loss:0.00000, loss_test:0.02172, lr:1.41e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.362, tt:7284.553\n",
      "Ep:206, loss:0.00000, loss_test:0.02173, lr:1.40e-02, fs:0.69182 (r=0.556,p=0.917),  time:35.362, tt:7319.901\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14338, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.648, tt:34.648\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14123, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:34.648, tt:69.296\n",
      "Ep:2, loss:0.00027, loss_test:0.13732, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:34.035, tt:102.104\n",
      "Ep:3, loss:0.00027, loss_test:0.13219, lr:1.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:34.438, tt:137.752\n",
      "Ep:4, loss:0.00026, loss_test:0.12592, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:34.261, tt:171.307\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11986, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:34.444, tt:206.666\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11620, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:34.592, tt:242.143\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11478, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:34.969, tt:279.756\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11448, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:35.412, tt:318.708\n",
      "Ep:9, loss:0.00023, loss_test:0.11372, lr:1.00e-02, fs:0.69643 (r=0.788,p=0.624),  time:35.747, tt:357.472\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11240, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:35.870, tt:394.569\n",
      "Ep:11, loss:0.00022, loss_test:0.11086, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:36.098, tt:433.180\n",
      "Ep:12, loss:0.00021, loss_test:0.11050, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:36.169, tt:470.201\n",
      "Ep:13, loss:0.00020, loss_test:0.10845, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:36.200, tt:506.800\n",
      "Ep:14, loss:0.00020, loss_test:0.10456, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:36.355, tt:545.319\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10204, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:36.481, tt:583.697\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10049, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:36.514, tt:620.745\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09682, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:36.530, tt:657.549\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09413, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:36.507, tt:693.632\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09276, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:36.498, tt:729.964\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09007, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:36.532, tt:767.167\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08993, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:36.538, tt:803.842\n",
      "Ep:22, loss:0.00015, loss_test:0.08924, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:36.539, tt:840.387\n",
      "Ep:23, loss:0.00015, loss_test:0.08700, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.532, tt:876.766\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08650, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:36.562, tt:914.063\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08393, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:36.538, tt:949.987\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08443, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.577, tt:987.572\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08348, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.542, tt:1023.174\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08236, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:36.567, tt:1060.434\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07947, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:36.635, tt:1099.045\n",
      "Ep:30, loss:0.00012, loss_test:0.08347, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.600, tt:1134.612\n",
      "Ep:31, loss:0.00012, loss_test:0.07776, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:36.638, tt:1172.423\n",
      "Ep:32, loss:0.00011, loss_test:0.07972, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:36.684, tt:1210.559\n",
      "Ep:33, loss:0.00011, loss_test:0.07840, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:36.665, tt:1246.622\n",
      "Ep:34, loss:0.00011, loss_test:0.07683, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:36.670, tt:1283.445\n",
      "Ep:35, loss:0.00010, loss_test:0.07739, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:36.646, tt:1319.245\n",
      "Ep:36, loss:0.00010, loss_test:0.07465, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:36.671, tt:1356.840\n",
      "Ep:37, loss:0.00010, loss_test:0.07699, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.656, tt:1392.916\n",
      "Ep:38, loss:0.00009, loss_test:0.07271, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.655, tt:1429.542\n",
      "Ep:39, loss:0.00009, loss_test:0.07601, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.684, tt:1467.347\n",
      "Ep:40, loss:0.00009, loss_test:0.07397, lr:9.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:36.700, tt:1504.714\n",
      "Ep:41, loss:0.00008, loss_test:0.07129, lr:9.80e-03, fs:0.81522 (r=0.758,p=0.882),  time:36.708, tt:1541.718\n",
      "Ep:42, loss:0.00008, loss_test:0.07377, lr:9.70e-03, fs:0.78261 (r=0.727,p=0.847),  time:36.672, tt:1576.882\n",
      "Ep:43, loss:0.00008, loss_test:0.07092, lr:9.61e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.657, tt:1612.920\n",
      "Ep:44, loss:0.00008, loss_test:0.07244, lr:9.51e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.677, tt:1650.458\n",
      "Ep:45, loss:0.00007, loss_test:0.06989, lr:9.41e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.687, tt:1687.620\n",
      "Ep:46, loss:0.00007, loss_test:0.07244, lr:9.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.704, tt:1725.103\n",
      "Ep:47, loss:0.00007, loss_test:0.06850, lr:9.23e-03, fs:0.80214 (r=0.758,p=0.852),  time:36.678, tt:1760.525\n",
      "Ep:48, loss:0.00007, loss_test:0.07470, lr:9.14e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.678, tt:1797.219\n",
      "Ep:49, loss:0.00006, loss_test:0.06838, lr:9.04e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.679, tt:1833.943\n",
      "Ep:50, loss:0.00006, loss_test:0.07165, lr:8.95e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.680, tt:1870.675\n",
      "Ep:51, loss:0.00006, loss_test:0.06827, lr:8.86e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.682, tt:1907.484\n",
      "Ep:52, loss:0.00006, loss_test:0.06976, lr:8.78e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.670, tt:1943.527\n",
      "Ep:53, loss:0.00006, loss_test:0.07100, lr:8.69e-03, fs:0.78212 (r=0.707,p=0.875),  time:36.649, tt:1979.022\n",
      "Ep:54, loss:0.00006, loss_test:0.07736, lr:8.60e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.629, tt:2014.621\n",
      "Ep:55, loss:0.00006, loss_test:0.06814, lr:8.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.633, tt:2051.463\n",
      "Ep:56, loss:0.00006, loss_test:0.07634, lr:8.43e-03, fs:0.75556 (r=0.687,p=0.840),  time:36.613, tt:2086.956\n",
      "Ep:57, loss:0.00006, loss_test:0.06932, lr:8.35e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.609, tt:2123.303\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06699, lr:8.35e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.603, tt:2159.574\n",
      "Ep:59, loss:0.00005, loss_test:0.07519, lr:8.35e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.588, tt:2195.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.06571, lr:8.35e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.589, tt:2231.940\n",
      "Ep:61, loss:0.00005, loss_test:0.07331, lr:8.35e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.577, tt:2267.796\n",
      "Ep:62, loss:0.00005, loss_test:0.06837, lr:8.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.558, tt:2303.123\n",
      "Ep:63, loss:0.00005, loss_test:0.06645, lr:8.35e-03, fs:0.80663 (r=0.737,p=0.890),  time:36.552, tt:2339.351\n",
      "Ep:64, loss:0.00005, loss_test:0.07015, lr:8.35e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.549, tt:2375.685\n",
      "Ep:65, loss:0.00004, loss_test:0.06716, lr:8.35e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.525, tt:2410.644\n",
      "Ep:66, loss:0.00004, loss_test:0.06919, lr:8.35e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.514, tt:2446.410\n",
      "Ep:67, loss:0.00004, loss_test:0.07067, lr:8.35e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.520, tt:2483.391\n",
      "Ep:68, loss:0.00004, loss_test:0.06753, lr:8.35e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.514, tt:2519.479\n",
      "Ep:69, loss:0.00004, loss_test:0.06996, lr:8.26e-03, fs:0.80000 (r=0.747,p=0.860),  time:36.493, tt:2554.487\n",
      "Ep:70, loss:0.00004, loss_test:0.06976, lr:8.18e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.502, tt:2591.646\n",
      "Ep:71, loss:0.00004, loss_test:0.06597, lr:8.10e-03, fs:0.78212 (r=0.707,p=0.875),  time:36.495, tt:2627.670\n",
      "Ep:72, loss:0.00004, loss_test:0.07060, lr:8.02e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.503, tt:2664.741\n",
      "Ep:73, loss:0.00004, loss_test:0.07075, lr:7.94e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.495, tt:2700.605\n",
      "Ep:74, loss:0.00004, loss_test:0.06577, lr:7.86e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.497, tt:2737.244\n",
      "Ep:75, loss:0.00004, loss_test:0.07119, lr:7.78e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.496, tt:2773.730\n",
      "Ep:76, loss:0.00003, loss_test:0.06811, lr:7.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.497, tt:2810.305\n",
      "Ep:77, loss:0.00003, loss_test:0.07052, lr:7.62e-03, fs:0.78161 (r=0.687,p=0.907),  time:36.502, tt:2847.183\n",
      "Ep:78, loss:0.00003, loss_test:0.06774, lr:7.55e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.536, tt:2886.310\n",
      "Ep:79, loss:0.00003, loss_test:0.07167, lr:7.47e-03, fs:0.78212 (r=0.707,p=0.875),  time:36.522, tt:2921.789\n",
      "Ep:80, loss:0.00003, loss_test:0.07046, lr:7.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.536, tt:2959.387\n",
      "Ep:81, loss:0.00003, loss_test:0.07044, lr:7.32e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.544, tt:2996.582\n",
      "Ep:82, loss:0.00003, loss_test:0.06980, lr:7.25e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.569, tt:3035.237\n",
      "Ep:83, loss:0.00003, loss_test:0.06903, lr:7.18e-03, fs:0.79096 (r=0.707,p=0.897),  time:36.571, tt:3071.980\n",
      "Ep:84, loss:0.00003, loss_test:0.07241, lr:7.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.575, tt:3108.863\n",
      "Ep:85, loss:0.00003, loss_test:0.07002, lr:7.03e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.585, tt:3146.333\n",
      "Ep:86, loss:0.00003, loss_test:0.07058, lr:6.96e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.551, tt:3179.972\n",
      "Ep:87, loss:0.00003, loss_test:0.06864, lr:6.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.522, tt:3213.975\n",
      "Ep:88, loss:0.00003, loss_test:0.07066, lr:6.83e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.499, tt:3248.394\n",
      "Ep:89, loss:0.00003, loss_test:0.06811, lr:6.76e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.501, tt:3285.077\n",
      "Ep:90, loss:0.00003, loss_test:0.07209, lr:6.69e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.497, tt:3321.245\n",
      "Ep:91, loss:0.00003, loss_test:0.06759, lr:6.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.480, tt:3356.160\n",
      "Ep:92, loss:0.00003, loss_test:0.07295, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.516, tt:3395.959\n",
      "Ep:93, loss:0.00003, loss_test:0.06884, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.527, tt:3433.508\n",
      "Ep:94, loss:0.00002, loss_test:0.07104, lr:6.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.516, tt:3469.036\n",
      "Ep:95, loss:0.00002, loss_test:0.06910, lr:6.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.509, tt:3504.823\n",
      "Ep:96, loss:0.00002, loss_test:0.06900, lr:6.30e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.515, tt:3541.965\n",
      "Ep:97, loss:0.00002, loss_test:0.07015, lr:6.24e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.521, tt:3579.093\n",
      "Ep:98, loss:0.00002, loss_test:0.07004, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.533, tt:3616.816\n",
      "Ep:99, loss:0.00002, loss_test:0.07011, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.540, tt:3653.994\n",
      "Ep:100, loss:0.00002, loss_test:0.07061, lr:6.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.549, tt:3691.473\n",
      "Ep:101, loss:0.00002, loss_test:0.06935, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.540, tt:3727.036\n",
      "Ep:102, loss:0.00002, loss_test:0.06978, lr:5.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.545, tt:3764.107\n",
      "Ep:103, loss:0.00002, loss_test:0.07157, lr:5.87e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.558, tt:3802.043\n",
      "Ep:104, loss:0.00002, loss_test:0.06821, lr:5.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.537, tt:3836.435\n",
      "Ep:105, loss:0.00002, loss_test:0.07173, lr:5.75e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.523, tt:3871.422\n",
      "Ep:106, loss:0.00002, loss_test:0.06928, lr:5.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.528, tt:3908.537\n",
      "Ep:107, loss:0.00002, loss_test:0.06951, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.515, tt:3943.657\n",
      "Ep:108, loss:0.00002, loss_test:0.07003, lr:5.58e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.511, tt:3979.649\n",
      "Ep:109, loss:0.00002, loss_test:0.06830, lr:5.53e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.504, tt:4015.452\n",
      "Ep:110, loss:0.00002, loss_test:0.07190, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.502, tt:4051.737\n",
      "Ep:111, loss:0.00002, loss_test:0.06865, lr:5.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.502, tt:4088.209\n",
      "Ep:112, loss:0.00002, loss_test:0.07133, lr:5.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.485, tt:4122.794\n",
      "Ep:113, loss:0.00002, loss_test:0.07022, lr:5.31e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.486, tt:4159.422\n",
      "Ep:114, loss:0.00002, loss_test:0.07086, lr:5.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.485, tt:4195.733\n",
      "Ep:115, loss:0.00002, loss_test:0.06902, lr:5.20e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.470, tt:4230.564\n",
      "Ep:116, loss:0.00002, loss_test:0.07116, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.472, tt:4267.205\n",
      "Ep:117, loss:0.00002, loss_test:0.06941, lr:5.10e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.455, tt:4301.745\n",
      "Ep:118, loss:0.00002, loss_test:0.06927, lr:5.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.461, tt:4338.860\n",
      "Ep:119, loss:0.00002, loss_test:0.07270, lr:5.00e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.461, tt:4375.314\n",
      "Ep:120, loss:0.00002, loss_test:0.06755, lr:4.95e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.449, tt:4410.381\n",
      "Ep:121, loss:0.00002, loss_test:0.07313, lr:4.90e-03, fs:0.77907 (r=0.677,p=0.918),  time:36.437, tt:4445.304\n",
      "Ep:122, loss:0.00002, loss_test:0.06945, lr:4.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.429, tt:4480.721\n",
      "Ep:123, loss:0.00002, loss_test:0.07086, lr:4.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.438, tt:4518.276\n",
      "Ep:124, loss:0.00002, loss_test:0.06962, lr:4.75e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.444, tt:4555.495\n",
      "Ep:125, loss:0.00002, loss_test:0.07039, lr:4.71e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.454, tt:4593.182\n",
      "Ep:126, loss:0.00002, loss_test:0.07103, lr:4.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.456, tt:4629.929\n",
      "Ep:127, loss:0.00002, loss_test:0.06995, lr:4.61e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.461, tt:4667.063\n",
      "Ep:128, loss:0.00002, loss_test:0.07022, lr:4.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.462, tt:4703.591\n",
      "Ep:129, loss:0.00002, loss_test:0.07054, lr:4.52e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.470, tt:4741.045\n",
      "Ep:130, loss:0.00002, loss_test:0.06990, lr:4.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.465, tt:4776.922\n",
      "Ep:131, loss:0.00002, loss_test:0.07031, lr:4.43e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.471, tt:4814.205\n",
      "Ep:132, loss:0.00002, loss_test:0.07061, lr:4.39e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.465, tt:4849.855\n",
      "Ep:133, loss:0.00002, loss_test:0.06941, lr:4.34e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.467, tt:4886.522\n",
      "Ep:134, loss:0.00002, loss_test:0.07011, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.471, tt:4923.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00002, loss_test:0.07033, lr:4.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.470, tt:4959.977\n",
      "Ep:136, loss:0.00002, loss_test:0.06984, lr:4.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.465, tt:4995.681\n",
      "Ep:137, loss:0.00002, loss_test:0.06965, lr:4.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.442, tt:5029.012\n",
      "Ep:138, loss:0.00002, loss_test:0.06993, lr:4.13e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.448, tt:5066.300\n",
      "Ep:139, loss:0.00002, loss_test:0.06964, lr:4.09e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.441, tt:5101.716\n",
      "Ep:140, loss:0.00002, loss_test:0.06983, lr:4.05e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.433, tt:5137.110\n",
      "Ep:141, loss:0.00002, loss_test:0.07005, lr:4.01e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.427, tt:5172.657\n",
      "Ep:142, loss:0.00002, loss_test:0.06975, lr:3.97e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.419, tt:5207.902\n",
      "Ep:143, loss:0.00002, loss_test:0.07030, lr:3.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.420, tt:5244.449\n",
      "Ep:144, loss:0.00002, loss_test:0.06968, lr:3.89e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.419, tt:5280.740\n",
      "Ep:145, loss:0.00002, loss_test:0.06977, lr:3.85e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.416, tt:5316.727\n",
      "Ep:146, loss:0.00001, loss_test:0.07065, lr:3.81e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.411, tt:5352.373\n",
      "Ep:147, loss:0.00001, loss_test:0.06960, lr:3.77e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.404, tt:5387.841\n",
      "Ep:148, loss:0.00001, loss_test:0.07082, lr:3.73e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.402, tt:5423.905\n",
      "Ep:149, loss:0.00001, loss_test:0.06931, lr:3.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.397, tt:5459.491\n",
      "Ep:150, loss:0.00001, loss_test:0.06970, lr:3.66e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.396, tt:5495.782\n",
      "Ep:151, loss:0.00001, loss_test:0.07050, lr:3.62e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.390, tt:5531.339\n",
      "Ep:152, loss:0.00001, loss_test:0.06891, lr:3.59e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.389, tt:5567.586\n",
      "Ep:153, loss:0.00001, loss_test:0.07020, lr:3.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.383, tt:5603.054\n",
      "Ep:154, loss:0.00001, loss_test:0.06972, lr:3.52e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.377, tt:5638.506\n",
      "Ep:155, loss:0.00001, loss_test:0.07045, lr:3.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.365, tt:5672.933\n",
      "Ep:156, loss:0.00001, loss_test:0.06985, lr:3.45e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.361, tt:5708.652\n",
      "Ep:157, loss:0.00001, loss_test:0.07032, lr:3.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.357, tt:5744.455\n",
      "Ep:158, loss:0.00001, loss_test:0.07074, lr:3.38e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.353, tt:5780.134\n",
      "Ep:159, loss:0.00001, loss_test:0.06920, lr:3.34e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.345, tt:5815.233\n",
      "Ep:160, loss:0.00001, loss_test:0.07039, lr:3.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.350, tt:5852.428\n",
      "Ep:161, loss:0.00001, loss_test:0.07181, lr:3.28e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.353, tt:5889.264\n",
      "Ep:162, loss:0.00001, loss_test:0.06898, lr:3.24e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.362, tt:5927.079\n",
      "Ep:163, loss:0.00001, loss_test:0.07001, lr:3.21e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.359, tt:5962.919\n",
      "Ep:164, loss:0.00001, loss_test:0.07057, lr:3.18e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.363, tt:5999.958\n",
      "Ep:165, loss:0.00001, loss_test:0.07003, lr:3.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.366, tt:6036.724\n",
      "Ep:166, loss:0.00001, loss_test:0.07054, lr:3.12e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.360, tt:6072.139\n",
      "Ep:167, loss:0.00001, loss_test:0.06969, lr:3.09e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.357, tt:6107.991\n",
      "Ep:168, loss:0.00001, loss_test:0.07076, lr:3.05e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.355, tt:6144.025\n",
      "Ep:169, loss:0.00001, loss_test:0.06935, lr:3.02e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.354, tt:6180.120\n",
      "Ep:170, loss:0.00001, loss_test:0.07009, lr:2.99e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.359, tt:6217.470\n",
      "Ep:171, loss:0.00001, loss_test:0.07071, lr:2.96e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.361, tt:6254.161\n",
      "Ep:172, loss:0.00001, loss_test:0.06969, lr:2.93e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.365, tt:6291.199\n",
      "Ep:173, loss:0.00001, loss_test:0.07006, lr:2.90e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.364, tt:6327.318\n",
      "Ep:174, loss:0.00001, loss_test:0.06965, lr:2.88e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.365, tt:6363.953\n",
      "Ep:175, loss:0.00001, loss_test:0.07094, lr:2.85e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.370, tt:6401.092\n",
      "Ep:176, loss:0.00001, loss_test:0.07058, lr:2.82e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.366, tt:6436.848\n",
      "Ep:177, loss:0.00001, loss_test:0.06967, lr:2.79e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.372, tt:6474.299\n",
      "Ep:178, loss:0.00001, loss_test:0.07039, lr:2.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.371, tt:6510.322\n",
      "Ep:179, loss:0.00001, loss_test:0.07015, lr:2.73e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.367, tt:6546.096\n",
      "Ep:180, loss:0.00001, loss_test:0.07052, lr:2.71e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.375, tt:6583.962\n",
      "Ep:181, loss:0.00001, loss_test:0.06914, lr:2.68e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.382, tt:6621.551\n",
      "Ep:182, loss:0.00001, loss_test:0.07038, lr:2.65e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.379, tt:6657.402\n",
      "Ep:183, loss:0.00001, loss_test:0.07101, lr:2.63e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.367, tt:6691.464\n",
      "Ep:184, loss:0.00001, loss_test:0.06961, lr:2.60e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.366, tt:6727.719\n",
      "Ep:185, loss:0.00001, loss_test:0.07003, lr:2.57e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.349, tt:6761.006\n",
      "Ep:186, loss:0.00001, loss_test:0.07013, lr:2.55e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.348, tt:6797.040\n",
      "Ep:187, loss:0.00001, loss_test:0.07079, lr:2.52e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.347, tt:6833.201\n",
      "Ep:188, loss:0.00001, loss_test:0.06977, lr:2.50e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.344, tt:6869.100\n",
      "Ep:189, loss:0.00001, loss_test:0.06932, lr:2.47e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.342, tt:6904.887\n",
      "Ep:190, loss:0.00001, loss_test:0.07061, lr:2.45e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.343, tt:6941.586\n",
      "Ep:191, loss:0.00001, loss_test:0.06978, lr:2.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.348, tt:6978.778\n",
      "Ep:192, loss:0.00001, loss_test:0.06938, lr:2.40e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.341, tt:7013.805\n",
      "Ep:193, loss:0.00001, loss_test:0.07009, lr:2.38e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.343, tt:7050.484\n",
      "Ep:194, loss:0.00001, loss_test:0.06989, lr:2.35e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.350, tt:7088.274\n",
      "Ep:195, loss:0.00001, loss_test:0.07038, lr:2.33e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.344, tt:7123.351\n",
      "Ep:196, loss:0.00001, loss_test:0.06920, lr:2.31e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.344, tt:7159.797\n",
      "Ep:197, loss:0.00001, loss_test:0.07033, lr:2.28e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.346, tt:7196.476\n",
      "Ep:198, loss:0.00001, loss_test:0.07081, lr:2.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.346, tt:7232.919\n",
      "Ep:199, loss:0.00001, loss_test:0.06888, lr:2.24e-03, fs:0.81395 (r=0.707,p=0.959),  time:36.349, tt:7269.771\n",
      "Ep:200, loss:0.00001, loss_test:0.07072, lr:2.21e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.350, tt:7306.322\n",
      "Ep:201, loss:0.00001, loss_test:0.07038, lr:2.19e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.349, tt:7342.569\n",
      "Ep:202, loss:0.00001, loss_test:0.06979, lr:2.17e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.349, tt:7378.788\n",
      "Ep:203, loss:0.00001, loss_test:0.07065, lr:2.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.340, tt:7413.456\n",
      "Ep:204, loss:0.00001, loss_test:0.06899, lr:2.13e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.329, tt:7447.384\n",
      "Ep:205, loss:0.00001, loss_test:0.07033, lr:2.11e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.312, tt:7480.359\n",
      "Ep:206, loss:0.00001, loss_test:0.07136, lr:2.08e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.292, tt:7512.526\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02460, lr:6.00e-02, fs:0.61240 (r=0.798,p=0.497),  time:29.580, tt:29.580\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02573, lr:6.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:30.909, tt:61.817\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02717, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.512, tt:91.535\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02713, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.330, tt:121.320\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02615, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:31.000, tt:155.001\n",
      "Ep:5, loss:0.00005, loss_test:0.02444, lr:6.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:31.409, tt:188.454\n",
      "Ep:6, loss:0.00005, loss_test:0.02272, lr:6.00e-02, fs:0.64516 (r=0.909,p=0.500),  time:31.562, tt:220.934\n",
      "Ep:7, loss:0.00004, loss_test:0.02161, lr:6.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:31.822, tt:254.578\n",
      "Ep:8, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:32.177, tt:289.590\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02046, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:32.424, tt:324.239\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:32.660, tt:359.257\n",
      "Ep:11, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:32.926, tt:395.113\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01992, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:33.092, tt:430.190\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01970, lr:6.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.375, tt:467.247\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01942, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:33.472, tt:502.075\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01923, lr:6.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:33.617, tt:537.868\n",
      "Ep:16, loss:0.00003, loss_test:0.01910, lr:6.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:33.682, tt:572.592\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01896, lr:6.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:33.709, tt:606.765\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01881, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:33.859, tt:643.325\n",
      "Ep:19, loss:0.00003, loss_test:0.01872, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:33.907, tt:678.137\n",
      "Ep:20, loss:0.00003, loss_test:0.01860, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:34.024, tt:714.507\n",
      "Ep:21, loss:0.00003, loss_test:0.01841, lr:6.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:34.049, tt:749.083\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:34.104, tt:784.387\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:34.196, tt:820.703\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01765, lr:6.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:34.243, tt:856.083\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01748, lr:6.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:34.319, tt:892.307\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.351, tt:927.471\n",
      "Ep:27, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.386, tt:962.802\n",
      "Ep:28, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:34.404, tt:997.704\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01688, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:34.413, tt:1032.393\n",
      "Ep:30, loss:0.00002, loss_test:0.01664, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:34.457, tt:1068.169\n",
      "Ep:31, loss:0.00002, loss_test:0.01643, lr:6.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:34.484, tt:1103.484\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01634, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:34.535, tt:1139.671\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:34.585, tt:1175.900\n",
      "Ep:34, loss:0.00002, loss_test:0.01625, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:34.639, tt:1212.378\n",
      "Ep:35, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:34.684, tt:1248.639\n",
      "Ep:36, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:34.703, tt:1284.013\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:34.728, tt:1319.668\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:34.747, tt:1355.136\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:34.754, tt:1390.173\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:34.769, tt:1425.545\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01615, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:34.790, tt:1461.185\n",
      "Ep:42, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:34.818, tt:1497.174\n",
      "Ep:43, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:34.850, tt:1533.421\n",
      "Ep:44, loss:0.00002, loss_test:0.01604, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:34.903, tt:1570.640\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01586, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:34.901, tt:1605.448\n",
      "Ep:46, loss:0.00002, loss_test:0.01603, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:34.893, tt:1639.975\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01599, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.915, tt:1675.903\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.927, tt:1711.425\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01587, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:34.952, tt:1747.599\n",
      "Ep:50, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.960, tt:1782.940\n",
      "Ep:51, loss:0.00001, loss_test:0.01575, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.945, tt:1817.119\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01595, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.951, tt:1852.428\n",
      "Ep:53, loss:0.00001, loss_test:0.01576, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.975, tt:1888.640\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.972, tt:1923.447\n",
      "Ep:55, loss:0.00001, loss_test:0.01588, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.955, tt:1957.468\n",
      "Ep:56, loss:0.00001, loss_test:0.01575, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.995, tt:1994.719\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01576, lr:6.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:35.005, tt:2030.310\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01578, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.007, tt:2065.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01581, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.029, tt:2101.769\n",
      "Ep:60, loss:0.00001, loss_test:0.01578, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.039, tt:2137.401\n",
      "Ep:61, loss:0.00001, loss_test:0.01591, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.064, tt:2173.992\n",
      "Ep:62, loss:0.00001, loss_test:0.01540, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.084, tt:2210.275\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01604, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.101, tt:2246.475\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01549, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.122, tt:2282.942\n",
      "Ep:65, loss:0.00001, loss_test:0.01622, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.150, tt:2319.880\n",
      "Ep:66, loss:0.00001, loss_test:0.01574, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.155, tt:2355.407\n",
      "Ep:67, loss:0.00001, loss_test:0.01599, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.168, tt:2391.402\n",
      "Ep:68, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:35.176, tt:2427.138\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01606, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.193, tt:2463.543\n",
      "Ep:70, loss:0.00001, loss_test:0.01629, lr:6.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:35.210, tt:2499.910\n",
      "Ep:71, loss:0.00001, loss_test:0.01576, lr:6.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:35.217, tt:2535.614\n",
      "Ep:72, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.238, tt:2572.401\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01581, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:35.254, tt:2608.828\n",
      "Ep:74, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.259, tt:2644.428\n",
      "Ep:75, loss:0.00001, loss_test:0.01601, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.271, tt:2680.575\n",
      "Ep:76, loss:0.00001, loss_test:0.01629, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.296, tt:2717.761\n",
      "Ep:77, loss:0.00001, loss_test:0.01643, lr:6.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.306, tt:2753.856\n",
      "Ep:78, loss:0.00001, loss_test:0.01630, lr:6.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.319, tt:2790.210\n",
      "Ep:79, loss:0.00001, loss_test:0.01660, lr:6.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.341, tt:2827.274\n",
      "Ep:80, loss:0.00001, loss_test:0.01655, lr:6.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.327, tt:2861.505\n",
      "Ep:81, loss:0.00001, loss_test:0.01673, lr:6.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.330, tt:2897.053\n",
      "Ep:82, loss:0.00001, loss_test:0.01687, lr:6.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.333, tt:2932.601\n",
      "Ep:83, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.307, tt:2965.821\n",
      "Ep:84, loss:0.00001, loss_test:0.01700, lr:5.94e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.302, tt:3000.692\n",
      "Ep:85, loss:0.00001, loss_test:0.01710, lr:5.88e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.296, tt:3035.438\n",
      "Ep:86, loss:0.00001, loss_test:0.01690, lr:5.82e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.304, tt:3071.414\n",
      "Ep:87, loss:0.00001, loss_test:0.01744, lr:5.76e-02, fs:0.81967 (r=0.758,p=0.893),  time:35.312, tt:3107.490\n",
      "Ep:88, loss:0.00001, loss_test:0.01675, lr:5.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.319, tt:3143.372\n",
      "Ep:89, loss:0.00001, loss_test:0.01703, lr:5.65e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.310, tt:3177.891\n",
      "Ep:90, loss:0.00001, loss_test:0.01736, lr:5.59e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.306, tt:3212.806\n",
      "Ep:91, loss:0.00001, loss_test:0.01700, lr:5.54e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.303, tt:3247.885\n",
      "Ep:92, loss:0.00001, loss_test:0.01719, lr:5.48e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.294, tt:3282.332\n",
      "Ep:93, loss:0.00001, loss_test:0.01762, lr:5.43e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.300, tt:3318.219\n",
      "Ep:94, loss:0.00001, loss_test:0.01690, lr:5.37e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.281, tt:3351.682\n",
      "Ep:95, loss:0.00001, loss_test:0.01808, lr:5.32e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.286, tt:3387.485\n",
      "Ep:96, loss:0.00001, loss_test:0.01702, lr:5.27e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.274, tt:3421.594\n",
      "Ep:97, loss:0.00001, loss_test:0.01825, lr:5.21e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.277, tt:3457.121\n",
      "Ep:98, loss:0.00001, loss_test:0.01708, lr:5.16e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.270, tt:3491.685\n",
      "Ep:99, loss:0.00001, loss_test:0.01819, lr:5.11e-02, fs:0.81111 (r=0.737,p=0.901),  time:35.262, tt:3526.207\n",
      "Ep:100, loss:0.00001, loss_test:0.01756, lr:5.06e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.261, tt:3561.394\n",
      "Ep:101, loss:0.00001, loss_test:0.01772, lr:5.01e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.264, tt:3596.950\n",
      "Ep:102, loss:0.00001, loss_test:0.01851, lr:4.96e-02, fs:0.81111 (r=0.737,p=0.901),  time:35.256, tt:3631.361\n",
      "Ep:103, loss:0.00001, loss_test:0.01725, lr:4.91e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.249, tt:3665.925\n",
      "Ep:104, loss:0.00001, loss_test:0.01934, lr:4.86e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.249, tt:3701.185\n",
      "Ep:105, loss:0.00001, loss_test:0.01721, lr:4.81e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.236, tt:3735.008\n",
      "Ep:106, loss:0.00001, loss_test:0.01908, lr:4.76e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.232, tt:3769.786\n",
      "Ep:107, loss:0.00000, loss_test:0.01752, lr:4.71e-02, fs:0.81564 (r=0.737,p=0.912),  time:35.211, tt:3802.802\n",
      "Ep:108, loss:0.00000, loss_test:0.01864, lr:4.67e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.190, tt:3835.673\n",
      "Ep:109, loss:0.00000, loss_test:0.01828, lr:4.62e-02, fs:0.81111 (r=0.737,p=0.901),  time:35.186, tt:3870.433\n",
      "Ep:110, loss:0.00000, loss_test:0.01848, lr:4.57e-02, fs:0.80899 (r=0.727,p=0.911),  time:35.173, tt:3904.249\n",
      "Ep:111, loss:0.00000, loss_test:0.01842, lr:4.53e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.168, tt:3938.761\n",
      "Ep:112, loss:0.00000, loss_test:0.01873, lr:4.48e-02, fs:0.80226 (r=0.717,p=0.910),  time:35.154, tt:3972.396\n",
      "Ep:113, loss:0.00000, loss_test:0.01853, lr:4.44e-02, fs:0.79545 (r=0.707,p=0.909),  time:35.135, tt:4005.401\n",
      "Ep:114, loss:0.00000, loss_test:0.01872, lr:4.39e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.147, tt:4041.927\n",
      "Ep:115, loss:0.00000, loss_test:0.01911, lr:4.35e-02, fs:0.79545 (r=0.707,p=0.909),  time:35.144, tt:4076.730\n",
      "Ep:116, loss:0.00000, loss_test:0.01877, lr:4.31e-02, fs:0.78857 (r=0.697,p=0.908),  time:35.137, tt:4111.006\n",
      "Ep:117, loss:0.00000, loss_test:0.01916, lr:4.26e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.128, tt:4145.048\n",
      "Ep:118, loss:0.00000, loss_test:0.01873, lr:4.22e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.111, tt:4178.166\n",
      "Ep:119, loss:0.00000, loss_test:0.01955, lr:4.18e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.100, tt:4211.988\n",
      "Ep:120, loss:0.00000, loss_test:0.01922, lr:4.14e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.090, tt:4245.855\n",
      "Ep:121, loss:0.00000, loss_test:0.01917, lr:4.10e-02, fs:0.78613 (r=0.687,p=0.919),  time:35.074, tt:4279.004\n",
      "Ep:122, loss:0.00000, loss_test:0.01946, lr:4.05e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.054, tt:4311.615\n",
      "Ep:123, loss:0.00000, loss_test:0.01944, lr:4.01e-02, fs:0.78161 (r=0.687,p=0.907),  time:35.034, tt:4344.201\n",
      "Ep:124, loss:0.00000, loss_test:0.01944, lr:3.97e-02, fs:0.78363 (r=0.677,p=0.931),  time:35.020, tt:4377.525\n",
      "Ep:125, loss:0.00000, loss_test:0.01956, lr:3.93e-02, fs:0.76744 (r=0.667,p=0.904),  time:35.009, tt:4411.112\n",
      "Ep:126, loss:0.00000, loss_test:0.01964, lr:3.89e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.021, tt:4447.705\n",
      "Ep:127, loss:0.00000, loss_test:0.01971, lr:3.86e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.019, tt:4482.369\n",
      "Ep:128, loss:0.00000, loss_test:0.01979, lr:3.82e-02, fs:0.77193 (r=0.667,p=0.917),  time:35.027, tt:4518.476\n",
      "Ep:129, loss:0.00000, loss_test:0.02010, lr:3.78e-02, fs:0.76471 (r=0.657,p=0.915),  time:35.038, tt:4554.895\n",
      "Ep:130, loss:0.00000, loss_test:0.01985, lr:3.74e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.041, tt:4590.425\n",
      "Ep:131, loss:0.00000, loss_test:0.01983, lr:3.70e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.038, tt:4624.961\n",
      "Ep:132, loss:0.00000, loss_test:0.02030, lr:3.67e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.039, tt:4660.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01987, lr:3.63e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.029, tt:4693.931\n",
      "Ep:134, loss:0.00000, loss_test:0.02028, lr:3.59e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.043, tt:4730.870\n",
      "Ep:135, loss:0.00000, loss_test:0.02029, lr:3.56e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.026, tt:4763.593\n",
      "Ep:136, loss:0.00000, loss_test:0.02002, lr:3.52e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.030, tt:4799.114\n",
      "Ep:137, loss:0.00000, loss_test:0.02071, lr:3.49e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.021, tt:4832.878\n",
      "Ep:138, loss:0.00000, loss_test:0.02000, lr:3.45e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.017, tt:4867.393\n",
      "Ep:139, loss:0.00000, loss_test:0.02086, lr:3.42e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.019, tt:4902.667\n",
      "Ep:140, loss:0.00000, loss_test:0.02024, lr:3.38e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.023, tt:4938.205\n",
      "Ep:141, loss:0.00000, loss_test:0.02067, lr:3.35e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.023, tt:4973.321\n",
      "Ep:142, loss:0.00000, loss_test:0.02055, lr:3.32e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.029, tt:5009.176\n",
      "Ep:143, loss:0.00000, loss_test:0.02091, lr:3.28e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.026, tt:5043.760\n",
      "Ep:144, loss:0.00000, loss_test:0.02069, lr:3.25e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.011, tt:5076.634\n",
      "Ep:145, loss:0.00000, loss_test:0.02094, lr:3.22e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.019, tt:5112.814\n",
      "Ep:146, loss:0.00000, loss_test:0.02067, lr:3.19e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.028, tt:5149.172\n",
      "Ep:147, loss:0.00000, loss_test:0.02103, lr:3.15e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.033, tt:5184.944\n",
      "Ep:148, loss:0.00000, loss_test:0.02081, lr:3.12e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.041, tt:5221.077\n",
      "Ep:149, loss:0.00000, loss_test:0.02113, lr:3.09e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.043, tt:5256.380\n",
      "Ep:150, loss:0.00000, loss_test:0.02102, lr:3.06e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.034, tt:5290.155\n",
      "Ep:151, loss:0.00000, loss_test:0.02106, lr:3.03e-02, fs:0.76647 (r=0.646,p=0.941),  time:35.028, tt:5324.256\n",
      "Ep:152, loss:0.00000, loss_test:0.02123, lr:3.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.031, tt:5359.783\n",
      "Ep:153, loss:0.00000, loss_test:0.02113, lr:2.97e-02, fs:0.76647 (r=0.646,p=0.941),  time:35.039, tt:5395.937\n",
      "Ep:154, loss:0.00000, loss_test:0.02140, lr:2.94e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.037, tt:5430.669\n",
      "Ep:155, loss:0.00000, loss_test:0.02129, lr:2.91e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.040, tt:5466.275\n",
      "Ep:156, loss:0.00000, loss_test:0.02126, lr:2.88e-02, fs:0.76647 (r=0.646,p=0.941),  time:35.040, tt:5501.313\n",
      "Ep:157, loss:0.00000, loss_test:0.02142, lr:2.85e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.041, tt:5536.517\n",
      "Ep:158, loss:0.00000, loss_test:0.02140, lr:2.82e-02, fs:0.76647 (r=0.646,p=0.941),  time:35.042, tt:5571.757\n",
      "Ep:159, loss:0.00000, loss_test:0.02156, lr:2.80e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.036, tt:5605.740\n",
      "Ep:160, loss:0.00000, loss_test:0.02142, lr:2.77e-02, fs:0.76647 (r=0.646,p=0.941),  time:35.036, tt:5640.785\n",
      "Ep:161, loss:0.00000, loss_test:0.02173, lr:2.74e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.031, tt:5675.083\n",
      "Ep:162, loss:0.00000, loss_test:0.02152, lr:2.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.040, tt:5711.447\n",
      "Ep:163, loss:0.00000, loss_test:0.02165, lr:2.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.030, tt:5744.966\n",
      "Ep:164, loss:0.00000, loss_test:0.02170, lr:2.66e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.021, tt:5778.465\n",
      "Ep:165, loss:0.00000, loss_test:0.02169, lr:2.63e-02, fs:0.75740 (r=0.646,p=0.914),  time:35.014, tt:5812.299\n",
      "Ep:166, loss:0.00000, loss_test:0.02172, lr:2.61e-02, fs:0.76190 (r=0.646,p=0.928),  time:35.000, tt:5844.935\n",
      "Ep:167, loss:0.00000, loss_test:0.02178, lr:2.58e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.983, tt:5877.141\n",
      "Ep:168, loss:0.00000, loss_test:0.02185, lr:2.55e-02, fs:0.76647 (r=0.646,p=0.941),  time:34.971, tt:5910.085\n",
      "Ep:169, loss:0.00000, loss_test:0.02187, lr:2.53e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.971, tt:5945.076\n",
      "Ep:170, loss:0.00000, loss_test:0.02188, lr:2.50e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.964, tt:5978.831\n",
      "Ep:171, loss:0.00000, loss_test:0.02208, lr:2.48e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.956, tt:6012.519\n",
      "Ep:172, loss:0.00000, loss_test:0.02186, lr:2.45e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.961, tt:6048.183\n",
      "Ep:173, loss:0.00000, loss_test:0.02196, lr:2.43e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.952, tt:6081.581\n",
      "Ep:174, loss:0.00000, loss_test:0.02213, lr:2.40e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.945, tt:6115.401\n",
      "Ep:175, loss:0.00000, loss_test:0.02212, lr:2.38e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.940, tt:6149.397\n",
      "Ep:176, loss:0.00000, loss_test:0.02219, lr:2.36e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.930, tt:6182.684\n",
      "Ep:177, loss:0.00000, loss_test:0.02229, lr:2.33e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.947, tt:6220.584\n",
      "Ep:178, loss:0.00000, loss_test:0.02221, lr:2.31e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.944, tt:6254.959\n",
      "Ep:179, loss:0.00000, loss_test:0.02233, lr:2.29e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.936, tt:6288.471\n",
      "Ep:180, loss:0.00000, loss_test:0.02220, lr:2.26e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.932, tt:6322.644\n",
      "Ep:181, loss:0.00000, loss_test:0.02237, lr:2.24e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.925, tt:6356.278\n",
      "Ep:182, loss:0.00000, loss_test:0.02236, lr:2.22e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.910, tt:6388.552\n",
      "Ep:183, loss:0.00000, loss_test:0.02237, lr:2.20e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.899, tt:6421.403\n",
      "Ep:184, loss:0.00000, loss_test:0.02235, lr:2.17e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.889, tt:6454.385\n",
      "Ep:185, loss:0.00000, loss_test:0.02250, lr:2.15e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.869, tt:6485.621\n",
      "Ep:186, loss:0.00000, loss_test:0.02250, lr:2.13e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.866, tt:6520.004\n",
      "Ep:187, loss:0.00000, loss_test:0.02240, lr:2.11e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.864, tt:6554.339\n",
      "Ep:188, loss:0.00000, loss_test:0.02267, lr:2.09e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.859, tt:6588.382\n",
      "Ep:189, loss:0.00000, loss_test:0.02248, lr:2.07e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.856, tt:6622.682\n",
      "Ep:190, loss:0.00000, loss_test:0.02263, lr:2.05e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.850, tt:6656.340\n",
      "Ep:191, loss:0.00000, loss_test:0.02259, lr:2.03e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.847, tt:6690.653\n",
      "Ep:192, loss:0.00000, loss_test:0.02270, lr:2.01e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.860, tt:6727.913\n",
      "Ep:193, loss:0.00000, loss_test:0.02263, lr:1.99e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.853, tt:6761.529\n",
      "Ep:194, loss:0.00000, loss_test:0.02276, lr:1.97e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.848, tt:6795.281\n",
      "Ep:195, loss:0.00000, loss_test:0.02262, lr:1.95e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.841, tt:6828.793\n",
      "Ep:196, loss:0.00000, loss_test:0.02285, lr:1.93e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.840, tt:6863.415\n",
      "Ep:197, loss:0.00000, loss_test:0.02279, lr:1.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.837, tt:6897.670\n",
      "Ep:198, loss:0.00000, loss_test:0.02269, lr:1.89e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.831, tt:6931.405\n",
      "Ep:199, loss:0.00000, loss_test:0.02284, lr:1.87e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.833, tt:6966.567\n",
      "Ep:200, loss:0.00000, loss_test:0.02295, lr:1.85e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.834, tt:7001.566\n",
      "Ep:201, loss:0.00000, loss_test:0.02277, lr:1.83e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.831, tt:7035.869\n",
      "Ep:202, loss:0.00000, loss_test:0.02287, lr:1.81e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.826, tt:7069.673\n",
      "Ep:203, loss:0.00000, loss_test:0.02303, lr:1.80e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.821, tt:7103.393\n",
      "Ep:204, loss:0.00000, loss_test:0.02292, lr:1.78e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.811, tt:7136.317\n",
      "Ep:205, loss:0.00000, loss_test:0.02290, lr:1.76e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.802, tt:7169.148\n",
      "Ep:206, loss:0.00000, loss_test:0.02310, lr:1.74e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.794, tt:7202.403\n",
      "Ep:207, loss:0.00000, loss_test:0.02298, lr:1.73e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.795, tt:7237.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.02299, lr:1.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.776, tt:7268.152\n",
      "Ep:209, loss:0.00000, loss_test:0.02322, lr:1.69e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.759, tt:7299.319\n",
      "Ep:210, loss:0.00000, loss_test:0.02311, lr:1.67e-02, fs:0.75740 (r=0.646,p=0.914),  time:34.746, tt:7331.407\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14035, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:32.890, tt:32.890\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13769, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:32.255, tt:64.510\n",
      "Ep:2, loss:0.00027, loss_test:0.13339, lr:1.00e-02, fs:0.65000 (r=0.919,p=0.503),  time:32.468, tt:97.404\n",
      "Ep:3, loss:0.00027, loss_test:0.12705, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:33.786, tt:135.144\n",
      "Ep:4, loss:0.00026, loss_test:0.12022, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:33.891, tt:169.455\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11511, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:34.002, tt:204.011\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11243, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:34.035, tt:238.248\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11076, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:34.349, tt:274.791\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11007, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:34.603, tt:311.424\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.10814, lr:1.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:34.674, tt:346.744\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.10525, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:34.637, tt:381.012\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10329, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:34.810, tt:417.721\n",
      "Ep:12, loss:0.00022, loss_test:0.10175, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:34.732, tt:451.520\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10062, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:34.804, tt:487.251\n",
      "Ep:14, loss:0.00021, loss_test:0.09877, lr:1.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:34.879, tt:523.184\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09714, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:35.003, tt:560.049\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09485, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:35.008, tt:595.136\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09289, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:35.242, tt:634.348\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00019, loss_test:0.09254, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:35.314, tt:670.972\n",
      "Ep:19, loss:0.00018, loss_test:0.09098, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:35.436, tt:708.713\n",
      "Ep:20, loss:0.00017, loss_test:0.08957, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:35.453, tt:744.511\n",
      "Ep:21, loss:0.00017, loss_test:0.08932, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:35.459, tt:780.094\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.08773, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:35.513, tt:816.803\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08610, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:35.619, tt:854.855\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08583, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:35.732, tt:893.292\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08461, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.777, tt:930.213\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08311, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:35.831, tt:967.441\n",
      "Ep:27, loss:0.00014, loss_test:0.08340, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:35.919, tt:1005.744\n",
      "Ep:28, loss:0.00013, loss_test:0.08195, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.932, tt:1042.028\n",
      "Ep:29, loss:0.00013, loss_test:0.08108, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:35.963, tt:1078.885\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08081, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:36.002, tt:1116.060\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07916, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:36.071, tt:1154.261\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07785, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:36.090, tt:1190.976\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07739, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:36.155, tt:1229.276\n",
      "Ep:34, loss:0.00011, loss_test:0.07601, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:36.204, tt:1267.140\n",
      "Ep:35, loss:0.00010, loss_test:0.07561, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:36.228, tt:1304.207\n",
      "Ep:36, loss:0.00010, loss_test:0.07539, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.268, tt:1341.929\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07440, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.307, tt:1379.663\n",
      "Ep:38, loss:0.00010, loss_test:0.07346, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:36.359, tt:1418.002\n",
      "Ep:39, loss:0.00009, loss_test:0.07218, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:36.386, tt:1455.438\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07369, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.417, tt:1493.077\n",
      "Ep:41, loss:0.00009, loss_test:0.07353, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:36.414, tt:1529.403\n",
      "Ep:42, loss:0.00008, loss_test:0.07283, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.429, tt:1566.442\n",
      "Ep:43, loss:0.00008, loss_test:0.07181, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.465, tt:1604.460\n",
      "Ep:44, loss:0.00008, loss_test:0.07123, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.519, tt:1643.350\n",
      "Ep:45, loss:0.00008, loss_test:0.07243, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:36.551, tt:1681.345\n",
      "Ep:46, loss:0.00007, loss_test:0.07093, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.559, tt:1718.296\n",
      "Ep:47, loss:0.00007, loss_test:0.07155, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:36.636, tt:1758.543\n",
      "Ep:48, loss:0.00007, loss_test:0.07294, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.639, tt:1795.321\n",
      "Ep:49, loss:0.00007, loss_test:0.07195, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.688, tt:1834.396\n",
      "Ep:50, loss:0.00007, loss_test:0.07660, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:36.714, tt:1872.439\n",
      "Ep:51, loss:0.00007, loss_test:0.07094, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:36.741, tt:1910.513\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.07716, lr:9.90e-03, fs:0.80628 (r=0.778,p=0.837),  time:36.748, tt:1947.670\n",
      "Ep:53, loss:0.00007, loss_test:0.07036, lr:9.90e-03, fs:0.81443 (r=0.798,p=0.832),  time:36.740, tt:1983.984\n",
      "Ep:54, loss:0.00006, loss_test:0.07837, lr:9.90e-03, fs:0.78534 (r=0.758,p=0.815),  time:36.737, tt:2020.528\n",
      "Ep:55, loss:0.00006, loss_test:0.07131, lr:9.90e-03, fs:0.81865 (r=0.798,p=0.840),  time:36.715, tt:2056.050\n",
      "Ep:56, loss:0.00006, loss_test:0.07579, lr:9.90e-03, fs:0.78495 (r=0.737,p=0.839),  time:36.750, tt:2094.736\n",
      "Ep:57, loss:0.00006, loss_test:0.07287, lr:9.90e-03, fs:0.79381 (r=0.778,p=0.811),  time:36.748, tt:2131.376\n",
      "Ep:58, loss:0.00006, loss_test:0.07270, lr:9.90e-03, fs:0.80214 (r=0.758,p=0.852),  time:36.765, tt:2169.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00005, loss_test:0.07315, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:36.769, tt:2206.155\n",
      "Ep:60, loss:0.00005, loss_test:0.07291, lr:9.90e-03, fs:0.79787 (r=0.758,p=0.843),  time:36.776, tt:2243.330\n",
      "Ep:61, loss:0.00006, loss_test:0.07420, lr:9.90e-03, fs:0.78947 (r=0.758,p=0.824),  time:36.786, tt:2280.713\n",
      "Ep:62, loss:0.00005, loss_test:0.07215, lr:9.90e-03, fs:0.80000 (r=0.747,p=0.860),  time:36.776, tt:2316.888\n",
      "Ep:63, loss:0.00005, loss_test:0.07377, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.763, tt:2352.823\n",
      "Ep:64, loss:0.00005, loss_test:0.07409, lr:9.70e-03, fs:0.79144 (r=0.747,p=0.841),  time:36.786, tt:2391.102\n",
      "Ep:65, loss:0.00005, loss_test:0.07690, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:36.778, tt:2427.320\n",
      "Ep:66, loss:0.00005, loss_test:0.07298, lr:9.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:36.766, tt:2463.353\n",
      "Ep:67, loss:0.00005, loss_test:0.07713, lr:9.41e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.767, tt:2500.132\n",
      "Ep:68, loss:0.00005, loss_test:0.07512, lr:9.32e-03, fs:0.80645 (r=0.758,p=0.862),  time:36.762, tt:2536.563\n",
      "Ep:69, loss:0.00005, loss_test:0.07386, lr:9.23e-03, fs:0.78947 (r=0.758,p=0.824),  time:36.747, tt:2572.287\n",
      "Ep:70, loss:0.00004, loss_test:0.07563, lr:9.14e-03, fs:0.81720 (r=0.768,p=0.874),  time:36.741, tt:2608.632\n",
      "Ep:71, loss:0.00004, loss_test:0.07619, lr:9.04e-03, fs:0.75000 (r=0.697,p=0.812),  time:36.744, tt:2645.550\n",
      "Ep:72, loss:0.00004, loss_test:0.07574, lr:8.95e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.745, tt:2682.362\n",
      "Ep:73, loss:0.00004, loss_test:0.07429, lr:8.86e-03, fs:0.75556 (r=0.687,p=0.840),  time:36.737, tt:2718.572\n",
      "Ep:74, loss:0.00004, loss_test:0.07901, lr:8.78e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.739, tt:2755.412\n",
      "Ep:75, loss:0.00004, loss_test:0.07404, lr:8.69e-03, fs:0.80628 (r=0.778,p=0.837),  time:36.744, tt:2792.511\n",
      "Ep:76, loss:0.00004, loss_test:0.07811, lr:8.60e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.759, tt:2830.406\n",
      "Ep:77, loss:0.00004, loss_test:0.07511, lr:8.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:36.767, tt:2867.802\n",
      "Ep:78, loss:0.00004, loss_test:0.07427, lr:8.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.788, tt:2906.213\n",
      "Ep:79, loss:0.00004, loss_test:0.08079, lr:8.35e-03, fs:0.79121 (r=0.727,p=0.867),  time:36.786, tt:2942.904\n",
      "Ep:80, loss:0.00004, loss_test:0.07259, lr:8.26e-03, fs:0.78453 (r=0.717,p=0.866),  time:36.778, tt:2978.979\n",
      "Ep:81, loss:0.00004, loss_test:0.07876, lr:8.18e-03, fs:0.77348 (r=0.707,p=0.854),  time:36.780, tt:3015.990\n",
      "Ep:82, loss:0.00004, loss_test:0.07554, lr:8.10e-03, fs:0.79781 (r=0.737,p=0.869),  time:36.772, tt:3052.096\n",
      "Ep:83, loss:0.00004, loss_test:0.07478, lr:8.02e-03, fs:0.76136 (r=0.677,p=0.870),  time:36.773, tt:3088.892\n",
      "Ep:84, loss:0.00003, loss_test:0.07741, lr:7.94e-03, fs:0.78689 (r=0.727,p=0.857),  time:36.760, tt:3124.584\n",
      "Ep:85, loss:0.00003, loss_test:0.07334, lr:7.86e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.765, tt:3161.760\n",
      "Ep:86, loss:0.00003, loss_test:0.07930, lr:7.78e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.751, tt:3197.323\n",
      "Ep:87, loss:0.00003, loss_test:0.07438, lr:7.70e-03, fs:0.80435 (r=0.747,p=0.871),  time:36.740, tt:3233.126\n",
      "Ep:88, loss:0.00003, loss_test:0.07844, lr:7.62e-03, fs:0.74713 (r=0.657,p=0.867),  time:36.720, tt:3268.094\n",
      "Ep:89, loss:0.00003, loss_test:0.07896, lr:7.55e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.694, tt:3302.429\n",
      "Ep:90, loss:0.00003, loss_test:0.07572, lr:7.47e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.668, tt:3336.747\n",
      "Ep:91, loss:0.00003, loss_test:0.07855, lr:7.40e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.664, tt:3373.070\n",
      "Ep:92, loss:0.00003, loss_test:0.07492, lr:7.32e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.659, tt:3409.274\n",
      "Ep:93, loss:0.00003, loss_test:0.07932, lr:7.25e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.657, tt:3445.798\n",
      "Ep:94, loss:0.00003, loss_test:0.07760, lr:7.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:36.662, tt:3482.873\n",
      "Ep:95, loss:0.00003, loss_test:0.07481, lr:7.11e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.651, tt:3518.480\n",
      "Ep:96, loss:0.00003, loss_test:0.07681, lr:7.03e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.633, tt:3553.375\n",
      "Ep:97, loss:0.00003, loss_test:0.07370, lr:6.96e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.623, tt:3589.051\n",
      "Ep:98, loss:0.00003, loss_test:0.07748, lr:6.89e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.616, tt:3624.994\n",
      "Ep:99, loss:0.00003, loss_test:0.07461, lr:6.83e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.621, tt:3662.146\n",
      "Ep:100, loss:0.00003, loss_test:0.07668, lr:6.76e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.616, tt:3698.253\n",
      "Ep:101, loss:0.00003, loss_test:0.07516, lr:6.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.617, tt:3734.961\n",
      "Ep:102, loss:0.00003, loss_test:0.07476, lr:6.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.616, tt:3771.484\n",
      "Ep:103, loss:0.00003, loss_test:0.07475, lr:6.56e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.602, tt:3806.641\n",
      "Ep:104, loss:0.00003, loss_test:0.07621, lr:6.49e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.599, tt:3842.932\n",
      "Ep:105, loss:0.00002, loss_test:0.07560, lr:6.43e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.596, tt:3879.190\n",
      "Ep:106, loss:0.00002, loss_test:0.07648, lr:6.36e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.602, tt:3916.391\n",
      "Ep:107, loss:0.00002, loss_test:0.07461, lr:6.30e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.609, tt:3953.818\n",
      "Ep:108, loss:0.00002, loss_test:0.07599, lr:6.24e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.601, tt:3989.473\n",
      "Ep:109, loss:0.00002, loss_test:0.07496, lr:6.17e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.598, tt:4025.822\n",
      "Ep:110, loss:0.00002, loss_test:0.07687, lr:6.11e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.590, tt:4061.473\n",
      "Ep:111, loss:0.00002, loss_test:0.07512, lr:6.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.597, tt:4098.855\n",
      "Ep:112, loss:0.00002, loss_test:0.07703, lr:5.99e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.601, tt:4135.873\n",
      "Ep:113, loss:0.00002, loss_test:0.07591, lr:5.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.596, tt:4171.887\n",
      "Ep:114, loss:0.00002, loss_test:0.07509, lr:5.87e-03, fs:0.76471 (r=0.657,p=0.915),  time:36.609, tt:4210.090\n",
      "Ep:115, loss:0.00002, loss_test:0.07777, lr:5.81e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.637, tt:4249.837\n",
      "Ep:116, loss:0.00002, loss_test:0.07460, lr:5.75e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.638, tt:4286.668\n",
      "Ep:117, loss:0.00002, loss_test:0.07526, lr:5.70e-03, fs:0.78824 (r=0.677,p=0.944),  time:36.644, tt:4323.978\n",
      "Ep:118, loss:0.00002, loss_test:0.07571, lr:5.64e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.638, tt:4359.881\n",
      "Ep:119, loss:0.00002, loss_test:0.07704, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.635, tt:4396.172\n",
      "Ep:120, loss:0.00002, loss_test:0.07758, lr:5.53e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.627, tt:4431.822\n",
      "Ep:121, loss:0.00002, loss_test:0.07489, lr:5.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:36.627, tt:4468.518\n",
      "Ep:122, loss:0.00002, loss_test:0.07954, lr:5.42e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.625, tt:4504.916\n",
      "Ep:123, loss:0.00002, loss_test:0.07480, lr:5.36e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.620, tt:4540.880\n",
      "Ep:124, loss:0.00002, loss_test:0.07802, lr:5.31e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.608, tt:4576.019\n",
      "Ep:125, loss:0.00002, loss_test:0.07647, lr:5.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.612, tt:4613.099\n",
      "Ep:126, loss:0.00002, loss_test:0.07731, lr:5.20e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.608, tt:4649.191\n",
      "Ep:127, loss:0.00002, loss_test:0.07599, lr:5.15e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.611, tt:4686.262\n",
      "Ep:128, loss:0.00002, loss_test:0.07528, lr:5.10e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.616, tt:4723.525\n",
      "Ep:129, loss:0.00002, loss_test:0.07650, lr:5.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.619, tt:4760.441\n",
      "Ep:130, loss:0.00002, loss_test:0.07706, lr:5.00e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.591, tt:4793.384\n",
      "Ep:131, loss:0.00002, loss_test:0.07724, lr:4.95e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.584, tt:4829.122\n",
      "Ep:132, loss:0.00002, loss_test:0.07620, lr:4.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.586, tt:4865.985\n",
      "Ep:133, loss:0.00002, loss_test:0.07755, lr:4.85e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.580, tt:4901.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.07612, lr:4.80e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.578, tt:4938.064\n",
      "Ep:135, loss:0.00002, loss_test:0.07945, lr:4.75e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.578, tt:4974.634\n",
      "Ep:136, loss:0.00002, loss_test:0.07476, lr:4.71e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.573, tt:5010.461\n",
      "Ep:137, loss:0.00002, loss_test:0.07969, lr:4.66e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.575, tt:5047.356\n",
      "Ep:138, loss:0.00002, loss_test:0.07653, lr:4.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.570, tt:5083.247\n",
      "Ep:139, loss:0.00002, loss_test:0.07695, lr:4.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.571, tt:5119.918\n",
      "Ep:140, loss:0.00002, loss_test:0.07917, lr:4.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.570, tt:5156.329\n",
      "Ep:141, loss:0.00002, loss_test:0.07732, lr:4.48e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.566, tt:5192.432\n",
      "Ep:142, loss:0.00002, loss_test:0.07716, lr:4.43e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.565, tt:5228.843\n",
      "Ep:143, loss:0.00002, loss_test:0.07907, lr:4.39e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.568, tt:5265.815\n",
      "Ep:144, loss:0.00002, loss_test:0.07648, lr:4.34e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.574, tt:5303.221\n",
      "Ep:145, loss:0.00002, loss_test:0.07906, lr:4.30e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.576, tt:5340.051\n",
      "Ep:146, loss:0.00002, loss_test:0.07739, lr:4.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.584, tt:5377.846\n",
      "Ep:147, loss:0.00002, loss_test:0.07755, lr:4.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.585, tt:5414.524\n",
      "Ep:148, loss:0.00002, loss_test:0.07788, lr:4.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.585, tt:5451.143\n",
      "Ep:149, loss:0.00002, loss_test:0.07726, lr:4.13e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.581, tt:5487.149\n",
      "Ep:150, loss:0.00002, loss_test:0.07846, lr:4.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.584, tt:5524.189\n",
      "Ep:151, loss:0.00002, loss_test:0.07798, lr:4.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.569, tt:5558.479\n",
      "Ep:152, loss:0.00002, loss_test:0.07918, lr:4.01e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.599, tt:5599.650\n",
      "Ep:153, loss:0.00002, loss_test:0.07837, lr:3.97e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.600, tt:5636.430\n",
      "Ep:154, loss:0.00002, loss_test:0.07759, lr:3.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.606, tt:5673.973\n",
      "Ep:155, loss:0.00002, loss_test:0.07888, lr:3.89e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.615, tt:5711.896\n",
      "Ep:156, loss:0.00001, loss_test:0.07859, lr:3.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.624, tt:5750.024\n",
      "Ep:157, loss:0.00001, loss_test:0.07806, lr:3.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.632, tt:5787.857\n",
      "Ep:158, loss:0.00001, loss_test:0.07852, lr:3.77e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.635, tt:5824.903\n",
      "Ep:159, loss:0.00001, loss_test:0.07881, lr:3.73e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.639, tt:5862.288\n",
      "Ep:160, loss:0.00001, loss_test:0.07830, lr:3.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.635, tt:5898.268\n",
      "Ep:161, loss:0.00001, loss_test:0.07899, lr:3.66e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.639, tt:5935.451\n",
      "Ep:162, loss:0.00001, loss_test:0.07820, lr:3.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.637, tt:5971.862\n",
      "Ep:163, loss:0.00001, loss_test:0.07866, lr:3.59e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.636, tt:6008.272\n",
      "Ep:164, loss:0.00001, loss_test:0.07902, lr:3.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.622, tt:6042.590\n",
      "Ep:165, loss:0.00001, loss_test:0.07834, lr:3.52e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.621, tt:6079.021\n",
      "Ep:166, loss:0.00001, loss_test:0.07835, lr:3.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.614, tt:6114.457\n",
      "Ep:167, loss:0.00001, loss_test:0.07834, lr:3.45e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.616, tt:6151.439\n",
      "Ep:168, loss:0.00001, loss_test:0.07857, lr:3.41e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.605, tt:6186.182\n",
      "Ep:169, loss:0.00001, loss_test:0.07849, lr:3.38e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.597, tt:6221.411\n",
      "Ep:170, loss:0.00001, loss_test:0.07922, lr:3.34e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.587, tt:6256.451\n",
      "Ep:171, loss:0.00001, loss_test:0.07741, lr:3.31e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.584, tt:6292.426\n",
      "Ep:172, loss:0.00001, loss_test:0.07956, lr:3.28e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.579, tt:6328.176\n",
      "Ep:173, loss:0.00001, loss_test:0.07825, lr:3.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.572, tt:6363.605\n",
      "Ep:174, loss:0.00001, loss_test:0.07919, lr:3.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.569, tt:6399.600\n",
      "Ep:175, loss:0.00001, loss_test:0.07942, lr:3.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.565, tt:6435.426\n",
      "Ep:176, loss:0.00001, loss_test:0.07814, lr:3.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.564, tt:6471.870\n",
      "Ep:177, loss:0.00001, loss_test:0.07942, lr:3.12e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.563, tt:6508.139\n",
      "Ep:178, loss:0.00001, loss_test:0.07941, lr:3.09e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.560, tt:6544.305\n",
      "Ep:179, loss:0.00001, loss_test:0.07860, lr:3.05e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.556, tt:6580.112\n",
      "Ep:180, loss:0.00001, loss_test:0.07882, lr:3.02e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.567, tt:6618.678\n",
      "Ep:181, loss:0.00001, loss_test:0.08121, lr:2.99e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.561, tt:6654.049\n",
      "Ep:182, loss:0.00001, loss_test:0.07792, lr:2.96e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.558, tt:6690.171\n",
      "Ep:183, loss:0.00001, loss_test:0.07849, lr:2.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.553, tt:6725.714\n",
      "Ep:184, loss:0.00001, loss_test:0.08022, lr:2.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.547, tt:6761.142\n",
      "Ep:185, loss:0.00001, loss_test:0.07852, lr:2.88e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.547, tt:6797.769\n",
      "Ep:186, loss:0.00001, loss_test:0.08032, lr:2.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:36.552, tt:6835.187\n",
      "Ep:187, loss:0.00001, loss_test:0.07955, lr:2.82e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.555, tt:6872.406\n",
      "Ep:188, loss:0.00001, loss_test:0.07863, lr:2.79e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.550, tt:6907.989\n",
      "Ep:189, loss:0.00001, loss_test:0.08054, lr:2.76e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.561, tt:6946.680\n",
      "Ep:190, loss:0.00001, loss_test:0.07904, lr:2.73e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.552, tt:6981.477\n",
      "Ep:191, loss:0.00001, loss_test:0.07897, lr:2.71e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.545, tt:7016.693\n",
      "Ep:192, loss:0.00001, loss_test:0.08007, lr:2.68e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.542, tt:7052.631\n",
      "Ep:193, loss:0.00001, loss_test:0.07897, lr:2.65e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.534, tt:7087.537\n",
      "Ep:194, loss:0.00001, loss_test:0.07900, lr:2.63e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.534, tt:7124.136\n",
      "Ep:195, loss:0.00001, loss_test:0.07941, lr:2.60e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.538, tt:7161.404\n",
      "Ep:196, loss:0.00001, loss_test:0.07856, lr:2.57e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.541, tt:7198.535\n",
      "Ep:197, loss:0.00001, loss_test:0.07983, lr:2.55e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.531, tt:7233.072\n",
      "Ep:198, loss:0.00001, loss_test:0.07921, lr:2.52e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.531, tt:7269.715\n",
      "Ep:199, loss:0.00001, loss_test:0.07906, lr:2.50e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.524, tt:7304.794\n",
      "Ep:200, loss:0.00001, loss_test:0.07973, lr:2.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.525, tt:7341.476\n",
      "Ep:201, loss:0.00001, loss_test:0.07904, lr:2.45e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.520, tt:7376.940\n",
      "Ep:202, loss:0.00001, loss_test:0.07894, lr:2.42e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.520, tt:7413.499\n",
      "Ep:203, loss:0.00001, loss_test:0.07944, lr:2.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.521, tt:7450.219\n",
      "Ep:204, loss:0.00001, loss_test:0.07911, lr:2.38e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.522, tt:7486.942\n",
      "Ep:205, loss:0.00001, loss_test:0.07895, lr:2.35e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.518, tt:7522.739\n",
      "Ep:206, loss:0.00001, loss_test:0.07992, lr:2.33e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.500, tt:7555.527\n",
      "Ep:207, loss:0.00001, loss_test:0.07881, lr:2.31e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.491, tt:7590.106\n",
      "Ep:208, loss:0.00001, loss_test:0.07929, lr:2.28e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.479, tt:7624.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00001, loss_test:0.07960, lr:2.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.462, tt:7656.929\n",
      "Ep:210, loss:0.00001, loss_test:0.07882, lr:2.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:36.441, tt:7689.001\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02513, lr:6.00e-02, fs:0.61660 (r=0.788,p=0.506),  time:25.862, tt:25.862\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02542, lr:6.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:26.492, tt:52.983\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02681, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:28.525, tt:85.574\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02652, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:30.167, tt:120.667\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02528, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:30.865, tt:154.323\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.64286 (r=0.909,p=0.497),  time:30.845, tt:185.072\n",
      "Ep:6, loss:0.00004, loss_test:0.02247, lr:6.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:31.109, tt:217.760\n",
      "Ep:7, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:31.298, tt:250.383\n",
      "Ep:8, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:31.625, tt:284.626\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02033, lr:6.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:31.993, tt:319.927\n",
      "Ep:10, loss:0.00004, loss_test:0.02031, lr:6.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:32.418, tt:356.595\n",
      "Ep:11, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:32.660, tt:391.915\n",
      "Ep:12, loss:0.00004, loss_test:0.01988, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:32.849, tt:427.042\n",
      "Ep:13, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:33.035, tt:462.486\n",
      "Ep:14, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:33.143, tt:497.149\n",
      "Ep:15, loss:0.00003, loss_test:0.01938, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:33.259, tt:532.152\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01918, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:33.356, tt:567.050\n",
      "Ep:17, loss:0.00003, loss_test:0.01894, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:33.383, tt:600.897\n",
      "Ep:18, loss:0.00003, loss_test:0.01872, lr:6.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:33.382, tt:634.261\n",
      "Ep:19, loss:0.00003, loss_test:0.01836, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:33.462, tt:669.232\n",
      "Ep:20, loss:0.00003, loss_test:0.01801, lr:6.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:33.499, tt:703.487\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:33.563, tt:738.381\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:33.652, tt:774.006\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:33.610, tt:806.630\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01690, lr:6.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:33.647, tt:841.163\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01670, lr:6.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:33.744, tt:877.355\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:33.772, tt:911.853\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:33.840, tt:947.508\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01630, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:33.848, tt:981.605\n",
      "Ep:29, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:33.918, tt:1017.536\n",
      "Ep:30, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:33.959, tt:1052.715\n",
      "Ep:31, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:34.021, tt:1088.685\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:34.068, tt:1124.235\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01592, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:34.093, tt:1159.153\n",
      "Ep:34, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:34.092, tt:1193.205\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01597, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:34.104, tt:1227.753\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01596, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:34.088, tt:1261.249\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:34.141, tt:1297.362\n",
      "Ep:38, loss:0.00002, loss_test:0.01593, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:34.141, tt:1331.508\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:34.192, tt:1367.664\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.226, tt:1403.263\n",
      "Ep:41, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.177, tt:1435.439\n",
      "Ep:42, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.202, tt:1470.696\n",
      "Ep:43, loss:0.00002, loss_test:0.01605, lr:6.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.223, tt:1505.791\n",
      "Ep:44, loss:0.00002, loss_test:0.01618, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.226, tt:1540.183\n",
      "Ep:45, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.267, tt:1576.274\n",
      "Ep:46, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.275, tt:1610.913\n",
      "Ep:47, loss:0.00001, loss_test:0.01631, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.231, tt:1643.067\n",
      "Ep:48, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:34.299, tt:1680.646\n",
      "Ep:49, loss:0.00001, loss_test:0.01624, lr:6.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.302, tt:1715.085\n",
      "Ep:50, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.325, tt:1750.593\n",
      "Ep:51, loss:0.00001, loss_test:0.01646, lr:5.94e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.314, tt:1784.336\n",
      "Ep:52, loss:0.00001, loss_test:0.01638, lr:5.88e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.301, tt:1817.928\n",
      "Ep:53, loss:0.00001, loss_test:0.01613, lr:5.82e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.296, tt:1851.983\n",
      "Ep:54, loss:0.00001, loss_test:0.01644, lr:5.76e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.283, tt:1885.551\n",
      "Ep:55, loss:0.00001, loss_test:0.01649, lr:5.71e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.288, tt:1920.137\n",
      "Ep:56, loss:0.00001, loss_test:0.01629, lr:5.65e-02, fs:0.77551 (r=0.768,p=0.784),  time:34.284, tt:1954.188\n",
      "Ep:57, loss:0.00001, loss_test:0.01645, lr:5.59e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.286, tt:1988.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01621, lr:5.54e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.277, tt:2022.328\n",
      "Ep:59, loss:0.00001, loss_test:0.01640, lr:5.48e-02, fs:0.77949 (r=0.768,p=0.792),  time:34.289, tt:2057.351\n",
      "Ep:60, loss:0.00001, loss_test:0.01653, lr:5.43e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.273, tt:2090.628\n",
      "Ep:61, loss:0.00001, loss_test:0.01638, lr:5.37e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.285, tt:2125.672\n",
      "Ep:62, loss:0.00001, loss_test:0.01650, lr:5.32e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.287, tt:2160.070\n",
      "Ep:63, loss:0.00001, loss_test:0.01651, lr:5.27e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.275, tt:2193.605\n",
      "Ep:64, loss:0.00001, loss_test:0.01635, lr:5.21e-02, fs:0.78125 (r=0.758,p=0.806),  time:34.275, tt:2227.904\n",
      "Ep:65, loss:0.00001, loss_test:0.01650, lr:5.16e-02, fs:0.77895 (r=0.747,p=0.813),  time:34.280, tt:2262.496\n",
      "Ep:66, loss:0.00001, loss_test:0.01660, lr:5.11e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.288, tt:2297.296\n",
      "Ep:67, loss:0.00001, loss_test:0.01657, lr:5.06e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.303, tt:2332.575\n",
      "Ep:68, loss:0.00001, loss_test:0.01668, lr:5.01e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.301, tt:2366.803\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01662, lr:5.01e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.305, tt:2401.333\n",
      "Ep:70, loss:0.00001, loss_test:0.01666, lr:5.01e-02, fs:0.79144 (r=0.747,p=0.841),  time:34.327, tt:2437.220\n",
      "Ep:71, loss:0.00001, loss_test:0.01676, lr:5.01e-02, fs:0.78495 (r=0.737,p=0.839),  time:34.335, tt:2472.104\n",
      "Ep:72, loss:0.00001, loss_test:0.01664, lr:5.01e-02, fs:0.78919 (r=0.737,p=0.849),  time:34.350, tt:2507.544\n",
      "Ep:73, loss:0.00001, loss_test:0.01669, lr:5.01e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.365, tt:2543.000\n",
      "Ep:74, loss:0.00001, loss_test:0.01705, lr:5.01e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.380, tt:2578.511\n",
      "Ep:75, loss:0.00001, loss_test:0.01683, lr:5.01e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.389, tt:2613.578\n",
      "Ep:76, loss:0.00001, loss_test:0.01689, lr:5.01e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.388, tt:2647.897\n",
      "Ep:77, loss:0.00001, loss_test:0.01716, lr:5.01e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.417, tt:2684.493\n",
      "Ep:78, loss:0.00001, loss_test:0.01698, lr:5.01e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.424, tt:2719.495\n",
      "Ep:79, loss:0.00001, loss_test:0.01724, lr:5.01e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.436, tt:2754.846\n",
      "Ep:80, loss:0.00001, loss_test:0.01717, lr:4.96e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.444, tt:2789.977\n",
      "Ep:81, loss:0.00001, loss_test:0.01723, lr:4.91e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.443, tt:2824.300\n",
      "Ep:82, loss:0.00001, loss_test:0.01731, lr:4.86e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.451, tt:2859.419\n",
      "Ep:83, loss:0.00001, loss_test:0.01745, lr:4.81e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.438, tt:2892.823\n",
      "Ep:84, loss:0.00001, loss_test:0.01733, lr:4.76e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.399, tt:2923.902\n",
      "Ep:85, loss:0.00001, loss_test:0.01763, lr:4.71e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.362, tt:2955.097\n",
      "Ep:86, loss:0.00001, loss_test:0.01765, lr:4.67e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.372, tt:2990.389\n",
      "Ep:87, loss:0.00001, loss_test:0.01772, lr:4.62e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.375, tt:3024.960\n",
      "Ep:88, loss:0.00001, loss_test:0.01777, lr:4.57e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.367, tt:3058.620\n",
      "Ep:89, loss:0.00001, loss_test:0.01775, lr:4.53e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.385, tt:3094.615\n",
      "Ep:90, loss:0.00001, loss_test:0.01796, lr:4.48e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.365, tt:3127.258\n",
      "Ep:91, loss:0.00001, loss_test:0.01777, lr:4.44e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.378, tt:3162.781\n",
      "Ep:92, loss:0.00001, loss_test:0.01803, lr:4.39e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.387, tt:3197.948\n",
      "Ep:93, loss:0.00001, loss_test:0.01805, lr:4.35e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.388, tt:3232.438\n",
      "Ep:94, loss:0.00001, loss_test:0.01807, lr:4.31e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.387, tt:3266.774\n",
      "Ep:95, loss:0.00001, loss_test:0.01803, lr:4.26e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.382, tt:3300.641\n",
      "Ep:96, loss:0.00001, loss_test:0.01832, lr:4.22e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.382, tt:3335.040\n",
      "Ep:97, loss:0.00001, loss_test:0.01830, lr:4.18e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.381, tt:3369.335\n",
      "Ep:98, loss:0.00001, loss_test:0.01811, lr:4.14e-02, fs:0.77596 (r=0.717,p=0.845),  time:34.381, tt:3403.724\n",
      "Ep:99, loss:0.00001, loss_test:0.01856, lr:4.10e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.365, tt:3436.472\n",
      "Ep:100, loss:0.00001, loss_test:0.01846, lr:4.05e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.361, tt:3470.480\n",
      "Ep:101, loss:0.00001, loss_test:0.01840, lr:4.01e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.381, tt:3506.884\n",
      "Ep:102, loss:0.00000, loss_test:0.01857, lr:3.97e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.391, tt:3542.299\n",
      "Ep:103, loss:0.00000, loss_test:0.01866, lr:3.93e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.389, tt:3576.458\n",
      "Ep:104, loss:0.00000, loss_test:0.01866, lr:3.89e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.402, tt:3612.221\n",
      "Ep:105, loss:0.00000, loss_test:0.01892, lr:3.86e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.402, tt:3646.648\n",
      "Ep:106, loss:0.00000, loss_test:0.01877, lr:3.82e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.404, tt:3681.195\n",
      "Ep:107, loss:0.00000, loss_test:0.01881, lr:3.78e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.400, tt:3715.219\n",
      "Ep:108, loss:0.00000, loss_test:0.01909, lr:3.74e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.392, tt:3748.749\n",
      "Ep:109, loss:0.00000, loss_test:0.01892, lr:3.70e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.399, tt:3783.868\n",
      "Ep:110, loss:0.00000, loss_test:0.01905, lr:3.67e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.412, tt:3819.722\n",
      "Ep:111, loss:0.00000, loss_test:0.01906, lr:3.63e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.413, tt:3854.281\n",
      "Ep:112, loss:0.00000, loss_test:0.01909, lr:3.59e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.414, tt:3888.819\n",
      "Ep:113, loss:0.00000, loss_test:0.01917, lr:3.56e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.413, tt:3923.078\n",
      "Ep:114, loss:0.00000, loss_test:0.01934, lr:3.52e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.407, tt:3956.847\n",
      "Ep:115, loss:0.00000, loss_test:0.01920, lr:3.49e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.414, tt:3992.002\n",
      "Ep:116, loss:0.00000, loss_test:0.01939, lr:3.45e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.413, tt:4026.297\n",
      "Ep:117, loss:0.00000, loss_test:0.01953, lr:3.42e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.415, tt:4060.993\n",
      "Ep:118, loss:0.00000, loss_test:0.01948, lr:3.38e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.418, tt:4095.759\n",
      "Ep:119, loss:0.00000, loss_test:0.01958, lr:3.35e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.423, tt:4130.754\n",
      "Ep:120, loss:0.00000, loss_test:0.01962, lr:3.32e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.422, tt:4165.006\n",
      "Ep:121, loss:0.00000, loss_test:0.01975, lr:3.28e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.422, tt:4199.433\n",
      "Ep:122, loss:0.00000, loss_test:0.01978, lr:3.25e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.438, tt:4235.913\n",
      "Ep:123, loss:0.00000, loss_test:0.01987, lr:3.22e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.451, tt:4271.971\n",
      "Ep:124, loss:0.00000, loss_test:0.01978, lr:3.19e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.452, tt:4306.455\n",
      "Ep:125, loss:0.00000, loss_test:0.02005, lr:3.15e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.468, tt:4342.906\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.01991, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.461, tt:4376.562\n",
      "Ep:127, loss:0.00000, loss_test:0.02004, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.461, tt:4411.052\n",
      "Ep:128, loss:0.00000, loss_test:0.02012, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.456, tt:4444.887\n",
      "Ep:129, loss:0.00000, loss_test:0.02014, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.460, tt:4479.826\n",
      "Ep:130, loss:0.00000, loss_test:0.02019, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.453, tt:4513.365\n",
      "Ep:131, loss:0.00000, loss_test:0.02030, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.463, tt:4549.103\n",
      "Ep:132, loss:0.00000, loss_test:0.02033, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.460, tt:4583.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.02039, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.461, tt:4617.734\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00000, loss_test:0.02041, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.455, tt:4651.423\n",
      "Ep:135, loss:0.00000, loss_test:0.02042, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.449, tt:4685.127\n",
      "Ep:136, loss:0.00000, loss_test:0.02061, lr:3.15e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.448, tt:4719.441\n",
      "Ep:137, loss:0.00000, loss_test:0.02050, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.453, tt:4754.504\n",
      "Ep:138, loss:0.00000, loss_test:0.02068, lr:3.15e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.448, tt:4788.222\n",
      "Ep:139, loss:0.00000, loss_test:0.02061, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.440, tt:4821.609\n",
      "Ep:140, loss:0.00000, loss_test:0.02076, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.436, tt:4855.487\n",
      "Ep:141, loss:0.00000, loss_test:0.02075, lr:3.15e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.437, tt:4890.061\n",
      "Ep:142, loss:0.00000, loss_test:0.02063, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.438, tt:4924.589\n",
      "Ep:143, loss:0.00000, loss_test:0.02095, lr:3.15e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.427, tt:4957.465\n",
      "Ep:144, loss:0.00000, loss_test:0.02089, lr:3.15e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.433, tt:4992.844\n",
      "Ep:145, loss:0.00000, loss_test:0.02090, lr:3.12e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.435, tt:5027.516\n",
      "Ep:146, loss:0.00000, loss_test:0.02111, lr:3.09e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.429, tt:5061.079\n",
      "Ep:147, loss:0.00000, loss_test:0.02090, lr:3.06e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.437, tt:5096.745\n",
      "Ep:148, loss:0.00000, loss_test:0.02119, lr:3.03e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.440, tt:5131.521\n",
      "Ep:149, loss:0.00000, loss_test:0.02125, lr:3.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.448, tt:5167.147\n",
      "Ep:150, loss:0.00000, loss_test:0.02117, lr:2.97e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.442, tt:5200.720\n",
      "Ep:151, loss:0.00000, loss_test:0.02140, lr:2.94e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.436, tt:5234.198\n",
      "Ep:152, loss:0.00000, loss_test:0.02139, lr:2.91e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.431, tt:5267.869\n",
      "Ep:153, loss:0.00000, loss_test:0.02135, lr:2.88e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.438, tt:5303.380\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00000, loss_test:0.02141, lr:2.88e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.431, tt:5336.772\n",
      "Ep:155, loss:0.00000, loss_test:0.02164, lr:2.88e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.433, tt:5371.591\n",
      "Ep:156, loss:0.00000, loss_test:0.02163, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.427, tt:5405.091\n",
      "Ep:157, loss:0.00000, loss_test:0.02158, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.430, tt:5440.015\n",
      "Ep:158, loss:0.00000, loss_test:0.02174, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.429, tt:5474.179\n",
      "Ep:159, loss:0.00000, loss_test:0.02170, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.429, tt:5508.643\n",
      "Ep:160, loss:0.00000, loss_test:0.02180, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.418, tt:5541.325\n",
      "Ep:161, loss:0.00000, loss_test:0.02209, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.425, tt:5576.830\n",
      "Ep:162, loss:0.00000, loss_test:0.02183, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.419, tt:5610.369\n",
      "Ep:163, loss:0.00000, loss_test:0.02204, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.424, tt:5645.613\n",
      "Ep:164, loss:0.00000, loss_test:0.02221, lr:2.88e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.430, tt:5680.903\n",
      "Ep:165, loss:0.00000, loss_test:0.02198, lr:2.85e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.428, tt:5715.082\n",
      "Ep:166, loss:0.00000, loss_test:0.02220, lr:2.82e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.426, tt:5749.110\n",
      "Ep:167, loss:0.00000, loss_test:0.02243, lr:2.80e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.425, tt:5783.471\n",
      "Ep:168, loss:0.00000, loss_test:0.02217, lr:2.77e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.427, tt:5818.118\n",
      "Ep:169, loss:0.00000, loss_test:0.02241, lr:2.74e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.423, tt:5851.889\n",
      "Ep:170, loss:0.00000, loss_test:0.02244, lr:2.71e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.422, tt:5886.143\n",
      "Ep:171, loss:0.00000, loss_test:0.02233, lr:2.69e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.418, tt:5919.818\n",
      "Ep:172, loss:0.00000, loss_test:0.02260, lr:2.66e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.418, tt:5954.229\n",
      "Ep:173, loss:0.00000, loss_test:0.02270, lr:2.63e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.423, tt:5989.604\n",
      "Ep:174, loss:0.00000, loss_test:0.02249, lr:2.61e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.415, tt:6022.658\n",
      "Ep:175, loss:0.00000, loss_test:0.02269, lr:2.58e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.412, tt:6056.479\n",
      "Ep:176, loss:0.00000, loss_test:0.02273, lr:2.55e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.413, tt:6091.144\n",
      "Ep:177, loss:0.00000, loss_test:0.02273, lr:2.53e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.417, tt:6126.182\n",
      "Ep:178, loss:0.00000, loss_test:0.02296, lr:2.50e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.422, tt:6161.521\n",
      "Ep:179, loss:0.00000, loss_test:0.02283, lr:2.48e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.418, tt:6195.237\n",
      "Ep:180, loss:0.00000, loss_test:0.02302, lr:2.45e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.417, tt:6229.393\n",
      "Ep:181, loss:0.00000, loss_test:0.02294, lr:2.43e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.423, tt:6265.078\n",
      "Ep:182, loss:0.00000, loss_test:0.02304, lr:2.40e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.421, tt:6299.132\n",
      "Ep:183, loss:0.00000, loss_test:0.02311, lr:2.38e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.415, tt:6332.428\n",
      "Ep:184, loss:0.00000, loss_test:0.02311, lr:2.36e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.415, tt:6366.722\n",
      "Ep:185, loss:0.00000, loss_test:0.02321, lr:2.33e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.418, tt:6401.797\n",
      "Ep:186, loss:0.00000, loss_test:0.02323, lr:2.31e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.425, tt:6437.423\n",
      "Ep:187, loss:0.00000, loss_test:0.02322, lr:2.29e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.419, tt:6470.702\n",
      "Ep:188, loss:0.00000, loss_test:0.02333, lr:2.26e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.422, tt:6505.704\n",
      "Ep:189, loss:0.00000, loss_test:0.02339, lr:2.24e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.414, tt:6538.650\n",
      "Ep:190, loss:0.00000, loss_test:0.02338, lr:2.22e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.410, tt:6572.349\n",
      "Ep:191, loss:0.00000, loss_test:0.02344, lr:2.20e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.409, tt:6606.535\n",
      "Ep:192, loss:0.00000, loss_test:0.02351, lr:2.17e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.408, tt:6640.705\n",
      "Ep:193, loss:0.00000, loss_test:0.02359, lr:2.15e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.410, tt:6675.524\n",
      "Ep:194, loss:0.00000, loss_test:0.02364, lr:2.13e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.415, tt:6710.834\n",
      "Ep:195, loss:0.00000, loss_test:0.02361, lr:2.11e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.420, tt:6746.377\n",
      "Ep:196, loss:0.00000, loss_test:0.02371, lr:2.09e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.418, tt:6780.318\n",
      "Ep:197, loss:0.00000, loss_test:0.02369, lr:2.07e-02, fs:0.76744 (r=0.667,p=0.904),  time:34.418, tt:6814.801\n",
      "Ep:198, loss:0.00000, loss_test:0.02375, lr:2.05e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.418, tt:6849.248\n",
      "Ep:199, loss:0.00000, loss_test:0.02387, lr:2.03e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.419, tt:6883.890\n",
      "Ep:200, loss:0.00000, loss_test:0.02384, lr:2.01e-02, fs:0.76023 (r=0.657,p=0.903),  time:34.423, tt:6919.069\n",
      "Ep:201, loss:0.00000, loss_test:0.02384, lr:1.99e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.422, tt:6953.200\n",
      "Ep:202, loss:0.00000, loss_test:0.02396, lr:1.97e-02, fs:0.76023 (r=0.657,p=0.903),  time:34.411, tt:6985.423\n",
      "Ep:203, loss:0.00000, loss_test:0.02400, lr:1.95e-02, fs:0.76023 (r=0.657,p=0.903),  time:34.413, tt:7020.223\n",
      "Ep:204, loss:0.00000, loss_test:0.02399, lr:1.93e-02, fs:0.76023 (r=0.657,p=0.903),  time:34.410, tt:7053.979\n",
      "Ep:205, loss:0.00000, loss_test:0.02407, lr:1.91e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.405, tt:7087.455\n",
      "Ep:206, loss:0.00000, loss_test:0.02413, lr:1.89e-02, fs:0.76744 (r=0.667,p=0.904),  time:34.417, tt:7124.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02408, lr:1.87e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.425, tt:7160.309\n",
      "Ep:208, loss:0.00000, loss_test:0.02413, lr:1.85e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.411, tt:7191.886\n",
      "Ep:209, loss:0.00000, loss_test:0.02429, lr:1.83e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.398, tt:7223.494\n",
      "Ep:210, loss:0.00000, loss_test:0.02419, lr:1.81e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.387, tt:7255.756\n",
      "Ep:211, loss:0.00000, loss_test:0.02421, lr:1.80e-02, fs:0.73054 (r=0.616,p=0.897),  time:34.384, tt:7289.427\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13724, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:30.925, tt:30.925\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13343, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:30.256, tt:60.512\n",
      "Ep:2, loss:0.00026, loss_test:0.12790, lr:1.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:31.810, tt:95.430\n",
      "Ep:3, loss:0.00026, loss_test:0.12171, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:32.970, tt:131.879\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11702, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:33.974, tt:169.868\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11464, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:33.800, tt:202.797\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11358, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:33.924, tt:237.469\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11273, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:33.962, tt:271.698\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11208, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:34.208, tt:307.871\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11072, lr:1.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:34.418, tt:344.184\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10911, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:34.486, tt:379.341\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10784, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:34.676, tt:416.109\n",
      "Ep:12, loss:0.00021, loss_test:0.10718, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:34.841, tt:452.928\n",
      "Ep:13, loss:0.00020, loss_test:0.10578, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:35.191, tt:492.678\n",
      "Ep:14, loss:0.00020, loss_test:0.10456, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:35.077, tt:526.150\n",
      "Ep:15, loss:0.00019, loss_test:0.10435, lr:1.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:35.289, tt:564.627\n",
      "Ep:16, loss:0.00019, loss_test:0.10247, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.415, tt:602.063\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09857, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:35.445, tt:638.007\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09797, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.483, tt:674.168\n",
      "Ep:19, loss:0.00017, loss_test:0.09896, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:35.617, tt:712.342\n",
      "Ep:20, loss:0.00017, loss_test:0.09466, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:35.671, tt:749.081\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09251, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:35.687, tt:785.122\n",
      "Ep:22, loss:0.00016, loss_test:0.09312, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:35.720, tt:821.568\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08983, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:35.760, tt:858.240\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08844, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:35.751, tt:893.765\n",
      "Ep:25, loss:0.00014, loss_test:0.08988, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.759, tt:929.744\n",
      "Ep:26, loss:0.00014, loss_test:0.08503, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.828, tt:967.352\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08495, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:35.863, tt:1004.176\n",
      "Ep:28, loss:0.00013, loss_test:0.08604, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:35.902, tt:1041.167\n",
      "Ep:29, loss:0.00012, loss_test:0.08144, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:35.919, tt:1077.556\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08250, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:35.977, tt:1115.297\n",
      "Ep:31, loss:0.00012, loss_test:0.08128, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:35.999, tt:1151.980\n",
      "Ep:32, loss:0.00011, loss_test:0.07944, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:36.039, tt:1189.279\n",
      "Ep:33, loss:0.00011, loss_test:0.07890, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:36.032, tt:1225.086\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08012, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:36.031, tt:1261.101\n",
      "Ep:35, loss:0.00010, loss_test:0.07681, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:36.011, tt:1296.400\n",
      "Ep:36, loss:0.00010, loss_test:0.07971, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.028, tt:1333.051\n",
      "Ep:37, loss:0.00009, loss_test:0.07811, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:36.041, tt:1369.550\n",
      "Ep:38, loss:0.00009, loss_test:0.07595, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:36.048, tt:1405.889\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07887, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.993, tt:1439.708\n",
      "Ep:40, loss:0.00009, loss_test:0.07771, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:35.952, tt:1474.028\n",
      "Ep:41, loss:0.00009, loss_test:0.07867, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.925, tt:1508.855\n",
      "Ep:42, loss:0.00008, loss_test:0.07283, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.929, tt:1544.943\n",
      "Ep:43, loss:0.00008, loss_test:0.08473, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:35.926, tt:1580.723\n",
      "Ep:44, loss:0.00008, loss_test:0.07174, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.933, tt:1616.983\n",
      "Ep:45, loss:0.00008, loss_test:0.08396, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:35.966, tt:1654.423\n",
      "Ep:46, loss:0.00008, loss_test:0.07107, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:36.002, tt:1692.090\n",
      "Ep:47, loss:0.00008, loss_test:0.07391, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:36.030, tt:1729.438\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.07868, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:36.052, tt:1766.560\n",
      "Ep:49, loss:0.00007, loss_test:0.07681, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:36.027, tt:1801.371\n",
      "Ep:50, loss:0.00007, loss_test:0.07222, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:36.073, tt:1839.715\n",
      "Ep:51, loss:0.00007, loss_test:0.09379, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:36.057, tt:1874.974\n",
      "Ep:52, loss:0.00007, loss_test:0.06967, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:36.084, tt:1912.442\n",
      "Ep:53, loss:0.00007, loss_test:0.09283, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:36.081, tt:1948.369\n",
      "Ep:54, loss:0.00007, loss_test:0.07160, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:36.097, tt:1985.352\n",
      "Ep:55, loss:0.00006, loss_test:0.08467, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.118, tt:2022.619\n",
      "Ep:56, loss:0.00006, loss_test:0.07552, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:36.134, tt:2059.638\n",
      "Ep:57, loss:0.00006, loss_test:0.07411, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:36.138, tt:2096.013\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.07356, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.168, tt:2133.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00006, loss_test:0.08362, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.163, tt:2169.809\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.07122, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:36.148, tt:2205.054\n",
      "Ep:61, loss:0.00005, loss_test:0.08257, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:36.149, tt:2241.243\n",
      "Ep:62, loss:0.00006, loss_test:0.07190, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:36.133, tt:2276.386\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07771, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.137, tt:2312.798\n",
      "Ep:64, loss:0.00005, loss_test:0.07661, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.139, tt:2349.062\n",
      "Ep:65, loss:0.00005, loss_test:0.07625, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:36.132, tt:2384.745\n",
      "Ep:66, loss:0.00005, loss_test:0.07778, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.151, tt:2422.109\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.07397, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:36.168, tt:2459.420\n",
      "Ep:68, loss:0.00005, loss_test:0.07926, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:36.176, tt:2496.143\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.07372, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:36.188, tt:2533.149\n",
      "Ep:70, loss:0.00005, loss_test:0.07861, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:36.190, tt:2569.498\n",
      "Ep:71, loss:0.00005, loss_test:0.07479, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:36.183, tt:2605.157\n",
      "Ep:72, loss:0.00005, loss_test:0.08058, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.190, tt:2641.848\n",
      "Ep:73, loss:0.00004, loss_test:0.07268, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:36.182, tt:2677.459\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.07178, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:36.193, tt:2714.464\n",
      "Ep:75, loss:0.00004, loss_test:0.07114, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:36.169, tt:2748.828\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.07719, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:36.174, tt:2785.403\n",
      "Ep:77, loss:0.00004, loss_test:0.07122, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:36.167, tt:2820.997\n",
      "Ep:78, loss:0.00004, loss_test:0.07692, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:36.170, tt:2857.453\n",
      "Ep:79, loss:0.00004, loss_test:0.07385, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:36.172, tt:2893.721\n",
      "Ep:80, loss:0.00004, loss_test:0.07533, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.159, tt:2928.915\n",
      "Ep:81, loss:0.00004, loss_test:0.07167, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.142, tt:2963.612\n",
      "Ep:82, loss:0.00004, loss_test:0.07121, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:36.155, tt:3000.840\n",
      "Ep:83, loss:0.00003, loss_test:0.07300, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:36.156, tt:3037.096\n",
      "Ep:84, loss:0.00003, loss_test:0.07333, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:36.154, tt:3073.129\n",
      "Ep:85, loss:0.00003, loss_test:0.07035, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:36.122, tt:3106.517\n",
      "Ep:86, loss:0.00003, loss_test:0.07701, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:36.127, tt:3143.084\n",
      "Ep:87, loss:0.00003, loss_test:0.07866, lr:9.90e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.109, tt:3177.570\n",
      "Ep:88, loss:0.00003, loss_test:0.07190, lr:9.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:36.067, tt:3209.973\n",
      "Ep:89, loss:0.00003, loss_test:0.07194, lr:9.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.038, tt:3243.403\n",
      "Ep:90, loss:0.00003, loss_test:0.07821, lr:9.61e-03, fs:0.78161 (r=0.687,p=0.907),  time:36.056, tt:3281.099\n",
      "Ep:91, loss:0.00003, loss_test:0.07780, lr:9.51e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.058, tt:3317.327\n",
      "Ep:92, loss:0.00003, loss_test:0.07722, lr:9.41e-03, fs:0.78857 (r=0.697,p=0.908),  time:36.066, tt:3354.155\n",
      "Ep:93, loss:0.00003, loss_test:0.07002, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.075, tt:3391.010\n",
      "Ep:94, loss:0.00003, loss_test:0.07808, lr:9.23e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.063, tt:3425.982\n",
      "Ep:95, loss:0.00003, loss_test:0.08683, lr:9.14e-03, fs:0.81564 (r=0.737,p=0.912),  time:36.052, tt:3461.038\n",
      "Ep:96, loss:0.00003, loss_test:0.06885, lr:9.04e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.058, tt:3497.660\n",
      "Ep:97, loss:0.00003, loss_test:0.07901, lr:8.95e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.069, tt:3534.767\n",
      "Ep:98, loss:0.00003, loss_test:0.07968, lr:8.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.075, tt:3571.402\n",
      "Ep:99, loss:0.00002, loss_test:0.07873, lr:8.78e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.087, tt:3608.704\n",
      "Ep:100, loss:0.00002, loss_test:0.07171, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:36.090, tt:3645.109\n",
      "Ep:101, loss:0.00002, loss_test:0.08732, lr:8.60e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.094, tt:3681.626\n",
      "Ep:102, loss:0.00002, loss_test:0.07852, lr:8.51e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.094, tt:3717.696\n",
      "Ep:103, loss:0.00002, loss_test:0.07662, lr:8.43e-03, fs:0.79545 (r=0.707,p=0.909),  time:36.091, tt:3753.452\n",
      "Ep:104, loss:0.00002, loss_test:0.07670, lr:8.35e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.085, tt:3788.971\n",
      "Ep:105, loss:0.00002, loss_test:0.08136, lr:8.26e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.097, tt:3826.259\n",
      "Ep:106, loss:0.00002, loss_test:0.07632, lr:8.18e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.098, tt:3862.442\n",
      "Ep:107, loss:0.00002, loss_test:0.08035, lr:8.10e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.094, tt:3898.101\n",
      "Ep:108, loss:0.00002, loss_test:0.07671, lr:8.02e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.101, tt:3935.055\n",
      "Ep:109, loss:0.00002, loss_test:0.07944, lr:7.94e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.130, tt:3974.297\n",
      "Ep:110, loss:0.00002, loss_test:0.08268, lr:7.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.146, tt:4012.216\n",
      "Ep:111, loss:0.00002, loss_test:0.08034, lr:7.78e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.145, tt:4048.244\n",
      "Ep:112, loss:0.00002, loss_test:0.07488, lr:7.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.136, tt:4083.371\n",
      "Ep:113, loss:0.00002, loss_test:0.08179, lr:7.62e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.150, tt:4121.057\n",
      "Ep:114, loss:0.00002, loss_test:0.09398, lr:7.55e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.164, tt:4158.885\n",
      "Ep:115, loss:0.00002, loss_test:0.07680, lr:7.47e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.174, tt:4196.207\n",
      "Ep:116, loss:0.00002, loss_test:0.07823, lr:7.40e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.193, tt:4234.556\n",
      "Ep:117, loss:0.00002, loss_test:0.08096, lr:7.32e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.210, tt:4272.747\n",
      "Ep:118, loss:0.00002, loss_test:0.07800, lr:7.25e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.217, tt:4309.853\n",
      "Ep:119, loss:0.00002, loss_test:0.08057, lr:7.18e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.216, tt:4345.895\n",
      "Ep:120, loss:0.00002, loss_test:0.08272, lr:7.11e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.233, tt:4384.187\n",
      "Ep:121, loss:0.00002, loss_test:0.07720, lr:7.03e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.239, tt:4421.131\n",
      "Ep:122, loss:0.00002, loss_test:0.08209, lr:6.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.251, tt:4458.927\n",
      "Ep:123, loss:0.00002, loss_test:0.07839, lr:6.89e-03, fs:0.82022 (r=0.737,p=0.924),  time:36.268, tt:4497.287\n",
      "Ep:124, loss:0.00002, loss_test:0.08261, lr:6.83e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.280, tt:4534.988\n",
      "Ep:125, loss:0.00002, loss_test:0.08112, lr:6.76e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.281, tt:4571.365\n",
      "Ep:126, loss:0.00002, loss_test:0.07766, lr:6.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.288, tt:4608.581\n",
      "Ep:127, loss:0.00001, loss_test:0.08143, lr:6.62e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.289, tt:4644.977\n",
      "Ep:128, loss:0.00001, loss_test:0.08036, lr:6.56e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.284, tt:4680.592\n",
      "Ep:129, loss:0.00001, loss_test:0.08071, lr:6.49e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.284, tt:4716.967\n",
      "Ep:130, loss:0.00001, loss_test:0.07913, lr:6.43e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.289, tt:4753.918\n",
      "Ep:131, loss:0.00001, loss_test:0.08154, lr:6.36e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.292, tt:4790.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.07804, lr:6.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.292, tt:4826.849\n",
      "Ep:133, loss:0.00001, loss_test:0.08196, lr:6.24e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.298, tt:4863.980\n",
      "Ep:134, loss:0.00001, loss_test:0.08130, lr:6.17e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.303, tt:4900.840\n",
      "Ep:135, loss:0.00001, loss_test:0.07820, lr:6.11e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.310, tt:4938.211\n",
      "Ep:136, loss:0.00001, loss_test:0.08035, lr:6.05e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.323, tt:4976.246\n",
      "Ep:137, loss:0.00001, loss_test:0.08553, lr:5.99e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.328, tt:5013.216\n",
      "Ep:138, loss:0.00001, loss_test:0.07862, lr:5.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.335, tt:5050.506\n",
      "Ep:139, loss:0.00001, loss_test:0.08466, lr:5.87e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.331, tt:5086.293\n",
      "Ep:140, loss:0.00001, loss_test:0.07951, lr:5.81e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.339, tt:5123.807\n",
      "Ep:141, loss:0.00001, loss_test:0.08114, lr:5.75e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.346, tt:5161.107\n",
      "Ep:142, loss:0.00001, loss_test:0.07965, lr:5.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.350, tt:5198.091\n",
      "Ep:143, loss:0.00001, loss_test:0.08362, lr:5.64e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.353, tt:5234.867\n",
      "Ep:144, loss:0.00001, loss_test:0.07929, lr:5.58e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.359, tt:5271.987\n",
      "Ep:145, loss:0.00001, loss_test:0.08323, lr:5.53e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.356, tt:5307.936\n",
      "Ep:146, loss:0.00001, loss_test:0.08121, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.356, tt:5344.360\n",
      "Ep:147, loss:0.00001, loss_test:0.07979, lr:5.42e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.376, tt:5383.624\n",
      "Ep:148, loss:0.00001, loss_test:0.08572, lr:5.36e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.367, tt:5418.713\n",
      "Ep:149, loss:0.00001, loss_test:0.07932, lr:5.31e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.345, tt:5451.817\n",
      "Ep:150, loss:0.00001, loss_test:0.08281, lr:5.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.344, tt:5488.005\n",
      "Ep:151, loss:0.00001, loss_test:0.08082, lr:5.20e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.354, tt:5525.752\n",
      "Ep:152, loss:0.00001, loss_test:0.08115, lr:5.15e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.358, tt:5562.702\n",
      "Ep:153, loss:0.00001, loss_test:0.07987, lr:5.10e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.368, tt:5600.602\n",
      "Ep:154, loss:0.00001, loss_test:0.08344, lr:5.05e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.371, tt:5637.484\n",
      "Ep:155, loss:0.00001, loss_test:0.07940, lr:5.00e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.378, tt:5674.968\n",
      "Ep:156, loss:0.00001, loss_test:0.08229, lr:4.95e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.383, tt:5712.147\n",
      "Ep:157, loss:0.00001, loss_test:0.07988, lr:4.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.391, tt:5749.739\n",
      "Ep:158, loss:0.00001, loss_test:0.08400, lr:4.85e-03, fs:0.77193 (r=0.667,p=0.917),  time:36.396, tt:5786.958\n",
      "Ep:159, loss:0.00001, loss_test:0.07959, lr:4.80e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.386, tt:5821.804\n",
      "Ep:160, loss:0.00001, loss_test:0.08169, lr:4.75e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.396, tt:5859.811\n",
      "Ep:161, loss:0.00001, loss_test:0.08100, lr:4.71e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.398, tt:5896.458\n",
      "Ep:162, loss:0.00001, loss_test:0.08378, lr:4.66e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.404, tt:5933.801\n",
      "Ep:163, loss:0.00001, loss_test:0.08230, lr:4.61e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.405, tt:5970.486\n",
      "Ep:164, loss:0.00001, loss_test:0.08159, lr:4.57e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.411, tt:6007.884\n",
      "Ep:165, loss:0.00001, loss_test:0.08261, lr:4.52e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.414, tt:6044.646\n",
      "Ep:166, loss:0.00001, loss_test:0.08248, lr:4.48e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.426, tt:6083.205\n",
      "Ep:167, loss:0.00001, loss_test:0.08170, lr:4.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.427, tt:6119.748\n",
      "Ep:168, loss:0.00001, loss_test:0.08182, lr:4.39e-03, fs:0.78613 (r=0.687,p=0.919),  time:36.424, tt:6155.632\n",
      "Ep:169, loss:0.00001, loss_test:0.08071, lr:4.34e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.429, tt:6192.855\n",
      "Ep:170, loss:0.00001, loss_test:0.08322, lr:4.30e-03, fs:0.79310 (r=0.697,p=0.920),  time:36.441, tt:6231.339\n",
      "Ep:171, loss:0.00001, loss_test:0.08125, lr:4.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.439, tt:6267.490\n",
      "Ep:172, loss:0.00001, loss_test:0.08216, lr:4.21e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.440, tt:6304.084\n",
      "Ep:173, loss:0.00001, loss_test:0.08178, lr:4.17e-03, fs:0.79769 (r=0.697,p=0.932),  time:36.455, tt:6343.188\n",
      "Ep:174, loss:0.00001, loss_test:0.08224, lr:4.13e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.453, tt:6379.212\n",
      "Ep:175, loss:0.00001, loss_test:0.08113, lr:4.09e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.465, tt:6417.791\n",
      "Ep:176, loss:0.00001, loss_test:0.08219, lr:4.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:36.471, tt:6455.402\n",
      "Ep:177, loss:0.00001, loss_test:0.08241, lr:4.01e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.478, tt:6493.105\n",
      "Ep:178, loss:0.00001, loss_test:0.08173, lr:3.97e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.483, tt:6530.480\n",
      "Ep:179, loss:0.00001, loss_test:0.08228, lr:3.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.491, tt:6568.331\n",
      "Ep:180, loss:0.00001, loss_test:0.08135, lr:3.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.506, tt:6607.523\n",
      "Ep:181, loss:0.00001, loss_test:0.08200, lr:3.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.506, tt:6644.156\n",
      "Ep:182, loss:0.00001, loss_test:0.08195, lr:3.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.509, tt:6681.212\n",
      "Ep:183, loss:0.00001, loss_test:0.08262, lr:3.77e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.507, tt:6717.334\n",
      "Ep:184, loss:0.00001, loss_test:0.08078, lr:3.73e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.506, tt:6753.615\n",
      "Ep:185, loss:0.00001, loss_test:0.08315, lr:3.70e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.497, tt:6788.437\n",
      "Ep:186, loss:0.00001, loss_test:0.08161, lr:3.66e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.500, tt:6825.516\n",
      "Ep:187, loss:0.00001, loss_test:0.08334, lr:3.62e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.510, tt:6863.843\n",
      "Ep:188, loss:0.00001, loss_test:0.08122, lr:3.59e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.508, tt:6900.062\n",
      "Ep:189, loss:0.00001, loss_test:0.08297, lr:3.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.522, tt:6939.169\n",
      "Ep:190, loss:0.00001, loss_test:0.08200, lr:3.52e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.520, tt:6975.292\n",
      "Ep:191, loss:0.00001, loss_test:0.08245, lr:3.48e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.528, tt:7013.329\n",
      "Ep:192, loss:0.00001, loss_test:0.08200, lr:3.45e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.536, tt:7051.374\n",
      "Ep:193, loss:0.00001, loss_test:0.08349, lr:3.41e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.536, tt:7088.001\n",
      "Ep:194, loss:0.00001, loss_test:0.08170, lr:3.38e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.540, tt:7125.296\n",
      "Ep:195, loss:0.00001, loss_test:0.08342, lr:3.34e-03, fs:0.77647 (r=0.667,p=0.930),  time:36.536, tt:7161.151\n",
      "Ep:196, loss:0.00001, loss_test:0.08116, lr:3.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.543, tt:7199.032\n",
      "Ep:197, loss:0.00001, loss_test:0.08355, lr:3.28e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.544, tt:7235.744\n",
      "Ep:198, loss:0.00001, loss_test:0.08117, lr:3.24e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.545, tt:7272.496\n",
      "Ep:199, loss:0.00001, loss_test:0.08400, lr:3.21e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.545, tt:7308.911\n",
      "Ep:200, loss:0.00001, loss_test:0.08161, lr:3.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.541, tt:7344.725\n",
      "Ep:201, loss:0.00001, loss_test:0.08370, lr:3.15e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.542, tt:7381.540\n",
      "Ep:202, loss:0.00001, loss_test:0.08161, lr:3.12e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.540, tt:7417.618\n",
      "Ep:203, loss:0.00001, loss_test:0.08257, lr:3.09e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.546, tt:7455.341\n",
      "Ep:204, loss:0.00001, loss_test:0.08326, lr:3.05e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.551, tt:7493.019\n",
      "Ep:205, loss:0.00001, loss_test:0.08214, lr:3.02e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.555, tt:7530.396\n",
      "Ep:206, loss:0.00001, loss_test:0.08369, lr:2.99e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.570, tt:7569.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00001, loss_test:0.08180, lr:2.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.584, tt:7609.526\n",
      "Ep:208, loss:0.00001, loss_test:0.08428, lr:2.93e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.580, tt:7645.288\n",
      "Ep:209, loss:0.00001, loss_test:0.08260, lr:2.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:36.558, tt:7677.167\n",
      "Ep:210, loss:0.00001, loss_test:0.08398, lr:2.88e-03, fs:0.77381 (r=0.657,p=0.942),  time:36.542, tt:7710.463\n",
      "Ep:211, loss:0.00001, loss_test:0.08132, lr:2.85e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.521, tt:7742.359\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02382, lr:6.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:28.041, tt:28.041\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02239, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:28.648, tt:57.295\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02618, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.202, tt:93.605\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02810, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.481, tt:129.925\n",
      "Ep:4, loss:0.00006, loss_test:0.02871, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.267, tt:166.336\n",
      "Ep:5, loss:0.00006, loss_test:0.02810, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.272, tt:199.633\n",
      "Ep:6, loss:0.00006, loss_test:0.02672, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.795, tt:229.564\n",
      "Ep:7, loss:0.00005, loss_test:0.02503, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:32.659, tt:261.273\n",
      "Ep:8, loss:0.00005, loss_test:0.02364, lr:6.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:32.789, tt:295.105\n",
      "Ep:9, loss:0.00005, loss_test:0.02274, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:32.986, tt:329.857\n",
      "Ep:10, loss:0.00005, loss_test:0.02230, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:33.187, tt:365.052\n",
      "Ep:11, loss:0.00005, loss_test:0.02212, lr:6.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:33.333, tt:399.999\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.02180, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:33.410, tt:434.332\n",
      "Ep:13, loss:0.00005, loss_test:0.02121, lr:6.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:33.616, tt:470.624\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02066, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:33.803, tt:507.051\n",
      "Ep:15, loss:0.00004, loss_test:0.02039, lr:6.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:33.845, tt:541.521\n",
      "Ep:16, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:33.976, tt:577.597\n",
      "Ep:17, loss:0.00004, loss_test:0.01971, lr:6.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:33.959, tt:611.267\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01929, lr:6.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:34.109, tt:648.068\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01894, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.151, tt:683.013\n",
      "Ep:20, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:34.213, tt:718.476\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01842, lr:6.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:34.263, tt:753.786\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01814, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:34.301, tt:788.920\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01787, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:34.352, tt:824.459\n",
      "Ep:24, loss:0.00004, loss_test:0.01757, lr:6.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:34.415, tt:860.374\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.387, tt:894.066\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:34.403, tt:928.883\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:34.432, tt:964.099\n",
      "Ep:28, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:34.436, tt:998.646\n",
      "Ep:29, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:34.480, tt:1034.413\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01561, lr:6.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:34.559, tt:1071.336\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:34.610, tt:1107.516\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01505, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:34.646, tt:1143.320\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01475, lr:6.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.656, tt:1178.296\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01452, lr:6.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:34.689, tt:1214.106\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01431, lr:6.00e-02, fs:0.77876 (r=0.889,p=0.693),  time:34.698, tt:1249.115\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.78222 (r=0.889,p=0.698),  time:34.717, tt:1284.533\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:34.711, tt:1319.013\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:34.734, tt:1354.645\n",
      "Ep:39, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.696, tt:1387.820\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.671, tt:1421.497\n",
      "Ep:41, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:34.673, tt:1456.265\n",
      "Ep:42, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:34.671, tt:1490.832\n",
      "Ep:43, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.703, tt:1526.931\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.692, tt:1561.126\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:34.686, tt:1595.570\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01304, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.684, tt:1630.164\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.666, tt:1663.983\n",
      "Ep:48, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.665, tt:1698.571\n",
      "Ep:49, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.657, tt:1732.860\n",
      "Ep:50, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:34.655, tt:1767.392\n",
      "Ep:51, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.647, tt:1801.643\n",
      "Ep:52, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:34.660, tt:1836.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00001, loss_test:0.01287, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.640, tt:1870.577\n",
      "Ep:54, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.628, tt:1904.544\n",
      "Ep:55, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.625, tt:1939.019\n",
      "Ep:56, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.618, tt:1973.229\n",
      "Ep:57, loss:0.00001, loss_test:0.01278, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.615, tt:2007.668\n",
      "Ep:58, loss:0.00001, loss_test:0.01275, lr:5.94e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.621, tt:2042.618\n",
      "Ep:59, loss:0.00001, loss_test:0.01281, lr:5.88e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.623, tt:2077.366\n",
      "Ep:60, loss:0.00001, loss_test:0.01286, lr:5.82e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.616, tt:2111.565\n",
      "Ep:61, loss:0.00001, loss_test:0.01276, lr:5.76e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.606, tt:2145.592\n",
      "Ep:62, loss:0.00001, loss_test:0.01267, lr:5.71e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.600, tt:2179.775\n",
      "Ep:63, loss:0.00001, loss_test:0.01285, lr:5.65e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.592, tt:2213.897\n",
      "Ep:64, loss:0.00001, loss_test:0.01280, lr:5.59e-02, fs:0.83077 (r=0.818,p=0.844),  time:34.585, tt:2248.028\n",
      "Ep:65, loss:0.00001, loss_test:0.01281, lr:5.54e-02, fs:0.83077 (r=0.818,p=0.844),  time:34.587, tt:2282.752\n",
      "Ep:66, loss:0.00001, loss_test:0.01283, lr:5.48e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.622, tt:2319.688\n",
      "Ep:67, loss:0.00001, loss_test:0.01284, lr:5.43e-02, fs:0.83077 (r=0.818,p=0.844),  time:34.599, tt:2352.730\n",
      "Ep:68, loss:0.00001, loss_test:0.01292, lr:5.37e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.590, tt:2386.682\n",
      "Ep:69, loss:0.00001, loss_test:0.01288, lr:5.32e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.577, tt:2420.357\n",
      "Ep:70, loss:0.00001, loss_test:0.01292, lr:5.27e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.552, tt:2453.187\n",
      "Ep:71, loss:0.00001, loss_test:0.01295, lr:5.21e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.554, tt:2487.882\n",
      "Ep:72, loss:0.00001, loss_test:0.01303, lr:5.16e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.559, tt:2522.805\n",
      "Ep:73, loss:0.00001, loss_test:0.01302, lr:5.11e-02, fs:0.82105 (r=0.788,p=0.857),  time:34.566, tt:2557.918\n",
      "Ep:74, loss:0.00001, loss_test:0.01315, lr:5.06e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.567, tt:2592.509\n",
      "Ep:75, loss:0.00001, loss_test:0.01316, lr:5.01e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.574, tt:2627.603\n",
      "Ep:76, loss:0.00001, loss_test:0.01319, lr:4.96e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.576, tt:2662.387\n",
      "Ep:77, loss:0.00001, loss_test:0.01328, lr:4.91e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.578, tt:2697.098\n",
      "Ep:78, loss:0.00001, loss_test:0.01333, lr:4.86e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.604, tt:2733.753\n",
      "Ep:79, loss:0.00001, loss_test:0.01335, lr:4.81e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.596, tt:2767.656\n",
      "Ep:80, loss:0.00001, loss_test:0.01335, lr:4.76e-02, fs:0.82105 (r=0.788,p=0.857),  time:34.611, tt:2803.464\n",
      "Ep:81, loss:0.00001, loss_test:0.01339, lr:4.71e-02, fs:0.82105 (r=0.788,p=0.857),  time:34.599, tt:2837.119\n",
      "Ep:82, loss:0.00001, loss_test:0.01349, lr:4.67e-02, fs:0.82105 (r=0.788,p=0.857),  time:34.605, tt:2872.182\n",
      "Ep:83, loss:0.00001, loss_test:0.01358, lr:4.62e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.579, tt:2904.628\n",
      "Ep:84, loss:0.00001, loss_test:0.01357, lr:4.57e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.577, tt:2939.028\n",
      "Ep:85, loss:0.00001, loss_test:0.01368, lr:4.53e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.582, tt:2974.021\n",
      "Ep:86, loss:0.00001, loss_test:0.01378, lr:4.48e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.591, tt:3009.459\n",
      "Ep:87, loss:0.00001, loss_test:0.01375, lr:4.44e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.583, tt:3043.347\n",
      "Ep:88, loss:0.00001, loss_test:0.01380, lr:4.39e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.612, tt:3080.435\n",
      "Ep:89, loss:0.00001, loss_test:0.01390, lr:4.35e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.626, tt:3116.330\n",
      "Ep:90, loss:0.00001, loss_test:0.01398, lr:4.31e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.623, tt:3150.673\n",
      "Ep:91, loss:0.00001, loss_test:0.01408, lr:4.26e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.612, tt:3184.323\n",
      "Ep:92, loss:0.00001, loss_test:0.01407, lr:4.22e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.628, tt:3220.371\n",
      "Ep:93, loss:0.00001, loss_test:0.01418, lr:4.18e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.656, tt:3257.666\n",
      "Ep:94, loss:0.00001, loss_test:0.01427, lr:4.14e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.669, tt:3293.560\n",
      "Ep:95, loss:0.00001, loss_test:0.01429, lr:4.10e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.667, tt:3328.071\n",
      "Ep:96, loss:0.00001, loss_test:0.01438, lr:4.05e-02, fs:0.82418 (r=0.758,p=0.904),  time:34.691, tt:3365.005\n",
      "Ep:97, loss:0.00001, loss_test:0.01451, lr:4.01e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.680, tt:3398.595\n",
      "Ep:98, loss:0.00001, loss_test:0.01459, lr:3.97e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.687, tt:3433.990\n",
      "Ep:99, loss:0.00001, loss_test:0.01467, lr:3.93e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.684, tt:3468.429\n",
      "Ep:100, loss:0.00001, loss_test:0.01474, lr:3.89e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.687, tt:3503.394\n",
      "Ep:101, loss:0.00001, loss_test:0.01483, lr:3.86e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.697, tt:3539.066\n",
      "Ep:102, loss:0.00001, loss_test:0.01488, lr:3.82e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.708, tt:3574.934\n",
      "Ep:103, loss:0.00001, loss_test:0.01494, lr:3.78e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.701, tt:3608.945\n",
      "Ep:104, loss:0.00001, loss_test:0.01506, lr:3.74e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.701, tt:3643.593\n",
      "Ep:105, loss:0.00001, loss_test:0.01514, lr:3.70e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.703, tt:3678.488\n",
      "Ep:106, loss:0.00001, loss_test:0.01512, lr:3.67e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.684, tt:3711.147\n",
      "Ep:107, loss:0.00001, loss_test:0.01521, lr:3.63e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.699, tt:3747.478\n",
      "Ep:108, loss:0.00001, loss_test:0.01526, lr:3.59e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.700, tt:3782.322\n",
      "Ep:109, loss:0.00000, loss_test:0.01530, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.687, tt:3815.612\n",
      "Ep:110, loss:0.00000, loss_test:0.01541, lr:3.52e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.675, tt:3848.954\n",
      "Ep:111, loss:0.00000, loss_test:0.01551, lr:3.49e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.676, tt:3883.740\n",
      "Ep:112, loss:0.00000, loss_test:0.01562, lr:3.45e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.666, tt:3917.219\n",
      "Ep:113, loss:0.00000, loss_test:0.01569, lr:3.42e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.655, tt:3950.655\n",
      "Ep:114, loss:0.00000, loss_test:0.01568, lr:3.38e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.659, tt:3985.733\n",
      "Ep:115, loss:0.00000, loss_test:0.01582, lr:3.35e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.653, tt:4019.780\n",
      "Ep:116, loss:0.00000, loss_test:0.01593, lr:3.32e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.656, tt:4054.802\n",
      "Ep:117, loss:0.00000, loss_test:0.01600, lr:3.28e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.652, tt:4088.948\n",
      "Ep:118, loss:0.00000, loss_test:0.01603, lr:3.25e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.636, tt:4121.688\n",
      "Ep:119, loss:0.00000, loss_test:0.01610, lr:3.22e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.634, tt:4156.079\n",
      "Ep:120, loss:0.00000, loss_test:0.01621, lr:3.19e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.629, tt:4190.098\n",
      "Ep:121, loss:0.00000, loss_test:0.01627, lr:3.15e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.631, tt:4225.028\n",
      "Ep:122, loss:0.00000, loss_test:0.01632, lr:3.12e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.627, tt:4259.099\n",
      "Ep:123, loss:0.00000, loss_test:0.01638, lr:3.09e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.627, tt:4293.710\n",
      "Ep:124, loss:0.00000, loss_test:0.01655, lr:3.06e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.619, tt:4327.405\n",
      "Ep:125, loss:0.00000, loss_test:0.01660, lr:3.03e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.613, tt:4361.176\n",
      "Ep:126, loss:0.00000, loss_test:0.01665, lr:3.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.611, tt:4395.607\n",
      "Ep:127, loss:0.00000, loss_test:0.01674, lr:2.97e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.601, tt:4428.895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.01683, lr:2.94e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.593, tt:4462.534\n",
      "Ep:129, loss:0.00000, loss_test:0.01694, lr:2.91e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.584, tt:4495.917\n",
      "Ep:130, loss:0.00000, loss_test:0.01701, lr:2.88e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.570, tt:4528.638\n",
      "Ep:131, loss:0.00000, loss_test:0.01709, lr:2.85e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.571, tt:4563.322\n",
      "Ep:132, loss:0.00000, loss_test:0.01716, lr:2.82e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.562, tt:4596.768\n",
      "Ep:133, loss:0.00000, loss_test:0.01719, lr:2.80e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.557, tt:4630.671\n",
      "Ep:134, loss:0.00000, loss_test:0.01732, lr:2.77e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.548, tt:4663.958\n",
      "Ep:135, loss:0.00000, loss_test:0.01743, lr:2.74e-02, fs:0.77647 (r=0.667,p=0.930),  time:34.548, tt:4698.470\n",
      "Ep:136, loss:0.00000, loss_test:0.01742, lr:2.71e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.554, tt:4733.922\n",
      "Ep:137, loss:0.00000, loss_test:0.01749, lr:2.69e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.562, tt:4769.625\n",
      "Ep:138, loss:0.00000, loss_test:0.01760, lr:2.66e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.562, tt:4804.179\n",
      "Ep:139, loss:0.00000, loss_test:0.01766, lr:2.63e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.573, tt:4840.258\n",
      "Ep:140, loss:0.00000, loss_test:0.01772, lr:2.61e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.579, tt:4875.669\n",
      "Ep:141, loss:0.00000, loss_test:0.01776, lr:2.58e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.584, tt:4910.917\n",
      "Ep:142, loss:0.00000, loss_test:0.01789, lr:2.55e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.589, tt:4946.164\n",
      "Ep:143, loss:0.00000, loss_test:0.01796, lr:2.53e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.596, tt:4981.802\n",
      "Ep:144, loss:0.00000, loss_test:0.01800, lr:2.50e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.603, tt:5017.377\n",
      "Ep:145, loss:0.00000, loss_test:0.01807, lr:2.48e-02, fs:0.76923 (r=0.657,p=0.929),  time:34.608, tt:5052.711\n",
      "Ep:146, loss:0.00000, loss_test:0.01812, lr:2.45e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.610, tt:5087.730\n",
      "Ep:147, loss:0.00000, loss_test:0.01816, lr:2.43e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.615, tt:5123.061\n",
      "Ep:148, loss:0.00000, loss_test:0.01824, lr:2.40e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.627, tt:5159.434\n",
      "Ep:149, loss:0.00000, loss_test:0.01834, lr:2.38e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.638, tt:5195.648\n",
      "Ep:150, loss:0.00000, loss_test:0.01839, lr:2.36e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.633, tt:5229.654\n",
      "Ep:151, loss:0.00000, loss_test:0.01845, lr:2.33e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.636, tt:5264.741\n",
      "Ep:152, loss:0.00000, loss_test:0.01850, lr:2.31e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.633, tt:5298.824\n",
      "Ep:153, loss:0.00000, loss_test:0.01856, lr:2.29e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.636, tt:5334.018\n",
      "Ep:154, loss:0.00000, loss_test:0.01864, lr:2.26e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.643, tt:5369.694\n",
      "Ep:155, loss:0.00000, loss_test:0.01867, lr:2.24e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.640, tt:5403.772\n",
      "Ep:156, loss:0.00000, loss_test:0.01874, lr:2.22e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.644, tt:5439.077\n",
      "Ep:157, loss:0.00000, loss_test:0.01881, lr:2.20e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.647, tt:5474.240\n",
      "Ep:158, loss:0.00000, loss_test:0.01887, lr:2.17e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.651, tt:5509.555\n",
      "Ep:159, loss:0.00000, loss_test:0.01893, lr:2.15e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.653, tt:5544.481\n",
      "Ep:160, loss:0.00000, loss_test:0.01897, lr:2.13e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.662, tt:5580.524\n",
      "Ep:161, loss:0.00000, loss_test:0.01904, lr:2.11e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.665, tt:5615.775\n",
      "Ep:162, loss:0.00000, loss_test:0.01908, lr:2.09e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.678, tt:5652.583\n",
      "Ep:163, loss:0.00000, loss_test:0.01914, lr:2.07e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.683, tt:5687.954\n",
      "Ep:164, loss:0.00000, loss_test:0.01918, lr:2.05e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.687, tt:5723.358\n",
      "Ep:165, loss:0.00000, loss_test:0.01923, lr:2.03e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.689, tt:5758.306\n",
      "Ep:166, loss:0.00000, loss_test:0.01927, lr:2.01e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.699, tt:5794.760\n",
      "Ep:167, loss:0.00000, loss_test:0.01930, lr:1.99e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.703, tt:5830.079\n",
      "Ep:168, loss:0.00000, loss_test:0.01937, lr:1.97e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.704, tt:5864.987\n",
      "Ep:169, loss:0.00000, loss_test:0.01941, lr:1.95e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.717, tt:5901.880\n",
      "Ep:170, loss:0.00000, loss_test:0.01946, lr:1.93e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.725, tt:5937.906\n",
      "Ep:171, loss:0.00000, loss_test:0.01949, lr:1.91e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.733, tt:5974.041\n",
      "Ep:172, loss:0.00000, loss_test:0.01955, lr:1.89e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.743, tt:6010.604\n",
      "Ep:173, loss:0.00000, loss_test:0.01962, lr:1.87e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.751, tt:6046.604\n",
      "Ep:174, loss:0.00000, loss_test:0.01965, lr:1.85e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.759, tt:6082.767\n",
      "Ep:175, loss:0.00000, loss_test:0.01968, lr:1.83e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.758, tt:6117.482\n",
      "Ep:176, loss:0.00000, loss_test:0.01971, lr:1.81e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.772, tt:6154.729\n",
      "Ep:177, loss:0.00000, loss_test:0.01978, lr:1.80e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.774, tt:6189.796\n",
      "Ep:178, loss:0.00000, loss_test:0.01982, lr:1.78e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.778, tt:6225.286\n",
      "Ep:179, loss:0.00000, loss_test:0.01986, lr:1.76e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.780, tt:6260.364\n",
      "Ep:180, loss:0.00000, loss_test:0.01993, lr:1.74e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.784, tt:6295.854\n",
      "Ep:181, loss:0.00000, loss_test:0.01996, lr:1.73e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.788, tt:6331.353\n",
      "Ep:182, loss:0.00000, loss_test:0.02000, lr:1.71e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.798, tt:6368.024\n",
      "Ep:183, loss:0.00000, loss_test:0.02002, lr:1.69e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.809, tt:6404.768\n",
      "Ep:184, loss:0.00000, loss_test:0.02007, lr:1.67e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.823, tt:6442.255\n",
      "Ep:185, loss:0.00000, loss_test:0.02012, lr:1.66e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.826, tt:6477.582\n",
      "Ep:186, loss:0.00000, loss_test:0.02017, lr:1.64e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.830, tt:6513.218\n",
      "Ep:187, loss:0.00000, loss_test:0.02021, lr:1.62e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.833, tt:6548.646\n",
      "Ep:188, loss:0.00000, loss_test:0.02024, lr:1.61e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.840, tt:6584.673\n",
      "Ep:189, loss:0.00000, loss_test:0.02026, lr:1.59e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.847, tt:6620.943\n",
      "Ep:190, loss:0.00000, loss_test:0.02030, lr:1.58e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.849, tt:6656.213\n",
      "Ep:191, loss:0.00000, loss_test:0.02035, lr:1.56e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.856, tt:6692.304\n",
      "Ep:192, loss:0.00000, loss_test:0.02039, lr:1.54e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.864, tt:6728.711\n",
      "Ep:193, loss:0.00000, loss_test:0.02042, lr:1.53e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.867, tt:6764.158\n",
      "Ep:194, loss:0.00000, loss_test:0.02047, lr:1.51e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.869, tt:6799.428\n",
      "Ep:195, loss:0.00000, loss_test:0.02050, lr:1.50e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.882, tt:6836.923\n",
      "Ep:196, loss:0.00000, loss_test:0.02054, lr:1.48e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.891, tt:6873.603\n",
      "Ep:197, loss:0.00000, loss_test:0.02057, lr:1.47e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.892, tt:6908.632\n",
      "Ep:198, loss:0.00000, loss_test:0.02058, lr:1.45e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.894, tt:6943.890\n",
      "Ep:199, loss:0.00000, loss_test:0.02062, lr:1.44e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.895, tt:6978.986\n",
      "Ep:200, loss:0.00000, loss_test:0.02066, lr:1.43e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.899, tt:7014.696\n",
      "Ep:201, loss:0.00000, loss_test:0.02071, lr:1.41e-02, fs:0.76190 (r=0.646,p=0.928),  time:34.898, tt:7049.399\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12515, lr:1.00e-02, fs:0.67883 (r=0.939,p=0.531),  time:31.454, tt:31.454\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12244, lr:1.00e-02, fs:0.68889 (r=0.939,p=0.544),  time:29.711, tt:59.422\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.11951, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:31.305, tt:93.914\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11707, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:32.746, tt:130.984\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11531, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:33.423, tt:167.114\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11427, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:33.710, tt:202.258\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11362, lr:1.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:33.932, tt:237.527\n",
      "Ep:7, loss:0.00025, loss_test:0.11294, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:33.914, tt:271.310\n",
      "Ep:8, loss:0.00024, loss_test:0.11169, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:34.086, tt:306.777\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.10967, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:34.404, tt:344.035\n",
      "Ep:10, loss:0.00023, loss_test:0.10746, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:34.647, tt:381.122\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.10560, lr:1.00e-02, fs:0.72881 (r=0.869,p=0.628),  time:34.837, tt:418.039\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.10393, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:35.249, tt:458.243\n",
      "Ep:13, loss:0.00022, loss_test:0.10174, lr:1.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:35.412, tt:495.769\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.09949, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:35.472, tt:532.085\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09816, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:35.619, tt:569.906\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.09708, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:35.763, tt:607.975\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.09634, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:35.801, tt:644.411\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09510, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:35.761, tt:679.465\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09369, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:35.798, tt:715.954\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09225, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:35.860, tt:753.062\n",
      "Ep:21, loss:0.00016, loss_test:0.09123, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:35.970, tt:791.330\n",
      "Ep:22, loss:0.00016, loss_test:0.09030, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:36.121, tt:830.791\n",
      "Ep:23, loss:0.00015, loss_test:0.08962, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:36.177, tt:868.258\n",
      "Ep:24, loss:0.00014, loss_test:0.08905, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:36.224, tt:905.605\n",
      "Ep:25, loss:0.00014, loss_test:0.08903, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:36.240, tt:942.245\n",
      "Ep:26, loss:0.00013, loss_test:0.08872, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:36.321, tt:980.663\n",
      "Ep:27, loss:0.00012, loss_test:0.08870, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:36.355, tt:1017.944\n",
      "Ep:28, loss:0.00012, loss_test:0.08832, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:36.364, tt:1054.549\n",
      "Ep:29, loss:0.00011, loss_test:0.08869, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:36.407, tt:1092.200\n",
      "Ep:30, loss:0.00011, loss_test:0.08772, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:36.464, tt:1130.380\n",
      "Ep:31, loss:0.00010, loss_test:0.08686, lr:9.90e-03, fs:0.73514 (r=0.687,p=0.791),  time:36.504, tt:1168.119\n",
      "Ep:32, loss:0.00010, loss_test:0.08602, lr:9.80e-03, fs:0.73913 (r=0.687,p=0.800),  time:36.440, tt:1202.534\n",
      "Ep:33, loss:0.00009, loss_test:0.08605, lr:9.70e-03, fs:0.74595 (r=0.697,p=0.802),  time:36.493, tt:1240.773\n",
      "Ep:34, loss:0.00009, loss_test:0.08609, lr:9.61e-03, fs:0.74317 (r=0.687,p=0.810),  time:36.493, tt:1277.264\n",
      "Ep:35, loss:0.00009, loss_test:0.08477, lr:9.51e-03, fs:0.75000 (r=0.697,p=0.812),  time:36.547, tt:1315.679\n",
      "Ep:36, loss:0.00008, loss_test:0.08540, lr:9.41e-03, fs:0.75410 (r=0.697,p=0.821),  time:36.529, tt:1351.591\n",
      "Ep:37, loss:0.00008, loss_test:0.08413, lr:9.32e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.567, tt:1389.551\n",
      "Ep:38, loss:0.00008, loss_test:0.08653, lr:9.23e-03, fs:0.74860 (r=0.677,p=0.838),  time:36.585, tt:1426.798\n",
      "Ep:39, loss:0.00008, loss_test:0.08389, lr:9.14e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.579, tt:1463.152\n",
      "Ep:40, loss:0.00007, loss_test:0.08642, lr:9.04e-03, fs:0.75281 (r=0.677,p=0.848),  time:36.579, tt:1499.739\n",
      "Ep:41, loss:0.00007, loss_test:0.08325, lr:8.95e-03, fs:0.76923 (r=0.707,p=0.843),  time:36.540, tt:1534.674\n",
      "Ep:42, loss:0.00007, loss_test:0.08552, lr:8.86e-03, fs:0.75556 (r=0.687,p=0.840),  time:36.549, tt:1571.610\n",
      "Ep:43, loss:0.00007, loss_test:0.08440, lr:8.78e-03, fs:0.75556 (r=0.687,p=0.840),  time:36.544, tt:1607.953\n",
      "Ep:44, loss:0.00006, loss_test:0.08648, lr:8.69e-03, fs:0.75824 (r=0.697,p=0.831),  time:36.541, tt:1644.336\n",
      "Ep:45, loss:0.00006, loss_test:0.08310, lr:8.60e-03, fs:0.75556 (r=0.687,p=0.840),  time:36.515, tt:1679.712\n",
      "Ep:46, loss:0.00006, loss_test:0.08544, lr:8.51e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.498, tt:1715.423\n",
      "Ep:47, loss:0.00006, loss_test:0.08438, lr:8.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.456, tt:1749.911\n",
      "Ep:48, loss:0.00006, loss_test:0.08383, lr:8.35e-03, fs:0.77348 (r=0.707,p=0.854),  time:36.407, tt:1783.929\n",
      "Ep:49, loss:0.00005, loss_test:0.08631, lr:8.26e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.385, tt:1819.266\n",
      "Ep:50, loss:0.00005, loss_test:0.08214, lr:8.18e-03, fs:0.76243 (r=0.697,p=0.841),  time:36.369, tt:1854.801\n",
      "Ep:51, loss:0.00005, loss_test:0.08600, lr:8.10e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.364, tt:1890.916\n",
      "Ep:52, loss:0.00005, loss_test:0.08282, lr:8.02e-03, fs:0.76667 (r=0.697,p=0.852),  time:36.365, tt:1927.361\n",
      "Ep:53, loss:0.00005, loss_test:0.08490, lr:7.94e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.380, tt:1964.504\n",
      "Ep:54, loss:0.00005, loss_test:0.08485, lr:7.86e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.398, tt:2001.896\n",
      "Ep:55, loss:0.00005, loss_test:0.08408, lr:7.78e-03, fs:0.77778 (r=0.707,p=0.864),  time:36.384, tt:2037.523\n",
      "Ep:56, loss:0.00004, loss_test:0.08491, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.379, tt:2073.602\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.08421, lr:7.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:36.410, tt:2111.773\n",
      "Ep:58, loss:0.00004, loss_test:0.08487, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.426, tt:2149.117\n",
      "Ep:59, loss:0.00004, loss_test:0.08496, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.427, tt:2185.605\n",
      "Ep:60, loss:0.00004, loss_test:0.08322, lr:7.70e-03, fs:0.78212 (r=0.707,p=0.875),  time:36.445, tt:2223.155\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.08444, lr:7.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:36.473, tt:2261.316\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.08325, lr:7.70e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.465, tt:2297.295\n",
      "Ep:63, loss:0.00004, loss_test:0.08250, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.465, tt:2333.751\n",
      "Ep:64, loss:0.00004, loss_test:0.08451, lr:7.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.479, tt:2371.127\n",
      "Ep:65, loss:0.00004, loss_test:0.08204, lr:7.70e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.497, tt:2408.830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00004, loss_test:0.08383, lr:7.70e-03, fs:0.77273 (r=0.687,p=0.883),  time:36.502, tt:2445.646\n",
      "Ep:67, loss:0.00004, loss_test:0.08167, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.516, tt:2483.116\n",
      "Ep:68, loss:0.00004, loss_test:0.08297, lr:7.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:36.541, tt:2521.351\n",
      "Ep:69, loss:0.00003, loss_test:0.08094, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.564, tt:2559.450\n",
      "Ep:70, loss:0.00003, loss_test:0.08359, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.562, tt:2595.919\n",
      "Ep:71, loss:0.00003, loss_test:0.07974, lr:7.70e-03, fs:0.78652 (r=0.707,p=0.886),  time:36.541, tt:2630.923\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00003, loss_test:0.08244, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.531, tt:2666.798\n",
      "Ep:73, loss:0.00003, loss_test:0.08006, lr:7.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:36.527, tt:2702.994\n",
      "Ep:74, loss:0.00003, loss_test:0.08033, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.525, tt:2739.357\n",
      "Ep:75, loss:0.00003, loss_test:0.08065, lr:7.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.551, tt:2777.857\n",
      "Ep:76, loss:0.00003, loss_test:0.07960, lr:7.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.562, tt:2815.296\n",
      "Ep:77, loss:0.00003, loss_test:0.08081, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.567, tt:2852.223\n",
      "Ep:78, loss:0.00003, loss_test:0.07958, lr:7.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.587, tt:2890.345\n",
      "Ep:79, loss:0.00003, loss_test:0.07988, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.600, tt:2927.993\n",
      "Ep:80, loss:0.00003, loss_test:0.07958, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.589, tt:2963.701\n",
      "Ep:81, loss:0.00003, loss_test:0.07843, lr:7.70e-03, fs:0.78161 (r=0.687,p=0.907),  time:36.614, tt:3002.345\n",
      "Ep:82, loss:0.00003, loss_test:0.08111, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.624, tt:3039.804\n",
      "Ep:83, loss:0.00003, loss_test:0.07966, lr:7.62e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.632, tt:3077.091\n",
      "Ep:84, loss:0.00003, loss_test:0.07885, lr:7.55e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.643, tt:3114.666\n",
      "Ep:85, loss:0.00003, loss_test:0.08062, lr:7.47e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.642, tt:3151.182\n",
      "Ep:86, loss:0.00003, loss_test:0.07900, lr:7.40e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.674, tt:3190.665\n",
      "Ep:87, loss:0.00002, loss_test:0.07852, lr:7.32e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.687, tt:3228.440\n",
      "Ep:88, loss:0.00002, loss_test:0.08005, lr:7.25e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.711, tt:3267.293\n",
      "Ep:89, loss:0.00002, loss_test:0.07881, lr:7.18e-03, fs:0.77457 (r=0.677,p=0.905),  time:36.744, tt:3306.964\n",
      "Ep:90, loss:0.00002, loss_test:0.07868, lr:7.11e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.747, tt:3343.955\n",
      "Ep:91, loss:0.00002, loss_test:0.07824, lr:7.03e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.762, tt:3382.100\n",
      "Ep:92, loss:0.00002, loss_test:0.07899, lr:6.96e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.771, tt:3419.739\n",
      "Ep:93, loss:0.00002, loss_test:0.07959, lr:6.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:36.770, tt:3456.391\n",
      "Ep:94, loss:0.00002, loss_test:0.07767, lr:6.83e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.768, tt:3492.931\n",
      "Ep:95, loss:0.00002, loss_test:0.07822, lr:6.76e-03, fs:0.77011 (r=0.677,p=0.893),  time:36.763, tt:3529.289\n",
      "Ep:96, loss:0.00002, loss_test:0.08098, lr:6.69e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.754, tt:3565.176\n",
      "Ep:97, loss:0.00002, loss_test:0.07769, lr:6.62e-03, fs:0.77714 (r=0.687,p=0.895),  time:36.716, tt:3598.165\n",
      "Ep:98, loss:0.00002, loss_test:0.07844, lr:6.56e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.673, tt:3630.645\n",
      "Ep:99, loss:0.00002, loss_test:0.07806, lr:6.49e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.663, tt:3666.252\n",
      "Ep:100, loss:0.00002, loss_test:0.07873, lr:6.43e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.667, tt:3703.403\n",
      "Ep:101, loss:0.00002, loss_test:0.07921, lr:6.36e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.659, tt:3739.238\n",
      "Ep:102, loss:0.00002, loss_test:0.07727, lr:6.30e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.660, tt:3775.929\n",
      "Ep:103, loss:0.00002, loss_test:0.07914, lr:6.24e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.668, tt:3813.464\n",
      "Ep:104, loss:0.00002, loss_test:0.07921, lr:6.17e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.677, tt:3851.047\n",
      "Ep:105, loss:0.00002, loss_test:0.07774, lr:6.11e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.666, tt:3886.631\n",
      "Ep:106, loss:0.00002, loss_test:0.07825, lr:6.05e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.661, tt:3922.675\n",
      "Ep:107, loss:0.00002, loss_test:0.07926, lr:5.99e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.635, tt:3956.589\n",
      "Ep:108, loss:0.00002, loss_test:0.07779, lr:5.93e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.630, tt:3992.715\n",
      "Ep:109, loss:0.00002, loss_test:0.07910, lr:5.87e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.616, tt:4027.739\n",
      "Ep:110, loss:0.00002, loss_test:0.07745, lr:5.81e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.617, tt:4064.534\n",
      "Ep:111, loss:0.00002, loss_test:0.07848, lr:5.75e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.611, tt:4100.474\n",
      "Ep:112, loss:0.00002, loss_test:0.07877, lr:5.70e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.610, tt:4136.890\n",
      "Ep:113, loss:0.00002, loss_test:0.07726, lr:5.64e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.605, tt:4172.988\n",
      "Ep:114, loss:0.00002, loss_test:0.07953, lr:5.58e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.600, tt:4208.962\n",
      "Ep:115, loss:0.00002, loss_test:0.07901, lr:5.53e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.607, tt:4246.382\n",
      "Ep:116, loss:0.00002, loss_test:0.07797, lr:5.47e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.611, tt:4283.478\n",
      "Ep:117, loss:0.00002, loss_test:0.07862, lr:5.42e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.599, tt:4318.728\n",
      "Ep:118, loss:0.00002, loss_test:0.07871, lr:5.36e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.595, tt:4354.826\n",
      "Ep:119, loss:0.00002, loss_test:0.07783, lr:5.31e-03, fs:0.76023 (r=0.657,p=0.903),  time:36.586, tt:4390.360\n",
      "Ep:120, loss:0.00002, loss_test:0.07985, lr:5.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.576, tt:4425.653\n",
      "Ep:121, loss:0.00002, loss_test:0.07717, lr:5.20e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.573, tt:4461.879\n",
      "Ep:122, loss:0.00002, loss_test:0.07853, lr:5.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.575, tt:4498.718\n",
      "Ep:123, loss:0.00002, loss_test:0.08018, lr:5.10e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.574, tt:4535.179\n",
      "Ep:124, loss:0.00002, loss_test:0.07827, lr:5.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.570, tt:4571.257\n",
      "Ep:125, loss:0.00002, loss_test:0.07822, lr:5.00e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.564, tt:4607.116\n",
      "Ep:126, loss:0.00002, loss_test:0.07987, lr:4.95e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.570, tt:4644.332\n",
      "Ep:127, loss:0.00002, loss_test:0.07842, lr:4.90e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.566, tt:4680.390\n",
      "Ep:128, loss:0.00002, loss_test:0.07805, lr:4.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.559, tt:4716.057\n",
      "Ep:129, loss:0.00001, loss_test:0.07969, lr:4.80e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.564, tt:4753.280\n",
      "Ep:130, loss:0.00001, loss_test:0.07828, lr:4.75e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.558, tt:4789.085\n",
      "Ep:131, loss:0.00001, loss_test:0.07895, lr:4.71e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.545, tt:4823.967\n",
      "Ep:132, loss:0.00001, loss_test:0.07953, lr:4.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.552, tt:4861.474\n",
      "Ep:133, loss:0.00001, loss_test:0.07798, lr:4.61e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.544, tt:4896.906\n",
      "Ep:134, loss:0.00001, loss_test:0.07885, lr:4.57e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.539, tt:4932.710\n",
      "Ep:135, loss:0.00001, loss_test:0.08004, lr:4.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.541, tt:4969.603\n",
      "Ep:136, loss:0.00001, loss_test:0.07850, lr:4.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.527, tt:5004.217\n",
      "Ep:137, loss:0.00001, loss_test:0.07817, lr:4.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.533, tt:5041.619\n",
      "Ep:138, loss:0.00001, loss_test:0.07943, lr:4.39e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.527, tt:5077.282\n",
      "Ep:139, loss:0.00001, loss_test:0.07902, lr:4.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.529, tt:5114.066\n",
      "Ep:140, loss:0.00001, loss_test:0.07846, lr:4.30e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.532, tt:5151.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.07908, lr:4.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.531, tt:5187.458\n",
      "Ep:142, loss:0.00001, loss_test:0.07889, lr:4.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.519, tt:5222.205\n",
      "Ep:143, loss:0.00001, loss_test:0.07905, lr:4.17e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.508, tt:5257.100\n",
      "Ep:144, loss:0.00001, loss_test:0.07923, lr:4.13e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.506, tt:5293.404\n",
      "Ep:145, loss:0.00001, loss_test:0.07837, lr:4.09e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.501, tt:5329.190\n",
      "Ep:146, loss:0.00001, loss_test:0.07966, lr:4.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.492, tt:5364.333\n",
      "Ep:147, loss:0.00001, loss_test:0.07934, lr:4.01e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.493, tt:5400.901\n",
      "Ep:148, loss:0.00001, loss_test:0.07866, lr:3.97e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.485, tt:5436.257\n",
      "Ep:149, loss:0.00001, loss_test:0.07922, lr:3.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.491, tt:5473.588\n",
      "Ep:150, loss:0.00001, loss_test:0.07890, lr:3.89e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.474, tt:5507.522\n",
      "Ep:151, loss:0.00001, loss_test:0.07931, lr:3.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.479, tt:5544.877\n",
      "Ep:152, loss:0.00001, loss_test:0.07967, lr:3.81e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.477, tt:5580.913\n",
      "Ep:153, loss:0.00001, loss_test:0.07938, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.466, tt:5615.755\n",
      "Ep:154, loss:0.00001, loss_test:0.07907, lr:3.73e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.462, tt:5651.682\n",
      "Ep:155, loss:0.00001, loss_test:0.07981, lr:3.70e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.459, tt:5687.665\n",
      "Ep:156, loss:0.00001, loss_test:0.07974, lr:3.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.437, tt:5720.611\n",
      "Ep:157, loss:0.00001, loss_test:0.07904, lr:3.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.436, tt:5756.818\n",
      "Ep:158, loss:0.00001, loss_test:0.07986, lr:3.59e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.435, tt:5793.150\n",
      "Ep:159, loss:0.00001, loss_test:0.07970, lr:3.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.434, tt:5829.370\n",
      "Ep:160, loss:0.00001, loss_test:0.07991, lr:3.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.421, tt:5863.827\n",
      "Ep:161, loss:0.00001, loss_test:0.07913, lr:3.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.420, tt:5900.061\n",
      "Ep:162, loss:0.00001, loss_test:0.07978, lr:3.45e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.410, tt:5934.851\n",
      "Ep:163, loss:0.00001, loss_test:0.08097, lr:3.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.417, tt:5972.321\n",
      "Ep:164, loss:0.00001, loss_test:0.07971, lr:3.38e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.411, tt:6007.871\n",
      "Ep:165, loss:0.00001, loss_test:0.07968, lr:3.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.409, tt:6043.939\n",
      "Ep:166, loss:0.00001, loss_test:0.07991, lr:3.31e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.412, tt:6080.732\n",
      "Ep:167, loss:0.00001, loss_test:0.08025, lr:3.28e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.407, tt:6116.358\n",
      "Ep:168, loss:0.00001, loss_test:0.07996, lr:3.24e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.416, tt:6154.360\n",
      "Ep:169, loss:0.00001, loss_test:0.08016, lr:3.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.417, tt:6190.896\n",
      "Ep:170, loss:0.00001, loss_test:0.07952, lr:3.18e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.418, tt:6227.507\n",
      "Ep:171, loss:0.00001, loss_test:0.08055, lr:3.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.425, tt:6265.129\n",
      "Ep:172, loss:0.00001, loss_test:0.08021, lr:3.12e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.430, tt:6302.317\n",
      "Ep:173, loss:0.00001, loss_test:0.07965, lr:3.09e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.429, tt:6338.676\n",
      "Ep:174, loss:0.00001, loss_test:0.08031, lr:3.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.444, tt:6377.692\n",
      "Ep:175, loss:0.00001, loss_test:0.08029, lr:3.02e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.440, tt:6413.455\n",
      "Ep:176, loss:0.00001, loss_test:0.08003, lr:2.99e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.431, tt:6448.270\n",
      "Ep:177, loss:0.00001, loss_test:0.08000, lr:2.96e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.430, tt:6484.514\n",
      "Ep:178, loss:0.00001, loss_test:0.08006, lr:2.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.429, tt:6520.744\n",
      "Ep:179, loss:0.00001, loss_test:0.08084, lr:2.90e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.426, tt:6556.602\n",
      "Ep:180, loss:0.00001, loss_test:0.08054, lr:2.88e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.423, tt:6592.605\n",
      "Ep:181, loss:0.00001, loss_test:0.07953, lr:2.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.434, tt:6630.915\n",
      "Ep:182, loss:0.00001, loss_test:0.08014, lr:2.82e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.436, tt:6667.705\n",
      "Ep:183, loss:0.00001, loss_test:0.07976, lr:2.79e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.435, tt:6704.000\n",
      "Ep:184, loss:0.00001, loss_test:0.07988, lr:2.76e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.441, tt:6741.499\n",
      "Ep:185, loss:0.00001, loss_test:0.08031, lr:2.73e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.438, tt:6777.390\n",
      "Ep:186, loss:0.00001, loss_test:0.07946, lr:2.71e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.429, tt:6812.160\n",
      "Ep:187, loss:0.00001, loss_test:0.08011, lr:2.68e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.435, tt:6849.689\n",
      "Ep:188, loss:0.00001, loss_test:0.08031, lr:2.65e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.431, tt:6885.465\n",
      "Ep:189, loss:0.00001, loss_test:0.07937, lr:2.63e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.435, tt:6922.737\n",
      "Ep:190, loss:0.00001, loss_test:0.08022, lr:2.60e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.436, tt:6959.223\n",
      "Ep:191, loss:0.00001, loss_test:0.08053, lr:2.57e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.445, tt:6997.494\n",
      "Ep:192, loss:0.00001, loss_test:0.07929, lr:2.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.460, tt:7036.706\n",
      "Ep:193, loss:0.00001, loss_test:0.08017, lr:2.52e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.457, tt:7072.605\n",
      "Ep:194, loss:0.00001, loss_test:0.08059, lr:2.50e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.462, tt:7110.163\n",
      "Ep:195, loss:0.00001, loss_test:0.07977, lr:2.47e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.465, tt:7147.082\n",
      "Ep:196, loss:0.00001, loss_test:0.07960, lr:2.45e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.460, tt:7182.588\n",
      "Ep:197, loss:0.00001, loss_test:0.07993, lr:2.42e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.465, tt:7220.144\n",
      "Ep:198, loss:0.00001, loss_test:0.07980, lr:2.40e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.466, tt:7256.754\n",
      "Ep:199, loss:0.00001, loss_test:0.07962, lr:2.38e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.467, tt:7293.374\n",
      "Ep:200, loss:0.00001, loss_test:0.07996, lr:2.35e-03, fs:0.75740 (r=0.646,p=0.914),  time:36.452, tt:7326.909\n",
      "Ep:201, loss:0.00001, loss_test:0.07982, lr:2.33e-03, fs:0.75294 (r=0.646,p=0.901),  time:36.431, tt:7359.093\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02186, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:24.258, tt:24.258\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02391, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:22.501, tt:45.002\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02638, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.784, tt:65.351\n",
      "Ep:3, loss:0.00005, loss_test:0.02693, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.198, tt:88.790\n",
      "Ep:4, loss:0.00005, loss_test:0.02667, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.561, tt:117.807\n",
      "Ep:5, loss:0.00005, loss_test:0.02576, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.603, tt:147.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00005, loss_test:0.02410, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:25.080, tt:175.558\n",
      "Ep:7, loss:0.00005, loss_test:0.02228, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:25.429, tt:203.430\n",
      "Ep:8, loss:0.00004, loss_test:0.02117, lr:6.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:25.696, tt:231.264\n",
      "Ep:9, loss:0.00004, loss_test:0.02105, lr:6.00e-02, fs:0.64228 (r=0.798,p=0.537),  time:25.906, tt:259.059\n",
      "Ep:10, loss:0.00004, loss_test:0.02091, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:25.829, tt:284.122\n",
      "Ep:11, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.66383 (r=0.788,p=0.574),  time:25.983, tt:311.790\n",
      "Ep:12, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.65306 (r=0.808,p=0.548),  time:26.029, tt:338.371\n",
      "Ep:13, loss:0.00004, loss_test:0.01940, lr:5.94e-02, fs:0.64314 (r=0.828,p=0.526),  time:26.328, tt:368.588\n",
      "Ep:14, loss:0.00004, loss_test:0.01927, lr:5.88e-02, fs:0.65385 (r=0.859,p=0.528),  time:26.544, tt:398.157\n",
      "Ep:15, loss:0.00004, loss_test:0.01903, lr:5.82e-02, fs:0.67451 (r=0.869,p=0.551),  time:26.755, tt:428.076\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01878, lr:5.82e-02, fs:0.68273 (r=0.859,p=0.567),  time:26.926, tt:457.749\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01855, lr:5.82e-02, fs:0.67769 (r=0.828,p=0.573),  time:27.139, tt:488.493\n",
      "Ep:18, loss:0.00004, loss_test:0.01829, lr:5.82e-02, fs:0.67769 (r=0.828,p=0.573),  time:27.210, tt:516.984\n",
      "Ep:19, loss:0.00004, loss_test:0.01805, lr:5.82e-02, fs:0.68313 (r=0.838,p=0.576),  time:27.332, tt:546.640\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01784, lr:5.82e-02, fs:0.69106 (r=0.859,p=0.578),  time:27.475, tt:576.982\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01761, lr:5.82e-02, fs:0.69388 (r=0.859,p=0.582),  time:27.628, tt:607.816\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01739, lr:5.82e-02, fs:0.68293 (r=0.848,p=0.571),  time:27.714, tt:637.421\n",
      "Ep:23, loss:0.00003, loss_test:0.01717, lr:5.82e-02, fs:0.69421 (r=0.848,p=0.587),  time:27.817, tt:667.598\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01689, lr:5.82e-02, fs:0.69456 (r=0.838,p=0.593),  time:27.860, tt:696.492\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01659, lr:5.82e-02, fs:0.70000 (r=0.848,p=0.596),  time:27.933, tt:726.258\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01625, lr:5.82e-02, fs:0.70000 (r=0.848,p=0.596),  time:27.965, tt:755.060\n",
      "Ep:27, loss:0.00003, loss_test:0.01591, lr:5.82e-02, fs:0.71130 (r=0.859,p=0.607),  time:28.046, tt:785.276\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01557, lr:5.82e-02, fs:0.71730 (r=0.859,p=0.616),  time:28.107, tt:815.093\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01520, lr:5.82e-02, fs:0.72574 (r=0.869,p=0.623),  time:28.128, tt:843.834\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01481, lr:5.82e-02, fs:0.73729 (r=0.879,p=0.635),  time:28.116, tt:871.596\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01450, lr:5.82e-02, fs:0.75000 (r=0.879,p=0.654),  time:28.156, tt:901.008\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01422, lr:5.82e-02, fs:0.75652 (r=0.879,p=0.664),  time:28.156, tt:929.138\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01400, lr:5.82e-02, fs:0.76652 (r=0.879,p=0.680),  time:28.177, tt:958.011\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01377, lr:5.82e-02, fs:0.77333 (r=0.879,p=0.690),  time:28.178, tt:986.221\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01359, lr:5.82e-02, fs:0.78924 (r=0.889,p=0.710),  time:28.231, tt:1016.319\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01339, lr:5.82e-02, fs:0.79821 (r=0.899,p=0.718),  time:28.242, tt:1044.958\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01317, lr:5.82e-02, fs:0.79464 (r=0.899,p=0.712),  time:28.306, tt:1075.611\n",
      "Ep:38, loss:0.00002, loss_test:0.01302, lr:5.82e-02, fs:0.79821 (r=0.899,p=0.718),  time:28.322, tt:1104.543\n",
      "Ep:39, loss:0.00002, loss_test:0.01295, lr:5.82e-02, fs:0.80180 (r=0.899,p=0.724),  time:28.372, tt:1134.895\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01282, lr:5.82e-02, fs:0.80909 (r=0.899,p=0.736),  time:28.402, tt:1164.473\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01274, lr:5.82e-02, fs:0.82569 (r=0.909,p=0.756),  time:28.436, tt:1194.309\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01276, lr:5.82e-02, fs:0.82791 (r=0.899,p=0.767),  time:28.442, tt:1223.024\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01260, lr:5.82e-02, fs:0.83721 (r=0.909,p=0.776),  time:28.479, tt:1253.082\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01238, lr:5.82e-02, fs:0.84259 (r=0.919,p=0.778),  time:28.481, tt:1281.636\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01244, lr:5.82e-02, fs:0.84906 (r=0.909,p=0.796),  time:28.495, tt:1310.751\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01241, lr:5.82e-02, fs:0.85446 (r=0.919,p=0.798),  time:28.475, tt:1338.348\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01233, lr:5.82e-02, fs:0.85849 (r=0.919,p=0.805),  time:28.495, tt:1367.773\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01235, lr:5.82e-02, fs:0.86538 (r=0.909,p=0.826),  time:28.505, tt:1396.731\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01244, lr:5.82e-02, fs:0.87379 (r=0.909,p=0.841),  time:28.529, tt:1426.462\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01226, lr:5.82e-02, fs:0.86124 (r=0.909,p=0.818),  time:28.543, tt:1455.698\n",
      "Ep:51, loss:0.00002, loss_test:0.01218, lr:5.82e-02, fs:0.86957 (r=0.909,p=0.833),  time:28.551, tt:1484.642\n",
      "Ep:52, loss:0.00002, loss_test:0.01216, lr:5.82e-02, fs:0.87379 (r=0.909,p=0.841),  time:28.584, tt:1514.973\n",
      "Ep:53, loss:0.00001, loss_test:0.01212, lr:5.82e-02, fs:0.87379 (r=0.909,p=0.841),  time:28.621, tt:1545.509\n",
      "Ep:54, loss:0.00001, loss_test:0.01227, lr:5.82e-02, fs:0.88235 (r=0.909,p=0.857),  time:28.660, tt:1576.308\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01225, lr:5.82e-02, fs:0.87255 (r=0.899,p=0.848),  time:28.686, tt:1606.406\n",
      "Ep:56, loss:0.00001, loss_test:0.01198, lr:5.82e-02, fs:0.87255 (r=0.899,p=0.848),  time:28.705, tt:1636.182\n",
      "Ep:57, loss:0.00001, loss_test:0.01239, lr:5.82e-02, fs:0.86294 (r=0.859,p=0.867),  time:28.723, tt:1665.950\n",
      "Ep:58, loss:0.00001, loss_test:0.01214, lr:5.82e-02, fs:0.86869 (r=0.869,p=0.869),  time:28.746, tt:1696.005\n",
      "Ep:59, loss:0.00001, loss_test:0.01216, lr:5.82e-02, fs:0.87310 (r=0.869,p=0.878),  time:28.759, tt:1725.559\n",
      "Ep:60, loss:0.00001, loss_test:0.01242, lr:5.82e-02, fs:0.83770 (r=0.808,p=0.870),  time:28.765, tt:1754.651\n",
      "Ep:61, loss:0.00001, loss_test:0.01227, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:28.753, tt:1782.672\n",
      "Ep:62, loss:0.00001, loss_test:0.01209, lr:5.82e-02, fs:0.84974 (r=0.828,p=0.872),  time:28.736, tt:1810.368\n",
      "Ep:63, loss:0.00001, loss_test:0.01239, lr:5.82e-02, fs:0.82353 (r=0.778,p=0.875),  time:28.765, tt:1840.935\n",
      "Ep:64, loss:0.00001, loss_test:0.01234, lr:5.82e-02, fs:0.81720 (r=0.768,p=0.874),  time:28.808, tt:1872.503\n",
      "Ep:65, loss:0.00001, loss_test:0.01221, lr:5.82e-02, fs:0.83770 (r=0.808,p=0.870),  time:28.824, tt:1902.354\n",
      "Ep:66, loss:0.00001, loss_test:0.01252, lr:5.76e-02, fs:0.82353 (r=0.778,p=0.875),  time:28.835, tt:1931.957\n",
      "Ep:67, loss:0.00001, loss_test:0.01229, lr:5.71e-02, fs:0.82353 (r=0.778,p=0.875),  time:28.843, tt:1961.301\n",
      "Ep:68, loss:0.00001, loss_test:0.01252, lr:5.65e-02, fs:0.81522 (r=0.758,p=0.882),  time:28.841, tt:1990.001\n",
      "Ep:69, loss:0.00001, loss_test:0.01272, lr:5.59e-02, fs:0.80874 (r=0.747,p=0.881),  time:28.819, tt:2017.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.01244, lr:5.54e-02, fs:0.81081 (r=0.758,p=0.872),  time:28.822, tt:2046.360\n",
      "Ep:71, loss:0.00001, loss_test:0.01270, lr:5.48e-02, fs:0.80220 (r=0.737,p=0.880),  time:28.816, tt:2074.759\n",
      "Ep:72, loss:0.00001, loss_test:0.01283, lr:5.43e-02, fs:0.79558 (r=0.727,p=0.878),  time:28.842, tt:2105.491\n",
      "Ep:73, loss:0.00001, loss_test:0.01284, lr:5.37e-02, fs:0.79330 (r=0.717,p=0.887),  time:28.831, tt:2133.462\n",
      "Ep:74, loss:0.00001, loss_test:0.01301, lr:5.32e-02, fs:0.80000 (r=0.727,p=0.889),  time:28.832, tt:2162.393\n",
      "Ep:75, loss:0.00001, loss_test:0.01298, lr:5.27e-02, fs:0.79330 (r=0.717,p=0.887),  time:28.838, tt:2191.705\n",
      "Ep:76, loss:0.00001, loss_test:0.01319, lr:5.21e-02, fs:0.79330 (r=0.717,p=0.887),  time:28.874, tt:2223.278\n",
      "Ep:77, loss:0.00001, loss_test:0.01314, lr:5.16e-02, fs:0.80000 (r=0.727,p=0.889),  time:28.884, tt:2252.973\n",
      "Ep:78, loss:0.00001, loss_test:0.01327, lr:5.11e-02, fs:0.80000 (r=0.727,p=0.889),  time:28.882, tt:2281.666\n",
      "Ep:79, loss:0.00001, loss_test:0.01328, lr:5.06e-02, fs:0.80000 (r=0.727,p=0.889),  time:28.886, tt:2310.855\n",
      "Ep:80, loss:0.00001, loss_test:0.01335, lr:5.01e-02, fs:0.79330 (r=0.717,p=0.887),  time:28.904, tt:2341.242\n",
      "Ep:81, loss:0.00001, loss_test:0.01343, lr:4.96e-02, fs:0.79775 (r=0.717,p=0.899),  time:28.907, tt:2370.358\n",
      "Ep:82, loss:0.00001, loss_test:0.01365, lr:4.91e-02, fs:0.79775 (r=0.717,p=0.899),  time:28.903, tt:2398.982\n",
      "Ep:83, loss:0.00001, loss_test:0.01349, lr:4.86e-02, fs:0.79775 (r=0.717,p=0.899),  time:28.916, tt:2428.969\n",
      "Ep:84, loss:0.00001, loss_test:0.01369, lr:4.81e-02, fs:0.79096 (r=0.707,p=0.897),  time:28.941, tt:2459.948\n",
      "Ep:85, loss:0.00001, loss_test:0.01381, lr:4.76e-02, fs:0.79096 (r=0.707,p=0.897),  time:28.953, tt:2489.987\n",
      "Ep:86, loss:0.00001, loss_test:0.01376, lr:4.71e-02, fs:0.78409 (r=0.697,p=0.896),  time:28.963, tt:2519.746\n",
      "Ep:87, loss:0.00001, loss_test:0.01399, lr:4.67e-02, fs:0.79096 (r=0.707,p=0.897),  time:28.963, tt:2548.788\n",
      "Ep:88, loss:0.00001, loss_test:0.01396, lr:4.62e-02, fs:0.78409 (r=0.697,p=0.896),  time:28.963, tt:2577.671\n",
      "Ep:89, loss:0.00001, loss_test:0.01393, lr:4.57e-02, fs:0.78409 (r=0.697,p=0.896),  time:28.963, tt:2606.656\n",
      "Ep:90, loss:0.00001, loss_test:0.01420, lr:4.53e-02, fs:0.77714 (r=0.687,p=0.895),  time:28.973, tt:2636.561\n",
      "Ep:91, loss:0.00001, loss_test:0.01417, lr:4.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:28.989, tt:2667.016\n",
      "Ep:92, loss:0.00001, loss_test:0.01434, lr:4.44e-02, fs:0.77011 (r=0.677,p=0.893),  time:28.991, tt:2696.127\n",
      "Ep:93, loss:0.00001, loss_test:0.01438, lr:4.39e-02, fs:0.77011 (r=0.677,p=0.893),  time:28.997, tt:2725.732\n",
      "Ep:94, loss:0.00001, loss_test:0.01450, lr:4.35e-02, fs:0.77011 (r=0.677,p=0.893),  time:28.995, tt:2754.500\n",
      "Ep:95, loss:0.00001, loss_test:0.01442, lr:4.31e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.023, tt:2786.175\n",
      "Ep:96, loss:0.00001, loss_test:0.01469, lr:4.26e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.045, tt:2817.394\n",
      "Ep:97, loss:0.00001, loss_test:0.01479, lr:4.22e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.046, tt:2846.550\n",
      "Ep:98, loss:0.00001, loss_test:0.01470, lr:4.18e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.075, tt:2878.464\n",
      "Ep:99, loss:0.00001, loss_test:0.01486, lr:4.14e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.078, tt:2907.847\n",
      "Ep:100, loss:0.00001, loss_test:0.01503, lr:4.10e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.109, tt:2940.058\n",
      "Ep:101, loss:0.00001, loss_test:0.01495, lr:4.05e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.123, tt:2970.573\n",
      "Ep:102, loss:0.00001, loss_test:0.01513, lr:4.01e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.138, tt:3001.189\n",
      "Ep:103, loss:0.00001, loss_test:0.01520, lr:3.97e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.151, tt:3031.661\n",
      "Ep:104, loss:0.00001, loss_test:0.01521, lr:3.93e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.163, tt:3062.125\n",
      "Ep:105, loss:0.00001, loss_test:0.01539, lr:3.89e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.172, tt:3092.278\n",
      "Ep:106, loss:0.00001, loss_test:0.01546, lr:3.86e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.183, tt:3122.530\n",
      "Ep:107, loss:0.00000, loss_test:0.01544, lr:3.82e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.184, tt:3151.833\n",
      "Ep:108, loss:0.00000, loss_test:0.01561, lr:3.78e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.191, tt:3181.836\n",
      "Ep:109, loss:0.00000, loss_test:0.01560, lr:3.74e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.201, tt:3212.111\n",
      "Ep:110, loss:0.00000, loss_test:0.01563, lr:3.70e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.210, tt:3242.350\n",
      "Ep:111, loss:0.00000, loss_test:0.01584, lr:3.67e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.212, tt:3271.741\n",
      "Ep:112, loss:0.00000, loss_test:0.01579, lr:3.63e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.187, tt:3298.163\n",
      "Ep:113, loss:0.00000, loss_test:0.01586, lr:3.59e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.192, tt:3327.847\n",
      "Ep:114, loss:0.00000, loss_test:0.01610, lr:3.56e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.201, tt:3358.097\n",
      "Ep:115, loss:0.00000, loss_test:0.01611, lr:3.52e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.203, tt:3387.596\n",
      "Ep:116, loss:0.00000, loss_test:0.01602, lr:3.49e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.217, tt:3418.377\n",
      "Ep:117, loss:0.00000, loss_test:0.01626, lr:3.45e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.220, tt:3447.938\n",
      "Ep:118, loss:0.00000, loss_test:0.01633, lr:3.42e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.220, tt:3477.160\n",
      "Ep:119, loss:0.00000, loss_test:0.01618, lr:3.38e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.224, tt:3506.859\n",
      "Ep:120, loss:0.00000, loss_test:0.01651, lr:3.35e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.218, tt:3535.324\n",
      "Ep:121, loss:0.00000, loss_test:0.01656, lr:3.32e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.237, tt:3566.888\n",
      "Ep:122, loss:0.00000, loss_test:0.01655, lr:3.28e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.242, tt:3596.760\n",
      "Ep:123, loss:0.00000, loss_test:0.01668, lr:3.25e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.243, tt:3626.149\n",
      "Ep:124, loss:0.00000, loss_test:0.01679, lr:3.22e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.236, tt:3654.489\n",
      "Ep:125, loss:0.00000, loss_test:0.01668, lr:3.19e-02, fs:0.77011 (r=0.677,p=0.893),  time:29.229, tt:3682.805\n",
      "Ep:126, loss:0.00000, loss_test:0.01693, lr:3.15e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.229, tt:3712.084\n",
      "Ep:127, loss:0.00000, loss_test:0.01694, lr:3.12e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.244, tt:3743.247\n",
      "Ep:128, loss:0.00000, loss_test:0.01700, lr:3.09e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.250, tt:3773.206\n",
      "Ep:129, loss:0.00000, loss_test:0.01708, lr:3.06e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.258, tt:3803.550\n",
      "Ep:130, loss:0.00000, loss_test:0.01717, lr:3.03e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.260, tt:3833.072\n",
      "Ep:131, loss:0.00000, loss_test:0.01716, lr:3.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.264, tt:3862.783\n",
      "Ep:132, loss:0.00000, loss_test:0.01727, lr:2.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.276, tt:3893.745\n",
      "Ep:133, loss:0.00000, loss_test:0.01736, lr:2.94e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.280, tt:3923.455\n",
      "Ep:134, loss:0.00000, loss_test:0.01731, lr:2.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.278, tt:3952.507\n",
      "Ep:135, loss:0.00000, loss_test:0.01748, lr:2.88e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.272, tt:3981.011\n",
      "Ep:136, loss:0.00000, loss_test:0.01746, lr:2.85e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.290, tt:4012.669\n",
      "Ep:137, loss:0.00000, loss_test:0.01756, lr:2.82e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.303, tt:4043.833\n",
      "Ep:138, loss:0.00000, loss_test:0.01760, lr:2.80e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.307, tt:4073.608\n",
      "Ep:139, loss:0.00000, loss_test:0.01769, lr:2.77e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.302, tt:4102.219\n",
      "Ep:140, loss:0.00000, loss_test:0.01768, lr:2.74e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.311, tt:4132.894\n",
      "Ep:141, loss:0.00000, loss_test:0.01784, lr:2.71e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.316, tt:4162.886\n",
      "Ep:142, loss:0.00000, loss_test:0.01786, lr:2.69e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.325, tt:4193.538\n",
      "Ep:143, loss:0.00000, loss_test:0.01782, lr:2.66e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.324, tt:4222.599\n",
      "Ep:144, loss:0.00000, loss_test:0.01796, lr:2.63e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.325, tt:4252.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.01801, lr:2.61e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.323, tt:4281.130\n",
      "Ep:146, loss:0.00000, loss_test:0.01804, lr:2.58e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.335, tt:4312.192\n",
      "Ep:147, loss:0.00000, loss_test:0.01805, lr:2.55e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.338, tt:4342.095\n",
      "Ep:148, loss:0.00000, loss_test:0.01819, lr:2.53e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.345, tt:4372.421\n",
      "Ep:149, loss:0.00000, loss_test:0.01818, lr:2.50e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.347, tt:4402.000\n",
      "Ep:150, loss:0.00000, loss_test:0.01823, lr:2.48e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.348, tt:4431.608\n",
      "Ep:151, loss:0.00000, loss_test:0.01829, lr:2.45e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.362, tt:4462.971\n",
      "Ep:152, loss:0.00000, loss_test:0.01832, lr:2.43e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.377, tt:4494.689\n",
      "Ep:153, loss:0.00000, loss_test:0.01841, lr:2.40e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.378, tt:4524.170\n",
      "Ep:154, loss:0.00000, loss_test:0.01841, lr:2.38e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.381, tt:4554.020\n",
      "Ep:155, loss:0.00000, loss_test:0.01850, lr:2.36e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.384, tt:4583.856\n",
      "Ep:156, loss:0.00000, loss_test:0.01859, lr:2.33e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.387, tt:4613.695\n",
      "Ep:157, loss:0.00000, loss_test:0.01850, lr:2.31e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.383, tt:4642.529\n",
      "Ep:158, loss:0.00000, loss_test:0.01860, lr:2.29e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.393, tt:4673.476\n",
      "Ep:159, loss:0.00000, loss_test:0.01864, lr:2.26e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.390, tt:4702.365\n",
      "Ep:160, loss:0.00000, loss_test:0.01873, lr:2.24e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.393, tt:4732.328\n",
      "Ep:161, loss:0.00000, loss_test:0.01874, lr:2.22e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.405, tt:4763.687\n",
      "Ep:162, loss:0.00000, loss_test:0.01876, lr:2.20e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.408, tt:4793.510\n",
      "Ep:163, loss:0.00000, loss_test:0.01885, lr:2.17e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.411, tt:4823.441\n",
      "Ep:164, loss:0.00000, loss_test:0.01891, lr:2.15e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.411, tt:4852.809\n",
      "Ep:165, loss:0.00000, loss_test:0.01881, lr:2.13e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.412, tt:4882.336\n",
      "Ep:166, loss:0.00000, loss_test:0.01895, lr:2.11e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.413, tt:4911.895\n",
      "Ep:167, loss:0.00000, loss_test:0.01902, lr:2.09e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.419, tt:4942.469\n",
      "Ep:168, loss:0.00000, loss_test:0.01898, lr:2.07e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.442, tt:4975.733\n",
      "Ep:169, loss:0.00000, loss_test:0.01897, lr:2.05e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.462, tt:5008.524\n",
      "Ep:170, loss:0.00000, loss_test:0.01915, lr:2.03e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.463, tt:5038.218\n",
      "Ep:171, loss:0.00000, loss_test:0.01913, lr:2.01e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.466, tt:5068.213\n",
      "Ep:172, loss:0.00000, loss_test:0.01908, lr:1.99e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.473, tt:5098.774\n",
      "Ep:173, loss:0.00000, loss_test:0.01920, lr:1.97e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.473, tt:5128.374\n",
      "Ep:174, loss:0.00000, loss_test:0.01930, lr:1.95e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.476, tt:5158.231\n",
      "Ep:175, loss:0.00000, loss_test:0.01929, lr:1.93e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.475, tt:5187.584\n",
      "Ep:176, loss:0.00000, loss_test:0.01927, lr:1.91e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.481, tt:5218.056\n",
      "Ep:177, loss:0.00000, loss_test:0.01933, lr:1.89e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.486, tt:5248.529\n",
      "Ep:178, loss:0.00000, loss_test:0.01941, lr:1.87e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.492, tt:5279.056\n",
      "Ep:179, loss:0.00000, loss_test:0.01937, lr:1.85e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.500, tt:5309.945\n",
      "Ep:180, loss:0.00000, loss_test:0.01943, lr:1.83e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.490, tt:5337.710\n",
      "Ep:181, loss:0.00000, loss_test:0.01950, lr:1.81e-02, fs:0.76744 (r=0.667,p=0.904),  time:29.486, tt:5366.401\n",
      "Ep:182, loss:0.00000, loss_test:0.01948, lr:1.80e-02, fs:0.77457 (r=0.677,p=0.905),  time:29.487, tt:5396.051\n",
      "Ep:183, loss:0.00000, loss_test:0.01950, lr:1.78e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.499, tt:5427.803\n",
      "Ep:184, loss:0.00000, loss_test:0.01957, lr:1.76e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.498, tt:5457.182\n",
      "Ep:185, loss:0.00000, loss_test:0.01964, lr:1.74e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.499, tt:5486.750\n",
      "Ep:186, loss:0.00000, loss_test:0.01963, lr:1.73e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.510, tt:5518.351\n",
      "Ep:187, loss:0.00000, loss_test:0.01965, lr:1.71e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.519, tt:5549.595\n",
      "Ep:188, loss:0.00000, loss_test:0.01971, lr:1.69e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.523, tt:5579.771\n",
      "Ep:189, loss:0.00000, loss_test:0.01978, lr:1.67e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.532, tt:5611.068\n",
      "Ep:190, loss:0.00000, loss_test:0.01977, lr:1.66e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.535, tt:5641.227\n",
      "Ep:191, loss:0.00000, loss_test:0.01979, lr:1.64e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.540, tt:5671.593\n",
      "Ep:192, loss:0.00000, loss_test:0.01985, lr:1.62e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.566, tt:5706.201\n",
      "Ep:193, loss:0.00000, loss_test:0.01984, lr:1.61e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.575, tt:5737.601\n",
      "Ep:194, loss:0.00000, loss_test:0.01987, lr:1.59e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.588, tt:5769.583\n",
      "Ep:195, loss:0.00000, loss_test:0.01990, lr:1.58e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.590, tt:5799.712\n",
      "Ep:196, loss:0.00000, loss_test:0.01990, lr:1.56e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.598, tt:5830.750\n",
      "Ep:197, loss:0.00000, loss_test:0.01994, lr:1.54e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.605, tt:5861.760\n",
      "Ep:198, loss:0.00000, loss_test:0.01997, lr:1.53e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.602, tt:5890.803\n",
      "Ep:199, loss:0.00000, loss_test:0.02000, lr:1.51e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.593, tt:5918.530\n",
      "Ep:200, loss:0.00000, loss_test:0.02002, lr:1.50e-02, fs:0.76023 (r=0.657,p=0.903),  time:29.589, tt:5947.364\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13457, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:29.554, tt:29.554\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13170, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:28.646, tt:57.292\n",
      "Ep:2, loss:0.00027, loss_test:0.12730, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:28.080, tt:84.240\n",
      "Ep:3, loss:0.00026, loss_test:0.12198, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:28.299, tt:113.198\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11613, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:28.391, tt:141.957\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11172, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:29.150, tt:174.899\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.10899, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:29.518, tt:206.625\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10639, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:29.738, tt:237.907\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.10515, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:29.842, tt:268.575\n",
      "Ep:9, loss:0.00023, loss_test:0.10413, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:29.897, tt:298.966\n",
      "Ep:10, loss:0.00023, loss_test:0.10373, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:29.897, tt:328.868\n",
      "Ep:11, loss:0.00022, loss_test:0.10347, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:29.841, tt:358.095\n",
      "Ep:12, loss:0.00022, loss_test:0.10305, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:30.103, tt:391.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:13, loss:0.00022, loss_test:0.10220, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:30.329, tt:424.601\n",
      "Ep:14, loss:0.00021, loss_test:0.10106, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:30.394, tt:455.911\n",
      "Ep:15, loss:0.00021, loss_test:0.09940, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:30.427, tt:486.838\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.09768, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:30.577, tt:519.817\n",
      "Ep:17, loss:0.00020, loss_test:0.09626, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:30.642, tt:551.565\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00020, loss_test:0.09519, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:30.761, tt:584.454\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.09399, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:30.878, tt:617.566\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00019, loss_test:0.09256, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:30.941, tt:649.758\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09134, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:31.022, tt:682.494\n",
      "Ep:22, loss:0.00018, loss_test:0.09025, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:31.056, tt:714.280\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.08888, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:31.136, tt:747.269\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.08788, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:31.150, tt:778.759\n",
      "Ep:25, loss:0.00017, loss_test:0.08664, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:31.208, tt:811.405\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.08520, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:31.247, tt:843.664\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.08430, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:31.238, tt:874.660\n",
      "Ep:28, loss:0.00015, loss_test:0.08341, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:31.292, tt:907.479\n",
      "Ep:29, loss:0.00015, loss_test:0.08378, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:31.277, tt:938.309\n",
      "Ep:30, loss:0.00014, loss_test:0.08255, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:31.277, tt:969.601\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.08376, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:31.279, tt:1000.919\n",
      "Ep:32, loss:0.00013, loss_test:0.08131, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:31.327, tt:1033.783\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08410, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:31.321, tt:1064.916\n",
      "Ep:34, loss:0.00012, loss_test:0.08000, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:31.329, tt:1096.527\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08251, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:31.351, tt:1128.631\n",
      "Ep:36, loss:0.00011, loss_test:0.07901, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.369, tt:1160.660\n",
      "Ep:37, loss:0.00011, loss_test:0.07735, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:31.394, tt:1192.967\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.08645, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:31.407, tt:1224.872\n",
      "Ep:39, loss:0.00010, loss_test:0.07640, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:31.419, tt:1256.771\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08380, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:31.411, tt:1287.862\n",
      "Ep:41, loss:0.00009, loss_test:0.07412, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:31.391, tt:1318.408\n",
      "Ep:42, loss:0.00009, loss_test:0.07682, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:31.371, tt:1348.974\n",
      "Ep:43, loss:0.00008, loss_test:0.07462, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:31.381, tt:1380.765\n",
      "Ep:44, loss:0.00008, loss_test:0.07382, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:31.380, tt:1412.118\n",
      "Ep:45, loss:0.00008, loss_test:0.08171, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:31.379, tt:1443.442\n",
      "Ep:46, loss:0.00008, loss_test:0.07066, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:31.387, tt:1475.170\n",
      "Ep:47, loss:0.00008, loss_test:0.07871, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:31.408, tt:1507.597\n",
      "Ep:48, loss:0.00007, loss_test:0.07022, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.399, tt:1538.548\n",
      "Ep:49, loss:0.00007, loss_test:0.07878, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.392, tt:1569.600\n",
      "Ep:50, loss:0.00007, loss_test:0.07107, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:31.387, tt:1600.743\n",
      "Ep:51, loss:0.00007, loss_test:0.07182, lr:9.90e-03, fs:0.77348 (r=0.707,p=0.854),  time:31.408, tt:1633.202\n",
      "Ep:52, loss:0.00006, loss_test:0.07515, lr:9.80e-03, fs:0.80000 (r=0.747,p=0.860),  time:31.444, tt:1666.549\n",
      "Ep:53, loss:0.00006, loss_test:0.06945, lr:9.70e-03, fs:0.76243 (r=0.697,p=0.841),  time:31.448, tt:1698.208\n",
      "Ep:54, loss:0.00006, loss_test:0.07669, lr:9.61e-03, fs:0.81111 (r=0.737,p=0.901),  time:31.426, tt:1728.439\n",
      "Ep:55, loss:0.00006, loss_test:0.07008, lr:9.51e-03, fs:0.77895 (r=0.747,p=0.813),  time:31.407, tt:1758.770\n",
      "Ep:56, loss:0.00006, loss_test:0.07938, lr:9.41e-03, fs:0.74854 (r=0.646,p=0.889),  time:31.411, tt:1790.444\n",
      "Ep:57, loss:0.00005, loss_test:0.06690, lr:9.32e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.422, tt:1822.475\n",
      "Ep:58, loss:0.00005, loss_test:0.07916, lr:9.23e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.420, tt:1853.778\n",
      "Ep:59, loss:0.00005, loss_test:0.07299, lr:9.14e-03, fs:0.76667 (r=0.697,p=0.852),  time:31.423, tt:1885.366\n",
      "Ep:60, loss:0.00005, loss_test:0.07071, lr:9.04e-03, fs:0.75581 (r=0.657,p=0.890),  time:31.416, tt:1916.360\n",
      "Ep:61, loss:0.00005, loss_test:0.07517, lr:8.95e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.422, tt:1948.159\n",
      "Ep:62, loss:0.00004, loss_test:0.07173, lr:8.86e-03, fs:0.74713 (r=0.657,p=0.867),  time:31.425, tt:1979.801\n",
      "Ep:63, loss:0.00004, loss_test:0.07306, lr:8.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.439, tt:2012.084\n",
      "Ep:64, loss:0.00004, loss_test:0.07255, lr:8.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:31.427, tt:2042.777\n",
      "Ep:65, loss:0.00004, loss_test:0.07128, lr:8.60e-03, fs:0.75581 (r=0.657,p=0.890),  time:31.418, tt:2073.603\n",
      "Ep:66, loss:0.00004, loss_test:0.07309, lr:8.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.424, tt:2105.378\n",
      "Ep:67, loss:0.00004, loss_test:0.07238, lr:8.43e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.422, tt:2136.725\n",
      "Ep:68, loss:0.00003, loss_test:0.07528, lr:8.35e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.423, tt:2168.192\n",
      "Ep:69, loss:0.00003, loss_test:0.07217, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.419, tt:2199.308\n",
      "Ep:70, loss:0.00003, loss_test:0.07259, lr:8.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.398, tt:2229.292\n",
      "Ep:71, loss:0.00003, loss_test:0.07529, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.396, tt:2260.527\n",
      "Ep:72, loss:0.00003, loss_test:0.07070, lr:8.02e-03, fs:0.76923 (r=0.657,p=0.929),  time:31.394, tt:2291.735\n",
      "Ep:73, loss:0.00003, loss_test:0.07787, lr:7.94e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.384, tt:2322.422\n",
      "Ep:74, loss:0.00003, loss_test:0.07156, lr:7.86e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.372, tt:2352.889\n",
      "Ep:75, loss:0.00003, loss_test:0.07534, lr:7.78e-03, fs:0.77381 (r=0.657,p=0.942),  time:31.372, tt:2384.274\n",
      "Ep:76, loss:0.00003, loss_test:0.07541, lr:7.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.360, tt:2414.726\n",
      "Ep:77, loss:0.00003, loss_test:0.07501, lr:7.62e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.383, tt:2447.850\n",
      "Ep:78, loss:0.00003, loss_test:0.07096, lr:7.55e-03, fs:0.76471 (r=0.657,p=0.915),  time:31.385, tt:2479.408\n",
      "Ep:79, loss:0.00003, loss_test:0.07817, lr:7.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.371, tt:2509.699\n",
      "Ep:80, loss:0.00003, loss_test:0.06981, lr:7.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.375, tt:2541.376\n",
      "Ep:81, loss:0.00002, loss_test:0.08138, lr:7.32e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.346, tt:2570.402\n",
      "Ep:82, loss:0.00002, loss_test:0.07121, lr:7.25e-03, fs:0.75740 (r=0.646,p=0.914),  time:31.342, tt:2601.414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00002, loss_test:0.07861, lr:7.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.341, tt:2632.604\n",
      "Ep:84, loss:0.00002, loss_test:0.07396, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.335, tt:2663.439\n",
      "Ep:85, loss:0.00002, loss_test:0.07458, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.327, tt:2694.141\n",
      "Ep:86, loss:0.00002, loss_test:0.07604, lr:6.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.321, tt:2724.902\n",
      "Ep:87, loss:0.00002, loss_test:0.07509, lr:6.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.336, tt:2757.602\n",
      "Ep:88, loss:0.00002, loss_test:0.07451, lr:6.83e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.326, tt:2788.053\n",
      "Ep:89, loss:0.00002, loss_test:0.07775, lr:6.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.323, tt:2819.036\n",
      "Ep:90, loss:0.00002, loss_test:0.07500, lr:6.69e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.328, tt:2850.858\n",
      "Ep:91, loss:0.00002, loss_test:0.07663, lr:6.62e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.338, tt:2883.058\n",
      "Ep:92, loss:0.00002, loss_test:0.07652, lr:6.56e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.352, tt:2915.721\n",
      "Ep:93, loss:0.00002, loss_test:0.07538, lr:6.49e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.357, tt:2947.551\n",
      "Ep:94, loss:0.00002, loss_test:0.07825, lr:6.43e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.357, tt:2978.951\n",
      "Ep:95, loss:0.00002, loss_test:0.07683, lr:6.36e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.370, tt:3011.530\n",
      "Ep:96, loss:0.00002, loss_test:0.07653, lr:6.30e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.374, tt:3043.258\n",
      "Ep:97, loss:0.00002, loss_test:0.07900, lr:6.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.378, tt:3075.037\n",
      "Ep:98, loss:0.00002, loss_test:0.07408, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.397, tt:3108.279\n",
      "Ep:99, loss:0.00002, loss_test:0.07962, lr:6.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.405, tt:3140.475\n",
      "Ep:100, loss:0.00002, loss_test:0.07567, lr:6.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.411, tt:3172.463\n",
      "Ep:101, loss:0.00002, loss_test:0.07760, lr:5.99e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.416, tt:3204.407\n",
      "Ep:102, loss:0.00001, loss_test:0.07589, lr:5.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.410, tt:3235.185\n",
      "Ep:103, loss:0.00001, loss_test:0.07771, lr:5.87e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.414, tt:3267.020\n",
      "Ep:104, loss:0.00001, loss_test:0.07690, lr:5.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.405, tt:3297.576\n",
      "Ep:105, loss:0.00001, loss_test:0.07466, lr:5.75e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.414, tt:3329.919\n",
      "Ep:106, loss:0.00001, loss_test:0.07619, lr:5.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.399, tt:3359.686\n",
      "Ep:107, loss:0.00001, loss_test:0.07593, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.404, tt:3391.585\n",
      "Ep:108, loss:0.00001, loss_test:0.07502, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.416, tt:3424.292\n",
      "Ep:109, loss:0.00001, loss_test:0.07868, lr:5.53e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.414, tt:3455.492\n",
      "Ep:110, loss:0.00001, loss_test:0.07632, lr:5.47e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.415, tt:3487.069\n",
      "Ep:111, loss:0.00001, loss_test:0.07687, lr:5.42e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.426, tt:3519.704\n",
      "Ep:112, loss:0.00001, loss_test:0.07595, lr:5.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.426, tt:3551.148\n",
      "Ep:113, loss:0.00001, loss_test:0.07574, lr:5.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.435, tt:3583.615\n",
      "Ep:114, loss:0.00001, loss_test:0.07705, lr:5.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.435, tt:3615.022\n",
      "Ep:115, loss:0.00001, loss_test:0.07487, lr:5.20e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.437, tt:3646.662\n",
      "Ep:116, loss:0.00001, loss_test:0.07708, lr:5.15e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.440, tt:3678.522\n",
      "Ep:117, loss:0.00001, loss_test:0.07600, lr:5.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.454, tt:3711.622\n",
      "Ep:118, loss:0.00001, loss_test:0.07677, lr:5.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.457, tt:3743.385\n",
      "Ep:119, loss:0.00001, loss_test:0.07535, lr:5.00e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.457, tt:3774.857\n",
      "Ep:120, loss:0.00001, loss_test:0.07707, lr:4.95e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.455, tt:3806.064\n",
      "Ep:121, loss:0.00001, loss_test:0.07536, lr:4.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.489, tt:3841.612\n",
      "Ep:122, loss:0.00001, loss_test:0.07774, lr:4.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.488, tt:3872.987\n",
      "Ep:123, loss:0.00001, loss_test:0.07702, lr:4.80e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.486, tt:3904.294\n",
      "Ep:124, loss:0.00001, loss_test:0.07631, lr:4.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.488, tt:3935.953\n",
      "Ep:125, loss:0.00001, loss_test:0.07728, lr:4.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.478, tt:3966.192\n",
      "Ep:126, loss:0.00001, loss_test:0.07889, lr:4.66e-03, fs:0.77108 (r=0.646,p=0.955),  time:31.487, tt:3998.851\n",
      "Ep:127, loss:0.00001, loss_test:0.07514, lr:4.61e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.493, tt:4031.051\n",
      "Ep:128, loss:0.00001, loss_test:0.07776, lr:4.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.492, tt:4062.450\n",
      "Ep:129, loss:0.00001, loss_test:0.07702, lr:4.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.502, tt:4095.212\n",
      "Ep:130, loss:0.00001, loss_test:0.07521, lr:4.48e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.505, tt:4127.120\n",
      "Ep:131, loss:0.00001, loss_test:0.07800, lr:4.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.506, tt:4158.780\n",
      "Ep:132, loss:0.00001, loss_test:0.07618, lr:4.39e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.513, tt:4191.262\n",
      "Ep:133, loss:0.00001, loss_test:0.07677, lr:4.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.520, tt:4223.705\n",
      "Ep:134, loss:0.00001, loss_test:0.07522, lr:4.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.519, tt:4255.052\n",
      "Ep:135, loss:0.00001, loss_test:0.07675, lr:4.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.534, tt:4288.557\n",
      "Ep:136, loss:0.00001, loss_test:0.07585, lr:4.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.533, tt:4319.980\n",
      "Ep:137, loss:0.00001, loss_test:0.07594, lr:4.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.536, tt:4351.959\n",
      "Ep:138, loss:0.00001, loss_test:0.07708, lr:4.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.542, tt:4384.271\n",
      "Ep:139, loss:0.00001, loss_test:0.07570, lr:4.09e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.546, tt:4416.474\n",
      "Ep:140, loss:0.00001, loss_test:0.07645, lr:4.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.556, tt:4449.395\n",
      "Ep:141, loss:0.00001, loss_test:0.07592, lr:4.01e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.563, tt:4481.998\n",
      "Ep:142, loss:0.00001, loss_test:0.07720, lr:3.97e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.564, tt:4513.633\n",
      "Ep:143, loss:0.00001, loss_test:0.07551, lr:3.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.560, tt:4544.587\n",
      "Ep:144, loss:0.00001, loss_test:0.07723, lr:3.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.569, tt:4577.542\n",
      "Ep:145, loss:0.00001, loss_test:0.07831, lr:3.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.573, tt:4609.685\n",
      "Ep:146, loss:0.00001, loss_test:0.07437, lr:3.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.578, tt:4641.914\n",
      "Ep:147, loss:0.00001, loss_test:0.07892, lr:3.77e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.582, tt:4674.158\n",
      "Ep:148, loss:0.00001, loss_test:0.07740, lr:3.73e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.591, tt:4707.046\n",
      "Ep:149, loss:0.00001, loss_test:0.07591, lr:3.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.585, tt:4737.728\n",
      "Ep:150, loss:0.00001, loss_test:0.07658, lr:3.66e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.587, tt:4769.703\n",
      "Ep:151, loss:0.00001, loss_test:0.07556, lr:3.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.591, tt:4801.799\n",
      "Ep:152, loss:0.00001, loss_test:0.07623, lr:3.59e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.590, tt:4833.271\n",
      "Ep:153, loss:0.00001, loss_test:0.07791, lr:3.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.598, tt:4866.098\n",
      "Ep:154, loss:0.00001, loss_test:0.07614, lr:3.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.587, tt:4895.915\n",
      "Ep:155, loss:0.00001, loss_test:0.07651, lr:3.48e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.568, tt:4924.557\n",
      "Ep:156, loss:0.00001, loss_test:0.07587, lr:3.45e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.552, tt:4953.661\n",
      "Ep:157, loss:0.00001, loss_test:0.07576, lr:3.41e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.554, tt:4985.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:158, loss:0.00001, loss_test:0.07724, lr:3.38e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.554, tt:5017.144\n",
      "Ep:159, loss:0.00001, loss_test:0.07546, lr:3.34e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.567, tt:5050.740\n",
      "Ep:160, loss:0.00001, loss_test:0.07773, lr:3.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.567, tt:5082.207\n",
      "Ep:161, loss:0.00001, loss_test:0.07809, lr:3.28e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.567, tt:5113.791\n",
      "Ep:162, loss:0.00001, loss_test:0.07488, lr:3.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.570, tt:5145.903\n",
      "Ep:163, loss:0.00001, loss_test:0.08056, lr:3.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.562, tt:5176.178\n",
      "Ep:164, loss:0.00001, loss_test:0.07837, lr:3.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:31.564, tt:5208.036\n",
      "Ep:165, loss:0.00001, loss_test:0.07524, lr:3.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.559, tt:5238.847\n",
      "Ep:166, loss:0.00001, loss_test:0.07822, lr:3.12e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.559, tt:5270.300\n",
      "Ep:167, loss:0.00001, loss_test:0.07905, lr:3.09e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.556, tt:5301.398\n",
      "Ep:168, loss:0.00001, loss_test:0.07645, lr:3.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.552, tt:5332.342\n",
      "Ep:169, loss:0.00001, loss_test:0.07657, lr:3.02e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.552, tt:5363.792\n",
      "Ep:170, loss:0.00001, loss_test:0.07826, lr:2.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.549, tt:5394.962\n",
      "Ep:171, loss:0.00001, loss_test:0.07711, lr:2.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.537, tt:5424.387\n",
      "Ep:172, loss:0.00001, loss_test:0.07626, lr:2.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.536, tt:5455.708\n",
      "Ep:173, loss:0.00001, loss_test:0.07701, lr:2.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.528, tt:5485.800\n",
      "Ep:174, loss:0.00001, loss_test:0.07732, lr:2.88e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.523, tt:5516.562\n",
      "Ep:175, loss:0.00001, loss_test:0.07659, lr:2.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.519, tt:5547.413\n",
      "Ep:176, loss:0.00001, loss_test:0.07687, lr:2.82e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.514, tt:5577.897\n",
      "Ep:177, loss:0.00001, loss_test:0.07732, lr:2.79e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.502, tt:5607.442\n",
      "Ep:178, loss:0.00001, loss_test:0.07640, lr:2.76e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.492, tt:5637.054\n",
      "Ep:179, loss:0.00001, loss_test:0.07629, lr:2.73e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.490, tt:5668.213\n",
      "Ep:180, loss:0.00001, loss_test:0.07771, lr:2.71e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.486, tt:5698.992\n",
      "Ep:181, loss:0.00001, loss_test:0.07715, lr:2.68e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.478, tt:5728.964\n",
      "Ep:182, loss:0.00001, loss_test:0.07721, lr:2.65e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.477, tt:5760.287\n",
      "Ep:183, loss:0.00001, loss_test:0.07745, lr:2.63e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.471, tt:5790.629\n",
      "Ep:184, loss:0.00001, loss_test:0.07592, lr:2.60e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.465, tt:5821.110\n",
      "Ep:185, loss:0.00001, loss_test:0.07767, lr:2.57e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.461, tt:5851.729\n",
      "Ep:186, loss:0.00001, loss_test:0.07869, lr:2.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.466, tt:5884.236\n",
      "Ep:187, loss:0.00001, loss_test:0.07562, lr:2.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.462, tt:5914.797\n",
      "Ep:188, loss:0.00001, loss_test:0.07766, lr:2.50e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.464, tt:5946.684\n",
      "Ep:189, loss:0.00001, loss_test:0.07818, lr:2.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.447, tt:5974.880\n",
      "Ep:190, loss:0.00001, loss_test:0.07677, lr:2.45e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6006.156\n",
      "Ep:191, loss:0.00001, loss_test:0.07667, lr:2.42e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6037.575\n",
      "Ep:192, loss:0.00001, loss_test:0.07777, lr:2.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.451, tt:6070.046\n",
      "Ep:193, loss:0.00001, loss_test:0.07774, lr:2.38e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6100.537\n",
      "Ep:194, loss:0.00001, loss_test:0.07620, lr:2.35e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6132.024\n",
      "Ep:195, loss:0.00001, loss_test:0.07767, lr:2.33e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6163.396\n",
      "Ep:196, loss:0.00001, loss_test:0.07807, lr:2.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.445, tt:6194.639\n",
      "Ep:197, loss:0.00001, loss_test:0.07666, lr:2.28e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.450, tt:6227.058\n",
      "Ep:198, loss:0.00001, loss_test:0.07717, lr:2.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.446, tt:6257.694\n",
      "Ep:199, loss:0.00001, loss_test:0.07717, lr:2.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.431, tt:6286.258\n",
      "Ep:200, loss:0.00001, loss_test:0.07694, lr:2.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:31.418, tt:6315.090\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.01971, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:41.476, tt:41.476\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02467, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.073, tt:82.145\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02764, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.653, tt:121.958\n",
      "Ep:3, loss:0.00005, loss_test:0.02854, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.461, tt:161.845\n",
      "Ep:4, loss:0.00006, loss_test:0.02850, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.892, tt:199.460\n",
      "Ep:5, loss:0.00006, loss_test:0.02763, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.374, tt:242.246\n",
      "Ep:6, loss:0.00005, loss_test:0.02607, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.493, tt:283.452\n",
      "Ep:7, loss:0.00005, loss_test:0.02407, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.392, tt:323.139\n",
      "Ep:8, loss:0.00005, loss_test:0.02193, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:40.439, tt:363.954\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02001, lr:6.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:40.300, tt:403.000\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01898, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:40.362, tt:443.987\n",
      "Ep:11, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.66667 (r=0.808,p=0.567),  time:40.280, tt:483.363\n",
      "Ep:12, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:40.340, tt:524.426\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01822, lr:6.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:40.423, tt:565.924\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01747, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:40.420, tt:606.298\n",
      "Ep:15, loss:0.00003, loss_test:0.01711, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:40.448, tt:647.163\n",
      "Ep:16, loss:0.00003, loss_test:0.01684, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:40.364, tt:686.183\n",
      "Ep:17, loss:0.00003, loss_test:0.01649, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:40.367, tt:726.599\n",
      "Ep:18, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:40.432, tt:768.214\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01575, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:40.447, tt:808.935\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01547, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:40.383, tt:848.037\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:40.437, tt:889.606\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01471, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:40.362, tt:928.324\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01430, lr:6.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:40.370, tt:968.873\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01396, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:40.346, tt:1008.659\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:40.266, tt:1046.903\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:40.294, tt:1087.943\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:40.297, tt:1128.311\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:40.306, tt:1168.872\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:40.311, tt:1209.335\n",
      "Ep:30, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:40.352, tt:1250.899\n",
      "Ep:31, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:40.341, tt:1290.914\n",
      "Ep:32, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:40.330, tt:1330.885\n",
      "Ep:33, loss:0.00002, loss_test:0.01280, lr:6.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:40.321, tt:1370.910\n",
      "Ep:34, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:40.322, tt:1411.260\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01263, lr:6.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:40.291, tt:1450.475\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01258, lr:6.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:40.274, tt:1490.126\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:40.256, tt:1529.720\n",
      "Ep:38, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:40.229, tt:1568.946\n",
      "Ep:39, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.236, tt:1609.432\n",
      "Ep:40, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:40.219, tt:1648.959\n",
      "Ep:41, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:40.249, tt:1690.442\n",
      "Ep:42, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:40.270, tt:1731.620\n",
      "Ep:43, loss:0.00001, loss_test:0.01220, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:40.234, tt:1770.308\n",
      "Ep:44, loss:0.00001, loss_test:0.01219, lr:6.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:40.244, tt:1810.966\n",
      "Ep:45, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:40.263, tt:1852.076\n",
      "Ep:46, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:40.276, tt:1892.979\n",
      "Ep:47, loss:0.00001, loss_test:0.01208, lr:6.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:40.286, tt:1933.713\n",
      "Ep:48, loss:0.00001, loss_test:0.01205, lr:5.94e-02, fs:0.86139 (r=0.879,p=0.845),  time:40.312, tt:1975.299\n",
      "Ep:49, loss:0.00001, loss_test:0.01205, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:40.336, tt:2016.818\n",
      "Ep:50, loss:0.00001, loss_test:0.01208, lr:5.82e-02, fs:0.86567 (r=0.879,p=0.853),  time:40.348, tt:2057.769\n",
      "Ep:51, loss:0.00001, loss_test:0.01212, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:40.451, tt:2103.431\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:40.430, tt:2142.794\n",
      "Ep:53, loss:0.00001, loss_test:0.01209, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:40.428, tt:2183.114\n",
      "Ep:54, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.86432 (r=0.869,p=0.860),  time:40.456, tt:2225.066\n",
      "Ep:55, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.85859 (r=0.859,p=0.859),  time:40.412, tt:2263.074\n",
      "Ep:56, loss:0.00001, loss_test:0.01211, lr:5.76e-02, fs:0.85279 (r=0.848,p=0.857),  time:40.395, tt:2302.494\n",
      "Ep:57, loss:0.00001, loss_test:0.01213, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.393, tt:2342.795\n",
      "Ep:58, loss:0.00001, loss_test:0.01214, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.371, tt:2381.882\n",
      "Ep:59, loss:0.00001, loss_test:0.01216, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.380, tt:2422.829\n",
      "Ep:60, loss:0.00001, loss_test:0.01216, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.386, tt:2463.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01220, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.376, tt:2503.313\n",
      "Ep:62, loss:0.00001, loss_test:0.01224, lr:5.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.346, tt:2541.800\n",
      "Ep:63, loss:0.00001, loss_test:0.01227, lr:5.71e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.324, tt:2580.759\n",
      "Ep:64, loss:0.00001, loss_test:0.01222, lr:5.65e-02, fs:0.84694 (r=0.838,p=0.856),  time:40.296, tt:2619.215\n",
      "Ep:65, loss:0.00001, loss_test:0.01226, lr:5.59e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.294, tt:2659.430\n",
      "Ep:66, loss:0.00001, loss_test:0.01230, lr:5.54e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.285, tt:2699.118\n",
      "Ep:67, loss:0.00001, loss_test:0.01230, lr:5.48e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.270, tt:2738.362\n",
      "Ep:68, loss:0.00001, loss_test:0.01228, lr:5.43e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.362, tt:2784.984\n",
      "Ep:69, loss:0.00001, loss_test:0.01231, lr:5.37e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.344, tt:2824.049\n",
      "Ep:70, loss:0.00001, loss_test:0.01236, lr:5.32e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.337, tt:2863.960\n",
      "Ep:71, loss:0.00001, loss_test:0.01237, lr:5.27e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.343, tt:2904.695\n",
      "Ep:72, loss:0.00001, loss_test:0.01242, lr:5.21e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.367, tt:2946.780\n",
      "Ep:73, loss:0.00001, loss_test:0.01244, lr:5.16e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.366, tt:2987.078\n",
      "Ep:74, loss:0.00001, loss_test:0.01245, lr:5.11e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.377, tt:3028.300\n",
      "Ep:75, loss:0.00001, loss_test:0.01253, lr:5.06e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.372, tt:3068.286\n",
      "Ep:76, loss:0.00001, loss_test:0.01252, lr:5.01e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.398, tt:3110.646\n",
      "Ep:77, loss:0.00001, loss_test:0.01253, lr:4.96e-02, fs:0.84656 (r=0.808,p=0.889),  time:40.412, tt:3152.136\n",
      "Ep:78, loss:0.00001, loss_test:0.01257, lr:4.91e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.384, tt:3190.355\n",
      "Ep:79, loss:0.00001, loss_test:0.01261, lr:4.86e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.381, tt:3230.502\n",
      "Ep:80, loss:0.00001, loss_test:0.01267, lr:4.81e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.382, tt:3270.968\n",
      "Ep:81, loss:0.00001, loss_test:0.01268, lr:4.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.394, tt:3312.271\n",
      "Ep:82, loss:0.00001, loss_test:0.01273, lr:4.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.405, tt:3353.596\n",
      "Ep:83, loss:0.00001, loss_test:0.01276, lr:4.67e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.409, tt:3394.323\n",
      "Ep:84, loss:0.00001, loss_test:0.01281, lr:4.62e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.410, tt:3434.842\n",
      "Ep:85, loss:0.00001, loss_test:0.01286, lr:4.57e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.419, tt:3476.052\n",
      "Ep:86, loss:0.00001, loss_test:0.01286, lr:4.53e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.429, tt:3517.336\n",
      "Ep:87, loss:0.00001, loss_test:0.01293, lr:4.48e-02, fs:0.85561 (r=0.808,p=0.909),  time:40.449, tt:3559.515\n",
      "Ep:88, loss:0.00001, loss_test:0.01296, lr:4.44e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.447, tt:3599.790\n",
      "Ep:89, loss:0.00001, loss_test:0.01297, lr:4.39e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.466, tt:3641.901\n",
      "Ep:90, loss:0.00001, loss_test:0.01298, lr:4.35e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.457, tt:3681.578\n",
      "Ep:91, loss:0.00001, loss_test:0.01303, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.462, tt:3722.469\n",
      "Ep:92, loss:0.00001, loss_test:0.01309, lr:4.26e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.468, tt:3763.537\n",
      "Ep:93, loss:0.00001, loss_test:0.01314, lr:4.22e-02, fs:0.84946 (r=0.798,p=0.908),  time:40.517, tt:3808.603\n",
      "Ep:94, loss:0.00001, loss_test:0.01315, lr:4.18e-02, fs:0.85405 (r=0.798,p=0.919),  time:40.516, tt:3848.977\n",
      "Ep:95, loss:0.00001, loss_test:0.01321, lr:4.14e-02, fs:0.85405 (r=0.798,p=0.919),  time:40.525, tt:3890.381\n",
      "Ep:96, loss:0.00001, loss_test:0.01323, lr:4.10e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.512, tt:3929.689\n",
      "Ep:97, loss:0.00001, loss_test:0.01330, lr:4.05e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.511, tt:3970.051\n",
      "Ep:98, loss:0.00001, loss_test:0.01330, lr:4.01e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.500, tt:4009.545\n",
      "Ep:99, loss:0.00001, loss_test:0.01332, lr:3.97e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.490, tt:4049.023\n",
      "Ep:100, loss:0.00001, loss_test:0.01335, lr:3.93e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.500, tt:4090.506\n",
      "Ep:101, loss:0.00001, loss_test:0.01338, lr:3.89e-02, fs:0.84783 (r=0.788,p=0.918),  time:40.481, tt:4129.093\n",
      "Ep:102, loss:0.00001, loss_test:0.01344, lr:3.86e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.493, tt:4170.735\n",
      "Ep:103, loss:0.00001, loss_test:0.01349, lr:3.82e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.487, tt:4210.616\n",
      "Ep:104, loss:0.00001, loss_test:0.01352, lr:3.78e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.473, tt:4249.626\n",
      "Ep:105, loss:0.00000, loss_test:0.01356, lr:3.74e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.471, tt:4289.959\n",
      "Ep:106, loss:0.00000, loss_test:0.01358, lr:3.70e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.479, tt:4331.305\n",
      "Ep:107, loss:0.00000, loss_test:0.01359, lr:3.67e-02, fs:0.84153 (r=0.778,p=0.917),  time:40.486, tt:4372.455\n",
      "Ep:108, loss:0.00000, loss_test:0.01367, lr:3.63e-02, fs:0.80899 (r=0.727,p=0.911),  time:40.484, tt:4412.709\n",
      "Ep:109, loss:0.00000, loss_test:0.01372, lr:3.59e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.478, tt:4452.616\n",
      "Ep:110, loss:0.00000, loss_test:0.01375, lr:3.56e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.517, tt:4497.343\n",
      "Ep:111, loss:0.00000, loss_test:0.01378, lr:3.52e-02, fs:0.80226 (r=0.717,p=0.910),  time:40.507, tt:4536.833\n",
      "Ep:112, loss:0.00000, loss_test:0.01383, lr:3.49e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.493, tt:4575.697\n",
      "Ep:113, loss:0.00000, loss_test:0.01385, lr:3.45e-02, fs:0.79545 (r=0.707,p=0.909),  time:40.494, tt:4616.343\n",
      "Ep:114, loss:0.00000, loss_test:0.01388, lr:3.42e-02, fs:0.80000 (r=0.707,p=0.921),  time:40.507, tt:4658.267\n",
      "Ep:115, loss:0.00000, loss_test:0.01391, lr:3.38e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.497, tt:4697.636\n",
      "Ep:116, loss:0.00000, loss_test:0.01397, lr:3.35e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.516, tt:4740.381\n",
      "Ep:117, loss:0.00000, loss_test:0.01399, lr:3.32e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.542, tt:4783.922\n",
      "Ep:118, loss:0.00000, loss_test:0.01398, lr:3.28e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.545, tt:4824.814\n",
      "Ep:119, loss:0.00000, loss_test:0.01406, lr:3.25e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.547, tt:4865.602\n",
      "Ep:120, loss:0.00000, loss_test:0.01409, lr:3.22e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.541, tt:4905.466\n",
      "Ep:121, loss:0.00000, loss_test:0.01412, lr:3.19e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.549, tt:4947.034\n",
      "Ep:122, loss:0.00000, loss_test:0.01415, lr:3.15e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.553, tt:4988.041\n",
      "Ep:123, loss:0.00000, loss_test:0.01419, lr:3.12e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.558, tt:5029.240\n",
      "Ep:124, loss:0.00000, loss_test:0.01422, lr:3.09e-02, fs:0.79769 (r=0.697,p=0.932),  time:40.553, tt:5069.087\n",
      "Ep:125, loss:0.00000, loss_test:0.01428, lr:3.06e-02, fs:0.80233 (r=0.697,p=0.945),  time:40.545, tt:5108.653\n",
      "Ep:126, loss:0.00000, loss_test:0.01430, lr:3.03e-02, fs:0.80233 (r=0.697,p=0.945),  time:40.550, tt:5149.808\n",
      "Ep:127, loss:0.00000, loss_test:0.01432, lr:3.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:40.523, tt:5186.987\n",
      "Ep:128, loss:0.00000, loss_test:0.01435, lr:2.97e-02, fs:0.80233 (r=0.697,p=0.945),  time:40.505, tt:5225.156\n",
      "Ep:129, loss:0.00000, loss_test:0.01438, lr:2.94e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.499, tt:5264.826\n",
      "Ep:130, loss:0.00000, loss_test:0.01445, lr:2.91e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.492, tt:5304.426\n",
      "Ep:131, loss:0.00000, loss_test:0.01445, lr:2.88e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.483, tt:5343.691\n",
      "Ep:132, loss:0.00000, loss_test:0.01449, lr:2.85e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.475, tt:5383.232\n",
      "Ep:133, loss:0.00000, loss_test:0.01452, lr:2.82e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.460, tt:5421.582\n",
      "Ep:134, loss:0.00000, loss_test:0.01454, lr:2.80e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.457, tt:5461.686\n",
      "Ep:135, loss:0.00000, loss_test:0.01460, lr:2.77e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.452, tt:5501.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.01464, lr:2.74e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.445, tt:5540.901\n",
      "Ep:137, loss:0.00000, loss_test:0.01466, lr:2.71e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.429, tt:5579.218\n",
      "Ep:138, loss:0.00000, loss_test:0.01471, lr:2.69e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.418, tt:5618.060\n",
      "Ep:139, loss:0.00000, loss_test:0.01473, lr:2.66e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.413, tt:5657.880\n",
      "Ep:140, loss:0.00000, loss_test:0.01474, lr:2.63e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.418, tt:5698.986\n",
      "Ep:141, loss:0.00000, loss_test:0.01479, lr:2.61e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.401, tt:5737.010\n",
      "Ep:142, loss:0.00000, loss_test:0.01484, lr:2.58e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.413, tt:5779.077\n",
      "Ep:143, loss:0.00000, loss_test:0.01488, lr:2.55e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.405, tt:5818.316\n",
      "Ep:144, loss:0.00000, loss_test:0.01488, lr:2.53e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.396, tt:5857.426\n",
      "Ep:145, loss:0.00000, loss_test:0.01490, lr:2.50e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.396, tt:5897.846\n",
      "Ep:146, loss:0.00000, loss_test:0.01496, lr:2.48e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.395, tt:5938.135\n",
      "Ep:147, loss:0.00000, loss_test:0.01500, lr:2.45e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.396, tt:5978.656\n",
      "Ep:148, loss:0.00000, loss_test:0.01503, lr:2.43e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.391, tt:6018.242\n",
      "Ep:149, loss:0.00000, loss_test:0.01504, lr:2.40e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.388, tt:6058.151\n",
      "Ep:150, loss:0.00000, loss_test:0.01506, lr:2.38e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.378, tt:6097.061\n",
      "Ep:151, loss:0.00000, loss_test:0.01510, lr:2.36e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.381, tt:6137.968\n",
      "Ep:152, loss:0.00000, loss_test:0.01513, lr:2.33e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.377, tt:6177.716\n",
      "Ep:153, loss:0.00000, loss_test:0.01516, lr:2.31e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.367, tt:6216.469\n",
      "Ep:154, loss:0.00000, loss_test:0.01519, lr:2.29e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.370, tt:6257.295\n",
      "Ep:155, loss:0.00000, loss_test:0.01520, lr:2.26e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.370, tt:6297.647\n",
      "Ep:156, loss:0.00000, loss_test:0.01523, lr:2.24e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.395, tt:6341.976\n",
      "Ep:157, loss:0.00000, loss_test:0.01527, lr:2.22e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.395, tt:6382.423\n",
      "Ep:158, loss:0.00000, loss_test:0.01531, lr:2.20e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.387, tt:6421.506\n",
      "Ep:159, loss:0.00000, loss_test:0.01531, lr:2.17e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.387, tt:6461.950\n",
      "Ep:160, loss:0.00000, loss_test:0.01533, lr:2.15e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.387, tt:6502.312\n",
      "Ep:161, loss:0.00000, loss_test:0.01536, lr:2.13e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.384, tt:6542.151\n",
      "Ep:162, loss:0.00000, loss_test:0.01541, lr:2.11e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.389, tt:6583.415\n",
      "Ep:163, loss:0.00000, loss_test:0.01544, lr:2.09e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.382, tt:6622.659\n",
      "Ep:164, loss:0.00000, loss_test:0.01546, lr:2.07e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.385, tt:6663.555\n",
      "Ep:165, loss:0.00000, loss_test:0.01546, lr:2.05e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.386, tt:6704.051\n",
      "Ep:166, loss:0.00000, loss_test:0.01549, lr:2.03e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.377, tt:6742.934\n",
      "Ep:167, loss:0.00000, loss_test:0.01553, lr:2.01e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.383, tt:6784.332\n",
      "Ep:168, loss:0.00000, loss_test:0.01556, lr:1.99e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.374, tt:6823.220\n",
      "Ep:169, loss:0.00000, loss_test:0.01558, lr:1.97e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.366, tt:6862.195\n",
      "Ep:170, loss:0.00000, loss_test:0.01560, lr:1.95e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.355, tt:6900.786\n",
      "Ep:171, loss:0.00000, loss_test:0.01561, lr:1.93e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.362, tt:6942.272\n",
      "Ep:172, loss:0.00000, loss_test:0.01566, lr:1.91e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.365, tt:6983.175\n",
      "Ep:173, loss:0.00000, loss_test:0.01567, lr:1.89e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.371, tt:7024.550\n",
      "Ep:174, loss:0.00000, loss_test:0.01568, lr:1.87e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.363, tt:7063.494\n",
      "Ep:175, loss:0.00000, loss_test:0.01572, lr:1.85e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.357, tt:7102.797\n",
      "Ep:176, loss:0.00000, loss_test:0.01575, lr:1.83e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.351, tt:7142.103\n",
      "Ep:177, loss:0.00000, loss_test:0.01574, lr:1.81e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.337, tt:7179.950\n",
      "Ep:178, loss:0.00000, loss_test:0.01577, lr:1.80e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.334, tt:7219.779\n",
      "Ep:179, loss:0.00000, loss_test:0.01581, lr:1.78e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.336, tt:7260.481\n",
      "Ep:180, loss:0.00000, loss_test:0.01584, lr:1.76e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.328, tt:7299.292\n",
      "Ep:181, loss:0.00000, loss_test:0.01585, lr:1.74e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.330, tt:7339.992\n",
      "Ep:182, loss:0.00000, loss_test:0.01586, lr:1.73e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.331, tt:7380.643\n",
      "Ep:183, loss:0.00000, loss_test:0.01589, lr:1.71e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.332, tt:7421.081\n",
      "Ep:184, loss:0.00000, loss_test:0.01592, lr:1.69e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.330, tt:7460.972\n",
      "Ep:185, loss:0.00000, loss_test:0.01594, lr:1.67e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.335, tt:7502.394\n",
      "Ep:186, loss:0.00000, loss_test:0.01595, lr:1.66e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.331, tt:7541.828\n",
      "Ep:187, loss:0.00000, loss_test:0.01599, lr:1.64e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.332, tt:7582.326\n",
      "Ep:188, loss:0.00000, loss_test:0.01601, lr:1.62e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.327, tt:7621.860\n",
      "Ep:189, loss:0.00000, loss_test:0.01602, lr:1.61e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.323, tt:7661.427\n",
      "Ep:190, loss:0.00000, loss_test:0.01604, lr:1.59e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.318, tt:7700.696\n",
      "Ep:191, loss:0.00000, loss_test:0.01606, lr:1.58e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.313, tt:7740.079\n",
      "Ep:192, loss:0.00000, loss_test:0.01607, lr:1.56e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.306, tt:7779.022\n",
      "Ep:193, loss:0.00000, loss_test:0.01609, lr:1.54e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.307, tt:7819.605\n",
      "Ep:194, loss:0.00000, loss_test:0.01610, lr:1.53e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.312, tt:7860.799\n",
      "Ep:195, loss:0.00000, loss_test:0.01612, lr:1.51e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.312, tt:7901.174\n",
      "Ep:196, loss:0.00000, loss_test:0.01614, lr:1.50e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.313, tt:7941.594\n",
      "Ep:197, loss:0.00000, loss_test:0.01616, lr:1.48e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.303, tt:7979.905\n",
      "Ep:198, loss:0.00000, loss_test:0.01619, lr:1.47e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.296, tt:8018.920\n",
      "Ep:199, loss:0.00000, loss_test:0.01621, lr:1.45e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.292, tt:8058.474\n",
      "Ep:200, loss:0.00000, loss_test:0.01623, lr:1.44e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.269, tt:8094.029\n",
      "Ep:201, loss:0.00000, loss_test:0.01624, lr:1.43e-02, fs:0.80702 (r=0.697,p=0.958),  time:40.247, tt:8129.847\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13692, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.815, tt:32.815\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13397, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:34.624, tt:69.247\n",
      "Ep:2, loss:0.00027, loss_test:0.12882, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:36.863, tt:110.590\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12153, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:37.677, tt:150.709\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00025, loss_test:0.11440, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:37.927, tt:189.635\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11033, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:38.328, tt:229.968\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10815, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:38.644, tt:270.506\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10605, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:38.988, tt:311.902\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10371, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:39.107, tt:351.966\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10043, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:39.306, tt:393.064\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09690, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:39.368, tt:433.044\n",
      "Ep:11, loss:0.00019, loss_test:0.09587, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:39.598, tt:475.175\n",
      "Ep:12, loss:0.00018, loss_test:0.09275, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:39.711, tt:516.246\n",
      "Ep:13, loss:0.00017, loss_test:0.09023, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:39.903, tt:558.646\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.08890, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:40.038, tt:600.573\n",
      "Ep:15, loss:0.00015, loss_test:0.08734, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:40.173, tt:642.764\n",
      "Ep:16, loss:0.00015, loss_test:0.08433, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:40.215, tt:683.647\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.08382, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:40.273, tt:724.910\n",
      "Ep:18, loss:0.00013, loss_test:0.08228, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:40.421, tt:768.000\n",
      "Ep:19, loss:0.00013, loss_test:0.07909, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:40.521, tt:810.426\n",
      "Ep:20, loss:0.00012, loss_test:0.07919, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:40.636, tt:853.354\n",
      "Ep:21, loss:0.00012, loss_test:0.07736, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:40.731, tt:896.081\n",
      "Ep:22, loss:0.00011, loss_test:0.07533, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:40.776, tt:937.837\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.07710, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:40.764, tt:978.341\n",
      "Ep:24, loss:0.00010, loss_test:0.07378, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:40.827, tt:1020.677\n",
      "Ep:25, loss:0.00010, loss_test:0.07282, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:40.868, tt:1062.561\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.07391, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:40.938, tt:1105.339\n",
      "Ep:27, loss:0.00009, loss_test:0.07184, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:40.936, tt:1146.196\n",
      "Ep:28, loss:0.00008, loss_test:0.07232, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:41.006, tt:1189.172\n",
      "Ep:29, loss:0.00008, loss_test:0.07281, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:41.029, tt:1230.866\n",
      "Ep:30, loss:0.00008, loss_test:0.06923, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:41.050, tt:1272.565\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.07214, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:41.112, tt:1315.572\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.06984, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:41.113, tt:1356.744\n",
      "Ep:33, loss:0.00007, loss_test:0.06950, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:41.129, tt:1398.375\n",
      "Ep:34, loss:0.00007, loss_test:0.07096, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:41.108, tt:1438.778\n",
      "Ep:35, loss:0.00006, loss_test:0.06819, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:41.134, tt:1480.841\n",
      "Ep:36, loss:0.00006, loss_test:0.07090, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:41.186, tt:1523.879\n",
      "Ep:37, loss:0.00006, loss_test:0.06730, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:41.216, tt:1566.191\n",
      "Ep:38, loss:0.00006, loss_test:0.06775, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:41.214, tt:1607.359\n",
      "Ep:39, loss:0.00005, loss_test:0.06961, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:41.239, tt:1649.566\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.06751, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.246, tt:1691.068\n",
      "Ep:41, loss:0.00005, loss_test:0.06845, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.246, tt:1732.331\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06867, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.281, tt:1775.068\n",
      "Ep:43, loss:0.00005, loss_test:0.06808, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.356, tt:1819.647\n",
      "Ep:44, loss:0.00004, loss_test:0.06791, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.379, tt:1862.038\n",
      "Ep:45, loss:0.00004, loss_test:0.06871, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:41.381, tt:1903.509\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00004, loss_test:0.06860, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.404, tt:1945.977\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.06708, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:41.428, tt:1988.544\n",
      "Ep:48, loss:0.00004, loss_test:0.06816, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.449, tt:2031.019\n",
      "Ep:49, loss:0.00004, loss_test:0.06755, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.460, tt:2073.018\n",
      "Ep:50, loss:0.00004, loss_test:0.06770, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.469, tt:2114.941\n",
      "Ep:51, loss:0.00003, loss_test:0.06752, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.496, tt:2157.797\n",
      "Ep:52, loss:0.00003, loss_test:0.06694, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.513, tt:2200.191\n",
      "Ep:53, loss:0.00003, loss_test:0.06778, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.517, tt:2241.938\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.06583, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.552, tt:2285.348\n",
      "Ep:55, loss:0.00003, loss_test:0.06781, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:41.560, tt:2327.379\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.06583, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.514, tt:2366.279\n",
      "Ep:57, loss:0.00003, loss_test:0.06645, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.532, tt:2408.883\n",
      "Ep:58, loss:0.00003, loss_test:0.06736, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.525, tt:2449.967\n",
      "Ep:59, loss:0.00003, loss_test:0.06543, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:41.543, tt:2492.582\n",
      "Ep:60, loss:0.00003, loss_test:0.06675, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.588, tt:2536.861\n",
      "Ep:61, loss:0.00002, loss_test:0.06605, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:41.586, tt:2578.349\n",
      "Ep:62, loss:0.00002, loss_test:0.06511, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.615, tt:2621.743\n",
      "Ep:63, loss:0.00002, loss_test:0.06564, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:41.606, tt:2662.791\n",
      "Ep:64, loss:0.00002, loss_test:0.06619, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:41.620, tt:2705.327\n",
      "Ep:65, loss:0.00002, loss_test:0.06483, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:41.600, tt:2745.628\n",
      "Ep:66, loss:0.00002, loss_test:0.06573, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:41.594, tt:2786.796\n",
      "Ep:67, loss:0.00002, loss_test:0.06637, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.585, tt:2827.758\n",
      "Ep:68, loss:0.00002, loss_test:0.06502, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.565, tt:2868.004\n",
      "Ep:69, loss:0.00002, loss_test:0.06587, lr:9.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.566, tt:2909.604\n",
      "Ep:70, loss:0.00002, loss_test:0.06652, lr:9.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.574, tt:2951.776\n",
      "Ep:71, loss:0.00002, loss_test:0.06563, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.608, tt:2995.765\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.06513, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.593, tt:3036.295\n",
      "Ep:73, loss:0.00002, loss_test:0.06666, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.623, tt:3080.102\n",
      "Ep:74, loss:0.00002, loss_test:0.06622, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.597, tt:3119.763\n",
      "Ep:75, loss:0.00002, loss_test:0.06570, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.595, tt:3161.188\n",
      "Ep:76, loss:0.00002, loss_test:0.06630, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.599, tt:3203.096\n",
      "Ep:77, loss:0.00002, loss_test:0.06649, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.614, tt:3245.886\n",
      "Ep:78, loss:0.00001, loss_test:0.06675, lr:9.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.627, tt:3288.501\n",
      "Ep:79, loss:0.00001, loss_test:0.06713, lr:9.51e-03, fs:0.84746 (r=0.758,p=0.962),  time:41.615, tt:3329.228\n",
      "Ep:80, loss:0.00001, loss_test:0.06746, lr:9.51e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.627, tt:3371.824\n",
      "Ep:81, loss:0.00001, loss_test:0.06713, lr:9.51e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.645, tt:3414.851\n",
      "Ep:82, loss:0.00001, loss_test:0.06743, lr:9.51e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.654, tt:3457.275\n",
      "Ep:83, loss:0.00001, loss_test:0.06776, lr:9.41e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.708, tt:3503.513\n",
      "Ep:84, loss:0.00001, loss_test:0.06697, lr:9.32e-03, fs:0.84091 (r=0.747,p=0.961),  time:41.732, tt:3547.225\n",
      "Ep:85, loss:0.00001, loss_test:0.06789, lr:9.23e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.820, tt:3596.505\n",
      "Ep:86, loss:0.00001, loss_test:0.06799, lr:9.14e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.845, tt:3640.509\n",
      "Ep:87, loss:0.00001, loss_test:0.06745, lr:9.04e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.865, tt:3684.132\n",
      "Ep:88, loss:0.00001, loss_test:0.06850, lr:8.95e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.885, tt:3727.800\n",
      "Ep:89, loss:0.00001, loss_test:0.06874, lr:8.86e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.896, tt:3770.638\n",
      "Ep:90, loss:0.00001, loss_test:0.06775, lr:8.78e-03, fs:0.81395 (r=0.707,p=0.959),  time:41.910, tt:3813.830\n",
      "Ep:91, loss:0.00001, loss_test:0.06874, lr:8.69e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.942, tt:3858.697\n",
      "Ep:92, loss:0.00001, loss_test:0.06964, lr:8.60e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.999, tt:3905.868\n",
      "Ep:93, loss:0.00001, loss_test:0.06847, lr:8.51e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.029, tt:3950.691\n",
      "Ep:94, loss:0.00001, loss_test:0.06887, lr:8.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.072, tt:3996.883\n",
      "Ep:95, loss:0.00001, loss_test:0.06898, lr:8.35e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.111, tt:4042.679\n",
      "Ep:96, loss:0.00001, loss_test:0.06915, lr:8.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.132, tt:4086.849\n",
      "Ep:97, loss:0.00001, loss_test:0.06891, lr:8.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.157, tt:4131.376\n",
      "Ep:98, loss:0.00001, loss_test:0.06931, lr:8.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.167, tt:4174.572\n",
      "Ep:99, loss:0.00001, loss_test:0.06915, lr:8.02e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.202, tt:4220.238\n",
      "Ep:100, loss:0.00001, loss_test:0.06959, lr:7.94e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.245, tt:4266.710\n",
      "Ep:101, loss:0.00001, loss_test:0.06898, lr:7.86e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.255, tt:4310.033\n",
      "Ep:102, loss:0.00001, loss_test:0.07063, lr:7.78e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.264, tt:4353.161\n",
      "Ep:103, loss:0.00001, loss_test:0.07027, lr:7.70e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.288, tt:4397.947\n",
      "Ep:104, loss:0.00001, loss_test:0.06958, lr:7.62e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.376, tt:4449.427\n",
      "Ep:105, loss:0.00001, loss_test:0.07090, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.387, tt:4493.034\n",
      "Ep:106, loss:0.00001, loss_test:0.07091, lr:7.47e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.388, tt:4535.568\n",
      "Ep:107, loss:0.00001, loss_test:0.06959, lr:7.40e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.394, tt:4578.501\n",
      "Ep:108, loss:0.00001, loss_test:0.07083, lr:7.32e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.418, tt:4623.551\n",
      "Ep:109, loss:0.00001, loss_test:0.07140, lr:7.25e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.442, tt:4668.662\n",
      "Ep:110, loss:0.00001, loss_test:0.07051, lr:7.18e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.460, tt:4713.101\n",
      "Ep:111, loss:0.00001, loss_test:0.07042, lr:7.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.466, tt:4756.204\n",
      "Ep:112, loss:0.00001, loss_test:0.07083, lr:7.03e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.481, tt:4800.360\n",
      "Ep:113, loss:0.00001, loss_test:0.07127, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.475, tt:4842.138\n",
      "Ep:114, loss:0.00001, loss_test:0.07111, lr:6.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.469, tt:4883.897\n",
      "Ep:115, loss:0.00001, loss_test:0.07162, lr:6.83e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.461, tt:4925.436\n",
      "Ep:116, loss:0.00001, loss_test:0.07183, lr:6.76e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.468, tt:4968.802\n",
      "Ep:117, loss:0.00001, loss_test:0.07142, lr:6.69e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.467, tt:5011.094\n",
      "Ep:118, loss:0.00001, loss_test:0.07249, lr:6.62e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.470, tt:5053.954\n",
      "Ep:119, loss:0.00001, loss_test:0.07171, lr:6.56e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.486, tt:5098.337\n",
      "Ep:120, loss:0.00001, loss_test:0.07133, lr:6.49e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.497, tt:5142.163\n",
      "Ep:121, loss:0.00001, loss_test:0.07271, lr:6.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.494, tt:5184.327\n",
      "Ep:122, loss:0.00001, loss_test:0.07127, lr:6.36e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.489, tt:5226.135\n",
      "Ep:123, loss:0.00001, loss_test:0.07176, lr:6.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.501, tt:5270.163\n",
      "Ep:124, loss:0.00001, loss_test:0.07224, lr:6.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.499, tt:5312.415\n",
      "Ep:125, loss:0.00001, loss_test:0.07116, lr:6.17e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.492, tt:5353.947\n",
      "Ep:126, loss:0.00001, loss_test:0.07223, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.490, tt:5396.285\n",
      "Ep:127, loss:0.00001, loss_test:0.07192, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.483, tt:5437.839\n",
      "Ep:128, loss:0.00001, loss_test:0.07163, lr:5.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.459, tt:5477.216\n",
      "Ep:129, loss:0.00000, loss_test:0.07218, lr:5.93e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.459, tt:5519.670\n",
      "Ep:130, loss:0.00000, loss_test:0.07163, lr:5.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.444, tt:5560.181\n",
      "Ep:131, loss:0.00000, loss_test:0.07154, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.418, tt:5599.191\n",
      "Ep:132, loss:0.00000, loss_test:0.07253, lr:5.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.423, tt:5642.195\n",
      "Ep:133, loss:0.00000, loss_test:0.07190, lr:5.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.421, tt:5684.458\n",
      "Ep:134, loss:0.00000, loss_test:0.07135, lr:5.64e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.403, tt:5724.344\n",
      "Ep:135, loss:0.00000, loss_test:0.07238, lr:5.58e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.403, tt:5766.761\n",
      "Ep:136, loss:0.00000, loss_test:0.07219, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.396, tt:5808.208\n",
      "Ep:137, loss:0.00000, loss_test:0.07126, lr:5.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.405, tt:5851.951\n",
      "Ep:138, loss:0.00000, loss_test:0.07216, lr:5.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.405, tt:5894.253\n",
      "Ep:139, loss:0.00000, loss_test:0.07249, lr:5.36e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.387, tt:5934.161\n",
      "Ep:140, loss:0.00000, loss_test:0.07157, lr:5.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.390, tt:5977.011\n",
      "Ep:141, loss:0.00000, loss_test:0.07157, lr:5.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.372, tt:6016.822\n",
      "Ep:142, loss:0.00000, loss_test:0.07193, lr:5.20e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.385, tt:6061.056\n",
      "Ep:143, loss:0.00000, loss_test:0.07180, lr:5.15e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.391, tt:6104.258\n",
      "Ep:144, loss:0.00000, loss_test:0.07152, lr:5.10e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.397, tt:6147.626\n",
      "Ep:145, loss:0.00000, loss_test:0.07135, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.398, tt:6190.051\n",
      "Ep:146, loss:0.00000, loss_test:0.07194, lr:5.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.399, tt:6232.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.07146, lr:4.95e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.391, tt:6273.928\n",
      "Ep:148, loss:0.00000, loss_test:0.07170, lr:4.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.391, tt:6316.284\n",
      "Ep:149, loss:0.00000, loss_test:0.07154, lr:4.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.383, tt:6357.398\n",
      "Ep:150, loss:0.00000, loss_test:0.07140, lr:4.80e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.387, tt:6400.427\n",
      "Ep:151, loss:0.00000, loss_test:0.07128, lr:4.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.394, tt:6443.886\n",
      "Ep:152, loss:0.00000, loss_test:0.07154, lr:4.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.383, tt:6484.568\n",
      "Ep:153, loss:0.00000, loss_test:0.07104, lr:4.66e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.373, tt:6525.423\n",
      "Ep:154, loss:0.00000, loss_test:0.07129, lr:4.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.373, tt:6567.856\n",
      "Ep:155, loss:0.00000, loss_test:0.07121, lr:4.57e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.372, tt:6609.983\n",
      "Ep:156, loss:0.00000, loss_test:0.07116, lr:4.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.365, tt:6651.377\n",
      "Ep:157, loss:0.00000, loss_test:0.07137, lr:4.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.359, tt:6692.665\n",
      "Ep:158, loss:0.00000, loss_test:0.07112, lr:4.43e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.360, tt:6735.217\n",
      "Ep:159, loss:0.00000, loss_test:0.07126, lr:4.39e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.356, tt:6777.003\n",
      "Ep:160, loss:0.00000, loss_test:0.07126, lr:4.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.349, tt:6818.230\n",
      "Ep:161, loss:0.00000, loss_test:0.07137, lr:4.30e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.338, tt:6858.781\n",
      "Ep:162, loss:0.00000, loss_test:0.07147, lr:4.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.338, tt:6901.170\n",
      "Ep:163, loss:0.00000, loss_test:0.07109, lr:4.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.346, tt:6944.709\n",
      "Ep:164, loss:0.00000, loss_test:0.07116, lr:4.17e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.337, tt:6985.644\n",
      "Ep:165, loss:0.00000, loss_test:0.07123, lr:4.13e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.332, tt:7027.168\n",
      "Ep:166, loss:0.00000, loss_test:0.07074, lr:4.09e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.336, tt:7070.155\n",
      "Ep:167, loss:0.00000, loss_test:0.07123, lr:4.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.328, tt:7111.082\n",
      "Ep:168, loss:0.00000, loss_test:0.07129, lr:4.01e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.319, tt:7151.833\n",
      "Ep:169, loss:0.00000, loss_test:0.07089, lr:3.97e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.307, tt:7192.132\n",
      "Ep:170, loss:0.00000, loss_test:0.07157, lr:3.93e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.298, tt:7232.999\n",
      "Ep:171, loss:0.00000, loss_test:0.07189, lr:3.89e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.287, tt:7273.363\n",
      "Ep:172, loss:0.00000, loss_test:0.07120, lr:3.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.296, tt:7317.163\n",
      "Ep:173, loss:0.00000, loss_test:0.07097, lr:3.81e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.297, tt:7359.683\n",
      "Ep:174, loss:0.00000, loss_test:0.07121, lr:3.77e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.289, tt:7400.662\n",
      "Ep:175, loss:0.00000, loss_test:0.07080, lr:3.73e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.278, tt:7440.985\n",
      "Ep:176, loss:0.00000, loss_test:0.07088, lr:3.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.271, tt:7481.949\n",
      "Ep:177, loss:0.00000, loss_test:0.07081, lr:3.66e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.268, tt:7523.674\n",
      "Ep:178, loss:0.00000, loss_test:0.07103, lr:3.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.267, tt:7565.792\n",
      "Ep:179, loss:0.00000, loss_test:0.07136, lr:3.59e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.263, tt:7607.301\n",
      "Ep:180, loss:0.00000, loss_test:0.07092, lr:3.55e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.249, tt:7646.983\n",
      "Ep:181, loss:0.00000, loss_test:0.07067, lr:3.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.236, tt:7687.019\n",
      "Ep:182, loss:0.00000, loss_test:0.07149, lr:3.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.232, tt:7728.503\n",
      "Ep:183, loss:0.00000, loss_test:0.07128, lr:3.45e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.231, tt:7770.475\n",
      "Ep:184, loss:0.00000, loss_test:0.07076, lr:3.41e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.223, tt:7811.313\n",
      "Ep:185, loss:0.00000, loss_test:0.07081, lr:3.38e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.209, tt:7850.924\n",
      "Ep:186, loss:0.00000, loss_test:0.07078, lr:3.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.213, tt:7893.759\n",
      "Ep:187, loss:0.00000, loss_test:0.07074, lr:3.31e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.213, tt:7936.092\n",
      "Ep:188, loss:0.00000, loss_test:0.07080, lr:3.28e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.201, tt:7976.000\n",
      "Ep:189, loss:0.00000, loss_test:0.07082, lr:3.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.210, tt:8019.864\n",
      "Ep:190, loss:0.00000, loss_test:0.07065, lr:3.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.211, tt:8062.373\n",
      "Ep:191, loss:0.00000, loss_test:0.07088, lr:3.18e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.207, tt:8103.797\n",
      "Ep:192, loss:0.00000, loss_test:0.07079, lr:3.15e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.219, tt:8148.177\n",
      "Ep:193, loss:0.00000, loss_test:0.07056, lr:3.12e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.215, tt:8189.800\n",
      "Ep:194, loss:0.00000, loss_test:0.07076, lr:3.09e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.217, tt:8232.348\n",
      "Ep:195, loss:0.00000, loss_test:0.07079, lr:3.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.219, tt:8274.996\n",
      "Ep:196, loss:0.00000, loss_test:0.07074, lr:3.02e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.223, tt:8317.903\n",
      "Ep:197, loss:0.00000, loss_test:0.07062, lr:2.99e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.220, tt:8359.642\n",
      "Ep:198, loss:0.00000, loss_test:0.07089, lr:2.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.227, tt:8403.200\n",
      "Ep:199, loss:0.00000, loss_test:0.07062, lr:2.93e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.229, tt:8445.786\n",
      "Ep:200, loss:0.00000, loss_test:0.07083, lr:2.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.207, tt:8483.621\n",
      "Ep:201, loss:0.00000, loss_test:0.07095, lr:2.88e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.172, tt:8518.769\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02086, lr:6.00e-02, fs:0.60967 (r=0.828,p=0.482),  time:25.630, tt:25.630\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02282, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.337, tt:56.674\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02359, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.812, tt:89.436\n",
      "Ep:3, loss:0.00005, loss_test:0.02305, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.052, tt:124.208\n",
      "Ep:4, loss:0.00004, loss_test:0.02162, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.648, tt:158.238\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01999, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:32.372, tt:194.229\n",
      "Ep:6, loss:0.00004, loss_test:0.01911, lr:6.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:32.710, tt:228.973\n",
      "Ep:7, loss:0.00004, loss_test:0.01911, lr:6.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:33.162, tt:265.297\n",
      "Ep:8, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.67532 (r=0.788,p=0.591),  time:33.384, tt:300.456\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01862, lr:6.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:33.572, tt:335.724\n",
      "Ep:10, loss:0.00004, loss_test:0.01843, lr:6.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:33.623, tt:369.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00003, loss_test:0.01828, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:33.735, tt:404.820\n",
      "Ep:12, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:33.866, tt:440.257\n",
      "Ep:13, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:34.120, tt:477.683\n",
      "Ep:14, loss:0.00003, loss_test:0.01749, lr:6.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:34.181, tt:512.715\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:34.271, tt:548.332\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01696, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:34.358, tt:584.083\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:34.327, tt:617.889\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01641, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:34.327, tt:652.218\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:34.370, tt:687.398\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:34.352, tt:721.396\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:34.400, tt:756.796\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:34.463, tt:792.653\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01510, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:34.433, tt:826.392\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01488, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:34.455, tt:861.387\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:34.429, tt:895.142\n",
      "Ep:26, loss:0.00002, loss_test:0.01460, lr:6.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:34.439, tt:929.842\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:34.532, tt:966.903\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01427, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:34.550, tt:1001.944\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01413, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.525, tt:1035.743\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.498, tt:1069.439\n",
      "Ep:31, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:34.501, tt:1104.045\n",
      "Ep:32, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:34.510, tt:1138.816\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.540, tt:1174.360\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:34.577, tt:1210.204\n",
      "Ep:35, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.554, tt:1243.947\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.528, tt:1277.530\n",
      "Ep:37, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.563, tt:1313.401\n",
      "Ep:38, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.572, tt:1348.315\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.572, tt:1382.887\n",
      "Ep:40, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.573, tt:1417.482\n",
      "Ep:41, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.587, tt:1452.670\n",
      "Ep:42, loss:0.00001, loss_test:0.01343, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.585, tt:1487.169\n",
      "Ep:43, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.593, tt:1522.112\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01336, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:34.586, tt:1556.382\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:34.657, tt:1594.222\n",
      "Ep:46, loss:0.00001, loss_test:0.01338, lr:6.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:34.658, tt:1628.929\n",
      "Ep:47, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:34.662, tt:1663.791\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01336, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.683, tt:1699.445\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01337, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.695, tt:1734.738\n",
      "Ep:50, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.690, tt:1769.209\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01346, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.701, tt:1804.436\n",
      "Ep:52, loss:0.00001, loss_test:0.01342, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.667, tt:1837.348\n",
      "Ep:53, loss:0.00001, loss_test:0.01344, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.671, tt:1872.243\n",
      "Ep:54, loss:0.00001, loss_test:0.01355, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.674, tt:1907.075\n",
      "Ep:55, loss:0.00001, loss_test:0.01351, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.693, tt:1942.798\n",
      "Ep:56, loss:0.00001, loss_test:0.01350, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.703, tt:1978.058\n",
      "Ep:57, loss:0.00001, loss_test:0.01357, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.717, tt:2013.573\n",
      "Ep:58, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.726, tt:2048.820\n",
      "Ep:59, loss:0.00001, loss_test:0.01359, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.727, tt:2083.639\n",
      "Ep:60, loss:0.00001, loss_test:0.01365, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.737, tt:2118.981\n",
      "Ep:61, loss:0.00001, loss_test:0.01366, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.755, tt:2154.821\n",
      "Ep:62, loss:0.00001, loss_test:0.01368, lr:5.94e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.764, tt:2190.145\n",
      "Ep:63, loss:0.00001, loss_test:0.01376, lr:5.88e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.739, tt:2223.280\n",
      "Ep:64, loss:0.00001, loss_test:0.01379, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.722, tt:2256.911\n",
      "Ep:65, loss:0.00001, loss_test:0.01380, lr:5.76e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.748, tt:2293.379\n",
      "Ep:66, loss:0.00001, loss_test:0.01385, lr:5.71e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.737, tt:2327.374\n",
      "Ep:67, loss:0.00001, loss_test:0.01391, lr:5.65e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.722, tt:2361.107\n",
      "Ep:68, loss:0.00001, loss_test:0.01399, lr:5.59e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.717, tt:2395.462\n",
      "Ep:69, loss:0.00001, loss_test:0.01404, lr:5.54e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.718, tt:2430.285\n",
      "Ep:70, loss:0.00001, loss_test:0.01404, lr:5.48e-02, fs:0.82412 (r=0.828,p=0.820),  time:34.722, tt:2465.240\n",
      "Ep:71, loss:0.00001, loss_test:0.01404, lr:5.43e-02, fs:0.81818 (r=0.818,p=0.818),  time:34.715, tt:2499.506\n",
      "Ep:72, loss:0.00001, loss_test:0.01411, lr:5.37e-02, fs:0.81818 (r=0.818,p=0.818),  time:34.698, tt:2532.984\n",
      "Ep:73, loss:0.00001, loss_test:0.01416, lr:5.32e-02, fs:0.81818 (r=0.818,p=0.818),  time:34.655, tt:2564.463\n",
      "Ep:74, loss:0.00001, loss_test:0.01422, lr:5.27e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.641, tt:2598.059\n",
      "Ep:75, loss:0.00001, loss_test:0.01423, lr:5.21e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.631, tt:2631.938\n",
      "Ep:76, loss:0.00001, loss_test:0.01423, lr:5.16e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.649, tt:2667.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00001, loss_test:0.01423, lr:5.11e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.644, tt:2702.207\n",
      "Ep:78, loss:0.00001, loss_test:0.01433, lr:5.06e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.648, tt:2737.231\n",
      "Ep:79, loss:0.00001, loss_test:0.01432, lr:5.01e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.650, tt:2771.978\n",
      "Ep:80, loss:0.00001, loss_test:0.01441, lr:4.96e-02, fs:0.80612 (r=0.798,p=0.814),  time:34.653, tt:2806.913\n",
      "Ep:81, loss:0.00001, loss_test:0.01446, lr:4.91e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.654, tt:2841.652\n",
      "Ep:82, loss:0.00001, loss_test:0.01443, lr:4.86e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.656, tt:2876.458\n",
      "Ep:83, loss:0.00001, loss_test:0.01450, lr:4.81e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.642, tt:2909.906\n",
      "Ep:84, loss:0.00001, loss_test:0.01454, lr:4.76e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.637, tt:2944.110\n",
      "Ep:85, loss:0.00001, loss_test:0.01463, lr:4.71e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.621, tt:2977.441\n",
      "Ep:86, loss:0.00001, loss_test:0.01462, lr:4.67e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.623, tt:3012.239\n",
      "Ep:87, loss:0.00001, loss_test:0.01462, lr:4.62e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.612, tt:3045.866\n",
      "Ep:88, loss:0.00001, loss_test:0.01463, lr:4.57e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.611, tt:3080.379\n",
      "Ep:89, loss:0.00001, loss_test:0.01468, lr:4.53e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.610, tt:3114.942\n",
      "Ep:90, loss:0.00001, loss_test:0.01472, lr:4.48e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.620, tt:3150.458\n",
      "Ep:91, loss:0.00001, loss_test:0.01475, lr:4.44e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.615, tt:3184.617\n",
      "Ep:92, loss:0.00000, loss_test:0.01476, lr:4.39e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.604, tt:3218.140\n",
      "Ep:93, loss:0.00000, loss_test:0.01484, lr:4.35e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.590, tt:3251.488\n",
      "Ep:94, loss:0.00000, loss_test:0.01490, lr:4.31e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.594, tt:3286.398\n",
      "Ep:95, loss:0.00000, loss_test:0.01496, lr:4.26e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.598, tt:3321.413\n",
      "Ep:96, loss:0.00000, loss_test:0.01493, lr:4.22e-02, fs:0.80214 (r=0.758,p=0.852),  time:34.598, tt:3356.040\n",
      "Ep:97, loss:0.00000, loss_test:0.01497, lr:4.18e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.599, tt:3390.716\n",
      "Ep:98, loss:0.00000, loss_test:0.01503, lr:4.14e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.607, tt:3426.140\n",
      "Ep:99, loss:0.00000, loss_test:0.01507, lr:4.10e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.613, tt:3461.304\n",
      "Ep:100, loss:0.00000, loss_test:0.01509, lr:4.05e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.624, tt:3497.015\n",
      "Ep:101, loss:0.00000, loss_test:0.01517, lr:4.01e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.642, tt:3533.434\n",
      "Ep:102, loss:0.00000, loss_test:0.01521, lr:3.97e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.647, tt:3568.610\n",
      "Ep:103, loss:0.00000, loss_test:0.01516, lr:3.93e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.657, tt:3604.305\n",
      "Ep:104, loss:0.00000, loss_test:0.01524, lr:3.89e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.698, tt:3643.305\n",
      "Ep:105, loss:0.00000, loss_test:0.01531, lr:3.86e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.698, tt:3677.941\n",
      "Ep:106, loss:0.00000, loss_test:0.01535, lr:3.82e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.716, tt:3714.651\n",
      "Ep:107, loss:0.00000, loss_test:0.01539, lr:3.78e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.719, tt:3749.629\n",
      "Ep:108, loss:0.00000, loss_test:0.01541, lr:3.74e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.738, tt:3786.489\n",
      "Ep:109, loss:0.00000, loss_test:0.01540, lr:3.70e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.737, tt:3821.090\n",
      "Ep:110, loss:0.00000, loss_test:0.01545, lr:3.67e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.753, tt:3857.585\n",
      "Ep:111, loss:0.00000, loss_test:0.01546, lr:3.63e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.748, tt:3891.796\n",
      "Ep:112, loss:0.00000, loss_test:0.01549, lr:3.59e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.728, tt:3924.220\n",
      "Ep:113, loss:0.00000, loss_test:0.01560, lr:3.56e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.738, tt:3960.179\n",
      "Ep:114, loss:0.00000, loss_test:0.01563, lr:3.52e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.735, tt:3994.522\n",
      "Ep:115, loss:0.00000, loss_test:0.01564, lr:3.49e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.742, tt:4030.061\n",
      "Ep:116, loss:0.00000, loss_test:0.01569, lr:3.45e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.756, tt:4066.424\n",
      "Ep:117, loss:0.00000, loss_test:0.01573, lr:3.42e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.763, tt:4102.034\n",
      "Ep:118, loss:0.00000, loss_test:0.01571, lr:3.38e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.767, tt:4137.270\n",
      "Ep:119, loss:0.00000, loss_test:0.01577, lr:3.35e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.777, tt:4173.294\n",
      "Ep:120, loss:0.00000, loss_test:0.01580, lr:3.32e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.777, tt:4208.049\n",
      "Ep:121, loss:0.00000, loss_test:0.01582, lr:3.28e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.781, tt:4243.224\n",
      "Ep:122, loss:0.00000, loss_test:0.01586, lr:3.25e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.778, tt:4277.663\n",
      "Ep:123, loss:0.00000, loss_test:0.01584, lr:3.22e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.774, tt:4311.961\n",
      "Ep:124, loss:0.00000, loss_test:0.01593, lr:3.19e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.777, tt:4347.164\n",
      "Ep:125, loss:0.00000, loss_test:0.01597, lr:3.15e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.775, tt:4381.617\n",
      "Ep:126, loss:0.00000, loss_test:0.01600, lr:3.12e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.780, tt:4417.076\n",
      "Ep:127, loss:0.00000, loss_test:0.01599, lr:3.09e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.777, tt:4451.423\n",
      "Ep:128, loss:0.00000, loss_test:0.01604, lr:3.06e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.776, tt:4486.146\n",
      "Ep:129, loss:0.00000, loss_test:0.01610, lr:3.03e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.779, tt:4521.242\n",
      "Ep:130, loss:0.00000, loss_test:0.01610, lr:3.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.780, tt:4556.120\n",
      "Ep:131, loss:0.00000, loss_test:0.01612, lr:2.97e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.771, tt:4589.739\n",
      "Ep:132, loss:0.00000, loss_test:0.01621, lr:2.94e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.775, tt:4625.050\n",
      "Ep:133, loss:0.00000, loss_test:0.01625, lr:2.91e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.773, tt:4659.559\n",
      "Ep:134, loss:0.00000, loss_test:0.01619, lr:2.88e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.784, tt:4695.775\n",
      "Ep:135, loss:0.00000, loss_test:0.01623, lr:2.85e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.780, tt:4730.042\n",
      "Ep:136, loss:0.00000, loss_test:0.01629, lr:2.82e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.779, tt:4764.699\n",
      "Ep:137, loss:0.00000, loss_test:0.01633, lr:2.80e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.779, tt:4799.569\n",
      "Ep:138, loss:0.00000, loss_test:0.01636, lr:2.77e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.783, tt:4834.820\n",
      "Ep:139, loss:0.00000, loss_test:0.01636, lr:2.74e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.776, tt:4868.618\n",
      "Ep:140, loss:0.00000, loss_test:0.01641, lr:2.71e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.777, tt:4903.540\n",
      "Ep:141, loss:0.00000, loss_test:0.01645, lr:2.69e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.772, tt:4937.647\n",
      "Ep:142, loss:0.00000, loss_test:0.01647, lr:2.66e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.770, tt:4972.158\n",
      "Ep:143, loss:0.00000, loss_test:0.01649, lr:2.63e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.779, tt:5008.136\n",
      "Ep:144, loss:0.00000, loss_test:0.01652, lr:2.61e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.790, tt:5044.524\n",
      "Ep:145, loss:0.00000, loss_test:0.01655, lr:2.58e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.790, tt:5079.283\n",
      "Ep:146, loss:0.00000, loss_test:0.01654, lr:2.55e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.782, tt:5112.919\n",
      "Ep:147, loss:0.00000, loss_test:0.01659, lr:2.53e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.795, tt:5149.602\n",
      "Ep:148, loss:0.00000, loss_test:0.01659, lr:2.50e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.792, tt:5184.073\n",
      "Ep:149, loss:0.00000, loss_test:0.01661, lr:2.48e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.794, tt:5219.071\n",
      "Ep:150, loss:0.00000, loss_test:0.01666, lr:2.45e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.793, tt:5253.753\n",
      "Ep:151, loss:0.00000, loss_test:0.01669, lr:2.43e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.793, tt:5288.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.01671, lr:2.40e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.797, tt:5323.874\n",
      "Ep:153, loss:0.00000, loss_test:0.01672, lr:2.38e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.780, tt:5356.057\n",
      "Ep:154, loss:0.00000, loss_test:0.01674, lr:2.36e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.763, tt:5388.272\n",
      "Ep:155, loss:0.00000, loss_test:0.01679, lr:2.33e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.751, tt:5421.159\n",
      "Ep:156, loss:0.00000, loss_test:0.01677, lr:2.31e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.751, tt:5455.895\n",
      "Ep:157, loss:0.00000, loss_test:0.01680, lr:2.29e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.747, tt:5489.966\n",
      "Ep:158, loss:0.00000, loss_test:0.01680, lr:2.26e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.764, tt:5527.452\n",
      "Ep:159, loss:0.00000, loss_test:0.01684, lr:2.24e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.752, tt:5560.328\n",
      "Ep:160, loss:0.00000, loss_test:0.01688, lr:2.22e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.758, tt:5596.059\n",
      "Ep:161, loss:0.00000, loss_test:0.01690, lr:2.20e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.756, tt:5630.434\n",
      "Ep:162, loss:0.00000, loss_test:0.01691, lr:2.17e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.760, tt:5665.824\n",
      "Ep:163, loss:0.00000, loss_test:0.01692, lr:2.15e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.760, tt:5700.691\n",
      "Ep:164, loss:0.00000, loss_test:0.01697, lr:2.13e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.762, tt:5735.781\n",
      "Ep:165, loss:0.00000, loss_test:0.01698, lr:2.11e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.760, tt:5770.111\n",
      "Ep:166, loss:0.00000, loss_test:0.01701, lr:2.09e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.758, tt:5804.606\n",
      "Ep:167, loss:0.00000, loss_test:0.01701, lr:2.07e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.756, tt:5839.042\n",
      "Ep:168, loss:0.00000, loss_test:0.01703, lr:2.05e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.751, tt:5872.936\n",
      "Ep:169, loss:0.00000, loss_test:0.01706, lr:2.03e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.748, tt:5907.164\n",
      "Ep:170, loss:0.00000, loss_test:0.01707, lr:2.01e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.745, tt:5941.403\n",
      "Ep:171, loss:0.00000, loss_test:0.01710, lr:1.99e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.740, tt:5975.198\n",
      "Ep:172, loss:0.00000, loss_test:0.01714, lr:1.97e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.741, tt:6010.184\n",
      "Ep:173, loss:0.00000, loss_test:0.01713, lr:1.95e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.740, tt:6044.827\n",
      "Ep:174, loss:0.00000, loss_test:0.01713, lr:1.93e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.735, tt:6078.542\n",
      "Ep:175, loss:0.00000, loss_test:0.01718, lr:1.91e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.730, tt:6112.520\n",
      "Ep:176, loss:0.00000, loss_test:0.01720, lr:1.89e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.728, tt:6146.851\n",
      "Ep:177, loss:0.00000, loss_test:0.01720, lr:1.87e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.719, tt:6179.985\n",
      "Ep:178, loss:0.00000, loss_test:0.01720, lr:1.85e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.733, tt:6217.293\n",
      "Ep:179, loss:0.00000, loss_test:0.01722, lr:1.83e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.728, tt:6250.960\n",
      "Ep:180, loss:0.00000, loss_test:0.01725, lr:1.81e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.722, tt:6284.633\n",
      "Ep:181, loss:0.00000, loss_test:0.01729, lr:1.80e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.716, tt:6318.280\n",
      "Ep:182, loss:0.00000, loss_test:0.01730, lr:1.78e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.707, tt:6351.447\n",
      "Ep:183, loss:0.00000, loss_test:0.01731, lr:1.76e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.703, tt:6385.442\n",
      "Ep:184, loss:0.00000, loss_test:0.01733, lr:1.74e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.696, tt:6418.841\n",
      "Ep:185, loss:0.00000, loss_test:0.01734, lr:1.73e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.694, tt:6453.172\n",
      "Ep:186, loss:0.00000, loss_test:0.01735, lr:1.71e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.695, tt:6487.987\n",
      "Ep:187, loss:0.00000, loss_test:0.01737, lr:1.69e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.700, tt:6523.695\n",
      "Ep:188, loss:0.00000, loss_test:0.01739, lr:1.67e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.701, tt:6558.473\n",
      "Ep:189, loss:0.00000, loss_test:0.01740, lr:1.66e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.700, tt:6593.029\n",
      "Ep:190, loss:0.00000, loss_test:0.01741, lr:1.64e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.696, tt:6626.851\n",
      "Ep:191, loss:0.00000, loss_test:0.01741, lr:1.62e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.698, tt:6662.093\n",
      "Ep:192, loss:0.00000, loss_test:0.01743, lr:1.61e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.701, tt:6697.200\n",
      "Ep:193, loss:0.00000, loss_test:0.01745, lr:1.59e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.704, tt:6732.526\n",
      "Ep:194, loss:0.00000, loss_test:0.01745, lr:1.58e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.701, tt:6766.685\n",
      "Ep:195, loss:0.00000, loss_test:0.01748, lr:1.56e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.698, tt:6800.807\n",
      "Ep:196, loss:0.00000, loss_test:0.01747, lr:1.54e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.695, tt:6834.905\n",
      "Ep:197, loss:0.00000, loss_test:0.01749, lr:1.53e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.674, tt:6865.444\n",
      "Ep:198, loss:0.00000, loss_test:0.01751, lr:1.51e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.665, tt:6898.429\n",
      "Ep:199, loss:0.00000, loss_test:0.01753, lr:1.50e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.652, tt:6930.481\n",
      "Ep:200, loss:0.00000, loss_test:0.01755, lr:1.48e-02, fs:0.78613 (r=0.687,p=0.919),  time:34.633, tt:6961.200\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14499, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.464, tt:31.464\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14397, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.766, tt:63.533\n",
      "Ep:2, loss:0.00028, loss_test:0.14225, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.540, tt:97.619\n",
      "Ep:3, loss:0.00028, loss_test:0.13950, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.210, tt:132.839\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13498, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:33.620, tt:168.100\n",
      "Ep:5, loss:0.00026, loss_test:0.12745, lr:1.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:33.918, tt:203.507\n",
      "Ep:6, loss:0.00024, loss_test:0.11698, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:34.268, tt:239.878\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11467, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:34.469, tt:275.754\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11404, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:34.503, tt:310.530\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11526, lr:1.00e-02, fs:0.66368 (r=0.747,p=0.597),  time:34.586, tt:345.863\n",
      "Ep:10, loss:0.00022, loss_test:0.11337, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:34.586, tt:380.447\n",
      "Ep:11, loss:0.00021, loss_test:0.10898, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:34.693, tt:416.319\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10821, lr:1.00e-02, fs:0.69307 (r=0.707,p=0.680),  time:34.739, tt:451.611\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10551, lr:1.00e-02, fs:0.69268 (r=0.717,p=0.670),  time:34.941, tt:489.177\n",
      "Ep:14, loss:0.00019, loss_test:0.10330, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:34.948, tt:524.224\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09918, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:35.003, tt:560.053\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09744, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:34.981, tt:594.675\n",
      "Ep:17, loss:0.00017, loss_test:0.09636, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:35.032, tt:630.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00017, loss_test:0.09453, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:35.011, tt:665.212\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09298, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:34.964, tt:699.287\n",
      "Ep:20, loss:0.00015, loss_test:0.09196, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:34.930, tt:733.521\n",
      "Ep:21, loss:0.00015, loss_test:0.09147, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:34.884, tt:767.444\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08936, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.933, tt:803.459\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.08861, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.906, tt:837.740\n",
      "Ep:24, loss:0.00013, loss_test:0.08633, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:34.884, tt:872.098\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08792, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:34.889, tt:907.114\n",
      "Ep:26, loss:0.00012, loss_test:0.08475, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.832, tt:940.457\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.08763, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:34.819, tt:974.934\n",
      "Ep:28, loss:0.00011, loss_test:0.08330, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.790, tt:1008.921\n",
      "Ep:29, loss:0.00010, loss_test:0.08529, lr:1.00e-02, fs:0.76301 (r=0.667,p=0.892),  time:34.757, tt:1042.696\n",
      "Ep:30, loss:0.00010, loss_test:0.08231, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.763, tt:1077.667\n",
      "Ep:31, loss:0.00009, loss_test:0.08364, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.742, tt:1111.758\n",
      "Ep:32, loss:0.00009, loss_test:0.08083, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.707, tt:1145.333\n",
      "Ep:33, loss:0.00008, loss_test:0.08137, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.718, tt:1180.425\n",
      "Ep:34, loss:0.00008, loss_test:0.08045, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.709, tt:1214.800\n",
      "Ep:35, loss:0.00008, loss_test:0.07946, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.685, tt:1248.669\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.07658, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.754, tt:1285.905\n",
      "Ep:37, loss:0.00007, loss_test:0.07877, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.731, tt:1319.763\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.07760, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.791, tt:1356.858\n",
      "Ep:39, loss:0.00006, loss_test:0.07652, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.791, tt:1391.629\n",
      "Ep:40, loss:0.00006, loss_test:0.07607, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.787, tt:1426.279\n",
      "Ep:41, loss:0.00006, loss_test:0.07776, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.816, tt:1462.278\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.07314, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.853, tt:1498.661\n",
      "Ep:43, loss:0.00005, loss_test:0.07502, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.892, tt:1535.258\n",
      "Ep:44, loss:0.00005, loss_test:0.07259, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:34.899, tt:1570.434\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.07369, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.936, tt:1607.062\n",
      "Ep:46, loss:0.00005, loss_test:0.07180, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:34.897, tt:1640.149\n",
      "Ep:47, loss:0.00005, loss_test:0.07219, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.916, tt:1675.951\n",
      "Ep:48, loss:0.00004, loss_test:0.07302, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:35.132, tt:1721.462\n",
      "Ep:49, loss:0.00004, loss_test:0.07345, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.126, tt:1756.288\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07118, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.125, tt:1791.358\n",
      "Ep:51, loss:0.00004, loss_test:0.07314, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:35.107, tt:1825.581\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.07080, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.101, tt:1860.351\n",
      "Ep:53, loss:0.00004, loss_test:0.07426, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:35.057, tt:1893.069\n",
      "Ep:54, loss:0.00003, loss_test:0.07348, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:35.143, tt:1932.884\n",
      "Ep:55, loss:0.00003, loss_test:0.07119, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:35.117, tt:1966.543\n",
      "Ep:56, loss:0.00003, loss_test:0.07470, lr:1.00e-02, fs:0.80952 (r=0.687,p=0.986),  time:35.131, tt:2002.465\n",
      "Ep:57, loss:0.00003, loss_test:0.07064, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:35.100, tt:2035.818\n",
      "Ep:58, loss:0.00003, loss_test:0.07342, lr:1.00e-02, fs:0.81395 (r=0.707,p=0.959),  time:35.050, tt:2067.949\n",
      "Ep:59, loss:0.00003, loss_test:0.07474, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:35.038, tt:2102.300\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.07190, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:35.019, tt:2136.158\n",
      "Ep:61, loss:0.00003, loss_test:0.07617, lr:1.00e-02, fs:0.79518 (r=0.667,p=0.985),  time:35.007, tt:2170.437\n",
      "Ep:62, loss:0.00003, loss_test:0.07092, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.949, tt:2201.775\n",
      "Ep:63, loss:0.00003, loss_test:0.07937, lr:1.00e-02, fs:0.78788 (r=0.657,p=0.985),  time:34.936, tt:2235.919\n",
      "Ep:64, loss:0.00002, loss_test:0.07030, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.900, tt:2268.500\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.08080, lr:1.00e-02, fs:0.80240 (r=0.677,p=0.985),  time:34.885, tt:2302.402\n",
      "Ep:66, loss:0.00002, loss_test:0.07259, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.866, tt:2336.002\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.07782, lr:1.00e-02, fs:0.79518 (r=0.667,p=0.985),  time:34.869, tt:2371.097\n",
      "Ep:68, loss:0.00002, loss_test:0.07519, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.862, tt:2405.445\n",
      "Ep:69, loss:0.00002, loss_test:0.07571, lr:1.00e-02, fs:0.80473 (r=0.687,p=0.971),  time:34.828, tt:2437.988\n",
      "Ep:70, loss:0.00002, loss_test:0.07539, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.822, tt:2472.396\n",
      "Ep:71, loss:0.00002, loss_test:0.08014, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:34.817, tt:2506.825\n",
      "Ep:72, loss:0.00002, loss_test:0.07286, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:34.797, tt:2540.204\n",
      "Ep:73, loss:0.00002, loss_test:0.07901, lr:1.00e-02, fs:0.79290 (r=0.677,p=0.957),  time:34.771, tt:2573.072\n",
      "Ep:74, loss:0.00002, loss_test:0.07727, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.760, tt:2606.983\n",
      "Ep:75, loss:0.00002, loss_test:0.07535, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.740, tt:2640.275\n",
      "Ep:76, loss:0.00002, loss_test:0.07788, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:34.757, tt:2676.305\n",
      "Ep:77, loss:0.00002, loss_test:0.07444, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:34.767, tt:2711.845\n",
      "Ep:78, loss:0.00001, loss_test:0.07973, lr:9.90e-03, fs:0.77844 (r=0.657,p=0.956),  time:34.763, tt:2746.244\n",
      "Ep:79, loss:0.00001, loss_test:0.07643, lr:9.80e-03, fs:0.81609 (r=0.717,p=0.947),  time:34.759, tt:2780.708\n",
      "Ep:80, loss:0.00001, loss_test:0.07993, lr:9.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.735, tt:2813.502\n",
      "Ep:81, loss:0.00001, loss_test:0.07877, lr:9.61e-03, fs:0.77844 (r=0.657,p=0.956),  time:34.743, tt:2848.897\n",
      "Ep:82, loss:0.00001, loss_test:0.07748, lr:9.51e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.739, tt:2883.296\n",
      "Ep:83, loss:0.00001, loss_test:0.07901, lr:9.41e-03, fs:0.77844 (r=0.657,p=0.956),  time:34.711, tt:2915.700\n",
      "Ep:84, loss:0.00001, loss_test:0.07866, lr:9.32e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.699, tt:2949.391\n",
      "Ep:85, loss:0.00001, loss_test:0.07745, lr:9.23e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.694, tt:2983.707\n",
      "Ep:86, loss:0.00001, loss_test:0.07924, lr:9.14e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.698, tt:3018.702\n",
      "Ep:87, loss:0.00001, loss_test:0.07893, lr:9.04e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.701, tt:3053.650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00001, loss_test:0.07863, lr:8.95e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.707, tt:3088.934\n",
      "Ep:89, loss:0.00001, loss_test:0.08094, lr:8.86e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.712, tt:3124.065\n",
      "Ep:90, loss:0.00001, loss_test:0.07672, lr:8.78e-03, fs:0.76190 (r=0.646,p=0.928),  time:34.702, tt:3157.848\n",
      "Ep:91, loss:0.00001, loss_test:0.08191, lr:8.69e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.719, tt:3194.188\n",
      "Ep:92, loss:0.00001, loss_test:0.07773, lr:8.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.729, tt:3229.827\n",
      "Ep:93, loss:0.00001, loss_test:0.08126, lr:8.51e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.731, tt:3264.722\n",
      "Ep:94, loss:0.00001, loss_test:0.08048, lr:8.43e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.727, tt:3299.097\n",
      "Ep:95, loss:0.00001, loss_test:0.08016, lr:8.35e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.723, tt:3333.435\n",
      "Ep:96, loss:0.00001, loss_test:0.07960, lr:8.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.726, tt:3368.435\n",
      "Ep:97, loss:0.00001, loss_test:0.08136, lr:8.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.732, tt:3403.695\n",
      "Ep:98, loss:0.00001, loss_test:0.07987, lr:8.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.736, tt:3438.842\n",
      "Ep:99, loss:0.00001, loss_test:0.08141, lr:8.02e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.736, tt:3473.561\n",
      "Ep:100, loss:0.00001, loss_test:0.07994, lr:7.94e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.755, tt:3510.256\n",
      "Ep:101, loss:0.00001, loss_test:0.08005, lr:7.86e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.766, tt:3546.099\n",
      "Ep:102, loss:0.00001, loss_test:0.08049, lr:7.78e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.771, tt:3581.457\n",
      "Ep:103, loss:0.00001, loss_test:0.08040, lr:7.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.770, tt:3616.108\n",
      "Ep:104, loss:0.00001, loss_test:0.08167, lr:7.62e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.768, tt:3650.639\n",
      "Ep:105, loss:0.00001, loss_test:0.08165, lr:7.55e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.765, tt:3685.122\n",
      "Ep:106, loss:0.00001, loss_test:0.08044, lr:7.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.764, tt:3719.743\n",
      "Ep:107, loss:0.00001, loss_test:0.08013, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.768, tt:3754.978\n",
      "Ep:108, loss:0.00001, loss_test:0.08339, lr:7.32e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.763, tt:3789.188\n",
      "Ep:109, loss:0.00001, loss_test:0.08182, lr:7.25e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.771, tt:3824.799\n",
      "Ep:110, loss:0.00001, loss_test:0.08052, lr:7.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.763, tt:3858.678\n",
      "Ep:111, loss:0.00001, loss_test:0.08311, lr:7.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.777, tt:3894.991\n",
      "Ep:112, loss:0.00001, loss_test:0.07993, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.783, tt:3930.456\n",
      "Ep:113, loss:0.00001, loss_test:0.08439, lr:6.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.772, tt:3963.955\n",
      "Ep:114, loss:0.00001, loss_test:0.08107, lr:6.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:34.777, tt:3999.318\n",
      "Ep:115, loss:0.00001, loss_test:0.08310, lr:6.83e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.777, tt:4034.180\n",
      "Ep:116, loss:0.00001, loss_test:0.08284, lr:6.76e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.763, tt:4067.252\n",
      "Ep:117, loss:0.00001, loss_test:0.08216, lr:6.69e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.748, tt:4100.205\n",
      "Ep:118, loss:0.00001, loss_test:0.08342, lr:6.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.723, tt:4132.033\n",
      "Ep:119, loss:0.00001, loss_test:0.08119, lr:6.56e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.690, tt:4162.853\n",
      "Ep:120, loss:0.00001, loss_test:0.08399, lr:6.49e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.665, tt:4194.435\n",
      "Ep:121, loss:0.00001, loss_test:0.08135, lr:6.43e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.631, tt:4224.994\n",
      "Ep:122, loss:0.00001, loss_test:0.08257, lr:6.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.612, tt:4257.218\n",
      "Ep:123, loss:0.00000, loss_test:0.08349, lr:6.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.596, tt:4289.937\n",
      "Ep:124, loss:0.00000, loss_test:0.08250, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.566, tt:4320.768\n",
      "Ep:125, loss:0.00000, loss_test:0.08309, lr:6.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.536, tt:4351.535\n",
      "Ep:126, loss:0.00000, loss_test:0.08130, lr:6.11e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.518, tt:4383.790\n",
      "Ep:127, loss:0.00000, loss_test:0.08329, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.498, tt:4415.800\n",
      "Ep:128, loss:0.00000, loss_test:0.08242, lr:5.99e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.486, tt:4448.719\n",
      "Ep:129, loss:0.00000, loss_test:0.08386, lr:5.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.454, tt:4478.997\n",
      "Ep:130, loss:0.00000, loss_test:0.08270, lr:5.87e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.437, tt:4511.239\n",
      "Ep:131, loss:0.00000, loss_test:0.08162, lr:5.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.430, tt:4544.746\n",
      "Ep:132, loss:0.00000, loss_test:0.08384, lr:5.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.425, tt:4578.505\n",
      "Ep:133, loss:0.00000, loss_test:0.08321, lr:5.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.410, tt:4610.960\n",
      "Ep:134, loss:0.00000, loss_test:0.08344, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.386, tt:4642.137\n",
      "Ep:135, loss:0.00000, loss_test:0.08294, lr:5.58e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.362, tt:4673.208\n",
      "Ep:136, loss:0.00000, loss_test:0.08349, lr:5.53e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.352, tt:4706.199\n",
      "Ep:137, loss:0.00000, loss_test:0.08262, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.333, tt:4737.926\n",
      "Ep:138, loss:0.00000, loss_test:0.08384, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.305, tt:4768.414\n",
      "Ep:139, loss:0.00000, loss_test:0.08381, lr:5.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.299, tt:4801.844\n",
      "Ep:140, loss:0.00000, loss_test:0.08387, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.281, tt:4833.688\n",
      "Ep:141, loss:0.00000, loss_test:0.08367, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.261, tt:4865.092\n",
      "Ep:142, loss:0.00000, loss_test:0.08334, lr:5.20e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.245, tt:4896.980\n",
      "Ep:143, loss:0.00000, loss_test:0.08379, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.233, tt:4929.597\n",
      "Ep:144, loss:0.00000, loss_test:0.08364, lr:5.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.219, tt:4961.692\n",
      "Ep:145, loss:0.00000, loss_test:0.08317, lr:5.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.207, tt:4994.234\n",
      "Ep:146, loss:0.00000, loss_test:0.08411, lr:5.00e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.188, tt:5025.613\n",
      "Ep:147, loss:0.00000, loss_test:0.08360, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.178, tt:5058.278\n",
      "Ep:148, loss:0.00000, loss_test:0.08332, lr:4.90e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.153, tt:5088.867\n",
      "Ep:149, loss:0.00000, loss_test:0.08326, lr:4.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.124, tt:5118.658\n",
      "Ep:150, loss:0.00000, loss_test:0.08390, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.104, tt:5149.694\n",
      "Ep:151, loss:0.00000, loss_test:0.08414, lr:4.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.082, tt:5180.536\n",
      "Ep:152, loss:0.00000, loss_test:0.08329, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:34.058, tt:5210.800\n",
      "Ep:153, loss:0.00000, loss_test:0.08311, lr:4.66e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.036, tt:5241.560\n",
      "Ep:154, loss:0.00000, loss_test:0.08343, lr:4.61e-03, fs:0.77108 (r=0.646,p=0.955),  time:34.010, tt:5271.543\n",
      "Ep:155, loss:0.00000, loss_test:0.08426, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.989, tt:5302.281\n",
      "Ep:156, loss:0.00000, loss_test:0.08327, lr:4.52e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.960, tt:5331.776\n",
      "Ep:157, loss:0.00000, loss_test:0.08381, lr:4.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.943, tt:5362.927\n",
      "Ep:158, loss:0.00000, loss_test:0.08438, lr:4.43e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.929, tt:5394.722\n",
      "Ep:159, loss:0.00000, loss_test:0.08377, lr:4.39e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.906, tt:5425.001\n",
      "Ep:160, loss:0.00000, loss_test:0.08294, lr:4.34e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.875, tt:5453.827\n",
      "Ep:161, loss:0.00000, loss_test:0.08466, lr:4.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.856, tt:5484.598\n",
      "Ep:162, loss:0.00000, loss_test:0.08411, lr:4.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.842, tt:5516.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.08415, lr:4.21e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.826, tt:5547.395\n",
      "Ep:164, loss:0.00000, loss_test:0.08490, lr:4.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.805, tt:5577.850\n",
      "Ep:165, loss:0.00000, loss_test:0.08391, lr:4.13e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.791, tt:5609.249\n",
      "Ep:166, loss:0.00000, loss_test:0.08473, lr:4.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.757, tt:5637.367\n",
      "Ep:167, loss:0.00000, loss_test:0.08567, lr:4.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.732, tt:5666.958\n",
      "Ep:168, loss:0.00000, loss_test:0.08474, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.709, tt:5696.750\n",
      "Ep:169, loss:0.00000, loss_test:0.08371, lr:3.97e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.681, tt:5725.707\n",
      "Ep:170, loss:0.00000, loss_test:0.08514, lr:3.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.666, tt:5756.895\n",
      "Ep:171, loss:0.00000, loss_test:0.08515, lr:3.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.654, tt:5788.546\n",
      "Ep:172, loss:0.00000, loss_test:0.08447, lr:3.85e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.635, tt:5818.817\n",
      "Ep:173, loss:0.00000, loss_test:0.08410, lr:3.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.614, tt:5848.892\n",
      "Ep:174, loss:0.00000, loss_test:0.08407, lr:3.77e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.593, tt:5878.835\n",
      "Ep:175, loss:0.00000, loss_test:0.08483, lr:3.73e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.574, tt:5909.055\n",
      "Ep:176, loss:0.00000, loss_test:0.08470, lr:3.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.544, tt:5937.346\n",
      "Ep:177, loss:0.00000, loss_test:0.08386, lr:3.66e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.514, tt:5965.470\n",
      "Ep:178, loss:0.00000, loss_test:0.08450, lr:3.62e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.494, tt:5995.466\n",
      "Ep:179, loss:0.00000, loss_test:0.08493, lr:3.59e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.471, tt:6024.704\n",
      "Ep:180, loss:0.00000, loss_test:0.08444, lr:3.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.459, tt:6056.015\n",
      "Ep:181, loss:0.00000, loss_test:0.08445, lr:3.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.449, tt:6087.693\n",
      "Ep:182, loss:0.00000, loss_test:0.08473, lr:3.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.429, tt:6117.546\n",
      "Ep:183, loss:0.00000, loss_test:0.08427, lr:3.45e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.415, tt:6148.389\n",
      "Ep:184, loss:0.00000, loss_test:0.08455, lr:3.41e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.396, tt:6178.236\n",
      "Ep:185, loss:0.00000, loss_test:0.08479, lr:3.38e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.387, tt:6209.935\n",
      "Ep:186, loss:0.00000, loss_test:0.08472, lr:3.34e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.368, tt:6239.761\n",
      "Ep:187, loss:0.00000, loss_test:0.08428, lr:3.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.340, tt:6267.910\n",
      "Ep:188, loss:0.00000, loss_test:0.08428, lr:3.28e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.320, tt:6297.492\n",
      "Ep:189, loss:0.00000, loss_test:0.08453, lr:3.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.303, tt:6327.650\n",
      "Ep:190, loss:0.00000, loss_test:0.08429, lr:3.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.295, tt:6359.414\n",
      "Ep:191, loss:0.00000, loss_test:0.08459, lr:3.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.280, tt:6389.829\n",
      "Ep:192, loss:0.00000, loss_test:0.08518, lr:3.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.276, tt:6422.316\n",
      "Ep:193, loss:0.00000, loss_test:0.08433, lr:3.12e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.251, tt:6450.719\n",
      "Ep:194, loss:0.00000, loss_test:0.08404, lr:3.09e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.243, tt:6482.319\n",
      "Ep:195, loss:0.00000, loss_test:0.08469, lr:3.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.232, tt:6513.518\n",
      "Ep:196, loss:0.00000, loss_test:0.08508, lr:3.02e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.207, tt:6541.728\n",
      "Ep:197, loss:0.00000, loss_test:0.08488, lr:2.99e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.161, tt:6565.888\n",
      "Ep:198, loss:0.00000, loss_test:0.08442, lr:2.96e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.123, tt:6591.564\n",
      "Ep:199, loss:0.00000, loss_test:0.08464, lr:2.93e-03, fs:0.77576 (r=0.646,p=0.970),  time:33.074, tt:6614.760\n",
      "Ep:200, loss:0.00000, loss_test:0.08488, lr:2.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:33.003, tt:6633.669\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02209, lr:6.00e-02, fs:0.61925 (r=0.851,p=0.487),  time:38.383, tt:38.383\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02382, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.605, tt:79.211\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02457, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.269, tt:120.806\n",
      "Ep:3, loss:0.00005, loss_test:0.02371, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.469, tt:161.877\n",
      "Ep:4, loss:0.00004, loss_test:0.02239, lr:6.00e-02, fs:0.64286 (r=0.931,p=0.491),  time:40.423, tt:202.116\n",
      "Ep:5, loss:0.00004, loss_test:0.02168, lr:6.00e-02, fs:0.62241 (r=0.862,p=0.487),  time:40.970, tt:245.818\n",
      "Ep:6, loss:0.00004, loss_test:0.02230, lr:6.00e-02, fs:0.64815 (r=0.805,p=0.543),  time:40.795, tt:285.568\n",
      "Ep:7, loss:0.00004, loss_test:0.02349, lr:6.00e-02, fs:0.65000 (r=0.747,p=0.575),  time:40.860, tt:326.880\n",
      "Ep:8, loss:0.00004, loss_test:0.02328, lr:6.00e-02, fs:0.64286 (r=0.724,p=0.578),  time:40.611, tt:365.500\n",
      "Ep:9, loss:0.00004, loss_test:0.02196, lr:6.00e-02, fs:0.64078 (r=0.759,p=0.555),  time:40.441, tt:404.415\n",
      "Ep:10, loss:0.00003, loss_test:0.02086, lr:6.00e-02, fs:0.63256 (r=0.782,p=0.531),  time:40.431, tt:444.735\n",
      "Ep:11, loss:0.00003, loss_test:0.02029, lr:6.00e-02, fs:0.63014 (r=0.793,p=0.523),  time:40.460, tt:485.522\n",
      "Ep:12, loss:0.00003, loss_test:0.01993, lr:6.00e-02, fs:0.64186 (r=0.793,p=0.539),  time:40.372, tt:524.836\n",
      "Ep:13, loss:0.00003, loss_test:0.01969, lr:5.94e-02, fs:0.64151 (r=0.782,p=0.544),  time:40.247, tt:563.464\n",
      "Ep:14, loss:0.00003, loss_test:0.01952, lr:5.88e-02, fs:0.66019 (r=0.782,p=0.571),  time:40.216, tt:603.244\n",
      "Ep:15, loss:0.00003, loss_test:0.01931, lr:5.82e-02, fs:0.68000 (r=0.782,p=0.602),  time:40.217, tt:643.480\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01898, lr:5.82e-02, fs:0.69036 (r=0.782,p=0.618),  time:40.098, tt:681.667\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01854, lr:5.82e-02, fs:0.68687 (r=0.782,p=0.613),  time:40.034, tt:720.610\n",
      "Ep:18, loss:0.00003, loss_test:0.01820, lr:5.82e-02, fs:0.70000 (r=0.805,p=0.619),  time:40.010, tt:760.191\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01795, lr:5.82e-02, fs:0.72549 (r=0.851,p=0.632),  time:40.094, tt:801.886\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01779, lr:5.82e-02, fs:0.74510 (r=0.874,p=0.650),  time:40.153, tt:843.209\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01763, lr:5.82e-02, fs:0.74627 (r=0.862,p=0.658),  time:40.155, tt:883.405\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01751, lr:5.82e-02, fs:0.75377 (r=0.862,p=0.670),  time:40.440, tt:930.109\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01737, lr:5.82e-02, fs:0.76142 (r=0.862,p=0.682),  time:40.429, tt:970.289\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01722, lr:5.82e-02, fs:0.75758 (r=0.862,p=0.676),  time:40.488, tt:1012.201\n",
      "Ep:25, loss:0.00002, loss_test:0.01711, lr:5.82e-02, fs:0.75758 (r=0.862,p=0.676),  time:40.633, tt:1056.447\n",
      "Ep:26, loss:0.00002, loss_test:0.01698, lr:5.82e-02, fs:0.76382 (r=0.874,p=0.679),  time:40.709, tt:1099.143\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01687, lr:5.82e-02, fs:0.76768 (r=0.874,p=0.685),  time:40.737, tt:1140.645\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01670, lr:5.82e-02, fs:0.76923 (r=0.862,p=0.694),  time:40.762, tt:1182.084\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01662, lr:5.82e-02, fs:0.77320 (r=0.862,p=0.701),  time:40.783, tt:1223.475\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01652, lr:5.82e-02, fs:0.78534 (r=0.862,p=0.721),  time:40.762, tt:1263.624\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01644, lr:5.82e-02, fs:0.78947 (r=0.862,p=0.728),  time:40.792, tt:1305.339\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01637, lr:5.82e-02, fs:0.78125 (r=0.862,p=0.714),  time:40.803, tt:1346.505\n",
      "Ep:33, loss:0.00002, loss_test:0.01632, lr:5.82e-02, fs:0.78947 (r=0.862,p=0.728),  time:40.898, tt:1390.520\n",
      "Ep:34, loss:0.00002, loss_test:0.01624, lr:5.82e-02, fs:0.78947 (r=0.862,p=0.728),  time:40.990, tt:1434.655\n",
      "Ep:35, loss:0.00002, loss_test:0.01616, lr:5.82e-02, fs:0.79365 (r=0.862,p=0.735),  time:41.055, tt:1477.967\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01616, lr:5.82e-02, fs:0.79787 (r=0.862,p=0.743),  time:41.036, tt:1518.321\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01615, lr:5.82e-02, fs:0.80214 (r=0.862,p=0.750),  time:41.053, tt:1560.028\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01610, lr:5.82e-02, fs:0.80645 (r=0.862,p=0.758),  time:41.042, tt:1600.632\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01610, lr:5.82e-02, fs:0.80645 (r=0.862,p=0.758),  time:41.084, tt:1643.350\n",
      "Ep:40, loss:0.00002, loss_test:0.01610, lr:5.82e-02, fs:0.80645 (r=0.862,p=0.758),  time:41.084, tt:1684.435\n",
      "Ep:41, loss:0.00002, loss_test:0.01610, lr:5.82e-02, fs:0.81081 (r=0.862,p=0.765),  time:41.099, tt:1726.156\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01609, lr:5.82e-02, fs:0.81081 (r=0.862,p=0.765),  time:41.078, tt:1766.376\n",
      "Ep:43, loss:0.00002, loss_test:0.01609, lr:5.82e-02, fs:0.81522 (r=0.862,p=0.773),  time:41.073, tt:1807.193\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01609, lr:5.82e-02, fs:0.81522 (r=0.862,p=0.773),  time:41.078, tt:1848.513\n",
      "Ep:45, loss:0.00002, loss_test:0.01611, lr:5.82e-02, fs:0.81967 (r=0.862,p=0.781),  time:41.087, tt:1890.013\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01623, lr:5.82e-02, fs:0.82418 (r=0.862,p=0.789),  time:41.104, tt:1931.884\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01633, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.147, tt:1975.050\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01642, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.147, tt:2016.199\n",
      "Ep:49, loss:0.00001, loss_test:0.01645, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.095, tt:2054.771\n",
      "Ep:50, loss:0.00001, loss_test:0.01652, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.115, tt:2096.859\n",
      "Ep:51, loss:0.00001, loss_test:0.01656, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.102, tt:2137.309\n",
      "Ep:52, loss:0.00001, loss_test:0.01654, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.074, tt:2176.941\n",
      "Ep:53, loss:0.00001, loss_test:0.01664, lr:5.82e-02, fs:0.82873 (r=0.862,p=0.798),  time:41.076, tt:2218.101\n",
      "Ep:54, loss:0.00001, loss_test:0.01670, lr:5.82e-02, fs:0.83799 (r=0.862,p=0.815),  time:41.070, tt:2258.866\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01680, lr:5.82e-02, fs:0.84270 (r=0.862,p=0.824),  time:41.074, tt:2300.136\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01693, lr:5.82e-02, fs:0.84270 (r=0.862,p=0.824),  time:41.054, tt:2340.062\n",
      "Ep:57, loss:0.00001, loss_test:0.01700, lr:5.82e-02, fs:0.85227 (r=0.862,p=0.843),  time:41.023, tt:2379.361\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01714, lr:5.82e-02, fs:0.85227 (r=0.862,p=0.843),  time:40.984, tt:2418.043\n",
      "Ep:59, loss:0.00001, loss_test:0.01731, lr:5.82e-02, fs:0.86207 (r=0.862,p=0.862),  time:41.017, tt:2461.038\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01742, lr:5.82e-02, fs:0.86705 (r=0.862,p=0.872),  time:40.995, tt:2500.713\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01746, lr:5.82e-02, fs:0.87209 (r=0.862,p=0.882),  time:41.005, tt:2542.285\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01758, lr:5.82e-02, fs:0.87209 (r=0.862,p=0.882),  time:40.998, tt:2582.875\n",
      "Ep:63, loss:0.00001, loss_test:0.01776, lr:5.82e-02, fs:0.87209 (r=0.862,p=0.882),  time:40.969, tt:2622.026\n",
      "Ep:64, loss:0.00001, loss_test:0.01787, lr:5.82e-02, fs:0.87209 (r=0.862,p=0.882),  time:40.942, tt:2661.247\n",
      "Ep:65, loss:0.00001, loss_test:0.01792, lr:5.82e-02, fs:0.87209 (r=0.862,p=0.882),  time:40.919, tt:2700.660\n",
      "Ep:66, loss:0.00001, loss_test:0.01821, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.904, tt:2740.539\n",
      "Ep:67, loss:0.00001, loss_test:0.01829, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.875, tt:2779.481\n",
      "Ep:68, loss:0.00001, loss_test:0.01845, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.867, tt:2819.848\n",
      "Ep:69, loss:0.00001, loss_test:0.01857, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.852, tt:2859.664\n",
      "Ep:70, loss:0.00001, loss_test:0.01876, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.867, tt:2901.539\n",
      "Ep:71, loss:0.00001, loss_test:0.01881, lr:5.82e-02, fs:0.86550 (r=0.851,p=0.881),  time:40.877, tt:2943.111\n",
      "Ep:72, loss:0.00001, loss_test:0.01913, lr:5.82e-02, fs:0.86391 (r=0.839,p=0.890),  time:40.871, tt:2983.589\n",
      "Ep:73, loss:0.00001, loss_test:0.01919, lr:5.76e-02, fs:0.86391 (r=0.839,p=0.890),  time:40.881, tt:3025.162\n",
      "Ep:74, loss:0.00001, loss_test:0.01939, lr:5.71e-02, fs:0.86391 (r=0.839,p=0.890),  time:40.873, tt:3065.473\n",
      "Ep:75, loss:0.00001, loss_test:0.01961, lr:5.65e-02, fs:0.85714 (r=0.828,p=0.889),  time:40.878, tt:3106.692\n",
      "Ep:76, loss:0.00001, loss_test:0.01967, lr:5.59e-02, fs:0.85714 (r=0.828,p=0.889),  time:40.869, tt:3146.914\n",
      "Ep:77, loss:0.00001, loss_test:0.01967, lr:5.54e-02, fs:0.86391 (r=0.839,p=0.890),  time:40.874, tt:3188.152\n",
      "Ep:78, loss:0.00001, loss_test:0.02000, lr:5.48e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.893, tt:3230.530\n",
      "Ep:79, loss:0.00001, loss_test:0.02026, lr:5.43e-02, fs:0.84337 (r=0.805,p=0.886),  time:40.886, tt:3270.866\n",
      "Ep:80, loss:0.00001, loss_test:0.02024, lr:5.37e-02, fs:0.85030 (r=0.816,p=0.887),  time:40.902, tt:3313.049\n",
      "Ep:81, loss:0.00001, loss_test:0.02043, lr:5.32e-02, fs:0.84337 (r=0.805,p=0.886),  time:40.907, tt:3354.340\n",
      "Ep:82, loss:0.00001, loss_test:0.02059, lr:5.27e-02, fs:0.82209 (r=0.770,p=0.882),  time:40.904, tt:3395.051\n",
      "Ep:83, loss:0.00001, loss_test:0.02069, lr:5.21e-02, fs:0.82927 (r=0.782,p=0.883),  time:40.922, tt:3437.453\n",
      "Ep:84, loss:0.00001, loss_test:0.02103, lr:5.16e-02, fs:0.80503 (r=0.736,p=0.889),  time:40.999, tt:3484.928\n",
      "Ep:85, loss:0.00001, loss_test:0.02119, lr:5.11e-02, fs:0.78981 (r=0.713,p=0.886),  time:41.002, tt:3526.143\n",
      "Ep:86, loss:0.00001, loss_test:0.02115, lr:5.06e-02, fs:0.78481 (r=0.713,p=0.873),  time:40.993, tt:3566.386\n",
      "Ep:87, loss:0.00001, loss_test:0.02141, lr:5.01e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.005, tt:3608.442\n",
      "Ep:88, loss:0.00001, loss_test:0.02166, lr:4.96e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.997, tt:3648.692\n",
      "Ep:89, loss:0.00001, loss_test:0.02174, lr:4.91e-02, fs:0.76623 (r=0.678,p=0.881),  time:41.017, tt:3691.511\n",
      "Ep:90, loss:0.00001, loss_test:0.02186, lr:4.86e-02, fs:0.76623 (r=0.678,p=0.881),  time:41.022, tt:3732.979\n",
      "Ep:91, loss:0.00001, loss_test:0.02199, lr:4.81e-02, fs:0.76623 (r=0.678,p=0.881),  time:41.023, tt:3774.122\n",
      "Ep:92, loss:0.00001, loss_test:0.02222, lr:4.76e-02, fs:0.76623 (r=0.678,p=0.881),  time:41.025, tt:3815.298\n",
      "Ep:93, loss:0.00001, loss_test:0.02238, lr:4.71e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.028, tt:3856.677\n",
      "Ep:94, loss:0.00001, loss_test:0.02250, lr:4.67e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.055, tt:3900.227\n",
      "Ep:95, loss:0.00001, loss_test:0.02262, lr:4.62e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.061, tt:3941.827\n",
      "Ep:96, loss:0.00001, loss_test:0.02287, lr:4.57e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.066, tt:3983.395\n",
      "Ep:97, loss:0.00001, loss_test:0.02303, lr:4.53e-02, fs:0.76000 (r=0.655,p=0.905),  time:41.041, tt:4022.055\n",
      "Ep:98, loss:0.00001, loss_test:0.02308, lr:4.48e-02, fs:0.76000 (r=0.655,p=0.905),  time:41.053, tt:4064.260\n",
      "Ep:99, loss:0.00001, loss_test:0.02326, lr:4.44e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.045, tt:4104.522\n",
      "Ep:100, loss:0.00001, loss_test:0.02344, lr:4.39e-02, fs:0.75676 (r=0.644,p=0.918),  time:41.041, tt:4145.120\n",
      "Ep:101, loss:0.00001, loss_test:0.02350, lr:4.35e-02, fs:0.75676 (r=0.644,p=0.918),  time:41.058, tt:4187.896\n",
      "Ep:102, loss:0.00001, loss_test:0.02370, lr:4.31e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.057, tt:4228.907\n",
      "Ep:103, loss:0.00001, loss_test:0.02385, lr:4.26e-02, fs:0.75676 (r=0.644,p=0.918),  time:41.046, tt:4268.748\n",
      "Ep:104, loss:0.00001, loss_test:0.02406, lr:4.22e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.047, tt:4309.910\n",
      "Ep:105, loss:0.00001, loss_test:0.02410, lr:4.18e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.094, tt:4355.949\n",
      "Ep:106, loss:0.00001, loss_test:0.02429, lr:4.14e-02, fs:0.74830 (r=0.632,p=0.917),  time:41.099, tt:4397.616\n",
      "Ep:107, loss:0.00001, loss_test:0.02449, lr:4.10e-02, fs:0.74830 (r=0.632,p=0.917),  time:41.114, tt:4440.328\n",
      "Ep:108, loss:0.00001, loss_test:0.02455, lr:4.05e-02, fs:0.74324 (r=0.632,p=0.902),  time:41.120, tt:4482.028\n",
      "Ep:109, loss:0.00001, loss_test:0.02463, lr:4.01e-02, fs:0.73469 (r=0.621,p=0.900),  time:41.102, tt:4521.179\n",
      "Ep:110, loss:0.00001, loss_test:0.02479, lr:3.97e-02, fs:0.73469 (r=0.621,p=0.900),  time:41.108, tt:4563.014\n",
      "Ep:111, loss:0.00001, loss_test:0.02495, lr:3.93e-02, fs:0.73469 (r=0.621,p=0.900),  time:41.090, tt:4602.036\n",
      "Ep:112, loss:0.00001, loss_test:0.02502, lr:3.89e-02, fs:0.73469 (r=0.621,p=0.900),  time:41.094, tt:4643.618\n",
      "Ep:113, loss:0.00001, loss_test:0.02510, lr:3.86e-02, fs:0.72603 (r=0.609,p=0.898),  time:41.090, tt:4684.238\n",
      "Ep:114, loss:0.00001, loss_test:0.02527, lr:3.82e-02, fs:0.71724 (r=0.598,p=0.897),  time:41.091, tt:4725.438\n",
      "Ep:115, loss:0.00001, loss_test:0.02532, lr:3.78e-02, fs:0.71724 (r=0.598,p=0.897),  time:41.099, tt:4767.457\n",
      "Ep:116, loss:0.00001, loss_test:0.02547, lr:3.74e-02, fs:0.71724 (r=0.598,p=0.897),  time:41.114, tt:4810.370\n",
      "Ep:117, loss:0.00001, loss_test:0.02565, lr:3.70e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.122, tt:4852.348\n",
      "Ep:118, loss:0.00000, loss_test:0.02580, lr:3.67e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.139, tt:4895.535\n",
      "Ep:119, loss:0.00000, loss_test:0.02590, lr:3.63e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.136, tt:4936.365\n",
      "Ep:120, loss:0.00000, loss_test:0.02602, lr:3.59e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.135, tt:4977.362\n",
      "Ep:121, loss:0.00000, loss_test:0.02607, lr:3.56e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.140, tt:5019.053\n",
      "Ep:122, loss:0.00000, loss_test:0.02619, lr:3.52e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.137, tt:5059.908\n",
      "Ep:123, loss:0.00000, loss_test:0.02628, lr:3.49e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.140, tt:5101.341\n",
      "Ep:124, loss:0.00000, loss_test:0.02639, lr:3.45e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.147, tt:5143.316\n",
      "Ep:125, loss:0.00000, loss_test:0.02650, lr:3.42e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.151, tt:5184.967\n",
      "Ep:126, loss:0.00000, loss_test:0.02662, lr:3.38e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.214, tt:5234.234\n",
      "Ep:127, loss:0.00000, loss_test:0.02664, lr:3.35e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.207, tt:5274.488\n",
      "Ep:128, loss:0.00000, loss_test:0.02684, lr:3.32e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.200, tt:5314.803\n",
      "Ep:129, loss:0.00000, loss_test:0.02694, lr:3.28e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.203, tt:5356.351\n",
      "Ep:130, loss:0.00000, loss_test:0.02702, lr:3.25e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.208, tt:5398.209\n",
      "Ep:131, loss:0.00000, loss_test:0.02707, lr:3.22e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.224, tt:5441.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.02725, lr:3.19e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.212, tt:5481.157\n",
      "Ep:133, loss:0.00000, loss_test:0.02733, lr:3.15e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.200, tt:5520.861\n",
      "Ep:134, loss:0.00000, loss_test:0.02727, lr:3.12e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.200, tt:5562.023\n",
      "Ep:135, loss:0.00000, loss_test:0.02731, lr:3.09e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.207, tt:5604.098\n",
      "Ep:136, loss:0.00000, loss_test:0.02757, lr:3.06e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.209, tt:5645.633\n",
      "Ep:137, loss:0.00000, loss_test:0.02766, lr:3.03e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.204, tt:5686.117\n",
      "Ep:138, loss:0.00000, loss_test:0.02773, lr:3.00e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.193, tt:5725.849\n",
      "Ep:139, loss:0.00000, loss_test:0.02782, lr:2.97e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.201, tt:5768.108\n",
      "Ep:140, loss:0.00000, loss_test:0.02794, lr:2.94e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.202, tt:5809.455\n",
      "Ep:141, loss:0.00000, loss_test:0.02804, lr:2.91e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.199, tt:5850.317\n",
      "Ep:142, loss:0.00000, loss_test:0.02806, lr:2.88e-02, fs:0.66187 (r=0.529,p=0.885),  time:41.201, tt:5891.720\n",
      "Ep:143, loss:0.00000, loss_test:0.02811, lr:2.85e-02, fs:0.66187 (r=0.529,p=0.885),  time:41.213, tt:5934.626\n",
      "Ep:144, loss:0.00000, loss_test:0.02823, lr:2.82e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.212, tt:5975.802\n",
      "Ep:145, loss:0.00000, loss_test:0.02833, lr:2.80e-02, fs:0.66187 (r=0.529,p=0.885),  time:41.215, tt:6017.398\n",
      "Ep:146, loss:0.00000, loss_test:0.02844, lr:2.77e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.203, tt:6056.794\n",
      "Ep:147, loss:0.00000, loss_test:0.02848, lr:2.74e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.259, tt:6106.305\n",
      "Ep:148, loss:0.00000, loss_test:0.02857, lr:2.71e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.265, tt:6148.416\n",
      "Ep:149, loss:0.00000, loss_test:0.02860, lr:2.69e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.271, tt:6190.652\n",
      "Ep:150, loss:0.00000, loss_test:0.02869, lr:2.66e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.269, tt:6231.558\n",
      "Ep:151, loss:0.00000, loss_test:0.02876, lr:2.63e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.268, tt:6272.805\n",
      "Ep:152, loss:0.00000, loss_test:0.02883, lr:2.61e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.254, tt:6311.898\n",
      "Ep:153, loss:0.00000, loss_test:0.02889, lr:2.58e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.264, tt:6354.593\n",
      "Ep:154, loss:0.00000, loss_test:0.02900, lr:2.55e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.259, tt:6395.104\n",
      "Ep:155, loss:0.00000, loss_test:0.02911, lr:2.53e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.260, tt:6436.524\n",
      "Ep:156, loss:0.00000, loss_test:0.02917, lr:2.50e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.259, tt:6477.622\n",
      "Ep:157, loss:0.00000, loss_test:0.02922, lr:2.48e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.268, tt:6520.358\n",
      "Ep:158, loss:0.00000, loss_test:0.02922, lr:2.45e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.267, tt:6561.418\n",
      "Ep:159, loss:0.00000, loss_test:0.02934, lr:2.43e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.266, tt:6602.610\n",
      "Ep:160, loss:0.00000, loss_test:0.02939, lr:2.40e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.274, tt:6645.176\n",
      "Ep:161, loss:0.00000, loss_test:0.02943, lr:2.38e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.274, tt:6686.363\n",
      "Ep:162, loss:0.00000, loss_test:0.02948, lr:2.36e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.281, tt:6728.814\n",
      "Ep:163, loss:0.00000, loss_test:0.02958, lr:2.33e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.275, tt:6769.060\n",
      "Ep:164, loss:0.00000, loss_test:0.02967, lr:2.31e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.277, tt:6810.774\n",
      "Ep:165, loss:0.00000, loss_test:0.02971, lr:2.29e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.282, tt:6852.845\n",
      "Ep:166, loss:0.00000, loss_test:0.02981, lr:2.26e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.289, tt:6895.244\n",
      "Ep:167, loss:0.00000, loss_test:0.02981, lr:2.24e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.303, tt:6938.872\n",
      "Ep:168, loss:0.00000, loss_test:0.02977, lr:2.22e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.333, tt:6985.268\n",
      "Ep:169, loss:0.00000, loss_test:0.02987, lr:2.20e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.342, tt:7028.144\n",
      "Ep:170, loss:0.00000, loss_test:0.02998, lr:2.17e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.341, tt:7069.232\n",
      "Ep:171, loss:0.00000, loss_test:0.03006, lr:2.15e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.336, tt:7109.851\n",
      "Ep:172, loss:0.00000, loss_test:0.03011, lr:2.13e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.333, tt:7150.671\n",
      "Ep:173, loss:0.00000, loss_test:0.03018, lr:2.11e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.325, tt:7190.617\n",
      "Ep:174, loss:0.00000, loss_test:0.03025, lr:2.09e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.330, tt:7232.667\n",
      "Ep:175, loss:0.00000, loss_test:0.03029, lr:2.07e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.325, tt:7273.265\n",
      "Ep:176, loss:0.00000, loss_test:0.03036, lr:2.05e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.322, tt:7314.007\n",
      "Ep:177, loss:0.00000, loss_test:0.03040, lr:2.03e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.317, tt:7354.393\n",
      "Ep:178, loss:0.00000, loss_test:0.03045, lr:2.01e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.316, tt:7395.641\n",
      "Ep:179, loss:0.00000, loss_test:0.03046, lr:1.99e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.312, tt:7436.085\n",
      "Ep:180, loss:0.00000, loss_test:0.03051, lr:1.97e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.308, tt:7476.673\n",
      "Ep:181, loss:0.00000, loss_test:0.03059, lr:1.95e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.299, tt:7516.329\n",
      "Ep:182, loss:0.00000, loss_test:0.03061, lr:1.93e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.300, tt:7557.820\n",
      "Ep:183, loss:0.00000, loss_test:0.03066, lr:1.91e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.296, tt:7598.530\n",
      "Ep:184, loss:0.00000, loss_test:0.03073, lr:1.89e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.296, tt:7639.693\n",
      "Ep:185, loss:0.00000, loss_test:0.03079, lr:1.87e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.291, tt:7680.195\n",
      "Ep:186, loss:0.00000, loss_test:0.03089, lr:1.85e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.298, tt:7722.806\n",
      "Ep:187, loss:0.00000, loss_test:0.03089, lr:1.83e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.299, tt:7764.221\n",
      "Ep:188, loss:0.00000, loss_test:0.03093, lr:1.81e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.295, tt:7804.737\n",
      "Ep:189, loss:0.00000, loss_test:0.03098, lr:1.80e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.295, tt:7845.999\n",
      "Ep:190, loss:0.00000, loss_test:0.03106, lr:1.78e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.294, tt:7887.244\n",
      "Ep:191, loss:0.00000, loss_test:0.03109, lr:1.76e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.289, tt:7927.540\n",
      "Ep:192, loss:0.00000, loss_test:0.03114, lr:1.74e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.289, tt:7968.726\n",
      "Ep:193, loss:0.00000, loss_test:0.03115, lr:1.73e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.284, tt:8009.084\n",
      "Ep:194, loss:0.00000, loss_test:0.03118, lr:1.71e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.277, tt:8049.072\n",
      "Ep:195, loss:0.00000, loss_test:0.03125, lr:1.69e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.266, tt:8088.175\n",
      "Ep:196, loss:0.00000, loss_test:0.03132, lr:1.67e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.254, tt:8127.034\n",
      "Ep:197, loss:0.00000, loss_test:0.03137, lr:1.66e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.243, tt:8166.056\n",
      "Ep:198, loss:0.00000, loss_test:0.03142, lr:1.64e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.238, tt:8206.456\n",
      "Ep:199, loss:0.00000, loss_test:0.03148, lr:1.62e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.229, tt:8245.790\n",
      "Ep:200, loss:0.00000, loss_test:0.03144, lr:1.61e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.233, tt:8287.745\n",
      "Ep:201, loss:0.00000, loss_test:0.03150, lr:1.59e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.233, tt:8329.029\n",
      "Ep:202, loss:0.00000, loss_test:0.03159, lr:1.58e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.223, tt:8368.232\n",
      "Ep:203, loss:0.00000, loss_test:0.03164, lr:1.56e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.225, tt:8409.807\n",
      "Ep:204, loss:0.00000, loss_test:0.03164, lr:1.54e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.231, tt:8452.285\n",
      "Ep:205, loss:0.00000, loss_test:0.03168, lr:1.53e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.228, tt:8492.953\n",
      "Ep:206, loss:0.00000, loss_test:0.03171, lr:1.51e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.222, tt:8532.888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.03175, lr:1.50e-02, fs:0.66176 (r=0.517,p=0.918),  time:41.225, tt:8574.758\n",
      "Ep:208, loss:0.00000, loss_test:0.03180, lr:1.48e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.221, tt:8615.262\n",
      "Ep:209, loss:0.00000, loss_test:0.03186, lr:1.47e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.219, tt:8655.941\n",
      "Ep:210, loss:0.00000, loss_test:0.03191, lr:1.45e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.203, tt:8693.871\n",
      "Ep:211, loss:0.00000, loss_test:0.03188, lr:1.44e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.180, tt:8730.156\n",
      "Ep:212, loss:0.00000, loss_test:0.03192, lr:1.43e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.152, tt:8765.461\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14310, lr:1.00e-02, fs:0.64062 (r=0.943,p=0.485),  time:36.395, tt:36.395\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14108, lr:1.00e-02, fs:0.64286 (r=0.931,p=0.491),  time:39.424, tt:78.848\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13707, lr:1.00e-02, fs:0.63115 (r=0.885,p=0.490),  time:40.220, tt:120.661\n",
      "Ep:3, loss:0.00025, loss_test:0.13030, lr:1.00e-02, fs:0.61111 (r=0.759,p=0.512),  time:40.725, tt:162.899\n",
      "Ep:4, loss:0.00024, loss_test:0.12633, lr:1.00e-02, fs:0.65537 (r=0.667,p=0.644),  time:40.764, tt:203.822\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00022, loss_test:0.12636, lr:1.00e-02, fs:0.64151 (r=0.586,p=0.708),  time:40.742, tt:244.450\n",
      "Ep:6, loss:0.00022, loss_test:0.12168, lr:1.00e-02, fs:0.65476 (r=0.632,p=0.679),  time:40.588, tt:284.114\n",
      "Ep:7, loss:0.00021, loss_test:0.12011, lr:1.00e-02, fs:0.64444 (r=0.667,p=0.624),  time:40.446, tt:323.565\n",
      "Ep:8, loss:0.00020, loss_test:0.11952, lr:1.00e-02, fs:0.65839 (r=0.609,p=0.716),  time:40.247, tt:362.225\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11777, lr:1.00e-02, fs:0.65409 (r=0.598,p=0.722),  time:40.277, tt:402.768\n",
      "Ep:10, loss:0.00019, loss_test:0.11099, lr:1.00e-02, fs:0.67857 (r=0.655,p=0.704),  time:40.388, tt:444.264\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.10843, lr:1.00e-02, fs:0.66258 (r=0.621,p=0.711),  time:40.505, tt:486.062\n",
      "Ep:12, loss:0.00018, loss_test:0.10925, lr:1.00e-02, fs:0.64935 (r=0.575,p=0.746),  time:40.863, tt:531.218\n",
      "Ep:13, loss:0.00017, loss_test:0.10311, lr:1.00e-02, fs:0.67925 (r=0.621,p=0.750),  time:40.994, tt:573.918\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10082, lr:1.00e-02, fs:0.67089 (r=0.609,p=0.746),  time:41.017, tt:615.258\n",
      "Ep:15, loss:0.00016, loss_test:0.09999, lr:1.00e-02, fs:0.68354 (r=0.621,p=0.761),  time:41.075, tt:657.201\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09583, lr:1.00e-02, fs:0.70000 (r=0.644,p=0.767),  time:41.004, tt:697.076\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09482, lr:1.00e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.974, tt:737.532\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09362, lr:1.00e-02, fs:0.77019 (r=0.713,p=0.838),  time:40.965, tt:778.327\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09080, lr:1.00e-02, fs:0.77844 (r=0.747,p=0.812),  time:40.949, tt:818.976\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.09080, lr:1.00e-02, fs:0.77576 (r=0.736,p=0.821),  time:41.016, tt:861.335\n",
      "Ep:21, loss:0.00013, loss_test:0.08791, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:41.056, tt:903.238\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08690, lr:1.00e-02, fs:0.79268 (r=0.747,p=0.844),  time:41.022, tt:943.506\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08782, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:40.975, tt:983.391\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08459, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:40.933, tt:1023.316\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08550, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:40.883, tt:1062.947\n",
      "Ep:26, loss:0.00011, loss_test:0.08459, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:40.929, tt:1105.078\n",
      "Ep:27, loss:0.00010, loss_test:0.08355, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:40.911, tt:1145.497\n",
      "Ep:28, loss:0.00010, loss_test:0.08506, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:40.810, tt:1183.494\n",
      "Ep:29, loss:0.00009, loss_test:0.08463, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:40.840, tt:1225.206\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08513, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:40.848, tt:1266.298\n",
      "Ep:31, loss:0.00009, loss_test:0.08377, lr:1.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:40.860, tt:1307.525\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.08318, lr:1.00e-02, fs:0.81013 (r=0.736,p=0.901),  time:40.925, tt:1350.512\n",
      "Ep:33, loss:0.00008, loss_test:0.08510, lr:1.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:40.961, tt:1392.663\n",
      "Ep:34, loss:0.00008, loss_test:0.08489, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:41.018, tt:1435.614\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.08084, lr:1.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:41.000, tt:1476.001\n",
      "Ep:36, loss:0.00007, loss_test:0.08883, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:41.046, tt:1518.695\n",
      "Ep:37, loss:0.00007, loss_test:0.08129, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:41.027, tt:1559.035\n",
      "Ep:38, loss:0.00007, loss_test:0.08851, lr:1.00e-02, fs:0.80263 (r=0.701,p=0.938),  time:40.986, tt:1598.470\n",
      "Ep:39, loss:0.00006, loss_test:0.08522, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:40.926, tt:1637.028\n",
      "Ep:40, loss:0.00006, loss_test:0.08585, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:40.905, tt:1677.088\n",
      "Ep:41, loss:0.00006, loss_test:0.08959, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:40.913, tt:1718.356\n",
      "Ep:42, loss:0.00005, loss_test:0.08351, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:40.896, tt:1758.543\n",
      "Ep:43, loss:0.00005, loss_test:0.09081, lr:1.00e-02, fs:0.81013 (r=0.736,p=0.901),  time:40.846, tt:1797.238\n",
      "Ep:44, loss:0.00005, loss_test:0.08545, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:40.830, tt:1837.338\n",
      "Ep:45, loss:0.00005, loss_test:0.09456, lr:1.00e-02, fs:0.79487 (r=0.713,p=0.899),  time:40.754, tt:1874.701\n",
      "Ep:46, loss:0.00004, loss_test:0.09183, lr:9.90e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.750, tt:1915.244\n",
      "Ep:47, loss:0.00004, loss_test:0.09590, lr:9.80e-03, fs:0.79747 (r=0.724,p=0.887),  time:40.627, tt:1950.104\n",
      "Ep:48, loss:0.00004, loss_test:0.10194, lr:9.70e-03, fs:0.77333 (r=0.667,p=0.921),  time:40.651, tt:1991.923\n",
      "Ep:49, loss:0.00004, loss_test:0.08521, lr:9.61e-03, fs:0.80000 (r=0.713,p=0.912),  time:40.618, tt:2030.878\n",
      "Ep:50, loss:0.00004, loss_test:0.12256, lr:9.51e-03, fs:0.68056 (r=0.563,p=0.860),  time:40.621, tt:2071.673\n",
      "Ep:51, loss:0.00004, loss_test:0.08455, lr:9.41e-03, fs:0.80769 (r=0.724,p=0.913),  time:40.599, tt:2111.151\n",
      "Ep:52, loss:0.00004, loss_test:0.11554, lr:9.32e-03, fs:0.67626 (r=0.540,p=0.904),  time:40.607, tt:2152.146\n",
      "Ep:53, loss:0.00004, loss_test:0.09271, lr:9.23e-03, fs:0.77333 (r=0.667,p=0.921),  time:40.606, tt:2192.705\n",
      "Ep:54, loss:0.00003, loss_test:0.10418, lr:9.14e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.644, tt:2235.437\n",
      "Ep:55, loss:0.00003, loss_test:0.09804, lr:9.04e-03, fs:0.77852 (r=0.667,p=0.935),  time:40.631, tt:2275.317\n",
      "Ep:56, loss:0.00003, loss_test:0.09940, lr:8.95e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.641, tt:2316.547\n",
      "Ep:57, loss:0.00003, loss_test:0.09674, lr:8.86e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.668, tt:2358.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00003, loss_test:0.10140, lr:8.78e-03, fs:0.73973 (r=0.621,p=0.915),  time:40.685, tt:2400.398\n",
      "Ep:59, loss:0.00003, loss_test:0.10136, lr:8.69e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.697, tt:2441.828\n",
      "Ep:60, loss:0.00003, loss_test:0.10153, lr:8.60e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.725, tt:2484.221\n",
      "Ep:61, loss:0.00003, loss_test:0.10107, lr:8.51e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.760, tt:2527.116\n",
      "Ep:62, loss:0.00002, loss_test:0.10055, lr:8.43e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.811, tt:2571.120\n",
      "Ep:63, loss:0.00002, loss_test:0.09843, lr:8.35e-03, fs:0.77027 (r=0.655,p=0.934),  time:40.822, tt:2612.619\n",
      "Ep:64, loss:0.00002, loss_test:0.10013, lr:8.26e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.818, tt:2653.169\n",
      "Ep:65, loss:0.00002, loss_test:0.09908, lr:8.18e-03, fs:0.76000 (r=0.655,p=0.905),  time:40.866, tt:2697.165\n",
      "Ep:66, loss:0.00002, loss_test:0.10230, lr:8.10e-03, fs:0.78082 (r=0.655,p=0.966),  time:40.911, tt:2741.023\n",
      "Ep:67, loss:0.00002, loss_test:0.09795, lr:8.02e-03, fs:0.77027 (r=0.655,p=0.934),  time:40.957, tt:2785.098\n",
      "Ep:68, loss:0.00002, loss_test:0.10114, lr:7.94e-03, fs:0.77027 (r=0.655,p=0.934),  time:40.966, tt:2826.665\n",
      "Ep:69, loss:0.00002, loss_test:0.09980, lr:7.86e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.980, tt:2868.572\n",
      "Ep:70, loss:0.00002, loss_test:0.09943, lr:7.78e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.015, tt:2912.071\n",
      "Ep:71, loss:0.00002, loss_test:0.09969, lr:7.70e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.051, tt:2955.691\n",
      "Ep:72, loss:0.00002, loss_test:0.10054, lr:7.62e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.100, tt:3000.298\n",
      "Ep:73, loss:0.00001, loss_test:0.09783, lr:7.55e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.130, tt:3043.597\n",
      "Ep:74, loss:0.00001, loss_test:0.09844, lr:7.47e-03, fs:0.77027 (r=0.655,p=0.934),  time:41.185, tt:3088.904\n",
      "Ep:75, loss:0.00001, loss_test:0.09901, lr:7.40e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.210, tt:3131.934\n",
      "Ep:76, loss:0.00001, loss_test:0.09984, lr:7.32e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.249, tt:3176.151\n",
      "Ep:77, loss:0.00001, loss_test:0.09757, lr:7.25e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.317, tt:3222.689\n",
      "Ep:78, loss:0.00001, loss_test:0.10262, lr:7.18e-03, fs:0.77551 (r=0.655,p=0.950),  time:41.356, tt:3267.144\n",
      "Ep:79, loss:0.00001, loss_test:0.10077, lr:7.11e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.408, tt:3312.653\n",
      "Ep:80, loss:0.00001, loss_test:0.10327, lr:7.03e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.443, tt:3356.923\n",
      "Ep:81, loss:0.00001, loss_test:0.09760, lr:6.96e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.459, tt:3399.608\n",
      "Ep:82, loss:0.00001, loss_test:0.10233, lr:6.89e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.512, tt:3445.483\n",
      "Ep:83, loss:0.00001, loss_test:0.09825, lr:6.83e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.534, tt:3488.866\n",
      "Ep:84, loss:0.00001, loss_test:0.10343, lr:6.76e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.563, tt:3532.848\n",
      "Ep:85, loss:0.00001, loss_test:0.09743, lr:6.69e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.597, tt:3577.343\n",
      "Ep:86, loss:0.00001, loss_test:0.10522, lr:6.62e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.628, tt:3621.651\n",
      "Ep:87, loss:0.00001, loss_test:0.10047, lr:6.56e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.655, tt:3665.630\n",
      "Ep:88, loss:0.00001, loss_test:0.10198, lr:6.49e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.687, tt:3710.144\n",
      "Ep:89, loss:0.00001, loss_test:0.10246, lr:6.43e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.711, tt:3753.954\n",
      "Ep:90, loss:0.00001, loss_test:0.10321, lr:6.36e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.752, tt:3799.466\n",
      "Ep:91, loss:0.00001, loss_test:0.10054, lr:6.30e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.790, tt:3844.717\n",
      "Ep:92, loss:0.00001, loss_test:0.10239, lr:6.24e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.800, tt:3887.357\n",
      "Ep:93, loss:0.00001, loss_test:0.10085, lr:6.17e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.826, tt:3931.624\n",
      "Ep:94, loss:0.00001, loss_test:0.10333, lr:6.11e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.848, tt:3975.587\n",
      "Ep:95, loss:0.00001, loss_test:0.10153, lr:6.05e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.868, tt:4019.335\n",
      "Ep:96, loss:0.00001, loss_test:0.10359, lr:5.99e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.953, tt:4069.431\n",
      "Ep:97, loss:0.00001, loss_test:0.10261, lr:5.93e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.959, tt:4112.018\n",
      "Ep:98, loss:0.00001, loss_test:0.10518, lr:5.87e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.961, tt:4154.101\n",
      "Ep:99, loss:0.00001, loss_test:0.10258, lr:5.81e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.962, tt:4196.175\n",
      "Ep:100, loss:0.00001, loss_test:0.10532, lr:5.75e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.952, tt:4237.106\n",
      "Ep:101, loss:0.00001, loss_test:0.10477, lr:5.70e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.944, tt:4278.254\n",
      "Ep:102, loss:0.00001, loss_test:0.10365, lr:5.64e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.937, tt:4319.529\n",
      "Ep:103, loss:0.00001, loss_test:0.10477, lr:5.58e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.943, tt:4362.101\n",
      "Ep:104, loss:0.00001, loss_test:0.10439, lr:5.53e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.956, tt:4405.408\n",
      "Ep:105, loss:0.00001, loss_test:0.10430, lr:5.47e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.959, tt:4447.628\n",
      "Ep:106, loss:0.00001, loss_test:0.10495, lr:5.42e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.962, tt:4489.880\n",
      "Ep:107, loss:0.00001, loss_test:0.10325, lr:5.36e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.961, tt:4531.817\n",
      "Ep:108, loss:0.00001, loss_test:0.10600, lr:5.31e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.955, tt:4573.056\n",
      "Ep:109, loss:0.00001, loss_test:0.10488, lr:5.26e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.948, tt:4614.262\n",
      "Ep:110, loss:0.00001, loss_test:0.10565, lr:5.20e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.934, tt:4654.668\n",
      "Ep:111, loss:0.00001, loss_test:0.10579, lr:5.15e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.926, tt:4695.679\n",
      "Ep:112, loss:0.00001, loss_test:0.10511, lr:5.10e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.899, tt:4734.626\n",
      "Ep:113, loss:0.00001, loss_test:0.10551, lr:5.05e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.887, tt:4775.089\n",
      "Ep:114, loss:0.00001, loss_test:0.10590, lr:5.00e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.883, tt:4816.532\n",
      "Ep:115, loss:0.00001, loss_test:0.10547, lr:4.95e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.894, tt:4859.674\n",
      "Ep:116, loss:0.00001, loss_test:0.10659, lr:4.90e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.926, tt:4905.353\n",
      "Ep:117, loss:0.00001, loss_test:0.10537, lr:4.85e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.932, tt:4947.972\n",
      "Ep:118, loss:0.00001, loss_test:0.10764, lr:4.80e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.933, tt:4990.076\n",
      "Ep:119, loss:0.00001, loss_test:0.10612, lr:4.75e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.926, tt:5031.155\n",
      "Ep:120, loss:0.00001, loss_test:0.10661, lr:4.71e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.928, tt:5073.334\n",
      "Ep:121, loss:0.00001, loss_test:0.10823, lr:4.66e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.934, tt:5115.990\n",
      "Ep:122, loss:0.00001, loss_test:0.10575, lr:4.61e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.940, tt:5158.629\n",
      "Ep:123, loss:0.00001, loss_test:0.10807, lr:4.57e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.947, tt:5201.399\n",
      "Ep:124, loss:0.00000, loss_test:0.10805, lr:4.52e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.935, tt:5241.870\n",
      "Ep:125, loss:0.00000, loss_test:0.10571, lr:4.48e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.919, tt:5281.816\n",
      "Ep:126, loss:0.00000, loss_test:0.10758, lr:4.43e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.909, tt:5322.484\n",
      "Ep:127, loss:0.00000, loss_test:0.10825, lr:4.39e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.914, tt:5364.951\n",
      "Ep:128, loss:0.00000, loss_test:0.10775, lr:4.34e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.915, tt:5407.069\n",
      "Ep:129, loss:0.00000, loss_test:0.10731, lr:4.30e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.931, tt:5451.049\n",
      "Ep:130, loss:0.00000, loss_test:0.10715, lr:4.26e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.934, tt:5493.313\n",
      "Ep:131, loss:0.00000, loss_test:0.10749, lr:4.21e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.934, tt:5535.340\n",
      "Ep:132, loss:0.00000, loss_test:0.10749, lr:4.17e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.939, tt:5577.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.10854, lr:4.13e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.920, tt:5617.241\n",
      "Ep:134, loss:0.00000, loss_test:0.10857, lr:4.09e-03, fs:0.78621 (r=0.655,p=0.983),  time:41.926, tt:5660.041\n",
      "Ep:135, loss:0.00000, loss_test:0.10832, lr:4.05e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.924, tt:5701.611\n",
      "Ep:136, loss:0.00000, loss_test:0.10799, lr:4.01e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.920, tt:5743.094\n",
      "Ep:137, loss:0.00000, loss_test:0.10835, lr:3.97e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.933, tt:5786.692\n",
      "Ep:138, loss:0.00000, loss_test:0.10928, lr:3.93e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.920, tt:5826.862\n",
      "Ep:139, loss:0.00000, loss_test:0.10869, lr:3.89e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.922, tt:5869.122\n",
      "Ep:140, loss:0.00000, loss_test:0.10803, lr:3.85e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.925, tt:5911.456\n",
      "Ep:141, loss:0.00000, loss_test:0.10917, lr:3.81e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.920, tt:5952.697\n",
      "Ep:142, loss:0.00000, loss_test:0.10883, lr:3.77e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.912, tt:5993.394\n",
      "Ep:143, loss:0.00000, loss_test:0.10998, lr:3.73e-03, fs:0.78621 (r=0.655,p=0.983),  time:41.917, tt:6036.000\n",
      "Ep:144, loss:0.00000, loss_test:0.10944, lr:3.70e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.908, tt:6076.706\n",
      "Ep:145, loss:0.00000, loss_test:0.11014, lr:3.66e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.914, tt:6119.439\n",
      "Ep:146, loss:0.00000, loss_test:0.10951, lr:3.62e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.921, tt:6162.399\n",
      "Ep:147, loss:0.00000, loss_test:0.11004, lr:3.59e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.927, tt:6205.170\n",
      "Ep:148, loss:0.00000, loss_test:0.11091, lr:3.55e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.919, tt:6245.988\n",
      "Ep:149, loss:0.00000, loss_test:0.11016, lr:3.52e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.928, tt:6289.212\n",
      "Ep:150, loss:0.00000, loss_test:0.10983, lr:3.48e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.932, tt:6331.768\n",
      "Ep:151, loss:0.00000, loss_test:0.11034, lr:3.45e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.932, tt:6373.724\n",
      "Ep:152, loss:0.00000, loss_test:0.11076, lr:3.41e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.938, tt:6416.504\n",
      "Ep:153, loss:0.00000, loss_test:0.11031, lr:3.38e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.946, tt:6459.759\n",
      "Ep:154, loss:0.00000, loss_test:0.11045, lr:3.34e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.949, tt:6502.078\n",
      "Ep:155, loss:0.00000, loss_test:0.11076, lr:3.31e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.952, tt:6544.490\n",
      "Ep:156, loss:0.00000, loss_test:0.11062, lr:3.28e-03, fs:0.78621 (r=0.655,p=0.983),  time:41.963, tt:6588.266\n",
      "Ep:157, loss:0.00000, loss_test:0.11131, lr:3.24e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.973, tt:6631.752\n",
      "Ep:158, loss:0.00000, loss_test:0.11102, lr:3.21e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.980, tt:6674.779\n",
      "Ep:159, loss:0.00000, loss_test:0.11143, lr:3.18e-03, fs:0.78621 (r=0.655,p=0.983),  time:41.973, tt:6715.610\n",
      "Ep:160, loss:0.00000, loss_test:0.11183, lr:3.15e-03, fs:0.78082 (r=0.655,p=0.966),  time:41.982, tt:6759.114\n",
      "Ep:161, loss:0.00000, loss_test:0.11210, lr:3.12e-03, fs:0.78621 (r=0.655,p=0.983),  time:41.992, tt:6802.678\n",
      "Ep:162, loss:0.00000, loss_test:0.11207, lr:3.09e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.001, tt:6846.104\n",
      "Ep:163, loss:0.00000, loss_test:0.11150, lr:3.05e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.007, tt:6889.102\n",
      "Ep:164, loss:0.00000, loss_test:0.11206, lr:3.02e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.017, tt:6932.861\n",
      "Ep:165, loss:0.00000, loss_test:0.11250, lr:2.99e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.036, tt:6977.918\n",
      "Ep:166, loss:0.00000, loss_test:0.11205, lr:2.96e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.038, tt:7020.313\n",
      "Ep:167, loss:0.00000, loss_test:0.11242, lr:2.93e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.050, tt:7064.352\n",
      "Ep:168, loss:0.00000, loss_test:0.11279, lr:2.90e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.064, tt:7108.759\n",
      "Ep:169, loss:0.00000, loss_test:0.11221, lr:2.88e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.062, tt:7150.566\n",
      "Ep:170, loss:0.00000, loss_test:0.11275, lr:2.85e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.065, tt:7193.090\n",
      "Ep:171, loss:0.00000, loss_test:0.11279, lr:2.82e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.065, tt:7235.126\n",
      "Ep:172, loss:0.00000, loss_test:0.11228, lr:2.79e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.066, tt:7277.353\n",
      "Ep:173, loss:0.00000, loss_test:0.11290, lr:2.76e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.072, tt:7320.588\n",
      "Ep:174, loss:0.00000, loss_test:0.11266, lr:2.73e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.079, tt:7363.882\n",
      "Ep:175, loss:0.00000, loss_test:0.11325, lr:2.71e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.081, tt:7406.282\n",
      "Ep:176, loss:0.00000, loss_test:0.11241, lr:2.68e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.083, tt:7448.661\n",
      "Ep:177, loss:0.00000, loss_test:0.11227, lr:2.65e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.095, tt:7492.847\n",
      "Ep:178, loss:0.00000, loss_test:0.11319, lr:2.63e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.098, tt:7535.577\n",
      "Ep:179, loss:0.00000, loss_test:0.11372, lr:2.60e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.111, tt:7580.005\n",
      "Ep:180, loss:0.00000, loss_test:0.11281, lr:2.57e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.106, tt:7621.193\n",
      "Ep:181, loss:0.00000, loss_test:0.11311, lr:2.55e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.112, tt:7664.433\n",
      "Ep:182, loss:0.00000, loss_test:0.11289, lr:2.52e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.120, tt:7708.041\n",
      "Ep:183, loss:0.00000, loss_test:0.11305, lr:2.50e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.123, tt:7750.693\n",
      "Ep:184, loss:0.00000, loss_test:0.11330, lr:2.47e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.128, tt:7793.688\n",
      "Ep:185, loss:0.00000, loss_test:0.11301, lr:2.45e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.142, tt:7838.389\n",
      "Ep:186, loss:0.00000, loss_test:0.11384, lr:2.42e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.150, tt:7882.135\n",
      "Ep:187, loss:0.00000, loss_test:0.11430, lr:2.40e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.153, tt:7924.702\n",
      "Ep:188, loss:0.00000, loss_test:0.11313, lr:2.38e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.154, tt:7967.152\n",
      "Ep:189, loss:0.00000, loss_test:0.11366, lr:2.35e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.157, tt:8009.914\n",
      "Ep:190, loss:0.00000, loss_test:0.11464, lr:2.33e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.158, tt:8052.177\n",
      "Ep:191, loss:0.00000, loss_test:0.11281, lr:2.31e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.169, tt:8096.402\n",
      "Ep:192, loss:0.00000, loss_test:0.11252, lr:2.28e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.162, tt:8137.220\n",
      "Ep:193, loss:0.00000, loss_test:0.11453, lr:2.26e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.165, tt:8180.002\n",
      "Ep:194, loss:0.00000, loss_test:0.11374, lr:2.24e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.176, tt:8224.389\n",
      "Ep:195, loss:0.00000, loss_test:0.11331, lr:2.21e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.183, tt:8267.872\n",
      "Ep:196, loss:0.00000, loss_test:0.11367, lr:2.19e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.181, tt:8309.567\n",
      "Ep:197, loss:0.00000, loss_test:0.11312, lr:2.17e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.174, tt:8350.397\n",
      "Ep:198, loss:0.00000, loss_test:0.11366, lr:2.15e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.172, tt:8392.276\n",
      "Ep:199, loss:0.00000, loss_test:0.11467, lr:2.13e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.164, tt:8432.787\n",
      "Ep:200, loss:0.00000, loss_test:0.11394, lr:2.11e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.171, tt:8476.374\n",
      "Ep:201, loss:0.00000, loss_test:0.11277, lr:2.08e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.182, tt:8520.677\n",
      "Ep:202, loss:0.00000, loss_test:0.11388, lr:2.06e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.186, tt:8563.782\n",
      "Ep:203, loss:0.00000, loss_test:0.11478, lr:2.04e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.187, tt:8606.225\n",
      "Ep:204, loss:0.00000, loss_test:0.11355, lr:2.02e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.174, tt:8645.755\n",
      "Ep:205, loss:0.00000, loss_test:0.11242, lr:2.00e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.166, tt:8686.098\n",
      "Ep:206, loss:0.00000, loss_test:0.11349, lr:1.98e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.158, tt:8726.633\n",
      "Ep:207, loss:0.00000, loss_test:0.11401, lr:1.96e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.151, tt:8767.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.11358, lr:1.94e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.158, tt:8810.961\n",
      "Ep:209, loss:0.00000, loss_test:0.11348, lr:1.92e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.149, tt:8851.211\n",
      "Ep:210, loss:0.00000, loss_test:0.11381, lr:1.90e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.141, tt:8891.706\n",
      "Ep:211, loss:0.00000, loss_test:0.11306, lr:1.89e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.111, tt:8927.629\n",
      "Ep:212, loss:0.00000, loss_test:0.11326, lr:1.87e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.056, tt:8957.952\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02168, lr:6.00e-02, fs:0.64629 (r=0.851,p=0.521),  time:30.113, tt:30.113\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:33.279, tt:66.559\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02296, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.516, tt:106.549\n",
      "Ep:3, loss:0.00004, loss_test:0.02188, lr:6.00e-02, fs:0.65370 (r=0.966,p=0.494),  time:37.331, tt:149.326\n",
      "Ep:4, loss:0.00004, loss_test:0.02084, lr:6.00e-02, fs:0.65021 (r=0.908,p=0.506),  time:37.823, tt:189.116\n",
      "Ep:5, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.65403 (r=0.793,p=0.556),  time:38.063, tt:228.380\n",
      "Ep:6, loss:0.00004, loss_test:0.02197, lr:6.00e-02, fs:0.62245 (r=0.701,p=0.560),  time:38.402, tt:268.815\n",
      "Ep:7, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.63158 (r=0.690,p=0.583),  time:38.640, tt:309.119\n",
      "Ep:8, loss:0.00003, loss_test:0.02032, lr:6.00e-02, fs:0.61386 (r=0.713,p=0.539),  time:39.109, tt:351.983\n",
      "Ep:9, loss:0.00003, loss_test:0.01927, lr:6.00e-02, fs:0.66055 (r=0.828,p=0.550),  time:39.358, tt:393.578\n",
      "Ep:10, loss:0.00003, loss_test:0.01874, lr:6.00e-02, fs:0.66372 (r=0.862,p=0.540),  time:39.599, tt:435.588\n",
      "Ep:11, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.68182 (r=0.862,p=0.564),  time:39.556, tt:474.675\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.69856 (r=0.839,p=0.598),  time:39.679, tt:515.830\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.69000 (r=0.793,p=0.611),  time:39.749, tt:556.479\n",
      "Ep:14, loss:0.00003, loss_test:0.01733, lr:6.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:39.835, tt:597.522\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.74510 (r=0.874,p=0.650),  time:39.787, tt:636.598\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01603, lr:6.00e-02, fs:0.77934 (r=0.954,p=0.659),  time:39.987, tt:679.773\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.77934 (r=0.954,p=0.659),  time:40.132, tt:722.379\n",
      "Ep:18, loss:0.00003, loss_test:0.01519, lr:6.00e-02, fs:0.80193 (r=0.954,p=0.692),  time:40.151, tt:762.867\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01489, lr:6.00e-02, fs:0.80000 (r=0.943,p=0.695),  time:40.214, tt:804.290\n",
      "Ep:20, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.82178 (r=0.954,p=0.722),  time:40.237, tt:844.977\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.82178 (r=0.954,p=0.722),  time:40.207, tt:884.555\n",
      "Ep:22, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.81592 (r=0.943,p=0.719),  time:40.228, tt:925.239\n",
      "Ep:23, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.81592 (r=0.943,p=0.719),  time:40.246, tt:965.903\n",
      "Ep:24, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.82412 (r=0.943,p=0.732),  time:40.270, tt:1006.743\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:40.296, tt:1047.707\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:40.347, tt:1089.382\n",
      "Ep:27, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:40.346, tt:1129.689\n",
      "Ep:28, loss:0.00002, loss_test:0.01282, lr:6.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:40.312, tt:1169.042\n",
      "Ep:29, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.84103 (r=0.943,p=0.759),  time:40.336, tt:1210.077\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.84103 (r=0.943,p=0.759),  time:40.370, tt:1251.460\n",
      "Ep:31, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:40.428, tt:1293.687\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.85279 (r=0.966,p=0.764),  time:40.440, tt:1334.517\n",
      "Ep:33, loss:0.00002, loss_test:0.01239, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:40.410, tt:1373.956\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01233, lr:6.00e-02, fs:0.86154 (r=0.966,p=0.778),  time:40.459, tt:1416.059\n",
      "Ep:35, loss:0.00002, loss_test:0.01233, lr:6.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:40.479, tt:1457.242\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.88421 (r=0.966,p=0.816),  time:40.482, tt:1497.840\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01236, lr:6.00e-02, fs:0.88421 (r=0.966,p=0.816),  time:40.461, tt:1537.534\n",
      "Ep:38, loss:0.00002, loss_test:0.01231, lr:6.00e-02, fs:0.88421 (r=0.966,p=0.816),  time:40.457, tt:1577.816\n",
      "Ep:39, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.88421 (r=0.966,p=0.816),  time:40.486, tt:1619.432\n",
      "Ep:40, loss:0.00002, loss_test:0.01235, lr:6.00e-02, fs:0.88889 (r=0.966,p=0.824),  time:40.451, tt:1658.498\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01233, lr:6.00e-02, fs:0.88298 (r=0.954,p=0.822),  time:40.473, tt:1699.854\n",
      "Ep:42, loss:0.00001, loss_test:0.01240, lr:6.00e-02, fs:0.88172 (r=0.943,p=0.828),  time:40.457, tt:1739.658\n",
      "Ep:43, loss:0.00001, loss_test:0.01249, lr:6.00e-02, fs:0.87432 (r=0.920,p=0.833),  time:40.401, tt:1777.661\n",
      "Ep:44, loss:0.00001, loss_test:0.01253, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:40.379, tt:1817.060\n",
      "Ep:45, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:40.348, tt:1856.003\n",
      "Ep:46, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:40.373, tt:1897.553\n",
      "Ep:47, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:40.357, tt:1937.152\n",
      "Ep:48, loss:0.00001, loss_test:0.01277, lr:6.00e-02, fs:0.86034 (r=0.885,p=0.837),  time:40.379, tt:1978.583\n",
      "Ep:49, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.86857 (r=0.874,p=0.864),  time:40.417, tt:2020.847\n",
      "Ep:50, loss:0.00001, loss_test:0.01292, lr:6.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:40.395, tt:2060.159\n",
      "Ep:51, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:40.373, tt:2099.387\n",
      "Ep:52, loss:0.00001, loss_test:0.01324, lr:5.94e-02, fs:0.83721 (r=0.828,p=0.847),  time:40.377, tt:2139.979\n",
      "Ep:53, loss:0.00001, loss_test:0.01317, lr:5.88e-02, fs:0.85057 (r=0.851,p=0.851),  time:40.382, tt:2180.633\n",
      "Ep:54, loss:0.00001, loss_test:0.01335, lr:5.82e-02, fs:0.84884 (r=0.839,p=0.859),  time:40.372, tt:2220.461\n",
      "Ep:55, loss:0.00001, loss_test:0.01349, lr:5.76e-02, fs:0.84211 (r=0.828,p=0.857),  time:40.392, tt:2261.948\n",
      "Ep:56, loss:0.00001, loss_test:0.01354, lr:5.71e-02, fs:0.83529 (r=0.816,p=0.855),  time:40.416, tt:2303.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01362, lr:5.65e-02, fs:0.82840 (r=0.805,p=0.854),  time:40.399, tt:2343.169\n",
      "Ep:58, loss:0.00001, loss_test:0.01380, lr:5.59e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.428, tt:2385.271\n",
      "Ep:59, loss:0.00001, loss_test:0.01383, lr:5.54e-02, fs:0.82840 (r=0.805,p=0.854),  time:40.433, tt:2425.988\n",
      "Ep:60, loss:0.00001, loss_test:0.01392, lr:5.48e-02, fs:0.82840 (r=0.805,p=0.854),  time:40.451, tt:2467.531\n",
      "Ep:61, loss:0.00001, loss_test:0.01406, lr:5.43e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.484, tt:2510.026\n",
      "Ep:62, loss:0.00001, loss_test:0.01416, lr:5.37e-02, fs:0.80000 (r=0.759,p=0.846),  time:40.508, tt:2552.005\n",
      "Ep:63, loss:0.00001, loss_test:0.01429, lr:5.32e-02, fs:0.80000 (r=0.759,p=0.846),  time:40.492, tt:2591.485\n",
      "Ep:64, loss:0.00001, loss_test:0.01439, lr:5.27e-02, fs:0.78528 (r=0.736,p=0.842),  time:40.472, tt:2630.655\n",
      "Ep:65, loss:0.00001, loss_test:0.01448, lr:5.21e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.482, tt:2671.810\n",
      "Ep:66, loss:0.00001, loss_test:0.01469, lr:5.16e-02, fs:0.78261 (r=0.724,p=0.851),  time:40.480, tt:2712.152\n",
      "Ep:67, loss:0.00001, loss_test:0.01475, lr:5.11e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.488, tt:2753.198\n",
      "Ep:68, loss:0.00001, loss_test:0.01484, lr:5.06e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.491, tt:2793.860\n",
      "Ep:69, loss:0.00001, loss_test:0.01500, lr:5.01e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.499, tt:2834.959\n",
      "Ep:70, loss:0.00001, loss_test:0.01515, lr:4.96e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.518, tt:2876.773\n",
      "Ep:71, loss:0.00001, loss_test:0.01515, lr:4.91e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.504, tt:2916.282\n",
      "Ep:72, loss:0.00001, loss_test:0.01521, lr:4.86e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.465, tt:2953.917\n",
      "Ep:73, loss:0.00001, loss_test:0.01545, lr:4.81e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.479, tt:2995.423\n",
      "Ep:74, loss:0.00001, loss_test:0.01553, lr:4.76e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.466, tt:3034.934\n",
      "Ep:75, loss:0.00001, loss_test:0.01562, lr:4.71e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.473, tt:3075.985\n",
      "Ep:76, loss:0.00001, loss_test:0.01570, lr:4.67e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.486, tt:3117.409\n",
      "Ep:77, loss:0.00001, loss_test:0.01578, lr:4.62e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.491, tt:3158.305\n",
      "Ep:78, loss:0.00001, loss_test:0.01602, lr:4.57e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.465, tt:3196.748\n",
      "Ep:79, loss:0.00001, loss_test:0.01611, lr:4.53e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.464, tt:3237.102\n",
      "Ep:80, loss:0.00001, loss_test:0.01601, lr:4.48e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.492, tt:3279.884\n",
      "Ep:81, loss:0.00001, loss_test:0.01625, lr:4.44e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.481, tt:3319.424\n",
      "Ep:82, loss:0.00001, loss_test:0.01636, lr:4.39e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.469, tt:3358.909\n",
      "Ep:83, loss:0.00001, loss_test:0.01633, lr:4.35e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.484, tt:3400.667\n",
      "Ep:84, loss:0.00001, loss_test:0.01648, lr:4.31e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.488, tt:3441.491\n",
      "Ep:85, loss:0.00001, loss_test:0.01666, lr:4.26e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.500, tt:3483.012\n",
      "Ep:86, loss:0.00001, loss_test:0.01671, lr:4.22e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.514, tt:3524.748\n",
      "Ep:87, loss:0.00001, loss_test:0.01670, lr:4.18e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.535, tt:3567.048\n",
      "Ep:88, loss:0.00001, loss_test:0.01690, lr:4.14e-02, fs:0.77632 (r=0.678,p=0.908),  time:40.531, tt:3607.262\n",
      "Ep:89, loss:0.00001, loss_test:0.01698, lr:4.10e-02, fs:0.77632 (r=0.678,p=0.908),  time:40.552, tt:3649.653\n",
      "Ep:90, loss:0.00001, loss_test:0.01704, lr:4.05e-02, fs:0.77632 (r=0.678,p=0.908),  time:40.572, tt:3692.045\n",
      "Ep:91, loss:0.00001, loss_test:0.01716, lr:4.01e-02, fs:0.77632 (r=0.678,p=0.908),  time:40.559, tt:3731.410\n",
      "Ep:92, loss:0.00001, loss_test:0.01733, lr:3.97e-02, fs:0.76821 (r=0.667,p=0.906),  time:40.562, tt:3772.260\n",
      "Ep:93, loss:0.00001, loss_test:0.01735, lr:3.93e-02, fs:0.76821 (r=0.667,p=0.906),  time:40.579, tt:3814.383\n",
      "Ep:94, loss:0.00001, loss_test:0.01735, lr:3.89e-02, fs:0.77632 (r=0.678,p=0.908),  time:40.585, tt:3855.605\n",
      "Ep:95, loss:0.00001, loss_test:0.01749, lr:3.86e-02, fs:0.76821 (r=0.667,p=0.906),  time:40.609, tt:3898.428\n",
      "Ep:96, loss:0.00001, loss_test:0.01752, lr:3.82e-02, fs:0.76821 (r=0.667,p=0.906),  time:40.622, tt:3940.314\n",
      "Ep:97, loss:0.00001, loss_test:0.01769, lr:3.78e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.634, tt:3982.176\n",
      "Ep:98, loss:0.00001, loss_test:0.01776, lr:3.74e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.647, tt:4024.072\n",
      "Ep:99, loss:0.00001, loss_test:0.01782, lr:3.70e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.642, tt:4064.176\n",
      "Ep:100, loss:0.00001, loss_test:0.01793, lr:3.67e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.655, tt:4106.202\n",
      "Ep:101, loss:0.00001, loss_test:0.01798, lr:3.63e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.651, tt:4146.361\n",
      "Ep:102, loss:0.00001, loss_test:0.01804, lr:3.59e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.651, tt:4187.028\n",
      "Ep:103, loss:0.00001, loss_test:0.01809, lr:3.56e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.642, tt:4226.814\n",
      "Ep:104, loss:0.00001, loss_test:0.01820, lr:3.52e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.646, tt:4267.871\n",
      "Ep:105, loss:0.00001, loss_test:0.01830, lr:3.49e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.658, tt:4309.737\n",
      "Ep:106, loss:0.00001, loss_test:0.01832, lr:3.45e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.663, tt:4350.892\n",
      "Ep:107, loss:0.00001, loss_test:0.01840, lr:3.42e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.666, tt:4391.903\n",
      "Ep:108, loss:0.00001, loss_test:0.01846, lr:3.38e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.664, tt:4432.358\n",
      "Ep:109, loss:0.00001, loss_test:0.01849, lr:3.35e-02, fs:0.76000 (r=0.655,p=0.905),  time:40.664, tt:4473.062\n",
      "Ep:110, loss:0.00001, loss_test:0.01850, lr:3.32e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.671, tt:4514.468\n",
      "Ep:111, loss:0.00001, loss_test:0.01870, lr:3.28e-02, fs:0.77027 (r=0.655,p=0.934),  time:40.663, tt:4554.248\n",
      "Ep:112, loss:0.00001, loss_test:0.01876, lr:3.25e-02, fs:0.77027 (r=0.655,p=0.934),  time:40.700, tt:4599.123\n",
      "Ep:113, loss:0.00001, loss_test:0.01874, lr:3.22e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.695, tt:4639.183\n",
      "Ep:114, loss:0.00000, loss_test:0.01881, lr:3.19e-02, fs:0.76510 (r=0.655,p=0.919),  time:40.698, tt:4680.229\n",
      "Ep:115, loss:0.00000, loss_test:0.01897, lr:3.15e-02, fs:0.77027 (r=0.655,p=0.934),  time:40.691, tt:4720.188\n",
      "Ep:116, loss:0.00000, loss_test:0.01898, lr:3.12e-02, fs:0.77027 (r=0.655,p=0.934),  time:40.690, tt:4760.743\n",
      "Ep:117, loss:0.00000, loss_test:0.01904, lr:3.09e-02, fs:0.77027 (r=0.655,p=0.934),  time:40.688, tt:4801.209\n",
      "Ep:118, loss:0.00000, loss_test:0.01912, lr:3.06e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.702, tt:4843.488\n",
      "Ep:119, loss:0.00000, loss_test:0.01917, lr:3.03e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.696, tt:4883.525\n",
      "Ep:120, loss:0.00000, loss_test:0.01922, lr:3.00e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.707, tt:4925.535\n",
      "Ep:121, loss:0.00000, loss_test:0.01925, lr:2.97e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.722, tt:4968.061\n",
      "Ep:122, loss:0.00000, loss_test:0.01943, lr:2.94e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.723, tt:5008.964\n",
      "Ep:123, loss:0.00000, loss_test:0.01938, lr:2.91e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.724, tt:5049.730\n",
      "Ep:124, loss:0.00000, loss_test:0.01939, lr:2.88e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.731, tt:5091.329\n",
      "Ep:125, loss:0.00000, loss_test:0.01961, lr:2.85e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.709, tt:5129.324\n",
      "Ep:126, loss:0.00000, loss_test:0.01963, lr:2.82e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.689, tt:5167.566\n",
      "Ep:127, loss:0.00000, loss_test:0.01957, lr:2.80e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.684, tt:5207.602\n",
      "Ep:128, loss:0.00000, loss_test:0.01967, lr:2.77e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.694, tt:5249.497\n",
      "Ep:129, loss:0.00000, loss_test:0.01974, lr:2.74e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.718, tt:5293.399\n",
      "Ep:130, loss:0.00000, loss_test:0.01981, lr:2.71e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.712, tt:5333.289\n",
      "Ep:131, loss:0.00000, loss_test:0.01987, lr:2.69e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.715, tt:5374.423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01995, lr:2.66e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.715, tt:5415.121\n",
      "Ep:133, loss:0.00000, loss_test:0.01989, lr:2.63e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.709, tt:5455.021\n",
      "Ep:134, loss:0.00000, loss_test:0.02006, lr:2.61e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.710, tt:5495.787\n",
      "Ep:135, loss:0.00000, loss_test:0.02006, lr:2.58e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.715, tt:5537.252\n",
      "Ep:136, loss:0.00000, loss_test:0.02012, lr:2.55e-02, fs:0.77551 (r=0.655,p=0.950),  time:40.708, tt:5577.031\n",
      "Ep:137, loss:0.00000, loss_test:0.02016, lr:2.53e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.706, tt:5617.441\n",
      "Ep:138, loss:0.00000, loss_test:0.02023, lr:2.50e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.710, tt:5658.733\n",
      "Ep:139, loss:0.00000, loss_test:0.02024, lr:2.48e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.712, tt:5699.715\n",
      "Ep:140, loss:0.00000, loss_test:0.02027, lr:2.45e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.689, tt:5737.138\n",
      "Ep:141, loss:0.00000, loss_test:0.02039, lr:2.43e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.681, tt:5776.740\n",
      "Ep:142, loss:0.00000, loss_test:0.02041, lr:2.40e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.672, tt:5816.047\n",
      "Ep:143, loss:0.00000, loss_test:0.02044, lr:2.38e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.661, tt:5855.235\n",
      "Ep:144, loss:0.00000, loss_test:0.02053, lr:2.36e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.644, tt:5893.344\n",
      "Ep:145, loss:0.00000, loss_test:0.02058, lr:2.33e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.636, tt:5932.895\n",
      "Ep:146, loss:0.00000, loss_test:0.02057, lr:2.31e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.659, tt:5976.927\n",
      "Ep:147, loss:0.00000, loss_test:0.02060, lr:2.29e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.652, tt:6016.463\n",
      "Ep:148, loss:0.00000, loss_test:0.02070, lr:2.26e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.640, tt:6055.321\n",
      "Ep:149, loss:0.00000, loss_test:0.02072, lr:2.24e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:6095.486\n",
      "Ep:150, loss:0.00000, loss_test:0.02076, lr:2.22e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:6136.142\n",
      "Ep:151, loss:0.00000, loss_test:0.02082, lr:2.20e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.635, tt:6176.457\n",
      "Ep:152, loss:0.00000, loss_test:0.02083, lr:2.17e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.634, tt:6216.985\n",
      "Ep:153, loss:0.00000, loss_test:0.02092, lr:2.15e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.635, tt:6257.719\n",
      "Ep:154, loss:0.00000, loss_test:0.02095, lr:2.13e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.627, tt:6297.262\n",
      "Ep:155, loss:0.00000, loss_test:0.02093, lr:2.11e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.630, tt:6338.221\n",
      "Ep:156, loss:0.00000, loss_test:0.02099, lr:2.09e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.626, tt:6378.356\n",
      "Ep:157, loss:0.00000, loss_test:0.02107, lr:2.07e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.619, tt:6417.790\n",
      "Ep:158, loss:0.00000, loss_test:0.02113, lr:2.05e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.610, tt:6456.980\n",
      "Ep:159, loss:0.00000, loss_test:0.02113, lr:2.03e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.611, tt:6497.744\n",
      "Ep:160, loss:0.00000, loss_test:0.02117, lr:2.01e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.610, tt:6538.226\n",
      "Ep:161, loss:0.00000, loss_test:0.02124, lr:1.99e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.607, tt:6578.287\n",
      "Ep:162, loss:0.00000, loss_test:0.02120, lr:1.97e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.609, tt:6619.257\n",
      "Ep:163, loss:0.00000, loss_test:0.02128, lr:1.95e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.614, tt:6660.734\n",
      "Ep:164, loss:0.00000, loss_test:0.02136, lr:1.93e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.620, tt:6702.293\n",
      "Ep:165, loss:0.00000, loss_test:0.02141, lr:1.91e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.622, tt:6743.280\n",
      "Ep:166, loss:0.00000, loss_test:0.02140, lr:1.89e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.631, tt:6785.438\n",
      "Ep:167, loss:0.00000, loss_test:0.02141, lr:1.87e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:6826.980\n",
      "Ep:168, loss:0.00000, loss_test:0.02156, lr:1.85e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.639, tt:6868.054\n",
      "Ep:169, loss:0.00000, loss_test:0.02155, lr:1.83e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.636, tt:6908.091\n",
      "Ep:170, loss:0.00000, loss_test:0.02153, lr:1.81e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.638, tt:6949.045\n",
      "Ep:171, loss:0.00000, loss_test:0.02156, lr:1.80e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.639, tt:6989.893\n",
      "Ep:172, loss:0.00000, loss_test:0.02165, lr:1.78e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.630, tt:7029.044\n",
      "Ep:173, loss:0.00000, loss_test:0.02168, lr:1.76e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.631, tt:7069.739\n",
      "Ep:174, loss:0.00000, loss_test:0.02167, lr:1.74e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.638, tt:7111.593\n",
      "Ep:175, loss:0.00000, loss_test:0.02171, lr:1.73e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.629, tt:7150.674\n",
      "Ep:176, loss:0.00000, loss_test:0.02177, lr:1.71e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.623, tt:7190.253\n",
      "Ep:177, loss:0.00000, loss_test:0.02181, lr:1.69e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.622, tt:7230.792\n",
      "Ep:178, loss:0.00000, loss_test:0.02180, lr:1.67e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.622, tt:7271.372\n",
      "Ep:179, loss:0.00000, loss_test:0.02184, lr:1.66e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:7314.742\n",
      "Ep:180, loss:0.00000, loss_test:0.02192, lr:1.64e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.635, tt:7354.974\n",
      "Ep:181, loss:0.00000, loss_test:0.02193, lr:1.62e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.633, tt:7395.159\n",
      "Ep:182, loss:0.00000, loss_test:0.02194, lr:1.61e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.622, tt:7433.745\n",
      "Ep:183, loss:0.00000, loss_test:0.02200, lr:1.59e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.624, tt:7474.848\n",
      "Ep:184, loss:0.00000, loss_test:0.02208, lr:1.58e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.626, tt:7515.751\n",
      "Ep:185, loss:0.00000, loss_test:0.02207, lr:1.56e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.611, tt:7553.562\n",
      "Ep:186, loss:0.00000, loss_test:0.02207, lr:1.54e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.610, tt:7594.157\n",
      "Ep:187, loss:0.00000, loss_test:0.02213, lr:1.53e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.611, tt:7634.910\n",
      "Ep:188, loss:0.00000, loss_test:0.02217, lr:1.51e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.610, tt:7675.334\n",
      "Ep:189, loss:0.00000, loss_test:0.02212, lr:1.50e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.604, tt:7714.825\n",
      "Ep:190, loss:0.00000, loss_test:0.02219, lr:1.48e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.607, tt:7755.963\n",
      "Ep:191, loss:0.00000, loss_test:0.02224, lr:1.47e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.606, tt:7796.346\n",
      "Ep:192, loss:0.00000, loss_test:0.02229, lr:1.45e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.601, tt:7835.901\n",
      "Ep:193, loss:0.00000, loss_test:0.02226, lr:1.44e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.601, tt:7876.652\n",
      "Ep:194, loss:0.00000, loss_test:0.02230, lr:1.43e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.600, tt:7917.095\n",
      "Ep:195, loss:0.00000, loss_test:0.02232, lr:1.41e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.602, tt:7957.940\n",
      "Ep:196, loss:0.00000, loss_test:0.02234, lr:1.40e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.614, tt:8001.027\n",
      "Ep:197, loss:0.00000, loss_test:0.02235, lr:1.38e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.617, tt:8042.162\n",
      "Ep:198, loss:0.00000, loss_test:0.02240, lr:1.37e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.623, tt:8083.889\n",
      "Ep:199, loss:0.00000, loss_test:0.02243, lr:1.36e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.619, tt:8123.807\n",
      "Ep:200, loss:0.00000, loss_test:0.02248, lr:1.34e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.630, tt:8166.694\n",
      "Ep:201, loss:0.00000, loss_test:0.02248, lr:1.33e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.630, tt:8207.245\n",
      "Ep:202, loss:0.00000, loss_test:0.02250, lr:1.32e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.631, tt:8248.091\n",
      "Ep:203, loss:0.00000, loss_test:0.02256, lr:1.30e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:8290.003\n",
      "Ep:204, loss:0.00000, loss_test:0.02258, lr:1.29e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.637, tt:8330.619\n",
      "Ep:205, loss:0.00000, loss_test:0.02258, lr:1.28e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.631, tt:8370.017\n",
      "Ep:206, loss:0.00000, loss_test:0.02257, lr:1.26e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.623, tt:8409.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02265, lr:1.25e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.629, tt:8450.866\n",
      "Ep:208, loss:0.00000, loss_test:0.02265, lr:1.24e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.651, tt:8496.000\n",
      "Ep:209, loss:0.00000, loss_test:0.02267, lr:1.23e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.656, tt:8537.785\n",
      "Ep:210, loss:0.00000, loss_test:0.02269, lr:1.21e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.659, tt:8579.083\n",
      "Ep:211, loss:0.00000, loss_test:0.02270, lr:1.20e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.642, tt:8616.038\n",
      "Ep:212, loss:0.00000, loss_test:0.02275, lr:1.19e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.628, tt:8653.768\n",
      "Ep:213, loss:0.00000, loss_test:0.02276, lr:1.18e-02, fs:0.78082 (r=0.655,p=0.966),  time:40.596, tt:8687.636\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14357, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.318, tt:36.318\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14174, lr:1.00e-02, fs:0.64567 (r=0.943,p=0.491),  time:35.530, tt:71.059\n",
      "Ep:2, loss:0.00027, loss_test:0.13809, lr:1.00e-02, fs:0.64000 (r=0.920,p=0.491),  time:36.347, tt:109.042\n",
      "Ep:3, loss:0.00026, loss_test:0.13180, lr:1.00e-02, fs:0.64103 (r=0.862,p=0.510),  time:37.341, tt:149.365\n",
      "Ep:4, loss:0.00025, loss_test:0.12397, lr:1.00e-02, fs:0.68599 (r=0.816,p=0.592),  time:37.743, tt:188.716\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.12046, lr:1.00e-02, fs:0.67760 (r=0.713,p=0.646),  time:38.020, tt:228.120\n",
      "Ep:6, loss:0.00022, loss_test:0.11904, lr:1.00e-02, fs:0.67391 (r=0.713,p=0.639),  time:38.434, tt:269.040\n",
      "Ep:7, loss:0.00022, loss_test:0.11851, lr:1.00e-02, fs:0.64615 (r=0.724,p=0.583),  time:38.741, tt:309.930\n",
      "Ep:8, loss:0.00021, loss_test:0.11391, lr:1.00e-02, fs:0.68927 (r=0.701,p=0.678),  time:38.741, tt:348.673\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11113, lr:1.00e-02, fs:0.67456 (r=0.655,p=0.695),  time:39.087, tt:390.865\n",
      "Ep:10, loss:0.00020, loss_test:0.10887, lr:1.00e-02, fs:0.69945 (r=0.736,p=0.667),  time:39.320, tt:432.521\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10739, lr:1.00e-02, fs:0.69565 (r=0.736,p=0.660),  time:39.444, tt:473.330\n",
      "Ep:12, loss:0.00018, loss_test:0.10479, lr:1.00e-02, fs:0.71186 (r=0.724,p=0.700),  time:39.482, tt:513.266\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10158, lr:1.00e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.571, tt:553.993\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09849, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:40.007, tt:600.102\n",
      "Ep:15, loss:0.00017, loss_test:0.09618, lr:1.00e-02, fs:0.77348 (r=0.805,p=0.745),  time:40.075, tt:641.203\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09314, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:40.044, tt:680.754\n",
      "Ep:17, loss:0.00015, loss_test:0.09115, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:40.113, tt:722.030\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08940, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:40.137, tt:762.602\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08742, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:40.064, tt:801.286\n",
      "Ep:20, loss:0.00014, loss_test:0.08506, lr:1.00e-02, fs:0.85263 (r=0.931,p=0.786),  time:40.004, tt:840.090\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08403, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:40.047, tt:881.041\n",
      "Ep:22, loss:0.00013, loss_test:0.08127, lr:1.00e-02, fs:0.86010 (r=0.954,p=0.783),  time:40.092, tt:922.120\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07941, lr:1.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:40.140, tt:963.363\n",
      "Ep:24, loss:0.00012, loss_test:0.07969, lr:1.00e-02, fs:0.85263 (r=0.931,p=0.786),  time:40.162, tt:1004.038\n",
      "Ep:25, loss:0.00011, loss_test:0.07738, lr:1.00e-02, fs:0.84946 (r=0.908,p=0.798),  time:40.165, tt:1044.286\n",
      "Ep:26, loss:0.00011, loss_test:0.07783, lr:1.00e-02, fs:0.86772 (r=0.943,p=0.804),  time:40.189, tt:1085.097\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.07508, lr:1.00e-02, fs:0.83243 (r=0.885,p=0.786),  time:40.174, tt:1124.886\n",
      "Ep:28, loss:0.00010, loss_test:0.07778, lr:1.00e-02, fs:0.85246 (r=0.897,p=0.812),  time:40.177, tt:1165.125\n",
      "Ep:29, loss:0.00010, loss_test:0.07500, lr:1.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:40.186, tt:1205.580\n",
      "Ep:30, loss:0.00009, loss_test:0.07512, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:40.169, tt:1245.254\n",
      "Ep:31, loss:0.00009, loss_test:0.07761, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.204, tt:1286.514\n",
      "Ep:32, loss:0.00009, loss_test:0.07473, lr:1.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:40.156, tt:1325.132\n",
      "Ep:33, loss:0.00009, loss_test:0.07433, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:40.182, tt:1366.203\n",
      "Ep:34, loss:0.00008, loss_test:0.07547, lr:1.00e-02, fs:0.84270 (r=0.862,p=0.824),  time:40.231, tt:1408.102\n",
      "Ep:35, loss:0.00008, loss_test:0.07357, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:40.234, tt:1448.415\n",
      "Ep:36, loss:0.00007, loss_test:0.07541, lr:1.00e-02, fs:0.84091 (r=0.851,p=0.831),  time:40.302, tt:1491.166\n",
      "Ep:37, loss:0.00007, loss_test:0.07825, lr:1.00e-02, fs:0.79762 (r=0.770,p=0.827),  time:40.291, tt:1531.041\n",
      "Ep:38, loss:0.00007, loss_test:0.07213, lr:9.90e-03, fs:0.83799 (r=0.862,p=0.815),  time:40.319, tt:1572.444\n",
      "Ep:39, loss:0.00007, loss_test:0.07943, lr:9.80e-03, fs:0.76543 (r=0.713,p=0.827),  time:40.369, tt:1614.746\n",
      "Ep:40, loss:0.00006, loss_test:0.07695, lr:9.70e-03, fs:0.78571 (r=0.759,p=0.815),  time:40.337, tt:1653.801\n",
      "Ep:41, loss:0.00006, loss_test:0.07387, lr:9.61e-03, fs:0.83429 (r=0.839,p=0.830),  time:40.387, tt:1696.237\n",
      "Ep:42, loss:0.00006, loss_test:0.08140, lr:9.51e-03, fs:0.76074 (r=0.713,p=0.816),  time:40.416, tt:1737.908\n",
      "Ep:43, loss:0.00006, loss_test:0.08114, lr:9.41e-03, fs:0.78528 (r=0.736,p=0.842),  time:40.403, tt:1777.719\n",
      "Ep:44, loss:0.00005, loss_test:0.07263, lr:9.32e-03, fs:0.83237 (r=0.828,p=0.837),  time:40.443, tt:1819.946\n",
      "Ep:45, loss:0.00005, loss_test:0.08230, lr:9.23e-03, fs:0.77019 (r=0.713,p=0.838),  time:40.424, tt:1859.521\n",
      "Ep:46, loss:0.00005, loss_test:0.07786, lr:9.14e-03, fs:0.78313 (r=0.747,p=0.823),  time:40.396, tt:1898.632\n",
      "Ep:47, loss:0.00005, loss_test:0.08409, lr:9.04e-03, fs:0.77019 (r=0.713,p=0.838),  time:40.352, tt:1936.911\n",
      "Ep:48, loss:0.00004, loss_test:0.08002, lr:8.95e-03, fs:0.77301 (r=0.724,p=0.829),  time:40.339, tt:1976.628\n",
      "Ep:49, loss:0.00004, loss_test:0.08630, lr:8.86e-03, fs:0.77987 (r=0.713,p=0.861),  time:40.390, tt:2019.482\n",
      "Ep:50, loss:0.00004, loss_test:0.07734, lr:8.78e-03, fs:0.81657 (r=0.793,p=0.841),  time:40.383, tt:2059.538\n",
      "Ep:51, loss:0.00004, loss_test:0.08742, lr:8.69e-03, fs:0.77707 (r=0.701,p=0.871),  time:40.384, tt:2099.952\n",
      "Ep:52, loss:0.00004, loss_test:0.08579, lr:8.60e-03, fs:0.76433 (r=0.690,p=0.857),  time:40.408, tt:2141.627\n",
      "Ep:53, loss:0.00004, loss_test:0.08766, lr:8.51e-03, fs:0.78710 (r=0.701,p=0.897),  time:40.379, tt:2180.468\n",
      "Ep:54, loss:0.00004, loss_test:0.07872, lr:8.43e-03, fs:0.80000 (r=0.759,p=0.846),  time:40.346, tt:2219.044\n",
      "Ep:55, loss:0.00004, loss_test:0.09187, lr:8.35e-03, fs:0.76316 (r=0.667,p=0.892),  time:40.349, tt:2259.523\n",
      "Ep:56, loss:0.00004, loss_test:0.08159, lr:8.26e-03, fs:0.77987 (r=0.713,p=0.861),  time:40.378, tt:2301.526\n",
      "Ep:57, loss:0.00004, loss_test:0.08826, lr:8.18e-03, fs:0.75497 (r=0.655,p=0.891),  time:40.407, tt:2343.628\n",
      "Ep:58, loss:0.00003, loss_test:0.08711, lr:8.10e-03, fs:0.78981 (r=0.713,p=0.886),  time:40.424, tt:2385.002\n",
      "Ep:59, loss:0.00003, loss_test:0.08622, lr:8.02e-03, fs:0.77419 (r=0.690,p=0.882),  time:40.388, tt:2423.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.09318, lr:7.94e-03, fs:0.79221 (r=0.701,p=0.910),  time:40.392, tt:2463.918\n",
      "Ep:61, loss:0.00003, loss_test:0.08507, lr:7.86e-03, fs:0.78710 (r=0.701,p=0.897),  time:40.408, tt:2505.272\n",
      "Ep:62, loss:0.00003, loss_test:0.08987, lr:7.78e-03, fs:0.77124 (r=0.678,p=0.894),  time:40.407, tt:2545.648\n",
      "Ep:63, loss:0.00003, loss_test:0.08899, lr:7.70e-03, fs:0.78981 (r=0.713,p=0.886),  time:40.386, tt:2584.712\n",
      "Ep:64, loss:0.00003, loss_test:0.10410, lr:7.62e-03, fs:0.75342 (r=0.632,p=0.932),  time:40.397, tt:2625.836\n",
      "Ep:65, loss:0.00003, loss_test:0.08121, lr:7.55e-03, fs:0.76923 (r=0.690,p=0.870),  time:40.413, tt:2667.255\n",
      "Ep:66, loss:0.00003, loss_test:0.09672, lr:7.47e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.407, tt:2707.246\n",
      "Ep:67, loss:0.00002, loss_test:0.09145, lr:7.40e-03, fs:0.79221 (r=0.701,p=0.910),  time:40.435, tt:2749.559\n",
      "Ep:68, loss:0.00002, loss_test:0.09190, lr:7.32e-03, fs:0.78947 (r=0.690,p=0.923),  time:40.462, tt:2791.910\n",
      "Ep:69, loss:0.00002, loss_test:0.09685, lr:7.25e-03, fs:0.79739 (r=0.701,p=0.924),  time:40.480, tt:2833.597\n",
      "Ep:70, loss:0.00003, loss_test:0.08803, lr:7.18e-03, fs:0.75817 (r=0.667,p=0.879),  time:40.492, tt:2874.959\n",
      "Ep:71, loss:0.00002, loss_test:0.09329, lr:7.11e-03, fs:0.76000 (r=0.655,p=0.905),  time:40.498, tt:2915.831\n",
      "Ep:72, loss:0.00002, loss_test:0.09099, lr:7.03e-03, fs:0.76821 (r=0.667,p=0.906),  time:40.482, tt:2955.194\n",
      "Ep:73, loss:0.00002, loss_test:0.09253, lr:6.96e-03, fs:0.78431 (r=0.690,p=0.909),  time:40.478, tt:2995.381\n",
      "Ep:74, loss:0.00002, loss_test:0.09266, lr:6.89e-03, fs:0.79739 (r=0.701,p=0.924),  time:40.492, tt:3036.872\n",
      "Ep:75, loss:0.00002, loss_test:0.09398, lr:6.83e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.491, tt:3077.318\n",
      "Ep:76, loss:0.00002, loss_test:0.09774, lr:6.76e-03, fs:0.78667 (r=0.678,p=0.937),  time:40.476, tt:3116.645\n",
      "Ep:77, loss:0.00002, loss_test:0.09075, lr:6.69e-03, fs:0.78431 (r=0.690,p=0.909),  time:40.466, tt:3156.331\n",
      "Ep:78, loss:0.00002, loss_test:0.09863, lr:6.62e-03, fs:0.77027 (r=0.655,p=0.934),  time:40.475, tt:3197.539\n",
      "Ep:79, loss:0.00002, loss_test:0.09544, lr:6.56e-03, fs:0.76510 (r=0.655,p=0.919),  time:40.476, tt:3238.103\n",
      "Ep:80, loss:0.00002, loss_test:0.09113, lr:6.49e-03, fs:0.76000 (r=0.655,p=0.905),  time:40.472, tt:3278.268\n",
      "Ep:81, loss:0.00002, loss_test:0.09697, lr:6.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:40.468, tt:3318.371\n",
      "Ep:82, loss:0.00002, loss_test:0.09341, lr:6.36e-03, fs:0.78667 (r=0.678,p=0.937),  time:40.456, tt:3357.869\n",
      "Ep:83, loss:0.00001, loss_test:0.09429, lr:6.30e-03, fs:0.78947 (r=0.690,p=0.923),  time:40.480, tt:3400.341\n",
      "Ep:84, loss:0.00001, loss_test:0.09657, lr:6.24e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.461, tt:3439.160\n",
      "Ep:85, loss:0.00001, loss_test:0.08960, lr:6.17e-03, fs:0.78431 (r=0.690,p=0.909),  time:40.478, tt:3481.126\n",
      "Ep:86, loss:0.00001, loss_test:0.09475, lr:6.11e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.483, tt:3522.014\n",
      "Ep:87, loss:0.00001, loss_test:0.09365, lr:6.05e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.489, tt:3563.015\n",
      "Ep:88, loss:0.00001, loss_test:0.09305, lr:5.99e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.470, tt:3601.821\n",
      "Ep:89, loss:0.00001, loss_test:0.09445, lr:5.93e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.464, tt:3641.773\n",
      "Ep:90, loss:0.00001, loss_test:0.09156, lr:5.87e-03, fs:0.78431 (r=0.690,p=0.909),  time:40.460, tt:3681.849\n",
      "Ep:91, loss:0.00001, loss_test:0.09743, lr:5.81e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.482, tt:3724.332\n",
      "Ep:92, loss:0.00001, loss_test:0.09259, lr:5.75e-03, fs:0.79470 (r=0.690,p=0.938),  time:40.503, tt:3766.738\n",
      "Ep:93, loss:0.00001, loss_test:0.09338, lr:5.70e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.517, tt:3808.606\n",
      "Ep:94, loss:0.00001, loss_test:0.09317, lr:5.64e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.532, tt:3850.499\n",
      "Ep:95, loss:0.00001, loss_test:0.09073, lr:5.58e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.539, tt:3891.790\n",
      "Ep:96, loss:0.00001, loss_test:0.09567, lr:5.53e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.535, tt:3931.920\n",
      "Ep:97, loss:0.00001, loss_test:0.09615, lr:5.47e-03, fs:0.78378 (r=0.667,p=0.951),  time:40.545, tt:3973.420\n",
      "Ep:98, loss:0.00001, loss_test:0.09178, lr:5.42e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.538, tt:4013.278\n",
      "Ep:99, loss:0.00001, loss_test:0.09321, lr:5.36e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.550, tt:4054.958\n",
      "Ep:100, loss:0.00001, loss_test:0.09269, lr:5.31e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.533, tt:4093.882\n",
      "Ep:101, loss:0.00001, loss_test:0.09341, lr:5.26e-03, fs:0.79195 (r=0.678,p=0.952),  time:40.544, tt:4135.455\n",
      "Ep:102, loss:0.00001, loss_test:0.09177, lr:5.20e-03, fs:0.78667 (r=0.678,p=0.937),  time:40.550, tt:4176.640\n",
      "Ep:103, loss:0.00001, loss_test:0.09451, lr:5.15e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.556, tt:4217.875\n",
      "Ep:104, loss:0.00001, loss_test:0.09455, lr:5.10e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.563, tt:4259.158\n",
      "Ep:105, loss:0.00001, loss_test:0.09130, lr:5.05e-03, fs:0.80000 (r=0.690,p=0.952),  time:40.580, tt:4301.477\n",
      "Ep:106, loss:0.00001, loss_test:0.09296, lr:5.00e-03, fs:0.78378 (r=0.667,p=0.951),  time:40.587, tt:4342.824\n",
      "Ep:107, loss:0.00001, loss_test:0.09257, lr:4.95e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.611, tt:4385.982\n",
      "Ep:108, loss:0.00001, loss_test:0.09387, lr:4.90e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.615, tt:4427.002\n",
      "Ep:109, loss:0.00001, loss_test:0.09574, lr:4.85e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.616, tt:4467.720\n",
      "Ep:110, loss:0.00001, loss_test:0.09098, lr:4.80e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.613, tt:4508.072\n",
      "Ep:111, loss:0.00001, loss_test:0.09374, lr:4.75e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.608, tt:4548.147\n",
      "Ep:112, loss:0.00001, loss_test:0.09303, lr:4.71e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.613, tt:4589.298\n",
      "Ep:113, loss:0.00001, loss_test:0.09342, lr:4.66e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.609, tt:4629.465\n",
      "Ep:114, loss:0.00001, loss_test:0.09334, lr:4.61e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.620, tt:4671.268\n",
      "Ep:115, loss:0.00001, loss_test:0.09239, lr:4.57e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.625, tt:4712.500\n",
      "Ep:116, loss:0.00000, loss_test:0.09366, lr:4.52e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.629, tt:4753.592\n",
      "Ep:117, loss:0.00000, loss_test:0.09468, lr:4.48e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.641, tt:4795.595\n",
      "Ep:118, loss:0.00000, loss_test:0.09202, lr:4.43e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.642, tt:4836.385\n",
      "Ep:119, loss:0.00000, loss_test:0.09429, lr:4.39e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.676, tt:4881.133\n",
      "Ep:120, loss:0.00000, loss_test:0.09364, lr:4.34e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.684, tt:4922.790\n",
      "Ep:121, loss:0.00000, loss_test:0.09277, lr:4.30e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.674, tt:4962.213\n",
      "Ep:122, loss:0.00000, loss_test:0.09423, lr:4.26e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.680, tt:5003.643\n",
      "Ep:123, loss:0.00000, loss_test:0.09558, lr:4.21e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.661, tt:5042.006\n",
      "Ep:124, loss:0.00000, loss_test:0.09187, lr:4.17e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.667, tt:5083.398\n",
      "Ep:125, loss:0.00000, loss_test:0.09483, lr:4.13e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.681, tt:5125.816\n",
      "Ep:126, loss:0.00000, loss_test:0.09548, lr:4.09e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.688, tt:5167.359\n",
      "Ep:127, loss:0.00000, loss_test:0.09289, lr:4.05e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.703, tt:5209.942\n",
      "Ep:128, loss:0.00000, loss_test:0.09421, lr:4.01e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.700, tt:5250.237\n",
      "Ep:129, loss:0.00000, loss_test:0.09463, lr:3.97e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.722, tt:5293.911\n",
      "Ep:130, loss:0.00000, loss_test:0.09367, lr:3.93e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.722, tt:5334.571\n",
      "Ep:131, loss:0.00000, loss_test:0.09386, lr:3.89e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.726, tt:5375.815\n",
      "Ep:132, loss:0.00000, loss_test:0.09423, lr:3.85e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.736, tt:5417.947\n",
      "Ep:133, loss:0.00000, loss_test:0.09524, lr:3.81e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.729, tt:5457.660\n",
      "Ep:134, loss:0.00000, loss_test:0.09520, lr:3.77e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.743, tt:5500.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.09334, lr:3.73e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.742, tt:5540.944\n",
      "Ep:136, loss:0.00000, loss_test:0.09368, lr:3.70e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.755, tt:5583.441\n",
      "Ep:137, loss:0.00000, loss_test:0.09458, lr:3.66e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.760, tt:5624.816\n",
      "Ep:138, loss:0.00000, loss_test:0.09422, lr:3.62e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.761, tt:5665.775\n",
      "Ep:139, loss:0.00000, loss_test:0.09393, lr:3.59e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.763, tt:5706.865\n",
      "Ep:140, loss:0.00000, loss_test:0.09467, lr:3.55e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.768, tt:5748.253\n",
      "Ep:141, loss:0.00000, loss_test:0.09494, lr:3.52e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.762, tt:5788.264\n",
      "Ep:142, loss:0.00000, loss_test:0.09417, lr:3.48e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.776, tt:5830.990\n",
      "Ep:143, loss:0.00000, loss_test:0.09430, lr:3.45e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.770, tt:5870.833\n",
      "Ep:144, loss:0.00000, loss_test:0.09528, lr:3.41e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.767, tt:5911.168\n",
      "Ep:145, loss:0.00000, loss_test:0.09378, lr:3.38e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.772, tt:5952.779\n",
      "Ep:146, loss:0.00000, loss_test:0.09409, lr:3.34e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.769, tt:5993.030\n",
      "Ep:147, loss:0.00000, loss_test:0.09475, lr:3.31e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.813, tt:6040.332\n",
      "Ep:148, loss:0.00000, loss_test:0.09397, lr:3.28e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.813, tt:6081.192\n",
      "Ep:149, loss:0.00000, loss_test:0.09462, lr:3.24e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.806, tt:6120.855\n",
      "Ep:150, loss:0.00000, loss_test:0.09445, lr:3.21e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.821, tt:6163.975\n",
      "Ep:151, loss:0.00000, loss_test:0.09446, lr:3.18e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.829, tt:6205.939\n",
      "Ep:152, loss:0.00000, loss_test:0.09483, lr:3.15e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.830, tt:6246.945\n",
      "Ep:153, loss:0.00000, loss_test:0.09462, lr:3.12e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.824, tt:6286.880\n",
      "Ep:154, loss:0.00000, loss_test:0.09481, lr:3.09e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.836, tt:6329.527\n",
      "Ep:155, loss:0.00000, loss_test:0.09379, lr:3.05e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.843, tt:6371.519\n",
      "Ep:156, loss:0.00000, loss_test:0.09500, lr:3.02e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.838, tt:6411.614\n",
      "Ep:157, loss:0.00000, loss_test:0.09585, lr:2.99e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.840, tt:6452.715\n",
      "Ep:158, loss:0.00000, loss_test:0.09438, lr:2.96e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.845, tt:6494.414\n",
      "Ep:159, loss:0.00000, loss_test:0.09392, lr:2.93e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.854, tt:6536.617\n",
      "Ep:160, loss:0.00000, loss_test:0.09662, lr:2.90e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.848, tt:6576.592\n",
      "Ep:161, loss:0.00000, loss_test:0.09700, lr:2.88e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.859, tt:6619.121\n",
      "Ep:162, loss:0.00000, loss_test:0.09430, lr:2.85e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.870, tt:6661.765\n",
      "Ep:163, loss:0.00000, loss_test:0.09402, lr:2.82e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.873, tt:6703.108\n",
      "Ep:164, loss:0.00000, loss_test:0.09579, lr:2.79e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.874, tt:6744.243\n",
      "Ep:165, loss:0.00000, loss_test:0.09583, lr:2.76e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.869, tt:6784.174\n",
      "Ep:166, loss:0.00000, loss_test:0.09486, lr:2.73e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.865, tt:6824.536\n",
      "Ep:167, loss:0.00000, loss_test:0.09448, lr:2.71e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.872, tt:6866.524\n",
      "Ep:168, loss:0.00000, loss_test:0.09465, lr:2.68e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.865, tt:6906.228\n",
      "Ep:169, loss:0.00000, loss_test:0.09548, lr:2.65e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.864, tt:6946.833\n",
      "Ep:170, loss:0.00000, loss_test:0.09614, lr:2.63e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.870, tt:6988.855\n",
      "Ep:171, loss:0.00000, loss_test:0.09572, lr:2.60e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.881, tt:7031.573\n",
      "Ep:172, loss:0.00000, loss_test:0.09471, lr:2.57e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.882, tt:7072.544\n",
      "Ep:173, loss:0.00000, loss_test:0.09482, lr:2.55e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.884, tt:7113.900\n",
      "Ep:174, loss:0.00000, loss_test:0.09544, lr:2.52e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.897, tt:7156.890\n",
      "Ep:175, loss:0.00000, loss_test:0.09544, lr:2.50e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.900, tt:7198.429\n",
      "Ep:176, loss:0.00000, loss_test:0.09503, lr:2.47e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.891, tt:7237.751\n",
      "Ep:177, loss:0.00000, loss_test:0.09502, lr:2.45e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.891, tt:7278.641\n",
      "Ep:178, loss:0.00000, loss_test:0.09512, lr:2.42e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.907, tt:7322.281\n",
      "Ep:179, loss:0.00000, loss_test:0.09502, lr:2.40e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.907, tt:7363.259\n",
      "Ep:180, loss:0.00000, loss_test:0.09520, lr:2.38e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.903, tt:7403.382\n",
      "Ep:181, loss:0.00000, loss_test:0.09546, lr:2.35e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.907, tt:7445.088\n",
      "Ep:182, loss:0.00000, loss_test:0.09496, lr:2.33e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.902, tt:7485.144\n",
      "Ep:183, loss:0.00000, loss_test:0.09484, lr:2.31e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.906, tt:7526.695\n",
      "Ep:184, loss:0.00000, loss_test:0.09573, lr:2.28e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.903, tt:7567.025\n",
      "Ep:185, loss:0.00000, loss_test:0.09600, lr:2.26e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.909, tt:7609.019\n",
      "Ep:186, loss:0.00000, loss_test:0.09547, lr:2.24e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.911, tt:7650.347\n",
      "Ep:187, loss:0.00000, loss_test:0.09488, lr:2.21e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.913, tt:7691.718\n",
      "Ep:188, loss:0.00000, loss_test:0.09517, lr:2.19e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.944, tt:7738.397\n",
      "Ep:189, loss:0.00000, loss_test:0.09571, lr:2.17e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.940, tt:7778.514\n",
      "Ep:190, loss:0.00000, loss_test:0.09549, lr:2.15e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.939, tt:7819.429\n",
      "Ep:191, loss:0.00000, loss_test:0.09491, lr:2.13e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.935, tt:7859.520\n",
      "Ep:192, loss:0.00000, loss_test:0.09512, lr:2.11e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.940, tt:7901.494\n",
      "Ep:193, loss:0.00000, loss_test:0.09548, lr:2.08e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.935, tt:7941.341\n",
      "Ep:194, loss:0.00000, loss_test:0.09526, lr:2.06e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.940, tt:7983.314\n",
      "Ep:195, loss:0.00000, loss_test:0.09517, lr:2.04e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.942, tt:8024.565\n",
      "Ep:196, loss:0.00000, loss_test:0.09545, lr:2.02e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.948, tt:8066.669\n",
      "Ep:197, loss:0.00000, loss_test:0.09540, lr:2.00e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.951, tt:8108.367\n",
      "Ep:198, loss:0.00000, loss_test:0.09513, lr:1.98e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.954, tt:8149.914\n",
      "Ep:199, loss:0.00000, loss_test:0.09517, lr:1.96e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.951, tt:8190.116\n",
      "Ep:200, loss:0.00000, loss_test:0.09518, lr:1.94e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.956, tt:8232.235\n",
      "Ep:201, loss:0.00000, loss_test:0.09535, lr:1.92e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.954, tt:8272.782\n",
      "Ep:202, loss:0.00000, loss_test:0.09527, lr:1.90e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.948, tt:8312.505\n",
      "Ep:203, loss:0.00000, loss_test:0.09501, lr:1.89e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.952, tt:8354.299\n",
      "Ep:204, loss:0.00000, loss_test:0.09550, lr:1.87e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.951, tt:8394.854\n",
      "Ep:205, loss:0.00000, loss_test:0.09581, lr:1.85e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.953, tt:8436.278\n",
      "Ep:206, loss:0.00000, loss_test:0.09595, lr:1.83e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.941, tt:8474.841\n",
      "Ep:207, loss:0.00000, loss_test:0.09535, lr:1.81e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.939, tt:8515.359\n",
      "Ep:208, loss:0.00000, loss_test:0.09483, lr:1.79e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.966, tt:8561.997\n",
      "Ep:209, loss:0.00000, loss_test:0.09590, lr:1.78e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.966, tt:8602.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09636, lr:1.76e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.973, tt:8645.381\n",
      "Ep:211, loss:0.00000, loss_test:0.09598, lr:1.74e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.975, tt:8686.776\n",
      "Ep:212, loss:0.00000, loss_test:0.09521, lr:1.72e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.957, tt:8723.904\n",
      "Ep:213, loss:0.00000, loss_test:0.09521, lr:1.71e-03, fs:0.77551 (r=0.655,p=0.950),  time:40.907, tt:8754.079\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02172, lr:6.00e-02, fs:0.61674 (r=0.805,p=0.500),  time:32.616, tt:32.616\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02264, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.560, tt:67.120\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02314, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.364, tt:103.091\n",
      "Ep:3, loss:0.00004, loss_test:0.02212, lr:6.00e-02, fs:0.67704 (r=1.000,p=0.512),  time:35.526, tt:142.105\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.64754 (r=0.908,p=0.503),  time:36.479, tt:182.393\n",
      "Ep:5, loss:0.00004, loss_test:0.02123, lr:6.00e-02, fs:0.67273 (r=0.851,p=0.556),  time:37.311, tt:223.865\n",
      "Ep:6, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.64646 (r=0.736,p=0.577),  time:37.860, tt:265.020\n",
      "Ep:7, loss:0.00004, loss_test:0.02149, lr:6.00e-02, fs:0.62564 (r=0.701,p=0.565),  time:38.144, tt:305.151\n",
      "Ep:8, loss:0.00004, loss_test:0.02028, lr:6.00e-02, fs:0.67633 (r=0.805,p=0.583),  time:38.418, tt:345.762\n",
      "Ep:9, loss:0.00003, loss_test:0.01954, lr:6.00e-02, fs:0.65778 (r=0.851,p=0.536),  time:38.475, tt:384.754\n",
      "Ep:10, loss:0.00003, loss_test:0.01917, lr:6.00e-02, fs:0.65801 (r=0.874,p=0.528),  time:38.774, tt:426.513\n",
      "Ep:11, loss:0.00003, loss_test:0.01885, lr:6.00e-02, fs:0.66667 (r=0.874,p=0.539),  time:38.830, tt:465.960\n",
      "Ep:12, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.69194 (r=0.839,p=0.589),  time:38.984, tt:506.790\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01844, lr:6.00e-02, fs:0.68627 (r=0.805,p=0.598),  time:39.211, tt:548.961\n",
      "Ep:14, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.69307 (r=0.805,p=0.609),  time:39.322, tt:589.826\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01752, lr:6.00e-02, fs:0.71154 (r=0.851,p=0.612),  time:39.460, tt:631.354\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01705, lr:6.00e-02, fs:0.73973 (r=0.931,p=0.614),  time:39.623, tt:673.588\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01665, lr:6.00e-02, fs:0.75799 (r=0.954,p=0.629),  time:39.705, tt:714.684\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01637, lr:6.00e-02, fs:0.75349 (r=0.931,p=0.633),  time:39.731, tt:754.897\n",
      "Ep:19, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.77295 (r=0.920,p=0.667),  time:39.718, tt:794.352\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.79612 (r=0.943,p=0.689),  time:39.817, tt:836.160\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01549, lr:6.00e-02, fs:0.80000 (r=0.966,p=0.683),  time:39.864, tt:877.001\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.80383 (r=0.966,p=0.689),  time:40.049, tt:921.119\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.80769 (r=0.966,p=0.694),  time:40.153, tt:963.672\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.81553 (r=0.966,p=0.706),  time:40.234, tt:1005.856\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01464, lr:6.00e-02, fs:0.80976 (r=0.954,p=0.703),  time:40.294, tt:1047.643\n",
      "Ep:26, loss:0.00002, loss_test:0.01447, lr:6.00e-02, fs:0.82353 (r=0.966,p=0.718),  time:40.257, tt:1086.926\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.81553 (r=0.966,p=0.706),  time:40.316, tt:1128.844\n",
      "Ep:28, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.82353 (r=0.966,p=0.718),  time:40.376, tt:1170.904\n",
      "Ep:29, loss:0.00002, loss_test:0.01394, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:40.457, tt:1213.723\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.82828 (r=0.943,p=0.739),  time:40.468, tt:1254.522\n",
      "Ep:31, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.82234 (r=0.931,p=0.736),  time:40.486, tt:1295.541\n",
      "Ep:32, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.82292 (r=0.908,p=0.752),  time:40.541, tt:1337.859\n",
      "Ep:33, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.83333 (r=0.920,p=0.762),  time:40.525, tt:1377.836\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.84211 (r=0.920,p=0.777),  time:40.537, tt:1418.800\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.563, tt:1460.267\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.558, tt:1500.647\n",
      "Ep:37, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.541, tt:1540.567\n",
      "Ep:38, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.548, tt:1581.378\n",
      "Ep:39, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.556, tt:1622.252\n",
      "Ep:40, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.85561 (r=0.920,p=0.800),  time:40.557, tt:1662.855\n",
      "Ep:41, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.85870 (r=0.908,p=0.814),  time:40.574, tt:1704.099\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01372, lr:6.00e-02, fs:0.85870 (r=0.908,p=0.814),  time:40.571, tt:1744.533\n",
      "Ep:43, loss:0.00001, loss_test:0.01367, lr:6.00e-02, fs:0.85870 (r=0.908,p=0.814),  time:40.597, tt:1786.261\n",
      "Ep:44, loss:0.00001, loss_test:0.01379, lr:6.00e-02, fs:0.84615 (r=0.885,p=0.811),  time:40.589, tt:1826.522\n",
      "Ep:45, loss:0.00001, loss_test:0.01386, lr:6.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:40.632, tt:1869.064\n",
      "Ep:46, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:40.640, tt:1910.079\n",
      "Ep:47, loss:0.00001, loss_test:0.01401, lr:6.00e-02, fs:0.84916 (r=0.874,p=0.826),  time:40.636, tt:1950.512\n",
      "Ep:48, loss:0.00001, loss_test:0.01416, lr:6.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:40.636, tt:1991.148\n",
      "Ep:49, loss:0.00001, loss_test:0.01431, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.658, tt:2032.920\n",
      "Ep:50, loss:0.00001, loss_test:0.01425, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.684, tt:2074.906\n",
      "Ep:51, loss:0.00001, loss_test:0.01450, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.730, tt:2117.976\n",
      "Ep:52, loss:0.00001, loss_test:0.01445, lr:6.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.731, tt:2158.727\n",
      "Ep:53, loss:0.00001, loss_test:0.01462, lr:5.94e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.747, tt:2200.334\n",
      "Ep:54, loss:0.00001, loss_test:0.01486, lr:5.88e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.766, tt:2242.133\n",
      "Ep:55, loss:0.00001, loss_test:0.01477, lr:5.82e-02, fs:0.84571 (r=0.851,p=0.841),  time:40.793, tt:2284.416\n",
      "Ep:56, loss:0.00001, loss_test:0.01497, lr:5.76e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.799, tt:2325.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01525, lr:5.71e-02, fs:0.82353 (r=0.805,p=0.843),  time:40.796, tt:2366.160\n",
      "Ep:58, loss:0.00001, loss_test:0.01518, lr:5.65e-02, fs:0.80952 (r=0.782,p=0.840),  time:40.796, tt:2406.971\n",
      "Ep:59, loss:0.00001, loss_test:0.01541, lr:5.59e-02, fs:0.80952 (r=0.782,p=0.840),  time:40.826, tt:2449.571\n",
      "Ep:60, loss:0.00001, loss_test:0.01562, lr:5.54e-02, fs:0.80240 (r=0.770,p=0.838),  time:40.826, tt:2490.357\n",
      "Ep:61, loss:0.00001, loss_test:0.01556, lr:5.48e-02, fs:0.81437 (r=0.782,p=0.850),  time:40.848, tt:2532.577\n",
      "Ep:62, loss:0.00001, loss_test:0.01576, lr:5.43e-02, fs:0.80000 (r=0.759,p=0.846),  time:40.859, tt:2574.145\n",
      "Ep:63, loss:0.00001, loss_test:0.01591, lr:5.37e-02, fs:0.79518 (r=0.759,p=0.835),  time:40.868, tt:2615.568\n",
      "Ep:64, loss:0.00001, loss_test:0.01593, lr:5.32e-02, fs:0.80000 (r=0.759,p=0.846),  time:40.901, tt:2658.587\n",
      "Ep:65, loss:0.00001, loss_test:0.01615, lr:5.27e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.925, tt:2701.057\n",
      "Ep:66, loss:0.00001, loss_test:0.01631, lr:5.21e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.941, tt:2743.080\n",
      "Ep:67, loss:0.00001, loss_test:0.01624, lr:5.16e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.953, tt:2784.799\n",
      "Ep:68, loss:0.00001, loss_test:0.01663, lr:5.11e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.988, tt:2828.198\n",
      "Ep:69, loss:0.00001, loss_test:0.01661, lr:5.06e-02, fs:0.79268 (r=0.747,p=0.844),  time:41.000, tt:2869.973\n",
      "Ep:70, loss:0.00001, loss_test:0.01671, lr:5.01e-02, fs:0.79268 (r=0.747,p=0.844),  time:40.973, tt:2909.049\n",
      "Ep:71, loss:0.00001, loss_test:0.01681, lr:4.96e-02, fs:0.79755 (r=0.747,p=0.855),  time:40.987, tt:2951.072\n",
      "Ep:72, loss:0.00001, loss_test:0.01693, lr:4.91e-02, fs:0.79755 (r=0.747,p=0.855),  time:40.989, tt:2992.227\n",
      "Ep:73, loss:0.00001, loss_test:0.01710, lr:4.86e-02, fs:0.79503 (r=0.736,p=0.865),  time:40.973, tt:3031.990\n",
      "Ep:74, loss:0.00001, loss_test:0.01726, lr:4.81e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.032, tt:3077.425\n",
      "Ep:75, loss:0.00001, loss_test:0.01726, lr:4.76e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.030, tt:3118.243\n",
      "Ep:76, loss:0.00001, loss_test:0.01734, lr:4.71e-02, fs:0.78750 (r=0.724,p=0.863),  time:41.034, tt:3159.646\n",
      "Ep:77, loss:0.00001, loss_test:0.01772, lr:4.67e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.038, tt:3200.985\n",
      "Ep:78, loss:0.00001, loss_test:0.01764, lr:4.62e-02, fs:0.79245 (r=0.724,p=0.875),  time:41.065, tt:3244.097\n",
      "Ep:79, loss:0.00001, loss_test:0.01790, lr:4.57e-02, fs:0.79245 (r=0.724,p=0.875),  time:41.057, tt:3284.584\n",
      "Ep:80, loss:0.00001, loss_test:0.01795, lr:4.53e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.054, tt:3325.408\n",
      "Ep:81, loss:0.00001, loss_test:0.01783, lr:4.48e-02, fs:0.79245 (r=0.724,p=0.875),  time:41.050, tt:3366.072\n",
      "Ep:82, loss:0.00001, loss_test:0.01823, lr:4.44e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.039, tt:3406.256\n",
      "Ep:83, loss:0.00001, loss_test:0.01824, lr:4.39e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.036, tt:3447.027\n",
      "Ep:84, loss:0.00001, loss_test:0.01822, lr:4.35e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.051, tt:3489.351\n",
      "Ep:85, loss:0.00001, loss_test:0.01850, lr:4.31e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.062, tt:3531.326\n",
      "Ep:86, loss:0.00001, loss_test:0.01860, lr:4.26e-02, fs:0.78481 (r=0.713,p=0.873),  time:41.057, tt:3572.002\n",
      "Ep:87, loss:0.00001, loss_test:0.01857, lr:4.22e-02, fs:0.77707 (r=0.701,p=0.871),  time:41.052, tt:3612.582\n",
      "Ep:88, loss:0.00001, loss_test:0.01886, lr:4.18e-02, fs:0.77707 (r=0.701,p=0.871),  time:41.077, tt:3655.844\n",
      "Ep:89, loss:0.00001, loss_test:0.01885, lr:4.14e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.089, tt:3697.987\n",
      "Ep:90, loss:0.00001, loss_test:0.01903, lr:4.10e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.097, tt:3739.833\n",
      "Ep:91, loss:0.00001, loss_test:0.01909, lr:4.05e-02, fs:0.77707 (r=0.701,p=0.871),  time:41.103, tt:3781.467\n",
      "Ep:92, loss:0.00001, loss_test:0.01906, lr:4.01e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.125, tt:3824.622\n",
      "Ep:93, loss:0.00001, loss_test:0.01927, lr:3.97e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.117, tt:3864.965\n",
      "Ep:94, loss:0.00001, loss_test:0.01942, lr:3.93e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.133, tt:3907.636\n",
      "Ep:95, loss:0.00001, loss_test:0.01948, lr:3.89e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.153, tt:3950.671\n",
      "Ep:96, loss:0.00001, loss_test:0.01956, lr:3.86e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.151, tt:3991.607\n",
      "Ep:97, loss:0.00001, loss_test:0.01978, lr:3.82e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.157, tt:4033.435\n",
      "Ep:98, loss:0.00001, loss_test:0.01978, lr:3.78e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.165, tt:4075.374\n",
      "Ep:99, loss:0.00001, loss_test:0.01983, lr:3.74e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.166, tt:4116.561\n",
      "Ep:100, loss:0.00001, loss_test:0.02001, lr:3.70e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.179, tt:4159.114\n",
      "Ep:101, loss:0.00001, loss_test:0.02012, lr:3.67e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.178, tt:4200.174\n",
      "Ep:102, loss:0.00001, loss_test:0.02005, lr:3.63e-02, fs:0.77419 (r=0.690,p=0.882),  time:41.181, tt:4241.652\n",
      "Ep:103, loss:0.00001, loss_test:0.02027, lr:3.59e-02, fs:0.77922 (r=0.690,p=0.896),  time:41.190, tt:4283.715\n",
      "Ep:104, loss:0.00001, loss_test:0.02031, lr:3.56e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.190, tt:4324.911\n",
      "Ep:105, loss:0.00001, loss_test:0.02045, lr:3.52e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.213, tt:4368.590\n",
      "Ep:106, loss:0.00001, loss_test:0.02063, lr:3.49e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.204, tt:4408.815\n",
      "Ep:107, loss:0.00001, loss_test:0.02058, lr:3.45e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.211, tt:4450.820\n",
      "Ep:108, loss:0.00001, loss_test:0.02074, lr:3.42e-02, fs:0.77124 (r=0.678,p=0.894),  time:41.208, tt:4491.707\n",
      "Ep:109, loss:0.00000, loss_test:0.02089, lr:3.38e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.208, tt:4532.905\n",
      "Ep:110, loss:0.00000, loss_test:0.02085, lr:3.35e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.206, tt:4573.897\n",
      "Ep:111, loss:0.00000, loss_test:0.02111, lr:3.32e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.195, tt:4613.845\n",
      "Ep:112, loss:0.00000, loss_test:0.02119, lr:3.28e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.187, tt:4654.079\n",
      "Ep:113, loss:0.00000, loss_test:0.02111, lr:3.25e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.187, tt:4695.283\n",
      "Ep:114, loss:0.00000, loss_test:0.02144, lr:3.22e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.192, tt:4737.064\n",
      "Ep:115, loss:0.00000, loss_test:0.02146, lr:3.19e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.189, tt:4777.889\n",
      "Ep:116, loss:0.00000, loss_test:0.02147, lr:3.15e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.180, tt:4818.097\n",
      "Ep:117, loss:0.00000, loss_test:0.02168, lr:3.12e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.176, tt:4858.728\n",
      "Ep:118, loss:0.00000, loss_test:0.02169, lr:3.09e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.172, tt:4899.409\n",
      "Ep:119, loss:0.00000, loss_test:0.02179, lr:3.06e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.170, tt:4940.446\n",
      "Ep:120, loss:0.00000, loss_test:0.02196, lr:3.03e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.172, tt:4981.809\n",
      "Ep:121, loss:0.00000, loss_test:0.02190, lr:3.00e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.171, tt:5022.897\n",
      "Ep:122, loss:0.00000, loss_test:0.02202, lr:2.97e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.174, tt:5064.452\n",
      "Ep:123, loss:0.00000, loss_test:0.02219, lr:2.94e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.174, tt:5105.543\n",
      "Ep:124, loss:0.00000, loss_test:0.02219, lr:2.91e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.163, tt:5145.365\n",
      "Ep:125, loss:0.00000, loss_test:0.02237, lr:2.88e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.158, tt:5185.869\n",
      "Ep:126, loss:0.00000, loss_test:0.02242, lr:2.85e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.153, tt:5226.483\n",
      "Ep:127, loss:0.00000, loss_test:0.02243, lr:2.82e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.151, tt:5267.311\n",
      "Ep:128, loss:0.00000, loss_test:0.02263, lr:2.80e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.145, tt:5307.662\n",
      "Ep:129, loss:0.00000, loss_test:0.02268, lr:2.77e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.141, tt:5348.348\n",
      "Ep:130, loss:0.00000, loss_test:0.02269, lr:2.74e-02, fs:0.76821 (r=0.667,p=0.906),  time:41.123, tt:5387.124\n",
      "Ep:131, loss:0.00000, loss_test:0.02287, lr:2.71e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.147, tt:5431.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.02292, lr:2.69e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.164, tt:5474.775\n",
      "Ep:133, loss:0.00000, loss_test:0.02292, lr:2.66e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.181, tt:5518.305\n",
      "Ep:134, loss:0.00000, loss_test:0.02315, lr:2.63e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.188, tt:5560.344\n",
      "Ep:135, loss:0.00000, loss_test:0.02317, lr:2.61e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.206, tt:5604.022\n",
      "Ep:136, loss:0.00000, loss_test:0.02324, lr:2.58e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.203, tt:5644.824\n",
      "Ep:137, loss:0.00000, loss_test:0.02336, lr:2.55e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.194, tt:5684.709\n",
      "Ep:138, loss:0.00000, loss_test:0.02336, lr:2.53e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.188, tt:5725.164\n",
      "Ep:139, loss:0.00000, loss_test:0.02345, lr:2.50e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.183, tt:5765.627\n",
      "Ep:140, loss:0.00000, loss_test:0.02357, lr:2.48e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.181, tt:5806.539\n",
      "Ep:141, loss:0.00000, loss_test:0.02363, lr:2.45e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.176, tt:5847.009\n",
      "Ep:142, loss:0.00000, loss_test:0.02366, lr:2.43e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.185, tt:5889.501\n",
      "Ep:143, loss:0.00000, loss_test:0.02375, lr:2.40e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.184, tt:5930.507\n",
      "Ep:144, loss:0.00000, loss_test:0.02376, lr:2.38e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.183, tt:5971.466\n",
      "Ep:145, loss:0.00000, loss_test:0.02391, lr:2.36e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.187, tt:6013.284\n",
      "Ep:146, loss:0.00000, loss_test:0.02397, lr:2.33e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.193, tt:6055.371\n",
      "Ep:147, loss:0.00000, loss_test:0.02405, lr:2.31e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.190, tt:6096.094\n",
      "Ep:148, loss:0.00000, loss_test:0.02410, lr:2.29e-02, fs:0.77333 (r=0.667,p=0.921),  time:41.191, tt:6137.505\n",
      "Ep:149, loss:0.00000, loss_test:0.02414, lr:2.26e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.205, tt:6180.824\n",
      "Ep:150, loss:0.00000, loss_test:0.02421, lr:2.24e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.216, tt:6223.551\n",
      "Ep:151, loss:0.00000, loss_test:0.02427, lr:2.22e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.224, tt:6266.002\n",
      "Ep:152, loss:0.00000, loss_test:0.02434, lr:2.20e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.230, tt:6308.204\n",
      "Ep:153, loss:0.00000, loss_test:0.02439, lr:2.17e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.219, tt:6347.692\n",
      "Ep:154, loss:0.00000, loss_test:0.02453, lr:2.15e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.217, tt:6388.575\n",
      "Ep:155, loss:0.00000, loss_test:0.02455, lr:2.13e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.220, tt:6430.282\n",
      "Ep:156, loss:0.00000, loss_test:0.02459, lr:2.11e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.225, tt:6472.381\n",
      "Ep:157, loss:0.00000, loss_test:0.02467, lr:2.09e-02, fs:0.76510 (r=0.655,p=0.919),  time:41.221, tt:6512.881\n",
      "Ep:158, loss:0.00000, loss_test:0.02467, lr:2.07e-02, fs:0.75676 (r=0.644,p=0.918),  time:41.242, tt:6557.467\n",
      "Ep:159, loss:0.00000, loss_test:0.02481, lr:2.05e-02, fs:0.74830 (r=0.632,p=0.917),  time:41.235, tt:6597.671\n",
      "Ep:160, loss:0.00000, loss_test:0.02488, lr:2.03e-02, fs:0.74830 (r=0.632,p=0.917),  time:41.250, tt:6641.253\n",
      "Ep:161, loss:0.00000, loss_test:0.02489, lr:2.01e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.249, tt:6682.382\n",
      "Ep:162, loss:0.00000, loss_test:0.02497, lr:1.99e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.261, tt:6725.565\n",
      "Ep:163, loss:0.00000, loss_test:0.02498, lr:1.97e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.283, tt:6770.481\n",
      "Ep:164, loss:0.00000, loss_test:0.02503, lr:1.95e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.288, tt:6812.459\n",
      "Ep:165, loss:0.00000, loss_test:0.02522, lr:1.93e-02, fs:0.72222 (r=0.598,p=0.912),  time:41.298, tt:6855.467\n",
      "Ep:166, loss:0.00000, loss_test:0.02519, lr:1.91e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.308, tt:6898.398\n",
      "Ep:167, loss:0.00000, loss_test:0.02524, lr:1.89e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.324, tt:6942.425\n",
      "Ep:168, loss:0.00000, loss_test:0.02535, lr:1.87e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.333, tt:6985.347\n",
      "Ep:169, loss:0.00000, loss_test:0.02532, lr:1.85e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.342, tt:7028.087\n",
      "Ep:170, loss:0.00000, loss_test:0.02535, lr:1.83e-02, fs:0.71329 (r=0.586,p=0.911),  time:41.352, tt:7071.277\n",
      "Ep:171, loss:0.00000, loss_test:0.02547, lr:1.81e-02, fs:0.69504 (r=0.563,p=0.907),  time:41.359, tt:7113.776\n",
      "Ep:172, loss:0.00000, loss_test:0.02551, lr:1.80e-02, fs:0.69504 (r=0.563,p=0.907),  time:41.363, tt:7155.798\n",
      "Ep:173, loss:0.00000, loss_test:0.02552, lr:1.78e-02, fs:0.69504 (r=0.563,p=0.907),  time:41.384, tt:7200.801\n",
      "Ep:174, loss:0.00000, loss_test:0.02560, lr:1.76e-02, fs:0.69504 (r=0.563,p=0.907),  time:41.393, tt:7243.792\n",
      "Ep:175, loss:0.00000, loss_test:0.02568, lr:1.74e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.396, tt:7285.684\n",
      "Ep:176, loss:0.00000, loss_test:0.02567, lr:1.73e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.390, tt:7326.004\n",
      "Ep:177, loss:0.00000, loss_test:0.02569, lr:1.71e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.396, tt:7368.454\n",
      "Ep:178, loss:0.00000, loss_test:0.02581, lr:1.69e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.397, tt:7410.077\n",
      "Ep:179, loss:0.00000, loss_test:0.02582, lr:1.67e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.404, tt:7452.724\n",
      "Ep:180, loss:0.00000, loss_test:0.02583, lr:1.66e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.411, tt:7495.386\n",
      "Ep:181, loss:0.00000, loss_test:0.02592, lr:1.64e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.415, tt:7537.526\n",
      "Ep:182, loss:0.00000, loss_test:0.02599, lr:1.62e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.402, tt:7576.650\n",
      "Ep:183, loss:0.00000, loss_test:0.02600, lr:1.61e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.400, tt:7617.568\n",
      "Ep:184, loss:0.00000, loss_test:0.02608, lr:1.59e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.400, tt:7658.907\n",
      "Ep:185, loss:0.00000, loss_test:0.02609, lr:1.58e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.398, tt:7699.979\n",
      "Ep:186, loss:0.00000, loss_test:0.02613, lr:1.56e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.399, tt:7741.702\n",
      "Ep:187, loss:0.00000, loss_test:0.02615, lr:1.54e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.405, tt:7784.129\n",
      "Ep:188, loss:0.00000, loss_test:0.02623, lr:1.53e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.398, tt:7824.215\n",
      "Ep:189, loss:0.00000, loss_test:0.02632, lr:1.51e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.385, tt:7863.231\n",
      "Ep:190, loss:0.00000, loss_test:0.02633, lr:1.50e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.383, tt:7904.089\n",
      "Ep:191, loss:0.00000, loss_test:0.02632, lr:1.48e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.393, tt:7947.375\n",
      "Ep:192, loss:0.00000, loss_test:0.02644, lr:1.47e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.385, tt:7987.314\n",
      "Ep:193, loss:0.00000, loss_test:0.02646, lr:1.45e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.385, tt:8028.645\n",
      "Ep:194, loss:0.00000, loss_test:0.02643, lr:1.44e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.384, tt:8069.904\n",
      "Ep:195, loss:0.00000, loss_test:0.02652, lr:1.43e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.386, tt:8111.701\n",
      "Ep:196, loss:0.00000, loss_test:0.02653, lr:1.41e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.384, tt:8152.692\n",
      "Ep:197, loss:0.00000, loss_test:0.02661, lr:1.40e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.380, tt:8193.239\n",
      "Ep:198, loss:0.00000, loss_test:0.02665, lr:1.38e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.384, tt:8235.506\n",
      "Ep:199, loss:0.00000, loss_test:0.02666, lr:1.37e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.380, tt:8276.016\n",
      "Ep:200, loss:0.00000, loss_test:0.02671, lr:1.36e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.366, tt:8314.512\n",
      "Ep:201, loss:0.00000, loss_test:0.02679, lr:1.34e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.368, tt:8356.424\n",
      "Ep:202, loss:0.00000, loss_test:0.02674, lr:1.33e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.361, tt:8396.370\n",
      "Ep:203, loss:0.00000, loss_test:0.02676, lr:1.32e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.363, tt:8438.022\n",
      "Ep:204, loss:0.00000, loss_test:0.02688, lr:1.30e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.362, tt:8479.122\n",
      "Ep:205, loss:0.00000, loss_test:0.02689, lr:1.29e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.357, tt:8519.482\n",
      "Ep:206, loss:0.00000, loss_test:0.02685, lr:1.28e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.353, tt:8560.162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02693, lr:1.26e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.350, tt:8600.898\n",
      "Ep:208, loss:0.00000, loss_test:0.02701, lr:1.25e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.352, tt:8642.470\n",
      "Ep:209, loss:0.00000, loss_test:0.02702, lr:1.24e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.345, tt:8682.453\n",
      "Ep:210, loss:0.00000, loss_test:0.02702, lr:1.23e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.337, tt:8722.115\n",
      "Ep:211, loss:0.00000, loss_test:0.02711, lr:1.21e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.334, tt:8762.851\n",
      "Ep:212, loss:0.00000, loss_test:0.02714, lr:1.20e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.334, tt:8804.218\n",
      "Ep:213, loss:0.00000, loss_test:0.02714, lr:1.19e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.304, tt:8839.035\n",
      "Ep:214, loss:0.00000, loss_test:0.02716, lr:1.18e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.250, tt:8868.782\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14327, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.973, tt:36.973\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14187, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.369, tt:74.738\n",
      "Ep:2, loss:0.00027, loss_test:0.13945, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:39.134, tt:117.403\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13521, lr:1.00e-02, fs:0.63745 (r=0.920,p=0.488),  time:39.490, tt:157.959\n",
      "Ep:4, loss:0.00026, loss_test:0.12888, lr:1.00e-02, fs:0.64348 (r=0.851,p=0.517),  time:39.582, tt:197.910\n",
      "Ep:5, loss:0.00024, loss_test:0.12188, lr:1.00e-02, fs:0.66010 (r=0.770,p=0.578),  time:40.123, tt:240.737\n",
      "Ep:6, loss:0.00023, loss_test:0.12081, lr:1.00e-02, fs:0.65217 (r=0.690,p=0.619),  time:40.568, tt:283.976\n",
      "Ep:7, loss:0.00022, loss_test:0.11798, lr:1.00e-02, fs:0.64481 (r=0.678,p=0.615),  time:40.747, tt:325.974\n",
      "Ep:8, loss:0.00021, loss_test:0.11600, lr:1.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:41.025, tt:369.222\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11368, lr:1.00e-02, fs:0.68421 (r=0.747,p=0.631),  time:41.279, tt:412.790\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11159, lr:1.00e-02, fs:0.69663 (r=0.713,p=0.681),  time:41.309, tt:454.403\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10846, lr:1.00e-02, fs:0.70000 (r=0.724,p=0.677),  time:41.388, tt:496.650\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10709, lr:1.00e-02, fs:0.70526 (r=0.770,p=0.650),  time:41.801, tt:543.411\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10310, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:41.672, tt:583.406\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09985, lr:1.00e-02, fs:0.72222 (r=0.747,p=0.699),  time:41.720, tt:625.806\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09723, lr:1.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:41.727, tt:667.629\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09496, lr:1.00e-02, fs:0.75676 (r=0.805,p=0.714),  time:41.715, tt:709.153\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09318, lr:1.00e-02, fs:0.76757 (r=0.816,p=0.724),  time:41.780, tt:752.046\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09050, lr:1.00e-02, fs:0.81026 (r=0.908,p=0.731),  time:41.877, tt:795.657\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08805, lr:1.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:41.783, tt:835.667\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.08622, lr:1.00e-02, fs:0.83077 (r=0.931,p=0.750),  time:41.891, tt:879.702\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08474, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:41.920, tt:922.239\n",
      "Ep:22, loss:0.00013, loss_test:0.08311, lr:1.00e-02, fs:0.84974 (r=0.943,p=0.774),  time:41.981, tt:965.569\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.08146, lr:1.00e-02, fs:0.84324 (r=0.897,p=0.796),  time:42.008, tt:1008.191\n",
      "Ep:24, loss:0.00013, loss_test:0.07955, lr:1.00e-02, fs:0.87047 (r=0.966,p=0.792),  time:42.009, tt:1050.214\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.07973, lr:1.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:42.111, tt:1094.889\n",
      "Ep:26, loss:0.00012, loss_test:0.07828, lr:1.00e-02, fs:0.86911 (r=0.954,p=0.798),  time:42.195, tt:1139.268\n",
      "Ep:27, loss:0.00011, loss_test:0.07767, lr:1.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:42.179, tt:1181.010\n",
      "Ep:28, loss:0.00011, loss_test:0.07738, lr:1.00e-02, fs:0.86598 (r=0.966,p=0.785),  time:42.127, tt:1221.674\n",
      "Ep:29, loss:0.00010, loss_test:0.07734, lr:1.00e-02, fs:0.86364 (r=0.874,p=0.854),  time:42.185, tt:1265.541\n",
      "Ep:30, loss:0.00010, loss_test:0.07527, lr:1.00e-02, fs:0.89119 (r=0.989,p=0.811),  time:42.181, tt:1307.624\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07724, lr:1.00e-02, fs:0.86047 (r=0.851,p=0.871),  time:42.159, tt:1349.098\n",
      "Ep:32, loss:0.00009, loss_test:0.07707, lr:1.00e-02, fs:0.86517 (r=0.885,p=0.846),  time:42.263, tt:1394.683\n",
      "Ep:33, loss:0.00009, loss_test:0.07518, lr:1.00e-02, fs:0.86957 (r=0.920,p=0.825),  time:42.267, tt:1437.092\n",
      "Ep:34, loss:0.00008, loss_test:0.07714, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:42.327, tt:1481.444\n",
      "Ep:35, loss:0.00008, loss_test:0.07445, lr:1.00e-02, fs:0.90323 (r=0.966,p=0.848),  time:42.372, tt:1525.399\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07637, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:42.347, tt:1566.837\n",
      "Ep:37, loss:0.00007, loss_test:0.07733, lr:1.00e-02, fs:0.82500 (r=0.759,p=0.904),  time:42.343, tt:1609.032\n",
      "Ep:38, loss:0.00007, loss_test:0.07286, lr:1.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:42.335, tt:1651.083\n",
      "Ep:39, loss:0.00007, loss_test:0.08079, lr:1.00e-02, fs:0.72603 (r=0.609,p=0.898),  time:42.300, tt:1691.994\n",
      "Ep:40, loss:0.00007, loss_test:0.07469, lr:1.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:42.298, tt:1734.210\n",
      "Ep:41, loss:0.00006, loss_test:0.07524, lr:1.00e-02, fs:0.83333 (r=0.805,p=0.864),  time:42.272, tt:1775.421\n",
      "Ep:42, loss:0.00006, loss_test:0.08512, lr:1.00e-02, fs:0.75325 (r=0.667,p=0.866),  time:42.275, tt:1817.845\n",
      "Ep:43, loss:0.00006, loss_test:0.07551, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:42.272, tt:1859.954\n",
      "Ep:44, loss:0.00006, loss_test:0.08173, lr:1.00e-02, fs:0.77987 (r=0.713,p=0.861),  time:42.267, tt:1901.992\n",
      "Ep:45, loss:0.00006, loss_test:0.07877, lr:1.00e-02, fs:0.79245 (r=0.724,p=0.875),  time:42.266, tt:1944.235\n",
      "Ep:46, loss:0.00005, loss_test:0.07928, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:42.230, tt:1984.832\n",
      "Ep:47, loss:0.00005, loss_test:0.08186, lr:9.90e-03, fs:0.76923 (r=0.690,p=0.870),  time:42.242, tt:2027.619\n",
      "Ep:48, loss:0.00005, loss_test:0.07614, lr:9.80e-03, fs:0.84524 (r=0.816,p=0.877),  time:42.243, tt:2069.922\n",
      "Ep:49, loss:0.00005, loss_test:0.08457, lr:9.70e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.234, tt:2111.693\n",
      "Ep:50, loss:0.00004, loss_test:0.07985, lr:9.61e-03, fs:0.78981 (r=0.713,p=0.886),  time:42.231, tt:2153.760\n",
      "Ep:51, loss:0.00004, loss_test:0.08298, lr:9.51e-03, fs:0.74172 (r=0.644,p=0.875),  time:42.201, tt:2194.440\n",
      "Ep:52, loss:0.00004, loss_test:0.07932, lr:9.41e-03, fs:0.81988 (r=0.759,p=0.892),  time:42.219, tt:2237.589\n",
      "Ep:53, loss:0.00004, loss_test:0.09130, lr:9.32e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.206, tt:2279.131\n",
      "Ep:54, loss:0.00004, loss_test:0.07900, lr:9.23e-03, fs:0.84524 (r=0.816,p=0.877),  time:42.174, tt:2319.588\n",
      "Ep:55, loss:0.00004, loss_test:0.09557, lr:9.14e-03, fs:0.62687 (r=0.483,p=0.894),  time:42.167, tt:2361.363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00004, loss_test:0.08619, lr:9.04e-03, fs:0.69444 (r=0.575,p=0.877),  time:42.157, tt:2402.967\n",
      "Ep:57, loss:0.00003, loss_test:0.09074, lr:8.95e-03, fs:0.69014 (r=0.563,p=0.891),  time:42.153, tt:2444.890\n",
      "Ep:58, loss:0.00003, loss_test:0.09853, lr:8.86e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.123, tt:2485.235\n",
      "Ep:59, loss:0.00003, loss_test:0.08483, lr:8.78e-03, fs:0.72848 (r=0.632,p=0.859),  time:42.109, tt:2526.570\n",
      "Ep:60, loss:0.00003, loss_test:0.09152, lr:8.69e-03, fs:0.62687 (r=0.483,p=0.894),  time:42.180, tt:2572.969\n",
      "Ep:61, loss:0.00003, loss_test:0.09106, lr:8.60e-03, fs:0.63768 (r=0.506,p=0.863),  time:42.183, tt:2615.364\n",
      "Ep:62, loss:0.00003, loss_test:0.08868, lr:8.51e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.188, tt:2657.848\n",
      "Ep:63, loss:0.00003, loss_test:0.09637, lr:8.43e-03, fs:0.61069 (r=0.460,p=0.909),  time:42.237, tt:2703.137\n",
      "Ep:64, loss:0.00002, loss_test:0.08731, lr:8.35e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.218, tt:2744.172\n",
      "Ep:65, loss:0.00002, loss_test:0.09685, lr:8.26e-03, fs:0.62121 (r=0.471,p=0.911),  time:42.233, tt:2787.386\n",
      "Ep:66, loss:0.00002, loss_test:0.08850, lr:8.18e-03, fs:0.68085 (r=0.552,p=0.889),  time:42.250, tt:2830.740\n",
      "Ep:67, loss:0.00002, loss_test:0.09543, lr:8.10e-03, fs:0.61069 (r=0.460,p=0.909),  time:42.257, tt:2873.491\n",
      "Ep:68, loss:0.00002, loss_test:0.08711, lr:8.02e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.279, tt:2917.218\n",
      "Ep:69, loss:0.00002, loss_test:0.09468, lr:7.94e-03, fs:0.60606 (r=0.460,p=0.889),  time:42.285, tt:2959.938\n",
      "Ep:70, loss:0.00002, loss_test:0.09581, lr:7.86e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.306, tt:3003.712\n",
      "Ep:71, loss:0.00002, loss_test:0.09764, lr:7.78e-03, fs:0.61069 (r=0.460,p=0.909),  time:42.338, tt:3048.342\n",
      "Ep:72, loss:0.00002, loss_test:0.09929, lr:7.70e-03, fs:0.64179 (r=0.494,p=0.915),  time:42.345, tt:3091.165\n",
      "Ep:73, loss:0.00002, loss_test:0.08916, lr:7.62e-03, fs:0.72973 (r=0.621,p=0.885),  time:42.342, tt:3133.291\n",
      "Ep:74, loss:0.00002, loss_test:0.10097, lr:7.55e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.364, tt:3177.277\n",
      "Ep:75, loss:0.00002, loss_test:0.09004, lr:7.47e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.378, tt:3220.724\n",
      "Ep:76, loss:0.00001, loss_test:0.09705, lr:7.40e-03, fs:0.64179 (r=0.494,p=0.915),  time:42.367, tt:3262.249\n",
      "Ep:77, loss:0.00001, loss_test:0.09380, lr:7.32e-03, fs:0.65217 (r=0.517,p=0.882),  time:42.380, tt:3305.630\n",
      "Ep:78, loss:0.00001, loss_test:0.09720, lr:7.25e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.377, tt:3347.748\n",
      "Ep:79, loss:0.00001, loss_test:0.09338, lr:7.18e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.393, tt:3391.466\n",
      "Ep:80, loss:0.00001, loss_test:0.09741, lr:7.11e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.391, tt:3433.704\n",
      "Ep:81, loss:0.00001, loss_test:0.09546, lr:7.03e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.376, tt:3474.814\n",
      "Ep:82, loss:0.00001, loss_test:0.09546, lr:6.96e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.382, tt:3517.693\n",
      "Ep:83, loss:0.00001, loss_test:0.09322, lr:6.89e-03, fs:0.65693 (r=0.517,p=0.900),  time:42.362, tt:3558.434\n",
      "Ep:84, loss:0.00001, loss_test:0.09638, lr:6.83e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.360, tt:3600.634\n",
      "Ep:85, loss:0.00001, loss_test:0.09603, lr:6.76e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.352, tt:3642.274\n",
      "Ep:86, loss:0.00001, loss_test:0.09952, lr:6.69e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.362, tt:3685.522\n",
      "Ep:87, loss:0.00001, loss_test:0.09369, lr:6.62e-03, fs:0.65693 (r=0.517,p=0.900),  time:42.340, tt:3725.916\n",
      "Ep:88, loss:0.00001, loss_test:0.10035, lr:6.56e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.335, tt:3767.812\n",
      "Ep:89, loss:0.00001, loss_test:0.09480, lr:6.49e-03, fs:0.65217 (r=0.517,p=0.882),  time:42.327, tt:3809.390\n",
      "Ep:90, loss:0.00001, loss_test:0.09783, lr:6.43e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.302, tt:3849.504\n",
      "Ep:91, loss:0.00001, loss_test:0.09736, lr:6.36e-03, fs:0.61069 (r=0.460,p=0.909),  time:42.310, tt:3892.487\n",
      "Ep:92, loss:0.00001, loss_test:0.09426, lr:6.30e-03, fs:0.65217 (r=0.517,p=0.882),  time:42.287, tt:3932.694\n",
      "Ep:93, loss:0.00001, loss_test:0.09731, lr:6.24e-03, fs:0.61069 (r=0.460,p=0.909),  time:42.248, tt:3971.311\n",
      "Ep:94, loss:0.00001, loss_test:0.09735, lr:6.17e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.213, tt:4010.250\n",
      "Ep:95, loss:0.00001, loss_test:0.09823, lr:6.11e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.202, tt:4051.352\n",
      "Ep:96, loss:0.00001, loss_test:0.09781, lr:6.05e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.209, tt:4094.256\n",
      "Ep:97, loss:0.00001, loss_test:0.09691, lr:5.99e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.179, tt:4133.565\n",
      "Ep:98, loss:0.00001, loss_test:0.09848, lr:5.93e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.168, tt:4174.597\n",
      "Ep:99, loss:0.00001, loss_test:0.09894, lr:5.87e-03, fs:0.63636 (r=0.483,p=0.933),  time:42.153, tt:4215.320\n",
      "Ep:100, loss:0.00001, loss_test:0.09440, lr:5.81e-03, fs:0.65693 (r=0.517,p=0.900),  time:42.163, tt:4258.498\n",
      "Ep:101, loss:0.00001, loss_test:0.10187, lr:5.75e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.148, tt:4299.081\n",
      "Ep:102, loss:0.00001, loss_test:0.10010, lr:5.70e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.142, tt:4340.588\n",
      "Ep:103, loss:0.00001, loss_test:0.09672, lr:5.64e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.144, tt:4383.020\n",
      "Ep:104, loss:0.00001, loss_test:0.09853, lr:5.58e-03, fs:0.63636 (r=0.483,p=0.933),  time:42.115, tt:4422.104\n",
      "Ep:105, loss:0.00001, loss_test:0.09740, lr:5.53e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.093, tt:4461.837\n",
      "Ep:106, loss:0.00001, loss_test:0.09699, lr:5.47e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.086, tt:4503.171\n",
      "Ep:107, loss:0.00001, loss_test:0.09775, lr:5.42e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.075, tt:4544.046\n",
      "Ep:108, loss:0.00001, loss_test:0.09853, lr:5.36e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.080, tt:4586.678\n",
      "Ep:109, loss:0.00001, loss_test:0.09545, lr:5.31e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.057, tt:4626.269\n",
      "Ep:110, loss:0.00001, loss_test:0.10011, lr:5.26e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.075, tt:4670.301\n",
      "Ep:111, loss:0.00001, loss_test:0.09785, lr:5.20e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.064, tt:4711.204\n",
      "Ep:112, loss:0.00001, loss_test:0.09822, lr:5.15e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.056, tt:4752.342\n",
      "Ep:113, loss:0.00001, loss_test:0.09925, lr:5.10e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.060, tt:4794.857\n",
      "Ep:114, loss:0.00001, loss_test:0.09730, lr:5.05e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.075, tt:4838.577\n",
      "Ep:115, loss:0.00001, loss_test:0.09898, lr:5.00e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.068, tt:4879.876\n",
      "Ep:116, loss:0.00000, loss_test:0.09768, lr:4.95e-03, fs:0.65672 (r=0.506,p=0.936),  time:42.080, tt:4923.348\n",
      "Ep:117, loss:0.00000, loss_test:0.09912, lr:4.90e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.072, tt:4964.555\n",
      "Ep:118, loss:0.00000, loss_test:0.09671, lr:4.85e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.071, tt:5006.410\n",
      "Ep:119, loss:0.00000, loss_test:0.10065, lr:4.80e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.064, tt:5047.640\n",
      "Ep:120, loss:0.00000, loss_test:0.10014, lr:4.75e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.073, tt:5090.843\n",
      "Ep:121, loss:0.00000, loss_test:0.09763, lr:4.71e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.054, tt:5130.617\n",
      "Ep:122, loss:0.00000, loss_test:0.09982, lr:4.66e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.044, tt:5171.376\n",
      "Ep:123, loss:0.00000, loss_test:0.09793, lr:4.61e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.058, tt:5215.175\n",
      "Ep:124, loss:0.00000, loss_test:0.09940, lr:4.57e-03, fs:0.62595 (r=0.471,p=0.932),  time:42.046, tt:5255.806\n",
      "Ep:125, loss:0.00000, loss_test:0.10017, lr:4.52e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.056, tt:5299.000\n",
      "Ep:126, loss:0.00000, loss_test:0.09823, lr:4.48e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.039, tt:5338.927\n",
      "Ep:127, loss:0.00000, loss_test:0.09998, lr:4.43e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.023, tt:5378.922\n",
      "Ep:128, loss:0.00000, loss_test:0.09931, lr:4.39e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.014, tt:5419.847\n",
      "Ep:129, loss:0.00000, loss_test:0.09963, lr:4.34e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.999, tt:5459.843\n",
      "Ep:130, loss:0.00000, loss_test:0.09869, lr:4.30e-03, fs:0.66667 (r=0.517,p=0.938),  time:41.991, tt:5500.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.10062, lr:4.26e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.005, tt:5544.691\n",
      "Ep:132, loss:0.00000, loss_test:0.09906, lr:4.21e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.041, tt:5591.442\n",
      "Ep:133, loss:0.00000, loss_test:0.09905, lr:4.17e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.039, tt:5633.287\n",
      "Ep:134, loss:0.00000, loss_test:0.09953, lr:4.13e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.042, tt:5675.713\n",
      "Ep:135, loss:0.00000, loss_test:0.09871, lr:4.09e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.030, tt:5716.085\n",
      "Ep:136, loss:0.00000, loss_test:0.10061, lr:4.05e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.029, tt:5758.004\n",
      "Ep:137, loss:0.00000, loss_test:0.09811, lr:4.01e-03, fs:0.66667 (r=0.517,p=0.938),  time:42.019, tt:5798.559\n",
      "Ep:138, loss:0.00000, loss_test:0.10074, lr:3.97e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.004, tt:5838.541\n",
      "Ep:139, loss:0.00000, loss_test:0.10008, lr:3.93e-03, fs:0.61538 (r=0.460,p=0.930),  time:42.001, tt:5880.092\n",
      "Ep:140, loss:0.00000, loss_test:0.09877, lr:3.89e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.994, tt:5921.123\n",
      "Ep:141, loss:0.00000, loss_test:0.10168, lr:3.85e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.971, tt:5959.846\n",
      "Ep:142, loss:0.00000, loss_test:0.10016, lr:3.81e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.977, tt:6002.681\n",
      "Ep:143, loss:0.00000, loss_test:0.10023, lr:3.77e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.966, tt:6043.140\n",
      "Ep:144, loss:0.00000, loss_test:0.10007, lr:3.73e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.955, tt:6083.483\n",
      "Ep:145, loss:0.00000, loss_test:0.09928, lr:3.70e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.943, tt:6123.678\n",
      "Ep:146, loss:0.00000, loss_test:0.09902, lr:3.66e-03, fs:0.62595 (r=0.471,p=0.932),  time:41.933, tt:6164.131\n",
      "Ep:147, loss:0.00000, loss_test:0.10114, lr:3.62e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.913, tt:6203.138\n",
      "Ep:148, loss:0.00000, loss_test:0.09979, lr:3.59e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.908, tt:6244.281\n",
      "Ep:149, loss:0.00000, loss_test:0.10048, lr:3.55e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.903, tt:6285.478\n",
      "Ep:150, loss:0.00000, loss_test:0.10086, lr:3.52e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.901, tt:6327.028\n",
      "Ep:151, loss:0.00000, loss_test:0.09988, lr:3.48e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.902, tt:6369.067\n",
      "Ep:152, loss:0.00000, loss_test:0.10024, lr:3.45e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.903, tt:6411.167\n",
      "Ep:153, loss:0.00000, loss_test:0.10012, lr:3.41e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.904, tt:6453.286\n",
      "Ep:154, loss:0.00000, loss_test:0.10117, lr:3.38e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.906, tt:6495.415\n",
      "Ep:155, loss:0.00000, loss_test:0.10047, lr:3.34e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.898, tt:6536.111\n",
      "Ep:156, loss:0.00000, loss_test:0.10037, lr:3.31e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.897, tt:6577.821\n",
      "Ep:157, loss:0.00000, loss_test:0.10160, lr:3.28e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.896, tt:6619.504\n",
      "Ep:158, loss:0.00000, loss_test:0.10002, lr:3.24e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.879, tt:6658.819\n",
      "Ep:159, loss:0.00000, loss_test:0.10108, lr:3.21e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.878, tt:6700.467\n",
      "Ep:160, loss:0.00000, loss_test:0.10151, lr:3.18e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.869, tt:6740.891\n",
      "Ep:161, loss:0.00000, loss_test:0.09972, lr:3.15e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.858, tt:6780.964\n",
      "Ep:162, loss:0.00000, loss_test:0.10253, lr:3.12e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.839, tt:6819.820\n",
      "Ep:163, loss:0.00000, loss_test:0.10261, lr:3.09e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.848, tt:6863.051\n",
      "Ep:164, loss:0.00000, loss_test:0.10017, lr:3.05e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.838, tt:6903.341\n",
      "Ep:165, loss:0.00000, loss_test:0.10154, lr:3.02e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.827, tt:6943.273\n",
      "Ep:166, loss:0.00000, loss_test:0.10180, lr:2.99e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.828, tt:6985.301\n",
      "Ep:167, loss:0.00000, loss_test:0.10035, lr:2.96e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.825, tt:7026.541\n",
      "Ep:168, loss:0.00000, loss_test:0.10184, lr:2.93e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.833, tt:7069.836\n",
      "Ep:169, loss:0.00000, loss_test:0.10091, lr:2.90e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.829, tt:7111.002\n",
      "Ep:170, loss:0.00000, loss_test:0.10084, lr:2.88e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.816, tt:7150.584\n",
      "Ep:171, loss:0.00000, loss_test:0.10185, lr:2.85e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.830, tt:7194.751\n",
      "Ep:172, loss:0.00000, loss_test:0.10149, lr:2.82e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.830, tt:7236.564\n",
      "Ep:173, loss:0.00000, loss_test:0.10133, lr:2.79e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.845, tt:7280.949\n",
      "Ep:174, loss:0.00000, loss_test:0.10281, lr:2.76e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.844, tt:7322.741\n",
      "Ep:175, loss:0.00000, loss_test:0.10193, lr:2.73e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.844, tt:7364.531\n",
      "Ep:176, loss:0.00000, loss_test:0.10094, lr:2.71e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.837, tt:7405.067\n",
      "Ep:177, loss:0.00000, loss_test:0.10320, lr:2.68e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.832, tt:7446.011\n",
      "Ep:178, loss:0.00000, loss_test:0.10252, lr:2.65e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.825, tt:7486.613\n",
      "Ep:179, loss:0.00000, loss_test:0.10077, lr:2.63e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.826, tt:7528.641\n",
      "Ep:180, loss:0.00000, loss_test:0.10175, lr:2.60e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.821, tt:7569.589\n",
      "Ep:181, loss:0.00000, loss_test:0.10178, lr:2.57e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.819, tt:7611.044\n",
      "Ep:182, loss:0.00000, loss_test:0.10108, lr:2.55e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.827, tt:7654.267\n",
      "Ep:183, loss:0.00000, loss_test:0.10247, lr:2.52e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.828, tt:7696.433\n",
      "Ep:184, loss:0.00000, loss_test:0.10261, lr:2.50e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.830, tt:7738.534\n",
      "Ep:185, loss:0.00000, loss_test:0.10142, lr:2.47e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.835, tt:7781.246\n",
      "Ep:186, loss:0.00000, loss_test:0.10229, lr:2.45e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.846, tt:7825.258\n",
      "Ep:187, loss:0.00000, loss_test:0.10206, lr:2.42e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.849, tt:7867.604\n",
      "Ep:188, loss:0.00000, loss_test:0.10168, lr:2.40e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.852, tt:7910.107\n",
      "Ep:189, loss:0.00000, loss_test:0.10228, lr:2.38e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.860, tt:7953.355\n",
      "Ep:190, loss:0.00000, loss_test:0.10167, lr:2.35e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.865, tt:7996.283\n",
      "Ep:191, loss:0.00000, loss_test:0.10201, lr:2.33e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.860, tt:8037.174\n",
      "Ep:192, loss:0.00000, loss_test:0.10260, lr:2.31e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.854, tt:8077.813\n",
      "Ep:193, loss:0.00000, loss_test:0.10173, lr:2.28e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.852, tt:8119.219\n",
      "Ep:194, loss:0.00000, loss_test:0.10252, lr:2.26e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.853, tt:8161.288\n",
      "Ep:195, loss:0.00000, loss_test:0.10328, lr:2.24e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.845, tt:8201.638\n",
      "Ep:196, loss:0.00000, loss_test:0.10218, lr:2.21e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.846, tt:8243.577\n",
      "Ep:197, loss:0.00000, loss_test:0.10180, lr:2.19e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.842, tt:8284.708\n",
      "Ep:198, loss:0.00000, loss_test:0.10245, lr:2.17e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.843, tt:8326.810\n",
      "Ep:199, loss:0.00000, loss_test:0.10185, lr:2.15e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.835, tt:8367.089\n",
      "Ep:200, loss:0.00000, loss_test:0.10167, lr:2.13e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.835, tt:8408.800\n",
      "Ep:201, loss:0.00000, loss_test:0.10286, lr:2.11e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.853, tt:8454.234\n",
      "Ep:202, loss:0.00000, loss_test:0.10256, lr:2.08e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.853, tt:8496.133\n",
      "Ep:203, loss:0.00000, loss_test:0.10162, lr:2.06e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.842, tt:8535.681\n",
      "Ep:204, loss:0.00000, loss_test:0.10260, lr:2.04e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.842, tt:8577.569\n",
      "Ep:205, loss:0.00000, loss_test:0.10358, lr:2.02e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.835, tt:8617.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.10270, lr:2.00e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.836, tt:8660.054\n",
      "Ep:207, loss:0.00000, loss_test:0.10161, lr:1.98e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.836, tt:8701.950\n",
      "Ep:208, loss:0.00000, loss_test:0.10313, lr:1.96e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.833, tt:8743.197\n",
      "Ep:209, loss:0.00000, loss_test:0.10402, lr:1.94e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.838, tt:8785.964\n",
      "Ep:210, loss:0.00000, loss_test:0.10292, lr:1.92e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.840, tt:8828.246\n",
      "Ep:211, loss:0.00000, loss_test:0.10175, lr:1.90e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.835, tt:8868.945\n",
      "Ep:212, loss:0.00000, loss_test:0.10333, lr:1.89e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.800, tt:8903.407\n",
      "Ep:213, loss:0.00000, loss_test:0.10358, lr:1.87e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.740, tt:8932.397\n",
      "Ep:214, loss:0.00000, loss_test:0.10246, lr:1.85e-03, fs:0.61538 (r=0.460,p=0.930),  time:41.639, tt:8952.450\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02249, lr:6.00e-02, fs:0.61069 (r=0.808,p=0.491),  time:14.268, tt:14.268\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02356, lr:6.00e-02, fs:0.63636 (r=0.919,p=0.487),  time:21.226, tt:42.452\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02369, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:25.025, tt:75.076\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:28.876, tt:115.504\n",
      "Ep:4, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:30.935, tt:154.674\n",
      "Ep:5, loss:0.00004, loss_test:0.02069, lr:6.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:32.318, tt:193.906\n",
      "Ep:6, loss:0.00004, loss_test:0.02047, lr:6.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:33.341, tt:233.387\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02024, lr:6.00e-02, fs:0.64035 (r=0.737,p=0.566),  time:34.255, tt:274.041\n",
      "Ep:8, loss:0.00004, loss_test:0.01967, lr:6.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:35.021, tt:315.189\n",
      "Ep:9, loss:0.00003, loss_test:0.01927, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:35.759, tt:357.589\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01902, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:36.163, tt:397.791\n",
      "Ep:11, loss:0.00003, loss_test:0.01875, lr:6.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:36.469, tt:437.627\n",
      "Ep:12, loss:0.00003, loss_test:0.01865, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:36.822, tt:478.687\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01864, lr:6.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:36.997, tt:517.959\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01863, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:37.259, tt:558.892\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:37.394, tt:598.306\n",
      "Ep:16, loss:0.00003, loss_test:0.01851, lr:6.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:37.586, tt:638.965\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01846, lr:6.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:37.827, tt:680.877\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01840, lr:6.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:37.885, tt:719.814\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01835, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:38.002, tt:760.041\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01824, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:38.100, tt:800.090\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01815, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:38.189, tt:840.167\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01798, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:38.308, tt:881.094\n",
      "Ep:23, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:38.384, tt:921.217\n",
      "Ep:24, loss:0.00002, loss_test:0.01783, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:38.402, tt:960.057\n",
      "Ep:25, loss:0.00002, loss_test:0.01780, lr:6.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:38.506, tt:1001.149\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01771, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:38.599, tt:1042.181\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01761, lr:6.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:38.661, tt:1082.516\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01759, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:38.702, tt:1122.350\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01752, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:38.844, tt:1165.328\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01742, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:38.917, tt:1206.419\n",
      "Ep:31, loss:0.00002, loss_test:0.01740, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:39.010, tt:1248.327\n",
      "Ep:32, loss:0.00002, loss_test:0.01741, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:39.056, tt:1288.838\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01737, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:39.082, tt:1328.795\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01734, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:39.120, tt:1369.217\n",
      "Ep:35, loss:0.00002, loss_test:0.01732, lr:6.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:39.176, tt:1410.345\n",
      "Ep:36, loss:0.00002, loss_test:0.01744, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:39.258, tt:1452.552\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01743, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:39.296, tt:1493.261\n",
      "Ep:38, loss:0.00002, loss_test:0.01740, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:39.320, tt:1533.472\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01745, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:39.350, tt:1574.003\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01757, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:39.401, tt:1615.443\n",
      "Ep:41, loss:0.00002, loss_test:0.01749, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:39.440, tt:1656.470\n",
      "Ep:42, loss:0.00001, loss_test:0.01748, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:39.483, tt:1697.773\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01764, lr:6.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:39.476, tt:1736.928\n",
      "Ep:44, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:39.491, tt:1777.115\n",
      "Ep:45, loss:0.00001, loss_test:0.01767, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:39.520, tt:1817.940\n",
      "Ep:46, loss:0.00001, loss_test:0.01756, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:39.511, tt:1857.016\n",
      "Ep:47, loss:0.00001, loss_test:0.01777, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:39.566, tt:1899.175\n",
      "Ep:48, loss:0.00001, loss_test:0.01763, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:39.586, tt:1939.690\n",
      "Ep:49, loss:0.00001, loss_test:0.01769, lr:6.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:39.622, tt:1981.109\n",
      "Ep:50, loss:0.00001, loss_test:0.01776, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:39.662, tt:2022.783\n",
      "Ep:51, loss:0.00001, loss_test:0.01772, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:39.672, tt:2062.951\n",
      "Ep:52, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:39.694, tt:2103.793\n",
      "Ep:53, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:39.698, tt:2143.717\n",
      "Ep:54, loss:0.00001, loss_test:0.01763, lr:5.94e-02, fs:0.81773 (r=0.838,p=0.798),  time:39.696, tt:2183.261\n",
      "Ep:55, loss:0.00001, loss_test:0.01769, lr:5.88e-02, fs:0.81773 (r=0.838,p=0.798),  time:39.684, tt:2222.306\n",
      "Ep:56, loss:0.00001, loss_test:0.01772, lr:5.82e-02, fs:0.82178 (r=0.838,p=0.806),  time:39.682, tt:2261.882\n",
      "Ep:57, loss:0.00001, loss_test:0.01765, lr:5.76e-02, fs:0.82178 (r=0.838,p=0.806),  time:39.663, tt:2300.461\n",
      "Ep:58, loss:0.00001, loss_test:0.01760, lr:5.71e-02, fs:0.82178 (r=0.838,p=0.806),  time:39.648, tt:2339.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01761, lr:5.65e-02, fs:0.82178 (r=0.838,p=0.806),  time:39.637, tt:2378.247\n",
      "Ep:60, loss:0.00001, loss_test:0.01762, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:39.635, tt:2417.723\n",
      "Ep:61, loss:0.00001, loss_test:0.01760, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.634, tt:2457.322\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01761, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.639, tt:2497.271\n",
      "Ep:63, loss:0.00001, loss_test:0.01755, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.658, tt:2538.100\n",
      "Ep:64, loss:0.00001, loss_test:0.01756, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.633, tt:2576.155\n",
      "Ep:65, loss:0.00001, loss_test:0.01763, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.608, tt:2614.149\n",
      "Ep:66, loss:0.00001, loss_test:0.01755, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.614, tt:2654.112\n",
      "Ep:67, loss:0.00001, loss_test:0.01758, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.594, tt:2692.366\n",
      "Ep:68, loss:0.00001, loss_test:0.01761, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.580, tt:2731.008\n",
      "Ep:69, loss:0.00001, loss_test:0.01753, lr:5.54e-02, fs:0.83000 (r=0.838,p=0.822),  time:39.544, tt:2768.072\n",
      "Ep:70, loss:0.00001, loss_test:0.01757, lr:5.54e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.529, tt:2806.535\n",
      "Ep:71, loss:0.00001, loss_test:0.01755, lr:5.54e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.539, tt:2846.781\n",
      "Ep:72, loss:0.00001, loss_test:0.01760, lr:5.54e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.563, tt:2888.109\n",
      "Ep:73, loss:0.00001, loss_test:0.01754, lr:5.48e-02, fs:0.82828 (r=0.828,p=0.828),  time:39.555, tt:2927.047\n",
      "Ep:74, loss:0.00001, loss_test:0.01762, lr:5.43e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.560, tt:2967.018\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01764, lr:5.43e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.608, tt:3010.199\n",
      "Ep:76, loss:0.00001, loss_test:0.01766, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:39.592, tt:3048.555\n",
      "Ep:77, loss:0.00001, loss_test:0.01764, lr:5.43e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.598, tt:3088.638\n",
      "Ep:78, loss:0.00001, loss_test:0.01762, lr:5.43e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.616, tt:3129.661\n",
      "Ep:79, loss:0.00001, loss_test:0.01772, lr:5.43e-02, fs:0.82051 (r=0.808,p=0.833),  time:39.642, tt:3171.365\n",
      "Ep:80, loss:0.00001, loss_test:0.01769, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:39.657, tt:3212.196\n",
      "Ep:81, loss:0.00001, loss_test:0.01762, lr:5.43e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.675, tt:3253.382\n",
      "Ep:82, loss:0.00001, loss_test:0.01771, lr:5.43e-02, fs:0.82653 (r=0.818,p=0.835),  time:39.672, tt:3292.773\n",
      "Ep:83, loss:0.00001, loss_test:0.01774, lr:5.43e-02, fs:0.81443 (r=0.798,p=0.832),  time:39.667, tt:3332.000\n",
      "Ep:84, loss:0.00001, loss_test:0.01769, lr:5.43e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.677, tt:3372.507\n",
      "Ep:85, loss:0.00001, loss_test:0.01780, lr:5.43e-02, fs:0.82474 (r=0.808,p=0.842),  time:39.691, tt:3413.421\n",
      "Ep:86, loss:0.00001, loss_test:0.01776, lr:5.37e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.689, tt:3452.929\n",
      "Ep:87, loss:0.00001, loss_test:0.01771, lr:5.32e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.705, tt:3494.031\n",
      "Ep:88, loss:0.00001, loss_test:0.01783, lr:5.27e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.804, tt:3542.519\n",
      "Ep:89, loss:0.00001, loss_test:0.01779, lr:5.21e-02, fs:0.81865 (r=0.798,p=0.840),  time:39.803, tt:3582.259\n",
      "Ep:90, loss:0.00001, loss_test:0.01793, lr:5.16e-02, fs:0.82292 (r=0.798,p=0.849),  time:39.789, tt:3620.789\n",
      "Ep:91, loss:0.00001, loss_test:0.01789, lr:5.11e-02, fs:0.82292 (r=0.798,p=0.849),  time:39.755, tt:3657.496\n",
      "Ep:92, loss:0.00001, loss_test:0.01780, lr:5.06e-02, fs:0.82292 (r=0.798,p=0.849),  time:39.752, tt:3696.954\n",
      "Ep:93, loss:0.00001, loss_test:0.01805, lr:5.01e-02, fs:0.82292 (r=0.798,p=0.849),  time:39.754, tt:3736.869\n",
      "Ep:94, loss:0.00001, loss_test:0.01792, lr:4.96e-02, fs:0.81053 (r=0.778,p=0.846),  time:39.752, tt:3776.407\n",
      "Ep:95, loss:0.00001, loss_test:0.01786, lr:4.91e-02, fs:0.81675 (r=0.788,p=0.848),  time:39.765, tt:3817.425\n",
      "Ep:96, loss:0.00001, loss_test:0.01795, lr:4.86e-02, fs:0.81675 (r=0.788,p=0.848),  time:39.801, tt:3860.652\n",
      "Ep:97, loss:0.00001, loss_test:0.01811, lr:4.81e-02, fs:0.81053 (r=0.778,p=0.846),  time:39.812, tt:3901.573\n",
      "Ep:98, loss:0.00001, loss_test:0.01792, lr:4.76e-02, fs:0.81053 (r=0.778,p=0.846),  time:39.816, tt:3941.832\n",
      "Ep:99, loss:0.00001, loss_test:0.01808, lr:4.71e-02, fs:0.82540 (r=0.788,p=0.867),  time:39.808, tt:3980.779\n",
      "Ep:100, loss:0.00001, loss_test:0.01820, lr:4.67e-02, fs:0.81915 (r=0.778,p=0.865),  time:39.808, tt:4020.590\n",
      "Ep:101, loss:0.00001, loss_test:0.01796, lr:4.62e-02, fs:0.82353 (r=0.778,p=0.875),  time:39.795, tt:4059.098\n",
      "Ep:102, loss:0.00001, loss_test:0.01817, lr:4.57e-02, fs:0.82979 (r=0.788,p=0.876),  time:39.809, tt:4100.292\n",
      "Ep:103, loss:0.00001, loss_test:0.01827, lr:4.53e-02, fs:0.81081 (r=0.758,p=0.872),  time:39.804, tt:4139.596\n",
      "Ep:104, loss:0.00001, loss_test:0.01817, lr:4.48e-02, fs:0.82353 (r=0.778,p=0.875),  time:39.792, tt:4178.211\n",
      "Ep:105, loss:0.00001, loss_test:0.01822, lr:4.44e-02, fs:0.81720 (r=0.768,p=0.874),  time:39.801, tt:4218.875\n",
      "Ep:106, loss:0.00001, loss_test:0.01830, lr:4.39e-02, fs:0.81081 (r=0.758,p=0.872),  time:39.778, tt:4256.234\n",
      "Ep:107, loss:0.00001, loss_test:0.01838, lr:4.35e-02, fs:0.82162 (r=0.768,p=0.884),  time:39.778, tt:4295.997\n",
      "Ep:108, loss:0.00001, loss_test:0.01828, lr:4.31e-02, fs:0.81720 (r=0.768,p=0.874),  time:39.779, tt:4335.889\n",
      "Ep:109, loss:0.00000, loss_test:0.01839, lr:4.26e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.839, tt:4382.284\n",
      "Ep:110, loss:0.00000, loss_test:0.01840, lr:4.22e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.840, tt:4422.256\n",
      "Ep:111, loss:0.00000, loss_test:0.01844, lr:4.18e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.845, tt:4462.646\n",
      "Ep:112, loss:0.00000, loss_test:0.01844, lr:4.14e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.861, tt:4504.308\n",
      "Ep:113, loss:0.00000, loss_test:0.01847, lr:4.10e-02, fs:0.81522 (r=0.758,p=0.882),  time:39.870, tt:4545.191\n",
      "Ep:114, loss:0.00000, loss_test:0.01853, lr:4.05e-02, fs:0.80874 (r=0.747,p=0.881),  time:39.880, tt:4586.177\n",
      "Ep:115, loss:0.00000, loss_test:0.01840, lr:4.01e-02, fs:0.82418 (r=0.758,p=0.904),  time:39.886, tt:4626.785\n",
      "Ep:116, loss:0.00000, loss_test:0.01861, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:39.892, tt:4667.380\n",
      "Ep:117, loss:0.00000, loss_test:0.01848, lr:3.93e-02, fs:0.82418 (r=0.758,p=0.904),  time:39.883, tt:4706.217\n",
      "Ep:118, loss:0.00000, loss_test:0.01866, lr:3.89e-02, fs:0.82222 (r=0.747,p=0.914),  time:39.885, tt:4746.258\n",
      "Ep:119, loss:0.00000, loss_test:0.01863, lr:3.86e-02, fs:0.82222 (r=0.747,p=0.914),  time:39.893, tt:4787.208\n",
      "Ep:120, loss:0.00000, loss_test:0.01855, lr:3.82e-02, fs:0.82873 (r=0.758,p=0.915),  time:39.882, tt:4825.767\n",
      "Ep:121, loss:0.00000, loss_test:0.01878, lr:3.78e-02, fs:0.82682 (r=0.747,p=0.925),  time:39.894, tt:4867.065\n",
      "Ep:122, loss:0.00000, loss_test:0.01862, lr:3.74e-02, fs:0.83333 (r=0.758,p=0.926),  time:39.913, tt:4909.260\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01875, lr:3.74e-02, fs:0.82682 (r=0.747,p=0.925),  time:39.921, tt:4950.174\n",
      "Ep:124, loss:0.00000, loss_test:0.01880, lr:3.74e-02, fs:0.82682 (r=0.747,p=0.925),  time:39.917, tt:4989.650\n",
      "Ep:125, loss:0.00000, loss_test:0.01868, lr:3.74e-02, fs:0.82022 (r=0.737,p=0.924),  time:39.922, tt:5030.182\n",
      "Ep:126, loss:0.00000, loss_test:0.01890, lr:3.74e-02, fs:0.81356 (r=0.727,p=0.923),  time:39.923, tt:5070.220\n",
      "Ep:127, loss:0.00000, loss_test:0.01882, lr:3.74e-02, fs:0.82682 (r=0.747,p=0.925),  time:39.928, tt:5110.730\n",
      "Ep:128, loss:0.00000, loss_test:0.01881, lr:3.74e-02, fs:0.82486 (r=0.737,p=0.936),  time:39.933, tt:5151.402\n",
      "Ep:129, loss:0.00000, loss_test:0.01897, lr:3.74e-02, fs:0.80000 (r=0.707,p=0.921),  time:39.937, tt:5191.842\n",
      "Ep:130, loss:0.00000, loss_test:0.01892, lr:3.74e-02, fs:0.81143 (r=0.717,p=0.934),  time:39.984, tt:5237.882\n",
      "Ep:131, loss:0.00000, loss_test:0.01897, lr:3.74e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.971, tt:5276.218\n",
      "Ep:132, loss:0.00000, loss_test:0.01888, lr:3.74e-02, fs:0.81143 (r=0.717,p=0.934),  time:39.975, tt:5316.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01908, lr:3.74e-02, fs:0.79070 (r=0.687,p=0.932),  time:39.971, tt:5356.133\n",
      "Ep:134, loss:0.00000, loss_test:0.01893, lr:3.70e-02, fs:0.79769 (r=0.697,p=0.932),  time:39.972, tt:5396.280\n",
      "Ep:135, loss:0.00000, loss_test:0.01896, lr:3.67e-02, fs:0.79070 (r=0.687,p=0.932),  time:39.976, tt:5436.691\n",
      "Ep:136, loss:0.00000, loss_test:0.01904, lr:3.63e-02, fs:0.79070 (r=0.687,p=0.932),  time:39.972, tt:5476.154\n",
      "Ep:137, loss:0.00000, loss_test:0.01903, lr:3.59e-02, fs:0.79070 (r=0.687,p=0.932),  time:39.982, tt:5517.569\n",
      "Ep:138, loss:0.00000, loss_test:0.01913, lr:3.56e-02, fs:0.78363 (r=0.677,p=0.931),  time:39.983, tt:5557.567\n",
      "Ep:139, loss:0.00000, loss_test:0.01911, lr:3.52e-02, fs:0.78363 (r=0.677,p=0.931),  time:39.985, tt:5597.875\n",
      "Ep:140, loss:0.00000, loss_test:0.01905, lr:3.49e-02, fs:0.78363 (r=0.677,p=0.931),  time:39.985, tt:5637.894\n",
      "Ep:141, loss:0.00000, loss_test:0.01920, lr:3.45e-02, fs:0.76923 (r=0.657,p=0.929),  time:39.983, tt:5677.573\n",
      "Ep:142, loss:0.00000, loss_test:0.01917, lr:3.42e-02, fs:0.75449 (r=0.636,p=0.926),  time:39.986, tt:5718.023\n",
      "Ep:143, loss:0.00000, loss_test:0.01921, lr:3.38e-02, fs:0.75449 (r=0.636,p=0.926),  time:39.982, tt:5757.398\n",
      "Ep:144, loss:0.00000, loss_test:0.01921, lr:3.35e-02, fs:0.75449 (r=0.636,p=0.926),  time:39.984, tt:5797.724\n",
      "Ep:145, loss:0.00000, loss_test:0.01932, lr:3.32e-02, fs:0.74699 (r=0.626,p=0.925),  time:39.976, tt:5836.477\n",
      "Ep:146, loss:0.00000, loss_test:0.01930, lr:3.28e-02, fs:0.74699 (r=0.626,p=0.925),  time:39.978, tt:5876.819\n",
      "Ep:147, loss:0.00000, loss_test:0.01935, lr:3.25e-02, fs:0.74699 (r=0.626,p=0.925),  time:39.984, tt:5917.677\n",
      "Ep:148, loss:0.00000, loss_test:0.01937, lr:3.22e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.977, tt:5956.552\n",
      "Ep:149, loss:0.00000, loss_test:0.01936, lr:3.19e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.981, tt:5997.179\n",
      "Ep:150, loss:0.00000, loss_test:0.01936, lr:3.15e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.980, tt:6036.979\n",
      "Ep:151, loss:0.00000, loss_test:0.01936, lr:3.12e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.988, tt:6078.211\n",
      "Ep:152, loss:0.00000, loss_test:0.01946, lr:3.09e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.986, tt:6117.862\n",
      "Ep:153, loss:0.00000, loss_test:0.01946, lr:3.06e-02, fs:0.73939 (r=0.616,p=0.924),  time:39.979, tt:6156.717\n",
      "Ep:154, loss:0.00000, loss_test:0.01945, lr:3.03e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.987, tt:6197.947\n",
      "Ep:155, loss:0.00000, loss_test:0.01945, lr:3.00e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.986, tt:6237.858\n",
      "Ep:156, loss:0.00000, loss_test:0.01957, lr:2.97e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.985, tt:6277.709\n",
      "Ep:157, loss:0.00000, loss_test:0.01956, lr:2.94e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.988, tt:6318.080\n",
      "Ep:158, loss:0.00000, loss_test:0.01953, lr:2.91e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.992, tt:6358.733\n",
      "Ep:159, loss:0.00000, loss_test:0.01956, lr:2.88e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.997, tt:6399.549\n",
      "Ep:160, loss:0.00000, loss_test:0.01959, lr:2.85e-02, fs:0.73171 (r=0.606,p=0.923),  time:39.983, tt:6437.228\n",
      "Ep:161, loss:0.00000, loss_test:0.01965, lr:2.82e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.971, tt:6475.243\n",
      "Ep:162, loss:0.00000, loss_test:0.01963, lr:2.80e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.969, tt:6514.932\n",
      "Ep:163, loss:0.00000, loss_test:0.01961, lr:2.77e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.968, tt:6554.708\n",
      "Ep:164, loss:0.00000, loss_test:0.01970, lr:2.74e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.964, tt:6594.102\n",
      "Ep:165, loss:0.00000, loss_test:0.01970, lr:2.71e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.969, tt:6634.869\n",
      "Ep:166, loss:0.00000, loss_test:0.01967, lr:2.69e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.969, tt:6674.752\n",
      "Ep:167, loss:0.00000, loss_test:0.01982, lr:2.66e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.975, tt:6715.745\n",
      "Ep:168, loss:0.00000, loss_test:0.01975, lr:2.63e-02, fs:0.72393 (r=0.596,p=0.922),  time:39.985, tt:6757.479\n",
      "Ep:169, loss:0.00000, loss_test:0.01979, lr:2.61e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.978, tt:6796.262\n",
      "Ep:170, loss:0.00000, loss_test:0.01980, lr:2.58e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.960, tt:6833.186\n",
      "Ep:171, loss:0.00000, loss_test:0.01987, lr:2.55e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.964, tt:6873.780\n",
      "Ep:172, loss:0.00000, loss_test:0.01984, lr:2.53e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.958, tt:6912.790\n",
      "Ep:173, loss:0.00000, loss_test:0.01989, lr:2.50e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.961, tt:6953.257\n",
      "Ep:174, loss:0.00000, loss_test:0.01982, lr:2.48e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.961, tt:6993.136\n",
      "Ep:175, loss:0.00000, loss_test:0.01991, lr:2.45e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.973, tt:7035.195\n",
      "Ep:176, loss:0.00000, loss_test:0.01992, lr:2.43e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.968, tt:7074.261\n",
      "Ep:177, loss:0.00000, loss_test:0.01997, lr:2.40e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.967, tt:7114.184\n",
      "Ep:178, loss:0.00000, loss_test:0.01997, lr:2.38e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.965, tt:7153.735\n",
      "Ep:179, loss:0.00000, loss_test:0.01994, lr:2.36e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.961, tt:7193.023\n",
      "Ep:180, loss:0.00000, loss_test:0.01995, lr:2.33e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.987, tt:7237.731\n",
      "Ep:181, loss:0.00000, loss_test:0.01999, lr:2.31e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.980, tt:7276.279\n",
      "Ep:182, loss:0.00000, loss_test:0.02006, lr:2.29e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.986, tt:7317.366\n",
      "Ep:183, loss:0.00000, loss_test:0.01997, lr:2.26e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.985, tt:7357.284\n",
      "Ep:184, loss:0.00000, loss_test:0.02002, lr:2.24e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.996, tt:7399.220\n",
      "Ep:185, loss:0.00000, loss_test:0.02008, lr:2.22e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.997, tt:7439.366\n",
      "Ep:186, loss:0.00000, loss_test:0.02006, lr:2.20e-02, fs:0.71605 (r=0.586,p=0.921),  time:40.001, tt:7480.185\n",
      "Ep:187, loss:0.00000, loss_test:0.02011, lr:2.17e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.998, tt:7519.620\n",
      "Ep:188, loss:0.00000, loss_test:0.02007, lr:2.15e-02, fs:0.71605 (r=0.586,p=0.921),  time:39.999, tt:7559.851\n",
      "Ep:189, loss:0.00000, loss_test:0.02012, lr:2.13e-02, fs:0.71605 (r=0.586,p=0.921),  time:40.009, tt:7601.782\n",
      "Ep:190, loss:0.00000, loss_test:0.02013, lr:2.11e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.005, tt:7641.009\n",
      "Ep:191, loss:0.00000, loss_test:0.02012, lr:2.09e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.014, tt:7682.769\n",
      "Ep:192, loss:0.00000, loss_test:0.02019, lr:2.07e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.024, tt:7724.652\n",
      "Ep:193, loss:0.00000, loss_test:0.02015, lr:2.05e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.016, tt:7763.094\n",
      "Ep:194, loss:0.00000, loss_test:0.02016, lr:2.03e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.021, tt:7804.001\n",
      "Ep:195, loss:0.00000, loss_test:0.02022, lr:2.01e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.024, tt:7844.708\n",
      "Ep:196, loss:0.00000, loss_test:0.02021, lr:1.99e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.022, tt:7884.267\n",
      "Ep:197, loss:0.00000, loss_test:0.02021, lr:1.97e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.023, tt:7924.526\n",
      "Ep:198, loss:0.00000, loss_test:0.02024, lr:1.95e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.019, tt:7963.721\n",
      "Ep:199, loss:0.00000, loss_test:0.02028, lr:1.93e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.028, tt:8005.689\n",
      "Ep:200, loss:0.00000, loss_test:0.02026, lr:1.91e-02, fs:0.72050 (r=0.586,p=0.935),  time:40.028, tt:8045.664\n",
      "Ep:201, loss:0.00000, loss_test:0.02031, lr:1.89e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.021, tt:8084.271\n",
      "Ep:202, loss:0.00000, loss_test:0.02031, lr:1.87e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.022, tt:8124.523\n",
      "Ep:203, loss:0.00000, loss_test:0.02029, lr:1.85e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.011, tt:8162.267\n",
      "Ep:204, loss:0.00000, loss_test:0.02037, lr:1.83e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.013, tt:8202.727\n",
      "Ep:205, loss:0.00000, loss_test:0.02036, lr:1.81e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.013, tt:8242.705\n",
      "Ep:206, loss:0.00000, loss_test:0.02034, lr:1.80e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.015, tt:8283.111\n",
      "Ep:207, loss:0.00000, loss_test:0.02037, lr:1.78e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.025, tt:8325.106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:208, loss:0.00000, loss_test:0.02038, lr:1.76e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.018, tt:8363.795\n",
      "Ep:209, loss:0.00000, loss_test:0.02037, lr:1.74e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.017, tt:8403.470\n",
      "Ep:210, loss:0.00000, loss_test:0.02045, lr:1.73e-02, fs:0.71250 (r=0.576,p=0.934),  time:40.036, tt:8447.503\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14544, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.175, tt:28.175\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14466, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.694, tt:63.388\n",
      "Ep:2, loss:0.00028, loss_test:0.14331, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.674, tt:95.023\n",
      "Ep:3, loss:0.00028, loss_test:0.14108, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.477, tt:133.910\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00027, loss_test:0.13746, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:35.345, tt:176.726\n",
      "Ep:5, loss:0.00026, loss_test:0.13185, lr:1.00e-02, fs:0.65480 (r=0.929,p=0.505),  time:36.415, tt:218.487\n",
      "Ep:6, loss:0.00025, loss_test:0.12480, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:36.621, tt:256.349\n",
      "Ep:7, loss:0.00024, loss_test:0.11797, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:37.022, tt:296.173\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11381, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:37.477, tt:337.292\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11346, lr:1.00e-02, fs:0.69912 (r=0.798,p=0.622),  time:37.790, tt:377.898\n",
      "Ep:10, loss:0.00022, loss_test:0.11158, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:38.196, tt:420.158\n",
      "Ep:11, loss:0.00021, loss_test:0.10971, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:38.494, tt:461.933\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10806, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:38.508, tt:500.602\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10723, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:38.774, tt:542.833\n",
      "Ep:14, loss:0.00019, loss_test:0.10491, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:38.979, tt:584.680\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10172, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:39.319, tt:629.110\n",
      "Ep:16, loss:0.00017, loss_test:0.09929, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:39.598, tt:673.160\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09904, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:39.654, tt:713.766\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09773, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:39.777, tt:755.757\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09557, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:39.892, tt:797.844\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09474, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:39.998, tt:839.963\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.09466, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:40.128, tt:882.810\n",
      "Ep:22, loss:0.00013, loss_test:0.09239, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:40.224, tt:925.146\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.08943, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:40.250, tt:965.989\n",
      "Ep:24, loss:0.00012, loss_test:0.09114, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.262, tt:1006.553\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08773, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:40.351, tt:1049.130\n",
      "Ep:26, loss:0.00011, loss_test:0.08900, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:40.385, tt:1090.395\n",
      "Ep:27, loss:0.00011, loss_test:0.08755, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:40.367, tt:1130.278\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08346, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.404, tt:1171.709\n",
      "Ep:29, loss:0.00010, loss_test:0.08644, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:40.450, tt:1213.496\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08107, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:40.494, tt:1255.307\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08177, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:40.544, tt:1297.404\n",
      "Ep:32, loss:0.00009, loss_test:0.08013, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:40.574, tt:1338.951\n",
      "Ep:33, loss:0.00008, loss_test:0.07797, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:40.648, tt:1382.041\n",
      "Ep:34, loss:0.00008, loss_test:0.08060, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:40.649, tt:1422.712\n",
      "Ep:35, loss:0.00008, loss_test:0.07682, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:40.650, tt:1463.402\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07961, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:40.705, tt:1506.093\n",
      "Ep:37, loss:0.00007, loss_test:0.07592, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:40.743, tt:1548.228\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.07594, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:40.774, tt:1590.179\n",
      "Ep:39, loss:0.00007, loss_test:0.07191, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:40.799, tt:1631.941\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.08361, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:40.797, tt:1672.673\n",
      "Ep:41, loss:0.00007, loss_test:0.06882, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.868, tt:1716.464\n",
      "Ep:42, loss:0.00006, loss_test:0.08481, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:40.897, tt:1758.555\n",
      "Ep:43, loss:0.00006, loss_test:0.06897, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:40.932, tt:1801.026\n",
      "Ep:44, loss:0.00006, loss_test:0.08101, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:40.947, tt:1842.597\n",
      "Ep:45, loss:0.00005, loss_test:0.07093, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:40.951, tt:1883.748\n",
      "Ep:46, loss:0.00005, loss_test:0.08002, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:40.950, tt:1924.672\n",
      "Ep:47, loss:0.00005, loss_test:0.07044, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:40.975, tt:1966.799\n",
      "Ep:48, loss:0.00005, loss_test:0.07131, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:40.974, tt:2007.737\n",
      "Ep:49, loss:0.00005, loss_test:0.07185, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:41.004, tt:2050.217\n",
      "Ep:50, loss:0.00005, loss_test:0.07026, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:41.006, tt:2091.312\n",
      "Ep:51, loss:0.00004, loss_test:0.07371, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:41.022, tt:2133.135\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.07003, lr:9.90e-03, fs:0.78409 (r=0.697,p=0.896),  time:41.048, tt:2175.557\n",
      "Ep:53, loss:0.00004, loss_test:0.07065, lr:9.90e-03, fs:0.83333 (r=0.758,p=0.926),  time:41.062, tt:2217.340\n",
      "Ep:54, loss:0.00004, loss_test:0.07147, lr:9.90e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.079, tt:2259.352\n",
      "Ep:55, loss:0.00004, loss_test:0.07010, lr:9.90e-03, fs:0.79769 (r=0.697,p=0.932),  time:41.063, tt:2299.543\n",
      "Ep:56, loss:0.00004, loss_test:0.06806, lr:9.90e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.061, tt:2340.450\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.06963, lr:9.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:41.064, tt:2381.725\n",
      "Ep:58, loss:0.00003, loss_test:0.07433, lr:9.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.070, tt:2423.140\n",
      "Ep:59, loss:0.00003, loss_test:0.06871, lr:9.90e-03, fs:0.79310 (r=0.697,p=0.920),  time:41.081, tt:2464.879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00003, loss_test:0.07581, lr:9.90e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.086, tt:2506.275\n",
      "Ep:61, loss:0.00003, loss_test:0.07188, lr:9.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.090, tt:2547.562\n",
      "Ep:62, loss:0.00003, loss_test:0.07217, lr:9.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.062, tt:2586.918\n",
      "Ep:63, loss:0.00003, loss_test:0.07258, lr:9.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.113, tt:2631.206\n",
      "Ep:64, loss:0.00003, loss_test:0.07341, lr:9.90e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.087, tt:2670.670\n",
      "Ep:65, loss:0.00002, loss_test:0.07295, lr:9.90e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.067, tt:2710.437\n",
      "Ep:66, loss:0.00002, loss_test:0.07763, lr:9.90e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.052, tt:2750.472\n",
      "Ep:67, loss:0.00002, loss_test:0.07184, lr:9.90e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.071, tt:2792.827\n",
      "Ep:68, loss:0.00002, loss_test:0.08265, lr:9.80e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.066, tt:2833.586\n",
      "Ep:69, loss:0.00002, loss_test:0.07656, lr:9.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:41.076, tt:2875.330\n",
      "Ep:70, loss:0.00002, loss_test:0.07887, lr:9.61e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.085, tt:2917.069\n",
      "Ep:71, loss:0.00002, loss_test:0.07905, lr:9.51e-03, fs:0.80240 (r=0.677,p=0.985),  time:41.076, tt:2957.485\n",
      "Ep:72, loss:0.00002, loss_test:0.08396, lr:9.41e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.068, tt:2997.957\n",
      "Ep:73, loss:0.00002, loss_test:0.08040, lr:9.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.076, tt:3039.612\n",
      "Ep:74, loss:0.00002, loss_test:0.08179, lr:9.23e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.050, tt:3078.772\n",
      "Ep:75, loss:0.00002, loss_test:0.07931, lr:9.14e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.061, tt:3120.642\n",
      "Ep:76, loss:0.00002, loss_test:0.08200, lr:9.04e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.074, tt:3162.712\n",
      "Ep:77, loss:0.00002, loss_test:0.08206, lr:8.95e-03, fs:0.77381 (r=0.657,p=0.942),  time:41.078, tt:3204.083\n",
      "Ep:78, loss:0.00002, loss_test:0.08426, lr:8.86e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.087, tt:3245.906\n",
      "Ep:79, loss:0.00001, loss_test:0.08221, lr:8.78e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.101, tt:3288.045\n",
      "Ep:80, loss:0.00001, loss_test:0.07866, lr:8.69e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.090, tt:3328.321\n",
      "Ep:81, loss:0.00001, loss_test:0.08803, lr:8.60e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.090, tt:3369.349\n",
      "Ep:82, loss:0.00001, loss_test:0.08463, lr:8.51e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.111, tt:3412.254\n",
      "Ep:83, loss:0.00001, loss_test:0.08619, lr:8.43e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.138, tt:3455.564\n",
      "Ep:84, loss:0.00001, loss_test:0.08577, lr:8.35e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.139, tt:3496.775\n",
      "Ep:85, loss:0.00001, loss_test:0.08743, lr:8.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.134, tt:3537.517\n",
      "Ep:86, loss:0.00001, loss_test:0.08572, lr:8.18e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.137, tt:3578.928\n",
      "Ep:87, loss:0.00001, loss_test:0.08924, lr:8.10e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.152, tt:3621.378\n",
      "Ep:88, loss:0.00001, loss_test:0.08788, lr:8.02e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.177, tt:3664.790\n",
      "Ep:89, loss:0.00001, loss_test:0.08827, lr:7.94e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.189, tt:3707.009\n",
      "Ep:90, loss:0.00001, loss_test:0.08965, lr:7.86e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.200, tt:3749.223\n",
      "Ep:91, loss:0.00001, loss_test:0.08716, lr:7.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.205, tt:3790.819\n",
      "Ep:92, loss:0.00001, loss_test:0.08807, lr:7.70e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.236, tt:3834.911\n",
      "Ep:93, loss:0.00001, loss_test:0.08874, lr:7.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.284, tt:3880.666\n",
      "Ep:94, loss:0.00001, loss_test:0.08773, lr:7.55e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.286, tt:3922.177\n",
      "Ep:95, loss:0.00001, loss_test:0.09148, lr:7.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.300, tt:3964.780\n",
      "Ep:96, loss:0.00001, loss_test:0.08748, lr:7.40e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.314, tt:4007.419\n",
      "Ep:97, loss:0.00001, loss_test:0.08846, lr:7.32e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.299, tt:4047.311\n",
      "Ep:98, loss:0.00001, loss_test:0.09134, lr:7.25e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.306, tt:4089.297\n",
      "Ep:99, loss:0.00001, loss_test:0.09113, lr:7.18e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.312, tt:4131.187\n",
      "Ep:100, loss:0.00001, loss_test:0.09039, lr:7.11e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.318, tt:4173.153\n",
      "Ep:101, loss:0.00001, loss_test:0.09314, lr:7.03e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.336, tt:4216.225\n",
      "Ep:102, loss:0.00001, loss_test:0.08815, lr:6.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.359, tt:4259.945\n",
      "Ep:103, loss:0.00001, loss_test:0.09563, lr:6.89e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.364, tt:4301.893\n",
      "Ep:104, loss:0.00001, loss_test:0.09222, lr:6.83e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.383, tt:4345.187\n",
      "Ep:105, loss:0.00000, loss_test:0.09106, lr:6.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.394, tt:4387.813\n",
      "Ep:106, loss:0.00000, loss_test:0.09055, lr:6.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.396, tt:4429.421\n",
      "Ep:107, loss:0.00000, loss_test:0.08872, lr:6.62e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.423, tt:4473.689\n",
      "Ep:108, loss:0.00000, loss_test:0.08889, lr:6.56e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.451, tt:4518.144\n",
      "Ep:109, loss:0.00000, loss_test:0.09144, lr:6.49e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.472, tt:4561.943\n",
      "Ep:110, loss:0.00000, loss_test:0.08952, lr:6.43e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.473, tt:4603.494\n",
      "Ep:111, loss:0.00000, loss_test:0.08971, lr:6.36e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.474, tt:4645.057\n",
      "Ep:112, loss:0.00000, loss_test:0.09263, lr:6.30e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.469, tt:4686.020\n",
      "Ep:113, loss:0.00000, loss_test:0.08973, lr:6.24e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.494, tt:4730.275\n",
      "Ep:114, loss:0.00000, loss_test:0.08972, lr:6.17e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.530, tt:4775.971\n",
      "Ep:115, loss:0.00000, loss_test:0.08992, lr:6.11e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.552, tt:4820.006\n",
      "Ep:116, loss:0.00000, loss_test:0.08889, lr:6.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.556, tt:4862.021\n",
      "Ep:117, loss:0.00000, loss_test:0.09051, lr:5.99e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.548, tt:4902.676\n",
      "Ep:118, loss:0.00000, loss_test:0.09187, lr:5.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.575, tt:4947.439\n",
      "Ep:119, loss:0.00000, loss_test:0.09060, lr:5.87e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.581, tt:4989.673\n",
      "Ep:120, loss:0.00000, loss_test:0.09153, lr:5.81e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.599, tt:5033.527\n",
      "Ep:121, loss:0.00000, loss_test:0.09116, lr:5.75e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.614, tt:5076.945\n",
      "Ep:122, loss:0.00000, loss_test:0.08986, lr:5.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.634, tt:5120.983\n",
      "Ep:123, loss:0.00000, loss_test:0.09021, lr:5.64e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.629, tt:5161.935\n",
      "Ep:124, loss:0.00000, loss_test:0.09004, lr:5.58e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.642, tt:5205.245\n",
      "Ep:125, loss:0.00000, loss_test:0.09136, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.658, tt:5248.948\n",
      "Ep:126, loss:0.00000, loss_test:0.08983, lr:5.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.671, tt:5292.208\n",
      "Ep:127, loss:0.00000, loss_test:0.09198, lr:5.42e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.684, tt:5335.550\n",
      "Ep:128, loss:0.00000, loss_test:0.09171, lr:5.36e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.714, tt:5381.169\n",
      "Ep:129, loss:0.00000, loss_test:0.09141, lr:5.31e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.731, tt:5425.009\n",
      "Ep:130, loss:0.00000, loss_test:0.09234, lr:5.26e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.753, tt:5469.668\n",
      "Ep:131, loss:0.00000, loss_test:0.09134, lr:5.20e-03, fs:0.78049 (r=0.646,p=0.985),  time:41.775, tt:5514.335\n",
      "Ep:132, loss:0.00000, loss_test:0.09148, lr:5.15e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.795, tt:5558.790\n",
      "Ep:133, loss:0.00000, loss_test:0.09060, lr:5.10e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.813, tt:5602.877\n",
      "Ep:134, loss:0.00000, loss_test:0.09094, lr:5.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.827, tt:5646.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.09180, lr:5.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.839, tt:5690.130\n",
      "Ep:136, loss:0.00000, loss_test:0.09204, lr:4.95e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.844, tt:5732.621\n",
      "Ep:137, loss:0.00000, loss_test:0.09257, lr:4.90e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.856, tt:5776.144\n",
      "Ep:138, loss:0.00000, loss_test:0.09170, lr:4.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.866, tt:5819.429\n",
      "Ep:139, loss:0.00000, loss_test:0.09073, lr:4.80e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.873, tt:5862.216\n",
      "Ep:140, loss:0.00000, loss_test:0.09173, lr:4.75e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.888, tt:5906.247\n",
      "Ep:141, loss:0.00000, loss_test:0.09263, lr:4.71e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.897, tt:5949.443\n",
      "Ep:142, loss:0.00000, loss_test:0.09167, lr:4.66e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.901, tt:5991.894\n",
      "Ep:143, loss:0.00000, loss_test:0.09230, lr:4.61e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.944, tt:6039.889\n",
      "Ep:144, loss:0.00000, loss_test:0.09273, lr:4.57e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.951, tt:6082.950\n",
      "Ep:145, loss:0.00000, loss_test:0.09208, lr:4.52e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.942, tt:6123.585\n",
      "Ep:146, loss:0.00000, loss_test:0.09217, lr:4.48e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.956, tt:6167.563\n",
      "Ep:147, loss:0.00000, loss_test:0.09218, lr:4.43e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.962, tt:6210.434\n",
      "Ep:148, loss:0.00000, loss_test:0.09163, lr:4.39e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.975, tt:6254.298\n",
      "Ep:149, loss:0.00000, loss_test:0.09240, lr:4.34e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.977, tt:6296.569\n",
      "Ep:150, loss:0.00000, loss_test:0.09278, lr:4.30e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.980, tt:6339.008\n",
      "Ep:151, loss:0.00000, loss_test:0.09170, lr:4.26e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.981, tt:6381.100\n",
      "Ep:152, loss:0.00000, loss_test:0.09235, lr:4.21e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.993, tt:6424.895\n",
      "Ep:153, loss:0.00000, loss_test:0.09261, lr:4.17e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.002, tt:6468.287\n",
      "Ep:154, loss:0.00000, loss_test:0.09183, lr:4.13e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.999, tt:6509.906\n",
      "Ep:155, loss:0.00000, loss_test:0.09219, lr:4.09e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.012, tt:6553.848\n",
      "Ep:156, loss:0.00000, loss_test:0.09268, lr:4.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.023, tt:6597.684\n",
      "Ep:157, loss:0.00000, loss_test:0.09268, lr:4.01e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.024, tt:6639.838\n",
      "Ep:158, loss:0.00000, loss_test:0.09244, lr:3.97e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.034, tt:6683.425\n",
      "Ep:159, loss:0.00000, loss_test:0.09270, lr:3.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.035, tt:6725.620\n",
      "Ep:160, loss:0.00000, loss_test:0.09314, lr:3.89e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.030, tt:6766.870\n",
      "Ep:161, loss:0.00000, loss_test:0.09248, lr:3.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.020, tt:6807.237\n",
      "Ep:162, loss:0.00000, loss_test:0.09243, lr:3.81e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.022, tt:6849.524\n",
      "Ep:163, loss:0.00000, loss_test:0.09242, lr:3.77e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.022, tt:6891.676\n",
      "Ep:164, loss:0.00000, loss_test:0.09188, lr:3.73e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.022, tt:6933.695\n",
      "Ep:165, loss:0.00000, loss_test:0.09276, lr:3.70e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.014, tt:6974.351\n",
      "Ep:166, loss:0.00000, loss_test:0.09322, lr:3.66e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.006, tt:7015.022\n",
      "Ep:167, loss:0.00000, loss_test:0.09336, lr:3.62e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.021, tt:7059.608\n",
      "Ep:168, loss:0.00000, loss_test:0.09321, lr:3.59e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.021, tt:7101.587\n",
      "Ep:169, loss:0.00000, loss_test:0.09288, lr:3.55e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.000, tt:7140.011\n",
      "Ep:170, loss:0.00000, loss_test:0.09298, lr:3.52e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.987, tt:7179.815\n",
      "Ep:171, loss:0.00000, loss_test:0.09347, lr:3.48e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.985, tt:7221.358\n",
      "Ep:172, loss:0.00000, loss_test:0.09270, lr:3.45e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.973, tt:7261.348\n",
      "Ep:173, loss:0.00000, loss_test:0.09231, lr:3.41e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.977, tt:7303.976\n",
      "Ep:174, loss:0.00000, loss_test:0.09281, lr:3.38e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.983, tt:7347.011\n",
      "Ep:175, loss:0.00000, loss_test:0.09203, lr:3.34e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.979, tt:7388.311\n",
      "Ep:176, loss:0.00000, loss_test:0.09252, lr:3.31e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.970, tt:7428.706\n",
      "Ep:177, loss:0.00000, loss_test:0.09322, lr:3.28e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.969, tt:7470.441\n",
      "Ep:178, loss:0.00000, loss_test:0.09240, lr:3.24e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.968, tt:7512.212\n",
      "Ep:179, loss:0.00000, loss_test:0.09268, lr:3.21e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.968, tt:7554.302\n",
      "Ep:180, loss:0.00000, loss_test:0.09263, lr:3.18e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.971, tt:7596.780\n",
      "Ep:181, loss:0.00000, loss_test:0.09268, lr:3.15e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.967, tt:7638.078\n",
      "Ep:182, loss:0.00000, loss_test:0.09336, lr:3.12e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.966, tt:7679.734\n",
      "Ep:183, loss:0.00000, loss_test:0.09311, lr:3.09e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.959, tt:7720.517\n",
      "Ep:184, loss:0.00000, loss_test:0.09197, lr:3.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.964, tt:7763.269\n",
      "Ep:185, loss:0.00000, loss_test:0.09272, lr:3.02e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.960, tt:7804.559\n",
      "Ep:186, loss:0.00000, loss_test:0.09267, lr:2.99e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.965, tt:7847.470\n",
      "Ep:187, loss:0.00000, loss_test:0.09232, lr:2.96e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.960, tt:7888.542\n",
      "Ep:188, loss:0.00000, loss_test:0.09249, lr:2.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.953, tt:7929.164\n",
      "Ep:189, loss:0.00000, loss_test:0.09263, lr:2.90e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.953, tt:7971.059\n",
      "Ep:190, loss:0.00000, loss_test:0.09260, lr:2.88e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.946, tt:8011.755\n",
      "Ep:191, loss:0.00000, loss_test:0.09250, lr:2.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.942, tt:8052.838\n",
      "Ep:192, loss:0.00000, loss_test:0.09240, lr:2.82e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.937, tt:8093.850\n",
      "Ep:193, loss:0.00000, loss_test:0.09271, lr:2.79e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.934, tt:8135.274\n",
      "Ep:194, loss:0.00000, loss_test:0.09351, lr:2.76e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.929, tt:8176.097\n",
      "Ep:195, loss:0.00000, loss_test:0.09298, lr:2.73e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.933, tt:8218.816\n",
      "Ep:196, loss:0.00000, loss_test:0.09225, lr:2.71e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.923, tt:8258.874\n",
      "Ep:197, loss:0.00000, loss_test:0.09258, lr:2.68e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.927, tt:8301.511\n",
      "Ep:198, loss:0.00000, loss_test:0.09258, lr:2.65e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.954, tt:8348.932\n",
      "Ep:199, loss:0.00000, loss_test:0.09231, lr:2.63e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.958, tt:8391.567\n",
      "Ep:200, loss:0.00000, loss_test:0.09222, lr:2.60e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.959, tt:8433.857\n",
      "Ep:201, loss:0.00000, loss_test:0.09234, lr:2.57e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.950, tt:8473.896\n",
      "Ep:202, loss:0.00000, loss_test:0.09287, lr:2.55e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.948, tt:8515.453\n",
      "Ep:203, loss:0.00000, loss_test:0.09311, lr:2.52e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.940, tt:8555.858\n",
      "Ep:204, loss:0.00000, loss_test:0.09273, lr:2.50e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.944, tt:8598.613\n",
      "Ep:205, loss:0.00000, loss_test:0.09245, lr:2.47e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.940, tt:8639.624\n",
      "Ep:206, loss:0.00000, loss_test:0.09289, lr:2.45e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.923, tt:8678.114\n",
      "Ep:207, loss:0.00000, loss_test:0.09281, lr:2.42e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.924, tt:8720.209\n",
      "Ep:208, loss:0.00000, loss_test:0.09229, lr:2.40e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.921, tt:8761.484\n",
      "Ep:209, loss:0.00000, loss_test:0.09265, lr:2.38e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.929, tt:8805.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09302, lr:2.35e-03, fs:0.78528 (r=0.646,p=1.000),  time:41.920, tt:8845.173\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02317, lr:6.00e-02, fs:0.61832 (r=0.818,p=0.497),  time:30.467, tt:30.467\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02323, lr:6.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:28.539, tt:57.078\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02303, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:27.708, tt:83.123\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02203, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:29.312, tt:117.246\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:32.095, tt:160.473\n",
      "Ep:5, loss:0.00004, loss_test:0.02030, lr:6.00e-02, fs:0.63359 (r=0.838,p=0.509),  time:33.482, tt:200.891\n",
      "Ep:6, loss:0.00004, loss_test:0.02034, lr:6.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:34.405, tt:240.834\n",
      "Ep:7, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:35.135, tt:281.081\n",
      "Ep:8, loss:0.00003, loss_test:0.01996, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:35.706, tt:321.352\n",
      "Ep:9, loss:0.00003, loss_test:0.01978, lr:6.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:36.244, tt:362.439\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01970, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:36.663, tt:403.294\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01965, lr:6.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:36.958, tt:443.501\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01972, lr:6.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:37.437, tt:486.677\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01989, lr:6.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:37.756, tt:528.577\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01992, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:38.156, tt:572.342\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01974, lr:6.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:38.287, tt:612.589\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01953, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:38.505, tt:654.588\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01946, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:38.605, tt:694.885\n",
      "Ep:18, loss:0.00003, loss_test:0.01949, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:38.813, tt:737.440\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01960, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:38.880, tt:777.604\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01962, lr:6.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:38.916, tt:817.243\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01962, lr:6.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:39.101, tt:860.222\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01966, lr:6.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:39.178, tt:901.092\n",
      "Ep:23, loss:0.00002, loss_test:0.01977, lr:6.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:39.250, tt:941.998\n",
      "Ep:24, loss:0.00002, loss_test:0.01983, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:39.360, tt:983.989\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.02000, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:39.393, tt:1024.213\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.02006, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:39.521, tt:1067.079\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.02007, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:39.548, tt:1107.355\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.02009, lr:6.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:39.548, tt:1146.889\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.02030, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.592, tt:1187.772\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.02045, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.593, tt:1227.398\n",
      "Ep:31, loss:0.00002, loss_test:0.02055, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.539, tt:1265.237\n",
      "Ep:32, loss:0.00002, loss_test:0.02072, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.609, tt:1307.084\n",
      "Ep:33, loss:0.00002, loss_test:0.02084, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.663, tt:1348.539\n",
      "Ep:34, loss:0.00002, loss_test:0.02104, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:39.674, tt:1388.586\n",
      "Ep:35, loss:0.00002, loss_test:0.02118, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:39.688, tt:1428.775\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.02132, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:39.700, tt:1468.918\n",
      "Ep:37, loss:0.00002, loss_test:0.02133, lr:6.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:39.759, tt:1510.826\n",
      "Ep:38, loss:0.00002, loss_test:0.02134, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:39.790, tt:1551.793\n",
      "Ep:39, loss:0.00002, loss_test:0.02142, lr:6.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:39.852, tt:1594.080\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.02153, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:39.861, tt:1634.312\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.02169, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:39.892, tt:1675.470\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.02172, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:39.937, tt:1717.277\n",
      "Ep:43, loss:0.00001, loss_test:0.02172, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:39.988, tt:1759.472\n",
      "Ep:44, loss:0.00001, loss_test:0.02167, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.027, tt:1801.198\n",
      "Ep:45, loss:0.00001, loss_test:0.02160, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.068, tt:1843.144\n",
      "Ep:46, loss:0.00001, loss_test:0.02155, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.089, tt:1884.192\n",
      "Ep:47, loss:0.00001, loss_test:0.02160, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:40.132, tt:1926.328\n",
      "Ep:48, loss:0.00001, loss_test:0.02164, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:40.162, tt:1967.918\n",
      "Ep:49, loss:0.00001, loss_test:0.02157, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.204, tt:2010.213\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.02158, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:40.223, tt:2051.352\n",
      "Ep:51, loss:0.00001, loss_test:0.02156, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.206, tt:2090.701\n",
      "Ep:52, loss:0.00001, loss_test:0.02159, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.230, tt:2132.193\n",
      "Ep:53, loss:0.00001, loss_test:0.02152, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.245, tt:2173.216\n",
      "Ep:54, loss:0.00001, loss_test:0.02143, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.275, tt:2215.106\n",
      "Ep:55, loss:0.00001, loss_test:0.02147, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.285, tt:2255.958\n",
      "Ep:56, loss:0.00001, loss_test:0.02145, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.312, tt:2297.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.02138, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.327, tt:2338.942\n",
      "Ep:58, loss:0.00001, loss_test:0.02137, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.332, tt:2379.581\n",
      "Ep:59, loss:0.00001, loss_test:0.02146, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:40.310, tt:2418.621\n",
      "Ep:60, loss:0.00001, loss_test:0.02136, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:40.304, tt:2458.553\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.02134, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:40.315, tt:2499.542\n",
      "Ep:62, loss:0.00001, loss_test:0.02138, lr:6.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:40.341, tt:2541.488\n",
      "Ep:63, loss:0.00001, loss_test:0.02127, lr:6.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:40.345, tt:2582.051\n",
      "Ep:64, loss:0.00001, loss_test:0.02118, lr:6.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:40.368, tt:2623.929\n",
      "Ep:65, loss:0.00001, loss_test:0.02115, lr:6.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:40.362, tt:2663.900\n",
      "Ep:66, loss:0.00001, loss_test:0.02123, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.374, tt:2705.027\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02115, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.400, tt:2747.216\n",
      "Ep:68, loss:0.00001, loss_test:0.02109, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.406, tt:2787.979\n",
      "Ep:69, loss:0.00001, loss_test:0.02100, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.419, tt:2829.350\n",
      "Ep:70, loss:0.00001, loss_test:0.02112, lr:6.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:40.438, tt:2871.125\n",
      "Ep:71, loss:0.00001, loss_test:0.02113, lr:6.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:40.476, tt:2914.276\n",
      "Ep:72, loss:0.00001, loss_test:0.02098, lr:6.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:40.501, tt:2956.551\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.02112, lr:6.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:40.527, tt:2998.969\n",
      "Ep:74, loss:0.00001, loss_test:0.02097, lr:6.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:40.537, tt:3040.291\n",
      "Ep:75, loss:0.00001, loss_test:0.02091, lr:6.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:40.550, tt:3081.819\n",
      "Ep:76, loss:0.00001, loss_test:0.02105, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.572, tt:3124.023\n",
      "Ep:77, loss:0.00001, loss_test:0.02106, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.576, tt:3164.936\n",
      "Ep:78, loss:0.00001, loss_test:0.02098, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:40.589, tt:3206.547\n",
      "Ep:79, loss:0.00001, loss_test:0.02112, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.605, tt:3248.393\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.02093, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.621, tt:3290.292\n",
      "Ep:81, loss:0.00001, loss_test:0.02096, lr:6.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:40.630, tt:3331.678\n",
      "Ep:82, loss:0.00001, loss_test:0.02101, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:40.642, tt:3373.305\n",
      "Ep:83, loss:0.00001, loss_test:0.02107, lr:6.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:40.634, tt:3413.264\n",
      "Ep:84, loss:0.00001, loss_test:0.02121, lr:6.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:40.655, tt:3455.671\n",
      "Ep:85, loss:0.00001, loss_test:0.02104, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.649, tt:3495.839\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.02133, lr:6.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:40.659, tt:3537.312\n",
      "Ep:87, loss:0.00001, loss_test:0.02115, lr:6.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.682, tt:3579.995\n",
      "Ep:88, loss:0.00001, loss_test:0.02112, lr:6.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:40.732, tt:3625.110\n",
      "Ep:89, loss:0.00001, loss_test:0.02136, lr:6.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.774, tt:3669.621\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.02111, lr:6.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.791, tt:3712.017\n",
      "Ep:91, loss:0.00001, loss_test:0.02113, lr:6.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:40.814, tt:3754.920\n",
      "Ep:92, loss:0.00001, loss_test:0.02137, lr:6.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.834, tt:3797.578\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.02124, lr:6.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.846, tt:3839.563\n",
      "Ep:94, loss:0.00001, loss_test:0.02129, lr:6.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:40.836, tt:3879.419\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.02134, lr:6.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.839, tt:3920.517\n",
      "Ep:96, loss:0.00001, loss_test:0.02143, lr:6.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:40.845, tt:3961.961\n",
      "Ep:97, loss:0.00001, loss_test:0.02142, lr:6.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:40.854, tt:4003.652\n",
      "Ep:98, loss:0.00001, loss_test:0.02151, lr:6.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:40.855, tt:4044.604\n",
      "Ep:99, loss:0.00001, loss_test:0.02140, lr:6.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:40.845, tt:4084.496\n",
      "Ep:100, loss:0.00000, loss_test:0.02149, lr:6.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.832, tt:4124.030\n",
      "Ep:101, loss:0.00000, loss_test:0.02159, lr:6.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.824, tt:4164.075\n",
      "Ep:102, loss:0.00000, loss_test:0.02153, lr:6.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.841, tt:4206.653\n",
      "Ep:103, loss:0.00000, loss_test:0.02155, lr:6.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.820, tt:4245.239\n",
      "Ep:104, loss:0.00000, loss_test:0.02166, lr:6.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.806, tt:4284.596\n",
      "Ep:105, loss:0.00000, loss_test:0.02163, lr:6.00e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.808, tt:4325.627\n",
      "Ep:106, loss:0.00000, loss_test:0.02175, lr:5.94e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.807, tt:4366.306\n",
      "Ep:107, loss:0.00000, loss_test:0.02190, lr:5.88e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.790, tt:4405.297\n",
      "Ep:108, loss:0.00000, loss_test:0.02169, lr:5.82e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.797, tt:4446.904\n",
      "Ep:109, loss:0.00000, loss_test:0.02189, lr:5.76e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.791, tt:4486.983\n",
      "Ep:110, loss:0.00000, loss_test:0.02186, lr:5.71e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.798, tt:4528.574\n",
      "Ep:111, loss:0.00000, loss_test:0.02194, lr:5.65e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.799, tt:4569.453\n",
      "Ep:112, loss:0.00000, loss_test:0.02196, lr:5.59e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.814, tt:4611.976\n",
      "Ep:113, loss:0.00000, loss_test:0.02207, lr:5.54e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.815, tt:4652.959\n",
      "Ep:114, loss:0.00000, loss_test:0.02213, lr:5.48e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.806, tt:4692.744\n",
      "Ep:115, loss:0.00000, loss_test:0.02200, lr:5.43e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.808, tt:4733.696\n",
      "Ep:116, loss:0.00000, loss_test:0.02232, lr:5.37e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.818, tt:4775.715\n",
      "Ep:117, loss:0.00000, loss_test:0.02216, lr:5.32e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.811, tt:4815.750\n",
      "Ep:118, loss:0.00000, loss_test:0.02230, lr:5.27e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.808, tt:4856.149\n",
      "Ep:119, loss:0.00000, loss_test:0.02230, lr:5.21e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.810, tt:4897.236\n",
      "Ep:120, loss:0.00000, loss_test:0.02253, lr:5.16e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.789, tt:4935.513\n",
      "Ep:121, loss:0.00000, loss_test:0.02233, lr:5.11e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.780, tt:4975.152\n",
      "Ep:122, loss:0.00000, loss_test:0.02259, lr:5.06e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.775, tt:5015.346\n",
      "Ep:123, loss:0.00000, loss_test:0.02267, lr:5.01e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.779, tt:5056.607\n",
      "Ep:124, loss:0.00000, loss_test:0.02253, lr:4.96e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.766, tt:5095.705\n",
      "Ep:125, loss:0.00000, loss_test:0.02267, lr:4.91e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.764, tt:5136.220\n",
      "Ep:126, loss:0.00000, loss_test:0.02279, lr:4.86e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.755, tt:5175.937\n",
      "Ep:127, loss:0.00000, loss_test:0.02264, lr:4.81e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.754, tt:5216.490\n",
      "Ep:128, loss:0.00000, loss_test:0.02278, lr:4.76e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.761, tt:5258.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.02286, lr:4.71e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.746, tt:5296.986\n",
      "Ep:130, loss:0.00000, loss_test:0.02289, lr:4.67e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.736, tt:5336.353\n",
      "Ep:131, loss:0.00000, loss_test:0.02289, lr:4.62e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.731, tt:5376.452\n",
      "Ep:132, loss:0.00000, loss_test:0.02299, lr:4.57e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.730, tt:5417.110\n",
      "Ep:133, loss:0.00000, loss_test:0.02297, lr:4.53e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.728, tt:5457.600\n",
      "Ep:134, loss:0.00000, loss_test:0.02313, lr:4.48e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.733, tt:5498.893\n",
      "Ep:135, loss:0.00000, loss_test:0.02305, lr:4.44e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.730, tt:5539.255\n",
      "Ep:136, loss:0.00000, loss_test:0.02319, lr:4.39e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.725, tt:5579.262\n",
      "Ep:137, loss:0.00000, loss_test:0.02322, lr:4.35e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.737, tt:5621.736\n",
      "Ep:138, loss:0.00000, loss_test:0.02330, lr:4.31e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.745, tt:5663.539\n",
      "Ep:139, loss:0.00000, loss_test:0.02324, lr:4.26e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.747, tt:5704.587\n",
      "Ep:140, loss:0.00000, loss_test:0.02336, lr:4.22e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.753, tt:5746.115\n",
      "Ep:141, loss:0.00000, loss_test:0.02334, lr:4.18e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.752, tt:5786.718\n",
      "Ep:142, loss:0.00000, loss_test:0.02337, lr:4.14e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.760, tt:5828.680\n",
      "Ep:143, loss:0.00000, loss_test:0.02330, lr:4.10e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.745, tt:5867.318\n",
      "Ep:144, loss:0.00000, loss_test:0.02343, lr:4.05e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.736, tt:5906.653\n",
      "Ep:145, loss:0.00000, loss_test:0.02334, lr:4.01e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.748, tt:5949.232\n",
      "Ep:146, loss:0.00000, loss_test:0.02349, lr:3.97e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.746, tt:5989.620\n",
      "Ep:147, loss:0.00000, loss_test:0.02359, lr:3.93e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.742, tt:6029.776\n",
      "Ep:148, loss:0.00000, loss_test:0.02355, lr:3.89e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.732, tt:6069.111\n",
      "Ep:149, loss:0.00000, loss_test:0.02359, lr:3.86e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.728, tt:6109.153\n",
      "Ep:150, loss:0.00000, loss_test:0.02352, lr:3.82e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.730, tt:6150.239\n",
      "Ep:151, loss:0.00000, loss_test:0.02359, lr:3.78e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.714, tt:6188.589\n",
      "Ep:152, loss:0.00000, loss_test:0.02372, lr:3.74e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.717, tt:6229.694\n",
      "Ep:153, loss:0.00000, loss_test:0.02361, lr:3.70e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.714, tt:6269.881\n",
      "Ep:154, loss:0.00000, loss_test:0.02372, lr:3.67e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.714, tt:6310.731\n",
      "Ep:155, loss:0.00000, loss_test:0.02375, lr:3.63e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.714, tt:6351.350\n",
      "Ep:156, loss:0.00000, loss_test:0.02373, lr:3.59e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.715, tt:6392.194\n",
      "Ep:157, loss:0.00000, loss_test:0.02382, lr:3.56e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.701, tt:6430.705\n",
      "Ep:158, loss:0.00000, loss_test:0.02378, lr:3.52e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.710, tt:6472.892\n",
      "Ep:159, loss:0.00000, loss_test:0.02379, lr:3.49e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.702, tt:6512.395\n",
      "Ep:160, loss:0.00000, loss_test:0.02396, lr:3.45e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.708, tt:6553.971\n",
      "Ep:161, loss:0.00000, loss_test:0.02398, lr:3.42e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:6593.326\n",
      "Ep:162, loss:0.00000, loss_test:0.02388, lr:3.38e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.697, tt:6633.580\n",
      "Ep:163, loss:0.00000, loss_test:0.02400, lr:3.35e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.694, tt:6673.876\n",
      "Ep:164, loss:0.00000, loss_test:0.02400, lr:3.32e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:6715.539\n",
      "Ep:165, loss:0.00000, loss_test:0.02394, lr:3.28e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.701, tt:6756.323\n",
      "Ep:166, loss:0.00000, loss_test:0.02398, lr:3.25e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.695, tt:6796.087\n",
      "Ep:167, loss:0.00000, loss_test:0.02403, lr:3.22e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.704, tt:6838.262\n",
      "Ep:168, loss:0.00000, loss_test:0.02412, lr:3.19e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.701, tt:6878.483\n",
      "Ep:169, loss:0.00000, loss_test:0.02409, lr:3.15e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:6918.942\n",
      "Ep:170, loss:0.00000, loss_test:0.02411, lr:3.12e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.690, tt:6957.932\n",
      "Ep:171, loss:0.00000, loss_test:0.02412, lr:3.09e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.682, tt:6997.314\n",
      "Ep:172, loss:0.00000, loss_test:0.02411, lr:3.06e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.685, tt:7038.558\n",
      "Ep:173, loss:0.00000, loss_test:0.02416, lr:3.03e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.684, tt:7079.025\n",
      "Ep:174, loss:0.00000, loss_test:0.02418, lr:3.00e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.679, tt:7118.856\n",
      "Ep:175, loss:0.00000, loss_test:0.02413, lr:2.97e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.687, tt:7160.881\n",
      "Ep:176, loss:0.00000, loss_test:0.02423, lr:2.94e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.684, tt:7201.140\n",
      "Ep:177, loss:0.00000, loss_test:0.02428, lr:2.91e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.687, tt:7242.232\n",
      "Ep:178, loss:0.00000, loss_test:0.02428, lr:2.88e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.687, tt:7282.959\n",
      "Ep:179, loss:0.00000, loss_test:0.02424, lr:2.85e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.697, tt:7325.375\n",
      "Ep:180, loss:0.00000, loss_test:0.02432, lr:2.82e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.705, tt:7367.677\n",
      "Ep:181, loss:0.00000, loss_test:0.02432, lr:2.80e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.703, tt:7408.015\n",
      "Ep:182, loss:0.00000, loss_test:0.02434, lr:2.77e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.704, tt:7448.789\n",
      "Ep:183, loss:0.00000, loss_test:0.02439, lr:2.74e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.707, tt:7490.100\n",
      "Ep:184, loss:0.00000, loss_test:0.02436, lr:2.71e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.715, tt:7532.278\n",
      "Ep:185, loss:0.00000, loss_test:0.02434, lr:2.69e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.711, tt:7572.178\n",
      "Ep:186, loss:0.00000, loss_test:0.02443, lr:2.66e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.705, tt:7611.777\n",
      "Ep:187, loss:0.00000, loss_test:0.02443, lr:2.63e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:7651.677\n",
      "Ep:188, loss:0.00000, loss_test:0.02444, lr:2.61e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:7692.214\n",
      "Ep:189, loss:0.00000, loss_test:0.02445, lr:2.58e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.700, tt:7732.976\n",
      "Ep:190, loss:0.00000, loss_test:0.02449, lr:2.55e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.691, tt:7771.919\n",
      "Ep:191, loss:0.00000, loss_test:0.02446, lr:2.53e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.678, tt:7810.246\n",
      "Ep:192, loss:0.00000, loss_test:0.02447, lr:2.50e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.670, tt:7849.230\n",
      "Ep:193, loss:0.00000, loss_test:0.02456, lr:2.48e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.669, tt:7889.716\n",
      "Ep:194, loss:0.00000, loss_test:0.02454, lr:2.45e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.666, tt:7929.917\n",
      "Ep:195, loss:0.00000, loss_test:0.02452, lr:2.43e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.667, tt:7970.786\n",
      "Ep:196, loss:0.00000, loss_test:0.02457, lr:2.40e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.663, tt:8010.642\n",
      "Ep:197, loss:0.00000, loss_test:0.02461, lr:2.38e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.666, tt:8051.820\n",
      "Ep:198, loss:0.00000, loss_test:0.02462, lr:2.36e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.666, tt:8092.456\n",
      "Ep:199, loss:0.00000, loss_test:0.02458, lr:2.33e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.659, tt:8131.747\n",
      "Ep:200, loss:0.00000, loss_test:0.02461, lr:2.31e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.652, tt:8171.081\n",
      "Ep:201, loss:0.00000, loss_test:0.02465, lr:2.29e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.645, tt:8210.292\n",
      "Ep:202, loss:0.00000, loss_test:0.02468, lr:2.26e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.642, tt:8250.362\n",
      "Ep:203, loss:0.00000, loss_test:0.02467, lr:2.24e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.641, tt:8290.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.02470, lr:2.22e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.633, tt:8329.679\n",
      "Ep:205, loss:0.00000, loss_test:0.02474, lr:2.20e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.635, tt:8370.865\n",
      "Ep:206, loss:0.00000, loss_test:0.02473, lr:2.17e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.634, tt:8411.337\n",
      "Ep:207, loss:0.00000, loss_test:0.02472, lr:2.15e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.636, tt:8452.229\n",
      "Ep:208, loss:0.00000, loss_test:0.02475, lr:2.13e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.636, tt:8492.912\n",
      "Ep:209, loss:0.00000, loss_test:0.02477, lr:2.11e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.637, tt:8533.683\n",
      "Ep:210, loss:0.00000, loss_test:0.02474, lr:2.09e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.639, tt:8574.846\n",
      "Ep:211, loss:0.00000, loss_test:0.02477, lr:2.07e-02, fs:0.83041 (r=0.717,p=0.986),  time:40.631, tt:8613.693\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14238, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.368, tt:38.368\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14030, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:35.950, tt:71.900\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13642, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:35.035, tt:105.104\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13019, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:33.958, tt:135.834\n",
      "Ep:4, loss:0.00025, loss_test:0.12133, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:35.496, tt:177.483\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11335, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:36.647, tt:219.883\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11014, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:37.248, tt:260.733\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10903, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:37.689, tt:301.512\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10820, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:38.565, tt:347.089\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10702, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:38.865, tt:388.649\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10358, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:39.207, tt:431.277\n",
      "Ep:11, loss:0.00019, loss_test:0.09990, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:39.447, tt:473.365\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09786, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:39.537, tt:513.975\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09620, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:39.538, tt:553.538\n",
      "Ep:14, loss:0.00017, loss_test:0.09464, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:39.858, tt:597.877\n",
      "Ep:15, loss:0.00017, loss_test:0.09279, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:40.097, tt:641.555\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09199, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:40.115, tt:681.950\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09079, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:40.250, tt:724.509\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08952, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:40.270, tt:765.138\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08822, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:40.357, tt:807.141\n",
      "Ep:20, loss:0.00014, loss_test:0.08763, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:40.451, tt:849.476\n",
      "Ep:21, loss:0.00013, loss_test:0.08622, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:40.574, tt:892.627\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08385, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.657, tt:935.109\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08523, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:40.663, tt:975.906\n",
      "Ep:24, loss:0.00012, loss_test:0.08562, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:40.706, tt:1017.645\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08293, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.705, tt:1058.332\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08312, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:40.779, tt:1101.031\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.08290, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.786, tt:1142.002\n",
      "Ep:28, loss:0.00010, loss_test:0.08103, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:40.854, tt:1184.764\n",
      "Ep:29, loss:0.00010, loss_test:0.08213, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.840, tt:1225.199\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.07896, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:40.923, tt:1268.614\n",
      "Ep:31, loss:0.00009, loss_test:0.08013, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:40.925, tt:1309.604\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.08091, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:40.921, tt:1350.398\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.07806, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:40.968, tt:1392.929\n",
      "Ep:34, loss:0.00008, loss_test:0.08001, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:41.037, tt:1436.296\n",
      "Ep:35, loss:0.00008, loss_test:0.07783, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:41.025, tt:1476.887\n",
      "Ep:36, loss:0.00007, loss_test:0.08254, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:41.103, tt:1520.814\n",
      "Ep:37, loss:0.00007, loss_test:0.07753, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:41.150, tt:1563.716\n",
      "Ep:38, loss:0.00007, loss_test:0.08126, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:41.176, tt:1605.872\n",
      "Ep:39, loss:0.00007, loss_test:0.07793, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:41.153, tt:1646.131\n",
      "Ep:40, loss:0.00006, loss_test:0.07756, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:41.207, tt:1689.487\n",
      "Ep:41, loss:0.00006, loss_test:0.08112, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:41.217, tt:1731.105\n",
      "Ep:42, loss:0.00006, loss_test:0.07749, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:41.227, tt:1772.755\n",
      "Ep:43, loss:0.00006, loss_test:0.08181, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:41.256, tt:1815.243\n",
      "Ep:44, loss:0.00005, loss_test:0.07870, lr:9.90e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.253, tt:1856.388\n",
      "Ep:45, loss:0.00005, loss_test:0.08190, lr:9.80e-03, fs:0.81111 (r=0.737,p=0.901),  time:41.306, tt:1900.087\n",
      "Ep:46, loss:0.00005, loss_test:0.08150, lr:9.70e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.332, tt:1942.622\n",
      "Ep:47, loss:0.00005, loss_test:0.07852, lr:9.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:41.330, tt:1983.842\n",
      "Ep:48, loss:0.00005, loss_test:0.08069, lr:9.51e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.351, tt:2026.177\n",
      "Ep:49, loss:0.00005, loss_test:0.08003, lr:9.41e-03, fs:0.80874 (r=0.747,p=0.881),  time:41.396, tt:2069.813\n",
      "Ep:50, loss:0.00004, loss_test:0.08240, lr:9.32e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.400, tt:2111.421\n",
      "Ep:51, loss:0.00004, loss_test:0.08462, lr:9.23e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.374, tt:2151.464\n",
      "Ep:52, loss:0.00004, loss_test:0.08002, lr:9.14e-03, fs:0.79775 (r=0.717,p=0.899),  time:41.434, tt:2196.022\n",
      "Ep:53, loss:0.00004, loss_test:0.08605, lr:9.04e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.447, tt:2238.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00004, loss_test:0.07752, lr:8.95e-03, fs:0.82353 (r=0.778,p=0.875),  time:41.466, tt:2280.620\n",
      "Ep:55, loss:0.00004, loss_test:0.09063, lr:8.86e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.481, tt:2322.926\n",
      "Ep:56, loss:0.00004, loss_test:0.07999, lr:8.78e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.473, tt:2363.953\n",
      "Ep:57, loss:0.00004, loss_test:0.09495, lr:8.69e-03, fs:0.78857 (r=0.697,p=0.908),  time:41.496, tt:2406.789\n",
      "Ep:58, loss:0.00004, loss_test:0.08152, lr:8.60e-03, fs:0.75429 (r=0.667,p=0.868),  time:41.499, tt:2448.435\n",
      "Ep:59, loss:0.00004, loss_test:0.08808, lr:8.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:41.499, tt:2489.954\n",
      "Ep:60, loss:0.00003, loss_test:0.08228, lr:8.43e-03, fs:0.76836 (r=0.687,p=0.872),  time:41.542, tt:2534.053\n",
      "Ep:61, loss:0.00003, loss_test:0.09441, lr:8.35e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.581, tt:2578.005\n",
      "Ep:62, loss:0.00003, loss_test:0.08106, lr:8.26e-03, fs:0.75145 (r=0.657,p=0.878),  time:41.584, tt:2619.793\n",
      "Ep:63, loss:0.00003, loss_test:0.09605, lr:8.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.627, tt:2664.143\n",
      "Ep:64, loss:0.00003, loss_test:0.08184, lr:8.10e-03, fs:0.74419 (r=0.646,p=0.877),  time:41.683, tt:2709.408\n",
      "Ep:65, loss:0.00003, loss_test:0.09015, lr:8.02e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.675, tt:2750.559\n",
      "Ep:66, loss:0.00003, loss_test:0.08029, lr:7.94e-03, fs:0.76571 (r=0.677,p=0.882),  time:41.632, tt:2789.326\n",
      "Ep:67, loss:0.00003, loss_test:0.09350, lr:7.86e-03, fs:0.77907 (r=0.677,p=0.918),  time:41.645, tt:2831.876\n",
      "Ep:68, loss:0.00003, loss_test:0.08372, lr:7.78e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.607, tt:2870.913\n",
      "Ep:69, loss:0.00003, loss_test:0.08736, lr:7.70e-03, fs:0.77457 (r=0.677,p=0.905),  time:41.627, tt:2913.867\n",
      "Ep:70, loss:0.00003, loss_test:0.09061, lr:7.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.630, tt:2955.765\n",
      "Ep:71, loss:0.00002, loss_test:0.08667, lr:7.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.634, tt:2997.680\n",
      "Ep:72, loss:0.00002, loss_test:0.08716, lr:7.47e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.613, tt:3037.766\n",
      "Ep:73, loss:0.00002, loss_test:0.08738, lr:7.40e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.588, tt:3077.512\n",
      "Ep:74, loss:0.00002, loss_test:0.08836, lr:7.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.578, tt:3118.320\n",
      "Ep:75, loss:0.00002, loss_test:0.08591, lr:7.25e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.593, tt:3161.080\n",
      "Ep:76, loss:0.00002, loss_test:0.08578, lr:7.18e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.593, tt:3202.681\n",
      "Ep:77, loss:0.00002, loss_test:0.08963, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.607, tt:3245.339\n",
      "Ep:78, loss:0.00002, loss_test:0.08428, lr:7.03e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.616, tt:3287.663\n",
      "Ep:79, loss:0.00002, loss_test:0.09451, lr:6.96e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.605, tt:3328.411\n",
      "Ep:80, loss:0.00002, loss_test:0.08317, lr:6.89e-03, fs:0.76471 (r=0.657,p=0.915),  time:41.630, tt:3372.033\n",
      "Ep:81, loss:0.00002, loss_test:0.09278, lr:6.83e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.624, tt:3413.188\n",
      "Ep:82, loss:0.00002, loss_test:0.08982, lr:6.76e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.634, tt:3455.619\n",
      "Ep:83, loss:0.00002, loss_test:0.08143, lr:6.69e-03, fs:0.78363 (r=0.677,p=0.931),  time:41.658, tt:3499.246\n",
      "Ep:84, loss:0.00002, loss_test:0.09302, lr:6.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.660, tt:3541.116\n",
      "Ep:85, loss:0.00002, loss_test:0.08608, lr:6.56e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.672, tt:3583.783\n",
      "Ep:86, loss:0.00002, loss_test:0.08682, lr:6.49e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.672, tt:3625.430\n",
      "Ep:87, loss:0.00001, loss_test:0.09140, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.670, tt:3666.918\n",
      "Ep:88, loss:0.00001, loss_test:0.08358, lr:6.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.667, tt:3708.336\n",
      "Ep:89, loss:0.00001, loss_test:0.09352, lr:6.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.666, tt:3749.932\n",
      "Ep:90, loss:0.00001, loss_test:0.09102, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.675, tt:3792.413\n",
      "Ep:91, loss:0.00001, loss_test:0.08616, lr:6.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.668, tt:3833.491\n",
      "Ep:92, loss:0.00001, loss_test:0.09171, lr:6.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.697, tt:3877.834\n",
      "Ep:93, loss:0.00001, loss_test:0.08757, lr:6.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.674, tt:3917.322\n",
      "Ep:94, loss:0.00001, loss_test:0.09077, lr:5.99e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.680, tt:3959.639\n",
      "Ep:95, loss:0.00001, loss_test:0.09052, lr:5.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.662, tt:3999.532\n",
      "Ep:96, loss:0.00001, loss_test:0.08785, lr:5.87e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.649, tt:4039.907\n",
      "Ep:97, loss:0.00001, loss_test:0.09421, lr:5.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.652, tt:4081.927\n",
      "Ep:98, loss:0.00001, loss_test:0.08677, lr:5.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.654, tt:4123.699\n",
      "Ep:99, loss:0.00001, loss_test:0.09468, lr:5.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.653, tt:4165.310\n",
      "Ep:100, loss:0.00001, loss_test:0.08907, lr:5.64e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.662, tt:4207.854\n",
      "Ep:101, loss:0.00001, loss_test:0.09170, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.657, tt:4249.014\n",
      "Ep:102, loss:0.00001, loss_test:0.09065, lr:5.53e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.676, tt:4292.667\n",
      "Ep:103, loss:0.00001, loss_test:0.09128, lr:5.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.677, tt:4334.455\n",
      "Ep:104, loss:0.00001, loss_test:0.08867, lr:5.42e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.695, tt:4377.992\n",
      "Ep:105, loss:0.00001, loss_test:0.09296, lr:5.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.711, tt:4421.335\n",
      "Ep:106, loss:0.00001, loss_test:0.08907, lr:5.31e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.712, tt:4463.158\n",
      "Ep:107, loss:0.00001, loss_test:0.09325, lr:5.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.718, tt:4505.494\n",
      "Ep:108, loss:0.00001, loss_test:0.08972, lr:5.20e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.752, tt:4550.945\n",
      "Ep:109, loss:0.00001, loss_test:0.09137, lr:5.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.739, tt:4591.267\n",
      "Ep:110, loss:0.00001, loss_test:0.09336, lr:5.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.750, tt:4634.274\n",
      "Ep:111, loss:0.00001, loss_test:0.09214, lr:5.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.760, tt:4677.082\n",
      "Ep:112, loss:0.00001, loss_test:0.09117, lr:5.00e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.785, tt:4721.657\n",
      "Ep:113, loss:0.00001, loss_test:0.09307, lr:4.95e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.790, tt:4764.068\n",
      "Ep:114, loss:0.00001, loss_test:0.09352, lr:4.90e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.802, tt:4807.224\n",
      "Ep:115, loss:0.00001, loss_test:0.08985, lr:4.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.806, tt:4849.543\n",
      "Ep:116, loss:0.00001, loss_test:0.09359, lr:4.80e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.816, tt:4892.444\n",
      "Ep:117, loss:0.00001, loss_test:0.09094, lr:4.75e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.819, tt:4934.624\n",
      "Ep:118, loss:0.00001, loss_test:0.09329, lr:4.71e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.809, tt:4975.221\n",
      "Ep:119, loss:0.00001, loss_test:0.09203, lr:4.66e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.812, tt:5017.433\n",
      "Ep:120, loss:0.00001, loss_test:0.09148, lr:4.61e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.833, tt:5061.789\n",
      "Ep:121, loss:0.00001, loss_test:0.09279, lr:4.57e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.837, tt:5104.093\n",
      "Ep:122, loss:0.00001, loss_test:0.09178, lr:4.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.831, tt:5145.196\n",
      "Ep:123, loss:0.00001, loss_test:0.09355, lr:4.48e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.812, tt:5184.643\n",
      "Ep:124, loss:0.00001, loss_test:0.09191, lr:4.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.805, tt:5225.621\n",
      "Ep:125, loss:0.00001, loss_test:0.09205, lr:4.39e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.811, tt:5268.128\n",
      "Ep:126, loss:0.00001, loss_test:0.09364, lr:4.34e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.817, tt:5310.795\n",
      "Ep:127, loss:0.00001, loss_test:0.09402, lr:4.30e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.821, tt:5353.106\n",
      "Ep:128, loss:0.00001, loss_test:0.09256, lr:4.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.810, tt:5393.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.09500, lr:4.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.797, tt:5433.563\n",
      "Ep:130, loss:0.00001, loss_test:0.09404, lr:4.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.801, tt:5475.901\n",
      "Ep:131, loss:0.00001, loss_test:0.09178, lr:4.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.810, tt:5518.935\n",
      "Ep:132, loss:0.00001, loss_test:0.09417, lr:4.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.806, tt:5560.150\n",
      "Ep:133, loss:0.00001, loss_test:0.09280, lr:4.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.805, tt:5601.861\n",
      "Ep:134, loss:0.00001, loss_test:0.09443, lr:4.01e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.799, tt:5642.894\n",
      "Ep:135, loss:0.00001, loss_test:0.09301, lr:3.97e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.806, tt:5685.607\n",
      "Ep:136, loss:0.00001, loss_test:0.09532, lr:3.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.800, tt:5726.587\n",
      "Ep:137, loss:0.00001, loss_test:0.09210, lr:3.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.803, tt:5768.850\n",
      "Ep:138, loss:0.00001, loss_test:0.09448, lr:3.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.806, tt:5811.052\n",
      "Ep:139, loss:0.00001, loss_test:0.09324, lr:3.81e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.825, tt:5855.431\n",
      "Ep:140, loss:0.00001, loss_test:0.09456, lr:3.77e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.825, tt:5897.343\n",
      "Ep:141, loss:0.00001, loss_test:0.09209, lr:3.73e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.835, tt:5940.599\n",
      "Ep:142, loss:0.00001, loss_test:0.09543, lr:3.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.837, tt:5982.646\n",
      "Ep:143, loss:0.00001, loss_test:0.09247, lr:3.66e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.843, tt:6025.381\n",
      "Ep:144, loss:0.00001, loss_test:0.09519, lr:3.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.849, tt:6068.070\n",
      "Ep:145, loss:0.00000, loss_test:0.09376, lr:3.59e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.851, tt:6110.292\n",
      "Ep:146, loss:0.00000, loss_test:0.09361, lr:3.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.861, tt:6153.610\n",
      "Ep:147, loss:0.00000, loss_test:0.09313, lr:3.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.859, tt:6195.109\n",
      "Ep:148, loss:0.00000, loss_test:0.09387, lr:3.48e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.871, tt:6238.716\n",
      "Ep:149, loss:0.00000, loss_test:0.09252, lr:3.45e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.900, tt:6284.954\n",
      "Ep:150, loss:0.00000, loss_test:0.09484, lr:3.41e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.899, tt:6326.714\n",
      "Ep:151, loss:0.00000, loss_test:0.09325, lr:3.38e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.891, tt:6367.461\n",
      "Ep:152, loss:0.00000, loss_test:0.09379, lr:3.34e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.890, tt:6409.149\n",
      "Ep:153, loss:0.00000, loss_test:0.09383, lr:3.31e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.893, tt:6451.549\n",
      "Ep:154, loss:0.00000, loss_test:0.09440, lr:3.28e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.893, tt:6493.453\n",
      "Ep:155, loss:0.00000, loss_test:0.09251, lr:3.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.905, tt:6537.163\n",
      "Ep:156, loss:0.00000, loss_test:0.09709, lr:3.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.922, tt:6581.766\n",
      "Ep:157, loss:0.00000, loss_test:0.09521, lr:3.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.928, tt:6624.657\n",
      "Ep:158, loss:0.00000, loss_test:0.09373, lr:3.15e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.937, tt:6667.994\n",
      "Ep:159, loss:0.00000, loss_test:0.09479, lr:3.12e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.944, tt:6711.049\n",
      "Ep:160, loss:0.00000, loss_test:0.09322, lr:3.09e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.959, tt:6755.427\n",
      "Ep:161, loss:0.00000, loss_test:0.09824, lr:3.05e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.971, tt:6799.382\n",
      "Ep:162, loss:0.00000, loss_test:0.09221, lr:3.02e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.976, tt:6842.079\n",
      "Ep:163, loss:0.00000, loss_test:0.09456, lr:2.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.988, tt:6886.013\n",
      "Ep:164, loss:0.00000, loss_test:0.09661, lr:2.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.986, tt:6927.751\n",
      "Ep:165, loss:0.00000, loss_test:0.09221, lr:2.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.970, tt:6967.099\n",
      "Ep:166, loss:0.00000, loss_test:0.09560, lr:2.90e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.957, tt:7006.806\n",
      "Ep:167, loss:0.00000, loss_test:0.09379, lr:2.88e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.966, tt:7050.312\n",
      "Ep:168, loss:0.00000, loss_test:0.09377, lr:2.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.966, tt:7092.187\n",
      "Ep:169, loss:0.00000, loss_test:0.09400, lr:2.82e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.992, tt:7138.706\n",
      "Ep:170, loss:0.00000, loss_test:0.09313, lr:2.79e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.984, tt:7179.285\n",
      "Ep:171, loss:0.00000, loss_test:0.09446, lr:2.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.985, tt:7221.352\n",
      "Ep:172, loss:0.00000, loss_test:0.09301, lr:2.73e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.982, tt:7262.859\n",
      "Ep:173, loss:0.00000, loss_test:0.09407, lr:2.71e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.992, tt:7306.539\n",
      "Ep:174, loss:0.00000, loss_test:0.09454, lr:2.68e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.994, tt:7349.022\n",
      "Ep:175, loss:0.00000, loss_test:0.09332, lr:2.65e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.995, tt:7391.133\n",
      "Ep:176, loss:0.00000, loss_test:0.09402, lr:2.63e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.991, tt:7432.415\n",
      "Ep:177, loss:0.00000, loss_test:0.09399, lr:2.60e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.989, tt:7474.051\n",
      "Ep:178, loss:0.00000, loss_test:0.09363, lr:2.57e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.992, tt:7516.603\n",
      "Ep:179, loss:0.00000, loss_test:0.09359, lr:2.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.990, tt:7558.243\n",
      "Ep:180, loss:0.00000, loss_test:0.09496, lr:2.52e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.990, tt:7600.174\n",
      "Ep:181, loss:0.00000, loss_test:0.09337, lr:2.50e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.989, tt:7642.079\n",
      "Ep:182, loss:0.00000, loss_test:0.09277, lr:2.47e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.985, tt:7683.222\n",
      "Ep:183, loss:0.00000, loss_test:0.09323, lr:2.45e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.976, tt:7723.585\n",
      "Ep:184, loss:0.00000, loss_test:0.09379, lr:2.42e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.974, tt:7765.129\n",
      "Ep:185, loss:0.00000, loss_test:0.09366, lr:2.40e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.984, tt:7809.103\n",
      "Ep:186, loss:0.00000, loss_test:0.09394, lr:2.38e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.991, tt:7852.398\n",
      "Ep:187, loss:0.00000, loss_test:0.09326, lr:2.35e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.996, tt:7895.285\n",
      "Ep:188, loss:0.00000, loss_test:0.09426, lr:2.33e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.993, tt:7936.677\n",
      "Ep:189, loss:0.00000, loss_test:0.09331, lr:2.31e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.996, tt:7979.272\n",
      "Ep:190, loss:0.00000, loss_test:0.09383, lr:2.28e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.989, tt:8019.843\n",
      "Ep:191, loss:0.00000, loss_test:0.09439, lr:2.26e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.988, tt:8061.779\n",
      "Ep:192, loss:0.00000, loss_test:0.09344, lr:2.24e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.982, tt:8102.446\n",
      "Ep:193, loss:0.00000, loss_test:0.09413, lr:2.21e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.977, tt:8143.613\n",
      "Ep:194, loss:0.00000, loss_test:0.09450, lr:2.19e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.988, tt:8187.744\n",
      "Ep:195, loss:0.00000, loss_test:0.09325, lr:2.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.981, tt:8228.187\n",
      "Ep:196, loss:0.00000, loss_test:0.09393, lr:2.15e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.972, tt:8268.577\n",
      "Ep:197, loss:0.00000, loss_test:0.09333, lr:2.13e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.984, tt:8312.877\n",
      "Ep:198, loss:0.00000, loss_test:0.09469, lr:2.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.981, tt:8354.124\n",
      "Ep:199, loss:0.00000, loss_test:0.09378, lr:2.08e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.983, tt:8396.624\n",
      "Ep:200, loss:0.00000, loss_test:0.09263, lr:2.06e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.980, tt:8437.942\n",
      "Ep:201, loss:0.00000, loss_test:0.09469, lr:2.04e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.974, tt:8478.836\n",
      "Ep:202, loss:0.00000, loss_test:0.09450, lr:2.02e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.973, tt:8520.535\n",
      "Ep:203, loss:0.00000, loss_test:0.09317, lr:2.00e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.978, tt:8563.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.09506, lr:1.98e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.979, tt:8605.688\n",
      "Ep:205, loss:0.00000, loss_test:0.09347, lr:1.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.969, tt:8645.595\n",
      "Ep:206, loss:0.00000, loss_test:0.09503, lr:1.94e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.965, tt:8686.842\n",
      "Ep:207, loss:0.00000, loss_test:0.09604, lr:1.92e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.964, tt:8728.597\n",
      "Ep:208, loss:0.00000, loss_test:0.09333, lr:1.90e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.956, tt:8768.754\n",
      "Ep:209, loss:0.00000, loss_test:0.09458, lr:1.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.941, tt:8807.706\n",
      "Ep:210, loss:0.00000, loss_test:0.09641, lr:1.87e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.937, tt:8848.641\n",
      "Ep:211, loss:0.00000, loss_test:0.09376, lr:1.85e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.935, tt:8890.232\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02057, lr:6.00e-02, fs:0.64220 (r=0.805,p=0.534),  time:12.151, tt:12.151\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02166, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.629, tt:23.257\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02217, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.500, tt:34.501\n",
      "Ep:3, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:11.439, tt:45.756\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01958, lr:6.00e-02, fs:0.67742 (r=0.966,p=0.522),  time:11.401, tt:57.003\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.67841 (r=0.885,p=0.550),  time:11.360, tt:68.160\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01828, lr:6.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:11.347, tt:79.430\n",
      "Ep:7, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.70000 (r=0.805,p=0.619),  time:11.330, tt:90.637\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.01698, lr:6.00e-02, fs:0.74178 (r=0.908,p=0.627),  time:11.309, tt:101.785\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01683, lr:6.00e-02, fs:0.73778 (r=0.954,p=0.601),  time:11.342, tt:113.419\n",
      "Ep:10, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.74561 (r=0.977,p=0.603),  time:11.341, tt:124.749\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01598, lr:6.00e-02, fs:0.77064 (r=0.966,p=0.641),  time:11.350, tt:136.206\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.79024 (r=0.931,p=0.686),  time:11.330, tt:147.293\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.80198 (r=0.931,p=0.704),  time:11.329, tt:158.603\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01513, lr:6.00e-02, fs:0.79412 (r=0.931,p=0.692),  time:11.315, tt:169.728\n",
      "Ep:15, loss:0.00003, loss_test:0.01495, lr:6.00e-02, fs:0.79000 (r=0.908,p=0.699),  time:11.310, tt:180.963\n",
      "Ep:16, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.80000 (r=0.897,p=0.722),  time:11.307, tt:192.227\n",
      "Ep:17, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.80214 (r=0.862,p=0.750),  time:11.303, tt:203.457\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01500, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:11.317, tt:215.027\n",
      "Ep:19, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.80220 (r=0.839,p=0.768),  time:11.308, tt:226.157\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01483, lr:6.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:11.307, tt:237.450\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:11.307, tt:248.753\n",
      "Ep:22, loss:0.00002, loss_test:0.01485, lr:6.00e-02, fs:0.79775 (r=0.816,p=0.780),  time:11.300, tt:259.910\n",
      "Ep:23, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.80000 (r=0.805,p=0.795),  time:11.301, tt:271.227\n",
      "Ep:24, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:11.307, tt:282.670\n",
      "Ep:25, loss:0.00002, loss_test:0.01514, lr:6.00e-02, fs:0.77381 (r=0.747,p=0.802),  time:11.318, tt:294.270\n",
      "Ep:26, loss:0.00002, loss_test:0.01520, lr:6.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:11.339, tt:306.161\n",
      "Ep:27, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:11.377, tt:318.565\n",
      "Ep:28, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:11.398, tt:330.531\n",
      "Ep:29, loss:0.00001, loss_test:0.01555, lr:6.00e-02, fs:0.76829 (r=0.724,p=0.818),  time:11.408, tt:342.241\n",
      "Ep:30, loss:0.00001, loss_test:0.01561, lr:6.00e-02, fs:0.77301 (r=0.724,p=0.829),  time:11.415, tt:353.877\n",
      "Ep:31, loss:0.00001, loss_test:0.01560, lr:6.00e-02, fs:0.78049 (r=0.736,p=0.831),  time:11.420, tt:365.447\n",
      "Ep:32, loss:0.00001, loss_test:0.01571, lr:5.94e-02, fs:0.77301 (r=0.724,p=0.829),  time:11.422, tt:376.911\n",
      "Ep:33, loss:0.00001, loss_test:0.01590, lr:5.88e-02, fs:0.77778 (r=0.724,p=0.840),  time:11.416, tt:388.161\n",
      "Ep:34, loss:0.00001, loss_test:0.01612, lr:5.82e-02, fs:0.78261 (r=0.724,p=0.851),  time:11.421, tt:399.746\n",
      "Ep:35, loss:0.00001, loss_test:0.01629, lr:5.76e-02, fs:0.78261 (r=0.724,p=0.851),  time:11.419, tt:411.100\n",
      "Ep:36, loss:0.00001, loss_test:0.01642, lr:5.71e-02, fs:0.78261 (r=0.724,p=0.851),  time:11.420, tt:422.530\n",
      "Ep:37, loss:0.00001, loss_test:0.01655, lr:5.65e-02, fs:0.77500 (r=0.713,p=0.849),  time:11.416, tt:433.819\n",
      "Ep:38, loss:0.00001, loss_test:0.01675, lr:5.59e-02, fs:0.77707 (r=0.701,p=0.871),  time:11.419, tt:445.335\n",
      "Ep:39, loss:0.00001, loss_test:0.01698, lr:5.54e-02, fs:0.78205 (r=0.701,p=0.884),  time:11.413, tt:456.533\n",
      "Ep:40, loss:0.00001, loss_test:0.01716, lr:5.48e-02, fs:0.78205 (r=0.701,p=0.884),  time:11.411, tt:467.863\n",
      "Ep:41, loss:0.00001, loss_test:0.01737, lr:5.43e-02, fs:0.78205 (r=0.701,p=0.884),  time:11.405, tt:479.015\n",
      "Ep:42, loss:0.00001, loss_test:0.01755, lr:5.37e-02, fs:0.78710 (r=0.701,p=0.897),  time:11.398, tt:490.096\n",
      "Ep:43, loss:0.00001, loss_test:0.01778, lr:5.32e-02, fs:0.77922 (r=0.690,p=0.896),  time:11.386, tt:500.996\n",
      "Ep:44, loss:0.00001, loss_test:0.01798, lr:5.27e-02, fs:0.78431 (r=0.690,p=0.909),  time:11.380, tt:512.111\n",
      "Ep:45, loss:0.00001, loss_test:0.01810, lr:5.21e-02, fs:0.77632 (r=0.678,p=0.908),  time:11.383, tt:523.601\n",
      "Ep:46, loss:0.00001, loss_test:0.01830, lr:5.16e-02, fs:0.76000 (r=0.655,p=0.905),  time:11.379, tt:534.829\n",
      "Ep:47, loss:0.00001, loss_test:0.01862, lr:5.11e-02, fs:0.75168 (r=0.644,p=0.903),  time:11.374, tt:545.934\n",
      "Ep:48, loss:0.00001, loss_test:0.01874, lr:5.06e-02, fs:0.75168 (r=0.644,p=0.903),  time:11.437, tt:560.427\n",
      "Ep:49, loss:0.00001, loss_test:0.01893, lr:5.01e-02, fs:0.75168 (r=0.644,p=0.903),  time:11.436, tt:571.816\n",
      "Ep:50, loss:0.00001, loss_test:0.01919, lr:4.96e-02, fs:0.75168 (r=0.644,p=0.903),  time:11.429, tt:582.897\n",
      "Ep:51, loss:0.00001, loss_test:0.01945, lr:4.91e-02, fs:0.74324 (r=0.632,p=0.902),  time:11.426, tt:594.138\n",
      "Ep:52, loss:0.00001, loss_test:0.01965, lr:4.86e-02, fs:0.74324 (r=0.632,p=0.902),  time:11.420, tt:605.271\n",
      "Ep:53, loss:0.00001, loss_test:0.01986, lr:4.81e-02, fs:0.73469 (r=0.621,p=0.900),  time:11.413, tt:616.322\n",
      "Ep:54, loss:0.00001, loss_test:0.02001, lr:4.76e-02, fs:0.73469 (r=0.621,p=0.900),  time:11.409, tt:627.473\n",
      "Ep:55, loss:0.00001, loss_test:0.02027, lr:4.71e-02, fs:0.71724 (r=0.598,p=0.897),  time:11.403, tt:638.571\n",
      "Ep:56, loss:0.00001, loss_test:0.02049, lr:4.67e-02, fs:0.72222 (r=0.598,p=0.912),  time:11.400, tt:649.777\n",
      "Ep:57, loss:0.00001, loss_test:0.02068, lr:4.62e-02, fs:0.70423 (r=0.575,p=0.909),  time:11.393, tt:660.817\n",
      "Ep:58, loss:0.00000, loss_test:0.02091, lr:4.57e-02, fs:0.70423 (r=0.575,p=0.909),  time:11.391, tt:672.048\n",
      "Ep:59, loss:0.00000, loss_test:0.02103, lr:4.53e-02, fs:0.70423 (r=0.575,p=0.909),  time:11.389, tt:683.322\n",
      "Ep:60, loss:0.00000, loss_test:0.02118, lr:4.48e-02, fs:0.68571 (r=0.552,p=0.906),  time:11.388, tt:694.641\n",
      "Ep:61, loss:0.00000, loss_test:0.02136, lr:4.44e-02, fs:0.68571 (r=0.552,p=0.906),  time:11.383, tt:705.767\n",
      "Ep:62, loss:0.00000, loss_test:0.02151, lr:4.39e-02, fs:0.69065 (r=0.552,p=0.923),  time:11.378, tt:716.797\n",
      "Ep:63, loss:0.00000, loss_test:0.02163, lr:4.35e-02, fs:0.69065 (r=0.552,p=0.923),  time:11.374, tt:727.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.02182, lr:4.31e-02, fs:0.68116 (r=0.540,p=0.922),  time:11.372, tt:739.155\n",
      "Ep:65, loss:0.00000, loss_test:0.02199, lr:4.26e-02, fs:0.67153 (r=0.529,p=0.920),  time:11.367, tt:750.253\n",
      "Ep:66, loss:0.00000, loss_test:0.02212, lr:4.22e-02, fs:0.67153 (r=0.529,p=0.920),  time:11.367, tt:761.593\n",
      "Ep:67, loss:0.00000, loss_test:0.02225, lr:4.18e-02, fs:0.67153 (r=0.529,p=0.920),  time:11.365, tt:772.808\n",
      "Ep:68, loss:0.00000, loss_test:0.02244, lr:4.14e-02, fs:0.66176 (r=0.517,p=0.918),  time:11.363, tt:784.021\n",
      "Ep:69, loss:0.00000, loss_test:0.02259, lr:4.10e-02, fs:0.65185 (r=0.506,p=0.917),  time:11.363, tt:795.404\n",
      "Ep:70, loss:0.00000, loss_test:0.02272, lr:4.05e-02, fs:0.64179 (r=0.494,p=0.915),  time:11.364, tt:806.835\n",
      "Ep:71, loss:0.00000, loss_test:0.02277, lr:4.01e-02, fs:0.64179 (r=0.494,p=0.915),  time:11.363, tt:818.168\n",
      "Ep:72, loss:0.00000, loss_test:0.02291, lr:3.97e-02, fs:0.64179 (r=0.494,p=0.915),  time:11.368, tt:829.856\n",
      "Ep:73, loss:0.00000, loss_test:0.02306, lr:3.93e-02, fs:0.63158 (r=0.483,p=0.913),  time:11.373, tt:841.584\n",
      "Ep:74, loss:0.00000, loss_test:0.02316, lr:3.89e-02, fs:0.63158 (r=0.483,p=0.913),  time:11.372, tt:852.887\n",
      "Ep:75, loss:0.00000, loss_test:0.02336, lr:3.86e-02, fs:0.63158 (r=0.483,p=0.913),  time:11.374, tt:864.390\n",
      "Ep:76, loss:0.00000, loss_test:0.02349, lr:3.82e-02, fs:0.63158 (r=0.483,p=0.913),  time:11.373, tt:875.699\n",
      "Ep:77, loss:0.00000, loss_test:0.02356, lr:3.78e-02, fs:0.63158 (r=0.483,p=0.913),  time:11.373, tt:887.105\n",
      "Ep:78, loss:0.00000, loss_test:0.02372, lr:3.74e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.374, tt:898.537\n",
      "Ep:79, loss:0.00000, loss_test:0.02376, lr:3.70e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.373, tt:909.833\n",
      "Ep:80, loss:0.00000, loss_test:0.02387, lr:3.67e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.379, tt:921.716\n",
      "Ep:81, loss:0.00000, loss_test:0.02405, lr:3.63e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.385, tt:933.602\n",
      "Ep:82, loss:0.00000, loss_test:0.02414, lr:3.59e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.387, tt:945.096\n",
      "Ep:83, loss:0.00000, loss_test:0.02423, lr:3.56e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.384, tt:956.284\n",
      "Ep:84, loss:0.00000, loss_test:0.02437, lr:3.52e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.378, tt:967.161\n",
      "Ep:85, loss:0.00000, loss_test:0.02442, lr:3.49e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.370, tt:977.835\n",
      "Ep:86, loss:0.00000, loss_test:0.02454, lr:3.45e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.363, tt:988.621\n",
      "Ep:87, loss:0.00000, loss_test:0.02465, lr:3.42e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.356, tt:999.296\n",
      "Ep:88, loss:0.00000, loss_test:0.02473, lr:3.38e-02, fs:0.62121 (r=0.471,p=0.911),  time:11.348, tt:1010.015\n",
      "Ep:89, loss:0.00000, loss_test:0.02480, lr:3.35e-02, fs:0.62595 (r=0.471,p=0.932),  time:11.340, tt:1020.623\n",
      "Ep:90, loss:0.00000, loss_test:0.02490, lr:3.32e-02, fs:0.61538 (r=0.460,p=0.930),  time:11.331, tt:1031.093\n",
      "Ep:91, loss:0.00000, loss_test:0.02496, lr:3.28e-02, fs:0.61538 (r=0.460,p=0.930),  time:11.321, tt:1041.543\n",
      "Ep:92, loss:0.00000, loss_test:0.02508, lr:3.25e-02, fs:0.61538 (r=0.460,p=0.930),  time:11.314, tt:1052.219\n",
      "Ep:93, loss:0.00000, loss_test:0.02516, lr:3.22e-02, fs:0.62595 (r=0.471,p=0.932),  time:11.308, tt:1062.958\n",
      "Ep:94, loss:0.00000, loss_test:0.02528, lr:3.19e-02, fs:0.61538 (r=0.460,p=0.930),  time:11.301, tt:1073.579\n",
      "Ep:95, loss:0.00000, loss_test:0.02533, lr:3.15e-02, fs:0.59375 (r=0.437,p=0.927),  time:11.294, tt:1084.215\n",
      "Ep:96, loss:0.00000, loss_test:0.02537, lr:3.12e-02, fs:0.59375 (r=0.437,p=0.927),  time:11.287, tt:1094.847\n",
      "Ep:97, loss:0.00000, loss_test:0.02542, lr:3.09e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.280, tt:1105.437\n",
      "Ep:98, loss:0.00000, loss_test:0.02549, lr:3.06e-02, fs:0.59375 (r=0.437,p=0.927),  time:11.273, tt:1116.004\n",
      "Ep:99, loss:0.00000, loss_test:0.02555, lr:3.03e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.266, tt:1126.632\n",
      "Ep:100, loss:0.00000, loss_test:0.02563, lr:3.00e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.260, tt:1137.230\n",
      "Ep:101, loss:0.00000, loss_test:0.02567, lr:2.97e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.254, tt:1147.938\n",
      "Ep:102, loss:0.00000, loss_test:0.02578, lr:2.94e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.249, tt:1158.616\n",
      "Ep:103, loss:0.00000, loss_test:0.02583, lr:2.91e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.242, tt:1169.188\n",
      "Ep:104, loss:0.00000, loss_test:0.02588, lr:2.88e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.237, tt:1179.856\n",
      "Ep:105, loss:0.00000, loss_test:0.02596, lr:2.85e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.249, tt:1192.360\n",
      "Ep:106, loss:0.00000, loss_test:0.02603, lr:2.82e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.242, tt:1202.935\n",
      "Ep:107, loss:0.00000, loss_test:0.02605, lr:2.80e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.236, tt:1213.517\n",
      "Ep:108, loss:0.00000, loss_test:0.02609, lr:2.77e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.231, tt:1224.182\n",
      "Ep:109, loss:0.00000, loss_test:0.02613, lr:2.74e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.226, tt:1234.899\n",
      "Ep:110, loss:0.00000, loss_test:0.02618, lr:2.71e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.221, tt:1245.511\n",
      "Ep:111, loss:0.00000, loss_test:0.02624, lr:2.69e-02, fs:0.59843 (r=0.437,p=0.950),  time:11.215, tt:1256.131\n",
      "Ep:112, loss:0.00000, loss_test:0.02631, lr:2.66e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.209, tt:1266.672\n",
      "Ep:113, loss:0.00000, loss_test:0.02635, lr:2.63e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.204, tt:1277.258\n",
      "Ep:114, loss:0.00000, loss_test:0.02642, lr:2.61e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.199, tt:1287.918\n",
      "Ep:115, loss:0.00000, loss_test:0.02649, lr:2.58e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.194, tt:1298.484\n",
      "Ep:116, loss:0.00000, loss_test:0.02650, lr:2.55e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.189, tt:1309.076\n",
      "Ep:117, loss:0.00000, loss_test:0.02657, lr:2.53e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.183, tt:1319.631\n",
      "Ep:118, loss:0.00000, loss_test:0.02658, lr:2.50e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.178, tt:1330.146\n",
      "Ep:119, loss:0.00000, loss_test:0.02662, lr:2.48e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.172, tt:1340.687\n",
      "Ep:120, loss:0.00000, loss_test:0.02669, lr:2.45e-02, fs:0.58730 (r=0.425,p=0.949),  time:11.167, tt:1351.245\n",
      "Ep:121, loss:0.00000, loss_test:0.02670, lr:2.43e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.163, tt:1361.860\n",
      "Ep:122, loss:0.00000, loss_test:0.02676, lr:2.40e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.159, tt:1372.526\n",
      "Ep:123, loss:0.00000, loss_test:0.02680, lr:2.38e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.156, tt:1383.287\n",
      "Ep:124, loss:0.00000, loss_test:0.02685, lr:2.36e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.152, tt:1394.027\n",
      "Ep:125, loss:0.00000, loss_test:0.02688, lr:2.33e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.149, tt:1404.713\n",
      "Ep:126, loss:0.00000, loss_test:0.02690, lr:2.31e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.146, tt:1415.548\n",
      "Ep:127, loss:0.00000, loss_test:0.02693, lr:2.29e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.143, tt:1426.265\n",
      "Ep:128, loss:0.00000, loss_test:0.02700, lr:2.26e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.140, tt:1437.005\n",
      "Ep:129, loss:0.00000, loss_test:0.02700, lr:2.24e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.137, tt:1447.765\n",
      "Ep:130, loss:0.00000, loss_test:0.02701, lr:2.22e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.134, tt:1458.513\n",
      "Ep:131, loss:0.00000, loss_test:0.02709, lr:2.20e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.131, tt:1469.244\n",
      "Ep:132, loss:0.00000, loss_test:0.02711, lr:2.17e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.127, tt:1479.955\n",
      "Ep:133, loss:0.00000, loss_test:0.02714, lr:2.15e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.124, tt:1490.645\n",
      "Ep:134, loss:0.00000, loss_test:0.02717, lr:2.13e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.121, tt:1501.349\n",
      "Ep:135, loss:0.00000, loss_test:0.02722, lr:2.11e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.118, tt:1512.036\n",
      "Ep:136, loss:0.00000, loss_test:0.02722, lr:2.09e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.115, tt:1522.792\n",
      "Ep:137, loss:0.00000, loss_test:0.02727, lr:2.07e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.115, tt:1533.846\n",
      "Ep:138, loss:0.00000, loss_test:0.02731, lr:2.05e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.114, tt:1544.815\n",
      "Ep:139, loss:0.00000, loss_test:0.02733, lr:2.03e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.112, tt:1555.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.02736, lr:2.01e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.109, tt:1566.387\n",
      "Ep:141, loss:0.00000, loss_test:0.02741, lr:1.99e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.105, tt:1576.938\n",
      "Ep:142, loss:0.00000, loss_test:0.02743, lr:1.97e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.103, tt:1587.709\n",
      "Ep:143, loss:0.00000, loss_test:0.02746, lr:1.95e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.100, tt:1598.430\n",
      "Ep:144, loss:0.00000, loss_test:0.02751, lr:1.93e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.103, tt:1609.881\n",
      "Ep:145, loss:0.00000, loss_test:0.02753, lr:1.91e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.102, tt:1620.837\n",
      "Ep:146, loss:0.00000, loss_test:0.02755, lr:1.89e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.100, tt:1631.718\n",
      "Ep:147, loss:0.00000, loss_test:0.02759, lr:1.87e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.098, tt:1642.514\n",
      "Ep:148, loss:0.00000, loss_test:0.02761, lr:1.85e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.096, tt:1653.325\n",
      "Ep:149, loss:0.00000, loss_test:0.02760, lr:1.83e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.094, tt:1664.028\n",
      "Ep:150, loss:0.00000, loss_test:0.02763, lr:1.81e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.092, tt:1674.873\n",
      "Ep:151, loss:0.00000, loss_test:0.02765, lr:1.80e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.089, tt:1685.545\n",
      "Ep:152, loss:0.00000, loss_test:0.02768, lr:1.78e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.088, tt:1696.453\n",
      "Ep:153, loss:0.00000, loss_test:0.02772, lr:1.76e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.087, tt:1707.378\n",
      "Ep:154, loss:0.00000, loss_test:0.02774, lr:1.74e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.085, tt:1718.165\n",
      "Ep:155, loss:0.00000, loss_test:0.02776, lr:1.73e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.083, tt:1728.993\n",
      "Ep:156, loss:0.00000, loss_test:0.02777, lr:1.71e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.083, tt:1740.013\n",
      "Ep:157, loss:0.00000, loss_test:0.02778, lr:1.69e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.081, tt:1750.823\n",
      "Ep:158, loss:0.00000, loss_test:0.02780, lr:1.67e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.079, tt:1761.634\n",
      "Ep:159, loss:0.00000, loss_test:0.02782, lr:1.66e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.078, tt:1772.497\n",
      "Ep:160, loss:0.00000, loss_test:0.02785, lr:1.64e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.077, tt:1783.371\n",
      "Ep:161, loss:0.00000, loss_test:0.02789, lr:1.62e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.075, tt:1794.075\n",
      "Ep:162, loss:0.00000, loss_test:0.02790, lr:1.61e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.073, tt:1804.846\n",
      "Ep:163, loss:0.00000, loss_test:0.02792, lr:1.59e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.071, tt:1815.610\n",
      "Ep:164, loss:0.00000, loss_test:0.02794, lr:1.58e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.080, tt:1828.275\n",
      "Ep:165, loss:0.00000, loss_test:0.02796, lr:1.56e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.078, tt:1838.981\n",
      "Ep:166, loss:0.00000, loss_test:0.02796, lr:1.54e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.076, tt:1849.756\n",
      "Ep:167, loss:0.00000, loss_test:0.02798, lr:1.53e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.074, tt:1860.451\n",
      "Ep:168, loss:0.00000, loss_test:0.02800, lr:1.51e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.071, tt:1871.036\n",
      "Ep:169, loss:0.00000, loss_test:0.02802, lr:1.50e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.069, tt:1881.673\n",
      "Ep:170, loss:0.00000, loss_test:0.02804, lr:1.48e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.066, tt:1892.370\n",
      "Ep:171, loss:0.00000, loss_test:0.02806, lr:1.47e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.065, tt:1903.137\n",
      "Ep:172, loss:0.00000, loss_test:0.02808, lr:1.45e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.063, tt:1913.856\n",
      "Ep:173, loss:0.00000, loss_test:0.02809, lr:1.44e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.061, tt:1924.686\n",
      "Ep:174, loss:0.00000, loss_test:0.02810, lr:1.43e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.060, tt:1935.463\n",
      "Ep:175, loss:0.00000, loss_test:0.02812, lr:1.41e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.058, tt:1946.258\n",
      "Ep:176, loss:0.00000, loss_test:0.02813, lr:1.40e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.056, tt:1956.932\n",
      "Ep:177, loss:0.00000, loss_test:0.02815, lr:1.38e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.054, tt:1967.605\n",
      "Ep:178, loss:0.00000, loss_test:0.02815, lr:1.37e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.052, tt:1978.240\n",
      "Ep:179, loss:0.00000, loss_test:0.02817, lr:1.36e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.050, tt:1988.984\n",
      "Ep:180, loss:0.00000, loss_test:0.02818, lr:1.34e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.049, tt:1999.780\n",
      "Ep:181, loss:0.00000, loss_test:0.02819, lr:1.33e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.047, tt:2010.607\n",
      "Ep:182, loss:0.00000, loss_test:0.02822, lr:1.32e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.046, tt:2021.408\n",
      "Ep:183, loss:0.00000, loss_test:0.02823, lr:1.30e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.045, tt:2032.231\n",
      "Ep:184, loss:0.00000, loss_test:0.02824, lr:1.29e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.043, tt:2043.016\n",
      "Ep:185, loss:0.00000, loss_test:0.02825, lr:1.28e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.042, tt:2053.739\n",
      "Ep:186, loss:0.00000, loss_test:0.02826, lr:1.26e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.040, tt:2064.435\n",
      "Ep:187, loss:0.00000, loss_test:0.02827, lr:1.25e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.038, tt:2075.231\n",
      "Ep:188, loss:0.00000, loss_test:0.02828, lr:1.24e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.038, tt:2086.123\n",
      "Ep:189, loss:0.00000, loss_test:0.02830, lr:1.23e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.036, tt:2096.913\n",
      "Ep:190, loss:0.00000, loss_test:0.02831, lr:1.21e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.035, tt:2107.661\n",
      "Ep:191, loss:0.00000, loss_test:0.02832, lr:1.20e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.033, tt:2118.357\n",
      "Ep:192, loss:0.00000, loss_test:0.02833, lr:1.19e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.033, tt:2129.377\n",
      "Ep:193, loss:0.00000, loss_test:0.02835, lr:1.18e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.031, tt:2140.101\n",
      "Ep:194, loss:0.00000, loss_test:0.02836, lr:1.17e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.030, tt:2150.861\n",
      "Ep:195, loss:0.00000, loss_test:0.02837, lr:1.15e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.029, tt:2161.648\n",
      "Ep:196, loss:0.00000, loss_test:0.02838, lr:1.14e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.027, tt:2172.254\n",
      "Ep:197, loss:0.00000, loss_test:0.02839, lr:1.13e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.025, tt:2182.855\n",
      "Ep:198, loss:0.00000, loss_test:0.02841, lr:1.12e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.023, tt:2193.602\n",
      "Ep:199, loss:0.00000, loss_test:0.02842, lr:1.11e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.022, tt:2204.308\n",
      "Ep:200, loss:0.00000, loss_test:0.02843, lr:1.10e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.020, tt:2215.117\n",
      "Ep:201, loss:0.00000, loss_test:0.02844, lr:1.09e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.020, tt:2226.091\n",
      "Ep:202, loss:0.00000, loss_test:0.02845, lr:1.08e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.019, tt:2236.903\n",
      "Ep:203, loss:0.00000, loss_test:0.02847, lr:1.07e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.018, tt:2247.754\n",
      "Ep:204, loss:0.00000, loss_test:0.02848, lr:1.05e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.017, tt:2258.484\n",
      "Ep:205, loss:0.00000, loss_test:0.02849, lr:1.04e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.016, tt:2269.244\n",
      "Ep:206, loss:0.00000, loss_test:0.02850, lr:1.03e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.014, tt:2279.985\n",
      "Ep:207, loss:0.00000, loss_test:0.02851, lr:1.02e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.013, tt:2290.658\n",
      "Ep:208, loss:0.00000, loss_test:0.02851, lr:1.01e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.012, tt:2301.467\n",
      "Ep:209, loss:0.00000, loss_test:0.02852, lr:1.00e-02, fs:0.59200 (r=0.425,p=0.974),  time:11.011, tt:2312.404\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13918, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.884, tt:10.884\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.13632, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:10.996, tt:21.991\n",
      "Ep:2, loss:0.00027, loss_test:0.13111, lr:1.00e-02, fs:0.67194 (r=0.977,p=0.512),  time:10.923, tt:32.770\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12326, lr:1.00e-02, fs:0.66953 (r=0.897,p=0.534),  time:10.909, tt:43.636\n",
      "Ep:4, loss:0.00025, loss_test:0.11628, lr:1.00e-02, fs:0.67890 (r=0.851,p=0.565),  time:10.883, tt:54.416\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11320, lr:1.00e-02, fs:0.67943 (r=0.816,p=0.582),  time:10.861, tt:65.167\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11116, lr:1.00e-02, fs:0.69268 (r=0.816,p=0.602),  time:10.847, tt:75.930\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10898, lr:1.00e-02, fs:0.69856 (r=0.839,p=0.598),  time:10.846, tt:86.771\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10606, lr:1.00e-02, fs:0.71220 (r=0.839,p=0.619),  time:10.849, tt:97.642\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10304, lr:1.00e-02, fs:0.73575 (r=0.816,p=0.670),  time:10.839, tt:108.388\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10068, lr:1.00e-02, fs:0.74866 (r=0.805,p=0.700),  time:10.822, tt:119.044\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09732, lr:1.00e-02, fs:0.75132 (r=0.816,p=0.696),  time:10.928, tt:131.142\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09446, lr:1.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:10.921, tt:141.968\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09209, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:10.917, tt:152.839\n",
      "Ep:14, loss:0.00018, loss_test:0.09072, lr:1.00e-02, fs:0.76647 (r=0.736,p=0.800),  time:10.920, tt:163.796\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08889, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:10.919, tt:174.702\n",
      "Ep:16, loss:0.00016, loss_test:0.08795, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:10.914, tt:185.535\n",
      "Ep:17, loss:0.00015, loss_test:0.08620, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:10.909, tt:196.359\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08639, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:10.907, tt:207.224\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08587, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:10.910, tt:218.193\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08762, lr:1.00e-02, fs:0.79290 (r=0.770,p=0.817),  time:10.915, tt:229.206\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.08404, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:10.909, tt:240.000\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08542, lr:1.00e-02, fs:0.77576 (r=0.736,p=0.821),  time:10.904, tt:250.800\n",
      "Ep:23, loss:0.00011, loss_test:0.08331, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:10.906, tt:261.739\n",
      "Ep:24, loss:0.00010, loss_test:0.08462, lr:1.00e-02, fs:0.76829 (r=0.724,p=0.818),  time:10.901, tt:272.530\n",
      "Ep:25, loss:0.00010, loss_test:0.08846, lr:1.00e-02, fs:0.77019 (r=0.713,p=0.838),  time:10.896, tt:283.300\n",
      "Ep:26, loss:0.00009, loss_test:0.08619, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:10.893, tt:294.115\n",
      "Ep:27, loss:0.00009, loss_test:0.08647, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:10.891, tt:304.944\n",
      "Ep:28, loss:0.00008, loss_test:0.08721, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:10.889, tt:315.795\n",
      "Ep:29, loss:0.00007, loss_test:0.08566, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:10.890, tt:326.688\n",
      "Ep:30, loss:0.00007, loss_test:0.08845, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:10.889, tt:337.552\n",
      "Ep:31, loss:0.00007, loss_test:0.08555, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:10.887, tt:348.372\n",
      "Ep:32, loss:0.00006, loss_test:0.09211, lr:1.00e-02, fs:0.70345 (r=0.586,p=0.879),  time:10.887, tt:359.281\n",
      "Ep:33, loss:0.00006, loss_test:0.08406, lr:9.90e-03, fs:0.78710 (r=0.701,p=0.897),  time:10.889, tt:370.219\n",
      "Ep:34, loss:0.00005, loss_test:0.09524, lr:9.80e-03, fs:0.70345 (r=0.586,p=0.879),  time:10.890, tt:381.139\n",
      "Ep:35, loss:0.00005, loss_test:0.08652, lr:9.70e-03, fs:0.76000 (r=0.655,p=0.905),  time:10.893, tt:392.141\n",
      "Ep:36, loss:0.00005, loss_test:0.09878, lr:9.61e-03, fs:0.70922 (r=0.575,p=0.926),  time:10.896, tt:403.156\n",
      "Ep:37, loss:0.00004, loss_test:0.09412, lr:9.51e-03, fs:0.73103 (r=0.609,p=0.914),  time:10.911, tt:414.616\n",
      "Ep:38, loss:0.00004, loss_test:0.09678, lr:9.41e-03, fs:0.69930 (r=0.575,p=0.893),  time:10.920, tt:425.891\n",
      "Ep:39, loss:0.00004, loss_test:0.09746, lr:9.32e-03, fs:0.70504 (r=0.563,p=0.942),  time:10.923, tt:436.919\n",
      "Ep:40, loss:0.00003, loss_test:0.09561, lr:9.23e-03, fs:0.69065 (r=0.552,p=0.923),  time:10.925, tt:447.918\n",
      "Ep:41, loss:0.00003, loss_test:0.09803, lr:9.14e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.928, tt:458.971\n",
      "Ep:42, loss:0.00003, loss_test:0.10129, lr:9.04e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.939, tt:470.384\n",
      "Ep:43, loss:0.00003, loss_test:0.10062, lr:8.95e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.945, tt:481.593\n",
      "Ep:44, loss:0.00003, loss_test:0.09942, lr:8.86e-03, fs:0.69565 (r=0.552,p=0.941),  time:10.951, tt:492.797\n",
      "Ep:45, loss:0.00003, loss_test:0.10448, lr:8.78e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.956, tt:503.963\n",
      "Ep:46, loss:0.00002, loss_test:0.10061, lr:8.69e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.964, tt:515.324\n",
      "Ep:47, loss:0.00002, loss_test:0.10434, lr:8.60e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.972, tt:526.664\n",
      "Ep:48, loss:0.00002, loss_test:0.10249, lr:8.51e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.978, tt:537.924\n",
      "Ep:49, loss:0.00002, loss_test:0.10475, lr:8.43e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.985, tt:549.249\n",
      "Ep:50, loss:0.00002, loss_test:0.10825, lr:8.35e-03, fs:0.70073 (r=0.552,p=0.960),  time:10.996, tt:560.809\n",
      "Ep:51, loss:0.00002, loss_test:0.10995, lr:8.26e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.001, tt:572.045\n",
      "Ep:52, loss:0.00001, loss_test:0.10768, lr:8.18e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.002, tt:583.099\n",
      "Ep:53, loss:0.00001, loss_test:0.11116, lr:8.10e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.005, tt:594.297\n",
      "Ep:54, loss:0.00001, loss_test:0.11462, lr:8.02e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.008, tt:605.437\n",
      "Ep:55, loss:0.00001, loss_test:0.11150, lr:7.94e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.009, tt:616.491\n",
      "Ep:56, loss:0.00001, loss_test:0.11439, lr:7.86e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.010, tt:627.561\n",
      "Ep:57, loss:0.00001, loss_test:0.11325, lr:7.78e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.008, tt:638.444\n",
      "Ep:58, loss:0.00001, loss_test:0.11687, lr:7.70e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.006, tt:649.374\n",
      "Ep:59, loss:0.00001, loss_test:0.11367, lr:7.62e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.004, tt:660.240\n",
      "Ep:60, loss:0.00001, loss_test:0.12150, lr:7.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.001, tt:671.065\n",
      "Ep:61, loss:0.00001, loss_test:0.11866, lr:7.47e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.001, tt:682.038\n",
      "Ep:62, loss:0.00001, loss_test:0.11718, lr:7.40e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.001, tt:693.052\n",
      "Ep:63, loss:0.00001, loss_test:0.12493, lr:7.32e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.001, tt:704.077\n",
      "Ep:64, loss:0.00001, loss_test:0.11682, lr:7.25e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.001, tt:715.064\n",
      "Ep:65, loss:0.00001, loss_test:0.12947, lr:7.18e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.001, tt:726.046\n",
      "Ep:66, loss:0.00001, loss_test:0.11992, lr:7.11e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.000, tt:736.974\n",
      "Ep:67, loss:0.00001, loss_test:0.12273, lr:7.03e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.999, tt:747.962\n",
      "Ep:68, loss:0.00001, loss_test:0.12526, lr:6.96e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:759.975\n",
      "Ep:69, loss:0.00001, loss_test:0.12357, lr:6.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:770.969\n",
      "Ep:70, loss:0.00001, loss_test:0.12514, lr:6.83e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.011, tt:781.785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00000, loss_test:0.12494, lr:6.76e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.012, tt:792.844\n",
      "Ep:72, loss:0.00000, loss_test:0.12599, lr:6.69e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.012, tt:803.891\n",
      "Ep:73, loss:0.00000, loss_test:0.12494, lr:6.62e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.013, tt:814.976\n",
      "Ep:74, loss:0.00000, loss_test:0.12477, lr:6.56e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.017, tt:826.276\n",
      "Ep:75, loss:0.00000, loss_test:0.12637, lr:6.49e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.017, tt:837.268\n",
      "Ep:76, loss:0.00000, loss_test:0.12591, lr:6.43e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.018, tt:848.410\n",
      "Ep:77, loss:0.00000, loss_test:0.12650, lr:6.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.018, tt:859.366\n",
      "Ep:78, loss:0.00000, loss_test:0.12776, lr:6.30e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.017, tt:870.306\n",
      "Ep:79, loss:0.00000, loss_test:0.12808, lr:6.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.016, tt:881.279\n",
      "Ep:80, loss:0.00000, loss_test:0.12742, lr:6.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.016, tt:892.306\n",
      "Ep:81, loss:0.00000, loss_test:0.12935, lr:6.11e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.016, tt:903.279\n",
      "Ep:82, loss:0.00000, loss_test:0.12750, lr:6.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:914.151\n",
      "Ep:83, loss:0.00000, loss_test:0.12900, lr:5.99e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:925.168\n",
      "Ep:84, loss:0.00000, loss_test:0.12879, lr:5.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.015, tt:936.289\n",
      "Ep:85, loss:0.00000, loss_test:0.12864, lr:5.87e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.016, tt:947.360\n",
      "Ep:86, loss:0.00000, loss_test:0.12815, lr:5.81e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.015, tt:958.294\n",
      "Ep:87, loss:0.00000, loss_test:0.13177, lr:5.75e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:969.212\n",
      "Ep:88, loss:0.00000, loss_test:0.13094, lr:5.70e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.015, tt:980.316\n",
      "Ep:89, loss:0.00000, loss_test:0.13030, lr:5.64e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:991.241\n",
      "Ep:90, loss:0.00000, loss_test:0.12950, lr:5.58e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:1002.281\n",
      "Ep:91, loss:0.00000, loss_test:0.13120, lr:5.53e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:1013.263\n",
      "Ep:92, loss:0.00000, loss_test:0.13073, lr:5.47e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:1024.282\n",
      "Ep:93, loss:0.00000, loss_test:0.13044, lr:5.42e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.014, tt:1035.302\n",
      "Ep:94, loss:0.00000, loss_test:0.13246, lr:5.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.012, tt:1046.141\n",
      "Ep:95, loss:0.00000, loss_test:0.13132, lr:5.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.010, tt:1056.969\n",
      "Ep:96, loss:0.00000, loss_test:0.13034, lr:5.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.011, tt:1068.027\n",
      "Ep:97, loss:0.00000, loss_test:0.13107, lr:5.20e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.010, tt:1078.943\n",
      "Ep:98, loss:0.00000, loss_test:0.13052, lr:5.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.009, tt:1089.941\n",
      "Ep:99, loss:0.00000, loss_test:0.13061, lr:5.10e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.008, tt:1100.754\n",
      "Ep:100, loss:0.00000, loss_test:0.13179, lr:5.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.004, tt:1111.434\n",
      "Ep:101, loss:0.00000, loss_test:0.13031, lr:5.00e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.001, tt:1122.090\n",
      "Ep:102, loss:0.00000, loss_test:0.13085, lr:4.95e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.999, tt:1132.928\n",
      "Ep:103, loss:0.00000, loss_test:0.13219, lr:4.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:1143.826\n",
      "Ep:104, loss:0.00000, loss_test:0.12973, lr:4.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1154.701\n",
      "Ep:105, loss:0.00000, loss_test:0.13052, lr:4.80e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:1165.790\n",
      "Ep:106, loss:0.00000, loss_test:0.13125, lr:4.75e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1176.675\n",
      "Ep:107, loss:0.00000, loss_test:0.13012, lr:4.71e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1187.469\n",
      "Ep:108, loss:0.00000, loss_test:0.13053, lr:4.66e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.994, tt:1198.334\n",
      "Ep:109, loss:0.00000, loss_test:0.13185, lr:4.61e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.992, tt:1209.154\n",
      "Ep:110, loss:0.00000, loss_test:0.13140, lr:4.57e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1219.980\n",
      "Ep:111, loss:0.00000, loss_test:0.13030, lr:4.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1231.041\n",
      "Ep:112, loss:0.00000, loss_test:0.13197, lr:4.48e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1241.956\n",
      "Ep:113, loss:0.00000, loss_test:0.13070, lr:4.43e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1252.918\n",
      "Ep:114, loss:0.00000, loss_test:0.13076, lr:4.39e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.988, tt:1263.666\n",
      "Ep:115, loss:0.00000, loss_test:0.13181, lr:4.34e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.986, tt:1274.419\n",
      "Ep:116, loss:0.00000, loss_test:0.12974, lr:4.30e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1285.271\n",
      "Ep:117, loss:0.00000, loss_test:0.13142, lr:4.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1296.225\n",
      "Ep:118, loss:0.00000, loss_test:0.13123, lr:4.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1307.221\n",
      "Ep:119, loss:0.00000, loss_test:0.13110, lr:4.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1318.209\n",
      "Ep:120, loss:0.00000, loss_test:0.13124, lr:4.13e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.984, tt:1329.119\n",
      "Ep:121, loss:0.00000, loss_test:0.13086, lr:4.09e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.983, tt:1339.945\n",
      "Ep:122, loss:0.00000, loss_test:0.13076, lr:4.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.983, tt:1350.945\n",
      "Ep:123, loss:0.00000, loss_test:0.13032, lr:4.01e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.982, tt:1361.766\n",
      "Ep:124, loss:0.00000, loss_test:0.13151, lr:3.97e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.982, tt:1372.732\n",
      "Ep:125, loss:0.00000, loss_test:0.13128, lr:3.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.006, tt:1386.785\n",
      "Ep:126, loss:0.00000, loss_test:0.13056, lr:3.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.006, tt:1397.789\n",
      "Ep:127, loss:0.00000, loss_test:0.13180, lr:3.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.005, tt:1408.640\n",
      "Ep:128, loss:0.00000, loss_test:0.13174, lr:3.81e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.004, tt:1419.541\n",
      "Ep:129, loss:0.00000, loss_test:0.13036, lr:3.77e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.003, tt:1430.401\n",
      "Ep:130, loss:0.00000, loss_test:0.13101, lr:3.73e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.005, tt:1441.671\n",
      "Ep:131, loss:0.00000, loss_test:0.13258, lr:3.70e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.004, tt:1452.572\n",
      "Ep:132, loss:0.00000, loss_test:0.13269, lr:3.66e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.003, tt:1463.385\n",
      "Ep:133, loss:0.00000, loss_test:0.13169, lr:3.62e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.003, tt:1474.424\n",
      "Ep:134, loss:0.00000, loss_test:0.13159, lr:3.59e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.003, tt:1485.406\n",
      "Ep:135, loss:0.00000, loss_test:0.13211, lr:3.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.002, tt:1496.310\n",
      "Ep:136, loss:0.00000, loss_test:0.13211, lr:3.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.000, tt:1507.055\n",
      "Ep:137, loss:0.00000, loss_test:0.13147, lr:3.48e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.000, tt:1517.956\n",
      "Ep:138, loss:0.00000, loss_test:0.13065, lr:3.45e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.999, tt:1528.852\n",
      "Ep:139, loss:0.00000, loss_test:0.13017, lr:3.41e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1539.621\n",
      "Ep:140, loss:0.00000, loss_test:0.13123, lr:3.38e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1550.574\n",
      "Ep:141, loss:0.00000, loss_test:0.13169, lr:3.34e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1561.580\n",
      "Ep:142, loss:0.00000, loss_test:0.13103, lr:3.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:1572.437\n",
      "Ep:143, loss:0.00000, loss_test:0.13101, lr:3.28e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:1583.360\n",
      "Ep:144, loss:0.00000, loss_test:0.13080, lr:3.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:1594.361\n",
      "Ep:145, loss:0.00000, loss_test:0.13101, lr:3.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1605.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.13108, lr:3.18e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1616.234\n",
      "Ep:147, loss:0.00000, loss_test:0.13049, lr:3.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1627.267\n",
      "Ep:148, loss:0.00000, loss_test:0.13069, lr:3.12e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1638.505\n",
      "Ep:149, loss:0.00000, loss_test:0.13088, lr:3.09e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.997, tt:1649.506\n",
      "Ep:150, loss:0.00000, loss_test:0.13064, lr:3.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:1660.366\n",
      "Ep:151, loss:0.00000, loss_test:0.13054, lr:3.02e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1671.213\n",
      "Ep:152, loss:0.00000, loss_test:0.13098, lr:2.99e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.994, tt:1682.111\n",
      "Ep:153, loss:0.00000, loss_test:0.13057, lr:2.96e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.994, tt:1693.141\n",
      "Ep:154, loss:0.00000, loss_test:0.13020, lr:2.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1704.162\n",
      "Ep:155, loss:0.00000, loss_test:0.13095, lr:2.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1715.164\n",
      "Ep:156, loss:0.00000, loss_test:0.13085, lr:2.88e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1726.249\n",
      "Ep:157, loss:0.00000, loss_test:0.12998, lr:2.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1737.172\n",
      "Ep:158, loss:0.00000, loss_test:0.13080, lr:2.82e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.995, tt:1748.185\n",
      "Ep:159, loss:0.00000, loss_test:0.13071, lr:2.79e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.994, tt:1759.108\n",
      "Ep:160, loss:0.00000, loss_test:0.13005, lr:2.76e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:1770.119\n",
      "Ep:161, loss:0.00000, loss_test:0.13086, lr:2.73e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.994, tt:1781.052\n",
      "Ep:162, loss:0.00000, loss_test:0.13052, lr:2.71e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.993, tt:1791.920\n",
      "Ep:163, loss:0.00000, loss_test:0.12982, lr:2.68e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.993, tt:1802.907\n",
      "Ep:164, loss:0.00000, loss_test:0.13048, lr:2.65e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.993, tt:1813.775\n",
      "Ep:165, loss:0.00000, loss_test:0.13065, lr:2.63e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.992, tt:1824.718\n",
      "Ep:166, loss:0.00000, loss_test:0.13002, lr:2.60e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1835.559\n",
      "Ep:167, loss:0.00000, loss_test:0.12993, lr:2.57e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.991, tt:1846.549\n",
      "Ep:168, loss:0.00000, loss_test:0.13044, lr:2.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.991, tt:1857.400\n",
      "Ep:169, loss:0.00000, loss_test:0.13049, lr:2.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.989, tt:1868.116\n",
      "Ep:170, loss:0.00000, loss_test:0.13042, lr:2.50e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.988, tt:1879.031\n",
      "Ep:171, loss:0.00000, loss_test:0.13022, lr:2.47e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.988, tt:1889.978\n",
      "Ep:172, loss:0.00000, loss_test:0.13027, lr:2.45e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.988, tt:1900.893\n",
      "Ep:173, loss:0.00000, loss_test:0.13094, lr:2.42e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.987, tt:1911.729\n",
      "Ep:174, loss:0.00000, loss_test:0.13133, lr:2.40e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.987, tt:1922.668\n",
      "Ep:175, loss:0.00000, loss_test:0.13067, lr:2.38e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.987, tt:1933.644\n",
      "Ep:176, loss:0.00000, loss_test:0.13036, lr:2.35e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.987, tt:1944.681\n",
      "Ep:177, loss:0.00000, loss_test:0.13109, lr:2.33e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.987, tt:1955.635\n",
      "Ep:178, loss:0.00000, loss_test:0.13185, lr:2.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.986, tt:1966.478\n",
      "Ep:179, loss:0.00000, loss_test:0.13077, lr:2.28e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1977.345\n",
      "Ep:180, loss:0.00000, loss_test:0.13043, lr:2.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.985, tt:1988.290\n",
      "Ep:181, loss:0.00000, loss_test:0.13097, lr:2.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.984, tt:1999.129\n",
      "Ep:182, loss:0.00000, loss_test:0.13123, lr:2.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.999, tt:2012.739\n",
      "Ep:183, loss:0.00000, loss_test:0.13093, lr:2.19e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:2023.721\n",
      "Ep:184, loss:0.00000, loss_test:0.13036, lr:2.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:2034.584\n",
      "Ep:185, loss:0.00000, loss_test:0.12997, lr:2.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.000, tt:2045.964\n",
      "Ep:186, loss:0.00000, loss_test:0.13002, lr:2.13e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.999, tt:2056.823\n",
      "Ep:187, loss:0.00000, loss_test:0.13047, lr:2.11e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.998, tt:2067.709\n",
      "Ep:188, loss:0.00000, loss_test:0.13029, lr:2.08e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.998, tt:2078.637\n",
      "Ep:189, loss:0.00000, loss_test:0.12981, lr:2.06e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:2089.657\n",
      "Ep:190, loss:0.00000, loss_test:0.13019, lr:2.04e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.998, tt:2100.680\n",
      "Ep:191, loss:0.00000, loss_test:0.13044, lr:2.02e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.998, tt:2111.671\n",
      "Ep:192, loss:0.00000, loss_test:0.13062, lr:2.00e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:2122.589\n",
      "Ep:193, loss:0.00000, loss_test:0.13003, lr:1.98e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.998, tt:2133.542\n",
      "Ep:194, loss:0.00000, loss_test:0.12999, lr:1.96e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.996, tt:2144.306\n",
      "Ep:195, loss:0.00000, loss_test:0.13014, lr:1.94e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.996, tt:2155.215\n",
      "Ep:196, loss:0.00000, loss_test:0.13060, lr:1.92e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:2166.078\n",
      "Ep:197, loss:0.00000, loss_test:0.13045, lr:1.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:2177.151\n",
      "Ep:198, loss:0.00000, loss_test:0.13007, lr:1.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.996, tt:2188.150\n",
      "Ep:199, loss:0.00000, loss_test:0.12975, lr:1.87e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.996, tt:2199.152\n",
      "Ep:200, loss:0.00000, loss_test:0.12983, lr:1.85e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.996, tt:2210.103\n",
      "Ep:201, loss:0.00000, loss_test:0.12999, lr:1.83e-03, fs:0.71111 (r=0.552,p=1.000),  time:10.995, tt:2221.003\n",
      "Ep:202, loss:0.00000, loss_test:0.12994, lr:1.81e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.994, tt:2231.852\n",
      "Ep:203, loss:0.00000, loss_test:0.12982, lr:1.79e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.994, tt:2242.822\n",
      "Ep:204, loss:0.00000, loss_test:0.12989, lr:1.78e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.994, tt:2253.702\n",
      "Ep:205, loss:0.00000, loss_test:0.13024, lr:1.76e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.994, tt:2264.668\n",
      "Ep:206, loss:0.00000, loss_test:0.13006, lr:1.74e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.993, tt:2275.571\n",
      "Ep:207, loss:0.00000, loss_test:0.13013, lr:1.72e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.993, tt:2286.559\n",
      "Ep:208, loss:0.00000, loss_test:0.13009, lr:1.71e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.993, tt:2297.615\n",
      "Ep:209, loss:0.00000, loss_test:0.13003, lr:1.69e-03, fs:0.70588 (r=0.552,p=0.980),  time:10.993, tt:2308.560\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02156, lr:6.00e-02, fs:0.61751 (r=0.770,p=0.515),  time:36.703, tt:36.703\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02291, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.776, tt:71.552\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02434, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.253, tt:105.760\n",
      "Ep:3, loss:0.00005, loss_test:0.02410, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.331, tt:141.324\n",
      "Ep:4, loss:0.00005, loss_test:0.02298, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:35.268, tt:176.340\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02160, lr:6.00e-02, fs:0.66667 (r=0.954,p=0.512),  time:35.177, tt:211.061\n",
      "Ep:6, loss:0.00004, loss_test:0.02088, lr:6.00e-02, fs:0.65517 (r=0.874,p=0.524),  time:35.410, tt:247.872\n",
      "Ep:7, loss:0.00004, loss_test:0.02098, lr:6.00e-02, fs:0.67273 (r=0.851,p=0.556),  time:35.365, tt:282.919\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02068, lr:6.00e-02, fs:0.66341 (r=0.782,p=0.576),  time:35.387, tt:318.486\n",
      "Ep:9, loss:0.00004, loss_test:0.01963, lr:6.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:35.343, tt:353.427\n",
      "Ep:10, loss:0.00003, loss_test:0.01896, lr:6.00e-02, fs:0.66376 (r=0.874,p=0.535),  time:35.456, tt:390.018\n",
      "Ep:11, loss:0.00003, loss_test:0.01869, lr:6.00e-02, fs:0.66957 (r=0.885,p=0.538),  time:35.544, tt:426.528\n",
      "Ep:12, loss:0.00003, loss_test:0.01841, lr:6.00e-02, fs:0.66964 (r=0.862,p=0.547),  time:35.453, tt:460.883\n",
      "Ep:13, loss:0.00003, loss_test:0.01824, lr:6.00e-02, fs:0.67308 (r=0.805,p=0.579),  time:35.470, tt:496.583\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01827, lr:6.00e-02, fs:0.69000 (r=0.793,p=0.611),  time:35.316, tt:529.746\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:35.322, tt:565.158\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.71134 (r=0.793,p=0.645),  time:35.393, tt:601.686\n",
      "Ep:17, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:35.480, tt:638.648\n",
      "Ep:18, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.72081 (r=0.816,p=0.645),  time:35.512, tt:674.722\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.72081 (r=0.816,p=0.645),  time:35.464, tt:709.278\n",
      "Ep:20, loss:0.00003, loss_test:0.01748, lr:6.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:35.417, tt:743.759\n",
      "Ep:21, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.73797 (r=0.793,p=0.690),  time:35.476, tt:780.478\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01741, lr:6.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:35.441, tt:815.154\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01729, lr:6.00e-02, fs:0.72826 (r=0.770,p=0.691),  time:35.413, tt:849.918\n",
      "Ep:24, loss:0.00002, loss_test:0.01720, lr:6.00e-02, fs:0.73224 (r=0.770,p=0.698),  time:35.426, tt:885.641\n",
      "Ep:25, loss:0.00002, loss_test:0.01725, lr:6.00e-02, fs:0.73333 (r=0.759,p=0.710),  time:35.458, tt:921.911\n",
      "Ep:26, loss:0.00002, loss_test:0.01735, lr:6.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:35.505, tt:958.634\n",
      "Ep:27, loss:0.00002, loss_test:0.01741, lr:6.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:35.511, tt:994.321\n",
      "Ep:28, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.72093 (r=0.713,p=0.729),  time:35.499, tt:1029.475\n",
      "Ep:29, loss:0.00002, loss_test:0.01749, lr:6.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:35.555, tt:1066.662\n",
      "Ep:30, loss:0.00002, loss_test:0.01750, lr:6.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:35.579, tt:1102.945\n",
      "Ep:31, loss:0.00002, loss_test:0.01755, lr:6.00e-02, fs:0.69880 (r=0.667,p=0.734),  time:35.610, tt:1139.509\n",
      "Ep:32, loss:0.00002, loss_test:0.01768, lr:6.00e-02, fs:0.68323 (r=0.632,p=0.743),  time:35.617, tt:1175.347\n",
      "Ep:33, loss:0.00002, loss_test:0.01784, lr:6.00e-02, fs:0.68750 (r=0.632,p=0.753),  time:35.631, tt:1211.445\n",
      "Ep:34, loss:0.00002, loss_test:0.01787, lr:5.94e-02, fs:0.69182 (r=0.632,p=0.764),  time:35.614, tt:1246.500\n",
      "Ep:35, loss:0.00001, loss_test:0.01788, lr:5.88e-02, fs:0.69620 (r=0.632,p=0.775),  time:35.590, tt:1281.236\n",
      "Ep:36, loss:0.00001, loss_test:0.01794, lr:5.82e-02, fs:0.70064 (r=0.632,p=0.786),  time:35.739, tt:1322.356\n",
      "Ep:37, loss:0.00001, loss_test:0.01811, lr:5.76e-02, fs:0.70064 (r=0.632,p=0.786),  time:35.704, tt:1356.767\n",
      "Ep:38, loss:0.00001, loss_test:0.01833, lr:5.71e-02, fs:0.70513 (r=0.632,p=0.797),  time:35.717, tt:1392.982\n",
      "Ep:39, loss:0.00001, loss_test:0.01834, lr:5.65e-02, fs:0.70968 (r=0.632,p=0.809),  time:35.772, tt:1430.896\n",
      "Ep:40, loss:0.00001, loss_test:0.01843, lr:5.59e-02, fs:0.70968 (r=0.632,p=0.809),  time:35.781, tt:1467.015\n",
      "Ep:41, loss:0.00001, loss_test:0.01865, lr:5.54e-02, fs:0.69737 (r=0.609,p=0.815),  time:35.792, tt:1503.262\n",
      "Ep:42, loss:0.00001, loss_test:0.01875, lr:5.48e-02, fs:0.68874 (r=0.598,p=0.812),  time:35.814, tt:1540.021\n",
      "Ep:43, loss:0.00001, loss_test:0.01887, lr:5.43e-02, fs:0.68000 (r=0.586,p=0.810),  time:35.826, tt:1576.363\n",
      "Ep:44, loss:0.00001, loss_test:0.01916, lr:5.37e-02, fs:0.68456 (r=0.586,p=0.823),  time:35.862, tt:1613.796\n",
      "Ep:45, loss:0.00001, loss_test:0.01928, lr:5.32e-02, fs:0.68456 (r=0.586,p=0.823),  time:35.834, tt:1648.368\n",
      "Ep:46, loss:0.00001, loss_test:0.01940, lr:5.27e-02, fs:0.68456 (r=0.586,p=0.823),  time:35.864, tt:1685.610\n",
      "Ep:47, loss:0.00001, loss_test:0.01955, lr:5.21e-02, fs:0.68919 (r=0.586,p=0.836),  time:35.894, tt:1722.905\n",
      "Ep:48, loss:0.00001, loss_test:0.01969, lr:5.16e-02, fs:0.68919 (r=0.586,p=0.836),  time:35.900, tt:1759.084\n",
      "Ep:49, loss:0.00001, loss_test:0.01989, lr:5.11e-02, fs:0.68493 (r=0.575,p=0.847),  time:35.921, tt:1796.071\n",
      "Ep:50, loss:0.00001, loss_test:0.02014, lr:5.06e-02, fs:0.67586 (r=0.563,p=0.845),  time:35.936, tt:1832.715\n",
      "Ep:51, loss:0.00001, loss_test:0.02019, lr:5.01e-02, fs:0.67586 (r=0.563,p=0.845),  time:35.993, tt:1871.645\n",
      "Ep:52, loss:0.00001, loss_test:0.02033, lr:4.96e-02, fs:0.66667 (r=0.552,p=0.842),  time:35.969, tt:1906.368\n",
      "Ep:53, loss:0.00001, loss_test:0.02047, lr:4.91e-02, fs:0.67133 (r=0.552,p=0.857),  time:35.920, tt:1939.704\n",
      "Ep:54, loss:0.00001, loss_test:0.02064, lr:4.86e-02, fs:0.67133 (r=0.552,p=0.857),  time:35.922, tt:1975.718\n",
      "Ep:55, loss:0.00001, loss_test:0.02074, lr:4.81e-02, fs:0.66197 (r=0.540,p=0.855),  time:35.916, tt:2011.313\n",
      "Ep:56, loss:0.00001, loss_test:0.02088, lr:4.76e-02, fs:0.66197 (r=0.540,p=0.855),  time:35.935, tt:2048.315\n",
      "Ep:57, loss:0.00001, loss_test:0.02100, lr:4.71e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.943, tt:2084.674\n",
      "Ep:58, loss:0.00001, loss_test:0.02113, lr:4.67e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.955, tt:2121.333\n",
      "Ep:59, loss:0.00001, loss_test:0.02126, lr:4.62e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.983, tt:2159.003\n",
      "Ep:60, loss:0.00001, loss_test:0.02140, lr:4.57e-02, fs:0.65714 (r=0.529,p=0.868),  time:35.946, tt:2192.718\n",
      "Ep:61, loss:0.00001, loss_test:0.02155, lr:4.53e-02, fs:0.63768 (r=0.506,p=0.863),  time:35.921, tt:2227.088\n",
      "Ep:62, loss:0.00001, loss_test:0.02166, lr:4.48e-02, fs:0.63768 (r=0.506,p=0.863),  time:35.928, tt:2263.459\n",
      "Ep:63, loss:0.00001, loss_test:0.02178, lr:4.44e-02, fs:0.63768 (r=0.506,p=0.863),  time:35.890, tt:2296.930\n",
      "Ep:64, loss:0.00001, loss_test:0.02199, lr:4.39e-02, fs:0.63704 (r=0.494,p=0.896),  time:35.858, tt:2330.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.02214, lr:4.35e-02, fs:0.62687 (r=0.483,p=0.894),  time:35.847, tt:2365.873\n",
      "Ep:66, loss:0.00001, loss_test:0.02223, lr:4.31e-02, fs:0.62687 (r=0.483,p=0.894),  time:35.840, tt:2401.313\n",
      "Ep:67, loss:0.00001, loss_test:0.02239, lr:4.26e-02, fs:0.62687 (r=0.483,p=0.894),  time:35.847, tt:2437.564\n",
      "Ep:68, loss:0.00001, loss_test:0.02262, lr:4.22e-02, fs:0.62687 (r=0.483,p=0.894),  time:35.830, tt:2472.260\n",
      "Ep:69, loss:0.00001, loss_test:0.02273, lr:4.18e-02, fs:0.62687 (r=0.483,p=0.894),  time:35.838, tt:2508.694\n",
      "Ep:70, loss:0.00001, loss_test:0.02290, lr:4.14e-02, fs:0.61069 (r=0.460,p=0.909),  time:35.852, tt:2545.462\n",
      "Ep:71, loss:0.00001, loss_test:0.02303, lr:4.10e-02, fs:0.61069 (r=0.460,p=0.909),  time:35.841, tt:2580.526\n",
      "Ep:72, loss:0.00001, loss_test:0.02314, lr:4.05e-02, fs:0.61069 (r=0.460,p=0.909),  time:35.830, tt:2615.613\n",
      "Ep:73, loss:0.00001, loss_test:0.02323, lr:4.01e-02, fs:0.61069 (r=0.460,p=0.909),  time:35.813, tt:2650.144\n",
      "Ep:74, loss:0.00000, loss_test:0.02340, lr:3.97e-02, fs:0.60000 (r=0.448,p=0.907),  time:35.813, tt:2685.960\n",
      "Ep:75, loss:0.00000, loss_test:0.02353, lr:3.93e-02, fs:0.60000 (r=0.448,p=0.907),  time:35.789, tt:2719.991\n",
      "Ep:76, loss:0.00000, loss_test:0.02365, lr:3.89e-02, fs:0.60000 (r=0.448,p=0.907),  time:35.744, tt:2752.305\n",
      "Ep:77, loss:0.00000, loss_test:0.02379, lr:3.86e-02, fs:0.60000 (r=0.448,p=0.907),  time:35.736, tt:2787.371\n",
      "Ep:78, loss:0.00000, loss_test:0.02396, lr:3.82e-02, fs:0.58915 (r=0.437,p=0.905),  time:35.735, tt:2823.046\n",
      "Ep:79, loss:0.00000, loss_test:0.02401, lr:3.78e-02, fs:0.58915 (r=0.437,p=0.905),  time:35.716, tt:2857.253\n",
      "Ep:80, loss:0.00000, loss_test:0.02418, lr:3.74e-02, fs:0.57812 (r=0.425,p=0.902),  time:35.728, tt:2894.009\n",
      "Ep:81, loss:0.00000, loss_test:0.02434, lr:3.70e-02, fs:0.57812 (r=0.425,p=0.902),  time:35.707, tt:2928.000\n",
      "Ep:82, loss:0.00000, loss_test:0.02444, lr:3.67e-02, fs:0.57812 (r=0.425,p=0.902),  time:35.712, tt:2964.128\n",
      "Ep:83, loss:0.00000, loss_test:0.02452, lr:3.63e-02, fs:0.57812 (r=0.425,p=0.902),  time:35.689, tt:2997.882\n",
      "Ep:84, loss:0.00000, loss_test:0.02470, lr:3.59e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.698, tt:3034.370\n",
      "Ep:85, loss:0.00000, loss_test:0.02483, lr:3.56e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.694, tt:3069.650\n",
      "Ep:86, loss:0.00000, loss_test:0.02493, lr:3.52e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.699, tt:3105.830\n",
      "Ep:87, loss:0.00000, loss_test:0.02501, lr:3.49e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.700, tt:3141.622\n",
      "Ep:88, loss:0.00000, loss_test:0.02511, lr:3.45e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.704, tt:3177.624\n",
      "Ep:89, loss:0.00000, loss_test:0.02519, lr:3.42e-02, fs:0.58268 (r=0.425,p=0.925),  time:35.710, tt:3213.863\n",
      "Ep:90, loss:0.00000, loss_test:0.02534, lr:3.38e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.717, tt:3250.219\n",
      "Ep:91, loss:0.00000, loss_test:0.02547, lr:3.35e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.714, tt:3285.664\n",
      "Ep:92, loss:0.00000, loss_test:0.02558, lr:3.32e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.762, tt:3325.861\n",
      "Ep:93, loss:0.00000, loss_test:0.02562, lr:3.28e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.770, tt:3362.426\n",
      "Ep:94, loss:0.00000, loss_test:0.02568, lr:3.25e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.753, tt:3396.569\n",
      "Ep:95, loss:0.00000, loss_test:0.02576, lr:3.22e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.765, tt:3433.484\n",
      "Ep:96, loss:0.00000, loss_test:0.02587, lr:3.19e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.755, tt:3468.203\n",
      "Ep:97, loss:0.00000, loss_test:0.02593, lr:3.15e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.761, tt:3504.593\n",
      "Ep:98, loss:0.00000, loss_test:0.02603, lr:3.12e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.758, tt:3540.024\n",
      "Ep:99, loss:0.00000, loss_test:0.02612, lr:3.09e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.777, tt:3577.692\n",
      "Ep:100, loss:0.00000, loss_test:0.02618, lr:3.06e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.790, tt:3614.840\n",
      "Ep:101, loss:0.00000, loss_test:0.02628, lr:3.03e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.773, tt:3648.820\n",
      "Ep:102, loss:0.00000, loss_test:0.02641, lr:3.00e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.771, tt:3684.439\n",
      "Ep:103, loss:0.00000, loss_test:0.02651, lr:2.97e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.770, tt:3720.126\n",
      "Ep:104, loss:0.00000, loss_test:0.02657, lr:2.94e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.763, tt:3755.099\n",
      "Ep:105, loss:0.00000, loss_test:0.02662, lr:2.91e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.771, tt:3791.766\n",
      "Ep:106, loss:0.00000, loss_test:0.02669, lr:2.88e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.767, tt:3827.108\n",
      "Ep:107, loss:0.00000, loss_test:0.02676, lr:2.85e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.771, tt:3863.252\n",
      "Ep:108, loss:0.00000, loss_test:0.02686, lr:2.82e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.784, tt:3900.407\n",
      "Ep:109, loss:0.00000, loss_test:0.02692, lr:2.80e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.786, tt:3936.469\n",
      "Ep:110, loss:0.00000, loss_test:0.02700, lr:2.77e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.777, tt:3971.224\n",
      "Ep:111, loss:0.00000, loss_test:0.02706, lr:2.74e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.842, tt:4014.320\n",
      "Ep:112, loss:0.00000, loss_test:0.02714, lr:2.71e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.831, tt:4048.859\n",
      "Ep:113, loss:0.00000, loss_test:0.02721, lr:2.69e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.826, tt:4084.194\n",
      "Ep:114, loss:0.00000, loss_test:0.02724, lr:2.66e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.832, tt:4120.624\n",
      "Ep:115, loss:0.00000, loss_test:0.02730, lr:2.63e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.831, tt:4156.423\n",
      "Ep:116, loss:0.00000, loss_test:0.02738, lr:2.61e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.847, tt:4194.102\n",
      "Ep:117, loss:0.00000, loss_test:0.02744, lr:2.58e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.857, tt:4231.137\n",
      "Ep:118, loss:0.00000, loss_test:0.02751, lr:2.55e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.870, tt:4268.584\n",
      "Ep:119, loss:0.00000, loss_test:0.02757, lr:2.53e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.873, tt:4304.748\n",
      "Ep:120, loss:0.00000, loss_test:0.02763, lr:2.50e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.866, tt:4339.806\n",
      "Ep:121, loss:0.00000, loss_test:0.02769, lr:2.48e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.860, tt:4374.959\n",
      "Ep:122, loss:0.00000, loss_test:0.02776, lr:2.45e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.859, tt:4410.682\n",
      "Ep:123, loss:0.00000, loss_test:0.02783, lr:2.43e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.844, tt:4444.657\n",
      "Ep:124, loss:0.00000, loss_test:0.02784, lr:2.40e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.846, tt:4480.737\n",
      "Ep:125, loss:0.00000, loss_test:0.02792, lr:2.38e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.854, tt:4517.653\n",
      "Ep:126, loss:0.00000, loss_test:0.02800, lr:2.36e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.864, tt:4554.760\n",
      "Ep:127, loss:0.00000, loss_test:0.02803, lr:2.33e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.850, tt:4588.794\n",
      "Ep:128, loss:0.00000, loss_test:0.02808, lr:2.31e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.837, tt:4622.963\n",
      "Ep:129, loss:0.00000, loss_test:0.02813, lr:2.29e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.844, tt:4659.738\n",
      "Ep:130, loss:0.00000, loss_test:0.02822, lr:2.26e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.854, tt:4696.884\n",
      "Ep:131, loss:0.00000, loss_test:0.02827, lr:2.24e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.867, tt:4734.496\n",
      "Ep:132, loss:0.00000, loss_test:0.02832, lr:2.22e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.875, tt:4771.363\n",
      "Ep:133, loss:0.00000, loss_test:0.02836, lr:2.20e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.881, tt:4808.035\n",
      "Ep:134, loss:0.00000, loss_test:0.02839, lr:2.17e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.883, tt:4844.180\n",
      "Ep:135, loss:0.00000, loss_test:0.02846, lr:2.15e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.902, tt:4882.637\n",
      "Ep:136, loss:0.00000, loss_test:0.02851, lr:2.13e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.903, tt:4918.743\n",
      "Ep:137, loss:0.00000, loss_test:0.02856, lr:2.11e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.904, tt:4954.788\n",
      "Ep:138, loss:0.00000, loss_test:0.02861, lr:2.09e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.895, tt:4989.337\n",
      "Ep:139, loss:0.00000, loss_test:0.02866, lr:2.07e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.897, tt:5025.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.02869, lr:2.05e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.898, tt:5061.687\n",
      "Ep:141, loss:0.00000, loss_test:0.02873, lr:2.03e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.900, tt:5097.759\n",
      "Ep:142, loss:0.00000, loss_test:0.02878, lr:2.01e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.899, tt:5133.525\n",
      "Ep:143, loss:0.00000, loss_test:0.02881, lr:1.99e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.870, tt:5165.219\n",
      "Ep:144, loss:0.00000, loss_test:0.02884, lr:1.97e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.796, tt:5190.353\n",
      "Ep:145, loss:0.00000, loss_test:0.02891, lr:1.95e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.732, tt:5216.806\n",
      "Ep:146, loss:0.00000, loss_test:0.02892, lr:1.93e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.652, tt:5240.888\n",
      "Ep:147, loss:0.00000, loss_test:0.02893, lr:1.91e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.549, tt:5261.203\n",
      "Ep:148, loss:0.00000, loss_test:0.02897, lr:1.89e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.407, tt:5275.644\n",
      "Ep:149, loss:0.00000, loss_test:0.02901, lr:1.87e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.256, tt:5288.332\n",
      "Ep:150, loss:0.00000, loss_test:0.02907, lr:1.85e-02, fs:0.58730 (r=0.425,p=0.949),  time:35.107, tt:5301.090\n",
      "Ep:151, loss:0.00000, loss_test:0.02910, lr:1.83e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.950, tt:5312.326\n",
      "Ep:152, loss:0.00000, loss_test:0.02914, lr:1.81e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.794, tt:5323.418\n",
      "Ep:153, loss:0.00000, loss_test:0.02916, lr:1.80e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.640, tt:5334.534\n",
      "Ep:154, loss:0.00000, loss_test:0.02920, lr:1.78e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.488, tt:5345.586\n",
      "Ep:155, loss:0.00000, loss_test:0.02922, lr:1.76e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.338, tt:5356.668\n",
      "Ep:156, loss:0.00000, loss_test:0.02927, lr:1.74e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.191, tt:5367.911\n",
      "Ep:157, loss:0.00000, loss_test:0.02931, lr:1.73e-02, fs:0.58730 (r=0.425,p=0.949),  time:34.044, tt:5378.969\n",
      "Ep:158, loss:0.00000, loss_test:0.02934, lr:1.71e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.900, tt:5390.113\n",
      "Ep:159, loss:0.00000, loss_test:0.02939, lr:1.69e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.758, tt:5401.246\n",
      "Ep:160, loss:0.00000, loss_test:0.02940, lr:1.67e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.617, tt:5412.331\n",
      "Ep:161, loss:0.00000, loss_test:0.02944, lr:1.66e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.478, tt:5423.433\n",
      "Ep:162, loss:0.00000, loss_test:0.02946, lr:1.64e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.341, tt:5434.507\n",
      "Ep:163, loss:0.00000, loss_test:0.02949, lr:1.62e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.205, tt:5445.661\n",
      "Ep:164, loss:0.00000, loss_test:0.02952, lr:1.61e-02, fs:0.58730 (r=0.425,p=0.949),  time:33.071, tt:5456.753\n",
      "Ep:165, loss:0.00000, loss_test:0.02956, lr:1.59e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.939, tt:5467.908\n",
      "Ep:166, loss:0.00000, loss_test:0.02959, lr:1.58e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.809, tt:5479.086\n",
      "Ep:167, loss:0.00000, loss_test:0.02961, lr:1.56e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.679, tt:5490.110\n",
      "Ep:168, loss:0.00000, loss_test:0.02963, lr:1.54e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.551, tt:5501.129\n",
      "Ep:169, loss:0.00000, loss_test:0.02966, lr:1.53e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.425, tt:5512.196\n",
      "Ep:170, loss:0.00000, loss_test:0.02970, lr:1.51e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.306, tt:5524.406\n",
      "Ep:171, loss:0.00000, loss_test:0.02973, lr:1.50e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.183, tt:5535.480\n",
      "Ep:172, loss:0.00000, loss_test:0.02975, lr:1.48e-02, fs:0.58730 (r=0.425,p=0.949),  time:32.061, tt:5546.527\n",
      "Ep:173, loss:0.00000, loss_test:0.02976, lr:1.47e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.940, tt:5557.493\n",
      "Ep:174, loss:0.00000, loss_test:0.02979, lr:1.45e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.820, tt:5568.485\n",
      "Ep:175, loss:0.00000, loss_test:0.02981, lr:1.44e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.701, tt:5579.407\n",
      "Ep:176, loss:0.00000, loss_test:0.02986, lr:1.43e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.584, tt:5590.375\n",
      "Ep:177, loss:0.00000, loss_test:0.02987, lr:1.41e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.468, tt:5601.393\n",
      "Ep:178, loss:0.00000, loss_test:0.02987, lr:1.40e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.354, tt:5612.356\n",
      "Ep:179, loss:0.00000, loss_test:0.02989, lr:1.38e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.241, tt:5623.400\n",
      "Ep:180, loss:0.00000, loss_test:0.02993, lr:1.37e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.130, tt:5634.444\n",
      "Ep:181, loss:0.00000, loss_test:0.02996, lr:1.36e-02, fs:0.58730 (r=0.425,p=0.949),  time:31.019, tt:5645.507\n",
      "Ep:182, loss:0.00000, loss_test:0.02998, lr:1.34e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.910, tt:5656.611\n",
      "Ep:183, loss:0.00000, loss_test:0.03001, lr:1.33e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.802, tt:5667.591\n",
      "Ep:184, loss:0.00000, loss_test:0.03004, lr:1.32e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.695, tt:5678.563\n",
      "Ep:185, loss:0.00000, loss_test:0.03005, lr:1.30e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.590, tt:5689.786\n",
      "Ep:186, loss:0.00000, loss_test:0.03009, lr:1.29e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.486, tt:5700.864\n",
      "Ep:187, loss:0.00000, loss_test:0.03009, lr:1.28e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.382, tt:5711.887\n",
      "Ep:188, loss:0.00000, loss_test:0.03011, lr:1.26e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.279, tt:5722.811\n",
      "Ep:189, loss:0.00000, loss_test:0.03012, lr:1.25e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.178, tt:5733.798\n",
      "Ep:190, loss:0.00000, loss_test:0.03017, lr:1.24e-02, fs:0.58730 (r=0.425,p=0.949),  time:30.077, tt:5744.773\n",
      "Ep:191, loss:0.00000, loss_test:0.03019, lr:1.23e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.978, tt:5755.758\n",
      "Ep:192, loss:0.00000, loss_test:0.03021, lr:1.21e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.880, tt:5766.833\n",
      "Ep:193, loss:0.00000, loss_test:0.03023, lr:1.20e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.783, tt:5777.867\n",
      "Ep:194, loss:0.00000, loss_test:0.03026, lr:1.19e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.687, tt:5788.904\n",
      "Ep:195, loss:0.00000, loss_test:0.03027, lr:1.18e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.591, tt:5799.855\n",
      "Ep:196, loss:0.00000, loss_test:0.03027, lr:1.17e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.497, tt:5810.811\n",
      "Ep:197, loss:0.00000, loss_test:0.03030, lr:1.15e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.404, tt:5821.895\n",
      "Ep:198, loss:0.00000, loss_test:0.03032, lr:1.14e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.319, tt:5834.476\n",
      "Ep:199, loss:0.00000, loss_test:0.03035, lr:1.13e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.227, tt:5845.492\n",
      "Ep:200, loss:0.00000, loss_test:0.03036, lr:1.12e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.137, tt:5856.552\n",
      "Ep:201, loss:0.00000, loss_test:0.03038, lr:1.11e-02, fs:0.58730 (r=0.425,p=0.949),  time:29.048, tt:5867.611\n",
      "Ep:202, loss:0.00000, loss_test:0.03040, lr:1.10e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.959, tt:5878.627\n",
      "Ep:203, loss:0.00000, loss_test:0.03041, lr:1.09e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.870, tt:5889.580\n",
      "Ep:204, loss:0.00000, loss_test:0.03044, lr:1.08e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.784, tt:5900.627\n",
      "Ep:205, loss:0.00000, loss_test:0.03045, lr:1.07e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.697, tt:5911.575\n",
      "Ep:206, loss:0.00000, loss_test:0.03047, lr:1.05e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.611, tt:5922.519\n",
      "Ep:207, loss:0.00000, loss_test:0.03049, lr:1.04e-02, fs:0.58730 (r=0.425,p=0.949),  time:28.527, tt:5933.565\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14287, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.069, tt:11.069\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14122, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.063, tt:22.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00028, loss_test:0.13805, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:11.059, tt:33.177\n",
      "Ep:3, loss:0.00027, loss_test:0.13238, lr:1.00e-02, fs:0.66935 (r=0.954,p=0.516),  time:11.047, tt:44.187\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12428, lr:1.00e-02, fs:0.68161 (r=0.874,p=0.559),  time:11.056, tt:55.279\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12030, lr:1.00e-02, fs:0.64211 (r=0.701,p=0.592),  time:11.058, tt:66.347\n",
      "Ep:6, loss:0.00023, loss_test:0.11821, lr:1.00e-02, fs:0.62147 (r=0.632,p=0.611),  time:11.066, tt:77.462\n",
      "Ep:7, loss:0.00022, loss_test:0.11284, lr:1.00e-02, fs:0.68000 (r=0.782,p=0.602),  time:11.069, tt:88.553\n",
      "Ep:8, loss:0.00021, loss_test:0.11048, lr:1.00e-02, fs:0.67327 (r=0.782,p=0.591),  time:11.079, tt:99.711\n",
      "Ep:9, loss:0.00020, loss_test:0.10668, lr:1.00e-02, fs:0.68208 (r=0.678,p=0.686),  time:11.095, tt:110.955\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10322, lr:1.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:11.097, tt:122.072\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.10069, lr:1.00e-02, fs:0.74033 (r=0.770,p=0.713),  time:11.097, tt:133.168\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.09864, lr:1.00e-02, fs:0.71951 (r=0.678,p=0.766),  time:11.098, tt:144.279\n",
      "Ep:13, loss:0.00017, loss_test:0.09624, lr:1.00e-02, fs:0.72941 (r=0.713,p=0.747),  time:11.099, tt:155.393\n",
      "Ep:14, loss:0.00016, loss_test:0.09409, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:11.097, tt:166.450\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.09336, lr:1.00e-02, fs:0.72050 (r=0.667,p=0.784),  time:11.095, tt:177.525\n",
      "Ep:16, loss:0.00015, loss_test:0.09039, lr:1.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:11.098, tt:188.664\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.09081, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:11.102, tt:199.834\n",
      "Ep:18, loss:0.00013, loss_test:0.08975, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:11.103, tt:210.954\n",
      "Ep:19, loss:0.00012, loss_test:0.08883, lr:1.00e-02, fs:0.73939 (r=0.701,p=0.782),  time:11.106, tt:222.122\n",
      "Ep:20, loss:0.00012, loss_test:0.08984, lr:1.00e-02, fs:0.72956 (r=0.667,p=0.806),  time:11.112, tt:233.347\n",
      "Ep:21, loss:0.00011, loss_test:0.08892, lr:1.00e-02, fs:0.72500 (r=0.667,p=0.795),  time:11.108, tt:244.383\n",
      "Ep:22, loss:0.00011, loss_test:0.08927, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:11.107, tt:255.451\n",
      "Ep:23, loss:0.00010, loss_test:0.08726, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:11.106, tt:266.545\n",
      "Ep:24, loss:0.00009, loss_test:0.09052, lr:1.00e-02, fs:0.70345 (r=0.586,p=0.879),  time:11.105, tt:277.613\n",
      "Ep:25, loss:0.00009, loss_test:0.08628, lr:1.00e-02, fs:0.75168 (r=0.644,p=0.903),  time:11.100, tt:288.600\n",
      "Ep:26, loss:0.00008, loss_test:0.08581, lr:1.00e-02, fs:0.73684 (r=0.644,p=0.862),  time:11.100, tt:299.708\n",
      "Ep:27, loss:0.00007, loss_test:0.08583, lr:1.00e-02, fs:0.73103 (r=0.609,p=0.914),  time:11.101, tt:310.834\n",
      "Ep:28, loss:0.00007, loss_test:0.08331, lr:9.90e-03, fs:0.74830 (r=0.632,p=0.917),  time:11.100, tt:321.910\n",
      "Ep:29, loss:0.00006, loss_test:0.08625, lr:9.80e-03, fs:0.73103 (r=0.609,p=0.914),  time:11.103, tt:333.082\n",
      "Ep:30, loss:0.00006, loss_test:0.08186, lr:9.70e-03, fs:0.77027 (r=0.655,p=0.934),  time:11.102, tt:344.148\n",
      "Ep:31, loss:0.00005, loss_test:0.08653, lr:9.61e-03, fs:0.75177 (r=0.609,p=0.981),  time:11.102, tt:355.249\n",
      "Ep:32, loss:0.00005, loss_test:0.07728, lr:9.51e-03, fs:0.81046 (r=0.713,p=0.939),  time:11.121, tt:366.978\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00004, loss_test:0.09177, lr:9.51e-03, fs:0.76596 (r=0.621,p=1.000),  time:11.120, tt:378.097\n",
      "Ep:34, loss:0.00004, loss_test:0.07980, lr:9.51e-03, fs:0.77551 (r=0.655,p=0.950),  time:11.120, tt:389.215\n",
      "Ep:35, loss:0.00004, loss_test:0.08928, lr:9.51e-03, fs:0.74286 (r=0.598,p=0.981),  time:11.119, tt:400.270\n",
      "Ep:36, loss:0.00003, loss_test:0.08318, lr:9.51e-03, fs:0.76056 (r=0.621,p=0.982),  time:11.118, tt:411.367\n",
      "Ep:37, loss:0.00003, loss_test:0.08416, lr:9.51e-03, fs:0.76056 (r=0.621,p=0.982),  time:11.115, tt:422.360\n",
      "Ep:38, loss:0.00003, loss_test:0.08400, lr:9.51e-03, fs:0.75177 (r=0.609,p=0.981),  time:11.116, tt:433.541\n",
      "Ep:39, loss:0.00003, loss_test:0.08586, lr:9.51e-03, fs:0.72993 (r=0.575,p=1.000),  time:11.115, tt:444.612\n",
      "Ep:40, loss:0.00002, loss_test:0.08667, lr:9.51e-03, fs:0.71533 (r=0.563,p=0.980),  time:11.115, tt:455.710\n",
      "Ep:41, loss:0.00002, loss_test:0.08980, lr:9.51e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.117, tt:466.905\n",
      "Ep:42, loss:0.00002, loss_test:0.08907, lr:9.51e-03, fs:0.70073 (r=0.552,p=0.960),  time:11.117, tt:478.046\n",
      "Ep:43, loss:0.00002, loss_test:0.09053, lr:9.51e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.118, tt:489.211\n",
      "Ep:44, loss:0.00002, loss_test:0.08879, lr:9.41e-03, fs:0.70588 (r=0.552,p=0.980),  time:11.120, tt:500.378\n",
      "Ep:45, loss:0.00002, loss_test:0.09187, lr:9.32e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.118, tt:511.421\n",
      "Ep:46, loss:0.00002, loss_test:0.08991, lr:9.23e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:522.467\n",
      "Ep:47, loss:0.00001, loss_test:0.09737, lr:9.14e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.117, tt:533.592\n",
      "Ep:48, loss:0.00001, loss_test:0.09149, lr:9.04e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.117, tt:544.735\n",
      "Ep:49, loss:0.00001, loss_test:0.09215, lr:8.95e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.115, tt:555.768\n",
      "Ep:50, loss:0.00001, loss_test:0.09292, lr:8.86e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.115, tt:566.879\n",
      "Ep:51, loss:0.00001, loss_test:0.09237, lr:8.78e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:578.007\n",
      "Ep:52, loss:0.00001, loss_test:0.09495, lr:8.69e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:589.122\n",
      "Ep:53, loss:0.00001, loss_test:0.09599, lr:8.60e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:600.238\n",
      "Ep:54, loss:0.00001, loss_test:0.09326, lr:8.51e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:611.369\n",
      "Ep:55, loss:0.00001, loss_test:0.09479, lr:8.43e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:622.517\n",
      "Ep:56, loss:0.00001, loss_test:0.09504, lr:8.35e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.118, tt:633.744\n",
      "Ep:57, loss:0.00001, loss_test:0.09673, lr:8.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.118, tt:644.841\n",
      "Ep:58, loss:0.00001, loss_test:0.09511, lr:8.18e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.118, tt:655.959\n",
      "Ep:59, loss:0.00001, loss_test:0.09604, lr:8.10e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.117, tt:667.010\n",
      "Ep:60, loss:0.00001, loss_test:0.09659, lr:8.02e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.115, tt:678.028\n",
      "Ep:61, loss:0.00001, loss_test:0.09757, lr:7.94e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:689.206\n",
      "Ep:62, loss:0.00001, loss_test:0.10041, lr:7.86e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.117, tt:700.368\n",
      "Ep:63, loss:0.00001, loss_test:0.09872, lr:7.78e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.116, tt:711.414\n",
      "Ep:64, loss:0.00001, loss_test:0.10023, lr:7.70e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.115, tt:722.463\n",
      "Ep:65, loss:0.00001, loss_test:0.10486, lr:7.62e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.114, tt:733.497\n",
      "Ep:66, loss:0.00001, loss_test:0.10001, lr:7.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.113, tt:744.588\n",
      "Ep:67, loss:0.00001, loss_test:0.10102, lr:7.47e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.112, tt:755.629\n",
      "Ep:68, loss:0.00001, loss_test:0.10245, lr:7.40e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.113, tt:766.808\n",
      "Ep:69, loss:0.00001, loss_test:0.09967, lr:7.32e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.113, tt:777.940\n",
      "Ep:70, loss:0.00000, loss_test:0.10043, lr:7.25e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.114, tt:789.105\n",
      "Ep:71, loss:0.00000, loss_test:0.10189, lr:7.18e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.113, tt:800.127\n",
      "Ep:72, loss:0.00000, loss_test:0.10125, lr:7.11e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.112, tt:811.146\n",
      "Ep:73, loss:0.00000, loss_test:0.10077, lr:7.03e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:822.227\n",
      "Ep:74, loss:0.00000, loss_test:0.10317, lr:6.96e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:833.325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00000, loss_test:0.10100, lr:6.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.110, tt:844.375\n",
      "Ep:76, loss:0.00000, loss_test:0.10041, lr:6.83e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:855.533\n",
      "Ep:77, loss:0.00000, loss_test:0.10181, lr:6.76e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.110, tt:866.593\n",
      "Ep:78, loss:0.00000, loss_test:0.09991, lr:6.69e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.110, tt:877.693\n",
      "Ep:79, loss:0.00000, loss_test:0.10273, lr:6.62e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:888.896\n",
      "Ep:80, loss:0.00000, loss_test:0.10157, lr:6.56e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:899.963\n",
      "Ep:81, loss:0.00000, loss_test:0.10035, lr:6.49e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.110, tt:911.032\n",
      "Ep:82, loss:0.00000, loss_test:0.10274, lr:6.43e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.110, tt:922.119\n",
      "Ep:83, loss:0.00000, loss_test:0.10150, lr:6.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:933.316\n",
      "Ep:84, loss:0.00000, loss_test:0.10068, lr:6.30e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:944.431\n",
      "Ep:85, loss:0.00000, loss_test:0.10314, lr:6.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:955.567\n",
      "Ep:86, loss:0.00000, loss_test:0.10119, lr:6.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:966.657\n",
      "Ep:87, loss:0.00000, loss_test:0.10187, lr:6.11e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.111, tt:977.783\n",
      "Ep:88, loss:0.00000, loss_test:0.10225, lr:6.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.141, tt:991.521\n",
      "Ep:89, loss:0.00000, loss_test:0.10133, lr:5.99e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1002.598\n",
      "Ep:90, loss:0.00000, loss_test:0.10108, lr:5.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1013.766\n",
      "Ep:91, loss:0.00000, loss_test:0.10182, lr:5.87e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1024.885\n",
      "Ep:92, loss:0.00000, loss_test:0.10091, lr:5.81e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1036.017\n",
      "Ep:93, loss:0.00000, loss_test:0.10060, lr:5.75e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1047.184\n",
      "Ep:94, loss:0.00000, loss_test:0.10251, lr:5.70e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.140, tt:1058.307\n",
      "Ep:95, loss:0.00000, loss_test:0.10159, lr:5.64e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.139, tt:1069.352\n",
      "Ep:96, loss:0.00000, loss_test:0.10057, lr:5.58e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.139, tt:1080.517\n",
      "Ep:97, loss:0.00000, loss_test:0.10175, lr:5.53e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.139, tt:1091.636\n",
      "Ep:98, loss:0.00000, loss_test:0.10159, lr:5.47e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.138, tt:1102.705\n",
      "Ep:99, loss:0.00000, loss_test:0.10098, lr:5.42e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.138, tt:1113.778\n",
      "Ep:100, loss:0.00000, loss_test:0.10134, lr:5.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.137, tt:1124.881\n",
      "Ep:101, loss:0.00000, loss_test:0.10116, lr:5.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.137, tt:1135.949\n",
      "Ep:102, loss:0.00000, loss_test:0.10122, lr:5.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.136, tt:1147.023\n",
      "Ep:103, loss:0.00000, loss_test:0.10254, lr:5.20e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.135, tt:1158.060\n",
      "Ep:104, loss:0.00000, loss_test:0.10224, lr:5.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.135, tt:1169.212\n",
      "Ep:105, loss:0.00000, loss_test:0.10049, lr:5.10e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.135, tt:1180.284\n",
      "Ep:106, loss:0.00000, loss_test:0.10101, lr:5.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.134, tt:1191.345\n",
      "Ep:107, loss:0.00000, loss_test:0.10181, lr:5.00e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.133, tt:1202.406\n",
      "Ep:108, loss:0.00000, loss_test:0.10072, lr:4.95e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1213.438\n",
      "Ep:109, loss:0.00000, loss_test:0.10135, lr:4.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1224.495\n",
      "Ep:110, loss:0.00000, loss_test:0.10166, lr:4.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1235.645\n",
      "Ep:111, loss:0.00000, loss_test:0.10106, lr:4.80e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1246.829\n",
      "Ep:112, loss:0.00000, loss_test:0.10296, lr:4.75e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1257.919\n",
      "Ep:113, loss:0.00000, loss_test:0.10265, lr:4.71e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.132, tt:1268.992\n",
      "Ep:114, loss:0.00000, loss_test:0.10101, lr:4.66e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.131, tt:1280.042\n",
      "Ep:115, loss:0.00000, loss_test:0.10052, lr:4.61e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.130, tt:1291.076\n",
      "Ep:116, loss:0.00000, loss_test:0.10157, lr:4.57e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.130, tt:1302.192\n",
      "Ep:117, loss:0.00000, loss_test:0.10150, lr:4.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.130, tt:1313.314\n",
      "Ep:118, loss:0.00000, loss_test:0.10080, lr:4.48e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.134, tt:1325.002\n",
      "Ep:119, loss:0.00000, loss_test:0.10135, lr:4.43e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.141, tt:1336.931\n",
      "Ep:120, loss:0.00000, loss_test:0.10147, lr:4.39e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.149, tt:1349.062\n",
      "Ep:121, loss:0.00000, loss_test:0.10046, lr:4.34e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.152, tt:1360.554\n",
      "Ep:122, loss:0.00000, loss_test:0.10099, lr:4.30e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.162, tt:1372.866\n",
      "Ep:123, loss:0.00000, loss_test:0.10204, lr:4.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.181, tt:1386.431\n",
      "Ep:124, loss:0.00000, loss_test:0.10131, lr:4.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.202, tt:1400.207\n",
      "Ep:125, loss:0.00000, loss_test:0.10118, lr:4.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.219, tt:1413.537\n",
      "Ep:126, loss:0.00000, loss_test:0.10217, lr:4.13e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.243, tt:1427.907\n",
      "Ep:127, loss:0.00000, loss_test:0.10183, lr:4.09e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.284, tt:1444.386\n",
      "Ep:128, loss:0.00000, loss_test:0.10203, lr:4.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.375, tt:1467.357\n",
      "Ep:129, loss:0.00000, loss_test:0.10143, lr:4.01e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.519, tt:1497.494\n",
      "Ep:130, loss:0.00000, loss_test:0.10082, lr:3.97e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.734, tt:1537.109\n",
      "Ep:131, loss:0.00000, loss_test:0.10088, lr:3.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:11.957, tt:1578.371\n",
      "Ep:132, loss:0.00000, loss_test:0.10076, lr:3.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:12.189, tt:1621.103\n",
      "Ep:133, loss:0.00000, loss_test:0.10145, lr:3.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:12.407, tt:1662.583\n",
      "Ep:134, loss:0.00000, loss_test:0.10159, lr:3.81e-03, fs:0.71111 (r=0.552,p=1.000),  time:12.618, tt:1703.421\n",
      "Ep:135, loss:0.00000, loss_test:0.10169, lr:3.77e-03, fs:0.71111 (r=0.552,p=1.000),  time:12.827, tt:1744.507\n",
      "Ep:136, loss:0.00000, loss_test:0.10122, lr:3.73e-03, fs:0.71111 (r=0.552,p=1.000),  time:13.018, tt:1783.455\n",
      "Ep:137, loss:0.00000, loss_test:0.10143, lr:3.70e-03, fs:0.71111 (r=0.552,p=1.000),  time:13.246, tt:1827.898\n",
      "Ep:138, loss:0.00000, loss_test:0.10142, lr:3.66e-03, fs:0.71111 (r=0.552,p=1.000),  time:13.451, tt:1869.715\n",
      "Ep:139, loss:0.00000, loss_test:0.10099, lr:3.62e-03, fs:0.71111 (r=0.552,p=1.000),  time:13.646, tt:1910.437\n",
      "Ep:140, loss:0.00000, loss_test:0.10088, lr:3.59e-03, fs:0.71111 (r=0.552,p=1.000),  time:13.831, tt:1950.229\n",
      "Ep:141, loss:0.00000, loss_test:0.10092, lr:3.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.025, tt:1991.524\n",
      "Ep:142, loss:0.00000, loss_test:0.10063, lr:3.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.227, tt:2034.402\n",
      "Ep:143, loss:0.00000, loss_test:0.10130, lr:3.48e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.409, tt:2074.957\n",
      "Ep:144, loss:0.00000, loss_test:0.10108, lr:3.45e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.590, tt:2115.524\n",
      "Ep:145, loss:0.00000, loss_test:0.10102, lr:3.41e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.771, tt:2156.591\n",
      "Ep:146, loss:0.00000, loss_test:0.10101, lr:3.38e-03, fs:0.71111 (r=0.552,p=1.000),  time:14.959, tt:2199.035\n",
      "Ep:147, loss:0.00000, loss_test:0.10101, lr:3.34e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.144, tt:2241.279\n",
      "Ep:148, loss:0.00000, loss_test:0.10118, lr:3.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.311, tt:2281.270\n",
      "Ep:149, loss:0.00000, loss_test:0.10128, lr:3.28e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.500, tt:2324.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00000, loss_test:0.10094, lr:3.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.664, tt:2365.332\n",
      "Ep:151, loss:0.00000, loss_test:0.10157, lr:3.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.831, tt:2406.285\n",
      "Ep:152, loss:0.00000, loss_test:0.10183, lr:3.18e-03, fs:0.71111 (r=0.552,p=1.000),  time:15.993, tt:2446.864\n",
      "Ep:153, loss:0.00000, loss_test:0.10179, lr:3.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.156, tt:2487.997\n",
      "Ep:154, loss:0.00000, loss_test:0.10152, lr:3.12e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.325, tt:2530.451\n",
      "Ep:155, loss:0.00000, loss_test:0.10174, lr:3.09e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.485, tt:2571.712\n",
      "Ep:156, loss:0.00000, loss_test:0.10157, lr:3.05e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.645, tt:2613.247\n",
      "Ep:157, loss:0.00000, loss_test:0.10139, lr:3.02e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.812, tt:2656.362\n",
      "Ep:158, loss:0.00000, loss_test:0.10127, lr:2.99e-03, fs:0.71111 (r=0.552,p=1.000),  time:16.949, tt:2694.857\n",
      "Ep:159, loss:0.00000, loss_test:0.10157, lr:2.96e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.107, tt:2737.172\n",
      "Ep:160, loss:0.00000, loss_test:0.10161, lr:2.93e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.271, tt:2780.663\n",
      "Ep:161, loss:0.00000, loss_test:0.10176, lr:2.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.416, tt:2821.328\n",
      "Ep:162, loss:0.00000, loss_test:0.10163, lr:2.88e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.561, tt:2862.419\n",
      "Ep:163, loss:0.00000, loss_test:0.10208, lr:2.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.698, tt:2902.552\n",
      "Ep:164, loss:0.00000, loss_test:0.10203, lr:2.82e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.816, tt:2939.701\n",
      "Ep:165, loss:0.00000, loss_test:0.10185, lr:2.79e-03, fs:0.71111 (r=0.552,p=1.000),  time:17.965, tt:2982.156\n",
      "Ep:166, loss:0.00000, loss_test:0.10144, lr:2.76e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.098, tt:3022.368\n",
      "Ep:167, loss:0.00000, loss_test:0.10161, lr:2.73e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.221, tt:3061.108\n",
      "Ep:168, loss:0.00000, loss_test:0.10216, lr:2.71e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.343, tt:3100.008\n",
      "Ep:169, loss:0.00000, loss_test:0.10245, lr:2.68e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.460, tt:3138.125\n",
      "Ep:170, loss:0.00000, loss_test:0.10197, lr:2.65e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.590, tt:3178.844\n",
      "Ep:171, loss:0.00000, loss_test:0.10204, lr:2.63e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.716, tt:3219.068\n",
      "Ep:172, loss:0.00000, loss_test:0.10218, lr:2.60e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.847, tt:3260.544\n",
      "Ep:173, loss:0.00000, loss_test:0.10220, lr:2.57e-03, fs:0.71111 (r=0.552,p=1.000),  time:18.984, tt:3303.234\n",
      "Ep:174, loss:0.00000, loss_test:0.10187, lr:2.55e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.115, tt:3345.130\n",
      "Ep:175, loss:0.00000, loss_test:0.10220, lr:2.52e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.251, tt:3388.146\n",
      "Ep:176, loss:0.00000, loss_test:0.10254, lr:2.50e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.374, tt:3429.241\n",
      "Ep:177, loss:0.00000, loss_test:0.10226, lr:2.47e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.504, tt:3471.637\n",
      "Ep:178, loss:0.00000, loss_test:0.10243, lr:2.45e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.645, tt:3516.435\n",
      "Ep:179, loss:0.00000, loss_test:0.10238, lr:2.42e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.778, tt:3560.075\n",
      "Ep:180, loss:0.00000, loss_test:0.10236, lr:2.40e-03, fs:0.71111 (r=0.552,p=1.000),  time:19.899, tt:3601.647\n",
      "Ep:181, loss:0.00000, loss_test:0.10256, lr:2.38e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.021, tt:3643.806\n",
      "Ep:182, loss:0.00000, loss_test:0.10243, lr:2.35e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.138, tt:3685.247\n",
      "Ep:183, loss:0.00000, loss_test:0.10249, lr:2.33e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.245, tt:3725.058\n",
      "Ep:184, loss:0.00000, loss_test:0.10200, lr:2.31e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.356, tt:3765.840\n",
      "Ep:185, loss:0.00000, loss_test:0.10184, lr:2.28e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.467, tt:3806.855\n",
      "Ep:186, loss:0.00000, loss_test:0.10225, lr:2.26e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.578, tt:3848.160\n",
      "Ep:187, loss:0.00000, loss_test:0.10255, lr:2.24e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.695, tt:3890.628\n",
      "Ep:188, loss:0.00000, loss_test:0.10236, lr:2.21e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.806, tt:3932.366\n",
      "Ep:189, loss:0.00000, loss_test:0.10249, lr:2.19e-03, fs:0.71111 (r=0.552,p=1.000),  time:20.909, tt:3972.782\n",
      "Ep:190, loss:0.00000, loss_test:0.10252, lr:2.17e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.017, tt:4014.288\n",
      "Ep:191, loss:0.00000, loss_test:0.10246, lr:2.15e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.125, tt:4055.913\n",
      "Ep:192, loss:0.00000, loss_test:0.10249, lr:2.13e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.240, tt:4099.267\n",
      "Ep:193, loss:0.00000, loss_test:0.10236, lr:2.11e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.348, tt:4141.554\n",
      "Ep:194, loss:0.00000, loss_test:0.10217, lr:2.08e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.499, tt:4192.321\n",
      "Ep:195, loss:0.00000, loss_test:0.10212, lr:2.06e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.609, tt:4235.419\n",
      "Ep:196, loss:0.00000, loss_test:0.10219, lr:2.04e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.713, tt:4277.493\n",
      "Ep:197, loss:0.00000, loss_test:0.10227, lr:2.02e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.806, tt:4317.533\n",
      "Ep:198, loss:0.00000, loss_test:0.10281, lr:2.00e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.902, tt:4358.443\n",
      "Ep:199, loss:0.00000, loss_test:0.10267, lr:1.98e-03, fs:0.71111 (r=0.552,p=1.000),  time:21.999, tt:4399.818\n",
      "Ep:200, loss:0.00000, loss_test:0.10211, lr:1.96e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.100, tt:4442.093\n",
      "Ep:201, loss:0.00000, loss_test:0.10226, lr:1.94e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.187, tt:4481.864\n",
      "Ep:202, loss:0.00000, loss_test:0.10266, lr:1.92e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.288, tt:4524.534\n",
      "Ep:203, loss:0.00000, loss_test:0.10267, lr:1.90e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.380, tt:4565.596\n",
      "Ep:204, loss:0.00000, loss_test:0.10261, lr:1.89e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.475, tt:4607.464\n",
      "Ep:205, loss:0.00000, loss_test:0.10275, lr:1.87e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.569, tt:4649.216\n",
      "Ep:206, loss:0.00000, loss_test:0.10257, lr:1.85e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.670, tt:4692.620\n",
      "Ep:207, loss:0.00000, loss_test:0.10235, lr:1.83e-03, fs:0.71111 (r=0.552,p=1.000),  time:22.765, tt:4735.106\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.01977, lr:6.00e-02, fs:0.64115 (r=0.770,p=0.549),  time:37.772, tt:37.772\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02068, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:39.381, tt:78.762\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02113, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.173, tt:117.519\n",
      "Ep:3, loss:0.00004, loss_test:0.01981, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:39.279, tt:157.117\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01832, lr:6.00e-02, fs:0.69748 (r=0.954,p=0.550),  time:39.309, tt:196.546\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01794, lr:6.00e-02, fs:0.70755 (r=0.862,p=0.600),  time:39.560, tt:237.361\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01810, lr:6.00e-02, fs:0.69430 (r=0.770,p=0.632),  time:39.319, tt:275.236\n",
      "Ep:7, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:39.298, tt:314.387\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00003, loss_test:0.01627, lr:6.00e-02, fs:0.75472 (r=0.920,p=0.640),  time:39.326, tt:353.931\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.75556 (r=0.977,p=0.616),  time:39.605, tt:396.048\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01555, lr:6.00e-02, fs:0.76233 (r=0.977,p=0.625),  time:39.783, tt:437.610\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.77725 (r=0.943,p=0.661),  time:39.917, tt:479.010\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.76142 (r=0.862,p=0.682),  time:40.027, tt:520.346\n",
      "Ep:13, loss:0.00003, loss_test:0.01504, lr:6.00e-02, fs:0.78307 (r=0.851,p=0.725),  time:40.110, tt:561.537\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01483, lr:6.00e-02, fs:0.77083 (r=0.851,p=0.705),  time:40.060, tt:600.897\n",
      "Ep:15, loss:0.00003, loss_test:0.01455, lr:6.00e-02, fs:0.77949 (r=0.874,p=0.704),  time:40.001, tt:640.015\n",
      "Ep:16, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.77157 (r=0.874,p=0.691),  time:40.047, tt:680.794\n",
      "Ep:17, loss:0.00002, loss_test:0.01423, lr:6.00e-02, fs:0.76923 (r=0.862,p=0.694),  time:40.101, tt:721.812\n",
      "Ep:18, loss:0.00002, loss_test:0.01425, lr:6.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:40.191, tt:763.635\n",
      "Ep:19, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.78919 (r=0.839,p=0.745),  time:40.185, tt:803.703\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:40.254, tt:845.335\n",
      "Ep:21, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:40.283, tt:886.231\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:40.307, tt:927.062\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.79310 (r=0.793,p=0.793),  time:40.259, tt:966.212\n",
      "Ep:24, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:40.273, tt:1006.816\n",
      "Ep:25, loss:0.00002, loss_test:0.01432, lr:6.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:40.306, tt:1047.958\n",
      "Ep:26, loss:0.00002, loss_test:0.01428, lr:6.00e-02, fs:0.78824 (r=0.770,p=0.807),  time:40.209, tt:1085.631\n",
      "Ep:27, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:40.175, tt:1124.889\n",
      "Ep:28, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.79042 (r=0.759,p=0.825),  time:40.075, tt:1162.164\n",
      "Ep:29, loss:0.00002, loss_test:0.01441, lr:6.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:40.074, tt:1202.215\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.01451, lr:6.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:40.014, tt:1240.438\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00001, loss_test:0.01462, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:39.997, tt:1279.916\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00001, loss_test:0.01471, lr:6.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:39.916, tt:1317.217\n",
      "Ep:33, loss:0.00001, loss_test:0.01481, lr:6.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:39.936, tt:1357.829\n",
      "Ep:34, loss:0.00001, loss_test:0.01492, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:39.914, tt:1396.977\n",
      "Ep:35, loss:0.00001, loss_test:0.01506, lr:6.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:39.853, tt:1434.705\n",
      "Ep:36, loss:0.00001, loss_test:0.01509, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:39.870, tt:1475.207\n",
      "Ep:37, loss:0.00001, loss_test:0.01531, lr:6.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:39.794, tt:1512.159\n",
      "Ep:38, loss:0.00001, loss_test:0.01555, lr:6.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:39.772, tt:1551.094\n",
      "Ep:39, loss:0.00001, loss_test:0.01570, lr:6.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:39.769, tt:1590.761\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01587, lr:6.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:39.714, tt:1628.280\n",
      "Ep:41, loss:0.00001, loss_test:0.01600, lr:6.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:39.661, tt:1665.761\n",
      "Ep:42, loss:0.00001, loss_test:0.01633, lr:6.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:39.648, tt:1704.867\n",
      "Ep:43, loss:0.00001, loss_test:0.01652, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.648, tt:1744.526\n",
      "Ep:44, loss:0.00001, loss_test:0.01660, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.611, tt:1782.485\n",
      "Ep:45, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.627, tt:1822.855\n",
      "Ep:46, loss:0.00001, loss_test:0.01696, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.603, tt:1861.335\n",
      "Ep:47, loss:0.00001, loss_test:0.01719, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.694, tt:1905.294\n",
      "Ep:48, loss:0.00001, loss_test:0.01733, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.689, tt:1944.768\n",
      "Ep:49, loss:0.00001, loss_test:0.01761, lr:6.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:39.673, tt:1983.639\n",
      "Ep:50, loss:0.00001, loss_test:0.01793, lr:6.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:39.653, tt:2022.299\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:39.648, tt:2061.717\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01834, lr:6.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:39.652, tt:2101.555\n",
      "Ep:53, loss:0.00001, loss_test:0.01847, lr:6.00e-02, fs:0.81529 (r=0.736,p=0.914),  time:39.609, tt:2138.868\n",
      "Ep:54, loss:0.00001, loss_test:0.01867, lr:6.00e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.624, tt:2179.324\n",
      "Ep:55, loss:0.00001, loss_test:0.01896, lr:6.00e-02, fs:0.77852 (r=0.667,p=0.935),  time:39.613, tt:2218.351\n",
      "Ep:56, loss:0.00001, loss_test:0.01912, lr:6.00e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.633, tt:2259.091\n",
      "Ep:57, loss:0.00001, loss_test:0.01938, lr:6.00e-02, fs:0.76510 (r=0.655,p=0.919),  time:39.617, tt:2297.786\n",
      "Ep:58, loss:0.00001, loss_test:0.01958, lr:6.00e-02, fs:0.76190 (r=0.644,p=0.933),  time:39.645, tt:2339.029\n",
      "Ep:59, loss:0.00001, loss_test:0.01973, lr:6.00e-02, fs:0.76712 (r=0.644,p=0.949),  time:39.682, tt:2380.904\n",
      "Ep:60, loss:0.00001, loss_test:0.01988, lr:6.00e-02, fs:0.76712 (r=0.644,p=0.949),  time:39.686, tt:2420.843\n",
      "Ep:61, loss:0.00000, loss_test:0.02011, lr:6.00e-02, fs:0.76712 (r=0.644,p=0.949),  time:39.726, tt:2462.983\n",
      "Ep:62, loss:0.00000, loss_test:0.02032, lr:6.00e-02, fs:0.76712 (r=0.644,p=0.949),  time:39.748, tt:2504.135\n",
      "Ep:63, loss:0.00000, loss_test:0.02056, lr:5.94e-02, fs:0.77241 (r=0.644,p=0.966),  time:39.788, tt:2546.404\n",
      "Ep:64, loss:0.00000, loss_test:0.02065, lr:5.88e-02, fs:0.77241 (r=0.644,p=0.966),  time:39.885, tt:2592.532\n",
      "Ep:65, loss:0.00000, loss_test:0.02078, lr:5.82e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.921, tt:2634.810\n",
      "Ep:66, loss:0.00000, loss_test:0.02091, lr:5.76e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.965, tt:2677.627\n",
      "Ep:67, loss:0.00000, loss_test:0.02116, lr:5.71e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.012, tt:2720.806\n",
      "Ep:68, loss:0.00000, loss_test:0.02140, lr:5.65e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.059, tt:2764.098\n",
      "Ep:69, loss:0.00000, loss_test:0.02144, lr:5.59e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.122, tt:2808.524\n",
      "Ep:70, loss:0.00000, loss_test:0.02162, lr:5.54e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.153, tt:2850.834\n",
      "Ep:71, loss:0.00000, loss_test:0.02178, lr:5.48e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.182, tt:2893.080\n",
      "Ep:72, loss:0.00000, loss_test:0.02187, lr:5.43e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.192, tt:2934.027\n",
      "Ep:73, loss:0.00000, loss_test:0.02202, lr:5.37e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.186, tt:2973.738\n",
      "Ep:74, loss:0.00000, loss_test:0.02206, lr:5.32e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.197, tt:3014.806\n",
      "Ep:75, loss:0.00000, loss_test:0.02234, lr:5.27e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.218, tt:3056.600\n",
      "Ep:76, loss:0.00000, loss_test:0.02239, lr:5.21e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.219, tt:3096.863\n",
      "Ep:77, loss:0.00000, loss_test:0.02254, lr:5.16e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.236, tt:3138.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00000, loss_test:0.02264, lr:5.11e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.234, tt:3178.453\n",
      "Ep:79, loss:0.00000, loss_test:0.02271, lr:5.06e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.263, tt:3221.001\n",
      "Ep:80, loss:0.00000, loss_test:0.02289, lr:5.01e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.259, tt:3260.940\n",
      "Ep:81, loss:0.00000, loss_test:0.02303, lr:4.96e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.256, tt:3301.022\n",
      "Ep:82, loss:0.00000, loss_test:0.02316, lr:4.91e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.268, tt:3342.219\n",
      "Ep:83, loss:0.00000, loss_test:0.02321, lr:4.86e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.253, tt:3381.274\n",
      "Ep:84, loss:0.00000, loss_test:0.02340, lr:4.81e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.249, tt:3421.140\n",
      "Ep:85, loss:0.00000, loss_test:0.02349, lr:4.76e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.252, tt:3461.644\n",
      "Ep:86, loss:0.00000, loss_test:0.02358, lr:4.71e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.284, tt:3504.744\n",
      "Ep:87, loss:0.00000, loss_test:0.02370, lr:4.67e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.286, tt:3545.194\n",
      "Ep:88, loss:0.00000, loss_test:0.02374, lr:4.62e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.277, tt:3584.629\n",
      "Ep:89, loss:0.00000, loss_test:0.02397, lr:4.57e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.282, tt:3625.344\n",
      "Ep:90, loss:0.00000, loss_test:0.02395, lr:4.53e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.306, tt:3667.891\n",
      "Ep:91, loss:0.00000, loss_test:0.02405, lr:4.48e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.317, tt:3709.152\n",
      "Ep:92, loss:0.00000, loss_test:0.02420, lr:4.44e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.313, tt:3749.143\n",
      "Ep:93, loss:0.00000, loss_test:0.02419, lr:4.39e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.320, tt:3790.102\n",
      "Ep:94, loss:0.00000, loss_test:0.02432, lr:4.35e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.331, tt:3831.449\n",
      "Ep:95, loss:0.00000, loss_test:0.02443, lr:4.31e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.352, tt:3873.818\n",
      "Ep:96, loss:0.00000, loss_test:0.02443, lr:4.26e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.330, tt:3912.005\n",
      "Ep:97, loss:0.00000, loss_test:0.02450, lr:4.22e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.333, tt:3952.609\n",
      "Ep:98, loss:0.00000, loss_test:0.02468, lr:4.18e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.323, tt:3991.936\n",
      "Ep:99, loss:0.00000, loss_test:0.02471, lr:4.14e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.315, tt:4031.506\n",
      "Ep:100, loss:0.00000, loss_test:0.02485, lr:4.10e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.347, tt:4075.009\n",
      "Ep:101, loss:0.00000, loss_test:0.02495, lr:4.05e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.360, tt:4116.716\n",
      "Ep:102, loss:0.00000, loss_test:0.02502, lr:4.01e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.355, tt:4156.612\n",
      "Ep:103, loss:0.00000, loss_test:0.02506, lr:3.97e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.365, tt:4197.995\n",
      "Ep:104, loss:0.00000, loss_test:0.02518, lr:3.93e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.360, tt:4237.763\n",
      "Ep:105, loss:0.00000, loss_test:0.02522, lr:3.89e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.353, tt:4277.411\n",
      "Ep:106, loss:0.00000, loss_test:0.02524, lr:3.86e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.340, tt:4316.378\n",
      "Ep:107, loss:0.00000, loss_test:0.02535, lr:3.82e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.327, tt:4355.357\n",
      "Ep:108, loss:0.00000, loss_test:0.02541, lr:3.78e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.320, tt:4394.892\n",
      "Ep:109, loss:0.00000, loss_test:0.02541, lr:3.74e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.303, tt:4433.346\n",
      "Ep:110, loss:0.00000, loss_test:0.02554, lr:3.70e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.338, tt:4477.490\n",
      "Ep:111, loss:0.00000, loss_test:0.02561, lr:3.67e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.344, tt:4518.544\n",
      "Ep:112, loss:0.00000, loss_test:0.02560, lr:3.63e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.332, tt:4557.492\n",
      "Ep:113, loss:0.00000, loss_test:0.02572, lr:3.59e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.311, tt:4595.428\n",
      "Ep:114, loss:0.00000, loss_test:0.02581, lr:3.56e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.297, tt:4634.103\n",
      "Ep:115, loss:0.00000, loss_test:0.02581, lr:3.52e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.277, tt:4672.125\n",
      "Ep:116, loss:0.00000, loss_test:0.02587, lr:3.49e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.278, tt:4712.501\n",
      "Ep:117, loss:0.00000, loss_test:0.02593, lr:3.45e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.234, tt:4747.637\n",
      "Ep:118, loss:0.00000, loss_test:0.02598, lr:3.42e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.209, tt:4784.919\n",
      "Ep:119, loss:0.00000, loss_test:0.02605, lr:3.38e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.170, tt:4820.441\n",
      "Ep:120, loss:0.00000, loss_test:0.02611, lr:3.35e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.163, tt:4859.736\n",
      "Ep:121, loss:0.00000, loss_test:0.02612, lr:3.32e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.142, tt:4897.298\n",
      "Ep:122, loss:0.00000, loss_test:0.02615, lr:3.28e-02, fs:0.76389 (r=0.632,p=0.965),  time:40.117, tt:4934.441\n",
      "Ep:123, loss:0.00000, loss_test:0.02627, lr:3.25e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.040, tt:4964.940\n",
      "Ep:124, loss:0.00000, loss_test:0.02629, lr:3.22e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.983, tt:4997.864\n",
      "Ep:125, loss:0.00000, loss_test:0.02633, lr:3.19e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.925, tt:5030.503\n",
      "Ep:126, loss:0.00000, loss_test:0.02641, lr:3.15e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.898, tt:5067.086\n",
      "Ep:127, loss:0.00000, loss_test:0.02648, lr:3.12e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.927, tt:5110.664\n",
      "Ep:128, loss:0.00000, loss_test:0.02649, lr:3.09e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.955, tt:5154.200\n",
      "Ep:129, loss:0.00000, loss_test:0.02655, lr:3.06e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.967, tt:5195.742\n",
      "Ep:130, loss:0.00000, loss_test:0.02658, lr:3.03e-02, fs:0.76923 (r=0.632,p=0.982),  time:39.998, tt:5239.740\n",
      "Ep:131, loss:0.00000, loss_test:0.02658, lr:3.00e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.006, tt:5280.735\n",
      "Ep:132, loss:0.00000, loss_test:0.02664, lr:2.97e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.011, tt:5321.474\n",
      "Ep:133, loss:0.00000, loss_test:0.02671, lr:2.94e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.039, tt:5365.260\n",
      "Ep:134, loss:0.00000, loss_test:0.02672, lr:2.91e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.082, tt:5411.096\n",
      "Ep:135, loss:0.00000, loss_test:0.02678, lr:2.88e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.089, tt:5452.063\n",
      "Ep:136, loss:0.00000, loss_test:0.02680, lr:2.85e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.085, tt:5491.706\n",
      "Ep:137, loss:0.00000, loss_test:0.02690, lr:2.82e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.106, tt:5534.692\n",
      "Ep:138, loss:0.00000, loss_test:0.02691, lr:2.80e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.112, tt:5575.500\n",
      "Ep:139, loss:0.00000, loss_test:0.02696, lr:2.77e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.115, tt:5616.096\n",
      "Ep:140, loss:0.00000, loss_test:0.02698, lr:2.74e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.138, tt:5659.482\n",
      "Ep:141, loss:0.00000, loss_test:0.02701, lr:2.71e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.153, tt:5701.666\n",
      "Ep:142, loss:0.00000, loss_test:0.02704, lr:2.69e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.155, tt:5742.117\n",
      "Ep:143, loss:0.00000, loss_test:0.02708, lr:2.66e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.177, tt:5785.520\n",
      "Ep:144, loss:0.00000, loss_test:0.02712, lr:2.63e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.184, tt:5826.610\n",
      "Ep:145, loss:0.00000, loss_test:0.02711, lr:2.61e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.183, tt:5866.688\n",
      "Ep:146, loss:0.00000, loss_test:0.02719, lr:2.58e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.178, tt:5906.103\n",
      "Ep:147, loss:0.00000, loss_test:0.02720, lr:2.55e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.201, tt:5949.817\n",
      "Ep:148, loss:0.00000, loss_test:0.02724, lr:2.53e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.217, tt:5992.388\n",
      "Ep:149, loss:0.00000, loss_test:0.02730, lr:2.50e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.225, tt:6033.714\n",
      "Ep:150, loss:0.00000, loss_test:0.02730, lr:2.48e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.238, tt:6075.894\n",
      "Ep:151, loss:0.00000, loss_test:0.02730, lr:2.45e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.248, tt:6117.764\n",
      "Ep:152, loss:0.00000, loss_test:0.02736, lr:2.43e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.265, tt:6160.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:153, loss:0.00000, loss_test:0.02737, lr:2.40e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.279, tt:6203.025\n",
      "Ep:154, loss:0.00000, loss_test:0.02739, lr:2.38e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.283, tt:6243.865\n",
      "Ep:155, loss:0.00000, loss_test:0.02746, lr:2.36e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.300, tt:6286.852\n",
      "Ep:156, loss:0.00000, loss_test:0.02746, lr:2.33e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.307, tt:6328.219\n",
      "Ep:157, loss:0.00000, loss_test:0.02746, lr:2.31e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.314, tt:6369.609\n",
      "Ep:158, loss:0.00000, loss_test:0.02751, lr:2.29e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.317, tt:6410.440\n",
      "Ep:159, loss:0.00000, loss_test:0.02755, lr:2.26e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.342, tt:6454.798\n",
      "Ep:160, loss:0.00000, loss_test:0.02756, lr:2.24e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.344, tt:6495.384\n",
      "Ep:161, loss:0.00000, loss_test:0.02757, lr:2.22e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.351, tt:6536.923\n",
      "Ep:162, loss:0.00000, loss_test:0.02761, lr:2.20e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.356, tt:6577.953\n",
      "Ep:163, loss:0.00000, loss_test:0.02765, lr:2.17e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.366, tt:6620.028\n",
      "Ep:164, loss:0.00000, loss_test:0.02765, lr:2.15e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.371, tt:6661.272\n",
      "Ep:165, loss:0.00000, loss_test:0.02766, lr:2.13e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.377, tt:6702.499\n",
      "Ep:166, loss:0.00000, loss_test:0.02772, lr:2.11e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.371, tt:6741.999\n",
      "Ep:167, loss:0.00000, loss_test:0.02774, lr:2.09e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.371, tt:6782.255\n",
      "Ep:168, loss:0.00000, loss_test:0.02775, lr:2.07e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.378, tt:6823.805\n",
      "Ep:169, loss:0.00000, loss_test:0.02780, lr:2.05e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.382, tt:6865.023\n",
      "Ep:170, loss:0.00000, loss_test:0.02781, lr:2.03e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.386, tt:6905.977\n",
      "Ep:171, loss:0.00000, loss_test:0.02780, lr:2.01e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.400, tt:6948.748\n",
      "Ep:172, loss:0.00000, loss_test:0.02784, lr:1.99e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.407, tt:6990.335\n",
      "Ep:173, loss:0.00000, loss_test:0.02786, lr:1.97e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.416, tt:7032.429\n",
      "Ep:174, loss:0.00000, loss_test:0.02788, lr:1.95e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.430, tt:7075.332\n",
      "Ep:175, loss:0.00000, loss_test:0.02790, lr:1.93e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.450, tt:7119.221\n",
      "Ep:176, loss:0.00000, loss_test:0.02791, lr:1.91e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.456, tt:7160.672\n",
      "Ep:177, loss:0.00000, loss_test:0.02794, lr:1.89e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.454, tt:7200.778\n",
      "Ep:178, loss:0.00000, loss_test:0.02793, lr:1.87e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.450, tt:7240.636\n",
      "Ep:179, loss:0.00000, loss_test:0.02797, lr:1.85e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.455, tt:7281.927\n",
      "Ep:180, loss:0.00000, loss_test:0.02798, lr:1.83e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.487, tt:7328.109\n",
      "Ep:181, loss:0.00000, loss_test:0.02801, lr:1.81e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.475, tt:7366.479\n",
      "Ep:182, loss:0.00000, loss_test:0.02803, lr:1.80e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.465, tt:7405.159\n",
      "Ep:183, loss:0.00000, loss_test:0.02803, lr:1.78e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.464, tt:7445.322\n",
      "Ep:184, loss:0.00000, loss_test:0.02805, lr:1.76e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.467, tt:7486.350\n",
      "Ep:185, loss:0.00000, loss_test:0.02805, lr:1.74e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.467, tt:7526.940\n",
      "Ep:186, loss:0.00000, loss_test:0.02807, lr:1.73e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.475, tt:7568.770\n",
      "Ep:187, loss:0.00000, loss_test:0.02809, lr:1.71e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.480, tt:7610.184\n",
      "Ep:188, loss:0.00000, loss_test:0.02810, lr:1.69e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.487, tt:7652.079\n",
      "Ep:189, loss:0.00000, loss_test:0.02814, lr:1.67e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.479, tt:7690.966\n",
      "Ep:190, loss:0.00000, loss_test:0.02815, lr:1.66e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.472, tt:7730.185\n",
      "Ep:191, loss:0.00000, loss_test:0.02817, lr:1.64e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.466, tt:7769.555\n",
      "Ep:192, loss:0.00000, loss_test:0.02817, lr:1.62e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.464, tt:7809.522\n",
      "Ep:193, loss:0.00000, loss_test:0.02817, lr:1.61e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.461, tt:7849.514\n",
      "Ep:194, loss:0.00000, loss_test:0.02820, lr:1.59e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.458, tt:7889.334\n",
      "Ep:195, loss:0.00000, loss_test:0.02821, lr:1.58e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.457, tt:7929.629\n",
      "Ep:196, loss:0.00000, loss_test:0.02822, lr:1.56e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.460, tt:7970.581\n",
      "Ep:197, loss:0.00000, loss_test:0.02824, lr:1.54e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.473, tt:8013.680\n",
      "Ep:198, loss:0.00000, loss_test:0.02823, lr:1.53e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.475, tt:8054.619\n",
      "Ep:199, loss:0.00000, loss_test:0.02823, lr:1.51e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.479, tt:8095.766\n",
      "Ep:200, loss:0.00000, loss_test:0.02826, lr:1.50e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.482, tt:8136.873\n",
      "Ep:201, loss:0.00000, loss_test:0.02827, lr:1.48e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.481, tt:8177.240\n",
      "Ep:202, loss:0.00000, loss_test:0.02829, lr:1.47e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.484, tt:8218.207\n",
      "Ep:203, loss:0.00000, loss_test:0.02831, lr:1.45e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.490, tt:8259.909\n",
      "Ep:204, loss:0.00000, loss_test:0.02833, lr:1.44e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.488, tt:8300.005\n",
      "Ep:205, loss:0.00000, loss_test:0.02832, lr:1.43e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.498, tt:8342.513\n",
      "Ep:206, loss:0.00000, loss_test:0.02835, lr:1.41e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.497, tt:8382.920\n",
      "Ep:207, loss:0.00000, loss_test:0.02835, lr:1.40e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.491, tt:8422.043\n",
      "Ep:208, loss:0.00000, loss_test:0.02836, lr:1.38e-02, fs:0.76923 (r=0.632,p=0.982),  time:40.499, tt:8464.199\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13647, lr:1.00e-02, fs:0.66929 (r=0.977,p=0.509),  time:40.617, tt:40.617\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13201, lr:1.00e-02, fs:0.66129 (r=0.943,p=0.509),  time:40.941, tt:81.882\n",
      "Ep:2, loss:0.00027, loss_test:0.12528, lr:1.00e-02, fs:0.67511 (r=0.920,p=0.533),  time:41.389, tt:124.168\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11781, lr:1.00e-02, fs:0.68807 (r=0.862,p=0.573),  time:40.452, tt:161.807\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11401, lr:1.00e-02, fs:0.68293 (r=0.805,p=0.593),  time:40.765, tt:203.826\n",
      "Ep:5, loss:0.00023, loss_test:0.11173, lr:1.00e-02, fs:0.70051 (r=0.793,p=0.627),  time:40.919, tt:245.514\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10938, lr:1.00e-02, fs:0.70874 (r=0.839,p=0.613),  time:41.087, tt:287.612\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10753, lr:1.00e-02, fs:0.71429 (r=0.862,p=0.610),  time:41.209, tt:329.673\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10450, lr:1.00e-02, fs:0.73367 (r=0.839,p=0.652),  time:41.234, tt:371.110\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10162, lr:1.00e-02, fs:0.72917 (r=0.805,p=0.667),  time:41.408, tt:414.081\n",
      "Ep:10, loss:0.00020, loss_test:0.09906, lr:1.00e-02, fs:0.72043 (r=0.770,p=0.677),  time:41.455, tt:456.005\n",
      "Ep:11, loss:0.00019, loss_test:0.09650, lr:1.00e-02, fs:0.74468 (r=0.805,p=0.693),  time:41.678, tt:500.132\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00018, loss_test:0.09369, lr:1.00e-02, fs:0.76190 (r=0.828,p=0.706),  time:41.639, tt:541.310\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09216, lr:1.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:41.575, tt:582.047\n",
      "Ep:14, loss:0.00017, loss_test:0.09026, lr:1.00e-02, fs:0.76503 (r=0.805,p=0.729),  time:41.694, tt:625.412\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08843, lr:1.00e-02, fs:0.78022 (r=0.816,p=0.747),  time:41.663, tt:666.600\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08682, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:41.754, tt:709.816\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.08579, lr:1.00e-02, fs:0.79121 (r=0.828,p=0.758),  time:41.804, tt:752.467\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08567, lr:1.00e-02, fs:0.78889 (r=0.816,p=0.763),  time:41.860, tt:795.331\n",
      "Ep:19, loss:0.00013, loss_test:0.08517, lr:1.00e-02, fs:0.78652 (r=0.805,p=0.769),  time:41.911, tt:838.226\n",
      "Ep:20, loss:0.00012, loss_test:0.08447, lr:1.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:41.929, tt:880.513\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.08392, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:41.858, tt:920.881\n",
      "Ep:22, loss:0.00011, loss_test:0.08260, lr:1.00e-02, fs:0.78363 (r=0.770,p=0.798),  time:41.844, tt:962.404\n",
      "Ep:23, loss:0.00010, loss_test:0.08126, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:41.914, tt:1005.927\n",
      "Ep:24, loss:0.00010, loss_test:0.07938, lr:1.00e-02, fs:0.79310 (r=0.793,p=0.793),  time:41.953, tt:1048.834\n",
      "Ep:25, loss:0.00009, loss_test:0.08195, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:41.988, tt:1091.689\n",
      "Ep:26, loss:0.00009, loss_test:0.07695, lr:1.00e-02, fs:0.79532 (r=0.782,p=0.810),  time:41.952, tt:1132.712\n",
      "Ep:27, loss:0.00008, loss_test:0.08384, lr:1.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:42.003, tt:1176.083\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.07612, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:41.909, tt:1215.370\n",
      "Ep:29, loss:0.00007, loss_test:0.08201, lr:1.00e-02, fs:0.82500 (r=0.759,p=0.904),  time:41.841, tt:1255.225\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00007, loss_test:0.07509, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:41.822, tt:1296.471\n",
      "Ep:31, loss:0.00006, loss_test:0.08217, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:41.824, tt:1338.378\n",
      "Ep:32, loss:0.00006, loss_test:0.07567, lr:1.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:41.829, tt:1380.349\n",
      "Ep:33, loss:0.00005, loss_test:0.07919, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:41.806, tt:1421.411\n",
      "Ep:34, loss:0.00005, loss_test:0.07630, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:41.814, tt:1463.506\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00005, loss_test:0.07645, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:41.832, tt:1505.952\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00004, loss_test:0.07963, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:41.795, tt:1546.410\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00004, loss_test:0.07688, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:41.756, tt:1586.737\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00004, loss_test:0.08217, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:41.740, tt:1627.862\n",
      "Ep:39, loss:0.00004, loss_test:0.07591, lr:1.00e-02, fs:0.78667 (r=0.678,p=0.937),  time:41.731, tt:1669.234\n",
      "Ep:40, loss:0.00003, loss_test:0.08378, lr:1.00e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.683, tt:1709.014\n",
      "Ep:41, loss:0.00003, loss_test:0.08070, lr:1.00e-02, fs:0.81879 (r=0.701,p=0.984),  time:41.662, tt:1749.818\n",
      "Ep:42, loss:0.00003, loss_test:0.08293, lr:1.00e-02, fs:0.71429 (r=0.575,p=0.943),  time:41.665, tt:1791.590\n",
      "Ep:43, loss:0.00003, loss_test:0.07904, lr:1.00e-02, fs:0.76923 (r=0.632,p=0.982),  time:41.641, tt:1832.223\n",
      "Ep:44, loss:0.00002, loss_test:0.08071, lr:1.00e-02, fs:0.75862 (r=0.632,p=0.948),  time:41.615, tt:1872.693\n",
      "Ep:45, loss:0.00002, loss_test:0.07891, lr:1.00e-02, fs:0.71429 (r=0.575,p=0.943),  time:41.605, tt:1913.821\n",
      "Ep:46, loss:0.00002, loss_test:0.08436, lr:1.00e-02, fs:0.75000 (r=0.621,p=0.947),  time:41.607, tt:1955.544\n",
      "Ep:47, loss:0.00002, loss_test:0.07867, lr:1.00e-02, fs:0.76923 (r=0.632,p=0.982),  time:41.593, tt:1996.446\n",
      "Ep:48, loss:0.00002, loss_test:0.08535, lr:1.00e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.735, tt:2045.005\n",
      "Ep:49, loss:0.00002, loss_test:0.08078, lr:9.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.736, tt:2086.777\n",
      "Ep:50, loss:0.00002, loss_test:0.08361, lr:9.80e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.742, tt:2128.849\n",
      "Ep:51, loss:0.00002, loss_test:0.08178, lr:9.70e-03, fs:0.76056 (r=0.621,p=0.982),  time:41.760, tt:2171.507\n",
      "Ep:52, loss:0.00001, loss_test:0.08339, lr:9.61e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.760, tt:2213.294\n",
      "Ep:53, loss:0.00001, loss_test:0.08395, lr:9.51e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.775, tt:2255.858\n",
      "Ep:54, loss:0.00001, loss_test:0.08131, lr:9.41e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.790, tt:2298.462\n",
      "Ep:55, loss:0.00001, loss_test:0.08238, lr:9.32e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.765, tt:2338.857\n",
      "Ep:56, loss:0.00001, loss_test:0.08508, lr:9.23e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.754, tt:2380.004\n",
      "Ep:57, loss:0.00001, loss_test:0.08998, lr:9.14e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.780, tt:2423.263\n",
      "Ep:58, loss:0.00001, loss_test:0.08208, lr:9.04e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.779, tt:2464.974\n",
      "Ep:59, loss:0.00001, loss_test:0.08564, lr:8.95e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.778, tt:2506.683\n",
      "Ep:60, loss:0.00001, loss_test:0.08652, lr:8.86e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.809, tt:2550.375\n",
      "Ep:61, loss:0.00001, loss_test:0.08532, lr:8.78e-03, fs:0.76056 (r=0.621,p=0.982),  time:41.796, tt:2591.338\n",
      "Ep:62, loss:0.00001, loss_test:0.08753, lr:8.69e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.838, tt:2635.773\n",
      "Ep:63, loss:0.00001, loss_test:0.08359, lr:8.60e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.828, tt:2676.977\n",
      "Ep:64, loss:0.00001, loss_test:0.08508, lr:8.51e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.815, tt:2718.002\n",
      "Ep:65, loss:0.00001, loss_test:0.08884, lr:8.43e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.781, tt:2757.542\n",
      "Ep:66, loss:0.00001, loss_test:0.08530, lr:8.35e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.803, tt:2800.782\n",
      "Ep:67, loss:0.00001, loss_test:0.08577, lr:8.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.805, tt:2842.708\n",
      "Ep:68, loss:0.00001, loss_test:0.09137, lr:8.18e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.867, tt:2888.831\n",
      "Ep:69, loss:0.00001, loss_test:0.08600, lr:8.10e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.868, tt:2930.748\n",
      "Ep:70, loss:0.00001, loss_test:0.08667, lr:8.02e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.907, tt:2975.387\n",
      "Ep:71, loss:0.00001, loss_test:0.08809, lr:7.94e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.894, tt:3016.341\n",
      "Ep:72, loss:0.00001, loss_test:0.08818, lr:7.86e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.880, tt:3057.227\n",
      "Ep:73, loss:0.00001, loss_test:0.08680, lr:7.78e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.880, tt:3099.151\n",
      "Ep:74, loss:0.00001, loss_test:0.08639, lr:7.70e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.904, tt:3142.834\n",
      "Ep:75, loss:0.00001, loss_test:0.08773, lr:7.62e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.890, tt:3183.662\n",
      "Ep:76, loss:0.00000, loss_test:0.08862, lr:7.55e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.872, tt:3224.118\n",
      "Ep:77, loss:0.00000, loss_test:0.08851, lr:7.47e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.883, tt:3266.907\n",
      "Ep:78, loss:0.00000, loss_test:0.08787, lr:7.40e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.860, tt:3306.901\n",
      "Ep:79, loss:0.00000, loss_test:0.09034, lr:7.32e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.860, tt:3348.785\n",
      "Ep:80, loss:0.00000, loss_test:0.08965, lr:7.25e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.862, tt:3390.838\n",
      "Ep:81, loss:0.00000, loss_test:0.08978, lr:7.18e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.846, tt:3431.349\n",
      "Ep:82, loss:0.00000, loss_test:0.09077, lr:7.11e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.833, tt:3472.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00000, loss_test:0.08987, lr:7.03e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.855, tt:3515.816\n",
      "Ep:84, loss:0.00000, loss_test:0.09026, lr:6.96e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.879, tt:3559.690\n",
      "Ep:85, loss:0.00000, loss_test:0.09061, lr:6.89e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.864, tt:3600.273\n",
      "Ep:86, loss:0.00000, loss_test:0.09155, lr:6.83e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.853, tt:3641.234\n",
      "Ep:87, loss:0.00000, loss_test:0.09152, lr:6.76e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.844, tt:3682.305\n",
      "Ep:88, loss:0.00000, loss_test:0.09274, lr:6.69e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.863, tt:3725.805\n",
      "Ep:89, loss:0.00000, loss_test:0.09252, lr:6.62e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.903, tt:3771.275\n",
      "Ep:90, loss:0.00000, loss_test:0.09274, lr:6.56e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.924, tt:3815.095\n",
      "Ep:91, loss:0.00000, loss_test:0.09311, lr:6.49e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.953, tt:3859.691\n",
      "Ep:92, loss:0.00000, loss_test:0.09262, lr:6.43e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.941, tt:3900.478\n",
      "Ep:93, loss:0.00000, loss_test:0.09377, lr:6.36e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.944, tt:3942.729\n",
      "Ep:94, loss:0.00000, loss_test:0.09445, lr:6.30e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.950, tt:3985.231\n",
      "Ep:95, loss:0.00000, loss_test:0.09426, lr:6.24e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.943, tt:4026.567\n",
      "Ep:96, loss:0.00000, loss_test:0.09484, lr:6.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.935, tt:4067.689\n",
      "Ep:97, loss:0.00000, loss_test:0.09441, lr:6.11e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.918, tt:4108.011\n",
      "Ep:98, loss:0.00000, loss_test:0.09452, lr:6.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.908, tt:4148.918\n",
      "Ep:99, loss:0.00000, loss_test:0.09388, lr:5.99e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.888, tt:4188.785\n",
      "Ep:100, loss:0.00000, loss_test:0.09482, lr:5.93e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.886, tt:4230.480\n",
      "Ep:101, loss:0.00000, loss_test:0.09488, lr:5.87e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.884, tt:4272.163\n",
      "Ep:102, loss:0.00000, loss_test:0.09402, lr:5.81e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.883, tt:4313.938\n",
      "Ep:103, loss:0.00000, loss_test:0.09398, lr:5.75e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.867, tt:4354.115\n",
      "Ep:104, loss:0.00000, loss_test:0.09517, lr:5.70e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.867, tt:4395.997\n",
      "Ep:105, loss:0.00000, loss_test:0.09519, lr:5.64e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.865, tt:4437.701\n",
      "Ep:106, loss:0.00000, loss_test:0.09499, lr:5.58e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.861, tt:4479.094\n",
      "Ep:107, loss:0.00000, loss_test:0.09502, lr:5.53e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.856, tt:4520.479\n",
      "Ep:108, loss:0.00000, loss_test:0.09486, lr:5.47e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.850, tt:4561.654\n",
      "Ep:109, loss:0.00000, loss_test:0.09471, lr:5.42e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.873, tt:4606.062\n",
      "Ep:110, loss:0.00000, loss_test:0.09531, lr:5.36e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.873, tt:4647.952\n",
      "Ep:111, loss:0.00000, loss_test:0.09547, lr:5.31e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.863, tt:4688.702\n",
      "Ep:112, loss:0.00000, loss_test:0.09498, lr:5.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.851, tt:4729.160\n",
      "Ep:113, loss:0.00000, loss_test:0.09520, lr:5.20e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.854, tt:4771.359\n",
      "Ep:114, loss:0.00000, loss_test:0.09566, lr:5.15e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.845, tt:4812.146\n",
      "Ep:115, loss:0.00000, loss_test:0.09597, lr:5.10e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.846, tt:4854.189\n",
      "Ep:116, loss:0.00000, loss_test:0.09503, lr:5.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.848, tt:4896.227\n",
      "Ep:117, loss:0.00000, loss_test:0.09492, lr:5.00e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.848, tt:4938.071\n",
      "Ep:118, loss:0.00000, loss_test:0.09507, lr:4.95e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.853, tt:4980.497\n",
      "Ep:119, loss:0.00000, loss_test:0.09573, lr:4.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.844, tt:5021.318\n",
      "Ep:120, loss:0.00000, loss_test:0.09431, lr:4.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.812, tt:5059.247\n",
      "Ep:121, loss:0.00000, loss_test:0.09519, lr:4.80e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.769, tt:5095.877\n",
      "Ep:122, loss:0.00000, loss_test:0.09622, lr:4.75e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.721, tt:5131.741\n",
      "Ep:123, loss:0.00000, loss_test:0.09578, lr:4.71e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.680, tt:5168.264\n",
      "Ep:124, loss:0.00000, loss_test:0.09562, lr:4.66e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.636, tt:5204.563\n",
      "Ep:125, loss:0.00000, loss_test:0.09596, lr:4.61e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.527, tt:5232.406\n",
      "Ep:126, loss:0.00000, loss_test:0.09746, lr:4.57e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.326, tt:5248.452\n",
      "Ep:127, loss:0.00000, loss_test:0.09721, lr:4.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:41.105, tt:5261.474\n",
      "Ep:128, loss:0.00000, loss_test:0.09647, lr:4.48e-03, fs:0.76923 (r=0.632,p=0.982),  time:40.873, tt:5272.620\n",
      "Ep:129, loss:0.00000, loss_test:0.09688, lr:4.43e-03, fs:0.76923 (r=0.632,p=0.982),  time:40.645, tt:5283.792\n",
      "Ep:130, loss:0.00000, loss_test:0.09602, lr:4.39e-03, fs:0.76923 (r=0.632,p=0.982),  time:40.420, tt:5295.019\n",
      "Ep:131, loss:0.00000, loss_test:0.09587, lr:4.34e-03, fs:0.76923 (r=0.632,p=0.982),  time:40.198, tt:5306.142\n",
      "Ep:132, loss:0.00000, loss_test:0.09558, lr:4.30e-03, fs:0.76923 (r=0.632,p=0.982),  time:39.980, tt:5317.294\n",
      "Ep:133, loss:0.00000, loss_test:0.09494, lr:4.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:39.764, tt:5328.406\n",
      "Ep:134, loss:0.00000, loss_test:0.09545, lr:4.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:39.552, tt:5339.506\n",
      "Ep:135, loss:0.00000, loss_test:0.09518, lr:4.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:39.343, tt:5350.691\n",
      "Ep:136, loss:0.00000, loss_test:0.09422, lr:4.13e-03, fs:0.76923 (r=0.632,p=0.982),  time:39.137, tt:5361.798\n",
      "Ep:137, loss:0.00000, loss_test:0.09457, lr:4.09e-03, fs:0.76923 (r=0.632,p=0.982),  time:38.933, tt:5372.792\n",
      "Ep:138, loss:0.00000, loss_test:0.09622, lr:4.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:38.733, tt:5383.923\n",
      "Ep:139, loss:0.00000, loss_test:0.09550, lr:4.01e-03, fs:0.76923 (r=0.632,p=0.982),  time:38.539, tt:5395.429\n",
      "Ep:140, loss:0.00000, loss_test:0.09508, lr:3.97e-03, fs:0.76923 (r=0.632,p=0.982),  time:38.345, tt:5406.594\n",
      "Ep:141, loss:0.00000, loss_test:0.09490, lr:3.93e-03, fs:0.76923 (r=0.632,p=0.982),  time:38.153, tt:5417.659\n",
      "Ep:142, loss:0.00000, loss_test:0.09416, lr:3.89e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.970, tt:5429.743\n",
      "Ep:143, loss:0.00000, loss_test:0.09451, lr:3.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.784, tt:5440.834\n",
      "Ep:144, loss:0.00000, loss_test:0.09456, lr:3.81e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.600, tt:5451.944\n",
      "Ep:145, loss:0.00000, loss_test:0.09382, lr:3.77e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.418, tt:5462.981\n",
      "Ep:146, loss:0.00000, loss_test:0.09380, lr:3.73e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.241, tt:5474.403\n",
      "Ep:147, loss:0.00000, loss_test:0.09437, lr:3.70e-03, fs:0.76923 (r=0.632,p=0.982),  time:37.064, tt:5485.472\n",
      "Ep:148, loss:0.00000, loss_test:0.09434, lr:3.66e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.889, tt:5496.389\n",
      "Ep:149, loss:0.00000, loss_test:0.09442, lr:3.62e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.716, tt:5507.400\n",
      "Ep:150, loss:0.00000, loss_test:0.09417, lr:3.59e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.546, tt:5518.425\n",
      "Ep:151, loss:0.00000, loss_test:0.09472, lr:3.55e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.379, tt:5529.531\n",
      "Ep:152, loss:0.00000, loss_test:0.09476, lr:3.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.212, tt:5540.470\n",
      "Ep:153, loss:0.00000, loss_test:0.09431, lr:3.48e-03, fs:0.76923 (r=0.632,p=0.982),  time:36.049, tt:5551.538\n",
      "Ep:154, loss:0.00000, loss_test:0.09385, lr:3.45e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.888, tt:5562.643\n",
      "Ep:155, loss:0.00000, loss_test:0.09404, lr:3.41e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.729, tt:5573.707\n",
      "Ep:156, loss:0.00000, loss_test:0.09434, lr:3.38e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.571, tt:5584.706\n",
      "Ep:157, loss:0.00000, loss_test:0.09407, lr:3.34e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.417, tt:5595.846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:158, loss:0.00000, loss_test:0.09354, lr:3.31e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.264, tt:5606.925\n",
      "Ep:159, loss:0.00000, loss_test:0.09432, lr:3.28e-03, fs:0.76923 (r=0.632,p=0.982),  time:35.112, tt:5617.951\n",
      "Ep:160, loss:0.00000, loss_test:0.09450, lr:3.24e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.963, tt:5629.051\n",
      "Ep:161, loss:0.00000, loss_test:0.09405, lr:3.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.816, tt:5640.200\n",
      "Ep:162, loss:0.00000, loss_test:0.09397, lr:3.18e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.670, tt:5651.260\n",
      "Ep:163, loss:0.00000, loss_test:0.09432, lr:3.15e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.526, tt:5662.280\n",
      "Ep:164, loss:0.00000, loss_test:0.09413, lr:3.12e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.384, tt:5673.311\n",
      "Ep:165, loss:0.00000, loss_test:0.09444, lr:3.09e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.243, tt:5684.360\n",
      "Ep:166, loss:0.00000, loss_test:0.09486, lr:3.05e-03, fs:0.76923 (r=0.632,p=0.982),  time:34.105, tt:5695.464\n",
      "Ep:167, loss:0.00000, loss_test:0.09446, lr:3.02e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.968, tt:5706.574\n",
      "Ep:168, loss:0.00000, loss_test:0.09464, lr:2.99e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.832, tt:5717.660\n",
      "Ep:169, loss:0.00000, loss_test:0.09441, lr:2.96e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.698, tt:5728.670\n",
      "Ep:170, loss:0.00000, loss_test:0.09371, lr:2.93e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.565, tt:5739.670\n",
      "Ep:171, loss:0.00000, loss_test:0.09324, lr:2.90e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.434, tt:5750.644\n",
      "Ep:172, loss:0.00000, loss_test:0.09368, lr:2.88e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.304, tt:5761.594\n",
      "Ep:173, loss:0.00000, loss_test:0.09427, lr:2.85e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.176, tt:5772.651\n",
      "Ep:174, loss:0.00000, loss_test:0.09396, lr:2.82e-03, fs:0.76923 (r=0.632,p=0.982),  time:33.050, tt:5783.683\n",
      "Ep:175, loss:0.00000, loss_test:0.09363, lr:2.79e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.925, tt:5794.756\n",
      "Ep:176, loss:0.00000, loss_test:0.09376, lr:2.76e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.801, tt:5805.721\n",
      "Ep:177, loss:0.00000, loss_test:0.09427, lr:2.73e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.678, tt:5816.723\n",
      "Ep:178, loss:0.00000, loss_test:0.09415, lr:2.71e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.563, tt:5828.836\n",
      "Ep:179, loss:0.00000, loss_test:0.09385, lr:2.68e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.444, tt:5839.856\n",
      "Ep:180, loss:0.00000, loss_test:0.09400, lr:2.65e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.328, tt:5851.372\n",
      "Ep:181, loss:0.00000, loss_test:0.09404, lr:2.63e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.211, tt:5862.452\n",
      "Ep:182, loss:0.00000, loss_test:0.09361, lr:2.60e-03, fs:0.76923 (r=0.632,p=0.982),  time:32.096, tt:5873.533\n",
      "Ep:183, loss:0.00000, loss_test:0.09332, lr:2.57e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.982, tt:5884.612\n",
      "Ep:184, loss:0.00000, loss_test:0.09315, lr:2.55e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.869, tt:5895.734\n",
      "Ep:185, loss:0.00000, loss_test:0.09351, lr:2.52e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.757, tt:5906.759\n",
      "Ep:186, loss:0.00000, loss_test:0.09382, lr:2.50e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.647, tt:5917.897\n",
      "Ep:187, loss:0.00000, loss_test:0.09354, lr:2.47e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.537, tt:5928.977\n",
      "Ep:188, loss:0.00000, loss_test:0.09360, lr:2.45e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.429, tt:5940.003\n",
      "Ep:189, loss:0.00000, loss_test:0.09379, lr:2.42e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.321, tt:5951.064\n",
      "Ep:190, loss:0.00000, loss_test:0.09352, lr:2.40e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.216, tt:5962.187\n",
      "Ep:191, loss:0.00000, loss_test:0.09330, lr:2.38e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.111, tt:5973.219\n",
      "Ep:192, loss:0.00000, loss_test:0.09330, lr:2.35e-03, fs:0.76923 (r=0.632,p=0.982),  time:31.006, tt:5984.211\n",
      "Ep:193, loss:0.00000, loss_test:0.09333, lr:2.33e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.903, tt:5995.125\n",
      "Ep:194, loss:0.00000, loss_test:0.09349, lr:2.31e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.801, tt:6006.179\n",
      "Ep:195, loss:0.00000, loss_test:0.09369, lr:2.28e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.700, tt:6017.216\n",
      "Ep:196, loss:0.00000, loss_test:0.09348, lr:2.26e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.601, tt:6028.458\n",
      "Ep:197, loss:0.00000, loss_test:0.09305, lr:2.24e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.503, tt:6039.553\n",
      "Ep:198, loss:0.00000, loss_test:0.09307, lr:2.21e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.405, tt:6050.557\n",
      "Ep:199, loss:0.00000, loss_test:0.09318, lr:2.19e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.308, tt:6061.656\n",
      "Ep:200, loss:0.00000, loss_test:0.09298, lr:2.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.213, tt:6072.732\n",
      "Ep:201, loss:0.00000, loss_test:0.09293, lr:2.15e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.118, tt:6083.847\n",
      "Ep:202, loss:0.00000, loss_test:0.09306, lr:2.13e-03, fs:0.76923 (r=0.632,p=0.982),  time:30.024, tt:6094.836\n",
      "Ep:203, loss:0.00000, loss_test:0.09336, lr:2.11e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.931, tt:6105.940\n",
      "Ep:204, loss:0.00000, loss_test:0.09371, lr:2.08e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.839, tt:6117.064\n",
      "Ep:205, loss:0.00000, loss_test:0.09359, lr:2.06e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.749, tt:6128.360\n",
      "Ep:206, loss:0.00000, loss_test:0.09320, lr:2.04e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.659, tt:6139.479\n",
      "Ep:207, loss:0.00000, loss_test:0.09312, lr:2.02e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.570, tt:6150.611\n",
      "Ep:208, loss:0.00000, loss_test:0.09332, lr:2.00e-03, fs:0.76923 (r=0.632,p=0.982),  time:29.482, tt:6161.708\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02196, lr:6.00e-02, fs:0.60967 (r=0.828,p=0.482),  time:40.845, tt:40.845\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02352, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:41.462, tt:82.924\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02465, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.643, tt:121.928\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02408, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.732, tt:166.927\n",
      "Ep:4, loss:0.00004, loss_test:0.02248, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:41.616, tt:208.078\n",
      "Ep:5, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:40.633, tt:243.797\n",
      "Ep:6, loss:0.00004, loss_test:0.01967, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:39.738, tt:278.166\n",
      "Ep:7, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:39.167, tt:313.332\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01960, lr:6.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:38.648, tt:347.832\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01948, lr:6.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:38.671, tt:386.708\n",
      "Ep:10, loss:0.00003, loss_test:0.01947, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:38.353, tt:421.883\n",
      "Ep:11, loss:0.00003, loss_test:0.01938, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:38.035, tt:456.423\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01911, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:37.858, tt:492.160\n",
      "Ep:13, loss:0.00003, loss_test:0.01889, lr:6.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:37.687, tt:527.621\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01886, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:37.439, tt:561.579\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01880, lr:6.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:37.254, tt:596.071\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01865, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:37.127, tt:631.155\n",
      "Ep:17, loss:0.00003, loss_test:0.01857, lr:6.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:37.094, tt:667.698\n",
      "Ep:18, loss:0.00003, loss_test:0.01850, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:37.048, tt:703.913\n",
      "Ep:19, loss:0.00003, loss_test:0.01844, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:36.996, tt:739.929\n",
      "Ep:20, loss:0.00003, loss_test:0.01847, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:36.875, tt:774.372\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01860, lr:6.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:36.848, tt:810.660\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01869, lr:6.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:36.767, tt:845.641\n",
      "Ep:23, loss:0.00002, loss_test:0.01873, lr:6.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:36.733, tt:881.600\n",
      "Ep:24, loss:0.00002, loss_test:0.01872, lr:6.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:36.759, tt:918.983\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01870, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:36.643, tt:952.717\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01870, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:36.596, tt:988.096\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01871, lr:6.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:36.515, tt:1022.431\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01879, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:36.399, tt:1055.558\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01887, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:36.348, tt:1090.427\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01891, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:36.189, tt:1121.850\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01900, lr:6.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:36.108, tt:1155.455\n",
      "Ep:32, loss:0.00002, loss_test:0.01906, lr:6.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:36.090, tt:1190.963\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01911, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:36.077, tt:1226.617\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01918, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:36.034, tt:1261.203\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01932, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:36.055, tt:1297.971\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01939, lr:6.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:36.058, tt:1334.134\n",
      "Ep:37, loss:0.00002, loss_test:0.01947, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.985, tt:1367.426\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01957, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.968, tt:1402.747\n",
      "Ep:39, loss:0.00002, loss_test:0.01961, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.973, tt:1438.902\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01976, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.961, tt:1474.403\n",
      "Ep:41, loss:0.00001, loss_test:0.01986, lr:6.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:35.959, tt:1510.290\n",
      "Ep:42, loss:0.00001, loss_test:0.01989, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.960, tt:1546.269\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01995, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:36.002, tt:1584.080\n",
      "Ep:44, loss:0.00001, loss_test:0.01999, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.989, tt:1619.503\n",
      "Ep:45, loss:0.00001, loss_test:0.02010, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.982, tt:1655.192\n",
      "Ep:46, loss:0.00001, loss_test:0.02016, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.974, tt:1690.774\n",
      "Ep:47, loss:0.00001, loss_test:0.02022, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.988, tt:1727.436\n",
      "Ep:48, loss:0.00001, loss_test:0.02024, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.982, tt:1763.119\n",
      "Ep:49, loss:0.00001, loss_test:0.02031, lr:6.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.999, tt:1799.934\n",
      "Ep:50, loss:0.00001, loss_test:0.02047, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:35.959, tt:1833.892\n",
      "Ep:51, loss:0.00001, loss_test:0.02065, lr:6.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:35.985, tt:1871.207\n",
      "Ep:52, loss:0.00001, loss_test:0.02074, lr:6.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.952, tt:1905.462\n",
      "Ep:53, loss:0.00001, loss_test:0.02068, lr:6.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.979, tt:1942.841\n",
      "Ep:54, loss:0.00001, loss_test:0.02077, lr:5.94e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.982, tt:1978.985\n",
      "Ep:55, loss:0.00001, loss_test:0.02078, lr:5.88e-02, fs:0.79188 (r=0.788,p=0.796),  time:35.973, tt:2014.484\n",
      "Ep:56, loss:0.00001, loss_test:0.02087, lr:5.82e-02, fs:0.79592 (r=0.788,p=0.804),  time:35.948, tt:2049.035\n",
      "Ep:57, loss:0.00001, loss_test:0.02095, lr:5.76e-02, fs:0.79592 (r=0.788,p=0.804),  time:35.944, tt:2084.763\n",
      "Ep:58, loss:0.00001, loss_test:0.02097, lr:5.71e-02, fs:0.79592 (r=0.788,p=0.804),  time:35.937, tt:2120.284\n",
      "Ep:59, loss:0.00001, loss_test:0.02086, lr:5.65e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.931, tt:2155.851\n",
      "Ep:60, loss:0.00001, loss_test:0.02103, lr:5.59e-02, fs:0.78756 (r=0.768,p=0.809),  time:35.933, tt:2191.923\n",
      "Ep:61, loss:0.00001, loss_test:0.02102, lr:5.54e-02, fs:0.77487 (r=0.747,p=0.804),  time:35.932, tt:2227.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.02101, lr:5.48e-02, fs:0.78534 (r=0.758,p=0.815),  time:35.939, tt:2264.160\n",
      "Ep:63, loss:0.00001, loss_test:0.02122, lr:5.43e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.957, tt:2301.275\n",
      "Ep:64, loss:0.00001, loss_test:0.02116, lr:5.37e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.976, tt:2338.422\n",
      "Ep:65, loss:0.00001, loss_test:0.02125, lr:5.32e-02, fs:0.77005 (r=0.727,p=0.818),  time:36.017, tt:2377.147\n",
      "Ep:66, loss:0.00001, loss_test:0.02126, lr:5.27e-02, fs:0.77005 (r=0.727,p=0.818),  time:35.998, tt:2411.869\n",
      "Ep:67, loss:0.00001, loss_test:0.02122, lr:5.21e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.966, tt:2445.697\n",
      "Ep:68, loss:0.00001, loss_test:0.02146, lr:5.16e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.948, tt:2480.412\n",
      "Ep:69, loss:0.00001, loss_test:0.02157, lr:5.11e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.928, tt:2514.992\n",
      "Ep:70, loss:0.00001, loss_test:0.02137, lr:5.06e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.931, tt:2551.102\n",
      "Ep:71, loss:0.00001, loss_test:0.02139, lr:5.01e-02, fs:0.78075 (r=0.737,p=0.830),  time:35.932, tt:2587.085\n",
      "Ep:72, loss:0.00001, loss_test:0.02150, lr:4.96e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.943, tt:2623.843\n",
      "Ep:73, loss:0.00001, loss_test:0.02155, lr:4.91e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.912, tt:2657.525\n",
      "Ep:74, loss:0.00001, loss_test:0.02163, lr:4.86e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.902, tt:2692.684\n",
      "Ep:75, loss:0.00001, loss_test:0.02159, lr:4.81e-02, fs:0.77838 (r=0.727,p=0.837),  time:35.892, tt:2727.804\n",
      "Ep:76, loss:0.00001, loss_test:0.02180, lr:4.76e-02, fs:0.76757 (r=0.717,p=0.826),  time:35.857, tt:2760.998\n",
      "Ep:77, loss:0.00001, loss_test:0.02179, lr:4.71e-02, fs:0.76087 (r=0.707,p=0.824),  time:35.816, tt:2793.621\n",
      "Ep:78, loss:0.00001, loss_test:0.02170, lr:4.67e-02, fs:0.77174 (r=0.717,p=0.835),  time:35.793, tt:2827.671\n",
      "Ep:79, loss:0.00001, loss_test:0.02191, lr:4.62e-02, fs:0.75410 (r=0.697,p=0.821),  time:35.794, tt:2863.549\n",
      "Ep:80, loss:0.00001, loss_test:0.02189, lr:4.57e-02, fs:0.76087 (r=0.707,p=0.824),  time:35.793, tt:2899.271\n",
      "Ep:81, loss:0.00001, loss_test:0.02173, lr:4.53e-02, fs:0.77596 (r=0.717,p=0.845),  time:35.767, tt:2932.885\n",
      "Ep:82, loss:0.00001, loss_test:0.02202, lr:4.48e-02, fs:0.75706 (r=0.677,p=0.859),  time:35.807, tt:2971.969\n",
      "Ep:83, loss:0.00001, loss_test:0.02208, lr:4.44e-02, fs:0.76404 (r=0.687,p=0.861),  time:35.808, tt:3007.900\n",
      "Ep:84, loss:0.00001, loss_test:0.02199, lr:4.39e-02, fs:0.76667 (r=0.697,p=0.852),  time:35.873, tt:3049.231\n",
      "Ep:85, loss:0.00001, loss_test:0.02210, lr:4.35e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.864, tt:3084.347\n",
      "Ep:86, loss:0.00001, loss_test:0.02220, lr:4.31e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.863, tt:3120.085\n",
      "Ep:87, loss:0.00001, loss_test:0.02210, lr:4.26e-02, fs:0.74576 (r=0.667,p=0.846),  time:35.867, tt:3156.295\n",
      "Ep:88, loss:0.00001, loss_test:0.02224, lr:4.22e-02, fs:0.75000 (r=0.667,p=0.857),  time:35.836, tt:3189.416\n",
      "Ep:89, loss:0.00001, loss_test:0.02230, lr:4.18e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.809, tt:3222.851\n",
      "Ep:90, loss:0.00001, loss_test:0.02227, lr:4.14e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.812, tt:3258.874\n",
      "Ep:91, loss:0.00001, loss_test:0.02239, lr:4.10e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.798, tt:3293.424\n",
      "Ep:92, loss:0.00001, loss_test:0.02243, lr:4.05e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.784, tt:3327.919\n",
      "Ep:93, loss:0.00001, loss_test:0.02252, lr:4.01e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.748, tt:3360.306\n",
      "Ep:94, loss:0.00001, loss_test:0.02254, lr:3.97e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.761, tt:3397.315\n",
      "Ep:95, loss:0.00001, loss_test:0.02255, lr:3.93e-02, fs:0.74286 (r=0.657,p=0.855),  time:35.743, tt:3431.335\n",
      "Ep:96, loss:0.00001, loss_test:0.02263, lr:3.89e-02, fs:0.74713 (r=0.657,p=0.867),  time:35.732, tt:3465.971\n",
      "Ep:97, loss:0.00001, loss_test:0.02280, lr:3.86e-02, fs:0.74713 (r=0.657,p=0.867),  time:35.709, tt:3499.474\n",
      "Ep:98, loss:0.00001, loss_test:0.02287, lr:3.82e-02, fs:0.74713 (r=0.657,p=0.867),  time:35.711, tt:3535.354\n",
      "Ep:99, loss:0.00001, loss_test:0.02286, lr:3.78e-02, fs:0.74713 (r=0.657,p=0.867),  time:35.688, tt:3568.841\n",
      "Ep:100, loss:0.00001, loss_test:0.02291, lr:3.74e-02, fs:0.74713 (r=0.657,p=0.867),  time:35.686, tt:3604.268\n",
      "Ep:101, loss:0.00001, loss_test:0.02301, lr:3.70e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.685, tt:3639.836\n",
      "Ep:102, loss:0.00001, loss_test:0.02300, lr:3.67e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.676, tt:3674.614\n",
      "Ep:103, loss:0.00001, loss_test:0.02303, lr:3.63e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.680, tt:3710.690\n",
      "Ep:104, loss:0.00001, loss_test:0.02314, lr:3.59e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.668, tt:3745.130\n",
      "Ep:105, loss:0.00001, loss_test:0.02321, lr:3.56e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.668, tt:3780.813\n",
      "Ep:106, loss:0.00001, loss_test:0.02329, lr:3.52e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.673, tt:3816.997\n",
      "Ep:107, loss:0.00001, loss_test:0.02337, lr:3.49e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.650, tt:3850.209\n",
      "Ep:108, loss:0.00001, loss_test:0.02332, lr:3.45e-02, fs:0.73988 (r=0.646,p=0.865),  time:35.624, tt:3883.028\n",
      "Ep:109, loss:0.00001, loss_test:0.02342, lr:3.42e-02, fs:0.73256 (r=0.636,p=0.863),  time:35.621, tt:3918.352\n",
      "Ep:110, loss:0.00001, loss_test:0.02349, lr:3.38e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.604, tt:3952.036\n",
      "Ep:111, loss:0.00000, loss_test:0.02348, lr:3.35e-02, fs:0.73373 (r=0.626,p=0.886),  time:35.605, tt:3987.733\n",
      "Ep:112, loss:0.00000, loss_test:0.02354, lr:3.32e-02, fs:0.73810 (r=0.626,p=0.899),  time:35.601, tt:4022.960\n",
      "Ep:113, loss:0.00000, loss_test:0.02365, lr:3.28e-02, fs:0.73810 (r=0.626,p=0.899),  time:35.619, tt:4060.527\n",
      "Ep:114, loss:0.00000, loss_test:0.02365, lr:3.25e-02, fs:0.73810 (r=0.626,p=0.899),  time:35.606, tt:4094.707\n",
      "Ep:115, loss:0.00000, loss_test:0.02366, lr:3.22e-02, fs:0.73810 (r=0.626,p=0.899),  time:35.580, tt:4127.290\n",
      "Ep:116, loss:0.00000, loss_test:0.02385, lr:3.19e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.559, tt:4160.453\n",
      "Ep:117, loss:0.00000, loss_test:0.02401, lr:3.15e-02, fs:0.73054 (r=0.616,p=0.897),  time:35.548, tt:4194.624\n",
      "Ep:118, loss:0.00000, loss_test:0.02387, lr:3.12e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.547, tt:4230.100\n",
      "Ep:119, loss:0.00000, loss_test:0.02396, lr:3.09e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.539, tt:4264.632\n",
      "Ep:120, loss:0.00000, loss_test:0.02407, lr:3.06e-02, fs:0.73494 (r=0.616,p=0.910),  time:35.531, tt:4299.250\n",
      "Ep:121, loss:0.00000, loss_test:0.02410, lr:3.03e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.530, tt:4334.693\n",
      "Ep:122, loss:0.00000, loss_test:0.02425, lr:3.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.527, tt:4369.811\n",
      "Ep:123, loss:0.00000, loss_test:0.02434, lr:2.97e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.522, tt:4404.694\n",
      "Ep:124, loss:0.00000, loss_test:0.02424, lr:2.94e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.496, tt:4437.017\n",
      "Ep:125, loss:0.00000, loss_test:0.02428, lr:2.91e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.497, tt:4472.560\n",
      "Ep:126, loss:0.00000, loss_test:0.02446, lr:2.88e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.491, tt:4507.348\n",
      "Ep:127, loss:0.00000, loss_test:0.02450, lr:2.85e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.487, tt:4542.326\n",
      "Ep:128, loss:0.00000, loss_test:0.02445, lr:2.82e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.466, tt:4575.137\n",
      "Ep:129, loss:0.00000, loss_test:0.02452, lr:2.80e-02, fs:0.70370 (r=0.576,p=0.905),  time:35.466, tt:4610.608\n",
      "Ep:130, loss:0.00000, loss_test:0.02463, lr:2.77e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.465, tt:4645.900\n",
      "Ep:131, loss:0.00000, loss_test:0.02470, lr:2.74e-02, fs:0.70807 (r=0.576,p=0.919),  time:35.446, tt:4678.915\n",
      "Ep:132, loss:0.00000, loss_test:0.02465, lr:2.71e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.429, tt:4712.082\n",
      "Ep:133, loss:0.00000, loss_test:0.02480, lr:2.69e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.427, tt:4747.221\n",
      "Ep:134, loss:0.00000, loss_test:0.02483, lr:2.66e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.409, tt:4780.183\n",
      "Ep:135, loss:0.00000, loss_test:0.02485, lr:2.63e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.404, tt:4815.012\n",
      "Ep:136, loss:0.00000, loss_test:0.02487, lr:2.61e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.388, tt:4848.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02501, lr:2.58e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.372, tt:4881.359\n",
      "Ep:138, loss:0.00000, loss_test:0.02499, lr:2.55e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.350, tt:4913.616\n",
      "Ep:139, loss:0.00000, loss_test:0.02498, lr:2.53e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.335, tt:4946.943\n",
      "Ep:140, loss:0.00000, loss_test:0.02506, lr:2.50e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.327, tt:4981.114\n",
      "Ep:141, loss:0.00000, loss_test:0.02514, lr:2.48e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.313, tt:5014.429\n",
      "Ep:142, loss:0.00000, loss_test:0.02522, lr:2.45e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.308, tt:5049.110\n",
      "Ep:143, loss:0.00000, loss_test:0.02524, lr:2.43e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.306, tt:5084.049\n",
      "Ep:144, loss:0.00000, loss_test:0.02524, lr:2.40e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.299, tt:5118.408\n",
      "Ep:145, loss:0.00000, loss_test:0.02534, lr:2.38e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.285, tt:5151.654\n",
      "Ep:146, loss:0.00000, loss_test:0.02530, lr:2.36e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.283, tt:5186.562\n",
      "Ep:147, loss:0.00000, loss_test:0.02538, lr:2.33e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.263, tt:5218.951\n",
      "Ep:148, loss:0.00000, loss_test:0.02541, lr:2.31e-02, fs:0.70000 (r=0.566,p=0.918),  time:35.248, tt:5252.014\n",
      "Ep:149, loss:0.00000, loss_test:0.02546, lr:2.29e-02, fs:0.70440 (r=0.566,p=0.933),  time:35.246, tt:5286.828\n",
      "Ep:150, loss:0.00000, loss_test:0.02557, lr:2.26e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.245, tt:5321.979\n",
      "Ep:151, loss:0.00000, loss_test:0.02562, lr:2.24e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.242, tt:5356.770\n",
      "Ep:152, loss:0.00000, loss_test:0.02561, lr:2.22e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.242, tt:5392.092\n",
      "Ep:153, loss:0.00000, loss_test:0.02563, lr:2.20e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.237, tt:5426.439\n",
      "Ep:154, loss:0.00000, loss_test:0.02576, lr:2.17e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.223, tt:5459.494\n",
      "Ep:155, loss:0.00000, loss_test:0.02581, lr:2.15e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.208, tt:5492.479\n",
      "Ep:156, loss:0.00000, loss_test:0.02579, lr:2.13e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.211, tt:5528.095\n",
      "Ep:157, loss:0.00000, loss_test:0.02587, lr:2.11e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.202, tt:5561.903\n",
      "Ep:158, loss:0.00000, loss_test:0.02591, lr:2.09e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.189, tt:5595.021\n",
      "Ep:159, loss:0.00000, loss_test:0.02595, lr:2.07e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.168, tt:5626.957\n",
      "Ep:160, loss:0.00000, loss_test:0.02599, lr:2.05e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.176, tt:5663.339\n",
      "Ep:161, loss:0.00000, loss_test:0.02600, lr:2.03e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.160, tt:5695.954\n",
      "Ep:162, loss:0.00000, loss_test:0.02606, lr:2.01e-02, fs:0.70886 (r=0.566,p=0.949),  time:35.183, tt:5734.776\n",
      "Ep:163, loss:0.00000, loss_test:0.02616, lr:1.99e-02, fs:0.70064 (r=0.556,p=0.948),  time:35.180, tt:5769.522\n",
      "Ep:164, loss:0.00000, loss_test:0.02619, lr:1.97e-02, fs:0.70064 (r=0.556,p=0.948),  time:35.166, tt:5802.376\n",
      "Ep:165, loss:0.00000, loss_test:0.02623, lr:1.95e-02, fs:0.70064 (r=0.556,p=0.948),  time:35.159, tt:5836.431\n",
      "Ep:166, loss:0.00000, loss_test:0.02627, lr:1.93e-02, fs:0.70064 (r=0.556,p=0.948),  time:35.148, tt:5869.755\n",
      "Ep:167, loss:0.00000, loss_test:0.02632, lr:1.91e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.150, tt:5905.195\n",
      "Ep:168, loss:0.00000, loss_test:0.02639, lr:1.89e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.134, tt:5937.677\n",
      "Ep:169, loss:0.00000, loss_test:0.02641, lr:1.87e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.129, tt:5971.850\n",
      "Ep:170, loss:0.00000, loss_test:0.02641, lr:1.85e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.114, tt:6004.557\n",
      "Ep:171, loss:0.00000, loss_test:0.02649, lr:1.83e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.104, tt:6037.893\n",
      "Ep:172, loss:0.00000, loss_test:0.02653, lr:1.81e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.100, tt:6072.248\n",
      "Ep:173, loss:0.00000, loss_test:0.02661, lr:1.80e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.099, tt:6107.190\n",
      "Ep:174, loss:0.00000, loss_test:0.02662, lr:1.78e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.093, tt:6141.275\n",
      "Ep:175, loss:0.00000, loss_test:0.02665, lr:1.76e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.083, tt:6174.630\n",
      "Ep:176, loss:0.00000, loss_test:0.02666, lr:1.74e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.083, tt:6209.689\n",
      "Ep:177, loss:0.00000, loss_test:0.02666, lr:1.73e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.079, tt:6244.092\n",
      "Ep:178, loss:0.00000, loss_test:0.02678, lr:1.71e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.077, tt:6278.746\n",
      "Ep:179, loss:0.00000, loss_test:0.02684, lr:1.69e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.069, tt:6312.381\n",
      "Ep:180, loss:0.00000, loss_test:0.02679, lr:1.67e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.060, tt:6345.860\n",
      "Ep:181, loss:0.00000, loss_test:0.02687, lr:1.66e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.048, tt:6378.698\n",
      "Ep:182, loss:0.00000, loss_test:0.02693, lr:1.64e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.049, tt:6413.922\n",
      "Ep:183, loss:0.00000, loss_test:0.02696, lr:1.62e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.040, tt:6447.287\n",
      "Ep:184, loss:0.00000, loss_test:0.02699, lr:1.61e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.041, tt:6482.558\n",
      "Ep:185, loss:0.00000, loss_test:0.02703, lr:1.59e-02, fs:0.70513 (r=0.556,p=0.965),  time:35.043, tt:6517.973\n",
      "Ep:186, loss:0.00000, loss_test:0.02706, lr:1.58e-02, fs:0.69677 (r=0.545,p=0.964),  time:35.067, tt:6557.540\n",
      "Ep:187, loss:0.00000, loss_test:0.02709, lr:1.56e-02, fs:0.69677 (r=0.545,p=0.964),  time:35.073, tt:6593.698\n",
      "Ep:188, loss:0.00000, loss_test:0.02716, lr:1.54e-02, fs:0.69677 (r=0.545,p=0.964),  time:35.074, tt:6628.957\n",
      "Ep:189, loss:0.00000, loss_test:0.02718, lr:1.53e-02, fs:0.69677 (r=0.545,p=0.964),  time:35.075, tt:6664.340\n",
      "Ep:190, loss:0.00000, loss_test:0.02721, lr:1.51e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.078, tt:6699.986\n",
      "Ep:191, loss:0.00000, loss_test:0.02722, lr:1.50e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.071, tt:6733.699\n",
      "Ep:192, loss:0.00000, loss_test:0.02731, lr:1.48e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.072, tt:6768.871\n",
      "Ep:193, loss:0.00000, loss_test:0.02734, lr:1.47e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.070, tt:6803.539\n",
      "Ep:194, loss:0.00000, loss_test:0.02732, lr:1.45e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.073, tt:6839.194\n",
      "Ep:195, loss:0.00000, loss_test:0.02734, lr:1.44e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.072, tt:6874.125\n",
      "Ep:196, loss:0.00000, loss_test:0.02742, lr:1.43e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.068, tt:6908.488\n",
      "Ep:197, loss:0.00000, loss_test:0.02744, lr:1.41e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.069, tt:6943.583\n",
      "Ep:198, loss:0.00000, loss_test:0.02745, lr:1.40e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.071, tt:6979.173\n",
      "Ep:199, loss:0.00000, loss_test:0.02750, lr:1.38e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.075, tt:7014.918\n",
      "Ep:200, loss:0.00000, loss_test:0.02755, lr:1.37e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.081, tt:7051.356\n",
      "Ep:201, loss:0.00000, loss_test:0.02757, lr:1.36e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.079, tt:7086.011\n",
      "Ep:202, loss:0.00000, loss_test:0.02755, lr:1.34e-02, fs:0.68831 (r=0.535,p=0.964),  time:35.058, tt:7116.687\n",
      "Ep:203, loss:0.00000, loss_test:0.02759, lr:1.33e-02, fs:0.68831 (r=0.535,p=0.964),  time:34.978, tt:7135.507\n",
      "Ep:204, loss:0.00000, loss_test:0.02766, lr:1.32e-02, fs:0.67974 (r=0.525,p=0.963),  time:34.861, tt:7146.570\n",
      "Ep:205, loss:0.00000, loss_test:0.02769, lr:1.30e-02, fs:0.68831 (r=0.535,p=0.964),  time:34.744, tt:7157.356\n",
      "Ep:206, loss:0.00000, loss_test:0.02767, lr:1.29e-02, fs:0.67974 (r=0.525,p=0.963),  time:34.628, tt:7168.087\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.03756, lr:1.00e-02, fs:0.56098 (r=0.465,p=0.708),  time:25.649, tt:25.649\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.02705, lr:1.00e-02, fs:0.59048 (r=0.626,p=0.559),  time:28.882, tt:57.764\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02360, lr:1.00e-02, fs:0.63077 (r=0.828,p=0.509),  time:31.187, tt:93.561\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02324, lr:1.00e-02, fs:0.63273 (r=0.879,p=0.494),  time:31.878, tt:127.511\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02369, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:32.364, tt:161.822\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02409, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:32.824, tt:196.946\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02424, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:33.086, tt:231.604\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02413, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:33.291, tt:266.327\n",
      "Ep:8, loss:0.00004, loss_test:0.02385, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:33.459, tt:301.134\n",
      "Ep:9, loss:0.00004, loss_test:0.02347, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:33.582, tt:335.818\n",
      "Ep:10, loss:0.00004, loss_test:0.02306, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:33.664, tt:370.306\n",
      "Ep:11, loss:0.00004, loss_test:0.02264, lr:1.00e-02, fs:0.64789 (r=0.929,p=0.497),  time:33.779, tt:405.353\n",
      "Ep:12, loss:0.00004, loss_test:0.02220, lr:1.00e-02, fs:0.63799 (r=0.899,p=0.494),  time:33.973, tt:441.648\n",
      "Ep:13, loss:0.00004, loss_test:0.02179, lr:1.00e-02, fs:0.64260 (r=0.899,p=0.500),  time:34.087, tt:477.221\n",
      "Ep:14, loss:0.00004, loss_test:0.02141, lr:1.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:34.133, tt:512.001\n",
      "Ep:15, loss:0.00004, loss_test:0.02108, lr:1.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:34.209, tt:547.346\n",
      "Ep:16, loss:0.00004, loss_test:0.02080, lr:1.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:34.239, tt:582.059\n",
      "Ep:17, loss:0.00004, loss_test:0.02055, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:34.277, tt:616.994\n",
      "Ep:18, loss:0.00004, loss_test:0.02036, lr:9.90e-03, fs:0.65625 (r=0.848,p=0.535),  time:34.330, tt:652.266\n",
      "Ep:19, loss:0.00004, loss_test:0.02021, lr:9.80e-03, fs:0.65354 (r=0.838,p=0.535),  time:34.339, tt:686.790\n",
      "Ep:20, loss:0.00004, loss_test:0.02011, lr:9.70e-03, fs:0.65613 (r=0.838,p=0.539),  time:34.407, tt:722.552\n",
      "Ep:21, loss:0.00004, loss_test:0.02005, lr:9.61e-03, fs:0.66142 (r=0.848,p=0.542),  time:34.519, tt:759.412\n",
      "Ep:22, loss:0.00004, loss_test:0.02000, lr:9.51e-03, fs:0.66406 (r=0.859,p=0.541),  time:34.544, tt:794.502\n",
      "Ep:23, loss:0.00004, loss_test:0.01994, lr:9.41e-03, fs:0.66667 (r=0.859,p=0.545),  time:34.580, tt:829.930\n",
      "Ep:24, loss:0.00003, loss_test:0.01987, lr:9.32e-03, fs:0.66667 (r=0.859,p=0.545),  time:34.614, tt:865.338\n",
      "Ep:25, loss:0.00003, loss_test:0.01979, lr:9.23e-03, fs:0.67188 (r=0.869,p=0.548),  time:34.626, tt:900.269\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01973, lr:9.23e-03, fs:0.66926 (r=0.869,p=0.544),  time:34.683, tt:936.452\n",
      "Ep:27, loss:0.00003, loss_test:0.01965, lr:9.23e-03, fs:0.66406 (r=0.859,p=0.541),  time:34.639, tt:969.900\n",
      "Ep:28, loss:0.00003, loss_test:0.01957, lr:9.23e-03, fs:0.66148 (r=0.859,p=0.538),  time:34.669, tt:1005.395\n",
      "Ep:29, loss:0.00003, loss_test:0.01950, lr:9.23e-03, fs:0.66667 (r=0.869,p=0.541),  time:34.720, tt:1041.613\n",
      "Ep:30, loss:0.00003, loss_test:0.01941, lr:9.23e-03, fs:0.66667 (r=0.869,p=0.541),  time:34.736, tt:1076.812\n",
      "Ep:31, loss:0.00003, loss_test:0.01934, lr:9.23e-03, fs:0.67442 (r=0.879,p=0.547),  time:34.743, tt:1111.787\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01927, lr:9.23e-03, fs:0.67954 (r=0.889,p=0.550),  time:34.755, tt:1146.925\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01919, lr:9.23e-03, fs:0.67954 (r=0.889,p=0.550),  time:34.770, tt:1182.192\n",
      "Ep:34, loss:0.00003, loss_test:0.01912, lr:9.23e-03, fs:0.67954 (r=0.889,p=0.550),  time:34.741, tt:1215.934\n",
      "Ep:35, loss:0.00003, loss_test:0.01906, lr:9.23e-03, fs:0.67954 (r=0.889,p=0.550),  time:34.739, tt:1250.594\n",
      "Ep:36, loss:0.00003, loss_test:0.01900, lr:9.23e-03, fs:0.67954 (r=0.889,p=0.550),  time:34.750, tt:1285.764\n",
      "Ep:37, loss:0.00003, loss_test:0.01895, lr:9.23e-03, fs:0.67442 (r=0.879,p=0.547),  time:34.764, tt:1321.030\n",
      "Ep:38, loss:0.00003, loss_test:0.01889, lr:9.23e-03, fs:0.67704 (r=0.879,p=0.551),  time:34.789, tt:1356.789\n",
      "Ep:39, loss:0.00003, loss_test:0.01881, lr:9.23e-03, fs:0.67969 (r=0.879,p=0.554),  time:34.801, tt:1392.025\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01874, lr:9.23e-03, fs:0.68235 (r=0.879,p=0.558),  time:34.847, tt:1428.728\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01867, lr:9.23e-03, fs:0.68775 (r=0.879,p=0.565),  time:34.867, tt:1464.411\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01860, lr:9.23e-03, fs:0.69048 (r=0.879,p=0.569),  time:34.890, tt:1500.267\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01853, lr:9.23e-03, fs:0.69565 (r=0.889,p=0.571),  time:34.910, tt:1536.025\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01848, lr:9.23e-03, fs:0.69565 (r=0.889,p=0.571),  time:34.897, tt:1570.369\n",
      "Ep:45, loss:0.00003, loss_test:0.01842, lr:9.23e-03, fs:0.69841 (r=0.889,p=0.575),  time:34.869, tt:1603.979\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01837, lr:9.23e-03, fs:0.70120 (r=0.889,p=0.579),  time:34.929, tt:1641.672\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01832, lr:9.23e-03, fs:0.70683 (r=0.889,p=0.587),  time:34.956, tt:1677.893\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01825, lr:9.23e-03, fs:0.70683 (r=0.889,p=0.587),  time:34.988, tt:1714.428\n",
      "Ep:49, loss:0.00003, loss_test:0.01819, lr:9.23e-03, fs:0.70683 (r=0.889,p=0.587),  time:34.975, tt:1748.767\n",
      "Ep:50, loss:0.00003, loss_test:0.01813, lr:9.23e-03, fs:0.69919 (r=0.869,p=0.585),  time:34.964, tt:1783.146\n",
      "Ep:51, loss:0.00003, loss_test:0.01808, lr:9.23e-03, fs:0.70204 (r=0.869,p=0.589),  time:34.988, tt:1819.357\n",
      "Ep:52, loss:0.00003, loss_test:0.01803, lr:9.23e-03, fs:0.70782 (r=0.869,p=0.597),  time:34.976, tt:1853.752\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01798, lr:9.23e-03, fs:0.70248 (r=0.859,p=0.594),  time:34.998, tt:1889.886\n",
      "Ep:54, loss:0.00003, loss_test:0.01793, lr:9.23e-03, fs:0.70248 (r=0.859,p=0.594),  time:34.995, tt:1924.753\n",
      "Ep:55, loss:0.00003, loss_test:0.01791, lr:9.23e-03, fs:0.70248 (r=0.859,p=0.594),  time:35.000, tt:1960.016\n",
      "Ep:56, loss:0.00003, loss_test:0.01787, lr:9.23e-03, fs:0.70248 (r=0.859,p=0.594),  time:35.000, tt:1994.987\n",
      "Ep:57, loss:0.00003, loss_test:0.01783, lr:9.23e-03, fs:0.70539 (r=0.859,p=0.599),  time:34.978, tt:2028.734\n",
      "Ep:58, loss:0.00003, loss_test:0.01780, lr:9.23e-03, fs:0.70539 (r=0.859,p=0.599),  time:34.961, tt:2062.671\n",
      "Ep:59, loss:0.00003, loss_test:0.01778, lr:9.23e-03, fs:0.70539 (r=0.859,p=0.599),  time:34.962, tt:2097.721\n",
      "Ep:60, loss:0.00003, loss_test:0.01775, lr:9.23e-03, fs:0.70000 (r=0.848,p=0.596),  time:34.955, tt:2132.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.01773, lr:9.23e-03, fs:0.69198 (r=0.828,p=0.594),  time:34.975, tt:2168.465\n",
      "Ep:62, loss:0.00003, loss_test:0.01771, lr:9.23e-03, fs:0.68908 (r=0.828,p=0.590),  time:34.980, tt:2203.724\n",
      "Ep:63, loss:0.00003, loss_test:0.01767, lr:9.23e-03, fs:0.68908 (r=0.828,p=0.590),  time:34.984, tt:2239.007\n",
      "Ep:64, loss:0.00003, loss_test:0.01764, lr:9.14e-03, fs:0.68908 (r=0.828,p=0.590),  time:34.989, tt:2274.275\n",
      "Ep:65, loss:0.00003, loss_test:0.01761, lr:9.04e-03, fs:0.68908 (r=0.828,p=0.590),  time:34.986, tt:2309.058\n",
      "Ep:66, loss:0.00003, loss_test:0.01757, lr:8.95e-03, fs:0.68908 (r=0.828,p=0.590),  time:35.015, tt:2346.038\n",
      "Ep:67, loss:0.00003, loss_test:0.01754, lr:8.86e-03, fs:0.69492 (r=0.828,p=0.599),  time:35.025, tt:2381.723\n",
      "Ep:68, loss:0.00002, loss_test:0.01751, lr:8.78e-03, fs:0.69492 (r=0.828,p=0.599),  time:35.049, tt:2418.382\n",
      "Ep:69, loss:0.00002, loss_test:0.01748, lr:8.69e-03, fs:0.69787 (r=0.828,p=0.603),  time:35.061, tt:2454.269\n",
      "Ep:70, loss:0.00002, loss_test:0.01745, lr:8.60e-03, fs:0.70386 (r=0.828,p=0.612),  time:35.065, tt:2489.609\n",
      "Ep:71, loss:0.00002, loss_test:0.01742, lr:8.51e-03, fs:0.70386 (r=0.828,p=0.612),  time:35.071, tt:2525.092\n",
      "Ep:72, loss:0.00002, loss_test:0.01741, lr:8.43e-03, fs:0.70386 (r=0.828,p=0.612),  time:35.082, tt:2561.015\n",
      "Ep:73, loss:0.00002, loss_test:0.01738, lr:8.35e-03, fs:0.70996 (r=0.828,p=0.621),  time:35.088, tt:2596.489\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00002, loss_test:0.01734, lr:8.35e-03, fs:0.70996 (r=0.828,p=0.621),  time:35.104, tt:2632.770\n",
      "Ep:75, loss:0.00002, loss_test:0.01733, lr:8.35e-03, fs:0.71304 (r=0.828,p=0.626),  time:35.115, tt:2668.750\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.01731, lr:8.35e-03, fs:0.71304 (r=0.828,p=0.626),  time:35.124, tt:2704.569\n",
      "Ep:77, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.71304 (r=0.828,p=0.626),  time:35.143, tt:2741.156\n",
      "Ep:78, loss:0.00002, loss_test:0.01728, lr:8.35e-03, fs:0.71304 (r=0.828,p=0.626),  time:35.176, tt:2778.912\n",
      "Ep:79, loss:0.00002, loss_test:0.01726, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.186, tt:2814.899\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.01726, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.181, tt:2849.651\n",
      "Ep:81, loss:0.00002, loss_test:0.01724, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.177, tt:2884.542\n",
      "Ep:82, loss:0.00002, loss_test:0.01722, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.185, tt:2920.350\n",
      "Ep:83, loss:0.00002, loss_test:0.01719, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.223, tt:2958.705\n",
      "Ep:84, loss:0.00002, loss_test:0.01717, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.232, tt:2994.723\n",
      "Ep:85, loss:0.00002, loss_test:0.01715, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.248, tt:3031.348\n",
      "Ep:86, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.268, tt:3068.290\n",
      "Ep:87, loss:0.00002, loss_test:0.01713, lr:8.35e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.298, tt:3106.219\n",
      "Ep:88, loss:0.00002, loss_test:0.01712, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:35.330, tt:3144.383\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00002, loss_test:0.01711, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:35.349, tt:3181.382\n",
      "Ep:90, loss:0.00002, loss_test:0.01711, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:35.367, tt:3218.417\n",
      "Ep:91, loss:0.00002, loss_test:0.01710, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:35.387, tt:3255.640\n",
      "Ep:92, loss:0.00002, loss_test:0.01709, lr:8.35e-03, fs:0.72489 (r=0.838,p=0.638),  time:35.403, tt:3292.459\n",
      "Ep:93, loss:0.00002, loss_test:0.01708, lr:8.35e-03, fs:0.72807 (r=0.838,p=0.643),  time:35.408, tt:3328.331\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.01707, lr:8.35e-03, fs:0.73128 (r=0.838,p=0.648),  time:35.406, tt:3363.614\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.01707, lr:8.35e-03, fs:0.73128 (r=0.838,p=0.648),  time:35.409, tt:3399.251\n",
      "Ep:96, loss:0.00002, loss_test:0.01706, lr:8.35e-03, fs:0.73128 (r=0.838,p=0.648),  time:35.400, tt:3433.829\n",
      "Ep:97, loss:0.00002, loss_test:0.01705, lr:8.35e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.406, tt:3469.798\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.01704, lr:8.35e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.403, tt:3504.902\n",
      "Ep:99, loss:0.00002, loss_test:0.01704, lr:8.35e-03, fs:0.73778 (r=0.838,p=0.659),  time:35.409, tt:3540.865\n",
      "Ep:100, loss:0.00002, loss_test:0.01706, lr:8.35e-03, fs:0.74667 (r=0.848,p=0.667),  time:35.417, tt:3577.112\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00002, loss_test:0.01705, lr:8.35e-03, fs:0.75000 (r=0.848,p=0.672),  time:35.410, tt:3611.849\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00002, loss_test:0.01705, lr:8.35e-03, fs:0.75000 (r=0.848,p=0.672),  time:35.403, tt:3646.464\n",
      "Ep:103, loss:0.00002, loss_test:0.01707, lr:8.35e-03, fs:0.75000 (r=0.848,p=0.672),  time:35.401, tt:3681.689\n",
      "Ep:104, loss:0.00002, loss_test:0.01707, lr:8.35e-03, fs:0.75000 (r=0.848,p=0.672),  time:35.393, tt:3716.229\n",
      "Ep:105, loss:0.00002, loss_test:0.01707, lr:8.35e-03, fs:0.75676 (r=0.848,p=0.683),  time:35.372, tt:3749.392\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.01708, lr:8.35e-03, fs:0.76018 (r=0.848,p=0.689),  time:35.359, tt:3783.420\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01709, lr:8.35e-03, fs:0.76018 (r=0.848,p=0.689),  time:35.349, tt:3817.710\n",
      "Ep:108, loss:0.00002, loss_test:0.01710, lr:8.35e-03, fs:0.76018 (r=0.848,p=0.689),  time:35.340, tt:3852.109\n",
      "Ep:109, loss:0.00002, loss_test:0.01711, lr:8.35e-03, fs:0.76018 (r=0.848,p=0.689),  time:35.341, tt:3887.504\n",
      "Ep:110, loss:0.00002, loss_test:0.01711, lr:8.35e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.332, tt:3921.899\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.01712, lr:8.35e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.333, tt:3957.313\n",
      "Ep:112, loss:0.00002, loss_test:0.01712, lr:8.35e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.335, tt:3992.887\n",
      "Ep:113, loss:0.00002, loss_test:0.01713, lr:8.35e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.328, tt:4027.386\n",
      "Ep:114, loss:0.00002, loss_test:0.01713, lr:8.35e-03, fs:0.76364 (r=0.848,p=0.694),  time:35.334, tt:4063.353\n",
      "Ep:115, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.343, tt:4099.829\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.332, tt:4133.814\n",
      "Ep:117, loss:0.00002, loss_test:0.01715, lr:8.35e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.315, tt:4167.130\n",
      "Ep:118, loss:0.00002, loss_test:0.01717, lr:8.35e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.314, tt:4202.414\n",
      "Ep:119, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.76712 (r=0.848,p=0.700),  time:35.312, tt:4237.440\n",
      "Ep:120, loss:0.00002, loss_test:0.01715, lr:8.35e-03, fs:0.76147 (r=0.838,p=0.697),  time:35.295, tt:4270.719\n",
      "Ep:121, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.76498 (r=0.838,p=0.703),  time:35.305, tt:4307.238\n",
      "Ep:122, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.76498 (r=0.838,p=0.703),  time:35.309, tt:4343.065\n",
      "Ep:123, loss:0.00002, loss_test:0.01717, lr:8.35e-03, fs:0.76498 (r=0.838,p=0.703),  time:35.304, tt:4377.701\n",
      "Ep:124, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.76498 (r=0.838,p=0.703),  time:35.311, tt:4413.856\n",
      "Ep:125, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.77209 (r=0.838,p=0.716),  time:35.302, tt:4448.109\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00002, loss_test:0.01714, lr:8.35e-03, fs:0.77209 (r=0.838,p=0.716),  time:35.337, tt:4487.816\n",
      "Ep:127, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.77209 (r=0.838,p=0.716),  time:35.335, tt:4522.939\n",
      "Ep:128, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.77934 (r=0.838,p=0.728),  time:35.338, tt:4558.581\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00002, loss_test:0.01717, lr:8.35e-03, fs:0.77358 (r=0.828,p=0.726),  time:35.340, tt:4594.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.77725 (r=0.828,p=0.732),  time:35.338, tt:4629.318\n",
      "Ep:131, loss:0.00002, loss_test:0.01716, lr:8.35e-03, fs:0.77725 (r=0.828,p=0.732),  time:35.342, tt:4665.089\n",
      "Ep:132, loss:0.00002, loss_test:0.01717, lr:8.35e-03, fs:0.77725 (r=0.828,p=0.732),  time:35.342, tt:4700.496\n",
      "Ep:133, loss:0.00002, loss_test:0.01719, lr:8.35e-03, fs:0.78095 (r=0.828,p=0.739),  time:35.336, tt:4735.020\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00002, loss_test:0.01719, lr:8.35e-03, fs:0.78095 (r=0.828,p=0.739),  time:35.334, tt:4770.081\n",
      "Ep:135, loss:0.00002, loss_test:0.01720, lr:8.35e-03, fs:0.79227 (r=0.828,p=0.759),  time:35.344, tt:4806.732\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00002, loss_test:0.01722, lr:8.35e-03, fs:0.79227 (r=0.828,p=0.759),  time:35.339, tt:4841.493\n",
      "Ep:137, loss:0.00002, loss_test:0.01721, lr:8.35e-03, fs:0.79612 (r=0.828,p=0.766),  time:35.341, tt:4877.056\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00002, loss_test:0.01720, lr:8.35e-03, fs:0.79227 (r=0.828,p=0.759),  time:35.337, tt:4911.782\n",
      "Ep:139, loss:0.00002, loss_test:0.01721, lr:8.35e-03, fs:0.79227 (r=0.828,p=0.759),  time:35.343, tt:4948.041\n",
      "Ep:140, loss:0.00002, loss_test:0.01724, lr:8.35e-03, fs:0.79612 (r=0.828,p=0.766),  time:35.342, tt:4983.236\n",
      "Ep:141, loss:0.00002, loss_test:0.01724, lr:8.35e-03, fs:0.79612 (r=0.828,p=0.766),  time:35.345, tt:5018.999\n",
      "Ep:142, loss:0.00002, loss_test:0.01723, lr:8.35e-03, fs:0.80000 (r=0.828,p=0.774),  time:35.341, tt:5053.826\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00002, loss_test:0.01724, lr:8.35e-03, fs:0.80000 (r=0.828,p=0.774),  time:35.341, tt:5089.050\n",
      "Ep:144, loss:0.00002, loss_test:0.01724, lr:8.35e-03, fs:0.80000 (r=0.828,p=0.774),  time:35.341, tt:5124.447\n",
      "Ep:145, loss:0.00002, loss_test:0.01726, lr:8.35e-03, fs:0.80392 (r=0.828,p=0.781),  time:35.341, tt:5159.721\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00002, loss_test:0.01726, lr:8.35e-03, fs:0.80000 (r=0.828,p=0.774),  time:35.331, tt:5193.718\n",
      "Ep:147, loss:0.00002, loss_test:0.01725, lr:8.35e-03, fs:0.80000 (r=0.828,p=0.774),  time:35.334, tt:5229.476\n",
      "Ep:148, loss:0.00002, loss_test:0.01727, lr:8.35e-03, fs:0.80392 (r=0.828,p=0.781),  time:35.333, tt:5264.603\n",
      "Ep:149, loss:0.00002, loss_test:0.01728, lr:8.35e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.336, tt:5300.367\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00002, loss_test:0.01729, lr:8.35e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.337, tt:5335.827\n",
      "Ep:151, loss:0.00002, loss_test:0.01729, lr:8.35e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.343, tt:5372.082\n",
      "Ep:152, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.80788 (r=0.828,p=0.788),  time:35.333, tt:5406.005\n",
      "Ep:153, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.81592 (r=0.828,p=0.804),  time:35.337, tt:5441.915\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.81592 (r=0.828,p=0.804),  time:35.334, tt:5476.742\n",
      "Ep:155, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.329, tt:5511.390\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.331, tt:5547.018\n",
      "Ep:157, loss:0.00002, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.325, tt:5581.309\n",
      "Ep:158, loss:0.00002, loss_test:0.01730, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.326, tt:5616.760\n",
      "Ep:159, loss:0.00002, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.326, tt:5652.223\n",
      "Ep:160, loss:0.00001, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.341, tt:5689.951\n",
      "Ep:161, loss:0.00001, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.343, tt:5725.551\n",
      "Ep:162, loss:0.00001, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.338, tt:5760.166\n",
      "Ep:163, loss:0.00001, loss_test:0.01732, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.344, tt:5796.424\n",
      "Ep:164, loss:0.00001, loss_test:0.01731, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.341, tt:5831.232\n",
      "Ep:165, loss:0.00001, loss_test:0.01733, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.343, tt:5866.902\n",
      "Ep:166, loss:0.00001, loss_test:0.01730, lr:8.35e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.343, tt:5902.346\n",
      "Ep:167, loss:0.00001, loss_test:0.01731, lr:8.26e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.355, tt:5939.653\n",
      "Ep:168, loss:0.00001, loss_test:0.01731, lr:8.18e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.357, tt:5975.328\n",
      "Ep:169, loss:0.00001, loss_test:0.01731, lr:8.10e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.358, tt:6010.814\n",
      "Ep:170, loss:0.00001, loss_test:0.01732, lr:8.02e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.365, tt:6047.342\n",
      "Ep:171, loss:0.00001, loss_test:0.01731, lr:7.94e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.367, tt:6083.109\n",
      "Ep:172, loss:0.00001, loss_test:0.01731, lr:7.86e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.377, tt:6120.139\n",
      "Ep:173, loss:0.00001, loss_test:0.01730, lr:7.78e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.386, tt:6157.110\n",
      "Ep:174, loss:0.00001, loss_test:0.01730, lr:7.70e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.387, tt:6192.718\n",
      "Ep:175, loss:0.00001, loss_test:0.01731, lr:7.62e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.393, tt:6229.144\n",
      "Ep:176, loss:0.00001, loss_test:0.01734, lr:7.55e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.401, tt:6265.963\n",
      "Ep:177, loss:0.00001, loss_test:0.01734, lr:7.47e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.390, tt:6299.444\n",
      "Ep:178, loss:0.00001, loss_test:0.01734, lr:7.40e-03, fs:0.82000 (r=0.828,p=0.812),  time:35.389, tt:6334.699\n",
      "Ep:179, loss:0.00001, loss_test:0.01733, lr:7.32e-03, fs:0.82412 (r=0.828,p=0.820),  time:35.394, tt:6370.982\n",
      "##########Best model found so far##########\n",
      "Ep:180, loss:0.00001, loss_test:0.01735, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.396, tt:6406.680\n",
      "##########Best model found so far##########\n",
      "Ep:181, loss:0.00001, loss_test:0.01735, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.399, tt:6442.565\n",
      "Ep:182, loss:0.00001, loss_test:0.01737, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.395, tt:6477.369\n",
      "Ep:183, loss:0.00001, loss_test:0.01736, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.398, tt:6513.151\n",
      "Ep:184, loss:0.00001, loss_test:0.01733, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.398, tt:6548.653\n",
      "Ep:185, loss:0.00001, loss_test:0.01734, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.402, tt:6584.767\n",
      "Ep:186, loss:0.00001, loss_test:0.01736, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.397, tt:6619.319\n",
      "Ep:187, loss:0.00001, loss_test:0.01738, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.393, tt:6653.858\n",
      "Ep:188, loss:0.00001, loss_test:0.01736, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.406, tt:6691.761\n",
      "Ep:189, loss:0.00001, loss_test:0.01736, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.407, tt:6727.389\n",
      "Ep:190, loss:0.00001, loss_test:0.01735, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.404, tt:6762.132\n",
      "Ep:191, loss:0.00001, loss_test:0.01736, lr:7.32e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.405, tt:6797.680\n",
      "Ep:192, loss:0.00001, loss_test:0.01737, lr:7.25e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.406, tt:6833.387\n",
      "Ep:193, loss:0.00001, loss_test:0.01738, lr:7.18e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.405, tt:6868.562\n",
      "Ep:194, loss:0.00001, loss_test:0.01740, lr:7.11e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.401, tt:6903.200\n",
      "Ep:195, loss:0.00001, loss_test:0.01740, lr:7.03e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.392, tt:6936.883\n",
      "Ep:196, loss:0.00001, loss_test:0.01737, lr:6.96e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.391, tt:6972.083\n",
      "Ep:197, loss:0.00001, loss_test:0.01739, lr:6.89e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.394, tt:7007.970\n",
      "Ep:198, loss:0.00001, loss_test:0.01742, lr:6.83e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.395, tt:7043.693\n",
      "Ep:199, loss:0.00001, loss_test:0.01741, lr:6.76e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.396, tt:7079.216\n",
      "Ep:200, loss:0.00001, loss_test:0.01740, lr:6.69e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.396, tt:7114.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00001, loss_test:0.01739, lr:6.62e-03, fs:0.82828 (r=0.828,p=0.828),  time:35.393, tt:7149.404\n",
      "Ep:202, loss:0.00001, loss_test:0.01740, lr:6.56e-03, fs:0.83249 (r=0.828,p=0.837),  time:35.396, tt:7185.359\n",
      "##########Best model found so far##########\n",
      "Ep:203, loss:0.00001, loss_test:0.01740, lr:6.56e-03, fs:0.83249 (r=0.828,p=0.837),  time:35.396, tt:7220.816\n",
      "Ep:204, loss:0.00001, loss_test:0.01740, lr:6.56e-03, fs:0.82653 (r=0.818,p=0.835),  time:35.387, tt:7254.427\n",
      "Ep:205, loss:0.00001, loss_test:0.01741, lr:6.56e-03, fs:0.82653 (r=0.818,p=0.835),  time:35.354, tt:7282.846\n",
      "Ep:206, loss:0.00001, loss_test:0.01740, lr:6.56e-03, fs:0.82653 (r=0.818,p=0.835),  time:35.324, tt:7312.126\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02833, lr:1.00e-02, fs:0.58286 (r=0.515,p=0.671),  time:32.903, tt:32.903\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02337, lr:1.00e-02, fs:0.58605 (r=0.636,p=0.543),  time:36.502, tt:73.005\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02157, lr:1.00e-02, fs:0.61719 (r=0.798,p=0.503),  time:37.336, tt:112.007\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02155, lr:1.00e-02, fs:0.64057 (r=0.909,p=0.495),  time:37.720, tt:150.878\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02201, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:37.442, tt:187.208\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02233, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:37.499, tt:224.992\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02240, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:37.800, tt:264.601\n",
      "Ep:7, loss:0.00004, loss_test:0.02225, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:37.935, tt:303.477\n",
      "Ep:8, loss:0.00004, loss_test:0.02195, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:38.204, tt:343.833\n",
      "Ep:9, loss:0.00004, loss_test:0.02153, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:38.230, tt:382.297\n",
      "Ep:10, loss:0.00004, loss_test:0.02108, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:38.386, tt:422.247\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02064, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:38.447, tt:461.361\n",
      "Ep:12, loss:0.00004, loss_test:0.02027, lr:1.00e-02, fs:0.65000 (r=0.919,p=0.503),  time:38.482, tt:500.265\n",
      "Ep:13, loss:0.00004, loss_test:0.02000, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:38.449, tt:538.284\n",
      "Ep:14, loss:0.00004, loss_test:0.01982, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:38.469, tt:577.038\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01970, lr:1.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:38.578, tt:617.240\n",
      "Ep:16, loss:0.00003, loss_test:0.01961, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:38.543, tt:655.233\n",
      "Ep:17, loss:0.00003, loss_test:0.01951, lr:1.00e-02, fs:0.64516 (r=0.808,p=0.537),  time:38.604, tt:694.880\n",
      "Ep:18, loss:0.00003, loss_test:0.01940, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:38.601, tt:733.416\n",
      "Ep:19, loss:0.00003, loss_test:0.01928, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:38.607, tt:772.134\n",
      "Ep:20, loss:0.00003, loss_test:0.01917, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:38.606, tt:810.721\n",
      "Ep:21, loss:0.00003, loss_test:0.01908, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:38.629, tt:849.828\n",
      "Ep:22, loss:0.00003, loss_test:0.01901, lr:1.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:38.543, tt:886.479\n",
      "Ep:23, loss:0.00003, loss_test:0.01896, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.547, tt:925.134\n",
      "Ep:24, loss:0.00003, loss_test:0.01890, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.624, tt:965.589\n",
      "Ep:25, loss:0.00003, loss_test:0.01882, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.590, tt:1003.344\n",
      "Ep:26, loss:0.00003, loss_test:0.01873, lr:9.90e-03, fs:0.66929 (r=0.859,p=0.548),  time:38.660, tt:1043.816\n",
      "Ep:27, loss:0.00003, loss_test:0.01864, lr:9.80e-03, fs:0.67194 (r=0.859,p=0.552),  time:38.637, tt:1081.825\n",
      "Ep:28, loss:0.00003, loss_test:0.01857, lr:9.70e-03, fs:0.67460 (r=0.859,p=0.556),  time:38.583, tt:1118.904\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01850, lr:9.70e-03, fs:0.68000 (r=0.859,p=0.563),  time:38.547, tt:1156.406\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01844, lr:9.70e-03, fs:0.68000 (r=0.859,p=0.563),  time:38.588, tt:1196.215\n",
      "Ep:31, loss:0.00003, loss_test:0.01840, lr:9.70e-03, fs:0.67470 (r=0.848,p=0.560),  time:38.586, tt:1234.746\n",
      "Ep:32, loss:0.00003, loss_test:0.01835, lr:9.70e-03, fs:0.68016 (r=0.848,p=0.568),  time:38.620, tt:1274.465\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01831, lr:9.70e-03, fs:0.68293 (r=0.848,p=0.571),  time:38.617, tt:1312.979\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01827, lr:9.70e-03, fs:0.68293 (r=0.848,p=0.571),  time:38.572, tt:1350.017\n",
      "Ep:35, loss:0.00003, loss_test:0.01824, lr:9.70e-03, fs:0.68571 (r=0.848,p=0.575),  time:38.587, tt:1389.125\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01820, lr:9.70e-03, fs:0.68571 (r=0.848,p=0.575),  time:38.622, tt:1428.997\n",
      "Ep:37, loss:0.00003, loss_test:0.01816, lr:9.70e-03, fs:0.68571 (r=0.848,p=0.575),  time:38.582, tt:1466.111\n",
      "Ep:38, loss:0.00003, loss_test:0.01812, lr:9.70e-03, fs:0.68852 (r=0.848,p=0.579),  time:38.580, tt:1504.618\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01809, lr:9.70e-03, fs:0.69421 (r=0.848,p=0.587),  time:38.599, tt:1543.978\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01806, lr:9.70e-03, fs:0.69136 (r=0.848,p=0.583),  time:38.597, tt:1582.472\n",
      "Ep:41, loss:0.00003, loss_test:0.01802, lr:9.70e-03, fs:0.69136 (r=0.848,p=0.583),  time:38.570, tt:1619.926\n",
      "Ep:42, loss:0.00003, loss_test:0.01799, lr:9.70e-03, fs:0.69959 (r=0.859,p=0.590),  time:38.525, tt:1656.569\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00003, loss_test:0.01796, lr:9.70e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.524, tt:1695.072\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01793, lr:9.70e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.562, tt:1735.268\n",
      "Ep:45, loss:0.00003, loss_test:0.01789, lr:9.70e-03, fs:0.70539 (r=0.859,p=0.599),  time:38.565, tt:1774.002\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01786, lr:9.70e-03, fs:0.70539 (r=0.859,p=0.599),  time:38.580, tt:1813.281\n",
      "Ep:47, loss:0.00003, loss_test:0.01782, lr:9.70e-03, fs:0.70293 (r=0.848,p=0.600),  time:38.566, tt:1851.145\n",
      "Ep:48, loss:0.00003, loss_test:0.01779, lr:9.70e-03, fs:0.70588 (r=0.848,p=0.604),  time:38.519, tt:1887.421\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01776, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.516, tt:1925.814\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01774, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.523, tt:1964.693\n",
      "Ep:51, loss:0.00003, loss_test:0.01771, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.516, tt:2002.811\n",
      "Ep:52, loss:0.00003, loss_test:0.01768, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.507, tt:2040.878\n",
      "Ep:53, loss:0.00003, loss_test:0.01765, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.505, tt:2079.292\n",
      "Ep:54, loss:0.00003, loss_test:0.01763, lr:9.70e-03, fs:0.70886 (r=0.848,p=0.609),  time:38.462, tt:2115.420\n",
      "Ep:55, loss:0.00003, loss_test:0.01760, lr:9.70e-03, fs:0.71795 (r=0.848,p=0.622),  time:38.441, tt:2152.699\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01757, lr:9.70e-03, fs:0.72103 (r=0.848,p=0.627),  time:38.442, tt:2191.216\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00003, loss_test:0.01754, lr:9.70e-03, fs:0.72103 (r=0.848,p=0.627),  time:38.437, tt:2229.367\n",
      "Ep:58, loss:0.00003, loss_test:0.01751, lr:9.70e-03, fs:0.72103 (r=0.848,p=0.627),  time:38.424, tt:2266.998\n",
      "Ep:59, loss:0.00003, loss_test:0.01748, lr:9.70e-03, fs:0.71795 (r=0.848,p=0.622),  time:38.378, tt:2302.677\n",
      "Ep:60, loss:0.00002, loss_test:0.01745, lr:9.70e-03, fs:0.72103 (r=0.848,p=0.627),  time:38.362, tt:2340.072\n",
      "Ep:61, loss:0.00002, loss_test:0.01743, lr:9.70e-03, fs:0.72414 (r=0.848,p=0.632),  time:38.351, tt:2377.763\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01740, lr:9.70e-03, fs:0.72414 (r=0.848,p=0.632),  time:38.369, tt:2417.217\n",
      "Ep:63, loss:0.00002, loss_test:0.01738, lr:9.70e-03, fs:0.72414 (r=0.848,p=0.632),  time:38.362, tt:2455.168\n",
      "Ep:64, loss:0.00002, loss_test:0.01736, lr:9.70e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.374, tt:2494.321\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.01734, lr:9.70e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.404, tt:2534.690\n",
      "Ep:66, loss:0.00002, loss_test:0.01731, lr:9.70e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.424, tt:2574.437\n",
      "Ep:67, loss:0.00002, loss_test:0.01729, lr:9.70e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.424, tt:2612.813\n",
      "Ep:68, loss:0.00002, loss_test:0.01726, lr:9.70e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.420, tt:2650.968\n",
      "Ep:69, loss:0.00002, loss_test:0.01724, lr:9.70e-03, fs:0.73043 (r=0.848,p=0.641),  time:38.415, tt:2689.026\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.01722, lr:9.70e-03, fs:0.73043 (r=0.848,p=0.641),  time:38.392, tt:2725.851\n",
      "Ep:71, loss:0.00002, loss_test:0.01720, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.412, tt:2765.695\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.01718, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.435, tt:2805.723\n",
      "Ep:73, loss:0.00002, loss_test:0.01717, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.452, tt:2845.454\n",
      "Ep:74, loss:0.00002, loss_test:0.01716, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.454, tt:2884.022\n",
      "Ep:75, loss:0.00002, loss_test:0.01715, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.438, tt:2921.253\n",
      "Ep:76, loss:0.00002, loss_test:0.01713, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.427, tt:2958.916\n",
      "Ep:77, loss:0.00002, loss_test:0.01712, lr:9.70e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.451, tt:2999.207\n",
      "Ep:78, loss:0.00002, loss_test:0.01711, lr:9.70e-03, fs:0.74009 (r=0.848,p=0.656),  time:38.455, tt:3037.962\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.01709, lr:9.70e-03, fs:0.74009 (r=0.848,p=0.656),  time:38.438, tt:3075.028\n",
      "Ep:80, loss:0.00002, loss_test:0.01707, lr:9.70e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.453, tt:3114.664\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01706, lr:9.70e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.426, tt:3150.953\n",
      "Ep:82, loss:0.00002, loss_test:0.01704, lr:9.70e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.447, tt:3191.067\n",
      "Ep:83, loss:0.00002, loss_test:0.01703, lr:9.70e-03, fs:0.74890 (r=0.859,p=0.664),  time:38.455, tt:3230.182\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.01702, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.454, tt:3268.566\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.01701, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.439, tt:3305.735\n",
      "Ep:86, loss:0.00002, loss_test:0.01700, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.426, tt:3343.058\n",
      "Ep:87, loss:0.00002, loss_test:0.01699, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.425, tt:3381.390\n",
      "Ep:88, loss:0.00002, loss_test:0.01698, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.406, tt:3418.154\n",
      "Ep:89, loss:0.00002, loss_test:0.01697, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.410, tt:3456.893\n",
      "Ep:90, loss:0.00002, loss_test:0.01695, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.407, tt:3495.036\n",
      "Ep:91, loss:0.00002, loss_test:0.01694, lr:9.70e-03, fs:0.75221 (r=0.859,p=0.669),  time:38.417, tt:3534.390\n",
      "Ep:92, loss:0.00002, loss_test:0.01693, lr:9.70e-03, fs:0.75556 (r=0.859,p=0.675),  time:38.414, tt:3572.516\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.01692, lr:9.70e-03, fs:0.75556 (r=0.859,p=0.675),  time:38.420, tt:3611.445\n",
      "Ep:94, loss:0.00002, loss_test:0.01692, lr:9.70e-03, fs:0.75556 (r=0.859,p=0.675),  time:38.402, tt:3648.157\n",
      "Ep:95, loss:0.00002, loss_test:0.01691, lr:9.70e-03, fs:0.75556 (r=0.859,p=0.675),  time:38.435, tt:3689.744\n",
      "Ep:96, loss:0.00002, loss_test:0.01689, lr:9.70e-03, fs:0.76233 (r=0.859,p=0.685),  time:38.455, tt:3730.118\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.01687, lr:9.70e-03, fs:0.76923 (r=0.859,p=0.697),  time:38.445, tt:3767.623\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.01686, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.442, tt:3805.796\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.01685, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.442, tt:3844.161\n",
      "Ep:100, loss:0.00002, loss_test:0.01684, lr:9.70e-03, fs:0.76923 (r=0.859,p=0.697),  time:38.438, tt:3882.253\n",
      "Ep:101, loss:0.00002, loss_test:0.01684, lr:9.70e-03, fs:0.76923 (r=0.859,p=0.697),  time:38.445, tt:3921.369\n",
      "Ep:102, loss:0.00002, loss_test:0.01683, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.451, tt:3960.404\n",
      "Ep:103, loss:0.00002, loss_test:0.01681, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.439, tt:3997.705\n",
      "Ep:104, loss:0.00002, loss_test:0.01681, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.435, tt:4035.675\n",
      "Ep:105, loss:0.00002, loss_test:0.01679, lr:9.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:38.423, tt:4072.790\n",
      "Ep:106, loss:0.00002, loss_test:0.01678, lr:9.70e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.423, tt:4111.282\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01677, lr:9.70e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.417, tt:4149.067\n",
      "Ep:108, loss:0.00002, loss_test:0.01675, lr:9.70e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.419, tt:4187.638\n",
      "Ep:109, loss:0.00002, loss_test:0.01673, lr:9.70e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.406, tt:4224.672\n",
      "Ep:110, loss:0.00002, loss_test:0.01671, lr:9.70e-03, fs:0.77982 (r=0.859,p=0.714),  time:38.405, tt:4262.995\n",
      "Ep:111, loss:0.00002, loss_test:0.01669, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:38.401, tt:4300.881\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.01668, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:38.419, tt:4341.314\n",
      "Ep:113, loss:0.00002, loss_test:0.01666, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:38.402, tt:4377.865\n",
      "Ep:114, loss:0.00002, loss_test:0.01665, lr:9.70e-03, fs:0.78341 (r=0.859,p=0.720),  time:38.405, tt:4416.524\n",
      "Ep:115, loss:0.00002, loss_test:0.01664, lr:9.70e-03, fs:0.78704 (r=0.859,p=0.726),  time:38.392, tt:4453.491\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.01663, lr:9.70e-03, fs:0.78704 (r=0.859,p=0.726),  time:38.389, tt:4491.459\n",
      "Ep:117, loss:0.00002, loss_test:0.01661, lr:9.70e-03, fs:0.78704 (r=0.859,p=0.726),  time:38.406, tt:4531.883\n",
      "Ep:118, loss:0.00002, loss_test:0.01661, lr:9.70e-03, fs:0.79070 (r=0.859,p=0.733),  time:38.405, tt:4570.153\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00002, loss_test:0.01660, lr:9.70e-03, fs:0.79439 (r=0.859,p=0.739),  time:38.410, tt:4609.238\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.01659, lr:9.70e-03, fs:0.79439 (r=0.859,p=0.739),  time:38.432, tt:4650.245\n",
      "Ep:121, loss:0.00002, loss_test:0.01659, lr:9.70e-03, fs:0.79439 (r=0.859,p=0.739),  time:38.435, tt:4689.079\n",
      "Ep:122, loss:0.00002, loss_test:0.01658, lr:9.70e-03, fs:0.79439 (r=0.859,p=0.739),  time:38.438, tt:4727.883\n",
      "Ep:123, loss:0.00002, loss_test:0.01657, lr:9.70e-03, fs:0.79812 (r=0.859,p=0.746),  time:38.428, tt:4765.130\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00002, loss_test:0.01656, lr:9.70e-03, fs:0.79812 (r=0.859,p=0.746),  time:38.439, tt:4804.920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00002, loss_test:0.01656, lr:9.70e-03, fs:0.79812 (r=0.859,p=0.746),  time:38.449, tt:4844.515\n",
      "Ep:126, loss:0.00002, loss_test:0.01655, lr:9.70e-03, fs:0.80569 (r=0.859,p=0.759),  time:38.456, tt:4883.949\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.01654, lr:9.70e-03, fs:0.80569 (r=0.859,p=0.759),  time:38.478, tt:4925.234\n",
      "Ep:128, loss:0.00002, loss_test:0.01654, lr:9.70e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.492, tt:4965.492\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00002, loss_test:0.01653, lr:9.70e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.480, tt:5002.431\n",
      "Ep:130, loss:0.00002, loss_test:0.01652, lr:9.70e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.483, tt:5041.278\n",
      "Ep:131, loss:0.00002, loss_test:0.01651, lr:9.70e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.486, tt:5080.118\n",
      "Ep:132, loss:0.00002, loss_test:0.01651, lr:9.70e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.483, tt:5118.289\n",
      "Ep:133, loss:0.00002, loss_test:0.01651, lr:9.70e-03, fs:0.81340 (r=0.859,p=0.773),  time:38.490, tt:5157.708\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00002, loss_test:0.01650, lr:9.70e-03, fs:0.81340 (r=0.859,p=0.773),  time:38.494, tt:5196.745\n",
      "Ep:135, loss:0.00002, loss_test:0.01648, lr:9.70e-03, fs:0.81340 (r=0.859,p=0.773),  time:38.475, tt:5232.552\n",
      "Ep:136, loss:0.00002, loss_test:0.01648, lr:9.70e-03, fs:0.81731 (r=0.859,p=0.780),  time:38.478, tt:5271.543\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00002, loss_test:0.01648, lr:9.70e-03, fs:0.81731 (r=0.859,p=0.780),  time:38.464, tt:5308.058\n",
      "Ep:138, loss:0.00002, loss_test:0.01647, lr:9.70e-03, fs:0.82126 (r=0.859,p=0.787),  time:38.466, tt:5346.722\n",
      "##########Best model found so far##########\n",
      "Ep:139, loss:0.00002, loss_test:0.01647, lr:9.70e-03, fs:0.82126 (r=0.859,p=0.787),  time:38.477, tt:5386.755\n",
      "Ep:140, loss:0.00002, loss_test:0.01645, lr:9.70e-03, fs:0.82126 (r=0.859,p=0.787),  time:38.473, tt:5424.719\n",
      "Ep:141, loss:0.00002, loss_test:0.01644, lr:9.70e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.475, tt:5463.389\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00002, loss_test:0.01643, lr:9.70e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.473, tt:5501.653\n",
      "Ep:143, loss:0.00002, loss_test:0.01643, lr:9.70e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.483, tt:5541.596\n",
      "Ep:144, loss:0.00002, loss_test:0.01643, lr:9.70e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.504, tt:5583.038\n",
      "Ep:145, loss:0.00002, loss_test:0.01642, lr:9.70e-03, fs:0.82524 (r=0.859,p=0.794),  time:38.512, tt:5622.695\n",
      "Ep:146, loss:0.00002, loss_test:0.01642, lr:9.70e-03, fs:0.82927 (r=0.859,p=0.802),  time:38.518, tt:5662.140\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00002, loss_test:0.01641, lr:9.70e-03, fs:0.82927 (r=0.859,p=0.802),  time:38.514, tt:5700.132\n",
      "Ep:148, loss:0.00002, loss_test:0.01640, lr:9.70e-03, fs:0.82927 (r=0.859,p=0.802),  time:38.516, tt:5738.854\n",
      "Ep:149, loss:0.00002, loss_test:0.01640, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.513, tt:5776.970\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00002, loss_test:0.01639, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.509, tt:5814.910\n",
      "Ep:151, loss:0.00002, loss_test:0.01637, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.512, tt:5853.822\n",
      "Ep:152, loss:0.00002, loss_test:0.01636, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.510, tt:5892.010\n",
      "Ep:153, loss:0.00002, loss_test:0.01634, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.515, tt:5931.305\n",
      "Ep:154, loss:0.00002, loss_test:0.01633, lr:9.70e-03, fs:0.83333 (r=0.859,p=0.810),  time:38.525, tt:5971.433\n",
      "Ep:155, loss:0.00002, loss_test:0.01632, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.517, tt:6008.593\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00002, loss_test:0.01632, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.509, tt:6045.902\n",
      "Ep:157, loss:0.00002, loss_test:0.01631, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.510, tt:6084.619\n",
      "Ep:158, loss:0.00002, loss_test:0.01630, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.493, tt:6120.321\n",
      "Ep:159, loss:0.00002, loss_test:0.01629, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.491, tt:6158.632\n",
      "Ep:160, loss:0.00002, loss_test:0.01628, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.521, tt:6201.863\n",
      "Ep:161, loss:0.00002, loss_test:0.01628, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.519, tt:6240.070\n",
      "Ep:162, loss:0.00001, loss_test:0.01627, lr:9.70e-03, fs:0.83744 (r=0.859,p=0.817),  time:38.516, tt:6278.136\n",
      "Ep:163, loss:0.00001, loss_test:0.01626, lr:9.70e-03, fs:0.84158 (r=0.859,p=0.825),  time:38.514, tt:6316.356\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00001, loss_test:0.01625, lr:9.70e-03, fs:0.84158 (r=0.859,p=0.825),  time:38.530, tt:6357.453\n",
      "Ep:165, loss:0.00001, loss_test:0.01625, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.532, tt:6396.385\n",
      "##########Best model found so far##########\n",
      "Ep:166, loss:0.00001, loss_test:0.01624, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.547, tt:6437.355\n",
      "Ep:167, loss:0.00001, loss_test:0.01623, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.553, tt:6476.837\n",
      "Ep:168, loss:0.00001, loss_test:0.01622, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.551, tt:6515.201\n",
      "Ep:169, loss:0.00001, loss_test:0.01622, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.565, tt:6556.100\n",
      "Ep:170, loss:0.00001, loss_test:0.01620, lr:9.70e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.564, tt:6594.389\n",
      "Ep:171, loss:0.00001, loss_test:0.01620, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.567, tt:6633.555\n",
      "##########Best model found so far##########\n",
      "Ep:172, loss:0.00001, loss_test:0.01619, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.576, tt:6673.658\n",
      "Ep:173, loss:0.00001, loss_test:0.01618, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.579, tt:6712.689\n",
      "Ep:174, loss:0.00001, loss_test:0.01617, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.581, tt:6751.727\n",
      "Ep:175, loss:0.00001, loss_test:0.01617, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.594, tt:6792.510\n",
      "Ep:176, loss:0.00001, loss_test:0.01615, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.597, tt:6831.758\n",
      "Ep:177, loss:0.00001, loss_test:0.01614, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.597, tt:6870.280\n",
      "Ep:178, loss:0.00001, loss_test:0.01612, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.610, tt:6911.135\n",
      "Ep:179, loss:0.00001, loss_test:0.01611, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.613, tt:6950.270\n",
      "Ep:180, loss:0.00001, loss_test:0.01611, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.621, tt:6990.368\n",
      "Ep:181, loss:0.00001, loss_test:0.01611, lr:9.70e-03, fs:0.85000 (r=0.859,p=0.842),  time:38.620, tt:7028.907\n",
      "Ep:182, loss:0.00001, loss_test:0.01611, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.618, tt:7067.077\n",
      "##########Best model found so far##########\n",
      "Ep:183, loss:0.00001, loss_test:0.01610, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.623, tt:7106.560\n",
      "Ep:184, loss:0.00001, loss_test:0.01609, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.626, tt:7145.870\n",
      "Ep:185, loss:0.00001, loss_test:0.01608, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.632, tt:7185.531\n",
      "Ep:186, loss:0.00001, loss_test:0.01608, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.631, tt:7224.054\n",
      "Ep:187, loss:0.00001, loss_test:0.01607, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.625, tt:7261.527\n",
      "Ep:188, loss:0.00001, loss_test:0.01605, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.621, tt:7299.327\n",
      "Ep:189, loss:0.00001, loss_test:0.01605, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.635, tt:7340.635\n",
      "Ep:190, loss:0.00001, loss_test:0.01604, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.630, tt:7378.250\n",
      "Ep:191, loss:0.00001, loss_test:0.01603, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.635, tt:7417.837\n",
      "Ep:192, loss:0.00001, loss_test:0.01602, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.642, tt:7457.991\n",
      "Ep:193, loss:0.00001, loss_test:0.01601, lr:9.70e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.648, tt:7497.678\n",
      "Ep:194, loss:0.00001, loss_test:0.01600, lr:9.61e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.651, tt:7536.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00001, loss_test:0.01599, lr:9.51e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.660, tt:7577.338\n",
      "Ep:196, loss:0.00001, loss_test:0.01598, lr:9.41e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.665, tt:7616.947\n",
      "Ep:197, loss:0.00001, loss_test:0.01598, lr:9.32e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.673, tt:7657.206\n",
      "Ep:198, loss:0.00001, loss_test:0.01597, lr:9.23e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.680, tt:7697.313\n",
      "Ep:199, loss:0.00001, loss_test:0.01595, lr:9.14e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.688, tt:7737.573\n",
      "Ep:200, loss:0.00001, loss_test:0.01595, lr:9.04e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.698, tt:7778.368\n",
      "Ep:201, loss:0.00001, loss_test:0.01594, lr:8.95e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.701, tt:7817.695\n",
      "Ep:202, loss:0.00001, loss_test:0.01593, lr:8.86e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.707, tt:7857.462\n",
      "Ep:203, loss:0.00001, loss_test:0.01593, lr:8.78e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.707, tt:7896.326\n",
      "Ep:204, loss:0.00001, loss_test:0.01592, lr:8.69e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.708, tt:7935.073\n",
      "Ep:205, loss:0.00001, loss_test:0.01592, lr:8.60e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.708, tt:7973.807\n",
      "Ep:206, loss:0.00001, loss_test:0.01592, lr:8.51e-03, fs:0.85427 (r=0.859,p=0.850),  time:38.698, tt:8010.587\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13759, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:30.738, tt:30.738\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13435, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:31.170, tt:62.339\n",
      "Ep:2, loss:0.00027, loss_test:0.12949, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:31.856, tt:95.567\n",
      "Ep:3, loss:0.00026, loss_test:0.12437, lr:1.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:31.753, tt:127.011\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12010, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:32.805, tt:164.027\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11785, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:33.561, tt:201.368\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11647, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:33.998, tt:237.985\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11505, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:34.228, tt:273.822\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11351, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:34.513, tt:310.615\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11137, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:34.874, tt:348.737\n",
      "Ep:10, loss:0.00022, loss_test:0.10871, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:35.039, tt:385.428\n",
      "Ep:11, loss:0.00022, loss_test:0.10636, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:35.090, tt:421.079\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10356, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:35.159, tt:457.063\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10221, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:35.266, tt:493.728\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10081, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:35.366, tt:530.492\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09839, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:35.470, tt:567.525\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09554, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:35.581, tt:604.882\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09444, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:35.601, tt:640.810\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09308, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:35.700, tt:678.302\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09191, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:35.795, tt:715.899\n",
      "Ep:20, loss:0.00016, loss_test:0.09060, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:35.812, tt:752.050\n",
      "Ep:21, loss:0.00016, loss_test:0.08856, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:35.859, tt:788.898\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08789, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:35.843, tt:824.396\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08661, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.841, tt:860.189\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08633, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:35.871, tt:896.769\n",
      "Ep:25, loss:0.00014, loss_test:0.08539, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:35.898, tt:933.335\n",
      "Ep:26, loss:0.00013, loss_test:0.08295, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:35.907, tt:969.495\n",
      "Ep:27, loss:0.00013, loss_test:0.08319, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:35.948, tt:1006.542\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08226, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:35.964, tt:1042.945\n",
      "Ep:29, loss:0.00012, loss_test:0.08071, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:35.997, tt:1079.896\n",
      "Ep:30, loss:0.00012, loss_test:0.07932, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.031, tt:1116.947\n",
      "Ep:31, loss:0.00011, loss_test:0.08046, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:36.038, tt:1153.218\n",
      "Ep:32, loss:0.00011, loss_test:0.07644, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:36.066, tt:1190.181\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07971, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:36.133, tt:1228.505\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07583, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:36.190, tt:1266.657\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07777, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:36.185, tt:1302.664\n",
      "Ep:36, loss:0.00009, loss_test:0.07765, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.156, tt:1337.759\n",
      "Ep:37, loss:0.00009, loss_test:0.07525, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:36.152, tt:1373.768\n",
      "Ep:38, loss:0.00009, loss_test:0.07685, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.153, tt:1409.960\n",
      "Ep:39, loss:0.00008, loss_test:0.07758, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.155, tt:1446.188\n",
      "Ep:40, loss:0.00008, loss_test:0.07351, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:36.171, tt:1482.999\n",
      "Ep:41, loss:0.00008, loss_test:0.07542, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.193, tt:1520.122\n",
      "Ep:42, loss:0.00007, loss_test:0.07363, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:36.204, tt:1556.759\n",
      "Ep:43, loss:0.00007, loss_test:0.07790, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.237, tt:1594.426\n",
      "Ep:44, loss:0.00007, loss_test:0.07371, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.234, tt:1630.509\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07233, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.248, tt:1667.408\n",
      "Ep:46, loss:0.00007, loss_test:0.07773, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:36.233, tt:1702.963\n",
      "Ep:47, loss:0.00006, loss_test:0.07088, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:36.210, tt:1738.075\n",
      "Ep:48, loss:0.00006, loss_test:0.07573, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.224, tt:1774.953\n",
      "Ep:49, loss:0.00006, loss_test:0.08159, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:36.234, tt:1811.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:50, loss:0.00006, loss_test:0.06934, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:36.259, tt:1849.220\n",
      "Ep:51, loss:0.00006, loss_test:0.08005, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:36.297, tt:1887.443\n",
      "Ep:52, loss:0.00005, loss_test:0.07122, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:36.293, tt:1923.547\n",
      "Ep:53, loss:0.00005, loss_test:0.07620, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:36.306, tt:1960.541\n",
      "Ep:54, loss:0.00005, loss_test:0.07640, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:36.308, tt:1996.962\n",
      "Ep:55, loss:0.00005, loss_test:0.07086, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:36.279, tt:2031.641\n",
      "Ep:56, loss:0.00005, loss_test:0.07942, lr:9.90e-03, fs:0.81081 (r=0.758,p=0.872),  time:36.283, tt:2068.144\n",
      "Ep:57, loss:0.00005, loss_test:0.07021, lr:9.80e-03, fs:0.80000 (r=0.707,p=0.921),  time:36.285, tt:2104.535\n",
      "Ep:58, loss:0.00005, loss_test:0.07452, lr:9.70e-03, fs:0.82609 (r=0.768,p=0.894),  time:36.304, tt:2141.911\n",
      "Ep:59, loss:0.00004, loss_test:0.07362, lr:9.61e-03, fs:0.82081 (r=0.717,p=0.959),  time:36.307, tt:2178.431\n",
      "Ep:60, loss:0.00004, loss_test:0.07243, lr:9.51e-03, fs:0.81720 (r=0.768,p=0.874),  time:36.318, tt:2215.397\n",
      "Ep:61, loss:0.00004, loss_test:0.07189, lr:9.41e-03, fs:0.81609 (r=0.717,p=0.947),  time:36.314, tt:2251.450\n",
      "Ep:62, loss:0.00004, loss_test:0.07354, lr:9.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:36.321, tt:2288.193\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.07070, lr:9.32e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.332, tt:2325.223\n",
      "Ep:64, loss:0.00004, loss_test:0.07503, lr:9.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.308, tt:2359.990\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.07074, lr:9.32e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.323, tt:2397.313\n",
      "Ep:66, loss:0.00004, loss_test:0.07294, lr:9.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.316, tt:2433.149\n",
      "Ep:67, loss:0.00004, loss_test:0.07730, lr:9.32e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.330, tt:2470.413\n",
      "Ep:68, loss:0.00004, loss_test:0.06951, lr:9.32e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.360, tt:2508.857\n",
      "Ep:69, loss:0.00003, loss_test:0.07809, lr:9.32e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.365, tt:2545.545\n",
      "Ep:70, loss:0.00003, loss_test:0.07017, lr:9.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.354, tt:2581.105\n",
      "Ep:71, loss:0.00003, loss_test:0.07585, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:36.349, tt:2617.160\n",
      "Ep:72, loss:0.00003, loss_test:0.07261, lr:9.32e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.342, tt:2652.999\n",
      "Ep:73, loss:0.00003, loss_test:0.07304, lr:9.32e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.345, tt:2689.518\n",
      "Ep:74, loss:0.00003, loss_test:0.07195, lr:9.32e-03, fs:0.82840 (r=0.707,p=1.000),  time:36.371, tt:2727.829\n",
      "Ep:75, loss:0.00003, loss_test:0.07189, lr:9.32e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.342, tt:2761.961\n",
      "Ep:76, loss:0.00003, loss_test:0.07117, lr:9.23e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.341, tt:2798.292\n",
      "Ep:77, loss:0.00003, loss_test:0.07266, lr:9.14e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.339, tt:2834.466\n",
      "Ep:78, loss:0.00003, loss_test:0.07043, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.362, tt:2872.626\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.07153, lr:9.04e-03, fs:0.82418 (r=0.758,p=0.904),  time:36.347, tt:2907.759\n",
      "Ep:80, loss:0.00003, loss_test:0.07156, lr:9.04e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.344, tt:2943.844\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00003, loss_test:0.07031, lr:9.04e-03, fs:0.80220 (r=0.737,p=0.880),  time:36.336, tt:2979.536\n",
      "Ep:82, loss:0.00003, loss_test:0.07184, lr:9.04e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.337, tt:3015.947\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.07154, lr:9.04e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.316, tt:3050.515\n",
      "Ep:84, loss:0.00002, loss_test:0.06926, lr:9.04e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.293, tt:3084.886\n",
      "Ep:85, loss:0.00002, loss_test:0.07196, lr:9.04e-03, fs:0.86034 (r=0.778,p=0.963),  time:36.286, tt:3120.592\n",
      "Ep:86, loss:0.00002, loss_test:0.07138, lr:9.04e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.309, tt:3158.924\n",
      "Ep:87, loss:0.00002, loss_test:0.07059, lr:9.04e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.326, tt:3196.671\n",
      "Ep:88, loss:0.00002, loss_test:0.07504, lr:9.04e-03, fs:0.84916 (r=0.768,p=0.950),  time:36.300, tt:3230.681\n",
      "Ep:89, loss:0.00002, loss_test:0.06993, lr:9.04e-03, fs:0.84571 (r=0.747,p=0.974),  time:36.304, tt:3267.326\n",
      "Ep:90, loss:0.00002, loss_test:0.07126, lr:9.04e-03, fs:0.82840 (r=0.707,p=1.000),  time:36.311, tt:3304.292\n",
      "Ep:91, loss:0.00002, loss_test:0.07286, lr:9.04e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.317, tt:3341.175\n",
      "Ep:92, loss:0.00002, loss_test:0.07125, lr:9.04e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.311, tt:3376.910\n",
      "Ep:93, loss:0.00002, loss_test:0.07156, lr:9.04e-03, fs:0.81871 (r=0.707,p=0.972),  time:36.332, tt:3415.225\n",
      "Ep:94, loss:0.00002, loss_test:0.07192, lr:8.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.346, tt:3452.845\n",
      "Ep:95, loss:0.00002, loss_test:0.07008, lr:8.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:36.376, tt:3492.120\n",
      "Ep:96, loss:0.00002, loss_test:0.07343, lr:8.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.424, tt:3533.095\n",
      "Ep:97, loss:0.00002, loss_test:0.07057, lr:8.69e-03, fs:0.80925 (r=0.707,p=0.946),  time:36.430, tt:3570.113\n",
      "Ep:98, loss:0.00002, loss_test:0.06992, lr:8.60e-03, fs:0.82143 (r=0.697,p=1.000),  time:36.450, tt:3608.520\n",
      "Ep:99, loss:0.00002, loss_test:0.07399, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.453, tt:3645.319\n",
      "Ep:100, loss:0.00002, loss_test:0.06821, lr:8.43e-03, fs:0.82840 (r=0.707,p=1.000),  time:36.458, tt:3682.296\n",
      "Ep:101, loss:0.00002, loss_test:0.07187, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.469, tt:3719.836\n",
      "Ep:102, loss:0.00002, loss_test:0.07125, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.472, tt:3756.666\n",
      "Ep:103, loss:0.00002, loss_test:0.06925, lr:8.18e-03, fs:0.82143 (r=0.697,p=1.000),  time:36.485, tt:3794.476\n",
      "Ep:104, loss:0.00002, loss_test:0.07612, lr:8.10e-03, fs:0.83616 (r=0.747,p=0.949),  time:36.488, tt:3831.285\n",
      "Ep:105, loss:0.00002, loss_test:0.06868, lr:8.02e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.503, tt:3869.348\n",
      "Ep:106, loss:0.00002, loss_test:0.07304, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.509, tt:3906.494\n",
      "Ep:107, loss:0.00002, loss_test:0.07111, lr:7.86e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.517, tt:3943.791\n",
      "Ep:108, loss:0.00002, loss_test:0.07123, lr:7.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.518, tt:3980.429\n",
      "Ep:109, loss:0.00002, loss_test:0.07082, lr:7.70e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.522, tt:4017.443\n",
      "Ep:110, loss:0.00002, loss_test:0.07216, lr:7.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.523, tt:4054.095\n",
      "Ep:111, loss:0.00002, loss_test:0.07090, lr:7.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.515, tt:4089.735\n",
      "Ep:112, loss:0.00002, loss_test:0.07096, lr:7.47e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.519, tt:4126.618\n",
      "Ep:113, loss:0.00002, loss_test:0.07182, lr:7.40e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.523, tt:4163.677\n",
      "Ep:114, loss:0.00002, loss_test:0.06934, lr:7.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.535, tt:4201.488\n",
      "Ep:115, loss:0.00001, loss_test:0.06969, lr:7.25e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.547, tt:4239.447\n",
      "Ep:116, loss:0.00001, loss_test:0.07227, lr:7.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:36.548, tt:4276.145\n",
      "Ep:117, loss:0.00001, loss_test:0.06940, lr:7.11e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.565, tt:4314.672\n",
      "Ep:118, loss:0.00001, loss_test:0.07014, lr:7.03e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.586, tt:4353.674\n",
      "Ep:119, loss:0.00001, loss_test:0.07103, lr:6.96e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.593, tt:4391.194\n",
      "Ep:120, loss:0.00001, loss_test:0.06899, lr:6.89e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.614, tt:4430.309\n",
      "Ep:121, loss:0.00001, loss_test:0.07053, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.612, tt:4466.610\n",
      "Ep:122, loss:0.00001, loss_test:0.06939, lr:6.76e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.624, tt:4504.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00001, loss_test:0.07081, lr:6.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.637, tt:4542.992\n",
      "Ep:124, loss:0.00001, loss_test:0.06875, lr:6.62e-03, fs:0.82353 (r=0.707,p=0.986),  time:36.652, tt:4581.459\n",
      "Ep:125, loss:0.00001, loss_test:0.07122, lr:6.56e-03, fs:0.85057 (r=0.747,p=0.987),  time:36.652, tt:4618.124\n",
      "Ep:126, loss:0.00001, loss_test:0.07019, lr:6.49e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.658, tt:4655.603\n",
      "Ep:127, loss:0.00001, loss_test:0.06894, lr:6.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:36.660, tt:4692.504\n",
      "Ep:128, loss:0.00001, loss_test:0.07213, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.671, tt:4730.584\n",
      "Ep:129, loss:0.00001, loss_test:0.06895, lr:6.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.690, tt:4769.720\n",
      "Ep:130, loss:0.00001, loss_test:0.07144, lr:6.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.696, tt:4807.200\n",
      "Ep:131, loss:0.00001, loss_test:0.06938, lr:6.17e-03, fs:0.81176 (r=0.697,p=0.972),  time:36.703, tt:4844.834\n",
      "Ep:132, loss:0.00001, loss_test:0.07142, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.715, tt:4883.061\n",
      "Ep:133, loss:0.00001, loss_test:0.06938, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:36.758, tt:4925.504\n",
      "Ep:134, loss:0.00001, loss_test:0.07087, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.759, tt:4962.424\n",
      "Ep:135, loss:0.00001, loss_test:0.06964, lr:5.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:36.765, tt:5000.043\n",
      "Ep:136, loss:0.00001, loss_test:0.07105, lr:5.87e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.766, tt:5036.929\n",
      "Ep:137, loss:0.00001, loss_test:0.06935, lr:5.81e-03, fs:0.85549 (r=0.747,p=1.000),  time:36.772, tt:5074.536\n",
      "Ep:138, loss:0.00001, loss_test:0.07072, lr:5.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.764, tt:5110.234\n",
      "Ep:139, loss:0.00001, loss_test:0.06903, lr:5.70e-03, fs:0.85549 (r=0.747,p=1.000),  time:36.764, tt:5147.001\n",
      "Ep:140, loss:0.00001, loss_test:0.07056, lr:5.64e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.780, tt:5185.939\n",
      "Ep:141, loss:0.00001, loss_test:0.06984, lr:5.58e-03, fs:0.86207 (r=0.758,p=1.000),  time:36.791, tt:5224.346\n",
      "Ep:142, loss:0.00001, loss_test:0.06901, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.790, tt:5260.959\n",
      "Ep:143, loss:0.00001, loss_test:0.06979, lr:5.47e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.802, tt:5299.559\n",
      "Ep:144, loss:0.00001, loss_test:0.06932, lr:5.42e-03, fs:0.82143 (r=0.697,p=1.000),  time:36.810, tt:5337.461\n",
      "Ep:145, loss:0.00001, loss_test:0.07163, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.808, tt:5373.972\n",
      "Ep:146, loss:0.00001, loss_test:0.06823, lr:5.31e-03, fs:0.82143 (r=0.697,p=1.000),  time:36.809, tt:5410.911\n",
      "Ep:147, loss:0.00001, loss_test:0.07112, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.809, tt:5447.662\n",
      "Ep:148, loss:0.00001, loss_test:0.06983, lr:5.20e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.813, tt:5485.157\n",
      "Ep:149, loss:0.00001, loss_test:0.06870, lr:5.15e-03, fs:0.85549 (r=0.747,p=1.000),  time:36.810, tt:5521.569\n",
      "Ep:150, loss:0.00001, loss_test:0.06980, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.815, tt:5559.109\n",
      "Ep:151, loss:0.00001, loss_test:0.06894, lr:5.05e-03, fs:0.86207 (r=0.758,p=1.000),  time:36.817, tt:5596.195\n",
      "Ep:152, loss:0.00001, loss_test:0.07018, lr:5.00e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.818, tt:5633.170\n",
      "Ep:153, loss:0.00001, loss_test:0.06874, lr:4.95e-03, fs:0.86207 (r=0.758,p=1.000),  time:36.810, tt:5668.774\n",
      "Ep:154, loss:0.00001, loss_test:0.06970, lr:4.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.809, tt:5705.318\n",
      "Ep:155, loss:0.00001, loss_test:0.06838, lr:4.85e-03, fs:0.85549 (r=0.747,p=1.000),  time:36.821, tt:5744.144\n",
      "Ep:156, loss:0.00001, loss_test:0.06885, lr:4.80e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.851, tt:5785.557\n",
      "Ep:157, loss:0.00001, loss_test:0.06974, lr:4.75e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.855, tt:5823.143\n",
      "Ep:158, loss:0.00001, loss_test:0.06970, lr:4.71e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.859, tt:5860.574\n",
      "Ep:159, loss:0.00001, loss_test:0.06958, lr:4.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:36.860, tt:5897.570\n",
      "Ep:160, loss:0.00001, loss_test:0.06844, lr:4.61e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.862, tt:5934.800\n",
      "Ep:161, loss:0.00001, loss_test:0.07000, lr:4.57e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.868, tt:5972.559\n",
      "Ep:162, loss:0.00001, loss_test:0.06886, lr:4.52e-03, fs:0.85714 (r=0.758,p=0.987),  time:36.872, tt:6010.202\n",
      "Ep:163, loss:0.00001, loss_test:0.06865, lr:4.48e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.876, tt:6047.709\n",
      "Ep:164, loss:0.00001, loss_test:0.07020, lr:4.43e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.881, tt:6085.429\n",
      "Ep:165, loss:0.00001, loss_test:0.06848, lr:4.39e-03, fs:0.85549 (r=0.747,p=1.000),  time:36.880, tt:6122.003\n",
      "Ep:166, loss:0.00001, loss_test:0.06844, lr:4.34e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.887, tt:6160.102\n",
      "Ep:167, loss:0.00001, loss_test:0.06982, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.898, tt:6198.846\n",
      "Ep:168, loss:0.00001, loss_test:0.06920, lr:4.26e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.910, tt:6237.873\n",
      "Ep:169, loss:0.00001, loss_test:0.06872, lr:4.21e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.914, tt:6275.297\n",
      "Ep:170, loss:0.00001, loss_test:0.06985, lr:4.17e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.925, tt:6314.232\n",
      "Ep:171, loss:0.00001, loss_test:0.06815, lr:4.13e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.926, tt:6351.242\n",
      "Ep:172, loss:0.00001, loss_test:0.06857, lr:4.09e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.930, tt:6388.942\n",
      "Ep:173, loss:0.00001, loss_test:0.06948, lr:4.05e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.936, tt:6426.885\n",
      "Ep:174, loss:0.00001, loss_test:0.06846, lr:4.01e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.940, tt:6464.543\n",
      "Ep:175, loss:0.00001, loss_test:0.06891, lr:3.97e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.940, tt:6501.427\n",
      "Ep:176, loss:0.00001, loss_test:0.06888, lr:3.93e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.943, tt:6538.975\n",
      "Ep:177, loss:0.00001, loss_test:0.06907, lr:3.89e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.951, tt:6577.278\n",
      "Ep:178, loss:0.00001, loss_test:0.06814, lr:3.85e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.956, tt:6615.136\n",
      "Ep:179, loss:0.00001, loss_test:0.06914, lr:3.81e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.975, tt:6655.568\n",
      "Ep:180, loss:0.00001, loss_test:0.06859, lr:3.77e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.986, tt:6694.518\n",
      "Ep:181, loss:0.00001, loss_test:0.06875, lr:3.73e-03, fs:0.86857 (r=0.768,p=1.000),  time:36.992, tt:6732.584\n",
      "Ep:182, loss:0.00001, loss_test:0.06954, lr:3.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.001, tt:6771.143\n",
      "Ep:183, loss:0.00001, loss_test:0.06840, lr:3.66e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.004, tt:6808.826\n",
      "Ep:184, loss:0.00001, loss_test:0.06868, lr:3.62e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.004, tt:6845.800\n",
      "Ep:185, loss:0.00001, loss_test:0.06885, lr:3.59e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.008, tt:6883.504\n",
      "Ep:186, loss:0.00001, loss_test:0.06889, lr:3.55e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.006, tt:6920.108\n",
      "Ep:187, loss:0.00001, loss_test:0.06796, lr:3.52e-03, fs:0.86207 (r=0.758,p=1.000),  time:37.016, tt:6959.070\n",
      "Ep:188, loss:0.00001, loss_test:0.06931, lr:3.48e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.024, tt:6997.590\n",
      "Ep:189, loss:0.00001, loss_test:0.06861, lr:3.45e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.027, tt:7035.101\n",
      "Ep:190, loss:0.00001, loss_test:0.06815, lr:3.41e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.033, tt:7073.276\n",
      "Ep:191, loss:0.00001, loss_test:0.06848, lr:3.38e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.032, tt:7110.155\n",
      "Ep:192, loss:0.00001, loss_test:0.06899, lr:3.34e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.039, tt:7148.529\n",
      "Ep:193, loss:0.00001, loss_test:0.06866, lr:3.31e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.052, tt:7187.993\n",
      "Ep:194, loss:0.00001, loss_test:0.06896, lr:3.28e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.063, tt:7227.330\n",
      "Ep:195, loss:0.00001, loss_test:0.06878, lr:3.24e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.064, tt:7264.460\n",
      "Ep:196, loss:0.00001, loss_test:0.06849, lr:3.21e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.071, tt:7302.931\n",
      "Ep:197, loss:0.00001, loss_test:0.06883, lr:3.18e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.073, tt:7340.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:198, loss:0.00001, loss_test:0.06820, lr:3.15e-03, fs:0.86207 (r=0.758,p=1.000),  time:37.080, tt:7379.004\n",
      "Ep:199, loss:0.00001, loss_test:0.06906, lr:3.12e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.079, tt:7415.822\n",
      "Ep:200, loss:0.00001, loss_test:0.06880, lr:3.09e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.065, tt:7450.025\n",
      "Ep:201, loss:0.00001, loss_test:0.06850, lr:3.05e-03, fs:0.86207 (r=0.758,p=1.000),  time:37.082, tt:7490.580\n",
      "Ep:202, loss:0.00001, loss_test:0.06886, lr:3.02e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.104, tt:7532.203\n",
      "Ep:203, loss:0.00001, loss_test:0.06854, lr:2.99e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.116, tt:7571.701\n",
      "Ep:204, loss:0.00001, loss_test:0.06908, lr:2.96e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.121, tt:7609.730\n",
      "Ep:205, loss:0.00001, loss_test:0.06861, lr:2.93e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.118, tt:7646.360\n",
      "Ep:206, loss:0.00001, loss_test:0.06887, lr:2.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:37.127, tt:7685.287\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14437, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.736, tt:37.736\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14302, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.837, tt:73.674\n",
      "Ep:2, loss:0.00028, loss_test:0.14051, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.622, tt:103.865\n",
      "Ep:3, loss:0.00027, loss_test:0.13614, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:35.467, tt:141.869\n",
      "Ep:4, loss:0.00026, loss_test:0.12902, lr:1.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:36.118, tt:180.588\n",
      "Ep:5, loss:0.00025, loss_test:0.11823, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:36.639, tt:219.835\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11057, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:37.051, tt:259.355\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11054, lr:1.00e-02, fs:0.65657 (r=0.657,p=0.657),  time:37.438, tt:299.503\n",
      "Ep:8, loss:0.00022, loss_test:0.10819, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:37.547, tt:337.925\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10960, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:37.456, tt:374.556\n",
      "Ep:10, loss:0.00020, loss_test:0.10484, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:37.548, tt:413.023\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10192, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:37.659, tt:451.904\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10058, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:37.593, tt:488.715\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09983, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:37.679, tt:527.502\n",
      "Ep:14, loss:0.00017, loss_test:0.09707, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:37.810, tt:567.150\n",
      "Ep:15, loss:0.00016, loss_test:0.09558, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:37.880, tt:606.087\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09255, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:37.980, tt:645.656\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09058, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:38.085, tt:685.527\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.08938, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:38.179, tt:725.401\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08891, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:38.080, tt:761.593\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08855, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:38.004, tt:798.076\n",
      "Ep:21, loss:0.00013, loss_test:0.08701, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:38.061, tt:837.335\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08573, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:38.015, tt:874.347\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08446, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:37.974, tt:911.386\n",
      "Ep:24, loss:0.00011, loss_test:0.08382, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:37.916, tt:947.901\n",
      "Ep:25, loss:0.00011, loss_test:0.08206, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:37.891, tt:985.164\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07991, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.917, tt:1023.746\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07991, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:37.941, tt:1062.350\n",
      "Ep:28, loss:0.00010, loss_test:0.07831, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.927, tt:1099.881\n",
      "Ep:29, loss:0.00009, loss_test:0.08060, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:37.908, tt:1137.232\n",
      "Ep:30, loss:0.00009, loss_test:0.07815, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:37.973, tt:1177.152\n",
      "Ep:31, loss:0.00008, loss_test:0.07813, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:38.001, tt:1216.023\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07766, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:37.947, tt:1252.248\n",
      "Ep:33, loss:0.00008, loss_test:0.07940, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:37.957, tt:1290.523\n",
      "Ep:34, loss:0.00008, loss_test:0.07430, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:37.938, tt:1327.847\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.07954, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:37.997, tt:1367.904\n",
      "Ep:36, loss:0.00007, loss_test:0.07255, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:37.948, tt:1404.058\n",
      "Ep:37, loss:0.00007, loss_test:0.08121, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:37.934, tt:1441.493\n",
      "Ep:38, loss:0.00006, loss_test:0.07231, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:37.911, tt:1478.548\n",
      "Ep:39, loss:0.00006, loss_test:0.07658, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:37.874, tt:1514.944\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.07432, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:37.871, tt:1552.701\n",
      "Ep:41, loss:0.00006, loss_test:0.07268, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:37.872, tt:1590.620\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.07630, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:37.865, tt:1628.185\n",
      "Ep:43, loss:0.00005, loss_test:0.07162, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:37.934, tt:1669.093\n",
      "Ep:44, loss:0.00005, loss_test:0.07599, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:37.869, tt:1704.084\n",
      "Ep:45, loss:0.00005, loss_test:0.07357, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:37.891, tt:1742.999\n",
      "Ep:46, loss:0.00004, loss_test:0.07612, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:37.890, tt:1780.850\n",
      "Ep:47, loss:0.00004, loss_test:0.07436, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:37.888, tt:1818.609\n",
      "Ep:48, loss:0.00004, loss_test:0.07578, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:37.951, tt:1859.609\n",
      "Ep:49, loss:0.00004, loss_test:0.07837, lr:1.00e-02, fs:0.86667 (r=0.788,p=0.963),  time:37.965, tt:1898.256\n",
      "Ep:50, loss:0.00004, loss_test:0.07223, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:38.000, tt:1938.016\n",
      "Ep:51, loss:0.00004, loss_test:0.07847, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:37.982, tt:1975.066\n",
      "Ep:52, loss:0.00004, loss_test:0.07242, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:37.966, tt:2012.175\n",
      "Ep:53, loss:0.00003, loss_test:0.08223, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:37.982, tt:2051.034\n",
      "Ep:54, loss:0.00004, loss_test:0.07282, lr:9.80e-03, fs:0.87097 (r=0.818,p=0.931),  time:38.000, tt:2090.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00003, loss_test:0.07944, lr:9.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:37.970, tt:2126.315\n",
      "Ep:56, loss:0.00003, loss_test:0.07530, lr:9.61e-03, fs:0.87293 (r=0.798,p=0.963),  time:37.971, tt:2164.339\n",
      "Ep:57, loss:0.00003, loss_test:0.07271, lr:9.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.969, tt:2202.218\n",
      "Ep:58, loss:0.00003, loss_test:0.07772, lr:9.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.965, tt:2239.915\n",
      "Ep:59, loss:0.00003, loss_test:0.07119, lr:9.32e-03, fs:0.87701 (r=0.828,p=0.932),  time:37.965, tt:2277.929\n",
      "Ep:60, loss:0.00003, loss_test:0.07825, lr:9.23e-03, fs:0.86667 (r=0.788,p=0.963),  time:37.961, tt:2315.621\n",
      "Ep:61, loss:0.00003, loss_test:0.07367, lr:9.14e-03, fs:0.87568 (r=0.818,p=0.942),  time:38.013, tt:2356.791\n",
      "Ep:62, loss:0.00002, loss_test:0.07685, lr:9.04e-03, fs:0.87432 (r=0.808,p=0.952),  time:38.015, tt:2394.950\n",
      "Ep:63, loss:0.00002, loss_test:0.07549, lr:8.95e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.993, tt:2431.557\n",
      "Ep:64, loss:0.00002, loss_test:0.07492, lr:8.86e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.924, tt:2465.079\n",
      "Ep:65, loss:0.00002, loss_test:0.07515, lr:8.78e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.918, tt:2502.571\n",
      "Ep:66, loss:0.00002, loss_test:0.07499, lr:8.69e-03, fs:0.86813 (r=0.798,p=0.952),  time:37.924, tt:2540.902\n",
      "Ep:67, loss:0.00002, loss_test:0.07484, lr:8.60e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.871, tt:2575.227\n",
      "Ep:68, loss:0.00002, loss_test:0.07564, lr:8.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:37.866, tt:2612.762\n",
      "Ep:69, loss:0.00002, loss_test:0.07453, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.856, tt:2649.890\n",
      "Ep:70, loss:0.00002, loss_test:0.07461, lr:8.35e-03, fs:0.87432 (r=0.808,p=0.952),  time:37.884, tt:2689.734\n",
      "Ep:71, loss:0.00002, loss_test:0.07690, lr:8.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:37.853, tt:2725.393\n",
      "Ep:72, loss:0.00002, loss_test:0.07488, lr:8.18e-03, fs:0.86813 (r=0.798,p=0.952),  time:37.824, tt:2761.148\n",
      "Ep:73, loss:0.00002, loss_test:0.07766, lr:8.10e-03, fs:0.84746 (r=0.758,p=0.962),  time:37.802, tt:2797.358\n",
      "Ep:74, loss:0.00002, loss_test:0.07496, lr:8.02e-03, fs:0.88043 (r=0.818,p=0.953),  time:37.776, tt:2833.181\n",
      "Ep:75, loss:0.00002, loss_test:0.07743, lr:7.94e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.789, tt:2871.991\n",
      "Ep:76, loss:0.00002, loss_test:0.07422, lr:7.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:37.751, tt:2906.861\n",
      "Ep:77, loss:0.00002, loss_test:0.07830, lr:7.78e-03, fs:0.87151 (r=0.788,p=0.975),  time:37.717, tt:2941.924\n",
      "Ep:78, loss:0.00002, loss_test:0.07404, lr:7.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:37.714, tt:2979.428\n",
      "Ep:79, loss:0.00001, loss_test:0.07962, lr:7.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:37.734, tt:3018.699\n",
      "Ep:80, loss:0.00001, loss_test:0.07623, lr:7.55e-03, fs:0.88398 (r=0.808,p=0.976),  time:37.741, tt:3057.030\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.07609, lr:7.55e-03, fs:0.88398 (r=0.808,p=0.976),  time:37.731, tt:3093.912\n",
      "Ep:82, loss:0.00001, loss_test:0.07708, lr:7.55e-03, fs:0.87151 (r=0.788,p=0.975),  time:37.751, tt:3133.296\n",
      "Ep:83, loss:0.00001, loss_test:0.07762, lr:7.55e-03, fs:0.87778 (r=0.798,p=0.975),  time:37.736, tt:3169.830\n",
      "Ep:84, loss:0.00001, loss_test:0.07872, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:37.724, tt:3206.578\n",
      "Ep:85, loss:0.00001, loss_test:0.07774, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:37.741, tt:3245.741\n",
      "Ep:86, loss:0.00001, loss_test:0.07795, lr:7.55e-03, fs:0.87778 (r=0.798,p=0.975),  time:37.713, tt:3281.049\n",
      "Ep:87, loss:0.00001, loss_test:0.07985, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.719, tt:3319.284\n",
      "Ep:88, loss:0.00001, loss_test:0.08070, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.721, tt:3357.203\n",
      "Ep:89, loss:0.00001, loss_test:0.07602, lr:7.55e-03, fs:0.88398 (r=0.808,p=0.976),  time:37.727, tt:3395.405\n",
      "Ep:90, loss:0.00001, loss_test:0.08156, lr:7.55e-03, fs:0.81657 (r=0.697,p=0.986),  time:37.727, tt:3433.156\n",
      "Ep:91, loss:0.00001, loss_test:0.08075, lr:7.55e-03, fs:0.82558 (r=0.717,p=0.973),  time:37.744, tt:3472.468\n",
      "Ep:92, loss:0.00001, loss_test:0.07788, lr:7.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.745, tt:3510.302\n",
      "Ep:93, loss:0.00001, loss_test:0.08114, lr:7.40e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.754, tt:3548.897\n",
      "Ep:94, loss:0.00001, loss_test:0.07837, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:37.771, tt:3588.220\n",
      "Ep:95, loss:0.00001, loss_test:0.07999, lr:7.25e-03, fs:0.84571 (r=0.747,p=0.974),  time:37.758, tt:3624.731\n",
      "Ep:96, loss:0.00001, loss_test:0.07919, lr:7.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:37.755, tt:3662.241\n",
      "Ep:97, loss:0.00001, loss_test:0.08118, lr:7.11e-03, fs:0.83237 (r=0.727,p=0.973),  time:37.755, tt:3699.941\n",
      "Ep:98, loss:0.00001, loss_test:0.08028, lr:7.03e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.740, tt:3736.212\n",
      "Ep:99, loss:0.00001, loss_test:0.08077, lr:6.96e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.721, tt:3772.120\n",
      "Ep:100, loss:0.00001, loss_test:0.08195, lr:6.89e-03, fs:0.80000 (r=0.667,p=1.000),  time:37.727, tt:3810.392\n",
      "Ep:101, loss:0.00001, loss_test:0.08055, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.734, tt:3848.871\n",
      "Ep:102, loss:0.00001, loss_test:0.08182, lr:6.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.743, tt:3887.519\n",
      "Ep:103, loss:0.00001, loss_test:0.08055, lr:6.69e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.763, tt:3927.310\n",
      "Ep:104, loss:0.00001, loss_test:0.08196, lr:6.62e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.768, tt:3965.637\n",
      "Ep:105, loss:0.00001, loss_test:0.08132, lr:6.56e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.771, tt:4003.736\n",
      "Ep:106, loss:0.00001, loss_test:0.08219, lr:6.49e-03, fs:0.79762 (r=0.677,p=0.971),  time:37.817, tt:4046.398\n",
      "Ep:107, loss:0.00001, loss_test:0.08176, lr:6.43e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.799, tt:4082.301\n",
      "Ep:108, loss:0.00001, loss_test:0.08241, lr:6.36e-03, fs:0.81657 (r=0.697,p=0.986),  time:37.806, tt:4120.831\n",
      "Ep:109, loss:0.00001, loss_test:0.08284, lr:6.30e-03, fs:0.76829 (r=0.636,p=0.969),  time:37.803, tt:4158.282\n",
      "Ep:110, loss:0.00001, loss_test:0.08305, lr:6.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:37.811, tt:4197.069\n",
      "Ep:111, loss:0.00001, loss_test:0.08293, lr:6.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:37.817, tt:4235.468\n",
      "Ep:112, loss:0.00001, loss_test:0.08282, lr:6.11e-03, fs:0.79042 (r=0.667,p=0.971),  time:37.823, tt:4274.002\n",
      "Ep:113, loss:0.00001, loss_test:0.08289, lr:6.05e-03, fs:0.80952 (r=0.687,p=0.986),  time:37.814, tt:4310.741\n",
      "Ep:114, loss:0.00001, loss_test:0.08307, lr:5.99e-03, fs:0.75309 (r=0.616,p=0.968),  time:37.831, tt:4350.603\n",
      "Ep:115, loss:0.00001, loss_test:0.08376, lr:5.93e-03, fs:0.77019 (r=0.626,p=1.000),  time:37.849, tt:4390.455\n",
      "Ep:116, loss:0.00001, loss_test:0.08382, lr:5.87e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.869, tt:4430.622\n",
      "Ep:117, loss:0.00001, loss_test:0.08404, lr:5.81e-03, fs:0.81437 (r=0.687,p=1.000),  time:37.866, tt:4468.208\n",
      "Ep:118, loss:0.00001, loss_test:0.08425, lr:5.75e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.878, tt:4507.495\n",
      "Ep:119, loss:0.00001, loss_test:0.08466, lr:5.70e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.886, tt:4546.275\n",
      "Ep:120, loss:0.00001, loss_test:0.08491, lr:5.64e-03, fs:0.80000 (r=0.667,p=1.000),  time:37.898, tt:4585.622\n",
      "Ep:121, loss:0.00001, loss_test:0.08485, lr:5.58e-03, fs:0.79268 (r=0.657,p=1.000),  time:37.881, tt:4621.526\n",
      "Ep:122, loss:0.00001, loss_test:0.08488, lr:5.53e-03, fs:0.77019 (r=0.626,p=1.000),  time:37.876, tt:4658.761\n",
      "Ep:123, loss:0.00001, loss_test:0.08590, lr:5.47e-03, fs:0.75472 (r=0.606,p=1.000),  time:37.879, tt:4697.031\n",
      "Ep:124, loss:0.00001, loss_test:0.08663, lr:5.42e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.896, tt:4737.056\n",
      "Ep:125, loss:0.00001, loss_test:0.08638, lr:5.36e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.884, tt:4773.423\n",
      "Ep:126, loss:0.00001, loss_test:0.08659, lr:5.31e-03, fs:0.74684 (r=0.596,p=1.000),  time:37.876, tt:4810.254\n",
      "Ep:127, loss:0.00001, loss_test:0.08686, lr:5.26e-03, fs:0.77778 (r=0.636,p=1.000),  time:37.865, tt:4846.709\n",
      "Ep:128, loss:0.00001, loss_test:0.08721, lr:5.20e-03, fs:0.74684 (r=0.596,p=1.000),  time:37.866, tt:4884.680\n",
      "Ep:129, loss:0.00001, loss_test:0.08720, lr:5.15e-03, fs:0.73885 (r=0.586,p=1.000),  time:37.857, tt:4921.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.08725, lr:5.10e-03, fs:0.75472 (r=0.606,p=1.000),  time:37.873, tt:4961.404\n",
      "Ep:131, loss:0.00001, loss_test:0.08782, lr:5.05e-03, fs:0.73885 (r=0.586,p=1.000),  time:37.874, tt:4999.328\n",
      "Ep:132, loss:0.00001, loss_test:0.08796, lr:5.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:37.862, tt:5035.643\n",
      "Ep:133, loss:0.00001, loss_test:0.08766, lr:4.95e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.852, tt:5072.214\n",
      "Ep:134, loss:0.00000, loss_test:0.08839, lr:4.90e-03, fs:0.73077 (r=0.576,p=1.000),  time:37.855, tt:5110.365\n",
      "Ep:135, loss:0.00000, loss_test:0.08765, lr:4.85e-03, fs:0.77019 (r=0.626,p=1.000),  time:37.848, tt:5147.341\n",
      "Ep:136, loss:0.00000, loss_test:0.08768, lr:4.80e-03, fs:0.76250 (r=0.616,p=1.000),  time:37.845, tt:5184.812\n",
      "Ep:137, loss:0.00000, loss_test:0.08858, lr:4.75e-03, fs:0.72258 (r=0.566,p=1.000),  time:37.848, tt:5223.027\n",
      "Ep:138, loss:0.00000, loss_test:0.08822, lr:4.71e-03, fs:0.73077 (r=0.576,p=1.000),  time:37.845, tt:5260.510\n",
      "Ep:139, loss:0.00000, loss_test:0.08770, lr:4.66e-03, fs:0.73077 (r=0.576,p=1.000),  time:37.840, tt:5297.645\n",
      "Ep:140, loss:0.00000, loss_test:0.08897, lr:4.61e-03, fs:0.72258 (r=0.566,p=1.000),  time:37.837, tt:5335.039\n",
      "Ep:141, loss:0.00000, loss_test:0.08892, lr:4.57e-03, fs:0.72258 (r=0.566,p=1.000),  time:37.833, tt:5372.221\n",
      "Ep:142, loss:0.00000, loss_test:0.08779, lr:4.52e-03, fs:0.72258 (r=0.566,p=1.000),  time:37.839, tt:5410.976\n",
      "Ep:143, loss:0.00000, loss_test:0.08926, lr:4.48e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.839, tt:5448.804\n",
      "Ep:144, loss:0.00000, loss_test:0.08955, lr:4.43e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.837, tt:5486.360\n",
      "Ep:145, loss:0.00000, loss_test:0.08878, lr:4.39e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.843, tt:5525.110\n",
      "Ep:146, loss:0.00000, loss_test:0.08980, lr:4.34e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.843, tt:5562.989\n",
      "Ep:147, loss:0.00000, loss_test:0.08960, lr:4.30e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.853, tt:5602.259\n",
      "Ep:148, loss:0.00000, loss_test:0.08918, lr:4.26e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.831, tt:5636.854\n",
      "Ep:149, loss:0.00000, loss_test:0.08978, lr:4.21e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.834, tt:5675.028\n",
      "Ep:150, loss:0.00000, loss_test:0.09006, lr:4.17e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.823, tt:5711.211\n",
      "Ep:151, loss:0.00000, loss_test:0.08931, lr:4.13e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.809, tt:5746.943\n",
      "Ep:152, loss:0.00000, loss_test:0.08995, lr:4.09e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.797, tt:5782.901\n",
      "Ep:153, loss:0.00000, loss_test:0.09090, lr:4.05e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.797, tt:5820.809\n",
      "Ep:154, loss:0.00000, loss_test:0.08970, lr:4.01e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.800, tt:5858.937\n",
      "Ep:155, loss:0.00000, loss_test:0.08914, lr:3.97e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.793, tt:5895.743\n",
      "Ep:156, loss:0.00000, loss_test:0.08995, lr:3.93e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.793, tt:5933.529\n",
      "Ep:157, loss:0.00000, loss_test:0.08994, lr:3.89e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.778, tt:5968.877\n",
      "Ep:158, loss:0.00000, loss_test:0.08937, lr:3.85e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.778, tt:6006.684\n",
      "Ep:159, loss:0.00000, loss_test:0.08966, lr:3.81e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.770, tt:6043.195\n",
      "Ep:160, loss:0.00000, loss_test:0.08935, lr:3.77e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.746, tt:6077.156\n",
      "Ep:161, loss:0.00000, loss_test:0.09013, lr:3.73e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.747, tt:6114.942\n",
      "Ep:162, loss:0.00000, loss_test:0.09033, lr:3.70e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.747, tt:6152.833\n",
      "Ep:163, loss:0.00000, loss_test:0.08998, lr:3.66e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.739, tt:6189.172\n",
      "Ep:164, loss:0.00000, loss_test:0.09026, lr:3.62e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.722, tt:6224.188\n",
      "Ep:165, loss:0.00000, loss_test:0.09090, lr:3.59e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.709, tt:6259.659\n",
      "Ep:166, loss:0.00000, loss_test:0.09049, lr:3.55e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.706, tt:6296.898\n",
      "Ep:167, loss:0.00000, loss_test:0.08995, lr:3.52e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.698, tt:6333.205\n",
      "Ep:168, loss:0.00000, loss_test:0.09031, lr:3.48e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.701, tt:6371.396\n",
      "Ep:169, loss:0.00000, loss_test:0.09056, lr:3.45e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.709, tt:6410.539\n",
      "Ep:170, loss:0.00000, loss_test:0.09067, lr:3.41e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.707, tt:6447.839\n",
      "Ep:171, loss:0.00000, loss_test:0.08921, lr:3.38e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.693, tt:6483.276\n",
      "Ep:172, loss:0.00000, loss_test:0.08951, lr:3.34e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.699, tt:6521.951\n",
      "Ep:173, loss:0.00000, loss_test:0.09076, lr:3.31e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.704, tt:6560.502\n",
      "Ep:174, loss:0.00000, loss_test:0.09076, lr:3.28e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.702, tt:6597.905\n",
      "Ep:175, loss:0.00000, loss_test:0.08973, lr:3.24e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.700, tt:6635.171\n",
      "Ep:176, loss:0.00000, loss_test:0.08897, lr:3.21e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.697, tt:6672.315\n",
      "Ep:177, loss:0.00000, loss_test:0.09044, lr:3.18e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.688, tt:6708.418\n",
      "Ep:178, loss:0.00000, loss_test:0.09080, lr:3.15e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.684, tt:6745.395\n",
      "Ep:179, loss:0.00000, loss_test:0.09034, lr:3.12e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.680, tt:6782.395\n",
      "Ep:180, loss:0.00000, loss_test:0.08984, lr:3.09e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.680, tt:6820.058\n",
      "Ep:181, loss:0.00000, loss_test:0.09003, lr:3.05e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.676, tt:6857.005\n",
      "Ep:182, loss:0.00000, loss_test:0.09056, lr:3.02e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.671, tt:6893.872\n",
      "Ep:183, loss:0.00000, loss_test:0.08981, lr:2.99e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.675, tt:6932.262\n",
      "Ep:184, loss:0.00000, loss_test:0.08959, lr:2.96e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.675, tt:6969.836\n",
      "Ep:185, loss:0.00000, loss_test:0.09050, lr:2.93e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.675, tt:7007.533\n",
      "Ep:186, loss:0.00000, loss_test:0.09032, lr:2.90e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.677, tt:7045.513\n",
      "Ep:187, loss:0.00000, loss_test:0.09006, lr:2.88e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.702, tt:7087.981\n",
      "Ep:188, loss:0.00000, loss_test:0.08982, lr:2.85e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.698, tt:7124.996\n",
      "Ep:189, loss:0.00000, loss_test:0.09009, lr:2.82e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.698, tt:7162.574\n",
      "Ep:190, loss:0.00000, loss_test:0.09050, lr:2.79e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.689, tt:7198.682\n",
      "Ep:191, loss:0.00000, loss_test:0.09017, lr:2.76e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.684, tt:7235.349\n",
      "Ep:192, loss:0.00000, loss_test:0.08962, lr:2.73e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.680, tt:7272.305\n",
      "Ep:193, loss:0.00000, loss_test:0.09011, lr:2.71e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.684, tt:7310.632\n",
      "Ep:194, loss:0.00000, loss_test:0.09024, lr:2.68e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.668, tt:7345.339\n",
      "Ep:195, loss:0.00000, loss_test:0.08993, lr:2.65e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.669, tt:7383.145\n",
      "Ep:196, loss:0.00000, loss_test:0.08995, lr:2.63e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.667, tt:7420.353\n",
      "Ep:197, loss:0.00000, loss_test:0.08970, lr:2.60e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.673, tt:7459.288\n",
      "Ep:198, loss:0.00000, loss_test:0.09020, lr:2.57e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.662, tt:7494.748\n",
      "Ep:199, loss:0.00000, loss_test:0.09003, lr:2.55e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.665, tt:7532.951\n",
      "Ep:200, loss:0.00000, loss_test:0.08980, lr:2.52e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.653, tt:7568.201\n",
      "Ep:201, loss:0.00000, loss_test:0.08990, lr:2.50e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.650, tt:7605.247\n",
      "Ep:202, loss:0.00000, loss_test:0.09010, lr:2.47e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.654, tt:7643.802\n",
      "Ep:203, loss:0.00000, loss_test:0.09033, lr:2.45e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.649, tt:7680.374\n",
      "Ep:204, loss:0.00000, loss_test:0.09020, lr:2.42e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.648, tt:7717.742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.08991, lr:2.40e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.649, tt:7755.644\n",
      "Ep:206, loss:0.00000, loss_test:0.09021, lr:2.38e-03, fs:0.71429 (r=0.556,p=1.000),  time:37.646, tt:7792.620\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00082, loss_test:0.01960, lr:1.00e-02, fs:0.67500 (r=0.931,p=0.529),  time:658.176, tt:658.176\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01757, lr:1.00e-02, fs:0.69955 (r=0.897,p=0.574),  time:657.707, tt:1315.415\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01650, lr:1.00e-02, fs:0.70874 (r=0.839,p=0.613),  time:657.134, tt:1971.403\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01566, lr:1.00e-02, fs:0.74627 (r=0.862,p=0.658),  time:654.825, tt:2619.299\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.01487, lr:1.00e-02, fs:0.77778 (r=0.885,p=0.694),  time:655.461, tt:3277.305\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.01421, lr:1.00e-02, fs:0.77320 (r=0.862,p=0.701),  time:655.552, tt:3933.311\n",
      "Ep:6, loss:0.00036, loss_test:0.01373, lr:1.00e-02, fs:0.78125 (r=0.862,p=0.714),  time:654.052, tt:4578.367\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00033, loss_test:0.01312, lr:1.00e-02, fs:0.78125 (r=0.862,p=0.714),  time:654.134, tt:5233.076\n",
      "Ep:8, loss:0.00030, loss_test:0.01260, lr:1.00e-02, fs:0.79787 (r=0.862,p=0.743),  time:653.559, tt:5882.033\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.01223, lr:1.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:654.331, tt:6543.307\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.01193, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:654.160, tt:7195.760\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.01170, lr:1.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:653.460, tt:7841.520\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01155, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:653.255, tt:8492.313\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.01128, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:653.003, tt:9142.043\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.01121, lr:1.00e-02, fs:0.86207 (r=0.862,p=0.862),  time:652.601, tt:9789.011\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.01117, lr:1.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:652.566, tt:10441.050\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.01123, lr:1.00e-02, fs:0.88235 (r=0.862,p=0.904),  time:652.520, tt:11092.832\n",
      "Ep:17, loss:0.00013, loss_test:0.01128, lr:1.00e-02, fs:0.89286 (r=0.862,p=0.926),  time:652.086, tt:11737.543\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00013, loss_test:0.01140, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:652.037, tt:12388.694\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.01141, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:651.790, tt:13035.802\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00011, loss_test:0.01167, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:651.675, tt:13685.174\n",
      "Ep:21, loss:0.00010, loss_test:0.01191, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:651.761, tt:14338.745\n",
      "Ep:22, loss:0.00009, loss_test:0.01209, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:652.235, tt:15001.414\n",
      "Ep:23, loss:0.00009, loss_test:0.01232, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:652.947, tt:15670.725\n",
      "Ep:24, loss:0.00008, loss_test:0.01247, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:652.764, tt:16319.110\n",
      "Ep:25, loss:0.00008, loss_test:0.01274, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:653.093, tt:16980.408\n",
      "Ep:26, loss:0.00007, loss_test:0.01296, lr:1.00e-02, fs:0.90909 (r=0.862,p=0.962),  time:652.071, tt:17605.917\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00095, loss_test:0.02122, lr:1.00e-02, fs:0.66935 (r=0.954,p=0.516),  time:635.630, tt:635.630\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00068, loss_test:0.01783, lr:1.00e-02, fs:0.70852 (r=0.908,p=0.581),  time:645.192, tt:1290.384\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00059, loss_test:0.01663, lr:1.00e-02, fs:0.72558 (r=0.897,p=0.609),  time:651.954, tt:1955.863\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.01585, lr:1.00e-02, fs:0.72727 (r=0.874,p=0.623),  time:653.037, tt:2612.148\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01533, lr:1.00e-02, fs:0.75248 (r=0.874,p=0.661),  time:652.790, tt:3263.949\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00042, loss_test:0.01472, lr:1.00e-02, fs:0.80392 (r=0.943,p=0.701),  time:652.927, tt:3917.561\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00037, loss_test:0.01432, lr:1.00e-02, fs:0.80000 (r=0.920,p=0.708),  time:651.565, tt:4560.954\n",
      "Ep:7, loss:0.00034, loss_test:0.01384, lr:1.00e-02, fs:0.78974 (r=0.885,p=0.713),  time:652.372, tt:5218.973\n",
      "Ep:8, loss:0.00030, loss_test:0.01362, lr:1.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:651.822, tt:5866.397\n",
      "Ep:9, loss:0.00027, loss_test:0.01341, lr:1.00e-02, fs:0.81081 (r=0.862,p=0.765),  time:652.931, tt:6529.313\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.01328, lr:1.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:653.077, tt:7183.846\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.01309, lr:1.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:652.912, tt:7834.943\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.01324, lr:1.00e-02, fs:0.84270 (r=0.862,p=0.824),  time:653.425, tt:8494.524\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.01330, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:655.005, tt:9170.071\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.01358, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:656.191, tt:9842.860\n",
      "Ep:15, loss:0.00016, loss_test:0.01374, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:656.650, tt:10506.397\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.01399, lr:1.00e-02, fs:0.83832 (r=0.805,p=0.875),  time:656.970, tt:11168.498\n",
      "Ep:17, loss:0.00014, loss_test:0.01436, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:657.896, tt:11842.125\n",
      "Ep:18, loss:0.00013, loss_test:0.01466, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:658.705, tt:12515.404\n",
      "Ep:19, loss:0.00012, loss_test:0.01506, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:659.294, tt:13185.888\n",
      "Ep:20, loss:0.00011, loss_test:0.01537, lr:1.00e-02, fs:0.80000 (r=0.736,p=0.877),  time:659.806, tt:13855.934\n",
      "Ep:21, loss:0.00010, loss_test:0.01579, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:659.898, tt:14517.756\n",
      "Ep:22, loss:0.00010, loss_test:0.01617, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:660.154, tt:15183.532\n",
      "Ep:23, loss:0.00009, loss_test:0.01662, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:660.175, tt:15844.194\n",
      "Ep:24, loss:0.00008, loss_test:0.01710, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:660.303, tt:16507.587\n",
      "Ep:25, loss:0.00008, loss_test:0.01741, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:660.445, tt:17171.574\n",
      "Ep:26, loss:0.00008, loss_test:0.01782, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:659.848, tt:17815.892\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00076, loss_test:0.01891, lr:1.00e-02, fs:0.65844 (r=0.920,p=0.513),  time:690.521, tt:690.521\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01751, lr:1.00e-02, fs:0.70852 (r=0.908,p=0.581),  time:688.733, tt:1377.467\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.01683, lr:1.00e-02, fs:0.71296 (r=0.885,p=0.597),  time:689.379, tt:2068.136\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01621, lr:1.00e-02, fs:0.74146 (r=0.874,p=0.644),  time:690.636, tt:2762.546\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01565, lr:1.00e-02, fs:0.77295 (r=0.920,p=0.667),  time:692.526, tt:3462.631\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.01521, lr:1.00e-02, fs:0.78641 (r=0.931,p=0.681),  time:692.572, tt:4155.434\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.01474, lr:1.00e-02, fs:0.80193 (r=0.954,p=0.692),  time:692.492, tt:4847.447\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01433, lr:1.00e-02, fs:0.82524 (r=0.977,p=0.714),  time:693.270, tt:5546.158\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.01397, lr:1.00e-02, fs:0.84466 (r=1.000,p=0.731),  time:694.001, tt:6246.009\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01365, lr:1.00e-02, fs:0.84878 (r=1.000,p=0.737),  time:693.806, tt:6938.059\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01340, lr:1.00e-02, fs:0.85000 (r=0.977,p=0.752),  time:693.274, tt:7626.019\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.01316, lr:1.00e-02, fs:0.85859 (r=0.977,p=0.766),  time:693.205, tt:8318.456\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.01289, lr:1.00e-02, fs:0.86294 (r=0.977,p=0.773),  time:693.758, tt:9018.848\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.01271, lr:1.00e-02, fs:0.86735 (r=0.977,p=0.780),  time:694.019, tt:9716.262\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.01257, lr:1.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:693.738, tt:10406.077\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.01239, lr:1.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:693.610, tt:11097.754\n",
      "Ep:16, loss:0.00024, loss_test:0.01224, lr:1.00e-02, fs:0.88542 (r=0.977,p=0.810),  time:693.556, tt:11790.456\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.01219, lr:1.00e-02, fs:0.87831 (r=0.954,p=0.814),  time:693.125, tt:12476.241\n",
      "Ep:18, loss:0.00022, loss_test:0.01201, lr:1.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:693.348, tt:13173.620\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.01199, lr:1.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:693.308, tt:13866.160\n",
      "Ep:20, loss:0.00020, loss_test:0.01193, lr:1.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:693.586, tt:14565.304\n",
      "Ep:21, loss:0.00019, loss_test:0.01190, lr:1.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:693.782, tt:15263.196\n",
      "Ep:22, loss:0.00018, loss_test:0.01196, lr:1.00e-02, fs:0.89247 (r=0.954,p=0.838),  time:693.864, tt:15958.879\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.01193, lr:1.00e-02, fs:0.89247 (r=0.954,p=0.838),  time:693.711, tt:16649.075\n",
      "Ep:24, loss:0.00016, loss_test:0.01192, lr:1.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:693.768, tt:17344.209\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.01195, lr:1.00e-02, fs:0.90217 (r=0.954,p=0.856),  time:693.633, tt:18034.459\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.01199, lr:1.00e-02, fs:0.90217 (r=0.954,p=0.856),  time:693.257, tt:18717.935\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.02043, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:680.842, tt:680.842\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00064, loss_test:0.01820, lr:1.00e-02, fs:0.68444 (r=0.885,p=0.558),  time:687.586, tt:1375.172\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00059, loss_test:0.01748, lr:1.00e-02, fs:0.69683 (r=0.885,p=0.575),  time:690.745, tt:2072.236\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00056, loss_test:0.01700, lr:1.00e-02, fs:0.71233 (r=0.897,p=0.591),  time:690.891, tt:2763.564\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00054, loss_test:0.01656, lr:1.00e-02, fs:0.71889 (r=0.897,p=0.600),  time:691.923, tt:3459.613\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00051, loss_test:0.01618, lr:1.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:693.280, tt:4159.677\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00049, loss_test:0.01583, lr:1.00e-02, fs:0.74528 (r=0.908,p=0.632),  time:701.826, tt:4912.784\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.01547, lr:1.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:702.351, tt:5618.804\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00046, loss_test:0.01515, lr:1.00e-02, fs:0.79412 (r=0.931,p=0.692),  time:702.357, tt:6321.215\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.01482, lr:1.00e-02, fs:0.80788 (r=0.943,p=0.707),  time:702.149, tt:7021.492\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01454, lr:1.00e-02, fs:0.81373 (r=0.954,p=0.709),  time:702.755, tt:7730.304\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.01425, lr:1.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:702.183, tt:8426.199\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00040, loss_test:0.01401, lr:1.00e-02, fs:0.83744 (r=0.977,p=0.733),  time:702.098, tt:9127.272\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00038, loss_test:0.01375, lr:1.00e-02, fs:0.84314 (r=0.989,p=0.735),  time:702.285, tt:9831.989\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00037, loss_test:0.01354, lr:1.00e-02, fs:0.85294 (r=1.000,p=0.744),  time:701.139, tt:10517.089\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00036, loss_test:0.01331, lr:1.00e-02, fs:0.84729 (r=0.989,p=0.741),  time:700.623, tt:11209.961\n",
      "Ep:16, loss:0.00035, loss_test:0.01313, lr:1.00e-02, fs:0.85149 (r=0.989,p=0.748),  time:701.048, tt:11917.814\n",
      "Ep:17, loss:0.00033, loss_test:0.01291, lr:1.00e-02, fs:0.85572 (r=0.989,p=0.754),  time:700.966, tt:12617.396\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00032, loss_test:0.01275, lr:1.00e-02, fs:0.85572 (r=0.989,p=0.754),  time:700.500, tt:13309.507\n",
      "Ep:19, loss:0.00031, loss_test:0.01260, lr:1.00e-02, fs:0.86869 (r=0.989,p=0.775),  time:700.374, tt:14007.473\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00030, loss_test:0.01247, lr:1.00e-02, fs:0.86869 (r=0.989,p=0.775),  time:700.384, tt:14708.074\n",
      "Ep:21, loss:0.00029, loss_test:0.01231, lr:1.00e-02, fs:0.87755 (r=0.989,p=0.789),  time:700.514, tt:15411.301\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00028, loss_test:0.01224, lr:1.00e-02, fs:0.89119 (r=0.989,p=0.811),  time:700.188, tt:16104.334\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00027, loss_test:0.01214, lr:1.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:700.500, tt:16811.989\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00027, loss_test:0.01202, lr:1.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:700.531, tt:17513.263\n",
      "Ep:25, loss:0.00026, loss_test:0.01191, lr:1.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:700.506, tt:18213.166\n",
      "Ep:26, loss:0.00025, loss_test:0.01184, lr:1.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:700.703, tt:18918.976\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00082, loss_test:0.01974, lr:1.00e-02, fs:0.64844 (r=0.954,p=0.491),  time:581.412, tt:581.412\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01742, lr:1.00e-02, fs:0.70270 (r=0.897,p=0.578),  time:584.343, tt:1168.686\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01661, lr:1.00e-02, fs:0.72558 (r=0.897,p=0.609),  time:591.329, tt:1773.986\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.01601, lr:1.00e-02, fs:0.74641 (r=0.897,p=0.639),  time:593.125, tt:2372.499\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01551, lr:1.00e-02, fs:0.75829 (r=0.920,p=0.645),  time:594.684, tt:2973.420\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00046, loss_test:0.01507, lr:1.00e-02, fs:0.78095 (r=0.943,p=0.667),  time:594.239, tt:3565.433\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.01464, lr:1.00e-02, fs:0.78846 (r=0.943,p=0.678),  time:594.115, tt:4158.806\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.01425, lr:1.00e-02, fs:0.80198 (r=0.931,p=0.704),  time:594.475, tt:4755.798\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.01392, lr:1.00e-02, fs:0.80788 (r=0.943,p=0.707),  time:595.294, tt:5357.643\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.01360, lr:1.00e-02, fs:0.81188 (r=0.943,p=0.713),  time:595.418, tt:5954.180\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.01330, lr:1.00e-02, fs:0.83333 (r=0.977,p=0.726),  time:595.504, tt:6550.540\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.01301, lr:1.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:595.748, tt:7148.977\n",
      "Ep:12, loss:0.00032, loss_test:0.01282, lr:1.00e-02, fs:0.83249 (r=0.943,p=0.745),  time:595.565, tt:7742.343\n",
      "Ep:13, loss:0.00030, loss_test:0.01260, lr:1.00e-02, fs:0.84103 (r=0.943,p=0.759),  time:596.330, tt:8348.627\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.01243, lr:1.00e-02, fs:0.84536 (r=0.943,p=0.766),  time:596.563, tt:8948.440\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.01224, lr:1.00e-02, fs:0.84974 (r=0.943,p=0.774),  time:596.896, tt:9550.336\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.01211, lr:1.00e-02, fs:0.83158 (r=0.908,p=0.767),  time:596.460, tt:10139.821\n",
      "Ep:17, loss:0.00025, loss_test:0.01197, lr:1.00e-02, fs:0.82353 (r=0.885,p=0.770),  time:596.336, tt:10734.055\n",
      "Ep:18, loss:0.00024, loss_test:0.01186, lr:1.00e-02, fs:0.83696 (r=0.885,p=0.794),  time:596.598, tt:11335.367\n",
      "Ep:19, loss:0.00023, loss_test:0.01175, lr:1.00e-02, fs:0.83243 (r=0.885,p=0.786),  time:596.921, tt:11938.426\n",
      "Ep:20, loss:0.00022, loss_test:0.01166, lr:1.00e-02, fs:0.83060 (r=0.874,p=0.792),  time:596.685, tt:12530.384\n",
      "Ep:21, loss:0.00021, loss_test:0.01163, lr:1.00e-02, fs:0.82022 (r=0.839,p=0.802),  time:596.780, tt:13129.158\n",
      "Ep:22, loss:0.00020, loss_test:0.01158, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:596.699, tt:13724.073\n",
      "Ep:23, loss:0.00019, loss_test:0.01149, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:596.574, tt:14317.770\n",
      "Ep:24, loss:0.00019, loss_test:0.01148, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:594.358, tt:14858.938\n",
      "Ep:25, loss:0.00018, loss_test:0.01146, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:591.940, tt:15390.449\n",
      "Ep:26, loss:0.00017, loss_test:0.01153, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:590.142, tt:15933.844\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00094, loss_test:0.02107, lr:1.00e-02, fs:0.67234 (r=0.908,p=0.534),  time:590.824, tt:590.824\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00068, loss_test:0.01691, lr:1.00e-02, fs:0.69058 (r=0.885,p=0.566),  time:590.737, tt:1181.474\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01480, lr:1.00e-02, fs:0.74886 (r=0.943,p=0.621),  time:594.730, tt:1784.189\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.01311, lr:1.00e-02, fs:0.79426 (r=0.954,p=0.680),  time:595.099, tt:2380.395\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00037, loss_test:0.01193, lr:1.00e-02, fs:0.82353 (r=0.966,p=0.718),  time:596.219, tt:2981.093\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00031, loss_test:0.01106, lr:1.00e-02, fs:0.85572 (r=0.989,p=0.754),  time:597.363, tt:3584.181\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.01078, lr:1.00e-02, fs:0.84043 (r=0.908,p=0.782),  time:597.534, tt:4182.741\n",
      "Ep:7, loss:0.00022, loss_test:0.01042, lr:1.00e-02, fs:0.84615 (r=0.885,p=0.811),  time:598.097, tt:4784.778\n",
      "Ep:8, loss:0.00019, loss_test:0.01045, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:598.247, tt:5384.221\n",
      "Ep:9, loss:0.00016, loss_test:0.01073, lr:1.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:597.999, tt:5979.994\n",
      "Ep:10, loss:0.00014, loss_test:0.01089, lr:1.00e-02, fs:0.87209 (r=0.862,p=0.882),  time:598.414, tt:6582.554\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00012, loss_test:0.01102, lr:1.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:599.167, tt:7190.001\n",
      "Ep:12, loss:0.00011, loss_test:0.01139, lr:1.00e-02, fs:0.87059 (r=0.851,p=0.892),  time:599.454, tt:7792.904\n",
      "Ep:13, loss:0.00009, loss_test:0.01160, lr:1.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:599.228, tt:8389.196\n",
      "Ep:14, loss:0.00008, loss_test:0.01205, lr:1.00e-02, fs:0.84663 (r=0.793,p=0.908),  time:599.364, tt:8990.458\n",
      "Ep:15, loss:0.00007, loss_test:0.01274, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:599.599, tt:9593.590\n",
      "Ep:16, loss:0.00007, loss_test:0.01325, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:599.272, tt:10187.632\n",
      "Ep:17, loss:0.00006, loss_test:0.01362, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:599.390, tt:10789.015\n",
      "Ep:18, loss:0.00006, loss_test:0.01426, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:599.004, tt:11381.071\n",
      "Ep:19, loss:0.00005, loss_test:0.01484, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:599.043, tt:11980.854\n",
      "Ep:20, loss:0.00005, loss_test:0.01557, lr:1.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:595.897, tt:12513.829\n",
      "Ep:21, loss:0.00004, loss_test:0.01590, lr:1.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:590.462, tt:12990.171\n",
      "Ep:22, loss:0.00004, loss_test:0.01626, lr:9.90e-03, fs:0.82353 (r=0.724,p=0.955),  time:584.335, tt:13439.701\n",
      "Ep:23, loss:0.00004, loss_test:0.01672, lr:9.80e-03, fs:0.82353 (r=0.724,p=0.955),  time:577.234, tt:13853.613\n",
      "Ep:24, loss:0.00003, loss_test:0.01705, lr:9.70e-03, fs:0.82895 (r=0.724,p=0.969),  time:566.772, tt:14169.289\n",
      "Ep:25, loss:0.00003, loss_test:0.01748, lr:9.61e-03, fs:0.82895 (r=0.724,p=0.969),  time:554.293, tt:14411.630\n",
      "Ep:26, loss:0.00003, loss_test:0.01788, lr:9.51e-03, fs:0.82895 (r=0.724,p=0.969),  time:542.479, tt:14646.931\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00072, loss_test:0.01768, lr:1.00e-02, fs:0.69406 (r=0.874,p=0.576),  time:693.933, tt:693.933\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.01610, lr:1.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:674.456, tt:1348.913\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00049, loss_test:0.01522, lr:1.00e-02, fs:0.76555 (r=0.920,p=0.656),  time:664.488, tt:1993.464\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00044, loss_test:0.01447, lr:1.00e-02, fs:0.79024 (r=0.931,p=0.686),  time:664.091, tt:2656.363\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01384, lr:1.00e-02, fs:0.81951 (r=0.966,p=0.712),  time:662.699, tt:3313.494\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.01318, lr:1.00e-02, fs:0.85149 (r=0.989,p=0.748),  time:661.233, tt:3967.400\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00034, loss_test:0.01263, lr:1.00e-02, fs:0.88776 (r=1.000,p=0.798),  time:660.111, tt:4620.775\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.01228, lr:1.00e-02, fs:0.90155 (r=1.000,p=0.821),  time:659.531, tt:5276.248\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.01193, lr:1.00e-02, fs:0.90155 (r=1.000,p=0.821),  time:658.344, tt:5925.096\n",
      "Ep:9, loss:0.00026, loss_test:0.01171, lr:1.00e-02, fs:0.90155 (r=1.000,p=0.821),  time:662.536, tt:6625.362\n",
      "Ep:10, loss:0.00024, loss_test:0.01144, lr:1.00e-02, fs:0.91579 (r=1.000,p=0.845),  time:669.821, tt:7368.026\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.01133, lr:1.00e-02, fs:0.93048 (r=1.000,p=0.870),  time:675.826, tt:8109.916\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01127, lr:1.00e-02, fs:0.93048 (r=1.000,p=0.870),  time:681.082, tt:8854.061\n",
      "Ep:13, loss:0.00019, loss_test:0.01109, lr:1.00e-02, fs:0.94565 (r=1.000,p=0.897),  time:685.499, tt:9596.991\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.01105, lr:1.00e-02, fs:0.96667 (r=1.000,p=0.935),  time:689.545, tt:10343.181\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.01103, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:692.694, tt:11083.109\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.01107, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:695.645, tt:11825.965\n",
      "Ep:17, loss:0.00014, loss_test:0.01099, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:698.136, tt:12566.441\n",
      "Ep:18, loss:0.00013, loss_test:0.01116, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:700.397, tt:13307.548\n",
      "Ep:19, loss:0.00013, loss_test:0.01125, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:702.963, tt:14059.256\n",
      "Ep:20, loss:0.00012, loss_test:0.01135, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:704.502, tt:14794.539\n",
      "Ep:21, loss:0.00011, loss_test:0.01150, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:706.177, tt:15535.903\n",
      "Ep:22, loss:0.00010, loss_test:0.01159, lr:1.00e-02, fs:0.97753 (r=1.000,p=0.956),  time:707.791, tt:16279.187\n",
      "Ep:23, loss:0.00010, loss_test:0.01169, lr:1.00e-02, fs:0.98305 (r=1.000,p=0.967),  time:709.405, tt:17025.717\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.01189, lr:1.00e-02, fs:0.98305 (r=1.000,p=0.967),  time:710.515, tt:17762.880\n",
      "Ep:25, loss:0.00009, loss_test:0.01197, lr:1.00e-02, fs:0.98305 (r=1.000,p=0.967),  time:711.803, tt:18506.882\n",
      "Ep:26, loss:0.00008, loss_test:0.01214, lr:1.00e-02, fs:0.98305 (r=1.000,p=0.967),  time:712.862, tt:19247.282\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14394, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.516, tt:45.516\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14269, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.920, tt:93.840\n",
      "Ep:2, loss:0.00001, loss_test:0.14051, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:46.608, tt:139.825\n",
      "Ep:3, loss:0.00001, loss_test:0.13692, lr:1.00e-02, fs:0.65370 (r=0.966,p=0.494),  time:46.717, tt:186.868\n",
      "Ep:4, loss:0.00001, loss_test:0.13113, lr:1.00e-02, fs:0.66667 (r=0.943,p=0.516),  time:46.944, tt:234.719\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.12315, lr:1.00e-02, fs:0.67580 (r=0.851,p=0.561),  time:47.254, tt:283.522\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.11703, lr:1.00e-02, fs:0.64894 (r=0.701,p=0.604),  time:47.401, tt:331.805\n",
      "Ep:7, loss:0.00001, loss_test:0.11478, lr:1.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:47.567, tt:380.532\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.11080, lr:1.00e-02, fs:0.68041 (r=0.759,p=0.617),  time:47.790, tt:430.113\n",
      "Ep:9, loss:0.00001, loss_test:0.10650, lr:1.00e-02, fs:0.70270 (r=0.747,p=0.663),  time:48.052, tt:480.520\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.10337, lr:1.00e-02, fs:0.71676 (r=0.713,p=0.721),  time:48.196, tt:530.156\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00001, loss_test:0.10124, lr:1.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:48.297, tt:579.560\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00001, loss_test:0.09927, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:48.313, tt:628.071\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.09750, lr:1.00e-02, fs:0.72727 (r=0.736,p=0.719),  time:48.359, tt:677.020\n",
      "Ep:14, loss:0.00001, loss_test:0.09537, lr:1.00e-02, fs:0.74444 (r=0.770,p=0.720),  time:48.878, tt:733.168\n",
      "Ep:15, loss:0.00001, loss_test:0.09355, lr:1.00e-02, fs:0.75824 (r=0.793,p=0.726),  time:48.839, tt:781.417\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09231, lr:1.00e-02, fs:0.73446 (r=0.747,p=0.722),  time:48.845, tt:830.357\n",
      "Ep:17, loss:0.00001, loss_test:0.09017, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:48.792, tt:878.256\n",
      "Ep:18, loss:0.00001, loss_test:0.08879, lr:1.00e-02, fs:0.74576 (r=0.759,p=0.733),  time:48.731, tt:925.880\n",
      "Ep:19, loss:0.00001, loss_test:0.08813, lr:1.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:48.760, tt:975.204\n",
      "Ep:20, loss:0.00001, loss_test:0.08669, lr:1.00e-02, fs:0.75281 (r=0.770,p=0.736),  time:48.670, tt:1022.067\n",
      "Ep:21, loss:0.00001, loss_test:0.08643, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:48.645, tt:1070.186\n",
      "Ep:22, loss:0.00001, loss_test:0.08512, lr:1.00e-02, fs:0.75281 (r=0.770,p=0.736),  time:48.628, tt:1118.434\n",
      "Ep:23, loss:0.00001, loss_test:0.08417, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:48.686, tt:1168.465\n",
      "Ep:24, loss:0.00001, loss_test:0.08271, lr:1.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:48.666, tt:1216.645\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.08153, lr:1.00e-02, fs:0.78161 (r=0.782,p=0.782),  time:48.634, tt:1264.488\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.07989, lr:1.00e-02, fs:0.79545 (r=0.805,p=0.787),  time:48.589, tt:1311.908\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.07890, lr:1.00e-02, fs:0.78857 (r=0.793,p=0.784),  time:48.570, tt:1359.948\n",
      "Ep:28, loss:0.00001, loss_test:0.07782, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:48.506, tt:1406.679\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.07629, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:48.492, tt:1454.758\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.07470, lr:1.00e-02, fs:0.80000 (r=0.782,p=0.819),  time:48.527, tt:1504.336\n",
      "Ep:31, loss:0.00000, loss_test:0.07283, lr:1.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:48.552, tt:1553.679\n",
      "Ep:32, loss:0.00000, loss_test:0.07236, lr:1.00e-02, fs:0.80000 (r=0.759,p=0.846),  time:48.687, tt:1606.682\n",
      "Ep:33, loss:0.00000, loss_test:0.07050, lr:1.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:48.726, tt:1656.686\n",
      "Ep:34, loss:0.00000, loss_test:0.06932, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:48.740, tt:1705.897\n",
      "Ep:35, loss:0.00000, loss_test:0.06809, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:48.743, tt:1754.763\n",
      "Ep:36, loss:0.00000, loss_test:0.06698, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:48.748, tt:1803.681\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.06658, lr:1.00e-02, fs:0.83230 (r=0.770,p=0.905),  time:48.681, tt:1849.894\n",
      "Ep:38, loss:0.00000, loss_test:0.06603, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:48.709, tt:1899.654\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.06558, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:48.738, tt:1949.512\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.06431, lr:1.00e-02, fs:0.83436 (r=0.782,p=0.895),  time:48.741, tt:1998.394\n",
      "Ep:41, loss:0.00000, loss_test:0.06560, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:48.736, tt:2046.898\n",
      "Ep:42, loss:0.00000, loss_test:0.06424, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:48.612, tt:2090.336\n",
      "Ep:43, loss:0.00000, loss_test:0.06325, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:48.591, tt:2137.992\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.06382, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:48.616, tt:2187.716\n",
      "Ep:45, loss:0.00000, loss_test:0.06470, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:48.603, tt:2235.723\n",
      "Ep:46, loss:0.00000, loss_test:0.06371, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:48.635, tt:2285.848\n",
      "Ep:47, loss:0.00000, loss_test:0.06371, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:48.624, tt:2333.949\n",
      "Ep:48, loss:0.00000, loss_test:0.06366, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:48.616, tt:2382.170\n",
      "Ep:49, loss:0.00000, loss_test:0.06600, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:48.653, tt:2432.641\n",
      "Ep:50, loss:0.00000, loss_test:0.06367, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:48.641, tt:2480.704\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00000, loss_test:0.06470, lr:1.00e-02, fs:0.85535 (r=0.782,p=0.944),  time:48.676, tt:2531.142\n",
      "Ep:52, loss:0.00000, loss_test:0.06184, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:48.694, tt:2580.782\n",
      "Ep:53, loss:0.00000, loss_test:0.06372, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:48.685, tt:2629.003\n",
      "Ep:54, loss:0.00000, loss_test:0.06652, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:48.697, tt:2678.311\n",
      "Ep:55, loss:0.00000, loss_test:0.06644, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:48.634, tt:2723.527\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00000, loss_test:0.06251, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:48.659, tt:2773.546\n",
      "Ep:57, loss:0.00000, loss_test:0.06259, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:48.635, tt:2820.849\n",
      "Ep:58, loss:0.00000, loss_test:0.06110, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:48.630, tt:2869.192\n",
      "Ep:59, loss:0.00000, loss_test:0.06370, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.597, tt:2915.824\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00000, loss_test:0.06478, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.606, tt:2964.992\n",
      "Ep:61, loss:0.00000, loss_test:0.06534, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.600, tt:3013.191\n",
      "Ep:62, loss:0.00000, loss_test:0.06267, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.568, tt:3059.759\n",
      "Ep:63, loss:0.00000, loss_test:0.06282, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:48.540, tt:3106.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00000, loss_test:0.06330, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:48.531, tt:3154.519\n",
      "Ep:65, loss:0.00000, loss_test:0.06140, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:48.526, tt:3202.734\n",
      "Ep:66, loss:0.00000, loss_test:0.06443, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.517, tt:3250.666\n",
      "Ep:67, loss:0.00000, loss_test:0.06566, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.517, tt:3299.137\n",
      "Ep:68, loss:0.00000, loss_test:0.06803, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.517, tt:3347.687\n",
      "Ep:69, loss:0.00000, loss_test:0.06433, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:48.513, tt:3395.895\n",
      "Ep:70, loss:0.00000, loss_test:0.06505, lr:1.00e-02, fs:0.86624 (r=0.782,p=0.971),  time:48.525, tt:3445.277\n",
      "Ep:71, loss:0.00000, loss_test:0.06427, lr:9.90e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.531, tt:3494.237\n",
      "Ep:72, loss:0.00000, loss_test:0.06732, lr:9.80e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.529, tt:3542.585\n",
      "Ep:73, loss:0.00000, loss_test:0.06687, lr:9.70e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.533, tt:3591.413\n",
      "Ep:74, loss:0.00000, loss_test:0.06696, lr:9.61e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.526, tt:3639.443\n",
      "Ep:75, loss:0.00000, loss_test:0.06643, lr:9.51e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.527, tt:3688.030\n",
      "Ep:76, loss:0.00000, loss_test:0.06592, lr:9.41e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.517, tt:3735.805\n",
      "Ep:77, loss:0.00000, loss_test:0.06499, lr:9.32e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.508, tt:3783.611\n",
      "Ep:78, loss:0.00000, loss_test:0.06500, lr:9.23e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.489, tt:3830.663\n",
      "Ep:79, loss:0.00000, loss_test:0.06600, lr:9.14e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.467, tt:3877.337\n",
      "Ep:80, loss:0.00000, loss_test:0.06636, lr:9.04e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.456, tt:3924.941\n",
      "Ep:81, loss:0.00000, loss_test:0.06609, lr:8.95e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.443, tt:3972.364\n",
      "Ep:82, loss:0.00000, loss_test:0.06463, lr:8.86e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.469, tt:4022.964\n",
      "Ep:83, loss:0.00000, loss_test:0.06614, lr:8.78e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.452, tt:4069.971\n",
      "Ep:84, loss:0.00000, loss_test:0.06557, lr:8.69e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.433, tt:4116.825\n",
      "Ep:85, loss:0.00000, loss_test:0.06657, lr:8.60e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.398, tt:4162.220\n",
      "Ep:86, loss:0.00000, loss_test:0.06615, lr:8.51e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.385, tt:4209.503\n",
      "Ep:87, loss:0.00000, loss_test:0.06678, lr:8.43e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.365, tt:4256.092\n",
      "Ep:88, loss:0.00000, loss_test:0.06613, lr:8.35e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.359, tt:4303.911\n",
      "Ep:89, loss:0.00000, loss_test:0.06569, lr:8.26e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.363, tt:4352.646\n",
      "Ep:90, loss:0.00000, loss_test:0.06655, lr:8.18e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.296, tt:4394.950\n",
      "Ep:91, loss:0.00000, loss_test:0.06772, lr:8.10e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.229, tt:4437.052\n",
      "Ep:92, loss:0.00000, loss_test:0.06650, lr:8.02e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.159, tt:4478.795\n",
      "Ep:93, loss:0.00000, loss_test:0.06669, lr:7.94e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.079, tt:4519.458\n",
      "Ep:94, loss:0.00000, loss_test:0.06800, lr:7.86e-03, fs:0.87179 (r=0.782,p=0.986),  time:48.017, tt:4561.604\n",
      "Ep:95, loss:0.00000, loss_test:0.06750, lr:7.78e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.939, tt:4602.166\n",
      "Ep:96, loss:0.00000, loss_test:0.06725, lr:7.70e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.864, tt:4642.807\n",
      "Ep:97, loss:0.00000, loss_test:0.06773, lr:7.62e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.813, tt:4685.690\n",
      "Ep:98, loss:0.00000, loss_test:0.06804, lr:7.55e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.737, tt:4726.013\n",
      "Ep:99, loss:0.00000, loss_test:0.06802, lr:7.47e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.679, tt:4767.920\n",
      "Ep:100, loss:0.00000, loss_test:0.06747, lr:7.40e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.612, tt:4808.855\n",
      "Ep:101, loss:0.00000, loss_test:0.06817, lr:7.32e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.556, tt:4850.722\n",
      "Ep:102, loss:0.00000, loss_test:0.06833, lr:7.25e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.524, tt:4894.929\n",
      "Ep:103, loss:0.00000, loss_test:0.06771, lr:7.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.423, tt:4931.986\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00000, loss_test:0.06829, lr:7.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.289, tt:4965.330\n",
      "Ep:105, loss:0.00000, loss_test:0.06846, lr:7.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:47.133, tt:4996.095\n",
      "Ep:106, loss:0.00000, loss_test:0.06824, lr:7.18e-03, fs:0.87742 (r=0.782,p=1.000),  time:46.919, tt:5020.305\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14590, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.847, tt:46.847\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14513, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.330, tt:94.661\n",
      "Ep:2, loss:0.00001, loss_test:0.14387, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.818, tt:140.455\n",
      "Ep:3, loss:0.00001, loss_test:0.14179, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:47.188, tt:188.754\n",
      "Ep:4, loss:0.00001, loss_test:0.13818, lr:1.00e-02, fs:0.65116 (r=0.966,p=0.491),  time:47.170, tt:235.852\n",
      "Ep:5, loss:0.00001, loss_test:0.13174, lr:1.00e-02, fs:0.65587 (r=0.931,p=0.506),  time:47.308, tt:283.847\n",
      "Ep:6, loss:0.00001, loss_test:0.12206, lr:1.00e-02, fs:0.69725 (r=0.874,p=0.580),  time:48.715, tt:341.006\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.11590, lr:1.00e-02, fs:0.70899 (r=0.770,p=0.657),  time:48.402, tt:387.218\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.11219, lr:1.00e-02, fs:0.71958 (r=0.782,p=0.667),  time:48.340, tt:435.058\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.10950, lr:1.00e-02, fs:0.71287 (r=0.828,p=0.626),  time:48.062, tt:480.618\n",
      "Ep:10, loss:0.00001, loss_test:0.10690, lr:1.00e-02, fs:0.71066 (r=0.805,p=0.636),  time:47.945, tt:527.393\n",
      "Ep:11, loss:0.00001, loss_test:0.10516, lr:1.00e-02, fs:0.71823 (r=0.747,p=0.691),  time:47.852, tt:574.225\n",
      "Ep:12, loss:0.00001, loss_test:0.10380, lr:1.00e-02, fs:0.70857 (r=0.713,p=0.705),  time:47.749, tt:620.740\n",
      "Ep:13, loss:0.00001, loss_test:0.10067, lr:1.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:47.763, tt:668.687\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.09944, lr:1.00e-02, fs:0.73743 (r=0.759,p=0.717),  time:47.676, tt:715.145\n",
      "Ep:15, loss:0.00001, loss_test:0.09899, lr:1.00e-02, fs:0.70588 (r=0.690,p=0.723),  time:47.648, tt:762.364\n",
      "Ep:16, loss:0.00001, loss_test:0.09666, lr:1.00e-02, fs:0.74157 (r=0.759,p=0.725),  time:47.617, tt:809.496\n",
      "Ep:17, loss:0.00001, loss_test:0.09637, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:47.589, tt:856.601\n",
      "Ep:18, loss:0.00001, loss_test:0.09584, lr:1.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:47.600, tt:904.396\n",
      "Ep:19, loss:0.00001, loss_test:0.09450, lr:1.00e-02, fs:0.74286 (r=0.747,p=0.739),  time:47.724, tt:954.488\n",
      "Ep:20, loss:0.00001, loss_test:0.09543, lr:1.00e-02, fs:0.74713 (r=0.747,p=0.747),  time:47.824, tt:1004.307\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.09293, lr:1.00e-02, fs:0.74576 (r=0.759,p=0.733),  time:47.804, tt:1051.699\n",
      "Ep:22, loss:0.00001, loss_test:0.09371, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:47.847, tt:1100.470\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.09197, lr:1.00e-02, fs:0.75000 (r=0.759,p=0.742),  time:47.862, tt:1148.687\n",
      "Ep:24, loss:0.00001, loss_test:0.09102, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:47.862, tt:1196.542\n",
      "Ep:25, loss:0.00001, loss_test:0.08926, lr:1.00e-02, fs:0.76571 (r=0.770,p=0.761),  time:47.952, tt:1246.749\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.08801, lr:1.00e-02, fs:0.76836 (r=0.782,p=0.756),  time:47.911, tt:1293.591\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.08719, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:47.895, tt:1341.072\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.08515, lr:1.00e-02, fs:0.79096 (r=0.805,p=0.778),  time:47.851, tt:1387.672\n",
      "Ep:29, loss:0.00001, loss_test:0.08448, lr:1.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:47.853, tt:1435.604\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.08275, lr:1.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:47.920, tt:1485.532\n",
      "Ep:31, loss:0.00000, loss_test:0.08094, lr:1.00e-02, fs:0.80682 (r=0.816,p=0.798),  time:47.921, tt:1533.463\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.08092, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:47.920, tt:1581.371\n",
      "Ep:33, loss:0.00000, loss_test:0.07836, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:47.954, tt:1630.449\n",
      "Ep:34, loss:0.00000, loss_test:0.07942, lr:1.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:47.953, tt:1678.344\n",
      "Ep:35, loss:0.00000, loss_test:0.07664, lr:1.00e-02, fs:0.78613 (r=0.782,p=0.791),  time:47.940, tt:1725.835\n",
      "Ep:36, loss:0.00000, loss_test:0.07829, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:47.968, tt:1774.814\n",
      "Ep:37, loss:0.00000, loss_test:0.07476, lr:1.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:47.974, tt:1823.009\n",
      "Ep:38, loss:0.00000, loss_test:0.07591, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:47.950, tt:1870.051\n",
      "Ep:39, loss:0.00000, loss_test:0.07495, lr:1.00e-02, fs:0.81176 (r=0.793,p=0.831),  time:47.962, tt:1918.486\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00000, loss_test:0.07369, lr:1.00e-02, fs:0.79755 (r=0.747,p=0.855),  time:47.915, tt:1964.509\n",
      "Ep:41, loss:0.00000, loss_test:0.07445, lr:1.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:47.958, tt:2014.247\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00000, loss_test:0.07235, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:47.855, tt:2057.782\n",
      "Ep:43, loss:0.00000, loss_test:0.07365, lr:1.00e-02, fs:0.81481 (r=0.759,p=0.880),  time:47.861, tt:2105.902\n",
      "Ep:44, loss:0.00000, loss_test:0.07223, lr:1.00e-02, fs:0.83019 (r=0.759,p=0.917),  time:47.749, tt:2148.703\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00000, loss_test:0.07175, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:47.640, tt:2191.436\n",
      "Ep:46, loss:0.00000, loss_test:0.07296, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:47.582, tt:2236.355\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00000, loss_test:0.07097, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:47.538, tt:2281.805\n",
      "Ep:48, loss:0.00000, loss_test:0.07135, lr:1.00e-02, fs:0.80795 (r=0.701,p=0.953),  time:47.536, tt:2329.276\n",
      "Ep:49, loss:0.00000, loss_test:0.07105, lr:1.00e-02, fs:0.80537 (r=0.690,p=0.968),  time:47.548, tt:2377.419\n",
      "Ep:50, loss:0.00000, loss_test:0.06988, lr:1.00e-02, fs:0.79730 (r=0.678,p=0.967),  time:47.597, tt:2427.450\n",
      "Ep:51, loss:0.00000, loss_test:0.06982, lr:1.00e-02, fs:0.79452 (r=0.667,p=0.983),  time:47.637, tt:2477.100\n",
      "Ep:52, loss:0.00000, loss_test:0.06936, lr:1.00e-02, fs:0.81879 (r=0.701,p=0.984),  time:47.672, tt:2526.635\n",
      "Ep:53, loss:0.00000, loss_test:0.07014, lr:1.00e-02, fs:0.73381 (r=0.586,p=0.981),  time:47.684, tt:2574.962\n",
      "Ep:54, loss:0.00000, loss_test:0.06900, lr:1.00e-02, fs:0.72464 (r=0.575,p=0.980),  time:47.677, tt:2622.209\n",
      "Ep:55, loss:0.00000, loss_test:0.06744, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:47.672, tt:2669.604\n",
      "Ep:56, loss:0.00000, loss_test:0.06894, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:47.681, tt:2717.831\n",
      "Ep:57, loss:0.00000, loss_test:0.06682, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:47.688, tt:2765.901\n",
      "Ep:58, loss:0.00000, loss_test:0.06860, lr:9.90e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.702, tt:2814.396\n",
      "Ep:59, loss:0.00000, loss_test:0.06729, lr:9.80e-03, fs:0.72464 (r=0.575,p=0.980),  time:47.695, tt:2861.698\n",
      "Ep:60, loss:0.00000, loss_test:0.06931, lr:9.70e-03, fs:0.74286 (r=0.598,p=0.981),  time:47.684, tt:2908.701\n",
      "Ep:61, loss:0.00000, loss_test:0.06934, lr:9.61e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.701, tt:2957.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00000, loss_test:0.06686, lr:9.51e-03, fs:0.81081 (r=0.690,p=0.984),  time:47.725, tt:3006.682\n",
      "Ep:63, loss:0.00000, loss_test:0.06975, lr:9.41e-03, fs:0.72464 (r=0.575,p=0.980),  time:47.704, tt:3053.044\n",
      "Ep:64, loss:0.00000, loss_test:0.06767, lr:9.32e-03, fs:0.87179 (r=0.782,p=0.986),  time:47.701, tt:3100.535\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00000, loss_test:0.06849, lr:9.32e-03, fs:0.71533 (r=0.563,p=0.980),  time:47.715, tt:3149.175\n",
      "Ep:66, loss:0.00000, loss_test:0.06872, lr:9.32e-03, fs:0.75177 (r=0.609,p=0.981),  time:47.706, tt:3196.322\n",
      "Ep:67, loss:0.00000, loss_test:0.06942, lr:9.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.720, tt:3244.929\n",
      "Ep:68, loss:0.00000, loss_test:0.06633, lr:9.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.723, tt:3292.860\n",
      "Ep:69, loss:0.00000, loss_test:0.06872, lr:9.32e-03, fs:0.84211 (r=0.736,p=0.985),  time:47.722, tt:3340.519\n",
      "Ep:70, loss:0.00000, loss_test:0.06953, lr:9.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.692, tt:3386.130\n",
      "Ep:71, loss:0.00000, loss_test:0.06751, lr:9.32e-03, fs:0.79452 (r=0.667,p=0.983),  time:47.680, tt:3432.977\n",
      "Ep:72, loss:0.00000, loss_test:0.06891, lr:9.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.708, tt:3482.671\n",
      "Ep:73, loss:0.00000, loss_test:0.06803, lr:9.32e-03, fs:0.75177 (r=0.609,p=0.981),  time:47.724, tt:3531.611\n",
      "Ep:74, loss:0.00000, loss_test:0.07007, lr:9.32e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.735, tt:3580.109\n",
      "Ep:75, loss:0.00000, loss_test:0.06720, lr:9.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.746, tt:3628.700\n",
      "Ep:76, loss:0.00000, loss_test:0.06985, lr:9.23e-03, fs:0.76056 (r=0.621,p=0.982),  time:47.742, tt:3676.145\n",
      "Ep:77, loss:0.00000, loss_test:0.06774, lr:9.14e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.742, tt:3723.840\n",
      "Ep:78, loss:0.00000, loss_test:0.06950, lr:9.04e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.772, tt:3773.962\n",
      "Ep:79, loss:0.00000, loss_test:0.06848, lr:8.95e-03, fs:0.82667 (r=0.713,p=0.984),  time:47.794, tt:3823.485\n",
      "Ep:80, loss:0.00000, loss_test:0.06939, lr:8.86e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.815, tt:3873.048\n",
      "Ep:81, loss:0.00000, loss_test:0.06878, lr:8.78e-03, fs:0.80272 (r=0.678,p=0.983),  time:47.821, tt:3921.307\n",
      "Ep:82, loss:0.00000, loss_test:0.06824, lr:8.69e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.834, tt:3970.198\n",
      "Ep:83, loss:0.00000, loss_test:0.06827, lr:8.60e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.835, tt:4018.106\n",
      "Ep:84, loss:0.00000, loss_test:0.06862, lr:8.51e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.834, tt:4065.897\n",
      "Ep:85, loss:0.00000, loss_test:0.07041, lr:8.43e-03, fs:0.75177 (r=0.609,p=0.981),  time:47.835, tt:4113.828\n",
      "Ep:86, loss:0.00000, loss_test:0.07045, lr:8.35e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.847, tt:4162.703\n",
      "Ep:87, loss:0.00000, loss_test:0.06973, lr:8.26e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.844, tt:4210.314\n",
      "Ep:88, loss:0.00000, loss_test:0.06908, lr:8.18e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.847, tt:4258.350\n",
      "Ep:89, loss:0.00000, loss_test:0.06966, lr:8.10e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.834, tt:4305.066\n",
      "Ep:90, loss:0.00000, loss_test:0.07122, lr:8.02e-03, fs:0.79452 (r=0.667,p=0.983),  time:47.821, tt:4351.734\n",
      "Ep:91, loss:0.00000, loss_test:0.07088, lr:7.94e-03, fs:0.82667 (r=0.713,p=0.984),  time:47.844, tt:4401.672\n",
      "Ep:92, loss:0.00000, loss_test:0.06965, lr:7.86e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.845, tt:4449.564\n",
      "Ep:93, loss:0.00000, loss_test:0.07163, lr:7.78e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.845, tt:4497.436\n",
      "Ep:94, loss:0.00000, loss_test:0.07149, lr:7.70e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.825, tt:4543.389\n",
      "Ep:95, loss:0.00000, loss_test:0.07112, lr:7.62e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.812, tt:4589.937\n",
      "Ep:96, loss:0.00000, loss_test:0.07025, lr:7.55e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.774, tt:4634.052\n",
      "Ep:97, loss:0.00000, loss_test:0.07117, lr:7.47e-03, fs:0.82667 (r=0.713,p=0.984),  time:47.705, tt:4675.100\n",
      "Ep:98, loss:0.00000, loss_test:0.07281, lr:7.40e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.645, tt:4716.823\n",
      "Ep:99, loss:0.00000, loss_test:0.07089, lr:7.32e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.585, tt:4758.490\n",
      "Ep:100, loss:0.00000, loss_test:0.07008, lr:7.25e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.526, tt:4800.100\n",
      "Ep:101, loss:0.00000, loss_test:0.07212, lr:7.18e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.473, tt:4842.272\n",
      "Ep:102, loss:0.00000, loss_test:0.07309, lr:7.11e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.394, tt:4881.568\n",
      "Ep:103, loss:0.00000, loss_test:0.07053, lr:7.03e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.343, tt:4923.636\n",
      "Ep:104, loss:0.00000, loss_test:0.07161, lr:6.96e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.355, tt:4972.240\n",
      "Ep:105, loss:0.00000, loss_test:0.07419, lr:6.89e-03, fs:0.70588 (r=0.552,p=0.980),  time:47.325, tt:5016.482\n",
      "Ep:106, loss:0.00000, loss_test:0.07040, lr:6.83e-03, fs:0.83444 (r=0.724,p=0.984),  time:47.247, tt:5055.408\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00345, loss_test:0.12707, lr:4.00e-03, fs:0.66063 (r=0.737,p=0.598),  time:577.875, tt:577.875\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00261, loss_test:0.10041, lr:4.00e-03, fs:0.72637 (r=0.737,p=0.716),  time:581.555, tt:1163.110\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00198, loss_test:0.08859, lr:4.00e-03, fs:0.78756 (r=0.768,p=0.809),  time:580.041, tt:1740.123\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00144, loss_test:0.08465, lr:4.00e-03, fs:0.82540 (r=0.788,p=0.867),  time:581.915, tt:2327.662\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00096, loss_test:0.08268, lr:4.00e-03, fs:0.85870 (r=0.798,p=0.929),  time:580.114, tt:2900.572\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00060, loss_test:0.08677, lr:4.00e-03, fs:0.80000 (r=0.687,p=0.958),  time:580.718, tt:3484.305\n",
      "Ep:6, loss:0.00038, loss_test:0.08342, lr:4.00e-03, fs:0.80473 (r=0.687,p=0.971),  time:580.736, tt:4065.152\n",
      "Ep:7, loss:0.00024, loss_test:0.08210, lr:4.00e-03, fs:0.76543 (r=0.626,p=0.984),  time:581.484, tt:4651.871\n",
      "Ep:8, loss:0.00015, loss_test:0.08519, lr:4.00e-03, fs:0.75776 (r=0.616,p=0.984),  time:582.278, tt:5240.505\n",
      "Ep:9, loss:0.00011, loss_test:0.08442, lr:4.00e-03, fs:0.74214 (r=0.596,p=0.983),  time:582.913, tt:5829.132\n",
      "Ep:10, loss:0.00008, loss_test:0.08688, lr:4.00e-03, fs:0.74214 (r=0.596,p=0.983),  time:578.854, tt:6367.391\n",
      "Ep:11, loss:0.00006, loss_test:0.08710, lr:4.00e-03, fs:0.75776 (r=0.616,p=0.984),  time:573.805, tt:6885.665\n",
      "Ep:12, loss:0.00005, loss_test:0.08792, lr:4.00e-03, fs:0.74684 (r=0.596,p=1.000),  time:570.880, tt:7421.444\n",
      "Ep:13, loss:0.00004, loss_test:0.08670, lr:4.00e-03, fs:0.80000 (r=0.667,p=1.000),  time:567.580, tt:7946.126\n",
      "Ep:14, loss:0.00003, loss_test:0.08697, lr:4.00e-03, fs:0.75472 (r=0.606,p=1.000),  time:565.245, tt:8478.674\n",
      "Ep:15, loss:0.00003, loss_test:0.08567, lr:4.00e-03, fs:0.80000 (r=0.667,p=1.000),  time:562.827, tt:9005.225\n",
      "Ep:16, loss:0.00002, loss_test:0.08629, lr:3.96e-03, fs:0.80000 (r=0.667,p=1.000),  time:555.805, tt:9448.692\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14487, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:83.146, tt:83.146\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.14422, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:82.187, tt:164.374\n",
      "Ep:2, loss:0.00056, loss_test:0.14315, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:82.548, tt:247.645\n",
      "Ep:3, loss:0.00056, loss_test:0.14151, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:83.419, tt:333.677\n",
      "Ep:4, loss:0.00055, loss_test:0.13889, lr:4.00e-03, fs:0.66216 (r=0.990,p=0.497),  time:83.540, tt:417.702\n",
      "Ep:5, loss:0.00054, loss_test:0.13487, lr:4.00e-03, fs:0.66894 (r=0.990,p=0.505),  time:84.253, tt:505.521\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00052, loss_test:0.12813, lr:4.00e-03, fs:0.66429 (r=0.939,p=0.514),  time:84.382, tt:590.676\n",
      "Ep:7, loss:0.00049, loss_test:0.11960, lr:4.00e-03, fs:0.67742 (r=0.848,p=0.564),  time:84.285, tt:674.278\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00046, loss_test:0.11749, lr:4.00e-03, fs:0.68203 (r=0.747,p=0.627),  time:84.253, tt:758.281\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00044, loss_test:0.11593, lr:4.00e-03, fs:0.67299 (r=0.717,p=0.634),  time:84.154, tt:841.537\n",
      "Ep:10, loss:0.00042, loss_test:0.11232, lr:4.00e-03, fs:0.69955 (r=0.788,p=0.629),  time:84.060, tt:924.662\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.10990, lr:4.00e-03, fs:0.68224 (r=0.737,p=0.635),  time:83.804, tt:1005.646\n",
      "Ep:12, loss:0.00038, loss_test:0.10796, lr:4.00e-03, fs:0.67662 (r=0.687,p=0.667),  time:83.850, tt:1090.054\n",
      "Ep:13, loss:0.00037, loss_test:0.10627, lr:4.00e-03, fs:0.67677 (r=0.677,p=0.677),  time:83.749, tt:1172.489\n",
      "Ep:14, loss:0.00035, loss_test:0.10524, lr:4.00e-03, fs:0.68367 (r=0.677,p=0.691),  time:84.022, tt:1260.331\n",
      "Ep:15, loss:0.00034, loss_test:0.10431, lr:4.00e-03, fs:0.67403 (r=0.616,p=0.744),  time:83.977, tt:1343.634\n",
      "Ep:16, loss:0.00032, loss_test:0.10254, lr:4.00e-03, fs:0.68852 (r=0.636,p=0.750),  time:83.791, tt:1424.451\n",
      "Ep:17, loss:0.00031, loss_test:0.10181, lr:4.00e-03, fs:0.68852 (r=0.636,p=0.750),  time:83.431, tt:1501.757\n",
      "Ep:18, loss:0.00030, loss_test:0.10060, lr:4.00e-03, fs:0.69613 (r=0.636,p=0.768),  time:83.223, tt:1581.232\n",
      "Ep:19, loss:0.00029, loss_test:0.09976, lr:4.00e-03, fs:0.72222 (r=0.657,p=0.802),  time:83.197, tt:1663.948\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00027, loss_test:0.09971, lr:4.00e-03, fs:0.72626 (r=0.657,p=0.812),  time:83.179, tt:1746.766\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00026, loss_test:0.09886, lr:4.00e-03, fs:0.73626 (r=0.677,p=0.807),  time:83.205, tt:1830.519\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00025, loss_test:0.09849, lr:4.00e-03, fs:0.74725 (r=0.687,p=0.819),  time:83.185, tt:1913.254\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00024, loss_test:0.09851, lr:4.00e-03, fs:0.74033 (r=0.677,p=0.817),  time:83.167, tt:1996.003\n",
      "Ep:24, loss:0.00023, loss_test:0.09695, lr:4.00e-03, fs:0.75138 (r=0.687,p=0.829),  time:83.186, tt:2079.642\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00022, loss_test:0.09827, lr:4.00e-03, fs:0.75281 (r=0.677,p=0.848),  time:83.188, tt:2162.890\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00022, loss_test:0.09623, lr:4.00e-03, fs:0.78022 (r=0.717,p=0.855),  time:82.996, tt:2240.901\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00021, loss_test:0.09765, lr:4.00e-03, fs:0.78022 (r=0.717,p=0.855),  time:82.942, tt:2322.385\n",
      "Ep:28, loss:0.00020, loss_test:0.09460, lr:4.00e-03, fs:0.77174 (r=0.717,p=0.835),  time:83.089, tt:2409.591\n",
      "Ep:29, loss:0.00019, loss_test:0.09716, lr:4.00e-03, fs:0.77095 (r=0.697,p=0.863),  time:83.262, tt:2497.869\n",
      "Ep:30, loss:0.00018, loss_test:0.09450, lr:4.00e-03, fs:0.78212 (r=0.707,p=0.875),  time:83.397, tt:2585.300\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00018, loss_test:0.09627, lr:4.00e-03, fs:0.77778 (r=0.707,p=0.864),  time:83.437, tt:2669.971\n",
      "Ep:32, loss:0.00017, loss_test:0.09532, lr:4.00e-03, fs:0.77966 (r=0.697,p=0.885),  time:83.449, tt:2753.826\n",
      "Ep:33, loss:0.00016, loss_test:0.09397, lr:4.00e-03, fs:0.77528 (r=0.697,p=0.873),  time:83.513, tt:2839.439\n",
      "Ep:34, loss:0.00015, loss_test:0.09611, lr:4.00e-03, fs:0.78409 (r=0.697,p=0.896),  time:83.530, tt:2923.554\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00015, loss_test:0.09292, lr:4.00e-03, fs:0.77528 (r=0.697,p=0.873),  time:83.504, tt:3006.149\n",
      "Ep:36, loss:0.00014, loss_test:0.09651, lr:4.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:83.511, tt:3089.916\n",
      "Ep:37, loss:0.00013, loss_test:0.09259, lr:4.00e-03, fs:0.77095 (r=0.697,p=0.863),  time:83.508, tt:3173.315\n",
      "Ep:38, loss:0.00013, loss_test:0.09692, lr:4.00e-03, fs:0.77457 (r=0.677,p=0.905),  time:83.522, tt:3257.343\n",
      "Ep:39, loss:0.00012, loss_test:0.09264, lr:4.00e-03, fs:0.76836 (r=0.687,p=0.872),  time:83.509, tt:3340.376\n",
      "Ep:40, loss:0.00012, loss_test:0.09706, lr:4.00e-03, fs:0.77907 (r=0.677,p=0.918),  time:83.535, tt:3424.932\n",
      "Ep:41, loss:0.00011, loss_test:0.09329, lr:4.00e-03, fs:0.76836 (r=0.687,p=0.872),  time:83.535, tt:3508.464\n",
      "Ep:42, loss:0.00011, loss_test:0.09727, lr:4.00e-03, fs:0.76301 (r=0.667,p=0.892),  time:83.540, tt:3592.235\n",
      "Ep:43, loss:0.00010, loss_test:0.09590, lr:4.00e-03, fs:0.79070 (r=0.687,p=0.932),  time:83.629, tt:3679.677\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.09616, lr:4.00e-03, fs:0.76301 (r=0.667,p=0.892),  time:83.662, tt:3764.774\n",
      "Ep:45, loss:0.00009, loss_test:0.09625, lr:4.00e-03, fs:0.77647 (r=0.667,p=0.930),  time:83.619, tt:3846.461\n",
      "Ep:46, loss:0.00009, loss_test:0.09861, lr:4.00e-03, fs:0.77647 (r=0.667,p=0.930),  time:83.588, tt:3928.619\n",
      "Ep:47, loss:0.00008, loss_test:0.09477, lr:4.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:83.587, tt:4012.156\n",
      "Ep:48, loss:0.00008, loss_test:0.09949, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:83.674, tt:4100.044\n",
      "Ep:49, loss:0.00008, loss_test:0.09797, lr:4.00e-03, fs:0.75740 (r=0.646,p=0.914),  time:83.692, tt:4184.607\n",
      "Ep:50, loss:0.00007, loss_test:0.09958, lr:4.00e-03, fs:0.74251 (r=0.626,p=0.912),  time:83.697, tt:4268.542\n",
      "Ep:51, loss:0.00007, loss_test:0.09805, lr:4.00e-03, fs:0.76190 (r=0.646,p=0.928),  time:83.680, tt:4351.368\n",
      "Ep:52, loss:0.00006, loss_test:0.10143, lr:4.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:83.676, tt:4434.803\n",
      "Ep:53, loss:0.00006, loss_test:0.09974, lr:4.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:83.628, tt:4515.886\n",
      "Ep:54, loss:0.00006, loss_test:0.10147, lr:4.00e-03, fs:0.73939 (r=0.616,p=0.924),  time:83.440, tt:4589.221\n",
      "Ep:55, loss:0.00005, loss_test:0.10113, lr:3.96e-03, fs:0.75449 (r=0.636,p=0.926),  time:83.092, tt:4653.173\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"10-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00431, loss_test:0.11458, lr:4.00e-03, fs:0.66968 (r=0.747,p=0.607),  time:754.423, tt:754.423\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00284, loss_test:0.08677, lr:4.00e-03, fs:0.78307 (r=0.747,p=0.822),  time:752.217, tt:1504.434\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00196, loss_test:0.07679, lr:4.00e-03, fs:0.82474 (r=0.808,p=0.842),  time:753.811, tt:2261.432\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00138, loss_test:0.07469, lr:4.00e-03, fs:0.86957 (r=0.808,p=0.941),  time:753.017, tt:3012.069\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00095, loss_test:0.07676, lr:4.00e-03, fs:0.86957 (r=0.808,p=0.941),  time:752.946, tt:3764.729\n",
      "Ep:5, loss:0.00065, loss_test:0.07960, lr:4.00e-03, fs:0.87912 (r=0.808,p=0.964),  time:749.985, tt:4499.907\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00044, loss_test:0.07580, lr:4.00e-03, fs:0.87912 (r=0.808,p=0.964),  time:748.200, tt:5237.402\n",
      "Ep:7, loss:0.00031, loss_test:0.08432, lr:4.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:746.013, tt:5968.100\n",
      "Ep:8, loss:0.00022, loss_test:0.08877, lr:4.00e-03, fs:0.79290 (r=0.677,p=0.957),  time:745.294, tt:6707.642\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df26c72f41c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"10-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00349, loss_test:0.08957, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:755.073, tt:755.073\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00178, loss_test:0.07705, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:754.544, tt:1509.087\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00087, loss_test:0.06843, lr:1.00e-02, fs:0.87778 (r=0.798,p=0.975),  time:750.653, tt:2251.959\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00042, loss_test:0.07809, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:752.312, tt:3009.247\n",
      "Ep:4, loss:0.00020, loss_test:0.08896, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:753.755, tt:3768.773\n",
      "Ep:5, loss:0.00010, loss_test:0.08847, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:754.926, tt:4529.558\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e46f5ec56c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"10-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00386, loss_test:0.10057, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:736.610, tt:736.610\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00222, loss_test:0.08418, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:746.013, tt:1492.027\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00129, loss_test:0.09741, lr:1.00e-02, fs:0.80473 (r=0.687,p=0.971),  time:747.296, tt:2241.887\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00073, loss_test:0.09565, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:750.681, tt:3002.723\n",
      "Ep:4, loss:0.00038, loss_test:0.09271, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:753.237, tt:3766.187\n",
      "Ep:5, loss:0.00021, loss_test:0.09424, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:752.751, tt:4516.507\n",
      "Ep:6, loss:0.00013, loss_test:0.10407, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:751.484, tt:5260.389\n",
      "Ep:7, loss:0.00007, loss_test:0.10598, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:749.477, tt:5995.819\n",
      "Ep:8, loss:0.00004, loss_test:0.10513, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:748.931, tt:6740.382\n",
      "Ep:9, loss:0.00003, loss_test:0.10720, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:747.938, tt:7479.383\n",
      "Ep:10, loss:0.00002, loss_test:0.10858, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:747.328, tt:8220.606\n",
      "Ep:11, loss:0.00002, loss_test:0.10715, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:747.845, tt:8974.134\n",
      "Ep:12, loss:0.00002, loss_test:0.10835, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:747.970, tt:9723.606\n",
      "Ep:13, loss:0.00001, loss_test:0.10984, lr:1.00e-02, fs:0.67974 (r=0.525,p=0.963),  time:747.990, tt:10471.858\n",
      "Ep:14, loss:0.00001, loss_test:0.10653, lr:9.90e-03, fs:0.67974 (r=0.525,p=0.963),  time:749.116, tt:11236.733\n",
      "Ep:15, loss:0.00001, loss_test:0.10629, lr:9.80e-03, fs:0.67974 (r=0.525,p=0.963),  time:748.845, tt:11981.517\n",
      "Ep:16, loss:0.00001, loss_test:0.10606, lr:9.70e-03, fs:0.67974 (r=0.525,p=0.963),  time:749.163, tt:12735.770\n",
      "Ep:17, loss:0.00001, loss_test:0.10728, lr:9.61e-03, fs:0.67974 (r=0.525,p=0.963),  time:750.455, tt:13508.182\n",
      "Ep:18, loss:0.00001, loss_test:0.10532, lr:9.51e-03, fs:0.67974 (r=0.525,p=0.963),  time:750.894, tt:14266.979\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14648, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.800, tt:19.800\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14619, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.169, tt:40.337\n",
      "Ep:2, loss:0.00004, loss_test:0.14575, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.531, tt:61.592\n",
      "Ep:3, loss:0.00004, loss_test:0.14513, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.391, tt:81.563\n",
      "Ep:4, loss:0.00004, loss_test:0.14430, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.301, tt:101.506\n",
      "Ep:5, loss:0.00004, loss_test:0.14317, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.159, tt:120.953\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.14166, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:20.220, tt:141.541\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.13961, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:20.136, tt:161.091\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.13679, lr:1.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:19.925, tt:179.327\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.13355, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:19.911, tt:199.114\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.13035, lr:1.00e-02, fs:0.63158 (r=0.788,p=0.527),  time:19.961, tt:219.572\n",
      "Ep:11, loss:0.00003, loss_test:0.12875, lr:1.00e-02, fs:0.61751 (r=0.677,p=0.568),  time:19.909, tt:238.907\n",
      "Ep:12, loss:0.00003, loss_test:0.12925, lr:1.00e-02, fs:0.58201 (r=0.556,p=0.611),  time:19.937, tt:259.175\n",
      "Ep:13, loss:0.00003, loss_test:0.13075, lr:1.00e-02, fs:0.56647 (r=0.495,p=0.662),  time:20.021, tt:280.298\n",
      "Ep:14, loss:0.00003, loss_test:0.13081, lr:1.00e-02, fs:0.55491 (r=0.485,p=0.649),  time:19.997, tt:299.953\n",
      "Ep:15, loss:0.00003, loss_test:0.13107, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:19.953, tt:319.241\n",
      "Ep:16, loss:0.00003, loss_test:0.13132, lr:1.00e-02, fs:0.60909 (r=0.677,p=0.554),  time:19.892, tt:338.164\n",
      "Ep:17, loss:0.00003, loss_test:0.13169, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:19.811, tt:356.596\n",
      "Ep:18, loss:0.00003, loss_test:0.13246, lr:1.00e-02, fs:0.58824 (r=0.556,p=0.625),  time:19.782, tt:375.864\n",
      "Ep:19, loss:0.00003, loss_test:0.13298, lr:1.00e-02, fs:0.57310 (r=0.495,p=0.681),  time:19.791, tt:395.818\n",
      "Ep:20, loss:0.00003, loss_test:0.13290, lr:1.00e-02, fs:0.60227 (r=0.535,p=0.688),  time:19.831, tt:416.441\n",
      "Ep:21, loss:0.00003, loss_test:0.13218, lr:9.90e-03, fs:0.58586 (r=0.586,p=0.586),  time:19.864, tt:437.003\n",
      "Ep:22, loss:0.00002, loss_test:0.13154, lr:9.80e-03, fs:0.58937 (r=0.616,p=0.565),  time:19.848, tt:456.495\n",
      "Ep:23, loss:0.00002, loss_test:0.13157, lr:9.70e-03, fs:0.59296 (r=0.596,p=0.590),  time:19.803, tt:475.274\n",
      "Ep:24, loss:0.00002, loss_test:0.13171, lr:9.61e-03, fs:0.59893 (r=0.566,p=0.636),  time:19.844, tt:496.093\n",
      "Ep:25, loss:0.00002, loss_test:0.13194, lr:9.51e-03, fs:0.61111 (r=0.556,p=0.679),  time:19.870, tt:516.611\n",
      "Ep:26, loss:0.00002, loss_test:0.13110, lr:9.41e-03, fs:0.58639 (r=0.566,p=0.609),  time:19.792, tt:534.391\n",
      "Ep:27, loss:0.00002, loss_test:0.13033, lr:9.32e-03, fs:0.59000 (r=0.596,p=0.584),  time:19.748, tt:552.944\n",
      "Ep:28, loss:0.00002, loss_test:0.13036, lr:9.23e-03, fs:0.61084 (r=0.626,p=0.596),  time:19.712, tt:571.643\n",
      "Ep:29, loss:0.00002, loss_test:0.13115, lr:9.14e-03, fs:0.60963 (r=0.576,p=0.648),  time:19.702, tt:591.050\n",
      "Ep:30, loss:0.00002, loss_test:0.13188, lr:9.04e-03, fs:0.61538 (r=0.566,p=0.675),  time:19.787, tt:613.400\n",
      "Ep:31, loss:0.00002, loss_test:0.13136, lr:8.95e-03, fs:0.61702 (r=0.586,p=0.652),  time:19.742, tt:631.741\n",
      "Ep:32, loss:0.00002, loss_test:0.13072, lr:8.86e-03, fs:0.63317 (r=0.636,p=0.630),  time:19.755, tt:651.928\n",
      "Ep:33, loss:0.00002, loss_test:0.13082, lr:8.78e-03, fs:0.63265 (r=0.626,p=0.639),  time:19.727, tt:670.710\n",
      "Ep:34, loss:0.00002, loss_test:0.13150, lr:8.69e-03, fs:0.61290 (r=0.576,p=0.655),  time:19.723, tt:690.317\n",
      "Ep:35, loss:0.00002, loss_test:0.13159, lr:8.60e-03, fs:0.62500 (r=0.606,p=0.645),  time:19.727, tt:710.179\n",
      "Ep:36, loss:0.00002, loss_test:0.13132, lr:8.51e-03, fs:0.62626 (r=0.626,p=0.626),  time:19.747, tt:730.651\n",
      "Ep:37, loss:0.00002, loss_test:0.13118, lr:8.43e-03, fs:0.62944 (r=0.626,p=0.633),  time:19.770, tt:751.246\n",
      "Ep:38, loss:0.00002, loss_test:0.13132, lr:8.35e-03, fs:0.62766 (r=0.596,p=0.663),  time:19.781, tt:771.453\n",
      "Ep:39, loss:0.00002, loss_test:0.13096, lr:8.26e-03, fs:0.62766 (r=0.596,p=0.663),  time:19.740, tt:789.616\n",
      "Ep:40, loss:0.00002, loss_test:0.13023, lr:8.18e-03, fs:0.65306 (r=0.646,p=0.660),  time:19.751, tt:809.809\n",
      "Ep:41, loss:0.00002, loss_test:0.13057, lr:8.10e-03, fs:0.64948 (r=0.636,p=0.663),  time:19.748, tt:829.417\n",
      "Ep:42, loss:0.00002, loss_test:0.13100, lr:8.02e-03, fs:0.65285 (r=0.636,p=0.670),  time:19.732, tt:848.480\n",
      "Ep:43, loss:0.00002, loss_test:0.13107, lr:7.94e-03, fs:0.64948 (r=0.636,p=0.663),  time:19.726, tt:867.927\n",
      "Ep:44, loss:0.00002, loss_test:0.13069, lr:7.86e-03, fs:0.65990 (r=0.657,p=0.663),  time:19.740, tt:888.322\n",
      "Ep:45, loss:0.00002, loss_test:0.13039, lr:7.78e-03, fs:0.66327 (r=0.657,p=0.670),  time:19.734, tt:907.781\n",
      "Ep:46, loss:0.00002, loss_test:0.13048, lr:7.70e-03, fs:0.64948 (r=0.636,p=0.663),  time:19.725, tt:927.094\n",
      "Ep:47, loss:0.00002, loss_test:0.13056, lr:7.62e-03, fs:0.63158 (r=0.606,p=0.659),  time:19.706, tt:945.905\n",
      "Ep:48, loss:0.00002, loss_test:0.13027, lr:7.55e-03, fs:0.66667 (r=0.657,p=0.677),  time:19.700, tt:965.276\n",
      "Ep:49, loss:0.00001, loss_test:0.13068, lr:7.47e-03, fs:0.65285 (r=0.636,p=0.670),  time:19.759, tt:987.958\n",
      "Ep:50, loss:0.00001, loss_test:0.13115, lr:7.40e-03, fs:0.63874 (r=0.616,p=0.663),  time:19.724, tt:1005.948\n",
      "Ep:51, loss:0.00001, loss_test:0.13100, lr:7.32e-03, fs:0.65285 (r=0.636,p=0.670),  time:19.716, tt:1025.243\n",
      "Ep:52, loss:0.00001, loss_test:0.13142, lr:7.25e-03, fs:0.64583 (r=0.626,p=0.667),  time:19.683, tt:1043.177\n",
      "Ep:53, loss:0.00001, loss_test:0.13176, lr:7.18e-03, fs:0.64211 (r=0.616,p=0.670),  time:19.635, tt:1060.265\n",
      "Ep:54, loss:0.00001, loss_test:0.13183, lr:7.11e-03, fs:0.64211 (r=0.616,p=0.670),  time:19.621, tt:1079.178\n",
      "Ep:55, loss:0.00001, loss_test:0.13173, lr:7.03e-03, fs:0.63542 (r=0.616,p=0.656),  time:19.634, tt:1099.506\n",
      "Ep:56, loss:0.00001, loss_test:0.13162, lr:6.96e-03, fs:0.63492 (r=0.606,p=0.667),  time:19.621, tt:1118.389\n",
      "Ep:57, loss:0.00001, loss_test:0.13137, lr:6.89e-03, fs:0.63874 (r=0.616,p=0.663),  time:19.639, tt:1139.087\n",
      "Ep:58, loss:0.00001, loss_test:0.13115, lr:6.83e-03, fs:0.64249 (r=0.626,p=0.660),  time:19.601, tt:1156.471\n",
      "Ep:59, loss:0.00001, loss_test:0.13153, lr:6.76e-03, fs:0.63492 (r=0.606,p=0.667),  time:19.571, tt:1174.243\n",
      "Ep:60, loss:0.00001, loss_test:0.13179, lr:6.69e-03, fs:0.64171 (r=0.606,p=0.682),  time:19.568, tt:1193.666\n",
      "Ep:61, loss:0.00001, loss_test:0.13146, lr:6.62e-03, fs:0.63158 (r=0.606,p=0.659),  time:19.572, tt:1213.481\n",
      "Ep:62, loss:0.00001, loss_test:0.13130, lr:6.56e-03, fs:0.63492 (r=0.606,p=0.667),  time:19.568, tt:1232.768\n",
      "Ep:63, loss:0.00001, loss_test:0.13142, lr:6.49e-03, fs:0.62703 (r=0.586,p=0.674),  time:19.543, tt:1250.748\n",
      "Ep:64, loss:0.00001, loss_test:0.13088, lr:6.43e-03, fs:0.63102 (r=0.596,p=0.670),  time:19.557, tt:1271.175\n",
      "Ep:65, loss:0.00001, loss_test:0.13045, lr:6.36e-03, fs:0.63492 (r=0.606,p=0.667),  time:19.562, tt:1291.102\n",
      "Ep:66, loss:0.00001, loss_test:0.13087, lr:6.30e-03, fs:0.61538 (r=0.566,p=0.675),  time:19.558, tt:1310.389\n",
      "Ep:67, loss:0.00001, loss_test:0.13135, lr:6.24e-03, fs:0.61453 (r=0.556,p=0.688),  time:19.556, tt:1329.801\n",
      "Ep:68, loss:0.00001, loss_test:0.13063, lr:6.17e-03, fs:0.61538 (r=0.566,p=0.675),  time:19.530, tt:1347.564\n",
      "Ep:69, loss:0.00001, loss_test:0.13070, lr:6.11e-03, fs:0.61538 (r=0.566,p=0.675),  time:19.575, tt:1370.272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.13134, lr:6.05e-03, fs:0.61453 (r=0.556,p=0.688),  time:19.588, tt:1390.728\n",
      "Ep:71, loss:0.00001, loss_test:0.13132, lr:5.99e-03, fs:0.61453 (r=0.556,p=0.688),  time:19.598, tt:1411.027\n",
      "Ep:72, loss:0.00001, loss_test:0.13091, lr:5.93e-03, fs:0.61111 (r=0.556,p=0.679),  time:19.596, tt:1430.519\n",
      "Ep:73, loss:0.00001, loss_test:0.13085, lr:5.87e-03, fs:0.62147 (r=0.556,p=0.705),  time:19.625, tt:1452.255\n",
      "Ep:74, loss:0.00001, loss_test:0.13036, lr:5.81e-03, fs:0.62147 (r=0.556,p=0.705),  time:19.622, tt:1471.655\n",
      "Ep:75, loss:0.00001, loss_test:0.13036, lr:5.75e-03, fs:0.61714 (r=0.545,p=0.711),  time:19.647, tt:1493.151\n",
      "Ep:76, loss:0.00001, loss_test:0.13078, lr:5.70e-03, fs:0.60000 (r=0.515,p=0.718),  time:19.648, tt:1512.910\n",
      "Ep:77, loss:0.00001, loss_test:0.13024, lr:5.64e-03, fs:0.61628 (r=0.535,p=0.726),  time:19.658, tt:1533.360\n",
      "Ep:78, loss:0.00001, loss_test:0.12945, lr:5.58e-03, fs:0.61714 (r=0.545,p=0.711),  time:19.676, tt:1554.434\n",
      "Ep:79, loss:0.00001, loss_test:0.12996, lr:5.53e-03, fs:0.61628 (r=0.535,p=0.726),  time:19.678, tt:1574.209\n",
      "Ep:80, loss:0.00001, loss_test:0.13021, lr:5.47e-03, fs:0.60000 (r=0.515,p=0.718),  time:19.713, tt:1596.780\n",
      "Ep:81, loss:0.00001, loss_test:0.12984, lr:5.42e-03, fs:0.61628 (r=0.535,p=0.726),  time:19.732, tt:1618.040\n",
      "Ep:82, loss:0.00001, loss_test:0.12972, lr:5.36e-03, fs:0.61628 (r=0.535,p=0.726),  time:19.751, tt:1639.339\n",
      "Ep:83, loss:0.00001, loss_test:0.12988, lr:5.31e-03, fs:0.61988 (r=0.535,p=0.736),  time:19.761, tt:1659.942\n",
      "Ep:84, loss:0.00001, loss_test:0.12951, lr:5.26e-03, fs:0.61628 (r=0.535,p=0.726),  time:19.763, tt:1679.833\n",
      "Ep:85, loss:0.00001, loss_test:0.12926, lr:5.20e-03, fs:0.62791 (r=0.545,p=0.740),  time:19.758, tt:1699.216\n",
      "Ep:86, loss:0.00001, loss_test:0.13046, lr:5.15e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.772, tt:1720.168\n",
      "Ep:87, loss:0.00001, loss_test:0.12901, lr:5.10e-03, fs:0.62791 (r=0.545,p=0.740),  time:19.788, tt:1741.375\n",
      "Ep:88, loss:0.00001, loss_test:0.12823, lr:5.05e-03, fs:0.64368 (r=0.566,p=0.747),  time:19.784, tt:1760.740\n",
      "Ep:89, loss:0.00001, loss_test:0.13004, lr:5.00e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.816, tt:1783.462\n",
      "Ep:90, loss:0.00001, loss_test:0.12964, lr:4.95e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.812, tt:1802.862\n",
      "Ep:91, loss:0.00001, loss_test:0.12780, lr:4.90e-03, fs:0.63636 (r=0.566,p=0.727),  time:19.821, tt:1823.512\n",
      "Ep:92, loss:0.00001, loss_test:0.12809, lr:4.85e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.826, tt:1843.843\n",
      "Ep:93, loss:0.00001, loss_test:0.12876, lr:4.80e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.839, tt:1864.825\n",
      "Ep:94, loss:0.00001, loss_test:0.12802, lr:4.75e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.853, tt:1886.069\n",
      "Ep:95, loss:0.00001, loss_test:0.12809, lr:4.71e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.877, tt:1908.145\n",
      "Ep:96, loss:0.00001, loss_test:0.12851, lr:4.66e-03, fs:0.62353 (r=0.535,p=0.746),  time:19.881, tt:1928.499\n",
      "Ep:97, loss:0.00001, loss_test:0.12748, lr:4.61e-03, fs:0.63158 (r=0.545,p=0.750),  time:19.881, tt:1948.366\n",
      "Ep:98, loss:0.00001, loss_test:0.12686, lr:4.57e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.873, tt:1967.416\n",
      "Ep:99, loss:0.00001, loss_test:0.12815, lr:4.52e-03, fs:0.63158 (r=0.545,p=0.750),  time:19.862, tt:1986.179\n",
      "Ep:100, loss:0.00001, loss_test:0.12796, lr:4.48e-03, fs:0.63158 (r=0.545,p=0.750),  time:19.864, tt:2006.268\n",
      "Ep:101, loss:0.00001, loss_test:0.12669, lr:4.43e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.871, tt:2026.798\n",
      "Ep:102, loss:0.00001, loss_test:0.12775, lr:4.39e-03, fs:0.63158 (r=0.545,p=0.750),  time:19.867, tt:2046.351\n",
      "Ep:103, loss:0.00001, loss_test:0.12726, lr:4.34e-03, fs:0.63158 (r=0.545,p=0.750),  time:19.884, tt:2067.982\n",
      "Ep:104, loss:0.00001, loss_test:0.12601, lr:4.30e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.894, tt:2088.876\n",
      "Ep:105, loss:0.00001, loss_test:0.12779, lr:4.26e-03, fs:0.64286 (r=0.545,p=0.783),  time:19.921, tt:2111.599\n",
      "Ep:106, loss:0.00001, loss_test:0.12728, lr:4.21e-03, fs:0.63905 (r=0.545,p=0.771),  time:19.935, tt:2133.002\n",
      "Ep:107, loss:0.00001, loss_test:0.12560, lr:4.17e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.942, tt:2153.714\n",
      "Ep:108, loss:0.00001, loss_test:0.12596, lr:4.13e-03, fs:0.63953 (r=0.556,p=0.753),  time:19.953, tt:2174.930\n",
      "Ep:109, loss:0.00001, loss_test:0.12767, lr:4.09e-03, fs:0.64286 (r=0.545,p=0.783),  time:19.960, tt:2195.597\n",
      "Ep:110, loss:0.00001, loss_test:0.12682, lr:4.05e-03, fs:0.63905 (r=0.545,p=0.771),  time:19.964, tt:2216.057\n",
      "Ep:111, loss:0.00001, loss_test:0.12455, lr:4.01e-03, fs:0.65896 (r=0.576,p=0.770),  time:19.956, tt:2235.093\n",
      "Ep:112, loss:0.00001, loss_test:0.12489, lr:3.97e-03, fs:0.65896 (r=0.576,p=0.770),  time:19.949, tt:2254.285\n",
      "Ep:113, loss:0.00001, loss_test:0.12711, lr:3.93e-03, fs:0.62651 (r=0.525,p=0.776),  time:19.943, tt:2273.517\n",
      "Ep:114, loss:0.00001, loss_test:0.12713, lr:3.89e-03, fs:0.62651 (r=0.525,p=0.776),  time:19.937, tt:2292.800\n",
      "Ep:115, loss:0.00001, loss_test:0.12509, lr:3.85e-03, fs:0.65896 (r=0.576,p=0.770),  time:20.001, tt:2320.100\n",
      "Ep:116, loss:0.00001, loss_test:0.12440, lr:3.81e-03, fs:0.65896 (r=0.576,p=0.770),  time:19.986, tt:2338.355\n",
      "Ep:117, loss:0.00001, loss_test:0.12565, lr:3.77e-03, fs:0.63905 (r=0.545,p=0.771),  time:19.980, tt:2357.666\n",
      "Ep:118, loss:0.00001, loss_test:0.12606, lr:3.73e-03, fs:0.63473 (r=0.535,p=0.779),  time:19.990, tt:2378.840\n",
      "Ep:119, loss:0.00001, loss_test:0.12478, lr:3.70e-03, fs:0.65116 (r=0.566,p=0.767),  time:20.000, tt:2400.047\n",
      "Ep:120, loss:0.00001, loss_test:0.12405, lr:3.66e-03, fs:0.65116 (r=0.566,p=0.767),  time:20.002, tt:2420.186\n",
      "Ep:121, loss:0.00001, loss_test:0.12483, lr:3.62e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.005, tt:2440.552\n",
      "Ep:122, loss:0.00001, loss_test:0.12481, lr:3.59e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.013, tt:2461.628\n",
      "Ep:123, loss:0.00001, loss_test:0.12412, lr:3.55e-03, fs:0.64706 (r=0.556,p=0.775),  time:20.014, tt:2481.730\n",
      "Ep:124, loss:0.00001, loss_test:0.12413, lr:3.52e-03, fs:0.62722 (r=0.535,p=0.757),  time:20.019, tt:2502.425\n",
      "Ep:125, loss:0.00001, loss_test:0.12493, lr:3.48e-03, fs:0.62651 (r=0.525,p=0.776),  time:20.027, tt:2523.404\n",
      "Ep:126, loss:0.00001, loss_test:0.12438, lr:3.45e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.036, tt:2544.597\n",
      "Ep:127, loss:0.00001, loss_test:0.12311, lr:3.41e-03, fs:0.65089 (r=0.556,p=0.786),  time:20.038, tt:2564.815\n",
      "Ep:128, loss:0.00001, loss_test:0.12377, lr:3.38e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.035, tt:2584.540\n",
      "Ep:129, loss:0.00001, loss_test:0.12466, lr:3.34e-03, fs:0.62651 (r=0.525,p=0.776),  time:20.022, tt:2602.889\n",
      "Ep:130, loss:0.00001, loss_test:0.12421, lr:3.31e-03, fs:0.63473 (r=0.535,p=0.779),  time:20.018, tt:2622.367\n",
      "Ep:131, loss:0.00001, loss_test:0.12320, lr:3.28e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.029, tt:2643.866\n",
      "Ep:132, loss:0.00001, loss_test:0.12378, lr:3.24e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.027, tt:2663.562\n",
      "Ep:133, loss:0.00001, loss_test:0.12392, lr:3.21e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.034, tt:2684.601\n",
      "Ep:134, loss:0.00001, loss_test:0.12340, lr:3.18e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.032, tt:2704.298\n",
      "Ep:135, loss:0.00001, loss_test:0.12332, lr:3.15e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.042, tt:2725.670\n",
      "Ep:136, loss:0.00001, loss_test:0.12376, lr:3.12e-03, fs:0.63473 (r=0.535,p=0.779),  time:20.037, tt:2745.133\n",
      "Ep:137, loss:0.00001, loss_test:0.12357, lr:3.09e-03, fs:0.63030 (r=0.525,p=0.788),  time:20.042, tt:2765.856\n",
      "Ep:138, loss:0.00001, loss_test:0.12268, lr:3.05e-03, fs:0.63855 (r=0.535,p=0.791),  time:20.033, tt:2784.636\n",
      "Ep:139, loss:0.00001, loss_test:0.12272, lr:3.02e-03, fs:0.63855 (r=0.535,p=0.791),  time:20.026, tt:2803.675\n",
      "Ep:140, loss:0.00001, loss_test:0.12332, lr:2.99e-03, fs:0.63030 (r=0.525,p=0.788),  time:20.017, tt:2822.464\n",
      "Ep:141, loss:0.00001, loss_test:0.12309, lr:2.96e-03, fs:0.64286 (r=0.545,p=0.783),  time:20.008, tt:2841.122\n",
      "Ep:142, loss:0.00001, loss_test:0.12258, lr:2.93e-03, fs:0.64671 (r=0.545,p=0.794),  time:20.004, tt:2860.509\n",
      "Ep:143, loss:0.00001, loss_test:0.12242, lr:2.90e-03, fs:0.63855 (r=0.535,p=0.791),  time:19.986, tt:2877.993\n",
      "Ep:144, loss:0.00001, loss_test:0.12225, lr:2.88e-03, fs:0.64671 (r=0.545,p=0.794),  time:19.989, tt:2898.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00001, loss_test:0.12250, lr:2.85e-03, fs:0.64671 (r=0.545,p=0.794),  time:19.987, tt:2918.154\n",
      "Ep:146, loss:0.00001, loss_test:0.12338, lr:2.82e-03, fs:0.63855 (r=0.535,p=0.791),  time:19.978, tt:2936.712\n",
      "Ep:147, loss:0.00001, loss_test:0.12312, lr:2.79e-03, fs:0.63855 (r=0.535,p=0.791),  time:19.971, tt:2955.746\n",
      "Ep:148, loss:0.00001, loss_test:0.12210, lr:2.76e-03, fs:0.65476 (r=0.556,p=0.797),  time:20.025, tt:2983.765\n",
      "Ep:149, loss:0.00001, loss_test:0.12213, lr:2.73e-03, fs:0.63855 (r=0.535,p=0.791),  time:20.013, tt:3001.894\n",
      "Ep:150, loss:0.00001, loss_test:0.12238, lr:2.71e-03, fs:0.64242 (r=0.535,p=0.803),  time:20.004, tt:3020.546\n",
      "Ep:151, loss:0.00001, loss_test:0.12224, lr:2.68e-03, fs:0.64242 (r=0.535,p=0.803),  time:19.990, tt:3038.423\n",
      "Ep:152, loss:0.00001, loss_test:0.12196, lr:2.65e-03, fs:0.65476 (r=0.556,p=0.797),  time:19.994, tt:3059.142\n",
      "Ep:153, loss:0.00001, loss_test:0.12226, lr:2.63e-03, fs:0.64634 (r=0.535,p=0.815),  time:19.996, tt:3079.323\n",
      "Ep:154, loss:0.00001, loss_test:0.12204, lr:2.60e-03, fs:0.66265 (r=0.556,p=0.821),  time:19.989, tt:3098.266\n",
      "Ep:155, loss:0.00001, loss_test:0.12143, lr:2.57e-03, fs:0.67059 (r=0.576,p=0.803),  time:19.989, tt:3118.294\n",
      "Ep:156, loss:0.00001, loss_test:0.12205, lr:2.55e-03, fs:0.66265 (r=0.556,p=0.821),  time:19.992, tt:3138.757\n",
      "Ep:157, loss:0.00001, loss_test:0.12222, lr:2.52e-03, fs:0.66265 (r=0.556,p=0.821),  time:19.999, tt:3159.850\n",
      "Ep:158, loss:0.00001, loss_test:0.12158, lr:2.50e-03, fs:0.66265 (r=0.556,p=0.821),  time:20.005, tt:3180.873\n",
      "Ep:159, loss:0.00001, loss_test:0.12148, lr:2.47e-03, fs:0.66265 (r=0.556,p=0.821),  time:20.011, tt:3201.736\n",
      "Ep:160, loss:0.00001, loss_test:0.12155, lr:2.45e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.013, tt:3222.091\n",
      "Ep:161, loss:0.00001, loss_test:0.12132, lr:2.42e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.016, tt:3242.642\n",
      "Ep:162, loss:0.00001, loss_test:0.12159, lr:2.40e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.017, tt:3262.765\n",
      "Ep:163, loss:0.00001, loss_test:0.12128, lr:2.38e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.024, tt:3284.014\n",
      "Ep:164, loss:0.00001, loss_test:0.12100, lr:2.35e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.031, tt:3305.113\n",
      "Ep:165, loss:0.00001, loss_test:0.12199, lr:2.33e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.040, tt:3326.597\n",
      "Ep:166, loss:0.00001, loss_test:0.12203, lr:2.31e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.040, tt:3346.760\n",
      "Ep:167, loss:0.00001, loss_test:0.12125, lr:2.28e-03, fs:0.66667 (r=0.556,p=0.833),  time:20.038, tt:3366.369\n",
      "Ep:168, loss:0.00001, loss_test:0.12059, lr:2.26e-03, fs:0.67857 (r=0.576,p=0.826),  time:20.045, tt:3387.647\n",
      "Ep:169, loss:0.00001, loss_test:0.12176, lr:2.24e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.050, tt:3408.478\n",
      "Ep:170, loss:0.00001, loss_test:0.12214, lr:2.21e-03, fs:0.67081 (r=0.545,p=0.871),  time:20.050, tt:3428.628\n",
      "Ep:171, loss:0.00001, loss_test:0.12167, lr:2.19e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.056, tt:3449.595\n",
      "Ep:172, loss:0.00001, loss_test:0.12089, lr:2.17e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.058, tt:3470.119\n",
      "Ep:173, loss:0.00001, loss_test:0.12097, lr:2.15e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.061, tt:3490.614\n",
      "Ep:174, loss:0.00001, loss_test:0.12116, lr:2.13e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.055, tt:3509.674\n",
      "Ep:175, loss:0.00000, loss_test:0.12118, lr:2.11e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.055, tt:3529.646\n",
      "Ep:176, loss:0.00000, loss_test:0.12107, lr:2.08e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.060, tt:3550.682\n",
      "Ep:177, loss:0.00000, loss_test:0.12084, lr:2.06e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.061, tt:3570.857\n",
      "Ep:178, loss:0.00000, loss_test:0.12065, lr:2.04e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.059, tt:3590.551\n",
      "Ep:179, loss:0.00000, loss_test:0.12078, lr:2.02e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.063, tt:3611.413\n",
      "Ep:180, loss:0.00000, loss_test:0.12061, lr:2.00e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.070, tt:3632.739\n",
      "Ep:181, loss:0.00000, loss_test:0.12056, lr:1.98e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.075, tt:3653.667\n",
      "Ep:182, loss:0.00000, loss_test:0.12053, lr:1.96e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.077, tt:3674.070\n",
      "Ep:183, loss:0.00000, loss_test:0.12053, lr:1.94e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.072, tt:3693.189\n",
      "Ep:184, loss:0.00000, loss_test:0.12035, lr:1.92e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.072, tt:3713.366\n",
      "Ep:185, loss:0.00000, loss_test:0.12016, lr:1.90e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.072, tt:3733.325\n",
      "Ep:186, loss:0.00000, loss_test:0.12081, lr:1.89e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.073, tt:3753.688\n",
      "Ep:187, loss:0.00000, loss_test:0.12088, lr:1.87e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.088, tt:3776.631\n",
      "Ep:188, loss:0.00000, loss_test:0.12039, lr:1.85e-03, fs:0.66258 (r=0.545,p=0.844),  time:20.095, tt:3797.924\n",
      "Ep:189, loss:0.00000, loss_test:0.12036, lr:1.83e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.090, tt:3817.055\n",
      "Ep:190, loss:0.00000, loss_test:0.12039, lr:1.81e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.095, tt:3838.233\n",
      "Ep:191, loss:0.00000, loss_test:0.12026, lr:1.79e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.090, tt:3857.312\n",
      "Ep:192, loss:0.00000, loss_test:0.12019, lr:1.78e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.086, tt:3876.655\n",
      "Ep:193, loss:0.00000, loss_test:0.12075, lr:1.76e-03, fs:0.65839 (r=0.535,p=0.855),  time:20.082, tt:3895.916\n",
      "Ep:194, loss:0.00000, loss_test:0.12074, lr:1.74e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.078, tt:3915.174\n",
      "Ep:195, loss:0.00000, loss_test:0.12025, lr:1.72e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.080, tt:3935.697\n",
      "Ep:196, loss:0.00000, loss_test:0.12030, lr:1.71e-03, fs:0.67073 (r=0.556,p=0.846),  time:20.082, tt:3956.219\n",
      "Ep:197, loss:0.00000, loss_test:0.12033, lr:1.69e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.081, tt:3976.003\n",
      "Ep:198, loss:0.00000, loss_test:0.12020, lr:1.67e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.075, tt:3994.869\n",
      "Ep:199, loss:0.00000, loss_test:0.12003, lr:1.65e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.077, tt:4015.312\n",
      "Ep:200, loss:0.00000, loss_test:0.12041, lr:1.64e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.072, tt:4034.490\n",
      "Ep:201, loss:0.00000, loss_test:0.12031, lr:1.62e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.070, tt:4054.133\n",
      "Ep:202, loss:0.00000, loss_test:0.11996, lr:1.61e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.070, tt:4074.272\n",
      "Ep:203, loss:0.00000, loss_test:0.12020, lr:1.59e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.066, tt:4093.526\n",
      "##########Best model found so far##########\n",
      "Ep:204, loss:0.00000, loss_test:0.12012, lr:1.59e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.064, tt:4113.020\n",
      "Ep:205, loss:0.00000, loss_test:0.11998, lr:1.59e-03, fs:0.67879 (r=0.566,p=0.848),  time:20.057, tt:4131.821\n",
      "Ep:206, loss:0.00000, loss_test:0.12022, lr:1.59e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.056, tt:4151.629\n",
      "Ep:207, loss:0.00000, loss_test:0.12009, lr:1.59e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.052, tt:4170.779\n",
      "Ep:208, loss:0.00000, loss_test:0.11984, lr:1.59e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.049, tt:4190.151\n",
      "Ep:209, loss:0.00000, loss_test:0.12012, lr:1.59e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.042, tt:4208.786\n",
      "Ep:210, loss:0.00000, loss_test:0.12001, lr:1.59e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.035, tt:4227.338\n",
      "Ep:211, loss:0.00000, loss_test:0.11967, lr:1.59e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.025, tt:4245.377\n",
      "Ep:212, loss:0.00000, loss_test:0.12039, lr:1.59e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.022, tt:4264.660\n",
      "Ep:213, loss:0.00000, loss_test:0.12049, lr:1.59e-03, fs:0.65409 (r=0.525,p=0.867),  time:20.019, tt:4284.091\n",
      "Ep:214, loss:0.00000, loss_test:0.12004, lr:1.59e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.025, tt:4305.376\n",
      "Ep:215, loss:0.00000, loss_test:0.11972, lr:1.57e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.021, tt:4324.531\n",
      "Ep:216, loss:0.00000, loss_test:0.12018, lr:1.56e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.014, tt:4343.117\n",
      "Ep:217, loss:0.00000, loss_test:0.12046, lr:1.54e-03, fs:0.66250 (r=0.535,p=0.869),  time:20.008, tt:4361.757\n",
      "Ep:218, loss:0.00000, loss_test:0.12014, lr:1.53e-03, fs:0.66667 (r=0.545,p=0.857),  time:20.001, tt:4380.283\n",
      "Ep:219, loss:0.00000, loss_test:0.11970, lr:1.51e-03, fs:0.67485 (r=0.556,p=0.859),  time:20.003, tt:4400.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:220, loss:0.00000, loss_test:0.12005, lr:1.50e-03, fs:0.68293 (r=0.566,p=0.862),  time:20.001, tt:4420.137\n",
      "Ep:221, loss:0.00000, loss_test:0.12017, lr:1.48e-03, fs:0.67485 (r=0.556,p=0.859),  time:19.999, tt:4439.748\n",
      "Ep:222, loss:0.00000, loss_test:0.11997, lr:1.47e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.991, tt:4458.005\n",
      "Ep:223, loss:0.00000, loss_test:0.11973, lr:1.45e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.992, tt:4478.261\n",
      "Ep:224, loss:0.00000, loss_test:0.11978, lr:1.44e-03, fs:0.67485 (r=0.556,p=0.859),  time:19.987, tt:4497.167\n",
      "Ep:225, loss:0.00000, loss_test:0.11990, lr:1.42e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.988, tt:4517.288\n",
      "Ep:226, loss:0.00000, loss_test:0.11976, lr:1.41e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.982, tt:4535.870\n",
      "Ep:227, loss:0.00000, loss_test:0.11962, lr:1.39e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.980, tt:4555.389\n",
      "Ep:228, loss:0.00000, loss_test:0.11968, lr:1.38e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.984, tt:4576.327\n",
      "Ep:229, loss:0.00000, loss_test:0.11957, lr:1.37e-03, fs:0.68293 (r=0.566,p=0.862),  time:19.981, tt:4595.726\n",
      "Ep:230, loss:0.00000, loss_test:0.11947, lr:1.35e-03, fs:0.67485 (r=0.556,p=0.859),  time:19.980, tt:4615.429\n",
      "Ep:231, loss:0.00000, loss_test:0.12006, lr:1.34e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.975, tt:4634.120\n",
      "Ep:232, loss:0.00000, loss_test:0.12018, lr:1.33e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.969, tt:4652.712\n",
      "Ep:233, loss:0.00000, loss_test:0.11979, lr:1.31e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.972, tt:4673.526\n",
      "Ep:234, loss:0.00000, loss_test:0.11931, lr:1.30e-03, fs:0.67485 (r=0.556,p=0.859),  time:19.971, tt:4693.221\n",
      "Ep:235, loss:0.00000, loss_test:0.11975, lr:1.29e-03, fs:0.67081 (r=0.545,p=0.871),  time:19.968, tt:4712.384\n",
      "Ep:236, loss:0.00000, loss_test:0.11991, lr:1.27e-03, fs:0.66250 (r=0.535,p=0.869),  time:19.962, tt:4730.934\n",
      "Ep:237, loss:0.00000, loss_test:0.11971, lr:1.26e-03, fs:0.67081 (r=0.545,p=0.871),  time:19.960, tt:4750.506\n",
      "Ep:238, loss:0.00000, loss_test:0.11927, lr:1.25e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.952, tt:4768.564\n",
      "Ep:239, loss:0.00000, loss_test:0.11960, lr:1.24e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.953, tt:4788.663\n",
      "Ep:240, loss:0.00000, loss_test:0.11995, lr:1.22e-03, fs:0.66250 (r=0.535,p=0.869),  time:19.955, tt:4809.069\n",
      "Ep:241, loss:0.00000, loss_test:0.11998, lr:1.21e-03, fs:0.66250 (r=0.535,p=0.869),  time:19.954, tt:4828.748\n",
      "Ep:242, loss:0.00000, loss_test:0.11972, lr:1.20e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.946, tt:4846.960\n",
      "Ep:243, loss:0.00000, loss_test:0.11945, lr:1.19e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.938, tt:4864.981\n",
      "Ep:244, loss:0.00000, loss_test:0.11960, lr:1.18e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.936, tt:4884.229\n",
      "Ep:245, loss:0.00000, loss_test:0.11991, lr:1.16e-03, fs:0.65409 (r=0.525,p=0.867),  time:19.934, tt:4903.809\n",
      "Ep:246, loss:0.00000, loss_test:0.11992, lr:1.15e-03, fs:0.65409 (r=0.525,p=0.867),  time:19.937, tt:4924.422\n",
      "Ep:247, loss:0.00000, loss_test:0.11963, lr:1.14e-03, fs:0.66667 (r=0.545,p=0.857),  time:19.932, tt:4943.182\n",
      "Ep:248, loss:0.00000, loss_test:0.11945, lr:1.13e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.932, tt:4963.064\n",
      "Ep:249, loss:0.00000, loss_test:0.11980, lr:1.12e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.933, tt:4983.135\n",
      "Ep:250, loss:0.00000, loss_test:0.11983, lr:1.11e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.933, tt:5003.302\n",
      "Ep:251, loss:0.00000, loss_test:0.11962, lr:1.10e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.934, tt:5023.370\n",
      "Ep:252, loss:0.00000, loss_test:0.11950, lr:1.08e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.937, tt:5044.184\n",
      "Ep:253, loss:0.00000, loss_test:0.11962, lr:1.07e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.953, tt:5068.111\n",
      "Ep:254, loss:0.00000, loss_test:0.11969, lr:1.06e-03, fs:0.65000 (r=0.525,p=0.852),  time:19.946, tt:5086.224\n",
      "Ep:255, loss:0.00000, loss_test:0.11952, lr:1.05e-03, fs:0.65000 (r=0.525,p=0.852),  time:19.940, tt:5104.695\n",
      "Ep:256, loss:0.00000, loss_test:0.11946, lr:1.04e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.940, tt:5124.569\n",
      "Ep:257, loss:0.00000, loss_test:0.11943, lr:1.03e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.933, tt:5142.732\n",
      "Ep:258, loss:0.00000, loss_test:0.11945, lr:1.02e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.934, tt:5163.012\n",
      "Ep:259, loss:0.00000, loss_test:0.11958, lr:1.01e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.937, tt:5183.534\n",
      "Ep:260, loss:0.00000, loss_test:0.11945, lr:1.00e-03, fs:0.65839 (r=0.535,p=0.855),  time:19.936, tt:5203.257\n",
      "Ep:261, loss:0.00000, loss_test:0.11941, lr:9.91e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.932, tt:5222.170\n",
      "Ep:262, loss:0.00000, loss_test:0.11950, lr:9.81e-04, fs:0.66250 (r=0.535,p=0.869),  time:19.927, tt:5240.840\n",
      "Ep:263, loss:0.00000, loss_test:0.11938, lr:9.71e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.928, tt:5261.095\n",
      "Ep:264, loss:0.00000, loss_test:0.11923, lr:9.62e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.925, tt:5280.155\n",
      "Ep:265, loss:0.00000, loss_test:0.11965, lr:9.52e-04, fs:0.63291 (r=0.505,p=0.847),  time:19.919, tt:5298.486\n",
      "Ep:266, loss:0.00000, loss_test:0.11974, lr:9.42e-04, fs:0.63291 (r=0.505,p=0.847),  time:19.916, tt:5317.689\n",
      "Ep:267, loss:0.00000, loss_test:0.11952, lr:9.33e-04, fs:0.64151 (r=0.515,p=0.850),  time:19.909, tt:5335.733\n",
      "Ep:268, loss:0.00000, loss_test:0.11926, lr:9.24e-04, fs:0.66667 (r=0.545,p=0.857),  time:19.909, tt:5355.623\n",
      "Ep:269, loss:0.00000, loss_test:0.11941, lr:9.14e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.910, tt:5375.686\n",
      "Ep:270, loss:0.00000, loss_test:0.11948, lr:9.05e-04, fs:0.66250 (r=0.535,p=0.869),  time:19.907, tt:5394.882\n",
      "Ep:271, loss:0.00000, loss_test:0.11941, lr:8.96e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.902, tt:5413.212\n",
      "Ep:272, loss:0.00000, loss_test:0.11938, lr:8.87e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.903, tt:5433.391\n",
      "Ep:273, loss:0.00000, loss_test:0.11960, lr:8.78e-04, fs:0.63291 (r=0.505,p=0.847),  time:19.907, tt:5454.466\n",
      "Ep:274, loss:0.00000, loss_test:0.11968, lr:8.70e-04, fs:0.63291 (r=0.505,p=0.847),  time:19.902, tt:5472.949\n",
      "Ep:275, loss:0.00000, loss_test:0.11950, lr:8.61e-04, fs:0.64151 (r=0.515,p=0.850),  time:19.894, tt:5490.627\n",
      "Ep:276, loss:0.00000, loss_test:0.11933, lr:8.52e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.888, tt:5508.846\n",
      "Ep:277, loss:0.00000, loss_test:0.11942, lr:8.44e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.882, tt:5527.218\n",
      "Ep:278, loss:0.00000, loss_test:0.11947, lr:8.35e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.878, tt:5545.901\n",
      "Ep:279, loss:0.00000, loss_test:0.11939, lr:8.27e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.877, tt:5565.568\n",
      "Ep:280, loss:0.00000, loss_test:0.11931, lr:8.19e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.876, tt:5585.266\n",
      "Ep:281, loss:0.00000, loss_test:0.11939, lr:8.11e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.872, tt:5603.793\n",
      "Ep:282, loss:0.00000, loss_test:0.11938, lr:8.02e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.864, tt:5621.485\n",
      "Ep:283, loss:0.00000, loss_test:0.11930, lr:7.94e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.859, tt:5639.928\n",
      "Ep:284, loss:0.00000, loss_test:0.11924, lr:7.87e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.851, tt:5657.667\n",
      "Ep:285, loss:0.00000, loss_test:0.11934, lr:7.79e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.841, tt:5674.491\n",
      "Ep:286, loss:0.00000, loss_test:0.11924, lr:7.71e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.844, tt:5695.246\n",
      "Ep:287, loss:0.00000, loss_test:0.11925, lr:7.63e-04, fs:0.65839 (r=0.535,p=0.855),  time:19.841, tt:5714.246\n",
      "Ep:288, loss:0.00000, loss_test:0.11928, lr:7.56e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.837, tt:5732.945\n",
      "Ep:289, loss:0.00000, loss_test:0.11929, lr:7.48e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.833, tt:5751.628\n",
      "Ep:290, loss:0.00000, loss_test:0.11928, lr:7.40e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.831, tt:5770.954\n",
      "Ep:291, loss:0.00000, loss_test:0.11924, lr:7.33e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.823, tt:5788.201\n",
      "Ep:292, loss:0.00000, loss_test:0.11930, lr:7.26e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.818, tt:5806.627\n",
      "Ep:293, loss:0.00000, loss_test:0.11926, lr:7.18e-04, fs:0.65000 (r=0.525,p=0.852),  time:19.816, tt:5825.759\n",
      "Ep:294, loss:0.00000, loss_test:0.11943, lr:7.11e-04, fs:0.64557 (r=0.515,p=0.864),  time:19.805, tt:5842.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:295, loss:0.00000, loss_test:0.11943, lr:7.04e-04, fs:0.64557 (r=0.515,p=0.864),  time:19.792, tt:5858.399\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13858, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:14.860, tt:14.860\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13749, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:16.863, tt:33.726\n",
      "Ep:2, loss:0.00004, loss_test:0.13582, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:17.422, tt:52.265\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.13418, lr:1.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:17.776, tt:71.103\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.13306, lr:1.00e-02, fs:0.69853 (r=0.960,p=0.549),  time:17.895, tt:89.473\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13188, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:17.889, tt:107.332\n",
      "Ep:6, loss:0.00004, loss_test:0.13109, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:18.095, tt:126.663\n",
      "Ep:7, loss:0.00003, loss_test:0.13025, lr:1.00e-02, fs:0.66397 (r=0.828,p=0.554),  time:18.125, tt:145.003\n",
      "Ep:8, loss:0.00003, loss_test:0.12924, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:18.191, tt:163.715\n",
      "Ep:9, loss:0.00003, loss_test:0.12813, lr:1.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:18.033, tt:180.330\n",
      "Ep:10, loss:0.00003, loss_test:0.12729, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:18.133, tt:199.461\n",
      "Ep:11, loss:0.00003, loss_test:0.12693, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:18.205, tt:218.465\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.12735, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:18.206, tt:236.677\n",
      "Ep:13, loss:0.00003, loss_test:0.12813, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:18.198, tt:254.772\n",
      "Ep:14, loss:0.00003, loss_test:0.12889, lr:1.00e-02, fs:0.64865 (r=0.727,p=0.585),  time:18.160, tt:272.399\n",
      "Ep:15, loss:0.00003, loss_test:0.12934, lr:1.00e-02, fs:0.60664 (r=0.646,p=0.571),  time:18.125, tt:289.998\n",
      "Ep:16, loss:0.00003, loss_test:0.12984, lr:1.00e-02, fs:0.59223 (r=0.616,p=0.570),  time:18.152, tt:308.583\n",
      "Ep:17, loss:0.00003, loss_test:0.13034, lr:1.00e-02, fs:0.57843 (r=0.596,p=0.562),  time:18.167, tt:326.997\n",
      "Ep:18, loss:0.00003, loss_test:0.13102, lr:1.00e-02, fs:0.60000 (r=0.636,p=0.568),  time:18.170, tt:345.238\n",
      "Ep:19, loss:0.00003, loss_test:0.13141, lr:1.00e-02, fs:0.59048 (r=0.626,p=0.559),  time:18.194, tt:363.873\n",
      "Ep:20, loss:0.00003, loss_test:0.13166, lr:1.00e-02, fs:0.59223 (r=0.616,p=0.570),  time:18.120, tt:380.525\n",
      "Ep:21, loss:0.00003, loss_test:0.13187, lr:1.00e-02, fs:0.59113 (r=0.606,p=0.577),  time:18.102, tt:398.236\n",
      "Ep:22, loss:0.00003, loss_test:0.13175, lr:1.00e-02, fs:0.57711 (r=0.586,p=0.569),  time:18.115, tt:416.635\n",
      "Ep:23, loss:0.00003, loss_test:0.13143, lr:9.90e-03, fs:0.58586 (r=0.586,p=0.586),  time:18.116, tt:434.786\n",
      "Ep:24, loss:0.00003, loss_test:0.13101, lr:9.80e-03, fs:0.59000 (r=0.596,p=0.584),  time:18.067, tt:451.681\n",
      "Ep:25, loss:0.00002, loss_test:0.13094, lr:9.70e-03, fs:0.58586 (r=0.586,p=0.586),  time:18.078, tt:470.038\n",
      "Ep:26, loss:0.00002, loss_test:0.13102, lr:9.61e-03, fs:0.54737 (r=0.525,p=0.571),  time:18.104, tt:488.808\n",
      "Ep:27, loss:0.00002, loss_test:0.13106, lr:9.51e-03, fs:0.53763 (r=0.505,p=0.575),  time:18.090, tt:506.511\n",
      "Ep:28, loss:0.00002, loss_test:0.13071, lr:9.41e-03, fs:0.53968 (r=0.515,p=0.567),  time:18.095, tt:524.762\n",
      "Ep:29, loss:0.00002, loss_test:0.13024, lr:9.32e-03, fs:0.53886 (r=0.525,p=0.553),  time:18.086, tt:542.582\n",
      "Ep:30, loss:0.00002, loss_test:0.12973, lr:9.23e-03, fs:0.53333 (r=0.525,p=0.542),  time:18.099, tt:561.082\n",
      "Ep:31, loss:0.00002, loss_test:0.12925, lr:9.14e-03, fs:0.51813 (r=0.505,p=0.532),  time:18.123, tt:579.934\n",
      "Ep:32, loss:0.00002, loss_test:0.12879, lr:9.04e-03, fs:0.52577 (r=0.515,p=0.537),  time:18.155, tt:599.110\n",
      "Ep:33, loss:0.00002, loss_test:0.12816, lr:8.95e-03, fs:0.56122 (r=0.556,p=0.567),  time:18.135, tt:616.590\n",
      "Ep:34, loss:0.00002, loss_test:0.12730, lr:8.86e-03, fs:0.59406 (r=0.606,p=0.583),  time:18.144, tt:635.054\n",
      "Ep:35, loss:0.00002, loss_test:0.12666, lr:8.78e-03, fs:0.59406 (r=0.606,p=0.583),  time:18.160, tt:653.765\n",
      "Ep:36, loss:0.00002, loss_test:0.12632, lr:8.69e-03, fs:0.59000 (r=0.596,p=0.584),  time:18.181, tt:672.681\n",
      "Ep:37, loss:0.00002, loss_test:0.12606, lr:8.60e-03, fs:0.59596 (r=0.596,p=0.596),  time:18.193, tt:691.316\n",
      "Ep:38, loss:0.00002, loss_test:0.12598, lr:8.51e-03, fs:0.59184 (r=0.586,p=0.598),  time:18.202, tt:709.885\n",
      "Ep:39, loss:0.00002, loss_test:0.12594, lr:8.43e-03, fs:0.58462 (r=0.576,p=0.594),  time:18.232, tt:729.297\n",
      "Ep:40, loss:0.00002, loss_test:0.12581, lr:8.35e-03, fs:0.58462 (r=0.576,p=0.594),  time:18.253, tt:748.372\n",
      "Ep:41, loss:0.00002, loss_test:0.12558, lr:8.26e-03, fs:0.59596 (r=0.596,p=0.596),  time:18.238, tt:765.983\n",
      "Ep:42, loss:0.00002, loss_test:0.12547, lr:8.18e-03, fs:0.61307 (r=0.616,p=0.610),  time:18.250, tt:784.739\n",
      "Ep:43, loss:0.00002, loss_test:0.12524, lr:8.10e-03, fs:0.61000 (r=0.616,p=0.604),  time:18.255, tt:803.202\n",
      "Ep:44, loss:0.00002, loss_test:0.12481, lr:8.02e-03, fs:0.62376 (r=0.636,p=0.612),  time:18.269, tt:822.111\n",
      "Ep:45, loss:0.00002, loss_test:0.12453, lr:7.94e-03, fs:0.63682 (r=0.646,p=0.627),  time:18.313, tt:842.403\n",
      "Ep:46, loss:0.00002, loss_test:0.12421, lr:7.86e-03, fs:0.64000 (r=0.646,p=0.634),  time:18.324, tt:861.241\n",
      "Ep:47, loss:0.00002, loss_test:0.12393, lr:7.78e-03, fs:0.64322 (r=0.646,p=0.640),  time:18.320, tt:879.376\n",
      "Ep:48, loss:0.00002, loss_test:0.12374, lr:7.70e-03, fs:0.63636 (r=0.636,p=0.636),  time:18.307, tt:897.049\n",
      "Ep:49, loss:0.00002, loss_test:0.12332, lr:7.62e-03, fs:0.65657 (r=0.657,p=0.657),  time:18.328, tt:916.401\n",
      "Ep:50, loss:0.00002, loss_test:0.12283, lr:7.55e-03, fs:0.65657 (r=0.657,p=0.657),  time:18.344, tt:935.548\n",
      "Ep:51, loss:0.00002, loss_test:0.12261, lr:7.47e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.350, tt:954.208\n",
      "Ep:52, loss:0.00002, loss_test:0.12251, lr:7.40e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.360, tt:973.059\n",
      "Ep:53, loss:0.00002, loss_test:0.12220, lr:7.32e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.389, tt:993.003\n",
      "Ep:54, loss:0.00002, loss_test:0.12182, lr:7.25e-03, fs:0.67000 (r=0.677,p=0.663),  time:18.406, tt:1012.322\n",
      "Ep:55, loss:0.00002, loss_test:0.12172, lr:7.18e-03, fs:0.67005 (r=0.667,p=0.673),  time:18.428, tt:1031.993\n",
      "Ep:56, loss:0.00002, loss_test:0.12160, lr:7.11e-03, fs:0.67692 (r=0.667,p=0.688),  time:18.438, tt:1050.980\n",
      "Ep:57, loss:0.00002, loss_test:0.12127, lr:7.03e-03, fs:0.68367 (r=0.677,p=0.691),  time:18.458, tt:1070.551\n",
      "Ep:58, loss:0.00002, loss_test:0.12101, lr:6.96e-03, fs:0.68367 (r=0.677,p=0.691),  time:18.470, tt:1089.757\n",
      "Ep:59, loss:0.00002, loss_test:0.12102, lr:6.89e-03, fs:0.68367 (r=0.677,p=0.691),  time:18.447, tt:1106.825\n",
      "Ep:60, loss:0.00001, loss_test:0.12139, lr:6.83e-03, fs:0.68367 (r=0.677,p=0.691),  time:18.450, tt:1125.448\n",
      "Ep:61, loss:0.00001, loss_test:0.12166, lr:6.76e-03, fs:0.68041 (r=0.667,p=0.695),  time:18.463, tt:1144.700\n",
      "Ep:62, loss:0.00001, loss_test:0.12153, lr:6.69e-03, fs:0.68041 (r=0.667,p=0.695),  time:18.479, tt:1164.180\n",
      "Ep:63, loss:0.00001, loss_test:0.12148, lr:6.62e-03, fs:0.68041 (r=0.667,p=0.695),  time:18.496, tt:1183.719\n",
      "Ep:64, loss:0.00001, loss_test:0.12170, lr:6.56e-03, fs:0.65263 (r=0.626,p=0.681),  time:18.501, tt:1202.575\n",
      "Ep:65, loss:0.00001, loss_test:0.12178, lr:6.49e-03, fs:0.65263 (r=0.626,p=0.681),  time:18.494, tt:1220.626\n",
      "Ep:66, loss:0.00001, loss_test:0.12172, lr:6.43e-03, fs:0.65969 (r=0.636,p=0.685),  time:18.490, tt:1238.833\n",
      "Ep:67, loss:0.00001, loss_test:0.12178, lr:6.36e-03, fs:0.65969 (r=0.636,p=0.685),  time:18.487, tt:1257.120\n",
      "Ep:68, loss:0.00001, loss_test:0.12216, lr:6.30e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.495, tt:1276.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.12246, lr:6.24e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.500, tt:1295.028\n",
      "Ep:70, loss:0.00001, loss_test:0.12271, lr:6.17e-03, fs:0.65608 (r=0.626,p=0.689),  time:18.505, tt:1313.871\n",
      "Ep:71, loss:0.00001, loss_test:0.12270, lr:6.11e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.483, tt:1330.763\n",
      "Ep:72, loss:0.00001, loss_test:0.12245, lr:6.05e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.481, tt:1349.078\n",
      "Ep:73, loss:0.00001, loss_test:0.12220, lr:5.99e-03, fs:0.65957 (r=0.626,p=0.697),  time:18.467, tt:1366.559\n",
      "Ep:74, loss:0.00001, loss_test:0.12230, lr:5.93e-03, fs:0.64516 (r=0.606,p=0.690),  time:18.458, tt:1384.314\n",
      "Ep:75, loss:0.00001, loss_test:0.12220, lr:5.87e-03, fs:0.64516 (r=0.606,p=0.690),  time:18.446, tt:1401.877\n",
      "Ep:76, loss:0.00001, loss_test:0.12157, lr:5.81e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.433, tt:1419.324\n",
      "Ep:77, loss:0.00001, loss_test:0.12128, lr:5.75e-03, fs:0.66310 (r=0.626,p=0.705),  time:18.416, tt:1436.487\n",
      "Ep:78, loss:0.00001, loss_test:0.12158, lr:5.70e-03, fs:0.64865 (r=0.606,p=0.698),  time:18.403, tt:1453.866\n",
      "Ep:79, loss:0.00001, loss_test:0.12151, lr:5.64e-03, fs:0.64865 (r=0.606,p=0.698),  time:18.382, tt:1470.570\n",
      "Ep:80, loss:0.00001, loss_test:0.12127, lr:5.58e-03, fs:0.64865 (r=0.606,p=0.698),  time:18.363, tt:1487.390\n",
      "Ep:81, loss:0.00001, loss_test:0.12130, lr:5.53e-03, fs:0.64865 (r=0.606,p=0.698),  time:18.349, tt:1504.609\n",
      "Ep:82, loss:0.00001, loss_test:0.12132, lr:5.47e-03, fs:0.65217 (r=0.606,p=0.706),  time:18.342, tt:1522.388\n",
      "Ep:83, loss:0.00001, loss_test:0.12120, lr:5.42e-03, fs:0.65217 (r=0.606,p=0.706),  time:18.314, tt:1538.402\n",
      "Ep:84, loss:0.00001, loss_test:0.12115, lr:5.36e-03, fs:0.65217 (r=0.606,p=0.706),  time:18.297, tt:1555.218\n",
      "Ep:85, loss:0.00001, loss_test:0.12083, lr:5.31e-03, fs:0.65217 (r=0.606,p=0.706),  time:18.283, tt:1572.334\n",
      "Ep:86, loss:0.00001, loss_test:0.12060, lr:5.26e-03, fs:0.65217 (r=0.606,p=0.706),  time:18.281, tt:1590.461\n",
      "Ep:87, loss:0.00001, loss_test:0.12094, lr:5.20e-03, fs:0.64481 (r=0.596,p=0.702),  time:18.279, tt:1608.520\n",
      "Ep:88, loss:0.00001, loss_test:0.12110, lr:5.15e-03, fs:0.64481 (r=0.596,p=0.702),  time:18.295, tt:1628.269\n",
      "Ep:89, loss:0.00001, loss_test:0.12092, lr:5.10e-03, fs:0.63736 (r=0.586,p=0.699),  time:18.291, tt:1646.165\n",
      "Ep:90, loss:0.00001, loss_test:0.12116, lr:5.05e-03, fs:0.62983 (r=0.576,p=0.695),  time:18.294, tt:1664.713\n",
      "Ep:91, loss:0.00001, loss_test:0.12164, lr:5.00e-03, fs:0.63687 (r=0.576,p=0.713),  time:18.292, tt:1682.858\n",
      "Ep:92, loss:0.00001, loss_test:0.12137, lr:4.95e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.286, tt:1700.606\n",
      "Ep:93, loss:0.00001, loss_test:0.12106, lr:4.90e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.284, tt:1718.701\n",
      "Ep:94, loss:0.00001, loss_test:0.12055, lr:4.85e-03, fs:0.63333 (r=0.576,p=0.704),  time:18.278, tt:1736.416\n",
      "Ep:95, loss:0.00001, loss_test:0.12102, lr:4.80e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.269, tt:1753.826\n",
      "Ep:96, loss:0.00001, loss_test:0.12092, lr:4.75e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.269, tt:1772.053\n",
      "Ep:97, loss:0.00001, loss_test:0.12041, lr:4.71e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.276, tt:1791.040\n",
      "Ep:98, loss:0.00001, loss_test:0.12023, lr:4.66e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.269, tt:1808.619\n",
      "Ep:99, loss:0.00001, loss_test:0.12036, lr:4.61e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.272, tt:1827.169\n",
      "Ep:100, loss:0.00001, loss_test:0.12027, lr:4.57e-03, fs:0.64804 (r=0.586,p=0.725),  time:18.273, tt:1845.613\n",
      "Ep:101, loss:0.00001, loss_test:0.12030, lr:4.52e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.267, tt:1863.276\n",
      "Ep:102, loss:0.00001, loss_test:0.12002, lr:4.48e-03, fs:0.64045 (r=0.576,p=0.722),  time:18.254, tt:1880.188\n",
      "Ep:103, loss:0.00001, loss_test:0.12035, lr:4.43e-03, fs:0.65169 (r=0.586,p=0.734),  time:18.249, tt:1897.947\n",
      "Ep:104, loss:0.00001, loss_test:0.12024, lr:4.39e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.250, tt:1916.266\n",
      "Ep:105, loss:0.00001, loss_test:0.11982, lr:4.34e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.243, tt:1933.717\n",
      "Ep:106, loss:0.00001, loss_test:0.11996, lr:4.30e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.244, tt:1952.092\n",
      "Ep:107, loss:0.00001, loss_test:0.11965, lr:4.26e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.238, tt:1969.751\n",
      "Ep:108, loss:0.00001, loss_test:0.11952, lr:4.21e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.235, tt:1987.663\n",
      "Ep:109, loss:0.00001, loss_test:0.12010, lr:4.17e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.230, tt:2005.301\n",
      "Ep:110, loss:0.00001, loss_test:0.11951, lr:4.13e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.222, tt:2022.668\n",
      "Ep:111, loss:0.00001, loss_test:0.11910, lr:4.09e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.219, tt:2040.544\n",
      "Ep:112, loss:0.00001, loss_test:0.11961, lr:4.05e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.217, tt:2058.536\n",
      "Ep:113, loss:0.00001, loss_test:0.11928, lr:4.01e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.219, tt:2077.014\n",
      "Ep:114, loss:0.00001, loss_test:0.11858, lr:3.97e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.222, tt:2095.493\n",
      "Ep:115, loss:0.00001, loss_test:0.11878, lr:3.93e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.222, tt:2113.800\n",
      "Ep:116, loss:0.00001, loss_test:0.11932, lr:3.89e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.221, tt:2131.827\n",
      "Ep:117, loss:0.00001, loss_test:0.11862, lr:3.85e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.222, tt:2150.157\n",
      "Ep:118, loss:0.00001, loss_test:0.11826, lr:3.81e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.219, tt:2168.031\n",
      "Ep:119, loss:0.00001, loss_test:0.11863, lr:3.77e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.212, tt:2185.447\n",
      "Ep:120, loss:0.00001, loss_test:0.11815, lr:3.73e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.211, tt:2203.513\n",
      "Ep:121, loss:0.00001, loss_test:0.11759, lr:3.70e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.213, tt:2222.001\n",
      "Ep:122, loss:0.00001, loss_test:0.11824, lr:3.66e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.222, tt:2241.286\n",
      "Ep:123, loss:0.00001, loss_test:0.11809, lr:3.62e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.224, tt:2259.806\n",
      "Ep:124, loss:0.00001, loss_test:0.11746, lr:3.59e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.227, tt:2278.425\n",
      "Ep:125, loss:0.00001, loss_test:0.11805, lr:3.55e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.234, tt:2297.446\n",
      "Ep:126, loss:0.00001, loss_test:0.11813, lr:3.52e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.247, tt:2317.335\n",
      "Ep:127, loss:0.00001, loss_test:0.11724, lr:3.48e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.258, tt:2337.022\n",
      "Ep:128, loss:0.00001, loss_test:0.11737, lr:3.45e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.255, tt:2354.875\n",
      "Ep:129, loss:0.00001, loss_test:0.11831, lr:3.41e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.261, tt:2373.950\n",
      "Ep:130, loss:0.00001, loss_test:0.11767, lr:3.38e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.267, tt:2392.937\n",
      "Ep:131, loss:0.00001, loss_test:0.11671, lr:3.34e-03, fs:0.64407 (r=0.576,p=0.731),  time:18.282, tt:2413.263\n",
      "Ep:132, loss:0.00001, loss_test:0.11748, lr:3.31e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.289, tt:2432.498\n",
      "Ep:133, loss:0.00001, loss_test:0.11862, lr:3.28e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.293, tt:2451.309\n",
      "Ep:134, loss:0.00001, loss_test:0.11778, lr:3.24e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.296, tt:2469.933\n",
      "Ep:135, loss:0.00001, loss_test:0.11684, lr:3.21e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.307, tt:2489.798\n",
      "Ep:136, loss:0.00001, loss_test:0.11738, lr:3.18e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.318, tt:2509.601\n",
      "Ep:137, loss:0.00001, loss_test:0.11813, lr:3.15e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.325, tt:2528.903\n",
      "Ep:138, loss:0.00001, loss_test:0.11751, lr:3.12e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.325, tt:2547.163\n",
      "Ep:139, loss:0.00001, loss_test:0.11668, lr:3.09e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.338, tt:2567.311\n",
      "Ep:140, loss:0.00001, loss_test:0.11724, lr:3.05e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.351, tt:2587.436\n",
      "Ep:141, loss:0.00001, loss_test:0.11796, lr:3.02e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.367, tt:2608.055\n",
      "Ep:142, loss:0.00001, loss_test:0.11750, lr:2.99e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.371, tt:2627.116\n",
      "Ep:143, loss:0.00001, loss_test:0.11690, lr:2.96e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.379, tt:2646.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.11706, lr:2.93e-03, fs:0.64773 (r=0.576,p=0.740),  time:18.386, tt:2665.957\n",
      "Ep:145, loss:0.00001, loss_test:0.11762, lr:2.90e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.394, tt:2685.564\n",
      "Ep:146, loss:0.00001, loss_test:0.11726, lr:2.88e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.396, tt:2704.187\n",
      "Ep:147, loss:0.00001, loss_test:0.11671, lr:2.85e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.400, tt:2723.203\n",
      "Ep:148, loss:0.00001, loss_test:0.11756, lr:2.82e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.411, tt:2743.189\n",
      "Ep:149, loss:0.00001, loss_test:0.11778, lr:2.79e-03, fs:0.65517 (r=0.576,p=0.760),  time:18.411, tt:2761.667\n",
      "Ep:150, loss:0.00001, loss_test:0.11718, lr:2.76e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.414, tt:2780.588\n",
      "Ep:151, loss:0.00001, loss_test:0.11715, lr:2.73e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.419, tt:2799.739\n",
      "Ep:152, loss:0.00001, loss_test:0.11735, lr:2.71e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.432, tt:2820.122\n",
      "Ep:153, loss:0.00001, loss_test:0.11725, lr:2.68e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.434, tt:2838.901\n",
      "Ep:154, loss:0.00001, loss_test:0.11753, lr:2.65e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.437, tt:2857.788\n",
      "Ep:155, loss:0.00001, loss_test:0.11786, lr:2.63e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.439, tt:2876.511\n",
      "Ep:156, loss:0.00001, loss_test:0.11751, lr:2.60e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.437, tt:2894.682\n",
      "Ep:157, loss:0.00001, loss_test:0.11690, lr:2.57e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.442, tt:2913.757\n",
      "Ep:158, loss:0.00001, loss_test:0.11710, lr:2.55e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.444, tt:2932.667\n",
      "Ep:159, loss:0.00001, loss_test:0.11791, lr:2.52e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.444, tt:2951.018\n",
      "Ep:160, loss:0.00001, loss_test:0.11787, lr:2.50e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.454, tt:2971.029\n",
      "Ep:161, loss:0.00001, loss_test:0.11711, lr:2.47e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.459, tt:2990.390\n",
      "Ep:162, loss:0.00001, loss_test:0.11725, lr:2.45e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.458, tt:3008.717\n",
      "Ep:163, loss:0.00001, loss_test:0.11754, lr:2.42e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.458, tt:3027.085\n",
      "Ep:164, loss:0.00001, loss_test:0.11790, lr:2.40e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.459, tt:3045.679\n",
      "Ep:165, loss:0.00001, loss_test:0.11790, lr:2.38e-03, fs:0.65896 (r=0.576,p=0.770),  time:18.462, tt:3064.618\n",
      "Ep:166, loss:0.00001, loss_test:0.11780, lr:2.35e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.461, tt:3083.021\n",
      "Ep:167, loss:0.00001, loss_test:0.11762, lr:2.33e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.458, tt:3100.963\n",
      "Ep:168, loss:0.00001, loss_test:0.11760, lr:2.31e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.461, tt:3119.833\n",
      "Ep:169, loss:0.00001, loss_test:0.11786, lr:2.28e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.458, tt:3137.891\n",
      "Ep:170, loss:0.00001, loss_test:0.11830, lr:2.26e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.462, tt:3157.016\n",
      "Ep:171, loss:0.00001, loss_test:0.11789, lr:2.24e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.466, tt:3176.101\n",
      "Ep:172, loss:0.00001, loss_test:0.11735, lr:2.21e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.472, tt:3195.668\n",
      "Ep:173, loss:0.00001, loss_test:0.11773, lr:2.19e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.476, tt:3214.909\n",
      "Ep:174, loss:0.00001, loss_test:0.11827, lr:2.17e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.479, tt:3233.868\n",
      "Ep:175, loss:0.00001, loss_test:0.11804, lr:2.15e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.481, tt:3252.579\n",
      "Ep:176, loss:0.00001, loss_test:0.11750, lr:2.13e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.487, tt:3272.178\n",
      "Ep:177, loss:0.00001, loss_test:0.11767, lr:2.11e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.491, tt:3291.419\n",
      "Ep:178, loss:0.00001, loss_test:0.11799, lr:2.08e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.491, tt:3309.958\n",
      "Ep:179, loss:0.00001, loss_test:0.11812, lr:2.06e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.500, tt:3330.074\n",
      "Ep:180, loss:0.00001, loss_test:0.11787, lr:2.04e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.503, tt:3349.117\n",
      "Ep:181, loss:0.00001, loss_test:0.11759, lr:2.02e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.504, tt:3367.816\n",
      "Ep:182, loss:0.00001, loss_test:0.11776, lr:2.00e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.498, tt:3385.150\n",
      "Ep:183, loss:0.00001, loss_test:0.11798, lr:1.98e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.499, tt:3403.881\n",
      "Ep:184, loss:0.00001, loss_test:0.11803, lr:1.96e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.507, tt:3423.721\n",
      "Ep:185, loss:0.00001, loss_test:0.11771, lr:1.94e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.511, tt:3442.984\n",
      "Ep:186, loss:0.00001, loss_test:0.11777, lr:1.92e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.511, tt:3461.623\n",
      "Ep:187, loss:0.00001, loss_test:0.11819, lr:1.90e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.511, tt:3480.150\n",
      "Ep:188, loss:0.00001, loss_test:0.11815, lr:1.89e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.510, tt:3498.442\n",
      "Ep:189, loss:0.00001, loss_test:0.11775, lr:1.87e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.515, tt:3517.921\n",
      "Ep:190, loss:0.00001, loss_test:0.11769, lr:1.85e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.515, tt:3536.409\n",
      "Ep:191, loss:0.00001, loss_test:0.11820, lr:1.83e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.518, tt:3555.480\n",
      "Ep:192, loss:0.00001, loss_test:0.11828, lr:1.81e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.525, tt:3575.275\n",
      "Ep:193, loss:0.00001, loss_test:0.11778, lr:1.79e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.524, tt:3593.635\n",
      "Ep:194, loss:0.00001, loss_test:0.11742, lr:1.78e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.525, tt:3612.466\n",
      "Ep:195, loss:0.00001, loss_test:0.11789, lr:1.76e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.527, tt:3631.204\n",
      "Ep:196, loss:0.00001, loss_test:0.11847, lr:1.74e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.529, tt:3650.139\n",
      "Ep:197, loss:0.00001, loss_test:0.11821, lr:1.72e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.532, tt:3669.421\n",
      "Ep:198, loss:0.00001, loss_test:0.11767, lr:1.71e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.536, tt:3688.648\n",
      "Ep:199, loss:0.00001, loss_test:0.11752, lr:1.69e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.543, tt:3708.563\n",
      "Ep:200, loss:0.00001, loss_test:0.11806, lr:1.67e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.545, tt:3727.455\n",
      "Ep:201, loss:0.00001, loss_test:0.11852, lr:1.65e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.547, tt:3746.514\n",
      "Ep:202, loss:0.00001, loss_test:0.11831, lr:1.64e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.552, tt:3766.051\n",
      "Ep:203, loss:0.00001, loss_test:0.11768, lr:1.62e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.547, tt:3783.546\n",
      "Ep:204, loss:0.00001, loss_test:0.11770, lr:1.61e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.544, tt:3801.473\n",
      "Ep:205, loss:0.00001, loss_test:0.11831, lr:1.59e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.550, tt:3821.344\n",
      "Ep:206, loss:0.00001, loss_test:0.11847, lr:1.57e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.551, tt:3840.067\n",
      "Ep:207, loss:0.00001, loss_test:0.11804, lr:1.56e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.554, tt:3859.218\n",
      "Ep:208, loss:0.00001, loss_test:0.11761, lr:1.54e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.556, tt:3878.173\n",
      "Ep:209, loss:0.00001, loss_test:0.11785, lr:1.53e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.557, tt:3897.051\n",
      "Ep:210, loss:0.00001, loss_test:0.11825, lr:1.51e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.560, tt:3916.084\n",
      "Ep:211, loss:0.00001, loss_test:0.11819, lr:1.50e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.562, tt:3935.165\n",
      "Ep:212, loss:0.00001, loss_test:0.11771, lr:1.48e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.567, tt:3954.731\n",
      "Ep:213, loss:0.00001, loss_test:0.11742, lr:1.47e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.569, tt:3973.766\n",
      "Ep:214, loss:0.00001, loss_test:0.11772, lr:1.45e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.571, tt:3992.781\n",
      "Ep:215, loss:0.00001, loss_test:0.11823, lr:1.44e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.575, tt:4012.139\n",
      "Ep:216, loss:0.00001, loss_test:0.11810, lr:1.42e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.573, tt:4030.278\n",
      "Ep:217, loss:0.00001, loss_test:0.11773, lr:1.41e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.572, tt:4048.764\n",
      "Ep:218, loss:0.00001, loss_test:0.11769, lr:1.39e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.573, tt:4067.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:219, loss:0.00001, loss_test:0.11795, lr:1.38e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.574, tt:4086.383\n",
      "Ep:220, loss:0.00001, loss_test:0.11812, lr:1.37e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.578, tt:4105.738\n",
      "Ep:221, loss:0.00001, loss_test:0.11792, lr:1.35e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.579, tt:4124.625\n",
      "Ep:222, loss:0.00001, loss_test:0.11763, lr:1.34e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.579, tt:4143.016\n",
      "Ep:223, loss:0.00001, loss_test:0.11766, lr:1.33e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.581, tt:4162.058\n",
      "Ep:224, loss:0.00001, loss_test:0.11808, lr:1.31e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.577, tt:4179.886\n",
      "Ep:225, loss:0.00001, loss_test:0.11816, lr:1.30e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.574, tt:4197.824\n",
      "Ep:226, loss:0.00001, loss_test:0.11772, lr:1.29e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.580, tt:4217.556\n",
      "Ep:227, loss:0.00001, loss_test:0.11751, lr:1.27e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.575, tt:4235.150\n",
      "Ep:228, loss:0.00001, loss_test:0.11768, lr:1.26e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.572, tt:4253.085\n",
      "Ep:229, loss:0.00001, loss_test:0.11790, lr:1.25e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.571, tt:4271.253\n",
      "Ep:230, loss:0.00001, loss_test:0.11782, lr:1.24e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.573, tt:4290.385\n",
      "Ep:231, loss:0.00001, loss_test:0.11778, lr:1.22e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.572, tt:4308.683\n",
      "Ep:232, loss:0.00001, loss_test:0.11760, lr:1.21e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.573, tt:4327.617\n",
      "Ep:233, loss:0.00001, loss_test:0.11771, lr:1.20e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.576, tt:4346.841\n",
      "Ep:234, loss:0.00001, loss_test:0.11792, lr:1.19e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.580, tt:4366.226\n",
      "Ep:235, loss:0.00001, loss_test:0.11778, lr:1.18e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.584, tt:4385.808\n",
      "Ep:236, loss:0.00001, loss_test:0.11761, lr:1.16e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.588, tt:4405.360\n",
      "Ep:237, loss:0.00001, loss_test:0.11779, lr:1.15e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.592, tt:4424.910\n",
      "Ep:238, loss:0.00001, loss_test:0.11792, lr:1.14e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.594, tt:4443.869\n",
      "Ep:239, loss:0.00001, loss_test:0.11776, lr:1.13e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.592, tt:4462.153\n",
      "Ep:240, loss:0.00001, loss_test:0.11776, lr:1.12e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.595, tt:4481.304\n",
      "Ep:241, loss:0.00001, loss_test:0.11762, lr:1.11e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.595, tt:4500.016\n",
      "Ep:242, loss:0.00001, loss_test:0.11786, lr:1.10e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.594, tt:4518.281\n",
      "Ep:243, loss:0.00001, loss_test:0.11801, lr:1.08e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.599, tt:4538.064\n",
      "Ep:244, loss:0.00001, loss_test:0.11784, lr:1.07e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.600, tt:4557.119\n",
      "Ep:245, loss:0.00001, loss_test:0.11755, lr:1.06e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.602, tt:4576.065\n",
      "Ep:246, loss:0.00001, loss_test:0.11770, lr:1.05e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.603, tt:4595.009\n",
      "Ep:247, loss:0.00001, loss_test:0.11803, lr:1.04e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.607, tt:4614.608\n",
      "Ep:248, loss:0.00001, loss_test:0.11802, lr:1.03e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.606, tt:4632.843\n",
      "Ep:249, loss:0.00001, loss_test:0.11765, lr:1.02e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.609, tt:4652.240\n",
      "Ep:250, loss:0.00001, loss_test:0.11766, lr:1.01e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.615, tt:4672.433\n",
      "Ep:251, loss:0.00001, loss_test:0.11790, lr:1.00e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.617, tt:4691.537\n",
      "Ep:252, loss:0.00001, loss_test:0.11787, lr:9.91e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.613, tt:4709.047\n",
      "Ep:253, loss:0.00001, loss_test:0.11786, lr:9.81e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.617, tt:4728.729\n",
      "Ep:254, loss:0.00001, loss_test:0.11772, lr:9.71e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.616, tt:4747.104\n",
      "Ep:255, loss:0.00001, loss_test:0.11773, lr:9.62e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.620, tt:4766.723\n",
      "Ep:256, loss:0.00001, loss_test:0.11798, lr:9.52e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.624, tt:4786.254\n",
      "Ep:257, loss:0.00001, loss_test:0.11800, lr:9.42e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.629, tt:4806.264\n",
      "Ep:258, loss:0.00001, loss_test:0.11769, lr:9.33e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.632, tt:4825.563\n",
      "Ep:259, loss:0.00001, loss_test:0.11769, lr:9.24e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.635, tt:4845.146\n",
      "Ep:260, loss:0.00001, loss_test:0.11787, lr:9.14e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.636, tt:4864.065\n",
      "Ep:261, loss:0.00001, loss_test:0.11792, lr:9.05e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.643, tt:4884.416\n",
      "Ep:262, loss:0.00001, loss_test:0.11803, lr:8.96e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.646, tt:4903.954\n",
      "Ep:263, loss:0.00001, loss_test:0.11785, lr:8.87e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.652, tt:4924.185\n",
      "Ep:264, loss:0.00001, loss_test:0.11768, lr:8.78e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.654, tt:4943.403\n",
      "Ep:265, loss:0.00001, loss_test:0.11785, lr:8.70e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.657, tt:4962.839\n",
      "Ep:266, loss:0.00001, loss_test:0.11791, lr:8.61e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.657, tt:4981.507\n",
      "Ep:267, loss:0.00001, loss_test:0.11791, lr:8.52e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.659, tt:5000.479\n",
      "Ep:268, loss:0.00001, loss_test:0.11785, lr:8.44e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.663, tt:5020.221\n",
      "Ep:269, loss:0.00001, loss_test:0.11781, lr:8.35e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.663, tt:5039.040\n",
      "Ep:270, loss:0.00001, loss_test:0.11782, lr:8.27e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.663, tt:5057.656\n",
      "Ep:271, loss:0.00001, loss_test:0.11800, lr:8.19e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.663, tt:5076.255\n",
      "Ep:272, loss:0.00001, loss_test:0.11796, lr:8.11e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.663, tt:5094.926\n",
      "Ep:273, loss:0.00001, loss_test:0.11777, lr:8.02e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.664, tt:5113.862\n",
      "Ep:274, loss:0.00001, loss_test:0.11787, lr:7.94e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.662, tt:5132.044\n",
      "Ep:275, loss:0.00001, loss_test:0.11795, lr:7.87e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.661, tt:5150.539\n",
      "Ep:276, loss:0.00001, loss_test:0.11796, lr:7.79e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.666, tt:5170.361\n",
      "Ep:277, loss:0.00001, loss_test:0.11804, lr:7.71e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.666, tt:5189.111\n",
      "Ep:278, loss:0.00001, loss_test:0.11800, lr:7.63e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.669, tt:5208.634\n",
      "Ep:279, loss:0.00001, loss_test:0.11788, lr:7.56e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.672, tt:5228.233\n",
      "Ep:280, loss:0.00001, loss_test:0.11805, lr:7.48e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.674, tt:5247.271\n",
      "Ep:281, loss:0.00001, loss_test:0.11793, lr:7.40e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.676, tt:5266.582\n",
      "Ep:282, loss:0.00001, loss_test:0.11786, lr:7.33e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5286.453\n",
      "Ep:283, loss:0.00001, loss_test:0.11812, lr:7.26e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5305.072\n",
      "Ep:284, loss:0.00001, loss_test:0.11810, lr:7.18e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5323.891\n",
      "Ep:285, loss:0.00001, loss_test:0.11786, lr:7.11e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5342.402\n",
      "Ep:286, loss:0.00001, loss_test:0.11801, lr:7.04e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5361.156\n",
      "Ep:287, loss:0.00001, loss_test:0.11810, lr:6.97e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.680, tt:5379.808\n",
      "Ep:288, loss:0.00001, loss_test:0.11806, lr:6.90e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.675, tt:5397.207\n",
      "Ep:289, loss:0.00001, loss_test:0.11793, lr:6.83e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.673, tt:5415.215\n",
      "Ep:290, loss:0.00001, loss_test:0.11800, lr:6.76e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.676, tt:5434.779\n",
      "Ep:291, loss:0.00001, loss_test:0.11801, lr:6.70e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.673, tt:5452.586\n",
      "Ep:292, loss:0.00001, loss_test:0.11806, lr:6.63e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.672, tt:5471.025\n",
      "Ep:293, loss:0.00001, loss_test:0.11799, lr:6.56e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.667, tt:5488.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:294, loss:0.00001, loss_test:0.11808, lr:6.50e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.657, tt:5503.911\n",
      "Ep:295, loss:0.00001, loss_test:0.11804, lr:6.43e-04, fs:0.66279 (r=0.576,p=0.781),  time:18.641, tt:5517.671\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.12804, lr:1.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:17.354, tt:17.354\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.12650, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:17.764, tt:35.528\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.12458, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:17.887, tt:53.661\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.12263, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:18.296, tt:73.186\n",
      "Ep:4, loss:0.00004, loss_test:0.12115, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:18.143, tt:90.714\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.12021, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:17.809, tt:106.856\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.11956, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:17.877, tt:125.140\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.11919, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:17.920, tt:143.359\n",
      "Ep:8, loss:0.00004, loss_test:0.11886, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:17.936, tt:161.423\n",
      "Ep:9, loss:0.00004, loss_test:0.11855, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:18.075, tt:180.747\n",
      "Ep:10, loss:0.00004, loss_test:0.11819, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:18.172, tt:199.895\n",
      "Ep:11, loss:0.00004, loss_test:0.11787, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:18.149, tt:217.788\n",
      "Ep:12, loss:0.00004, loss_test:0.11761, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:18.193, tt:236.508\n",
      "Ep:13, loss:0.00004, loss_test:0.11739, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:18.231, tt:255.233\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.11717, lr:1.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:18.170, tt:272.554\n",
      "Ep:15, loss:0.00004, loss_test:0.11693, lr:1.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:18.243, tt:291.888\n",
      "Ep:16, loss:0.00004, loss_test:0.11663, lr:1.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:18.258, tt:310.390\n",
      "Ep:17, loss:0.00004, loss_test:0.11628, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:18.275, tt:328.948\n",
      "Ep:18, loss:0.00003, loss_test:0.11586, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:18.288, tt:347.474\n",
      "Ep:19, loss:0.00003, loss_test:0.11546, lr:1.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:18.309, tt:366.181\n",
      "Ep:20, loss:0.00003, loss_test:0.11520, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:18.347, tt:385.288\n",
      "Ep:21, loss:0.00003, loss_test:0.11495, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.392, tt:404.616\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.11468, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.408, tt:423.392\n",
      "Ep:23, loss:0.00003, loss_test:0.11444, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:18.408, tt:441.783\n",
      "Ep:24, loss:0.00003, loss_test:0.11424, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.402, tt:460.046\n",
      "Ep:25, loss:0.00003, loss_test:0.11403, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.432, tt:479.230\n",
      "Ep:26, loss:0.00003, loss_test:0.11381, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:18.449, tt:498.114\n",
      "Ep:27, loss:0.00003, loss_test:0.11362, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:18.434, tt:516.151\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.11342, lr:1.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:18.468, tt:535.566\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.11319, lr:1.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:18.464, tt:553.918\n",
      "Ep:30, loss:0.00003, loss_test:0.11294, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:18.501, tt:573.540\n",
      "Ep:31, loss:0.00003, loss_test:0.11269, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:18.487, tt:591.595\n",
      "Ep:32, loss:0.00003, loss_test:0.11235, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:18.500, tt:610.503\n",
      "Ep:33, loss:0.00003, loss_test:0.11183, lr:1.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:18.493, tt:628.746\n",
      "Ep:34, loss:0.00003, loss_test:0.11112, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:18.523, tt:648.311\n",
      "Ep:35, loss:0.00003, loss_test:0.11060, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:18.526, tt:666.923\n",
      "Ep:36, loss:0.00003, loss_test:0.11029, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:18.531, tt:685.639\n",
      "Ep:37, loss:0.00003, loss_test:0.11017, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:18.525, tt:703.958\n",
      "Ep:38, loss:0.00003, loss_test:0.11011, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:18.527, tt:722.539\n",
      "Ep:39, loss:0.00003, loss_test:0.11005, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:18.546, tt:741.844\n",
      "Ep:40, loss:0.00003, loss_test:0.10998, lr:9.90e-03, fs:0.69604 (r=0.798,p=0.617),  time:18.554, tt:760.695\n",
      "Ep:41, loss:0.00003, loss_test:0.10983, lr:9.80e-03, fs:0.69027 (r=0.788,p=0.614),  time:18.573, tt:780.047\n",
      "Ep:42, loss:0.00003, loss_test:0.10990, lr:9.70e-03, fs:0.68750 (r=0.778,p=0.616),  time:18.599, tt:799.754\n",
      "Ep:43, loss:0.00003, loss_test:0.11005, lr:9.61e-03, fs:0.69604 (r=0.798,p=0.617),  time:18.623, tt:819.425\n",
      "Ep:44, loss:0.00003, loss_test:0.11010, lr:9.51e-03, fs:0.69027 (r=0.788,p=0.614),  time:18.643, tt:838.930\n",
      "Ep:45, loss:0.00003, loss_test:0.11006, lr:9.41e-03, fs:0.69027 (r=0.788,p=0.614),  time:18.633, tt:857.111\n",
      "Ep:46, loss:0.00003, loss_test:0.10998, lr:9.32e-03, fs:0.69027 (r=0.788,p=0.614),  time:18.651, tt:876.579\n",
      "Ep:47, loss:0.00003, loss_test:0.11001, lr:9.23e-03, fs:0.69643 (r=0.788,p=0.624),  time:18.654, tt:895.386\n",
      "Ep:48, loss:0.00003, loss_test:0.11019, lr:9.14e-03, fs:0.69369 (r=0.778,p=0.626),  time:18.672, tt:914.913\n",
      "Ep:49, loss:0.00003, loss_test:0.11053, lr:9.04e-03, fs:0.69369 (r=0.778,p=0.626),  time:18.692, tt:934.580\n",
      "Ep:50, loss:0.00003, loss_test:0.11088, lr:8.95e-03, fs:0.69369 (r=0.778,p=0.626),  time:18.704, tt:953.919\n",
      "Ep:51, loss:0.00003, loss_test:0.11105, lr:8.86e-03, fs:0.69369 (r=0.778,p=0.626),  time:18.724, tt:973.655\n",
      "Ep:52, loss:0.00002, loss_test:0.11111, lr:8.78e-03, fs:0.68468 (r=0.768,p=0.618),  time:18.768, tt:994.712\n",
      "Ep:53, loss:0.00002, loss_test:0.11109, lr:8.69e-03, fs:0.68182 (r=0.758,p=0.620),  time:18.781, tt:1014.180\n",
      "Ep:54, loss:0.00002, loss_test:0.11108, lr:8.60e-03, fs:0.68203 (r=0.747,p=0.627),  time:18.819, tt:1035.039\n",
      "Ep:55, loss:0.00002, loss_test:0.11106, lr:8.51e-03, fs:0.66667 (r=0.727,p=0.615),  time:18.823, tt:1054.103\n",
      "Ep:56, loss:0.00002, loss_test:0.11102, lr:8.43e-03, fs:0.66667 (r=0.727,p=0.615),  time:18.812, tt:1072.288\n",
      "Ep:57, loss:0.00002, loss_test:0.11088, lr:8.35e-03, fs:0.66977 (r=0.727,p=0.621),  time:18.814, tt:1091.227\n",
      "Ep:58, loss:0.00002, loss_test:0.11079, lr:8.26e-03, fs:0.66981 (r=0.717,p=0.628),  time:18.820, tt:1110.386\n",
      "Ep:59, loss:0.00002, loss_test:0.11072, lr:8.18e-03, fs:0.66667 (r=0.707,p=0.631),  time:18.832, tt:1129.950\n",
      "Ep:60, loss:0.00002, loss_test:0.11064, lr:8.10e-03, fs:0.66986 (r=0.707,p=0.636),  time:18.840, tt:1149.237\n",
      "Ep:61, loss:0.00002, loss_test:0.11042, lr:8.02e-03, fs:0.67308 (r=0.707,p=0.642),  time:18.848, tt:1168.602\n",
      "Ep:62, loss:0.00002, loss_test:0.11021, lr:7.94e-03, fs:0.67961 (r=0.707,p=0.654),  time:18.860, tt:1188.175\n",
      "Ep:63, loss:0.00002, loss_test:0.10987, lr:7.86e-03, fs:0.67961 (r=0.707,p=0.654),  time:18.871, tt:1207.720\n",
      "Ep:64, loss:0.00002, loss_test:0.10946, lr:7.78e-03, fs:0.66995 (r=0.687,p=0.654),  time:18.876, tt:1226.910\n",
      "Ep:65, loss:0.00002, loss_test:0.10916, lr:7.70e-03, fs:0.68932 (r=0.717,p=0.664),  time:18.884, tt:1246.373\n",
      "Ep:66, loss:0.00002, loss_test:0.10893, lr:7.62e-03, fs:0.68269 (r=0.717,p=0.651),  time:18.892, tt:1265.738\n",
      "Ep:67, loss:0.00002, loss_test:0.10890, lr:7.55e-03, fs:0.68900 (r=0.727,p=0.655),  time:18.906, tt:1285.587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00002, loss_test:0.10899, lr:7.47e-03, fs:0.68900 (r=0.727,p=0.655),  time:18.901, tt:1304.160\n",
      "Ep:69, loss:0.00002, loss_test:0.10861, lr:7.40e-03, fs:0.68900 (r=0.727,p=0.655),  time:18.912, tt:1323.861\n",
      "Ep:70, loss:0.00002, loss_test:0.10817, lr:7.32e-03, fs:0.68900 (r=0.727,p=0.655),  time:18.929, tt:1343.930\n",
      "Ep:71, loss:0.00002, loss_test:0.10811, lr:7.25e-03, fs:0.70192 (r=0.737,p=0.670),  time:18.927, tt:1362.770\n",
      "Ep:72, loss:0.00002, loss_test:0.10815, lr:7.18e-03, fs:0.71154 (r=0.747,p=0.679),  time:18.939, tt:1382.569\n",
      "Ep:73, loss:0.00002, loss_test:0.10782, lr:7.11e-03, fs:0.71845 (r=0.747,p=0.692),  time:18.946, tt:1401.976\n",
      "Ep:74, loss:0.00002, loss_test:0.10762, lr:7.03e-03, fs:0.71845 (r=0.747,p=0.692),  time:18.942, tt:1420.637\n",
      "Ep:75, loss:0.00002, loss_test:0.10755, lr:6.96e-03, fs:0.71845 (r=0.747,p=0.692),  time:18.947, tt:1439.965\n",
      "Ep:76, loss:0.00002, loss_test:0.10739, lr:6.89e-03, fs:0.72727 (r=0.768,p=0.691),  time:18.950, tt:1459.168\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.10709, lr:6.89e-03, fs:0.73077 (r=0.768,p=0.697),  time:18.951, tt:1478.180\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.10681, lr:6.89e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.960, tt:1497.879\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.10694, lr:6.89e-03, fs:0.73077 (r=0.768,p=0.697),  time:18.961, tt:1516.869\n",
      "Ep:80, loss:0.00002, loss_test:0.10743, lr:6.89e-03, fs:0.72381 (r=0.768,p=0.685),  time:18.965, tt:1536.129\n",
      "Ep:81, loss:0.00002, loss_test:0.10729, lr:6.89e-03, fs:0.72727 (r=0.768,p=0.691),  time:18.953, tt:1554.158\n",
      "Ep:82, loss:0.00002, loss_test:0.10677, lr:6.89e-03, fs:0.73786 (r=0.768,p=0.710),  time:19.000, tt:1577.014\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.10709, lr:6.89e-03, fs:0.73171 (r=0.758,p=0.708),  time:18.989, tt:1595.101\n",
      "Ep:84, loss:0.00002, loss_test:0.10698, lr:6.89e-03, fs:0.72464 (r=0.758,p=0.694),  time:18.969, tt:1612.378\n",
      "Ep:85, loss:0.00002, loss_test:0.10673, lr:6.89e-03, fs:0.72816 (r=0.758,p=0.701),  time:18.964, tt:1630.878\n",
      "Ep:86, loss:0.00002, loss_test:0.10649, lr:6.89e-03, fs:0.72816 (r=0.758,p=0.701),  time:18.956, tt:1649.201\n",
      "Ep:87, loss:0.00002, loss_test:0.10641, lr:6.89e-03, fs:0.72816 (r=0.758,p=0.701),  time:18.955, tt:1668.015\n",
      "Ep:88, loss:0.00001, loss_test:0.10673, lr:6.89e-03, fs:0.74627 (r=0.758,p=0.735),  time:18.942, tt:1685.811\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.10542, lr:6.89e-03, fs:0.73529 (r=0.758,p=0.714),  time:18.950, tt:1705.533\n",
      "Ep:90, loss:0.00001, loss_test:0.10597, lr:6.89e-03, fs:0.75000 (r=0.758,p=0.743),  time:18.944, tt:1723.923\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.10520, lr:6.89e-03, fs:0.74257 (r=0.758,p=0.728),  time:18.925, tt:1741.073\n",
      "Ep:92, loss:0.00001, loss_test:0.10501, lr:6.89e-03, fs:0.75000 (r=0.758,p=0.743),  time:18.920, tt:1759.565\n",
      "Ep:93, loss:0.00001, loss_test:0.10490, lr:6.89e-03, fs:0.74257 (r=0.758,p=0.728),  time:18.924, tt:1778.835\n",
      "Ep:94, loss:0.00001, loss_test:0.10502, lr:6.89e-03, fs:0.73737 (r=0.737,p=0.737),  time:18.920, tt:1797.367\n",
      "Ep:95, loss:0.00001, loss_test:0.10230, lr:6.89e-03, fs:0.74877 (r=0.768,p=0.731),  time:18.916, tt:1815.906\n",
      "Ep:96, loss:0.00001, loss_test:0.10658, lr:6.89e-03, fs:0.72821 (r=0.717,p=0.740),  time:18.904, tt:1833.709\n",
      "Ep:97, loss:0.00001, loss_test:0.10102, lr:6.89e-03, fs:0.75248 (r=0.768,p=0.738),  time:18.907, tt:1852.857\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.10569, lr:6.89e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.904, tt:1871.471\n",
      "Ep:99, loss:0.00001, loss_test:0.10026, lr:6.89e-03, fs:0.75000 (r=0.758,p=0.743),  time:18.905, tt:1890.451\n",
      "Ep:100, loss:0.00001, loss_test:0.10232, lr:6.89e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.910, tt:1909.909\n",
      "Ep:101, loss:0.00001, loss_test:0.10027, lr:6.89e-03, fs:0.74490 (r=0.737,p=0.753),  time:18.910, tt:1928.795\n",
      "Ep:102, loss:0.00001, loss_test:0.09933, lr:6.89e-03, fs:0.75758 (r=0.758,p=0.758),  time:18.908, tt:1947.519\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.10389, lr:6.89e-03, fs:0.73575 (r=0.717,p=0.755),  time:18.900, tt:1965.580\n",
      "Ep:104, loss:0.00001, loss_test:0.09882, lr:6.89e-03, fs:0.76382 (r=0.768,p=0.760),  time:18.909, tt:1985.489\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.10577, lr:6.89e-03, fs:0.75789 (r=0.727,p=0.791),  time:18.906, tt:2004.059\n",
      "Ep:106, loss:0.00001, loss_test:0.09858, lr:6.89e-03, fs:0.77612 (r=0.788,p=0.765),  time:18.907, tt:2023.035\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.10386, lr:6.89e-03, fs:0.74737 (r=0.717,p=0.780),  time:18.901, tt:2041.259\n",
      "Ep:108, loss:0.00001, loss_test:0.09994, lr:6.89e-03, fs:0.76289 (r=0.747,p=0.779),  time:18.896, tt:2059.636\n",
      "Ep:109, loss:0.00001, loss_test:0.09913, lr:6.89e-03, fs:0.78000 (r=0.788,p=0.772),  time:18.900, tt:2079.001\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.10554, lr:6.89e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.898, tt:2097.711\n",
      "Ep:111, loss:0.00001, loss_test:0.09943, lr:6.89e-03, fs:0.78607 (r=0.798,p=0.775),  time:18.897, tt:2116.466\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00001, loss_test:0.10247, lr:6.89e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.899, tt:2135.623\n",
      "Ep:113, loss:0.00001, loss_test:0.10085, lr:6.89e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.894, tt:2153.891\n",
      "Ep:114, loss:0.00001, loss_test:0.09859, lr:6.89e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.892, tt:2172.530\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.10160, lr:6.89e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.893, tt:2191.537\n",
      "Ep:116, loss:0.00001, loss_test:0.09957, lr:6.89e-03, fs:0.78173 (r=0.778,p=0.786),  time:18.891, tt:2210.301\n",
      "Ep:117, loss:0.00001, loss_test:0.09724, lr:6.89e-03, fs:0.78571 (r=0.778,p=0.794),  time:18.890, tt:2228.963\n",
      "Ep:118, loss:0.00001, loss_test:0.10229, lr:6.89e-03, fs:0.76757 (r=0.717,p=0.826),  time:18.894, tt:2248.385\n",
      "Ep:119, loss:0.00001, loss_test:0.10008, lr:6.89e-03, fs:0.77778 (r=0.778,p=0.778),  time:18.889, tt:2266.689\n",
      "Ep:120, loss:0.00001, loss_test:0.09770, lr:6.89e-03, fs:0.76923 (r=0.758,p=0.781),  time:18.895, tt:2286.331\n",
      "Ep:121, loss:0.00001, loss_test:0.10106, lr:6.89e-03, fs:0.79581 (r=0.768,p=0.826),  time:18.892, tt:2304.835\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.10502, lr:6.89e-03, fs:0.76382 (r=0.768,p=0.760),  time:18.898, tt:2324.508\n",
      "Ep:123, loss:0.00001, loss_test:0.10054, lr:6.89e-03, fs:0.78788 (r=0.788,p=0.788),  time:18.907, tt:2344.433\n",
      "Ep:124, loss:0.00001, loss_test:0.09845, lr:6.89e-03, fs:0.78756 (r=0.768,p=0.809),  time:18.904, tt:2363.007\n",
      "Ep:125, loss:0.00001, loss_test:0.10780, lr:6.89e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.905, tt:2382.062\n",
      "Ep:126, loss:0.00001, loss_test:0.10597, lr:6.89e-03, fs:0.79630 (r=0.869,p=0.735),  time:18.908, tt:2401.353\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.10123, lr:6.89e-03, fs:0.80208 (r=0.778,p=0.828),  time:18.911, tt:2420.546\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.09822, lr:6.89e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.914, tt:2439.922\n",
      "Ep:129, loss:0.00001, loss_test:0.10556, lr:6.89e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.915, tt:2458.983\n",
      "Ep:130, loss:0.00001, loss_test:0.10815, lr:6.89e-03, fs:0.77073 (r=0.798,p=0.745),  time:18.911, tt:2477.354\n",
      "Ep:131, loss:0.00001, loss_test:0.10436, lr:6.89e-03, fs:0.76923 (r=0.707,p=0.843),  time:18.914, tt:2496.681\n",
      "Ep:132, loss:0.00001, loss_test:0.09115, lr:6.89e-03, fs:0.78218 (r=0.798,p=0.767),  time:18.925, tt:2516.967\n",
      "Ep:133, loss:0.00001, loss_test:0.10991, lr:6.89e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.932, tt:2536.946\n",
      "Ep:134, loss:0.00001, loss_test:0.10923, lr:6.89e-03, fs:0.77477 (r=0.869,p=0.699),  time:18.940, tt:2556.921\n",
      "Ep:135, loss:0.00001, loss_test:0.10473, lr:6.89e-03, fs:0.76289 (r=0.747,p=0.779),  time:18.946, tt:2576.668\n",
      "Ep:136, loss:0.00001, loss_test:0.09285, lr:6.89e-03, fs:0.80203 (r=0.798,p=0.806),  time:18.947, tt:2595.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.08688, lr:6.89e-03, fs:0.78974 (r=0.778,p=0.802),  time:18.945, tt:2614.374\n",
      "Ep:138, loss:0.00001, loss_test:0.10695, lr:6.89e-03, fs:0.75676 (r=0.707,p=0.814),  time:18.945, tt:2633.311\n",
      "Ep:139, loss:0.00001, loss_test:0.10518, lr:6.83e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.946, tt:2652.399\n",
      "Ep:140, loss:0.00001, loss_test:0.10139, lr:6.76e-03, fs:0.79808 (r=0.838,p=0.761),  time:18.948, tt:2671.735\n",
      "Ep:141, loss:0.00001, loss_test:0.09477, lr:6.69e-03, fs:0.77083 (r=0.747,p=0.796),  time:18.941, tt:2689.664\n",
      "Ep:142, loss:0.00001, loss_test:0.08819, lr:6.62e-03, fs:0.79793 (r=0.778,p=0.819),  time:18.953, tt:2710.349\n",
      "Ep:143, loss:0.00001, loss_test:0.09204, lr:6.56e-03, fs:0.75789 (r=0.727,p=0.791),  time:18.955, tt:2729.465\n",
      "Ep:144, loss:0.00001, loss_test:0.10397, lr:6.49e-03, fs:0.72928 (r=0.667,p=0.805),  time:18.948, tt:2747.485\n",
      "Ep:145, loss:0.00001, loss_test:0.10648, lr:6.43e-03, fs:0.76190 (r=0.727,p=0.800),  time:18.945, tt:2765.968\n",
      "Ep:146, loss:0.00001, loss_test:0.10481, lr:6.36e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.942, tt:2784.496\n",
      "Ep:147, loss:0.00001, loss_test:0.09749, lr:6.30e-03, fs:0.78125 (r=0.758,p=0.806),  time:18.943, tt:2803.578\n",
      "Ep:148, loss:0.00001, loss_test:0.09317, lr:6.24e-03, fs:0.80214 (r=0.758,p=0.852),  time:18.938, tt:2821.778\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00001, loss_test:0.09451, lr:6.24e-03, fs:0.78723 (r=0.747,p=0.831),  time:18.942, tt:2841.240\n",
      "Ep:150, loss:0.00001, loss_test:0.09578, lr:6.24e-03, fs:0.74725 (r=0.687,p=0.819),  time:18.944, tt:2860.557\n",
      "Ep:151, loss:0.00001, loss_test:0.09747, lr:6.24e-03, fs:0.73626 (r=0.677,p=0.807),  time:18.947, tt:2879.888\n",
      "Ep:152, loss:0.00001, loss_test:0.09663, lr:6.24e-03, fs:0.77895 (r=0.747,p=0.813),  time:18.950, tt:2899.424\n",
      "Ep:153, loss:0.00001, loss_test:0.09307, lr:6.24e-03, fs:0.78534 (r=0.758,p=0.815),  time:18.951, tt:2918.510\n",
      "Ep:154, loss:0.00001, loss_test:0.09038, lr:6.24e-03, fs:0.82292 (r=0.798,p=0.849),  time:18.950, tt:2937.310\n",
      "##########Best model found so far##########\n",
      "Ep:155, loss:0.00001, loss_test:0.09294, lr:6.24e-03, fs:0.79348 (r=0.737,p=0.859),  time:18.953, tt:2956.737\n",
      "Ep:156, loss:0.00001, loss_test:0.09688, lr:6.24e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.954, tt:2975.703\n",
      "Ep:157, loss:0.00001, loss_test:0.09724, lr:6.24e-03, fs:0.74444 (r=0.677,p=0.827),  time:18.965, tt:2996.504\n",
      "Ep:158, loss:0.00001, loss_test:0.09541, lr:6.24e-03, fs:0.77596 (r=0.717,p=0.845),  time:18.967, tt:3015.777\n",
      "Ep:159, loss:0.00001, loss_test:0.09294, lr:6.24e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.969, tt:3035.086\n",
      "Ep:160, loss:0.00001, loss_test:0.09236, lr:6.24e-03, fs:0.77348 (r=0.707,p=0.854),  time:18.966, tt:3053.600\n",
      "Ep:161, loss:0.00001, loss_test:0.09587, lr:6.24e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.966, tt:3072.534\n",
      "Ep:162, loss:0.00001, loss_test:0.09708, lr:6.24e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.964, tt:3091.089\n",
      "Ep:163, loss:0.00001, loss_test:0.09546, lr:6.24e-03, fs:0.76836 (r=0.687,p=0.872),  time:18.966, tt:3110.403\n",
      "Ep:164, loss:0.00001, loss_test:0.09503, lr:6.24e-03, fs:0.80000 (r=0.747,p=0.860),  time:18.968, tt:3129.798\n",
      "Ep:165, loss:0.00001, loss_test:0.09562, lr:6.24e-03, fs:0.79570 (r=0.747,p=0.851),  time:18.969, tt:3148.821\n",
      "Ep:166, loss:0.00001, loss_test:0.09605, lr:6.17e-03, fs:0.76667 (r=0.697,p=0.852),  time:18.976, tt:3169.030\n",
      "Ep:167, loss:0.00000, loss_test:0.09636, lr:6.11e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.984, tt:3189.278\n",
      "Ep:168, loss:0.00000, loss_test:0.09361, lr:6.05e-03, fs:0.77273 (r=0.687,p=0.883),  time:18.980, tt:3207.679\n",
      "Ep:169, loss:0.00000, loss_test:0.09311, lr:5.99e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.983, tt:3227.029\n",
      "Ep:170, loss:0.00000, loss_test:0.09495, lr:5.93e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.977, tt:3244.987\n",
      "Ep:171, loss:0.00000, loss_test:0.09319, lr:5.87e-03, fs:0.77273 (r=0.687,p=0.883),  time:18.974, tt:3263.467\n",
      "Ep:172, loss:0.00000, loss_test:0.09398, lr:5.81e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.971, tt:3282.009\n",
      "Ep:173, loss:0.00000, loss_test:0.09476, lr:5.75e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.964, tt:3299.691\n",
      "Ep:174, loss:0.00000, loss_test:0.09337, lr:5.70e-03, fs:0.77966 (r=0.697,p=0.885),  time:18.961, tt:3318.158\n",
      "Ep:175, loss:0.00000, loss_test:0.09409, lr:5.64e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.953, tt:3335.734\n",
      "Ep:176, loss:0.00000, loss_test:0.09491, lr:5.58e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.948, tt:3353.885\n",
      "Ep:177, loss:0.00000, loss_test:0.09683, lr:5.53e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.943, tt:3371.781\n",
      "Ep:178, loss:0.00000, loss_test:0.09583, lr:5.47e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.940, tt:3390.302\n",
      "Ep:179, loss:0.00000, loss_test:0.09262, lr:5.42e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.938, tt:3408.822\n",
      "Ep:180, loss:0.00000, loss_test:0.09306, lr:5.36e-03, fs:0.79558 (r=0.727,p=0.878),  time:18.925, tt:3425.343\n",
      "Ep:181, loss:0.00000, loss_test:0.09469, lr:5.31e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.919, tt:3443.274\n",
      "Ep:182, loss:0.00000, loss_test:0.09374, lr:5.26e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.912, tt:3460.912\n",
      "Ep:183, loss:0.00000, loss_test:0.09228, lr:5.20e-03, fs:0.78889 (r=0.717,p=0.877),  time:18.906, tt:3478.676\n",
      "Ep:184, loss:0.00000, loss_test:0.09272, lr:5.15e-03, fs:0.77528 (r=0.697,p=0.873),  time:18.902, tt:3496.924\n",
      "Ep:185, loss:0.00000, loss_test:0.09389, lr:5.10e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.899, tt:3515.130\n",
      "Ep:186, loss:0.00000, loss_test:0.09363, lr:5.05e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.892, tt:3532.747\n",
      "Ep:187, loss:0.00000, loss_test:0.09171, lr:5.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.886, tt:3550.659\n",
      "Ep:188, loss:0.00000, loss_test:0.09301, lr:4.95e-03, fs:0.76836 (r=0.687,p=0.872),  time:18.876, tt:3567.542\n",
      "Ep:189, loss:0.00000, loss_test:0.09401, lr:4.90e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.870, tt:3585.375\n",
      "Ep:190, loss:0.00000, loss_test:0.09214, lr:4.85e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.873, tt:3604.809\n",
      "Ep:191, loss:0.00000, loss_test:0.09138, lr:4.80e-03, fs:0.80874 (r=0.747,p=0.881),  time:18.868, tt:3622.704\n",
      "Ep:192, loss:0.00000, loss_test:0.09284, lr:4.75e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.872, tt:3642.358\n",
      "Ep:193, loss:0.00000, loss_test:0.09340, lr:4.71e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.871, tt:3660.935\n",
      "Ep:194, loss:0.00000, loss_test:0.09267, lr:4.66e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.894, tt:3684.393\n",
      "Ep:195, loss:0.00000, loss_test:0.09263, lr:4.61e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.899, tt:3704.182\n",
      "Ep:196, loss:0.00000, loss_test:0.09364, lr:4.57e-03, fs:0.76404 (r=0.687,p=0.861),  time:18.893, tt:3721.859\n",
      "Ep:197, loss:0.00000, loss_test:0.09342, lr:4.52e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.891, tt:3740.484\n",
      "Ep:198, loss:0.00000, loss_test:0.09269, lr:4.48e-03, fs:0.78889 (r=0.717,p=0.877),  time:18.899, tt:3760.904\n",
      "Ep:199, loss:0.00000, loss_test:0.09229, lr:4.43e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.890, tt:3777.945\n",
      "Ep:200, loss:0.00000, loss_test:0.09394, lr:4.39e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.885, tt:3795.854\n",
      "Ep:201, loss:0.00000, loss_test:0.09360, lr:4.34e-03, fs:0.80435 (r=0.747,p=0.871),  time:18.885, tt:3814.751\n",
      "Ep:202, loss:0.00000, loss_test:0.09170, lr:4.30e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.880, tt:3832.642\n",
      "Ep:203, loss:0.00000, loss_test:0.09323, lr:4.26e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.874, tt:3850.340\n",
      "Ep:204, loss:0.00000, loss_test:0.09448, lr:4.21e-03, fs:0.77273 (r=0.687,p=0.883),  time:18.878, tt:3869.936\n",
      "Ep:205, loss:0.00000, loss_test:0.09297, lr:4.17e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.876, tt:3888.488\n",
      "Ep:206, loss:0.00000, loss_test:0.09274, lr:4.13e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.876, tt:3907.376\n",
      "Ep:207, loss:0.00000, loss_test:0.09452, lr:4.09e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.877, tt:3926.329\n",
      "Ep:208, loss:0.00000, loss_test:0.09468, lr:4.05e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.878, tt:3945.501\n",
      "Ep:209, loss:0.00000, loss_test:0.09257, lr:4.01e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.878, tt:3964.430\n",
      "Ep:210, loss:0.00000, loss_test:0.09219, lr:3.97e-03, fs:0.78212 (r=0.707,p=0.875),  time:18.882, tt:3984.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:211, loss:0.00000, loss_test:0.09368, lr:3.93e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.888, tt:4004.178\n",
      "Ep:212, loss:0.00000, loss_test:0.09460, lr:3.89e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.891, tt:4023.782\n",
      "Ep:213, loss:0.00000, loss_test:0.09364, lr:3.85e-03, fs:0.77273 (r=0.687,p=0.883),  time:18.895, tt:4043.588\n",
      "Ep:214, loss:0.00000, loss_test:0.09229, lr:3.81e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.899, tt:4063.349\n",
      "Ep:215, loss:0.00000, loss_test:0.09377, lr:3.77e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.894, tt:4081.092\n",
      "Ep:216, loss:0.00000, loss_test:0.09505, lr:3.73e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.897, tt:4100.739\n",
      "Ep:217, loss:0.00000, loss_test:0.09385, lr:3.70e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.896, tt:4119.368\n",
      "Ep:218, loss:0.00000, loss_test:0.09282, lr:3.66e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.899, tt:4138.773\n",
      "Ep:219, loss:0.00000, loss_test:0.09365, lr:3.62e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.898, tt:4157.526\n",
      "Ep:220, loss:0.00000, loss_test:0.09416, lr:3.59e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.898, tt:4176.371\n",
      "Ep:221, loss:0.00000, loss_test:0.09414, lr:3.55e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.898, tt:4195.329\n",
      "Ep:222, loss:0.00000, loss_test:0.09379, lr:3.52e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.899, tt:4214.456\n",
      "Ep:223, loss:0.00000, loss_test:0.09387, lr:3.48e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.898, tt:4233.240\n",
      "Ep:224, loss:0.00000, loss_test:0.09436, lr:3.45e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.898, tt:4252.110\n",
      "Ep:225, loss:0.00000, loss_test:0.09454, lr:3.41e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.899, tt:4271.216\n",
      "Ep:226, loss:0.00000, loss_test:0.09401, lr:3.38e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.899, tt:4290.100\n",
      "Ep:227, loss:0.00000, loss_test:0.09368, lr:3.34e-03, fs:0.76136 (r=0.677,p=0.870),  time:18.904, tt:4310.084\n",
      "Ep:228, loss:0.00000, loss_test:0.09418, lr:3.31e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.902, tt:4328.537\n",
      "Ep:229, loss:0.00000, loss_test:0.09439, lr:3.28e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.903, tt:4347.698\n",
      "Ep:230, loss:0.00000, loss_test:0.09398, lr:3.24e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.907, tt:4367.488\n",
      "Ep:231, loss:0.00000, loss_test:0.09387, lr:3.21e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.910, tt:4387.108\n",
      "Ep:232, loss:0.00000, loss_test:0.09424, lr:3.18e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.910, tt:4406.142\n",
      "Ep:233, loss:0.00000, loss_test:0.09408, lr:3.15e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.915, tt:4426.145\n",
      "Ep:234, loss:0.00000, loss_test:0.09414, lr:3.12e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.921, tt:4446.340\n",
      "Ep:235, loss:0.00000, loss_test:0.09437, lr:3.09e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.922, tt:4465.623\n",
      "Ep:236, loss:0.00000, loss_test:0.09433, lr:3.05e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.926, tt:4485.390\n",
      "Ep:237, loss:0.00000, loss_test:0.09453, lr:3.02e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.927, tt:4504.626\n",
      "Ep:238, loss:0.00000, loss_test:0.09443, lr:2.99e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.930, tt:4524.372\n",
      "Ep:239, loss:0.00000, loss_test:0.09433, lr:2.96e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.933, tt:4543.840\n",
      "Ep:240, loss:0.00000, loss_test:0.09457, lr:2.93e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.934, tt:4562.996\n",
      "Ep:241, loss:0.00000, loss_test:0.09465, lr:2.90e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.933, tt:4581.770\n",
      "Ep:242, loss:0.00000, loss_test:0.09455, lr:2.88e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.930, tt:4599.948\n",
      "Ep:243, loss:0.00000, loss_test:0.09488, lr:2.85e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.923, tt:4617.172\n",
      "Ep:244, loss:0.00000, loss_test:0.09506, lr:2.82e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.918, tt:4634.817\n",
      "Ep:245, loss:0.00000, loss_test:0.09479, lr:2.79e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.915, tt:4653.065\n",
      "Ep:246, loss:0.00000, loss_test:0.09485, lr:2.76e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.912, tt:4671.257\n",
      "Ep:247, loss:0.00000, loss_test:0.09511, lr:2.73e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.911, tt:4689.837\n",
      "Ep:248, loss:0.00000, loss_test:0.09499, lr:2.71e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.909, tt:4708.408\n",
      "Ep:249, loss:0.00000, loss_test:0.09483, lr:2.68e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.907, tt:4726.705\n",
      "Ep:250, loss:0.00000, loss_test:0.09499, lr:2.65e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.907, tt:4745.722\n",
      "Ep:251, loss:0.00000, loss_test:0.09504, lr:2.63e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:4765.263\n",
      "Ep:252, loss:0.00000, loss_test:0.09505, lr:2.60e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.907, tt:4783.474\n",
      "Ep:253, loss:0.00000, loss_test:0.09512, lr:2.57e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.907, tt:4802.306\n",
      "Ep:254, loss:0.00000, loss_test:0.09511, lr:2.55e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.905, tt:4820.700\n",
      "Ep:255, loss:0.00000, loss_test:0.09517, lr:2.52e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.901, tt:4838.566\n",
      "Ep:256, loss:0.00000, loss_test:0.09504, lr:2.50e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.900, tt:4857.378\n",
      "Ep:257, loss:0.00000, loss_test:0.09528, lr:2.47e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.899, tt:4876.054\n",
      "Ep:258, loss:0.00000, loss_test:0.09523, lr:2.45e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.900, tt:4895.034\n",
      "Ep:259, loss:0.00000, loss_test:0.09531, lr:2.42e-03, fs:0.76571 (r=0.677,p=0.882),  time:18.901, tt:4914.237\n",
      "Ep:260, loss:0.00000, loss_test:0.09534, lr:2.40e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.902, tt:4933.421\n",
      "Ep:261, loss:0.00000, loss_test:0.09528, lr:2.38e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.909, tt:4954.174\n",
      "Ep:262, loss:0.00000, loss_test:0.09547, lr:2.35e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.911, tt:4973.545\n",
      "Ep:263, loss:0.00000, loss_test:0.09537, lr:2.33e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:4992.237\n",
      "Ep:264, loss:0.00000, loss_test:0.09534, lr:2.31e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.909, tt:5010.779\n",
      "Ep:265, loss:0.00000, loss_test:0.09534, lr:2.28e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.909, tt:5029.924\n",
      "Ep:266, loss:0.00000, loss_test:0.09537, lr:2.26e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:5049.041\n",
      "Ep:267, loss:0.00000, loss_test:0.09573, lr:2.24e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:5067.920\n",
      "Ep:268, loss:0.00000, loss_test:0.09579, lr:2.21e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:5086.757\n",
      "Ep:269, loss:0.00000, loss_test:0.09555, lr:2.19e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.905, tt:5104.435\n",
      "Ep:270, loss:0.00000, loss_test:0.09565, lr:2.17e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.909, tt:5124.405\n",
      "Ep:271, loss:0.00000, loss_test:0.09583, lr:2.15e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.911, tt:5143.869\n",
      "Ep:272, loss:0.00000, loss_test:0.09582, lr:2.13e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.910, tt:5162.449\n",
      "Ep:273, loss:0.00000, loss_test:0.09576, lr:2.11e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.913, tt:5182.053\n",
      "Ep:274, loss:0.00000, loss_test:0.09593, lr:2.08e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.915, tt:5201.716\n",
      "Ep:275, loss:0.00000, loss_test:0.09586, lr:2.06e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.916, tt:5220.681\n",
      "Ep:276, loss:0.00000, loss_test:0.09578, lr:2.04e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.916, tt:5239.841\n",
      "Ep:277, loss:0.00000, loss_test:0.09603, lr:2.02e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.915, tt:5258.305\n",
      "Ep:278, loss:0.00000, loss_test:0.09600, lr:2.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.913, tt:5276.625\n",
      "Ep:279, loss:0.00000, loss_test:0.09589, lr:1.98e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.916, tt:5296.493\n",
      "Ep:280, loss:0.00000, loss_test:0.09599, lr:1.96e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.915, tt:5315.127\n",
      "Ep:281, loss:0.00000, loss_test:0.09616, lr:1.94e-03, fs:0.77011 (r=0.677,p=0.893),  time:18.914, tt:5333.715\n",
      "Ep:282, loss:0.00000, loss_test:0.09625, lr:1.92e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.913, tt:5352.268\n",
      "Ep:283, loss:0.00000, loss_test:0.09623, lr:1.90e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.918, tt:5372.771\n",
      "Ep:284, loss:0.00000, loss_test:0.09618, lr:1.89e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.917, tt:5391.450\n",
      "Ep:285, loss:0.00000, loss_test:0.09632, lr:1.87e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.917, tt:5410.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:286, loss:0.00000, loss_test:0.09623, lr:1.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.918, tt:5429.412\n",
      "Ep:287, loss:0.00000, loss_test:0.09643, lr:1.83e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.917, tt:5448.046\n",
      "Ep:288, loss:0.00000, loss_test:0.09662, lr:1.81e-03, fs:0.77457 (r=0.677,p=0.905),  time:18.920, tt:5467.768\n",
      "Ep:289, loss:0.00000, loss_test:0.09651, lr:1.79e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.921, tt:5487.154\n",
      "Ep:290, loss:0.00000, loss_test:0.09648, lr:1.78e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.920, tt:5505.802\n",
      "Ep:291, loss:0.00000, loss_test:0.09669, lr:1.76e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.922, tt:5525.139\n",
      "Ep:292, loss:0.00000, loss_test:0.09680, lr:1.74e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.923, tt:5544.340\n",
      "Ep:293, loss:0.00000, loss_test:0.09678, lr:1.72e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.919, tt:5562.071\n",
      "Ep:294, loss:0.00000, loss_test:0.09669, lr:1.71e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.900, tt:5575.444\n",
      "Ep:295, loss:0.00000, loss_test:0.09673, lr:1.69e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.874, tt:5586.773\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14100, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.557, tt:14.557\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14042, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.266, tt:30.531\n",
      "Ep:2, loss:0.00004, loss_test:0.13954, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.636, tt:46.908\n",
      "Ep:3, loss:0.00004, loss_test:0.13827, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:15.745, tt:62.981\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.13657, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:15.866, tt:79.328\n",
      "Ep:5, loss:0.00004, loss_test:0.13440, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:15.766, tt:94.594\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13170, lr:1.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:15.875, tt:111.124\n",
      "Ep:7, loss:0.00004, loss_test:0.12878, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:15.957, tt:127.655\n",
      "Ep:8, loss:0.00004, loss_test:0.12564, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:15.917, tt:143.254\n",
      "Ep:9, loss:0.00003, loss_test:0.12270, lr:1.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:15.914, tt:159.141\n",
      "Ep:10, loss:0.00003, loss_test:0.12013, lr:1.00e-02, fs:0.63677 (r=0.717,p=0.573),  time:15.821, tt:174.027\n",
      "Ep:11, loss:0.00003, loss_test:0.11850, lr:1.00e-02, fs:0.62439 (r=0.646,p=0.604),  time:16.094, tt:193.132\n",
      "Ep:12, loss:0.00003, loss_test:0.11770, lr:1.00e-02, fs:0.62887 (r=0.616,p=0.642),  time:16.120, tt:209.555\n",
      "Ep:13, loss:0.00003, loss_test:0.11694, lr:1.00e-02, fs:0.61538 (r=0.606,p=0.625),  time:16.146, tt:226.049\n",
      "Ep:14, loss:0.00003, loss_test:0.11630, lr:1.00e-02, fs:0.64356 (r=0.657,p=0.631),  time:16.153, tt:242.300\n",
      "Ep:15, loss:0.00003, loss_test:0.11580, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:16.114, tt:257.823\n",
      "Ep:16, loss:0.00003, loss_test:0.11594, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:16.122, tt:274.071\n",
      "Ep:17, loss:0.00003, loss_test:0.11581, lr:9.90e-03, fs:0.66071 (r=0.747,p=0.592),  time:16.129, tt:290.322\n",
      "Ep:18, loss:0.00003, loss_test:0.11509, lr:9.80e-03, fs:0.65471 (r=0.737,p=0.589),  time:16.165, tt:307.136\n",
      "Ep:19, loss:0.00003, loss_test:0.11375, lr:9.70e-03, fs:0.67281 (r=0.737,p=0.619),  time:16.153, tt:323.055\n",
      "Ep:20, loss:0.00003, loss_test:0.11228, lr:9.61e-03, fs:0.67290 (r=0.727,p=0.626),  time:16.175, tt:339.671\n",
      "Ep:21, loss:0.00003, loss_test:0.11137, lr:9.51e-03, fs:0.66986 (r=0.707,p=0.636),  time:16.136, tt:354.991\n",
      "Ep:22, loss:0.00003, loss_test:0.11090, lr:9.41e-03, fs:0.68627 (r=0.707,p=0.667),  time:16.133, tt:371.068\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.11043, lr:9.41e-03, fs:0.69608 (r=0.717,p=0.676),  time:16.095, tt:386.273\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.11017, lr:9.41e-03, fs:0.69268 (r=0.717,p=0.670),  time:16.057, tt:401.434\n",
      "Ep:25, loss:0.00003, loss_test:0.11025, lr:9.41e-03, fs:0.69231 (r=0.727,p=0.661),  time:16.033, tt:416.866\n",
      "Ep:26, loss:0.00003, loss_test:0.11037, lr:9.41e-03, fs:0.68900 (r=0.727,p=0.655),  time:16.051, tt:433.381\n",
      "Ep:27, loss:0.00003, loss_test:0.11029, lr:9.41e-03, fs:0.68571 (r=0.727,p=0.649),  time:16.070, tt:449.960\n",
      "Ep:28, loss:0.00003, loss_test:0.10996, lr:9.41e-03, fs:0.68900 (r=0.727,p=0.655),  time:16.072, tt:466.087\n",
      "Ep:29, loss:0.00003, loss_test:0.10946, lr:9.41e-03, fs:0.69565 (r=0.727,p=0.667),  time:16.086, tt:482.583\n",
      "Ep:30, loss:0.00003, loss_test:0.10907, lr:9.41e-03, fs:0.70647 (r=0.717,p=0.696),  time:16.088, tt:498.718\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.10871, lr:9.41e-03, fs:0.71642 (r=0.727,p=0.706),  time:16.090, tt:514.891\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.10835, lr:9.41e-03, fs:0.72000 (r=0.727,p=0.713),  time:16.077, tt:530.530\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10802, lr:9.41e-03, fs:0.72637 (r=0.737,p=0.716),  time:16.089, tt:547.035\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.10769, lr:9.41e-03, fs:0.72277 (r=0.737,p=0.709),  time:16.075, tt:562.628\n",
      "Ep:35, loss:0.00002, loss_test:0.10735, lr:9.41e-03, fs:0.73529 (r=0.758,p=0.714),  time:16.069, tt:578.480\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10702, lr:9.41e-03, fs:0.73892 (r=0.758,p=0.721),  time:16.082, tt:595.025\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.10661, lr:9.41e-03, fs:0.73892 (r=0.758,p=0.721),  time:16.067, tt:610.546\n",
      "Ep:38, loss:0.00002, loss_test:0.10617, lr:9.41e-03, fs:0.74257 (r=0.758,p=0.728),  time:16.022, tt:624.841\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10583, lr:9.41e-03, fs:0.73632 (r=0.747,p=0.725),  time:16.020, tt:640.780\n",
      "Ep:40, loss:0.00002, loss_test:0.10552, lr:9.41e-03, fs:0.73632 (r=0.747,p=0.725),  time:16.017, tt:656.688\n",
      "Ep:41, loss:0.00002, loss_test:0.10519, lr:9.41e-03, fs:0.74627 (r=0.758,p=0.735),  time:16.024, tt:673.011\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10479, lr:9.41e-03, fs:0.76238 (r=0.778,p=0.748),  time:16.079, tt:691.407\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.10423, lr:9.41e-03, fs:0.76617 (r=0.778,p=0.755),  time:16.086, tt:707.787\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.10372, lr:9.41e-03, fs:0.77000 (r=0.778,p=0.762),  time:16.077, tt:723.487\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.10333, lr:9.41e-03, fs:0.76382 (r=0.768,p=0.760),  time:16.056, tt:738.582\n",
      "Ep:46, loss:0.00002, loss_test:0.10308, lr:9.41e-03, fs:0.75758 (r=0.758,p=0.758),  time:16.047, tt:754.226\n",
      "Ep:47, loss:0.00002, loss_test:0.10291, lr:9.41e-03, fs:0.76531 (r=0.758,p=0.773),  time:16.044, tt:770.089\n",
      "Ep:48, loss:0.00002, loss_test:0.10264, lr:9.41e-03, fs:0.77157 (r=0.768,p=0.776),  time:16.029, tt:785.404\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.10215, lr:9.41e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.003, tt:800.144\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.10147, lr:9.41e-03, fs:0.78788 (r=0.788,p=0.788),  time:16.007, tt:816.370\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.10078, lr:9.41e-03, fs:0.78392 (r=0.788,p=0.780),  time:15.967, tt:830.300\n",
      "Ep:52, loss:0.00002, loss_test:0.10034, lr:9.41e-03, fs:0.79000 (r=0.798,p=0.782),  time:15.970, tt:846.427\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.10014, lr:9.41e-03, fs:0.79397 (r=0.798,p=0.790),  time:15.938, tt:860.677\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00002, loss_test:0.09995, lr:9.41e-03, fs:0.79397 (r=0.798,p=0.790),  time:15.933, tt:876.327\n",
      "Ep:55, loss:0.00002, loss_test:0.09966, lr:9.41e-03, fs:0.79397 (r=0.798,p=0.790),  time:15.939, tt:892.611\n",
      "Ep:56, loss:0.00002, loss_test:0.09918, lr:9.41e-03, fs:0.79000 (r=0.798,p=0.782),  time:15.930, tt:908.024\n",
      "Ep:57, loss:0.00002, loss_test:0.09874, lr:9.41e-03, fs:0.78788 (r=0.788,p=0.788),  time:15.939, tt:924.440\n",
      "Ep:58, loss:0.00002, loss_test:0.09848, lr:9.41e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.927, tt:939.707\n",
      "Ep:59, loss:0.00002, loss_test:0.09838, lr:9.41e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.924, tt:955.418\n",
      "Ep:60, loss:0.00002, loss_test:0.09826, lr:9.41e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.914, tt:970.742\n",
      "Ep:61, loss:0.00002, loss_test:0.09798, lr:9.41e-03, fs:0.77387 (r=0.778,p=0.770),  time:15.908, tt:986.277\n",
      "Ep:62, loss:0.00002, loss_test:0.09753, lr:9.41e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.904, tt:1001.976\n",
      "Ep:63, loss:0.00002, loss_test:0.09705, lr:9.41e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.889, tt:1016.903\n",
      "Ep:64, loss:0.00002, loss_test:0.09662, lr:9.41e-03, fs:0.77000 (r=0.778,p=0.762),  time:15.890, tt:1032.840\n",
      "Ep:65, loss:0.00002, loss_test:0.09629, lr:9.32e-03, fs:0.77778 (r=0.778,p=0.778),  time:15.889, tt:1048.675\n",
      "Ep:66, loss:0.00002, loss_test:0.09590, lr:9.23e-03, fs:0.79000 (r=0.798,p=0.782),  time:15.894, tt:1064.906\n",
      "Ep:67, loss:0.00002, loss_test:0.09545, lr:9.14e-03, fs:0.79000 (r=0.798,p=0.782),  time:15.886, tt:1080.238\n",
      "Ep:68, loss:0.00002, loss_test:0.09499, lr:9.04e-03, fs:0.79000 (r=0.798,p=0.782),  time:15.896, tt:1096.793\n",
      "Ep:69, loss:0.00002, loss_test:0.09458, lr:8.95e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.886, tt:1112.053\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.09431, lr:8.95e-03, fs:0.79602 (r=0.808,p=0.784),  time:15.909, tt:1129.562\n",
      "Ep:71, loss:0.00002, loss_test:0.09408, lr:8.95e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.909, tt:1145.425\n",
      "Ep:72, loss:0.00002, loss_test:0.09375, lr:8.95e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.922, tt:1162.280\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.09349, lr:8.95e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.923, tt:1178.328\n",
      "Ep:74, loss:0.00002, loss_test:0.09336, lr:8.95e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.913, tt:1193.497\n",
      "Ep:75, loss:0.00002, loss_test:0.09322, lr:8.95e-03, fs:0.80000 (r=0.808,p=0.792),  time:15.909, tt:1209.065\n",
      "Ep:76, loss:0.00002, loss_test:0.09298, lr:8.95e-03, fs:0.80402 (r=0.808,p=0.800),  time:15.904, tt:1224.634\n",
      "Ep:77, loss:0.00002, loss_test:0.09272, lr:8.95e-03, fs:0.79188 (r=0.788,p=0.796),  time:15.910, tt:1241.016\n",
      "Ep:78, loss:0.00001, loss_test:0.09248, lr:8.95e-03, fs:0.79188 (r=0.788,p=0.796),  time:15.908, tt:1256.733\n",
      "Ep:79, loss:0.00001, loss_test:0.09229, lr:8.95e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.911, tt:1272.844\n",
      "Ep:80, loss:0.00001, loss_test:0.09210, lr:8.95e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.901, tt:1288.015\n",
      "Ep:81, loss:0.00001, loss_test:0.09189, lr:8.95e-03, fs:0.79188 (r=0.788,p=0.796),  time:15.896, tt:1303.491\n",
      "Ep:82, loss:0.00001, loss_test:0.09179, lr:8.95e-03, fs:0.79188 (r=0.788,p=0.796),  time:15.904, tt:1320.042\n",
      "Ep:83, loss:0.00001, loss_test:0.09156, lr:8.95e-03, fs:0.79592 (r=0.788,p=0.804),  time:15.904, tt:1335.937\n",
      "Ep:84, loss:0.00001, loss_test:0.09128, lr:8.86e-03, fs:0.79188 (r=0.788,p=0.796),  time:15.912, tt:1352.515\n",
      "Ep:85, loss:0.00001, loss_test:0.09104, lr:8.78e-03, fs:0.79798 (r=0.798,p=0.798),  time:15.927, tt:1369.745\n",
      "Ep:86, loss:0.00001, loss_test:0.09096, lr:8.69e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.929, tt:1385.820\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.09082, lr:8.69e-03, fs:0.81026 (r=0.798,p=0.823),  time:15.922, tt:1401.131\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.09059, lr:8.69e-03, fs:0.81026 (r=0.798,p=0.823),  time:15.934, tt:1418.110\n",
      "Ep:89, loss:0.00001, loss_test:0.09039, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.934, tt:1434.044\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.09026, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.945, tt:1450.982\n",
      "Ep:91, loss:0.00001, loss_test:0.09020, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.950, tt:1467.425\n",
      "Ep:92, loss:0.00001, loss_test:0.09010, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.947, tt:1483.049\n",
      "Ep:93, loss:0.00001, loss_test:0.08999, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.959, tt:1500.155\n",
      "Ep:94, loss:0.00001, loss_test:0.08987, lr:8.69e-03, fs:0.81026 (r=0.798,p=0.823),  time:15.958, tt:1516.037\n",
      "Ep:95, loss:0.00001, loss_test:0.08971, lr:8.69e-03, fs:0.81026 (r=0.798,p=0.823),  time:15.953, tt:1531.455\n",
      "Ep:96, loss:0.00001, loss_test:0.08947, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.960, tt:1548.081\n",
      "Ep:97, loss:0.00001, loss_test:0.08930, lr:8.69e-03, fs:0.81633 (r=0.808,p=0.825),  time:15.964, tt:1564.494\n",
      "Ep:98, loss:0.00001, loss_test:0.08931, lr:8.69e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.995, tt:1583.469\n",
      "Ep:99, loss:0.00001, loss_test:0.08927, lr:8.69e-03, fs:0.81250 (r=0.788,p=0.839),  time:15.999, tt:1599.940\n",
      "Ep:100, loss:0.00001, loss_test:0.08923, lr:8.69e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.998, tt:1615.832\n",
      "Ep:101, loss:0.00001, loss_test:0.08910, lr:8.60e-03, fs:0.79365 (r=0.758,p=0.833),  time:15.997, tt:1631.708\n",
      "Ep:102, loss:0.00001, loss_test:0.08895, lr:8.51e-03, fs:0.80000 (r=0.768,p=0.835),  time:16.004, tt:1648.407\n",
      "Ep:103, loss:0.00001, loss_test:0.08896, lr:8.43e-03, fs:0.79365 (r=0.758,p=0.833),  time:16.006, tt:1664.590\n",
      "Ep:104, loss:0.00001, loss_test:0.08891, lr:8.35e-03, fs:0.78723 (r=0.747,p=0.831),  time:16.004, tt:1680.389\n",
      "Ep:105, loss:0.00001, loss_test:0.08879, lr:8.26e-03, fs:0.77419 (r=0.727,p=0.828),  time:16.000, tt:1696.009\n",
      "Ep:106, loss:0.00001, loss_test:0.08868, lr:8.18e-03, fs:0.78495 (r=0.737,p=0.839),  time:15.998, tt:1711.796\n",
      "Ep:107, loss:0.00001, loss_test:0.08862, lr:8.10e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.989, tt:1726.765\n",
      "Ep:108, loss:0.00001, loss_test:0.08854, lr:8.02e-03, fs:0.77838 (r=0.727,p=0.837),  time:15.990, tt:1742.920\n",
      "Ep:109, loss:0.00001, loss_test:0.08844, lr:7.94e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.983, tt:1758.183\n",
      "Ep:110, loss:0.00001, loss_test:0.08841, lr:7.86e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.985, tt:1774.361\n",
      "Ep:111, loss:0.00001, loss_test:0.08831, lr:7.78e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.985, tt:1790.342\n",
      "Ep:112, loss:0.00001, loss_test:0.08820, lr:7.70e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.994, tt:1807.289\n",
      "Ep:113, loss:0.00001, loss_test:0.08814, lr:7.62e-03, fs:0.78919 (r=0.737,p=0.849),  time:15.992, tt:1823.140\n",
      "Ep:114, loss:0.00001, loss_test:0.08816, lr:7.55e-03, fs:0.79348 (r=0.737,p=0.859),  time:16.002, tt:1840.196\n",
      "Ep:115, loss:0.00001, loss_test:0.08802, lr:7.47e-03, fs:0.79348 (r=0.737,p=0.859),  time:16.006, tt:1856.687\n",
      "Ep:116, loss:0.00001, loss_test:0.08794, lr:7.40e-03, fs:0.79348 (r=0.737,p=0.859),  time:16.002, tt:1872.206\n",
      "Ep:117, loss:0.00001, loss_test:0.08800, lr:7.32e-03, fs:0.79348 (r=0.737,p=0.859),  time:16.011, tt:1889.273\n",
      "Ep:118, loss:0.00001, loss_test:0.08800, lr:7.25e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.022, tt:1906.657\n",
      "Ep:119, loss:0.00001, loss_test:0.08795, lr:7.18e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.031, tt:1923.756\n",
      "Ep:120, loss:0.00001, loss_test:0.08780, lr:7.11e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.035, tt:1940.235\n",
      "Ep:121, loss:0.00001, loss_test:0.08768, lr:7.03e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.035, tt:1956.219\n",
      "Ep:122, loss:0.00001, loss_test:0.08768, lr:6.96e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.038, tt:1972.644\n",
      "Ep:123, loss:0.00001, loss_test:0.08759, lr:6.89e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.037, tt:1988.615\n",
      "Ep:124, loss:0.00001, loss_test:0.08751, lr:6.83e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.031, tt:2003.918\n",
      "Ep:125, loss:0.00001, loss_test:0.08745, lr:6.76e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.027, tt:2019.465\n",
      "Ep:126, loss:0.00001, loss_test:0.08753, lr:6.69e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.027, tt:2035.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00001, loss_test:0.08744, lr:6.62e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.024, tt:2051.108\n",
      "Ep:128, loss:0.00001, loss_test:0.08732, lr:6.56e-03, fs:0.80435 (r=0.747,p=0.871),  time:16.026, tt:2067.306\n",
      "Ep:129, loss:0.00001, loss_test:0.08740, lr:6.49e-03, fs:0.80435 (r=0.747,p=0.871),  time:16.020, tt:2082.605\n",
      "Ep:130, loss:0.00001, loss_test:0.08739, lr:6.43e-03, fs:0.80435 (r=0.747,p=0.871),  time:16.016, tt:2098.151\n",
      "Ep:131, loss:0.00001, loss_test:0.08743, lr:6.36e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.018, tt:2114.353\n",
      "Ep:132, loss:0.00001, loss_test:0.08744, lr:6.30e-03, fs:0.79781 (r=0.737,p=0.869),  time:16.019, tt:2130.498\n",
      "Ep:133, loss:0.00001, loss_test:0.08728, lr:6.24e-03, fs:0.81081 (r=0.758,p=0.872),  time:16.017, tt:2146.323\n",
      "Ep:134, loss:0.00001, loss_test:0.08716, lr:6.17e-03, fs:0.81081 (r=0.758,p=0.872),  time:16.011, tt:2161.434\n",
      "Ep:135, loss:0.00001, loss_test:0.08719, lr:6.11e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.998, tt:2175.732\n",
      "Ep:136, loss:0.00001, loss_test:0.08711, lr:6.05e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.991, tt:2190.744\n",
      "Ep:137, loss:0.00001, loss_test:0.08693, lr:5.99e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.987, tt:2206.199\n",
      "Ep:138, loss:0.00001, loss_test:0.08691, lr:5.93e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.977, tt:2220.805\n",
      "Ep:139, loss:0.00001, loss_test:0.08691, lr:5.87e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.974, tt:2236.381\n",
      "Ep:140, loss:0.00001, loss_test:0.08682, lr:5.81e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.977, tt:2252.819\n",
      "Ep:141, loss:0.00001, loss_test:0.08678, lr:5.75e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.981, tt:2269.314\n",
      "Ep:142, loss:0.00001, loss_test:0.08681, lr:5.70e-03, fs:0.80645 (r=0.758,p=0.862),  time:15.976, tt:2284.603\n",
      "Ep:143, loss:0.00001, loss_test:0.08674, lr:5.64e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.971, tt:2299.799\n",
      "Ep:144, loss:0.00001, loss_test:0.08675, lr:5.58e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.968, tt:2315.311\n",
      "Ep:145, loss:0.00001, loss_test:0.08677, lr:5.53e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.964, tt:2330.798\n",
      "Ep:146, loss:0.00001, loss_test:0.08672, lr:5.47e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.954, tt:2345.306\n",
      "Ep:147, loss:0.00001, loss_test:0.08669, lr:5.42e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.945, tt:2359.812\n",
      "Ep:148, loss:0.00001, loss_test:0.08675, lr:5.36e-03, fs:0.81081 (r=0.758,p=0.872),  time:15.937, tt:2374.667\n",
      "Ep:149, loss:0.00001, loss_test:0.08680, lr:5.31e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.935, tt:2390.249\n",
      "Ep:150, loss:0.00001, loss_test:0.08683, lr:5.26e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.932, tt:2405.791\n",
      "Ep:151, loss:0.00001, loss_test:0.08681, lr:5.20e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.922, tt:2420.070\n",
      "Ep:152, loss:0.00001, loss_test:0.08677, lr:5.15e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.912, tt:2434.610\n",
      "Ep:153, loss:0.00001, loss_test:0.08673, lr:5.10e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.914, tt:2450.825\n",
      "Ep:154, loss:0.00001, loss_test:0.08672, lr:5.05e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.915, tt:2466.772\n",
      "Ep:155, loss:0.00001, loss_test:0.08677, lr:5.00e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.907, tt:2481.432\n",
      "Ep:156, loss:0.00001, loss_test:0.08679, lr:4.95e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.907, tt:2497.374\n",
      "Ep:157, loss:0.00001, loss_test:0.08677, lr:4.90e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.903, tt:2512.717\n",
      "Ep:158, loss:0.00001, loss_test:0.08676, lr:4.85e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.897, tt:2527.584\n",
      "Ep:159, loss:0.00001, loss_test:0.08678, lr:4.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.890, tt:2542.378\n",
      "Ep:160, loss:0.00001, loss_test:0.08680, lr:4.75e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.888, tt:2557.965\n",
      "Ep:161, loss:0.00001, loss_test:0.08679, lr:4.71e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.889, tt:2573.949\n",
      "Ep:162, loss:0.00001, loss_test:0.08673, lr:4.66e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.885, tt:2589.296\n",
      "Ep:163, loss:0.00001, loss_test:0.08671, lr:4.61e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.884, tt:2605.015\n",
      "Ep:164, loss:0.00001, loss_test:0.08675, lr:4.57e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.880, tt:2620.257\n",
      "Ep:165, loss:0.00001, loss_test:0.08678, lr:4.52e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.876, tt:2635.361\n",
      "Ep:166, loss:0.00001, loss_test:0.08675, lr:4.48e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.873, tt:2650.776\n",
      "Ep:167, loss:0.00001, loss_test:0.08672, lr:4.43e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.870, tt:2666.190\n",
      "Ep:168, loss:0.00001, loss_test:0.08680, lr:4.39e-03, fs:0.80435 (r=0.747,p=0.871),  time:15.870, tt:2681.969\n",
      "Ep:169, loss:0.00001, loss_test:0.08684, lr:4.34e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.866, tt:2697.268\n",
      "Ep:170, loss:0.00001, loss_test:0.08686, lr:4.30e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.861, tt:2712.225\n",
      "Ep:171, loss:0.00001, loss_test:0.08691, lr:4.26e-03, fs:0.79781 (r=0.737,p=0.869),  time:15.861, tt:2728.024\n",
      "Ep:172, loss:0.00001, loss_test:0.08697, lr:4.21e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.854, tt:2742.789\n",
      "Ep:173, loss:0.00001, loss_test:0.08696, lr:4.17e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.851, tt:2758.029\n",
      "Ep:174, loss:0.00001, loss_test:0.08692, lr:4.13e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.851, tt:2773.908\n",
      "Ep:175, loss:0.00001, loss_test:0.08695, lr:4.09e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.847, tt:2789.096\n",
      "Ep:176, loss:0.00001, loss_test:0.08698, lr:4.05e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.849, tt:2805.252\n",
      "Ep:177, loss:0.00001, loss_test:0.08696, lr:4.01e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.844, tt:2820.263\n",
      "Ep:178, loss:0.00001, loss_test:0.08695, lr:3.97e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.845, tt:2836.225\n",
      "Ep:179, loss:0.00001, loss_test:0.08698, lr:3.93e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.848, tt:2852.695\n",
      "Ep:180, loss:0.00001, loss_test:0.08702, lr:3.89e-03, fs:0.80220 (r=0.737,p=0.880),  time:15.847, tt:2868.349\n",
      "Ep:181, loss:0.00001, loss_test:0.08704, lr:3.85e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.847, tt:2884.128\n",
      "Ep:182, loss:0.00001, loss_test:0.08708, lr:3.81e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.843, tt:2899.248\n",
      "Ep:183, loss:0.00001, loss_test:0.08712, lr:3.77e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.836, tt:2913.859\n",
      "Ep:184, loss:0.00001, loss_test:0.08713, lr:3.73e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.834, tt:2929.381\n",
      "Ep:185, loss:0.00001, loss_test:0.08713, lr:3.70e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.833, tt:2944.929\n",
      "Ep:186, loss:0.00001, loss_test:0.08714, lr:3.66e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.833, tt:2960.740\n",
      "Ep:187, loss:0.00001, loss_test:0.08716, lr:3.62e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.829, tt:2975.918\n",
      "Ep:188, loss:0.00001, loss_test:0.08718, lr:3.59e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.826, tt:2991.196\n",
      "Ep:189, loss:0.00001, loss_test:0.08719, lr:3.55e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.825, tt:3006.812\n",
      "Ep:190, loss:0.00001, loss_test:0.08720, lr:3.52e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.820, tt:3021.699\n",
      "Ep:191, loss:0.00001, loss_test:0.08727, lr:3.48e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.816, tt:3036.707\n",
      "Ep:192, loss:0.00001, loss_test:0.08731, lr:3.45e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.814, tt:3052.059\n",
      "Ep:193, loss:0.00001, loss_test:0.08731, lr:3.41e-03, fs:0.79558 (r=0.727,p=0.878),  time:15.814, tt:3067.938\n",
      "Ep:194, loss:0.00001, loss_test:0.08731, lr:3.38e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.813, tt:3083.611\n",
      "Ep:195, loss:0.00001, loss_test:0.08731, lr:3.34e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.831, tt:3102.834\n",
      "Ep:196, loss:0.00001, loss_test:0.08732, lr:3.31e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.832, tt:3118.873\n",
      "Ep:197, loss:0.00001, loss_test:0.08735, lr:3.28e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.827, tt:3133.768\n",
      "Ep:198, loss:0.00001, loss_test:0.08740, lr:3.24e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.817, tt:3147.534\n",
      "Ep:199, loss:0.00001, loss_test:0.08738, lr:3.21e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.817, tt:3163.405\n",
      "Ep:200, loss:0.00001, loss_test:0.08734, lr:3.18e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.813, tt:3178.439\n",
      "Ep:201, loss:0.00001, loss_test:0.08738, lr:3.15e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.815, tt:3194.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00001, loss_test:0.08739, lr:3.12e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.812, tt:3209.795\n",
      "Ep:203, loss:0.00001, loss_test:0.08736, lr:3.09e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.808, tt:3224.827\n",
      "Ep:204, loss:0.00001, loss_test:0.08737, lr:3.05e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.804, tt:3239.846\n",
      "Ep:205, loss:0.00001, loss_test:0.08743, lr:3.02e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.797, tt:3254.244\n",
      "Ep:206, loss:0.00001, loss_test:0.08747, lr:2.99e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.797, tt:3270.046\n",
      "Ep:207, loss:0.00001, loss_test:0.08750, lr:2.96e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.790, tt:3284.408\n",
      "Ep:208, loss:0.00001, loss_test:0.08747, lr:2.93e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.789, tt:3299.972\n",
      "Ep:209, loss:0.00001, loss_test:0.08745, lr:2.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.790, tt:3315.866\n",
      "Ep:210, loss:0.00001, loss_test:0.08747, lr:2.88e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.785, tt:3330.670\n",
      "Ep:211, loss:0.00001, loss_test:0.08750, lr:2.85e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.784, tt:3346.104\n",
      "Ep:212, loss:0.00001, loss_test:0.08749, lr:2.82e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.782, tt:3361.569\n",
      "Ep:213, loss:0.00001, loss_test:0.08745, lr:2.79e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.785, tt:3378.024\n",
      "Ep:214, loss:0.00001, loss_test:0.08748, lr:2.76e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.780, tt:3392.745\n",
      "Ep:215, loss:0.00001, loss_test:0.08750, lr:2.73e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.777, tt:3407.896\n",
      "Ep:216, loss:0.00001, loss_test:0.08748, lr:2.71e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.775, tt:3423.126\n",
      "Ep:217, loss:0.00001, loss_test:0.08745, lr:2.68e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.775, tt:3438.873\n",
      "Ep:218, loss:0.00001, loss_test:0.08748, lr:2.65e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.769, tt:3453.400\n",
      "Ep:219, loss:0.00001, loss_test:0.08750, lr:2.63e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.768, tt:3468.876\n",
      "Ep:220, loss:0.00001, loss_test:0.08746, lr:2.60e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.762, tt:3483.312\n",
      "Ep:221, loss:0.00001, loss_test:0.08748, lr:2.57e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.759, tt:3498.427\n",
      "Ep:222, loss:0.00001, loss_test:0.08752, lr:2.55e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.755, tt:3513.411\n",
      "Ep:223, loss:0.00001, loss_test:0.08751, lr:2.52e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.759, tt:3529.951\n",
      "Ep:224, loss:0.00001, loss_test:0.08752, lr:2.50e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.756, tt:3545.106\n",
      "Ep:225, loss:0.00001, loss_test:0.08754, lr:2.47e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.756, tt:3560.840\n",
      "Ep:226, loss:0.00001, loss_test:0.08755, lr:2.45e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.752, tt:3575.764\n",
      "Ep:227, loss:0.00001, loss_test:0.08749, lr:2.42e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.753, tt:3591.586\n",
      "Ep:228, loss:0.00001, loss_test:0.08747, lr:2.40e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:3606.702\n",
      "Ep:229, loss:0.00001, loss_test:0.08748, lr:2.38e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.747, tt:3621.699\n",
      "Ep:230, loss:0.00001, loss_test:0.08748, lr:2.35e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.742, tt:3636.410\n",
      "Ep:231, loss:0.00001, loss_test:0.08745, lr:2.33e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.737, tt:3650.993\n",
      "Ep:232, loss:0.00001, loss_test:0.08747, lr:2.31e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.737, tt:3666.812\n",
      "Ep:233, loss:0.00001, loss_test:0.08750, lr:2.28e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.739, tt:3682.995\n",
      "Ep:234, loss:0.00001, loss_test:0.08750, lr:2.26e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.742, tt:3699.258\n",
      "Ep:235, loss:0.00001, loss_test:0.08748, lr:2.24e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:3717.010\n",
      "Ep:236, loss:0.00001, loss_test:0.08750, lr:2.21e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.749, tt:3732.504\n",
      "Ep:237, loss:0.00001, loss_test:0.08754, lr:2.19e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.748, tt:3748.134\n",
      "Ep:238, loss:0.00001, loss_test:0.08755, lr:2.17e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.746, tt:3763.320\n",
      "Ep:239, loss:0.00001, loss_test:0.08753, lr:2.15e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:3779.886\n",
      "Ep:240, loss:0.00001, loss_test:0.08753, lr:2.13e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.751, tt:3795.998\n",
      "Ep:241, loss:0.00001, loss_test:0.08757, lr:2.11e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:3811.438\n",
      "Ep:242, loss:0.00001, loss_test:0.08758, lr:2.08e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:3827.213\n",
      "Ep:243, loss:0.00001, loss_test:0.08754, lr:2.06e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.754, tt:3843.965\n",
      "Ep:244, loss:0.00001, loss_test:0.08752, lr:2.04e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.754, tt:3859.836\n",
      "Ep:245, loss:0.00001, loss_test:0.08754, lr:2.02e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.758, tt:3876.587\n",
      "Ep:246, loss:0.00001, loss_test:0.08756, lr:2.00e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.761, tt:3893.091\n",
      "Ep:247, loss:0.00001, loss_test:0.08756, lr:1.98e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.761, tt:3908.606\n",
      "Ep:248, loss:0.00001, loss_test:0.08756, lr:1.96e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.759, tt:3923.984\n",
      "Ep:249, loss:0.00001, loss_test:0.08755, lr:1.94e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.757, tt:3939.340\n",
      "Ep:250, loss:0.00001, loss_test:0.08756, lr:1.92e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.756, tt:3954.771\n",
      "Ep:251, loss:0.00001, loss_test:0.08756, lr:1.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.759, tt:3971.304\n",
      "Ep:252, loss:0.00001, loss_test:0.08759, lr:1.89e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.756, tt:3986.294\n",
      "Ep:253, loss:0.00001, loss_test:0.08762, lr:1.87e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.755, tt:4001.793\n",
      "Ep:254, loss:0.00001, loss_test:0.08762, lr:1.85e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.755, tt:4017.434\n",
      "Ep:255, loss:0.00001, loss_test:0.08760, lr:1.83e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.755, tt:4033.213\n",
      "Ep:256, loss:0.00001, loss_test:0.08761, lr:1.81e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.753, tt:4048.456\n",
      "Ep:257, loss:0.00001, loss_test:0.08762, lr:1.79e-03, fs:0.78889 (r=0.717,p=0.877),  time:15.750, tt:4063.625\n",
      "Ep:258, loss:0.00001, loss_test:0.08763, lr:1.78e-03, fs:0.79330 (r=0.717,p=0.887),  time:15.752, tt:4079.856\n",
      "Ep:259, loss:0.00001, loss_test:0.08765, lr:1.76e-03, fs:0.79330 (r=0.717,p=0.887),  time:15.752, tt:4095.586\n",
      "Ep:260, loss:0.00001, loss_test:0.08768, lr:1.74e-03, fs:0.79775 (r=0.717,p=0.899),  time:15.752, tt:4111.270\n",
      "Ep:261, loss:0.00001, loss_test:0.08771, lr:1.72e-03, fs:0.79775 (r=0.717,p=0.899),  time:15.749, tt:4126.179\n",
      "Ep:262, loss:0.00001, loss_test:0.08772, lr:1.71e-03, fs:0.79330 (r=0.717,p=0.887),  time:15.747, tt:4141.539\n",
      "Ep:263, loss:0.00001, loss_test:0.08773, lr:1.69e-03, fs:0.79330 (r=0.717,p=0.887),  time:15.746, tt:4156.858\n",
      "Ep:264, loss:0.00001, loss_test:0.08775, lr:1.67e-03, fs:0.79330 (r=0.717,p=0.887),  time:15.746, tt:4172.721\n",
      "Ep:265, loss:0.00001, loss_test:0.08777, lr:1.65e-03, fs:0.79096 (r=0.707,p=0.897),  time:15.750, tt:4189.513\n",
      "Ep:266, loss:0.00001, loss_test:0.08778, lr:1.64e-03, fs:0.79096 (r=0.707,p=0.897),  time:15.751, tt:4205.444\n",
      "Ep:267, loss:0.00001, loss_test:0.08782, lr:1.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.753, tt:4221.767\n",
      "Ep:268, loss:0.00001, loss_test:0.08783, lr:1.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.754, tt:4237.862\n",
      "Ep:269, loss:0.00001, loss_test:0.08783, lr:1.59e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.753, tt:4253.321\n",
      "Ep:270, loss:0.00001, loss_test:0.08783, lr:1.57e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.755, tt:4269.605\n",
      "Ep:271, loss:0.00001, loss_test:0.08786, lr:1.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.757, tt:4285.865\n",
      "Ep:272, loss:0.00001, loss_test:0.08788, lr:1.54e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.758, tt:4301.899\n",
      "Ep:273, loss:0.00001, loss_test:0.08788, lr:1.53e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.758, tt:4317.775\n",
      "Ep:274, loss:0.00001, loss_test:0.08789, lr:1.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.758, tt:4333.395\n",
      "Ep:275, loss:0.00001, loss_test:0.08791, lr:1.50e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.759, tt:4349.565\n",
      "Ep:276, loss:0.00001, loss_test:0.08792, lr:1.48e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.766, tt:4367.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:277, loss:0.00001, loss_test:0.08794, lr:1.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.766, tt:4382.848\n",
      "Ep:278, loss:0.00001, loss_test:0.08795, lr:1.45e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.768, tt:4399.395\n",
      "Ep:279, loss:0.00001, loss_test:0.08797, lr:1.44e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.766, tt:4414.578\n",
      "Ep:280, loss:0.00001, loss_test:0.08797, lr:1.42e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.767, tt:4430.470\n",
      "Ep:281, loss:0.00001, loss_test:0.08799, lr:1.41e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.769, tt:4446.937\n",
      "Ep:282, loss:0.00001, loss_test:0.08801, lr:1.39e-03, fs:0.78409 (r=0.697,p=0.896),  time:15.775, tt:4464.309\n",
      "Ep:283, loss:0.00001, loss_test:0.08801, lr:1.38e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.778, tt:4481.073\n",
      "Ep:284, loss:0.00001, loss_test:0.08805, lr:1.37e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.781, tt:4497.452\n",
      "Ep:285, loss:0.00001, loss_test:0.08808, lr:1.35e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.791, tt:4516.368\n",
      "Ep:286, loss:0.00001, loss_test:0.08809, lr:1.34e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.793, tt:4532.575\n",
      "Ep:287, loss:0.00001, loss_test:0.08810, lr:1.33e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.792, tt:4548.106\n",
      "Ep:288, loss:0.00001, loss_test:0.08813, lr:1.31e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.791, tt:4563.611\n",
      "Ep:289, loss:0.00001, loss_test:0.08813, lr:1.30e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.791, tt:4579.383\n",
      "Ep:290, loss:0.00001, loss_test:0.08816, lr:1.29e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.793, tt:4595.642\n",
      "Ep:291, loss:0.00001, loss_test:0.08817, lr:1.27e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.793, tt:4611.465\n",
      "Ep:292, loss:0.00001, loss_test:0.08818, lr:1.26e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.790, tt:4626.504\n",
      "Ep:293, loss:0.00001, loss_test:0.08818, lr:1.25e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.788, tt:4641.579\n",
      "Ep:294, loss:0.00001, loss_test:0.08820, lr:1.24e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.785, tt:4656.657\n",
      "Ep:295, loss:0.00001, loss_test:0.08822, lr:1.22e-03, fs:0.77714 (r=0.687,p=0.895),  time:15.760, tt:4665.028\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14348, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.941, tt:18.941\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14317, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.413, tt:38.826\n",
      "Ep:2, loss:0.00004, loss_test:0.14269, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.746, tt:59.238\n",
      "Ep:3, loss:0.00004, loss_test:0.14201, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.888, tt:79.553\n",
      "Ep:4, loss:0.00004, loss_test:0.14111, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.771, tt:98.854\n",
      "Ep:5, loss:0.00004, loss_test:0.13991, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.890, tt:119.337\n",
      "Ep:6, loss:0.00004, loss_test:0.13832, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.006, tt:140.044\n",
      "Ep:7, loss:0.00004, loss_test:0.13626, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.071, tt:160.571\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.13349, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:20.036, tt:180.327\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.12979, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:19.980, tt:199.795\n",
      "Ep:10, loss:0.00004, loss_test:0.12503, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:19.965, tt:219.616\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.11951, lr:1.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:20.007, tt:240.084\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.11446, lr:1.00e-02, fs:0.67544 (r=0.778,p=0.597),  time:19.859, tt:258.172\n",
      "Ep:13, loss:0.00003, loss_test:0.11317, lr:1.00e-02, fs:0.63366 (r=0.646,p=0.621),  time:19.830, tt:277.623\n",
      "Ep:14, loss:0.00003, loss_test:0.11290, lr:1.00e-02, fs:0.62105 (r=0.596,p=0.648),  time:19.754, tt:296.310\n",
      "Ep:15, loss:0.00003, loss_test:0.11194, lr:1.00e-02, fs:0.62500 (r=0.606,p=0.645),  time:19.744, tt:315.905\n",
      "Ep:16, loss:0.00003, loss_test:0.11041, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:19.699, tt:334.882\n",
      "Ep:17, loss:0.00003, loss_test:0.11008, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:19.676, tt:354.161\n",
      "Ep:18, loss:0.00003, loss_test:0.11009, lr:1.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:19.616, tt:372.708\n",
      "Ep:19, loss:0.00003, loss_test:0.10857, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:19.602, tt:392.039\n",
      "Ep:20, loss:0.00003, loss_test:0.10700, lr:1.00e-02, fs:0.68269 (r=0.717,p=0.651),  time:19.601, tt:411.614\n",
      "Ep:21, loss:0.00003, loss_test:0.10637, lr:1.00e-02, fs:0.66341 (r=0.687,p=0.642),  time:19.545, tt:429.989\n",
      "Ep:22, loss:0.00003, loss_test:0.10587, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:19.555, tt:449.764\n",
      "Ep:23, loss:0.00003, loss_test:0.10510, lr:9.90e-03, fs:0.68367 (r=0.677,p=0.691),  time:19.549, tt:469.186\n",
      "Ep:24, loss:0.00003, loss_test:0.10450, lr:9.80e-03, fs:0.66337 (r=0.677,p=0.650),  time:19.546, tt:488.652\n",
      "Ep:25, loss:0.00003, loss_test:0.10456, lr:9.70e-03, fs:0.68900 (r=0.727,p=0.655),  time:19.502, tt:507.047\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10469, lr:9.70e-03, fs:0.70698 (r=0.768,p=0.655),  time:19.455, tt:525.279\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.10452, lr:9.70e-03, fs:0.68599 (r=0.717,p=0.657),  time:19.437, tt:544.233\n",
      "Ep:28, loss:0.00002, loss_test:0.10416, lr:9.70e-03, fs:0.69951 (r=0.717,p=0.683),  time:19.410, tt:562.884\n",
      "Ep:29, loss:0.00002, loss_test:0.10397, lr:9.70e-03, fs:0.72165 (r=0.707,p=0.737),  time:19.403, tt:582.103\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.10383, lr:9.70e-03, fs:0.73196 (r=0.717,p=0.747),  time:19.441, tt:602.668\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.10377, lr:9.70e-03, fs:0.71717 (r=0.717,p=0.717),  time:19.399, tt:620.761\n",
      "Ep:32, loss:0.00002, loss_test:0.10392, lr:9.70e-03, fs:0.70244 (r=0.727,p=0.679),  time:19.398, tt:640.125\n",
      "Ep:33, loss:0.00002, loss_test:0.10367, lr:9.70e-03, fs:0.71220 (r=0.737,p=0.689),  time:19.408, tt:659.865\n",
      "Ep:34, loss:0.00002, loss_test:0.10321, lr:9.70e-03, fs:0.72449 (r=0.717,p=0.732),  time:19.416, tt:679.550\n",
      "Ep:35, loss:0.00002, loss_test:0.10289, lr:9.70e-03, fs:0.72632 (r=0.697,p=0.758),  time:19.352, tt:696.675\n",
      "Ep:36, loss:0.00002, loss_test:0.10260, lr:9.70e-03, fs:0.72251 (r=0.697,p=0.750),  time:19.355, tt:716.150\n",
      "Ep:37, loss:0.00002, loss_test:0.10240, lr:9.70e-03, fs:0.74112 (r=0.737,p=0.745),  time:19.390, tt:736.836\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.10190, lr:9.70e-03, fs:0.74372 (r=0.747,p=0.740),  time:19.387, tt:756.109\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10107, lr:9.70e-03, fs:0.74227 (r=0.727,p=0.758),  time:19.407, tt:776.269\n",
      "Ep:40, loss:0.00002, loss_test:0.10052, lr:9.70e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.426, tt:796.477\n",
      "Ep:41, loss:0.00002, loss_test:0.10027, lr:9.70e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.411, tt:815.261\n",
      "Ep:42, loss:0.00002, loss_test:0.10007, lr:9.70e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.422, tt:835.165\n",
      "Ep:43, loss:0.00002, loss_test:0.09990, lr:9.70e-03, fs:0.73469 (r=0.727,p=0.742),  time:19.472, tt:856.788\n",
      "Ep:44, loss:0.00002, loss_test:0.09960, lr:9.70e-03, fs:0.73196 (r=0.717,p=0.747),  time:19.493, tt:877.178\n",
      "Ep:45, loss:0.00002, loss_test:0.09940, lr:9.70e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.495, tt:896.778\n",
      "Ep:46, loss:0.00002, loss_test:0.09932, lr:9.70e-03, fs:0.73298 (r=0.707,p=0.761),  time:19.523, tt:917.593\n",
      "Ep:47, loss:0.00002, loss_test:0.09930, lr:9.70e-03, fs:0.73684 (r=0.707,p=0.769),  time:19.525, tt:937.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00002, loss_test:0.09913, lr:9.70e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.548, tt:957.843\n",
      "Ep:49, loss:0.00002, loss_test:0.09873, lr:9.70e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.595, tt:979.759\n",
      "Ep:50, loss:0.00002, loss_test:0.09830, lr:9.61e-03, fs:0.73016 (r=0.697,p=0.767),  time:19.606, tt:999.894\n",
      "Ep:51, loss:0.00002, loss_test:0.09787, lr:9.51e-03, fs:0.73797 (r=0.697,p=0.784),  time:19.627, tt:1020.609\n",
      "Ep:52, loss:0.00002, loss_test:0.09748, lr:9.41e-03, fs:0.73797 (r=0.697,p=0.784),  time:19.636, tt:1040.683\n",
      "Ep:53, loss:0.00002, loss_test:0.09716, lr:9.32e-03, fs:0.75789 (r=0.727,p=0.791),  time:19.642, tt:1060.646\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.09694, lr:9.32e-03, fs:0.75789 (r=0.727,p=0.791),  time:19.641, tt:1080.229\n",
      "Ep:55, loss:0.00001, loss_test:0.09678, lr:9.32e-03, fs:0.75936 (r=0.717,p=0.807),  time:19.636, tt:1099.607\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.09645, lr:9.32e-03, fs:0.75936 (r=0.717,p=0.807),  time:19.633, tt:1119.099\n",
      "Ep:57, loss:0.00001, loss_test:0.09590, lr:9.32e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.661, tt:1140.351\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.09560, lr:9.32e-03, fs:0.76440 (r=0.737,p=0.793),  time:19.676, tt:1160.858\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.09570, lr:9.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.703, tt:1182.168\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.09563, lr:9.32e-03, fs:0.76596 (r=0.727,p=0.809),  time:19.706, tt:1202.067\n",
      "Ep:61, loss:0.00001, loss_test:0.09525, lr:9.32e-03, fs:0.76596 (r=0.727,p=0.809),  time:19.725, tt:1222.926\n",
      "Ep:62, loss:0.00001, loss_test:0.09509, lr:9.32e-03, fs:0.76596 (r=0.727,p=0.809),  time:19.743, tt:1243.809\n",
      "Ep:63, loss:0.00001, loss_test:0.09537, lr:9.32e-03, fs:0.77005 (r=0.727,p=0.818),  time:19.751, tt:1264.037\n",
      "Ep:64, loss:0.00001, loss_test:0.09562, lr:9.32e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.772, tt:1285.206\n",
      "Ep:65, loss:0.00001, loss_test:0.09567, lr:9.32e-03, fs:0.75676 (r=0.707,p=0.814),  time:19.774, tt:1305.108\n",
      "Ep:66, loss:0.00001, loss_test:0.09557, lr:9.32e-03, fs:0.75410 (r=0.697,p=0.821),  time:19.783, tt:1325.461\n",
      "Ep:67, loss:0.00001, loss_test:0.09545, lr:9.32e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.791, tt:1345.809\n",
      "Ep:68, loss:0.00001, loss_test:0.09547, lr:9.32e-03, fs:0.76087 (r=0.707,p=0.824),  time:19.810, tt:1366.889\n",
      "Ep:69, loss:0.00001, loss_test:0.09571, lr:9.32e-03, fs:0.76503 (r=0.707,p=0.833),  time:19.829, tt:1388.004\n",
      "Ep:70, loss:0.00001, loss_test:0.09597, lr:9.32e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.845, tt:1409.018\n",
      "Ep:71, loss:0.00001, loss_test:0.09594, lr:9.23e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.845, tt:1428.845\n",
      "Ep:72, loss:0.00001, loss_test:0.09587, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.871, tt:1450.559\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.09612, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.869, tt:1470.298\n",
      "Ep:74, loss:0.00001, loss_test:0.09631, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.874, tt:1490.548\n",
      "Ep:75, loss:0.00001, loss_test:0.09643, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.874, tt:1510.388\n",
      "Ep:76, loss:0.00001, loss_test:0.09602, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.873, tt:1530.255\n",
      "Ep:77, loss:0.00001, loss_test:0.09588, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.867, tt:1549.658\n",
      "Ep:78, loss:0.00001, loss_test:0.09600, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.884, tt:1570.821\n",
      "Ep:79, loss:0.00001, loss_test:0.09619, lr:9.14e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.875, tt:1590.020\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.09610, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.878, tt:1610.106\n",
      "Ep:81, loss:0.00001, loss_test:0.09593, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.864, tt:1628.876\n",
      "Ep:82, loss:0.00001, loss_test:0.09619, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.846, tt:1647.195\n",
      "Ep:83, loss:0.00001, loss_test:0.09628, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.827, tt:1665.487\n",
      "Ep:84, loss:0.00001, loss_test:0.09599, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.808, tt:1683.678\n",
      "Ep:85, loss:0.00001, loss_test:0.09556, lr:9.14e-03, fs:0.78919 (r=0.737,p=0.849),  time:19.802, tt:1702.988\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.09587, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.801, tt:1722.693\n",
      "Ep:87, loss:0.00001, loss_test:0.09582, lr:9.14e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.799, tt:1742.309\n",
      "Ep:88, loss:0.00001, loss_test:0.09571, lr:9.14e-03, fs:0.78689 (r=0.727,p=0.857),  time:19.791, tt:1761.428\n",
      "Ep:89, loss:0.00001, loss_test:0.09576, lr:9.14e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.786, tt:1780.765\n",
      "Ep:90, loss:0.00001, loss_test:0.09548, lr:9.14e-03, fs:0.79570 (r=0.747,p=0.851),  time:19.774, tt:1799.454\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.09559, lr:9.14e-03, fs:0.79570 (r=0.747,p=0.851),  time:19.781, tt:1819.890\n",
      "Ep:92, loss:0.00001, loss_test:0.09570, lr:9.14e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.756, tt:1837.298\n",
      "Ep:93, loss:0.00001, loss_test:0.09554, lr:9.14e-03, fs:0.78689 (r=0.727,p=0.857),  time:19.744, tt:1855.912\n",
      "Ep:94, loss:0.00001, loss_test:0.09591, lr:9.14e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.748, tt:1876.035\n",
      "Ep:95, loss:0.00001, loss_test:0.09592, lr:9.14e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.737, tt:1894.773\n",
      "Ep:96, loss:0.00001, loss_test:0.09570, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.729, tt:1913.708\n",
      "Ep:97, loss:0.00001, loss_test:0.09613, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.728, tt:1933.318\n",
      "Ep:98, loss:0.00001, loss_test:0.09599, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.726, tt:1952.854\n",
      "Ep:99, loss:0.00001, loss_test:0.09592, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.724, tt:1972.405\n",
      "Ep:100, loss:0.00001, loss_test:0.09620, lr:9.14e-03, fs:0.79348 (r=0.737,p=0.859),  time:19.722, tt:1991.905\n",
      "Ep:101, loss:0.00001, loss_test:0.09640, lr:9.14e-03, fs:0.79781 (r=0.737,p=0.869),  time:19.720, tt:2011.444\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.09615, lr:9.14e-03, fs:0.80435 (r=0.747,p=0.871),  time:19.709, tt:2030.078\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.09636, lr:9.14e-03, fs:0.79121 (r=0.727,p=0.867),  time:19.711, tt:2049.924\n",
      "Ep:104, loss:0.00001, loss_test:0.09637, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.702, tt:2068.684\n",
      "Ep:105, loss:0.00001, loss_test:0.09608, lr:9.14e-03, fs:0.80435 (r=0.747,p=0.871),  time:19.694, tt:2087.578\n",
      "Ep:106, loss:0.00001, loss_test:0.09586, lr:9.14e-03, fs:0.79781 (r=0.737,p=0.869),  time:19.729, tt:2110.965\n",
      "Ep:107, loss:0.00001, loss_test:0.09609, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.725, tt:2130.284\n",
      "Ep:108, loss:0.00001, loss_test:0.09657, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.714, tt:2148.814\n",
      "Ep:109, loss:0.00001, loss_test:0.09661, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.713, tt:2168.406\n",
      "Ep:110, loss:0.00001, loss_test:0.09619, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.707, tt:2187.497\n",
      "Ep:111, loss:0.00001, loss_test:0.09655, lr:9.14e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.709, tt:2207.458\n",
      "Ep:112, loss:0.00001, loss_test:0.09640, lr:9.14e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.718, tt:2228.133\n",
      "Ep:113, loss:0.00001, loss_test:0.09664, lr:9.14e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.740, tt:2250.328\n",
      "Ep:114, loss:0.00001, loss_test:0.09655, lr:9.04e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.752, tt:2271.488\n",
      "Ep:115, loss:0.00001, loss_test:0.09634, lr:8.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.753, tt:2291.351\n",
      "Ep:116, loss:0.00001, loss_test:0.09666, lr:8.86e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.749, tt:2310.634\n",
      "Ep:117, loss:0.00001, loss_test:0.09594, lr:8.78e-03, fs:0.77528 (r=0.697,p=0.873),  time:19.755, tt:2331.138\n",
      "Ep:118, loss:0.00001, loss_test:0.09686, lr:8.69e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.767, tt:2352.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.09637, lr:8.60e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.771, tt:2372.566\n",
      "Ep:120, loss:0.00001, loss_test:0.09545, lr:8.51e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.768, tt:2391.918\n",
      "Ep:121, loss:0.00001, loss_test:0.09677, lr:8.43e-03, fs:0.78212 (r=0.707,p=0.875),  time:19.772, tt:2412.241\n",
      "Ep:122, loss:0.00001, loss_test:0.09612, lr:8.35e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.775, tt:2432.372\n",
      "Ep:123, loss:0.00000, loss_test:0.09500, lr:8.26e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.783, tt:2453.075\n",
      "Ep:124, loss:0.00000, loss_test:0.09575, lr:8.18e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.791, tt:2473.829\n",
      "Ep:125, loss:0.00000, loss_test:0.09549, lr:8.10e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.794, tt:2494.008\n",
      "Ep:126, loss:0.00000, loss_test:0.09474, lr:8.02e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.800, tt:2514.574\n",
      "Ep:127, loss:0.00000, loss_test:0.09580, lr:7.94e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.807, tt:2535.263\n",
      "Ep:128, loss:0.00000, loss_test:0.09526, lr:7.86e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.812, tt:2555.782\n",
      "Ep:129, loss:0.00000, loss_test:0.09462, lr:7.78e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.808, tt:2575.100\n",
      "Ep:130, loss:0.00000, loss_test:0.09473, lr:7.70e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.809, tt:2594.924\n",
      "Ep:131, loss:0.00000, loss_test:0.09412, lr:7.62e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.806, tt:2614.417\n",
      "Ep:132, loss:0.00000, loss_test:0.09430, lr:7.55e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.816, tt:2635.584\n",
      "Ep:133, loss:0.00000, loss_test:0.09445, lr:7.47e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.822, tt:2656.184\n",
      "Ep:134, loss:0.00000, loss_test:0.09381, lr:7.40e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.836, tt:2677.879\n",
      "Ep:135, loss:0.00000, loss_test:0.09412, lr:7.32e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.839, tt:2698.146\n",
      "Ep:136, loss:0.00000, loss_test:0.09406, lr:7.25e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.841, tt:2718.233\n",
      "Ep:137, loss:0.00000, loss_test:0.09360, lr:7.18e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.849, tt:2739.144\n",
      "Ep:138, loss:0.00000, loss_test:0.09354, lr:7.11e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.856, tt:2760.040\n",
      "Ep:139, loss:0.00000, loss_test:0.09295, lr:7.03e-03, fs:0.78652 (r=0.707,p=0.886),  time:19.855, tt:2779.684\n",
      "Ep:140, loss:0.00000, loss_test:0.09333, lr:6.96e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.853, tt:2799.231\n",
      "Ep:141, loss:0.00000, loss_test:0.09343, lr:6.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.860, tt:2820.113\n",
      "Ep:142, loss:0.00000, loss_test:0.09303, lr:6.83e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.868, tt:2841.172\n",
      "Ep:143, loss:0.00000, loss_test:0.09289, lr:6.76e-03, fs:0.77966 (r=0.697,p=0.885),  time:19.874, tt:2861.835\n",
      "Ep:144, loss:0.00000, loss_test:0.09354, lr:6.69e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.877, tt:2882.235\n",
      "Ep:145, loss:0.00000, loss_test:0.09316, lr:6.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.882, tt:2902.715\n",
      "Ep:146, loss:0.00000, loss_test:0.09287, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.885, tt:2923.135\n",
      "Ep:147, loss:0.00000, loss_test:0.09311, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.898, tt:2944.938\n",
      "Ep:148, loss:0.00000, loss_test:0.09290, lr:6.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.898, tt:2964.833\n",
      "Ep:149, loss:0.00000, loss_test:0.09280, lr:6.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.904, tt:2985.672\n",
      "Ep:150, loss:0.00000, loss_test:0.09314, lr:6.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.904, tt:3005.482\n",
      "Ep:151, loss:0.00000, loss_test:0.09277, lr:6.24e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.898, tt:3024.441\n",
      "Ep:152, loss:0.00000, loss_test:0.09290, lr:6.17e-03, fs:0.78409 (r=0.697,p=0.896),  time:19.898, tt:3044.460\n",
      "Ep:153, loss:0.00000, loss_test:0.09291, lr:6.11e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.907, tt:3065.670\n",
      "Ep:154, loss:0.00000, loss_test:0.09327, lr:6.05e-03, fs:0.77011 (r=0.677,p=0.893),  time:19.908, tt:3085.810\n",
      "Ep:155, loss:0.00000, loss_test:0.09270, lr:5.99e-03, fs:0.77011 (r=0.677,p=0.893),  time:19.906, tt:3105.365\n",
      "Ep:156, loss:0.00000, loss_test:0.09273, lr:5.93e-03, fs:0.76301 (r=0.667,p=0.892),  time:19.910, tt:3125.809\n",
      "Ep:157, loss:0.00000, loss_test:0.09289, lr:5.87e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.917, tt:3146.848\n",
      "Ep:158, loss:0.00000, loss_test:0.09271, lr:5.81e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.912, tt:3165.991\n",
      "Ep:159, loss:0.00000, loss_test:0.09299, lr:5.75e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.913, tt:3186.068\n",
      "Ep:160, loss:0.00000, loss_test:0.09311, lr:5.70e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.917, tt:3206.603\n",
      "Ep:161, loss:0.00000, loss_test:0.09285, lr:5.64e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.915, tt:3226.174\n",
      "Ep:162, loss:0.00000, loss_test:0.09281, lr:5.58e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.919, tt:3246.721\n",
      "Ep:163, loss:0.00000, loss_test:0.09283, lr:5.53e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.911, tt:3265.373\n",
      "Ep:164, loss:0.00000, loss_test:0.09312, lr:5.47e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.916, tt:3286.104\n",
      "Ep:165, loss:0.00000, loss_test:0.09309, lr:5.42e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.915, tt:3305.967\n",
      "Ep:166, loss:0.00000, loss_test:0.09267, lr:5.36e-03, fs:0.75581 (r=0.657,p=0.890),  time:19.920, tt:3326.594\n",
      "Ep:167, loss:0.00000, loss_test:0.09346, lr:5.31e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.913, tt:3345.319\n",
      "Ep:168, loss:0.00000, loss_test:0.09329, lr:5.26e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.913, tt:3365.318\n",
      "Ep:169, loss:0.00000, loss_test:0.09273, lr:5.20e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.916, tt:3385.739\n",
      "Ep:170, loss:0.00000, loss_test:0.09375, lr:5.15e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.926, tt:3407.366\n",
      "Ep:171, loss:0.00000, loss_test:0.09338, lr:5.10e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.931, tt:3428.061\n",
      "Ep:172, loss:0.00000, loss_test:0.09231, lr:5.05e-03, fs:0.75145 (r=0.657,p=0.878),  time:19.933, tt:3448.436\n",
      "Ep:173, loss:0.00000, loss_test:0.09368, lr:5.00e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.930, tt:3467.839\n",
      "Ep:174, loss:0.00000, loss_test:0.09393, lr:4.95e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.927, tt:3487.286\n",
      "Ep:175, loss:0.00000, loss_test:0.09296, lr:4.90e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.928, tt:3507.324\n",
      "Ep:176, loss:0.00000, loss_test:0.09349, lr:4.85e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.932, tt:3527.907\n",
      "Ep:177, loss:0.00000, loss_test:0.09377, lr:4.80e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.925, tt:3546.718\n",
      "Ep:178, loss:0.00000, loss_test:0.09329, lr:4.75e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.926, tt:3566.833\n",
      "Ep:179, loss:0.00000, loss_test:0.09287, lr:4.71e-03, fs:0.74854 (r=0.646,p=0.889),  time:19.926, tt:3586.703\n",
      "Ep:180, loss:0.00000, loss_test:0.09388, lr:4.66e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.926, tt:3606.549\n",
      "Ep:181, loss:0.00000, loss_test:0.09371, lr:4.61e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.925, tt:3626.368\n",
      "Ep:182, loss:0.00000, loss_test:0.09290, lr:4.57e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.922, tt:3645.743\n",
      "Ep:183, loss:0.00000, loss_test:0.09329, lr:4.52e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.926, tt:3666.446\n",
      "Ep:184, loss:0.00000, loss_test:0.09344, lr:4.48e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.949, tt:3690.526\n",
      "Ep:185, loss:0.00000, loss_test:0.09339, lr:4.43e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.938, tt:3708.542\n",
      "Ep:186, loss:0.00000, loss_test:0.09327, lr:4.39e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.936, tt:3728.061\n",
      "Ep:187, loss:0.00000, loss_test:0.09287, lr:4.34e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.937, tt:3748.180\n",
      "Ep:188, loss:0.00000, loss_test:0.09317, lr:4.30e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.932, tt:3767.199\n",
      "Ep:189, loss:0.00000, loss_test:0.09364, lr:4.26e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.922, tt:3785.275\n",
      "Ep:190, loss:0.00000, loss_test:0.09314, lr:4.21e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.923, tt:3805.379\n",
      "Ep:191, loss:0.00000, loss_test:0.09302, lr:4.17e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.918, tt:3824.225\n",
      "Ep:192, loss:0.00000, loss_test:0.09326, lr:4.13e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.919, tt:3844.380\n",
      "Ep:193, loss:0.00000, loss_test:0.09301, lr:4.09e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.919, tt:3864.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:194, loss:0.00000, loss_test:0.09310, lr:4.05e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.922, tt:3884.771\n",
      "Ep:195, loss:0.00000, loss_test:0.09335, lr:4.01e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.925, tt:3905.356\n",
      "Ep:196, loss:0.00000, loss_test:0.09305, lr:3.97e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.926, tt:3925.404\n",
      "Ep:197, loss:0.00000, loss_test:0.09295, lr:3.93e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.927, tt:3945.451\n",
      "Ep:198, loss:0.00000, loss_test:0.09336, lr:3.89e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.928, tt:3965.754\n",
      "Ep:199, loss:0.00000, loss_test:0.09308, lr:3.85e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.926, tt:3985.254\n",
      "Ep:200, loss:0.00000, loss_test:0.09309, lr:3.81e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.926, tt:4005.050\n",
      "Ep:201, loss:0.00000, loss_test:0.09312, lr:3.77e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.924, tt:4024.659\n",
      "Ep:202, loss:0.00000, loss_test:0.09298, lr:3.73e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.917, tt:4043.190\n",
      "Ep:203, loss:0.00000, loss_test:0.09339, lr:3.70e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.918, tt:4063.249\n",
      "Ep:204, loss:0.00000, loss_test:0.09335, lr:3.66e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.920, tt:4083.552\n",
      "Ep:205, loss:0.00000, loss_test:0.09291, lr:3.62e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.921, tt:4103.799\n",
      "Ep:206, loss:0.00000, loss_test:0.09348, lr:3.59e-03, fs:0.74118 (r=0.636,p=0.887),  time:19.922, tt:4123.842\n",
      "Ep:207, loss:0.00000, loss_test:0.09375, lr:3.55e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4143.817\n",
      "Ep:208, loss:0.00000, loss_test:0.09347, lr:3.52e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4163.645\n",
      "Ep:209, loss:0.00000, loss_test:0.09302, lr:3.48e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.916, tt:4182.391\n",
      "Ep:210, loss:0.00000, loss_test:0.09333, lr:3.45e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.916, tt:4202.199\n",
      "Ep:211, loss:0.00000, loss_test:0.09332, lr:3.41e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.915, tt:4222.011\n",
      "Ep:212, loss:0.00000, loss_test:0.09295, lr:3.38e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.914, tt:4241.622\n",
      "Ep:213, loss:0.00000, loss_test:0.09299, lr:3.34e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.908, tt:4260.347\n",
      "Ep:214, loss:0.00000, loss_test:0.09353, lr:3.31e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.908, tt:4280.305\n",
      "Ep:215, loss:0.00000, loss_test:0.09344, lr:3.28e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.905, tt:4299.507\n",
      "Ep:216, loss:0.00000, loss_test:0.09282, lr:3.24e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.918, tt:4322.307\n",
      "Ep:217, loss:0.00000, loss_test:0.09311, lr:3.21e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.920, tt:4342.473\n",
      "Ep:218, loss:0.00000, loss_test:0.09349, lr:3.18e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.921, tt:4362.732\n",
      "Ep:219, loss:0.00000, loss_test:0.09348, lr:3.15e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4382.796\n",
      "Ep:220, loss:0.00000, loss_test:0.09299, lr:3.12e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4402.674\n",
      "Ep:221, loss:0.00000, loss_test:0.09287, lr:3.09e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4422.600\n",
      "Ep:222, loss:0.00000, loss_test:0.09364, lr:3.05e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4442.547\n",
      "Ep:223, loss:0.00000, loss_test:0.09380, lr:3.02e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.917, tt:4461.517\n",
      "Ep:224, loss:0.00000, loss_test:0.09332, lr:2.99e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.914, tt:4480.652\n",
      "Ep:225, loss:0.00000, loss_test:0.09291, lr:2.96e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.914, tt:4500.643\n",
      "Ep:226, loss:0.00000, loss_test:0.09325, lr:2.93e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.913, tt:4520.297\n",
      "Ep:227, loss:0.00000, loss_test:0.09346, lr:2.90e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.914, tt:4540.374\n",
      "Ep:228, loss:0.00000, loss_test:0.09327, lr:2.88e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.912, tt:4559.848\n",
      "Ep:229, loss:0.00000, loss_test:0.09312, lr:2.85e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.909, tt:4579.007\n",
      "Ep:230, loss:0.00000, loss_test:0.09318, lr:2.82e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.907, tt:4598.617\n",
      "Ep:231, loss:0.00000, loss_test:0.09319, lr:2.79e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.906, tt:4618.106\n",
      "Ep:232, loss:0.00000, loss_test:0.09315, lr:2.76e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.907, tt:4638.309\n",
      "Ep:233, loss:0.00000, loss_test:0.09315, lr:2.73e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.908, tt:4658.542\n",
      "Ep:234, loss:0.00000, loss_test:0.09325, lr:2.71e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.911, tt:4679.012\n",
      "Ep:235, loss:0.00000, loss_test:0.09313, lr:2.68e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.909, tt:4698.623\n",
      "Ep:236, loss:0.00000, loss_test:0.09299, lr:2.65e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.909, tt:4718.348\n",
      "Ep:237, loss:0.00000, loss_test:0.09315, lr:2.63e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.908, tt:4738.208\n",
      "Ep:238, loss:0.00000, loss_test:0.09342, lr:2.60e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.910, tt:4758.551\n",
      "Ep:239, loss:0.00000, loss_test:0.09327, lr:2.57e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.912, tt:4778.995\n",
      "Ep:240, loss:0.00000, loss_test:0.09284, lr:2.55e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.916, tt:4799.776\n",
      "Ep:241, loss:0.00000, loss_test:0.09289, lr:2.52e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.917, tt:4819.820\n",
      "Ep:242, loss:0.00000, loss_test:0.09342, lr:2.50e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.921, tt:4840.748\n",
      "Ep:243, loss:0.00000, loss_test:0.09358, lr:2.47e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.919, tt:4860.136\n",
      "Ep:244, loss:0.00000, loss_test:0.09332, lr:2.45e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.918, tt:4879.964\n",
      "Ep:245, loss:0.00000, loss_test:0.09291, lr:2.42e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.921, tt:4900.512\n",
      "Ep:246, loss:0.00000, loss_test:0.09308, lr:2.40e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.922, tt:4920.856\n",
      "Ep:247, loss:0.00000, loss_test:0.09338, lr:2.38e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.927, tt:4942.017\n",
      "Ep:248, loss:0.00000, loss_test:0.09336, lr:2.35e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.927, tt:4961.880\n",
      "Ep:249, loss:0.00000, loss_test:0.09307, lr:2.33e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.937, tt:4984.316\n",
      "Ep:250, loss:0.00000, loss_test:0.09315, lr:2.31e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.938, tt:5004.539\n",
      "Ep:251, loss:0.00000, loss_test:0.09335, lr:2.28e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.941, tt:5025.134\n",
      "Ep:252, loss:0.00000, loss_test:0.09332, lr:2.26e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.941, tt:5045.116\n",
      "Ep:253, loss:0.00000, loss_test:0.09308, lr:2.24e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.939, tt:5064.387\n",
      "Ep:254, loss:0.00000, loss_test:0.09306, lr:2.21e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.940, tt:5084.691\n",
      "Ep:255, loss:0.00000, loss_test:0.09319, lr:2.19e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.942, tt:5105.185\n",
      "Ep:256, loss:0.00000, loss_test:0.09328, lr:2.17e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.944, tt:5125.623\n",
      "Ep:257, loss:0.00000, loss_test:0.09319, lr:2.15e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.941, tt:5144.851\n",
      "Ep:258, loss:0.00000, loss_test:0.09321, lr:2.13e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.943, tt:5165.228\n",
      "Ep:259, loss:0.00000, loss_test:0.09331, lr:2.11e-03, fs:0.75449 (r=0.636,p=0.926),  time:19.946, tt:5186.038\n",
      "Ep:260, loss:0.00000, loss_test:0.09330, lr:2.08e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.953, tt:5207.804\n",
      "Ep:261, loss:0.00000, loss_test:0.09331, lr:2.06e-03, fs:0.74556 (r=0.636,p=0.900),  time:19.954, tt:5228.057\n",
      "Ep:262, loss:0.00000, loss_test:0.09339, lr:2.04e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.958, tt:5249.053\n",
      "Ep:263, loss:0.00000, loss_test:0.09337, lr:2.02e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.967, tt:5271.161\n",
      "Ep:264, loss:0.00000, loss_test:0.09332, lr:2.00e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.970, tt:5292.047\n",
      "Ep:265, loss:0.00000, loss_test:0.09338, lr:1.98e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.969, tt:5311.807\n",
      "Ep:266, loss:0.00000, loss_test:0.09355, lr:1.96e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.972, tt:5332.547\n",
      "Ep:267, loss:0.00000, loss_test:0.09354, lr:1.94e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.976, tt:5353.591\n",
      "Ep:268, loss:0.00000, loss_test:0.09338, lr:1.92e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.978, tt:5374.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:269, loss:0.00000, loss_test:0.09340, lr:1.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.975, tt:5393.176\n",
      "Ep:270, loss:0.00000, loss_test:0.09363, lr:1.89e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.982, tt:5415.019\n",
      "Ep:271, loss:0.00000, loss_test:0.09371, lr:1.87e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.985, tt:5435.792\n",
      "Ep:272, loss:0.00000, loss_test:0.09363, lr:1.85e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.992, tt:5457.827\n",
      "Ep:273, loss:0.00000, loss_test:0.09354, lr:1.83e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.999, tt:5479.734\n",
      "Ep:274, loss:0.00000, loss_test:0.09363, lr:1.81e-03, fs:0.75904 (r=0.636,p=0.940),  time:19.999, tt:5499.849\n",
      "Ep:275, loss:0.00000, loss_test:0.09368, lr:1.79e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.000, tt:5519.919\n",
      "Ep:276, loss:0.00000, loss_test:0.09370, lr:1.78e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.001, tt:5540.309\n",
      "Ep:277, loss:0.00000, loss_test:0.09368, lr:1.76e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.006, tt:5561.579\n",
      "Ep:278, loss:0.00000, loss_test:0.09377, lr:1.74e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.009, tt:5582.638\n",
      "Ep:279, loss:0.00000, loss_test:0.09381, lr:1.72e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.015, tt:5604.110\n",
      "Ep:280, loss:0.00000, loss_test:0.09372, lr:1.71e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.010, tt:5622.876\n",
      "Ep:281, loss:0.00000, loss_test:0.09387, lr:1.69e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.022, tt:5646.134\n",
      "Ep:282, loss:0.00000, loss_test:0.09395, lr:1.67e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.022, tt:5666.089\n",
      "Ep:283, loss:0.00000, loss_test:0.09387, lr:1.65e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.026, tt:5687.437\n",
      "Ep:284, loss:0.00000, loss_test:0.09371, lr:1.64e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.031, tt:5708.791\n",
      "Ep:285, loss:0.00000, loss_test:0.09394, lr:1.62e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.034, tt:5729.613\n",
      "Ep:286, loss:0.00000, loss_test:0.09406, lr:1.61e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.031, tt:5748.862\n",
      "Ep:287, loss:0.00000, loss_test:0.09401, lr:1.59e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.031, tt:5768.836\n",
      "Ep:288, loss:0.00000, loss_test:0.09382, lr:1.57e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.035, tt:5789.991\n",
      "Ep:289, loss:0.00000, loss_test:0.09384, lr:1.56e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.039, tt:5811.282\n",
      "Ep:290, loss:0.00000, loss_test:0.09398, lr:1.54e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.040, tt:5831.590\n",
      "Ep:291, loss:0.00000, loss_test:0.09404, lr:1.53e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.041, tt:5851.976\n",
      "Ep:292, loss:0.00000, loss_test:0.09398, lr:1.51e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.044, tt:5872.911\n",
      "Ep:293, loss:0.00000, loss_test:0.09388, lr:1.50e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.048, tt:5894.089\n",
      "Ep:294, loss:0.00000, loss_test:0.09391, lr:1.48e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.054, tt:5915.884\n",
      "Ep:295, loss:0.00000, loss_test:0.09403, lr:1.47e-03, fs:0.75904 (r=0.636,p=0.940),  time:20.045, tt:5933.263\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13908, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:11.181, tt:11.181\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13830, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:14.681, tt:29.362\n",
      "Ep:2, loss:0.00004, loss_test:0.13708, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:15.773, tt:47.320\n",
      "Ep:3, loss:0.00004, loss_test:0.13532, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:16.365, tt:65.460\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.13294, lr:1.00e-02, fs:0.67586 (r=0.990,p=0.513),  time:16.841, tt:84.207\n",
      "Ep:5, loss:0.00004, loss_test:0.13007, lr:1.00e-02, fs:0.68817 (r=0.970,p=0.533),  time:17.038, tt:102.230\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.12690, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:17.139, tt:119.974\n",
      "Ep:7, loss:0.00004, loss_test:0.12387, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:17.314, tt:138.513\n",
      "Ep:8, loss:0.00004, loss_test:0.12207, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:17.460, tt:157.136\n",
      "Ep:9, loss:0.00004, loss_test:0.12106, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:17.498, tt:174.976\n",
      "Ep:10, loss:0.00004, loss_test:0.11995, lr:1.00e-02, fs:0.66667 (r=0.798,p=0.572),  time:17.559, tt:193.151\n",
      "Ep:11, loss:0.00003, loss_test:0.11869, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:17.654, tt:211.844\n",
      "Ep:12, loss:0.00003, loss_test:0.11757, lr:1.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:17.655, tt:229.515\n",
      "Ep:13, loss:0.00003, loss_test:0.11663, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:17.764, tt:248.695\n",
      "Ep:14, loss:0.00003, loss_test:0.11607, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:17.874, tt:268.112\n",
      "Ep:15, loss:0.00003, loss_test:0.11550, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:17.984, tt:287.747\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.11490, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:18.059, tt:306.997\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.11398, lr:1.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:18.115, tt:326.077\n",
      "Ep:18, loss:0.00003, loss_test:0.11285, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:18.278, tt:347.273\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11196, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:18.319, tt:366.381\n",
      "Ep:20, loss:0.00003, loss_test:0.11130, lr:1.00e-02, fs:0.69027 (r=0.788,p=0.614),  time:18.337, tt:385.080\n",
      "Ep:21, loss:0.00003, loss_test:0.11093, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:18.377, tt:404.285\n",
      "Ep:22, loss:0.00003, loss_test:0.11051, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:18.388, tt:422.926\n",
      "Ep:23, loss:0.00003, loss_test:0.10991, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:18.412, tt:441.890\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10934, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:18.469, tt:461.722\n",
      "Ep:25, loss:0.00003, loss_test:0.10890, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:18.520, tt:481.513\n",
      "Ep:26, loss:0.00003, loss_test:0.10871, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:18.592, tt:501.989\n",
      "Ep:27, loss:0.00003, loss_test:0.10853, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:18.610, tt:521.087\n",
      "Ep:28, loss:0.00003, loss_test:0.10805, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:18.678, tt:541.670\n",
      "Ep:29, loss:0.00003, loss_test:0.10749, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:18.710, tt:561.294\n",
      "Ep:30, loss:0.00003, loss_test:0.10704, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:18.744, tt:581.061\n",
      "Ep:31, loss:0.00003, loss_test:0.10684, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:18.747, tt:599.918\n",
      "Ep:32, loss:0.00002, loss_test:0.10686, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:18.762, tt:619.144\n",
      "Ep:33, loss:0.00002, loss_test:0.10670, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:18.799, tt:639.180\n",
      "Ep:34, loss:0.00002, loss_test:0.10633, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:18.826, tt:658.895\n",
      "Ep:35, loss:0.00002, loss_test:0.10578, lr:9.90e-03, fs:0.69767 (r=0.758,p=0.647),  time:18.865, tt:679.127\n",
      "Ep:36, loss:0.00002, loss_test:0.10525, lr:9.80e-03, fs:0.67619 (r=0.717,p=0.640),  time:18.885, tt:698.736\n",
      "Ep:37, loss:0.00002, loss_test:0.10508, lr:9.70e-03, fs:0.69194 (r=0.737,p=0.652),  time:18.881, tt:717.480\n",
      "Ep:38, loss:0.00002, loss_test:0.10518, lr:9.61e-03, fs:0.69194 (r=0.737,p=0.652),  time:18.887, tt:736.612\n",
      "Ep:39, loss:0.00002, loss_test:0.10533, lr:9.51e-03, fs:0.69194 (r=0.737,p=0.652),  time:18.894, tt:755.741\n",
      "Ep:40, loss:0.00002, loss_test:0.10526, lr:9.41e-03, fs:0.68868 (r=0.737,p=0.646),  time:18.891, tt:774.542\n",
      "Ep:41, loss:0.00002, loss_test:0.10500, lr:9.32e-03, fs:0.69484 (r=0.747,p=0.649),  time:18.903, tt:793.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:42, loss:0.00002, loss_test:0.10490, lr:9.23e-03, fs:0.69524 (r=0.737,p=0.658),  time:18.921, tt:813.592\n",
      "Ep:43, loss:0.00002, loss_test:0.10482, lr:9.14e-03, fs:0.69856 (r=0.737,p=0.664),  time:18.921, tt:832.533\n",
      "Ep:44, loss:0.00002, loss_test:0.10465, lr:9.04e-03, fs:0.70192 (r=0.737,p=0.670),  time:18.927, tt:851.712\n",
      "Ep:45, loss:0.00002, loss_test:0.10437, lr:8.95e-03, fs:0.71770 (r=0.758,p=0.682),  time:18.940, tt:871.247\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10407, lr:8.95e-03, fs:0.71090 (r=0.758,p=0.670),  time:18.967, tt:891.471\n",
      "Ep:47, loss:0.00002, loss_test:0.10377, lr:8.95e-03, fs:0.72300 (r=0.778,p=0.675),  time:18.973, tt:910.703\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.10335, lr:8.95e-03, fs:0.74178 (r=0.798,p=0.693),  time:18.978, tt:929.942\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.10273, lr:8.95e-03, fs:0.73684 (r=0.778,p=0.700),  time:18.984, tt:949.222\n",
      "Ep:50, loss:0.00002, loss_test:0.10194, lr:8.95e-03, fs:0.74396 (r=0.778,p=0.713),  time:18.969, tt:967.413\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.10133, lr:8.95e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.957, tt:985.756\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.10109, lr:8.95e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.964, tt:1005.094\n",
      "Ep:53, loss:0.00002, loss_test:0.10094, lr:8.95e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.978, tt:1024.813\n",
      "Ep:54, loss:0.00002, loss_test:0.10071, lr:8.95e-03, fs:0.76190 (r=0.808,p=0.721),  time:18.976, tt:1043.674\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.10034, lr:8.95e-03, fs:0.76190 (r=0.808,p=0.721),  time:18.985, tt:1063.160\n",
      "Ep:56, loss:0.00002, loss_test:0.09984, lr:8.95e-03, fs:0.76777 (r=0.818,p=0.723),  time:18.992, tt:1082.545\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.09970, lr:8.95e-03, fs:0.76777 (r=0.818,p=0.723),  time:19.027, tt:1103.552\n",
      "Ep:58, loss:0.00002, loss_test:0.09944, lr:8.95e-03, fs:0.77358 (r=0.828,p=0.726),  time:19.030, tt:1122.792\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.09889, lr:8.95e-03, fs:0.76777 (r=0.818,p=0.723),  time:19.031, tt:1141.860\n",
      "Ep:60, loss:0.00002, loss_test:0.09833, lr:8.95e-03, fs:0.76777 (r=0.818,p=0.723),  time:19.038, tt:1161.322\n",
      "Ep:61, loss:0.00002, loss_test:0.09809, lr:8.95e-03, fs:0.77512 (r=0.818,p=0.736),  time:19.055, tt:1181.408\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.09811, lr:8.95e-03, fs:0.77512 (r=0.818,p=0.736),  time:19.047, tt:1199.947\n",
      "Ep:63, loss:0.00002, loss_test:0.09790, lr:8.95e-03, fs:0.77512 (r=0.818,p=0.736),  time:19.051, tt:1219.262\n",
      "Ep:64, loss:0.00002, loss_test:0.09740, lr:8.95e-03, fs:0.77512 (r=0.818,p=0.736),  time:19.050, tt:1238.281\n",
      "Ep:65, loss:0.00002, loss_test:0.09717, lr:8.95e-03, fs:0.77885 (r=0.818,p=0.743),  time:19.041, tt:1256.730\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.09703, lr:8.95e-03, fs:0.77885 (r=0.818,p=0.743),  time:19.040, tt:1275.710\n",
      "Ep:67, loss:0.00002, loss_test:0.09680, lr:8.95e-03, fs:0.78469 (r=0.828,p=0.745),  time:19.032, tt:1294.199\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.09653, lr:8.95e-03, fs:0.78469 (r=0.828,p=0.745),  time:19.050, tt:1314.473\n",
      "Ep:69, loss:0.00002, loss_test:0.09633, lr:8.95e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.049, tt:1333.461\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.09600, lr:8.95e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.037, tt:1351.630\n",
      "Ep:71, loss:0.00001, loss_test:0.09579, lr:8.95e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.028, tt:1370.005\n",
      "Ep:72, loss:0.00001, loss_test:0.09580, lr:8.95e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.019, tt:1388.384\n",
      "Ep:73, loss:0.00001, loss_test:0.09575, lr:8.95e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.011, tt:1406.839\n",
      "Ep:74, loss:0.00001, loss_test:0.09534, lr:8.95e-03, fs:0.79412 (r=0.818,p=0.771),  time:18.997, tt:1424.750\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.09512, lr:8.95e-03, fs:0.79612 (r=0.828,p=0.766),  time:18.999, tt:1443.922\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.09506, lr:8.95e-03, fs:0.79612 (r=0.828,p=0.766),  time:19.012, tt:1463.949\n",
      "Ep:77, loss:0.00001, loss_test:0.09487, lr:8.95e-03, fs:0.79412 (r=0.818,p=0.771),  time:19.012, tt:1482.918\n",
      "Ep:78, loss:0.00001, loss_test:0.09474, lr:8.95e-03, fs:0.80198 (r=0.818,p=0.786),  time:19.006, tt:1501.465\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.09447, lr:8.95e-03, fs:0.80198 (r=0.818,p=0.786),  time:19.010, tt:1520.797\n",
      "Ep:80, loss:0.00001, loss_test:0.09438, lr:8.95e-03, fs:0.80597 (r=0.818,p=0.794),  time:19.003, tt:1539.235\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.09426, lr:8.95e-03, fs:0.80597 (r=0.818,p=0.794),  time:18.994, tt:1557.520\n",
      "Ep:82, loss:0.00001, loss_test:0.09402, lr:8.95e-03, fs:0.81818 (r=0.818,p=0.818),  time:18.986, tt:1575.864\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.09404, lr:8.95e-03, fs:0.81818 (r=0.818,p=0.818),  time:18.986, tt:1594.850\n",
      "Ep:84, loss:0.00001, loss_test:0.09397, lr:8.95e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.984, tt:1613.670\n",
      "Ep:85, loss:0.00001, loss_test:0.09379, lr:8.95e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.980, tt:1632.309\n",
      "Ep:86, loss:0.00001, loss_test:0.09373, lr:8.95e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.981, tt:1651.325\n",
      "Ep:87, loss:0.00001, loss_test:0.09382, lr:8.95e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.987, tt:1670.840\n",
      "Ep:88, loss:0.00001, loss_test:0.09355, lr:8.95e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.989, tt:1690.011\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.09352, lr:8.95e-03, fs:0.81865 (r=0.798,p=0.840),  time:19.002, tt:1710.144\n",
      "Ep:90, loss:0.00001, loss_test:0.09355, lr:8.95e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.999, tt:1728.873\n",
      "Ep:91, loss:0.00001, loss_test:0.09313, lr:8.95e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.997, tt:1747.724\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.09313, lr:8.95e-03, fs:0.82474 (r=0.808,p=0.842),  time:19.001, tt:1767.087\n",
      "Ep:93, loss:0.00001, loss_test:0.09300, lr:8.95e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.999, tt:1785.938\n",
      "Ep:94, loss:0.00001, loss_test:0.09269, lr:8.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.998, tt:1804.773\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.09281, lr:8.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.994, tt:1823.408\n",
      "Ep:96, loss:0.00001, loss_test:0.09293, lr:8.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.982, tt:1841.244\n",
      "Ep:97, loss:0.00001, loss_test:0.09233, lr:8.95e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.995, tt:1861.485\n",
      "Ep:98, loss:0.00001, loss_test:0.09272, lr:8.95e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.998, tt:1880.827\n",
      "Ep:99, loss:0.00001, loss_test:0.09214, lr:8.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.999, tt:1899.874\n",
      "Ep:100, loss:0.00001, loss_test:0.09214, lr:8.95e-03, fs:0.82902 (r=0.808,p=0.851),  time:19.002, tt:1919.184\n",
      "Ep:101, loss:0.00001, loss_test:0.09188, lr:8.95e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.005, tt:1938.536\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.09157, lr:8.95e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.015, tt:1958.593\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.09166, lr:8.95e-03, fs:0.83077 (r=0.818,p=0.844),  time:19.020, tt:1978.116\n",
      "Ep:104, loss:0.00001, loss_test:0.09136, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.022, tt:1997.271\n",
      "Ep:105, loss:0.00001, loss_test:0.09123, lr:8.95e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.031, tt:2017.299\n",
      "Ep:106, loss:0.00001, loss_test:0.09116, lr:8.95e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.048, tt:2038.106\n",
      "Ep:107, loss:0.00001, loss_test:0.09073, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.043, tt:2056.693\n",
      "Ep:108, loss:0.00001, loss_test:0.09078, lr:8.95e-03, fs:0.83158 (r=0.798,p=0.868),  time:19.051, tt:2076.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00001, loss_test:0.09050, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.048, tt:2095.262\n",
      "Ep:110, loss:0.00001, loss_test:0.09066, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.052, tt:2114.769\n",
      "Ep:111, loss:0.00001, loss_test:0.08996, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.048, tt:2133.357\n",
      "Ep:112, loss:0.00001, loss_test:0.08969, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2153.129\n",
      "Ep:113, loss:0.00001, loss_test:0.08984, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2172.117\n",
      "Ep:114, loss:0.00001, loss_test:0.08971, lr:8.86e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2191.224\n",
      "Ep:115, loss:0.00001, loss_test:0.08929, lr:8.78e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2210.220\n",
      "Ep:116, loss:0.00001, loss_test:0.08918, lr:8.69e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.050, tt:2228.820\n",
      "Ep:117, loss:0.00001, loss_test:0.08896, lr:8.60e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.035, tt:2246.173\n",
      "Ep:118, loss:0.00001, loss_test:0.08889, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.031, tt:2264.740\n",
      "Ep:119, loss:0.00001, loss_test:0.08885, lr:8.43e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.032, tt:2283.851\n",
      "Ep:120, loss:0.00001, loss_test:0.08848, lr:8.35e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.035, tt:2303.190\n",
      "Ep:121, loss:0.00001, loss_test:0.08863, lr:8.26e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.043, tt:2323.246\n",
      "Ep:122, loss:0.00001, loss_test:0.08827, lr:8.18e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.049, tt:2343.080\n",
      "Ep:123, loss:0.00001, loss_test:0.08777, lr:8.10e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.060, tt:2363.475\n",
      "Ep:124, loss:0.00001, loss_test:0.08811, lr:8.02e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.060, tt:2382.463\n",
      "Ep:125, loss:0.00001, loss_test:0.08809, lr:7.94e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.054, tt:2400.801\n",
      "Ep:126, loss:0.00001, loss_test:0.08783, lr:7.86e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2419.892\n",
      "Ep:127, loss:0.00001, loss_test:0.08743, lr:7.78e-03, fs:0.83422 (r=0.788,p=0.886),  time:19.053, tt:2438.740\n",
      "Ep:128, loss:0.00001, loss_test:0.08765, lr:7.70e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.054, tt:2458.003\n",
      "Ep:129, loss:0.00001, loss_test:0.08756, lr:7.62e-03, fs:0.83422 (r=0.788,p=0.886),  time:19.057, tt:2477.430\n",
      "Ep:130, loss:0.00001, loss_test:0.08742, lr:7.55e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.063, tt:2497.254\n",
      "Ep:131, loss:0.00001, loss_test:0.08726, lr:7.47e-03, fs:0.83598 (r=0.798,p=0.878),  time:19.063, tt:2516.344\n",
      "Ep:132, loss:0.00001, loss_test:0.08724, lr:7.40e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.069, tt:2536.179\n",
      "Ep:133, loss:0.00001, loss_test:0.08748, lr:7.32e-03, fs:0.82979 (r=0.788,p=0.876),  time:19.067, tt:2554.966\n",
      "Ep:134, loss:0.00001, loss_test:0.08712, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.066, tt:2573.945\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00001, loss_test:0.08662, lr:7.25e-03, fs:0.83422 (r=0.788,p=0.886),  time:19.071, tt:2593.658\n",
      "Ep:136, loss:0.00001, loss_test:0.08689, lr:7.25e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.074, tt:2613.138\n",
      "Ep:137, loss:0.00001, loss_test:0.08695, lr:7.25e-03, fs:0.83422 (r=0.788,p=0.886),  time:19.077, tt:2632.598\n",
      "Ep:138, loss:0.00001, loss_test:0.08673, lr:7.25e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.086, tt:2652.985\n",
      "Ep:139, loss:0.00001, loss_test:0.08660, lr:7.25e-03, fs:0.83422 (r=0.788,p=0.886),  time:19.096, tt:2673.449\n",
      "Ep:140, loss:0.00001, loss_test:0.08639, lr:7.25e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.099, tt:2692.903\n",
      "Ep:141, loss:0.00001, loss_test:0.08607, lr:7.25e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.100, tt:2712.230\n",
      "Ep:142, loss:0.00001, loss_test:0.08639, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.106, tt:2732.129\n",
      "Ep:143, loss:0.00001, loss_test:0.08641, lr:7.25e-03, fs:0.84043 (r=0.798,p=0.888),  time:19.101, tt:2750.600\n",
      "Ep:144, loss:0.00001, loss_test:0.08612, lr:7.25e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.108, tt:2770.611\n",
      "Ep:145, loss:0.00001, loss_test:0.08582, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.106, tt:2789.435\n",
      "Ep:146, loss:0.00001, loss_test:0.08587, lr:7.18e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.100, tt:2807.732\n",
      "Ep:147, loss:0.00001, loss_test:0.08586, lr:7.11e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.102, tt:2827.028\n",
      "Ep:148, loss:0.00001, loss_test:0.08582, lr:7.03e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.099, tt:2845.788\n",
      "Ep:149, loss:0.00001, loss_test:0.08557, lr:6.96e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.102, tt:2865.307\n",
      "Ep:150, loss:0.00001, loss_test:0.08546, lr:6.89e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.100, tt:2884.128\n",
      "Ep:151, loss:0.00001, loss_test:0.08580, lr:6.83e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.099, tt:2903.077\n",
      "Ep:152, loss:0.00001, loss_test:0.08572, lr:6.76e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.093, tt:2921.153\n",
      "Ep:153, loss:0.00001, loss_test:0.08538, lr:6.69e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.090, tt:2939.908\n",
      "Ep:154, loss:0.00001, loss_test:0.08547, lr:6.62e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.083, tt:2957.836\n",
      "Ep:155, loss:0.00001, loss_test:0.08558, lr:6.56e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.095, tt:2978.756\n",
      "Ep:156, loss:0.00000, loss_test:0.08546, lr:6.49e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.091, tt:2997.335\n",
      "Ep:157, loss:0.00000, loss_test:0.08529, lr:6.43e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.093, tt:3016.753\n",
      "Ep:158, loss:0.00000, loss_test:0.08521, lr:6.36e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.092, tt:3035.628\n",
      "Ep:159, loss:0.00000, loss_test:0.08514, lr:6.30e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.093, tt:3054.859\n",
      "Ep:160, loss:0.00000, loss_test:0.08521, lr:6.24e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.093, tt:3073.981\n",
      "Ep:161, loss:0.00000, loss_test:0.08521, lr:6.17e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.095, tt:3093.321\n",
      "Ep:162, loss:0.00000, loss_test:0.08512, lr:6.11e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.101, tt:3113.397\n",
      "Ep:163, loss:0.00000, loss_test:0.08505, lr:6.05e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.102, tt:3132.667\n",
      "Ep:164, loss:0.00000, loss_test:0.08508, lr:5.99e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.099, tt:3151.366\n",
      "Ep:165, loss:0.00000, loss_test:0.08509, lr:5.93e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.101, tt:3170.809\n",
      "Ep:166, loss:0.00000, loss_test:0.08516, lr:5.87e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.106, tt:3190.628\n",
      "Ep:167, loss:0.00000, loss_test:0.08501, lr:5.81e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.114, tt:3211.088\n",
      "Ep:168, loss:0.00000, loss_test:0.08490, lr:5.75e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.115, tt:3230.386\n",
      "Ep:169, loss:0.00000, loss_test:0.08505, lr:5.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.123, tt:3250.883\n",
      "Ep:170, loss:0.00000, loss_test:0.08497, lr:5.64e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.125, tt:3270.344\n",
      "Ep:171, loss:0.00000, loss_test:0.08491, lr:5.58e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.130, tt:3290.372\n",
      "Ep:172, loss:0.00000, loss_test:0.08483, lr:5.53e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.130, tt:3309.471\n",
      "Ep:173, loss:0.00000, loss_test:0.08479, lr:5.47e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.123, tt:3327.394\n",
      "Ep:174, loss:0.00000, loss_test:0.08481, lr:5.42e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.118, tt:3345.656\n",
      "Ep:175, loss:0.00000, loss_test:0.08491, lr:5.36e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.115, tt:3364.218\n",
      "Ep:176, loss:0.00000, loss_test:0.08491, lr:5.31e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.108, tt:3382.194\n",
      "Ep:177, loss:0.00000, loss_test:0.08477, lr:5.26e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.108, tt:3401.219\n",
      "Ep:178, loss:0.00000, loss_test:0.08476, lr:5.20e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.110, tt:3420.606\n",
      "Ep:179, loss:0.00000, loss_test:0.08472, lr:5.15e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.110, tt:3439.773\n",
      "Ep:180, loss:0.00000, loss_test:0.08475, lr:5.10e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.112, tt:3459.287\n",
      "Ep:181, loss:0.00000, loss_test:0.08469, lr:5.05e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.111, tt:3478.195\n",
      "Ep:182, loss:0.00000, loss_test:0.08463, lr:5.00e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.110, tt:3497.149\n",
      "Ep:183, loss:0.00000, loss_test:0.08470, lr:4.95e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.111, tt:3516.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:184, loss:0.00000, loss_test:0.08471, lr:4.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.115, tt:3536.360\n",
      "Ep:185, loss:0.00000, loss_test:0.08467, lr:4.85e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.112, tt:3554.839\n",
      "Ep:186, loss:0.00000, loss_test:0.08463, lr:4.80e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.116, tt:3574.689\n",
      "Ep:187, loss:0.00000, loss_test:0.08462, lr:4.75e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.113, tt:3593.317\n",
      "Ep:188, loss:0.00000, loss_test:0.08466, lr:4.71e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.110, tt:3611.780\n",
      "Ep:189, loss:0.00000, loss_test:0.08465, lr:4.66e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.107, tt:3630.247\n",
      "Ep:190, loss:0.00000, loss_test:0.08468, lr:4.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.105, tt:3649.001\n",
      "Ep:191, loss:0.00000, loss_test:0.08463, lr:4.57e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.099, tt:3666.923\n",
      "Ep:192, loss:0.00000, loss_test:0.08460, lr:4.52e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.091, tt:3684.646\n",
      "Ep:193, loss:0.00000, loss_test:0.08474, lr:4.48e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.093, tt:3704.118\n",
      "Ep:194, loss:0.00000, loss_test:0.08476, lr:4.43e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.098, tt:3724.021\n",
      "Ep:195, loss:0.00000, loss_test:0.08467, lr:4.39e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.095, tt:3742.559\n",
      "Ep:196, loss:0.00000, loss_test:0.08459, lr:4.34e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.098, tt:3762.254\n",
      "Ep:197, loss:0.00000, loss_test:0.08465, lr:4.30e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.101, tt:3782.073\n",
      "Ep:198, loss:0.00000, loss_test:0.08461, lr:4.26e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.100, tt:3800.811\n",
      "Ep:199, loss:0.00000, loss_test:0.08457, lr:4.21e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.101, tt:3820.230\n",
      "Ep:200, loss:0.00000, loss_test:0.08462, lr:4.17e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.107, tt:3840.557\n",
      "Ep:201, loss:0.00000, loss_test:0.08462, lr:4.13e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.107, tt:3859.687\n",
      "Ep:202, loss:0.00000, loss_test:0.08461, lr:4.09e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.108, tt:3878.910\n",
      "Ep:203, loss:0.00000, loss_test:0.08454, lr:4.05e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.110, tt:3898.433\n",
      "Ep:204, loss:0.00000, loss_test:0.08469, lr:4.01e-03, fs:0.84492 (r=0.798,p=0.898),  time:19.113, tt:3918.200\n",
      "Ep:205, loss:0.00000, loss_test:0.08470, lr:3.97e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.113, tt:3937.284\n",
      "Ep:206, loss:0.00000, loss_test:0.08465, lr:3.93e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.121, tt:3958.004\n",
      "Ep:207, loss:0.00000, loss_test:0.08468, lr:3.89e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.120, tt:3976.994\n",
      "Ep:208, loss:0.00000, loss_test:0.08459, lr:3.85e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.121, tt:3996.290\n",
      "Ep:209, loss:0.00000, loss_test:0.08445, lr:3.81e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.124, tt:4015.990\n",
      "Ep:210, loss:0.00000, loss_test:0.08451, lr:3.77e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.127, tt:4035.696\n",
      "Ep:211, loss:0.00000, loss_test:0.08450, lr:3.73e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.129, tt:4055.408\n",
      "Ep:212, loss:0.00000, loss_test:0.08450, lr:3.70e-03, fs:0.83243 (r=0.778,p=0.895),  time:19.129, tt:4074.483\n",
      "Ep:213, loss:0.00000, loss_test:0.08458, lr:3.66e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.141, tt:4096.162\n",
      "Ep:214, loss:0.00000, loss_test:0.08438, lr:3.62e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.147, tt:4116.698\n",
      "Ep:215, loss:0.00000, loss_test:0.08438, lr:3.59e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.148, tt:4135.997\n",
      "Ep:216, loss:0.00000, loss_test:0.08447, lr:3.55e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.148, tt:4155.091\n",
      "Ep:217, loss:0.00000, loss_test:0.08446, lr:3.52e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.149, tt:4174.586\n",
      "Ep:218, loss:0.00000, loss_test:0.08434, lr:3.48e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.154, tt:4194.825\n",
      "Ep:219, loss:0.00000, loss_test:0.08434, lr:3.45e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.153, tt:4213.629\n",
      "Ep:220, loss:0.00000, loss_test:0.08444, lr:3.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.156, tt:4233.380\n",
      "Ep:221, loss:0.00000, loss_test:0.08437, lr:3.38e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.163, tt:4254.223\n",
      "Ep:222, loss:0.00000, loss_test:0.08433, lr:3.34e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.163, tt:4273.436\n",
      "Ep:223, loss:0.00000, loss_test:0.08432, lr:3.31e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.170, tt:4294.084\n",
      "Ep:224, loss:0.00000, loss_test:0.08430, lr:3.28e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.171, tt:4313.571\n",
      "Ep:225, loss:0.00000, loss_test:0.08434, lr:3.24e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.172, tt:4332.843\n",
      "Ep:226, loss:0.00000, loss_test:0.08437, lr:3.21e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.175, tt:4352.626\n",
      "Ep:227, loss:0.00000, loss_test:0.08433, lr:3.18e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.176, tt:4372.197\n",
      "Ep:228, loss:0.00000, loss_test:0.08423, lr:3.15e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.179, tt:4391.976\n",
      "Ep:229, loss:0.00000, loss_test:0.08425, lr:3.12e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.184, tt:4412.255\n",
      "Ep:230, loss:0.00000, loss_test:0.08426, lr:3.09e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.185, tt:4431.641\n",
      "Ep:231, loss:0.00000, loss_test:0.08422, lr:3.05e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.187, tt:4451.469\n",
      "Ep:232, loss:0.00000, loss_test:0.08426, lr:3.02e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.189, tt:4471.101\n",
      "Ep:233, loss:0.00000, loss_test:0.08431, lr:2.99e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.190, tt:4490.427\n",
      "Ep:234, loss:0.00000, loss_test:0.08425, lr:2.96e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.190, tt:4509.691\n",
      "Ep:235, loss:0.00000, loss_test:0.08419, lr:2.93e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.191, tt:4529.033\n",
      "Ep:236, loss:0.00000, loss_test:0.08425, lr:2.90e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.192, tt:4548.388\n",
      "Ep:237, loss:0.00000, loss_test:0.08430, lr:2.88e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.193, tt:4567.971\n",
      "Ep:238, loss:0.00000, loss_test:0.08420, lr:2.85e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.195, tt:4587.659\n",
      "Ep:239, loss:0.00000, loss_test:0.08419, lr:2.82e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.199, tt:4607.826\n",
      "Ep:240, loss:0.00000, loss_test:0.08421, lr:2.79e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.201, tt:4627.332\n",
      "Ep:241, loss:0.00000, loss_test:0.08426, lr:2.76e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.201, tt:4646.671\n",
      "Ep:242, loss:0.00000, loss_test:0.08425, lr:2.73e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.211, tt:4668.202\n",
      "Ep:243, loss:0.00000, loss_test:0.08416, lr:2.71e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.211, tt:4687.480\n",
      "Ep:244, loss:0.00000, loss_test:0.08419, lr:2.68e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.209, tt:4706.215\n",
      "Ep:245, loss:0.00000, loss_test:0.08422, lr:2.65e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.209, tt:4725.354\n",
      "Ep:246, loss:0.00000, loss_test:0.08422, lr:2.63e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.211, tt:4745.081\n",
      "Ep:247, loss:0.00000, loss_test:0.08419, lr:2.60e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.210, tt:4764.063\n",
      "Ep:248, loss:0.00000, loss_test:0.08415, lr:2.57e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.211, tt:4783.582\n",
      "Ep:249, loss:0.00000, loss_test:0.08422, lr:2.55e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.212, tt:4802.961\n",
      "Ep:250, loss:0.00000, loss_test:0.08425, lr:2.52e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.207, tt:4820.835\n",
      "Ep:251, loss:0.00000, loss_test:0.08423, lr:2.50e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.207, tt:4840.286\n",
      "Ep:252, loss:0.00000, loss_test:0.08415, lr:2.47e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.206, tt:4859.181\n",
      "Ep:253, loss:0.00000, loss_test:0.08416, lr:2.45e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.203, tt:4877.660\n",
      "Ep:254, loss:0.00000, loss_test:0.08423, lr:2.42e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.199, tt:4895.818\n",
      "Ep:255, loss:0.00000, loss_test:0.08426, lr:2.40e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.201, tt:4915.418\n",
      "Ep:256, loss:0.00000, loss_test:0.08419, lr:2.38e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.206, tt:4935.933\n",
      "Ep:257, loss:0.00000, loss_test:0.08421, lr:2.35e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.201, tt:4953.915\n",
      "Ep:258, loss:0.00000, loss_test:0.08422, lr:2.33e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.203, tt:4973.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:259, loss:0.00000, loss_test:0.08423, lr:2.31e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.206, tt:4993.520\n",
      "Ep:260, loss:0.00000, loss_test:0.08419, lr:2.28e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.210, tt:5013.731\n",
      "Ep:261, loss:0.00000, loss_test:0.08418, lr:2.26e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.210, tt:5033.062\n",
      "Ep:262, loss:0.00000, loss_test:0.08422, lr:2.24e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.213, tt:5053.110\n",
      "Ep:263, loss:0.00000, loss_test:0.08421, lr:2.21e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.212, tt:5072.101\n",
      "Ep:264, loss:0.00000, loss_test:0.08416, lr:2.19e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.210, tt:5090.739\n",
      "Ep:265, loss:0.00000, loss_test:0.08422, lr:2.17e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.213, tt:5110.582\n",
      "Ep:266, loss:0.00000, loss_test:0.08423, lr:2.15e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.214, tt:5130.160\n",
      "Ep:267, loss:0.00000, loss_test:0.08421, lr:2.13e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.215, tt:5149.520\n",
      "Ep:268, loss:0.00000, loss_test:0.08417, lr:2.11e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.212, tt:5167.999\n",
      "Ep:269, loss:0.00000, loss_test:0.08421, lr:2.08e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.214, tt:5187.890\n",
      "Ep:270, loss:0.00000, loss_test:0.08426, lr:2.06e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.219, tt:5208.417\n",
      "Ep:271, loss:0.00000, loss_test:0.08424, lr:2.04e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.222, tt:5228.283\n",
      "Ep:272, loss:0.00000, loss_test:0.08419, lr:2.02e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.222, tt:5247.618\n",
      "Ep:273, loss:0.00000, loss_test:0.08422, lr:2.00e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.222, tt:5266.701\n",
      "Ep:274, loss:0.00000, loss_test:0.08422, lr:1.98e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.222, tt:5286.008\n",
      "Ep:275, loss:0.00000, loss_test:0.08423, lr:1.96e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.223, tt:5305.472\n",
      "Ep:276, loss:0.00000, loss_test:0.08422, lr:1.94e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.225, tt:5325.267\n",
      "Ep:277, loss:0.00000, loss_test:0.08417, lr:1.92e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.224, tt:5344.275\n",
      "Ep:278, loss:0.00000, loss_test:0.08419, lr:1.90e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.227, tt:5364.333\n",
      "Ep:279, loss:0.00000, loss_test:0.08426, lr:1.89e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.229, tt:5384.140\n",
      "Ep:280, loss:0.00000, loss_test:0.08419, lr:1.87e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.231, tt:5403.896\n",
      "Ep:281, loss:0.00000, loss_test:0.08412, lr:1.85e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.231, tt:5423.248\n",
      "Ep:282, loss:0.00000, loss_test:0.08415, lr:1.83e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.229, tt:5441.708\n",
      "Ep:283, loss:0.00000, loss_test:0.08420, lr:1.81e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.227, tt:5460.594\n",
      "Ep:284, loss:0.00000, loss_test:0.08418, lr:1.79e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.228, tt:5479.881\n",
      "Ep:285, loss:0.00000, loss_test:0.08419, lr:1.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.227, tt:5498.932\n",
      "Ep:286, loss:0.00000, loss_test:0.08420, lr:1.76e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.226, tt:5517.796\n",
      "Ep:287, loss:0.00000, loss_test:0.08413, lr:1.74e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.221, tt:5535.750\n",
      "Ep:288, loss:0.00000, loss_test:0.08409, lr:1.72e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.220, tt:5554.543\n",
      "Ep:289, loss:0.00000, loss_test:0.08415, lr:1.71e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.216, tt:5572.741\n",
      "Ep:290, loss:0.00000, loss_test:0.08415, lr:1.69e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.212, tt:5590.568\n",
      "Ep:291, loss:0.00000, loss_test:0.08412, lr:1.67e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.211, tt:5609.661\n",
      "Ep:292, loss:0.00000, loss_test:0.08411, lr:1.65e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.209, tt:5628.356\n",
      "Ep:293, loss:0.00000, loss_test:0.08412, lr:1.64e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.207, tt:5646.995\n",
      "Ep:294, loss:0.00000, loss_test:0.08413, lr:1.62e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.204, tt:5665.252\n",
      "Ep:295, loss:0.00000, loss_test:0.08414, lr:1.61e-03, fs:0.83871 (r=0.788,p=0.897),  time:19.204, tt:5684.283\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14467, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:64.117, tt:64.117\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14217, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:63.286, tt:126.573\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.13623, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:64.108, tt:192.323\n",
      "Ep:3, loss:0.00049, loss_test:0.12797, lr:1.00e-02, fs:0.60944 (r=0.717,p=0.530),  time:64.748, tt:258.990\n",
      "Ep:4, loss:0.00046, loss_test:0.12337, lr:1.00e-02, fs:0.62069 (r=0.636,p=0.606),  time:64.715, tt:323.574\n",
      "Ep:5, loss:0.00043, loss_test:0.11889, lr:1.00e-02, fs:0.63507 (r=0.677,p=0.598),  time:65.908, tt:395.446\n",
      "Ep:6, loss:0.00041, loss_test:0.11251, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:65.800, tt:460.601\n",
      "Ep:7, loss:0.00038, loss_test:0.10814, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:65.820, tt:526.560\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.10347, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:65.805, tt:592.249\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09960, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:65.656, tt:656.558\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.09645, lr:1.00e-02, fs:0.71910 (r=0.646,p=0.810),  time:65.600, tt:721.600\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.09230, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:65.576, tt:786.910\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.08985, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:65.478, tt:851.216\n",
      "Ep:13, loss:0.00028, loss_test:0.08743, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:65.445, tt:916.227\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.08564, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:65.671, tt:985.063\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08576, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:65.583, tt:1049.324\n",
      "Ep:16, loss:0.00024, loss_test:0.08295, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:65.613, tt:1115.419\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.08214, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:65.686, tt:1182.348\n",
      "Ep:18, loss:0.00022, loss_test:0.08287, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:65.692, tt:1248.144\n",
      "Ep:19, loss:0.00021, loss_test:0.08140, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:65.718, tt:1314.352\n",
      "Ep:20, loss:0.00020, loss_test:0.07959, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:65.855, tt:1382.959\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.07820, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:65.831, tt:1448.293\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.07655, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:65.855, tt:1514.670\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.07893, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:65.970, tt:1583.285\n",
      "Ep:24, loss:0.00017, loss_test:0.07835, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:65.912, tt:1647.808\n",
      "Ep:25, loss:0.00016, loss_test:0.07469, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:65.873, tt:1712.695\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07522, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:65.957, tt:1780.847\n",
      "Ep:27, loss:0.00014, loss_test:0.07704, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:65.931, tt:1846.070\n",
      "Ep:28, loss:0.00014, loss_test:0.07486, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:65.926, tt:1911.865\n",
      "Ep:29, loss:0.00013, loss_test:0.07201, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:65.859, tt:1975.772\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07600, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:65.858, tt:2041.605\n",
      "Ep:31, loss:0.00012, loss_test:0.07939, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:65.692, tt:2102.141\n",
      "Ep:32, loss:0.00011, loss_test:0.07923, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:65.729, tt:2169.064\n",
      "Ep:33, loss:0.00011, loss_test:0.07401, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:65.682, tt:2233.204\n",
      "Ep:34, loss:0.00010, loss_test:0.07834, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:65.714, tt:2300.004\n",
      "Ep:35, loss:0.00009, loss_test:0.07631, lr:1.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:65.765, tt:2367.550\n",
      "Ep:36, loss:0.00009, loss_test:0.07796, lr:1.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:65.733, tt:2432.110\n",
      "Ep:37, loss:0.00008, loss_test:0.08201, lr:1.00e-02, fs:0.80240 (r=0.677,p=0.985),  time:65.680, tt:2495.854\n",
      "Ep:38, loss:0.00008, loss_test:0.07714, lr:1.00e-02, fs:0.80952 (r=0.687,p=0.986),  time:65.665, tt:2560.944\n",
      "Ep:39, loss:0.00008, loss_test:0.07525, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:65.685, tt:2627.412\n",
      "Ep:40, loss:0.00007, loss_test:0.07875, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:65.684, tt:2693.047\n",
      "Ep:41, loss:0.00007, loss_test:0.08482, lr:9.90e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.735, tt:2760.890\n",
      "Ep:42, loss:0.00007, loss_test:0.07185, lr:9.80e-03, fs:0.80000 (r=0.707,p=0.921),  time:65.779, tt:2828.490\n",
      "Ep:43, loss:0.00006, loss_test:0.08089, lr:9.70e-03, fs:0.76543 (r=0.626,p=0.984),  time:65.752, tt:2893.093\n",
      "Ep:44, loss:0.00006, loss_test:0.08519, lr:9.61e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.837, tt:2962.657\n",
      "Ep:45, loss:0.00006, loss_test:0.07453, lr:9.51e-03, fs:0.76074 (r=0.626,p=0.969),  time:65.840, tt:3028.633\n",
      "Ep:46, loss:0.00006, loss_test:0.08229, lr:9.41e-03, fs:0.75776 (r=0.616,p=0.984),  time:65.892, tt:3096.917\n",
      "Ep:47, loss:0.00005, loss_test:0.08148, lr:9.32e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.881, tt:3162.300\n",
      "Ep:48, loss:0.00005, loss_test:0.07893, lr:9.23e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.872, tt:3227.744\n",
      "Ep:49, loss:0.00005, loss_test:0.08462, lr:9.14e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.834, tt:3291.675\n",
      "Ep:50, loss:0.00005, loss_test:0.07778, lr:9.04e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.842, tt:3357.922\n",
      "Ep:51, loss:0.00005, loss_test:0.08180, lr:8.95e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.856, tt:3424.531\n",
      "Ep:52, loss:0.00004, loss_test:0.08345, lr:8.86e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.873, tt:3491.282\n",
      "Ep:53, loss:0.00004, loss_test:0.08264, lr:8.78e-03, fs:0.74847 (r=0.616,p=0.953),  time:65.939, tt:3560.732\n",
      "Ep:54, loss:0.00004, loss_test:0.08171, lr:8.69e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.949, tt:3627.196\n",
      "Ep:55, loss:0.00004, loss_test:0.08549, lr:8.60e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.951, tt:3693.247\n",
      "Ep:56, loss:0.00004, loss_test:0.07923, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:65.993, tt:3761.622\n",
      "Ep:57, loss:0.00004, loss_test:0.08623, lr:8.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:66.008, tt:3828.485\n",
      "Ep:58, loss:0.00003, loss_test:0.08568, lr:8.35e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.982, tt:3892.948\n",
      "Ep:59, loss:0.00003, loss_test:0.08331, lr:8.26e-03, fs:0.75472 (r=0.606,p=1.000),  time:65.979, tt:3958.764\n",
      "Ep:60, loss:0.00003, loss_test:0.08177, lr:8.18e-03, fs:0.72050 (r=0.586,p=0.935),  time:65.967, tt:4023.990\n",
      "Ep:61, loss:0.00003, loss_test:0.08450, lr:8.10e-03, fs:0.75472 (r=0.606,p=1.000),  time:65.997, tt:4091.786\n",
      "Ep:62, loss:0.00003, loss_test:0.08572, lr:8.02e-03, fs:0.73077 (r=0.576,p=1.000),  time:65.958, tt:4155.325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.08340, lr:7.94e-03, fs:0.74534 (r=0.606,p=0.968),  time:65.932, tt:4219.633\n",
      "Ep:64, loss:0.00003, loss_test:0.08491, lr:7.86e-03, fs:0.73418 (r=0.586,p=0.983),  time:65.928, tt:4285.327\n",
      "Ep:65, loss:0.00003, loss_test:0.08181, lr:7.78e-03, fs:0.75472 (r=0.606,p=1.000),  time:66.003, tt:4356.221\n",
      "Ep:66, loss:0.00002, loss_test:0.08405, lr:7.70e-03, fs:0.75472 (r=0.606,p=1.000),  time:66.008, tt:4422.555\n",
      "Ep:67, loss:0.00002, loss_test:0.08692, lr:7.62e-03, fs:0.71795 (r=0.566,p=0.982),  time:65.994, tt:4487.559\n",
      "Ep:68, loss:0.00002, loss_test:0.08377, lr:7.55e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.983, tt:4552.806\n",
      "Ep:69, loss:0.00002, loss_test:0.08317, lr:7.47e-03, fs:0.75000 (r=0.606,p=0.984),  time:65.999, tt:4619.949\n",
      "Ep:70, loss:0.00002, loss_test:0.08511, lr:7.40e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.985, tt:4684.932\n",
      "Ep:71, loss:0.00002, loss_test:0.08501, lr:7.32e-03, fs:0.71795 (r=0.566,p=0.982),  time:65.958, tt:4748.963\n",
      "Ep:72, loss:0.00002, loss_test:0.08493, lr:7.25e-03, fs:0.71429 (r=0.556,p=1.000),  time:65.966, tt:4815.537\n",
      "Ep:73, loss:0.00002, loss_test:0.08451, lr:7.18e-03, fs:0.73885 (r=0.586,p=1.000),  time:65.968, tt:4881.629\n",
      "Ep:74, loss:0.00002, loss_test:0.08371, lr:7.11e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.962, tt:4947.154\n",
      "Ep:75, loss:0.00002, loss_test:0.08572, lr:7.03e-03, fs:0.74214 (r=0.596,p=0.983),  time:65.966, tt:5013.453\n",
      "Ep:76, loss:0.00002, loss_test:0.08373, lr:6.96e-03, fs:0.70130 (r=0.545,p=0.982),  time:65.986, tt:5080.949\n",
      "Ep:77, loss:0.00002, loss_test:0.08645, lr:6.89e-03, fs:0.74684 (r=0.596,p=1.000),  time:66.016, tt:5149.216\n",
      "Ep:78, loss:0.00002, loss_test:0.08425, lr:6.83e-03, fs:0.72611 (r=0.576,p=0.983),  time:66.019, tt:5215.500\n",
      "Ep:79, loss:0.00002, loss_test:0.08620, lr:6.76e-03, fs:0.70968 (r=0.556,p=0.982),  time:66.012, tt:5280.980\n",
      "Ep:80, loss:0.00002, loss_test:0.08564, lr:6.69e-03, fs:0.76250 (r=0.616,p=1.000),  time:66.011, tt:5346.876\n",
      "Ep:81, loss:0.00002, loss_test:0.08476, lr:6.62e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.026, tt:5414.158\n",
      "Ep:82, loss:0.00002, loss_test:0.08657, lr:6.56e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.039, tt:5481.200\n",
      "Ep:83, loss:0.00002, loss_test:0.08547, lr:6.49e-03, fs:0.74684 (r=0.596,p=1.000),  time:66.067, tt:5549.631\n",
      "Ep:84, loss:0.00001, loss_test:0.08490, lr:6.43e-03, fs:0.75000 (r=0.606,p=0.984),  time:66.085, tt:5617.234\n",
      "Ep:85, loss:0.00001, loss_test:0.08675, lr:6.36e-03, fs:0.69737 (r=0.535,p=1.000),  time:66.086, tt:5683.428\n",
      "Ep:86, loss:0.00001, loss_test:0.08512, lr:6.30e-03, fs:0.75000 (r=0.606,p=0.984),  time:66.082, tt:5749.130\n",
      "Ep:87, loss:0.00001, loss_test:0.08638, lr:6.24e-03, fs:0.73885 (r=0.586,p=1.000),  time:66.082, tt:5815.242\n",
      "Ep:88, loss:0.00001, loss_test:0.08750, lr:6.17e-03, fs:0.68874 (r=0.525,p=1.000),  time:66.086, tt:5881.678\n",
      "Ep:89, loss:0.00001, loss_test:0.08486, lr:6.11e-03, fs:0.75000 (r=0.606,p=0.984),  time:66.098, tt:5948.777\n",
      "Ep:90, loss:0.00001, loss_test:0.08827, lr:6.05e-03, fs:0.68874 (r=0.525,p=1.000),  time:66.094, tt:6014.548\n",
      "Ep:91, loss:0.00001, loss_test:0.08602, lr:5.99e-03, fs:0.73077 (r=0.576,p=1.000),  time:66.066, tt:6078.099\n",
      "Ep:92, loss:0.00001, loss_test:0.08689, lr:5.93e-03, fs:0.73885 (r=0.586,p=1.000),  time:66.074, tt:6144.862\n",
      "Ep:93, loss:0.00001, loss_test:0.08765, lr:5.87e-03, fs:0.69737 (r=0.535,p=1.000),  time:66.047, tt:6208.375\n",
      "Ep:94, loss:0.00001, loss_test:0.08624, lr:5.81e-03, fs:0.74214 (r=0.596,p=0.983),  time:66.034, tt:6273.226\n",
      "Ep:95, loss:0.00001, loss_test:0.08752, lr:5.75e-03, fs:0.68000 (r=0.515,p=1.000),  time:66.025, tt:6338.377\n",
      "Ep:96, loss:0.00001, loss_test:0.08631, lr:5.70e-03, fs:0.74684 (r=0.596,p=1.000),  time:66.006, tt:6402.556\n",
      "Ep:97, loss:0.00001, loss_test:0.08750, lr:5.64e-03, fs:0.68874 (r=0.525,p=1.000),  time:65.993, tt:6467.299\n",
      "Ep:98, loss:0.00001, loss_test:0.08666, lr:5.58e-03, fs:0.73418 (r=0.586,p=0.983),  time:66.010, tt:6534.999\n",
      "Ep:99, loss:0.00001, loss_test:0.08809, lr:5.53e-03, fs:0.70588 (r=0.545,p=1.000),  time:66.027, tt:6602.690\n",
      "Ep:100, loss:0.00001, loss_test:0.08767, lr:5.47e-03, fs:0.70588 (r=0.545,p=1.000),  time:65.993, tt:6665.261\n",
      "Ep:101, loss:0.00001, loss_test:0.08778, lr:5.42e-03, fs:0.72611 (r=0.576,p=0.983),  time:65.992, tt:6731.207\n",
      "Ep:102, loss:0.00001, loss_test:0.08828, lr:5.36e-03, fs:0.70588 (r=0.545,p=1.000),  time:65.941, tt:6791.962\n",
      "Ep:103, loss:0.00001, loss_test:0.08824, lr:5.31e-03, fs:0.73077 (r=0.576,p=1.000),  time:65.865, tt:6849.980\n",
      "Ep:104, loss:0.00001, loss_test:0.08737, lr:5.26e-03, fs:0.70968 (r=0.556,p=0.982),  time:65.809, tt:6909.958\n",
      "Ep:105, loss:0.00001, loss_test:0.08825, lr:5.20e-03, fs:0.73077 (r=0.576,p=1.000),  time:65.762, tt:6970.757\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14457, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:82.507, tt:82.507\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14081, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:81.824, tt:163.648\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.13028, lr:1.00e-02, fs:0.60976 (r=0.758,p=0.510),  time:82.007, tt:246.021\n",
      "Ep:3, loss:0.00047, loss_test:0.12865, lr:1.00e-02, fs:0.62176 (r=0.606,p=0.638),  time:82.568, tt:330.272\n",
      "Ep:4, loss:0.00044, loss_test:0.11940, lr:1.00e-02, fs:0.62443 (r=0.697,p=0.566),  time:82.612, tt:413.060\n",
      "Ep:5, loss:0.00041, loss_test:0.11346, lr:1.00e-02, fs:0.68817 (r=0.646,p=0.736),  time:82.501, tt:495.007\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00038, loss_test:0.10434, lr:1.00e-02, fs:0.69792 (r=0.677,p=0.720),  time:82.223, tt:575.558\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.09635, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:82.260, tt:658.078\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00032, loss_test:0.09168, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:82.354, tt:741.190\n",
      "Ep:9, loss:0.00029, loss_test:0.08972, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:82.431, tt:824.306\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.08728, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:82.391, tt:906.302\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.08419, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:82.414, tt:988.968\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.08553, lr:1.00e-02, fs:0.77095 (r=0.697,p=0.863),  time:82.642, tt:1074.351\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.07920, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:82.598, tt:1156.371\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.07490, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:82.478, tt:1237.169\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.07502, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:82.629, tt:1322.069\n",
      "Ep:16, loss:0.00017, loss_test:0.07712, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:82.584, tt:1403.936\n",
      "Ep:17, loss:0.00015, loss_test:0.07976, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:82.540, tt:1485.723\n",
      "Ep:18, loss:0.00014, loss_test:0.07332, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:82.602, tt:1569.442\n",
      "Ep:19, loss:0.00013, loss_test:0.07417, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:82.551, tt:1651.014\n",
      "Ep:20, loss:0.00011, loss_test:0.07260, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:82.528, tt:1733.093\n",
      "Ep:21, loss:0.00010, loss_test:0.06972, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:82.512, tt:1815.273\n",
      "Ep:22, loss:0.00010, loss_test:0.06656, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:82.570, tt:1899.102\n",
      "Ep:23, loss:0.00009, loss_test:0.06997, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:82.406, tt:1977.733\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00009, loss_test:0.07329, lr:1.00e-02, fs:0.76923 (r=0.657,p=0.929),  time:82.401, tt:2060.036\n",
      "Ep:25, loss:0.00008, loss_test:0.07983, lr:1.00e-02, fs:0.72956 (r=0.586,p=0.967),  time:82.434, tt:2143.295\n",
      "Ep:26, loss:0.00008, loss_test:0.07022, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:82.459, tt:2226.383\n",
      "Ep:27, loss:0.00007, loss_test:0.07018, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:82.460, tt:2308.884\n",
      "Ep:28, loss:0.00006, loss_test:0.07213, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:82.531, tt:2393.395\n",
      "Ep:29, loss:0.00005, loss_test:0.06912, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:82.474, tt:2474.226\n",
      "Ep:30, loss:0.00005, loss_test:0.07339, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:82.470, tt:2556.581\n",
      "Ep:31, loss:0.00005, loss_test:0.07776, lr:1.00e-02, fs:0.75309 (r=0.616,p=0.968),  time:82.651, tt:2644.832\n",
      "Ep:32, loss:0.00004, loss_test:0.07741, lr:1.00e-02, fs:0.75309 (r=0.616,p=0.968),  time:82.625, tt:2726.620\n",
      "Ep:33, loss:0.00004, loss_test:0.08036, lr:1.00e-02, fs:0.75309 (r=0.616,p=0.968),  time:82.617, tt:2808.977\n",
      "Ep:34, loss:0.00004, loss_test:0.07742, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:82.551, tt:2889.295\n",
      "Ep:35, loss:0.00003, loss_test:0.08254, lr:9.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.512, tt:2970.423\n",
      "Ep:36, loss:0.00003, loss_test:0.08244, lr:9.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.495, tt:3052.315\n",
      "Ep:37, loss:0.00003, loss_test:0.07767, lr:9.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:82.536, tt:3136.355\n",
      "Ep:38, loss:0.00003, loss_test:0.08354, lr:9.61e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.484, tt:3216.858\n",
      "Ep:39, loss:0.00002, loss_test:0.07916, lr:9.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.452, tt:3298.078\n",
      "Ep:40, loss:0.00002, loss_test:0.08078, lr:9.41e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.432, tt:3379.699\n",
      "Ep:41, loss:0.00002, loss_test:0.08093, lr:9.32e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.500, tt:3464.998\n",
      "Ep:42, loss:0.00002, loss_test:0.08259, lr:9.23e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.539, tt:3549.181\n",
      "Ep:43, loss:0.00002, loss_test:0.07974, lr:9.14e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.473, tt:3628.821\n",
      "Ep:44, loss:0.00002, loss_test:0.08166, lr:9.04e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.491, tt:3712.104\n",
      "Ep:45, loss:0.00001, loss_test:0.08265, lr:8.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.523, tt:3796.039\n",
      "Ep:46, loss:0.00001, loss_test:0.08279, lr:8.86e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.562, tt:3880.414\n",
      "Ep:47, loss:0.00001, loss_test:0.08437, lr:8.78e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.591, tt:3964.361\n",
      "Ep:48, loss:0.00001, loss_test:0.08108, lr:8.69e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.526, tt:4043.787\n",
      "Ep:49, loss:0.00001, loss_test:0.08432, lr:8.60e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.530, tt:4126.482\n",
      "Ep:50, loss:0.00001, loss_test:0.08411, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.560, tt:4210.543\n",
      "Ep:51, loss:0.00001, loss_test:0.08255, lr:8.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.546, tt:4292.386\n",
      "Ep:52, loss:0.00001, loss_test:0.08423, lr:8.35e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.556, tt:4375.458\n",
      "Ep:53, loss:0.00001, loss_test:0.08462, lr:8.26e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.574, tt:4458.997\n",
      "Ep:54, loss:0.00001, loss_test:0.08610, lr:8.18e-03, fs:0.76250 (r=0.616,p=1.000),  time:82.589, tt:4542.405\n",
      "Ep:55, loss:0.00001, loss_test:0.08359, lr:8.10e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.604, tt:4625.846\n",
      "Ep:56, loss:0.00001, loss_test:0.08574, lr:8.02e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.594, tt:4707.877\n",
      "Ep:57, loss:0.00001, loss_test:0.08636, lr:7.94e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.578, tt:4789.543\n",
      "Ep:58, loss:0.00001, loss_test:0.08438, lr:7.86e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.611, tt:4874.059\n",
      "Ep:59, loss:0.00001, loss_test:0.08444, lr:7.78e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.619, tt:4957.130\n",
      "Ep:60, loss:0.00001, loss_test:0.08671, lr:7.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.640, tt:5041.038\n",
      "Ep:61, loss:0.00001, loss_test:0.08453, lr:7.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.615, tt:5122.130\n",
      "Ep:62, loss:0.00001, loss_test:0.08486, lr:7.55e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.589, tt:5203.121\n",
      "Ep:63, loss:0.00001, loss_test:0.08558, lr:7.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.556, tt:5283.585\n",
      "Ep:64, loss:0.00001, loss_test:0.08530, lr:7.40e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.573, tt:5367.221\n",
      "Ep:65, loss:0.00001, loss_test:0.08564, lr:7.32e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.582, tt:5450.396\n",
      "Ep:66, loss:0.00001, loss_test:0.08576, lr:7.25e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.628, tt:5536.052\n",
      "Ep:67, loss:0.00001, loss_test:0.08514, lr:7.18e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.676, tt:5621.975\n",
      "Ep:68, loss:0.00000, loss_test:0.08696, lr:7.11e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.674, tt:5704.473\n",
      "Ep:69, loss:0.00000, loss_test:0.08903, lr:7.03e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.698, tt:5788.846\n",
      "Ep:70, loss:0.00000, loss_test:0.08489, lr:6.96e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.695, tt:5871.357\n",
      "Ep:71, loss:0.00000, loss_test:0.08697, lr:6.89e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.701, tt:5954.465\n",
      "Ep:72, loss:0.00000, loss_test:0.08665, lr:6.83e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.701, tt:6037.141\n",
      "Ep:73, loss:0.00000, loss_test:0.08733, lr:6.76e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.676, tt:6118.048\n",
      "Ep:74, loss:0.00000, loss_test:0.08694, lr:6.69e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.675, tt:6200.602\n",
      "Ep:75, loss:0.00000, loss_test:0.08598, lr:6.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.680, tt:6283.666\n",
      "Ep:76, loss:0.00000, loss_test:0.08766, lr:6.56e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.674, tt:6365.921\n",
      "Ep:77, loss:0.00000, loss_test:0.08749, lr:6.49e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.731, tt:6453.053\n",
      "Ep:78, loss:0.00000, loss_test:0.08800, lr:6.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.754, tt:6537.600\n",
      "Ep:79, loss:0.00000, loss_test:0.08737, lr:6.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.769, tt:6621.486\n",
      "Ep:80, loss:0.00000, loss_test:0.08926, lr:6.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.777, tt:6704.949\n",
      "Ep:81, loss:0.00000, loss_test:0.08756, lr:6.24e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.796, tt:6789.287\n",
      "Ep:82, loss:0.00000, loss_test:0.08841, lr:6.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.783, tt:6870.959\n",
      "Ep:83, loss:0.00000, loss_test:0.08796, lr:6.11e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.770, tt:6952.710\n",
      "Ep:84, loss:0.00000, loss_test:0.09022, lr:6.05e-03, fs:0.76250 (r=0.616,p=1.000),  time:82.776, tt:7035.928\n",
      "Ep:85, loss:0.00000, loss_test:0.08803, lr:5.99e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.804, tt:7121.183\n",
      "Ep:86, loss:0.00000, loss_test:0.08930, lr:5.93e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.801, tt:7203.671\n",
      "Ep:87, loss:0.00000, loss_test:0.08853, lr:5.87e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.772, tt:7283.956\n",
      "Ep:88, loss:0.00000, loss_test:0.08992, lr:5.81e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.749, tt:7364.645\n",
      "Ep:89, loss:0.00000, loss_test:0.08776, lr:5.75e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.753, tt:7447.778\n",
      "Ep:90, loss:0.00000, loss_test:0.08970, lr:5.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.742, tt:7529.487\n",
      "Ep:91, loss:0.00000, loss_test:0.08852, lr:5.64e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.702, tt:7608.602\n",
      "Ep:92, loss:0.00000, loss_test:0.08876, lr:5.58e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.714, tt:7692.381\n",
      "Ep:93, loss:0.00000, loss_test:0.08760, lr:5.53e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.727, tt:7776.308\n",
      "Ep:94, loss:0.00000, loss_test:0.09006, lr:5.47e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.696, tt:7856.159\n",
      "Ep:95, loss:0.00000, loss_test:0.08822, lr:5.42e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.678, tt:7937.046\n",
      "Ep:96, loss:0.00000, loss_test:0.08840, lr:5.36e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.702, tt:8022.129\n",
      "Ep:97, loss:0.00000, loss_test:0.08870, lr:5.31e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.710, tt:8105.626\n",
      "Ep:98, loss:0.00000, loss_test:0.08825, lr:5.26e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.734, tt:8190.689\n",
      "Ep:99, loss:0.00000, loss_test:0.08888, lr:5.20e-03, fs:0.76250 (r=0.616,p=1.000),  time:82.727, tt:8272.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00000, loss_test:0.08784, lr:5.15e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.724, tt:8355.156\n",
      "Ep:101, loss:0.00000, loss_test:0.08812, lr:5.10e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.733, tt:8438.803\n",
      "Ep:102, loss:0.00000, loss_test:0.08781, lr:5.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.730, tt:8521.179\n",
      "Ep:103, loss:0.00000, loss_test:0.08789, lr:5.00e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.692, tt:8599.998\n",
      "Ep:104, loss:0.00000, loss_test:0.08841, lr:4.95e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.598, tt:8672.837\n",
      "Ep:105, loss:0.00000, loss_test:0.08841, lr:4.90e-03, fs:0.75776 (r=0.616,p=0.984),  time:82.600, tt:8755.613\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14302, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:75.074, tt:75.074\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00053, loss_test:0.13885, lr:1.00e-02, fs:0.62687 (r=0.848,p=0.497),  time:75.912, tt:151.825\n",
      "Ep:2, loss:0.00050, loss_test:0.13694, lr:1.00e-02, fs:0.62500 (r=0.758,p=0.532),  time:76.871, tt:230.613\n",
      "Ep:3, loss:0.00048, loss_test:0.13318, lr:1.00e-02, fs:0.60759 (r=0.727,p=0.522),  time:76.430, tt:305.721\n",
      "Ep:4, loss:0.00046, loss_test:0.12778, lr:1.00e-02, fs:0.61803 (r=0.727,p=0.537),  time:76.134, tt:380.668\n",
      "Ep:5, loss:0.00043, loss_test:0.12225, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:75.926, tt:455.556\n",
      "Ep:6, loss:0.00041, loss_test:0.11512, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:75.976, tt:531.834\n",
      "Ep:7, loss:0.00038, loss_test:0.10975, lr:1.00e-02, fs:0.68063 (r=0.657,p=0.707),  time:75.870, tt:606.957\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.10623, lr:1.00e-02, fs:0.69792 (r=0.677,p=0.720),  time:75.597, tt:680.374\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.10026, lr:1.00e-02, fs:0.69565 (r=0.646,p=0.753),  time:75.489, tt:754.894\n",
      "Ep:10, loss:0.00032, loss_test:0.09883, lr:1.00e-02, fs:0.68478 (r=0.636,p=0.741),  time:75.611, tt:831.717\n",
      "Ep:11, loss:0.00030, loss_test:0.09609, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:75.643, tt:907.715\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00028, loss_test:0.09419, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:75.876, tt:986.384\n",
      "Ep:13, loss:0.00026, loss_test:0.09072, lr:1.00e-02, fs:0.72131 (r=0.667,p=0.786),  time:75.962, tt:1063.463\n",
      "Ep:14, loss:0.00025, loss_test:0.09202, lr:1.00e-02, fs:0.72316 (r=0.646,p=0.821),  time:75.971, tt:1139.565\n",
      "Ep:15, loss:0.00023, loss_test:0.08883, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:76.100, tt:1217.602\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.08703, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:76.147, tt:1294.506\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.08842, lr:1.00e-02, fs:0.70787 (r=0.636,p=0.797),  time:76.224, tt:1372.031\n",
      "Ep:18, loss:0.00019, loss_test:0.08637, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:76.305, tt:1449.798\n",
      "Ep:19, loss:0.00018, loss_test:0.08675, lr:1.00e-02, fs:0.70175 (r=0.606,p=0.833),  time:76.284, tt:1525.685\n",
      "Ep:20, loss:0.00017, loss_test:0.08684, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:76.264, tt:1601.548\n",
      "Ep:21, loss:0.00016, loss_test:0.08857, lr:1.00e-02, fs:0.67081 (r=0.545,p=0.871),  time:76.174, tt:1675.818\n",
      "Ep:22, loss:0.00015, loss_test:0.08707, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:76.077, tt:1749.772\n",
      "Ep:23, loss:0.00013, loss_test:0.08582, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:76.108, tt:1826.583\n",
      "Ep:24, loss:0.00013, loss_test:0.08717, lr:1.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:76.055, tt:1901.383\n",
      "Ep:25, loss:0.00012, loss_test:0.08651, lr:1.00e-02, fs:0.71765 (r=0.616,p=0.859),  time:75.988, tt:1975.682\n",
      "Ep:26, loss:0.00011, loss_test:0.08958, lr:1.00e-02, fs:0.67925 (r=0.545,p=0.900),  time:75.970, tt:2051.196\n",
      "Ep:27, loss:0.00010, loss_test:0.08546, lr:1.00e-02, fs:0.66258 (r=0.545,p=0.844),  time:76.001, tt:2128.040\n",
      "Ep:28, loss:0.00010, loss_test:0.08681, lr:9.90e-03, fs:0.67500 (r=0.545,p=0.885),  time:76.004, tt:2204.104\n",
      "Ep:29, loss:0.00009, loss_test:0.10114, lr:9.80e-03, fs:0.69677 (r=0.545,p=0.964),  time:76.009, tt:2280.275\n",
      "Ep:30, loss:0.00009, loss_test:0.08835, lr:9.70e-03, fs:0.67901 (r=0.556,p=0.873),  time:75.943, tt:2354.218\n",
      "Ep:31, loss:0.00008, loss_test:0.09047, lr:9.61e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.893, tt:2428.578\n",
      "Ep:32, loss:0.00008, loss_test:0.09759, lr:9.51e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.992, tt:2507.722\n",
      "Ep:33, loss:0.00007, loss_test:0.09005, lr:9.41e-03, fs:0.68354 (r=0.545,p=0.915),  time:76.098, tt:2587.329\n",
      "Ep:34, loss:0.00008, loss_test:0.09393, lr:9.32e-03, fs:0.69231 (r=0.545,p=0.947),  time:76.066, tt:2662.297\n",
      "Ep:35, loss:0.00007, loss_test:0.09629, lr:9.23e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.992, tt:2735.704\n",
      "Ep:36, loss:0.00006, loss_test:0.08946, lr:9.14e-03, fs:0.71429 (r=0.606,p=0.870),  time:75.964, tt:2810.663\n",
      "Ep:37, loss:0.00006, loss_test:0.09046, lr:9.04e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.940, tt:2885.707\n",
      "Ep:38, loss:0.00006, loss_test:0.09334, lr:8.95e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.889, tt:2959.684\n",
      "Ep:39, loss:0.00006, loss_test:0.10678, lr:8.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.785, tt:3031.394\n",
      "Ep:40, loss:0.00006, loss_test:0.10896, lr:8.78e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.723, tt:3104.640\n",
      "Ep:41, loss:0.00006, loss_test:0.10729, lr:8.69e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.690, tt:3178.965\n",
      "Ep:42, loss:0.00005, loss_test:0.10298, lr:8.60e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.627, tt:3251.958\n",
      "Ep:43, loss:0.00005, loss_test:0.10180, lr:8.51e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.613, tt:3326.993\n",
      "Ep:44, loss:0.00005, loss_test:0.10160, lr:8.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.633, tt:3403.464\n",
      "Ep:45, loss:0.00004, loss_test:0.10475, lr:8.35e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.592, tt:3477.219\n",
      "Ep:46, loss:0.00004, loss_test:0.10220, lr:8.26e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.522, tt:3549.557\n",
      "Ep:47, loss:0.00004, loss_test:0.09988, lr:8.18e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.503, tt:3624.137\n",
      "Ep:48, loss:0.00004, loss_test:0.09614, lr:8.10e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.504, tt:3699.719\n",
      "Ep:49, loss:0.00004, loss_test:0.10156, lr:8.02e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.523, tt:3776.166\n",
      "Ep:50, loss:0.00003, loss_test:0.10204, lr:7.94e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.509, tt:3850.981\n",
      "Ep:51, loss:0.00003, loss_test:0.09906, lr:7.86e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.563, tt:3929.265\n",
      "Ep:52, loss:0.00003, loss_test:0.10089, lr:7.78e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.559, tt:4004.649\n",
      "Ep:53, loss:0.00003, loss_test:0.10293, lr:7.70e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.529, tt:4078.583\n",
      "Ep:54, loss:0.00003, loss_test:0.10763, lr:7.62e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.515, tt:4153.314\n",
      "Ep:55, loss:0.00003, loss_test:0.10584, lr:7.55e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.527, tt:4229.485\n",
      "Ep:56, loss:0.00003, loss_test:0.10842, lr:7.47e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.579, tt:4308.012\n",
      "Ep:57, loss:0.00003, loss_test:0.10600, lr:7.40e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.590, tt:4384.212\n",
      "Ep:58, loss:0.00003, loss_test:0.11104, lr:7.32e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.572, tt:4458.735\n",
      "Ep:59, loss:0.00003, loss_test:0.11107, lr:7.25e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.544, tt:4532.626\n",
      "Ep:60, loss:0.00003, loss_test:0.11635, lr:7.18e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.538, tt:4607.841\n",
      "Ep:61, loss:0.00003, loss_test:0.11205, lr:7.11e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.520, tt:4682.221\n",
      "Ep:62, loss:0.00003, loss_test:0.10758, lr:7.03e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.525, tt:4758.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.10516, lr:6.96e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.513, tt:4832.830\n",
      "Ep:64, loss:0.00002, loss_test:0.09104, lr:6.89e-03, fs:0.68354 (r=0.545,p=0.915),  time:75.474, tt:4905.826\n",
      "Ep:65, loss:0.00002, loss_test:0.09709, lr:6.83e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.499, tt:4982.931\n",
      "Ep:66, loss:0.00002, loss_test:0.10813, lr:6.76e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.485, tt:5057.510\n",
      "Ep:67, loss:0.00002, loss_test:0.10719, lr:6.69e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.482, tt:5132.757\n",
      "Ep:68, loss:0.00002, loss_test:0.10083, lr:6.62e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.460, tt:5206.717\n",
      "Ep:69, loss:0.00002, loss_test:0.10203, lr:6.56e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.420, tt:5279.425\n",
      "Ep:70, loss:0.00002, loss_test:0.10614, lr:6.49e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.401, tt:5353.467\n",
      "Ep:71, loss:0.00002, loss_test:0.10684, lr:6.43e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.407, tt:5429.302\n",
      "Ep:72, loss:0.00002, loss_test:0.10220, lr:6.36e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.396, tt:5503.906\n",
      "Ep:73, loss:0.00002, loss_test:0.09969, lr:6.30e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.404, tt:5579.918\n",
      "Ep:74, loss:0.00002, loss_test:0.10363, lr:6.24e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.354, tt:5651.530\n",
      "Ep:75, loss:0.00002, loss_test:0.10328, lr:6.17e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.336, tt:5725.532\n",
      "Ep:76, loss:0.00002, loss_test:0.10023, lr:6.11e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.341, tt:5801.259\n",
      "Ep:77, loss:0.00002, loss_test:0.10293, lr:6.05e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.308, tt:5874.005\n",
      "Ep:78, loss:0.00002, loss_test:0.10539, lr:5.99e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.311, tt:5949.584\n",
      "Ep:79, loss:0.00002, loss_test:0.10375, lr:5.93e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.310, tt:6024.774\n",
      "Ep:80, loss:0.00002, loss_test:0.10180, lr:5.87e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.284, tt:6098.001\n",
      "Ep:81, loss:0.00002, loss_test:0.10377, lr:5.81e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.255, tt:6170.929\n",
      "Ep:82, loss:0.00002, loss_test:0.10324, lr:5.75e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.237, tt:6244.711\n",
      "Ep:83, loss:0.00002, loss_test:0.10323, lr:5.70e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.217, tt:6318.231\n",
      "Ep:84, loss:0.00002, loss_test:0.10309, lr:5.64e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.207, tt:6392.621\n",
      "Ep:85, loss:0.00002, loss_test:0.10195, lr:5.58e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.196, tt:6466.883\n",
      "Ep:86, loss:0.00001, loss_test:0.10530, lr:5.53e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.207, tt:6542.970\n",
      "Ep:87, loss:0.00001, loss_test:0.10217, lr:5.47e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.201, tt:6617.702\n",
      "Ep:88, loss:0.00001, loss_test:0.10182, lr:5.42e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.190, tt:6691.932\n",
      "Ep:89, loss:0.00001, loss_test:0.10637, lr:5.36e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.180, tt:6766.183\n",
      "Ep:90, loss:0.00001, loss_test:0.10322, lr:5.31e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.188, tt:6842.105\n",
      "Ep:91, loss:0.00001, loss_test:0.10041, lr:5.26e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.227, tt:6920.874\n",
      "Ep:92, loss:0.00001, loss_test:0.10405, lr:5.20e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.243, tt:6997.597\n",
      "Ep:93, loss:0.00001, loss_test:0.10379, lr:5.15e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.247, tt:7073.192\n",
      "Ep:94, loss:0.00001, loss_test:0.10473, lr:5.10e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.266, tt:7150.284\n",
      "Ep:95, loss:0.00001, loss_test:0.10215, lr:5.05e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.263, tt:7225.227\n",
      "Ep:96, loss:0.00001, loss_test:0.10248, lr:5.00e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.266, tt:7300.846\n",
      "Ep:97, loss:0.00001, loss_test:0.10362, lr:4.95e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.284, tt:7377.868\n",
      "Ep:98, loss:0.00001, loss_test:0.10262, lr:4.90e-03, fs:0.69231 (r=0.545,p=0.947),  time:75.273, tt:7452.054\n",
      "Ep:99, loss:0.00001, loss_test:0.10546, lr:4.85e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.253, tt:7525.349\n",
      "Ep:100, loss:0.00001, loss_test:0.10223, lr:4.80e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.244, tt:7599.644\n",
      "Ep:101, loss:0.00001, loss_test:0.10401, lr:4.75e-03, fs:0.69677 (r=0.545,p=0.964),  time:75.191, tt:7669.434\n",
      "Ep:102, loss:0.00001, loss_test:0.10436, lr:4.71e-03, fs:0.68790 (r=0.545,p=0.931),  time:75.034, tt:7728.475\n",
      "Ep:103, loss:0.00001, loss_test:0.10348, lr:4.66e-03, fs:0.69231 (r=0.545,p=0.947),  time:74.599, tt:7758.340\n",
      "Ep:104, loss:0.00001, loss_test:0.10302, lr:4.61e-03, fs:0.68790 (r=0.545,p=0.931),  time:74.116, tt:7782.190\n",
      "Ep:105, loss:0.00001, loss_test:0.10536, lr:4.57e-03, fs:0.68790 (r=0.545,p=0.931),  time:73.616, tt:7803.317\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"10-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "#             loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02250, lr:6.00e-02, fs:0.65169 (r=0.879,p=0.518),  time:33.747, tt:33.747\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02646, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:34.172, tt:68.343\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02832, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.120, tt:102.361\n",
      "Ep:3, loss:0.00006, loss_test:0.02903, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:34.200, tt:136.800\n",
      "Ep:4, loss:0.00006, loss_test:0.02899, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:34.265, tt:171.323\n",
      "Ep:5, loss:0.00006, loss_test:0.02853, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:34.323, tt:205.938\n",
      "Ep:6, loss:0.00006, loss_test:0.02775, lr:6.00e-02, fs:0.63830 (r=0.909,p=0.492),  time:34.179, tt:239.254\n",
      "Ep:7, loss:0.00005, loss_test:0.02693, lr:6.00e-02, fs:0.62545 (r=0.869,p=0.489),  time:34.305, tt:274.441\n",
      "Ep:8, loss:0.00005, loss_test:0.02623, lr:6.00e-02, fs:0.62731 (r=0.859,p=0.494),  time:34.428, tt:309.855\n",
      "Ep:9, loss:0.00005, loss_test:0.02550, lr:6.00e-02, fs:0.62921 (r=0.848,p=0.500),  time:34.356, tt:343.560\n",
      "Ep:10, loss:0.00005, loss_test:0.02483, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:34.325, tt:377.571\n",
      "Ep:11, loss:0.00005, loss_test:0.02428, lr:6.00e-02, fs:0.63878 (r=0.848,p=0.512),  time:34.319, tt:411.824\n",
      "Ep:12, loss:0.00005, loss_test:0.02370, lr:6.00e-02, fs:0.63158 (r=0.848,p=0.503),  time:34.269, tt:445.495\n",
      "Ep:13, loss:0.00005, loss_test:0.02317, lr:5.94e-02, fs:0.64419 (r=0.869,p=0.512),  time:34.248, tt:479.472\n",
      "Ep:14, loss:0.00005, loss_test:0.02245, lr:5.88e-02, fs:0.65169 (r=0.879,p=0.518),  time:34.220, tt:513.302\n",
      "Ep:15, loss:0.00004, loss_test:0.02179, lr:5.82e-02, fs:0.66667 (r=0.899,p=0.530),  time:34.250, tt:548.006\n",
      "Ep:16, loss:0.00004, loss_test:0.02133, lr:5.76e-02, fs:0.66920 (r=0.889,p=0.537),  time:34.346, tt:583.875\n",
      "Ep:17, loss:0.00004, loss_test:0.02094, lr:5.71e-02, fs:0.65900 (r=0.869,p=0.531),  time:34.288, tt:617.185\n",
      "Ep:18, loss:0.00004, loss_test:0.02072, lr:5.65e-02, fs:0.65900 (r=0.869,p=0.531),  time:34.252, tt:650.795\n",
      "Ep:19, loss:0.00004, loss_test:0.02059, lr:5.59e-02, fs:0.65414 (r=0.879,p=0.521),  time:34.343, tt:686.867\n",
      "Ep:20, loss:0.00004, loss_test:0.02039, lr:5.54e-02, fs:0.65428 (r=0.889,p=0.518),  time:34.411, tt:722.626\n",
      "Ep:21, loss:0.00004, loss_test:0.02005, lr:5.48e-02, fs:0.66667 (r=0.889,p=0.533),  time:34.474, tt:758.422\n",
      "Ep:22, loss:0.00004, loss_test:0.01972, lr:5.43e-02, fs:0.65891 (r=0.859,p=0.535),  time:34.491, tt:793.304\n",
      "Ep:23, loss:0.00004, loss_test:0.01946, lr:5.37e-02, fs:0.66406 (r=0.859,p=0.541),  time:34.491, tt:827.788\n",
      "Ep:24, loss:0.00004, loss_test:0.01928, lr:5.32e-02, fs:0.66667 (r=0.859,p=0.545),  time:34.560, tt:864.009\n",
      "Ep:25, loss:0.00004, loss_test:0.01910, lr:5.27e-02, fs:0.67451 (r=0.869,p=0.551),  time:34.542, tt:898.100\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01895, lr:5.27e-02, fs:0.68504 (r=0.879,p=0.561),  time:34.597, tt:934.114\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01872, lr:5.27e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.577, tt:968.165\n",
      "Ep:28, loss:0.00004, loss_test:0.01840, lr:5.27e-02, fs:0.68775 (r=0.879,p=0.565),  time:34.589, tt:1003.079\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01810, lr:5.27e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.585, tt:1037.554\n",
      "Ep:30, loss:0.00003, loss_test:0.01780, lr:5.27e-02, fs:0.69076 (r=0.869,p=0.573),  time:34.598, tt:1072.553\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01746, lr:5.27e-02, fs:0.69919 (r=0.869,p=0.585),  time:34.618, tt:1107.773\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01720, lr:5.27e-02, fs:0.69919 (r=0.869,p=0.585),  time:34.681, tt:1144.457\n",
      "Ep:33, loss:0.00003, loss_test:0.01697, lr:5.27e-02, fs:0.70204 (r=0.869,p=0.589),  time:34.706, tt:1180.009\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01688, lr:5.27e-02, fs:0.71605 (r=0.879,p=0.604),  time:34.699, tt:1214.479\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01664, lr:5.27e-02, fs:0.71967 (r=0.869,p=0.614),  time:34.685, tt:1248.662\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01639, lr:5.27e-02, fs:0.72574 (r=0.869,p=0.623),  time:34.676, tt:1282.998\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01630, lr:5.27e-02, fs:0.72269 (r=0.869,p=0.619),  time:34.677, tt:1317.731\n",
      "Ep:38, loss:0.00003, loss_test:0.01619, lr:5.27e-02, fs:0.72650 (r=0.859,p=0.630),  time:34.675, tt:1352.332\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01601, lr:5.27e-02, fs:0.73504 (r=0.869,p=0.637),  time:34.687, tt:1387.480\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01589, lr:5.27e-02, fs:0.73043 (r=0.848,p=0.641),  time:34.674, tt:1421.614\n",
      "Ep:41, loss:0.00003, loss_test:0.01591, lr:5.27e-02, fs:0.73362 (r=0.848,p=0.646),  time:34.681, tt:1456.583\n",
      "Ep:42, loss:0.00003, loss_test:0.01570, lr:5.27e-02, fs:0.73043 (r=0.848,p=0.641),  time:34.707, tt:1492.381\n",
      "Ep:43, loss:0.00003, loss_test:0.01549, lr:5.27e-02, fs:0.72489 (r=0.838,p=0.638),  time:34.712, tt:1527.309\n",
      "Ep:44, loss:0.00002, loss_test:0.01538, lr:5.27e-02, fs:0.72489 (r=0.838,p=0.638),  time:34.703, tt:1561.627\n",
      "Ep:45, loss:0.00002, loss_test:0.01543, lr:5.27e-02, fs:0.72566 (r=0.828,p=0.646),  time:34.700, tt:1596.214\n",
      "Ep:46, loss:0.00002, loss_test:0.01509, lr:5.27e-02, fs:0.72889 (r=0.828,p=0.651),  time:34.680, tt:1629.942\n",
      "Ep:47, loss:0.00002, loss_test:0.01519, lr:5.27e-02, fs:0.74545 (r=0.828,p=0.678),  time:34.668, tt:1664.079\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01522, lr:5.27e-02, fs:0.73973 (r=0.818,p=0.675),  time:34.697, tt:1700.149\n",
      "Ep:49, loss:0.00002, loss_test:0.01527, lr:5.27e-02, fs:0.74312 (r=0.818,p=0.681),  time:34.710, tt:1735.476\n",
      "Ep:50, loss:0.00002, loss_test:0.01535, lr:5.27e-02, fs:0.74074 (r=0.808,p=0.684),  time:34.731, tt:1771.292\n",
      "Ep:51, loss:0.00002, loss_test:0.01517, lr:5.27e-02, fs:0.75701 (r=0.818,p=0.704),  time:34.727, tt:1805.788\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01547, lr:5.27e-02, fs:0.75829 (r=0.808,p=0.714),  time:34.724, tt:1840.383\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01597, lr:5.27e-02, fs:0.76190 (r=0.808,p=0.721),  time:34.726, tt:1875.229\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01596, lr:5.27e-02, fs:0.76555 (r=0.808,p=0.727),  time:34.744, tt:1910.930\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01630, lr:5.27e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.731, tt:1944.957\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01560, lr:5.27e-02, fs:0.77451 (r=0.798,p=0.752),  time:34.716, tt:1978.792\n",
      "Ep:57, loss:0.00002, loss_test:0.01677, lr:5.27e-02, fs:0.77000 (r=0.778,p=0.762),  time:34.714, tt:2013.419\n",
      "Ep:58, loss:0.00002, loss_test:0.01588, lr:5.27e-02, fs:0.77612 (r=0.788,p=0.765),  time:34.708, tt:2047.770\n",
      "Ep:59, loss:0.00002, loss_test:0.01755, lr:5.27e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.710, tt:2082.610\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01599, lr:5.27e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.707, tt:2117.151\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01867, lr:5.27e-02, fs:0.77778 (r=0.778,p=0.778),  time:34.701, tt:2151.476\n",
      "Ep:62, loss:0.00001, loss_test:0.01637, lr:5.27e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.686, tt:2185.219\n",
      "Ep:63, loss:0.00001, loss_test:0.01792, lr:5.27e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.684, tt:2219.763\n",
      "Ep:64, loss:0.00001, loss_test:0.01955, lr:5.27e-02, fs:0.77157 (r=0.768,p=0.776),  time:34.675, tt:2253.858\n",
      "Ep:65, loss:0.00001, loss_test:0.01642, lr:5.27e-02, fs:0.79381 (r=0.778,p=0.811),  time:34.677, tt:2288.650\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01995, lr:5.27e-02, fs:0.76042 (r=0.737,p=0.785),  time:34.690, tt:2324.242\n",
      "Ep:67, loss:0.00001, loss_test:0.02025, lr:5.27e-02, fs:0.76440 (r=0.737,p=0.793),  time:34.703, tt:2359.786\n",
      "Ep:68, loss:0.00001, loss_test:0.01857, lr:5.27e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.703, tt:2394.522\n",
      "Ep:69, loss:0.00001, loss_test:0.01841, lr:5.27e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.720, tt:2430.400\n",
      "Ep:70, loss:0.00001, loss_test:0.02115, lr:5.27e-02, fs:0.76042 (r=0.737,p=0.785),  time:34.706, tt:2464.094\n",
      "Ep:71, loss:0.00001, loss_test:0.02222, lr:5.27e-02, fs:0.74468 (r=0.707,p=0.787),  time:34.686, tt:2497.391\n",
      "Ep:72, loss:0.00001, loss_test:0.02038, lr:5.27e-02, fs:0.76842 (r=0.737,p=0.802),  time:34.691, tt:2532.447\n",
      "Ep:73, loss:0.00001, loss_test:0.01888, lr:5.27e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.685, tt:2566.655\n",
      "Ep:74, loss:0.00001, loss_test:0.02261, lr:5.27e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.650, tt:2598.724\n",
      "Ep:75, loss:0.00001, loss_test:0.02635, lr:5.27e-02, fs:0.73404 (r=0.697,p=0.775),  time:34.626, tt:2631.612\n",
      "Ep:76, loss:0.00001, loss_test:0.01956, lr:5.27e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.607, tt:2664.747\n",
      "Ep:77, loss:0.00001, loss_test:0.01857, lr:5.21e-02, fs:0.78534 (r=0.758,p=0.815),  time:34.577, tt:2697.019\n",
      "Ep:78, loss:0.00001, loss_test:0.02520, lr:5.16e-02, fs:0.75556 (r=0.687,p=0.840),  time:34.570, tt:2731.048\n",
      "Ep:79, loss:0.00001, loss_test:0.02279, lr:5.11e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.553, tt:2764.204\n",
      "Ep:80, loss:0.00001, loss_test:0.01828, lr:5.06e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.547, tt:2798.337\n",
      "Ep:81, loss:0.00001, loss_test:0.02720, lr:5.01e-02, fs:0.75676 (r=0.707,p=0.814),  time:34.522, tt:2830.837\n",
      "Ep:82, loss:0.00001, loss_test:0.02252, lr:4.96e-02, fs:0.78723 (r=0.747,p=0.831),  time:34.514, tt:2864.622\n",
      "Ep:83, loss:0.00001, loss_test:0.01798, lr:4.91e-02, fs:0.75936 (r=0.717,p=0.807),  time:34.501, tt:2898.081\n",
      "Ep:84, loss:0.00001, loss_test:0.03213, lr:4.86e-02, fs:0.70968 (r=0.667,p=0.759),  time:34.493, tt:2931.870\n",
      "Ep:85, loss:0.00001, loss_test:0.01758, lr:4.81e-02, fs:0.77005 (r=0.727,p=0.818),  time:34.483, tt:2965.526\n",
      "Ep:86, loss:0.00001, loss_test:0.02995, lr:4.76e-02, fs:0.71910 (r=0.646,p=0.810),  time:34.470, tt:2998.932\n",
      "Ep:87, loss:0.00001, loss_test:0.02086, lr:4.71e-02, fs:0.75410 (r=0.697,p=0.821),  time:34.462, tt:3032.693\n",
      "Ep:88, loss:0.00001, loss_test:0.02983, lr:4.67e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.458, tt:3066.802\n",
      "Ep:89, loss:0.00001, loss_test:0.02620, lr:4.62e-02, fs:0.76087 (r=0.707,p=0.824),  time:34.471, tt:3102.408\n",
      "Ep:90, loss:0.00001, loss_test:0.02721, lr:4.57e-02, fs:0.76243 (r=0.697,p=0.841),  time:34.457, tt:3135.572\n",
      "Ep:91, loss:0.00001, loss_test:0.02814, lr:4.53e-02, fs:0.77419 (r=0.727,p=0.828),  time:34.463, tt:3170.616\n",
      "Ep:92, loss:0.00001, loss_test:0.02682, lr:4.48e-02, fs:0.70175 (r=0.606,p=0.833),  time:34.466, tt:3205.360\n",
      "Ep:93, loss:0.00001, loss_test:0.03031, lr:4.44e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.447, tt:3238.065\n",
      "Ep:94, loss:0.00001, loss_test:0.02788, lr:4.39e-02, fs:0.68235 (r=0.586,p=0.817),  time:34.451, tt:3272.834\n",
      "Ep:95, loss:0.00001, loss_test:0.03052, lr:4.35e-02, fs:0.67857 (r=0.576,p=0.826),  time:34.434, tt:3305.655\n",
      "Ep:96, loss:0.00001, loss_test:0.03027, lr:4.31e-02, fs:0.68639 (r=0.586,p=0.829),  time:34.413, tt:3338.063\n",
      "Ep:97, loss:0.00001, loss_test:0.02635, lr:4.26e-02, fs:0.64634 (r=0.535,p=0.815),  time:34.391, tt:3370.312\n",
      "Ep:98, loss:0.00001, loss_test:0.03597, lr:4.22e-02, fs:0.70857 (r=0.626,p=0.816),  time:34.380, tt:3403.649\n",
      "Ep:99, loss:0.00001, loss_test:0.02868, lr:4.18e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.372, tt:3437.179\n",
      "Ep:100, loss:0.00001, loss_test:0.02769, lr:4.14e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.353, tt:3469.618\n",
      "Ep:101, loss:0.00001, loss_test:0.03478, lr:4.10e-02, fs:0.64242 (r=0.535,p=0.803),  time:34.347, tt:3503.415\n",
      "Ep:102, loss:0.00001, loss_test:0.02676, lr:4.05e-02, fs:0.64634 (r=0.535,p=0.815),  time:34.335, tt:3536.545\n",
      "Ep:103, loss:0.00001, loss_test:0.03607, lr:4.01e-02, fs:0.62577 (r=0.515,p=0.797),  time:34.326, tt:3569.875\n",
      "Ep:104, loss:0.00001, loss_test:0.03002, lr:3.97e-02, fs:0.63804 (r=0.525,p=0.812),  time:34.329, tt:3604.512\n",
      "Ep:105, loss:0.00001, loss_test:0.03186, lr:3.93e-02, fs:0.62112 (r=0.505,p=0.806),  time:34.324, tt:3638.318\n",
      "Ep:106, loss:0.00000, loss_test:0.03317, lr:3.89e-02, fs:0.61250 (r=0.495,p=0.803),  time:34.322, tt:3672.507\n",
      "Ep:107, loss:0.00000, loss_test:0.03372, lr:3.86e-02, fs:0.59873 (r=0.475,p=0.810),  time:34.317, tt:3706.209\n",
      "Ep:108, loss:0.00000, loss_test:0.03405, lr:3.82e-02, fs:0.60377 (r=0.485,p=0.800),  time:34.310, tt:3739.836\n",
      "Ep:109, loss:0.00000, loss_test:0.03379, lr:3.78e-02, fs:0.59494 (r=0.475,p=0.797),  time:34.320, tt:3775.232\n",
      "Ep:110, loss:0.00000, loss_test:0.03537, lr:3.74e-02, fs:0.57692 (r=0.455,p=0.789),  time:34.306, tt:3807.988\n",
      "Ep:111, loss:0.00000, loss_test:0.03363, lr:3.70e-02, fs:0.64596 (r=0.525,p=0.839),  time:34.285, tt:3839.936\n",
      "Ep:112, loss:0.00000, loss_test:0.03715, lr:3.67e-02, fs:0.56209 (r=0.434,p=0.796),  time:34.269, tt:3872.444\n",
      "Ep:113, loss:0.00000, loss_test:0.03412, lr:3.63e-02, fs:0.64596 (r=0.525,p=0.839),  time:34.267, tt:3906.492\n",
      "Ep:114, loss:0.00000, loss_test:0.03562, lr:3.59e-02, fs:0.61146 (r=0.485,p=0.828),  time:34.261, tt:3940.028\n",
      "Ep:115, loss:0.00000, loss_test:0.03809, lr:3.56e-02, fs:0.56954 (r=0.434,p=0.827),  time:34.238, tt:3971.575\n",
      "Ep:116, loss:0.00000, loss_test:0.03700, lr:3.52e-02, fs:0.58824 (r=0.455,p=0.833),  time:34.228, tt:4004.715\n",
      "Ep:117, loss:0.00000, loss_test:0.03457, lr:3.49e-02, fs:0.65000 (r=0.525,p=0.852),  time:34.223, tt:4038.363\n",
      "Ep:118, loss:0.00000, loss_test:0.04332, lr:3.45e-02, fs:0.62893 (r=0.505,p=0.833),  time:34.216, tt:4071.760\n",
      "Ep:119, loss:0.00000, loss_test:0.03190, lr:3.42e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.209, tt:4105.094\n",
      "Ep:120, loss:0.00000, loss_test:0.04125, lr:3.38e-02, fs:0.58442 (r=0.455,p=0.818),  time:34.199, tt:4138.135\n",
      "Ep:121, loss:0.00000, loss_test:0.03316, lr:3.35e-02, fs:0.65000 (r=0.525,p=0.852),  time:34.194, tt:4171.675\n",
      "Ep:122, loss:0.00000, loss_test:0.04087, lr:3.32e-02, fs:0.56954 (r=0.434,p=0.827),  time:34.188, tt:4205.139\n",
      "Ep:123, loss:0.00000, loss_test:0.03734, lr:3.28e-02, fs:0.58278 (r=0.444,p=0.846),  time:34.192, tt:4239.821\n",
      "Ep:124, loss:0.00000, loss_test:0.03661, lr:3.25e-02, fs:0.61538 (r=0.485,p=0.842),  time:34.201, tt:4275.065\n",
      "Ep:125, loss:0.00000, loss_test:0.03992, lr:3.22e-02, fs:0.57718 (r=0.434,p=0.860),  time:34.198, tt:4308.917\n",
      "Ep:126, loss:0.00000, loss_test:0.03446, lr:3.19e-02, fs:0.64151 (r=0.515,p=0.850),  time:34.203, tt:4343.725\n",
      "Ep:127, loss:0.00000, loss_test:0.04000, lr:3.15e-02, fs:0.57333 (r=0.434,p=0.843),  time:34.206, tt:4378.326\n",
      "Ep:128, loss:0.00000, loss_test:0.03531, lr:3.12e-02, fs:0.64968 (r=0.515,p=0.879),  time:34.214, tt:4413.595\n",
      "Ep:129, loss:0.00000, loss_test:0.04173, lr:3.09e-02, fs:0.56954 (r=0.434,p=0.827),  time:34.239, tt:4451.070\n",
      "Ep:130, loss:0.00000, loss_test:0.03784, lr:3.06e-02, fs:0.57718 (r=0.434,p=0.860),  time:34.233, tt:4484.554\n",
      "Ep:131, loss:0.00000, loss_test:0.04027, lr:3.03e-02, fs:0.56757 (r=0.424,p=0.857),  time:34.234, tt:4518.936\n",
      "Ep:132, loss:0.00000, loss_test:0.03871, lr:3.00e-02, fs:0.54795 (r=0.404,p=0.851),  time:34.235, tt:4553.208\n",
      "Ep:133, loss:0.00000, loss_test:0.04072, lr:2.97e-02, fs:0.56757 (r=0.424,p=0.857),  time:34.233, tt:4587.174\n",
      "Ep:134, loss:0.00000, loss_test:0.04085, lr:2.94e-02, fs:0.53793 (r=0.394,p=0.848),  time:34.242, tt:4622.641\n",
      "Ep:135, loss:0.00000, loss_test:0.03770, lr:2.91e-02, fs:0.61935 (r=0.485,p=0.857),  time:34.247, tt:4657.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.04311, lr:2.88e-02, fs:0.56757 (r=0.424,p=0.857),  time:34.256, tt:4693.089\n",
      "Ep:137, loss:0.00000, loss_test:0.03814, lr:2.85e-02, fs:0.57718 (r=0.434,p=0.860),  time:34.246, tt:4726.003\n",
      "Ep:138, loss:0.00000, loss_test:0.04138, lr:2.82e-02, fs:0.55782 (r=0.414,p=0.854),  time:34.248, tt:4760.459\n",
      "Ep:139, loss:0.00000, loss_test:0.04117, lr:2.80e-02, fs:0.54795 (r=0.404,p=0.851),  time:34.240, tt:4793.630\n",
      "Ep:140, loss:0.00000, loss_test:0.04228, lr:2.77e-02, fs:0.54795 (r=0.404,p=0.851),  time:34.227, tt:4825.976\n",
      "Ep:141, loss:0.00000, loss_test:0.04196, lr:2.74e-02, fs:0.52778 (r=0.384,p=0.844),  time:34.213, tt:4858.196\n",
      "Ep:142, loss:0.00000, loss_test:0.04003, lr:2.71e-02, fs:0.55782 (r=0.414,p=0.854),  time:34.211, tt:4892.224\n",
      "Ep:143, loss:0.00000, loss_test:0.04282, lr:2.69e-02, fs:0.56757 (r=0.424,p=0.857),  time:34.205, tt:4925.530\n",
      "Ep:144, loss:0.00000, loss_test:0.04151, lr:2.66e-02, fs:0.51748 (r=0.374,p=0.841),  time:34.206, tt:4959.856\n",
      "Ep:145, loss:0.00000, loss_test:0.04237, lr:2.63e-02, fs:0.51748 (r=0.374,p=0.841),  time:34.193, tt:4992.133\n",
      "Ep:146, loss:0.00000, loss_test:0.04372, lr:2.61e-02, fs:0.54795 (r=0.404,p=0.851),  time:34.189, tt:5025.743\n",
      "Ep:147, loss:0.00000, loss_test:0.04043, lr:2.58e-02, fs:0.51748 (r=0.374,p=0.841),  time:34.187, tt:5059.707\n",
      "Ep:148, loss:0.00000, loss_test:0.04443, lr:2.55e-02, fs:0.51748 (r=0.374,p=0.841),  time:34.179, tt:5092.726\n",
      "Ep:149, loss:0.00000, loss_test:0.04134, lr:2.53e-02, fs:0.49645 (r=0.354,p=0.833),  time:34.174, tt:5126.041\n",
      "Ep:150, loss:0.00000, loss_test:0.04371, lr:2.50e-02, fs:0.51748 (r=0.374,p=0.841),  time:34.168, tt:5159.300\n",
      "Ep:151, loss:0.00000, loss_test:0.04213, lr:2.48e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.161, tt:5192.501\n",
      "Ep:152, loss:0.00000, loss_test:0.04338, lr:2.45e-02, fs:0.49645 (r=0.354,p=0.833),  time:34.161, tt:5226.663\n",
      "Ep:153, loss:0.00000, loss_test:0.04395, lr:2.43e-02, fs:0.50704 (r=0.364,p=0.837),  time:34.145, tt:5258.348\n",
      "Ep:154, loss:0.00000, loss_test:0.04159, lr:2.40e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.154, tt:5293.797\n",
      "Ep:155, loss:0.00000, loss_test:0.04538, lr:2.38e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.150, tt:5327.389\n",
      "Ep:156, loss:0.00000, loss_test:0.04174, lr:2.36e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.153, tt:5362.011\n",
      "Ep:157, loss:0.00000, loss_test:0.04556, lr:2.33e-02, fs:0.49645 (r=0.354,p=0.833),  time:34.144, tt:5394.792\n",
      "Ep:158, loss:0.00000, loss_test:0.04200, lr:2.31e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.145, tt:5429.048\n",
      "Ep:159, loss:0.00000, loss_test:0.04610, lr:2.29e-02, fs:0.50704 (r=0.364,p=0.837),  time:34.140, tt:5462.467\n",
      "Ep:160, loss:0.00000, loss_test:0.04177, lr:2.26e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.136, tt:5495.841\n",
      "Ep:161, loss:0.00000, loss_test:0.04565, lr:2.24e-02, fs:0.49645 (r=0.354,p=0.833),  time:34.134, tt:5529.702\n",
      "Ep:162, loss:0.00000, loss_test:0.04278, lr:2.22e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.127, tt:5562.777\n",
      "Ep:163, loss:0.00000, loss_test:0.04542, lr:2.20e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.124, tt:5596.333\n",
      "Ep:164, loss:0.00000, loss_test:0.04327, lr:2.17e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.123, tt:5630.305\n",
      "Ep:165, loss:0.00000, loss_test:0.04442, lr:2.15e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.128, tt:5665.293\n",
      "Ep:166, loss:0.00000, loss_test:0.04421, lr:2.13e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.136, tt:5700.646\n",
      "Ep:167, loss:0.00000, loss_test:0.04385, lr:2.11e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.136, tt:5734.877\n",
      "Ep:168, loss:0.00000, loss_test:0.04608, lr:2.09e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.141, tt:5769.790\n",
      "Ep:169, loss:0.00000, loss_test:0.04169, lr:2.07e-02, fs:0.49645 (r=0.354,p=0.833),  time:34.147, tt:5804.948\n",
      "Ep:170, loss:0.00000, loss_test:0.04663, lr:2.05e-02, fs:0.47482 (r=0.333,p=0.825),  time:34.151, tt:5839.869\n",
      "Ep:171, loss:0.00000, loss_test:0.04247, lr:2.03e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.152, tt:5874.142\n",
      "Ep:172, loss:0.00000, loss_test:0.04643, lr:2.01e-02, fs:0.50704 (r=0.364,p=0.837),  time:34.156, tt:5908.976\n",
      "Ep:173, loss:0.00000, loss_test:0.04208, lr:1.99e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.154, tt:5942.785\n",
      "Ep:174, loss:0.00000, loss_test:0.04720, lr:1.97e-02, fs:0.48921 (r=0.343,p=0.850),  time:34.155, tt:5977.077\n",
      "Ep:175, loss:0.00000, loss_test:0.04225, lr:1.95e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.156, tt:6011.512\n",
      "Ep:176, loss:0.00000, loss_test:0.04755, lr:1.93e-02, fs:0.48921 (r=0.343,p=0.850),  time:34.157, tt:6045.832\n",
      "Ep:177, loss:0.00000, loss_test:0.04246, lr:1.91e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.158, tt:6080.191\n",
      "Ep:178, loss:0.00000, loss_test:0.04779, lr:1.89e-02, fs:0.53147 (r=0.384,p=0.864),  time:34.157, tt:6114.082\n",
      "Ep:179, loss:0.00000, loss_test:0.04239, lr:1.87e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.161, tt:6149.034\n",
      "Ep:180, loss:0.00000, loss_test:0.04717, lr:1.85e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.163, tt:6183.582\n",
      "Ep:181, loss:0.00000, loss_test:0.04355, lr:1.83e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.165, tt:6217.980\n",
      "Ep:182, loss:0.00000, loss_test:0.04643, lr:1.81e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.166, tt:6252.421\n",
      "Ep:183, loss:0.00000, loss_test:0.04449, lr:1.80e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.169, tt:6287.018\n",
      "Ep:184, loss:0.00000, loss_test:0.04553, lr:1.78e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.173, tt:6322.010\n",
      "Ep:185, loss:0.00000, loss_test:0.04500, lr:1.76e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.173, tt:6356.102\n",
      "Ep:186, loss:0.00000, loss_test:0.04518, lr:1.74e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.177, tt:6391.098\n",
      "Ep:187, loss:0.00000, loss_test:0.04615, lr:1.73e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.174, tt:6424.679\n",
      "Ep:188, loss:0.00000, loss_test:0.04463, lr:1.71e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.180, tt:6459.927\n",
      "Ep:189, loss:0.00000, loss_test:0.04683, lr:1.69e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.182, tt:6494.651\n",
      "Ep:190, loss:0.00000, loss_test:0.04491, lr:1.67e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.186, tt:6529.495\n",
      "Ep:191, loss:0.00000, loss_test:0.04639, lr:1.66e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.179, tt:6562.399\n",
      "Ep:192, loss:0.00000, loss_test:0.04456, lr:1.64e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.180, tt:6596.784\n",
      "Ep:193, loss:0.00000, loss_test:0.04773, lr:1.62e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.162, tt:6627.514\n",
      "Ep:194, loss:0.00000, loss_test:0.04442, lr:1.61e-02, fs:0.46377 (r=0.323,p=0.821),  time:34.130, tt:6655.299\n",
      "Ep:195, loss:0.00000, loss_test:0.04745, lr:1.59e-02, fs:0.46715 (r=0.323,p=0.842),  time:34.102, tt:6683.918\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02216, lr:6.00e-02, fs:0.58730 (r=0.747,p=0.484),  time:30.648, tt:30.648\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02259, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.293, tt:58.587\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02395, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.880, tt:89.641\n",
      "Ep:3, loss:0.00004, loss_test:0.02419, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.123, tt:120.493\n",
      "Ep:4, loss:0.00004, loss_test:0.02353, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.286, tt:151.432\n",
      "Ep:5, loss:0.00004, loss_test:0.02235, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.438, tt:182.628\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:30.804, tt:215.625\n",
      "Ep:7, loss:0.00004, loss_test:0.01996, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:31.004, tt:248.031\n",
      "Ep:8, loss:0.00004, loss_test:0.01953, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:31.101, tt:279.908\n",
      "Ep:9, loss:0.00004, loss_test:0.01954, lr:6.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:31.067, tt:310.672\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:10, loss:0.00004, loss_test:0.01947, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:31.184, tt:343.021\n",
      "Ep:11, loss:0.00003, loss_test:0.01921, lr:6.00e-02, fs:0.63673 (r=0.788,p=0.534),  time:31.127, tt:373.521\n",
      "Ep:12, loss:0.00003, loss_test:0.01902, lr:6.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:31.017, tt:403.216\n",
      "Ep:13, loss:0.00003, loss_test:0.01893, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:31.161, tt:436.256\n",
      "Ep:14, loss:0.00003, loss_test:0.01884, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:31.099, tt:466.480\n",
      "Ep:15, loss:0.00003, loss_test:0.01869, lr:6.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:31.045, tt:496.727\n",
      "Ep:16, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:31.087, tt:528.471\n",
      "Ep:17, loss:0.00003, loss_test:0.01845, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:31.129, tt:560.314\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01838, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:31.165, tt:592.139\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01825, lr:6.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:31.292, tt:625.845\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01807, lr:6.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:31.269, tt:656.645\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:31.217, tt:686.784\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01769, lr:6.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:31.142, tt:716.264\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:31.173, tt:748.141\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:31.210, tt:780.245\n",
      "Ep:25, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:31.199, tt:811.169\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01754, lr:6.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:31.177, tt:841.789\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01757, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.164, tt:872.598\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01758, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.163, tt:903.716\n",
      "Ep:29, loss:0.00002, loss_test:0.01756, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:31.093, tt:932.798\n",
      "Ep:30, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:31.089, tt:963.744\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01752, lr:6.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:31.063, tt:994.030\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01753, lr:6.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:31.036, tt:1024.199\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:31.043, tt:1055.467\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.75000 (r=0.848,p=0.672),  time:31.060, tt:1087.092\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01755, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:31.096, tt:1119.438\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:31.058, tt:1149.147\n",
      "Ep:37, loss:0.00002, loss_test:0.01751, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:31.045, tt:1179.718\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01748, lr:6.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:31.050, tt:1210.938\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01749, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:31.027, tt:1241.096\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01748, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.997, tt:1270.895\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01745, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.988, tt:1301.506\n",
      "Ep:42, loss:0.00002, loss_test:0.01744, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.963, tt:1331.388\n",
      "Ep:43, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.976, tt:1362.943\n",
      "Ep:44, loss:0.00002, loss_test:0.01747, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.974, tt:1393.811\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01747, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.953, tt:1423.847\n",
      "Ep:46, loss:0.00002, loss_test:0.01752, lr:6.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.965, tt:1455.378\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01754, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.957, tt:1485.919\n",
      "Ep:48, loss:0.00002, loss_test:0.01748, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.963, tt:1517.185\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01747, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.935, tt:1546.730\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01747, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.919, tt:1576.871\n",
      "Ep:51, loss:0.00002, loss_test:0.01745, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:30.901, tt:1606.851\n",
      "Ep:52, loss:0.00002, loss_test:0.01743, lr:6.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:30.897, tt:1637.566\n",
      "Ep:53, loss:0.00002, loss_test:0.01743, lr:6.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.901, tt:1668.649\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01745, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.888, tt:1698.838\n",
      "Ep:55, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.884, tt:1729.478\n",
      "Ep:56, loss:0.00002, loss_test:0.01746, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.857, tt:1758.826\n",
      "Ep:57, loss:0.00001, loss_test:0.01741, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.908, tt:1792.665\n",
      "Ep:58, loss:0.00001, loss_test:0.01737, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.886, tt:1822.288\n",
      "Ep:59, loss:0.00001, loss_test:0.01740, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.859, tt:1851.527\n",
      "Ep:60, loss:0.00001, loss_test:0.01737, lr:6.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.858, tt:1882.359\n",
      "Ep:61, loss:0.00001, loss_test:0.01732, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.846, tt:1912.446\n",
      "Ep:62, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:30.819, tt:1941.584\n",
      "Ep:63, loss:0.00001, loss_test:0.01728, lr:6.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:30.806, tt:1971.594\n",
      "Ep:64, loss:0.00001, loss_test:0.01728, lr:6.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.798, tt:2001.880\n",
      "Ep:65, loss:0.00001, loss_test:0.01732, lr:5.94e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.777, tt:2031.315\n",
      "Ep:66, loss:0.00001, loss_test:0.01730, lr:5.88e-02, fs:0.80203 (r=0.798,p=0.806),  time:30.766, tt:2061.319\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01730, lr:5.88e-02, fs:0.80203 (r=0.798,p=0.806),  time:30.774, tt:2092.652\n",
      "Ep:68, loss:0.00001, loss_test:0.01725, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.771, tt:2123.231\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01721, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.740, tt:2151.802\n",
      "Ep:70, loss:0.00001, loss_test:0.01719, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:30.731, tt:2181.885\n",
      "Ep:71, loss:0.00001, loss_test:0.01713, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.714, tt:2211.418\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01712, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.710, tt:2241.799\n",
      "Ep:73, loss:0.00001, loss_test:0.01709, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.683, tt:2270.510\n",
      "Ep:74, loss:0.00001, loss_test:0.01708, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.667, tt:2300.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00001, loss_test:0.01707, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.669, tt:2330.840\n",
      "Ep:76, loss:0.00001, loss_test:0.01704, lr:5.88e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.659, tt:2360.763\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01703, lr:5.88e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.647, tt:2390.487\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01698, lr:5.88e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.625, tt:2419.336\n",
      "Ep:79, loss:0.00001, loss_test:0.01694, lr:5.88e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.601, tt:2448.099\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01689, lr:5.88e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.590, tt:2477.810\n",
      "Ep:81, loss:0.00001, loss_test:0.01685, lr:5.88e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.568, tt:2506.572\n",
      "Ep:82, loss:0.00001, loss_test:0.01684, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.518, tt:2532.960\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01685, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.502, tt:2562.136\n",
      "Ep:84, loss:0.00001, loss_test:0.01683, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.486, tt:2591.324\n",
      "Ep:85, loss:0.00001, loss_test:0.01676, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.456, tt:2619.254\n",
      "Ep:86, loss:0.00001, loss_test:0.01673, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.444, tt:2648.644\n",
      "Ep:87, loss:0.00001, loss_test:0.01674, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.448, tt:2679.448\n",
      "Ep:88, loss:0.00001, loss_test:0.01669, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.446, tt:2709.703\n",
      "Ep:89, loss:0.00001, loss_test:0.01666, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.446, tt:2740.174\n",
      "Ep:90, loss:0.00001, loss_test:0.01663, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.443, tt:2770.345\n",
      "Ep:91, loss:0.00001, loss_test:0.01658, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.424, tt:2799.033\n",
      "Ep:92, loss:0.00001, loss_test:0.01658, lr:5.88e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.421, tt:2829.123\n",
      "Ep:93, loss:0.00001, loss_test:0.01661, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.403, tt:2857.914\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01659, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.401, tt:2888.073\n",
      "Ep:95, loss:0.00001, loss_test:0.01661, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.401, tt:2918.513\n",
      "Ep:96, loss:0.00001, loss_test:0.01662, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.382, tt:2947.025\n",
      "Ep:97, loss:0.00001, loss_test:0.01657, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.367, tt:2975.997\n",
      "Ep:98, loss:0.00001, loss_test:0.01653, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.345, tt:3004.156\n",
      "Ep:99, loss:0.00001, loss_test:0.01649, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.352, tt:3035.175\n",
      "Ep:100, loss:0.00001, loss_test:0.01645, lr:5.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.345, tt:3064.863\n",
      "Ep:101, loss:0.00001, loss_test:0.01644, lr:5.88e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.330, tt:3093.614\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01644, lr:5.88e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.350, tt:3126.077\n",
      "Ep:103, loss:0.00001, loss_test:0.01639, lr:5.88e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.328, tt:3154.140\n",
      "Ep:104, loss:0.00001, loss_test:0.01637, lr:5.88e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.319, tt:3183.447\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01639, lr:5.88e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.315, tt:3213.399\n",
      "Ep:106, loss:0.00001, loss_test:0.01638, lr:5.88e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.307, tt:3242.891\n",
      "Ep:107, loss:0.00001, loss_test:0.01636, lr:5.88e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.326, tt:3275.239\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01632, lr:5.88e-02, fs:0.85561 (r=0.808,p=0.909),  time:30.318, tt:3304.701\n",
      "Ep:109, loss:0.00001, loss_test:0.01634, lr:5.88e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.304, tt:3333.413\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.01633, lr:5.88e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.308, tt:3364.163\n",
      "Ep:111, loss:0.00001, loss_test:0.01634, lr:5.88e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.304, tt:3394.006\n",
      "Ep:112, loss:0.00001, loss_test:0.01633, lr:5.88e-02, fs:0.86022 (r=0.808,p=0.920),  time:30.314, tt:3425.513\n",
      "Ep:113, loss:0.00001, loss_test:0.01632, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.307, tt:3455.004\n",
      "Ep:114, loss:0.00001, loss_test:0.01631, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.302, tt:3484.778\n",
      "Ep:115, loss:0.00001, loss_test:0.01626, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.296, tt:3514.378\n",
      "Ep:116, loss:0.00001, loss_test:0.01623, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.288, tt:3543.689\n",
      "Ep:117, loss:0.00001, loss_test:0.01622, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.282, tt:3573.281\n",
      "Ep:118, loss:0.00001, loss_test:0.01626, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.282, tt:3603.524\n",
      "Ep:119, loss:0.00001, loss_test:0.01628, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.290, tt:3634.826\n",
      "Ep:120, loss:0.00001, loss_test:0.01623, lr:5.88e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.291, tt:3665.185\n",
      "Ep:121, loss:0.00001, loss_test:0.01623, lr:5.82e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.281, tt:3694.248\n",
      "Ep:122, loss:0.00001, loss_test:0.01617, lr:5.76e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.278, tt:3724.232\n",
      "Ep:123, loss:0.00001, loss_test:0.01617, lr:5.71e-02, fs:0.84783 (r=0.788,p=0.918),  time:30.285, tt:3755.381\n",
      "Ep:124, loss:0.00001, loss_test:0.01622, lr:5.65e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.285, tt:3785.615\n",
      "Ep:125, loss:0.00001, loss_test:0.01622, lr:5.59e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.283, tt:3815.658\n",
      "Ep:126, loss:0.00001, loss_test:0.01617, lr:5.54e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.282, tt:3845.875\n",
      "Ep:127, loss:0.00001, loss_test:0.01620, lr:5.48e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.279, tt:3875.737\n",
      "Ep:128, loss:0.00001, loss_test:0.01623, lr:5.43e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.282, tt:3906.364\n",
      "Ep:129, loss:0.00001, loss_test:0.01617, lr:5.37e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.290, tt:3937.678\n",
      "Ep:130, loss:0.00001, loss_test:0.01615, lr:5.32e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.288, tt:3967.725\n",
      "Ep:131, loss:0.00001, loss_test:0.01617, lr:5.27e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.290, tt:3998.332\n",
      "Ep:132, loss:0.00001, loss_test:0.01619, lr:5.21e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.286, tt:4027.985\n",
      "Ep:133, loss:0.00001, loss_test:0.01615, lr:5.16e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.283, tt:4057.964\n",
      "Ep:134, loss:0.00001, loss_test:0.01614, lr:5.11e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.282, tt:4088.099\n",
      "Ep:135, loss:0.00001, loss_test:0.01620, lr:5.06e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.275, tt:4117.415\n",
      "Ep:136, loss:0.00001, loss_test:0.01621, lr:5.01e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.259, tt:4145.449\n",
      "Ep:137, loss:0.00001, loss_test:0.01621, lr:4.96e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.262, tt:4176.149\n",
      "Ep:138, loss:0.00001, loss_test:0.01615, lr:4.91e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.263, tt:4206.500\n",
      "Ep:139, loss:0.00001, loss_test:0.01616, lr:4.86e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.257, tt:4236.035\n",
      "Ep:140, loss:0.00001, loss_test:0.01616, lr:4.81e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.264, tt:4267.166\n",
      "Ep:141, loss:0.00001, loss_test:0.01615, lr:4.76e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.263, tt:4297.386\n",
      "Ep:142, loss:0.00001, loss_test:0.01616, lr:4.71e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.264, tt:4327.789\n",
      "Ep:143, loss:0.00001, loss_test:0.01619, lr:4.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.271, tt:4359.087\n",
      "Ep:144, loss:0.00001, loss_test:0.01621, lr:4.62e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.262, tt:4387.955\n",
      "Ep:145, loss:0.00001, loss_test:0.01621, lr:4.57e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.255, tt:4417.278\n",
      "Ep:146, loss:0.00001, loss_test:0.01617, lr:4.53e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.252, tt:4447.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.01616, lr:4.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.249, tt:4476.796\n",
      "Ep:148, loss:0.00001, loss_test:0.01617, lr:4.44e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.253, tt:4507.675\n",
      "Ep:149, loss:0.00001, loss_test:0.01620, lr:4.39e-02, fs:0.82873 (r=0.758,p=0.915),  time:30.246, tt:4536.838\n",
      "Ep:150, loss:0.00001, loss_test:0.01619, lr:4.35e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.248, tt:4567.521\n",
      "Ep:151, loss:0.00001, loss_test:0.01616, lr:4.31e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.257, tt:4599.033\n",
      "Ep:152, loss:0.00001, loss_test:0.01618, lr:4.26e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.259, tt:4629.595\n",
      "Ep:153, loss:0.00001, loss_test:0.01622, lr:4.22e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.254, tt:4659.183\n",
      "Ep:154, loss:0.00000, loss_test:0.01621, lr:4.18e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.256, tt:4689.643\n",
      "Ep:155, loss:0.00000, loss_test:0.01621, lr:4.14e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.250, tt:4719.058\n",
      "Ep:156, loss:0.00000, loss_test:0.01623, lr:4.10e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.248, tt:4748.861\n",
      "Ep:157, loss:0.00000, loss_test:0.01625, lr:4.05e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.247, tt:4779.065\n",
      "Ep:158, loss:0.00000, loss_test:0.01625, lr:4.01e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.247, tt:4809.328\n",
      "Ep:159, loss:0.00000, loss_test:0.01624, lr:3.97e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.253, tt:4840.435\n",
      "Ep:160, loss:0.00000, loss_test:0.01624, lr:3.93e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.254, tt:4870.839\n",
      "Ep:161, loss:0.00000, loss_test:0.01625, lr:3.89e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.260, tt:4902.070\n",
      "Ep:162, loss:0.00000, loss_test:0.01625, lr:3.86e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.254, tt:4931.414\n",
      "Ep:163, loss:0.00000, loss_test:0.01625, lr:3.82e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.244, tt:4960.092\n",
      "Ep:164, loss:0.00000, loss_test:0.01626, lr:3.78e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.240, tt:4989.568\n",
      "Ep:165, loss:0.00000, loss_test:0.01626, lr:3.74e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.235, tt:5018.988\n",
      "Ep:166, loss:0.00000, loss_test:0.01628, lr:3.70e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.229, tt:5048.320\n",
      "Ep:167, loss:0.00000, loss_test:0.01630, lr:3.67e-02, fs:0.82222 (r=0.747,p=0.914),  time:30.225, tt:5077.791\n",
      "Ep:168, loss:0.00000, loss_test:0.01633, lr:3.63e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.222, tt:5107.518\n",
      "Ep:169, loss:0.00000, loss_test:0.01632, lr:3.59e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.228, tt:5138.781\n",
      "Ep:170, loss:0.00000, loss_test:0.01630, lr:3.56e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.219, tt:5167.427\n",
      "Ep:171, loss:0.00000, loss_test:0.01631, lr:3.52e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.213, tt:5196.679\n",
      "Ep:172, loss:0.00000, loss_test:0.01631, lr:3.49e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.211, tt:5226.471\n",
      "Ep:173, loss:0.00000, loss_test:0.01633, lr:3.45e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.203, tt:5255.306\n",
      "Ep:174, loss:0.00000, loss_test:0.01634, lr:3.42e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.202, tt:5285.365\n",
      "Ep:175, loss:0.00000, loss_test:0.01634, lr:3.38e-02, fs:0.81564 (r=0.737,p=0.912),  time:30.204, tt:5315.825\n",
      "Ep:176, loss:0.00000, loss_test:0.01633, lr:3.35e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.197, tt:5344.866\n",
      "Ep:177, loss:0.00000, loss_test:0.01634, lr:3.32e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.195, tt:5374.629\n",
      "Ep:178, loss:0.00000, loss_test:0.01637, lr:3.28e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.205, tt:5406.645\n",
      "Ep:179, loss:0.00000, loss_test:0.01635, lr:3.25e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.200, tt:5435.922\n",
      "Ep:180, loss:0.00000, loss_test:0.01637, lr:3.22e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.197, tt:5465.603\n",
      "Ep:181, loss:0.00000, loss_test:0.01639, lr:3.19e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.186, tt:5493.794\n",
      "Ep:182, loss:0.00000, loss_test:0.01637, lr:3.15e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.190, tt:5524.745\n",
      "Ep:183, loss:0.00000, loss_test:0.01639, lr:3.12e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.185, tt:5554.112\n",
      "Ep:184, loss:0.00000, loss_test:0.01639, lr:3.09e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.184, tt:5584.063\n",
      "Ep:185, loss:0.00000, loss_test:0.01640, lr:3.06e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.174, tt:5612.454\n",
      "Ep:186, loss:0.00000, loss_test:0.01639, lr:3.03e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.178, tt:5643.292\n",
      "Ep:187, loss:0.00000, loss_test:0.01642, lr:3.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.181, tt:5674.024\n",
      "Ep:188, loss:0.00000, loss_test:0.01642, lr:2.97e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.176, tt:5703.350\n",
      "Ep:189, loss:0.00000, loss_test:0.01642, lr:2.94e-02, fs:0.82022 (r=0.737,p=0.924),  time:30.173, tt:5732.845\n",
      "Ep:190, loss:0.00000, loss_test:0.01644, lr:2.91e-02, fs:0.81356 (r=0.727,p=0.923),  time:30.173, tt:5763.000\n",
      "Ep:191, loss:0.00000, loss_test:0.01646, lr:2.88e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.163, tt:5791.375\n",
      "Ep:192, loss:0.00000, loss_test:0.01646, lr:2.85e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.148, tt:5818.523\n",
      "Ep:193, loss:0.00000, loss_test:0.01647, lr:2.82e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.131, tt:5845.391\n",
      "Ep:194, loss:0.00000, loss_test:0.01646, lr:2.80e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.126, tt:5874.494\n",
      "Ep:195, loss:0.00000, loss_test:0.01648, lr:2.77e-02, fs:0.80682 (r=0.717,p=0.922),  time:30.069, tt:5893.495\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02127, lr:6.00e-02, fs:0.61765 (r=0.848,p=0.486),  time:35.942, tt:35.942\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02380, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.503, tt:75.005\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02533, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.136, tt:111.409\n",
      "Ep:3, loss:0.00005, loss_test:0.02512, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.977, tt:151.910\n",
      "Ep:4, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.167, tt:190.837\n",
      "Ep:5, loss:0.00004, loss_test:0.02193, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:38.450, tt:230.698\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02028, lr:6.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:38.518, tt:269.623\n",
      "Ep:7, loss:0.00004, loss_test:0.01950, lr:6.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:38.428, tt:307.426\n",
      "Ep:8, loss:0.00004, loss_test:0.01935, lr:6.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:38.415, tt:345.732\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01918, lr:6.00e-02, fs:0.67227 (r=0.808,p=0.576),  time:38.246, tt:382.456\n",
      "Ep:10, loss:0.00004, loss_test:0.01891, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:38.245, tt:420.692\n",
      "Ep:11, loss:0.00003, loss_test:0.01881, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:38.317, tt:459.807\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01862, lr:6.00e-02, fs:0.69373 (r=0.949,p=0.547),  time:38.454, tt:499.907\n",
      "Ep:13, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:38.445, tt:538.227\n",
      "Ep:14, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:38.454, tt:576.815\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.73896 (r=0.929,p=0.613),  time:38.514, tt:616.223\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.73469 (r=0.909,p=0.616),  time:38.532, tt:655.036\n",
      "Ep:17, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:38.658, tt:695.848\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:38.720, tt:735.671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:38.715, tt:774.291\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01562, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:38.744, tt:813.617\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01544, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:38.686, tt:851.092\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.75862 (r=0.889,p=0.662),  time:38.689, tt:889.840\n",
      "Ep:23, loss:0.00002, loss_test:0.01524, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:38.679, tt:928.302\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:38.717, tt:967.925\n",
      "Ep:25, loss:0.00002, loss_test:0.01507, lr:6.00e-02, fs:0.77056 (r=0.899,p=0.674),  time:38.737, tt:1007.165\n",
      "Ep:26, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:38.773, tt:1046.876\n",
      "Ep:27, loss:0.00002, loss_test:0.01490, lr:6.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:38.784, tt:1085.942\n",
      "Ep:28, loss:0.00002, loss_test:0.01487, lr:6.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:38.807, tt:1125.390\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01482, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:38.786, tt:1163.590\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01473, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:38.738, tt:1200.885\n",
      "Ep:31, loss:0.00002, loss_test:0.01467, lr:6.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:38.689, tt:1238.045\n",
      "Ep:32, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:38.719, tt:1277.737\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:38.747, tt:1317.412\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01455, lr:6.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:38.742, tt:1355.968\n",
      "Ep:35, loss:0.00002, loss_test:0.01455, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.801, tt:1396.827\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01456, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.761, tt:1434.168\n",
      "Ep:37, loss:0.00002, loss_test:0.01455, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.797, tt:1474.291\n",
      "Ep:38, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.772, tt:1512.095\n",
      "Ep:39, loss:0.00002, loss_test:0.01453, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.743, tt:1549.735\n",
      "Ep:40, loss:0.00002, loss_test:0.01454, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:38.768, tt:1589.502\n",
      "Ep:41, loss:0.00002, loss_test:0.01450, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:38.811, tt:1630.081\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.822, tt:1669.364\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.792, tt:1706.839\n",
      "Ep:44, loss:0.00001, loss_test:0.01444, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.780, tt:1745.090\n",
      "Ep:45, loss:0.00001, loss_test:0.01442, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.764, tt:1783.141\n",
      "Ep:46, loss:0.00001, loss_test:0.01441, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:38.779, tt:1822.612\n",
      "Ep:47, loss:0.00001, loss_test:0.01445, lr:6.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:38.749, tt:1859.931\n",
      "Ep:48, loss:0.00001, loss_test:0.01449, lr:6.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:38.738, tt:1898.158\n",
      "Ep:49, loss:0.00001, loss_test:0.01450, lr:6.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:38.707, tt:1935.353\n",
      "Ep:50, loss:0.00001, loss_test:0.01448, lr:6.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:38.676, tt:1972.472\n",
      "Ep:51, loss:0.00001, loss_test:0.01447, lr:6.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:38.622, tt:2008.337\n",
      "Ep:52, loss:0.00001, loss_test:0.01453, lr:6.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:38.626, tt:2047.179\n",
      "Ep:53, loss:0.00001, loss_test:0.01455, lr:6.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:38.615, tt:2085.211\n",
      "Ep:54, loss:0.00001, loss_test:0.01456, lr:5.94e-02, fs:0.80000 (r=0.788,p=0.812),  time:38.601, tt:2123.030\n",
      "Ep:55, loss:0.00001, loss_test:0.01454, lr:5.88e-02, fs:0.80000 (r=0.788,p=0.812),  time:38.651, tt:2164.483\n",
      "Ep:56, loss:0.00001, loss_test:0.01452, lr:5.82e-02, fs:0.80000 (r=0.788,p=0.812),  time:38.645, tt:2202.769\n",
      "Ep:57, loss:0.00001, loss_test:0.01454, lr:5.76e-02, fs:0.81026 (r=0.798,p=0.823),  time:38.615, tt:2239.685\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01455, lr:5.76e-02, fs:0.81026 (r=0.798,p=0.823),  time:38.600, tt:2277.381\n",
      "Ep:59, loss:0.00001, loss_test:0.01461, lr:5.76e-02, fs:0.80412 (r=0.788,p=0.821),  time:38.581, tt:2314.860\n",
      "Ep:60, loss:0.00001, loss_test:0.01469, lr:5.76e-02, fs:0.80412 (r=0.788,p=0.821),  time:38.569, tt:2352.684\n",
      "Ep:61, loss:0.00001, loss_test:0.01473, lr:5.76e-02, fs:0.80208 (r=0.778,p=0.828),  time:38.554, tt:2390.356\n",
      "Ep:62, loss:0.00001, loss_test:0.01471, lr:5.76e-02, fs:0.80208 (r=0.778,p=0.828),  time:38.532, tt:2427.494\n",
      "Ep:63, loss:0.00001, loss_test:0.01470, lr:5.76e-02, fs:0.80208 (r=0.778,p=0.828),  time:38.507, tt:2464.421\n",
      "Ep:64, loss:0.00001, loss_test:0.01477, lr:5.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:38.491, tt:2501.924\n",
      "Ep:65, loss:0.00001, loss_test:0.01484, lr:5.76e-02, fs:0.80628 (r=0.778,p=0.837),  time:38.455, tt:2538.020\n",
      "Ep:66, loss:0.00001, loss_test:0.01486, lr:5.76e-02, fs:0.80423 (r=0.768,p=0.844),  time:38.466, tt:2577.198\n",
      "Ep:67, loss:0.00001, loss_test:0.01491, lr:5.76e-02, fs:0.81481 (r=0.778,p=0.856),  time:38.466, tt:2615.705\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01492, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.462, tt:2653.883\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01497, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.453, tt:2691.698\n",
      "Ep:70, loss:0.00001, loss_test:0.01500, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.429, tt:2728.442\n",
      "Ep:71, loss:0.00001, loss_test:0.01508, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.404, tt:2765.105\n",
      "Ep:72, loss:0.00001, loss_test:0.01513, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.406, tt:2803.641\n",
      "Ep:73, loss:0.00001, loss_test:0.01517, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.411, tt:2842.393\n",
      "Ep:74, loss:0.00001, loss_test:0.01528, lr:5.76e-02, fs:0.81283 (r=0.768,p=0.864),  time:38.411, tt:2880.804\n",
      "Ep:75, loss:0.00001, loss_test:0.01525, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.379, tt:2916.775\n",
      "Ep:76, loss:0.00001, loss_test:0.01524, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.376, tt:2954.977\n",
      "Ep:77, loss:0.00001, loss_test:0.01531, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.365, tt:2992.451\n",
      "Ep:78, loss:0.00001, loss_test:0.01532, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.357, tt:3030.221\n",
      "Ep:79, loss:0.00001, loss_test:0.01532, lr:5.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:38.346, tt:3067.661\n",
      "Ep:80, loss:0.00001, loss_test:0.01543, lr:5.71e-02, fs:0.82353 (r=0.778,p=0.875),  time:38.319, tt:3103.844\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01555, lr:5.71e-02, fs:0.81720 (r=0.768,p=0.874),  time:38.309, tt:3141.374\n",
      "Ep:82, loss:0.00001, loss_test:0.01554, lr:5.71e-02, fs:0.83243 (r=0.778,p=0.895),  time:38.312, tt:3179.877\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01564, lr:5.71e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.306, tt:3217.697\n",
      "Ep:84, loss:0.00001, loss_test:0.01571, lr:5.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:38.296, tt:3255.135\n",
      "Ep:85, loss:0.00001, loss_test:0.01562, lr:5.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:38.296, tt:3293.480\n",
      "Ep:86, loss:0.00001, loss_test:0.01566, lr:5.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:38.304, tt:3332.459\n",
      "Ep:87, loss:0.00001, loss_test:0.01566, lr:5.71e-02, fs:0.83696 (r=0.778,p=0.906),  time:38.309, tt:3371.207\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:88, loss:0.00001, loss_test:0.01572, lr:5.71e-02, fs:0.83696 (r=0.778,p=0.906),  time:38.303, tt:3408.969\n",
      "Ep:89, loss:0.00001, loss_test:0.01576, lr:5.71e-02, fs:0.84153 (r=0.778,p=0.917),  time:38.297, tt:3446.765\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01589, lr:5.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:38.300, tt:3485.341\n",
      "Ep:91, loss:0.00001, loss_test:0.01592, lr:5.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:38.305, tt:3524.040\n",
      "Ep:92, loss:0.00001, loss_test:0.01593, lr:5.71e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.310, tt:3562.808\n",
      "Ep:93, loss:0.00001, loss_test:0.01607, lr:5.71e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.293, tt:3599.526\n",
      "Ep:94, loss:0.00001, loss_test:0.01612, lr:5.71e-02, fs:0.83333 (r=0.758,p=0.926),  time:38.302, tt:3638.686\n",
      "Ep:95, loss:0.00001, loss_test:0.01620, lr:5.71e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.312, tt:3677.989\n",
      "Ep:96, loss:0.00001, loss_test:0.01623, lr:5.71e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.317, tt:3716.757\n",
      "Ep:97, loss:0.00001, loss_test:0.01632, lr:5.71e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.313, tt:3754.693\n",
      "Ep:98, loss:0.00001, loss_test:0.01636, lr:5.71e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.310, tt:3792.689\n",
      "Ep:99, loss:0.00001, loss_test:0.01636, lr:5.71e-02, fs:0.82022 (r=0.737,p=0.924),  time:38.302, tt:3830.216\n",
      "Ep:100, loss:0.00001, loss_test:0.01649, lr:5.71e-02, fs:0.82022 (r=0.737,p=0.924),  time:38.300, tt:3868.262\n",
      "Ep:101, loss:0.00001, loss_test:0.01659, lr:5.65e-02, fs:0.81356 (r=0.727,p=0.923),  time:38.302, tt:3906.841\n",
      "Ep:102, loss:0.00001, loss_test:0.01662, lr:5.59e-02, fs:0.80682 (r=0.717,p=0.922),  time:38.315, tt:3946.419\n",
      "Ep:103, loss:0.00001, loss_test:0.01673, lr:5.54e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.330, tt:3986.334\n",
      "Ep:104, loss:0.00001, loss_test:0.01693, lr:5.48e-02, fs:0.79310 (r=0.697,p=0.920),  time:38.341, tt:4025.794\n",
      "Ep:105, loss:0.00000, loss_test:0.01696, lr:5.43e-02, fs:0.79310 (r=0.697,p=0.920),  time:38.341, tt:4064.137\n",
      "Ep:106, loss:0.00000, loss_test:0.01687, lr:5.37e-02, fs:0.80000 (r=0.707,p=0.921),  time:38.350, tt:4103.412\n",
      "Ep:107, loss:0.00000, loss_test:0.01702, lr:5.32e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.360, tt:4142.843\n",
      "Ep:108, loss:0.00000, loss_test:0.01711, lr:5.27e-02, fs:0.79769 (r=0.697,p=0.932),  time:38.363, tt:4181.570\n",
      "Ep:109, loss:0.00000, loss_test:0.01710, lr:5.21e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.376, tt:4221.400\n",
      "Ep:110, loss:0.00000, loss_test:0.01723, lr:5.16e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.367, tt:4258.771\n",
      "Ep:111, loss:0.00000, loss_test:0.01730, lr:5.11e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.369, tt:4297.345\n",
      "Ep:112, loss:0.00000, loss_test:0.01736, lr:5.06e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.373, tt:4336.153\n",
      "Ep:113, loss:0.00000, loss_test:0.01745, lr:5.01e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.381, tt:4375.441\n",
      "Ep:114, loss:0.00000, loss_test:0.01758, lr:4.96e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.398, tt:4415.739\n",
      "Ep:115, loss:0.00000, loss_test:0.01754, lr:4.91e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.391, tt:4453.342\n",
      "Ep:116, loss:0.00000, loss_test:0.01762, lr:4.86e-02, fs:0.79532 (r=0.687,p=0.944),  time:38.390, tt:4491.613\n",
      "Ep:117, loss:0.00000, loss_test:0.01774, lr:4.81e-02, fs:0.78824 (r=0.677,p=0.944),  time:38.382, tt:4529.045\n",
      "Ep:118, loss:0.00000, loss_test:0.01775, lr:4.76e-02, fs:0.78824 (r=0.677,p=0.944),  time:38.397, tt:4569.260\n",
      "Ep:119, loss:0.00000, loss_test:0.01782, lr:4.71e-02, fs:0.78824 (r=0.677,p=0.944),  time:38.403, tt:4608.336\n",
      "Ep:120, loss:0.00000, loss_test:0.01793, lr:4.67e-02, fs:0.78824 (r=0.677,p=0.944),  time:38.407, tt:4647.215\n",
      "Ep:121, loss:0.00000, loss_test:0.01794, lr:4.62e-02, fs:0.78824 (r=0.677,p=0.944),  time:38.418, tt:4686.986\n",
      "Ep:122, loss:0.00000, loss_test:0.01803, lr:4.57e-02, fs:0.78571 (r=0.667,p=0.957),  time:38.417, tt:4725.325\n",
      "Ep:123, loss:0.00000, loss_test:0.01815, lr:4.53e-02, fs:0.78571 (r=0.667,p=0.957),  time:38.419, tt:4763.912\n",
      "Ep:124, loss:0.00000, loss_test:0.01813, lr:4.48e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.422, tt:4802.784\n",
      "Ep:125, loss:0.00000, loss_test:0.01820, lr:4.44e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.423, tt:4841.267\n",
      "Ep:126, loss:0.00000, loss_test:0.01828, lr:4.39e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.427, tt:4880.258\n",
      "Ep:127, loss:0.00000, loss_test:0.01839, lr:4.35e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.417, tt:4917.359\n",
      "Ep:128, loss:0.00000, loss_test:0.01840, lr:4.31e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.417, tt:4955.749\n",
      "Ep:129, loss:0.00000, loss_test:0.01841, lr:4.26e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.415, tt:4993.909\n",
      "Ep:130, loss:0.00000, loss_test:0.01849, lr:4.22e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.412, tt:5031.963\n",
      "Ep:131, loss:0.00000, loss_test:0.01854, lr:4.18e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.406, tt:5069.631\n",
      "Ep:132, loss:0.00000, loss_test:0.01859, lr:4.14e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.413, tt:5108.913\n",
      "Ep:133, loss:0.00000, loss_test:0.01867, lr:4.10e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.404, tt:5146.092\n",
      "Ep:134, loss:0.00000, loss_test:0.01873, lr:4.05e-02, fs:0.77844 (r=0.657,p=0.956),  time:38.410, tt:5185.410\n",
      "Ep:135, loss:0.00000, loss_test:0.01875, lr:4.01e-02, fs:0.77108 (r=0.646,p=0.955),  time:38.417, tt:5224.698\n",
      "Ep:136, loss:0.00000, loss_test:0.01879, lr:3.97e-02, fs:0.77108 (r=0.646,p=0.955),  time:38.411, tt:5262.325\n",
      "Ep:137, loss:0.00000, loss_test:0.01895, lr:3.93e-02, fs:0.77108 (r=0.646,p=0.955),  time:38.409, tt:5300.396\n",
      "Ep:138, loss:0.00000, loss_test:0.01901, lr:3.89e-02, fs:0.76364 (r=0.636,p=0.955),  time:38.409, tt:5338.870\n",
      "Ep:139, loss:0.00000, loss_test:0.01900, lr:3.86e-02, fs:0.77108 (r=0.646,p=0.955),  time:38.414, tt:5377.894\n",
      "Ep:140, loss:0.00000, loss_test:0.01904, lr:3.82e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.424, tt:5417.793\n",
      "Ep:141, loss:0.00000, loss_test:0.01913, lr:3.78e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.438, tt:5458.251\n",
      "Ep:142, loss:0.00000, loss_test:0.01917, lr:3.74e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.422, tt:5494.350\n",
      "Ep:143, loss:0.00000, loss_test:0.01920, lr:3.70e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.420, tt:5532.460\n",
      "Ep:144, loss:0.00000, loss_test:0.01928, lr:3.67e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.423, tt:5571.369\n",
      "Ep:145, loss:0.00000, loss_test:0.01931, lr:3.63e-02, fs:0.75610 (r=0.626,p=0.954),  time:38.428, tt:5610.483\n",
      "Ep:146, loss:0.00000, loss_test:0.01938, lr:3.59e-02, fs:0.74847 (r=0.616,p=0.953),  time:38.429, tt:5648.998\n",
      "Ep:147, loss:0.00000, loss_test:0.01945, lr:3.56e-02, fs:0.74847 (r=0.616,p=0.953),  time:38.422, tt:5686.508\n",
      "Ep:148, loss:0.00000, loss_test:0.01945, lr:3.52e-02, fs:0.74847 (r=0.616,p=0.953),  time:38.430, tt:5726.061\n",
      "Ep:149, loss:0.00000, loss_test:0.01950, lr:3.49e-02, fs:0.74074 (r=0.606,p=0.952),  time:38.424, tt:5763.572\n",
      "Ep:150, loss:0.00000, loss_test:0.01955, lr:3.45e-02, fs:0.74074 (r=0.606,p=0.952),  time:38.438, tt:5804.167\n",
      "Ep:151, loss:0.00000, loss_test:0.01958, lr:3.42e-02, fs:0.74847 (r=0.616,p=0.953),  time:38.440, tt:5842.938\n",
      "Ep:152, loss:0.00000, loss_test:0.01962, lr:3.38e-02, fs:0.74074 (r=0.606,p=0.952),  time:38.446, tt:5882.229\n",
      "Ep:153, loss:0.00000, loss_test:0.01966, lr:3.35e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.442, tt:5920.136\n",
      "Ep:154, loss:0.00000, loss_test:0.01970, lr:3.32e-02, fs:0.74074 (r=0.606,p=0.952),  time:38.458, tt:5960.915\n",
      "Ep:155, loss:0.00000, loss_test:0.01973, lr:3.28e-02, fs:0.73292 (r=0.596,p=0.952),  time:38.464, tt:6000.322\n",
      "Ep:156, loss:0.00000, loss_test:0.01980, lr:3.25e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.450, tt:6036.686\n",
      "Ep:157, loss:0.00000, loss_test:0.01981, lr:3.22e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.457, tt:6076.201\n",
      "Ep:158, loss:0.00000, loss_test:0.01983, lr:3.19e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.468, tt:6116.444\n",
      "Ep:159, loss:0.00000, loss_test:0.01988, lr:3.15e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.473, tt:6155.719\n",
      "Ep:160, loss:0.00000, loss_test:0.01992, lr:3.12e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.480, tt:6195.273\n",
      "Ep:161, loss:0.00000, loss_test:0.01999, lr:3.09e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.480, tt:6233.837\n",
      "Ep:162, loss:0.00000, loss_test:0.02001, lr:3.06e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.487, tt:6273.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00000, loss_test:0.02003, lr:3.03e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.478, tt:6310.391\n",
      "Ep:164, loss:0.00000, loss_test:0.02011, lr:3.00e-02, fs:0.72500 (r=0.586,p=0.951),  time:38.478, tt:6348.914\n",
      "Ep:165, loss:0.00000, loss_test:0.02014, lr:2.97e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.478, tt:6387.304\n",
      "Ep:166, loss:0.00000, loss_test:0.02015, lr:2.94e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.476, tt:6425.430\n",
      "Ep:167, loss:0.00000, loss_test:0.02017, lr:2.91e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.469, tt:6462.869\n",
      "Ep:168, loss:0.00000, loss_test:0.02020, lr:2.88e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.462, tt:6500.050\n",
      "Ep:169, loss:0.00000, loss_test:0.02025, lr:2.85e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.458, tt:6537.805\n",
      "Ep:170, loss:0.00000, loss_test:0.02025, lr:2.82e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.445, tt:6574.025\n",
      "Ep:171, loss:0.00000, loss_test:0.02025, lr:2.80e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.442, tt:6612.075\n",
      "Ep:172, loss:0.00000, loss_test:0.02028, lr:2.77e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.447, tt:6651.286\n",
      "Ep:173, loss:0.00000, loss_test:0.02036, lr:2.74e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.445, tt:6689.381\n",
      "Ep:174, loss:0.00000, loss_test:0.02039, lr:2.71e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.434, tt:6725.985\n",
      "Ep:175, loss:0.00000, loss_test:0.02041, lr:2.69e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.434, tt:6764.384\n",
      "Ep:176, loss:0.00000, loss_test:0.02046, lr:2.66e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.428, tt:6801.668\n",
      "Ep:177, loss:0.00000, loss_test:0.02048, lr:2.63e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.425, tt:6839.739\n",
      "Ep:178, loss:0.00000, loss_test:0.02049, lr:2.61e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.422, tt:6877.582\n",
      "Ep:179, loss:0.00000, loss_test:0.02054, lr:2.58e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.415, tt:6914.773\n",
      "Ep:180, loss:0.00000, loss_test:0.02058, lr:2.55e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.399, tt:6950.224\n",
      "Ep:181, loss:0.00000, loss_test:0.02061, lr:2.53e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.408, tt:6990.283\n",
      "Ep:182, loss:0.00000, loss_test:0.02064, lr:2.50e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.402, tt:7027.614\n",
      "Ep:183, loss:0.00000, loss_test:0.02064, lr:2.48e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.395, tt:7064.710\n",
      "Ep:184, loss:0.00000, loss_test:0.02067, lr:2.45e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.388, tt:7101.723\n",
      "Ep:185, loss:0.00000, loss_test:0.02073, lr:2.43e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.384, tt:7139.498\n",
      "Ep:186, loss:0.00000, loss_test:0.02075, lr:2.40e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.389, tt:7178.673\n",
      "Ep:187, loss:0.00000, loss_test:0.02077, lr:2.38e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.383, tt:7216.032\n",
      "Ep:188, loss:0.00000, loss_test:0.02078, lr:2.36e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.378, tt:7253.416\n",
      "Ep:189, loss:0.00000, loss_test:0.02082, lr:2.33e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.371, tt:7290.411\n",
      "Ep:190, loss:0.00000, loss_test:0.02086, lr:2.31e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.367, tt:7328.045\n",
      "Ep:191, loss:0.00000, loss_test:0.02088, lr:2.29e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.347, tt:7362.687\n",
      "Ep:192, loss:0.00000, loss_test:0.02087, lr:2.26e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.347, tt:7401.009\n",
      "Ep:193, loss:0.00000, loss_test:0.02088, lr:2.24e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.342, tt:7438.333\n",
      "Ep:194, loss:0.00000, loss_test:0.02092, lr:2.22e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.322, tt:7472.803\n",
      "Ep:195, loss:0.00000, loss_test:0.02096, lr:2.20e-02, fs:0.71698 (r=0.576,p=0.950),  time:38.284, tt:7503.623\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02273, lr:6.00e-02, fs:0.61993 (r=0.848,p=0.488),  time:31.505, tt:31.505\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02601, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:32.901, tt:65.803\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02785, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.297, tt:96.892\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02817, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.921, tt:131.685\n",
      "Ep:4, loss:0.00005, loss_test:0.02754, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.958, tt:164.789\n",
      "Ep:5, loss:0.00005, loss_test:0.02626, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:33.240, tt:199.441\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02447, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:33.251, tt:232.755\n",
      "Ep:7, loss:0.00005, loss_test:0.02257, lr:6.00e-02, fs:0.65018 (r=0.929,p=0.500),  time:33.183, tt:265.465\n",
      "Ep:8, loss:0.00004, loss_test:0.02129, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:33.323, tt:299.906\n",
      "Ep:9, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:33.242, tt:332.417\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02092, lr:6.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:33.383, tt:367.215\n",
      "Ep:11, loss:0.00004, loss_test:0.02093, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:33.378, tt:400.530\n",
      "Ep:12, loss:0.00004, loss_test:0.02089, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:33.384, tt:433.989\n",
      "Ep:13, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.64885 (r=0.859,p=0.521),  time:33.236, tt:465.308\n",
      "Ep:14, loss:0.00004, loss_test:0.02043, lr:6.00e-02, fs:0.64591 (r=0.838,p=0.525),  time:33.244, tt:498.663\n",
      "Ep:15, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.63780 (r=0.818,p=0.523),  time:33.428, tt:534.850\n",
      "Ep:16, loss:0.00003, loss_test:0.02001, lr:6.00e-02, fs:0.65060 (r=0.818,p=0.540),  time:33.548, tt:570.313\n",
      "Ep:17, loss:0.00003, loss_test:0.01982, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:33.556, tt:604.006\n",
      "Ep:18, loss:0.00003, loss_test:0.01960, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:33.635, tt:639.059\n",
      "Ep:19, loss:0.00003, loss_test:0.01931, lr:6.00e-02, fs:0.67220 (r=0.818,p=0.570),  time:33.651, tt:673.022\n",
      "Ep:20, loss:0.00003, loss_test:0.01899, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:33.627, tt:706.161\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01872, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:33.614, tt:739.505\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01858, lr:6.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:33.524, tt:771.046\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01842, lr:6.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:33.599, tt:806.367\n",
      "Ep:24, loss:0.00003, loss_test:0.01825, lr:6.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:33.596, tt:839.906\n",
      "Ep:25, loss:0.00003, loss_test:0.01812, lr:6.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:33.573, tt:872.888\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01800, lr:6.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:33.585, tt:906.797\n",
      "Ep:27, loss:0.00003, loss_test:0.01788, lr:6.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:33.627, tt:941.569\n",
      "Ep:28, loss:0.00003, loss_test:0.01780, lr:6.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:33.670, tt:976.435\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:33.693, tt:1010.776\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01757, lr:6.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:33.703, tt:1044.778\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01748, lr:6.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:33.724, tt:1079.177\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01752, lr:6.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:33.778, tt:1114.685\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:33, loss:0.00002, loss_test:0.01766, lr:6.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:33.816, tt:1149.740\n",
      "Ep:34, loss:0.00002, loss_test:0.01769, lr:6.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:33.842, tt:1184.470\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01767, lr:6.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:33.851, tt:1218.627\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01774, lr:6.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:33.886, tt:1253.782\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01781, lr:6.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:33.957, tt:1290.355\n",
      "Ep:38, loss:0.00002, loss_test:0.01791, lr:6.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:34.006, tt:1326.215\n",
      "Ep:39, loss:0.00002, loss_test:0.01800, lr:6.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:34.046, tt:1361.842\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01810, lr:6.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:34.107, tt:1398.387\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01815, lr:6.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:34.126, tt:1433.303\n",
      "Ep:42, loss:0.00002, loss_test:0.01809, lr:6.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:34.148, tt:1468.360\n",
      "Ep:43, loss:0.00002, loss_test:0.01809, lr:6.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:34.151, tt:1502.631\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01813, lr:6.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:34.149, tt:1536.692\n",
      "Ep:45, loss:0.00002, loss_test:0.01813, lr:6.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:34.186, tt:1572.571\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01803, lr:6.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:34.220, tt:1608.331\n",
      "Ep:47, loss:0.00001, loss_test:0.01805, lr:6.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:34.253, tt:1644.131\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.261, tt:1678.807\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01807, lr:6.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.282, tt:1714.082\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01812, lr:6.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.300, tt:1749.313\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.325, tt:1784.900\n",
      "Ep:52, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:34.353, tt:1820.724\n",
      "Ep:53, loss:0.00001, loss_test:0.01823, lr:6.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:34.379, tt:1856.471\n",
      "Ep:54, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.405, tt:1892.271\n",
      "Ep:55, loss:0.00001, loss_test:0.01823, lr:6.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:34.428, tt:1927.957\n",
      "Ep:56, loss:0.00001, loss_test:0.01821, lr:6.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:34.427, tt:1962.340\n",
      "Ep:57, loss:0.00001, loss_test:0.01825, lr:6.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:34.414, tt:1996.002\n",
      "Ep:58, loss:0.00001, loss_test:0.01829, lr:6.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:34.457, tt:2032.957\n",
      "Ep:59, loss:0.00001, loss_test:0.01831, lr:6.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:34.506, tt:2070.348\n",
      "Ep:60, loss:0.00001, loss_test:0.01842, lr:6.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.526, tt:2106.059\n",
      "Ep:61, loss:0.00001, loss_test:0.01847, lr:6.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.567, tt:2143.158\n",
      "Ep:62, loss:0.00001, loss_test:0.01851, lr:5.94e-02, fs:0.76087 (r=0.707,p=0.824),  time:34.589, tt:2179.102\n",
      "Ep:63, loss:0.00001, loss_test:0.01867, lr:5.88e-02, fs:0.74725 (r=0.687,p=0.819),  time:34.609, tt:2214.976\n",
      "Ep:64, loss:0.00001, loss_test:0.01885, lr:5.82e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.622, tt:2250.447\n",
      "Ep:65, loss:0.00001, loss_test:0.01879, lr:5.76e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.635, tt:2285.892\n",
      "Ep:66, loss:0.00001, loss_test:0.01900, lr:5.71e-02, fs:0.75281 (r=0.677,p=0.848),  time:34.660, tt:2322.220\n",
      "Ep:67, loss:0.00001, loss_test:0.01919, lr:5.65e-02, fs:0.74576 (r=0.667,p=0.846),  time:34.690, tt:2358.940\n",
      "Ep:68, loss:0.00001, loss_test:0.01899, lr:5.59e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.685, tt:2393.288\n",
      "Ep:69, loss:0.00001, loss_test:0.01934, lr:5.54e-02, fs:0.75281 (r=0.677,p=0.848),  time:34.692, tt:2428.432\n",
      "Ep:70, loss:0.00001, loss_test:0.01924, lr:5.48e-02, fs:0.73864 (r=0.657,p=0.844),  time:34.712, tt:2464.576\n",
      "Ep:71, loss:0.00001, loss_test:0.01937, lr:5.43e-02, fs:0.72414 (r=0.636,p=0.840),  time:34.730, tt:2500.595\n",
      "Ep:72, loss:0.00001, loss_test:0.01954, lr:5.37e-02, fs:0.73143 (r=0.646,p=0.842),  time:34.737, tt:2535.805\n",
      "Ep:73, loss:0.00001, loss_test:0.01948, lr:5.32e-02, fs:0.70930 (r=0.616,p=0.836),  time:34.761, tt:2572.328\n",
      "Ep:74, loss:0.00001, loss_test:0.01957, lr:5.27e-02, fs:0.71345 (r=0.616,p=0.847),  time:34.746, tt:2605.948\n",
      "Ep:75, loss:0.00001, loss_test:0.01969, lr:5.21e-02, fs:0.73256 (r=0.636,p=0.863),  time:34.757, tt:2641.533\n",
      "Ep:76, loss:0.00001, loss_test:0.01964, lr:5.16e-02, fs:0.70303 (r=0.586,p=0.879),  time:34.788, tt:2678.664\n",
      "Ep:77, loss:0.00001, loss_test:0.01994, lr:5.11e-02, fs:0.68675 (r=0.576,p=0.851),  time:34.813, tt:2715.387\n",
      "Ep:78, loss:0.00001, loss_test:0.01979, lr:5.06e-02, fs:0.67485 (r=0.556,p=0.859),  time:34.825, tt:2751.199\n",
      "Ep:79, loss:0.00001, loss_test:0.01998, lr:5.01e-02, fs:0.67485 (r=0.556,p=0.859),  time:34.840, tt:2787.187\n",
      "Ep:80, loss:0.00001, loss_test:0.02022, lr:4.96e-02, fs:0.66667 (r=0.545,p=0.857),  time:34.844, tt:2822.338\n",
      "Ep:81, loss:0.00001, loss_test:0.02004, lr:4.91e-02, fs:0.66667 (r=0.545,p=0.857),  time:34.855, tt:2858.133\n",
      "Ep:82, loss:0.00001, loss_test:0.02028, lr:4.86e-02, fs:0.66667 (r=0.545,p=0.857),  time:34.848, tt:2892.425\n",
      "Ep:83, loss:0.00001, loss_test:0.02028, lr:4.81e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.853, tt:2927.641\n",
      "Ep:84, loss:0.00001, loss_test:0.02034, lr:4.76e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.863, tt:2963.360\n",
      "Ep:85, loss:0.00001, loss_test:0.02047, lr:4.71e-02, fs:0.66250 (r=0.535,p=0.869),  time:34.889, tt:3000.476\n",
      "Ep:86, loss:0.00001, loss_test:0.02048, lr:4.67e-02, fs:0.65409 (r=0.525,p=0.867),  time:34.887, tt:3035.190\n",
      "Ep:87, loss:0.00001, loss_test:0.02054, lr:4.62e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.904, tt:3071.581\n",
      "Ep:88, loss:0.00001, loss_test:0.02050, lr:4.57e-02, fs:0.64968 (r=0.515,p=0.879),  time:34.923, tt:3108.127\n",
      "Ep:89, loss:0.00001, loss_test:0.02075, lr:4.53e-02, fs:0.64557 (r=0.515,p=0.864),  time:34.936, tt:3144.231\n",
      "Ep:90, loss:0.00001, loss_test:0.02071, lr:4.48e-02, fs:0.65385 (r=0.515,p=0.895),  time:34.935, tt:3179.041\n",
      "Ep:91, loss:0.00001, loss_test:0.02077, lr:4.44e-02, fs:0.65385 (r=0.515,p=0.895),  time:34.935, tt:3213.984\n",
      "Ep:92, loss:0.00001, loss_test:0.02092, lr:4.39e-02, fs:0.65385 (r=0.515,p=0.895),  time:34.936, tt:3249.063\n",
      "Ep:93, loss:0.00001, loss_test:0.02083, lr:4.35e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.935, tt:3283.885\n",
      "Ep:94, loss:0.00001, loss_test:0.02110, lr:4.31e-02, fs:0.65385 (r=0.515,p=0.895),  time:34.957, tt:3320.941\n",
      "Ep:95, loss:0.00001, loss_test:0.02098, lr:4.26e-02, fs:0.66234 (r=0.515,p=0.927),  time:34.978, tt:3357.919\n",
      "Ep:96, loss:0.00001, loss_test:0.02122, lr:4.22e-02, fs:0.65385 (r=0.515,p=0.895),  time:34.984, tt:3393.417\n",
      "Ep:97, loss:0.00001, loss_test:0.02133, lr:4.18e-02, fs:0.65806 (r=0.515,p=0.911),  time:34.996, tt:3429.608\n",
      "Ep:98, loss:0.00001, loss_test:0.02126, lr:4.14e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.003, tt:3465.307\n",
      "Ep:99, loss:0.00001, loss_test:0.02156, lr:4.10e-02, fs:0.65385 (r=0.515,p=0.895),  time:35.025, tt:3502.494\n",
      "Ep:100, loss:0.00001, loss_test:0.02146, lr:4.05e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.031, tt:3538.144\n",
      "Ep:101, loss:0.00001, loss_test:0.02164, lr:4.01e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.012, tt:3571.223\n",
      "Ep:102, loss:0.00001, loss_test:0.02174, lr:3.97e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.027, tt:3607.753\n",
      "Ep:103, loss:0.00001, loss_test:0.02175, lr:3.93e-02, fs:0.66234 (r=0.515,p=0.927),  time:35.043, tt:3644.452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00001, loss_test:0.02190, lr:3.89e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.041, tt:3679.322\n",
      "Ep:105, loss:0.00001, loss_test:0.02190, lr:3.86e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.051, tt:3715.423\n",
      "Ep:106, loss:0.00000, loss_test:0.02188, lr:3.82e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.052, tt:3750.574\n",
      "Ep:107, loss:0.00000, loss_test:0.02207, lr:3.78e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.063, tt:3786.765\n",
      "Ep:108, loss:0.00000, loss_test:0.02202, lr:3.74e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.079, tt:3823.593\n",
      "Ep:109, loss:0.00000, loss_test:0.02227, lr:3.70e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.096, tt:3860.530\n",
      "Ep:110, loss:0.00000, loss_test:0.02227, lr:3.67e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.103, tt:3896.433\n",
      "Ep:111, loss:0.00000, loss_test:0.02228, lr:3.63e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.102, tt:3931.397\n",
      "Ep:112, loss:0.00000, loss_test:0.02245, lr:3.59e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.113, tt:3967.752\n",
      "Ep:113, loss:0.00000, loss_test:0.02240, lr:3.56e-02, fs:0.66667 (r=0.515,p=0.944),  time:35.118, tt:4003.411\n",
      "Ep:114, loss:0.00000, loss_test:0.02262, lr:3.52e-02, fs:0.65806 (r=0.515,p=0.911),  time:35.135, tt:4040.562\n",
      "Ep:115, loss:0.00000, loss_test:0.02268, lr:3.49e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.137, tt:4075.857\n",
      "Ep:116, loss:0.00000, loss_test:0.02271, lr:3.45e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.133, tt:4110.552\n",
      "Ep:117, loss:0.00000, loss_test:0.02275, lr:3.42e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.142, tt:4146.803\n",
      "Ep:118, loss:0.00000, loss_test:0.02284, lr:3.38e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.158, tt:4183.765\n",
      "Ep:119, loss:0.00000, loss_test:0.02297, lr:3.35e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.162, tt:4219.477\n",
      "Ep:120, loss:0.00000, loss_test:0.02287, lr:3.32e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.156, tt:4253.841\n",
      "Ep:121, loss:0.00000, loss_test:0.02302, lr:3.28e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.160, tt:4289.533\n",
      "Ep:122, loss:0.00000, loss_test:0.02308, lr:3.25e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.157, tt:4324.352\n",
      "Ep:123, loss:0.00000, loss_test:0.02312, lr:3.22e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.173, tt:4361.391\n",
      "Ep:124, loss:0.00000, loss_test:0.02318, lr:3.19e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.177, tt:4397.136\n",
      "Ep:125, loss:0.00000, loss_test:0.02324, lr:3.15e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.199, tt:4435.079\n",
      "Ep:126, loss:0.00000, loss_test:0.02340, lr:3.12e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.203, tt:4470.826\n",
      "Ep:127, loss:0.00000, loss_test:0.02337, lr:3.09e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.215, tt:4507.456\n",
      "Ep:128, loss:0.00000, loss_test:0.02346, lr:3.06e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.214, tt:4542.646\n",
      "Ep:129, loss:0.00000, loss_test:0.02356, lr:3.03e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.227, tt:4579.530\n",
      "Ep:130, loss:0.00000, loss_test:0.02353, lr:3.00e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.215, tt:4613.106\n",
      "Ep:131, loss:0.00000, loss_test:0.02371, lr:2.97e-02, fs:0.64935 (r=0.505,p=0.909),  time:35.217, tt:4648.687\n",
      "Ep:132, loss:0.00000, loss_test:0.02371, lr:2.94e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.212, tt:4683.249\n",
      "Ep:133, loss:0.00000, loss_test:0.02380, lr:2.91e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.216, tt:4718.944\n",
      "Ep:134, loss:0.00000, loss_test:0.02381, lr:2.88e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.218, tt:4754.445\n",
      "Ep:135, loss:0.00000, loss_test:0.02379, lr:2.85e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.226, tt:4790.772\n",
      "Ep:136, loss:0.00000, loss_test:0.02397, lr:2.82e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.237, tt:4827.475\n",
      "Ep:137, loss:0.00000, loss_test:0.02404, lr:2.80e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.240, tt:4863.162\n",
      "Ep:138, loss:0.00000, loss_test:0.02403, lr:2.77e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.241, tt:4898.462\n",
      "Ep:139, loss:0.00000, loss_test:0.02407, lr:2.74e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.245, tt:4934.276\n",
      "Ep:140, loss:0.00000, loss_test:0.02412, lr:2.71e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.261, tt:4971.867\n",
      "Ep:141, loss:0.00000, loss_test:0.02426, lr:2.69e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.263, tt:5007.338\n",
      "Ep:142, loss:0.00000, loss_test:0.02425, lr:2.66e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.258, tt:5041.963\n",
      "Ep:143, loss:0.00000, loss_test:0.02430, lr:2.63e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.256, tt:5076.882\n",
      "Ep:144, loss:0.00000, loss_test:0.02432, lr:2.61e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.255, tt:5111.978\n",
      "Ep:145, loss:0.00000, loss_test:0.02439, lr:2.58e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.251, tt:5146.687\n",
      "Ep:146, loss:0.00000, loss_test:0.02438, lr:2.55e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.247, tt:5181.250\n",
      "Ep:147, loss:0.00000, loss_test:0.02451, lr:2.53e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.235, tt:5214.749\n",
      "Ep:148, loss:0.00000, loss_test:0.02460, lr:2.50e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.237, tt:5250.318\n",
      "Ep:149, loss:0.00000, loss_test:0.02459, lr:2.48e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.244, tt:5286.550\n",
      "Ep:150, loss:0.00000, loss_test:0.02469, lr:2.45e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.248, tt:5322.457\n",
      "Ep:151, loss:0.00000, loss_test:0.02468, lr:2.43e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.243, tt:5357.001\n",
      "Ep:152, loss:0.00000, loss_test:0.02477, lr:2.40e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.242, tt:5391.989\n",
      "Ep:153, loss:0.00000, loss_test:0.02484, lr:2.38e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.248, tt:5428.119\n",
      "Ep:154, loss:0.00000, loss_test:0.02487, lr:2.36e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.244, tt:5462.775\n",
      "Ep:155, loss:0.00000, loss_test:0.02493, lr:2.33e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.247, tt:5498.498\n",
      "Ep:156, loss:0.00000, loss_test:0.02490, lr:2.31e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.249, tt:5534.101\n",
      "Ep:157, loss:0.00000, loss_test:0.02506, lr:2.29e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.245, tt:5568.754\n",
      "Ep:158, loss:0.00000, loss_test:0.02499, lr:2.26e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.249, tt:5604.640\n",
      "Ep:159, loss:0.00000, loss_test:0.02504, lr:2.24e-02, fs:0.65359 (r=0.505,p=0.926),  time:35.250, tt:5640.046\n",
      "Ep:160, loss:0.00000, loss_test:0.02514, lr:2.22e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.240, tt:5673.702\n",
      "Ep:161, loss:0.00000, loss_test:0.02516, lr:2.20e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.237, tt:5708.393\n",
      "Ep:162, loss:0.00000, loss_test:0.02520, lr:2.17e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.246, tt:5745.063\n",
      "Ep:163, loss:0.00000, loss_test:0.02526, lr:2.15e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.249, tt:5780.915\n",
      "Ep:164, loss:0.00000, loss_test:0.02532, lr:2.13e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.251, tt:5816.462\n",
      "Ep:165, loss:0.00000, loss_test:0.02534, lr:2.11e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.247, tt:5850.942\n",
      "Ep:166, loss:0.00000, loss_test:0.02534, lr:2.09e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.245, tt:5885.943\n",
      "Ep:167, loss:0.00000, loss_test:0.02540, lr:2.07e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.253, tt:5922.550\n",
      "Ep:168, loss:0.00000, loss_test:0.02550, lr:2.05e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.260, tt:5958.965\n",
      "Ep:169, loss:0.00000, loss_test:0.02545, lr:2.03e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.265, tt:5995.096\n",
      "Ep:170, loss:0.00000, loss_test:0.02554, lr:2.01e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.266, tt:6030.427\n",
      "Ep:171, loss:0.00000, loss_test:0.02560, lr:1.99e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.266, tt:6065.794\n",
      "Ep:172, loss:0.00000, loss_test:0.02559, lr:1.97e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.274, tt:6102.333\n",
      "Ep:173, loss:0.00000, loss_test:0.02566, lr:1.95e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.277, tt:6138.155\n",
      "Ep:174, loss:0.00000, loss_test:0.02573, lr:1.93e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.280, tt:6173.955\n",
      "Ep:175, loss:0.00000, loss_test:0.02577, lr:1.91e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.283, tt:6209.734\n",
      "Ep:176, loss:0.00000, loss_test:0.02572, lr:1.89e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.283, tt:6245.165\n",
      "Ep:177, loss:0.00000, loss_test:0.02581, lr:1.87e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.288, tt:6281.284\n",
      "Ep:178, loss:0.00000, loss_test:0.02584, lr:1.85e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.290, tt:6316.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:179, loss:0.00000, loss_test:0.02584, lr:1.83e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.296, tt:6353.358\n",
      "Ep:180, loss:0.00000, loss_test:0.02593, lr:1.81e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.295, tt:6388.346\n",
      "Ep:181, loss:0.00000, loss_test:0.02600, lr:1.80e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.302, tt:6424.962\n",
      "Ep:182, loss:0.00000, loss_test:0.02596, lr:1.78e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.308, tt:6461.445\n",
      "Ep:183, loss:0.00000, loss_test:0.02602, lr:1.76e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.320, tt:6498.865\n",
      "Ep:184, loss:0.00000, loss_test:0.02604, lr:1.74e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.317, tt:6533.557\n",
      "Ep:185, loss:0.00000, loss_test:0.02610, lr:1.73e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.320, tt:6569.559\n",
      "Ep:186, loss:0.00000, loss_test:0.02611, lr:1.71e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.345, tt:6609.486\n",
      "Ep:187, loss:0.00000, loss_test:0.02612, lr:1.69e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.343, tt:6644.547\n",
      "Ep:188, loss:0.00000, loss_test:0.02614, lr:1.67e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.345, tt:6680.142\n",
      "Ep:189, loss:0.00000, loss_test:0.02623, lr:1.66e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.350, tt:6716.589\n",
      "Ep:190, loss:0.00000, loss_test:0.02630, lr:1.64e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.351, tt:6752.060\n",
      "Ep:191, loss:0.00000, loss_test:0.02622, lr:1.62e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.356, tt:6788.376\n",
      "Ep:192, loss:0.00000, loss_test:0.02627, lr:1.61e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.356, tt:6823.714\n",
      "Ep:193, loss:0.00000, loss_test:0.02630, lr:1.59e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.354, tt:6858.674\n",
      "Ep:194, loss:0.00000, loss_test:0.02632, lr:1.58e-02, fs:0.66225 (r=0.505,p=0.962),  time:35.288, tt:6881.155\n",
      "Ep:195, loss:0.00000, loss_test:0.02641, lr:1.56e-02, fs:0.65789 (r=0.505,p=0.943),  time:35.184, tt:6896.121\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"10-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13050, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:39.485, tt:39.485\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00025, loss_test:0.11720, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:41.110, tt:82.221\n",
      "Ep:2, loss:0.00025, loss_test:0.11197, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:40.780, tt:122.341\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00024, loss_test:0.11020, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:41.090, tt:164.362\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.10549, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:41.283, tt:206.416\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00022, loss_test:0.10130, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:41.289, tt:247.734\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00021, loss_test:0.10001, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:41.512, tt:290.587\n",
      "Ep:7, loss:0.00021, loss_test:0.09749, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:41.655, tt:333.241\n",
      "Ep:8, loss:0.00020, loss_test:0.09591, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:41.799, tt:376.193\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.09519, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:41.615, tt:416.145\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09371, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:41.784, tt:459.626\n",
      "Ep:11, loss:0.00018, loss_test:0.09415, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:41.866, tt:502.387\n",
      "Ep:12, loss:0.00018, loss_test:0.09105, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:41.797, tt:543.363\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09133, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:41.739, tt:584.352\n",
      "Ep:14, loss:0.00017, loss_test:0.09134, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.687, tt:625.305\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09043, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:41.582, tt:665.320\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08773, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:41.609, tt:707.348\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08622, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:41.671, tt:750.077\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09295, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:41.744, tt:793.133\n",
      "Ep:19, loss:0.00015, loss_test:0.08298, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.720, tt:834.409\n",
      "Ep:20, loss:0.00015, loss_test:0.08189, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:41.743, tt:876.613\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09976, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:41.819, tt:920.007\n",
      "Ep:22, loss:0.00015, loss_test:0.08398, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:41.813, tt:961.698\n",
      "Ep:23, loss:0.00014, loss_test:0.08978, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.810, tt:1003.437\n",
      "Ep:24, loss:0.00014, loss_test:0.09219, lr:1.00e-02, fs:0.79070 (r=0.859,p=0.733),  time:41.823, tt:1045.572\n",
      "Ep:25, loss:0.00013, loss_test:0.08579, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:41.840, tt:1087.828\n",
      "Ep:26, loss:0.00013, loss_test:0.08235, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:41.754, tt:1127.353\n",
      "Ep:27, loss:0.00013, loss_test:0.08583, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:41.708, tt:1167.835\n",
      "Ep:28, loss:0.00012, loss_test:0.09565, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:41.642, tt:1207.624\n",
      "Ep:29, loss:0.00013, loss_test:0.09391, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:41.563, tt:1246.895\n",
      "Ep:30, loss:0.00011, loss_test:0.08627, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:41.600, tt:1289.596\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08321, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.566, tt:1330.118\n",
      "Ep:32, loss:0.00011, loss_test:0.10249, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:41.641, tt:1374.168\n",
      "Ep:33, loss:0.00012, loss_test:0.08774, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.577, tt:1413.630\n",
      "Ep:34, loss:0.00011, loss_test:0.09219, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:41.649, tt:1457.710\n",
      "Ep:35, loss:0.00011, loss_test:0.08958, lr:1.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:41.638, tt:1498.972\n",
      "Ep:36, loss:0.00011, loss_test:0.09216, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:41.646, tt:1540.893\n",
      "Ep:37, loss:0.00011, loss_test:0.09073, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.670, tt:1583.444\n",
      "Ep:38, loss:0.00010, loss_test:0.08957, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:41.636, tt:1623.797\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08504, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:41.605, tt:1664.188\n",
      "Ep:40, loss:0.00010, loss_test:0.09695, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:41.583, tt:1704.909\n",
      "Ep:41, loss:0.00010, loss_test:0.08073, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:41.586, tt:1746.631\n",
      "Ep:42, loss:0.00008, loss_test:0.08502, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:41.580, tt:1787.954\n",
      "Ep:43, loss:0.00008, loss_test:0.07987, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.587, tt:1829.832\n",
      "Ep:44, loss:0.00008, loss_test:0.07710, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.605, tt:1872.219\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.08182, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:41.572, tt:1912.334\n",
      "Ep:46, loss:0.00007, loss_test:0.08289, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.573, tt:1953.916\n",
      "Ep:47, loss:0.00008, loss_test:0.08051, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:41.572, tt:1995.479\n",
      "Ep:48, loss:0.00007, loss_test:0.07916, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:41.598, tt:2038.279\n",
      "Ep:49, loss:0.00007, loss_test:0.07890, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:41.570, tt:2078.511\n",
      "Ep:50, loss:0.00006, loss_test:0.07843, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:41.571, tt:2120.124\n",
      "Ep:51, loss:0.00006, loss_test:0.07853, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:41.554, tt:2160.790\n",
      "Ep:52, loss:0.00005, loss_test:0.07596, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:41.569, tt:2203.155\n",
      "Ep:53, loss:0.00006, loss_test:0.06933, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:41.551, tt:2243.735\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.07697, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:41.565, tt:2286.081\n",
      "Ep:55, loss:0.00006, loss_test:0.07695, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:41.561, tt:2327.436\n",
      "Ep:56, loss:0.00006, loss_test:0.07925, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:41.622, tt:2372.440\n",
      "Ep:57, loss:0.00006, loss_test:0.08832, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:41.632, tt:2414.644\n",
      "Ep:58, loss:0.00007, loss_test:0.08059, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.626, tt:2455.941\n",
      "Ep:59, loss:0.00006, loss_test:0.08918, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:41.629, tt:2497.715\n",
      "Ep:60, loss:0.00005, loss_test:0.07479, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:41.613, tt:2538.393\n",
      "Ep:61, loss:0.00005, loss_test:0.07677, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:41.636, tt:2581.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00006, loss_test:0.07179, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:41.646, tt:2623.713\n",
      "Ep:63, loss:0.00005, loss_test:0.08412, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:41.669, tt:2666.831\n",
      "Ep:64, loss:0.00005, loss_test:0.07132, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.690, tt:2709.837\n",
      "Ep:65, loss:0.00005, loss_test:0.07516, lr:9.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.681, tt:2750.936\n",
      "Ep:66, loss:0.00005, loss_test:0.07594, lr:9.80e-03, fs:0.75532 (r=0.717,p=0.798),  time:41.714, tt:2794.851\n",
      "Ep:67, loss:0.00004, loss_test:0.07194, lr:9.70e-03, fs:0.78495 (r=0.737,p=0.839),  time:41.739, tt:2838.264\n",
      "Ep:68, loss:0.00004, loss_test:0.07640, lr:9.61e-03, fs:0.76596 (r=0.727,p=0.809),  time:41.764, tt:2881.744\n",
      "Ep:69, loss:0.00004, loss_test:0.06835, lr:9.51e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.773, tt:2924.135\n",
      "Ep:70, loss:0.00003, loss_test:0.07479, lr:9.41e-03, fs:0.81283 (r=0.768,p=0.864),  time:41.785, tt:2966.726\n",
      "Ep:71, loss:0.00003, loss_test:0.07866, lr:9.32e-03, fs:0.74872 (r=0.737,p=0.760),  time:41.793, tt:3009.069\n",
      "Ep:72, loss:0.00003, loss_test:0.07662, lr:9.23e-03, fs:0.80208 (r=0.778,p=0.828),  time:41.813, tt:3052.348\n",
      "Ep:73, loss:0.00003, loss_test:0.07109, lr:9.14e-03, fs:0.80208 (r=0.778,p=0.828),  time:41.800, tt:3093.187\n",
      "Ep:74, loss:0.00003, loss_test:0.06722, lr:9.04e-03, fs:0.83422 (r=0.788,p=0.886),  time:41.837, tt:3137.778\n",
      "Ep:75, loss:0.00003, loss_test:0.07141, lr:8.95e-03, fs:0.82796 (r=0.778,p=0.885),  time:41.854, tt:3180.927\n",
      "Ep:76, loss:0.00003, loss_test:0.07756, lr:8.86e-03, fs:0.81915 (r=0.778,p=0.865),  time:41.871, tt:3224.051\n",
      "Ep:77, loss:0.00003, loss_test:0.06966, lr:8.78e-03, fs:0.82979 (r=0.788,p=0.876),  time:41.869, tt:3265.763\n",
      "Ep:78, loss:0.00003, loss_test:0.07176, lr:8.69e-03, fs:0.82540 (r=0.788,p=0.867),  time:41.905, tt:3310.474\n",
      "Ep:79, loss:0.00003, loss_test:0.06864, lr:8.60e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.912, tt:3352.980\n",
      "Ep:80, loss:0.00003, loss_test:0.07414, lr:8.51e-03, fs:0.75556 (r=0.687,p=0.840),  time:41.917, tt:3395.276\n",
      "Ep:81, loss:0.00003, loss_test:0.06817, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:41.946, tt:3439.552\n",
      "Ep:82, loss:0.00003, loss_test:0.06442, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:41.966, tt:3483.157\n",
      "Ep:83, loss:0.00002, loss_test:0.07372, lr:8.26e-03, fs:0.83243 (r=0.778,p=0.895),  time:41.963, tt:3524.890\n",
      "Ep:84, loss:0.00002, loss_test:0.06781, lr:8.18e-03, fs:0.82162 (r=0.768,p=0.884),  time:41.950, tt:3565.735\n",
      "Ep:85, loss:0.00002, loss_test:0.06960, lr:8.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.950, tt:3607.668\n",
      "Ep:86, loss:0.00002, loss_test:0.06965, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.987, tt:3652.837\n",
      "Ep:87, loss:0.00002, loss_test:0.06742, lr:7.94e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.993, tt:3695.347\n",
      "Ep:88, loss:0.00002, loss_test:0.07123, lr:7.86e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.993, tt:3737.409\n",
      "Ep:89, loss:0.00002, loss_test:0.06692, lr:7.78e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.000, tt:3779.980\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.06825, lr:7.78e-03, fs:0.81967 (r=0.758,p=0.893),  time:42.016, tt:3823.429\n",
      "Ep:91, loss:0.00002, loss_test:0.07342, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.043, tt:3867.915\n",
      "Ep:92, loss:0.00002, loss_test:0.06951, lr:7.78e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.062, tt:3911.766\n",
      "Ep:93, loss:0.00002, loss_test:0.07050, lr:7.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.080, tt:3955.539\n",
      "Ep:94, loss:0.00001, loss_test:0.07276, lr:7.78e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.076, tt:3997.262\n",
      "Ep:95, loss:0.00001, loss_test:0.07161, lr:7.78e-03, fs:0.83243 (r=0.778,p=0.895),  time:42.059, tt:4037.632\n",
      "Ep:96, loss:0.00001, loss_test:0.07224, lr:7.78e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.052, tt:4079.054\n",
      "Ep:97, loss:0.00001, loss_test:0.07088, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.057, tt:4121.599\n",
      "Ep:98, loss:0.00001, loss_test:0.07209, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.045, tt:4162.445\n",
      "Ep:99, loss:0.00001, loss_test:0.07351, lr:7.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.056, tt:4205.649\n",
      "Ep:100, loss:0.00001, loss_test:0.07440, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.060, tt:4248.091\n",
      "Ep:101, loss:0.00001, loss_test:0.07361, lr:7.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.044, tt:4288.484\n",
      "Ep:102, loss:0.00001, loss_test:0.07399, lr:7.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.049, tt:4331.035\n",
      "Ep:103, loss:0.00001, loss_test:0.07268, lr:7.55e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.051, tt:4373.253\n",
      "Ep:104, loss:0.00001, loss_test:0.07519, lr:7.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.053, tt:4415.553\n",
      "Ep:105, loss:0.00001, loss_test:0.07353, lr:7.40e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.065, tt:4458.921\n",
      "Ep:106, loss:0.00001, loss_test:0.07236, lr:7.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.066, tt:4501.105\n",
      "Ep:107, loss:0.00001, loss_test:0.07449, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:42.064, tt:4542.934\n",
      "Ep:108, loss:0.00001, loss_test:0.07206, lr:7.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:42.060, tt:4584.512\n",
      "Ep:109, loss:0.00001, loss_test:0.07660, lr:7.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.070, tt:4627.655\n",
      "Ep:110, loss:0.00001, loss_test:0.07278, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.076, tt:4670.487\n",
      "Ep:111, loss:0.00001, loss_test:0.07532, lr:6.96e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.079, tt:4712.888\n",
      "Ep:112, loss:0.00001, loss_test:0.07350, lr:6.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.075, tt:4754.511\n",
      "Ep:113, loss:0.00001, loss_test:0.07501, lr:6.83e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.070, tt:4795.965\n",
      "Ep:114, loss:0.00001, loss_test:0.07543, lr:6.76e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.070, tt:4838.091\n",
      "Ep:115, loss:0.00001, loss_test:0.07685, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.081, tt:4881.341\n",
      "Ep:116, loss:0.00001, loss_test:0.07539, lr:6.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.078, tt:4923.160\n",
      "Ep:117, loss:0.00001, loss_test:0.07363, lr:6.56e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.087, tt:4966.235\n",
      "Ep:118, loss:0.00001, loss_test:0.07497, lr:6.49e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.103, tt:5010.309\n",
      "Ep:119, loss:0.00001, loss_test:0.07110, lr:6.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.101, tt:5052.098\n",
      "Ep:120, loss:0.00001, loss_test:0.07660, lr:6.36e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.089, tt:5092.749\n",
      "Ep:121, loss:0.00001, loss_test:0.07090, lr:6.30e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.073, tt:5132.858\n",
      "Ep:122, loss:0.00001, loss_test:0.07740, lr:6.24e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.070, tt:5174.594\n",
      "Ep:123, loss:0.00001, loss_test:0.07332, lr:6.17e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.085, tt:5218.546\n",
      "Ep:124, loss:0.00001, loss_test:0.07777, lr:6.11e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.089, tt:5261.132\n",
      "Ep:125, loss:0.00001, loss_test:0.07661, lr:6.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.121, tt:5307.212\n",
      "Ep:126, loss:0.00001, loss_test:0.07640, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.118, tt:5348.974\n",
      "Ep:127, loss:0.00001, loss_test:0.07570, lr:5.93e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.124, tt:5391.835\n",
      "Ep:128, loss:0.00001, loss_test:0.07531, lr:5.87e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.139, tt:5435.951\n",
      "Ep:129, loss:0.00000, loss_test:0.07529, lr:5.81e-03, fs:0.84444 (r=0.768,p=0.938),  time:42.141, tt:5478.305\n",
      "Ep:130, loss:0.00000, loss_test:0.07659, lr:5.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.143, tt:5520.743\n",
      "Ep:131, loss:0.00000, loss_test:0.07891, lr:5.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:42.151, tt:5563.929\n",
      "Ep:132, loss:0.00000, loss_test:0.07518, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.138, tt:5604.323\n",
      "Ep:133, loss:0.00000, loss_test:0.07918, lr:5.58e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.123, tt:5644.543\n",
      "Ep:134, loss:0.00000, loss_test:0.07487, lr:5.53e-03, fs:0.79070 (r=0.687,p=0.932),  time:42.107, tt:5684.494\n",
      "Ep:135, loss:0.00000, loss_test:0.07588, lr:5.47e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.115, tt:5727.645\n",
      "Ep:136, loss:0.00000, loss_test:0.07588, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.110, tt:5769.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.07788, lr:5.36e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.110, tt:5811.162\n",
      "Ep:138, loss:0.00000, loss_test:0.07588, lr:5.31e-03, fs:0.80460 (r=0.707,p=0.933),  time:42.103, tt:5852.278\n",
      "Ep:139, loss:0.00000, loss_test:0.07899, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:42.099, tt:5893.825\n",
      "Ep:140, loss:0.00000, loss_test:0.07622, lr:5.20e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.104, tt:5936.732\n",
      "Ep:141, loss:0.00000, loss_test:0.07731, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:42.096, tt:5977.645\n",
      "Ep:142, loss:0.00000, loss_test:0.07706, lr:5.10e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.107, tt:6021.269\n",
      "Ep:143, loss:0.00000, loss_test:0.07717, lr:5.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.097, tt:6062.019\n",
      "Ep:144, loss:0.00000, loss_test:0.07911, lr:5.00e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.108, tt:6105.603\n",
      "Ep:145, loss:0.00000, loss_test:0.07538, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:42.097, tt:6146.111\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00000, loss_test:0.08032, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.101, tt:6188.883\n",
      "Ep:147, loss:0.00000, loss_test:0.07616, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:42.102, tt:6231.113\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.07897, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.105, tt:6273.617\n",
      "Ep:149, loss:0.00000, loss_test:0.07735, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:42.097, tt:6314.536\n",
      "Ep:150, loss:0.00000, loss_test:0.07759, lr:4.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:42.090, tt:6355.641\n",
      "Ep:151, loss:0.00000, loss_test:0.07783, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.081, tt:6396.313\n",
      "Ep:152, loss:0.00000, loss_test:0.07637, lr:4.95e-03, fs:0.84571 (r=0.747,p=0.974),  time:42.071, tt:6436.922\n",
      "Ep:153, loss:0.00000, loss_test:0.08072, lr:4.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:42.057, tt:6476.746\n",
      "Ep:154, loss:0.00000, loss_test:0.07712, lr:4.95e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.058, tt:6519.052\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12944, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:17.605, tt:17.605\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12686, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:17.075, tt:34.151\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12406, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:17.467, tt:52.402\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12231, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:18.229, tt:72.918\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12138, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:18.100, tt:90.499\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12110, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:18.009, tt:108.055\n",
      "Ep:6, loss:0.00026, loss_test:0.12012, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:18.084, tt:126.586\n",
      "Ep:7, loss:0.00026, loss_test:0.11896, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:18.063, tt:144.503\n",
      "Ep:8, loss:0.00025, loss_test:0.11742, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:18.041, tt:162.367\n",
      "Ep:9, loss:0.00025, loss_test:0.11507, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:18.515, tt:185.147\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.11252, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:18.471, tt:203.176\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11055, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:18.257, tt:219.084\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10877, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:18.216, tt:236.807\n",
      "Ep:13, loss:0.00023, loss_test:0.10679, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:18.170, tt:254.387\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.10492, lr:1.00e-02, fs:0.72951 (r=0.899,p=0.614),  time:18.147, tt:272.212\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00022, loss_test:0.10320, lr:1.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:18.036, tt:288.569\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.10201, lr:1.00e-02, fs:0.74380 (r=0.909,p=0.629),  time:17.984, tt:305.733\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10123, lr:1.00e-02, fs:0.73469 (r=0.909,p=0.616),  time:17.820, tt:320.767\n",
      "Ep:18, loss:0.00021, loss_test:0.09949, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:17.822, tt:338.618\n",
      "Ep:19, loss:0.00020, loss_test:0.09915, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:17.850, tt:357.006\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09834, lr:1.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:17.722, tt:372.160\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.09679, lr:1.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:17.651, tt:388.329\n",
      "Ep:22, loss:0.00019, loss_test:0.09598, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:17.712, tt:407.371\n",
      "Ep:23, loss:0.00019, loss_test:0.09371, lr:1.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:17.706, tt:424.954\n",
      "Ep:24, loss:0.00018, loss_test:0.09264, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:17.762, tt:444.059\n",
      "Ep:25, loss:0.00018, loss_test:0.09129, lr:1.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:17.886, tt:465.048\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.09024, lr:1.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:17.902, tt:483.355\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.08828, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:17.859, tt:500.049\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08594, lr:1.00e-02, fs:0.78788 (r=0.919,p=0.689),  time:17.885, tt:518.657\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.08589, lr:1.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:17.837, tt:535.105\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08222, lr:1.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:17.783, tt:551.274\n",
      "Ep:31, loss:0.00015, loss_test:0.08303, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:17.795, tt:569.435\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.08003, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:17.862, tt:589.446\n",
      "Ep:33, loss:0.00015, loss_test:0.07750, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:17.894, tt:608.397\n",
      "Ep:34, loss:0.00014, loss_test:0.08360, lr:1.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:17.905, tt:626.690\n",
      "Ep:35, loss:0.00014, loss_test:0.07617, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:17.894, tt:644.175\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.07589, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:17.831, tt:659.744\n",
      "Ep:37, loss:0.00013, loss_test:0.07509, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:17.869, tt:679.040\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.07431, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:17.878, tt:697.236\n",
      "Ep:39, loss:0.00012, loss_test:0.07507, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:17.820, tt:712.818\n",
      "Ep:40, loss:0.00012, loss_test:0.07384, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:17.852, tt:731.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00011, loss_test:0.07547, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:17.824, tt:748.611\n",
      "Ep:42, loss:0.00013, loss_test:0.07925, lr:1.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:17.802, tt:765.469\n",
      "Ep:43, loss:0.00014, loss_test:0.08387, lr:1.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:17.794, tt:782.918\n",
      "Ep:44, loss:0.00013, loss_test:0.07874, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:17.771, tt:799.689\n",
      "Ep:45, loss:0.00015, loss_test:0.08738, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:17.728, tt:815.466\n",
      "Ep:46, loss:0.00014, loss_test:0.09011, lr:1.00e-02, fs:0.77165 (r=0.990,p=0.632),  time:17.765, tt:834.949\n",
      "Ep:47, loss:0.00015, loss_test:0.07131, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:17.790, tt:853.912\n",
      "Ep:48, loss:0.00012, loss_test:0.07950, lr:1.00e-02, fs:0.79508 (r=0.980,p=0.669),  time:17.800, tt:872.209\n",
      "Ep:49, loss:0.00012, loss_test:0.07141, lr:9.90e-03, fs:0.82667 (r=0.939,p=0.738),  time:17.819, tt:890.958\n",
      "Ep:50, loss:0.00011, loss_test:0.07135, lr:9.80e-03, fs:0.80734 (r=0.889,p=0.739),  time:17.885, tt:912.127\n",
      "Ep:51, loss:0.00010, loss_test:0.06982, lr:9.70e-03, fs:0.82819 (r=0.949,p=0.734),  time:17.922, tt:931.967\n",
      "Ep:52, loss:0.00010, loss_test:0.06925, lr:9.61e-03, fs:0.85973 (r=0.960,p=0.779),  time:17.963, tt:952.056\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.07019, lr:9.61e-03, fs:0.82969 (r=0.960,p=0.731),  time:18.002, tt:972.119\n",
      "Ep:54, loss:0.00009, loss_test:0.06820, lr:9.61e-03, fs:0.81731 (r=0.859,p=0.780),  time:17.990, tt:989.433\n",
      "Ep:55, loss:0.00009, loss_test:0.06546, lr:9.61e-03, fs:0.84071 (r=0.960,p=0.748),  time:18.027, tt:1009.508\n",
      "Ep:56, loss:0.00008, loss_test:0.06644, lr:9.61e-03, fs:0.79621 (r=0.848,p=0.750),  time:18.029, tt:1027.647\n",
      "Ep:57, loss:0.00007, loss_test:0.06439, lr:9.61e-03, fs:0.86222 (r=0.980,p=0.770),  time:17.988, tt:1043.326\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.06505, lr:9.61e-03, fs:0.82791 (r=0.899,p=0.767),  time:17.989, tt:1061.328\n",
      "Ep:59, loss:0.00007, loss_test:0.06524, lr:9.61e-03, fs:0.83962 (r=0.899,p=0.788),  time:17.990, tt:1079.379\n",
      "Ep:60, loss:0.00007, loss_test:0.06537, lr:9.61e-03, fs:0.82791 (r=0.899,p=0.767),  time:17.969, tt:1096.121\n",
      "Ep:61, loss:0.00006, loss_test:0.06411, lr:9.61e-03, fs:0.80583 (r=0.838,p=0.776),  time:17.954, tt:1113.158\n",
      "Ep:62, loss:0.00006, loss_test:0.06940, lr:9.61e-03, fs:0.81860 (r=0.889,p=0.759),  time:17.938, tt:1130.103\n",
      "Ep:63, loss:0.00006, loss_test:0.06321, lr:9.61e-03, fs:0.81553 (r=0.848,p=0.785),  time:17.922, tt:1146.992\n",
      "Ep:64, loss:0.00006, loss_test:0.06550, lr:9.61e-03, fs:0.83654 (r=0.879,p=0.798),  time:17.922, tt:1164.929\n",
      "Ep:65, loss:0.00005, loss_test:0.06167, lr:9.61e-03, fs:0.85167 (r=0.899,p=0.809),  time:17.925, tt:1183.026\n",
      "Ep:66, loss:0.00005, loss_test:0.06044, lr:9.61e-03, fs:0.84729 (r=0.869,p=0.827),  time:17.896, tt:1199.015\n",
      "Ep:67, loss:0.00005, loss_test:0.06279, lr:9.61e-03, fs:0.82000 (r=0.828,p=0.812),  time:17.875, tt:1215.476\n",
      "Ep:68, loss:0.00005, loss_test:0.06201, lr:9.61e-03, fs:0.84906 (r=0.909,p=0.796),  time:17.861, tt:1232.437\n",
      "Ep:69, loss:0.00005, loss_test:0.06640, lr:9.51e-03, fs:0.84793 (r=0.929,p=0.780),  time:17.838, tt:1248.653\n",
      "Ep:70, loss:0.00006, loss_test:0.05950, lr:9.41e-03, fs:0.84694 (r=0.838,p=0.856),  time:17.836, tt:1266.369\n",
      "Ep:71, loss:0.00005, loss_test:0.06244, lr:9.32e-03, fs:0.85849 (r=0.919,p=0.805),  time:17.865, tt:1286.301\n",
      "Ep:72, loss:0.00005, loss_test:0.06016, lr:9.23e-03, fs:0.84103 (r=0.828,p=0.854),  time:17.860, tt:1303.747\n",
      "Ep:73, loss:0.00005, loss_test:0.06588, lr:9.14e-03, fs:0.80788 (r=0.828,p=0.788),  time:17.859, tt:1321.589\n",
      "Ep:74, loss:0.00005, loss_test:0.05986, lr:9.04e-03, fs:0.84422 (r=0.848,p=0.840),  time:17.879, tt:1340.895\n",
      "Ep:75, loss:0.00005, loss_test:0.06934, lr:8.95e-03, fs:0.79245 (r=0.848,p=0.743),  time:17.867, tt:1357.866\n",
      "Ep:76, loss:0.00005, loss_test:0.05307, lr:8.86e-03, fs:0.91346 (r=0.960,p=0.872),  time:17.850, tt:1374.461\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.06409, lr:8.86e-03, fs:0.82759 (r=0.848,p=0.808),  time:17.847, tt:1392.057\n",
      "Ep:78, loss:0.00005, loss_test:0.06338, lr:8.86e-03, fs:0.80000 (r=0.788,p=0.812),  time:17.838, tt:1409.168\n",
      "Ep:79, loss:0.00004, loss_test:0.06002, lr:8.86e-03, fs:0.84264 (r=0.838,p=0.847),  time:17.814, tt:1425.132\n",
      "Ep:80, loss:0.00004, loss_test:0.05969, lr:8.86e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.820, tt:1443.457\n",
      "Ep:81, loss:0.00004, loss_test:0.06078, lr:8.86e-03, fs:0.83505 (r=0.818,p=0.853),  time:17.818, tt:1461.113\n",
      "Ep:82, loss:0.00004, loss_test:0.05780, lr:8.86e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.794, tt:1476.908\n",
      "Ep:83, loss:0.00003, loss_test:0.05618, lr:8.86e-03, fs:0.87129 (r=0.889,p=0.854),  time:17.775, tt:1493.126\n",
      "Ep:84, loss:0.00003, loss_test:0.05783, lr:8.86e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.733, tt:1507.317\n",
      "Ep:85, loss:0.00003, loss_test:0.05822, lr:8.86e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.694, tt:1521.663\n",
      "Ep:86, loss:0.00003, loss_test:0.05466, lr:8.86e-03, fs:0.85714 (r=0.848,p=0.866),  time:17.656, tt:1536.058\n",
      "Ep:87, loss:0.00003, loss_test:0.05839, lr:8.86e-03, fs:0.86139 (r=0.879,p=0.845),  time:17.655, tt:1553.621\n",
      "Ep:88, loss:0.00003, loss_test:0.05638, lr:8.78e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.646, tt:1570.521\n",
      "Ep:89, loss:0.00003, loss_test:0.05427, lr:8.69e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.609, tt:1584.808\n",
      "Ep:90, loss:0.00003, loss_test:0.05643, lr:8.60e-03, fs:0.86432 (r=0.869,p=0.860),  time:17.590, tt:1600.712\n",
      "Ep:91, loss:0.00003, loss_test:0.05693, lr:8.51e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.553, tt:1614.855\n",
      "Ep:92, loss:0.00003, loss_test:0.05924, lr:8.43e-03, fs:0.85149 (r=0.869,p=0.835),  time:17.542, tt:1631.392\n",
      "Ep:93, loss:0.00003, loss_test:0.05908, lr:8.35e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.563, tt:1650.889\n",
      "Ep:94, loss:0.00002, loss_test:0.05561, lr:8.26e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.557, tt:1667.888\n",
      "Ep:95, loss:0.00002, loss_test:0.06108, lr:8.18e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.557, tt:1685.512\n",
      "Ep:96, loss:0.00002, loss_test:0.05738, lr:8.10e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.569, tt:1704.169\n",
      "Ep:97, loss:0.00002, loss_test:0.05979, lr:8.02e-03, fs:0.87437 (r=0.879,p=0.870),  time:17.550, tt:1719.911\n",
      "Ep:98, loss:0.00002, loss_test:0.05616, lr:7.94e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.540, tt:1736.509\n",
      "Ep:99, loss:0.00002, loss_test:0.05914, lr:7.86e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.552, tt:1755.250\n",
      "Ep:100, loss:0.00002, loss_test:0.05810, lr:7.78e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.530, tt:1770.509\n",
      "Ep:101, loss:0.00002, loss_test:0.05652, lr:7.70e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.501, tt:1785.060\n",
      "Ep:102, loss:0.00002, loss_test:0.05932, lr:7.62e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.505, tt:1802.965\n",
      "Ep:103, loss:0.00002, loss_test:0.06232, lr:7.55e-03, fs:0.87310 (r=0.869,p=0.878),  time:17.512, tt:1821.265\n",
      "Ep:104, loss:0.00002, loss_test:0.05366, lr:7.47e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.509, tt:1838.497\n",
      "Ep:105, loss:0.00002, loss_test:0.06113, lr:7.40e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.523, tt:1857.423\n",
      "Ep:106, loss:0.00002, loss_test:0.06158, lr:7.32e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.519, tt:1874.518\n",
      "Ep:107, loss:0.00002, loss_test:0.05975, lr:7.25e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.509, tt:1890.981\n",
      "Ep:108, loss:0.00002, loss_test:0.05625, lr:7.18e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.499, tt:1907.440\n",
      "Ep:109, loss:0.00002, loss_test:0.06204, lr:7.11e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.498, tt:1924.800\n",
      "Ep:110, loss:0.00002, loss_test:0.05620, lr:7.03e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.504, tt:1942.904\n",
      "Ep:111, loss:0.00002, loss_test:0.05726, lr:6.96e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.501, tt:1960.159\n",
      "Ep:112, loss:0.00002, loss_test:0.05639, lr:6.89e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.505, tt:1978.040\n",
      "Ep:113, loss:0.00002, loss_test:0.06195, lr:6.83e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.516, tt:1996.801\n",
      "Ep:114, loss:0.00002, loss_test:0.06076, lr:6.76e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.508, tt:2013.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00002, loss_test:0.05830, lr:6.69e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.515, tt:2031.757\n",
      "Ep:116, loss:0.00002, loss_test:0.05844, lr:6.62e-03, fs:0.87879 (r=0.879,p=0.879),  time:17.508, tt:2048.404\n",
      "Ep:117, loss:0.00002, loss_test:0.06097, lr:6.56e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.494, tt:2064.236\n",
      "Ep:118, loss:0.00002, loss_test:0.05939, lr:6.49e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.496, tt:2082.080\n",
      "Ep:119, loss:0.00002, loss_test:0.05764, lr:6.43e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.485, tt:2098.159\n",
      "Ep:120, loss:0.00002, loss_test:0.05980, lr:6.36e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.488, tt:2116.021\n",
      "Ep:121, loss:0.00002, loss_test:0.06387, lr:6.30e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.496, tt:2134.550\n",
      "Ep:122, loss:0.00001, loss_test:0.05794, lr:6.24e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.491, tt:2151.435\n",
      "Ep:123, loss:0.00001, loss_test:0.05942, lr:6.17e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.486, tt:2168.314\n",
      "Ep:124, loss:0.00001, loss_test:0.06187, lr:6.11e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.493, tt:2186.674\n",
      "Ep:125, loss:0.00001, loss_test:0.06079, lr:6.05e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.477, tt:2202.068\n",
      "Ep:126, loss:0.00001, loss_test:0.05826, lr:5.99e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.460, tt:2217.433\n",
      "Ep:127, loss:0.00001, loss_test:0.06155, lr:5.93e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.449, tt:2233.420\n",
      "Ep:128, loss:0.00001, loss_test:0.06076, lr:5.87e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.446, tt:2250.481\n",
      "Ep:129, loss:0.00001, loss_test:0.06097, lr:5.81e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.436, tt:2266.653\n",
      "Ep:130, loss:0.00001, loss_test:0.06178, lr:5.75e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.448, tt:2285.653\n",
      "Ep:131, loss:0.00001, loss_test:0.06174, lr:5.70e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.458, tt:2304.456\n",
      "Ep:132, loss:0.00001, loss_test:0.06314, lr:5.64e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.449, tt:2320.755\n",
      "Ep:133, loss:0.00001, loss_test:0.05951, lr:5.58e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.463, tt:2339.988\n",
      "Ep:134, loss:0.00001, loss_test:0.06414, lr:5.53e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.467, tt:2358.053\n",
      "Ep:135, loss:0.00001, loss_test:0.06116, lr:5.47e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.462, tt:2374.787\n",
      "Ep:136, loss:0.00001, loss_test:0.05959, lr:5.42e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.473, tt:2393.776\n",
      "Ep:137, loss:0.00001, loss_test:0.06244, lr:5.36e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.484, tt:2412.752\n",
      "Ep:138, loss:0.00001, loss_test:0.06161, lr:5.31e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.478, tt:2429.497\n",
      "Ep:139, loss:0.00001, loss_test:0.06363, lr:5.26e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.492, tt:2448.870\n",
      "Ep:140, loss:0.00001, loss_test:0.06269, lr:5.20e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.502, tt:2467.793\n",
      "Ep:141, loss:0.00001, loss_test:0.06363, lr:5.15e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.503, tt:2485.459\n",
      "Ep:142, loss:0.00001, loss_test:0.06091, lr:5.10e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.515, tt:2504.689\n",
      "Ep:143, loss:0.00001, loss_test:0.06428, lr:5.05e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.525, tt:2523.549\n",
      "Ep:144, loss:0.00001, loss_test:0.06311, lr:5.00e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.509, tt:2538.799\n",
      "Ep:145, loss:0.00001, loss_test:0.06147, lr:4.95e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.509, tt:2556.277\n",
      "Ep:146, loss:0.00001, loss_test:0.06341, lr:4.90e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.514, tt:2574.534\n",
      "Ep:147, loss:0.00001, loss_test:0.06291, lr:4.85e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.494, tt:2589.137\n",
      "Ep:148, loss:0.00001, loss_test:0.06220, lr:4.80e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.478, tt:2604.170\n",
      "Ep:149, loss:0.00001, loss_test:0.06451, lr:4.75e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.477, tt:2621.496\n",
      "Ep:150, loss:0.00001, loss_test:0.06186, lr:4.71e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.467, tt:2637.496\n",
      "Ep:151, loss:0.00001, loss_test:0.06329, lr:4.66e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.448, tt:2652.082\n",
      "Ep:152, loss:0.00001, loss_test:0.06246, lr:4.61e-03, fs:0.88776 (r=0.879,p=0.897),  time:17.442, tt:2668.552\n",
      "Ep:153, loss:0.00001, loss_test:0.06306, lr:4.57e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.434, tt:2684.888\n",
      "Ep:154, loss:0.00001, loss_test:0.06342, lr:4.52e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.416, tt:2699.465\n",
      "Ep:155, loss:0.00001, loss_test:0.06294, lr:4.48e-03, fs:0.89231 (r=0.879,p=0.906),  time:17.434, tt:2719.699\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12762, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:20.339, tt:20.339\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12562, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:20.173, tt:40.346\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12361, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:20.584, tt:61.753\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12246, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:20.274, tt:81.095\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12137, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:20.668, tt:103.340\n",
      "Ep:5, loss:0.00026, loss_test:0.12030, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:20.450, tt:122.700\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11884, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:20.225, tt:141.576\n",
      "Ep:7, loss:0.00025, loss_test:0.11666, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:20.466, tt:163.728\n",
      "Ep:8, loss:0.00025, loss_test:0.11398, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:20.374, tt:183.368\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.11238, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:20.196, tt:201.955\n",
      "Ep:10, loss:0.00025, loss_test:0.11087, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:20.241, tt:222.655\n",
      "Ep:11, loss:0.00024, loss_test:0.10871, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:20.196, tt:242.351\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10675, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:20.238, tt:263.089\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.10436, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:20.273, tt:283.826\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.10220, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:20.219, tt:303.278\n",
      "Ep:15, loss:0.00022, loss_test:0.10228, lr:1.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:20.168, tt:322.695\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.09859, lr:1.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:20.198, tt:343.369\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.09707, lr:1.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:20.254, tt:364.579\n",
      "Ep:18, loss:0.00020, loss_test:0.09695, lr:1.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:20.263, tt:384.992\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.09265, lr:1.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:20.190, tt:403.803\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.09176, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:20.234, tt:424.919\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09234, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:20.287, tt:446.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00017, loss_test:0.08547, lr:1.00e-02, fs:0.80349 (r=0.929,p=0.708),  time:20.277, tt:466.382\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09007, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:20.291, tt:486.986\n",
      "Ep:24, loss:0.00015, loss_test:0.08233, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:20.248, tt:506.202\n",
      "Ep:25, loss:0.00015, loss_test:0.08495, lr:1.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:20.202, tt:525.255\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08159, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:20.252, tt:546.811\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.08241, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:20.178, tt:564.993\n",
      "Ep:28, loss:0.00013, loss_test:0.08030, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:20.199, tt:585.775\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08018, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:20.262, tt:607.855\n",
      "Ep:30, loss:0.00012, loss_test:0.08328, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:20.273, tt:628.448\n",
      "Ep:31, loss:0.00012, loss_test:0.08687, lr:1.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:20.255, tt:648.172\n",
      "Ep:32, loss:0.00012, loss_test:0.07251, lr:1.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:20.304, tt:670.043\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08121, lr:1.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:20.348, tt:691.830\n",
      "Ep:34, loss:0.00012, loss_test:0.06970, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:20.328, tt:711.496\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07726, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:20.292, tt:730.527\n",
      "Ep:36, loss:0.00010, loss_test:0.06968, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:20.313, tt:751.588\n",
      "Ep:37, loss:0.00010, loss_test:0.07534, lr:1.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:20.309, tt:771.745\n",
      "Ep:38, loss:0.00009, loss_test:0.07100, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:20.293, tt:791.428\n",
      "Ep:39, loss:0.00009, loss_test:0.07193, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:20.320, tt:812.792\n",
      "Ep:40, loss:0.00008, loss_test:0.07343, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:20.278, tt:831.379\n",
      "Ep:41, loss:0.00007, loss_test:0.07354, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:20.343, tt:854.415\n",
      "Ep:42, loss:0.00007, loss_test:0.06341, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:20.385, tt:876.543\n",
      "Ep:43, loss:0.00007, loss_test:0.07466, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:20.407, tt:897.922\n",
      "Ep:44, loss:0.00006, loss_test:0.06468, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:20.389, tt:917.482\n",
      "Ep:45, loss:0.00006, loss_test:0.07530, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:20.391, tt:938.002\n",
      "Ep:46, loss:0.00005, loss_test:0.06749, lr:9.90e-03, fs:0.82051 (r=0.808,p=0.833),  time:20.438, tt:960.571\n",
      "Ep:47, loss:0.00005, loss_test:0.07477, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:20.455, tt:981.863\n",
      "Ep:48, loss:0.00005, loss_test:0.06840, lr:9.70e-03, fs:0.77895 (r=0.747,p=0.813),  time:20.462, tt:1002.619\n",
      "Ep:49, loss:0.00005, loss_test:0.06386, lr:9.61e-03, fs:0.83770 (r=0.808,p=0.870),  time:20.562, tt:1028.110\n",
      "Ep:50, loss:0.00005, loss_test:0.06398, lr:9.51e-03, fs:0.85427 (r=0.859,p=0.850),  time:20.551, tt:1048.090\n",
      "Ep:51, loss:0.00005, loss_test:0.06316, lr:9.41e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.507, tt:1066.349\n",
      "Ep:52, loss:0.00004, loss_test:0.06926, lr:9.32e-03, fs:0.82292 (r=0.798,p=0.849),  time:20.545, tt:1088.873\n",
      "Ep:53, loss:0.00004, loss_test:0.06039, lr:9.23e-03, fs:0.80829 (r=0.788,p=0.830),  time:20.537, tt:1109.021\n",
      "Ep:54, loss:0.00004, loss_test:0.07371, lr:9.14e-03, fs:0.79144 (r=0.747,p=0.841),  time:20.531, tt:1129.181\n",
      "Ep:55, loss:0.00004, loss_test:0.06191, lr:9.04e-03, fs:0.84211 (r=0.808,p=0.879),  time:20.538, tt:1150.111\n",
      "Ep:56, loss:0.00004, loss_test:0.06254, lr:8.95e-03, fs:0.83249 (r=0.828,p=0.837),  time:20.498, tt:1168.398\n",
      "Ep:57, loss:0.00004, loss_test:0.06202, lr:8.86e-03, fs:0.85561 (r=0.808,p=0.909),  time:20.501, tt:1189.077\n",
      "Ep:58, loss:0.00003, loss_test:0.06815, lr:8.78e-03, fs:0.78534 (r=0.758,p=0.815),  time:20.446, tt:1206.305\n",
      "Ep:59, loss:0.00003, loss_test:0.06256, lr:8.69e-03, fs:0.82609 (r=0.768,p=0.894),  time:20.446, tt:1226.757\n",
      "Ep:60, loss:0.00003, loss_test:0.06444, lr:8.60e-03, fs:0.80423 (r=0.768,p=0.844),  time:20.440, tt:1246.867\n",
      "Ep:61, loss:0.00003, loss_test:0.06601, lr:8.51e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.410, tt:1265.406\n",
      "Ep:62, loss:0.00003, loss_test:0.06567, lr:8.43e-03, fs:0.79144 (r=0.747,p=0.841),  time:20.419, tt:1286.398\n",
      "Ep:63, loss:0.00003, loss_test:0.06350, lr:8.35e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.417, tt:1306.705\n",
      "Ep:64, loss:0.00003, loss_test:0.06261, lr:8.26e-03, fs:0.81481 (r=0.778,p=0.856),  time:20.391, tt:1325.427\n",
      "Ep:65, loss:0.00003, loss_test:0.06745, lr:8.18e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.391, tt:1345.833\n",
      "Ep:66, loss:0.00003, loss_test:0.06781, lr:8.10e-03, fs:0.79787 (r=0.758,p=0.843),  time:20.364, tt:1364.394\n",
      "Ep:67, loss:0.00003, loss_test:0.06170, lr:8.02e-03, fs:0.82162 (r=0.768,p=0.884),  time:20.352, tt:1383.911\n",
      "Ep:68, loss:0.00003, loss_test:0.07168, lr:7.94e-03, fs:0.79787 (r=0.758,p=0.843),  time:20.368, tt:1405.366\n",
      "Ep:69, loss:0.00003, loss_test:0.06239, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:20.364, tt:1425.497\n",
      "Ep:70, loss:0.00002, loss_test:0.06750, lr:7.78e-03, fs:0.80214 (r=0.758,p=0.852),  time:20.380, tt:1446.989\n",
      "Ep:71, loss:0.00002, loss_test:0.06427, lr:7.70e-03, fs:0.82979 (r=0.788,p=0.876),  time:20.369, tt:1466.593\n",
      "Ep:72, loss:0.00002, loss_test:0.06569, lr:7.62e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.383, tt:1487.930\n",
      "Ep:73, loss:0.00002, loss_test:0.06216, lr:7.55e-03, fs:0.81720 (r=0.768,p=0.874),  time:20.410, tt:1510.356\n",
      "Ep:74, loss:0.00002, loss_test:0.06631, lr:7.47e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.372, tt:1527.875\n",
      "Ep:75, loss:0.00002, loss_test:0.06662, lr:7.40e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.394, tt:1549.909\n",
      "Ep:76, loss:0.00002, loss_test:0.06058, lr:7.32e-03, fs:0.81283 (r=0.768,p=0.864),  time:20.420, tt:1572.328\n",
      "Ep:77, loss:0.00002, loss_test:0.06526, lr:7.25e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.428, tt:1593.404\n",
      "Ep:78, loss:0.00002, loss_test:0.06501, lr:7.18e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.459, tt:1616.229\n",
      "Ep:79, loss:0.00002, loss_test:0.06390, lr:7.11e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.459, tt:1636.758\n",
      "Ep:80, loss:0.00002, loss_test:0.06716, lr:7.03e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.482, tt:1659.043\n",
      "Ep:81, loss:0.00002, loss_test:0.06333, lr:6.96e-03, fs:0.80645 (r=0.758,p=0.862),  time:20.471, tt:1678.634\n",
      "Ep:82, loss:0.00002, loss_test:0.06472, lr:6.89e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.456, tt:1697.828\n",
      "Ep:83, loss:0.00002, loss_test:0.06625, lr:6.83e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.485, tt:1720.721\n",
      "Ep:84, loss:0.00002, loss_test:0.06588, lr:6.76e-03, fs:0.81081 (r=0.758,p=0.872),  time:20.468, tt:1739.806\n",
      "Ep:85, loss:0.00002, loss_test:0.06542, lr:6.69e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.438, tt:1757.663\n",
      "Ep:86, loss:0.00002, loss_test:0.06631, lr:6.62e-03, fs:0.81522 (r=0.758,p=0.882),  time:20.441, tt:1778.373\n",
      "Ep:87, loss:0.00002, loss_test:0.06333, lr:6.56e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.433, tt:1798.127\n",
      "Ep:88, loss:0.00002, loss_test:0.06456, lr:6.49e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.431, tt:1818.350\n",
      "Ep:89, loss:0.00002, loss_test:0.06645, lr:6.43e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.448, tt:1840.291\n",
      "Ep:90, loss:0.00002, loss_test:0.06611, lr:6.36e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.425, tt:1858.686\n",
      "Ep:91, loss:0.00002, loss_test:0.06374, lr:6.30e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.416, tt:1878.248\n",
      "Ep:92, loss:0.00002, loss_test:0.06798, lr:6.24e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.395, tt:1896.729\n",
      "Ep:93, loss:0.00002, loss_test:0.06327, lr:6.17e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.391, tt:1916.719\n",
      "Ep:94, loss:0.00002, loss_test:0.06440, lr:6.11e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.389, tt:1936.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00002, loss_test:0.06555, lr:6.05e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.378, tt:1956.326\n",
      "Ep:96, loss:0.00002, loss_test:0.06622, lr:5.99e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.392, tt:1978.026\n",
      "Ep:97, loss:0.00002, loss_test:0.06356, lr:5.93e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.400, tt:1999.182\n",
      "Ep:98, loss:0.00001, loss_test:0.06741, lr:5.87e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.411, tt:2020.710\n",
      "Ep:99, loss:0.00001, loss_test:0.06361, lr:5.81e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.424, tt:2042.389\n",
      "Ep:100, loss:0.00001, loss_test:0.06723, lr:5.75e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.424, tt:2062.805\n",
      "Ep:101, loss:0.00001, loss_test:0.06508, lr:5.70e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.427, tt:2083.510\n",
      "Ep:102, loss:0.00001, loss_test:0.06462, lr:5.64e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.432, tt:2104.516\n",
      "Ep:103, loss:0.00001, loss_test:0.06621, lr:5.58e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.434, tt:2125.136\n",
      "Ep:104, loss:0.00001, loss_test:0.06556, lr:5.53e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.457, tt:2147.969\n",
      "Ep:105, loss:0.00001, loss_test:0.06595, lr:5.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.444, tt:2167.030\n",
      "Ep:106, loss:0.00001, loss_test:0.06616, lr:5.42e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.437, tt:2186.757\n",
      "Ep:107, loss:0.00001, loss_test:0.06441, lr:5.36e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.450, tt:2208.594\n",
      "Ep:108, loss:0.00001, loss_test:0.06621, lr:5.31e-03, fs:0.81967 (r=0.758,p=0.893),  time:20.437, tt:2227.638\n",
      "Ep:109, loss:0.00001, loss_test:0.06385, lr:5.26e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.453, tt:2249.877\n",
      "Ep:110, loss:0.00001, loss_test:0.06811, lr:5.20e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.465, tt:2271.663\n",
      "Ep:111, loss:0.00001, loss_test:0.06380, lr:5.15e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.452, tt:2290.579\n",
      "Ep:112, loss:0.00001, loss_test:0.06723, lr:5.10e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.449, tt:2310.727\n",
      "Ep:113, loss:0.00001, loss_test:0.06733, lr:5.05e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.446, tt:2330.810\n",
      "Ep:114, loss:0.00001, loss_test:0.06392, lr:5.00e-03, fs:0.82418 (r=0.758,p=0.904),  time:20.424, tt:2348.708\n",
      "Ep:115, loss:0.00001, loss_test:0.06617, lr:4.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.423, tt:2369.035\n",
      "Ep:116, loss:0.00001, loss_test:0.06661, lr:4.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.416, tt:2388.630\n",
      "Ep:117, loss:0.00001, loss_test:0.06581, lr:4.85e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.455, tt:2413.704\n",
      "Ep:118, loss:0.00001, loss_test:0.06478, lr:4.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.449, tt:2433.429\n",
      "Ep:119, loss:0.00001, loss_test:0.06803, lr:4.75e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.432, tt:2451.895\n",
      "Ep:120, loss:0.00001, loss_test:0.06496, lr:4.71e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.453, tt:2474.860\n",
      "Ep:121, loss:0.00001, loss_test:0.06744, lr:4.66e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.466, tt:2496.805\n",
      "Ep:122, loss:0.00001, loss_test:0.06441, lr:4.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.462, tt:2516.806\n",
      "Ep:123, loss:0.00001, loss_test:0.06925, lr:4.57e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.465, tt:2537.605\n",
      "Ep:124, loss:0.00001, loss_test:0.06314, lr:4.52e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.469, tt:2558.600\n",
      "Ep:125, loss:0.00001, loss_test:0.06556, lr:4.48e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.472, tt:2579.424\n",
      "Ep:126, loss:0.00001, loss_test:0.06811, lr:4.43e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.474, tt:2600.210\n",
      "Ep:127, loss:0.00001, loss_test:0.06652, lr:4.39e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.469, tt:2620.013\n",
      "Ep:128, loss:0.00001, loss_test:0.06671, lr:4.34e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.467, tt:2640.202\n",
      "Ep:129, loss:0.00001, loss_test:0.06424, lr:4.30e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.460, tt:2659.862\n",
      "Ep:130, loss:0.00001, loss_test:0.06826, lr:4.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.490, tt:2684.158\n",
      "Ep:131, loss:0.00001, loss_test:0.06450, lr:4.21e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.477, tt:2702.949\n",
      "Ep:132, loss:0.00001, loss_test:0.06535, lr:4.17e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.476, tt:2723.365\n",
      "Ep:133, loss:0.00001, loss_test:0.06625, lr:4.13e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.487, tt:2745.204\n",
      "Ep:134, loss:0.00001, loss_test:0.06457, lr:4.09e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.496, tt:2766.900\n",
      "Ep:135, loss:0.00001, loss_test:0.06574, lr:4.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.517, tt:2790.369\n",
      "Ep:136, loss:0.00001, loss_test:0.06454, lr:4.01e-03, fs:0.82873 (r=0.758,p=0.915),  time:20.533, tt:2813.088\n",
      "Ep:137, loss:0.00001, loss_test:0.06687, lr:3.97e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.527, tt:2832.716\n",
      "Ep:138, loss:0.00001, loss_test:0.06429, lr:3.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.533, tt:2854.099\n",
      "Ep:139, loss:0.00001, loss_test:0.06556, lr:3.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.528, tt:2873.981\n",
      "Ep:140, loss:0.00001, loss_test:0.06610, lr:3.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.537, tt:2895.780\n",
      "Ep:141, loss:0.00001, loss_test:0.06446, lr:3.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.540, tt:2916.656\n",
      "Ep:142, loss:0.00001, loss_test:0.06442, lr:3.77e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.537, tt:2936.765\n",
      "Ep:143, loss:0.00001, loss_test:0.06461, lr:3.73e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.553, tt:2959.641\n",
      "Ep:144, loss:0.00001, loss_test:0.06426, lr:3.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.544, tt:2978.952\n",
      "Ep:145, loss:0.00001, loss_test:0.06393, lr:3.66e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.552, tt:3000.584\n",
      "Ep:146, loss:0.00001, loss_test:0.06420, lr:3.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.554, tt:3021.388\n",
      "Ep:147, loss:0.00001, loss_test:0.06523, lr:3.59e-03, fs:0.83333 (r=0.758,p=0.926),  time:20.544, tt:3040.520\n",
      "Ep:148, loss:0.00001, loss_test:0.06409, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:20.549, tt:3061.820\n",
      "Ep:149, loss:0.00001, loss_test:0.06464, lr:3.52e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.549, tt:3082.393\n",
      "Ep:150, loss:0.00001, loss_test:0.06377, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:20.535, tt:3100.734\n",
      "Ep:151, loss:0.00001, loss_test:0.06577, lr:3.45e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.533, tt:3121.026\n",
      "Ep:152, loss:0.00001, loss_test:0.06358, lr:3.41e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.520, tt:3139.491\n",
      "Ep:153, loss:0.00001, loss_test:0.06583, lr:3.38e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.504, tt:3157.673\n",
      "Ep:154, loss:0.00001, loss_test:0.06261, lr:3.34e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.492, tt:3176.188\n",
      "Ep:155, loss:0.00001, loss_test:0.06566, lr:3.31e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.473, tt:3193.755\n",
      "Ep:156, loss:0.00001, loss_test:0.06414, lr:3.28e-03, fs:0.84270 (r=0.758,p=0.949),  time:20.476, tt:3214.737\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14545, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.746, tt:41.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14484, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.294, tt:82.588\n",
      "Ep:2, loss:0.00028, loss_test:0.14383, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.570, tt:124.711\n",
      "Ep:3, loss:0.00028, loss_test:0.14220, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.032, tt:168.126\n",
      "Ep:4, loss:0.00027, loss_test:0.13961, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.907, tt:209.537\n",
      "Ep:5, loss:0.00027, loss_test:0.13565, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:41.732, tt:250.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00026, loss_test:0.12940, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:41.663, tt:291.641\n",
      "Ep:7, loss:0.00024, loss_test:0.12084, lr:1.00e-02, fs:0.66946 (r=0.808,p=0.571),  time:41.534, tt:332.269\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11500, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:41.461, tt:373.153\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11334, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:41.441, tt:414.407\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11209, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:41.294, tt:454.237\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11201, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:41.243, tt:494.916\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10914, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:41.164, tt:535.136\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10742, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:41.301, tt:578.208\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10743, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:41.303, tt:619.538\n",
      "Ep:15, loss:0.00019, loss_test:0.10680, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:41.238, tt:659.815\n",
      "Ep:16, loss:0.00019, loss_test:0.10375, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:41.207, tt:700.518\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10237, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:41.168, tt:741.029\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10193, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:41.160, tt:782.034\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10076, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.207, tt:824.140\n",
      "Ep:20, loss:0.00017, loss_test:0.09988, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.254, tt:866.331\n",
      "Ep:21, loss:0.00017, loss_test:0.09918, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:41.134, tt:904.944\n",
      "Ep:22, loss:0.00016, loss_test:0.09822, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:41.148, tt:946.401\n",
      "Ep:23, loss:0.00016, loss_test:0.09778, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:41.191, tt:988.584\n",
      "Ep:24, loss:0.00016, loss_test:0.09723, lr:1.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:41.230, tt:1030.751\n",
      "Ep:25, loss:0.00015, loss_test:0.09693, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:41.250, tt:1072.498\n",
      "Ep:26, loss:0.00015, loss_test:0.09675, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:41.262, tt:1114.069\n",
      "Ep:27, loss:0.00015, loss_test:0.09564, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:41.241, tt:1154.735\n",
      "Ep:28, loss:0.00014, loss_test:0.09555, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:41.274, tt:1196.943\n",
      "Ep:29, loss:0.00014, loss_test:0.09550, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:41.296, tt:1238.866\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09433, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.315, tt:1280.774\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.09494, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:41.316, tt:1322.124\n",
      "Ep:32, loss:0.00013, loss_test:0.09370, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:41.317, tt:1363.467\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.09330, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:41.257, tt:1402.742\n",
      "Ep:34, loss:0.00013, loss_test:0.09305, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:41.259, tt:1444.075\n",
      "Ep:35, loss:0.00012, loss_test:0.09247, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:41.229, tt:1484.236\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.09231, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.213, tt:1524.869\n",
      "Ep:37, loss:0.00012, loss_test:0.09151, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:41.191, tt:1565.247\n",
      "Ep:38, loss:0.00012, loss_test:0.09165, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:41.179, tt:1605.962\n",
      "Ep:39, loss:0.00012, loss_test:0.09038, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:41.190, tt:1647.614\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.09090, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:41.238, tt:1690.742\n",
      "Ep:41, loss:0.00011, loss_test:0.08974, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:41.230, tt:1731.648\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.08994, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:41.258, tt:1774.078\n",
      "Ep:43, loss:0.00011, loss_test:0.08871, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:41.225, tt:1813.882\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08901, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:41.226, tt:1855.184\n",
      "Ep:45, loss:0.00010, loss_test:0.08806, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:41.224, tt:1896.296\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00010, loss_test:0.08791, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:41.217, tt:1937.186\n",
      "Ep:47, loss:0.00010, loss_test:0.08705, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.227, tt:1978.898\n",
      "Ep:48, loss:0.00010, loss_test:0.08724, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.222, tt:2019.881\n",
      "Ep:49, loss:0.00010, loss_test:0.08585, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:41.240, tt:2062.024\n",
      "Ep:50, loss:0.00009, loss_test:0.08705, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:41.234, tt:2102.943\n",
      "Ep:51, loss:0.00009, loss_test:0.08531, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:41.251, tt:2145.035\n",
      "Ep:52, loss:0.00009, loss_test:0.08619, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:41.242, tt:2185.844\n",
      "Ep:53, loss:0.00009, loss_test:0.08430, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.233, tt:2226.591\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00009, loss_test:0.08618, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:41.260, tt:2269.288\n",
      "Ep:55, loss:0.00009, loss_test:0.08485, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:41.265, tt:2310.836\n",
      "Ep:56, loss:0.00008, loss_test:0.08625, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:41.272, tt:2352.495\n",
      "Ep:57, loss:0.00008, loss_test:0.08485, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:41.252, tt:2392.599\n",
      "Ep:58, loss:0.00008, loss_test:0.08565, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:41.229, tt:2432.500\n",
      "Ep:59, loss:0.00008, loss_test:0.08399, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:41.231, tt:2473.885\n",
      "Ep:60, loss:0.00008, loss_test:0.08471, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.205, tt:2513.490\n",
      "Ep:61, loss:0.00008, loss_test:0.08205, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.186, tt:2553.504\n",
      "Ep:62, loss:0.00008, loss_test:0.08388, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:41.183, tt:2594.556\n",
      "Ep:63, loss:0.00007, loss_test:0.08190, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:41.171, tt:2634.971\n",
      "Ep:64, loss:0.00007, loss_test:0.08251, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:41.164, tt:2675.663\n",
      "Ep:65, loss:0.00007, loss_test:0.08224, lr:9.90e-03, fs:0.77005 (r=0.727,p=0.818),  time:41.183, tt:2718.060\n",
      "Ep:66, loss:0.00007, loss_test:0.08135, lr:9.80e-03, fs:0.77419 (r=0.727,p=0.828),  time:41.202, tt:2760.535\n",
      "Ep:67, loss:0.00007, loss_test:0.08230, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:41.215, tt:2802.627\n",
      "Ep:68, loss:0.00007, loss_test:0.08039, lr:9.61e-03, fs:0.80423 (r=0.768,p=0.844),  time:41.232, tt:2844.981\n",
      "Ep:69, loss:0.00007, loss_test:0.08270, lr:9.51e-03, fs:0.75978 (r=0.687,p=0.850),  time:41.245, tt:2887.147\n",
      "Ep:70, loss:0.00006, loss_test:0.07994, lr:9.41e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.243, tt:2928.262\n",
      "Ep:71, loss:0.00006, loss_test:0.08193, lr:9.32e-03, fs:0.77095 (r=0.697,p=0.863),  time:41.250, tt:2969.978\n",
      "Ep:72, loss:0.00006, loss_test:0.08057, lr:9.23e-03, fs:0.78495 (r=0.737,p=0.839),  time:41.243, tt:3010.732\n",
      "Ep:73, loss:0.00006, loss_test:0.08036, lr:9.14e-03, fs:0.80220 (r=0.737,p=0.880),  time:41.203, tt:3049.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00006, loss_test:0.08222, lr:9.04e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.218, tt:3091.349\n",
      "Ep:75, loss:0.00006, loss_test:0.07869, lr:8.95e-03, fs:0.83598 (r=0.798,p=0.878),  time:41.198, tt:3131.074\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00006, loss_test:0.08425, lr:8.95e-03, fs:0.74713 (r=0.657,p=0.867),  time:41.226, tt:3174.439\n",
      "Ep:77, loss:0.00006, loss_test:0.07896, lr:8.95e-03, fs:0.78075 (r=0.737,p=0.830),  time:41.220, tt:3215.176\n",
      "Ep:78, loss:0.00006, loss_test:0.08193, lr:8.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:41.217, tt:3256.124\n",
      "Ep:79, loss:0.00006, loss_test:0.07946, lr:8.95e-03, fs:0.77348 (r=0.707,p=0.854),  time:41.226, tt:3298.052\n",
      "Ep:80, loss:0.00006, loss_test:0.08138, lr:8.95e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.239, tt:3340.399\n",
      "Ep:81, loss:0.00006, loss_test:0.07908, lr:8.95e-03, fs:0.78075 (r=0.737,p=0.830),  time:41.255, tt:3382.894\n",
      "Ep:82, loss:0.00005, loss_test:0.08237, lr:8.95e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.249, tt:3423.670\n",
      "Ep:83, loss:0.00005, loss_test:0.08095, lr:8.95e-03, fs:0.78919 (r=0.737,p=0.849),  time:41.246, tt:3464.701\n",
      "Ep:84, loss:0.00005, loss_test:0.08097, lr:8.95e-03, fs:0.78652 (r=0.707,p=0.886),  time:41.266, tt:3507.600\n",
      "Ep:85, loss:0.00005, loss_test:0.07832, lr:8.95e-03, fs:0.80851 (r=0.768,p=0.854),  time:41.249, tt:3547.395\n",
      "Ep:86, loss:0.00005, loss_test:0.08107, lr:8.95e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.212, tt:3585.426\n",
      "Ep:87, loss:0.00005, loss_test:0.07948, lr:8.86e-03, fs:0.78453 (r=0.717,p=0.866),  time:41.165, tt:3622.489\n",
      "Ep:88, loss:0.00005, loss_test:0.07984, lr:8.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.118, tt:3659.537\n",
      "Ep:89, loss:0.00005, loss_test:0.07921, lr:8.69e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.138, tt:3702.390\n",
      "Ep:90, loss:0.00005, loss_test:0.08237, lr:8.60e-03, fs:0.78212 (r=0.707,p=0.875),  time:41.145, tt:3744.222\n",
      "Ep:91, loss:0.00005, loss_test:0.07864, lr:8.51e-03, fs:0.80000 (r=0.747,p=0.860),  time:41.163, tt:3786.984\n",
      "Ep:92, loss:0.00004, loss_test:0.08285, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:41.209, tt:3832.480\n",
      "Ep:93, loss:0.00004, loss_test:0.07735, lr:8.35e-03, fs:0.82353 (r=0.778,p=0.875),  time:41.215, tt:3874.256\n",
      "Ep:94, loss:0.00004, loss_test:0.08474, lr:8.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:41.224, tt:3916.327\n",
      "Ep:95, loss:0.00004, loss_test:0.07828, lr:8.18e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.219, tt:3957.002\n",
      "Ep:96, loss:0.00004, loss_test:0.08412, lr:8.10e-03, fs:0.79330 (r=0.717,p=0.887),  time:41.243, tt:4000.540\n",
      "Ep:97, loss:0.00004, loss_test:0.07859, lr:8.02e-03, fs:0.78022 (r=0.717,p=0.855),  time:41.268, tt:4044.250\n",
      "Ep:98, loss:0.00004, loss_test:0.08270, lr:7.94e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.281, tt:4086.849\n",
      "Ep:99, loss:0.00004, loss_test:0.07822, lr:7.86e-03, fs:0.80000 (r=0.747,p=0.860),  time:41.292, tt:4129.228\n",
      "Ep:100, loss:0.00004, loss_test:0.08367, lr:7.78e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.312, tt:4172.515\n",
      "Ep:101, loss:0.00004, loss_test:0.07815, lr:7.70e-03, fs:0.80645 (r=0.758,p=0.862),  time:41.315, tt:4214.119\n",
      "Ep:102, loss:0.00004, loss_test:0.08246, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.323, tt:4256.270\n",
      "Ep:103, loss:0.00004, loss_test:0.07772, lr:7.55e-03, fs:0.81081 (r=0.758,p=0.872),  time:41.317, tt:4296.953\n",
      "Ep:104, loss:0.00004, loss_test:0.08059, lr:7.47e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.348, tt:4341.566\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.07753, lr:7.47e-03, fs:0.79558 (r=0.727,p=0.878),  time:41.356, tt:4383.742\n",
      "Ep:106, loss:0.00004, loss_test:0.08144, lr:7.47e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.356, tt:4425.051\n",
      "Ep:107, loss:0.00004, loss_test:0.07874, lr:7.47e-03, fs:0.82609 (r=0.768,p=0.894),  time:41.369, tt:4467.850\n",
      "Ep:108, loss:0.00004, loss_test:0.08171, lr:7.47e-03, fs:0.78889 (r=0.717,p=0.877),  time:41.394, tt:4511.974\n",
      "Ep:109, loss:0.00004, loss_test:0.07724, lr:7.47e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.419, tt:4556.124\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00003, loss_test:0.08080, lr:7.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:41.449, tt:4600.816\n",
      "Ep:111, loss:0.00003, loss_test:0.07962, lr:7.47e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.469, tt:4644.556\n",
      "Ep:112, loss:0.00003, loss_test:0.07918, lr:7.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.489, tt:4688.272\n",
      "Ep:113, loss:0.00003, loss_test:0.08098, lr:7.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:41.506, tt:4731.699\n",
      "Ep:114, loss:0.00003, loss_test:0.07717, lr:7.47e-03, fs:0.84492 (r=0.798,p=0.898),  time:41.503, tt:4772.851\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00003, loss_test:0.08012, lr:7.47e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.507, tt:4814.838\n",
      "Ep:116, loss:0.00003, loss_test:0.07930, lr:7.47e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.514, tt:4857.094\n",
      "Ep:117, loss:0.00003, loss_test:0.07793, lr:7.47e-03, fs:0.82162 (r=0.768,p=0.884),  time:41.513, tt:4898.585\n",
      "Ep:118, loss:0.00003, loss_test:0.08051, lr:7.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.561, tt:4945.753\n",
      "Ep:119, loss:0.00003, loss_test:0.07718, lr:7.47e-03, fs:0.81522 (r=0.758,p=0.882),  time:41.571, tt:4988.499\n",
      "Ep:120, loss:0.00003, loss_test:0.07999, lr:7.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.590, tt:5032.430\n",
      "Ep:121, loss:0.00003, loss_test:0.08025, lr:7.47e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.598, tt:5074.942\n",
      "Ep:122, loss:0.00003, loss_test:0.07715, lr:7.47e-03, fs:0.84153 (r=0.778,p=0.917),  time:41.602, tt:5117.020\n",
      "Ep:123, loss:0.00003, loss_test:0.08089, lr:7.47e-03, fs:0.82486 (r=0.737,p=0.936),  time:41.604, tt:5158.868\n",
      "Ep:124, loss:0.00003, loss_test:0.07730, lr:7.47e-03, fs:0.81967 (r=0.758,p=0.893),  time:41.606, tt:5200.691\n",
      "Ep:125, loss:0.00003, loss_test:0.07963, lr:7.47e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.613, tt:5243.265\n",
      "Ep:126, loss:0.00003, loss_test:0.07846, lr:7.40e-03, fs:0.80874 (r=0.747,p=0.881),  time:41.613, tt:5284.842\n",
      "Ep:127, loss:0.00003, loss_test:0.07746, lr:7.32e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.609, tt:5325.960\n",
      "Ep:128, loss:0.00003, loss_test:0.08022, lr:7.25e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.615, tt:5368.348\n",
      "Ep:129, loss:0.00003, loss_test:0.07745, lr:7.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.624, tt:5411.108\n",
      "Ep:130, loss:0.00003, loss_test:0.08013, lr:7.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.652, tt:5456.465\n",
      "Ep:131, loss:0.00003, loss_test:0.07651, lr:7.03e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.655, tt:5498.397\n",
      "Ep:132, loss:0.00003, loss_test:0.07942, lr:6.96e-03, fs:0.83978 (r=0.768,p=0.927),  time:41.671, tt:5542.182\n",
      "Ep:133, loss:0.00003, loss_test:0.07838, lr:6.89e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.667, tt:5583.445\n",
      "Ep:134, loss:0.00003, loss_test:0.07876, lr:6.83e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.692, tt:5628.408\n",
      "Ep:135, loss:0.00002, loss_test:0.07753, lr:6.76e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.700, tt:5671.205\n",
      "Ep:136, loss:0.00002, loss_test:0.07896, lr:6.69e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.716, tt:5715.036\n",
      "Ep:137, loss:0.00002, loss_test:0.07706, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.715, tt:5756.675\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00002, loss_test:0.07968, lr:6.62e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.735, tt:5801.220\n",
      "Ep:139, loss:0.00002, loss_test:0.07745, lr:6.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.747, tt:5844.642\n",
      "Ep:140, loss:0.00002, loss_test:0.07738, lr:6.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.760, tt:5888.090\n",
      "Ep:141, loss:0.00002, loss_test:0.08008, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.764, tt:5930.438\n",
      "Ep:142, loss:0.00002, loss_test:0.07728, lr:6.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:41.776, tt:5974.039\n",
      "Ep:143, loss:0.00002, loss_test:0.08016, lr:6.62e-03, fs:0.83616 (r=0.747,p=0.949),  time:41.783, tt:6016.774\n",
      "Ep:144, loss:0.00002, loss_test:0.07739, lr:6.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.788, tt:6059.310\n",
      "Ep:145, loss:0.00002, loss_test:0.07899, lr:6.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:41.797, tt:6102.426\n",
      "Ep:146, loss:0.00002, loss_test:0.07726, lr:6.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:41.798, tt:6144.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00002, loss_test:0.08010, lr:6.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.811, tt:6188.072\n",
      "Ep:148, loss:0.00002, loss_test:0.07724, lr:6.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:41.831, tt:6232.859\n",
      "Ep:149, loss:0.00002, loss_test:0.07998, lr:6.56e-03, fs:0.82955 (r=0.737,p=0.948),  time:41.835, tt:6275.234\n",
      "Ep:150, loss:0.00002, loss_test:0.07667, lr:6.49e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.839, tt:6317.762\n",
      "Ep:151, loss:0.00002, loss_test:0.08015, lr:6.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:41.838, tt:6359.383\n",
      "Ep:152, loss:0.00002, loss_test:0.07825, lr:6.36e-03, fs:0.81111 (r=0.737,p=0.901),  time:41.826, tt:6399.419\n",
      "Ep:153, loss:0.00002, loss_test:0.07856, lr:6.30e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.819, tt:6440.098\n",
      "Ep:154, loss:0.00002, loss_test:0.07886, lr:6.24e-03, fs:0.82022 (r=0.737,p=0.924),  time:41.832, tt:6483.903\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.14575, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.399, tt:16.399\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14531, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.030, tt:34.059\n",
      "Ep:2, loss:0.00028, loss_test:0.14459, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.052, tt:54.156\n",
      "Ep:3, loss:0.00028, loss_test:0.14354, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:18.055, tt:72.221\n",
      "Ep:4, loss:0.00028, loss_test:0.14196, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:17.718, tt:88.590\n",
      "Ep:5, loss:0.00028, loss_test:0.13960, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:17.623, tt:105.737\n",
      "Ep:6, loss:0.00027, loss_test:0.13600, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:17.405, tt:121.834\n",
      "Ep:7, loss:0.00026, loss_test:0.13008, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:17.522, tt:140.178\n",
      "Ep:8, loss:0.00025, loss_test:0.12192, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:17.450, tt:157.052\n",
      "Ep:9, loss:0.00024, loss_test:0.11491, lr:1.00e-02, fs:0.64253 (r=0.717,p=0.582),  time:17.453, tt:174.534\n",
      "Ep:10, loss:0.00023, loss_test:0.11150, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:17.464, tt:192.109\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10978, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:17.476, tt:209.710\n",
      "Ep:12, loss:0.00022, loss_test:0.10866, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:17.613, tt:228.970\n",
      "Ep:13, loss:0.00021, loss_test:0.10339, lr:1.00e-02, fs:0.68203 (r=0.747,p=0.627),  time:17.692, tt:247.690\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.09872, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:17.665, tt:264.969\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.09695, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:17.614, tt:281.830\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.09542, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:17.422, tt:296.171\n",
      "Ep:17, loss:0.00018, loss_test:0.09224, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:17.251, tt:310.527\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09062, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:17.305, tt:328.794\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.08909, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:17.315, tt:346.308\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08699, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:17.168, tt:360.518\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08517, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:17.037, tt:374.824\n",
      "Ep:22, loss:0.00016, loss_test:0.08448, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:17.005, tt:391.108\n",
      "Ep:23, loss:0.00015, loss_test:0.08376, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:17.047, tt:409.124\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08203, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:17.075, tt:426.869\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.08091, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:17.151, tt:445.931\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08043, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:17.199, tt:464.376\n",
      "Ep:27, loss:0.00014, loss_test:0.07932, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:17.259, tt:483.251\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07828, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:17.258, tt:500.476\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07705, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.243, tt:517.294\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07671, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:17.241, tt:534.467\n",
      "Ep:31, loss:0.00012, loss_test:0.07592, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.226, tt:551.229\n",
      "Ep:32, loss:0.00012, loss_test:0.07531, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:17.206, tt:567.809\n",
      "Ep:33, loss:0.00012, loss_test:0.07469, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:17.199, tt:584.774\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.07415, lr:1.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:17.179, tt:601.248\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07352, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:17.190, tt:618.824\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07300, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:17.159, tt:634.868\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07253, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:17.171, tt:652.501\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07258, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:17.195, tt:670.614\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07229, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:17.176, tt:687.052\n",
      "Ep:40, loss:0.00010, loss_test:0.07090, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:17.143, tt:702.868\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.07143, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:17.154, tt:720.447\n",
      "Ep:42, loss:0.00009, loss_test:0.07019, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:17.136, tt:736.862\n",
      "Ep:43, loss:0.00009, loss_test:0.07002, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:17.135, tt:753.937\n",
      "Ep:44, loss:0.00009, loss_test:0.06969, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:17.128, tt:770.781\n",
      "Ep:45, loss:0.00009, loss_test:0.07049, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.142, tt:788.521\n",
      "Ep:46, loss:0.00009, loss_test:0.06870, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:17.141, tt:805.636\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.06971, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:17.156, tt:823.464\n",
      "Ep:48, loss:0.00008, loss_test:0.06807, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:17.149, tt:840.283\n",
      "Ep:49, loss:0.00008, loss_test:0.06851, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.136, tt:856.785\n",
      "Ep:50, loss:0.00008, loss_test:0.06704, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:17.121, tt:873.169\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00007, loss_test:0.06811, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.128, tt:890.682\n",
      "Ep:52, loss:0.00007, loss_test:0.06691, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:17.127, tt:907.724\n",
      "Ep:53, loss:0.00007, loss_test:0.06698, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.107, tt:923.786\n",
      "Ep:54, loss:0.00007, loss_test:0.06638, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:17.113, tt:941.206\n",
      "Ep:55, loss:0.00007, loss_test:0.06724, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:17.120, tt:958.701\n",
      "Ep:56, loss:0.00007, loss_test:0.06659, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:17.129, tt:976.373\n",
      "Ep:57, loss:0.00006, loss_test:0.06580, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:17.131, tt:993.606\n",
      "Ep:58, loss:0.00006, loss_test:0.06759, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:17.128, tt:1010.554\n",
      "Ep:59, loss:0.00006, loss_test:0.06501, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:17.135, tt:1028.075\n",
      "Ep:60, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.141, tt:1045.594\n",
      "Ep:61, loss:0.00006, loss_test:0.06392, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:17.134, tt:1062.310\n",
      "Ep:62, loss:0.00006, loss_test:0.06701, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.152, tt:1080.550\n",
      "Ep:63, loss:0.00006, loss_test:0.06447, lr:9.80e-03, fs:0.86957 (r=0.909,p=0.833),  time:17.174, tt:1099.158\n",
      "Ep:64, loss:0.00005, loss_test:0.06544, lr:9.70e-03, fs:0.84264 (r=0.838,p=0.847),  time:17.156, tt:1115.146\n",
      "Ep:65, loss:0.00005, loss_test:0.06541, lr:9.61e-03, fs:0.84878 (r=0.879,p=0.821),  time:17.164, tt:1132.849\n",
      "Ep:66, loss:0.00005, loss_test:0.06332, lr:9.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.144, tt:1148.668\n",
      "Ep:67, loss:0.00005, loss_test:0.06570, lr:9.41e-03, fs:0.85149 (r=0.869,p=0.835),  time:17.146, tt:1165.957\n",
      "Ep:68, loss:0.00005, loss_test:0.06218, lr:9.32e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.170, tt:1184.737\n",
      "Ep:69, loss:0.00005, loss_test:0.06572, lr:9.23e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.161, tt:1201.304\n",
      "Ep:70, loss:0.00005, loss_test:0.06337, lr:9.14e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.163, tt:1218.579\n",
      "Ep:71, loss:0.00005, loss_test:0.06312, lr:9.04e-03, fs:0.84848 (r=0.848,p=0.848),  time:17.154, tt:1235.122\n",
      "Ep:72, loss:0.00004, loss_test:0.06409, lr:8.95e-03, fs:0.84000 (r=0.848,p=0.832),  time:17.144, tt:1251.478\n",
      "Ep:73, loss:0.00004, loss_test:0.06164, lr:8.86e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.148, tt:1268.949\n",
      "Ep:74, loss:0.00004, loss_test:0.06290, lr:8.78e-03, fs:0.86432 (r=0.869,p=0.860),  time:17.160, tt:1286.980\n",
      "Ep:75, loss:0.00004, loss_test:0.06143, lr:8.69e-03, fs:0.85714 (r=0.848,p=0.866),  time:17.163, tt:1304.373\n",
      "Ep:76, loss:0.00004, loss_test:0.06310, lr:8.60e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.160, tt:1321.355\n",
      "Ep:77, loss:0.00004, loss_test:0.06281, lr:8.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:17.151, tt:1337.745\n",
      "Ep:78, loss:0.00004, loss_test:0.06164, lr:8.43e-03, fs:0.85279 (r=0.848,p=0.857),  time:17.139, tt:1353.986\n",
      "Ep:79, loss:0.00004, loss_test:0.06225, lr:8.35e-03, fs:0.86154 (r=0.848,p=0.875),  time:17.131, tt:1370.502\n",
      "Ep:80, loss:0.00004, loss_test:0.06092, lr:8.26e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.135, tt:1387.895\n",
      "Ep:81, loss:0.00004, loss_test:0.06194, lr:8.18e-03, fs:0.85128 (r=0.838,p=0.865),  time:17.115, tt:1403.406\n",
      "Ep:82, loss:0.00004, loss_test:0.06099, lr:8.10e-03, fs:0.86010 (r=0.838,p=0.883),  time:17.114, tt:1420.487\n",
      "Ep:83, loss:0.00004, loss_test:0.06080, lr:8.02e-03, fs:0.85567 (r=0.838,p=0.874),  time:17.111, tt:1437.310\n",
      "Ep:84, loss:0.00004, loss_test:0.06193, lr:7.94e-03, fs:0.84974 (r=0.828,p=0.872),  time:17.107, tt:1454.075\n",
      "Ep:85, loss:0.00003, loss_test:0.06070, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.097, tt:1470.369\n",
      "Ep:86, loss:0.00003, loss_test:0.05994, lr:7.78e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.085, tt:1486.353\n",
      "Ep:87, loss:0.00003, loss_test:0.06193, lr:7.70e-03, fs:0.85417 (r=0.828,p=0.882),  time:17.099, tt:1504.688\n",
      "Ep:88, loss:0.00003, loss_test:0.05869, lr:7.62e-03, fs:0.86869 (r=0.869,p=0.869),  time:17.094, tt:1521.367\n",
      "Ep:89, loss:0.00003, loss_test:0.06159, lr:7.55e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.095, tt:1538.529\n",
      "Ep:90, loss:0.00003, loss_test:0.05976, lr:7.47e-03, fs:0.88325 (r=0.879,p=0.888),  time:17.094, tt:1555.525\n",
      "Ep:91, loss:0.00003, loss_test:0.06068, lr:7.40e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.084, tt:1571.696\n",
      "Ep:92, loss:0.00003, loss_test:0.05946, lr:7.32e-03, fs:0.87755 (r=0.869,p=0.887),  time:17.072, tt:1587.686\n",
      "Ep:93, loss:0.00003, loss_test:0.06166, lr:7.25e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.064, tt:1603.975\n",
      "Ep:94, loss:0.00003, loss_test:0.05942, lr:7.18e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.064, tt:1621.079\n",
      "Ep:95, loss:0.00003, loss_test:0.06191, lr:7.11e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.082, tt:1639.829\n",
      "Ep:96, loss:0.00003, loss_test:0.06011, lr:7.03e-03, fs:0.86458 (r=0.838,p=0.892),  time:17.086, tt:1657.379\n",
      "Ep:97, loss:0.00003, loss_test:0.06233, lr:6.96e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.081, tt:1673.976\n",
      "Ep:98, loss:0.00003, loss_test:0.06144, lr:6.89e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.074, tt:1690.359\n",
      "Ep:99, loss:0.00003, loss_test:0.05965, lr:6.83e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.080, tt:1707.981\n",
      "Ep:100, loss:0.00003, loss_test:0.06203, lr:6.76e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.085, tt:1725.556\n",
      "Ep:101, loss:0.00003, loss_test:0.05952, lr:6.69e-03, fs:0.85864 (r=0.828,p=0.891),  time:17.084, tt:1742.539\n",
      "Ep:102, loss:0.00003, loss_test:0.06143, lr:6.62e-03, fs:0.84043 (r=0.798,p=0.888),  time:17.093, tt:1760.597\n",
      "Ep:103, loss:0.00003, loss_test:0.05943, lr:6.56e-03, fs:0.87234 (r=0.828,p=0.921),  time:17.088, tt:1777.129\n",
      "Ep:104, loss:0.00003, loss_test:0.06025, lr:6.49e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.084, tt:1793.845\n",
      "Ep:105, loss:0.00003, loss_test:0.05977, lr:6.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.082, tt:1810.742\n",
      "Ep:106, loss:0.00003, loss_test:0.05972, lr:6.36e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.081, tt:1827.643\n",
      "Ep:107, loss:0.00003, loss_test:0.05907, lr:6.30e-03, fs:0.87047 (r=0.848,p=0.894),  time:17.082, tt:1844.883\n",
      "Ep:108, loss:0.00002, loss_test:0.06004, lr:6.24e-03, fs:0.87097 (r=0.818,p=0.931),  time:17.073, tt:1860.986\n",
      "Ep:109, loss:0.00002, loss_test:0.05993, lr:6.17e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.076, tt:1878.326\n",
      "Ep:110, loss:0.00002, loss_test:0.05884, lr:6.11e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.080, tt:1895.875\n",
      "Ep:111, loss:0.00002, loss_test:0.06179, lr:6.05e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.082, tt:1913.173\n",
      "Ep:112, loss:0.00002, loss_test:0.06009, lr:5.99e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.078, tt:1929.820\n",
      "Ep:113, loss:0.00002, loss_test:0.05960, lr:5.93e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.071, tt:1946.091\n",
      "Ep:114, loss:0.00002, loss_test:0.06069, lr:5.87e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.062, tt:1962.107\n",
      "Ep:115, loss:0.00002, loss_test:0.05850, lr:5.81e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.062, tt:1979.154\n",
      "Ep:116, loss:0.00002, loss_test:0.06009, lr:5.75e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.064, tt:1996.476\n",
      "Ep:117, loss:0.00002, loss_test:0.06067, lr:5.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.058, tt:2012.871\n",
      "Ep:118, loss:0.00002, loss_test:0.05829, lr:5.64e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.050, tt:2028.987\n",
      "Ep:119, loss:0.00002, loss_test:0.06110, lr:5.58e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.050, tt:2045.950\n",
      "Ep:120, loss:0.00002, loss_test:0.06017, lr:5.53e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.050, tt:2063.012\n",
      "Ep:121, loss:0.00002, loss_test:0.05928, lr:5.47e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.055, tt:2080.695\n",
      "Ep:122, loss:0.00002, loss_test:0.05938, lr:5.42e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.052, tt:2097.365\n",
      "Ep:123, loss:0.00002, loss_test:0.05944, lr:5.36e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.048, tt:2113.950\n",
      "Ep:124, loss:0.00002, loss_test:0.05941, lr:5.31e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.047, tt:2130.905\n",
      "Ep:125, loss:0.00002, loss_test:0.05883, lr:5.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.045, tt:2147.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00002, loss_test:0.05919, lr:5.20e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.050, tt:2165.309\n",
      "Ep:127, loss:0.00002, loss_test:0.05909, lr:5.15e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.055, tt:2183.084\n",
      "Ep:128, loss:0.00002, loss_test:0.05931, lr:5.10e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.049, tt:2199.306\n",
      "Ep:129, loss:0.00002, loss_test:0.05943, lr:5.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.042, tt:2215.495\n",
      "Ep:130, loss:0.00002, loss_test:0.05868, lr:5.00e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.040, tt:2232.299\n",
      "Ep:131, loss:0.00002, loss_test:0.05942, lr:4.95e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.034, tt:2248.520\n",
      "Ep:132, loss:0.00002, loss_test:0.05951, lr:4.90e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.025, tt:2264.259\n",
      "Ep:133, loss:0.00002, loss_test:0.05881, lr:4.85e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.026, tt:2281.505\n",
      "Ep:134, loss:0.00002, loss_test:0.05910, lr:4.80e-03, fs:0.84656 (r=0.808,p=0.889),  time:17.023, tt:2298.090\n",
      "Ep:135, loss:0.00002, loss_test:0.06016, lr:4.75e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.020, tt:2314.760\n",
      "Ep:136, loss:0.00002, loss_test:0.05869, lr:4.71e-03, fs:0.86911 (r=0.838,p=0.902),  time:17.023, tt:2332.156\n",
      "Ep:137, loss:0.00002, loss_test:0.05994, lr:4.66e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.026, tt:2349.546\n",
      "Ep:138, loss:0.00002, loss_test:0.06071, lr:4.61e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.022, tt:2366.118\n",
      "Ep:139, loss:0.00002, loss_test:0.05862, lr:4.57e-03, fs:0.86316 (r=0.828,p=0.901),  time:17.022, tt:2383.033\n",
      "Ep:140, loss:0.00002, loss_test:0.06024, lr:4.52e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.034, tt:2401.760\n",
      "Ep:141, loss:0.00002, loss_test:0.05918, lr:4.48e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.029, tt:2418.078\n",
      "Ep:142, loss:0.00002, loss_test:0.05944, lr:4.43e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.025, tt:2434.634\n",
      "Ep:143, loss:0.00002, loss_test:0.05939, lr:4.39e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.021, tt:2451.041\n",
      "Ep:144, loss:0.00002, loss_test:0.05923, lr:4.34e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.015, tt:2467.109\n",
      "Ep:145, loss:0.00002, loss_test:0.05971, lr:4.30e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.017, tt:2484.445\n",
      "Ep:146, loss:0.00002, loss_test:0.05923, lr:4.26e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.027, tt:2502.958\n",
      "Ep:147, loss:0.00002, loss_test:0.05922, lr:4.21e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.046, tt:2522.744\n",
      "Ep:148, loss:0.00002, loss_test:0.05936, lr:4.17e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.054, tt:2540.998\n",
      "Ep:149, loss:0.00002, loss_test:0.05945, lr:4.13e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.046, tt:2556.910\n",
      "Ep:150, loss:0.00002, loss_test:0.05990, lr:4.09e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.033, tt:2572.034\n",
      "Ep:151, loss:0.00002, loss_test:0.05903, lr:4.05e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.017, tt:2586.594\n",
      "Ep:152, loss:0.00002, loss_test:0.05967, lr:4.01e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.005, tt:2601.705\n",
      "Ep:153, loss:0.00002, loss_test:0.06020, lr:3.97e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.010, tt:2619.465\n",
      "Ep:154, loss:0.00002, loss_test:0.05837, lr:3.93e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.013, tt:2637.037\n",
      "Ep:155, loss:0.00002, loss_test:0.05996, lr:3.89e-03, fs:0.85106 (r=0.808,p=0.899),  time:17.006, tt:2652.968\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.318, tt:18.318\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14076, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.961, tt:37.922\n",
      "Ep:2, loss:0.00028, loss_test:0.13915, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:19.394, tt:58.182\n",
      "Ep:3, loss:0.00027, loss_test:0.13668, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:19.771, tt:79.084\n",
      "Ep:4, loss:0.00027, loss_test:0.13312, lr:1.00e-02, fs:0.66429 (r=0.939,p=0.514),  time:19.689, tt:98.445\n",
      "Ep:5, loss:0.00026, loss_test:0.12820, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:19.844, tt:119.062\n",
      "Ep:6, loss:0.00026, loss_test:0.12385, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:19.735, tt:138.142\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12093, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:19.624, tt:156.990\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11843, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:19.523, tt:175.703\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11624, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:19.578, tt:195.779\n",
      "Ep:10, loss:0.00024, loss_test:0.11531, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:19.562, tt:215.182\n",
      "Ep:11, loss:0.00023, loss_test:0.11390, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:19.594, tt:235.125\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11137, lr:1.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:19.662, tt:255.604\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10888, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:19.730, tt:276.218\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00021, loss_test:0.10713, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:19.809, tt:297.139\n",
      "Ep:15, loss:0.00020, loss_test:0.10547, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:19.781, tt:316.499\n",
      "Ep:16, loss:0.00020, loss_test:0.10268, lr:1.00e-02, fs:0.69484 (r=0.747,p=0.649),  time:19.744, tt:335.642\n",
      "Ep:17, loss:0.00019, loss_test:0.10026, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:19.785, tt:356.135\n",
      "Ep:18, loss:0.00018, loss_test:0.09850, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:19.805, tt:376.289\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09743, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:19.824, tt:396.483\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09531, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:19.925, tt:418.432\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09418, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:19.964, tt:439.214\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09329, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:20.008, tt:460.179\n",
      "Ep:23, loss:0.00016, loss_test:0.09129, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:20.027, tt:480.642\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08980, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:20.035, tt:500.886\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08841, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:20.051, tt:521.330\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08710, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:20.034, tt:540.931\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.08612, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:20.077, tt:562.147\n",
      "Ep:28, loss:0.00014, loss_test:0.08432, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:20.057, tt:581.658\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08296, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:20.041, tt:601.226\n",
      "Ep:30, loss:0.00013, loss_test:0.08235, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:20.034, tt:621.045\n",
      "Ep:31, loss:0.00013, loss_test:0.08063, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:20.027, tt:640.855\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:32, loss:0.00012, loss_test:0.08024, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:20.088, tt:662.909\n",
      "Ep:33, loss:0.00012, loss_test:0.07896, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:20.071, tt:682.413\n",
      "Ep:34, loss:0.00012, loss_test:0.07854, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:20.114, tt:703.996\n",
      "Ep:35, loss:0.00011, loss_test:0.07799, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:20.118, tt:724.255\n",
      "Ep:36, loss:0.00011, loss_test:0.07672, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:20.081, tt:742.993\n",
      "Ep:37, loss:0.00011, loss_test:0.07601, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:20.095, tt:763.620\n",
      "Ep:38, loss:0.00011, loss_test:0.07610, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.072, tt:782.826\n",
      "Ep:39, loss:0.00010, loss_test:0.07507, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:20.055, tt:802.203\n",
      "Ep:40, loss:0.00010, loss_test:0.07506, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:20.083, tt:823.395\n",
      "Ep:41, loss:0.00010, loss_test:0.07465, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:20.093, tt:843.911\n",
      "Ep:42, loss:0.00009, loss_test:0.07441, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:20.063, tt:862.714\n",
      "Ep:43, loss:0.00009, loss_test:0.07472, lr:9.90e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.954, tt:877.998\n",
      "Ep:44, loss:0.00009, loss_test:0.07473, lr:9.80e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.892, tt:895.117\n",
      "Ep:45, loss:0.00009, loss_test:0.07447, lr:9.70e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.904, tt:915.569\n",
      "Ep:46, loss:0.00009, loss_test:0.07417, lr:9.61e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.820, tt:931.560\n",
      "Ep:47, loss:0.00008, loss_test:0.07431, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:19.737, tt:947.353\n",
      "Ep:48, loss:0.00008, loss_test:0.07395, lr:9.41e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.703, tt:965.432\n",
      "Ep:49, loss:0.00008, loss_test:0.07374, lr:9.32e-03, fs:0.79798 (r=0.798,p=0.798),  time:19.690, tt:984.482\n",
      "Ep:50, loss:0.00008, loss_test:0.07379, lr:9.23e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.703, tt:1004.849\n",
      "Ep:51, loss:0.00008, loss_test:0.07347, lr:9.14e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.730, tt:1025.947\n",
      "Ep:52, loss:0.00007, loss_test:0.07318, lr:9.04e-03, fs:0.79592 (r=0.788,p=0.804),  time:19.730, tt:1045.706\n",
      "Ep:53, loss:0.00007, loss_test:0.07281, lr:8.95e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.716, tt:1064.649\n",
      "Ep:54, loss:0.00007, loss_test:0.07350, lr:8.86e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.710, tt:1084.032\n",
      "Ep:55, loss:0.00007, loss_test:0.07291, lr:8.78e-03, fs:0.78125 (r=0.758,p=0.806),  time:19.735, tt:1105.162\n",
      "Ep:56, loss:0.00007, loss_test:0.07269, lr:8.69e-03, fs:0.78756 (r=0.768,p=0.809),  time:19.733, tt:1124.789\n",
      "Ep:57, loss:0.00007, loss_test:0.07320, lr:8.60e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.760, tt:1146.080\n",
      "Ep:58, loss:0.00006, loss_test:0.07185, lr:8.51e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.772, tt:1166.553\n",
      "Ep:59, loss:0.00006, loss_test:0.07345, lr:8.43e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.775, tt:1186.529\n",
      "Ep:60, loss:0.00006, loss_test:0.07194, lr:8.35e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.773, tt:1206.137\n",
      "Ep:61, loss:0.00006, loss_test:0.07259, lr:8.26e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.775, tt:1226.052\n",
      "Ep:62, loss:0.00006, loss_test:0.07269, lr:8.18e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.771, tt:1245.543\n",
      "Ep:63, loss:0.00006, loss_test:0.07172, lr:8.10e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.775, tt:1265.622\n",
      "Ep:64, loss:0.00006, loss_test:0.07227, lr:8.02e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.772, tt:1285.195\n",
      "Ep:65, loss:0.00006, loss_test:0.07181, lr:7.94e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.811, tt:1307.543\n",
      "Ep:66, loss:0.00006, loss_test:0.07202, lr:7.86e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.840, tt:1329.309\n",
      "Ep:67, loss:0.00005, loss_test:0.07162, lr:7.78e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.861, tt:1350.577\n",
      "Ep:68, loss:0.00005, loss_test:0.07089, lr:7.70e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.872, tt:1371.192\n",
      "Ep:69, loss:0.00005, loss_test:0.07208, lr:7.62e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.874, tt:1391.174\n",
      "Ep:70, loss:0.00005, loss_test:0.07090, lr:7.55e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.880, tt:1411.465\n",
      "Ep:71, loss:0.00005, loss_test:0.07070, lr:7.47e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.872, tt:1430.817\n",
      "Ep:72, loss:0.00005, loss_test:0.07229, lr:7.40e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.883, tt:1451.431\n",
      "Ep:73, loss:0.00005, loss_test:0.07018, lr:7.32e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.881, tt:1471.207\n",
      "Ep:74, loss:0.00005, loss_test:0.07017, lr:7.25e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.879, tt:1490.947\n",
      "Ep:75, loss:0.00005, loss_test:0.07088, lr:7.18e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.864, tt:1509.658\n",
      "Ep:76, loss:0.00005, loss_test:0.07053, lr:7.11e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.868, tt:1529.850\n",
      "Ep:77, loss:0.00005, loss_test:0.07043, lr:7.03e-03, fs:0.76440 (r=0.737,p=0.793),  time:19.872, tt:1550.033\n",
      "Ep:78, loss:0.00005, loss_test:0.07005, lr:6.96e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.883, tt:1570.722\n",
      "Ep:79, loss:0.00005, loss_test:0.07065, lr:6.89e-03, fs:0.75532 (r=0.717,p=0.798),  time:19.880, tt:1590.429\n",
      "Ep:80, loss:0.00005, loss_test:0.07056, lr:6.83e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.872, tt:1609.649\n",
      "Ep:81, loss:0.00004, loss_test:0.06960, lr:6.76e-03, fs:0.77005 (r=0.727,p=0.818),  time:19.873, tt:1629.619\n",
      "Ep:82, loss:0.00004, loss_test:0.07026, lr:6.69e-03, fs:0.75393 (r=0.727,p=0.783),  time:19.882, tt:1650.217\n",
      "Ep:83, loss:0.00004, loss_test:0.07015, lr:6.62e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.905, tt:1672.037\n",
      "Ep:84, loss:0.00004, loss_test:0.06968, lr:6.56e-03, fs:0.76596 (r=0.727,p=0.809),  time:19.918, tt:1692.996\n",
      "Ep:85, loss:0.00004, loss_test:0.07006, lr:6.49e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.926, tt:1713.616\n",
      "Ep:86, loss:0.00004, loss_test:0.06954, lr:6.43e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.911, tt:1732.264\n",
      "Ep:87, loss:0.00004, loss_test:0.07004, lr:6.36e-03, fs:0.77005 (r=0.727,p=0.818),  time:19.928, tt:1753.626\n",
      "Ep:88, loss:0.00004, loss_test:0.06960, lr:6.30e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.937, tt:1774.382\n",
      "Ep:89, loss:0.00004, loss_test:0.06949, lr:6.24e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.945, tt:1795.042\n",
      "Ep:90, loss:0.00004, loss_test:0.06990, lr:6.17e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.923, tt:1813.029\n",
      "Ep:91, loss:0.00004, loss_test:0.06977, lr:6.11e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.918, tt:1832.425\n",
      "Ep:92, loss:0.00004, loss_test:0.06918, lr:6.05e-03, fs:0.76190 (r=0.727,p=0.800),  time:19.907, tt:1851.388\n",
      "Ep:93, loss:0.00004, loss_test:0.06922, lr:5.99e-03, fs:0.76042 (r=0.737,p=0.785),  time:19.925, tt:1872.947\n",
      "Ep:94, loss:0.00004, loss_test:0.06948, lr:5.93e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.928, tt:1893.175\n",
      "Ep:95, loss:0.00004, loss_test:0.06914, lr:5.87e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.916, tt:1911.981\n",
      "Ep:96, loss:0.00004, loss_test:0.06962, lr:5.81e-03, fs:0.76684 (r=0.747,p=0.787),  time:19.907, tt:1931.024\n",
      "Ep:97, loss:0.00004, loss_test:0.06928, lr:5.75e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.903, tt:1950.513\n",
      "Ep:98, loss:0.00004, loss_test:0.06893, lr:5.70e-03, fs:0.77487 (r=0.747,p=0.804),  time:19.919, tt:1972.017\n",
      "Ep:99, loss:0.00004, loss_test:0.06979, lr:5.64e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.936, tt:1993.580\n",
      "Ep:100, loss:0.00004, loss_test:0.06894, lr:5.58e-03, fs:0.76440 (r=0.737,p=0.793),  time:19.933, tt:2013.238\n",
      "Ep:101, loss:0.00004, loss_test:0.06911, lr:5.53e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.931, tt:2032.951\n",
      "Ep:102, loss:0.00004, loss_test:0.06902, lr:5.47e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.918, tt:2051.537\n",
      "Ep:103, loss:0.00004, loss_test:0.06883, lr:5.42e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.920, tt:2071.668\n",
      "Ep:104, loss:0.00004, loss_test:0.06912, lr:5.36e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.929, tt:2092.582\n",
      "Ep:105, loss:0.00003, loss_test:0.06942, lr:5.31e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.962, tt:2115.975\n",
      "Ep:106, loss:0.00003, loss_test:0.06893, lr:5.26e-03, fs:0.77249 (r=0.737,p=0.811),  time:19.949, tt:2134.525\n",
      "Ep:107, loss:0.00003, loss_test:0.06924, lr:5.20e-03, fs:0.76842 (r=0.737,p=0.802),  time:19.932, tt:2152.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00003, loss_test:0.06894, lr:5.15e-03, fs:0.77660 (r=0.737,p=0.820),  time:19.924, tt:2171.753\n",
      "Ep:109, loss:0.00003, loss_test:0.06944, lr:5.10e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.938, tt:2193.212\n",
      "Ep:110, loss:0.00003, loss_test:0.06893, lr:5.05e-03, fs:0.77660 (r=0.737,p=0.820),  time:19.959, tt:2215.408\n",
      "Ep:111, loss:0.00003, loss_test:0.06891, lr:5.00e-03, fs:0.77838 (r=0.727,p=0.837),  time:19.951, tt:2234.482\n",
      "Ep:112, loss:0.00003, loss_test:0.06919, lr:4.95e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.936, tt:2252.761\n",
      "Ep:113, loss:0.00003, loss_test:0.06928, lr:4.90e-03, fs:0.76344 (r=0.717,p=0.816),  time:19.925, tt:2271.429\n",
      "Ep:114, loss:0.00003, loss_test:0.06866, lr:4.85e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.924, tt:2291.299\n",
      "Ep:115, loss:0.00003, loss_test:0.06908, lr:4.80e-03, fs:0.76757 (r=0.717,p=0.826),  time:19.928, tt:2311.663\n",
      "Ep:116, loss:0.00003, loss_test:0.06862, lr:4.75e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.926, tt:2331.382\n",
      "Ep:117, loss:0.00003, loss_test:0.06899, lr:4.71e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.912, tt:2349.589\n",
      "Ep:118, loss:0.00003, loss_test:0.06971, lr:4.66e-03, fs:0.77419 (r=0.727,p=0.828),  time:19.913, tt:2369.680\n",
      "Ep:119, loss:0.00003, loss_test:0.06888, lr:4.61e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.926, tt:2391.135\n",
      "Ep:120, loss:0.00003, loss_test:0.06855, lr:4.57e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.921, tt:2410.389\n",
      "Ep:121, loss:0.00003, loss_test:0.06899, lr:4.52e-03, fs:0.76757 (r=0.717,p=0.826),  time:19.922, tt:2430.438\n",
      "Ep:122, loss:0.00003, loss_test:0.06915, lr:4.48e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.920, tt:2450.153\n",
      "Ep:123, loss:0.00003, loss_test:0.06861, lr:4.43e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.907, tt:2468.411\n",
      "Ep:124, loss:0.00003, loss_test:0.06932, lr:4.39e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.907, tt:2488.393\n",
      "Ep:125, loss:0.00003, loss_test:0.06913, lr:4.34e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.913, tt:2509.076\n",
      "Ep:126, loss:0.00003, loss_test:0.06888, lr:4.30e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.928, tt:2530.860\n",
      "Ep:127, loss:0.00003, loss_test:0.06903, lr:4.26e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.926, tt:2550.527\n",
      "Ep:128, loss:0.00003, loss_test:0.06885, lr:4.21e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.924, tt:2570.152\n",
      "Ep:129, loss:0.00003, loss_test:0.06859, lr:4.17e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.926, tt:2590.324\n",
      "Ep:130, loss:0.00003, loss_test:0.06906, lr:4.13e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2609.569\n",
      "Ep:131, loss:0.00003, loss_test:0.06949, lr:4.09e-03, fs:0.77174 (r=0.717,p=0.835),  time:19.919, tt:2629.284\n",
      "Ep:132, loss:0.00003, loss_test:0.06869, lr:4.05e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.916, tt:2648.769\n",
      "Ep:133, loss:0.00003, loss_test:0.06900, lr:4.01e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.907, tt:2667.541\n",
      "Ep:134, loss:0.00003, loss_test:0.06931, lr:3.97e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.901, tt:2686.656\n",
      "Ep:135, loss:0.00003, loss_test:0.06908, lr:3.93e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.902, tt:2706.731\n",
      "Ep:136, loss:0.00003, loss_test:0.06863, lr:3.89e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.910, tt:2727.627\n",
      "Ep:137, loss:0.00003, loss_test:0.06901, lr:3.85e-03, fs:0.77596 (r=0.717,p=0.845),  time:19.919, tt:2748.846\n",
      "Ep:138, loss:0.00003, loss_test:0.06948, lr:3.81e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.912, tt:2767.701\n",
      "Ep:139, loss:0.00003, loss_test:0.06861, lr:3.77e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.918, tt:2788.471\n",
      "Ep:140, loss:0.00003, loss_test:0.06908, lr:3.73e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.918, tt:2808.395\n",
      "Ep:141, loss:0.00003, loss_test:0.06972, lr:3.70e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.923, tt:2829.073\n",
      "Ep:142, loss:0.00003, loss_test:0.06901, lr:3.66e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2848.501\n",
      "Ep:143, loss:0.00003, loss_test:0.06892, lr:3.62e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.917, tt:2868.062\n",
      "Ep:144, loss:0.00003, loss_test:0.06980, lr:3.59e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.917, tt:2887.947\n",
      "Ep:145, loss:0.00003, loss_test:0.06927, lr:3.55e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.920, tt:2908.341\n",
      "Ep:146, loss:0.00003, loss_test:0.06890, lr:3.52e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.920, tt:2928.244\n",
      "Ep:147, loss:0.00003, loss_test:0.06955, lr:3.48e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.918, tt:2947.889\n",
      "Ep:148, loss:0.00003, loss_test:0.06963, lr:3.45e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.912, tt:2966.929\n",
      "Ep:149, loss:0.00003, loss_test:0.06899, lr:3.41e-03, fs:0.78022 (r=0.717,p=0.855),  time:19.914, tt:2987.134\n",
      "Ep:150, loss:0.00003, loss_test:0.06928, lr:3.38e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.917, tt:3007.525\n",
      "Ep:151, loss:0.00003, loss_test:0.06977, lr:3.34e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.922, tt:3028.085\n",
      "Ep:152, loss:0.00003, loss_test:0.06892, lr:3.31e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.911, tt:3046.324\n",
      "Ep:153, loss:0.00003, loss_test:0.06897, lr:3.28e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.893, tt:3063.530\n",
      "Ep:154, loss:0.00003, loss_test:0.06968, lr:3.24e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.876, tt:3080.733\n",
      "Ep:155, loss:0.00003, loss_test:0.06965, lr:3.21e-03, fs:0.78889 (r=0.717,p=0.877),  time:19.863, tt:3098.592\n",
      "Ep:156, loss:0.00003, loss_test:0.06862, lr:3.18e-03, fs:0.78453 (r=0.717,p=0.866),  time:19.848, tt:3116.211\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14372, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.571, tt:53.571\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14188, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.751, tt:107.502\n",
      "Ep:2, loss:0.00027, loss_test:0.13839, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.755, tt:161.265\n",
      "Ep:3, loss:0.00026, loss_test:0.13219, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:53.804, tt:215.216\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12122, lr:1.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:53.603, tt:268.014\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11418, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:53.194, tt:319.164\n",
      "Ep:6, loss:0.00022, loss_test:0.11575, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:53.334, tt:373.338\n",
      "Ep:7, loss:0.00022, loss_test:0.11465, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:53.258, tt:426.062\n",
      "Ep:8, loss:0.00021, loss_test:0.11089, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:53.209, tt:478.877\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10802, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:53.164, tt:531.644\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10613, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:53.201, tt:585.214\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10471, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:53.175, tt:638.094\n",
      "Ep:12, loss:0.00019, loss_test:0.10242, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:52.976, tt:688.686\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10077, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:53.073, tt:743.019\n",
      "Ep:14, loss:0.00018, loss_test:0.09987, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:53.145, tt:797.182\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09651, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:53.094, tt:849.508\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00017, loss_test:0.09520, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:53.033, tt:901.566\n",
      "Ep:17, loss:0.00016, loss_test:0.09485, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:52.964, tt:953.353\n",
      "Ep:18, loss:0.00016, loss_test:0.09254, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:52.914, tt:1005.364\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09164, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:52.818, tt:1056.356\n",
      "Ep:20, loss:0.00015, loss_test:0.09133, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:52.878, tt:1110.432\n",
      "Ep:21, loss:0.00014, loss_test:0.08951, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:53.021, tt:1166.463\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08931, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:53.095, tt:1221.176\n",
      "Ep:23, loss:0.00014, loss_test:0.08787, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:53.145, tt:1275.472\n",
      "Ep:24, loss:0.00013, loss_test:0.08679, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:53.131, tt:1328.280\n",
      "Ep:25, loss:0.00013, loss_test:0.08499, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:53.092, tt:1380.380\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08498, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:53.147, tt:1434.963\n",
      "Ep:27, loss:0.00012, loss_test:0.08292, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:53.126, tt:1487.539\n",
      "Ep:28, loss:0.00012, loss_test:0.08205, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:52.912, tt:1534.434\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.08120, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.894, tt:1586.818\n",
      "Ep:30, loss:0.00011, loss_test:0.08007, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.850, tt:1638.362\n",
      "Ep:31, loss:0.00010, loss_test:0.08049, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:52.867, tt:1691.734\n",
      "Ep:32, loss:0.00010, loss_test:0.07846, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:52.844, tt:1743.854\n",
      "Ep:33, loss:0.00010, loss_test:0.07893, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:52.934, tt:1799.769\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07652, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:52.940, tt:1852.895\n",
      "Ep:35, loss:0.00009, loss_test:0.07665, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:52.915, tt:1904.957\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.07600, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:52.941, tt:1958.825\n",
      "Ep:37, loss:0.00009, loss_test:0.07590, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:52.937, tt:2011.606\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.07415, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:52.968, tt:2065.733\n",
      "Ep:39, loss:0.00008, loss_test:0.07510, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:52.968, tt:2118.700\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.07137, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:53.042, tt:2174.720\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.07505, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:53.023, tt:2226.982\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.07122, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:53.007, tt:2279.308\n",
      "Ep:43, loss:0.00007, loss_test:0.07301, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:52.999, tt:2331.976\n",
      "Ep:44, loss:0.00007, loss_test:0.07039, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:52.963, tt:2383.352\n",
      "Ep:45, loss:0.00007, loss_test:0.07067, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:52.962, tt:2436.252\n",
      "Ep:46, loss:0.00007, loss_test:0.07551, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:53.022, tt:2492.052\n",
      "Ep:47, loss:0.00007, loss_test:0.06752, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:53.052, tt:2546.490\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07288, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:53.044, tt:2599.167\n",
      "Ep:49, loss:0.00006, loss_test:0.06884, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:53.066, tt:2653.316\n",
      "Ep:50, loss:0.00006, loss_test:0.06920, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:53.069, tt:2706.502\n",
      "Ep:51, loss:0.00006, loss_test:0.07345, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:53.042, tt:2758.200\n",
      "Ep:52, loss:0.00006, loss_test:0.06862, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:52.985, tt:2808.210\n",
      "Ep:53, loss:0.00005, loss_test:0.06895, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:52.996, tt:2861.771\n",
      "Ep:54, loss:0.00005, loss_test:0.06920, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:53.017, tt:2915.959\n",
      "Ep:55, loss:0.00005, loss_test:0.07224, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.013, tt:2968.711\n",
      "Ep:56, loss:0.00005, loss_test:0.06709, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:53.004, tt:3021.216\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06853, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:52.971, tt:3072.301\n",
      "Ep:58, loss:0.00004, loss_test:0.06815, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:52.943, tt:3123.623\n",
      "Ep:59, loss:0.00004, loss_test:0.06824, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:52.937, tt:3176.223\n",
      "Ep:60, loss:0.00004, loss_test:0.06812, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:52.982, tt:3231.899\n",
      "Ep:61, loss:0.00004, loss_test:0.06731, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:52.992, tt:3285.522\n",
      "Ep:62, loss:0.00004, loss_test:0.06457, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:52.985, tt:3338.030\n",
      "Ep:63, loss:0.00004, loss_test:0.06840, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:52.957, tt:3389.249\n",
      "Ep:64, loss:0.00004, loss_test:0.07255, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:52.993, tt:3444.543\n",
      "Ep:65, loss:0.00003, loss_test:0.06330, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:52.981, tt:3496.771\n",
      "Ep:66, loss:0.00003, loss_test:0.06937, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:52.967, tt:3548.796\n",
      "Ep:67, loss:0.00003, loss_test:0.06436, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:52.956, tt:3601.011\n",
      "Ep:68, loss:0.00003, loss_test:0.06610, lr:9.90e-03, fs:0.83978 (r=0.768,p=0.927),  time:52.930, tt:3652.195\n",
      "Ep:69, loss:0.00003, loss_test:0.07118, lr:9.80e-03, fs:0.77011 (r=0.677,p=0.893),  time:52.929, tt:3705.035\n",
      "Ep:70, loss:0.00003, loss_test:0.06579, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:52.945, tt:3759.115\n",
      "Ep:71, loss:0.00003, loss_test:0.06883, lr:9.61e-03, fs:0.79310 (r=0.697,p=0.920),  time:52.951, tt:3812.443\n",
      "Ep:72, loss:0.00003, loss_test:0.07095, lr:9.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:52.976, tt:3867.284\n",
      "Ep:73, loss:0.00003, loss_test:0.06413, lr:9.41e-03, fs:0.84571 (r=0.747,p=0.974),  time:52.953, tt:3918.554\n",
      "Ep:74, loss:0.00003, loss_test:0.07079, lr:9.32e-03, fs:0.79348 (r=0.737,p=0.859),  time:52.950, tt:3971.236\n",
      "Ep:75, loss:0.00003, loss_test:0.07446, lr:9.23e-03, fs:0.75000 (r=0.636,p=0.913),  time:52.965, tt:4025.328\n",
      "Ep:76, loss:0.00003, loss_test:0.06684, lr:9.14e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.979, tt:4079.396\n",
      "Ep:77, loss:0.00003, loss_test:0.07296, lr:9.04e-03, fs:0.74699 (r=0.626,p=0.925),  time:52.975, tt:4132.017\n",
      "Ep:78, loss:0.00003, loss_test:0.06732, lr:8.95e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.966, tt:4184.344\n",
      "Ep:79, loss:0.00002, loss_test:0.06913, lr:8.86e-03, fs:0.79532 (r=0.687,p=0.944),  time:52.985, tt:4238.767\n",
      "Ep:80, loss:0.00003, loss_test:0.06573, lr:8.78e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.974, tt:4290.880\n",
      "Ep:81, loss:0.00002, loss_test:0.07020, lr:8.69e-03, fs:0.77844 (r=0.657,p=0.956),  time:53.007, tt:4346.605\n",
      "Ep:82, loss:0.00002, loss_test:0.06407, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:53.011, tt:4399.940\n",
      "Ep:83, loss:0.00002, loss_test:0.07045, lr:8.51e-03, fs:0.75904 (r=0.636,p=0.940),  time:53.040, tt:4455.344\n",
      "Ep:84, loss:0.00002, loss_test:0.06625, lr:8.43e-03, fs:0.80925 (r=0.707,p=0.946),  time:53.021, tt:4506.802\n",
      "Ep:85, loss:0.00002, loss_test:0.06945, lr:8.35e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.022, tt:4559.902\n",
      "Ep:86, loss:0.00002, loss_test:0.06527, lr:8.26e-03, fs:0.80460 (r=0.707,p=0.933),  time:53.036, tt:4614.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:87, loss:0.00002, loss_test:0.07163, lr:8.18e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.032, tt:4666.854\n",
      "Ep:88, loss:0.00002, loss_test:0.06682, lr:8.10e-03, fs:0.78107 (r=0.667,p=0.943),  time:53.048, tt:4721.277\n",
      "Ep:89, loss:0.00002, loss_test:0.07018, lr:8.02e-03, fs:0.74074 (r=0.606,p=0.952),  time:53.060, tt:4775.413\n",
      "Ep:90, loss:0.00002, loss_test:0.07049, lr:7.94e-03, fs:0.74390 (r=0.616,p=0.938),  time:53.075, tt:4829.809\n",
      "Ep:91, loss:0.00001, loss_test:0.06910, lr:7.86e-03, fs:0.75152 (r=0.626,p=0.939),  time:53.059, tt:4881.441\n",
      "Ep:92, loss:0.00001, loss_test:0.07112, lr:7.78e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.063, tt:4934.893\n",
      "Ep:93, loss:0.00001, loss_test:0.06938, lr:7.70e-03, fs:0.75152 (r=0.626,p=0.939),  time:53.054, tt:4987.071\n",
      "Ep:94, loss:0.00001, loss_test:0.07356, lr:7.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.056, tt:5040.345\n",
      "Ep:95, loss:0.00001, loss_test:0.07119, lr:7.55e-03, fs:0.74390 (r=0.616,p=0.938),  time:53.067, tt:5094.426\n",
      "Ep:96, loss:0.00001, loss_test:0.07325, lr:7.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.071, tt:5147.918\n",
      "Ep:97, loss:0.00001, loss_test:0.07116, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.059, tt:5199.778\n",
      "Ep:98, loss:0.00001, loss_test:0.07251, lr:7.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.048, tt:5251.774\n",
      "Ep:99, loss:0.00001, loss_test:0.07203, lr:7.25e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.053, tt:5305.282\n",
      "Ep:100, loss:0.00001, loss_test:0.07344, lr:7.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:53.059, tt:5358.915\n",
      "Ep:101, loss:0.00001, loss_test:0.07366, lr:7.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.961, tt:5402.035\n",
      "Ep:102, loss:0.00001, loss_test:0.07280, lr:7.03e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.820, tt:5440.445\n",
      "Ep:103, loss:0.00001, loss_test:0.07512, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.728, tt:5483.705\n",
      "Ep:104, loss:0.00001, loss_test:0.07366, lr:6.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.713, tt:5534.833\n",
      "Ep:105, loss:0.00001, loss_test:0.07661, lr:6.83e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.714, tt:5587.725\n",
      "Ep:106, loss:0.00001, loss_test:0.07520, lr:6.76e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.702, tt:5639.061\n",
      "Ep:107, loss:0.00001, loss_test:0.07552, lr:6.69e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.696, tt:5691.140\n",
      "Ep:108, loss:0.00001, loss_test:0.07587, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.669, tt:5740.919\n",
      "Ep:109, loss:0.00001, loss_test:0.07568, lr:6.56e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.681, tt:5794.889\n",
      "Ep:110, loss:0.00001, loss_test:0.07775, lr:6.49e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.676, tt:5847.083\n",
      "Ep:111, loss:0.00001, loss_test:0.07423, lr:6.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.668, tt:5898.839\n",
      "Ep:112, loss:0.00001, loss_test:0.07778, lr:6.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.647, tt:5949.066\n",
      "Ep:113, loss:0.00001, loss_test:0.07492, lr:6.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.648, tt:6001.829\n",
      "Ep:114, loss:0.00001, loss_test:0.08077, lr:6.24e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.649, tt:6054.660\n",
      "Ep:115, loss:0.00001, loss_test:0.07499, lr:6.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.635, tt:6105.652\n",
      "Ep:116, loss:0.00001, loss_test:0.07905, lr:6.11e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.658, tt:6160.984\n",
      "Ep:117, loss:0.00001, loss_test:0.07824, lr:6.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.646, tt:6212.245\n",
      "Ep:118, loss:0.00001, loss_test:0.07865, lr:5.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.636, tt:6263.645\n",
      "Ep:119, loss:0.00001, loss_test:0.07869, lr:5.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.625, tt:6314.956\n",
      "Ep:120, loss:0.00001, loss_test:0.07825, lr:5.87e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.629, tt:6368.072\n",
      "Ep:121, loss:0.00001, loss_test:0.07919, lr:5.81e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.624, tt:6420.126\n",
      "Ep:122, loss:0.00001, loss_test:0.07690, lr:5.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.615, tt:6471.685\n",
      "Ep:123, loss:0.00001, loss_test:0.08226, lr:5.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.605, tt:6522.981\n",
      "Ep:124, loss:0.00001, loss_test:0.07778, lr:5.64e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.599, tt:6574.937\n",
      "Ep:125, loss:0.00001, loss_test:0.08104, lr:5.58e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.614, tt:6629.369\n",
      "Ep:126, loss:0.00001, loss_test:0.07923, lr:5.53e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.598, tt:6680.008\n",
      "Ep:127, loss:0.00001, loss_test:0.07846, lr:5.47e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.592, tt:6731.783\n",
      "Ep:128, loss:0.00001, loss_test:0.08204, lr:5.42e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.584, tt:6783.322\n",
      "Ep:129, loss:0.00001, loss_test:0.07901, lr:5.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.582, tt:6835.696\n",
      "Ep:130, loss:0.00001, loss_test:0.08180, lr:5.31e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.576, tt:6887.495\n",
      "Ep:131, loss:0.00001, loss_test:0.08031, lr:5.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.581, tt:6940.637\n",
      "Ep:132, loss:0.00001, loss_test:0.08121, lr:5.20e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.560, tt:6990.500\n",
      "Ep:133, loss:0.00000, loss_test:0.08016, lr:5.15e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.547, tt:7041.285\n",
      "Ep:134, loss:0.00000, loss_test:0.08011, lr:5.10e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.549, tt:7094.068\n",
      "Ep:135, loss:0.00000, loss_test:0.08044, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.541, tt:7145.540\n",
      "Ep:136, loss:0.00000, loss_test:0.08069, lr:5.00e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.549, tt:7199.151\n",
      "Ep:137, loss:0.00000, loss_test:0.08167, lr:4.95e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.539, tt:7250.449\n",
      "Ep:138, loss:0.00000, loss_test:0.08108, lr:4.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.522, tt:7300.503\n",
      "Ep:139, loss:0.00000, loss_test:0.08047, lr:4.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.536, tt:7355.054\n",
      "Ep:140, loss:0.00000, loss_test:0.08257, lr:4.80e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.516, tt:7404.774\n",
      "Ep:141, loss:0.00000, loss_test:0.08140, lr:4.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.528, tt:7458.928\n",
      "Ep:142, loss:0.00000, loss_test:0.08164, lr:4.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.502, tt:7507.855\n",
      "Ep:143, loss:0.00000, loss_test:0.08212, lr:4.66e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.496, tt:7559.431\n",
      "Ep:144, loss:0.00000, loss_test:0.08057, lr:4.61e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.488, tt:7610.714\n",
      "Ep:145, loss:0.00000, loss_test:0.08427, lr:4.57e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.479, tt:7661.929\n",
      "Ep:146, loss:0.00000, loss_test:0.08036, lr:4.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.474, tt:7713.718\n",
      "Ep:147, loss:0.00000, loss_test:0.08335, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.471, tt:7765.702\n",
      "Ep:148, loss:0.00000, loss_test:0.08196, lr:4.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.467, tt:7817.594\n",
      "Ep:149, loss:0.00000, loss_test:0.08493, lr:4.39e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.459, tt:7868.854\n",
      "Ep:150, loss:0.00000, loss_test:0.08464, lr:4.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.450, tt:7920.026\n",
      "Ep:151, loss:0.00000, loss_test:0.08082, lr:4.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.430, tt:7969.359\n",
      "Ep:152, loss:0.00000, loss_test:0.08609, lr:4.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.427, tt:8021.301\n",
      "Ep:153, loss:0.00000, loss_test:0.08314, lr:4.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.418, tt:8072.352\n",
      "Ep:154, loss:0.00000, loss_test:0.08516, lr:4.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:52.415, tt:8124.379\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:0, loss:0.00028, loss_test:0.14496, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.559, tt:20.559\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14438, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.518, tt:39.036\n",
      "Ep:2, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.127, tt:60.380\n",
      "Ep:3, loss:0.00028, loss_test:0.14195, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.815, tt:79.262\n",
      "Ep:4, loss:0.00028, loss_test:0.13979, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.216, tt:101.080\n",
      "Ep:5, loss:0.00027, loss_test:0.13632, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:19.897, tt:119.384\n",
      "Ep:6, loss:0.00026, loss_test:0.13053, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:19.957, tt:139.702\n",
      "Ep:7, loss:0.00025, loss_test:0.12069, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:19.875, tt:158.998\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10880, lr:1.00e-02, fs:0.66667 (r=0.727,p=0.615),  time:19.727, tt:177.546\n",
      "Ep:9, loss:0.00023, loss_test:0.10434, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:19.717, tt:197.170\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10678, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:19.834, tt:218.179\n",
      "Ep:11, loss:0.00021, loss_test:0.10455, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:20.071, tt:240.850\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09619, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:19.915, tt:258.894\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09319, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:19.992, tt:279.890\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09199, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:19.818, tt:297.264\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08735, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:19.857, tt:317.710\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08442, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:19.773, tt:336.142\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08296, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:19.920, tt:358.562\n",
      "Ep:18, loss:0.00016, loss_test:0.08007, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:19.868, tt:377.500\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07778, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:19.927, tt:398.548\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.07693, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:19.906, tt:418.029\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07416, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:19.987, tt:439.715\n",
      "Ep:22, loss:0.00013, loss_test:0.07291, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:20.064, tt:461.482\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.07150, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:20.036, tt:480.853\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07000, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:20.096, tt:502.403\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.06932, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:20.117, tt:523.048\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.06823, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:20.128, tt:543.451\n",
      "Ep:27, loss:0.00011, loss_test:0.06691, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:20.102, tt:562.857\n",
      "Ep:28, loss:0.00010, loss_test:0.06738, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:20.118, tt:583.436\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.06449, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:20.065, tt:601.960\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.06480, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:20.106, tt:623.288\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.06438, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:20.041, tt:641.314\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06407, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:20.089, tt:662.944\n",
      "Ep:33, loss:0.00008, loss_test:0.06342, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:20.080, tt:682.727\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.06128, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:20.089, tt:703.118\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.06132, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:20.110, tt:723.951\n",
      "Ep:36, loss:0.00007, loss_test:0.06120, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:20.062, tt:742.293\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.06058, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:20.094, tt:763.570\n",
      "Ep:38, loss:0.00007, loss_test:0.06140, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:20.088, tt:783.422\n",
      "Ep:39, loss:0.00006, loss_test:0.05988, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:20.114, tt:804.574\n",
      "Ep:40, loss:0.00006, loss_test:0.06139, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:20.113, tt:824.651\n",
      "Ep:41, loss:0.00006, loss_test:0.06004, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:20.140, tt:845.859\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06100, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:20.122, tt:865.235\n",
      "Ep:43, loss:0.00005, loss_test:0.06061, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:20.139, tt:886.128\n",
      "Ep:44, loss:0.00005, loss_test:0.06178, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.133, tt:905.975\n",
      "Ep:45, loss:0.00005, loss_test:0.05967, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:20.141, tt:926.508\n",
      "Ep:46, loss:0.00005, loss_test:0.06057, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.127, tt:945.991\n",
      "Ep:47, loss:0.00004, loss_test:0.05818, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:20.173, tt:968.311\n",
      "Ep:48, loss:0.00004, loss_test:0.06179, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:20.166, tt:988.132\n",
      "Ep:49, loss:0.00004, loss_test:0.06160, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:20.219, tt:1010.951\n",
      "Ep:50, loss:0.00004, loss_test:0.06075, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:20.198, tt:1030.091\n",
      "Ep:51, loss:0.00004, loss_test:0.06326, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.208, tt:1050.816\n",
      "Ep:52, loss:0.00004, loss_test:0.05896, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:20.207, tt:1070.977\n",
      "Ep:53, loss:0.00004, loss_test:0.06284, lr:9.90e-03, fs:0.82682 (r=0.747,p=0.925),  time:20.173, tt:1089.357\n",
      "Ep:54, loss:0.00004, loss_test:0.05866, lr:9.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:20.187, tt:1110.258\n",
      "Ep:55, loss:0.00004, loss_test:0.05992, lr:9.70e-03, fs:0.85405 (r=0.798,p=0.919),  time:20.164, tt:1129.166\n",
      "Ep:56, loss:0.00003, loss_test:0.05931, lr:9.61e-03, fs:0.86911 (r=0.838,p=0.902),  time:20.206, tt:1151.713\n",
      "Ep:57, loss:0.00003, loss_test:0.06326, lr:9.51e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.217, tt:1172.596\n",
      "Ep:58, loss:0.00003, loss_test:0.05807, lr:9.41e-03, fs:0.87047 (r=0.848,p=0.894),  time:20.237, tt:1194.008\n",
      "Ep:59, loss:0.00003, loss_test:0.06712, lr:9.32e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.235, tt:1214.077\n",
      "Ep:60, loss:0.00003, loss_test:0.05950, lr:9.23e-03, fs:0.83871 (r=0.788,p=0.897),  time:20.256, tt:1235.615\n",
      "Ep:61, loss:0.00003, loss_test:0.06299, lr:9.14e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.251, tt:1255.561\n",
      "Ep:62, loss:0.00003, loss_test:0.06145, lr:9.04e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.233, tt:1274.689\n",
      "Ep:63, loss:0.00003, loss_test:0.05902, lr:8.95e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.218, tt:1293.954\n",
      "Ep:64, loss:0.00002, loss_test:0.06321, lr:8.86e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.225, tt:1314.597\n",
      "Ep:65, loss:0.00002, loss_test:0.05942, lr:8.78e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.199, tt:1333.109\n",
      "Ep:66, loss:0.00002, loss_test:0.06177, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.191, tt:1352.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00002, loss_test:0.05987, lr:8.60e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.198, tt:1373.435\n",
      "Ep:68, loss:0.00002, loss_test:0.06267, lr:8.51e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.204, tt:1394.053\n",
      "Ep:69, loss:0.00002, loss_test:0.06162, lr:8.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.223, tt:1415.593\n",
      "Ep:70, loss:0.00002, loss_test:0.06001, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.219, tt:1435.572\n",
      "Ep:71, loss:0.00002, loss_test:0.06273, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.240, tt:1457.271\n",
      "Ep:72, loss:0.00002, loss_test:0.06239, lr:8.18e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.275, tt:1480.066\n",
      "Ep:73, loss:0.00002, loss_test:0.06143, lr:8.10e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.302, tt:1502.330\n",
      "Ep:74, loss:0.00002, loss_test:0.06353, lr:8.02e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.329, tt:1524.658\n",
      "Ep:75, loss:0.00002, loss_test:0.06099, lr:7.94e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.343, tt:1546.053\n",
      "Ep:76, loss:0.00002, loss_test:0.06250, lr:7.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:1566.424\n",
      "Ep:77, loss:0.00002, loss_test:0.06266, lr:7.78e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:1586.116\n",
      "Ep:78, loss:0.00002, loss_test:0.06438, lr:7.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.336, tt:1606.517\n",
      "Ep:79, loss:0.00001, loss_test:0.05957, lr:7.62e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.334, tt:1626.686\n",
      "Ep:80, loss:0.00001, loss_test:0.06780, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.312, tt:1645.297\n",
      "Ep:81, loss:0.00001, loss_test:0.06171, lr:7.47e-03, fs:0.80226 (r=0.717,p=0.910),  time:20.329, tt:1666.978\n",
      "Ep:82, loss:0.00001, loss_test:0.06410, lr:7.40e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.324, tt:1686.875\n",
      "Ep:83, loss:0.00001, loss_test:0.06360, lr:7.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.324, tt:1707.254\n",
      "Ep:84, loss:0.00001, loss_test:0.06688, lr:7.25e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.330, tt:1728.043\n",
      "Ep:85, loss:0.00001, loss_test:0.06153, lr:7.18e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.323, tt:1747.794\n",
      "Ep:86, loss:0.00001, loss_test:0.06731, lr:7.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.320, tt:1767.821\n",
      "Ep:87, loss:0.00001, loss_test:0.06219, lr:7.03e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.350, tt:1790.767\n",
      "Ep:88, loss:0.00001, loss_test:0.06828, lr:6.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.352, tt:1811.294\n",
      "Ep:89, loss:0.00001, loss_test:0.06365, lr:6.89e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.363, tt:1832.697\n",
      "Ep:90, loss:0.00001, loss_test:0.06764, lr:6.83e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.351, tt:1851.904\n",
      "Ep:91, loss:0.00001, loss_test:0.06362, lr:6.76e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:1871.577\n",
      "Ep:92, loss:0.00001, loss_test:0.06526, lr:6.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.328, tt:1890.467\n",
      "Ep:93, loss:0.00001, loss_test:0.06423, lr:6.62e-03, fs:0.80682 (r=0.717,p=0.922),  time:20.324, tt:1910.422\n",
      "Ep:94, loss:0.00001, loss_test:0.06633, lr:6.56e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.309, tt:1929.381\n",
      "Ep:95, loss:0.00001, loss_test:0.06720, lr:6.49e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.296, tt:1948.449\n",
      "Ep:96, loss:0.00001, loss_test:0.06478, lr:6.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.284, tt:1967.508\n",
      "Ep:97, loss:0.00001, loss_test:0.06722, lr:6.36e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.272, tt:1986.671\n",
      "Ep:98, loss:0.00001, loss_test:0.06497, lr:6.30e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.317, tt:2011.346\n",
      "Ep:99, loss:0.00001, loss_test:0.06629, lr:6.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.318, tt:2031.773\n",
      "Ep:100, loss:0.00001, loss_test:0.06557, lr:6.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.340, tt:2054.317\n",
      "Ep:101, loss:0.00001, loss_test:0.06785, lr:6.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.354, tt:2076.148\n",
      "Ep:102, loss:0.00001, loss_test:0.06652, lr:6.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.367, tt:2097.772\n",
      "Ep:103, loss:0.00001, loss_test:0.06653, lr:5.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.369, tt:2118.412\n",
      "Ep:104, loss:0.00001, loss_test:0.06695, lr:5.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.371, tt:2138.927\n",
      "Ep:105, loss:0.00001, loss_test:0.06573, lr:5.87e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.373, tt:2159.494\n",
      "Ep:106, loss:0.00001, loss_test:0.06627, lr:5.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.359, tt:2178.421\n",
      "Ep:107, loss:0.00001, loss_test:0.06618, lr:5.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.361, tt:2198.963\n",
      "Ep:108, loss:0.00001, loss_test:0.06499, lr:5.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2218.459\n",
      "Ep:109, loss:0.00001, loss_test:0.06830, lr:5.64e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.356, tt:2239.112\n",
      "Ep:110, loss:0.00001, loss_test:0.06569, lr:5.58e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2259.215\n",
      "Ep:111, loss:0.00001, loss_test:0.06711, lr:5.53e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.346, tt:2278.738\n",
      "Ep:112, loss:0.00001, loss_test:0.06577, lr:5.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.338, tt:2298.249\n",
      "Ep:113, loss:0.00001, loss_test:0.06724, lr:5.42e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.339, tt:2318.666\n",
      "Ep:114, loss:0.00001, loss_test:0.06732, lr:5.36e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.330, tt:2337.913\n",
      "Ep:115, loss:0.00001, loss_test:0.06604, lr:5.31e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.346, tt:2360.153\n",
      "Ep:116, loss:0.00001, loss_test:0.06704, lr:5.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2382.393\n",
      "Ep:117, loss:0.00001, loss_test:0.06598, lr:5.20e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2402.709\n",
      "Ep:118, loss:0.00001, loss_test:0.06857, lr:5.15e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.361, tt:2422.960\n",
      "Ep:119, loss:0.00001, loss_test:0.06543, lr:5.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.364, tt:2443.691\n",
      "Ep:120, loss:0.00001, loss_test:0.06723, lr:5.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.361, tt:2463.737\n",
      "Ep:121, loss:0.00001, loss_test:0.06717, lr:5.00e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.354, tt:2483.167\n",
      "Ep:122, loss:0.00001, loss_test:0.06635, lr:4.95e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2502.450\n",
      "Ep:123, loss:0.00001, loss_test:0.06774, lr:4.90e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.334, tt:2521.354\n",
      "Ep:124, loss:0.00001, loss_test:0.06751, lr:4.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.340, tt:2542.477\n",
      "Ep:125, loss:0.00001, loss_test:0.06792, lr:4.80e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.347, tt:2563.736\n",
      "Ep:126, loss:0.00001, loss_test:0.06716, lr:4.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.342, tt:2583.384\n",
      "Ep:127, loss:0.00001, loss_test:0.06807, lr:4.71e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.333, tt:2602.579\n",
      "Ep:128, loss:0.00001, loss_test:0.06901, lr:4.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.356, tt:2625.909\n",
      "Ep:129, loss:0.00001, loss_test:0.06610, lr:4.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.350, tt:2645.445\n",
      "Ep:130, loss:0.00001, loss_test:0.06909, lr:4.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.362, tt:2667.397\n",
      "Ep:131, loss:0.00001, loss_test:0.06733, lr:4.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.353, tt:2686.641\n",
      "Ep:132, loss:0.00001, loss_test:0.06700, lr:4.48e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.344, tt:2705.693\n",
      "Ep:133, loss:0.00001, loss_test:0.06796, lr:4.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.339, tt:2725.466\n",
      "Ep:134, loss:0.00001, loss_test:0.06716, lr:4.39e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:2745.261\n",
      "Ep:135, loss:0.00001, loss_test:0.06827, lr:4.34e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.333, tt:2765.236\n",
      "Ep:136, loss:0.00001, loss_test:0.06708, lr:4.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.336, tt:2786.047\n",
      "Ep:137, loss:0.00001, loss_test:0.06694, lr:4.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:2807.311\n",
      "Ep:138, loss:0.00001, loss_test:0.06856, lr:4.21e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.349, tt:2828.474\n",
      "Ep:139, loss:0.00001, loss_test:0.06764, lr:4.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.359, tt:2850.238\n",
      "Ep:140, loss:0.00001, loss_test:0.06830, lr:4.13e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.357, tt:2870.332\n",
      "Ep:141, loss:0.00001, loss_test:0.06888, lr:4.09e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.357, tt:2890.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.06669, lr:4.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.347, tt:2909.676\n",
      "Ep:143, loss:0.00000, loss_test:0.06860, lr:4.01e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.344, tt:2929.500\n",
      "Ep:144, loss:0.00000, loss_test:0.06811, lr:3.97e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2949.981\n",
      "Ep:145, loss:0.00000, loss_test:0.06766, lr:3.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:20.348, tt:2970.828\n",
      "Ep:146, loss:0.00000, loss_test:0.06817, lr:3.89e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.345, tt:2990.735\n",
      "Ep:147, loss:0.00000, loss_test:0.06709, lr:3.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.343, tt:3010.702\n",
      "Ep:148, loss:0.00000, loss_test:0.06937, lr:3.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.341, tt:3030.820\n",
      "Ep:149, loss:0.00000, loss_test:0.06958, lr:3.77e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.334, tt:3050.072\n",
      "Ep:150, loss:0.00000, loss_test:0.06728, lr:3.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.335, tt:3070.518\n",
      "Ep:151, loss:0.00000, loss_test:0.06921, lr:3.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.329, tt:3089.942\n",
      "Ep:152, loss:0.00000, loss_test:0.06903, lr:3.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.322, tt:3109.260\n",
      "Ep:153, loss:0.00000, loss_test:0.06721, lr:3.62e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.304, tt:3126.766\n",
      "Ep:154, loss:0.00000, loss_test:0.06897, lr:3.59e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.295, tt:3145.762\n",
      "Ep:155, loss:0.00000, loss_test:0.06800, lr:3.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:20.292, tt:3165.491\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14235, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:25.796, tt:25.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14072, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:24.250, tt:48.500\n",
      "Ep:2, loss:0.00027, loss_test:0.13771, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:24.311, tt:72.934\n",
      "Ep:3, loss:0.00027, loss_test:0.13296, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:24.136, tt:96.542\n",
      "Ep:4, loss:0.00026, loss_test:0.12804, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:23.915, tt:119.574\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12366, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:23.770, tt:142.620\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11932, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:23.706, tt:165.942\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11565, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:23.641, tt:189.129\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11208, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:23.574, tt:212.167\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10581, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:23.695, tt:236.955\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10330, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:23.650, tt:260.152\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10248, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:23.670, tt:284.042\n",
      "Ep:12, loss:0.00019, loss_test:0.09773, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:23.586, tt:306.622\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09461, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:23.775, tt:332.850\n",
      "Ep:14, loss:0.00017, loss_test:0.09402, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:23.919, tt:358.779\n",
      "Ep:15, loss:0.00017, loss_test:0.09087, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:23.893, tt:382.287\n",
      "Ep:16, loss:0.00016, loss_test:0.08982, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:24.001, tt:408.020\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08575, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:23.927, tt:430.690\n",
      "Ep:18, loss:0.00014, loss_test:0.08379, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:23.967, tt:455.364\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08294, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:23.855, tt:477.091\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08061, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:23.966, tt:503.283\n",
      "Ep:21, loss:0.00013, loss_test:0.07952, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:23.912, tt:526.066\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07760, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:23.905, tt:549.814\n",
      "Ep:23, loss:0.00012, loss_test:0.07619, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:23.986, tt:575.671\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07490, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:23.922, tt:598.042\n",
      "Ep:25, loss:0.00011, loss_test:0.07338, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:23.954, tt:622.803\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07174, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:23.896, tt:645.190\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07088, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:23.937, tt:670.235\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.07016, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:23.883, tt:692.598\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.06905, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:23.903, tt:717.077\n",
      "Ep:30, loss:0.00009, loss_test:0.06877, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:23.829, tt:738.703\n",
      "Ep:31, loss:0.00008, loss_test:0.06774, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:23.751, tt:760.022\n",
      "Ep:32, loss:0.00008, loss_test:0.06738, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:23.607, tt:779.031\n",
      "Ep:33, loss:0.00008, loss_test:0.06677, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:23.534, tt:800.166\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06574, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:23.374, tt:818.092\n",
      "Ep:35, loss:0.00007, loss_test:0.06638, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:23.267, tt:837.600\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.06505, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:23.192, tt:858.112\n",
      "Ep:37, loss:0.00006, loss_test:0.06572, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:23.216, tt:882.211\n",
      "Ep:38, loss:0.00006, loss_test:0.06400, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:23.272, tt:907.598\n",
      "Ep:39, loss:0.00006, loss_test:0.06449, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:23.239, tt:929.550\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.06279, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:23.244, tt:953.005\n",
      "Ep:41, loss:0.00006, loss_test:0.06285, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:23.258, tt:976.817\n",
      "Ep:42, loss:0.00005, loss_test:0.06220, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:23.334, tt:1003.370\n",
      "Ep:43, loss:0.00005, loss_test:0.06110, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:23.305, tt:1025.440\n",
      "Ep:44, loss:0.00005, loss_test:0.06131, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:23.369, tt:1051.623\n",
      "Ep:45, loss:0.00005, loss_test:0.06041, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:23.364, tt:1074.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00005, loss_test:0.06106, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:23.365, tt:1098.176\n",
      "Ep:47, loss:0.00004, loss_test:0.06019, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:23.378, tt:1122.124\n",
      "Ep:48, loss:0.00004, loss_test:0.06053, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:23.362, tt:1144.721\n",
      "Ep:49, loss:0.00004, loss_test:0.05943, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:23.368, tt:1168.393\n",
      "Ep:50, loss:0.00004, loss_test:0.06046, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:23.365, tt:1191.637\n",
      "Ep:51, loss:0.00004, loss_test:0.05919, lr:9.90e-03, fs:0.84375 (r=0.818,p=0.871),  time:23.406, tt:1217.125\n",
      "Ep:52, loss:0.00004, loss_test:0.05927, lr:9.80e-03, fs:0.83598 (r=0.798,p=0.878),  time:23.426, tt:1241.597\n",
      "Ep:53, loss:0.00004, loss_test:0.05806, lr:9.70e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.414, tt:1264.383\n",
      "Ep:54, loss:0.00004, loss_test:0.05897, lr:9.61e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.393, tt:1286.590\n",
      "Ep:55, loss:0.00003, loss_test:0.05811, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.421, tt:1311.549\n",
      "Ep:56, loss:0.00003, loss_test:0.05785, lr:9.41e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.446, tt:1336.449\n",
      "Ep:57, loss:0.00003, loss_test:0.05814, lr:9.32e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.444, tt:1359.733\n",
      "Ep:58, loss:0.00003, loss_test:0.05733, lr:9.23e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.476, tt:1385.113\n",
      "Ep:59, loss:0.00003, loss_test:0.05732, lr:9.14e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.470, tt:1408.218\n",
      "Ep:60, loss:0.00003, loss_test:0.05822, lr:9.04e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.503, tt:1433.654\n",
      "Ep:61, loss:0.00003, loss_test:0.05800, lr:8.95e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.490, tt:1456.400\n",
      "Ep:62, loss:0.00003, loss_test:0.05712, lr:8.86e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.513, tt:1481.310\n",
      "Ep:63, loss:0.00003, loss_test:0.05807, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:23.519, tt:1505.224\n",
      "Ep:64, loss:0.00003, loss_test:0.05669, lr:8.69e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.518, tt:1528.670\n",
      "Ep:65, loss:0.00003, loss_test:0.05662, lr:8.60e-03, fs:0.85106 (r=0.808,p=0.899),  time:23.533, tt:1553.209\n",
      "Ep:66, loss:0.00003, loss_test:0.05733, lr:8.51e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.534, tt:1576.750\n",
      "Ep:67, loss:0.00002, loss_test:0.05542, lr:8.43e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.550, tt:1601.368\n",
      "Ep:68, loss:0.00002, loss_test:0.05533, lr:8.35e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.558, tt:1625.479\n",
      "Ep:69, loss:0.00002, loss_test:0.05714, lr:8.26e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.601, tt:1652.082\n",
      "Ep:70, loss:0.00002, loss_test:0.05511, lr:8.18e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.588, tt:1674.766\n",
      "Ep:71, loss:0.00002, loss_test:0.05620, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.621, tt:1700.705\n",
      "Ep:72, loss:0.00002, loss_test:0.05478, lr:8.02e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.616, tt:1723.983\n",
      "Ep:73, loss:0.00002, loss_test:0.05554, lr:7.94e-03, fs:0.84817 (r=0.818,p=0.880),  time:23.594, tt:1745.957\n",
      "Ep:74, loss:0.00002, loss_test:0.05411, lr:7.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:23.619, tt:1771.400\n",
      "Ep:75, loss:0.00002, loss_test:0.05422, lr:7.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.621, tt:1795.215\n",
      "Ep:76, loss:0.00002, loss_test:0.05453, lr:7.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.665, tt:1822.234\n",
      "Ep:77, loss:0.00002, loss_test:0.05368, lr:7.62e-03, fs:0.85714 (r=0.818,p=0.900),  time:23.648, tt:1844.506\n",
      "Ep:78, loss:0.00002, loss_test:0.05422, lr:7.55e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.681, tt:1870.779\n",
      "Ep:79, loss:0.00002, loss_test:0.05445, lr:7.47e-03, fs:0.85263 (r=0.818,p=0.890),  time:23.664, tt:1893.134\n",
      "Ep:80, loss:0.00002, loss_test:0.05342, lr:7.40e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.690, tt:1918.887\n",
      "Ep:81, loss:0.00002, loss_test:0.05497, lr:7.32e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.703, tt:1943.674\n",
      "Ep:82, loss:0.00002, loss_test:0.05337, lr:7.25e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.705, tt:1967.477\n",
      "Ep:83, loss:0.00002, loss_test:0.05438, lr:7.18e-03, fs:0.85864 (r=0.828,p=0.891),  time:23.716, tt:1992.137\n",
      "Ep:84, loss:0.00002, loss_test:0.05398, lr:7.11e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.713, tt:2015.590\n",
      "Ep:85, loss:0.00002, loss_test:0.05382, lr:7.03e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.735, tt:2041.244\n",
      "Ep:86, loss:0.00002, loss_test:0.05422, lr:6.96e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.748, tt:2066.113\n",
      "Ep:87, loss:0.00001, loss_test:0.05421, lr:6.89e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.765, tt:2091.299\n",
      "Ep:88, loss:0.00001, loss_test:0.05360, lr:6.83e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.783, tt:2116.678\n",
      "Ep:89, loss:0.00001, loss_test:0.05454, lr:6.76e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.781, tt:2140.308\n",
      "Ep:90, loss:0.00001, loss_test:0.05439, lr:6.69e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.818, tt:2167.462\n",
      "Ep:91, loss:0.00001, loss_test:0.05328, lr:6.62e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.791, tt:2188.786\n",
      "Ep:92, loss:0.00001, loss_test:0.05444, lr:6.56e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.812, tt:2214.533\n",
      "Ep:93, loss:0.00001, loss_test:0.05352, lr:6.49e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.779, tt:2235.200\n",
      "Ep:94, loss:0.00001, loss_test:0.05453, lr:6.43e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.792, tt:2260.262\n",
      "Ep:95, loss:0.00001, loss_test:0.05434, lr:6.36e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.787, tt:2283.541\n",
      "Ep:96, loss:0.00001, loss_test:0.05332, lr:6.30e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.793, tt:2307.946\n",
      "Ep:97, loss:0.00001, loss_test:0.05440, lr:6.24e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.785, tt:2330.885\n",
      "Ep:98, loss:0.00001, loss_test:0.05320, lr:6.17e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.788, tt:2355.000\n",
      "Ep:99, loss:0.00001, loss_test:0.05452, lr:6.11e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.799, tt:2379.920\n",
      "Ep:100, loss:0.00001, loss_test:0.05431, lr:6.05e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.798, tt:2403.563\n",
      "Ep:101, loss:0.00001, loss_test:0.05394, lr:5.99e-03, fs:0.86170 (r=0.818,p=0.910),  time:23.793, tt:2426.891\n",
      "Ep:102, loss:0.00001, loss_test:0.05431, lr:5.93e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.766, tt:2447.918\n",
      "Ep:103, loss:0.00001, loss_test:0.05462, lr:5.87e-03, fs:0.86170 (r=0.818,p=0.910),  time:23.776, tt:2472.722\n",
      "Ep:104, loss:0.00001, loss_test:0.05316, lr:5.81e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.767, tt:2495.486\n",
      "Ep:105, loss:0.00001, loss_test:0.05455, lr:5.75e-03, fs:0.86316 (r=0.828,p=0.901),  time:23.787, tt:2521.397\n",
      "Ep:106, loss:0.00001, loss_test:0.05479, lr:5.70e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.785, tt:2544.980\n",
      "Ep:107, loss:0.00001, loss_test:0.05407, lr:5.64e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.799, tt:2570.336\n",
      "Ep:108, loss:0.00001, loss_test:0.05373, lr:5.58e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.810, tt:2595.319\n",
      "Ep:109, loss:0.00001, loss_test:0.05458, lr:5.53e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.786, tt:2616.491\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.05411, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.812, tt:2643.085\n",
      "Ep:111, loss:0.00001, loss_test:0.05439, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.791, tt:2664.564\n",
      "Ep:112, loss:0.00001, loss_test:0.05439, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.799, tt:2689.255\n",
      "Ep:113, loss:0.00001, loss_test:0.05373, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.775, tt:2710.383\n",
      "Ep:114, loss:0.00001, loss_test:0.05485, lr:5.53e-03, fs:0.86022 (r=0.808,p=0.920),  time:23.779, tt:2734.634\n",
      "Ep:115, loss:0.00001, loss_test:0.05362, lr:5.53e-03, fs:0.86772 (r=0.828,p=0.911),  time:23.781, tt:2758.653\n",
      "Ep:116, loss:0.00001, loss_test:0.05478, lr:5.53e-03, fs:0.85561 (r=0.808,p=0.909),  time:23.782, tt:2782.553\n",
      "Ep:117, loss:0.00001, loss_test:0.05464, lr:5.53e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.810, tt:2809.575\n",
      "Ep:118, loss:0.00001, loss_test:0.05442, lr:5.53e-03, fs:0.86631 (r=0.818,p=0.920),  time:23.809, tt:2833.274\n",
      "Ep:119, loss:0.00001, loss_test:0.05474, lr:5.53e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.819, tt:2858.257\n",
      "Ep:120, loss:0.00001, loss_test:0.05484, lr:5.53e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.800, tt:2879.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.05451, lr:5.47e-03, fs:0.87234 (r=0.828,p=0.921),  time:23.798, tt:2903.324\n",
      "Ep:122, loss:0.00001, loss_test:0.05469, lr:5.42e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.797, tt:2927.054\n",
      "Ep:123, loss:0.00001, loss_test:0.05531, lr:5.36e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.811, tt:2952.545\n",
      "Ep:124, loss:0.00001, loss_test:0.05463, lr:5.31e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.808, tt:2976.062\n",
      "Ep:125, loss:0.00001, loss_test:0.05473, lr:5.26e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.808, tt:2999.754\n",
      "Ep:126, loss:0.00001, loss_test:0.05410, lr:5.20e-03, fs:0.87701 (r=0.828,p=0.932),  time:23.806, tt:3023.328\n",
      "Ep:127, loss:0.00001, loss_test:0.05412, lr:5.15e-03, fs:0.86486 (r=0.808,p=0.930),  time:23.802, tt:3046.628\n",
      "Ep:128, loss:0.00001, loss_test:0.05445, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.809, tt:3071.313\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.05495, lr:5.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:23.820, tt:3096.666\n",
      "Ep:130, loss:0.00001, loss_test:0.05468, lr:5.10e-03, fs:0.86957 (r=0.808,p=0.941),  time:23.824, tt:3120.960\n",
      "Ep:131, loss:0.00001, loss_test:0.05468, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.813, tt:3143.290\n",
      "Ep:132, loss:0.00001, loss_test:0.05574, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.827, tt:3168.996\n",
      "Ep:133, loss:0.00001, loss_test:0.05446, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.823, tt:3192.229\n",
      "Ep:134, loss:0.00001, loss_test:0.05525, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.825, tt:3216.334\n",
      "Ep:135, loss:0.00001, loss_test:0.05533, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.822, tt:3239.836\n",
      "Ep:136, loss:0.00001, loss_test:0.05447, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:23.816, tt:3262.780\n",
      "Ep:137, loss:0.00001, loss_test:0.05531, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.819, tt:3287.082\n",
      "Ep:138, loss:0.00001, loss_test:0.05636, lr:5.10e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.815, tt:3310.314\n",
      "Ep:139, loss:0.00001, loss_test:0.05521, lr:5.10e-03, fs:0.87568 (r=0.818,p=0.942),  time:23.830, tt:3336.261\n",
      "Ep:140, loss:0.00001, loss_test:0.05482, lr:5.05e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.830, tt:3360.057\n",
      "Ep:141, loss:0.00001, loss_test:0.05528, lr:5.00e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.840, tt:3385.350\n",
      "Ep:142, loss:0.00001, loss_test:0.05505, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:23.837, tt:3408.763\n",
      "Ep:143, loss:0.00001, loss_test:0.05486, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.845, tt:3433.649\n",
      "Ep:144, loss:0.00001, loss_test:0.05462, lr:4.85e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.846, tt:3457.740\n",
      "Ep:145, loss:0.00001, loss_test:0.05526, lr:4.80e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.833, tt:3479.605\n",
      "Ep:146, loss:0.00001, loss_test:0.05526, lr:4.75e-03, fs:0.87432 (r=0.808,p=0.952),  time:23.846, tt:3505.348\n",
      "Ep:147, loss:0.00001, loss_test:0.05495, lr:4.71e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.834, tt:3527.430\n",
      "Ep:148, loss:0.00001, loss_test:0.05520, lr:4.66e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.840, tt:3552.189\n",
      "Ep:149, loss:0.00000, loss_test:0.05497, lr:4.61e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.838, tt:3575.700\n",
      "Ep:150, loss:0.00000, loss_test:0.05496, lr:4.57e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.838, tt:3599.576\n",
      "Ep:151, loss:0.00000, loss_test:0.05544, lr:4.52e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.843, tt:3624.123\n",
      "Ep:152, loss:0.00000, loss_test:0.05569, lr:4.48e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.848, tt:3648.816\n",
      "Ep:153, loss:0.00000, loss_test:0.05521, lr:4.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.848, tt:3672.534\n",
      "Ep:154, loss:0.00000, loss_test:0.05529, lr:4.39e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.857, tt:3697.838\n",
      "Ep:155, loss:0.00000, loss_test:0.05504, lr:4.34e-03, fs:0.87293 (r=0.798,p=0.963),  time:23.849, tt:3720.459\n",
      "Ep:156, loss:0.00000, loss_test:0.05486, lr:4.30e-03, fs:0.87912 (r=0.808,p=0.964),  time:23.827, tt:3740.841\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14381, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.466, tt:41.466\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14193, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:40.893, tt:81.786\n",
      "Ep:2, loss:0.00027, loss_test:0.13835, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:41.286, tt:123.859\n",
      "Ep:3, loss:0.00027, loss_test:0.13219, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:40.509, tt:162.035\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12165, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:40.536, tt:202.681\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11208, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:40.547, tt:243.282\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10737, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:40.516, tt:283.614\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10704, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:40.402, tt:323.213\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10519, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:40.694, tt:366.250\n",
      "Ep:9, loss:0.00021, loss_test:0.10369, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:40.893, tt:408.925\n",
      "Ep:10, loss:0.00020, loss_test:0.10243, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:40.953, tt:450.488\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10076, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:40.925, tt:491.105\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09958, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:40.935, tt:532.156\n",
      "Ep:13, loss:0.00018, loss_test:0.09877, lr:1.00e-02, fs:0.74312 (r=0.818,p=0.681),  time:41.047, tt:574.653\n",
      "Ep:14, loss:0.00018, loss_test:0.09721, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:41.087, tt:616.309\n",
      "Ep:15, loss:0.00018, loss_test:0.09619, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:41.033, tt:656.524\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09646, lr:1.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:41.054, tt:697.920\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09487, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:41.066, tt:739.185\n",
      "Ep:18, loss:0.00016, loss_test:0.09354, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:41.029, tt:779.554\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09378, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:41.004, tt:820.074\n",
      "Ep:20, loss:0.00016, loss_test:0.09294, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:40.925, tt:859.419\n",
      "Ep:21, loss:0.00015, loss_test:0.09298, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:40.934, tt:900.554\n",
      "Ep:22, loss:0.00015, loss_test:0.09125, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:40.880, tt:940.245\n",
      "Ep:23, loss:0.00015, loss_test:0.09154, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.855, tt:980.513\n",
      "Ep:24, loss:0.00014, loss_test:0.09146, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:40.837, tt:1020.928\n",
      "Ep:25, loss:0.00014, loss_test:0.09049, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:40.843, tt:1061.909\n",
      "Ep:26, loss:0.00014, loss_test:0.09040, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:40.804, tt:1101.718\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:27, loss:0.00013, loss_test:0.08848, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:40.813, tt:1142.760\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08966, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:40.854, tt:1184.767\n",
      "Ep:29, loss:0.00013, loss_test:0.08798, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:40.969, tt:1229.057\n",
      "Ep:30, loss:0.00012, loss_test:0.08876, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:40.977, tt:1270.288\n",
      "Ep:31, loss:0.00012, loss_test:0.08654, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:40.951, tt:1310.428\n",
      "Ep:32, loss:0.00012, loss_test:0.08672, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:40.928, tt:1350.620\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08742, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:40.941, tt:1391.991\n",
      "Ep:34, loss:0.00011, loss_test:0.08572, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:41.016, tt:1435.563\n",
      "Ep:35, loss:0.00011, loss_test:0.08571, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.002, tt:1476.071\n",
      "Ep:36, loss:0.00011, loss_test:0.08748, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:41.014, tt:1517.535\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08569, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:41.059, tt:1560.249\n",
      "Ep:38, loss:0.00010, loss_test:0.08307, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:41.027, tt:1600.049\n",
      "Ep:39, loss:0.00010, loss_test:0.08470, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:41.130, tt:1645.206\n",
      "Ep:40, loss:0.00010, loss_test:0.08326, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:41.228, tt:1690.364\n",
      "Ep:41, loss:0.00010, loss_test:0.08446, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.237, tt:1731.957\n",
      "Ep:42, loss:0.00010, loss_test:0.08763, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:41.162, tt:1769.945\n",
      "Ep:43, loss:0.00009, loss_test:0.08033, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:41.176, tt:1811.744\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.08549, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:41.177, tt:1852.959\n",
      "Ep:45, loss:0.00009, loss_test:0.08036, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:41.152, tt:1892.973\n",
      "Ep:46, loss:0.00009, loss_test:0.08330, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.139, tt:1933.536\n",
      "Ep:47, loss:0.00009, loss_test:0.07846, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.133, tt:1974.364\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.08053, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:41.164, tt:2017.041\n",
      "Ep:49, loss:0.00008, loss_test:0.08243, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.106, tt:2055.324\n",
      "Ep:50, loss:0.00008, loss_test:0.08456, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:41.075, tt:2094.835\n",
      "Ep:51, loss:0.00008, loss_test:0.08026, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:41.032, tt:2133.671\n",
      "Ep:52, loss:0.00008, loss_test:0.07724, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:41.017, tt:2173.922\n",
      "Ep:53, loss:0.00008, loss_test:0.08058, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.006, tt:2214.312\n",
      "Ep:54, loss:0.00007, loss_test:0.07947, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:40.996, tt:2254.795\n",
      "Ep:55, loss:0.00007, loss_test:0.07728, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:41.018, tt:2297.007\n",
      "Ep:56, loss:0.00007, loss_test:0.07602, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:41.023, tt:2338.302\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.07892, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.000, tt:2377.975\n",
      "Ep:58, loss:0.00007, loss_test:0.08611, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:40.979, tt:2417.734\n",
      "Ep:59, loss:0.00007, loss_test:0.08342, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:40.984, tt:2459.058\n",
      "Ep:60, loss:0.00007, loss_test:0.07415, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:41.013, tt:2501.803\n",
      "Ep:61, loss:0.00007, loss_test:0.07374, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.034, tt:2544.130\n",
      "Ep:62, loss:0.00006, loss_test:0.08484, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.081, tt:2588.118\n",
      "Ep:63, loss:0.00006, loss_test:0.07354, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:41.098, tt:2630.258\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.07596, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:41.119, tt:2672.738\n",
      "Ep:65, loss:0.00006, loss_test:0.08281, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.142, tt:2715.386\n",
      "Ep:66, loss:0.00007, loss_test:0.07536, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:41.177, tt:2758.853\n",
      "Ep:67, loss:0.00006, loss_test:0.07256, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:41.172, tt:2799.723\n",
      "Ep:68, loss:0.00007, loss_test:0.08223, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:41.211, tt:2843.542\n",
      "Ep:69, loss:0.00006, loss_test:0.07135, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:41.224, tt:2885.682\n",
      "Ep:70, loss:0.00006, loss_test:0.07230, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:41.258, tt:2929.312\n",
      "Ep:71, loss:0.00005, loss_test:0.07983, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:41.287, tt:2972.635\n",
      "Ep:72, loss:0.00005, loss_test:0.07117, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:41.317, tt:3016.146\n",
      "Ep:73, loss:0.00005, loss_test:0.07775, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.328, tt:3058.301\n",
      "Ep:74, loss:0.00005, loss_test:0.07114, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.340, tt:3100.482\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.07368, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:41.401, tt:3146.456\n",
      "Ep:76, loss:0.00005, loss_test:0.07082, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.455, tt:3192.065\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00005, loss_test:0.07034, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:41.490, tt:3236.224\n",
      "Ep:78, loss:0.00005, loss_test:0.07615, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:41.540, tt:3281.670\n",
      "Ep:79, loss:0.00005, loss_test:0.07402, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:41.557, tt:3324.521\n",
      "Ep:80, loss:0.00004, loss_test:0.07194, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.596, tt:3369.309\n",
      "Ep:81, loss:0.00004, loss_test:0.07547, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:41.621, tt:3412.907\n",
      "Ep:82, loss:0.00004, loss_test:0.06783, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.651, tt:3457.052\n",
      "Ep:83, loss:0.00004, loss_test:0.08256, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:41.652, tt:3498.781\n",
      "Ep:84, loss:0.00005, loss_test:0.07140, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.620, tt:3537.661\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00004, loss_test:0.06794, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:41.608, tt:3578.250\n",
      "Ep:86, loss:0.00004, loss_test:0.08042, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:41.539, tt:3613.858\n",
      "Ep:87, loss:0.00004, loss_test:0.06633, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:41.582, tt:3659.229\n",
      "Ep:88, loss:0.00004, loss_test:0.07684, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:41.632, tt:3705.249\n",
      "Ep:89, loss:0.00004, loss_test:0.06893, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:41.664, tt:3749.765\n",
      "Ep:90, loss:0.00004, loss_test:0.06911, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:41.707, tt:3795.331\n",
      "Ep:91, loss:0.00004, loss_test:0.07018, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:41.730, tt:3839.156\n",
      "Ep:92, loss:0.00003, loss_test:0.07022, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.740, tt:3881.776\n",
      "Ep:93, loss:0.00004, loss_test:0.07026, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.750, tt:3924.463\n",
      "Ep:94, loss:0.00003, loss_test:0.07473, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:41.788, tt:3969.906\n",
      "Ep:95, loss:0.00003, loss_test:0.06597, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:41.818, tt:4014.539\n",
      "Ep:96, loss:0.00003, loss_test:0.07689, lr:9.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:41.839, tt:4058.374\n",
      "Ep:97, loss:0.00003, loss_test:0.06615, lr:9.80e-03, fs:0.88442 (r=0.889,p=0.880),  time:41.887, tt:4104.942\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:98, loss:0.00003, loss_test:0.06492, lr:9.80e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.904, tt:4148.505\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00003, loss_test:0.07578, lr:9.80e-03, fs:0.79144 (r=0.747,p=0.841),  time:41.965, tt:4196.498\n",
      "Ep:100, loss:0.00003, loss_test:0.06520, lr:9.80e-03, fs:0.89119 (r=0.869,p=0.915),  time:41.982, tt:4240.137\n",
      "Ep:101, loss:0.00003, loss_test:0.07843, lr:9.80e-03, fs:0.75138 (r=0.687,p=0.829),  time:42.021, tt:4286.101\n",
      "Ep:102, loss:0.00003, loss_test:0.06723, lr:9.80e-03, fs:0.87958 (r=0.848,p=0.913),  time:42.039, tt:4330.037\n",
      "Ep:103, loss:0.00003, loss_test:0.07239, lr:9.80e-03, fs:0.79781 (r=0.737,p=0.869),  time:42.063, tt:4374.579\n",
      "Ep:104, loss:0.00003, loss_test:0.06867, lr:9.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:42.080, tt:4418.351\n",
      "Ep:105, loss:0.00003, loss_test:0.06689, lr:9.80e-03, fs:0.89796 (r=0.889,p=0.907),  time:42.097, tt:4462.312\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.07071, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:42.114, tt:4506.199\n",
      "Ep:107, loss:0.00003, loss_test:0.06775, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:42.145, tt:4551.708\n",
      "Ep:108, loss:0.00003, loss_test:0.07168, lr:9.80e-03, fs:0.85128 (r=0.838,p=0.865),  time:42.147, tt:4594.075\n",
      "Ep:109, loss:0.00003, loss_test:0.07166, lr:9.80e-03, fs:0.75145 (r=0.657,p=0.878),  time:42.167, tt:4638.360\n",
      "Ep:110, loss:0.00003, loss_test:0.07361, lr:9.80e-03, fs:0.82979 (r=0.788,p=0.876),  time:42.171, tt:4680.928\n",
      "Ep:111, loss:0.00002, loss_test:0.06822, lr:9.80e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.203, tt:4726.744\n",
      "Ep:112, loss:0.00002, loss_test:0.07811, lr:9.80e-03, fs:0.73034 (r=0.657,p=0.823),  time:42.235, tt:4772.516\n",
      "Ep:113, loss:0.00002, loss_test:0.07074, lr:9.80e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.253, tt:4816.858\n",
      "Ep:114, loss:0.00002, loss_test:0.06992, lr:9.80e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.273, tt:4861.389\n",
      "Ep:115, loss:0.00002, loss_test:0.08026, lr:9.80e-03, fs:0.74444 (r=0.677,p=0.827),  time:42.304, tt:4907.284\n",
      "Ep:116, loss:0.00003, loss_test:0.06861, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:42.334, tt:4953.023\n",
      "Ep:117, loss:0.00003, loss_test:0.06501, lr:9.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:42.369, tt:4999.582\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00003, loss_test:0.08350, lr:9.70e-03, fs:0.77174 (r=0.717,p=0.835),  time:42.383, tt:5043.636\n",
      "Ep:119, loss:0.00002, loss_test:0.06661, lr:9.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:42.406, tt:5088.728\n",
      "Ep:120, loss:0.00002, loss_test:0.08151, lr:9.70e-03, fs:0.76923 (r=0.707,p=0.843),  time:42.410, tt:5131.579\n",
      "Ep:121, loss:0.00002, loss_test:0.07198, lr:9.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.415, tt:5174.683\n",
      "Ep:122, loss:0.00002, loss_test:0.07847, lr:9.70e-03, fs:0.81915 (r=0.778,p=0.865),  time:42.430, tt:5218.946\n",
      "Ep:123, loss:0.00002, loss_test:0.07352, lr:9.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:42.444, tt:5263.007\n",
      "Ep:124, loss:0.00002, loss_test:0.07448, lr:9.70e-03, fs:0.80663 (r=0.737,p=0.890),  time:42.463, tt:5307.861\n",
      "Ep:125, loss:0.00002, loss_test:0.06691, lr:9.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:42.484, tt:5353.003\n",
      "Ep:126, loss:0.00002, loss_test:0.08248, lr:9.70e-03, fs:0.74286 (r=0.657,p=0.855),  time:42.515, tt:5399.366\n",
      "Ep:127, loss:0.00002, loss_test:0.06432, lr:9.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:42.531, tt:5443.907\n",
      "Ep:128, loss:0.00002, loss_test:0.07794, lr:9.70e-03, fs:0.75145 (r=0.657,p=0.878),  time:42.535, tt:5487.078\n",
      "Ep:129, loss:0.00002, loss_test:0.06796, lr:9.61e-03, fs:0.86631 (r=0.818,p=0.920),  time:42.603, tt:5538.382\n",
      "Ep:130, loss:0.00002, loss_test:0.07639, lr:9.51e-03, fs:0.76023 (r=0.657,p=0.903),  time:42.621, tt:5583.396\n",
      "Ep:131, loss:0.00002, loss_test:0.06799, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.641, tt:5628.665\n",
      "Ep:132, loss:0.00002, loss_test:0.07445, lr:9.32e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.643, tt:5671.521\n",
      "Ep:133, loss:0.00002, loss_test:0.07093, lr:9.23e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.652, tt:5715.364\n",
      "Ep:134, loss:0.00002, loss_test:0.07922, lr:9.14e-03, fs:0.74118 (r=0.636,p=0.887),  time:42.681, tt:5761.939\n",
      "Ep:135, loss:0.00002, loss_test:0.06739, lr:9.04e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.697, tt:5806.858\n",
      "Ep:136, loss:0.00002, loss_test:0.07941, lr:8.95e-03, fs:0.74286 (r=0.657,p=0.855),  time:42.703, tt:5850.316\n",
      "Ep:137, loss:0.00002, loss_test:0.06770, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.730, tt:5896.748\n",
      "Ep:138, loss:0.00002, loss_test:0.07947, lr:8.78e-03, fs:0.74713 (r=0.657,p=0.867),  time:42.735, tt:5940.211\n",
      "Ep:139, loss:0.00002, loss_test:0.06688, lr:8.69e-03, fs:0.84091 (r=0.747,p=0.961),  time:42.753, tt:5985.376\n",
      "Ep:140, loss:0.00002, loss_test:0.07869, lr:8.60e-03, fs:0.73988 (r=0.646,p=0.865),  time:42.760, tt:6029.158\n",
      "Ep:141, loss:0.00002, loss_test:0.07054, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.773, tt:6073.721\n",
      "Ep:142, loss:0.00002, loss_test:0.07506, lr:8.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:42.775, tt:6116.769\n",
      "Ep:143, loss:0.00002, loss_test:0.06923, lr:8.35e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.774, tt:6159.400\n",
      "Ep:144, loss:0.00002, loss_test:0.07371, lr:8.26e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.788, tt:6204.234\n",
      "Ep:145, loss:0.00002, loss_test:0.07054, lr:8.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.792, tt:6247.625\n",
      "Ep:146, loss:0.00002, loss_test:0.07301, lr:8.10e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.804, tt:6292.179\n",
      "Ep:147, loss:0.00001, loss_test:0.07210, lr:8.02e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.780, tt:6331.475\n",
      "Ep:148, loss:0.00001, loss_test:0.07314, lr:7.94e-03, fs:0.74699 (r=0.626,p=0.925),  time:42.778, tt:6373.922\n",
      "Ep:149, loss:0.00001, loss_test:0.07386, lr:7.86e-03, fs:0.77011 (r=0.677,p=0.893),  time:42.755, tt:6413.207\n",
      "Ep:150, loss:0.00001, loss_test:0.07227, lr:7.78e-03, fs:0.75152 (r=0.626,p=0.939),  time:42.774, tt:6458.851\n",
      "Ep:151, loss:0.00001, loss_test:0.07302, lr:7.70e-03, fs:0.75449 (r=0.636,p=0.926),  time:42.777, tt:6502.142\n",
      "Ep:152, loss:0.00001, loss_test:0.07279, lr:7.62e-03, fs:0.74251 (r=0.626,p=0.912),  time:42.781, tt:6545.510\n",
      "Ep:153, loss:0.00001, loss_test:0.07120, lr:7.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.801, tt:6591.301\n",
      "Ep:154, loss:0.00001, loss_test:0.07593, lr:7.47e-03, fs:0.73810 (r=0.626,p=0.899),  time:42.784, tt:6631.524\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14085, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:19.147, tt:19.147\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13906, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:19.424, tt:38.848\n",
      "Ep:2, loss:0.00027, loss_test:0.13560, lr:1.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:19.893, tt:59.680\n",
      "Ep:3, loss:0.00026, loss_test:0.13019, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:19.686, tt:78.743\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12377, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:19.598, tt:97.992\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11820, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:19.449, tt:116.694\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11330, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:19.106, tt:133.742\n",
      "Ep:7, loss:0.00024, loss_test:0.10998, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:19.211, tt:153.689\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00023, loss_test:0.10797, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:19.473, tt:175.257\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10531, lr:1.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:19.755, tt:197.555\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10202, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:19.536, tt:214.897\n",
      "Ep:11, loss:0.00021, loss_test:0.09944, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:19.472, tt:233.660\n",
      "Ep:12, loss:0.00020, loss_test:0.09738, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:19.342, tt:251.452\n",
      "Ep:13, loss:0.00020, loss_test:0.09526, lr:1.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:19.278, tt:269.888\n",
      "Ep:14, loss:0.00019, loss_test:0.09249, lr:1.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:19.254, tt:288.815\n",
      "Ep:15, loss:0.00018, loss_test:0.09007, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:19.274, tt:308.387\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08803, lr:1.00e-02, fs:0.76106 (r=0.869,p=0.677),  time:19.170, tt:325.891\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08620, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:19.119, tt:344.139\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08422, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:19.048, tt:361.905\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08276, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:19.026, tt:380.514\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08232, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:19.020, tt:399.411\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08066, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:18.952, tt:416.936\n",
      "Ep:22, loss:0.00015, loss_test:0.08089, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:18.895, tt:434.576\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07921, lr:1.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:18.888, tt:453.313\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07882, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:18.860, tt:471.488\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07786, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:18.873, tt:490.710\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07622, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:18.865, tt:509.362\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07500, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:18.819, tt:526.930\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07547, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:18.789, tt:544.872\n",
      "Ep:29, loss:0.00012, loss_test:0.07360, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:18.823, tt:564.676\n",
      "Ep:30, loss:0.00012, loss_test:0.07307, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:18.787, tt:582.388\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07279, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:18.775, tt:600.814\n",
      "Ep:32, loss:0.00011, loss_test:0.07136, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:18.856, tt:622.256\n",
      "Ep:33, loss:0.00011, loss_test:0.07201, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:18.898, tt:642.548\n",
      "Ep:34, loss:0.00010, loss_test:0.07083, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:18.928, tt:662.484\n",
      "Ep:35, loss:0.00010, loss_test:0.07105, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:18.909, tt:680.708\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.06841, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:18.914, tt:699.817\n",
      "Ep:37, loss:0.00009, loss_test:0.06786, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:18.970, tt:720.850\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.06725, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:19.026, tt:742.011\n",
      "Ep:39, loss:0.00009, loss_test:0.06644, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:19.089, tt:763.551\n",
      "Ep:40, loss:0.00008, loss_test:0.06591, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:19.110, tt:783.523\n",
      "Ep:41, loss:0.00008, loss_test:0.06470, lr:1.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:19.177, tt:805.447\n",
      "Ep:42, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:19.155, tt:823.682\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.06415, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:19.186, tt:844.165\n",
      "Ep:44, loss:0.00007, loss_test:0.06495, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:19.209, tt:864.420\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06350, lr:1.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:19.163, tt:881.483\n",
      "Ep:46, loss:0.00007, loss_test:0.06295, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:19.175, tt:901.247\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06413, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:19.175, tt:920.416\n",
      "Ep:48, loss:0.00006, loss_test:0.06138, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:19.154, tt:938.547\n",
      "Ep:49, loss:0.00006, loss_test:0.06099, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:19.165, tt:958.251\n",
      "Ep:50, loss:0.00006, loss_test:0.06165, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:19.162, tt:977.286\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.06034, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:19.128, tt:994.648\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.06459, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:19.086, tt:1011.570\n",
      "Ep:53, loss:0.00005, loss_test:0.05941, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:19.080, tt:1030.330\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.06071, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:19.066, tt:1048.603\n",
      "Ep:55, loss:0.00005, loss_test:0.06113, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:19.057, tt:1067.187\n",
      "Ep:56, loss:0.00005, loss_test:0.06035, lr:1.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:19.019, tt:1084.071\n",
      "Ep:57, loss:0.00005, loss_test:0.05767, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.039, tt:1104.285\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.05773, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.055, tt:1124.269\n",
      "Ep:59, loss:0.00004, loss_test:0.05967, lr:1.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:19.053, tt:1143.188\n",
      "Ep:60, loss:0.00005, loss_test:0.05847, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:19.038, tt:1161.300\n",
      "Ep:61, loss:0.00004, loss_test:0.05685, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:19.039, tt:1180.403\n",
      "Ep:62, loss:0.00004, loss_test:0.05703, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:19.050, tt:1200.168\n",
      "Ep:63, loss:0.00004, loss_test:0.05676, lr:1.00e-02, fs:0.92019 (r=0.990,p=0.860),  time:19.083, tt:1221.336\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.05458, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:19.137, tt:1243.920\n",
      "Ep:65, loss:0.00004, loss_test:0.05937, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:19.176, tt:1265.620\n",
      "Ep:66, loss:0.00004, loss_test:0.05431, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:19.178, tt:1284.902\n",
      "Ep:67, loss:0.00004, loss_test:0.05687, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:19.170, tt:1303.583\n",
      "Ep:68, loss:0.00004, loss_test:0.05341, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:19.162, tt:1322.173\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.05549, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:19.175, tt:1342.237\n",
      "Ep:70, loss:0.00004, loss_test:0.05333, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:19.187, tt:1362.256\n",
      "Ep:71, loss:0.00003, loss_test:0.05267, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:19.185, tt:1381.319\n",
      "Ep:72, loss:0.00003, loss_test:0.05288, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:19.185, tt:1400.535\n",
      "Ep:73, loss:0.00003, loss_test:0.05495, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:19.182, tt:1419.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00003, loss_test:0.05413, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:19.178, tt:1438.331\n",
      "Ep:75, loss:0.00003, loss_test:0.05210, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:19.206, tt:1459.668\n",
      "Ep:76, loss:0.00003, loss_test:0.05372, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:19.192, tt:1477.761\n",
      "Ep:77, loss:0.00003, loss_test:0.05395, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:19.176, tt:1495.690\n",
      "Ep:78, loss:0.00003, loss_test:0.05193, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:19.157, tt:1513.441\n",
      "Ep:79, loss:0.00003, loss_test:0.05409, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:19.170, tt:1533.585\n",
      "Ep:80, loss:0.00003, loss_test:0.05366, lr:9.90e-03, fs:0.85859 (r=0.859,p=0.859),  time:19.192, tt:1554.514\n",
      "Ep:81, loss:0.00003, loss_test:0.05144, lr:9.80e-03, fs:0.87685 (r=0.899,p=0.856),  time:19.195, tt:1574.015\n",
      "Ep:82, loss:0.00003, loss_test:0.05289, lr:9.70e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.175, tt:1591.567\n",
      "Ep:83, loss:0.00003, loss_test:0.05290, lr:9.61e-03, fs:0.87685 (r=0.899,p=0.856),  time:19.213, tt:1613.887\n",
      "Ep:84, loss:0.00003, loss_test:0.05309, lr:9.51e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.236, tt:1635.054\n",
      "Ep:85, loss:0.00003, loss_test:0.05213, lr:9.41e-03, fs:0.91346 (r=0.960,p=0.872),  time:19.230, tt:1653.760\n",
      "Ep:86, loss:0.00003, loss_test:0.05449, lr:9.32e-03, fs:0.86869 (r=0.869,p=0.869),  time:19.209, tt:1671.192\n",
      "Ep:87, loss:0.00003, loss_test:0.05373, lr:9.23e-03, fs:0.87437 (r=0.879,p=0.870),  time:19.214, tt:1690.859\n",
      "Ep:88, loss:0.00003, loss_test:0.04945, lr:9.14e-03, fs:0.91707 (r=0.949,p=0.887),  time:19.224, tt:1710.956\n",
      "Ep:89, loss:0.00003, loss_test:0.05979, lr:9.04e-03, fs:0.85128 (r=0.838,p=0.865),  time:19.215, tt:1729.384\n",
      "Ep:90, loss:0.00003, loss_test:0.04911, lr:8.95e-03, fs:0.92233 (r=0.960,p=0.888),  time:19.202, tt:1747.383\n",
      "Ep:91, loss:0.00003, loss_test:0.05805, lr:8.86e-03, fs:0.86000 (r=0.869,p=0.851),  time:19.200, tt:1766.418\n",
      "Ep:92, loss:0.00002, loss_test:0.05008, lr:8.78e-03, fs:0.87879 (r=0.879,p=0.879),  time:19.185, tt:1784.223\n",
      "Ep:93, loss:0.00002, loss_test:0.05516, lr:8.69e-03, fs:0.86432 (r=0.869,p=0.860),  time:19.173, tt:1802.240\n",
      "Ep:94, loss:0.00002, loss_test:0.04982, lr:8.60e-03, fs:0.90000 (r=0.909,p=0.891),  time:19.167, tt:1820.889\n",
      "Ep:95, loss:0.00002, loss_test:0.05416, lr:8.51e-03, fs:0.86000 (r=0.869,p=0.851),  time:19.171, tt:1840.424\n",
      "Ep:96, loss:0.00002, loss_test:0.05032, lr:8.43e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.159, tt:1858.383\n",
      "Ep:97, loss:0.00002, loss_test:0.05463, lr:8.35e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.161, tt:1877.825\n",
      "Ep:98, loss:0.00002, loss_test:0.05115, lr:8.26e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.141, tt:1894.916\n",
      "Ep:99, loss:0.00002, loss_test:0.05344, lr:8.18e-03, fs:0.85714 (r=0.848,p=0.866),  time:19.120, tt:1912.019\n",
      "Ep:100, loss:0.00002, loss_test:0.05238, lr:8.10e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.112, tt:1930.346\n",
      "Ep:101, loss:0.00002, loss_test:0.05299, lr:8.02e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.121, tt:1950.390\n",
      "Ep:102, loss:0.00002, loss_test:0.05336, lr:7.94e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.121, tt:1969.496\n",
      "Ep:103, loss:0.00002, loss_test:0.05135, lr:7.86e-03, fs:0.88000 (r=0.889,p=0.871),  time:19.106, tt:1986.975\n",
      "Ep:104, loss:0.00002, loss_test:0.05378, lr:7.78e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.105, tt:2005.987\n",
      "Ep:105, loss:0.00002, loss_test:0.05218, lr:7.70e-03, fs:0.87310 (r=0.869,p=0.878),  time:19.121, tt:2026.854\n",
      "Ep:106, loss:0.00002, loss_test:0.05216, lr:7.62e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.147, tt:2048.781\n",
      "Ep:107, loss:0.00002, loss_test:0.05301, lr:7.55e-03, fs:0.86598 (r=0.848,p=0.884),  time:19.134, tt:2066.462\n",
      "Ep:108, loss:0.00002, loss_test:0.05070, lr:7.47e-03, fs:0.88660 (r=0.869,p=0.905),  time:19.122, tt:2084.276\n",
      "Ep:109, loss:0.00002, loss_test:0.05399, lr:7.40e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.131, tt:2104.391\n",
      "Ep:110, loss:0.00002, loss_test:0.05128, lr:7.32e-03, fs:0.88205 (r=0.869,p=0.896),  time:19.116, tt:2121.916\n",
      "Ep:111, loss:0.00002, loss_test:0.05362, lr:7.25e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.102, tt:2139.432\n",
      "Ep:112, loss:0.00002, loss_test:0.05283, lr:7.18e-03, fs:0.87500 (r=0.848,p=0.903),  time:19.089, tt:2157.042\n",
      "Ep:113, loss:0.00002, loss_test:0.05160, lr:7.11e-03, fs:0.86294 (r=0.859,p=0.867),  time:19.095, tt:2176.786\n",
      "Ep:114, loss:0.00002, loss_test:0.05286, lr:7.03e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.085, tt:2194.827\n",
      "Ep:115, loss:0.00002, loss_test:0.05206, lr:6.96e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.093, tt:2214.841\n",
      "Ep:116, loss:0.00002, loss_test:0.05201, lr:6.89e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.110, tt:2235.844\n",
      "Ep:117, loss:0.00001, loss_test:0.05195, lr:6.83e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.129, tt:2257.250\n",
      "Ep:118, loss:0.00001, loss_test:0.05301, lr:6.76e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.126, tt:2275.986\n",
      "Ep:119, loss:0.00001, loss_test:0.05116, lr:6.69e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.112, tt:2293.434\n",
      "Ep:120, loss:0.00001, loss_test:0.05290, lr:6.62e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.092, tt:2310.129\n",
      "Ep:121, loss:0.00001, loss_test:0.05249, lr:6.56e-03, fs:0.87047 (r=0.848,p=0.894),  time:19.100, tt:2330.244\n",
      "Ep:122, loss:0.00001, loss_test:0.05118, lr:6.49e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.100, tt:2349.344\n",
      "Ep:123, loss:0.00001, loss_test:0.05260, lr:6.43e-03, fs:0.86598 (r=0.848,p=0.884),  time:19.112, tt:2369.843\n",
      "Ep:124, loss:0.00001, loss_test:0.05169, lr:6.36e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.108, tt:2388.537\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
