{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number = \"21-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bert2_400',\n",
       " 1: 'Bert2_832',\n",
       " 2: 'Bert2_832_400_200_100',\n",
       " 3: 'Bert2_832_600_400_200',\n",
       " 4: 'Bert_300',\n",
       " 5: 'Bert_300_300_200',\n",
       " 6: 'Bert_768',\n",
       " 7: 'Fasttext2',\n",
       " 8: 'Fasttext2_150',\n",
       " 9: 'Fasttext2_200_200',\n",
       " 10: 'Fasttext2_200_200_100',\n",
       " 11: 'Fasttext2_200_200_200',\n",
       " 12: 'Fasttext2_200_200_200_100',\n",
       " 13: 'Fasttext2_200_200_200_100_relu',\n",
       " 14: 'Fasttext2_300_250_200_150',\n",
       " 15: 'Fasttext2_364',\n",
       " 16: 'Fasttext2_364_200_100',\n",
       " 17: 'Fasttext2_364_200_100_relu',\n",
       " 18: 'Fasttext2_364_300_200_100',\n",
       " 19: 'Fasttext2_364_300_200_100_relu',\n",
       " 20: 'Fasttext2_364_300_250_200',\n",
       " 21: 'Fasttext2_364_364_364',\n",
       " 22: 'Fasttext2_364_nn',\n",
       " 23: 'Fasttext2_3GCN_300_250_200_150',\n",
       " 24: 'Fasttext2_728',\n",
       " 25: 'Fasttext2_728364',\n",
       " 26: 'Fasttext2_728_364',\n",
       " 27: 'Fasttext2d_300_250_200_150',\n",
       " 28: 'Fasttext2d_364',\n",
       " 29: 'Fasttext2d_364_364_364',\n",
       " 30: 'Fasttext2d_728_364',\n",
       " 31: 'Fasttext3GCN_300',\n",
       " 32: 'FasttextSum_150',\n",
       " 33: 'FasttextSum_300_250_200_150',\n",
       " 34: 'FasttextSum_364',\n",
       " 35: 'FasttextSum_364_200_100',\n",
       " 36: 'FasttextSum_364_300_200_100',\n",
       " 37: 'FasttextSumd_150',\n",
       " 38: 'FasttextSumd_300_250_200_150',\n",
       " 39: 'Fasttext_150',\n",
       " 40: 'Fasttext_150_150_100',\n",
       " 41: 'Fasttext_200_200_200_100',\n",
       " 42: 'Fasttext_300',\n",
       " 43: 'Fasttext_300_200_100',\n",
       " 44: 'Fasttext_300_250_200_150',\n",
       " 45: 'Fasttext_300_300_300',\n",
       " 46: 'Fasttext_3GCN',\n",
       " 47: 'Fasttext_600_300',\n",
       " 48: 'Fasttext_simple_300_300'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24416, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.656, tt:12.656\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24216, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:14.126, tt:28.253\n",
      "Ep:2, loss:0.00059, loss_test:0.23781, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:16.439, tt:49.316\n",
      "Ep:3, loss:0.00057, loss_test:0.22830, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:19.318, tt:77.272\n",
      "Ep:4, loss:0.00050, loss_test:0.21220, lr:9.22e-03, fs:0.66667 (r=0.990,p=0.503),  time:21.654, tt:108.271\n",
      "Ep:5, loss:0.00042, loss_test:0.18921, lr:9.04e-03, fs:0.64469 (r=0.889,p=0.506),  time:23.632, tt:141.791\n",
      "Ep:6, loss:0.00035, loss_test:0.19149, lr:8.86e-03, fs:0.69333 (r=0.788,p=0.619),  time:25.312, tt:177.187\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18981, lr:8.68e-03, fs:0.67257 (r=0.768,p=0.598),  time:26.343, tt:210.741\n",
      "Ep:8, loss:0.00031, loss_test:0.18908, lr:8.51e-03, fs:0.68224 (r=0.737,p=0.635),  time:27.345, tt:246.108\n",
      "Ep:9, loss:0.00029, loss_test:0.18952, lr:8.34e-03, fs:0.70531 (r=0.737,p=0.676),  time:28.057, tt:280.567\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.18455, lr:8.17e-03, fs:0.70370 (r=0.768,p=0.650),  time:28.602, tt:314.618\n",
      "Ep:11, loss:0.00027, loss_test:0.18314, lr:8.01e-03, fs:0.71698 (r=0.768,p=0.673),  time:29.052, tt:348.627\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.18948, lr:7.85e-03, fs:0.75862 (r=0.778,p=0.740),  time:29.521, tt:383.768\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.18198, lr:7.69e-03, fs:0.73394 (r=0.808,p=0.672),  time:29.852, tt:417.925\n",
      "Ep:14, loss:0.00025, loss_test:0.17958, lr:7.54e-03, fs:0.73488 (r=0.798,p=0.681),  time:30.037, tt:450.557\n",
      "Ep:15, loss:0.00025, loss_test:0.18359, lr:7.39e-03, fs:0.73469 (r=0.727,p=0.742),  time:30.326, tt:485.213\n",
      "Ep:16, loss:0.00025, loss_test:0.17672, lr:7.24e-03, fs:0.75362 (r=0.788,p=0.722),  time:30.626, tt:520.645\n",
      "Ep:17, loss:0.00024, loss_test:0.17227, lr:7.09e-03, fs:0.75117 (r=0.808,p=0.702),  time:30.721, tt:552.973\n",
      "Ep:18, loss:0.00024, loss_test:0.17385, lr:6.95e-03, fs:0.73632 (r=0.747,p=0.725),  time:30.913, tt:587.353\n",
      "Ep:19, loss:0.00023, loss_test:0.17357, lr:6.81e-03, fs:0.74372 (r=0.747,p=0.740),  time:31.101, tt:622.029\n",
      "Ep:20, loss:0.00022, loss_test:0.17133, lr:6.68e-03, fs:0.73786 (r=0.768,p=0.710),  time:31.294, tt:657.165\n",
      "Ep:21, loss:0.00022, loss_test:0.17146, lr:6.54e-03, fs:0.73367 (r=0.737,p=0.730),  time:31.377, tt:690.292\n",
      "Ep:22, loss:0.00022, loss_test:0.16869, lr:6.41e-03, fs:0.74877 (r=0.768,p=0.731),  time:31.509, tt:724.707\n",
      "Ep:23, loss:0.00022, loss_test:0.16474, lr:6.28e-03, fs:0.74641 (r=0.788,p=0.709),  time:31.614, tt:758.734\n",
      "Ep:24, loss:0.00021, loss_test:0.16412, lr:6.16e-03, fs:0.74146 (r=0.768,p=0.717),  time:31.714, tt:792.846\n",
      "Ep:25, loss:0.00020, loss_test:0.16296, lr:6.03e-03, fs:0.75117 (r=0.808,p=0.702),  time:31.783, tt:826.355\n",
      "Ep:26, loss:0.00020, loss_test:0.16543, lr:5.91e-03, fs:0.75127 (r=0.747,p=0.755),  time:31.846, tt:859.844\n",
      "Ep:27, loss:0.00020, loss_test:0.16439, lr:5.80e-03, fs:0.76142 (r=0.758,p=0.765),  time:31.940, tt:894.331\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.16121, lr:5.68e-03, fs:0.76847 (r=0.788,p=0.750),  time:32.058, tt:929.681\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.16032, lr:5.57e-03, fs:0.77387 (r=0.778,p=0.770),  time:32.069, tt:962.071\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00019, loss_test:0.16185, lr:5.45e-03, fs:0.76142 (r=0.758,p=0.765),  time:32.132, tt:996.080\n",
      "Ep:31, loss:0.00018, loss_test:0.16040, lr:5.35e-03, fs:0.77228 (r=0.788,p=0.757),  time:32.205, tt:1030.555\n",
      "Ep:32, loss:0.00019, loss_test:0.16010, lr:5.24e-03, fs:0.76098 (r=0.788,p=0.736),  time:32.259, tt:1064.555\n",
      "Ep:33, loss:0.00018, loss_test:0.16117, lr:5.13e-03, fs:0.78607 (r=0.798,p=0.775),  time:32.348, tt:1099.841\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.15989, lr:5.03e-03, fs:0.79000 (r=0.798,p=0.782),  time:32.417, tt:1134.594\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00017, loss_test:0.15407, lr:4.93e-03, fs:0.78049 (r=0.808,p=0.755),  time:32.417, tt:1167.027\n",
      "Ep:36, loss:0.00016, loss_test:0.15698, lr:4.83e-03, fs:0.79592 (r=0.788,p=0.804),  time:32.506, tt:1202.706\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00016, loss_test:0.15347, lr:4.74e-03, fs:0.78607 (r=0.798,p=0.775),  time:32.559, tt:1237.230\n",
      "Ep:38, loss:0.00016, loss_test:0.15179, lr:4.64e-03, fs:0.80193 (r=0.838,p=0.769),  time:32.584, tt:1270.774\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00015, loss_test:0.15499, lr:4.55e-03, fs:0.78607 (r=0.798,p=0.775),  time:32.629, tt:1305.151\n",
      "Ep:40, loss:0.00015, loss_test:0.15505, lr:4.46e-03, fs:0.79803 (r=0.818,p=0.779),  time:32.704, tt:1340.883\n",
      "Ep:41, loss:0.00015, loss_test:0.15268, lr:4.37e-03, fs:0.80000 (r=0.828,p=0.774),  time:32.761, tt:1375.974\n",
      "Ep:42, loss:0.00014, loss_test:0.15046, lr:4.28e-03, fs:0.80583 (r=0.838,p=0.776),  time:32.824, tt:1411.441\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00014, loss_test:0.15060, lr:4.19e-03, fs:0.80976 (r=0.838,p=0.783),  time:32.856, tt:1445.682\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00014, loss_test:0.14924, lr:4.11e-03, fs:0.81373 (r=0.838,p=0.790),  time:32.898, tt:1480.421\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00013, loss_test:0.14846, lr:4.03e-03, fs:0.81159 (r=0.848,p=0.778),  time:32.943, tt:1515.383\n",
      "Ep:46, loss:0.00014, loss_test:0.14787, lr:3.95e-03, fs:0.81773 (r=0.838,p=0.798),  time:33.008, tt:1551.377\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00013, loss_test:0.14898, lr:3.87e-03, fs:0.81773 (r=0.838,p=0.798),  time:33.071, tt:1587.409\n",
      "Ep:48, loss:0.00013, loss_test:0.14805, lr:3.79e-03, fs:0.81951 (r=0.848,p=0.792),  time:33.149, tt:1624.305\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00013, loss_test:0.14518, lr:3.72e-03, fs:0.82524 (r=0.859,p=0.794),  time:33.206, tt:1660.314\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00012, loss_test:0.14740, lr:3.64e-03, fs:0.83168 (r=0.848,p=0.816),  time:33.238, tt:1695.125\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00013, loss_test:0.14894, lr:3.57e-03, fs:0.82587 (r=0.838,p=0.814),  time:33.280, tt:1730.566\n",
      "Ep:52, loss:0.00012, loss_test:0.14745, lr:3.50e-03, fs:0.82353 (r=0.848,p=0.800),  time:33.311, tt:1765.471\n",
      "Ep:53, loss:0.00012, loss_test:0.14777, lr:3.43e-03, fs:0.82178 (r=0.838,p=0.806),  time:33.322, tt:1799.363\n",
      "Ep:54, loss:0.00011, loss_test:0.14800, lr:3.36e-03, fs:0.82524 (r=0.859,p=0.794),  time:33.352, tt:1834.358\n",
      "Ep:55, loss:0.00011, loss_test:0.14618, lr:3.29e-03, fs:0.83495 (r=0.869,p=0.804),  time:33.393, tt:1869.991\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00011, loss_test:0.14692, lr:3.23e-03, fs:0.81951 (r=0.848,p=0.792),  time:33.420, tt:1904.945\n",
      "Ep:57, loss:0.00011, loss_test:0.14237, lr:3.16e-03, fs:0.82857 (r=0.879,p=0.784),  time:33.459, tt:1940.647\n",
      "Ep:58, loss:0.00010, loss_test:0.15059, lr:3.10e-03, fs:0.83417 (r=0.838,p=0.830),  time:33.515, tt:1977.371\n",
      "Ep:59, loss:0.00011, loss_test:0.14995, lr:3.04e-03, fs:0.84000 (r=0.848,p=0.832),  time:33.550, tt:2013.002\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00010, loss_test:0.14604, lr:2.98e-03, fs:0.82353 (r=0.848,p=0.800),  time:33.573, tt:2047.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00010, loss_test:0.14826, lr:2.92e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.584, tt:2082.188\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00010, loss_test:0.14537, lr:2.86e-03, fs:0.83333 (r=0.859,p=0.810),  time:33.606, tt:2117.199\n",
      "Ep:63, loss:0.00010, loss_test:0.14454, lr:2.80e-03, fs:0.81951 (r=0.848,p=0.792),  time:33.620, tt:2151.706\n",
      "Ep:64, loss:0.00009, loss_test:0.14577, lr:2.74e-03, fs:0.83744 (r=0.859,p=0.817),  time:33.624, tt:2185.593\n",
      "Ep:65, loss:0.00009, loss_test:0.14484, lr:2.69e-03, fs:0.83333 (r=0.859,p=0.810),  time:33.637, tt:2220.068\n",
      "Ep:66, loss:0.00009, loss_test:0.14620, lr:2.64e-03, fs:0.83744 (r=0.859,p=0.817),  time:33.653, tt:2254.747\n",
      "Ep:67, loss:0.00009, loss_test:0.14704, lr:2.58e-03, fs:0.84422 (r=0.848,p=0.840),  time:33.672, tt:2289.722\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00008, loss_test:0.14209, lr:2.53e-03, fs:0.82857 (r=0.879,p=0.784),  time:33.678, tt:2323.816\n",
      "Ep:69, loss:0.00008, loss_test:0.14666, lr:2.48e-03, fs:0.85427 (r=0.859,p=0.850),  time:33.670, tt:2356.883\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00008, loss_test:0.14569, lr:2.43e-03, fs:0.85427 (r=0.859,p=0.850),  time:33.672, tt:2390.741\n",
      "Ep:71, loss:0.00008, loss_test:0.14321, lr:2.38e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.689, tt:2425.606\n",
      "Ep:72, loss:0.00008, loss_test:0.14387, lr:2.33e-03, fs:0.84577 (r=0.859,p=0.833),  time:33.709, tt:2460.756\n",
      "Ep:73, loss:0.00008, loss_test:0.14272, lr:2.29e-03, fs:0.83333 (r=0.859,p=0.810),  time:33.673, tt:2491.831\n",
      "Ep:74, loss:0.00008, loss_test:0.14214, lr:2.24e-03, fs:0.83333 (r=0.859,p=0.810),  time:33.675, tt:2525.635\n",
      "Ep:75, loss:0.00008, loss_test:0.14483, lr:2.20e-03, fs:0.84848 (r=0.848,p=0.848),  time:33.650, tt:2557.376\n",
      "Ep:76, loss:0.00007, loss_test:0.14134, lr:2.15e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.670, tt:2592.567\n",
      "Ep:77, loss:0.00007, loss_test:0.14087, lr:2.11e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.675, tt:2626.635\n",
      "Ep:78, loss:0.00007, loss_test:0.14454, lr:2.07e-03, fs:0.85279 (r=0.848,p=0.857),  time:33.654, tt:2658.687\n",
      "Ep:79, loss:0.00007, loss_test:0.14295, lr:2.03e-03, fs:0.84158 (r=0.859,p=0.825),  time:33.648, tt:2691.862\n",
      "Ep:80, loss:0.00007, loss_test:0.14566, lr:1.99e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.631, tt:2724.121\n",
      "Ep:81, loss:0.00007, loss_test:0.14465, lr:1.95e-03, fs:0.83673 (r=0.828,p=0.845),  time:33.640, tt:2758.484\n",
      "Ep:82, loss:0.00007, loss_test:0.14083, lr:1.91e-03, fs:0.83495 (r=0.869,p=0.804),  time:33.641, tt:2792.166\n",
      "Ep:83, loss:0.00007, loss_test:0.14400, lr:1.87e-03, fs:0.86000 (r=0.869,p=0.851),  time:33.645, tt:2826.173\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00007, loss_test:0.14759, lr:1.83e-03, fs:0.84974 (r=0.828,p=0.872),  time:33.653, tt:2860.500\n",
      "Ep:85, loss:0.00007, loss_test:0.14309, lr:1.80e-03, fs:0.85279 (r=0.848,p=0.857),  time:33.658, tt:2894.579\n",
      "Ep:86, loss:0.00006, loss_test:0.14087, lr:1.76e-03, fs:0.85149 (r=0.869,p=0.835),  time:33.671, tt:2929.359\n",
      "Ep:87, loss:0.00006, loss_test:0.14230, lr:1.72e-03, fs:0.85572 (r=0.869,p=0.843),  time:33.688, tt:2964.543\n",
      "Ep:88, loss:0.00006, loss_test:0.14539, lr:1.69e-03, fs:0.85279 (r=0.848,p=0.857),  time:33.692, tt:2998.554\n",
      "Ep:89, loss:0.00006, loss_test:0.14684, lr:1.66e-03, fs:0.83077 (r=0.818,p=0.844),  time:33.686, tt:3031.764\n",
      "Ep:90, loss:0.00006, loss_test:0.14406, lr:1.62e-03, fs:0.84422 (r=0.848,p=0.840),  time:33.687, tt:3065.559\n",
      "Ep:91, loss:0.00006, loss_test:0.14171, lr:1.59e-03, fs:0.85149 (r=0.869,p=0.835),  time:33.709, tt:3101.182\n",
      "Ep:92, loss:0.00006, loss_test:0.14204, lr:1.56e-03, fs:0.84577 (r=0.859,p=0.833),  time:33.741, tt:3137.957\n",
      "Ep:93, loss:0.00005, loss_test:0.14495, lr:1.53e-03, fs:0.84694 (r=0.838,p=0.856),  time:33.764, tt:3173.778\n",
      "Ep:94, loss:0.00006, loss_test:0.14488, lr:1.50e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.760, tt:3207.157\n",
      "Ep:95, loss:0.00005, loss_test:0.14332, lr:1.47e-03, fs:0.85128 (r=0.838,p=0.865),  time:33.758, tt:3240.788\n",
      "Ep:96, loss:0.00005, loss_test:0.14410, lr:1.44e-03, fs:0.85714 (r=0.848,p=0.866),  time:33.772, tt:3275.844\n",
      "Ep:97, loss:0.00005, loss_test:0.14442, lr:1.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:33.789, tt:3311.286\n",
      "Ep:98, loss:0.00005, loss_test:0.14371, lr:1.38e-03, fs:0.84848 (r=0.848,p=0.848),  time:33.786, tt:3344.833\n",
      "Ep:99, loss:0.00005, loss_test:0.14510, lr:1.35e-03, fs:0.84375 (r=0.818,p=0.871),  time:33.801, tt:3380.053\n",
      "Ep:100, loss:0.00005, loss_test:0.14546, lr:1.33e-03, fs:0.84974 (r=0.828,p=0.872),  time:33.824, tt:3416.256\n",
      "Ep:101, loss:0.00005, loss_test:0.14545, lr:1.30e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.835, tt:3451.136\n",
      "Ep:102, loss:0.00005, loss_test:0.14495, lr:1.27e-03, fs:0.85128 (r=0.838,p=0.865),  time:33.869, tt:3488.548\n",
      "Ep:103, loss:0.00005, loss_test:0.14418, lr:1.25e-03, fs:0.84103 (r=0.828,p=0.854),  time:33.873, tt:3522.815\n",
      "Ep:104, loss:0.00005, loss_test:0.14453, lr:1.22e-03, fs:0.84103 (r=0.828,p=0.854),  time:33.886, tt:3558.005\n",
      "Ep:105, loss:0.00005, loss_test:0.14650, lr:1.20e-03, fs:0.84817 (r=0.818,p=0.880),  time:33.890, tt:3592.316\n",
      "Ep:106, loss:0.00005, loss_test:0.14722, lr:1.17e-03, fs:0.84375 (r=0.818,p=0.871),  time:33.896, tt:3626.895\n",
      "Ep:107, loss:0.00005, loss_test:0.14643, lr:1.15e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.913, tt:3662.619\n",
      "Ep:108, loss:0.00005, loss_test:0.14716, lr:1.13e-03, fs:0.84817 (r=0.818,p=0.880),  time:33.921, tt:3697.442\n",
      "Ep:109, loss:0.00005, loss_test:0.14703, lr:1.11e-03, fs:0.84817 (r=0.818,p=0.880),  time:33.928, tt:3732.121\n",
      "Ep:110, loss:0.00004, loss_test:0.14694, lr:1.08e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.949, tt:3768.344\n",
      "Ep:111, loss:0.00005, loss_test:0.14739, lr:1.06e-03, fs:0.84536 (r=0.828,p=0.863),  time:33.958, tt:3803.285\n",
      "Ep:112, loss:0.00004, loss_test:0.14934, lr:1.04e-03, fs:0.84211 (r=0.808,p=0.879),  time:33.968, tt:3838.423\n",
      "Ep:113, loss:0.00004, loss_test:0.14874, lr:1.02e-03, fs:0.84211 (r=0.808,p=0.879),  time:33.992, tt:3875.139\n",
      "Ep:114, loss:0.00004, loss_test:0.14642, lr:9.99e-04, fs:0.84375 (r=0.818,p=0.871),  time:34.000, tt:3910.042\n",
      "Ep:115, loss:0.00004, loss_test:0.14498, lr:9.79e-04, fs:0.83077 (r=0.818,p=0.844),  time:33.995, tt:3943.401\n",
      "Ep:116, loss:0.00004, loss_test:0.14599, lr:9.60e-04, fs:0.84974 (r=0.828,p=0.872),  time:34.002, tt:3978.205\n",
      "Ep:117, loss:0.00004, loss_test:0.14855, lr:9.41e-04, fs:0.84817 (r=0.818,p=0.880),  time:34.013, tt:4013.540\n",
      "Ep:118, loss:0.00004, loss_test:0.14970, lr:9.22e-04, fs:0.83598 (r=0.798,p=0.878),  time:34.027, tt:4049.178\n",
      "Ep:119, loss:0.00004, loss_test:0.14946, lr:9.03e-04, fs:0.83598 (r=0.798,p=0.878),  time:34.031, tt:4083.698\n",
      "Ep:120, loss:0.00004, loss_test:0.14876, lr:8.85e-04, fs:0.84375 (r=0.818,p=0.871),  time:34.034, tt:4118.139\n",
      "Ep:121, loss:0.00004, loss_test:0.14811, lr:8.68e-04, fs:0.84375 (r=0.818,p=0.871),  time:34.020, tt:4150.414\n",
      "Ep:122, loss:0.00004, loss_test:0.14745, lr:8.50e-04, fs:0.83938 (r=0.818,p=0.862),  time:33.996, tt:4181.469\n",
      "Ep:123, loss:0.00004, loss_test:0.14782, lr:8.33e-04, fs:0.84536 (r=0.828,p=0.863),  time:33.998, tt:4215.776\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24339, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.431, tt:31.431\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24114, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.237, tt:64.474\n",
      "Ep:2, loss:0.00059, loss_test:0.23611, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.336, tt:94.007\n",
      "Ep:3, loss:0.00057, loss_test:0.22615, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.831, tt:127.323\n",
      "Ep:4, loss:0.00051, loss_test:0.21237, lr:9.22e-03, fs:0.67123 (r=0.990,p=0.508),  time:31.817, tt:159.083\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.20101, lr:9.04e-03, fs:0.68482 (r=0.889,p=0.557),  time:32.419, tt:194.515\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:6, loss:0.00033, loss_test:0.21394, lr:8.86e-03, fs:0.68519 (r=0.747,p=0.632),  time:32.655, tt:228.585\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.20905, lr:8.68e-03, fs:0.68519 (r=0.747,p=0.632),  time:32.799, tt:262.388\n",
      "Ep:8, loss:0.00031, loss_test:0.20882, lr:8.51e-03, fs:0.69124 (r=0.758,p=0.636),  time:33.019, tt:297.172\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.21722, lr:8.34e-03, fs:0.69652 (r=0.707,p=0.686),  time:33.182, tt:331.822\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.21118, lr:8.17e-03, fs:0.68627 (r=0.707,p=0.667),  time:33.392, tt:367.307\n",
      "Ep:11, loss:0.00028, loss_test:0.20210, lr:8.01e-03, fs:0.68627 (r=0.707,p=0.667),  time:33.388, tt:400.651\n",
      "Ep:12, loss:0.00027, loss_test:0.20219, lr:7.85e-03, fs:0.68687 (r=0.687,p=0.687),  time:33.489, tt:435.363\n",
      "Ep:13, loss:0.00026, loss_test:0.19903, lr:7.69e-03, fs:0.70408 (r=0.697,p=0.711),  time:33.598, tt:470.371\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00026, loss_test:0.18929, lr:7.54e-03, fs:0.73333 (r=0.778,p=0.694),  time:33.670, tt:505.044\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.19518, lr:7.39e-03, fs:0.70103 (r=0.687,p=0.716),  time:33.673, tt:538.762\n",
      "Ep:16, loss:0.00025, loss_test:0.19842, lr:7.24e-03, fs:0.70103 (r=0.687,p=0.716),  time:33.635, tt:571.802\n",
      "Ep:17, loss:0.00024, loss_test:0.19003, lr:7.09e-03, fs:0.69608 (r=0.717,p=0.676),  time:33.573, tt:604.309\n",
      "Ep:18, loss:0.00024, loss_test:0.19298, lr:6.95e-03, fs:0.71579 (r=0.687,p=0.747),  time:33.592, tt:638.253\n",
      "Ep:19, loss:0.00024, loss_test:0.19778, lr:6.81e-03, fs:0.73684 (r=0.707,p=0.769),  time:33.621, tt:672.428\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.18587, lr:6.68e-03, fs:0.76000 (r=0.768,p=0.752),  time:33.642, tt:706.482\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.18363, lr:6.54e-03, fs:0.72115 (r=0.758,p=0.688),  time:33.697, tt:741.336\n",
      "Ep:22, loss:0.00022, loss_test:0.19600, lr:6.41e-03, fs:0.73797 (r=0.697,p=0.784),  time:33.676, tt:774.541\n",
      "Ep:23, loss:0.00023, loss_test:0.19293, lr:6.28e-03, fs:0.73016 (r=0.697,p=0.767),  time:33.682, tt:808.356\n",
      "Ep:24, loss:0.00022, loss_test:0.18520, lr:6.16e-03, fs:0.72727 (r=0.727,p=0.727),  time:33.670, tt:841.744\n",
      "Ep:25, loss:0.00022, loss_test:0.19075, lr:6.03e-03, fs:0.73846 (r=0.727,p=0.750),  time:33.636, tt:874.539\n",
      "Ep:26, loss:0.00020, loss_test:0.18506, lr:5.91e-03, fs:0.73786 (r=0.768,p=0.710),  time:33.618, tt:907.687\n",
      "Ep:27, loss:0.00020, loss_test:0.18576, lr:5.80e-03, fs:0.77157 (r=0.768,p=0.776),  time:33.661, tt:942.496\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00020, loss_test:0.19385, lr:5.68e-03, fs:0.75532 (r=0.717,p=0.798),  time:33.693, tt:977.097\n",
      "Ep:29, loss:0.00020, loss_test:0.18200, lr:5.57e-03, fs:0.74877 (r=0.768,p=0.731),  time:33.708, tt:1011.241\n",
      "Ep:30, loss:0.00019, loss_test:0.18301, lr:5.45e-03, fs:0.76382 (r=0.768,p=0.760),  time:33.715, tt:1045.164\n",
      "Ep:31, loss:0.00018, loss_test:0.18608, lr:5.35e-03, fs:0.78756 (r=0.768,p=0.809),  time:33.718, tt:1078.972\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00019, loss_test:0.18535, lr:5.24e-03, fs:0.78974 (r=0.778,p=0.802),  time:33.727, tt:1112.994\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00018, loss_test:0.18386, lr:5.13e-03, fs:0.76000 (r=0.768,p=0.752),  time:33.813, tt:1149.634\n",
      "Ep:34, loss:0.00018, loss_test:0.18228, lr:5.03e-03, fs:0.76768 (r=0.768,p=0.768),  time:33.775, tt:1182.120\n",
      "Ep:35, loss:0.00017, loss_test:0.18338, lr:4.93e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.765, tt:1215.551\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00017, loss_test:0.17883, lr:4.83e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.795, tt:1250.411\n",
      "Ep:37, loss:0.00017, loss_test:0.18134, lr:4.74e-03, fs:0.78000 (r=0.788,p=0.772),  time:33.800, tt:1284.402\n",
      "Ep:38, loss:0.00017, loss_test:0.18316, lr:4.64e-03, fs:0.78571 (r=0.778,p=0.794),  time:33.823, tt:1319.114\n",
      "Ep:39, loss:0.00016, loss_test:0.18343, lr:4.55e-03, fs:0.79793 (r=0.778,p=0.819),  time:33.868, tt:1354.729\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00015, loss_test:0.17709, lr:4.46e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.856, tt:1388.097\n",
      "Ep:41, loss:0.00015, loss_test:0.18040, lr:4.37e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.835, tt:1421.080\n",
      "Ep:42, loss:0.00015, loss_test:0.18377, lr:4.28e-03, fs:0.80000 (r=0.788,p=0.812),  time:33.852, tt:1455.633\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00015, loss_test:0.17826, lr:4.19e-03, fs:0.79000 (r=0.798,p=0.782),  time:33.879, tt:1490.664\n",
      "Ep:44, loss:0.00014, loss_test:0.17807, lr:4.11e-03, fs:0.79397 (r=0.798,p=0.790),  time:33.918, tt:1526.311\n",
      "Ep:45, loss:0.00014, loss_test:0.18606, lr:4.03e-03, fs:0.80829 (r=0.788,p=0.830),  time:33.929, tt:1560.742\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00014, loss_test:0.18205, lr:3.95e-03, fs:0.81443 (r=0.798,p=0.832),  time:33.911, tt:1593.803\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00013, loss_test:0.17308, lr:3.87e-03, fs:0.80583 (r=0.838,p=0.776),  time:33.934, tt:1628.839\n",
      "Ep:48, loss:0.00013, loss_test:0.17830, lr:3.79e-03, fs:0.81188 (r=0.828,p=0.796),  time:33.926, tt:1662.374\n",
      "Ep:49, loss:0.00013, loss_test:0.18476, lr:3.72e-03, fs:0.79793 (r=0.778,p=0.819),  time:33.922, tt:1696.105\n",
      "Ep:50, loss:0.00013, loss_test:0.17662, lr:3.64e-03, fs:0.81407 (r=0.818,p=0.810),  time:33.905, tt:1729.168\n",
      "Ep:51, loss:0.00013, loss_test:0.17434, lr:3.57e-03, fs:0.81773 (r=0.838,p=0.798),  time:33.923, tt:1763.995\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00012, loss_test:0.18545, lr:3.50e-03, fs:0.80412 (r=0.788,p=0.821),  time:33.910, tt:1797.256\n",
      "Ep:53, loss:0.00012, loss_test:0.17473, lr:3.43e-03, fs:0.80392 (r=0.828,p=0.781),  time:33.914, tt:1831.376\n",
      "Ep:54, loss:0.00012, loss_test:0.17353, lr:3.36e-03, fs:0.81818 (r=0.818,p=0.818),  time:33.918, tt:1865.495\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00011, loss_test:0.18294, lr:3.29e-03, fs:0.80208 (r=0.778,p=0.828),  time:33.916, tt:1899.320\n",
      "Ep:56, loss:0.00011, loss_test:0.18090, lr:3.23e-03, fs:0.82051 (r=0.808,p=0.833),  time:33.922, tt:1933.532\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00011, loss_test:0.17489, lr:3.16e-03, fs:0.81592 (r=0.828,p=0.804),  time:33.900, tt:1966.201\n",
      "Ep:58, loss:0.00011, loss_test:0.17196, lr:3.10e-03, fs:0.82000 (r=0.828,p=0.812),  time:33.915, tt:2000.988\n",
      "Ep:59, loss:0.00010, loss_test:0.17918, lr:3.04e-03, fs:0.82474 (r=0.808,p=0.842),  time:33.926, tt:2035.565\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00010, loss_test:0.17971, lr:2.98e-03, fs:0.80412 (r=0.788,p=0.821),  time:33.943, tt:2070.510\n",
      "Ep:61, loss:0.00010, loss_test:0.17980, lr:2.92e-03, fs:0.79381 (r=0.778,p=0.811),  time:33.950, tt:2104.898\n",
      "Ep:62, loss:0.00010, loss_test:0.17860, lr:2.86e-03, fs:0.80208 (r=0.778,p=0.828),  time:33.968, tt:2139.960\n",
      "Ep:63, loss:0.00010, loss_test:0.17814, lr:2.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:33.974, tt:2174.359\n",
      "Ep:64, loss:0.00009, loss_test:0.18042, lr:2.74e-03, fs:0.76596 (r=0.727,p=0.809),  time:33.960, tt:2207.368\n",
      "Ep:65, loss:0.00009, loss_test:0.17981, lr:2.69e-03, fs:0.76596 (r=0.727,p=0.809),  time:33.956, tt:2241.064\n",
      "Ep:66, loss:0.00009, loss_test:0.17737, lr:2.64e-03, fs:0.79581 (r=0.768,p=0.826),  time:33.946, tt:2274.412\n",
      "Ep:67, loss:0.00009, loss_test:0.18058, lr:2.58e-03, fs:0.79144 (r=0.747,p=0.841),  time:33.940, tt:2307.933\n",
      "Ep:68, loss:0.00009, loss_test:0.18168, lr:2.53e-03, fs:0.77419 (r=0.727,p=0.828),  time:33.923, tt:2340.677\n",
      "Ep:69, loss:0.00009, loss_test:0.18092, lr:2.48e-03, fs:0.76344 (r=0.717,p=0.816),  time:33.924, tt:2374.696\n",
      "Ep:70, loss:0.00008, loss_test:0.17987, lr:2.43e-03, fs:0.75269 (r=0.707,p=0.805),  time:33.914, tt:2407.899\n",
      "Ep:71, loss:0.00008, loss_test:0.17427, lr:2.38e-03, fs:0.80402 (r=0.808,p=0.800),  time:33.902, tt:2440.941\n",
      "Ep:72, loss:0.00008, loss_test:0.17789, lr:2.33e-03, fs:0.77249 (r=0.737,p=0.811),  time:33.912, tt:2475.568\n",
      "Ep:73, loss:0.00008, loss_test:0.17749, lr:2.29e-03, fs:0.75676 (r=0.707,p=0.814),  time:33.939, tt:2511.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00007, loss_test:0.17718, lr:2.24e-03, fs:0.78125 (r=0.758,p=0.806),  time:33.956, tt:2546.726\n",
      "Ep:75, loss:0.00007, loss_test:0.18227, lr:2.20e-03, fs:0.75000 (r=0.697,p=0.812),  time:33.954, tt:2580.483\n",
      "Ep:76, loss:0.00007, loss_test:0.18153, lr:2.15e-03, fs:0.74317 (r=0.687,p=0.810),  time:33.964, tt:2615.258\n",
      "Ep:77, loss:0.00007, loss_test:0.17748, lr:2.11e-03, fs:0.77660 (r=0.737,p=0.820),  time:33.967, tt:2649.433\n",
      "Ep:78, loss:0.00007, loss_test:0.17806, lr:2.07e-03, fs:0.76757 (r=0.717,p=0.826),  time:33.975, tt:2684.000\n",
      "Ep:79, loss:0.00007, loss_test:0.18074, lr:2.03e-03, fs:0.74317 (r=0.687,p=0.810),  time:33.991, tt:2719.263\n",
      "Ep:80, loss:0.00007, loss_test:0.17917, lr:1.99e-03, fs:0.75676 (r=0.707,p=0.814),  time:34.017, tt:2755.339\n",
      "Ep:81, loss:0.00007, loss_test:0.18042, lr:1.95e-03, fs:0.72928 (r=0.667,p=0.805),  time:34.029, tt:2790.386\n",
      "Ep:82, loss:0.00007, loss_test:0.18338, lr:1.91e-03, fs:0.74033 (r=0.677,p=0.817),  time:34.008, tt:2822.697\n",
      "Ep:83, loss:0.00006, loss_test:0.18113, lr:1.87e-03, fs:0.74725 (r=0.687,p=0.819),  time:34.011, tt:2856.937\n",
      "Ep:84, loss:0.00006, loss_test:0.17653, lr:1.83e-03, fs:0.77419 (r=0.727,p=0.828),  time:34.027, tt:2892.261\n",
      "Ep:85, loss:0.00006, loss_test:0.17907, lr:1.80e-03, fs:0.74725 (r=0.687,p=0.819),  time:34.023, tt:2925.996\n",
      "Ep:86, loss:0.00006, loss_test:0.18279, lr:1.76e-03, fs:0.74033 (r=0.677,p=0.817),  time:34.016, tt:2959.419\n",
      "Ep:87, loss:0.00006, loss_test:0.17922, lr:1.72e-03, fs:0.77838 (r=0.727,p=0.837),  time:34.015, tt:2993.302\n",
      "Ep:88, loss:0.00006, loss_test:0.17749, lr:1.69e-03, fs:0.76087 (r=0.707,p=0.824),  time:34.007, tt:3026.617\n",
      "Ep:89, loss:0.00006, loss_test:0.17633, lr:1.66e-03, fs:0.75269 (r=0.707,p=0.805),  time:33.999, tt:3059.948\n",
      "Ep:90, loss:0.00006, loss_test:0.17723, lr:1.62e-03, fs:0.74317 (r=0.687,p=0.810),  time:34.001, tt:3094.112\n",
      "Ep:91, loss:0.00006, loss_test:0.18127, lr:1.59e-03, fs:0.72626 (r=0.657,p=0.812),  time:33.997, tt:3127.738\n",
      "Ep:92, loss:0.00006, loss_test:0.17999, lr:1.56e-03, fs:0.72316 (r=0.646,p=0.821),  time:34.002, tt:3162.232\n",
      "Ep:93, loss:0.00006, loss_test:0.17832, lr:1.53e-03, fs:0.72928 (r=0.667,p=0.805),  time:34.002, tt:3196.147\n",
      "Ep:94, loss:0.00005, loss_test:0.17812, lr:1.50e-03, fs:0.73333 (r=0.667,p=0.815),  time:33.986, tt:3228.710\n",
      "Ep:95, loss:0.00005, loss_test:0.18197, lr:1.47e-03, fs:0.72626 (r=0.657,p=0.812),  time:33.998, tt:3263.799\n",
      "Ep:96, loss:0.00006, loss_test:0.18355, lr:1.44e-03, fs:0.71186 (r=0.636,p=0.808),  time:33.995, tt:3297.558\n",
      "Ep:97, loss:0.00005, loss_test:0.18338, lr:1.41e-03, fs:0.71508 (r=0.646,p=0.800),  time:33.991, tt:3331.104\n",
      "Ep:98, loss:0.00005, loss_test:0.18270, lr:1.38e-03, fs:0.70718 (r=0.646,p=0.780),  time:33.977, tt:3363.763\n",
      "Ep:99, loss:0.00005, loss_test:0.18157, lr:1.35e-03, fs:0.71508 (r=0.646,p=0.800),  time:33.968, tt:3396.807\n",
      "Ep:100, loss:0.00005, loss_test:0.18203, lr:1.33e-03, fs:0.71186 (r=0.636,p=0.808),  time:33.947, tt:3428.678\n",
      "Ep:101, loss:0.00005, loss_test:0.18145, lr:1.30e-03, fs:0.71508 (r=0.646,p=0.800),  time:33.948, tt:3462.702\n",
      "Ep:102, loss:0.00005, loss_test:0.18078, lr:1.27e-03, fs:0.71823 (r=0.657,p=0.793),  time:33.944, tt:3496.221\n",
      "Ep:103, loss:0.00005, loss_test:0.17990, lr:1.25e-03, fs:0.71111 (r=0.646,p=0.790),  time:33.952, tt:3530.968\n",
      "Ep:104, loss:0.00005, loss_test:0.17927, lr:1.22e-03, fs:0.71111 (r=0.646,p=0.790),  time:33.954, tt:3565.191\n",
      "Ep:105, loss:0.00005, loss_test:0.17979, lr:1.20e-03, fs:0.71111 (r=0.646,p=0.790),  time:33.958, tt:3599.583\n",
      "Ep:106, loss:0.00004, loss_test:0.18087, lr:1.17e-03, fs:0.70391 (r=0.636,p=0.787),  time:33.947, tt:3632.381\n",
      "Ep:107, loss:0.00005, loss_test:0.17943, lr:1.15e-03, fs:0.69663 (r=0.626,p=0.785),  time:33.945, tt:3666.061\n",
      "Ep:108, loss:0.00005, loss_test:0.17887, lr:1.13e-03, fs:0.70391 (r=0.636,p=0.787),  time:33.934, tt:3698.820\n",
      "Ep:109, loss:0.00004, loss_test:0.18068, lr:1.11e-03, fs:0.70787 (r=0.636,p=0.797),  time:33.930, tt:3732.260\n",
      "Ep:110, loss:0.00004, loss_test:0.18356, lr:1.08e-03, fs:0.70455 (r=0.626,p=0.805),  time:33.933, tt:3766.615\n",
      "Ep:111, loss:0.00004, loss_test:0.18365, lr:1.06e-03, fs:0.71111 (r=0.646,p=0.790),  time:33.927, tt:3799.842\n",
      "Ep:112, loss:0.00004, loss_test:0.18298, lr:1.04e-03, fs:0.69663 (r=0.626,p=0.785),  time:33.942, tt:3835.437\n",
      "Ep:113, loss:0.00004, loss_test:0.18064, lr:1.02e-03, fs:0.70787 (r=0.636,p=0.797),  time:33.944, tt:3869.597\n",
      "Ep:114, loss:0.00004, loss_test:0.18035, lr:9.99e-04, fs:0.70787 (r=0.636,p=0.797),  time:33.928, tt:3901.732\n",
      "Ep:115, loss:0.00004, loss_test:0.18041, lr:9.79e-04, fs:0.70056 (r=0.626,p=0.795),  time:33.926, tt:3935.439\n",
      "Ep:116, loss:0.00004, loss_test:0.18176, lr:9.60e-04, fs:0.70056 (r=0.626,p=0.795),  time:33.940, tt:3970.941\n",
      "Ep:117, loss:0.00004, loss_test:0.18300, lr:9.41e-04, fs:0.70056 (r=0.626,p=0.795),  time:33.947, tt:4005.713\n",
      "Ep:118, loss:0.00004, loss_test:0.18161, lr:9.22e-04, fs:0.70056 (r=0.626,p=0.795),  time:33.938, tt:4038.661\n",
      "Ep:119, loss:0.00004, loss_test:0.18061, lr:9.03e-04, fs:0.70056 (r=0.626,p=0.795),  time:33.944, tt:4073.256\n",
      "Ep:120, loss:0.00004, loss_test:0.18018, lr:8.85e-04, fs:0.69663 (r=0.626,p=0.785),  time:33.920, tt:4104.363\n",
      "Ep:121, loss:0.00004, loss_test:0.18067, lr:8.68e-04, fs:0.69663 (r=0.626,p=0.785),  time:33.917, tt:4137.902\n",
      "Ep:122, loss:0.00004, loss_test:0.18159, lr:8.50e-04, fs:0.70455 (r=0.626,p=0.805),  time:33.907, tt:4170.601\n",
      "Ep:123, loss:0.00004, loss_test:0.18166, lr:8.33e-04, fs:0.70455 (r=0.626,p=0.805),  time:33.904, tt:4204.065\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24346, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.054, tt:34.054\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.24122, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:32.042, tt:64.085\n",
      "Ep:2, loss:0.00060, loss_test:0.23639, lr:9.60e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.384, tt:94.151\n",
      "Ep:3, loss:0.00056, loss_test:0.22617, lr:9.41e-03, fs:0.66667 (r=1.000,p=0.500),  time:31.566, tt:126.266\n",
      "Ep:4, loss:0.00051, loss_test:0.20841, lr:9.22e-03, fs:0.66894 (r=0.990,p=0.505),  time:32.395, tt:161.977\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00043, loss_test:0.18971, lr:9.04e-03, fs:0.69853 (r=0.960,p=0.549),  time:32.311, tt:193.866\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.19323, lr:8.86e-03, fs:0.70339 (r=0.838,p=0.606),  time:32.702, tt:228.913\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00032, loss_test:0.19211, lr:8.68e-03, fs:0.69748 (r=0.838,p=0.597),  time:32.961, tt:263.685\n",
      "Ep:8, loss:0.00031, loss_test:0.18868, lr:8.51e-03, fs:0.72803 (r=0.879,p=0.621),  time:33.318, tt:299.864\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.18767, lr:8.34e-03, fs:0.74138 (r=0.869,p=0.647),  time:33.359, tt:333.595\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00029, loss_test:0.18385, lr:8.17e-03, fs:0.73191 (r=0.869,p=0.632),  time:33.527, tt:368.802\n",
      "Ep:11, loss:0.00029, loss_test:0.18064, lr:8.01e-03, fs:0.71681 (r=0.818,p=0.638),  time:33.593, tt:403.122\n",
      "Ep:12, loss:0.00027, loss_test:0.18263, lr:7.85e-03, fs:0.72381 (r=0.768,p=0.685),  time:33.665, tt:437.645\n",
      "Ep:13, loss:0.00026, loss_test:0.17927, lr:7.69e-03, fs:0.72986 (r=0.778,p=0.688),  time:33.620, tt:470.676\n",
      "Ep:14, loss:0.00026, loss_test:0.17624, lr:7.54e-03, fs:0.71429 (r=0.808,p=0.640),  time:33.654, tt:504.804\n",
      "Ep:15, loss:0.00025, loss_test:0.17095, lr:7.39e-03, fs:0.74336 (r=0.848,p=0.661),  time:33.623, tt:537.975\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00025, loss_test:0.17635, lr:7.24e-03, fs:0.75728 (r=0.788,p=0.729),  time:33.599, tt:571.185\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.17472, lr:7.09e-03, fs:0.75962 (r=0.798,p=0.725),  time:33.573, tt:604.310\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00023, loss_test:0.16760, lr:6.95e-03, fs:0.74107 (r=0.838,p=0.664),  time:33.482, tt:636.155\n",
      "Ep:19, loss:0.00022, loss_test:0.16900, lr:6.81e-03, fs:0.75000 (r=0.818,p=0.692),  time:33.500, tt:669.991\n",
      "Ep:20, loss:0.00022, loss_test:0.16797, lr:6.68e-03, fs:0.77512 (r=0.818,p=0.736),  time:33.451, tt:702.480\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.16159, lr:6.54e-03, fs:0.77130 (r=0.869,p=0.694),  time:33.407, tt:734.953\n",
      "Ep:22, loss:0.00021, loss_test:0.16327, lr:6.41e-03, fs:0.76995 (r=0.828,p=0.719),  time:33.408, tt:768.388\n",
      "Ep:23, loss:0.00021, loss_test:0.16231, lr:6.28e-03, fs:0.77143 (r=0.818,p=0.730),  time:33.389, tt:801.347\n",
      "Ep:24, loss:0.00021, loss_test:0.16041, lr:6.16e-03, fs:0.74419 (r=0.808,p=0.690),  time:33.189, tt:829.726\n",
      "Ep:25, loss:0.00019, loss_test:0.16051, lr:6.03e-03, fs:0.76852 (r=0.838,p=0.709),  time:32.657, tt:849.082\n",
      "Ep:26, loss:0.00019, loss_test:0.15791, lr:5.91e-03, fs:0.78505 (r=0.848,p=0.730),  time:32.252, tt:870.795\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00019, loss_test:0.15841, lr:5.80e-03, fs:0.80769 (r=0.848,p=0.771),  time:31.774, tt:889.675\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00019, loss_test:0.16241, lr:5.68e-03, fs:0.81407 (r=0.818,p=0.810),  time:31.415, tt:911.036\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00018, loss_test:0.15697, lr:5.57e-03, fs:0.78302 (r=0.838,p=0.735),  time:31.022, tt:930.653\n",
      "Ep:30, loss:0.00018, loss_test:0.15677, lr:5.45e-03, fs:0.80769 (r=0.848,p=0.771),  time:30.690, tt:951.377\n",
      "Ep:31, loss:0.00018, loss_test:0.16156, lr:5.35e-03, fs:0.81407 (r=0.818,p=0.810),  time:30.376, tt:972.029\n",
      "Ep:32, loss:0.00017, loss_test:0.15693, lr:5.24e-03, fs:0.81773 (r=0.838,p=0.798),  time:30.038, tt:991.255\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00016, loss_test:0.15887, lr:5.13e-03, fs:0.79808 (r=0.838,p=0.761),  time:29.826, tt:1014.093\n",
      "Ep:34, loss:0.00016, loss_test:0.16142, lr:5.03e-03, fs:0.81818 (r=0.818,p=0.818),  time:29.625, tt:1036.878\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00016, loss_test:0.15454, lr:4.93e-03, fs:0.81951 (r=0.848,p=0.792),  time:29.388, tt:1057.971\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00015, loss_test:0.15764, lr:4.83e-03, fs:0.82000 (r=0.828,p=0.812),  time:29.144, tt:1078.339\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00015, loss_test:0.16187, lr:4.74e-03, fs:0.82234 (r=0.818,p=0.827),  time:28.891, tt:1097.871\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00014, loss_test:0.15393, lr:4.64e-03, fs:0.82524 (r=0.859,p=0.794),  time:28.728, tt:1120.381\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00014, loss_test:0.15353, lr:4.55e-03, fs:0.82759 (r=0.848,p=0.808),  time:28.499, tt:1139.976\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.15919, lr:4.46e-03, fs:0.81675 (r=0.788,p=0.848),  time:28.315, tt:1160.915\n",
      "Ep:41, loss:0.00013, loss_test:0.15105, lr:4.37e-03, fs:0.83092 (r=0.869,p=0.796),  time:28.130, tt:1181.474\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.15569, lr:4.28e-03, fs:0.82412 (r=0.828,p=0.820),  time:28.006, tt:1204.246\n",
      "Ep:43, loss:0.00012, loss_test:0.15982, lr:4.19e-03, fs:0.81026 (r=0.798,p=0.823),  time:27.840, tt:1224.951\n",
      "Ep:44, loss:0.00012, loss_test:0.15638, lr:4.11e-03, fs:0.82000 (r=0.828,p=0.812),  time:27.728, tt:1247.754\n",
      "Ep:45, loss:0.00012, loss_test:0.15638, lr:4.03e-03, fs:0.82412 (r=0.828,p=0.820),  time:27.614, tt:1270.238\n",
      "Ep:46, loss:0.00011, loss_test:0.16020, lr:3.95e-03, fs:0.81865 (r=0.798,p=0.840),  time:27.538, tt:1294.281\n",
      "Ep:47, loss:0.00011, loss_test:0.15848, lr:3.87e-03, fs:0.80203 (r=0.798,p=0.806),  time:27.420, tt:1316.139\n",
      "Ep:48, loss:0.00011, loss_test:0.15671, lr:3.79e-03, fs:0.83077 (r=0.818,p=0.844),  time:27.321, tt:1338.720\n",
      "Ep:49, loss:0.00011, loss_test:0.16161, lr:3.72e-03, fs:0.83158 (r=0.798,p=0.868),  time:27.243, tt:1362.155\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00010, loss_test:0.15810, lr:3.64e-03, fs:0.81250 (r=0.788,p=0.839),  time:27.142, tt:1384.221\n",
      "Ep:51, loss:0.00010, loss_test:0.15333, lr:3.57e-03, fs:0.81818 (r=0.818,p=0.818),  time:27.043, tt:1406.212\n",
      "Ep:52, loss:0.00009, loss_test:0.16155, lr:3.50e-03, fs:0.82723 (r=0.798,p=0.859),  time:26.952, tt:1428.458\n",
      "Ep:53, loss:0.00009, loss_test:0.16059, lr:3.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:26.828, tt:1448.733\n",
      "Ep:54, loss:0.00009, loss_test:0.15471, lr:3.36e-03, fs:0.82105 (r=0.788,p=0.857),  time:26.732, tt:1470.241\n",
      "Ep:55, loss:0.00009, loss_test:0.15586, lr:3.29e-03, fs:0.80829 (r=0.788,p=0.830),  time:26.625, tt:1491.019\n",
      "Ep:56, loss:0.00009, loss_test:0.16263, lr:3.23e-03, fs:0.81915 (r=0.778,p=0.865),  time:26.526, tt:1511.963\n",
      "Ep:57, loss:0.00008, loss_test:0.16109, lr:3.16e-03, fs:0.82723 (r=0.798,p=0.859),  time:26.385, tt:1530.312\n",
      "Ep:58, loss:0.00008, loss_test:0.15561, lr:3.10e-03, fs:0.82105 (r=0.788,p=0.857),  time:26.242, tt:1548.271\n",
      "Ep:59, loss:0.00008, loss_test:0.15733, lr:3.04e-03, fs:0.81481 (r=0.778,p=0.856),  time:26.123, tt:1567.395\n",
      "Ep:60, loss:0.00008, loss_test:0.16574, lr:2.98e-03, fs:0.81481 (r=0.778,p=0.856),  time:26.007, tt:1586.439\n",
      "Ep:61, loss:0.00007, loss_test:0.16048, lr:2.92e-03, fs:0.80851 (r=0.768,p=0.854),  time:25.888, tt:1605.035\n",
      "Ep:62, loss:0.00007, loss_test:0.15952, lr:2.86e-03, fs:0.80645 (r=0.758,p=0.862),  time:25.808, tt:1625.886\n",
      "Ep:63, loss:0.00007, loss_test:0.16504, lr:2.80e-03, fs:0.81319 (r=0.747,p=0.892),  time:25.729, tt:1646.636\n",
      "Ep:64, loss:0.00007, loss_test:0.16348, lr:2.74e-03, fs:0.83158 (r=0.798,p=0.868),  time:25.611, tt:1664.731\n",
      "Ep:65, loss:0.00007, loss_test:0.15871, lr:2.69e-03, fs:0.82105 (r=0.788,p=0.857),  time:25.558, tt:1686.818\n",
      "Ep:66, loss:0.00006, loss_test:0.16106, lr:2.64e-03, fs:0.81915 (r=0.778,p=0.865),  time:25.463, tt:1706.022\n",
      "Ep:67, loss:0.00006, loss_test:0.16595, lr:2.58e-03, fs:0.79348 (r=0.737,p=0.859),  time:25.384, tt:1726.146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072c7752a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,124,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24189, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.091, tt:15.091\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23888, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:15.398, tt:30.797\n",
      "Ep:2, loss:0.00059, loss_test:0.23230, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:16.527, tt:49.580\n",
      "Ep:3, loss:0.00055, loss_test:0.21925, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:18.363, tt:73.451\n",
      "Ep:4, loss:0.00048, loss_test:0.19794, lr:9.61e-03, fs:0.66438 (r=0.980,p=0.503),  time:20.602, tt:103.010\n",
      "Ep:5, loss:0.00038, loss_test:0.18306, lr:9.51e-03, fs:0.65000 (r=0.788,p=0.553),  time:22.356, tt:134.135\n",
      "Ep:6, loss:0.00031, loss_test:0.18269, lr:9.41e-03, fs:0.69333 (r=0.788,p=0.619),  time:24.627, tt:172.390\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00031, loss_test:0.18239, lr:9.32e-03, fs:0.71171 (r=0.798,p=0.642),  time:26.525, tt:212.203\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.18219, lr:9.23e-03, fs:0.69333 (r=0.788,p=0.619),  time:28.116, tt:253.044\n",
      "Ep:9, loss:0.00028, loss_test:0.18540, lr:9.14e-03, fs:0.75117 (r=0.808,p=0.702),  time:29.322, tt:293.216\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.18645, lr:9.04e-03, fs:0.73786 (r=0.768,p=0.710),  time:30.361, tt:333.974\n",
      "Ep:11, loss:0.00026, loss_test:0.18251, lr:8.95e-03, fs:0.71429 (r=0.758,p=0.676),  time:31.339, tt:376.072\n",
      "Ep:12, loss:0.00025, loss_test:0.18772, lr:8.86e-03, fs:0.71351 (r=0.667,p=0.767),  time:32.056, tt:416.723\n",
      "Ep:13, loss:0.00024, loss_test:0.17763, lr:8.78e-03, fs:0.74396 (r=0.778,p=0.713),  time:32.845, tt:459.836\n",
      "Ep:14, loss:0.00024, loss_test:0.17440, lr:8.69e-03, fs:0.75829 (r=0.808,p=0.714),  time:33.576, tt:503.647\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.17667, lr:8.60e-03, fs:0.76471 (r=0.788,p=0.743),  time:33.876, tt:542.020\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.17407, lr:8.51e-03, fs:0.73737 (r=0.737,p=0.737),  time:34.097, tt:579.646\n",
      "Ep:17, loss:0.00022, loss_test:0.16991, lr:8.43e-03, fs:0.73786 (r=0.768,p=0.710),  time:34.437, tt:619.866\n",
      "Ep:18, loss:0.00022, loss_test:0.17321, lr:8.35e-03, fs:0.76617 (r=0.778,p=0.755),  time:34.688, tt:659.081\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.17036, lr:8.26e-03, fs:0.74396 (r=0.778,p=0.713),  time:34.985, tt:699.698\n",
      "Ep:20, loss:0.00020, loss_test:0.16486, lr:8.18e-03, fs:0.73733 (r=0.808,p=0.678),  time:35.171, tt:738.596\n",
      "Ep:21, loss:0.00019, loss_test:0.16270, lr:8.10e-03, fs:0.75122 (r=0.778,p=0.726),  time:35.520, tt:781.439\n",
      "Ep:22, loss:0.00019, loss_test:0.15911, lr:8.02e-03, fs:0.80952 (r=0.859,p=0.766),  time:35.795, tt:823.282\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.15762, lr:7.94e-03, fs:0.77358 (r=0.828,p=0.726),  time:36.116, tt:866.774\n",
      "Ep:24, loss:0.00018, loss_test:0.15791, lr:7.86e-03, fs:0.79612 (r=0.828,p=0.766),  time:36.352, tt:908.792\n",
      "Ep:25, loss:0.00018, loss_test:0.15965, lr:7.78e-03, fs:0.77778 (r=0.778,p=0.778),  time:36.487, tt:948.668\n",
      "Ep:26, loss:0.00017, loss_test:0.15890, lr:7.70e-03, fs:0.77833 (r=0.798,p=0.760),  time:36.537, tt:986.508\n",
      "Ep:27, loss:0.00017, loss_test:0.15694, lr:7.62e-03, fs:0.80189 (r=0.859,p=0.752),  time:36.641, tt:1025.960\n",
      "Ep:28, loss:0.00016, loss_test:0.15650, lr:7.55e-03, fs:0.77228 (r=0.788,p=0.757),  time:36.726, tt:1065.051\n",
      "Ep:29, loss:0.00016, loss_test:0.15178, lr:7.47e-03, fs:0.83254 (r=0.879,p=0.791),  time:36.785, tt:1103.560\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.14928, lr:7.40e-03, fs:0.82243 (r=0.889,p=0.765),  time:36.918, tt:1144.473\n",
      "Ep:31, loss:0.00015, loss_test:0.15477, lr:7.32e-03, fs:0.77949 (r=0.768,p=0.792),  time:37.133, tt:1188.256\n",
      "Ep:32, loss:0.00015, loss_test:0.15315, lr:7.25e-03, fs:0.84211 (r=0.889,p=0.800),  time:37.362, tt:1232.960\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.14572, lr:7.18e-03, fs:0.82569 (r=0.909,p=0.756),  time:37.567, tt:1277.283\n",
      "Ep:34, loss:0.00014, loss_test:0.14693, lr:7.11e-03, fs:0.83810 (r=0.889,p=0.793),  time:37.754, tt:1321.402\n",
      "Ep:35, loss:0.00014, loss_test:0.14577, lr:7.03e-03, fs:0.83019 (r=0.889,p=0.779),  time:37.809, tt:1361.109\n",
      "Ep:36, loss:0.00014, loss_test:0.15004, lr:6.96e-03, fs:0.85294 (r=0.879,p=0.829),  time:37.880, tt:1401.557\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.14342, lr:6.89e-03, fs:0.84259 (r=0.919,p=0.778),  time:37.954, tt:1442.256\n",
      "Ep:38, loss:0.00013, loss_test:0.14813, lr:6.83e-03, fs:0.80402 (r=0.808,p=0.800),  time:37.987, tt:1481.479\n",
      "Ep:39, loss:0.00012, loss_test:0.14593, lr:6.76e-03, fs:0.82927 (r=0.859,p=0.802),  time:38.032, tt:1521.274\n",
      "Ep:40, loss:0.00012, loss_test:0.14115, lr:6.69e-03, fs:0.84762 (r=0.899,p=0.802),  time:38.095, tt:1561.905\n",
      "Ep:41, loss:0.00012, loss_test:0.14098, lr:6.62e-03, fs:0.84615 (r=0.889,p=0.807),  time:38.239, tt:1606.058\n",
      "Ep:42, loss:0.00011, loss_test:0.14011, lr:6.56e-03, fs:0.86124 (r=0.909,p=0.818),  time:38.398, tt:1651.125\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.14050, lr:6.49e-03, fs:0.84360 (r=0.899,p=0.795),  time:38.533, tt:1695.446\n",
      "Ep:44, loss:0.00010, loss_test:0.13946, lr:6.43e-03, fs:0.84762 (r=0.899,p=0.802),  time:38.668, tt:1740.065\n",
      "Ep:45, loss:0.00010, loss_test:0.13684, lr:6.36e-03, fs:0.85854 (r=0.889,p=0.830),  time:38.738, tt:1781.957\n",
      "Ep:46, loss:0.00010, loss_test:0.13719, lr:6.30e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.814, tt:1824.244\n",
      "Ep:47, loss:0.00010, loss_test:0.13685, lr:6.24e-03, fs:0.86957 (r=0.909,p=0.833),  time:38.883, tt:1866.396\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00010, loss_test:0.13277, lr:6.17e-03, fs:0.84360 (r=0.899,p=0.795),  time:38.948, tt:1908.440\n",
      "Ep:49, loss:0.00009, loss_test:0.13594, lr:6.11e-03, fs:0.85427 (r=0.859,p=0.850),  time:39.000, tt:1950.015\n",
      "Ep:50, loss:0.00009, loss_test:0.13487, lr:6.05e-03, fs:0.84615 (r=0.889,p=0.807),  time:39.066, tt:1992.347\n",
      "Ep:51, loss:0.00009, loss_test:0.13796, lr:5.99e-03, fs:0.86408 (r=0.899,p=0.832),  time:39.193, tt:2038.031\n",
      "Ep:52, loss:0.00009, loss_test:0.13791, lr:5.93e-03, fs:0.87562 (r=0.889,p=0.863),  time:39.288, tt:2082.262\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.13430, lr:5.87e-03, fs:0.85714 (r=0.909,p=0.811),  time:39.427, tt:2129.078\n",
      "Ep:54, loss:0.00008, loss_test:0.13223, lr:5.81e-03, fs:0.86829 (r=0.899,p=0.840),  time:39.492, tt:2172.082\n",
      "Ep:55, loss:0.00008, loss_test:0.13529, lr:5.75e-03, fs:0.86124 (r=0.909,p=0.818),  time:39.524, tt:2213.333\n",
      "Ep:56, loss:0.00007, loss_test:0.13201, lr:5.70e-03, fs:0.85990 (r=0.899,p=0.824),  time:39.526, tt:2252.972\n",
      "Ep:57, loss:0.00007, loss_test:0.13019, lr:5.64e-03, fs:0.84615 (r=0.889,p=0.807),  time:39.531, tt:2292.776\n",
      "Ep:58, loss:0.00007, loss_test:0.13077, lr:5.58e-03, fs:0.85294 (r=0.879,p=0.829),  time:39.564, tt:2334.275\n",
      "Ep:59, loss:0.00007, loss_test:0.13206, lr:5.53e-03, fs:0.84729 (r=0.869,p=0.827),  time:39.582, tt:2374.941\n",
      "Ep:60, loss:0.00006, loss_test:0.12855, lr:5.47e-03, fs:0.85990 (r=0.899,p=0.824),  time:39.615, tt:2416.502\n",
      "Ep:61, loss:0.00006, loss_test:0.12984, lr:5.42e-03, fs:0.88119 (r=0.899,p=0.864),  time:39.699, tt:2461.310\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.13031, lr:5.36e-03, fs:0.85437 (r=0.889,p=0.822),  time:39.761, tt:2504.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.12983, lr:5.31e-03, fs:0.87685 (r=0.899,p=0.856),  time:39.859, tt:2551.000\n",
      "Ep:64, loss:0.00006, loss_test:0.12913, lr:5.26e-03, fs:0.85990 (r=0.899,p=0.824),  time:39.889, tt:2592.779\n",
      "Ep:65, loss:0.00006, loss_test:0.12912, lr:5.20e-03, fs:0.86432 (r=0.869,p=0.860),  time:39.912, tt:2634.179\n",
      "Ep:66, loss:0.00006, loss_test:0.13003, lr:5.15e-03, fs:0.84729 (r=0.869,p=0.827),  time:39.909, tt:2673.882\n",
      "Ep:67, loss:0.00006, loss_test:0.12825, lr:5.10e-03, fs:0.86275 (r=0.889,p=0.838),  time:39.916, tt:2714.312\n",
      "Ep:68, loss:0.00005, loss_test:0.12996, lr:5.05e-03, fs:0.85567 (r=0.838,p=0.874),  time:39.944, tt:2756.108\n",
      "Ep:69, loss:0.00005, loss_test:0.12347, lr:5.00e-03, fs:0.85577 (r=0.899,p=0.817),  time:39.951, tt:2796.571\n",
      "Ep:70, loss:0.00005, loss_test:0.12953, lr:4.95e-03, fs:0.85427 (r=0.859,p=0.850),  time:40.003, tt:2840.179\n",
      "Ep:71, loss:0.00005, loss_test:0.13279, lr:4.90e-03, fs:0.87179 (r=0.859,p=0.885),  time:40.056, tt:2884.067\n",
      "Ep:72, loss:0.00005, loss_test:0.12742, lr:4.85e-03, fs:0.86700 (r=0.889,p=0.846),  time:40.123, tt:2928.970\n",
      "Ep:73, loss:0.00005, loss_test:0.13227, lr:4.75e-03, fs:0.86432 (r=0.869,p=0.860),  time:40.186, tt:2973.757\n",
      "Ep:74, loss:0.00005, loss_test:0.12889, lr:4.66e-03, fs:0.87879 (r=0.879,p=0.879),  time:40.196, tt:3014.701\n",
      "Ep:75, loss:0.00004, loss_test:0.13003, lr:4.57e-03, fs:0.87562 (r=0.889,p=0.863),  time:40.206, tt:3055.655\n",
      "Ep:76, loss:0.00004, loss_test:0.12779, lr:4.48e-03, fs:0.87310 (r=0.869,p=0.878),  time:40.212, tt:3096.330\n",
      "Ep:77, loss:0.00004, loss_test:0.12730, lr:4.39e-03, fs:0.87562 (r=0.889,p=0.863),  time:40.255, tt:3139.856\n",
      "Ep:78, loss:0.00004, loss_test:0.13126, lr:4.30e-03, fs:0.88083 (r=0.859,p=0.904),  time:40.265, tt:3180.899\n",
      "Ep:79, loss:0.00004, loss_test:0.12649, lr:4.21e-03, fs:0.88000 (r=0.889,p=0.871),  time:40.264, tt:3221.086\n",
      "Ep:80, loss:0.00004, loss_test:0.13046, lr:4.13e-03, fs:0.86735 (r=0.859,p=0.876),  time:40.316, tt:3265.584\n",
      "Ep:81, loss:0.00004, loss_test:0.12859, lr:4.05e-03, fs:0.88205 (r=0.869,p=0.896),  time:40.360, tt:3309.484\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.12202, lr:4.01e-03, fs:0.88119 (r=0.899,p=0.864),  time:40.410, tt:3354.028\n",
      "Ep:83, loss:0.00004, loss_test:0.12637, lr:3.97e-03, fs:0.87805 (r=0.909,p=0.849),  time:40.453, tt:3398.035\n",
      "Ep:84, loss:0.00004, loss_test:0.12815, lr:3.93e-03, fs:0.87629 (r=0.859,p=0.895),  time:40.445, tt:3437.834\n",
      "Ep:85, loss:0.00004, loss_test:0.12460, lr:3.89e-03, fs:0.88205 (r=0.869,p=0.896),  time:40.439, tt:3477.788\n",
      "Ep:86, loss:0.00003, loss_test:0.12195, lr:3.85e-03, fs:0.86829 (r=0.899,p=0.840),  time:40.438, tt:3518.063\n",
      "Ep:87, loss:0.00003, loss_test:0.12587, lr:3.81e-03, fs:0.88660 (r=0.869,p=0.905),  time:40.428, tt:3557.656\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.12963, lr:3.77e-03, fs:0.88542 (r=0.859,p=0.914),  time:40.404, tt:3595.937\n",
      "Ep:89, loss:0.00004, loss_test:0.12786, lr:3.73e-03, fs:0.87437 (r=0.879,p=0.870),  time:40.378, tt:3634.013\n",
      "Ep:90, loss:0.00003, loss_test:0.12246, lr:3.70e-03, fs:0.87000 (r=0.879,p=0.861),  time:40.382, tt:3674.764\n",
      "Ep:91, loss:0.00003, loss_test:0.12331, lr:3.66e-03, fs:0.87437 (r=0.879,p=0.870),  time:40.406, tt:3717.375\n",
      "Ep:92, loss:0.00003, loss_test:0.13054, lr:3.62e-03, fs:0.87500 (r=0.848,p=0.903),  time:40.440, tt:3760.882\n",
      "Ep:93, loss:0.00003, loss_test:0.13068, lr:3.59e-03, fs:0.88083 (r=0.859,p=0.904),  time:40.457, tt:3802.949\n",
      "Ep:94, loss:0.00003, loss_test:0.12537, lr:3.55e-03, fs:0.88119 (r=0.899,p=0.864),  time:40.449, tt:3842.696\n",
      "Ep:95, loss:0.00003, loss_test:0.12938, lr:3.52e-03, fs:0.87047 (r=0.848,p=0.894),  time:40.423, tt:3880.615\n",
      "Ep:96, loss:0.00003, loss_test:0.12720, lr:3.48e-03, fs:0.86154 (r=0.848,p=0.875),  time:40.408, tt:3919.534\n",
      "Ep:97, loss:0.00003, loss_test:0.12454, lr:3.45e-03, fs:0.85427 (r=0.859,p=0.850),  time:40.393, tt:3958.553\n",
      "Ep:98, loss:0.00003, loss_test:0.12774, lr:3.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:40.384, tt:3998.001\n",
      "Ep:99, loss:0.00003, loss_test:0.12630, lr:3.34e-03, fs:0.86294 (r=0.859,p=0.867),  time:40.397, tt:4039.727\n",
      "Ep:100, loss:0.00003, loss_test:0.12748, lr:3.28e-03, fs:0.86294 (r=0.859,p=0.867),  time:40.426, tt:4082.978\n",
      "Ep:101, loss:0.00003, loss_test:0.13059, lr:3.21e-03, fs:0.87500 (r=0.848,p=0.903),  time:40.447, tt:4125.593\n",
      "Ep:102, loss:0.00002, loss_test:0.12924, lr:3.15e-03, fs:0.87629 (r=0.859,p=0.895),  time:40.475, tt:4168.936\n",
      "Ep:103, loss:0.00003, loss_test:0.12631, lr:3.09e-03, fs:0.87047 (r=0.848,p=0.894),  time:40.477, tt:4209.602\n",
      "Ep:104, loss:0.00002, loss_test:0.12728, lr:3.02e-03, fs:0.87958 (r=0.848,p=0.913),  time:40.465, tt:4248.877\n",
      "Ep:105, loss:0.00003, loss_test:0.13013, lr:2.96e-03, fs:0.87958 (r=0.848,p=0.913),  time:40.460, tt:4288.796\n",
      "Ep:106, loss:0.00003, loss_test:0.12919, lr:2.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:40.448, tt:4327.970\n",
      "Ep:107, loss:0.00002, loss_test:0.13151, lr:2.85e-03, fs:0.89005 (r=0.859,p=0.924),  time:40.440, tt:4367.492\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00002, loss_test:0.13006, lr:2.82e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.432, tt:4407.098\n",
      "Ep:109, loss:0.00002, loss_test:0.12989, lr:2.79e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.440, tt:4448.374\n",
      "Ep:110, loss:0.00002, loss_test:0.12870, lr:2.76e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.463, tt:4491.383\n",
      "Ep:111, loss:0.00002, loss_test:0.13183, lr:2.73e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.489, tt:4534.759\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.13025, lr:2.71e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.511, tt:4577.740\n",
      "Ep:113, loss:0.00002, loss_test:0.12890, lr:2.68e-03, fs:0.87500 (r=0.848,p=0.903),  time:40.523, tt:4619.675\n",
      "Ep:114, loss:0.00002, loss_test:0.13278, lr:2.65e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.522, tt:4660.068\n",
      "Ep:115, loss:0.00002, loss_test:0.13382, lr:2.63e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.517, tt:4699.926\n",
      "Ep:116, loss:0.00002, loss_test:0.13448, lr:2.60e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.537, tt:4742.849\n",
      "Ep:117, loss:0.00002, loss_test:0.13293, lr:2.57e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.521, tt:4781.536\n",
      "Ep:118, loss:0.00002, loss_test:0.13284, lr:2.55e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.507, tt:4820.367\n",
      "Ep:119, loss:0.00002, loss_test:0.13250, lr:2.52e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.530, tt:4863.590\n",
      "Ep:120, loss:0.00002, loss_test:0.13252, lr:2.50e-03, fs:0.88889 (r=0.848,p=0.933),  time:40.555, tt:4907.118\n",
      "Ep:121, loss:0.00002, loss_test:0.13252, lr:2.47e-03, fs:0.88421 (r=0.848,p=0.923),  time:40.600, tt:4953.242\n",
      "Ep:122, loss:0.00002, loss_test:0.13443, lr:2.45e-03, fs:0.89362 (r=0.848,p=0.944),  time:40.628, tt:4997.242\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24318, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.804, tt:43.804\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24052, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:41.227, tt:82.454\n",
      "Ep:2, loss:0.00058, loss_test:0.23462, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:41.000, tt:123.000\n",
      "Ep:3, loss:0.00055, loss_test:0.22335, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.013, tt:160.051\n",
      "Ep:4, loss:0.00048, loss_test:0.20735, lr:9.61e-03, fs:0.67128 (r=0.980,p=0.511),  time:38.660, tt:193.302\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.20096, lr:9.51e-03, fs:0.68644 (r=0.818,p=0.591),  time:38.302, tt:229.812\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.20002, lr:9.41e-03, fs:0.71053 (r=0.818,p=0.628),  time:37.881, tt:265.165\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.19851, lr:9.32e-03, fs:0.69091 (r=0.768,p=0.628),  time:38.286, tt:306.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00028, loss_test:0.19855, lr:9.23e-03, fs:0.69484 (r=0.747,p=0.649),  time:38.766, tt:348.891\n",
      "Ep:9, loss:0.00028, loss_test:0.20187, lr:9.14e-03, fs:0.70647 (r=0.717,p=0.696),  time:38.952, tt:389.519\n",
      "Ep:10, loss:0.00026, loss_test:0.18605, lr:9.04e-03, fs:0.75325 (r=0.879,p=0.659),  time:39.030, tt:429.329\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.18420, lr:8.95e-03, fs:0.77273 (r=0.859,p=0.702),  time:39.062, tt:468.742\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.19195, lr:8.86e-03, fs:0.71921 (r=0.737,p=0.702),  time:39.004, tt:507.055\n",
      "Ep:13, loss:0.00025, loss_test:0.18860, lr:8.78e-03, fs:0.73529 (r=0.758,p=0.714),  time:39.019, tt:546.262\n",
      "Ep:14, loss:0.00023, loss_test:0.18336, lr:8.69e-03, fs:0.74766 (r=0.808,p=0.696),  time:39.072, tt:586.082\n",
      "Ep:15, loss:0.00022, loss_test:0.17371, lr:8.60e-03, fs:0.79821 (r=0.899,p=0.718),  time:39.154, tt:626.456\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.17919, lr:8.51e-03, fs:0.75377 (r=0.758,p=0.750),  time:39.310, tt:668.270\n",
      "Ep:17, loss:0.00022, loss_test:0.17701, lr:8.43e-03, fs:0.74882 (r=0.798,p=0.705),  time:39.468, tt:710.421\n",
      "Ep:18, loss:0.00022, loss_test:0.17379, lr:8.35e-03, fs:0.80374 (r=0.869,p=0.748),  time:39.674, tt:753.812\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.17325, lr:8.26e-03, fs:0.79808 (r=0.838,p=0.761),  time:39.673, tt:793.458\n",
      "Ep:20, loss:0.00020, loss_test:0.17292, lr:8.18e-03, fs:0.78431 (r=0.808,p=0.762),  time:39.694, tt:833.583\n",
      "Ep:21, loss:0.00019, loss_test:0.16623, lr:8.10e-03, fs:0.83036 (r=0.939,p=0.744),  time:39.698, tt:873.345\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.16942, lr:8.02e-03, fs:0.77295 (r=0.808,p=0.741),  time:39.738, tt:913.970\n",
      "Ep:23, loss:0.00019, loss_test:0.16760, lr:7.94e-03, fs:0.80198 (r=0.818,p=0.786),  time:39.721, tt:953.315\n",
      "Ep:24, loss:0.00019, loss_test:0.16816, lr:7.86e-03, fs:0.78818 (r=0.808,p=0.769),  time:39.660, tt:991.506\n",
      "Ep:25, loss:0.00018, loss_test:0.16815, lr:7.78e-03, fs:0.77512 (r=0.818,p=0.736),  time:39.829, tt:1035.559\n",
      "Ep:26, loss:0.00018, loss_test:0.16628, lr:7.70e-03, fs:0.79000 (r=0.798,p=0.782),  time:39.959, tt:1078.894\n",
      "Ep:27, loss:0.00017, loss_test:0.16718, lr:7.62e-03, fs:0.79412 (r=0.818,p=0.771),  time:40.096, tt:1122.682\n",
      "Ep:28, loss:0.00016, loss_test:0.16422, lr:7.55e-03, fs:0.80000 (r=0.828,p=0.774),  time:40.261, tt:1167.566\n",
      "Ep:29, loss:0.00016, loss_test:0.15965, lr:7.47e-03, fs:0.76415 (r=0.818,p=0.717),  time:40.319, tt:1209.569\n",
      "Ep:30, loss:0.00015, loss_test:0.16286, lr:7.40e-03, fs:0.80808 (r=0.808,p=0.808),  time:40.352, tt:1250.904\n",
      "Ep:31, loss:0.00015, loss_test:0.15835, lr:7.32e-03, fs:0.77295 (r=0.808,p=0.741),  time:40.348, tt:1291.151\n",
      "Ep:32, loss:0.00015, loss_test:0.16659, lr:7.25e-03, fs:0.80402 (r=0.808,p=0.800),  time:40.319, tt:1330.512\n",
      "Ep:33, loss:0.00014, loss_test:0.15922, lr:7.11e-03, fs:0.77885 (r=0.818,p=0.743),  time:40.329, tt:1371.171\n",
      "Ep:34, loss:0.00014, loss_test:0.16551, lr:6.96e-03, fs:0.80597 (r=0.818,p=0.794),  time:40.272, tt:1409.531\n",
      "Ep:35, loss:0.00014, loss_test:0.16424, lr:6.83e-03, fs:0.77512 (r=0.818,p=0.736),  time:40.398, tt:1454.339\n",
      "Ep:36, loss:0.00014, loss_test:0.16416, lr:6.69e-03, fs:0.82000 (r=0.828,p=0.812),  time:40.496, tt:1498.338\n",
      "Ep:37, loss:0.00013, loss_test:0.16016, lr:6.56e-03, fs:0.81000 (r=0.818,p=0.802),  time:40.609, tt:1543.153\n",
      "Ep:38, loss:0.00012, loss_test:0.15290, lr:6.43e-03, fs:0.76995 (r=0.828,p=0.719),  time:40.662, tt:1585.832\n",
      "Ep:39, loss:0.00012, loss_test:0.16524, lr:6.30e-03, fs:0.80402 (r=0.808,p=0.800),  time:40.706, tt:1628.255\n",
      "Ep:40, loss:0.00011, loss_test:0.16068, lr:6.17e-03, fs:0.78641 (r=0.818,p=0.757),  time:40.737, tt:1670.216\n",
      "Ep:41, loss:0.00011, loss_test:0.16332, lr:6.05e-03, fs:0.80597 (r=0.818,p=0.794),  time:40.784, tt:1712.927\n",
      "Ep:42, loss:0.00011, loss_test:0.16175, lr:5.93e-03, fs:0.81407 (r=0.818,p=0.810),  time:40.811, tt:1754.878\n",
      "Ep:43, loss:0.00011, loss_test:0.16000, lr:5.81e-03, fs:0.80597 (r=0.818,p=0.794),  time:40.854, tt:1797.595\n",
      "Ep:44, loss:0.00010, loss_test:0.16055, lr:5.70e-03, fs:0.81818 (r=0.818,p=0.818),  time:40.893, tt:1840.185\n",
      "Ep:45, loss:0.00010, loss_test:0.15692, lr:5.58e-03, fs:0.80000 (r=0.808,p=0.792),  time:40.953, tt:1883.820\n",
      "Ep:46, loss:0.00010, loss_test:0.16169, lr:5.47e-03, fs:0.79208 (r=0.808,p=0.777),  time:41.051, tt:1929.376\n",
      "Ep:47, loss:0.00009, loss_test:0.16243, lr:5.36e-03, fs:0.81218 (r=0.808,p=0.816),  time:41.140, tt:1974.731\n",
      "Ep:48, loss:0.00009, loss_test:0.15723, lr:5.26e-03, fs:0.80198 (r=0.818,p=0.786),  time:41.234, tt:2020.462\n",
      "Ep:49, loss:0.00009, loss_test:0.15731, lr:5.15e-03, fs:0.80808 (r=0.808,p=0.808),  time:41.210, tt:2060.509\n",
      "Ep:50, loss:0.00009, loss_test:0.15685, lr:5.05e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.192, tt:2100.805\n",
      "Ep:51, loss:0.00008, loss_test:0.15673, lr:4.95e-03, fs:0.80808 (r=0.808,p=0.808),  time:41.169, tt:2140.808\n",
      "Ep:52, loss:0.00008, loss_test:0.15922, lr:4.85e-03, fs:0.78818 (r=0.808,p=0.769),  time:41.166, tt:2181.807\n",
      "Ep:53, loss:0.00008, loss_test:0.15900, lr:4.75e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.154, tt:2222.322\n",
      "Ep:54, loss:0.00008, loss_test:0.15904, lr:4.66e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.138, tt:2262.590\n",
      "Ep:55, loss:0.00007, loss_test:0.15549, lr:4.57e-03, fs:0.79602 (r=0.808,p=0.784),  time:41.195, tt:2306.921\n",
      "Ep:56, loss:0.00008, loss_test:0.15764, lr:4.48e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.230, tt:2350.101\n",
      "Ep:57, loss:0.00007, loss_test:0.16204, lr:4.39e-03, fs:0.80000 (r=0.808,p=0.792),  time:41.268, tt:2393.528\n",
      "Ep:58, loss:0.00008, loss_test:0.16299, lr:4.30e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.281, tt:2435.600\n",
      "Ep:59, loss:0.00007, loss_test:0.15868, lr:4.21e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.242, tt:2474.491\n",
      "Ep:60, loss:0.00007, loss_test:0.15528, lr:4.13e-03, fs:0.80402 (r=0.808,p=0.800),  time:41.214, tt:2514.046\n",
      "Ep:61, loss:0.00007, loss_test:0.15830, lr:4.05e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.204, tt:2554.642\n",
      "Ep:62, loss:0.00007, loss_test:0.16121, lr:3.97e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.187, tt:2594.761\n",
      "Ep:63, loss:0.00006, loss_test:0.15747, lr:3.89e-03, fs:0.79208 (r=0.808,p=0.777),  time:41.137, tt:2632.767\n",
      "Ep:64, loss:0.00006, loss_test:0.15732, lr:3.81e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.104, tt:2671.742\n",
      "Ep:65, loss:0.00006, loss_test:0.15905, lr:3.73e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.116, tt:2713.629\n",
      "Ep:66, loss:0.00006, loss_test:0.16220, lr:3.66e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.130, tt:2755.678\n",
      "Ep:67, loss:0.00006, loss_test:0.16224, lr:3.59e-03, fs:0.83770 (r=0.808,p=0.870),  time:41.153, tt:2798.393\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.16134, lr:3.55e-03, fs:0.83333 (r=0.808,p=0.860),  time:41.163, tt:2840.277\n",
      "Ep:69, loss:0.00006, loss_test:0.15859, lr:3.52e-03, fs:0.81218 (r=0.808,p=0.816),  time:41.138, tt:2879.635\n",
      "Ep:70, loss:0.00006, loss_test:0.15856, lr:3.48e-03, fs:0.82051 (r=0.808,p=0.833),  time:41.118, tt:2919.354\n",
      "Ep:71, loss:0.00006, loss_test:0.15993, lr:3.45e-03, fs:0.81481 (r=0.778,p=0.856),  time:41.094, tt:2958.744\n",
      "Ep:72, loss:0.00005, loss_test:0.15878, lr:3.41e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.053, tt:2996.876\n",
      "Ep:73, loss:0.00005, loss_test:0.15935, lr:3.38e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.022, tt:3035.613\n",
      "Ep:74, loss:0.00005, loss_test:0.16175, lr:3.34e-03, fs:0.82540 (r=0.788,p=0.867),  time:40.976, tt:3073.183\n",
      "Ep:75, loss:0.00005, loss_test:0.16118, lr:3.31e-03, fs:0.82474 (r=0.808,p=0.842),  time:40.991, tt:3115.299\n",
      "Ep:76, loss:0.00005, loss_test:0.16011, lr:3.28e-03, fs:0.82474 (r=0.808,p=0.842),  time:41.029, tt:3159.195\n",
      "Ep:77, loss:0.00005, loss_test:0.16045, lr:3.24e-03, fs:0.83158 (r=0.798,p=0.868),  time:41.063, tt:3202.922\n",
      "Ep:78, loss:0.00005, loss_test:0.16197, lr:3.21e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.082, tt:3245.457\n",
      "Ep:79, loss:0.00004, loss_test:0.16293, lr:3.15e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.061, tt:3284.884\n",
      "Ep:80, loss:0.00004, loss_test:0.16405, lr:3.09e-03, fs:0.81675 (r=0.788,p=0.848),  time:41.045, tt:3324.620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00004, loss_test:0.16369, lr:3.02e-03, fs:0.82902 (r=0.808,p=0.851),  time:41.004, tt:3362.291\n",
      "Ep:82, loss:0.00004, loss_test:0.16198, lr:2.96e-03, fs:0.82902 (r=0.808,p=0.851),  time:40.974, tt:3400.803\n",
      "Ep:83, loss:0.00004, loss_test:0.16106, lr:2.90e-03, fs:0.83158 (r=0.798,p=0.868),  time:40.955, tt:3440.210\n",
      "Ep:84, loss:0.00004, loss_test:0.16056, lr:2.85e-03, fs:0.82723 (r=0.798,p=0.859),  time:40.949, tt:3480.674\n",
      "Ep:85, loss:0.00004, loss_test:0.15985, lr:2.79e-03, fs:0.81633 (r=0.808,p=0.825),  time:40.960, tt:3522.592\n",
      "Ep:86, loss:0.00004, loss_test:0.16139, lr:2.73e-03, fs:0.82292 (r=0.798,p=0.849),  time:40.960, tt:3563.519\n",
      "Ep:87, loss:0.00004, loss_test:0.16518, lr:2.68e-03, fs:0.83598 (r=0.798,p=0.878),  time:40.988, tt:3606.922\n",
      "Ep:88, loss:0.00004, loss_test:0.16455, lr:2.63e-03, fs:0.83770 (r=0.808,p=0.870),  time:40.990, tt:3648.149\n",
      "Ep:89, loss:0.00004, loss_test:0.16213, lr:2.57e-03, fs:0.83598 (r=0.798,p=0.878),  time:40.955, tt:3685.981\n",
      "Ep:90, loss:0.00004, loss_test:0.16132, lr:2.52e-03, fs:0.80645 (r=0.758,p=0.862),  time:40.922, tt:3723.943\n",
      "Ep:91, loss:0.00004, loss_test:0.16320, lr:2.47e-03, fs:0.83770 (r=0.808,p=0.870),  time:40.900, tt:3762.809\n",
      "Ep:92, loss:0.00004, loss_test:0.16356, lr:2.42e-03, fs:0.83770 (r=0.808,p=0.870),  time:40.841, tt:3798.189\n",
      "Ep:93, loss:0.00004, loss_test:0.16555, lr:2.38e-03, fs:0.84656 (r=0.808,p=0.889),  time:40.826, tt:3837.685\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.16550, lr:2.35e-03, fs:0.84043 (r=0.798,p=0.888),  time:40.803, tt:3876.242\n",
      "Ep:95, loss:0.00004, loss_test:0.16388, lr:2.33e-03, fs:0.83770 (r=0.808,p=0.870),  time:40.758, tt:3912.797\n",
      "Ep:96, loss:0.00004, loss_test:0.16446, lr:2.31e-03, fs:0.83333 (r=0.808,p=0.860),  time:40.730, tt:3950.849\n",
      "Ep:97, loss:0.00004, loss_test:0.16484, lr:2.28e-03, fs:0.83158 (r=0.798,p=0.868),  time:40.726, tt:3991.125\n",
      "Ep:98, loss:0.00004, loss_test:0.16472, lr:2.26e-03, fs:0.83770 (r=0.808,p=0.870),  time:40.700, tt:4029.297\n",
      "Ep:99, loss:0.00003, loss_test:0.16583, lr:2.24e-03, fs:0.84043 (r=0.798,p=0.888),  time:40.670, tt:4066.986\n",
      "Ep:100, loss:0.00003, loss_test:0.16774, lr:2.21e-03, fs:0.84492 (r=0.798,p=0.898),  time:40.647, tt:4105.340\n",
      "Ep:101, loss:0.00003, loss_test:0.16712, lr:2.19e-03, fs:0.84656 (r=0.808,p=0.889),  time:40.622, tt:4143.420\n",
      "Ep:102, loss:0.00003, loss_test:0.16421, lr:2.17e-03, fs:0.83333 (r=0.808,p=0.860),  time:40.578, tt:4179.558\n",
      "Ep:103, loss:0.00003, loss_test:0.16471, lr:2.15e-03, fs:0.82353 (r=0.778,p=0.875),  time:40.550, tt:4217.186\n",
      "Ep:104, loss:0.00003, loss_test:0.16659, lr:2.13e-03, fs:0.83243 (r=0.778,p=0.895),  time:40.545, tt:4257.268\n",
      "Ep:105, loss:0.00003, loss_test:0.16724, lr:2.08e-03, fs:0.84492 (r=0.798,p=0.898),  time:40.528, tt:4296.007\n",
      "Ep:106, loss:0.00003, loss_test:0.16772, lr:2.04e-03, fs:0.84211 (r=0.808,p=0.879),  time:40.514, tt:4334.982\n",
      "Ep:107, loss:0.00003, loss_test:0.16891, lr:2.00e-03, fs:0.82162 (r=0.768,p=0.884),  time:40.498, tt:4373.761\n",
      "Ep:108, loss:0.00003, loss_test:0.16845, lr:1.96e-03, fs:0.77528 (r=0.697,p=0.873),  time:40.468, tt:4410.973\n",
      "Ep:109, loss:0.00003, loss_test:0.16592, lr:1.92e-03, fs:0.79348 (r=0.737,p=0.859),  time:40.432, tt:4447.549\n",
      "Ep:110, loss:0.00003, loss_test:0.16500, lr:1.89e-03, fs:0.83598 (r=0.798,p=0.878),  time:40.428, tt:4487.547\n",
      "Ep:111, loss:0.00003, loss_test:0.16718, lr:1.85e-03, fs:0.82353 (r=0.778,p=0.875),  time:40.398, tt:4524.610\n",
      "Ep:112, loss:0.00003, loss_test:0.16919, lr:1.81e-03, fs:0.83243 (r=0.778,p=0.895),  time:40.373, tt:4562.205\n",
      "Ep:113, loss:0.00003, loss_test:0.17063, lr:1.78e-03, fs:0.83243 (r=0.778,p=0.895),  time:40.348, tt:4599.701\n",
      "Ep:114, loss:0.00003, loss_test:0.17060, lr:1.74e-03, fs:0.82353 (r=0.778,p=0.875),  time:40.330, tt:4637.990\n",
      "Ep:115, loss:0.00003, loss_test:0.16811, lr:1.71e-03, fs:0.81522 (r=0.758,p=0.882),  time:40.311, tt:4676.094\n",
      "Ep:116, loss:0.00003, loss_test:0.16785, lr:1.67e-03, fs:0.80851 (r=0.768,p=0.854),  time:40.292, tt:4714.150\n",
      "Ep:117, loss:0.00003, loss_test:0.16843, lr:1.64e-03, fs:0.82979 (r=0.788,p=0.876),  time:40.297, tt:4755.069\n",
      "Ep:118, loss:0.00003, loss_test:0.16877, lr:1.61e-03, fs:0.82796 (r=0.778,p=0.885),  time:40.292, tt:4794.729\n",
      "Ep:119, loss:0.00003, loss_test:0.16852, lr:1.57e-03, fs:0.82796 (r=0.778,p=0.885),  time:40.272, tt:4832.664\n",
      "Ep:120, loss:0.00003, loss_test:0.16874, lr:1.54e-03, fs:0.82796 (r=0.778,p=0.885),  time:40.257, tt:4871.051\n",
      "Ep:121, loss:0.00003, loss_test:0.16943, lr:1.51e-03, fs:0.82162 (r=0.768,p=0.884),  time:40.246, tt:4910.069\n",
      "Ep:122, loss:0.00003, loss_test:0.17028, lr:1.48e-03, fs:0.81967 (r=0.758,p=0.893),  time:40.233, tt:4948.692\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24322, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.702, tt:38.702\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24057, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.714, tt:77.428\n",
      "Ep:2, loss:0.00059, loss_test:0.23481, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.410, tt:115.231\n",
      "Ep:3, loss:0.00055, loss_test:0.22332, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:38.441, tt:153.762\n",
      "Ep:4, loss:0.00048, loss_test:0.20246, lr:9.61e-03, fs:0.67586 (r=0.990,p=0.513),  time:37.324, tt:186.621\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.19603, lr:9.51e-03, fs:0.69767 (r=0.909,p=0.566),  time:37.191, tt:223.147\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.19294, lr:9.41e-03, fs:0.70356 (r=0.899,p=0.578),  time:36.701, tt:256.904\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.18952, lr:9.32e-03, fs:0.73029 (r=0.889,p=0.620),  time:35.932, tt:287.457\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.18615, lr:9.23e-03, fs:0.70886 (r=0.848,p=0.609),  time:36.224, tt:326.014\n",
      "Ep:9, loss:0.00028, loss_test:0.18472, lr:9.14e-03, fs:0.69643 (r=0.788,p=0.624),  time:36.186, tt:361.861\n",
      "Ep:10, loss:0.00027, loss_test:0.18015, lr:9.04e-03, fs:0.71930 (r=0.828,p=0.636),  time:36.438, tt:400.816\n",
      "Ep:11, loss:0.00026, loss_test:0.17467, lr:8.95e-03, fs:0.74208 (r=0.828,p=0.672),  time:36.666, tt:439.991\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00025, loss_test:0.17266, lr:8.86e-03, fs:0.74107 (r=0.838,p=0.664),  time:36.816, tt:478.604\n",
      "Ep:13, loss:0.00025, loss_test:0.17318, lr:8.78e-03, fs:0.71818 (r=0.798,p=0.653),  time:36.921, tt:516.896\n",
      "Ep:14, loss:0.00023, loss_test:0.17237, lr:8.69e-03, fs:0.72566 (r=0.828,p=0.646),  time:36.967, tt:554.504\n",
      "Ep:15, loss:0.00023, loss_test:0.16854, lr:8.60e-03, fs:0.73636 (r=0.818,p=0.669),  time:37.048, tt:592.774\n",
      "Ep:16, loss:0.00023, loss_test:0.16697, lr:8.51e-03, fs:0.76147 (r=0.838,p=0.697),  time:37.182, tt:632.098\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.16173, lr:8.43e-03, fs:0.77419 (r=0.848,p=0.712),  time:37.269, tt:670.834\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.16104, lr:8.35e-03, fs:0.76018 (r=0.848,p=0.689),  time:37.185, tt:706.507\n",
      "Ep:19, loss:0.00021, loss_test:0.16127, lr:8.26e-03, fs:0.76995 (r=0.828,p=0.719),  time:37.257, tt:745.148\n",
      "Ep:20, loss:0.00021, loss_test:0.15736, lr:8.18e-03, fs:0.77130 (r=0.869,p=0.694),  time:37.357, tt:784.494\n",
      "Ep:21, loss:0.00019, loss_test:0.15695, lr:8.10e-03, fs:0.78899 (r=0.869,p=0.723),  time:37.510, tt:825.214\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00019, loss_test:0.15806, lr:8.02e-03, fs:0.81517 (r=0.869,p=0.768),  time:37.591, tt:864.582\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.15161, lr:7.94e-03, fs:0.77477 (r=0.869,p=0.699),  time:37.592, tt:902.207\n",
      "Ep:24, loss:0.00018, loss_test:0.15490, lr:7.86e-03, fs:0.81517 (r=0.869,p=0.768),  time:37.636, tt:940.906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00017, loss_test:0.15167, lr:7.78e-03, fs:0.80189 (r=0.859,p=0.752),  time:37.695, tt:980.061\n",
      "Ep:26, loss:0.00017, loss_test:0.15234, lr:7.70e-03, fs:0.77273 (r=0.859,p=0.702),  time:37.785, tt:1020.201\n",
      "Ep:27, loss:0.00016, loss_test:0.15248, lr:7.62e-03, fs:0.80952 (r=0.859,p=0.766),  time:37.793, tt:1058.209\n",
      "Ep:28, loss:0.00016, loss_test:0.14743, lr:7.55e-03, fs:0.80556 (r=0.879,p=0.744),  time:37.809, tt:1096.468\n",
      "Ep:29, loss:0.00015, loss_test:0.14758, lr:7.47e-03, fs:0.80556 (r=0.879,p=0.744),  time:37.887, tt:1136.607\n",
      "Ep:30, loss:0.00015, loss_test:0.14815, lr:7.40e-03, fs:0.81106 (r=0.889,p=0.746),  time:37.936, tt:1176.003\n",
      "Ep:31, loss:0.00014, loss_test:0.14796, lr:7.32e-03, fs:0.80184 (r=0.879,p=0.737),  time:37.961, tt:1214.754\n",
      "Ep:32, loss:0.00014, loss_test:0.15080, lr:7.25e-03, fs:0.81905 (r=0.869,p=0.775),  time:38.031, tt:1255.037\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00014, loss_test:0.14990, lr:7.18e-03, fs:0.80000 (r=0.869,p=0.741),  time:38.000, tt:1292.001\n",
      "Ep:34, loss:0.00014, loss_test:0.14787, lr:7.11e-03, fs:0.80751 (r=0.869,p=0.754),  time:37.934, tt:1327.706\n",
      "Ep:35, loss:0.00013, loss_test:0.15055, lr:7.03e-03, fs:0.81308 (r=0.879,p=0.757),  time:37.963, tt:1366.661\n",
      "Ep:36, loss:0.00013, loss_test:0.15606, lr:6.96e-03, fs:0.83092 (r=0.869,p=0.796),  time:37.978, tt:1405.171\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.14919, lr:6.89e-03, fs:0.80952 (r=0.859,p=0.766),  time:38.006, tt:1444.224\n",
      "Ep:38, loss:0.00012, loss_test:0.14706, lr:6.83e-03, fs:0.80751 (r=0.869,p=0.754),  time:38.022, tt:1482.847\n",
      "Ep:39, loss:0.00011, loss_test:0.15375, lr:6.76e-03, fs:0.81340 (r=0.859,p=0.773),  time:38.054, tt:1522.158\n",
      "Ep:40, loss:0.00011, loss_test:0.14956, lr:6.69e-03, fs:0.83092 (r=0.869,p=0.796),  time:38.097, tt:1561.965\n",
      "Ep:41, loss:0.00011, loss_test:0.15490, lr:6.62e-03, fs:0.79397 (r=0.798,p=0.790),  time:38.115, tt:1600.833\n",
      "Ep:42, loss:0.00010, loss_test:0.15851, lr:6.56e-03, fs:0.82178 (r=0.838,p=0.806),  time:38.145, tt:1640.257\n",
      "Ep:43, loss:0.00010, loss_test:0.14998, lr:6.49e-03, fs:0.82000 (r=0.828,p=0.812),  time:38.185, tt:1680.160\n",
      "Ep:44, loss:0.00010, loss_test:0.15424, lr:6.43e-03, fs:0.84577 (r=0.859,p=0.833),  time:38.190, tt:1718.570\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.14957, lr:6.36e-03, fs:0.81373 (r=0.838,p=0.790),  time:38.208, tt:1757.575\n",
      "Ep:46, loss:0.00009, loss_test:0.14851, lr:6.30e-03, fs:0.84158 (r=0.859,p=0.825),  time:38.255, tt:1797.976\n",
      "Ep:47, loss:0.00009, loss_test:0.15883, lr:6.24e-03, fs:0.83158 (r=0.798,p=0.868),  time:38.326, tt:1839.667\n",
      "Ep:48, loss:0.00009, loss_test:0.14881, lr:6.17e-03, fs:0.81818 (r=0.818,p=0.818),  time:38.368, tt:1880.051\n",
      "Ep:49, loss:0.00008, loss_test:0.15047, lr:6.11e-03, fs:0.81865 (r=0.798,p=0.840),  time:38.374, tt:1918.701\n",
      "Ep:50, loss:0.00008, loss_test:0.14814, lr:6.05e-03, fs:0.81443 (r=0.798,p=0.832),  time:38.393, tt:1958.056\n",
      "Ep:51, loss:0.00009, loss_test:0.14845, lr:5.99e-03, fs:0.81026 (r=0.798,p=0.823),  time:38.408, tt:1997.208\n",
      "Ep:52, loss:0.00008, loss_test:0.15283, lr:5.93e-03, fs:0.83598 (r=0.798,p=0.878),  time:38.425, tt:2036.503\n",
      "Ep:53, loss:0.00007, loss_test:0.14483, lr:5.87e-03, fs:0.82292 (r=0.798,p=0.849),  time:38.442, tt:2075.865\n",
      "Ep:54, loss:0.00007, loss_test:0.14804, lr:5.81e-03, fs:0.84043 (r=0.798,p=0.888),  time:38.477, tt:2116.235\n",
      "Ep:55, loss:0.00007, loss_test:0.14827, lr:5.75e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.527, tt:2157.513\n",
      "Ep:56, loss:0.00007, loss_test:0.14452, lr:5.64e-03, fs:0.83598 (r=0.798,p=0.878),  time:38.534, tt:2196.455\n",
      "Ep:57, loss:0.00007, loss_test:0.14798, lr:5.53e-03, fs:0.83598 (r=0.798,p=0.878),  time:38.549, tt:2235.846\n",
      "Ep:58, loss:0.00007, loss_test:0.14723, lr:5.42e-03, fs:0.83871 (r=0.788,p=0.897),  time:38.600, tt:2277.412\n",
      "Ep:59, loss:0.00007, loss_test:0.15087, lr:5.31e-03, fs:0.85870 (r=0.798,p=0.929),  time:38.656, tt:2319.378\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.15260, lr:5.26e-03, fs:0.82105 (r=0.788,p=0.857),  time:38.664, tt:2358.479\n",
      "Ep:61, loss:0.00006, loss_test:0.14608, lr:5.20e-03, fs:0.83422 (r=0.788,p=0.886),  time:38.707, tt:2399.806\n",
      "Ep:62, loss:0.00006, loss_test:0.15731, lr:5.15e-03, fs:0.86188 (r=0.788,p=0.951),  time:38.739, tt:2440.537\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.15945, lr:5.10e-03, fs:0.86188 (r=0.788,p=0.951),  time:38.782, tt:2482.020\n",
      "Ep:64, loss:0.00006, loss_test:0.14698, lr:5.05e-03, fs:0.83871 (r=0.788,p=0.897),  time:38.813, tt:2522.847\n",
      "Ep:65, loss:0.00006, loss_test:0.15818, lr:5.00e-03, fs:0.84783 (r=0.788,p=0.918),  time:38.806, tt:2561.206\n",
      "Ep:66, loss:0.00005, loss_test:0.15219, lr:4.95e-03, fs:0.83871 (r=0.788,p=0.897),  time:38.843, tt:2602.501\n",
      "Ep:67, loss:0.00005, loss_test:0.15391, lr:4.90e-03, fs:0.83696 (r=0.778,p=0.906),  time:38.865, tt:2642.821\n",
      "Ep:68, loss:0.00006, loss_test:0.15266, lr:4.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:38.887, tt:2683.200\n",
      "Ep:69, loss:0.00005, loss_test:0.15752, lr:4.80e-03, fs:0.84783 (r=0.788,p=0.918),  time:38.920, tt:2724.399\n",
      "Ep:70, loss:0.00005, loss_test:0.15680, lr:4.75e-03, fs:0.83871 (r=0.788,p=0.897),  time:38.941, tt:2764.814\n",
      "Ep:71, loss:0.00005, loss_test:0.14375, lr:4.71e-03, fs:0.82979 (r=0.788,p=0.876),  time:38.957, tt:2804.937\n",
      "Ep:72, loss:0.00005, loss_test:0.15280, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:38.943, tt:2842.803\n",
      "Ep:73, loss:0.00005, loss_test:0.15896, lr:4.61e-03, fs:0.86034 (r=0.778,p=0.963),  time:38.960, tt:2883.075\n",
      "Ep:74, loss:0.00004, loss_test:0.15227, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:38.990, tt:2924.280\n",
      "Ep:75, loss:0.00005, loss_test:0.15174, lr:4.43e-03, fs:0.85246 (r=0.788,p=0.929),  time:39.003, tt:2964.219\n",
      "Ep:76, loss:0.00004, loss_test:0.15628, lr:4.34e-03, fs:0.86034 (r=0.778,p=0.963),  time:39.010, tt:3003.803\n",
      "Ep:77, loss:0.00004, loss_test:0.15304, lr:4.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:39.031, tt:3044.410\n",
      "Ep:78, loss:0.00004, loss_test:0.15259, lr:4.17e-03, fs:0.85246 (r=0.788,p=0.929),  time:39.033, tt:3083.617\n",
      "Ep:79, loss:0.00004, loss_test:0.14883, lr:4.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:39.029, tt:3122.284\n",
      "Ep:80, loss:0.00004, loss_test:0.15576, lr:4.01e-03, fs:0.86034 (r=0.778,p=0.963),  time:39.024, tt:3160.967\n",
      "Ep:81, loss:0.00004, loss_test:0.15896, lr:3.93e-03, fs:0.85227 (r=0.758,p=0.974),  time:39.017, tt:3199.405\n",
      "Ep:82, loss:0.00004, loss_test:0.15137, lr:3.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:39.012, tt:3238.036\n",
      "Ep:83, loss:0.00004, loss_test:0.15851, lr:3.77e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.998, tt:3275.823\n",
      "Ep:84, loss:0.00004, loss_test:0.15806, lr:3.70e-03, fs:0.84746 (r=0.758,p=0.962),  time:39.017, tt:3316.419\n",
      "Ep:85, loss:0.00004, loss_test:0.15343, lr:3.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:39.006, tt:3354.513\n",
      "Ep:86, loss:0.00003, loss_test:0.15271, lr:3.55e-03, fs:0.84444 (r=0.768,p=0.938),  time:39.013, tt:3394.132\n",
      "Ep:87, loss:0.00003, loss_test:0.15936, lr:3.48e-03, fs:0.84746 (r=0.758,p=0.962),  time:39.006, tt:3432.527\n",
      "Ep:88, loss:0.00003, loss_test:0.15704, lr:3.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:39.012, tt:3472.070\n",
      "Ep:89, loss:0.00003, loss_test:0.15767, lr:3.34e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.996, tt:3509.621\n",
      "Ep:90, loss:0.00003, loss_test:0.16217, lr:3.28e-03, fs:0.85227 (r=0.758,p=0.974),  time:39.003, tt:3549.264\n",
      "Ep:91, loss:0.00003, loss_test:0.15954, lr:3.21e-03, fs:0.84746 (r=0.758,p=0.962),  time:39.014, tt:3589.316\n",
      "Ep:92, loss:0.00003, loss_test:0.15632, lr:3.15e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.984, tt:3625.498\n",
      "Ep:93, loss:0.00003, loss_test:0.16031, lr:3.09e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.975, tt:3663.657\n",
      "Ep:94, loss:0.00003, loss_test:0.16031, lr:3.02e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.961, tt:3701.332\n",
      "Ep:95, loss:0.00003, loss_test:0.15758, lr:2.96e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.948, tt:3739.037\n",
      "Ep:96, loss:0.00003, loss_test:0.15906, lr:2.90e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.952, tt:3778.352\n",
      "Ep:97, loss:0.00003, loss_test:0.16093, lr:2.85e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.963, tt:3818.416\n",
      "Ep:98, loss:0.00003, loss_test:0.15902, lr:2.79e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.935, tt:3854.577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00003, loss_test:0.16019, lr:2.73e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.913, tt:3891.284\n",
      "Ep:100, loss:0.00003, loss_test:0.16265, lr:2.68e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.904, tt:3929.299\n",
      "Ep:101, loss:0.00003, loss_test:0.16352, lr:2.63e-03, fs:0.84270 (r=0.758,p=0.949),  time:38.897, tt:3967.443\n",
      "Ep:102, loss:0.00003, loss_test:0.16382, lr:2.57e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.907, tt:4007.414\n",
      "Ep:103, loss:0.00003, loss_test:0.16259, lr:2.52e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.898, tt:4045.380\n",
      "Ep:104, loss:0.00003, loss_test:0.16350, lr:2.47e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.900, tt:4084.471\n",
      "Ep:105, loss:0.00002, loss_test:0.16218, lr:2.42e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.887, tt:4122.035\n",
      "Ep:106, loss:0.00003, loss_test:0.16076, lr:2.38e-03, fs:0.84746 (r=0.758,p=0.962),  time:38.867, tt:4158.757\n",
      "Ep:107, loss:0.00003, loss_test:0.16139, lr:2.33e-03, fs:0.85227 (r=0.758,p=0.974),  time:38.865, tt:4197.460\n",
      "Ep:108, loss:0.00003, loss_test:0.16459, lr:2.28e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.860, tt:4235.774\n",
      "Ep:109, loss:0.00002, loss_test:0.16556, lr:2.24e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.846, tt:4273.035\n",
      "Ep:110, loss:0.00002, loss_test:0.16263, lr:2.19e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.845, tt:4311.764\n",
      "Ep:111, loss:0.00002, loss_test:0.16060, lr:2.15e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.852, tt:4351.419\n",
      "Ep:112, loss:0.00002, loss_test:0.16144, lr:2.11e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.838, tt:4388.723\n",
      "Ep:113, loss:0.00002, loss_test:0.16200, lr:2.06e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.828, tt:4426.372\n",
      "Ep:114, loss:0.00002, loss_test:0.16411, lr:2.02e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.827, tt:4465.157\n",
      "Ep:115, loss:0.00002, loss_test:0.16681, lr:1.98e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.825, tt:4503.653\n",
      "Ep:116, loss:0.00002, loss_test:0.16585, lr:1.94e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.815, tt:4541.308\n",
      "Ep:117, loss:0.00002, loss_test:0.16340, lr:1.90e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.809, tt:4579.431\n",
      "Ep:118, loss:0.00002, loss_test:0.16372, lr:1.87e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.814, tt:4618.906\n",
      "Ep:119, loss:0.00002, loss_test:0.16275, lr:1.83e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.801, tt:4656.113\n",
      "Ep:120, loss:0.00002, loss_test:0.16323, lr:1.79e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.800, tt:4694.756\n",
      "Ep:121, loss:0.00002, loss_test:0.16404, lr:1.76e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.801, tt:4733.695\n",
      "Ep:122, loss:0.00002, loss_test:0.16383, lr:1.72e-03, fs:0.85714 (r=0.758,p=0.987),  time:38.815, tt:4774.246\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 23\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24410, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.763, tt:39.763\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.24167, lr:9.90e-03, fs:0.66667 (r=1.000,p=0.500),  time:40.109, tt:80.218\n",
      "Ep:2, loss:0.00059, loss_test:0.23657, lr:9.80e-03, fs:0.66667 (r=1.000,p=0.500),  time:39.831, tt:119.493\n",
      "Ep:3, loss:0.00055, loss_test:0.22584, lr:9.70e-03, fs:0.66667 (r=1.000,p=0.500),  time:39.662, tt:158.646\n",
      "Ep:4, loss:0.00049, loss_test:0.20680, lr:9.61e-03, fs:0.66441 (r=0.990,p=0.500),  time:38.762, tt:193.810\n",
      "Ep:5, loss:0.00038, loss_test:0.19539, lr:9.51e-03, fs:0.69291 (r=0.889,p=0.568),  time:38.989, tt:233.933\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.19699, lr:9.41e-03, fs:0.71901 (r=0.879,p=0.608),  time:38.465, tt:269.258\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.19345, lr:9.32e-03, fs:0.73191 (r=0.869,p=0.632),  time:38.069, tt:304.556\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.19198, lr:9.23e-03, fs:0.72489 (r=0.838,p=0.638),  time:37.994, tt:341.950\n",
      "Ep:9, loss:0.00028, loss_test:0.18749, lr:9.14e-03, fs:0.72566 (r=0.828,p=0.646),  time:38.191, tt:381.909\n",
      "Ep:10, loss:0.00027, loss_test:0.19318, lr:9.04e-03, fs:0.72072 (r=0.808,p=0.650),  time:38.495, tt:423.440\n",
      "Ep:11, loss:0.00026, loss_test:0.19274, lr:8.95e-03, fs:0.67556 (r=0.768,p=0.603),  time:38.592, tt:463.108\n",
      "Ep:12, loss:0.00025, loss_test:0.18972, lr:8.86e-03, fs:0.69124 (r=0.758,p=0.636),  time:38.879, tt:505.431\n",
      "Ep:13, loss:0.00024, loss_test:0.18464, lr:8.78e-03, fs:0.70423 (r=0.758,p=0.658),  time:38.889, tt:544.442\n",
      "Ep:14, loss:0.00024, loss_test:0.18579, lr:8.69e-03, fs:0.69725 (r=0.768,p=0.639),  time:38.997, tt:584.953\n",
      "Ep:15, loss:0.00023, loss_test:0.18598, lr:8.60e-03, fs:0.69811 (r=0.747,p=0.655),  time:39.011, tt:624.177\n",
      "Ep:16, loss:0.00022, loss_test:0.18486, lr:8.51e-03, fs:0.69159 (r=0.747,p=0.643),  time:38.928, tt:661.770\n",
      "Ep:17, loss:0.00022, loss_test:0.18469, lr:8.43e-03, fs:0.73934 (r=0.788,p=0.696),  time:38.936, tt:700.853\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00021, loss_test:0.17509, lr:8.35e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.860, tt:738.331\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.18076, lr:8.26e-03, fs:0.75349 (r=0.818,p=0.698),  time:38.870, tt:777.408\n",
      "Ep:20, loss:0.00020, loss_test:0.17569, lr:8.18e-03, fs:0.75926 (r=0.828,p=0.701),  time:38.794, tt:814.667\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.17019, lr:8.10e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.791, tt:853.400\n",
      "Ep:22, loss:0.00019, loss_test:0.17637, lr:8.02e-03, fs:0.76279 (r=0.828,p=0.707),  time:38.748, tt:891.215\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.16643, lr:7.94e-03, fs:0.76364 (r=0.848,p=0.694),  time:38.745, tt:929.872\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.16507, lr:7.86e-03, fs:0.76147 (r=0.838,p=0.697),  time:38.665, tt:966.637\n",
      "Ep:25, loss:0.00017, loss_test:0.16725, lr:7.78e-03, fs:0.76852 (r=0.838,p=0.709),  time:38.693, tt:1006.019\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.16126, lr:7.70e-03, fs:0.78378 (r=0.879,p=0.707),  time:38.743, tt:1046.056\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.16295, lr:7.62e-03, fs:0.80569 (r=0.859,p=0.759),  time:38.719, tt:1084.120\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.16217, lr:7.55e-03, fs:0.82028 (r=0.899,p=0.754),  time:38.706, tt:1122.470\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.15273, lr:7.47e-03, fs:0.79821 (r=0.899,p=0.718),  time:38.638, tt:1159.147\n",
      "Ep:30, loss:0.00015, loss_test:0.15538, lr:7.40e-03, fs:0.81279 (r=0.899,p=0.742),  time:38.596, tt:1196.483\n",
      "Ep:31, loss:0.00014, loss_test:0.16635, lr:7.32e-03, fs:0.81159 (r=0.848,p=0.778),  time:38.530, tt:1232.975\n",
      "Ep:32, loss:0.00014, loss_test:0.15089, lr:7.25e-03, fs:0.81279 (r=0.899,p=0.742),  time:38.506, tt:1270.706\n",
      "Ep:33, loss:0.00013, loss_test:0.15193, lr:7.18e-03, fs:0.81106 (r=0.889,p=0.746),  time:38.397, tt:1305.494\n",
      "Ep:34, loss:0.00013, loss_test:0.15655, lr:7.11e-03, fs:0.82407 (r=0.899,p=0.761),  time:38.396, tt:1343.865\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.15389, lr:7.03e-03, fs:0.83721 (r=0.909,p=0.776),  time:38.337, tt:1380.118\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.14703, lr:6.96e-03, fs:0.82407 (r=0.899,p=0.761),  time:38.335, tt:1418.386\n",
      "Ep:37, loss:0.00012, loss_test:0.15678, lr:6.89e-03, fs:0.83871 (r=0.919,p=0.771),  time:38.265, tt:1454.067\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.15195, lr:6.83e-03, fs:0.83412 (r=0.889,p=0.786),  time:38.278, tt:1492.838\n",
      "Ep:39, loss:0.00011, loss_test:0.14489, lr:6.76e-03, fs:0.81481 (r=0.889,p=0.752),  time:38.214, tt:1528.553\n",
      "Ep:40, loss:0.00011, loss_test:0.15458, lr:6.69e-03, fs:0.84112 (r=0.909,p=0.783),  time:38.224, tt:1567.196\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00011, loss_test:0.15251, lr:6.62e-03, fs:0.82629 (r=0.889,p=0.772),  time:38.203, tt:1604.515\n",
      "Ep:42, loss:0.00010, loss_test:0.14373, lr:6.56e-03, fs:0.84762 (r=0.899,p=0.802),  time:38.129, tt:1639.549\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.15963, lr:6.49e-03, fs:0.84507 (r=0.909,p=0.789),  time:38.094, tt:1676.155\n",
      "Ep:44, loss:0.00010, loss_test:0.14506, lr:6.43e-03, fs:0.82569 (r=0.909,p=0.756),  time:38.055, tt:1712.478\n",
      "Ep:45, loss:0.00009, loss_test:0.14363, lr:6.36e-03, fs:0.83019 (r=0.889,p=0.779),  time:38.012, tt:1748.558\n",
      "Ep:46, loss:0.00009, loss_test:0.15253, lr:6.30e-03, fs:0.84360 (r=0.899,p=0.795),  time:37.990, tt:1785.514\n",
      "Ep:47, loss:0.00010, loss_test:0.14703, lr:6.24e-03, fs:0.82629 (r=0.889,p=0.772),  time:37.971, tt:1822.628\n",
      "Ep:48, loss:0.00009, loss_test:0.14528, lr:6.17e-03, fs:0.83810 (r=0.889,p=0.793),  time:37.967, tt:1860.382\n",
      "Ep:49, loss:0.00009, loss_test:0.14640, lr:6.11e-03, fs:0.83412 (r=0.889,p=0.786),  time:37.956, tt:1897.777\n",
      "Ep:50, loss:0.00008, loss_test:0.14886, lr:6.05e-03, fs:0.83412 (r=0.889,p=0.786),  time:37.961, tt:1936.008\n",
      "Ep:51, loss:0.00008, loss_test:0.14331, lr:5.99e-03, fs:0.84878 (r=0.879,p=0.821),  time:37.964, tt:1974.127\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.14690, lr:5.93e-03, fs:0.85854 (r=0.889,p=0.830),  time:37.970, tt:2012.410\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.15257, lr:5.87e-03, fs:0.84507 (r=0.909,p=0.789),  time:37.968, tt:2050.253\n",
      "Ep:54, loss:0.00008, loss_test:0.14543, lr:5.81e-03, fs:0.83654 (r=0.879,p=0.798),  time:37.891, tt:2083.999\n",
      "Ep:55, loss:0.00007, loss_test:0.14989, lr:5.75e-03, fs:0.85294 (r=0.879,p=0.829),  time:37.821, tt:2117.958\n",
      "Ep:56, loss:0.00007, loss_test:0.14836, lr:5.70e-03, fs:0.84058 (r=0.879,p=0.806),  time:37.760, tt:2152.305\n",
      "Ep:57, loss:0.00007, loss_test:0.14401, lr:5.64e-03, fs:0.84878 (r=0.879,p=0.821),  time:37.709, tt:2187.136\n",
      "Ep:58, loss:0.00007, loss_test:0.14451, lr:5.58e-03, fs:0.84878 (r=0.879,p=0.821),  time:37.686, tt:2223.487\n",
      "Ep:59, loss:0.00007, loss_test:0.14454, lr:5.53e-03, fs:0.85024 (r=0.889,p=0.815),  time:37.663, tt:2259.774\n",
      "Ep:60, loss:0.00007, loss_test:0.14641, lr:5.47e-03, fs:0.85854 (r=0.889,p=0.830),  time:37.637, tt:2295.861\n",
      "Ep:61, loss:0.00007, loss_test:0.14911, lr:5.42e-03, fs:0.84466 (r=0.879,p=0.813),  time:37.635, tt:2333.372\n",
      "Ep:62, loss:0.00006, loss_test:0.14950, lr:5.36e-03, fs:0.86700 (r=0.889,p=0.846),  time:37.616, tt:2369.839\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.15297, lr:5.31e-03, fs:0.84878 (r=0.879,p=0.821),  time:37.615, tt:2407.335\n",
      "Ep:64, loss:0.00006, loss_test:0.14793, lr:5.26e-03, fs:0.84000 (r=0.848,p=0.832),  time:37.624, tt:2445.570\n",
      "Ep:65, loss:0.00006, loss_test:0.14520, lr:5.20e-03, fs:0.88000 (r=0.889,p=0.871),  time:37.602, tt:2481.714\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.14979, lr:5.15e-03, fs:0.85714 (r=0.879,p=0.837),  time:37.604, tt:2519.436\n",
      "Ep:67, loss:0.00005, loss_test:0.14981, lr:5.10e-03, fs:0.86700 (r=0.889,p=0.846),  time:37.615, tt:2557.843\n",
      "Ep:68, loss:0.00005, loss_test:0.14727, lr:5.05e-03, fs:0.85714 (r=0.879,p=0.837),  time:37.587, tt:2593.494\n",
      "Ep:69, loss:0.00005, loss_test:0.14633, lr:5.00e-03, fs:0.86139 (r=0.879,p=0.845),  time:37.584, tt:2630.910\n",
      "Ep:70, loss:0.00005, loss_test:0.15037, lr:4.95e-03, fs:0.86869 (r=0.869,p=0.869),  time:37.582, tt:2668.294\n",
      "Ep:71, loss:0.00005, loss_test:0.15281, lr:4.90e-03, fs:0.87000 (r=0.879,p=0.861),  time:37.575, tt:2705.432\n",
      "Ep:72, loss:0.00005, loss_test:0.14987, lr:4.85e-03, fs:0.85859 (r=0.859,p=0.859),  time:37.552, tt:2741.296\n",
      "Ep:73, loss:0.00005, loss_test:0.15376, lr:4.80e-03, fs:0.80000 (r=0.768,p=0.835),  time:37.545, tt:2778.315\n",
      "Ep:74, loss:0.00005, loss_test:0.14520, lr:4.75e-03, fs:0.86139 (r=0.879,p=0.845),  time:37.513, tt:2813.464\n",
      "Ep:75, loss:0.00004, loss_test:0.14943, lr:4.71e-03, fs:0.85572 (r=0.869,p=0.843),  time:37.496, tt:2849.719\n",
      "Ep:76, loss:0.00005, loss_test:0.15330, lr:4.66e-03, fs:0.82474 (r=0.808,p=0.842),  time:37.505, tt:2887.878\n",
      "Ep:77, loss:0.00004, loss_test:0.14818, lr:4.57e-03, fs:0.86567 (r=0.879,p=0.853),  time:37.497, tt:2924.784\n",
      "Ep:78, loss:0.00004, loss_test:0.14955, lr:4.48e-03, fs:0.86139 (r=0.879,p=0.845),  time:37.470, tt:2960.145\n",
      "Ep:79, loss:0.00004, loss_test:0.15406, lr:4.39e-03, fs:0.78919 (r=0.737,p=0.849),  time:37.463, tt:2997.014\n",
      "Ep:80, loss:0.00004, loss_test:0.15166, lr:4.30e-03, fs:0.83505 (r=0.818,p=0.853),  time:37.474, tt:3035.384\n",
      "Ep:81, loss:0.00004, loss_test:0.15517, lr:4.21e-03, fs:0.86735 (r=0.859,p=0.876),  time:37.430, tt:3069.231\n",
      "Ep:82, loss:0.00004, loss_test:0.15574, lr:4.13e-03, fs:0.82474 (r=0.808,p=0.842),  time:37.395, tt:3103.750\n",
      "Ep:83, loss:0.00004, loss_test:0.15484, lr:4.05e-03, fs:0.82105 (r=0.788,p=0.857),  time:37.378, tt:3139.730\n",
      "Ep:84, loss:0.00004, loss_test:0.15122, lr:3.97e-03, fs:0.86432 (r=0.869,p=0.860),  time:37.374, tt:3176.778\n",
      "Ep:85, loss:0.00004, loss_test:0.15904, lr:3.89e-03, fs:0.75824 (r=0.697,p=0.831),  time:37.362, tt:3213.098\n",
      "Ep:86, loss:0.00004, loss_test:0.15448, lr:3.81e-03, fs:0.84103 (r=0.828,p=0.854),  time:37.373, tt:3251.452\n",
      "Ep:87, loss:0.00004, loss_test:0.15361, lr:3.73e-03, fs:0.88325 (r=0.879,p=0.888),  time:37.388, tt:3290.157\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00003, loss_test:0.16298, lr:3.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:37.404, tt:3328.945\n",
      "Ep:89, loss:0.00004, loss_test:0.15730, lr:3.66e-03, fs:0.80874 (r=0.747,p=0.881),  time:37.449, tt:3370.368\n",
      "Ep:90, loss:0.00003, loss_test:0.15095, lr:3.62e-03, fs:0.84211 (r=0.808,p=0.879),  time:37.511, tt:3413.468\n",
      "Ep:91, loss:0.00003, loss_test:0.16726, lr:3.59e-03, fs:0.80423 (r=0.768,p=0.844),  time:37.583, tt:3457.591\n",
      "Ep:92, loss:0.00003, loss_test:0.16330, lr:3.55e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.647, tt:3501.141\n",
      "Ep:93, loss:0.00003, loss_test:0.15203, lr:3.52e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.703, tt:3544.100\n",
      "Ep:94, loss:0.00003, loss_test:0.16091, lr:3.48e-03, fs:0.82162 (r=0.768,p=0.884),  time:37.777, tt:3588.811\n",
      "Ep:95, loss:0.00003, loss_test:0.16707, lr:3.45e-03, fs:0.77528 (r=0.697,p=0.873),  time:37.838, tt:3632.426\n",
      "Ep:96, loss:0.00003, loss_test:0.15600, lr:3.41e-03, fs:0.84043 (r=0.798,p=0.888),  time:37.861, tt:3672.497\n",
      "Ep:97, loss:0.00003, loss_test:0.15284, lr:3.38e-03, fs:0.87755 (r=0.869,p=0.887),  time:37.905, tt:3714.648\n",
      "Ep:98, loss:0.00003, loss_test:0.16219, lr:3.34e-03, fs:0.80000 (r=0.727,p=0.889),  time:37.951, tt:3757.179\n",
      "Ep:99, loss:0.00003, loss_test:0.16628, lr:3.28e-03, fs:0.84324 (r=0.788,p=0.907),  time:38.024, tt:3802.418\n",
      "Ep:100, loss:0.00003, loss_test:0.16134, lr:3.21e-03, fs:0.87234 (r=0.828,p=0.921),  time:38.091, tt:3847.194\n",
      "Ep:101, loss:0.00003, loss_test:0.16050, lr:3.15e-03, fs:0.77528 (r=0.697,p=0.873),  time:38.160, tt:3892.357\n",
      "Ep:102, loss:0.00003, loss_test:0.16228, lr:3.09e-03, fs:0.77095 (r=0.697,p=0.863),  time:38.218, tt:3936.426\n",
      "Ep:103, loss:0.00003, loss_test:0.16481, lr:3.02e-03, fs:0.86022 (r=0.808,p=0.920),  time:38.284, tt:3981.584\n",
      "Ep:104, loss:0.00002, loss_test:0.16131, lr:2.96e-03, fs:0.83060 (r=0.768,p=0.905),  time:38.319, tt:4023.503\n",
      "Ep:105, loss:0.00002, loss_test:0.16220, lr:2.90e-03, fs:0.76667 (r=0.697,p=0.852),  time:38.371, tt:4067.344\n",
      "Ep:106, loss:0.00002, loss_test:0.16750, lr:2.85e-03, fs:0.81319 (r=0.747,p=0.892),  time:38.412, tt:4110.044\n",
      "Ep:107, loss:0.00002, loss_test:0.16327, lr:2.79e-03, fs:0.84783 (r=0.788,p=0.918),  time:38.447, tt:4152.232\n",
      "Ep:108, loss:0.00002, loss_test:0.15869, lr:2.73e-03, fs:0.87831 (r=0.838,p=0.922),  time:38.495, tt:4195.914\n",
      "Ep:109, loss:0.00002, loss_test:0.16518, lr:2.68e-03, fs:0.78409 (r=0.697,p=0.896),  time:38.546, tt:4240.030\n",
      "Ep:110, loss:0.00002, loss_test:0.16618, lr:2.63e-03, fs:0.83516 (r=0.768,p=0.916),  time:38.603, tt:4284.973\n",
      "Ep:111, loss:0.00002, loss_test:0.16050, lr:2.57e-03, fs:0.84946 (r=0.798,p=0.908),  time:38.643, tt:4328.023\n",
      "Ep:112, loss:0.00002, loss_test:0.16472, lr:2.52e-03, fs:0.77528 (r=0.697,p=0.873),  time:38.667, tt:4369.386\n",
      "Ep:113, loss:0.00002, loss_test:0.17012, lr:2.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:38.709, tt:4412.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:114, loss:0.00002, loss_test:0.16349, lr:2.42e-03, fs:0.83060 (r=0.768,p=0.905),  time:38.756, tt:4456.959\n",
      "Ep:115, loss:0.00002, loss_test:0.15931, lr:2.38e-03, fs:0.83060 (r=0.768,p=0.905),  time:38.786, tt:4499.174\n",
      "Ep:116, loss:0.00002, loss_test:0.16003, lr:2.33e-03, fs:0.79558 (r=0.727,p=0.878),  time:38.801, tt:4539.753\n",
      "Ep:117, loss:0.00002, loss_test:0.16343, lr:2.28e-03, fs:0.78212 (r=0.707,p=0.875),  time:38.832, tt:4582.152\n",
      "Ep:118, loss:0.00002, loss_test:0.16470, lr:2.24e-03, fs:0.79096 (r=0.707,p=0.897),  time:38.852, tt:4623.380\n",
      "Ep:119, loss:0.00002, loss_test:0.16637, lr:2.19e-03, fs:0.80226 (r=0.717,p=0.910),  time:38.891, tt:4666.879\n",
      "Ep:120, loss:0.00002, loss_test:0.16549, lr:2.15e-03, fs:0.81768 (r=0.747,p=0.902),  time:38.923, tt:4709.626\n",
      "Ep:121, loss:0.00002, loss_test:0.16189, lr:2.11e-03, fs:0.83060 (r=0.768,p=0.905),  time:38.954, tt:4752.370\n",
      "Ep:122, loss:0.00002, loss_test:0.16360, lr:2.06e-03, fs:0.78857 (r=0.697,p=0.908),  time:38.975, tt:4793.949\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 24\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24604, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.408, tt:42.408\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1230bd3a7753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mth_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m#create log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(training, g, features, mask, loss)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m#naive way of testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mth_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m#calculate test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mthreshold_acc\u001b[0;34m(model, g, features, mask, loss, print_details, threshold_dist, threshold_cos, path)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m#mask = np.array([x for x in mask if x[2]==1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m#dist() | max(0, m - dist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,123,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00061, loss_test:0.24233, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:16.246, tt:16.246\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.23951, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:21.392, tt:42.784\n",
      "Ep:2, loss:0.00058, loss_test:0.23296, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:22.668, tt:68.003\n",
      "Ep:3, loss:0.00055, loss_test:0.21881, lr:8.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:24.691, tt:98.765\n",
      "Ep:4, loss:0.00045, loss_test:0.19490, lr:8.00e-03, fs:0.66667 (r=0.980,p=0.505),  time:27.055, tt:135.276\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.18538, lr:8.00e-03, fs:0.66129 (r=0.828,p=0.550),  time:28.380, tt:170.282\n",
      "Ep:6, loss:0.00033, loss_test:0.18698, lr:8.00e-03, fs:0.66964 (r=0.758,p=0.600),  time:29.297, tt:205.080\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.18591, lr:8.00e-03, fs:0.70046 (r=0.768,p=0.644),  time:30.160, tt:241.278\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00029, loss_test:0.18661, lr:8.00e-03, fs:0.71090 (r=0.758,p=0.670),  time:31.096, tt:279.868\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00028, loss_test:0.19161, lr:8.00e-03, fs:0.71429 (r=0.758,p=0.676),  time:31.947, tt:319.469\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00027, loss_test:0.18377, lr:8.00e-03, fs:0.72811 (r=0.798,p=0.669),  time:32.554, tt:358.091\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.18503, lr:8.00e-03, fs:0.73684 (r=0.778,p=0.700),  time:32.971, tt:395.652\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.18775, lr:8.00e-03, fs:0.70352 (r=0.707,p=0.700),  time:33.236, tt:432.074\n",
      "Ep:13, loss:0.00025, loss_test:0.17977, lr:8.00e-03, fs:0.71362 (r=0.768,p=0.667),  time:33.363, tt:467.082\n",
      "Ep:14, loss:0.00025, loss_test:0.17750, lr:8.00e-03, fs:0.69903 (r=0.727,p=0.673),  time:33.524, tt:502.854\n",
      "Ep:15, loss:0.00023, loss_test:0.18001, lr:8.00e-03, fs:0.71921 (r=0.737,p=0.702),  time:33.677, tt:538.832\n",
      "Ep:16, loss:0.00023, loss_test:0.17604, lr:8.00e-03, fs:0.72195 (r=0.747,p=0.698),  time:33.831, tt:575.123\n",
      "Ep:17, loss:0.00023, loss_test:0.17596, lr:8.00e-03, fs:0.71963 (r=0.778,p=0.670),  time:34.127, tt:614.278\n",
      "Ep:18, loss:0.00022, loss_test:0.17497, lr:8.00e-03, fs:0.70936 (r=0.727,p=0.692),  time:34.446, tt:654.472\n",
      "Ep:19, loss:0.00021, loss_test:0.17496, lr:8.00e-03, fs:0.73077 (r=0.768,p=0.697),  time:34.714, tt:694.271\n",
      "Ep:20, loss:0.00021, loss_test:0.17413, lr:8.00e-03, fs:0.73267 (r=0.747,p=0.718),  time:34.940, tt:733.730\n",
      "Ep:21, loss:0.00020, loss_test:0.17228, lr:8.00e-03, fs:0.71111 (r=0.808,p=0.635),  time:35.002, tt:770.053\n",
      "Ep:22, loss:0.00020, loss_test:0.16848, lr:8.00e-03, fs:0.71845 (r=0.747,p=0.692),  time:35.059, tt:806.354\n",
      "Ep:23, loss:0.00020, loss_test:0.16933, lr:8.00e-03, fs:0.73684 (r=0.778,p=0.700),  time:35.067, tt:841.617\n",
      "Ep:24, loss:0.00019, loss_test:0.16919, lr:8.00e-03, fs:0.72362 (r=0.727,p=0.720),  time:35.111, tt:877.768\n",
      "Ep:25, loss:0.00019, loss_test:0.16579, lr:8.00e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.126, tt:913.264\n",
      "Ep:26, loss:0.00019, loss_test:0.16967, lr:8.00e-03, fs:0.74112 (r=0.737,p=0.745),  time:35.124, tt:948.337\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.16202, lr:8.00e-03, fs:0.74528 (r=0.798,p=0.699),  time:35.300, tt:988.398\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00018, loss_test:0.16110, lr:8.00e-03, fs:0.77143 (r=0.818,p=0.730),  time:35.507, tt:1029.702\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.16106, lr:8.00e-03, fs:0.71616 (r=0.828,p=0.631),  time:35.621, tt:1068.635\n",
      "Ep:30, loss:0.00018, loss_test:0.16971, lr:8.00e-03, fs:0.74490 (r=0.737,p=0.753),  time:35.734, tt:1107.760\n",
      "Ep:31, loss:0.00018, loss_test:0.16630, lr:8.00e-03, fs:0.72558 (r=0.788,p=0.672),  time:35.699, tt:1142.363\n",
      "Ep:32, loss:0.00017, loss_test:0.15986, lr:8.00e-03, fs:0.79821 (r=0.899,p=0.718),  time:35.693, tt:1177.885\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.15983, lr:8.00e-03, fs:0.76617 (r=0.778,p=0.755),  time:35.727, tt:1214.718\n",
      "Ep:34, loss:0.00016, loss_test:0.16194, lr:8.00e-03, fs:0.76923 (r=0.758,p=0.781),  time:35.730, tt:1250.558\n",
      "Ep:35, loss:0.00015, loss_test:0.15488, lr:8.00e-03, fs:0.75490 (r=0.778,p=0.733),  time:35.755, tt:1287.176\n",
      "Ep:36, loss:0.00015, loss_test:0.15030, lr:8.00e-03, fs:0.75598 (r=0.798,p=0.718),  time:35.799, tt:1324.579\n",
      "Ep:37, loss:0.00015, loss_test:0.15428, lr:8.00e-03, fs:0.76847 (r=0.788,p=0.750),  time:35.924, tt:1365.110\n",
      "Ep:38, loss:0.00014, loss_test:0.15176, lr:8.00e-03, fs:0.77934 (r=0.838,p=0.728),  time:36.010, tt:1404.393\n",
      "Ep:39, loss:0.00015, loss_test:0.15169, lr:8.00e-03, fs:0.76190 (r=0.808,p=0.721),  time:36.074, tt:1442.969\n",
      "Ep:40, loss:0.00013, loss_test:0.14718, lr:8.00e-03, fs:0.78173 (r=0.778,p=0.786),  time:36.164, tt:1482.710\n",
      "Ep:41, loss:0.00013, loss_test:0.14339, lr:8.00e-03, fs:0.80392 (r=0.828,p=0.781),  time:36.184, tt:1519.737\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00013, loss_test:0.14243, lr:8.00e-03, fs:0.79024 (r=0.818,p=0.764),  time:36.174, tt:1555.490\n",
      "Ep:43, loss:0.00012, loss_test:0.14099, lr:8.00e-03, fs:0.79602 (r=0.808,p=0.784),  time:36.243, tt:1594.685\n",
      "Ep:44, loss:0.00012, loss_test:0.14515, lr:8.00e-03, fs:0.80976 (r=0.838,p=0.783),  time:36.314, tt:1634.136\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00011, loss_test:0.14456, lr:8.00e-03, fs:0.77512 (r=0.818,p=0.736),  time:36.341, tt:1671.667\n",
      "Ep:46, loss:0.00012, loss_test:0.14215, lr:8.00e-03, fs:0.80000 (r=0.828,p=0.774),  time:36.407, tt:1711.126\n",
      "Ep:47, loss:0.00010, loss_test:0.13587, lr:8.00e-03, fs:0.80383 (r=0.848,p=0.764),  time:36.536, tt:1753.733\n",
      "Ep:48, loss:0.00010, loss_test:0.13946, lr:8.00e-03, fs:0.81250 (r=0.788,p=0.839),  time:36.654, tt:1796.024\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00010, loss_test:0.13519, lr:8.00e-03, fs:0.81218 (r=0.808,p=0.816),  time:36.808, tt:1840.402\n",
      "Ep:50, loss:0.00009, loss_test:0.13368, lr:8.00e-03, fs:0.80597 (r=0.818,p=0.794),  time:36.939, tt:1883.904\n",
      "Ep:51, loss:0.00009, loss_test:0.13590, lr:8.00e-03, fs:0.77885 (r=0.818,p=0.743),  time:37.016, tt:1924.831\n",
      "Ep:52, loss:0.00009, loss_test:0.12812, lr:8.00e-03, fs:0.85714 (r=0.970,p=0.768),  time:37.083, tt:1965.414\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00009, loss_test:0.14013, lr:8.00e-03, fs:0.81026 (r=0.798,p=0.823),  time:37.154, tt:2006.333\n",
      "Ep:54, loss:0.00009, loss_test:0.13369, lr:8.00e-03, fs:0.85446 (r=0.919,p=0.798),  time:37.209, tt:2046.521\n",
      "Ep:55, loss:0.00008, loss_test:0.13897, lr:8.00e-03, fs:0.81633 (r=0.808,p=0.825),  time:37.304, tt:2089.033\n",
      "Ep:56, loss:0.00007, loss_test:0.13349, lr:8.00e-03, fs:0.81218 (r=0.808,p=0.816),  time:37.353, tt:2129.125\n",
      "Ep:57, loss:0.00007, loss_test:0.12975, lr:8.00e-03, fs:0.79412 (r=0.818,p=0.771),  time:37.488, tt:2174.329\n",
      "Ep:58, loss:0.00007, loss_test:0.12368, lr:8.00e-03, fs:0.87437 (r=0.879,p=0.870),  time:37.594, tt:2218.072\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.12805, lr:8.00e-03, fs:0.83505 (r=0.818,p=0.853),  time:37.730, tt:2263.828\n",
      "Ep:60, loss:0.00006, loss_test:0.12427, lr:8.00e-03, fs:0.83168 (r=0.848,p=0.816),  time:37.816, tt:2306.756\n",
      "Ep:61, loss:0.00006, loss_test:0.12625, lr:8.00e-03, fs:0.84375 (r=0.818,p=0.871),  time:37.876, tt:2348.299\n",
      "Ep:62, loss:0.00006, loss_test:0.13244, lr:8.00e-03, fs:0.81865 (r=0.798,p=0.840),  time:37.916, tt:2388.711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.13924, lr:8.00e-03, fs:0.80597 (r=0.818,p=0.794),  time:37.978, tt:2430.606\n",
      "Ep:64, loss:0.00006, loss_test:0.12960, lr:8.00e-03, fs:0.82828 (r=0.828,p=0.828),  time:38.036, tt:2472.317\n",
      "Ep:65, loss:0.00006, loss_test:0.13586, lr:8.00e-03, fs:0.79803 (r=0.818,p=0.779),  time:38.072, tt:2512.764\n",
      "Ep:66, loss:0.00005, loss_test:0.12382, lr:8.00e-03, fs:0.87179 (r=0.859,p=0.885),  time:38.120, tt:2554.048\n",
      "Ep:67, loss:0.00005, loss_test:0.12958, lr:8.00e-03, fs:0.81000 (r=0.818,p=0.802),  time:38.201, tt:2597.660\n",
      "Ep:68, loss:0.00005, loss_test:0.13773, lr:8.00e-03, fs:0.81773 (r=0.838,p=0.798),  time:38.263, tt:2640.145\n",
      "Ep:69, loss:0.00005, loss_test:0.13321, lr:8.00e-03, fs:0.81675 (r=0.788,p=0.848),  time:38.335, tt:2683.456\n",
      "Ep:70, loss:0.00005, loss_test:0.13659, lr:7.92e-03, fs:0.83077 (r=0.818,p=0.844),  time:38.384, tt:2725.242\n",
      "Ep:71, loss:0.00004, loss_test:0.13200, lr:7.84e-03, fs:0.86022 (r=0.808,p=0.920),  time:38.393, tt:2764.275\n",
      "Ep:72, loss:0.00004, loss_test:0.13189, lr:7.76e-03, fs:0.82234 (r=0.818,p=0.827),  time:38.416, tt:2804.334\n",
      "Ep:73, loss:0.00004, loss_test:0.12996, lr:7.68e-03, fs:0.82653 (r=0.818,p=0.835),  time:38.434, tt:2844.149\n",
      "Ep:74, loss:0.00003, loss_test:0.13248, lr:7.61e-03, fs:0.82540 (r=0.788,p=0.867),  time:38.445, tt:2883.343\n",
      "Ep:75, loss:0.00004, loss_test:0.14793, lr:7.53e-03, fs:0.85870 (r=0.798,p=0.929),  time:38.472, tt:2923.906\n",
      "Ep:76, loss:0.00004, loss_test:0.13122, lr:7.46e-03, fs:0.83938 (r=0.818,p=0.862),  time:38.508, tt:2965.090\n",
      "Ep:77, loss:0.00004, loss_test:0.13439, lr:7.38e-03, fs:0.82796 (r=0.778,p=0.885),  time:38.574, tt:3008.762\n",
      "Ep:78, loss:0.00004, loss_test:0.13007, lr:7.31e-03, fs:0.83696 (r=0.778,p=0.906),  time:38.622, tt:3051.145\n",
      "Ep:79, loss:0.00004, loss_test:0.13394, lr:7.24e-03, fs:0.82474 (r=0.808,p=0.842),  time:38.662, tt:3092.994\n",
      "Ep:80, loss:0.00003, loss_test:0.14042, lr:7.16e-03, fs:0.84324 (r=0.788,p=0.907),  time:38.704, tt:3134.989\n",
      "Ep:81, loss:0.00004, loss_test:0.14275, lr:7.09e-03, fs:0.82796 (r=0.778,p=0.885),  time:38.733, tt:3176.111\n",
      "Ep:82, loss:0.00004, loss_test:0.14490, lr:7.02e-03, fs:0.84817 (r=0.818,p=0.880),  time:38.732, tt:3214.794\n",
      "Ep:83, loss:0.00004, loss_test:0.13179, lr:6.95e-03, fs:0.85417 (r=0.828,p=0.882),  time:38.743, tt:3254.433\n",
      "Ep:84, loss:0.00003, loss_test:0.13865, lr:6.88e-03, fs:0.83417 (r=0.838,p=0.830),  time:38.755, tt:3294.136\n",
      "Ep:85, loss:0.00003, loss_test:0.12284, lr:6.81e-03, fs:0.88776 (r=0.879,p=0.897),  time:38.767, tt:3333.980\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00003, loss_test:0.12333, lr:6.81e-03, fs:0.84946 (r=0.798,p=0.908),  time:38.800, tt:3375.563\n",
      "Ep:87, loss:0.00003, loss_test:0.12779, lr:6.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:38.829, tt:3416.916\n",
      "Ep:88, loss:0.00003, loss_test:0.12085, lr:6.81e-03, fs:0.84694 (r=0.838,p=0.856),  time:38.886, tt:3460.837\n",
      "Ep:89, loss:0.00003, loss_test:0.14169, lr:6.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:38.952, tt:3505.688\n",
      "Ep:90, loss:0.00002, loss_test:0.12922, lr:6.81e-03, fs:0.82796 (r=0.778,p=0.885),  time:38.954, tt:3544.832\n",
      "Ep:91, loss:0.00002, loss_test:0.13402, lr:6.81e-03, fs:0.85106 (r=0.808,p=0.899),  time:38.962, tt:3584.488\n",
      "Ep:92, loss:0.00002, loss_test:0.13149, lr:6.81e-03, fs:0.84324 (r=0.788,p=0.907),  time:38.986, tt:3625.691\n",
      "Ep:93, loss:0.00002, loss_test:0.13693, lr:6.81e-03, fs:0.82653 (r=0.818,p=0.835),  time:38.984, tt:3664.506\n",
      "Ep:94, loss:0.00002, loss_test:0.14316, lr:6.81e-03, fs:0.83696 (r=0.778,p=0.906),  time:38.990, tt:3704.053\n",
      "Ep:95, loss:0.00002, loss_test:0.14275, lr:6.81e-03, fs:0.83516 (r=0.768,p=0.916),  time:38.996, tt:3743.647\n",
      "Ep:96, loss:0.00002, loss_test:0.12915, lr:6.81e-03, fs:0.86022 (r=0.808,p=0.920),  time:39.040, tt:3786.894\n",
      "Ep:97, loss:0.00002, loss_test:0.12090, lr:6.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:39.100, tt:3831.796\n",
      "Ep:98, loss:0.00002, loss_test:0.12420, lr:6.81e-03, fs:0.85714 (r=0.818,p=0.900),  time:39.146, tt:3875.440\n",
      "Ep:99, loss:0.00002, loss_test:0.14411, lr:6.81e-03, fs:0.83429 (r=0.737,p=0.961),  time:39.199, tt:3919.915\n",
      "Ep:100, loss:0.00002, loss_test:0.14146, lr:6.74e-03, fs:0.84615 (r=0.778,p=0.928),  time:39.209, tt:3960.063\n",
      "Ep:101, loss:0.00001, loss_test:0.12927, lr:6.68e-03, fs:0.83696 (r=0.778,p=0.906),  time:39.227, tt:4001.194\n",
      "Ep:102, loss:0.00002, loss_test:0.14060, lr:6.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:39.245, tt:4042.277\n",
      "Ep:103, loss:0.00001, loss_test:0.13385, lr:6.54e-03, fs:0.89362 (r=0.848,p=0.944),  time:39.269, tt:4083.964\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.13817, lr:6.54e-03, fs:0.83938 (r=0.818,p=0.862),  time:39.274, tt:4123.787\n",
      "Ep:105, loss:0.00002, loss_test:0.14701, lr:6.54e-03, fs:0.85083 (r=0.778,p=0.939),  time:39.293, tt:4165.074\n",
      "Ep:106, loss:0.00002, loss_test:0.15945, lr:6.54e-03, fs:0.82682 (r=0.747,p=0.925),  time:39.331, tt:4208.429\n",
      "Ep:107, loss:0.00002, loss_test:0.15189, lr:6.54e-03, fs:0.81768 (r=0.747,p=0.902),  time:39.370, tt:4251.964\n",
      "Ep:108, loss:0.00002, loss_test:0.13687, lr:6.54e-03, fs:0.82222 (r=0.747,p=0.914),  time:39.415, tt:4296.259\n",
      "Ep:109, loss:0.00002, loss_test:0.14199, lr:6.54e-03, fs:0.82486 (r=0.737,p=0.936),  time:39.456, tt:4340.184\n",
      "Ep:110, loss:0.00002, loss_test:0.13332, lr:6.54e-03, fs:0.81143 (r=0.717,p=0.934),  time:39.468, tt:4380.959\n",
      "Ep:111, loss:0.00002, loss_test:0.12922, lr:6.54e-03, fs:0.86957 (r=0.808,p=0.941),  time:39.466, tt:4420.146\n",
      "Ep:112, loss:0.00002, loss_test:0.12790, lr:6.54e-03, fs:0.85556 (r=0.778,p=0.951),  time:39.462, tt:4459.253\n",
      "Ep:113, loss:0.00002, loss_test:0.14601, lr:6.54e-03, fs:0.81481 (r=0.778,p=0.856),  time:39.471, tt:4499.700\n",
      "Ep:114, loss:0.00002, loss_test:0.16172, lr:6.48e-03, fs:0.75410 (r=0.697,p=0.821),  time:39.467, tt:4538.660\n",
      "Ep:115, loss:0.00003, loss_test:0.13918, lr:6.41e-03, fs:0.83598 (r=0.798,p=0.878),  time:39.473, tt:4578.812\n",
      "Ep:116, loss:0.00003, loss_test:0.12826, lr:6.35e-03, fs:0.84817 (r=0.818,p=0.880),  time:39.513, tt:4622.967\n",
      "Ep:117, loss:0.00004, loss_test:0.13527, lr:6.29e-03, fs:0.81522 (r=0.758,p=0.882),  time:39.566, tt:4668.802\n",
      "Ep:118, loss:0.00005, loss_test:0.16052, lr:6.22e-03, fs:0.70782 (r=0.869,p=0.597),  time:39.613, tt:4713.913\n",
      "Ep:119, loss:0.00016, loss_test:0.16243, lr:6.16e-03, fs:0.70817 (r=0.919,p=0.576),  time:39.654, tt:4758.504\n",
      "Ep:120, loss:0.00016, loss_test:0.13789, lr:6.10e-03, fs:0.75573 (r=1.000,p=0.607),  time:39.605, tt:4792.170\n",
      "Ep:121, loss:0.00016, loss_test:0.15784, lr:6.04e-03, fs:0.76847 (r=0.788,p=0.750),  time:39.539, tt:4823.729\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-355502d63c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.5+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_env\u001b[0;34m(ds_name, ns, st, sp, we, cv)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Test positive samples: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_dgl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dgl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ds_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_embedding_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FASTTEXT2_CLEAN2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./word_embeddings/clean2_fasttext_short.gpickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-747>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/networkx/readwrite/gpickle.py\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_rebuild_tensor_v2\u001b[0;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rebuild_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# NB: This line exists only for backwards compatibility; the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_rebuild_tensor\u001b[0;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# first construct a tensor with the correct dtype/device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1 --> best = 96\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.5+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,122,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.08994, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:49.247, tt:49.247\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08632, lr:1.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:59.457, tt:118.913\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08264, lr:1.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:62.977, tt:188.930\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08053, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:64.632, tt:258.530\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.07845, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:66.257, tt:331.285\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.07505, lr:1.00e-02, fs:0.67925 (r=0.909,p=0.542),  time:67.067, tt:402.400\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.07307, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:68.390, tt:478.727\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.07121, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:69.900, tt:559.204\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.06992, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:71.367, tt:642.299\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00024, loss_test:0.06893, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:72.257, tt:722.573\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00023, loss_test:0.06739, lr:1.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:73.014, tt:803.149\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06744, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:73.556, tt:882.675\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.06703, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:73.784, tt:959.197\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06590, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:73.811, tt:1033.348\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.06607, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:73.819, tt:1107.279\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.06515, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:73.827, tt:1181.234\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06468, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:74.124, tt:1260.112\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06465, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:74.328, tt:1337.908\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06439, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:74.485, tt:1415.208\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06387, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:74.791, tt:1495.811\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06449, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:75.004, tt:1575.079\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.06428, lr:1.00e-02, fs:0.73303 (r=0.818,p=0.664),  time:75.204, tt:1654.484\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.06312, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:75.009, tt:1725.204\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00016, loss_test:0.06392, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:74.893, tt:1797.423\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.06332, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:74.709, tt:1867.729\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.06287, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:74.609, tt:1939.828\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.06381, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:74.777, tt:2018.983\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.06273, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:74.891, tt:2096.948\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.06297, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:74.969, tt:2174.113\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.06418, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:75.135, tt:2254.041\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.06190, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:75.290, tt:2333.980\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.06427, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:75.381, tt:2412.195\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.06299, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:75.294, tt:2484.707\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.06179, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:75.187, tt:2556.347\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00011, loss_test:0.06418, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:75.074, tt:2627.598\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.06339, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:75.131, tt:2704.721\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.06132, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:75.243, tt:2784.002\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.06627, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:75.353, tt:2863.403\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.05974, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:75.418, tt:2941.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.06418, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:75.445, tt:3017.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06175, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:75.587, tt:3099.082\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.06138, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:75.533, tt:3172.398\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.06370, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:75.528, tt:3247.684\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.05972, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:75.420, tt:3318.488\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.06262, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:75.435, tt:3394.563\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.06025, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:75.536, tt:3474.671\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.06179, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:75.619, tt:3554.083\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.05990, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:75.654, tt:3631.406\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.06151, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:75.714, tt:3709.992\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.06045, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:75.785, tt:3789.235\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.06243, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:75.840, tt:3867.858\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.06079, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:75.843, tt:3943.830\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.06363, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:75.743, tt:4014.396\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.06082, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:75.690, tt:4087.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.06022, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:75.710, tt:4164.032\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.06360, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:75.812, tt:4245.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.05969, lr:9.90e-03, fs:0.80198 (r=0.818,p=0.786),  time:75.838, tt:4322.790\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.06436, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:75.931, tt:4404.015\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.05965, lr:9.70e-03, fs:0.81407 (r=0.818,p=0.810),  time:76.001, tt:4484.040\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.06243, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.042, tt:4562.539\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.06125, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:75.997, tt:4635.791\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06246, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:75.969, tt:4710.078\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.06341, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:75.926, tt:4783.337\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.06055, lr:9.61e-03, fs:0.82474 (r=0.808,p=0.842),  time:75.898, tt:4857.469\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.06380, lr:9.61e-03, fs:0.82540 (r=0.788,p=0.867),  time:75.985, tt:4939.022\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.06097, lr:9.61e-03, fs:0.81250 (r=0.788,p=0.839),  time:76.098, tt:5022.496\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.06487, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:76.167, tt:5103.170\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.06227, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.216, tt:5182.661\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.06286, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.273, tt:5262.808\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.06384, lr:9.61e-03, fs:0.82105 (r=0.788,p=0.857),  time:76.307, tt:5341.475\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.06329, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.330, tt:5419.463\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.06277, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.286, tt:5492.570\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.06376, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.224, tt:5564.358\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.06288, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.305, tt:5646.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.06466, lr:9.61e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.364, tt:5727.268\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.06247, lr:9.61e-03, fs:0.81675 (r=0.788,p=0.848),  time:76.445, tt:5809.819\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.06440, lr:9.51e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.507, tt:5891.004\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.06387, lr:9.41e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.558, tt:5971.535\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.06397, lr:9.32e-03, fs:0.79144 (r=0.747,p=0.841),  time:76.567, tt:6048.771\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.06331, lr:9.23e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.526, tt:6122.087\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.06530, lr:9.14e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.453, tt:6192.702\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.06370, lr:9.04e-03, fs:0.81053 (r=0.778,p=0.846),  time:76.382, tt:6263.354\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.06614, lr:8.95e-03, fs:0.79121 (r=0.727,p=0.867),  time:76.343, tt:6336.437\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.06424, lr:8.86e-03, fs:0.81915 (r=0.778,p=0.865),  time:76.405, tt:6418.028\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.06456, lr:8.78e-03, fs:0.80000 (r=0.747,p=0.860),  time:76.432, tt:6496.695\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.06423, lr:8.69e-03, fs:0.80435 (r=0.747,p=0.871),  time:76.479, tt:6577.201\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.06493, lr:8.60e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.513, tt:6656.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.06398, lr:8.51e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.530, tt:6734.624\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.06543, lr:8.43e-03, fs:0.77778 (r=0.707,p=0.864),  time:76.576, tt:6815.268\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.06517, lr:8.35e-03, fs:0.82353 (r=0.778,p=0.875),  time:76.522, tt:6887.016\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.06612, lr:8.26e-03, fs:0.77348 (r=0.707,p=0.854),  time:76.499, tt:6961.419\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.06489, lr:8.18e-03, fs:0.78022 (r=0.717,p=0.855),  time:76.504, tt:7038.339\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.06665, lr:8.10e-03, fs:0.80663 (r=0.737,p=0.890),  time:76.527, tt:7117.019\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.06547, lr:8.02e-03, fs:0.78689 (r=0.727,p=0.857),  time:76.568, tt:7197.438\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.06439, lr:7.94e-03, fs:0.80645 (r=0.758,p=0.862),  time:76.605, tt:7277.433\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.06556, lr:7.86e-03, fs:0.79781 (r=0.737,p=0.869),  time:76.636, tt:7357.024\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.06535, lr:7.78e-03, fs:0.78689 (r=0.727,p=0.857),  time:76.698, tt:7439.750\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.06594, lr:7.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:76.749, tt:7521.377\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.06562, lr:7.62e-03, fs:0.78689 (r=0.727,p=0.857),  time:76.759, tt:7599.132\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.06570, lr:7.55e-03, fs:0.78652 (r=0.707,p=0.886),  time:76.737, tt:7673.747\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.06600, lr:7.47e-03, fs:0.78453 (r=0.717,p=0.866),  time:76.709, tt:7747.567\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.06538, lr:7.40e-03, fs:0.79121 (r=0.727,p=0.867),  time:76.689, tt:7822.327\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.06604, lr:7.32e-03, fs:0.77778 (r=0.707,p=0.864),  time:76.729, tt:7903.054\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.06710, lr:7.25e-03, fs:0.77273 (r=0.687,p=0.883),  time:76.747, tt:7981.638\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.06569, lr:7.18e-03, fs:0.77778 (r=0.707,p=0.864),  time:76.786, tt:8062.485\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.06640, lr:7.11e-03, fs:0.78652 (r=0.707,p=0.886),  time:76.845, tt:8145.568\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.06642, lr:7.03e-03, fs:0.80220 (r=0.737,p=0.880),  time:76.874, tt:8225.468\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.06707, lr:6.96e-03, fs:0.77273 (r=0.687,p=0.883),  time:76.905, tt:8305.783\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.06609, lr:6.89e-03, fs:0.78212 (r=0.707,p=0.875),  time:76.862, tt:8377.978\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.06698, lr:6.83e-03, fs:0.77966 (r=0.697,p=0.885),  time:76.843, tt:8452.680\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.06614, lr:6.76e-03, fs:0.77966 (r=0.697,p=0.885),  time:76.789, tt:8523.582\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.06753, lr:6.69e-03, fs:0.80663 (r=0.737,p=0.890),  time:76.794, tt:8600.921\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.06717, lr:6.62e-03, fs:0.77273 (r=0.687,p=0.883),  time:76.826, tt:8681.320\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.06703, lr:6.56e-03, fs:0.77528 (r=0.697,p=0.873),  time:76.843, tt:8760.063\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.06637, lr:6.49e-03, fs:0.78212 (r=0.707,p=0.875),  time:76.863, tt:8839.219\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.06605, lr:6.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:76.887, tt:8918.883\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06807, lr:6.36e-03, fs:0.77273 (r=0.687,p=0.883),  time:76.936, tt:9001.557\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.06720, lr:6.30e-03, fs:0.77714 (r=0.687,p=0.895),  time:76.943, tt:9079.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.06800, lr:6.24e-03, fs:0.77011 (r=0.677,p=0.893),  time:76.918, tt:9153.240\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.06645, lr:6.17e-03, fs:0.79330 (r=0.717,p=0.887),  time:76.882, tt:9225.857\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.06746, lr:6.11e-03, fs:0.78161 (r=0.687,p=0.907),  time:76.842, tt:9297.875\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09046, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:62.963, tt:62.963\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08707, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:70.600, tt:141.201\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08423, lr:1.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:74.696, tt:224.087\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08092, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:76.834, tt:307.337\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.07796, lr:1.00e-02, fs:0.70111 (r=0.960,p=0.552),  time:77.460, tt:387.301\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.07695, lr:1.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:77.030, tt:462.183\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.07597, lr:1.00e-02, fs:0.74104 (r=0.939,p=0.612),  time:76.192, tt:533.347\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.07422, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:75.999, tt:607.992\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07402, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:75.941, tt:683.471\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07236, lr:1.00e-02, fs:0.74699 (r=0.939,p=0.620),  time:76.260, tt:762.595\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00023, loss_test:0.07165, lr:1.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:76.486, tt:841.347\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.07226, lr:1.00e-02, fs:0.75949 (r=0.909,p=0.652),  time:76.704, tt:920.449\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.07065, lr:1.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:77.017, tt:1001.224\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00021, loss_test:0.07189, lr:1.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:77.241, tt:1081.375\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00020, loss_test:0.06996, lr:1.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:77.407, tt:1161.109\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.07114, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:77.068, tt:1233.085\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.06996, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:76.835, tt:1306.196\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.07059, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:76.696, tt:1380.527\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.06960, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:76.734, tt:1457.946\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06900, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:76.893, tt:1537.858\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.07021, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:77.026, tt:1617.545\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.06867, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:77.242, tt:1699.325\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.06932, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:77.379, tt:1779.713\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00015, loss_test:0.06929, lr:9.90e-03, fs:0.74667 (r=0.848,p=0.667),  time:77.531, tt:1860.737\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.06937, lr:9.80e-03, fs:0.73778 (r=0.838,p=0.659),  time:77.434, tt:1935.848\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.06949, lr:9.70e-03, fs:0.75000 (r=0.848,p=0.672),  time:77.248, tt:2008.438\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.06986, lr:9.61e-03, fs:0.74775 (r=0.838,p=0.675),  time:77.079, tt:2081.126\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.06903, lr:9.51e-03, fs:0.74667 (r=0.848,p=0.667),  time:76.945, tt:2154.454\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.06952, lr:9.41e-03, fs:0.74439 (r=0.838,p=0.669),  time:76.997, tt:2232.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00012, loss_test:0.06998, lr:9.32e-03, fs:0.75113 (r=0.838,p=0.680),  time:77.047, tt:2311.419\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.06886, lr:9.23e-03, fs:0.74107 (r=0.838,p=0.664),  time:77.129, tt:2391.007\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.07096, lr:9.14e-03, fs:0.76147 (r=0.838,p=0.697),  time:77.197, tt:2470.318\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.06752, lr:9.14e-03, fs:0.74336 (r=0.848,p=0.661),  time:77.294, tt:2550.717\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.07119, lr:9.14e-03, fs:0.78302 (r=0.838,p=0.735),  time:77.319, tt:2628.856\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.06721, lr:9.14e-03, fs:0.74336 (r=0.848,p=0.661),  time:77.128, tt:2699.492\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.06922, lr:9.14e-03, fs:0.77209 (r=0.838,p=0.716),  time:76.981, tt:2771.331\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.06918, lr:9.14e-03, fs:0.76147 (r=0.838,p=0.697),  time:76.886, tt:2844.766\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.06737, lr:9.14e-03, fs:0.76018 (r=0.848,p=0.689),  time:76.837, tt:2919.793\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.06836, lr:9.14e-03, fs:0.76147 (r=0.838,p=0.697),  time:76.906, tt:2999.316\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.06795, lr:9.14e-03, fs:0.76852 (r=0.838,p=0.709),  time:76.967, tt:3078.667\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06756, lr:9.14e-03, fs:0.76712 (r=0.848,p=0.700),  time:76.999, tt:3156.939\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.06859, lr:9.14e-03, fs:0.77570 (r=0.838,p=0.722),  time:77.033, tt:3235.385\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.06753, lr:9.14e-03, fs:0.77419 (r=0.848,p=0.712),  time:77.066, tt:3313.844\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.06756, lr:9.14e-03, fs:0.77419 (r=0.848,p=0.712),  time:77.038, tt:3389.687\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.06896, lr:9.14e-03, fs:0.77934 (r=0.838,p=0.728),  time:76.907, tt:3460.814\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.06514, lr:9.04e-03, fs:0.76364 (r=0.848,p=0.694),  time:76.812, tt:3533.366\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.06853, lr:8.95e-03, fs:0.77778 (r=0.848,p=0.718),  time:76.714, tt:3605.547\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.06690, lr:8.86e-03, fs:0.78140 (r=0.848,p=0.724),  time:76.720, tt:3682.570\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00006, loss_test:0.06614, lr:8.78e-03, fs:0.77064 (r=0.848,p=0.706),  time:76.723, tt:3759.434\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.06867, lr:8.69e-03, fs:0.78505 (r=0.848,p=0.730),  time:76.760, tt:3838.020\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.06810, lr:8.69e-03, fs:0.78505 (r=0.848,p=0.730),  time:76.758, tt:3914.661\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.06683, lr:8.69e-03, fs:0.77778 (r=0.848,p=0.718),  time:76.776, tt:3992.341\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.06708, lr:8.69e-03, fs:0.78140 (r=0.848,p=0.724),  time:76.779, tt:4069.285\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.06718, lr:8.69e-03, fs:0.78140 (r=0.848,p=0.724),  time:76.657, tt:4139.487\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.06787, lr:8.69e-03, fs:0.78505 (r=0.848,p=0.730),  time:76.530, tt:4209.175\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00006, loss_test:0.06719, lr:8.69e-03, fs:0.78505 (r=0.848,p=0.730),  time:76.438, tt:4280.526\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.06667, lr:8.69e-03, fs:0.77778 (r=0.848,p=0.718),  time:76.328, tt:4350.686\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.06802, lr:8.69e-03, fs:0.79245 (r=0.848,p=0.743),  time:76.357, tt:4428.709\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.06622, lr:8.69e-03, fs:0.78140 (r=0.848,p=0.724),  time:76.338, tt:4503.956\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.06849, lr:8.69e-03, fs:0.80000 (r=0.848,p=0.757),  time:76.317, tt:4579.023\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.06851, lr:8.69e-03, fs:0.79245 (r=0.848,p=0.743),  time:76.319, tt:4655.443\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06813, lr:8.69e-03, fs:0.79245 (r=0.848,p=0.743),  time:76.337, tt:4732.886\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.06917, lr:8.69e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.350, tt:4810.078\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.06866, lr:8.69e-03, fs:0.79245 (r=0.848,p=0.743),  time:76.279, tt:4881.874\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.07084, lr:8.69e-03, fs:0.80769 (r=0.848,p=0.771),  time:76.219, tt:4954.253\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.06733, lr:8.69e-03, fs:0.79621 (r=0.848,p=0.750),  time:76.141, tt:5025.281\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.07068, lr:8.69e-03, fs:0.81553 (r=0.848,p=0.785),  time:76.084, tt:5097.660\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.06973, lr:8.69e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.111, tt:5175.516\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.06891, lr:8.69e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.174, tt:5255.979\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.07002, lr:8.69e-03, fs:0.81159 (r=0.848,p=0.778),  time:76.236, tt:5336.553\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.06886, lr:8.69e-03, fs:0.80769 (r=0.848,p=0.771),  time:76.280, tt:5415.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.07250, lr:8.69e-03, fs:0.80612 (r=0.798,p=0.814),  time:76.312, tt:5494.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00003, loss_test:0.07032, lr:8.69e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.316, tt:5571.056\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00003, loss_test:0.06951, lr:8.69e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.237, tt:5641.520\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00003, loss_test:0.07165, lr:8.69e-03, fs:0.78392 (r=0.788,p=0.780),  time:76.164, tt:5712.318\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.07197, lr:8.69e-03, fs:0.77320 (r=0.758,p=0.789),  time:76.119, tt:5785.021\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.07009, lr:8.69e-03, fs:0.81553 (r=0.848,p=0.785),  time:76.129, tt:5861.940\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.07104, lr:8.69e-03, fs:0.80597 (r=0.818,p=0.794),  time:76.197, tt:5943.376\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.06986, lr:8.60e-03, fs:0.81951 (r=0.848,p=0.792),  time:76.216, tt:6021.059\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.07089, lr:8.60e-03, fs:0.78571 (r=0.778,p=0.794),  time:76.258, tt:6100.647\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.06955, lr:8.60e-03, fs:0.81951 (r=0.848,p=0.792),  time:76.295, tt:6179.926\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.07337, lr:8.60e-03, fs:0.76440 (r=0.737,p=0.793),  time:76.310, tt:6257.426\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.06972, lr:8.60e-03, fs:0.81159 (r=0.848,p=0.778),  time:76.283, tt:6331.506\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.07266, lr:8.60e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.266, tt:6406.321\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00002, loss_test:0.06992, lr:8.60e-03, fs:0.80383 (r=0.848,p=0.764),  time:76.219, tt:6478.588\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00002, loss_test:0.07177, lr:8.60e-03, fs:0.74737 (r=0.717,p=0.780),  time:76.192, tt:6552.503\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00002, loss_test:0.07121, lr:8.60e-03, fs:0.74737 (r=0.717,p=0.780),  time:76.217, tt:6630.902\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00002, loss_test:0.07114, lr:8.60e-03, fs:0.76684 (r=0.747,p=0.787),  time:76.235, tt:6708.717\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00002, loss_test:0.07289, lr:8.60e-03, fs:0.72432 (r=0.677,p=0.779),  time:76.244, tt:6785.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00002, loss_test:0.07191, lr:8.60e-03, fs:0.72727 (r=0.687,p=0.773),  time:76.243, tt:6861.838\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.07275, lr:8.51e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.277, tt:6941.234\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00002, loss_test:0.07150, lr:8.43e-03, fs:0.72432 (r=0.677,p=0.779),  time:76.272, tt:7016.996\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.07256, lr:8.35e-03, fs:0.72432 (r=0.677,p=0.779),  time:76.215, tt:7088.023\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.07124, lr:8.26e-03, fs:0.71739 (r=0.667,p=0.776),  time:76.174, tt:7160.354\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.07175, lr:8.18e-03, fs:0.72131 (r=0.667,p=0.786),  time:76.111, tt:7230.550\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.07128, lr:8.10e-03, fs:0.71038 (r=0.657,p=0.774),  time:76.142, tt:7309.593\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.07350, lr:8.02e-03, fs:0.71823 (r=0.657,p=0.793),  time:76.169, tt:7388.369\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.07326, lr:7.94e-03, fs:0.71038 (r=0.657,p=0.774),  time:76.210, tt:7468.556\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.07161, lr:7.86e-03, fs:0.71038 (r=0.657,p=0.774),  time:76.233, tt:7547.023\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.07254, lr:7.78e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.256, tt:7625.594\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.07272, lr:7.70e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.274, tt:7703.713\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.07227, lr:7.62e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.242, tt:7776.680\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.07418, lr:7.55e-03, fs:0.71823 (r=0.657,p=0.793),  time:76.225, tt:7851.160\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.07165, lr:7.47e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.205, tt:7925.339\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.07458, lr:7.40e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.216, tt:8002.682\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.07286, lr:7.32e-03, fs:0.71429 (r=0.657,p=0.783),  time:76.265, tt:8084.069\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.07403, lr:7.25e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.341, tt:8168.528\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.07312, lr:7.18e-03, fs:0.72222 (r=0.657,p=0.802),  time:76.365, tt:8247.366\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.07324, lr:7.11e-03, fs:0.72222 (r=0.657,p=0.802),  time:76.381, tt:8325.493\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.07289, lr:7.03e-03, fs:0.72222 (r=0.657,p=0.802),  time:76.419, tt:8406.132\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00001, loss_test:0.07256, lr:6.96e-03, fs:0.71823 (r=0.657,p=0.793),  time:76.403, tt:8480.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00001, loss_test:0.07271, lr:6.89e-03, fs:0.71823 (r=0.657,p=0.793),  time:76.350, tt:8551.190\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.07482, lr:6.83e-03, fs:0.71823 (r=0.657,p=0.793),  time:76.330, tt:8625.325\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.07430, lr:6.76e-03, fs:0.72222 (r=0.657,p=0.802),  time:76.328, tt:8701.380\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00001, loss_test:0.07399, lr:6.69e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.367, tt:8782.256\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00001, loss_test:0.07404, lr:6.62e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.408, tt:8863.379\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00001, loss_test:0.07489, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.430, tt:8942.366\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.07514, lr:6.49e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.465, tt:9022.830\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.07557, lr:6.43e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.492, tt:9102.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.07442, lr:6.36e-03, fs:0.72626 (r=0.657,p=0.812),  time:76.510, tt:9181.161\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.07343, lr:6.30e-03, fs:0.72222 (r=0.657,p=0.802),  time:76.466, tt:9252.413\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09097, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:66.295, tt:66.295\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.08695, lr:1.00e-02, fs:0.67808 (r=1.000,p=0.513),  time:71.758, tt:143.517\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00034, loss_test:0.08190, lr:1.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:74.858, tt:224.574\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.07937, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:76.201, tt:304.802\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.07778, lr:1.00e-02, fs:0.69286 (r=0.980,p=0.536),  time:77.121, tt:385.607\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.07401, lr:1.00e-02, fs:0.69343 (r=0.960,p=0.543),  time:77.397, tt:464.381\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00029, loss_test:0.07131, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:77.959, tt:545.711\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00028, loss_test:0.06948, lr:1.00e-02, fs:0.72180 (r=0.970,p=0.575),  time:77.794, tt:622.353\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.06775, lr:1.00e-02, fs:0.73208 (r=0.980,p=0.584),  time:77.622, tt:698.601\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.06605, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:77.306, tt:773.063\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.06465, lr:1.00e-02, fs:0.74131 (r=0.970,p=0.600),  time:77.083, tt:847.917\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.06354, lr:1.00e-02, fs:0.75000 (r=0.970,p=0.611),  time:77.597, tt:931.164\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.06272, lr:1.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:77.891, tt:1012.581\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.06195, lr:1.00e-02, fs:0.75591 (r=0.970,p=0.619),  time:77.962, tt:1091.474\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.06163, lr:1.00e-02, fs:0.76923 (r=0.960,p=0.642),  time:78.130, tt:1171.946\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.06105, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:78.193, tt:1251.087\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06096, lr:1.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:78.302, tt:1331.134\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06010, lr:1.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:77.968, tt:1403.427\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.05962, lr:1.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:77.748, tt:1477.214\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.05861, lr:1.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:77.501, tt:1550.027\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.05874, lr:1.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:77.427, tt:1625.972\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00017, loss_test:0.05814, lr:1.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:77.620, tt:1707.640\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.05812, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:77.613, tt:1785.099\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00015, loss_test:0.05770, lr:1.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:77.703, tt:1864.878\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.05822, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:77.865, tt:1946.621\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00015, loss_test:0.05738, lr:1.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:77.927, tt:2026.113\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.05880, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:77.826, tt:2101.300\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00014, loss_test:0.05769, lr:1.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:77.651, tt:2174.241\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.05738, lr:1.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:77.568, tt:2249.475\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00013, loss_test:0.05798, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:77.319, tt:2319.567\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.05727, lr:1.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:77.349, tt:2397.822\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.05824, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:77.413, tt:2477.225\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.05785, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:77.471, tt:2556.532\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.05833, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:77.497, tt:2634.911\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.05849, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:77.622, tt:2716.765\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.05937, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:77.654, tt:2795.552\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.05780, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:77.551, tt:2869.373\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.06036, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:77.389, tt:2940.786\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.05856, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:77.199, tt:3010.753\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00008, loss_test:0.05910, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:77.115, tt:3084.608\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00008, loss_test:0.05899, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:77.210, tt:3165.631\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.06095, lr:1.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:77.231, tt:3243.708\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.05810, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:77.250, tt:3321.735\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.06131, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:77.251, tt:3399.038\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.06039, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:77.303, tt:3478.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.06090, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:77.290, tt:3555.323\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.05930, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:77.144, tt:3625.762\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.06114, lr:9.90e-03, fs:0.79227 (r=0.828,p=0.759),  time:77.010, tt:3696.462\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00006, loss_test:0.06020, lr:9.80e-03, fs:0.79024 (r=0.818,p=0.764),  time:76.884, tt:3767.326\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.05938, lr:9.70e-03, fs:0.78641 (r=0.818,p=0.757),  time:76.925, tt:3846.241\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.06058, lr:9.61e-03, fs:0.78641 (r=0.818,p=0.757),  time:76.924, tt:3923.121\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.06150, lr:9.51e-03, fs:0.80597 (r=0.818,p=0.794),  time:76.935, tt:4000.636\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.06142, lr:9.41e-03, fs:0.80198 (r=0.818,p=0.786),  time:76.953, tt:4078.534\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00005, loss_test:0.06186, lr:9.32e-03, fs:0.79412 (r=0.818,p=0.771),  time:76.917, tt:4153.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00005, loss_test:0.06092, lr:9.23e-03, fs:0.81000 (r=0.818,p=0.802),  time:76.968, tt:4233.214\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00005, loss_test:0.06166, lr:9.14e-03, fs:0.80402 (r=0.808,p=0.800),  time:76.950, tt:4309.221\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.06142, lr:9.04e-03, fs:0.78818 (r=0.808,p=0.769),  time:76.811, tt:4378.206\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.06283, lr:8.95e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.725, tt:4450.042\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.06154, lr:8.86e-03, fs:0.80808 (r=0.808,p=0.808),  time:76.682, tt:4524.237\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.06132, lr:8.78e-03, fs:0.80808 (r=0.808,p=0.808),  time:76.701, tt:4602.046\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.06244, lr:8.69e-03, fs:0.80000 (r=0.808,p=0.792),  time:76.737, tt:4680.945\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06248, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.726, tt:4757.035\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00004, loss_test:0.06198, lr:8.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.772, tt:4836.658\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00004, loss_test:0.06188, lr:8.43e-03, fs:0.80808 (r=0.808,p=0.808),  time:76.778, tt:4913.809\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.06230, lr:8.35e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.780, tt:4990.712\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.06379, lr:8.26e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.709, tt:5062.782\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.06268, lr:8.18e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.639, tt:5134.823\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.06345, lr:8.10e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.598, tt:5208.634\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.06313, lr:8.02e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.578, tt:5283.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.06425, lr:7.94e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.604, tt:5362.295\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.06235, lr:7.86e-03, fs:0.80808 (r=0.808,p=0.808),  time:76.626, tt:5440.480\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.06488, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.646, tt:5518.480\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.06236, lr:7.78e-03, fs:0.81218 (r=0.808,p=0.816),  time:76.678, tt:5597.467\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.06595, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.751, tt:5679.577\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.06335, lr:7.78e-03, fs:0.80808 (r=0.808,p=0.808),  time:76.744, tt:5755.782\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00003, loss_test:0.06415, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.678, tt:5827.518\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.06231, lr:7.78e-03, fs:0.80402 (r=0.808,p=0.800),  time:76.649, tt:5901.964\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.06337, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.629, tt:5977.043\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.06395, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.674, tt:6057.278\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.06489, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.729, tt:6138.349\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.06470, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.762, tt:6217.729\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.06440, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.794, tt:6297.110\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.06503, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.866, tt:6379.892\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.06439, lr:7.78e-03, fs:0.81633 (r=0.808,p=0.825),  time:76.878, tt:6457.775\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.06431, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.848, tt:6532.040\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.06612, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.811, tt:6605.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.06619, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.762, tt:6678.266\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.06452, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.783, tt:6756.902\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.06506, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.795, tt:6834.713\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.06439, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.825, tt:6914.208\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00003, loss_test:0.06672, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.875, tt:6995.636\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.06649, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.924, tt:7076.971\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00003, loss_test:0.06597, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.950, tt:7156.326\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00003, loss_test:0.06589, lr:7.78e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.911, tt:7229.638\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00003, loss_test:0.06737, lr:7.70e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.871, tt:7302.753\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.06545, lr:7.62e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.838, tt:7376.429\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.06634, lr:7.55e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.825, tt:7452.051\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.06709, lr:7.47e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.859, tt:7532.223\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.06711, lr:7.40e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.890, tt:7612.090\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.06738, lr:7.32e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.920, tt:7692.049\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.06705, lr:7.25e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.953, tt:7772.296\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.06734, lr:7.18e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.993, tt:7853.295\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.06793, lr:7.11e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.017, tt:7932.730\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.06783, lr:7.03e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.975, tt:8005.390\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.06686, lr:6.96e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.952, tt:8079.960\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.06838, lr:6.89e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.908, tt:8152.288\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.06689, lr:6.83e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.942, tt:8232.831\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.06781, lr:6.76e-03, fs:0.82051 (r=0.808,p=0.833),  time:76.981, tt:8313.965\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.06812, lr:6.69e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.000, tt:8392.993\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.06826, lr:6.62e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.051, tt:8475.560\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.06873, lr:6.56e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.091, tt:8557.051\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.07010, lr:6.49e-03, fs:0.82902 (r=0.808,p=0.851),  time:77.129, tt:8638.465\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.06954, lr:6.49e-03, fs:0.82474 (r=0.808,p=0.842),  time:77.094, tt:8711.571\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.06716, lr:6.49e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.066, tt:8785.527\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00002, loss_test:0.06883, lr:6.49e-03, fs:0.82474 (r=0.808,p=0.842),  time:77.031, tt:8858.527\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.06859, lr:6.49e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.016, tt:8933.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.06832, lr:6.49e-03, fs:0.82051 (r=0.808,p=0.833),  time:77.048, tt:9014.628\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00002, loss_test:0.06991, lr:6.49e-03, fs:0.83333 (r=0.808,p=0.860),  time:77.087, tt:9096.259\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00002, loss_test:0.07026, lr:6.49e-03, fs:0.83333 (r=0.808,p=0.860),  time:77.105, tt:9175.531\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00002, loss_test:0.07050, lr:6.49e-03, fs:0.84211 (r=0.808,p=0.879),  time:77.143, tt:9257.102\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00002, loss_test:0.07010, lr:6.49e-03, fs:0.83770 (r=0.808,p=0.870),  time:77.125, tt:9332.068\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 23\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09330, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:65.491, tt:65.491\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00035, loss_test:0.09002, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:69.294, tt:138.588\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.08732, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:71.197, tt:213.590\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.08603, lr:1.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:73.254, tt:293.015\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00031, loss_test:0.08423, lr:1.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:74.837, tt:374.186\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00030, loss_test:0.08194, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:75.470, tt:452.819\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.07967, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:76.200, tt:533.397\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.07809, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:76.693, tt:613.547\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.07740, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:76.948, tt:692.533\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.07567, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:76.714, tt:767.138\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07458, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:76.454, tt:840.994\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00023, loss_test:0.07474, lr:1.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:76.191, tt:914.289\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00022, loss_test:0.07375, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:75.879, tt:986.430\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00021, loss_test:0.07239, lr:1.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:76.277, tt:1067.881\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00021, loss_test:0.07220, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:76.491, tt:1147.360\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00020, loss_test:0.07222, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:76.665, tt:1226.633\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00019, loss_test:0.07107, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:76.954, tt:1308.216\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.07091, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:77.034, tt:1386.605\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00018, loss_test:0.06987, lr:1.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:77.274, tt:1468.212\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00018, loss_test:0.06944, lr:1.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:77.012, tt:1540.241\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00017, loss_test:0.06929, lr:1.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:76.801, tt:1612.813\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00016, loss_test:0.06913, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:76.676, tt:1686.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00016, loss_test:0.06773, lr:1.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:76.650, tt:1762.951\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00015, loss_test:0.06786, lr:1.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:76.794, tt:1843.067\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00015, loss_test:0.06787, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:77.004, tt:1925.095\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00014, loss_test:0.06673, lr:1.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:77.071, tt:2003.854\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00014, loss_test:0.06697, lr:1.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:77.285, tt:2086.688\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00013, loss_test:0.06680, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:77.317, tt:2164.863\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00013, loss_test:0.06633, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:77.306, tt:2241.870\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00012, loss_test:0.06679, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:77.137, tt:2314.106\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00012, loss_test:0.06644, lr:1.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:76.971, tt:2386.097\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00012, loss_test:0.06773, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:76.835, tt:2458.707\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00011, loss_test:0.06450, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:76.910, tt:2538.035\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00011, loss_test:0.06900, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:76.951, tt:2616.318\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00010, loss_test:0.06485, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:76.957, tt:2693.500\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00010, loss_test:0.06567, lr:1.00e-02, fs:0.72727 (r=0.808,p=0.661),  time:77.020, tt:2772.736\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00010, loss_test:0.06787, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:77.119, tt:2853.395\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00009, loss_test:0.06709, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:77.188, tt:2933.130\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00009, loss_test:0.06654, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:77.064, tt:3005.494\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00009, loss_test:0.06739, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:77.015, tt:3080.592\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06712, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:76.901, tt:3152.929\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00008, loss_test:0.06682, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:76.865, tt:3228.311\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00008, loss_test:0.06802, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:76.909, tt:3307.094\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00008, loss_test:0.06716, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:76.924, tt:3384.641\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00007, loss_test:0.06747, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:76.947, tt:3462.624\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00007, loss_test:0.06802, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:76.953, tt:3539.852\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00007, loss_test:0.06632, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:77.022, tt:3620.017\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00007, loss_test:0.06776, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:76.987, tt:3695.356\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.06792, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:76.875, tt:3766.873\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00006, loss_test:0.06641, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:76.802, tt:3840.109\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00006, loss_test:0.06742, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:76.770, tt:3915.272\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00006, loss_test:0.06721, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:76.799, tt:3993.547\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.06697, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:76.835, tt:4072.273\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.07059, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:76.909, tt:4153.076\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.06522, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:76.917, tt:4230.437\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00005, loss_test:0.07020, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:76.947, tt:4309.032\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00005, loss_test:0.06793, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:76.994, tt:4388.654\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00005, loss_test:0.06949, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:76.935, tt:4462.202\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.06953, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:76.846, tt:4533.897\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.06771, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:76.813, tt:4608.808\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.07120, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:76.788, tt:4684.092\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.06878, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:76.891, tt:4767.248\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.06940, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:76.955, tt:4848.157\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.07037, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:76.988, tt:4927.221\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00004, loss_test:0.07010, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:77.027, tt:5006.732\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00004, loss_test:0.06966, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:77.055, tt:5085.639\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00004, loss_test:0.07080, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:77.054, tt:5162.602\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.07108, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:76.998, tt:5235.853\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:68, loss:0.00004, loss_test:0.07024, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:76.931, tt:5308.236\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:69, loss:0.00004, loss_test:0.07191, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:76.859, tt:5380.147\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:70, loss:0.00004, loss_test:0.07086, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:76.874, tt:5458.050\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:71, loss:0.00004, loss_test:0.07424, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:76.917, tt:5538.010\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:72, loss:0.00004, loss_test:0.07183, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:76.948, tt:5617.218\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:73, loss:0.00004, loss_test:0.07378, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:76.997, tt:5697.777\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:74, loss:0.00004, loss_test:0.07249, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:77.032, tt:5777.389\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:75, loss:0.00004, loss_test:0.07411, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:77.058, tt:5856.416\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:76, loss:0.00003, loss_test:0.07474, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:76.995, tt:5928.640\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:77, loss:0.00003, loss_test:0.07224, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:76.965, tt:6003.246\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:78, loss:0.00003, loss_test:0.07383, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:76.900, tt:6075.069\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:79, loss:0.00003, loss_test:0.07369, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:76.900, tt:6152.039\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:80, loss:0.00003, loss_test:0.07604, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:76.959, tt:6233.658\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:81, loss:0.00003, loss_test:0.07659, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:76.981, tt:6312.470\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:82, loss:0.00003, loss_test:0.07468, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:76.980, tt:6389.365\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:83, loss:0.00003, loss_test:0.07563, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:76.987, tt:6466.919\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:84, loss:0.00003, loss_test:0.07524, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:77.017, tt:6546.479\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:85, loss:0.00003, loss_test:0.07615, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:77.021, tt:6623.779\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:86, loss:0.00003, loss_test:0.07747, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:76.952, tt:6694.806\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:87, loss:0.00003, loss_test:0.07698, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:76.909, tt:6768.033\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:88, loss:0.00003, loss_test:0.07963, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:76.858, tt:6840.364\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:89, loss:0.00003, loss_test:0.07539, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:76.878, tt:6919.047\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:90, loss:0.00002, loss_test:0.07741, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:76.920, tt:6999.750\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:91, loss:0.00003, loss_test:0.07824, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:76.961, tt:7080.377\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:92, loss:0.00002, loss_test:0.07818, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:76.973, tt:7158.525\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:93, loss:0.00002, loss_test:0.07890, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:76.998, tt:7237.821\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:94, loss:0.00002, loss_test:0.07659, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:77.028, tt:7317.656\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:95, loss:0.00002, loss_test:0.07702, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:76.998, tt:7391.763\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:96, loss:0.00002, loss_test:0.07645, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:76.945, tt:7463.627\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:97, loss:0.00002, loss_test:0.07768, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:76.907, tt:7536.898\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:98, loss:0.00002, loss_test:0.07826, lr:9.90e-03, fs:0.78756 (r=0.768,p=0.809),  time:76.921, tt:7615.209\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:99, loss:0.00002, loss_test:0.07766, lr:9.80e-03, fs:0.76042 (r=0.737,p=0.785),  time:76.938, tt:7693.839\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:100, loss:0.00002, loss_test:0.07659, lr:9.70e-03, fs:0.76289 (r=0.747,p=0.779),  time:76.964, tt:7773.349\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:101, loss:0.00002, loss_test:0.07796, lr:9.61e-03, fs:0.77720 (r=0.758,p=0.798),  time:76.987, tt:7852.692\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:102, loss:0.00002, loss_test:0.07673, lr:9.51e-03, fs:0.76923 (r=0.758,p=0.781),  time:77.007, tt:7931.671\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:103, loss:0.00002, loss_test:0.07693, lr:9.41e-03, fs:0.77249 (r=0.737,p=0.811),  time:77.026, tt:8010.754\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:104, loss:0.00002, loss_test:0.07930, lr:9.32e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.985, tt:8083.437\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:105, loss:0.00002, loss_test:0.07619, lr:9.23e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.936, tt:8155.175\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:106, loss:0.00002, loss_test:0.07947, lr:9.14e-03, fs:0.77660 (r=0.737,p=0.820),  time:76.895, tt:8227.714\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:107, loss:0.00002, loss_test:0.07828, lr:9.04e-03, fs:0.77249 (r=0.737,p=0.811),  time:76.853, tt:8300.080\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:108, loss:0.00002, loss_test:0.07708, lr:8.95e-03, fs:0.78974 (r=0.778,p=0.802),  time:76.860, tt:8377.723\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:109, loss:0.00002, loss_test:0.07896, lr:8.86e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.857, tt:8454.284\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:110, loss:0.00002, loss_test:0.07818, lr:8.78e-03, fs:0.78756 (r=0.768,p=0.809),  time:76.863, tt:8531.739\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:111, loss:0.00002, loss_test:0.07844, lr:8.69e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.869, tt:8609.350\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:112, loss:0.00002, loss_test:0.07808, lr:8.60e-03, fs:0.76440 (r=0.737,p=0.793),  time:76.860, tt:8685.189\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:113, loss:0.00002, loss_test:0.07952, lr:8.51e-03, fs:0.77660 (r=0.737,p=0.820),  time:76.887, tt:8765.089\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:114, loss:0.00001, loss_test:0.07720, lr:8.43e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.862, tt:8839.172\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:115, loss:0.00002, loss_test:0.07935, lr:8.35e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.815, tt:8910.499\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:116, loss:0.00002, loss_test:0.07956, lr:8.26e-03, fs:0.77660 (r=0.737,p=0.820),  time:76.771, tt:8982.262\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:117, loss:0.00001, loss_test:0.08002, lr:8.18e-03, fs:0.78723 (r=0.747,p=0.831),  time:76.745, tt:9055.877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:118, loss:0.00001, loss_test:0.07813, lr:8.10e-03, fs:0.76842 (r=0.737,p=0.802),  time:76.746, tt:9132.766\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:119, loss:0.00001, loss_test:0.07889, lr:8.02e-03, fs:0.77249 (r=0.737,p=0.811),  time:76.732, tt:9207.889\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:120, loss:0.00001, loss_test:0.07974, lr:7.94e-03, fs:0.77249 (r=0.737,p=0.811),  time:76.633, tt:9272.633\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 24\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:0, loss:0.00036, loss_test:0.09617, lr:1.00e-02, fs:0.64111 (r=0.929,p=0.489),  time:69.242, tt:69.242\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:1, loss:0.00034, loss_test:0.09644, lr:1.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:73.182, tt:146.364\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:2, loss:0.00033, loss_test:0.09760, lr:1.00e-02, fs:0.57143 (r=0.707,p=0.479),  time:71.517, tt:214.552\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:3, loss:0.00032, loss_test:0.09426, lr:1.00e-02, fs:0.57851 (r=0.707,p=0.490),  time:70.762, tt:283.047\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:4, loss:0.00030, loss_test:0.08949, lr:1.00e-02, fs:0.60156 (r=0.778,p=0.490),  time:71.041, tt:355.206\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:5, loss:0.00029, loss_test:0.08811, lr:1.00e-02, fs:0.62295 (r=0.768,p=0.524),  time:70.796, tt:424.773\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:6, loss:0.00028, loss_test:0.08728, lr:1.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:70.887, tt:496.208\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:7, loss:0.00027, loss_test:0.08389, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:70.591, tt:564.728\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:8, loss:0.00026, loss_test:0.08191, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:70.476, tt:634.288\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:9, loss:0.00025, loss_test:0.08122, lr:1.00e-02, fs:0.65254 (r=0.778,p=0.562),  time:70.303, tt:703.034\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:10, loss:0.00024, loss_test:0.07819, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:70.251, tt:772.766\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:11, loss:0.00024, loss_test:0.07684, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:70.276, tt:843.316\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:12, loss:0.00023, loss_test:0.07532, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:70.118, tt:911.529\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:13, loss:0.00022, loss_test:0.07327, lr:1.00e-02, fs:0.69880 (r=0.879,p=0.580),  time:69.904, tt:978.659\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:14, loss:0.00022, loss_test:0.07244, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:69.906, tt:1048.597\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:15, loss:0.00021, loss_test:0.07152, lr:1.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:69.858, tt:1117.724\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:16, loss:0.00020, loss_test:0.06996, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:69.721, tt:1185.264\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:17, loss:0.00019, loss_test:0.06931, lr:1.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:69.643, tt:1253.578\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:18, loss:0.00019, loss_test:0.06871, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:69.623, tt:1322.831\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:19, loss:0.00019, loss_test:0.06835, lr:1.00e-02, fs:0.73418 (r=0.879,p=0.630),  time:69.628, tt:1392.553\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:20, loss:0.00018, loss_test:0.06721, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:69.588, tt:1461.358\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:21, loss:0.00018, loss_test:0.06655, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:69.611, tt:1531.438\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:22, loss:0.00017, loss_test:0.06631, lr:1.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:69.666, tt:1602.321\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:23, loss:0.00017, loss_test:0.06542, lr:1.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:69.676, tt:1672.216\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:24, loss:0.00016, loss_test:0.06452, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:69.677, tt:1741.932\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:25, loss:0.00016, loss_test:0.06555, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:69.668, tt:1811.376\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:26, loss:0.00015, loss_test:0.06413, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:69.616, tt:1879.635\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:27, loss:0.00015, loss_test:0.06422, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:69.556, tt:1947.562\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:28, loss:0.00014, loss_test:0.06330, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:69.625, tt:2019.129\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:29, loss:0.00014, loss_test:0.06418, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:69.633, tt:2088.993\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:30, loss:0.00014, loss_test:0.06247, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:69.513, tt:2154.912\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:31, loss:0.00013, loss_test:0.06267, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:69.577, tt:2226.464\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:32, loss:0.00012, loss_test:0.06100, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:69.656, tt:2298.659\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:33, loss:0.00012, loss_test:0.06149, lr:1.00e-02, fs:0.75893 (r=0.859,p=0.680),  time:69.670, tt:2368.778\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:34, loss:0.00012, loss_test:0.05989, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:69.685, tt:2438.978\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:35, loss:0.00011, loss_test:0.06165, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:69.663, tt:2507.860\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:36, loss:0.00011, loss_test:0.05968, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:69.664, tt:2577.575\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:37, loss:0.00010, loss_test:0.06111, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:69.657, tt:2646.954\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:38, loss:0.00010, loss_test:0.05939, lr:1.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:69.615, tt:2714.997\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:39, loss:0.00010, loss_test:0.05892, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:69.661, tt:2786.425\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:40, loss:0.00009, loss_test:0.06077, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:69.685, tt:2857.083\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:41, loss:0.00009, loss_test:0.05907, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:69.734, tt:2928.843\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:42, loss:0.00009, loss_test:0.05900, lr:1.00e-02, fs:0.79439 (r=0.859,p=0.739),  time:69.770, tt:3000.126\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:43, loss:0.00009, loss_test:0.05980, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:69.775, tt:3070.091\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:44, loss:0.00008, loss_test:0.05815, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:69.777, tt:3139.977\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:45, loss:0.00008, loss_test:0.05968, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:69.790, tt:3210.320\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:46, loss:0.00008, loss_test:0.05943, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:69.783, tt:3279.796\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:47, loss:0.00008, loss_test:0.05826, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:69.797, tt:3350.244\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:48, loss:0.00007, loss_test:0.05838, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:69.803, tt:3420.363\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:49, loss:0.00007, loss_test:0.05783, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:69.818, tt:3490.913\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:50, loss:0.00007, loss_test:0.05799, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:69.802, tt:3559.877\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:51, loss:0.00007, loss_test:0.05648, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:69.769, tt:3627.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:52, loss:0.00006, loss_test:0.05791, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:69.790, tt:3698.872\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:53, loss:0.00006, loss_test:0.05649, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:69.787, tt:3768.491\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:54, loss:0.00006, loss_test:0.05787, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:69.769, tt:3837.310\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:55, loss:0.00006, loss_test:0.05727, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:69.776, tt:3907.429\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:56, loss:0.00006, loss_test:0.05671, lr:1.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:69.786, tt:3977.800\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:57, loss:0.00006, loss_test:0.05742, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:69.782, tt:4047.343\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:58, loss:0.00005, loss_test:0.05680, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:69.745, tt:4114.970\n",
      "##########Best model found so far##########\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:59, loss:0.00005, loss_test:0.05731, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:69.714, tt:4182.858\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:60, loss:0.00005, loss_test:0.05524, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:69.701, tt:4251.772\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:61, loss:0.00005, loss_test:0.05748, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:69.697, tt:4321.243\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:62, loss:0.00005, loss_test:0.05632, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:69.714, tt:4391.993\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:63, loss:0.00005, loss_test:0.05736, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:69.708, tt:4461.304\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:64, loss:0.00005, loss_test:0.05798, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:69.685, tt:4529.498\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:65, loss:0.00005, loss_test:0.05652, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:69.668, tt:4598.078\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:66, loss:0.00005, loss_test:0.05632, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:69.625, tt:4664.906\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n",
      "Ep:67, loss:0.00004, loss_test:0.05638, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:69.628, tt:4734.705\n",
      "888\n",
      "888\n",
      "888\n",
      "888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0307a213a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m#             np.random.shuffle(split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2, target)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,121,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 91\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:0, loss:0.00056, loss_test:0.10033, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:36.853, tt:36.853\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:1, loss:0.00041, loss_test:0.10679, lr:1.00e-02, fs:0.56502 (r=0.636,p=0.508),  time:36.911, tt:73.821\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:2, loss:0.00037, loss_test:0.10167, lr:1.00e-02, fs:0.57658 (r=0.646,p=0.520),  time:37.001, tt:111.004\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:3, loss:0.00034, loss_test:0.09585, lr:1.00e-02, fs:0.61333 (r=0.697,p=0.548),  time:37.123, tt:148.494\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:4, loss:0.00032, loss_test:0.09358, lr:1.00e-02, fs:0.62443 (r=0.697,p=0.566),  time:37.204, tt:186.022\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:5, loss:0.00030, loss_test:0.09653, lr:1.00e-02, fs:0.60000 (r=0.606,p=0.594),  time:37.308, tt:223.847\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:6, loss:0.00029, loss_test:0.09230, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:37.624, tt:263.371\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:7, loss:0.00028, loss_test:0.08957, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:38.835, tt:310.678\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:8, loss:0.00026, loss_test:0.09339, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:40.431, tt:363.878\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:9, loss:0.00025, loss_test:0.08914, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:41.975, tt:419.753\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:10, loss:0.00024, loss_test:0.08720, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:43.491, tt:478.397\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:11, loss:0.00023, loss_test:0.09371, lr:1.00e-02, fs:0.65969 (r=0.636,p=0.685),  time:44.654, tt:535.846\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:12, loss:0.00021, loss_test:0.08652, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:45.620, tt:593.062\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:13, loss:0.00020, loss_test:0.08528, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:46.538, tt:651.527\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:14, loss:0.00020, loss_test:0.08450, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:47.333, tt:709.988\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:15, loss:0.00019, loss_test:0.09227, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:48.084, tt:769.345\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:16, loss:0.00018, loss_test:0.08195, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:48.809, tt:829.744\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:17, loss:0.00017, loss_test:0.08351, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:49.298, tt:887.364\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:18, loss:0.00017, loss_test:0.08790, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:49.603, tt:942.463\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:19, loss:0.00016, loss_test:0.09544, lr:1.00e-02, fs:0.69231 (r=0.636,p=0.759),  time:50.200, tt:1004.005\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:20, loss:0.00016, loss_test:0.08073, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:50.466, tt:1059.780\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:21, loss:0.00015, loss_test:0.08771, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:50.756, tt:1116.623\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:22, loss:0.00014, loss_test:0.08695, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:51.114, tt:1175.631\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:23, loss:0.00013, loss_test:0.07523, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:51.460, tt:1235.034\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:24, loss:0.00013, loss_test:0.08886, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:51.713, tt:1292.823\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:25, loss:0.00012, loss_test:0.08191, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:51.931, tt:1350.203\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:26, loss:0.00012, loss_test:0.08169, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:52.252, tt:1410.808\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:27, loss:0.00011, loss_test:0.07971, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:52.442, tt:1468.371\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:28, loss:0.00010, loss_test:0.07650, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:52.642, tt:1526.625\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:29, loss:0.00010, loss_test:0.07731, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:52.798, tt:1583.941\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:30, loss:0.00009, loss_test:0.08118, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:52.943, tt:1641.242\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:31, loss:0.00009, loss_test:0.07301, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:53.076, tt:1698.428\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:32, loss:0.00009, loss_test:0.07978, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:53.215, tt:1756.095\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:33, loss:0.00008, loss_test:0.07635, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:53.342, tt:1813.613\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:34, loss:0.00008, loss_test:0.07470, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:53.412, tt:1869.425\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:35, loss:0.00007, loss_test:0.07947, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:53.552, tt:1927.888\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:36, loss:0.00007, loss_test:0.07131, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:53.631, tt:1984.342\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:37, loss:0.00007, loss_test:0.07955, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:53.744, tt:2042.291\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:38, loss:0.00007, loss_test:0.07553, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:53.855, tt:2100.335\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:39, loss:0.00006, loss_test:0.07686, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:53.971, tt:2158.824\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:40, loss:0.00006, loss_test:0.07509, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:54.183, tt:2221.487\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:41, loss:0.00006, loss_test:0.07566, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:54.355, tt:2282.891\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:42, loss:0.00006, loss_test:0.07444, lr:9.90e-03, fs:0.78125 (r=0.758,p=0.806),  time:54.393, tt:2338.915\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:43, loss:0.00005, loss_test:0.07759, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:54.452, tt:2395.891\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:44, loss:0.00005, loss_test:0.07542, lr:9.80e-03, fs:0.80214 (r=0.758,p=0.852),  time:54.482, tt:2451.669\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:45, loss:0.00005, loss_test:0.07461, lr:9.80e-03, fs:0.77320 (r=0.758,p=0.789),  time:54.530, tt:2508.393\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:46, loss:0.00005, loss_test:0.07770, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:54.560, tt:2564.302\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:47, loss:0.00005, loss_test:0.07154, lr:9.80e-03, fs:0.78534 (r=0.758,p=0.815),  time:54.605, tt:2621.037\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:48, loss:0.00005, loss_test:0.07778, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:54.649, tt:2677.812\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:49, loss:0.00004, loss_test:0.07495, lr:9.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:54.690, tt:2734.476\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:50, loss:0.00004, loss_test:0.07497, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:54.770, tt:2793.248\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:51, loss:0.00004, loss_test:0.07387, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:54.820, tt:2850.620\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:52, loss:0.00004, loss_test:0.07739, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:54.901, tt:2909.778\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:53, loss:0.00004, loss_test:0.07485, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:55.095, tt:2975.127\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:54, loss:0.00004, loss_test:0.07701, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:55.557, tt:3055.634\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:55, loss:0.00004, loss_test:0.07186, lr:9.80e-03, fs:0.79167 (r=0.768,p=0.817),  time:56.144, tt:3144.079\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:56, loss:0.00004, loss_test:0.07547, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:56.746, tt:3234.501\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:57, loss:0.00004, loss_test:0.08007, lr:9.80e-03, fs:0.81081 (r=0.758,p=0.872),  time:57.305, tt:3323.681\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:58, loss:0.00003, loss_test:0.07438, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:57.835, tt:3412.271\n",
      "1080\n",
      "1026\n",
      "1032\n",
      "1050\n",
      "1026\n",
      "114\n",
      "Ep:59, loss:0.00003, loss_test:0.07380, lr:9.80e-03, fs:0.80645 (r=0.758,p=0.862),  time:58.254, tt:3495.223\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"92-92\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 91\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:0, loss:0.00059, loss_test:0.09547, lr:1.00e-02, fs:0.64469 (r=0.889,p=0.506),  time:70.423, tt:70.423\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:1, loss:0.00054, loss_test:0.09257, lr:1.00e-02, fs:0.63670 (r=0.859,p=0.506),  time:73.902, tt:147.804\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:2, loss:0.00049, loss_test:0.09122, lr:1.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:77.102, tt:231.307\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:3, loss:0.00046, loss_test:0.09048, lr:1.00e-02, fs:0.62451 (r=0.798,p=0.513),  time:78.372, tt:313.487\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:4, loss:0.00043, loss_test:0.08670, lr:1.00e-02, fs:0.65021 (r=0.798,p=0.549),  time:78.347, tt:391.732\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:5, loss:0.00040, loss_test:0.08498, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:80.456, tt:482.735\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:6, loss:0.00039, loss_test:0.08207, lr:1.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:84.803, tt:593.621\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:7, loss:0.00036, loss_test:0.08290, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:90.099, tt:720.791\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:8, loss:0.00034, loss_test:0.08177, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:93.743, tt:843.685\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:9, loss:0.00033, loss_test:0.08130, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:96.462, tt:964.625\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:10, loss:0.00030, loss_test:0.08264, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:97.886, tt:1076.742\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:11, loss:0.00029, loss_test:0.07973, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:97.345, tt:1168.138\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:12, loss:0.00027, loss_test:0.07909, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:97.202, tt:1263.625\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:13, loss:0.00026, loss_test:0.08062, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:98.733, tt:1382.258\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:14, loss:0.00025, loss_test:0.07936, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:100.070, tt:1501.056\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:15, loss:0.00023, loss_test:0.07846, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:100.468, tt:1607.489\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:16, loss:0.00022, loss_test:0.07919, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:100.972, tt:1716.518\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:17, loss:0.00021, loss_test:0.07822, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:101.185, tt:1821.321\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:18, loss:0.00019, loss_test:0.07860, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:101.291, tt:1924.532\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:19, loss:0.00019, loss_test:0.08037, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:101.464, tt:2029.279\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:20, loss:0.00017, loss_test:0.07653, lr:1.00e-02, fs:0.69159 (r=0.747,p=0.643),  time:101.712, tt:2135.948\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:21, loss:0.00017, loss_test:0.07740, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:101.946, tt:2242.811\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:22, loss:0.00017, loss_test:0.07839, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:102.064, tt:2347.462\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:23, loss:0.00016, loss_test:0.07756, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:102.295, tt:2455.091\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:24, loss:0.00015, loss_test:0.07415, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:102.545, tt:2563.631\n",
      "##########Best model found so far##########\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:25, loss:0.00015, loss_test:0.08103, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:102.778, tt:2672.225\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:26, loss:0.00013, loss_test:0.08296, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:102.957, tt:2779.848\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:27, loss:0.00012, loss_test:0.08006, lr:1.00e-02, fs:0.68132 (r=0.626,p=0.747),  time:103.106, tt:2886.967\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:28, loss:0.00012, loss_test:0.07737, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:103.285, tt:2995.266\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:29, loss:0.00011, loss_test:0.07536, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:103.552, tt:3106.550\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:30, loss:0.00011, loss_test:0.07848, lr:1.00e-02, fs:0.70588 (r=0.667,p=0.750),  time:103.827, tt:3218.646\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:31, loss:0.00011, loss_test:0.08558, lr:1.00e-02, fs:0.69714 (r=0.616,p=0.803),  time:103.823, tt:3322.334\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:32, loss:0.00010, loss_test:0.08598, lr:1.00e-02, fs:0.70115 (r=0.616,p=0.813),  time:104.056, tt:3433.848\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:33, loss:0.00010, loss_test:0.07688, lr:1.00e-02, fs:0.67391 (r=0.626,p=0.729),  time:104.382, tt:3548.980\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:34, loss:0.00009, loss_test:0.08212, lr:1.00e-02, fs:0.68508 (r=0.626,p=0.756),  time:102.672, tt:3593.505\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:35, loss:0.00009, loss_test:0.08347, lr:1.00e-02, fs:0.68539 (r=0.616,p=0.772),  time:101.032, tt:3637.140\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:36, loss:0.00008, loss_test:0.08179, lr:9.90e-03, fs:0.69318 (r=0.616,p=0.792),  time:99.471, tt:3680.426\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:37, loss:0.00008, loss_test:0.07979, lr:9.80e-03, fs:0.69274 (r=0.626,p=0.775),  time:97.992, tt:3723.688\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:38, loss:0.00008, loss_test:0.08293, lr:9.70e-03, fs:0.70520 (r=0.616,p=0.824),  time:96.589, tt:3766.972\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:39, loss:0.00007, loss_test:0.08689, lr:9.61e-03, fs:0.67470 (r=0.566,p=0.836),  time:95.325, tt:3813.020\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:40, loss:0.00007, loss_test:0.08452, lr:9.51e-03, fs:0.71345 (r=0.616,p=0.847),  time:94.066, tt:3856.699\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:41, loss:0.00007, loss_test:0.08807, lr:9.41e-03, fs:0.72189 (r=0.616,p=0.871),  time:92.865, tt:3900.334\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:42, loss:0.00007, loss_test:0.08800, lr:9.32e-03, fs:0.70588 (r=0.606,p=0.845),  time:91.705, tt:3943.307\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:43, loss:0.00006, loss_test:0.08466, lr:9.23e-03, fs:0.68966 (r=0.606,p=0.800),  time:90.617, tt:3987.155\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:44, loss:0.00006, loss_test:0.08476, lr:9.14e-03, fs:0.71264 (r=0.626,p=0.827),  time:89.575, tt:4030.874\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:45, loss:0.00006, loss_test:0.08685, lr:9.04e-03, fs:0.70588 (r=0.606,p=0.845),  time:88.578, tt:4074.580\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:46, loss:0.00005, loss_test:0.08795, lr:8.95e-03, fs:0.70175 (r=0.606,p=0.833),  time:87.625, tt:4118.374\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:47, loss:0.00005, loss_test:0.08823, lr:8.86e-03, fs:0.70588 (r=0.606,p=0.845),  time:86.692, tt:4161.227\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:48, loss:0.00005, loss_test:0.08878, lr:8.78e-03, fs:0.67470 (r=0.566,p=0.836),  time:85.816, tt:4204.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:49, loss:0.00005, loss_test:0.08764, lr:8.69e-03, fs:0.69006 (r=0.596,p=0.819),  time:84.979, tt:4248.971\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:50, loss:0.00005, loss_test:0.08704, lr:8.60e-03, fs:0.71345 (r=0.616,p=0.847),  time:84.165, tt:4292.431\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:51, loss:0.00005, loss_test:0.08946, lr:8.51e-03, fs:0.66667 (r=0.556,p=0.833),  time:83.386, tt:4336.062\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:52, loss:0.00005, loss_test:0.08975, lr:8.43e-03, fs:0.66667 (r=0.556,p=0.833),  time:82.651, tt:4380.508\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:53, loss:0.00004, loss_test:0.08843, lr:8.35e-03, fs:0.66258 (r=0.545,p=0.844),  time:81.949, tt:4425.236\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:54, loss:0.00004, loss_test:0.08714, lr:8.26e-03, fs:0.65854 (r=0.545,p=0.831),  time:81.334, tt:4473.366\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:55, loss:0.00004, loss_test:0.08878, lr:8.18e-03, fs:0.66258 (r=0.545,p=0.844),  time:80.669, tt:4517.449\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:56, loss:0.00004, loss_test:0.09192, lr:8.10e-03, fs:0.66667 (r=0.545,p=0.857),  time:80.020, tt:4561.156\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:57, loss:0.00004, loss_test:0.09076, lr:8.02e-03, fs:0.66258 (r=0.545,p=0.844),  time:79.404, tt:4605.436\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:58, loss:0.00004, loss_test:0.09012, lr:7.94e-03, fs:0.67073 (r=0.556,p=0.846),  time:78.818, tt:4650.233\n",
      "1104\n",
      "1032\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1040\n",
      "856\n",
      "Ep:59, loss:0.00004, loss_test:0.09195, lr:7.86e-03, fs:0.66258 (r=0.545,p=0.844),  time:78.237, tt:4694.197\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,\"92-92\",4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 91\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:0, loss:0.00035, loss_test:0.09639, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:26.175, tt:26.175\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:1, loss:0.00034, loss_test:0.09473, lr:1.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:26.979, tt:53.958\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:2, loss:0.00031, loss_test:0.09727, lr:1.00e-02, fs:0.61538 (r=0.768,p=0.514),  time:27.382, tt:82.146\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:3, loss:0.00029, loss_test:0.09477, lr:1.00e-02, fs:0.61905 (r=0.788,p=0.510),  time:27.527, tt:110.107\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:4, loss:0.00028, loss_test:0.09358, lr:1.00e-02, fs:0.62151 (r=0.788,p=0.513),  time:28.088, tt:140.442\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:5, loss:0.00027, loss_test:0.09541, lr:1.00e-02, fs:0.61411 (r=0.747,p=0.521),  time:28.201, tt:169.209\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:6, loss:0.00026, loss_test:0.09205, lr:1.00e-02, fs:0.61224 (r=0.758,p=0.514),  time:30.261, tt:211.825\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:7, loss:0.00025, loss_test:0.09055, lr:1.00e-02, fs:0.60905 (r=0.747,p=0.514),  time:31.621, tt:252.964\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:8, loss:0.00024, loss_test:0.08885, lr:1.00e-02, fs:0.62185 (r=0.747,p=0.532),  time:32.870, tt:295.832\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:9, loss:0.00023, loss_test:0.08568, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:34.479, tt:344.788\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:10, loss:0.00023, loss_test:0.08491, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:35.954, tt:395.498\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:11, loss:0.00021, loss_test:0.08434, lr:1.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:36.945, tt:443.346\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:12, loss:0.00021, loss_test:0.08321, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:38.104, tt:495.353\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:13, loss:0.00020, loss_test:0.08328, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:38.342, tt:536.792\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:14, loss:0.00020, loss_test:0.08217, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:38.552, tt:578.287\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:15, loss:0.00019, loss_test:0.08305, lr:1.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:38.951, tt:623.218\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:16, loss:0.00019, loss_test:0.08113, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:39.171, tt:665.915\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:17, loss:0.00018, loss_test:0.08272, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:39.910, tt:718.383\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:18, loss:0.00018, loss_test:0.08146, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:40.313, tt:765.956\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:19, loss:0.00017, loss_test:0.08177, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:40.828, tt:816.555\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:20, loss:0.00017, loss_test:0.08239, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:41.150, tt:864.147\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:21, loss:0.00016, loss_test:0.08270, lr:1.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:41.146, tt:905.217\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:22, loss:0.00016, loss_test:0.08104, lr:1.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:41.275, tt:949.329\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:23, loss:0.00016, loss_test:0.08449, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:41.213, tt:989.117\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:24, loss:0.00015, loss_test:0.08176, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:41.580, tt:1039.509\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:25, loss:0.00015, loss_test:0.08422, lr:1.00e-02, fs:0.71171 (r=0.798,p=0.642),  time:41.845, tt:1087.960\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:26, loss:0.00014, loss_test:0.08159, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:42.165, tt:1138.453\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:27, loss:0.00014, loss_test:0.08321, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:42.477, tt:1189.368\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:28, loss:0.00014, loss_test:0.08188, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:42.492, tt:1232.261\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:29, loss:0.00014, loss_test:0.08487, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:42.587, tt:1277.608\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:30, loss:0.00013, loss_test:0.08135, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:42.562, tt:1319.410\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:31, loss:0.00013, loss_test:0.08266, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:42.612, tt:1363.570\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:32, loss:0.00012, loss_test:0.08189, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:42.765, tt:1411.238\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:33, loss:0.00012, loss_test:0.08460, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:43.044, tt:1463.498\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:34, loss:0.00011, loss_test:0.08218, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:43.257, tt:1513.979\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:35, loss:0.00011, loss_test:0.08331, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:43.382, tt:1561.745\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:36, loss:0.00011, loss_test:0.08338, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:43.347, tt:1603.823\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:37, loss:0.00011, loss_test:0.08443, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:43.232, tt:1642.800\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:38, loss:0.00010, loss_test:0.08355, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:43.281, tt:1687.947\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:39, loss:0.00010, loss_test:0.08445, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:43.219, tt:1728.773\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:40, loss:0.00009, loss_test:0.08244, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:43.338, tt:1776.876\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:41, loss:0.00009, loss_test:0.08503, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:43.445, tt:1824.705\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:42, loss:0.00009, loss_test:0.08447, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:43.578, tt:1873.869\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:43, loss:0.00008, loss_test:0.08617, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:43.753, tt:1925.117\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:44, loss:0.00008, loss_test:0.08472, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:43.687, tt:1965.922\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:45, loss:0.00008, loss_test:0.08828, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:43.682, tt:2009.365\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:46, loss:0.00008, loss_test:0.08359, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:43.806, tt:2058.873\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:47, loss:0.00007, loss_test:0.08528, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:44.308, tt:2126.761\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:48, loss:0.00007, loss_test:0.08563, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:44.791, tt:2194.740\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:49, loss:0.00007, loss_test:0.08591, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:45.362, tt:2268.095\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:50, loss:0.00007, loss_test:0.08565, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:45.917, tt:2341.778\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:51, loss:0.00006, loss_test:0.08820, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:46.379, tt:2411.730\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:52, loss:0.00006, loss_test:0.08518, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:46.769, tt:2478.773\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:53, loss:0.00006, loss_test:0.08612, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:47.116, tt:2544.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:54, loss:0.00006, loss_test:0.08329, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:47.463, tt:2610.469\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:55, loss:0.00006, loss_test:0.08798, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:47.836, tt:2678.829\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:56, loss:0.00005, loss_test:0.08254, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:48.259, tt:2750.773\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:57, loss:0.00005, loss_test:0.08801, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:48.658, tt:2822.141\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:58, loss:0.00005, loss_test:0.08463, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:48.875, tt:2883.604\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:59, loss:0.00005, loss_test:0.08496, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:48.836, tt:2930.144\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:60, loss:0.00005, loss_test:0.08384, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:48.680, tt:2969.464\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:61, loss:0.00005, loss_test:0.08409, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:48.557, tt:3010.531\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:62, loss:0.00005, loss_test:0.08545, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:48.415, tt:3050.167\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:63, loss:0.00005, loss_test:0.08435, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:48.292, tt:3090.702\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:64, loss:0.00005, loss_test:0.08548, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:48.263, tt:3137.099\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:65, loss:0.00004, loss_test:0.08376, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:48.276, tt:3186.221\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:66, loss:0.00005, loss_test:0.08512, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:48.300, tt:3236.104\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:67, loss:0.00004, loss_test:0.08852, lr:9.90e-03, fs:0.75132 (r=0.717,p=0.789),  time:48.263, tt:3281.871\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:68, loss:0.00004, loss_test:0.08284, lr:9.80e-03, fs:0.76842 (r=0.737,p=0.802),  time:48.159, tt:3322.953\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:69, loss:0.00004, loss_test:0.08870, lr:9.70e-03, fs:0.75132 (r=0.717,p=0.789),  time:48.040, tt:3362.833\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:70, loss:0.00004, loss_test:0.08370, lr:9.61e-03, fs:0.76684 (r=0.747,p=0.787),  time:47.935, tt:3403.419\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:71, loss:0.00004, loss_test:0.08727, lr:9.51e-03, fs:0.75393 (r=0.727,p=0.783),  time:47.874, tt:3446.926\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:72, loss:0.00004, loss_test:0.08502, lr:9.41e-03, fs:0.77249 (r=0.737,p=0.811),  time:47.902, tt:3496.880\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:73, loss:0.00004, loss_test:0.08546, lr:9.32e-03, fs:0.78974 (r=0.778,p=0.802),  time:47.866, tt:3542.115\n",
      "##########Best model found so far##########\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:74, loss:0.00004, loss_test:0.08615, lr:9.32e-03, fs:0.74194 (r=0.697,p=0.793),  time:47.855, tt:3589.092\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:75, loss:0.00004, loss_test:0.08607, lr:9.32e-03, fs:0.78571 (r=0.778,p=0.794),  time:47.796, tt:3632.520\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:76, loss:0.00003, loss_test:0.08637, lr:9.32e-03, fs:0.74468 (r=0.707,p=0.787),  time:47.695, tt:3672.495\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:77, loss:0.00003, loss_test:0.08513, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:47.584, tt:3711.514\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:78, loss:0.00003, loss_test:0.08630, lr:9.32e-03, fs:0.76842 (r=0.737,p=0.802),  time:47.480, tt:3750.880\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:79, loss:0.00003, loss_test:0.08615, lr:9.32e-03, fs:0.71739 (r=0.667,p=0.776),  time:47.440, tt:3795.196\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:80, loss:0.00003, loss_test:0.08646, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:47.431, tt:3841.887\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:81, loss:0.00003, loss_test:0.08583, lr:9.32e-03, fs:0.78351 (r=0.768,p=0.800),  time:47.442, tt:3890.224\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:82, loss:0.00003, loss_test:0.08648, lr:9.32e-03, fs:0.73118 (r=0.687,p=0.782),  time:47.414, tt:3935.371\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:83, loss:0.00003, loss_test:0.08725, lr:9.32e-03, fs:0.77174 (r=0.717,p=0.835),  time:47.370, tt:3979.082\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:84, loss:0.00003, loss_test:0.08862, lr:9.32e-03, fs:0.75532 (r=0.717,p=0.798),  time:47.287, tt:4019.404\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:85, loss:0.00003, loss_test:0.08778, lr:9.23e-03, fs:0.72626 (r=0.657,p=0.812),  time:47.228, tt:4061.579\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:86, loss:0.00003, loss_test:0.08775, lr:9.14e-03, fs:0.77249 (r=0.737,p=0.811),  time:47.148, tt:4101.898\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:87, loss:0.00003, loss_test:0.08677, lr:9.04e-03, fs:0.73224 (r=0.677,p=0.798),  time:47.167, tt:4150.737\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:88, loss:0.00003, loss_test:0.08831, lr:8.95e-03, fs:0.74033 (r=0.677,p=0.817),  time:47.156, tt:4196.864\n",
      "1056\n",
      "1028\n",
      "1040\n",
      "428\n",
      "Ep:89, loss:0.00003, loss_test:0.08747, lr:8.86e-03, fs:0.72527 (r=0.667,p=0.795),  time:47.107, tt:4239.611\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,90,\"92-92\",2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:0, loss:0.00056, loss_test:0.08252, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:54.633, tt:54.633\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:1, loss:0.00030, loss_test:0.09595, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:71.254, tt:142.507\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:2, loss:0.00023, loss_test:0.10067, lr:1.00e-02, fs:0.67416 (r=0.606,p=0.759),  time:78.762, tt:236.286\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:3, loss:0.00021, loss_test:0.09766, lr:1.00e-02, fs:0.70270 (r=0.657,p=0.756),  time:81.368, tt:325.473\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:4, loss:0.00020, loss_test:0.08543, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:82.666, tt:413.332\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:5, loss:0.00019, loss_test:0.09069, lr:1.00e-02, fs:0.71579 (r=0.687,p=0.747),  time:84.027, tt:504.163\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:6, loss:0.00017, loss_test:0.08408, lr:1.00e-02, fs:0.68783 (r=0.657,p=0.722),  time:85.898, tt:601.285\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:7, loss:0.00017, loss_test:0.08407, lr:1.00e-02, fs:0.69519 (r=0.657,p=0.739),  time:87.453, tt:699.621\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:8, loss:0.00016, loss_test:0.08911, lr:1.00e-02, fs:0.71591 (r=0.636,p=0.818),  time:88.327, tt:794.941\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:9, loss:0.00016, loss_test:0.07858, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:88.357, tt:883.571\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:10, loss:0.00015, loss_test:0.08213, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:88.174, tt:969.914\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:11, loss:0.00014, loss_test:0.08182, lr:1.00e-02, fs:0.73626 (r=0.677,p=0.807),  time:88.061, tt:1056.735\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:12, loss:0.00014, loss_test:0.07639, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:88.512, tt:1150.652\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:13, loss:0.00014, loss_test:0.07779, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:88.996, tt:1245.948\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:14, loss:0.00013, loss_test:0.07717, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:89.457, tt:1341.858\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:15, loss:0.00013, loss_test:0.07616, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:89.910, tt:1438.559\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:16, loss:0.00012, loss_test:0.07594, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:89.899, tt:1528.287\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:17, loss:0.00012, loss_test:0.07274, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:89.789, tt:1616.206\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:18, loss:0.00011, loss_test:0.07547, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:89.658, tt:1703.503\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:19, loss:0.00011, loss_test:0.07275, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:90.011, tt:1800.212\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:20, loss:0.00011, loss_test:0.07534, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:90.333, tt:1896.993\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:21, loss:0.00010, loss_test:0.07012, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:90.711, tt:1995.632\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:22, loss:0.00010, loss_test:0.07229, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:90.917, tt:2091.090\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:23, loss:0.00010, loss_test:0.07282, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:90.864, tt:2180.739\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:24, loss:0.00010, loss_test:0.07453, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:90.810, tt:2270.242\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:25, loss:0.00009, loss_test:0.07139, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:90.775, tt:2360.157\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:26, loss:0.00009, loss_test:0.06826, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:91.097, tt:2459.618\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:27, loss:0.00009, loss_test:0.06985, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:91.311, tt:2556.718\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:28, loss:0.00009, loss_test:0.07107, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:91.643, tt:2657.633\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:29, loss:0.00008, loss_test:0.06864, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:91.631, tt:2748.915\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:30, loss:0.00008, loss_test:0.07070, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:91.517, tt:2837.015\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:31, loss:0.00008, loss_test:0.06883, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:91.369, tt:2923.809\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:32, loss:0.00007, loss_test:0.06899, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:91.302, tt:3012.964\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:33, loss:0.00007, loss_test:0.06638, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:91.475, tt:3110.147\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:34, loss:0.00007, loss_test:0.06914, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:91.599, tt:3205.948\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:35, loss:0.00007, loss_test:0.06837, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:91.704, tt:3301.334\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:36, loss:0.00006, loss_test:0.06684, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:91.681, tt:3392.185\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:37, loss:0.00006, loss_test:0.06432, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:91.583, tt:3480.144\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:38, loss:0.00006, loss_test:0.06498, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:91.480, tt:3567.728\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:39, loss:0.00006, loss_test:0.06297, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:91.529, tt:3661.160\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:40, loss:0.00006, loss_test:0.06411, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:91.694, tt:3759.465\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:41, loss:0.00005, loss_test:0.06373, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:91.789, tt:3855.155\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:42, loss:0.00005, loss_test:0.06230, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:91.892, tt:3951.355\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:43, loss:0.00005, loss_test:0.06390, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:91.848, tt:4041.306\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:44, loss:0.00005, loss_test:0.06136, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:91.783, tt:4130.247\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:45, loss:0.00005, loss_test:0.05889, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:91.667, tt:4216.689\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:46, loss:0.00005, loss_test:0.05896, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:91.687, tt:4309.312\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:47, loss:0.00005, loss_test:0.06212, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:91.717, tt:4402.431\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:48, loss:0.00004, loss_test:0.06099, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:91.814, tt:4498.869\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00004, loss_test:0.05610, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:91.966, tt:4598.293\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:50, loss:0.00004, loss_test:0.05757, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:91.894, tt:4686.616\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:51, loss:0.00004, loss_test:0.06250, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:91.818, tt:4774.547\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:52, loss:0.00004, loss_test:0.06077, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:91.744, tt:4862.436\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:53, loss:0.00004, loss_test:0.05600, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:91.749, tt:4954.424\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:54, loss:0.00004, loss_test:0.05986, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:91.895, tt:5054.239\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:55, loss:0.00004, loss_test:0.05960, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:91.988, tt:5151.335\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:56, loss:0.00003, loss_test:0.06073, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:92.049, tt:5246.773\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:57, loss:0.00003, loss_test:0.05666, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:91.957, tt:5333.507\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:58, loss:0.00003, loss_test:0.06093, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:91.889, tt:5421.431\n",
      "1075\n",
      "1065\n",
      "1030\n",
      "1030\n",
      "240\n",
      "Ep:59, loss:0.00003, loss_test:0.05719, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:91.825, tt:5509.522\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:0, loss:0.00056, loss_test:0.08578, lr:1.00e-02, fs:0.68116 (r=0.949,p=0.531),  time:83.352, tt:83.352\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:1, loss:0.00031, loss_test:0.10412, lr:1.00e-02, fs:0.56989 (r=0.535,p=0.609),  time:84.167, tt:168.334\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:2, loss:0.00024, loss_test:0.10612, lr:1.00e-02, fs:0.57317 (r=0.475,p=0.723),  time:89.277, tt:267.830\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:3, loss:0.00022, loss_test:0.09480, lr:1.00e-02, fs:0.62295 (r=0.576,p=0.679),  time:88.651, tt:354.605\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:4, loss:0.00020, loss_test:0.09394, lr:1.00e-02, fs:0.64773 (r=0.576,p=0.740),  time:88.003, tt:440.016\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:5, loss:0.00019, loss_test:0.09131, lr:1.00e-02, fs:0.65537 (r=0.586,p=0.744),  time:87.833, tt:526.995\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:6, loss:0.00017, loss_test:0.08658, lr:1.00e-02, fs:0.68449 (r=0.646,p=0.727),  time:88.418, tt:618.929\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:7, loss:0.00017, loss_test:0.08663, lr:1.00e-02, fs:0.65574 (r=0.606,p=0.714),  time:89.497, tt:715.979\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:8, loss:0.00016, loss_test:0.08866, lr:1.00e-02, fs:0.65143 (r=0.576,p=0.750),  time:90.265, tt:812.383\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:9, loss:0.00015, loss_test:0.08418, lr:1.00e-02, fs:0.66667 (r=0.616,p=0.726),  time:90.996, tt:909.963\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:10, loss:0.00015, loss_test:0.08415, lr:1.00e-02, fs:0.68156 (r=0.616,p=0.762),  time:91.072, tt:1001.794\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:11, loss:0.00014, loss_test:0.08513, lr:1.00e-02, fs:0.67045 (r=0.596,p=0.766),  time:91.067, tt:1092.801\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:12, loss:0.00014, loss_test:0.08135, lr:1.00e-02, fs:0.68750 (r=0.667,p=0.710),  time:91.173, tt:1185.255\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:13, loss:0.00013, loss_test:0.08149, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:91.631, tt:1282.840\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:14, loss:0.00013, loss_test:0.08838, lr:1.00e-02, fs:0.71006 (r=0.606,p=0.857),  time:91.858, tt:1377.872\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:15, loss:0.00012, loss_test:0.08715, lr:1.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:92.218, tt:1475.491\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:16, loss:0.00012, loss_test:0.07786, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:92.454, tt:1571.723\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:17, loss:0.00012, loss_test:0.08815, lr:1.00e-02, fs:0.67485 (r=0.556,p=0.859),  time:92.300, tt:1661.408\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:18, loss:0.00011, loss_test:0.08840, lr:1.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:92.301, tt:1753.726\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:19, loss:0.00011, loss_test:0.07606, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:92.209, tt:1844.178\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:20, loss:0.00011, loss_test:0.08386, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:92.418, tt:1940.782\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:21, loss:0.00010, loss_test:0.09097, lr:1.00e-02, fs:0.65806 (r=0.515,p=0.911),  time:92.464, tt:2034.197\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:22, loss:0.00010, loss_test:0.08091, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:92.604, tt:2129.901\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:23, loss:0.00009, loss_test:0.07463, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:92.674, tt:2224.167\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:24, loss:0.00009, loss_test:0.08631, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:92.394, tt:2309.848\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:25, loss:0.00009, loss_test:0.08267, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:92.441, tt:2403.456\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:26, loss:0.00009, loss_test:0.07295, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:92.387, tt:2494.449\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:27, loss:0.00009, loss_test:0.08274, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:92.548, tt:2591.336\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:28, loss:0.00008, loss_test:0.08167, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:92.674, tt:2687.542\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:29, loss:0.00008, loss_test:0.07689, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:92.825, tt:2784.743\n",
      "##########Best model found so far##########\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:30, loss:0.00007, loss_test:0.08605, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:92.916, tt:2880.388\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:31, loss:0.00007, loss_test:0.07585, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:92.792, tt:2969.339\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:32, loss:0.00007, loss_test:0.08012, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:92.678, tt:3058.362\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:33, loss:0.00006, loss_test:0.07942, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:92.783, tt:3154.613\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:34, loss:0.00006, loss_test:0.07760, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:93.119, tt:3259.173\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:35, loss:0.00006, loss_test:0.07924, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:93.257, tt:3357.247\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:36, loss:0.00006, loss_test:0.07907, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:93.392, tt:3455.518\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:37, loss:0.00006, loss_test:0.07761, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:93.389, tt:3548.774\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:38, loss:0.00005, loss_test:0.07710, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:93.349, tt:3640.601\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:39, loss:0.00005, loss_test:0.07793, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:93.329, tt:3733.157\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:40, loss:0.00005, loss_test:0.07160, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:93.316, tt:3825.960\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:41, loss:0.00005, loss_test:0.08431, lr:9.90e-03, fs:0.76364 (r=0.636,p=0.955),  time:93.411, tt:3923.272\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:42, loss:0.00005, loss_test:0.07359, lr:9.80e-03, fs:0.81250 (r=0.788,p=0.839),  time:93.474, tt:4019.371\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:43, loss:0.00005, loss_test:0.07608, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:93.604, tt:4118.586\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00004, loss_test:0.07972, lr:9.61e-03, fs:0.77348 (r=0.707,p=0.854),  time:93.488, tt:4206.982\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:45, loss:0.00004, loss_test:0.07334, lr:9.51e-03, fs:0.79365 (r=0.758,p=0.833),  time:93.431, tt:4297.841\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:46, loss:0.00004, loss_test:0.07896, lr:9.41e-03, fs:0.81522 (r=0.758,p=0.882),  time:93.349, tt:4387.388\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:47, loss:0.00004, loss_test:0.07780, lr:9.32e-03, fs:0.80226 (r=0.717,p=0.910),  time:93.456, tt:4485.898\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:48, loss:0.00004, loss_test:0.07265, lr:9.23e-03, fs:0.81675 (r=0.788,p=0.848),  time:93.512, tt:4582.108\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:49, loss:0.00004, loss_test:0.07999, lr:9.14e-03, fs:0.81395 (r=0.707,p=0.959),  time:93.624, tt:4681.215\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:50, loss:0.00004, loss_test:0.07401, lr:9.04e-03, fs:0.75132 (r=0.717,p=0.789),  time:93.652, tt:4776.238\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:51, loss:0.00004, loss_test:0.07791, lr:8.95e-03, fs:0.83146 (r=0.747,p=0.937),  time:93.579, tt:4866.125\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:52, loss:0.00004, loss_test:0.07418, lr:8.86e-03, fs:0.75269 (r=0.707,p=0.805),  time:93.495, tt:4955.260\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:53, loss:0.00004, loss_test:0.07719, lr:8.78e-03, fs:0.82222 (r=0.747,p=0.914),  time:93.420, tt:5044.687\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:54, loss:0.00004, loss_test:0.07572, lr:8.69e-03, fs:0.77348 (r=0.707,p=0.854),  time:93.496, tt:5142.270\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:55, loss:0.00003, loss_test:0.07668, lr:8.60e-03, fs:0.82682 (r=0.747,p=0.925),  time:93.550, tt:5238.789\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:56, loss:0.00003, loss_test:0.07447, lr:8.51e-03, fs:0.78689 (r=0.727,p=0.857),  time:93.626, tt:5336.680\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:57, loss:0.00003, loss_test:0.07810, lr:8.43e-03, fs:0.80000 (r=0.707,p=0.921),  time:93.639, tt:5431.075\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:58, loss:0.00003, loss_test:0.07599, lr:8.35e-03, fs:0.77778 (r=0.707,p=0.864),  time:93.559, tt:5519.993\n",
      "1075\n",
      "1060\n",
      "1045\n",
      "1050\n",
      "210\n",
      "Ep:59, loss:0.00003, loss_test:0.07561, lr:8.26e-03, fs:0.81967 (r=0.758,p=0.893),  time:93.476, tt:5608.572\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1080\n",
      "1055\n",
      "1060\n",
      "1035\n",
      "210\n",
      "Ep:0, loss:0.00057, loss_test:0.08496, lr:1.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:84.476, tt:84.476\n",
      "##########Best model found so far##########\n",
      "1080\n",
      "1055\n",
      "1060\n",
      "1035\n",
      "210\n",
      "Ep:1, loss:0.00031, loss_test:0.09592, lr:1.00e-02, fs:0.63959 (r=0.636,p=0.643),  time:84.362, tt:168.725\n",
      "1080\n",
      "1055\n",
      "1060\n",
      "1035\n",
      "210\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e897897f90e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_ran\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"isolation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mending\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Values for CV out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;31m#         train_batch = shuffle_splits_ns(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m \u001b[0;31m#         np.random.shuffle(train_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;31m#         numb_splits = int(len(train_mask) / training.batch_splits) + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;31m#         train_batch = np.array_split(train_mask,numb_splits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:0, loss:0.00032, loss_test:0.09044, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:34.292, tt:34.292\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:1, loss:0.00028, loss_test:0.08432, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:39.409, tt:78.817\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:2, loss:0.00023, loss_test:0.09049, lr:1.00e-02, fs:0.64706 (r=0.667,p=0.629),  time:46.247, tt:138.740\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:3, loss:0.00021, loss_test:0.08852, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:49.906, tt:199.626\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:4, loss:0.00020, loss_test:0.08353, lr:1.00e-02, fs:0.62069 (r=0.727,p=0.541),  time:51.663, tt:258.313\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:5, loss:0.00019, loss_test:0.08758, lr:1.00e-02, fs:0.65672 (r=0.667,p=0.647),  time:53.170, tt:319.018\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:6, loss:0.00018, loss_test:0.08665, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:54.191, tt:379.334\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:7, loss:0.00018, loss_test:0.08186, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:55.037, tt:440.292\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:8, loss:0.00017, loss_test:0.08634, lr:1.00e-02, fs:0.66667 (r=0.646,p=0.688),  time:55.300, tt:497.702\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:9, loss:0.00016, loss_test:0.08137, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:55.675, tt:556.750\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:10, loss:0.00016, loss_test:0.08258, lr:1.00e-02, fs:0.67347 (r=0.667,p=0.680),  time:56.167, tt:617.842\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:11, loss:0.00015, loss_test:0.08299, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:56.216, tt:674.597\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:12, loss:0.00015, loss_test:0.07823, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:55.992, tt:727.899\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:13, loss:0.00014, loss_test:0.08097, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:55.902, tt:782.629\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:14, loss:0.00014, loss_test:0.08050, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:55.855, tt:837.820\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:15, loss:0.00014, loss_test:0.07686, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:55.707, tt:891.317\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:16, loss:0.00014, loss_test:0.07987, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:55.602, tt:945.241\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:17, loss:0.00013, loss_test:0.07755, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:55.501, tt:999.021\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:18, loss:0.00013, loss_test:0.07620, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:55.306, tt:1050.815\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:19, loss:0.00012, loss_test:0.07711, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:55.227, tt:1104.534\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:20, loss:0.00012, loss_test:0.07511, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:55.184, tt:1158.871\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:21, loss:0.00012, loss_test:0.07634, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:55.223, tt:1214.914\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:22, loss:0.00012, loss_test:0.07498, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:55.128, tt:1267.939\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:23, loss:0.00011, loss_test:0.07498, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:55.172, tt:1324.139\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:24, loss:0.00011, loss_test:0.07449, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:55.172, tt:1379.313\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:25, loss:0.00011, loss_test:0.07524, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:55.116, tt:1433.029\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:26, loss:0.00010, loss_test:0.07337, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:55.091, tt:1487.448\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:27, loss:0.00010, loss_test:0.07550, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:55.108, tt:1543.017\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:28, loss:0.00010, loss_test:0.07184, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:55.025, tt:1595.729\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:29, loss:0.00010, loss_test:0.07373, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:54.950, tt:1648.504\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:30, loss:0.00009, loss_test:0.07157, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:54.959, tt:1703.715\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:31, loss:0.00009, loss_test:0.07236, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:54.941, tt:1758.122\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:32, loss:0.00009, loss_test:0.07089, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:54.898, tt:1811.625\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:33, loss:0.00008, loss_test:0.07072, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:54.892, tt:1866.316\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:34, loss:0.00009, loss_test:0.07323, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:54.897, tt:1921.409\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:35, loss:0.00008, loss_test:0.06784, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:54.916, tt:1976.968\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:36, loss:0.00008, loss_test:0.07020, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:54.859, tt:2029.771\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:37, loss:0.00008, loss_test:0.07058, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:54.874, tt:2085.230\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:38, loss:0.00007, loss_test:0.07001, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:54.920, tt:2141.878\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:39, loss:0.00007, loss_test:0.06949, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:54.917, tt:2196.676\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:40, loss:0.00007, loss_test:0.07072, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:54.943, tt:2252.671\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:41, loss:0.00007, loss_test:0.06900, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:54.932, tt:2307.143\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:42, loss:0.00007, loss_test:0.06975, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:54.906, tt:2360.949\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:43, loss:0.00007, loss_test:0.06827, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:54.898, tt:2415.495\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:44, loss:0.00006, loss_test:0.06891, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:54.893, tt:2470.193\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:45, loss:0.00006, loss_test:0.06914, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:54.910, tt:2525.856\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:46, loss:0.00006, loss_test:0.06692, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:54.888, tt:2579.742\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:47, loss:0.00006, loss_test:0.06710, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.843, tt:2632.457\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:48, loss:0.00006, loss_test:0.06601, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:54.825, tt:2686.401\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:49, loss:0.00006, loss_test:0.06803, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:54.808, tt:2740.392\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:50, loss:0.00005, loss_test:0.06555, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.821, tt:2795.883\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:51, loss:0.00005, loss_test:0.06917, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:54.806, tt:2849.906\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:52, loss:0.00005, loss_test:0.06488, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.796, tt:2904.177\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:53, loss:0.00005, loss_test:0.06870, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:54.773, tt:2957.734\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:54, loss:0.00005, loss_test:0.06424, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.753, tt:3011.422\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:55, loss:0.00005, loss_test:0.06754, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:54.730, tt:3064.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:56, loss:0.00005, loss_test:0.06559, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.704, tt:3118.151\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:57, loss:0.00005, loss_test:0.06420, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.653, tt:3169.892\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:58, loss:0.00005, loss_test:0.07030, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:54.662, tt:3225.055\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:59, loss:0.00005, loss_test:0.06268, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:54.651, tt:3279.072\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:60, loss:0.00004, loss_test:0.06736, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:54.601, tt:3330.659\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:61, loss:0.00004, loss_test:0.06352, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:54.570, tt:3383.330\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:62, loss:0.00004, loss_test:0.06662, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:54.592, tt:3439.321\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:63, loss:0.00004, loss_test:0.06378, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:54.562, tt:3491.960\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:64, loss:0.00004, loss_test:0.06454, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:54.538, tt:3544.983\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:65, loss:0.00004, loss_test:0.06665, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:54.502, tt:3597.101\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:66, loss:0.00004, loss_test:0.06095, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:54.480, tt:3650.176\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:67, loss:0.00004, loss_test:0.06596, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:54.431, tt:3701.335\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:68, loss:0.00004, loss_test:0.06352, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:54.427, tt:3755.464\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:69, loss:0.00003, loss_test:0.06178, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:54.440, tt:3810.772\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:70, loss:0.00003, loss_test:0.06303, lr:9.90e-03, fs:0.79793 (r=0.778,p=0.819),  time:54.447, tt:3865.763\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:71, loss:0.00003, loss_test:0.06067, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:54.446, tt:3920.090\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:72, loss:0.00003, loss_test:0.06176, lr:9.70e-03, fs:0.80628 (r=0.778,p=0.837),  time:54.453, tt:3975.101\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:73, loss:0.00003, loss_test:0.06209, lr:9.61e-03, fs:0.79793 (r=0.778,p=0.819),  time:54.451, tt:4029.351\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:74, loss:0.00003, loss_test:0.06103, lr:9.51e-03, fs:0.81053 (r=0.778,p=0.846),  time:54.421, tt:4081.598\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:75, loss:0.00003, loss_test:0.06286, lr:9.41e-03, fs:0.81053 (r=0.778,p=0.846),  time:54.413, tt:4135.350\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:76, loss:0.00003, loss_test:0.06016, lr:9.32e-03, fs:0.81053 (r=0.778,p=0.846),  time:54.407, tt:4189.321\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:77, loss:0.00003, loss_test:0.06269, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:54.395, tt:4242.796\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:78, loss:0.00003, loss_test:0.06221, lr:9.23e-03, fs:0.81915 (r=0.778,p=0.865),  time:54.352, tt:4293.833\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:79, loss:0.00003, loss_test:0.06077, lr:9.23e-03, fs:0.81481 (r=0.778,p=0.856),  time:54.339, tt:4347.096\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:80, loss:0.00003, loss_test:0.06269, lr:9.23e-03, fs:0.82796 (r=0.778,p=0.885),  time:54.341, tt:4401.646\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:81, loss:0.00003, loss_test:0.06180, lr:9.23e-03, fs:0.81481 (r=0.778,p=0.856),  time:54.346, tt:4456.367\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:82, loss:0.00003, loss_test:0.06077, lr:9.23e-03, fs:0.81481 (r=0.778,p=0.856),  time:54.339, tt:4510.137\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:83, loss:0.00003, loss_test:0.06229, lr:9.23e-03, fs:0.81481 (r=0.778,p=0.856),  time:54.288, tt:4560.200\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:84, loss:0.00003, loss_test:0.06237, lr:9.23e-03, fs:0.82796 (r=0.778,p=0.885),  time:54.287, tt:4614.396\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:85, loss:0.00002, loss_test:0.06179, lr:9.23e-03, fs:0.82796 (r=0.778,p=0.885),  time:54.274, tt:4667.575\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:86, loss:0.00002, loss_test:0.06380, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:54.263, tt:4720.896\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:87, loss:0.00002, loss_test:0.06263, lr:9.23e-03, fs:0.82796 (r=0.778,p=0.885),  time:54.247, tt:4773.695\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:88, loss:0.00002, loss_test:0.06314, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:54.248, tt:4828.074\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:89, loss:0.00002, loss_test:0.06274, lr:9.23e-03, fs:0.83243 (r=0.778,p=0.895),  time:54.212, tt:4879.036\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:90, loss:0.00002, loss_test:0.06376, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:54.198, tt:4931.992\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:91, loss:0.00002, loss_test:0.06226, lr:9.23e-03, fs:0.82796 (r=0.778,p=0.885),  time:54.182, tt:4984.771\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:92, loss:0.00002, loss_test:0.06394, lr:9.23e-03, fs:0.81967 (r=0.758,p=0.893),  time:54.162, tt:5037.059\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:93, loss:0.00002, loss_test:0.06301, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:54.129, tt:5088.154\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:94, loss:0.00002, loss_test:0.06513, lr:9.23e-03, fs:0.80447 (r=0.727,p=0.900),  time:54.129, tt:5142.209\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:95, loss:0.00002, loss_test:0.06521, lr:9.23e-03, fs:0.82609 (r=0.768,p=0.894),  time:54.113, tt:5194.880\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:96, loss:0.00002, loss_test:0.06750, lr:9.23e-03, fs:0.80226 (r=0.717,p=0.910),  time:54.101, tt:5247.756\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:97, loss:0.00002, loss_test:0.06231, lr:9.23e-03, fs:0.82353 (r=0.778,p=0.875),  time:54.116, tt:5303.352\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:98, loss:0.00002, loss_test:0.06451, lr:9.23e-03, fs:0.81768 (r=0.747,p=0.902),  time:54.085, tt:5354.447\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:99, loss:0.00002, loss_test:0.06426, lr:9.23e-03, fs:0.83060 (r=0.768,p=0.905),  time:54.075, tt:5407.543\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:100, loss:0.00002, loss_test:0.06444, lr:9.23e-03, fs:0.80663 (r=0.737,p=0.890),  time:54.085, tt:5462.579\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:101, loss:0.00002, loss_test:0.06281, lr:9.14e-03, fs:0.82162 (r=0.768,p=0.884),  time:54.072, tt:5515.354\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:102, loss:0.00002, loss_test:0.06578, lr:9.04e-03, fs:0.82022 (r=0.737,p=0.924),  time:54.087, tt:5570.946\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:103, loss:0.00002, loss_test:0.06316, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:54.081, tt:5624.408\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:104, loss:0.00002, loss_test:0.06483, lr:8.86e-03, fs:0.81564 (r=0.737,p=0.912),  time:54.092, tt:5679.630\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:105, loss:0.00002, loss_test:0.06162, lr:8.78e-03, fs:0.83243 (r=0.778,p=0.895),  time:54.096, tt:5734.169\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:106, loss:0.00002, loss_test:0.06532, lr:8.69e-03, fs:0.81356 (r=0.727,p=0.923),  time:54.088, tt:5787.444\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:107, loss:0.00002, loss_test:0.06449, lr:8.60e-03, fs:0.82873 (r=0.758,p=0.915),  time:54.111, tt:5843.996\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:108, loss:0.00001, loss_test:0.06308, lr:8.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:54.119, tt:5899.014\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:109, loss:0.00002, loss_test:0.06460, lr:8.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:54.120, tt:5953.169\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:110, loss:0.00002, loss_test:0.06512, lr:8.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:54.125, tt:6007.824\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:111, loss:0.00002, loss_test:0.06458, lr:8.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:54.129, tt:6062.435\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:112, loss:0.00001, loss_test:0.06241, lr:8.51e-03, fs:0.83060 (r=0.768,p=0.905),  time:54.123, tt:6115.896\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:113, loss:0.00001, loss_test:0.06447, lr:8.51e-03, fs:0.83799 (r=0.758,p=0.938),  time:54.115, tt:6169.063\n",
      "##########Best model found so far##########\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:114, loss:0.00001, loss_test:0.06442, lr:8.51e-03, fs:0.82873 (r=0.758,p=0.915),  time:54.110, tt:6222.637\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:115, loss:0.00001, loss_test:0.06387, lr:8.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:54.112, tt:6276.984\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:116, loss:0.00001, loss_test:0.06348, lr:8.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:54.120, tt:6331.999\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:117, loss:0.00001, loss_test:0.06478, lr:8.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:54.118, tt:6385.947\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:118, loss:0.00001, loss_test:0.06753, lr:8.51e-03, fs:0.80925 (r=0.707,p=0.946),  time:54.111, tt:6439.150\n",
      "1029\n",
      "1038\n",
      "597\n",
      "Ep:119, loss:0.00001, loss_test:0.06316, lr:8.51e-03, fs:0.81768 (r=0.747,p=0.902),  time:54.087, tt:6490.457\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:0, loss:0.00032, loss_test:0.09075, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:49.273, tt:49.273\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:1, loss:0.00029, loss_test:0.08616, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:42.658, tt:85.316\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:2, loss:0.00023, loss_test:0.09636, lr:1.00e-02, fs:0.61084 (r=0.626,p=0.596),  time:44.581, tt:133.742\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:3, loss:0.00021, loss_test:0.09050, lr:1.00e-02, fs:0.67606 (r=0.727,p=0.632),  time:46.787, tt:187.149\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:4, loss:0.00020, loss_test:0.08518, lr:1.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:48.313, tt:241.565\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:5, loss:0.00019, loss_test:0.09013, lr:1.00e-02, fs:0.69000 (r=0.697,p=0.683),  time:49.177, tt:295.062\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:6, loss:0.00019, loss_test:0.08506, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:49.927, tt:349.490\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:7, loss:0.00018, loss_test:0.08407, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:50.373, tt:402.982\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:8, loss:0.00017, loss_test:0.08642, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:50.774, tt:456.965\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:9, loss:0.00017, loss_test:0.07990, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:51.140, tt:511.404\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:10, loss:0.00016, loss_test:0.08104, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:51.417, tt:565.587\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:11, loss:0.00016, loss_test:0.07989, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:51.539, tt:618.465\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:12, loss:0.00015, loss_test:0.07576, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:51.714, tt:672.282\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:13, loss:0.00015, loss_test:0.08014, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:51.987, tt:727.813\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:14, loss:0.00014, loss_test:0.07687, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:52.172, tt:782.573\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:15, loss:0.00014, loss_test:0.07618, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:52.262, tt:836.186\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:16, loss:0.00014, loss_test:0.07899, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:52.276, tt:888.690\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:17, loss:0.00013, loss_test:0.07466, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:52.466, tt:944.390\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:18, loss:0.00013, loss_test:0.07497, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:52.587, tt:999.146\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:19, loss:0.00013, loss_test:0.07708, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:52.633, tt:1052.653\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:20, loss:0.00012, loss_test:0.07363, lr:1.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:52.791, tt:1108.608\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:21, loss:0.00012, loss_test:0.07464, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:52.943, tt:1164.747\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:22, loss:0.00012, loss_test:0.07505, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:53.208, tt:1223.785\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:23, loss:0.00012, loss_test:0.07358, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:53.419, tt:1282.066\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:24, loss:0.00011, loss_test:0.07434, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:53.715, tt:1342.869\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:25, loss:0.00011, loss_test:0.07154, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:53.959, tt:1402.943\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:26, loss:0.00010, loss_test:0.07325, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:54.244, tt:1464.589\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:27, loss:0.00010, loss_test:0.07268, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:54.353, tt:1521.898\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:28, loss:0.00010, loss_test:0.07205, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:54.421, tt:1578.202\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:29, loss:0.00010, loss_test:0.06929, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:54.457, tt:1633.712\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:30, loss:0.00009, loss_test:0.07138, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:54.408, tt:1686.646\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:31, loss:0.00009, loss_test:0.07059, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:54.445, tt:1742.242\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:32, loss:0.00009, loss_test:0.07117, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:54.658, tt:1803.711\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:33, loss:0.00009, loss_test:0.06969, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:54.843, tt:1864.671\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:34, loss:0.00009, loss_test:0.07296, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:55.027, tt:1925.960\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:35, loss:0.00008, loss_test:0.06736, lr:1.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:55.174, tt:1986.271\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:36, loss:0.00008, loss_test:0.07379, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:55.368, tt:2048.609\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:37, loss:0.00008, loss_test:0.06808, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:55.369, tt:2104.007\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:38, loss:0.00008, loss_test:0.07360, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:55.386, tt:2160.043\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:39, loss:0.00007, loss_test:0.06577, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:55.435, tt:2217.382\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:40, loss:0.00007, loss_test:0.07488, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:55.454, tt:2273.626\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:41, loss:0.00007, loss_test:0.06563, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:55.548, tt:2333.036\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:42, loss:0.00007, loss_test:0.07351, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:55.646, tt:2392.787\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:43, loss:0.00007, loss_test:0.06618, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:55.729, tt:2452.078\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:44, loss:0.00006, loss_test:0.07102, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:55.825, tt:2512.110\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:45, loss:0.00006, loss_test:0.06811, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:55.967, tt:2574.503\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:46, loss:0.00006, loss_test:0.06954, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:56.026, tt:2633.222\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:47, loss:0.00006, loss_test:0.06878, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:56.035, tt:2689.677\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:48, loss:0.00006, loss_test:0.06805, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:56.035, tt:2745.697\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:49, loss:0.00006, loss_test:0.07002, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:55.999, tt:2799.968\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:50, loss:0.00006, loss_test:0.06904, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:56.020, tt:2857.019\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:51, loss:0.00005, loss_test:0.07046, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:56.071, tt:2915.714\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:52, loss:0.00005, loss_test:0.06836, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:56.153, tt:2976.130\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:53, loss:0.00005, loss_test:0.06695, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:56.249, tt:3037.442\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:54, loss:0.00005, loss_test:0.07000, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:56.298, tt:3096.377\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:55, loss:0.00005, loss_test:0.06713, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:56.371, tt:3156.800\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:56, loss:0.00005, loss_test:0.07148, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:56.422, tt:3216.032\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:57, loss:0.00005, loss_test:0.06597, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:56.373, tt:3269.631\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:58, loss:0.00004, loss_test:0.07186, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:56.366, tt:3325.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:59, loss:0.00004, loss_test:0.06454, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:56.343, tt:3380.567\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:60, loss:0.00004, loss_test:0.07048, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:56.339, tt:3436.687\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:61, loss:0.00004, loss_test:0.06606, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:56.334, tt:3492.682\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:62, loss:0.00004, loss_test:0.06800, lr:1.00e-02, fs:0.89855 (r=0.939,p=0.861),  time:56.380, tt:3551.967\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:63, loss:0.00004, loss_test:0.06599, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:56.464, tt:3613.676\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:64, loss:0.00004, loss_test:0.06634, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:56.533, tt:3674.623\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:65, loss:0.00004, loss_test:0.06782, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:56.578, tt:3734.175\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:66, loss:0.00004, loss_test:0.06493, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:56.641, tt:3794.963\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:67, loss:0.00003, loss_test:0.06605, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:56.630, tt:3850.847\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:68, loss:0.00004, loss_test:0.06747, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:56.606, tt:3905.807\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:69, loss:0.00003, loss_test:0.06349, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:56.580, tt:3960.634\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:70, loss:0.00003, loss_test:0.06705, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:56.545, tt:4014.705\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:71, loss:0.00003, loss_test:0.06638, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:56.519, tt:4069.387\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:72, loss:0.00003, loss_test:0.06662, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:56.557, tt:4128.678\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:73, loss:0.00003, loss_test:0.06801, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:56.558, tt:4185.320\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:74, loss:0.00003, loss_test:0.06717, lr:9.90e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.604, tt:4245.315\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:75, loss:0.00003, loss_test:0.06918, lr:9.80e-03, fs:0.89655 (r=0.919,p=0.875),  time:56.651, tt:4305.438\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:76, loss:0.00003, loss_test:0.06533, lr:9.70e-03, fs:0.87204 (r=0.929,p=0.821),  time:56.692, tt:4365.289\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:77, loss:0.00003, loss_test:0.06780, lr:9.61e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.702, tt:4422.764\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:78, loss:0.00003, loss_test:0.06501, lr:9.51e-03, fs:0.88462 (r=0.929,p=0.844),  time:56.686, tt:4478.215\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:79, loss:0.00003, loss_test:0.06838, lr:9.41e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.659, tt:4532.690\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:80, loss:0.00003, loss_test:0.06687, lr:9.41e-03, fs:0.88462 (r=0.929,p=0.844),  time:56.639, tt:4587.759\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:81, loss:0.00003, loss_test:0.06748, lr:9.41e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.650, tt:4645.330\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:82, loss:0.00003, loss_test:0.06520, lr:9.41e-03, fs:0.87619 (r=0.929,p=0.829),  time:56.687, tt:4704.984\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:83, loss:0.00003, loss_test:0.06839, lr:9.41e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.723, tt:4764.751\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:84, loss:0.00002, loss_test:0.06530, lr:9.41e-03, fs:0.87204 (r=0.929,p=0.821),  time:56.741, tt:4822.948\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:85, loss:0.00002, loss_test:0.06837, lr:9.41e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.782, tt:4883.255\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:86, loss:0.00002, loss_test:0.06772, lr:9.41e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.800, tt:4941.630\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:87, loss:0.00002, loss_test:0.06725, lr:9.41e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.767, tt:4995.472\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:88, loss:0.00002, loss_test:0.06665, lr:9.41e-03, fs:0.89320 (r=0.929,p=0.860),  time:56.761, tt:5051.719\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:89, loss:0.00002, loss_test:0.06790, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.737, tt:5106.298\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:90, loss:0.00002, loss_test:0.06670, lr:9.41e-03, fs:0.88889 (r=0.929,p=0.852),  time:56.696, tt:5159.329\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:91, loss:0.00002, loss_test:0.06765, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.690, tt:5215.486\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:92, loss:0.00002, loss_test:0.06744, lr:9.41e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.728, tt:5275.670\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:93, loss:0.00002, loss_test:0.06934, lr:9.41e-03, fs:0.92000 (r=0.929,p=0.911),  time:56.760, tt:5335.465\n",
      "##########Best model found so far##########\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:94, loss:0.00002, loss_test:0.06692, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.797, tt:5395.726\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:95, loss:0.00002, loss_test:0.06793, lr:9.41e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.834, tt:5456.049\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:96, loss:0.00002, loss_test:0.06733, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.855, tt:5514.907\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:97, loss:0.00002, loss_test:0.06701, lr:9.41e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.825, tt:5568.859\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:98, loss:0.00002, loss_test:0.06881, lr:9.41e-03, fs:0.91542 (r=0.929,p=0.902),  time:56.803, tt:5623.454\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:99, loss:0.00002, loss_test:0.06749, lr:9.41e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.788, tt:5678.789\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:102, loss:0.00002, loss_test:0.06761, lr:9.41e-03, fs:0.91542 (r=0.929,p=0.902),  time:56.789, tt:5849.239\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:103, loss:0.00002, loss_test:0.06674, lr:9.41e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.816, tt:5908.835\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:104, loss:0.00002, loss_test:0.06874, lr:9.41e-03, fs:0.91542 (r=0.929,p=0.902),  time:56.839, tt:5968.118\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:105, loss:0.00002, loss_test:0.06702, lr:9.32e-03, fs:0.89756 (r=0.929,p=0.868),  time:56.872, tt:6028.381\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:106, loss:0.00002, loss_test:0.06698, lr:9.23e-03, fs:0.90196 (r=0.929,p=0.876),  time:56.885, tt:6086.691\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:107, loss:0.00002, loss_test:0.06779, lr:9.14e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.873, tt:6142.316\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:108, loss:0.00001, loss_test:0.06770, lr:9.04e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.846, tt:6196.235\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:109, loss:0.00002, loss_test:0.06819, lr:8.95e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.855, tt:6254.017\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:110, loss:0.00001, loss_test:0.06747, lr:8.86e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.856, tt:6311.032\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:111, loss:0.00001, loss_test:0.06856, lr:8.78e-03, fs:0.91542 (r=0.929,p=0.902),  time:56.874, tt:6369.915\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:112, loss:0.00001, loss_test:0.06870, lr:8.69e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.893, tt:6428.860\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:113, loss:0.00001, loss_test:0.06833, lr:8.60e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.898, tt:6486.384\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:114, loss:0.00001, loss_test:0.06956, lr:8.51e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.933, tt:6547.247\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:115, loss:0.00001, loss_test:0.06891, lr:8.43e-03, fs:0.91089 (r=0.929,p=0.893),  time:56.977, tt:6609.369\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:116, loss:0.00001, loss_test:0.06817, lr:8.35e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.990, tt:6667.856\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:117, loss:0.00001, loss_test:0.07076, lr:8.26e-03, fs:0.92000 (r=0.929,p=0.911),  time:56.984, tt:6724.148\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:118, loss:0.00001, loss_test:0.06875, lr:8.18e-03, fs:0.90640 (r=0.929,p=0.885),  time:56.967, tt:6779.023\n",
      "1026\n",
      "1050\n",
      "588\n",
      "Ep:119, loss:0.00001, loss_test:0.07012, lr:8.10e-03, fs:0.92000 (r=0.929,p=0.911),  time:56.951, tt:6834.138\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 17766 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:0, loss:0.00032, loss_test:0.08930, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:53.798, tt:53.798\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:1, loss:0.00028, loss_test:0.08243, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:49.944, tt:99.888\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:2, loss:0.00023, loss_test:0.08652, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:52.335, tt:157.004\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:3, loss:0.00021, loss_test:0.08327, lr:1.00e-02, fs:0.68696 (r=0.798,p=0.603),  time:53.878, tt:215.513\n",
      "##########Best model found so far##########\n",
      "1032\n",
      "1026\n",
      "606\n",
      "Ep:4, loss:0.00020, loss_test:0.07864, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:55.066, tt:275.332\n",
      "1032\n",
      "1026\n",
      "606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9884dd7af360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.8+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations, nsample)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#splits1\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.8+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 20\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14572, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.285, tt:22.285\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14413, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.966, tt:57.933\n",
      "Ep:2, loss:0.00054, loss_test:0.14053, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:36.041, tt:108.123\n",
      "Ep:3, loss:0.00050, loss_test:0.13487, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:42.168, tt:168.673\n",
      "Ep:4, loss:0.00045, loss_test:0.14143, lr:1.00e-02, fs:0.51852 (r=0.495,p=0.544),  time:45.372, tt:226.860\n",
      "Ep:5, loss:0.00043, loss_test:0.12994, lr:1.00e-02, fs:0.62500 (r=0.707,p=0.560),  time:47.173, tt:283.038\n",
      "Ep:6, loss:0.00042, loss_test:0.12787, lr:1.00e-02, fs:0.62559 (r=0.667,p=0.589),  time:48.780, tt:341.461\n",
      "Ep:7, loss:0.00039, loss_test:0.12647, lr:1.00e-02, fs:0.62944 (r=0.626,p=0.633),  time:50.075, tt:400.600\n",
      "Ep:8, loss:0.00037, loss_test:0.11928, lr:1.00e-02, fs:0.66019 (r=0.687,p=0.636),  time:51.123, tt:460.110\n",
      "Ep:9, loss:0.00036, loss_test:0.11633, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:52.017, tt:520.165\n",
      "Ep:10, loss:0.00034, loss_test:0.11147, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:52.734, tt:580.072\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.10991, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:53.340, tt:640.086\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.10885, lr:1.00e-02, fs:0.69697 (r=0.697,p=0.697),  time:53.865, tt:700.244\n",
      "Ep:13, loss:0.00030, loss_test:0.10793, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:54.225, tt:759.144\n",
      "Ep:14, loss:0.00029, loss_test:0.10804, lr:1.00e-02, fs:0.62703 (r=0.586,p=0.674),  time:54.439, tt:816.586\n",
      "Ep:15, loss:0.00028, loss_test:0.10544, lr:1.00e-02, fs:0.67368 (r=0.646,p=0.703),  time:54.634, tt:874.149\n",
      "Ep:16, loss:0.00027, loss_test:0.10749, lr:1.00e-02, fs:0.60335 (r=0.545,p=0.675),  time:55.089, tt:936.517\n",
      "Ep:17, loss:0.00026, loss_test:0.10525, lr:1.00e-02, fs:0.66310 (r=0.626,p=0.705),  time:55.490, tt:998.826\n",
      "Ep:18, loss:0.00025, loss_test:0.10613, lr:1.00e-02, fs:0.61364 (r=0.545,p=0.701),  time:55.834, tt:1060.847\n",
      "Ep:19, loss:0.00024, loss_test:0.10547, lr:1.00e-02, fs:0.63333 (r=0.576,p=0.704),  time:56.047, tt:1120.938\n",
      "Ep:20, loss:0.00023, loss_test:0.10505, lr:1.00e-02, fs:0.63636 (r=0.566,p=0.727),  time:56.430, tt:1185.029\n",
      "Ep:21, loss:0.00022, loss_test:0.10622, lr:1.00e-02, fs:0.62353 (r=0.535,p=0.746),  time:56.609, tt:1245.388\n",
      "Ep:22, loss:0.00021, loss_test:0.10288, lr:1.00e-02, fs:0.64000 (r=0.566,p=0.737),  time:56.739, tt:1304.994\n",
      "Ep:23, loss:0.00020, loss_test:0.10459, lr:9.90e-03, fs:0.62791 (r=0.545,p=0.740),  time:56.779, tt:1362.702\n",
      "Ep:24, loss:0.00019, loss_test:0.10319, lr:9.80e-03, fs:0.63158 (r=0.545,p=0.750),  time:56.932, tt:1423.304\n",
      "Ep:25, loss:0.00018, loss_test:0.10267, lr:9.70e-03, fs:0.62722 (r=0.535,p=0.757),  time:57.091, tt:1484.372\n",
      "Ep:26, loss:0.00017, loss_test:0.10382, lr:9.61e-03, fs:0.63473 (r=0.535,p=0.779),  time:57.192, tt:1544.187\n",
      "Ep:27, loss:0.00016, loss_test:0.10531, lr:9.51e-03, fs:0.62651 (r=0.525,p=0.776),  time:57.350, tt:1605.787\n",
      "Ep:28, loss:0.00015, loss_test:0.10136, lr:9.41e-03, fs:0.64327 (r=0.556,p=0.764),  time:57.490, tt:1667.215\n",
      "Ep:29, loss:0.00015, loss_test:0.09879, lr:9.32e-03, fs:0.67045 (r=0.596,p=0.766),  time:57.609, tt:1728.273\n",
      "Ep:30, loss:0.00014, loss_test:0.10415, lr:9.23e-03, fs:0.62112 (r=0.505,p=0.806),  time:57.726, tt:1789.501\n",
      "Ep:31, loss:0.00013, loss_test:0.10012, lr:9.14e-03, fs:0.67836 (r=0.586,p=0.806),  time:57.818, tt:1850.179\n",
      "Ep:32, loss:0.00012, loss_test:0.09883, lr:9.04e-03, fs:0.67066 (r=0.566,p=0.824),  time:57.925, tt:1911.531\n",
      "Ep:33, loss:0.00012, loss_test:0.10322, lr:8.95e-03, fs:0.66667 (r=0.556,p=0.833),  time:58.063, tt:1974.134\n",
      "Ep:34, loss:0.00011, loss_test:0.09753, lr:8.86e-03, fs:0.70238 (r=0.596,p=0.855),  time:58.106, tt:2033.694\n",
      "Ep:35, loss:0.00011, loss_test:0.09909, lr:8.78e-03, fs:0.65854 (r=0.545,p=0.831),  time:58.222, tt:2096.002\n",
      "Ep:36, loss:0.00011, loss_test:0.09920, lr:8.69e-03, fs:0.64596 (r=0.525,p=0.839),  time:58.292, tt:2156.813\n",
      "Ep:37, loss:0.00010, loss_test:0.10048, lr:8.60e-03, fs:0.69461 (r=0.586,p=0.853),  time:58.364, tt:2217.820\n",
      "Ep:38, loss:0.00010, loss_test:0.09929, lr:8.51e-03, fs:0.74576 (r=0.667,p=0.846),  time:58.435, tt:2278.976\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.10325, lr:8.51e-03, fs:0.70732 (r=0.586,p=0.892),  time:58.534, tt:2341.376\n",
      "Ep:40, loss:0.00009, loss_test:0.09920, lr:8.51e-03, fs:0.73810 (r=0.626,p=0.899),  time:58.732, tt:2408.004\n",
      "Ep:41, loss:0.00009, loss_test:0.10122, lr:8.51e-03, fs:0.66258 (r=0.545,p=0.844),  time:58.798, tt:2469.522\n",
      "Ep:42, loss:0.00009, loss_test:0.09932, lr:8.51e-03, fs:0.66250 (r=0.535,p=0.869),  time:58.757, tt:2526.560\n",
      "Ep:43, loss:0.00008, loss_test:0.09795, lr:8.51e-03, fs:0.68293 (r=0.566,p=0.862),  time:58.700, tt:2582.801\n",
      "Ep:44, loss:0.00008, loss_test:0.10140, lr:8.51e-03, fs:0.72619 (r=0.616,p=0.884),  time:58.687, tt:2640.936\n",
      "Ep:45, loss:0.00008, loss_test:0.10660, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:58.786, tt:2704.156\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.10326, lr:8.51e-03, fs:0.76190 (r=0.646,p=0.928),  time:58.736, tt:2760.580\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.09799, lr:8.51e-03, fs:0.71856 (r=0.606,p=0.882),  time:58.745, tt:2819.781\n",
      "Ep:48, loss:0.00007, loss_test:0.10419, lr:8.51e-03, fs:0.67089 (r=0.535,p=0.898),  time:58.727, tt:2877.616\n",
      "Ep:49, loss:0.00007, loss_test:0.10215, lr:8.51e-03, fs:0.74118 (r=0.636,p=0.887),  time:58.692, tt:2934.587\n",
      "Ep:50, loss:0.00007, loss_test:0.10472, lr:8.51e-03, fs:0.71166 (r=0.586,p=0.906),  time:58.691, tt:2993.226\n",
      "Ep:51, loss:0.00006, loss_test:0.10506, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:58.692, tt:3051.986\n",
      "Ep:52, loss:0.00006, loss_test:0.10139, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:58.705, tt:3111.374\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.10712, lr:8.51e-03, fs:0.70440 (r=0.566,p=0.933),  time:58.741, tt:3172.013\n",
      "Ep:54, loss:0.00006, loss_test:0.10361, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:58.784, tt:3233.099\n",
      "Ep:55, loss:0.00006, loss_test:0.10241, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:58.772, tt:3291.225\n",
      "Ep:56, loss:0.00005, loss_test:0.10470, lr:8.51e-03, fs:0.70807 (r=0.576,p=0.919),  time:58.803, tt:3351.744\n",
      "Ep:57, loss:0.00005, loss_test:0.10057, lr:8.51e-03, fs:0.73939 (r=0.616,p=0.924),  time:58.917, tt:3417.168\n",
      "Ep:58, loss:0.00005, loss_test:0.10247, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:58.955, tt:3478.339\n",
      "Ep:59, loss:0.00005, loss_test:0.10412, lr:8.51e-03, fs:0.76190 (r=0.646,p=0.928),  time:59.025, tt:3541.472\n",
      "Ep:60, loss:0.00005, loss_test:0.10522, lr:8.51e-03, fs:0.76190 (r=0.646,p=0.928),  time:59.126, tt:3606.655\n",
      "Ep:61, loss:0.00005, loss_test:0.10317, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:59.203, tt:3670.584\n",
      "Ep:62, loss:0.00005, loss_test:0.10228, lr:8.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.256, tt:3733.129\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.10414, lr:8.51e-03, fs:0.67949 (r=0.535,p=0.930),  time:59.318, tt:3796.373\n",
      "Ep:64, loss:0.00004, loss_test:0.10581, lr:8.51e-03, fs:0.75309 (r=0.616,p=0.968),  time:59.414, tt:3861.924\n",
      "Ep:65, loss:0.00004, loss_test:0.10629, lr:8.51e-03, fs:0.78824 (r=0.677,p=0.944),  time:59.439, tt:3922.975\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00004, loss_test:0.10522, lr:8.51e-03, fs:0.75904 (r=0.636,p=0.940),  time:59.425, tt:3981.479\n",
      "Ep:67, loss:0.00004, loss_test:0.10699, lr:8.51e-03, fs:0.77108 (r=0.646,p=0.955),  time:59.413, tt:4040.102\n",
      "Ep:68, loss:0.00004, loss_test:0.10265, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:59.386, tt:4097.633\n",
      "Ep:69, loss:0.00004, loss_test:0.10678, lr:8.51e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.419, tt:4159.336\n",
      "Ep:70, loss:0.00004, loss_test:0.10503, lr:8.51e-03, fs:0.77381 (r=0.657,p=0.942),  time:59.440, tt:4220.273\n",
      "Ep:71, loss:0.00004, loss_test:0.10511, lr:8.51e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.474, tt:4282.104\n",
      "Ep:72, loss:0.00004, loss_test:0.10325, lr:8.51e-03, fs:0.74534 (r=0.606,p=0.968),  time:59.502, tt:4343.631\n",
      "Ep:73, loss:0.00003, loss_test:0.10238, lr:8.51e-03, fs:0.79042 (r=0.667,p=0.971),  time:59.541, tt:4406.042\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00003, loss_test:0.10710, lr:8.51e-03, fs:0.76829 (r=0.636,p=0.969),  time:59.570, tt:4467.759\n",
      "Ep:75, loss:0.00003, loss_test:0.11134, lr:8.51e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.575, tt:4527.680\n",
      "Ep:76, loss:0.00003, loss_test:0.10538, lr:8.51e-03, fs:0.77844 (r=0.657,p=0.956),  time:59.580, tt:4587.692\n",
      "Ep:77, loss:0.00003, loss_test:0.10526, lr:8.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.565, tt:4646.087\n",
      "Ep:78, loss:0.00003, loss_test:0.10943, lr:8.51e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.588, tt:4707.415\n",
      "Ep:79, loss:0.00003, loss_test:0.10944, lr:8.51e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.594, tt:4767.518\n",
      "Ep:80, loss:0.00003, loss_test:0.10236, lr:8.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:59.577, tt:4825.745\n",
      "Ep:81, loss:0.00003, loss_test:0.10724, lr:8.51e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.560, tt:4883.899\n",
      "Ep:82, loss:0.00003, loss_test:0.10635, lr:8.51e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.582, tt:4945.298\n",
      "Ep:83, loss:0.00003, loss_test:0.10589, lr:8.51e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.578, tt:5004.573\n",
      "Ep:84, loss:0.00003, loss_test:0.10649, lr:8.51e-03, fs:0.74534 (r=0.606,p=0.968),  time:59.598, tt:5065.825\n",
      "Ep:85, loss:0.00003, loss_test:0.10706, lr:8.43e-03, fs:0.70513 (r=0.556,p=0.965),  time:59.612, tt:5126.648\n",
      "Ep:86, loss:0.00003, loss_test:0.10797, lr:8.35e-03, fs:0.74534 (r=0.606,p=0.968),  time:59.627, tt:5187.562\n",
      "Ep:87, loss:0.00003, loss_test:0.10743, lr:8.26e-03, fs:0.69677 (r=0.545,p=0.964),  time:59.624, tt:5246.877\n",
      "Ep:88, loss:0.00002, loss_test:0.10546, lr:8.18e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.659, tt:5309.668\n",
      "Ep:89, loss:0.00002, loss_test:0.10621, lr:8.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:59.695, tt:5372.521\n",
      "Ep:90, loss:0.00002, loss_test:0.10903, lr:8.02e-03, fs:0.72956 (r=0.586,p=0.967),  time:59.699, tt:5432.629\n",
      "Ep:91, loss:0.00002, loss_test:0.10693, lr:7.94e-03, fs:0.71338 (r=0.566,p=0.966),  time:59.723, tt:5494.544\n",
      "Ep:92, loss:0.00002, loss_test:0.10586, lr:7.86e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.734, tt:5555.292\n",
      "Ep:93, loss:0.00002, loss_test:0.10930, lr:7.78e-03, fs:0.68831 (r=0.535,p=0.964),  time:59.770, tt:5618.364\n",
      "Ep:94, loss:0.00002, loss_test:0.10772, lr:7.70e-03, fs:0.73750 (r=0.596,p=0.967),  time:59.792, tt:5680.279\n",
      "Ep:95, loss:0.00002, loss_test:0.11519, lr:7.62e-03, fs:0.64430 (r=0.485,p=0.960),  time:59.794, tt:5740.180\n",
      "Ep:96, loss:0.00002, loss_test:0.10783, lr:7.55e-03, fs:0.68387 (r=0.535,p=0.946),  time:59.804, tt:5800.992\n",
      "Ep:97, loss:0.00002, loss_test:0.10803, lr:7.47e-03, fs:0.67974 (r=0.525,p=0.963),  time:59.795, tt:5859.867\n",
      "Ep:98, loss:0.00002, loss_test:0.11175, lr:7.40e-03, fs:0.67105 (r=0.515,p=0.962),  time:59.807, tt:5920.890\n",
      "Ep:99, loss:0.00002, loss_test:0.10886, lr:7.32e-03, fs:0.66667 (r=0.515,p=0.944),  time:59.815, tt:5981.514\n",
      "Ep:100, loss:0.00002, loss_test:0.10981, lr:7.25e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.816, tt:6041.465\n",
      "Ep:101, loss:0.00002, loss_test:0.10906, lr:7.18e-03, fs:0.66667 (r=0.515,p=0.944),  time:59.812, tt:6100.857\n",
      "Ep:102, loss:0.00002, loss_test:0.11241, lr:7.11e-03, fs:0.66225 (r=0.505,p=0.962),  time:59.814, tt:6160.821\n",
      "Ep:103, loss:0.00002, loss_test:0.11161, lr:7.03e-03, fs:0.64430 (r=0.485,p=0.960),  time:59.848, tt:6224.197\n",
      "Ep:104, loss:0.00002, loss_test:0.10804, lr:6.96e-03, fs:0.66667 (r=0.515,p=0.944),  time:59.865, tt:6285.776\n",
      "Ep:105, loss:0.00002, loss_test:0.11181, lr:6.89e-03, fs:0.64430 (r=0.485,p=0.960),  time:59.902, tt:6349.614\n",
      "Ep:106, loss:0.00002, loss_test:0.11450, lr:6.83e-03, fs:0.63514 (r=0.475,p=0.959),  time:59.926, tt:6412.035\n",
      "Ep:107, loss:0.00002, loss_test:0.11111, lr:6.76e-03, fs:0.64430 (r=0.485,p=0.960),  time:59.948, tt:6474.373\n",
      "Ep:108, loss:0.00002, loss_test:0.11227, lr:6.69e-03, fs:0.64430 (r=0.485,p=0.960),  time:59.962, tt:6535.865\n",
      "Ep:109, loss:0.00002, loss_test:0.11051, lr:6.62e-03, fs:0.64000 (r=0.485,p=0.941),  time:59.970, tt:6596.737\n",
      "Ep:110, loss:0.00002, loss_test:0.10998, lr:6.56e-03, fs:0.65333 (r=0.495,p=0.961),  time:59.967, tt:6656.307\n",
      "Ep:111, loss:0.00002, loss_test:0.11437, lr:6.49e-03, fs:0.63514 (r=0.475,p=0.959),  time:59.974, tt:6717.054\n",
      "Ep:112, loss:0.00002, loss_test:0.11121, lr:6.43e-03, fs:0.63087 (r=0.475,p=0.940),  time:59.983, tt:6778.028\n",
      "Ep:113, loss:0.00002, loss_test:0.11288, lr:6.36e-03, fs:0.63514 (r=0.475,p=0.959),  time:59.986, tt:6838.399\n",
      "Ep:114, loss:0.00001, loss_test:0.11157, lr:6.30e-03, fs:0.64000 (r=0.485,p=0.941),  time:59.996, tt:6899.546\n",
      "Ep:115, loss:0.00001, loss_test:0.11273, lr:6.24e-03, fs:0.63514 (r=0.475,p=0.959),  time:60.013, tt:6961.510\n",
      "Ep:116, loss:0.00001, loss_test:0.11565, lr:6.17e-03, fs:0.62585 (r=0.465,p=0.958),  time:60.026, tt:7022.995\n",
      "Ep:117, loss:0.00001, loss_test:0.11162, lr:6.11e-03, fs:0.63087 (r=0.475,p=0.940),  time:60.041, tt:7084.799\n",
      "Ep:118, loss:0.00001, loss_test:0.11288, lr:6.05e-03, fs:0.62585 (r=0.465,p=0.958),  time:60.054, tt:7146.398\n",
      "Ep:119, loss:0.00001, loss_test:0.11380, lr:5.99e-03, fs:0.62162 (r=0.465,p=0.939),  time:60.050, tt:7205.976\n",
      "Ep:120, loss:0.00001, loss_test:0.11291, lr:5.93e-03, fs:0.62585 (r=0.465,p=0.958),  time:60.049, tt:7265.899\n",
      "Ep:121, loss:0.00001, loss_test:0.11359, lr:5.87e-03, fs:0.62585 (r=0.465,p=0.958),  time:60.070, tt:7328.587\n",
      "Ep:122, loss:0.00001, loss_test:0.11590, lr:5.81e-03, fs:0.61644 (r=0.455,p=0.957),  time:60.080, tt:7389.822\n",
      "Ep:123, loss:0.00001, loss_test:0.11340, lr:5.75e-03, fs:0.62585 (r=0.465,p=0.958),  time:60.089, tt:7451.074\n",
      "Ep:124, loss:0.00001, loss_test:0.11607, lr:5.70e-03, fs:0.61644 (r=0.455,p=0.957),  time:60.099, tt:7512.413\n",
      "Ep:125, loss:0.00001, loss_test:0.11452, lr:5.64e-03, fs:0.61644 (r=0.455,p=0.957),  time:60.112, tt:7574.073\n",
      "Ep:126, loss:0.00001, loss_test:0.11580, lr:5.58e-03, fs:0.61644 (r=0.455,p=0.957),  time:60.117, tt:7634.847\n",
      "Ep:127, loss:0.00001, loss_test:0.11428, lr:5.53e-03, fs:0.61224 (r=0.455,p=0.938),  time:60.117, tt:7695.027\n",
      "Ep:128, loss:0.00001, loss_test:0.11838, lr:5.47e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.120, tt:7755.510\n",
      "Ep:129, loss:0.00001, loss_test:0.11677, lr:5.42e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.127, tt:7816.458\n",
      "Ep:130, loss:0.00001, loss_test:0.11556, lr:5.36e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.124, tt:7876.229\n",
      "Ep:131, loss:0.00001, loss_test:0.12088, lr:5.31e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.126, tt:7936.693\n",
      "Ep:132, loss:0.00001, loss_test:0.11689, lr:5.26e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.142, tt:7998.852\n",
      "Ep:133, loss:0.00001, loss_test:0.11749, lr:5.20e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.154, tt:8060.647\n",
      "Ep:134, loss:0.00001, loss_test:0.11928, lr:5.15e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.160, tt:8121.566\n",
      "Ep:135, loss:0.00001, loss_test:0.11595, lr:5.10e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.163, tt:8182.229\n",
      "Ep:136, loss:0.00001, loss_test:0.11968, lr:5.05e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.157, tt:8241.517\n",
      "Ep:137, loss:0.00001, loss_test:0.11655, lr:5.00e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.172, tt:8303.738\n",
      "Ep:138, loss:0.00001, loss_test:0.11846, lr:4.95e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.174, tt:8364.161\n",
      "Ep:139, loss:0.00001, loss_test:0.11734, lr:4.90e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.175, tt:8424.448\n",
      "Ep:140, loss:0.00001, loss_test:0.12061, lr:4.85e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.198, tt:8487.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00001, loss_test:0.11631, lr:4.80e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.213, tt:8550.219\n",
      "Ep:142, loss:0.00001, loss_test:0.11947, lr:4.75e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.239, tt:8614.115\n",
      "Ep:143, loss:0.00001, loss_test:0.11670, lr:4.71e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.246, tt:8675.423\n",
      "Ep:144, loss:0.00001, loss_test:0.11952, lr:4.66e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.269, tt:8739.006\n",
      "Ep:145, loss:0.00001, loss_test:0.11854, lr:4.61e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.279, tt:8800.737\n",
      "Ep:146, loss:0.00001, loss_test:0.11983, lr:4.57e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.290, tt:8862.683\n",
      "Ep:147, loss:0.00001, loss_test:0.11769, lr:4.52e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.321, tt:8927.563\n",
      "Ep:148, loss:0.00001, loss_test:0.12048, lr:4.48e-03, fs:0.60690 (r=0.444,p=0.957),  time:60.340, tt:8990.626\n",
      "Ep:149, loss:0.00001, loss_test:0.11750, lr:4.43e-03, fs:0.60274 (r=0.444,p=0.936),  time:60.315, tt:9047.308\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 21\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14364, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.320, tt:59.320\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14154, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.099, tt:116.198\n",
      "Ep:2, loss:0.00055, loss_test:0.13705, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:56.344, tt:169.031\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.12677, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:58.179, tt:232.717\n",
      "Ep:4, loss:0.00046, loss_test:0.12130, lr:1.00e-02, fs:0.64186 (r=0.697,p=0.595),  time:59.194, tt:295.968\n",
      "Ep:5, loss:0.00044, loss_test:0.11572, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:60.231, tt:361.388\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.11236, lr:1.00e-02, fs:0.68376 (r=0.808,p=0.593),  time:60.737, tt:425.162\n",
      "Ep:7, loss:0.00040, loss_test:0.10925, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:60.871, tt:486.969\n",
      "Ep:8, loss:0.00038, loss_test:0.10540, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:61.197, tt:550.776\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.10161, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:61.351, tt:613.508\n",
      "Ep:10, loss:0.00035, loss_test:0.09798, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:61.363, tt:674.995\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.09592, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:61.525, tt:738.305\n",
      "Ep:12, loss:0.00032, loss_test:0.09365, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:61.764, tt:802.929\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.09131, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:61.830, tt:865.614\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.08993, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:61.981, tt:929.719\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.08906, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:62.012, tt:992.185\n",
      "Ep:16, loss:0.00027, loss_test:0.08736, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:62.160, tt:1056.720\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.08677, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:62.379, tt:1122.821\n",
      "Ep:18, loss:0.00025, loss_test:0.08519, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:62.502, tt:1187.529\n",
      "Ep:19, loss:0.00024, loss_test:0.08422, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:62.476, tt:1249.528\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.08323, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:62.554, tt:1313.642\n",
      "Ep:21, loss:0.00022, loss_test:0.08288, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:62.728, tt:1380.021\n",
      "Ep:22, loss:0.00021, loss_test:0.08204, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:62.788, tt:1444.125\n",
      "Ep:23, loss:0.00020, loss_test:0.08101, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:62.909, tt:1509.808\n",
      "Ep:24, loss:0.00019, loss_test:0.08082, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:62.934, tt:1573.340\n",
      "Ep:25, loss:0.00018, loss_test:0.07941, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:63.078, tt:1640.032\n",
      "Ep:26, loss:0.00017, loss_test:0.07951, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:63.201, tt:1706.423\n",
      "Ep:27, loss:0.00016, loss_test:0.07658, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:63.248, tt:1770.946\n",
      "Ep:28, loss:0.00015, loss_test:0.07574, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:63.264, tt:1834.660\n",
      "Ep:29, loss:0.00014, loss_test:0.07659, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:63.343, tt:1900.295\n",
      "Ep:30, loss:0.00014, loss_test:0.07376, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:63.396, tt:1965.274\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.07635, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:63.416, tt:2029.302\n",
      "Ep:32, loss:0.00012, loss_test:0.07295, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:63.459, tt:2094.157\n",
      "Ep:33, loss:0.00012, loss_test:0.07397, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:63.623, tt:2163.174\n",
      "Ep:34, loss:0.00011, loss_test:0.07452, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:63.594, tt:2225.796\n",
      "Ep:35, loss:0.00010, loss_test:0.07274, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:63.565, tt:2288.327\n",
      "Ep:36, loss:0.00010, loss_test:0.07402, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:63.617, tt:2353.822\n",
      "Ep:37, loss:0.00009, loss_test:0.07221, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:63.623, tt:2417.665\n",
      "Ep:38, loss:0.00009, loss_test:0.07296, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:63.661, tt:2482.787\n",
      "Ep:39, loss:0.00009, loss_test:0.07473, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:63.665, tt:2546.599\n",
      "Ep:40, loss:0.00008, loss_test:0.07075, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:63.708, tt:2612.034\n",
      "Ep:41, loss:0.00008, loss_test:0.07278, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:63.685, tt:2674.785\n",
      "Ep:42, loss:0.00008, loss_test:0.07203, lr:9.90e-03, fs:0.79348 (r=0.737,p=0.859),  time:63.688, tt:2738.593\n",
      "Ep:43, loss:0.00007, loss_test:0.07103, lr:9.80e-03, fs:0.81283 (r=0.768,p=0.864),  time:63.655, tt:2800.808\n",
      "Ep:44, loss:0.00007, loss_test:0.07442, lr:9.70e-03, fs:0.78889 (r=0.717,p=0.877),  time:63.657, tt:2864.543\n",
      "Ep:45, loss:0.00007, loss_test:0.07134, lr:9.61e-03, fs:0.83158 (r=0.798,p=0.868),  time:63.656, tt:2928.175\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.07243, lr:9.61e-03, fs:0.80435 (r=0.747,p=0.871),  time:63.724, tt:2995.036\n",
      "Ep:47, loss:0.00006, loss_test:0.07409, lr:9.61e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.752, tt:3060.076\n",
      "Ep:48, loss:0.00006, loss_test:0.07155, lr:9.61e-03, fs:0.81283 (r=0.768,p=0.864),  time:63.753, tt:3123.878\n",
      "Ep:49, loss:0.00006, loss_test:0.07737, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:63.776, tt:3188.801\n",
      "Ep:50, loss:0.00006, loss_test:0.07298, lr:9.61e-03, fs:0.85106 (r=0.808,p=0.899),  time:63.787, tt:3253.148\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.07679, lr:9.61e-03, fs:0.80000 (r=0.727,p=0.889),  time:63.822, tt:3318.748\n",
      "Ep:52, loss:0.00005, loss_test:0.07374, lr:9.61e-03, fs:0.81967 (r=0.758,p=0.893),  time:63.863, tt:3384.723\n",
      "Ep:53, loss:0.00005, loss_test:0.07307, lr:9.61e-03, fs:0.80663 (r=0.737,p=0.890),  time:63.881, tt:3449.562\n",
      "Ep:54, loss:0.00005, loss_test:0.07558, lr:9.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:63.876, tt:3513.153\n",
      "Ep:55, loss:0.00005, loss_test:0.07226, lr:9.61e-03, fs:0.84375 (r=0.818,p=0.871),  time:63.876, tt:3577.060\n",
      "Ep:56, loss:0.00005, loss_test:0.07477, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:63.857, tt:3639.843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00005, loss_test:0.07584, lr:9.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:63.888, tt:3705.523\n",
      "Ep:58, loss:0.00005, loss_test:0.07234, lr:9.61e-03, fs:0.82162 (r=0.768,p=0.884),  time:63.915, tt:3770.998\n",
      "Ep:59, loss:0.00004, loss_test:0.07494, lr:9.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:63.937, tt:3836.209\n",
      "Ep:60, loss:0.00004, loss_test:0.07272, lr:9.61e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.988, tt:3903.276\n",
      "Ep:61, loss:0.00004, loss_test:0.07719, lr:9.61e-03, fs:0.78857 (r=0.697,p=0.908),  time:64.024, tt:3969.508\n",
      "Ep:62, loss:0.00004, loss_test:0.07310, lr:9.51e-03, fs:0.84656 (r=0.808,p=0.889),  time:64.055, tt:4035.471\n",
      "Ep:63, loss:0.00004, loss_test:0.07434, lr:9.41e-03, fs:0.79545 (r=0.707,p=0.909),  time:64.068, tt:4100.322\n",
      "Ep:64, loss:0.00004, loss_test:0.07876, lr:9.32e-03, fs:0.79310 (r=0.697,p=0.920),  time:64.103, tt:4166.714\n",
      "Ep:65, loss:0.00004, loss_test:0.07274, lr:9.23e-03, fs:0.86458 (r=0.838,p=0.892),  time:64.124, tt:4232.194\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.07549, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.157, tt:4298.502\n",
      "Ep:67, loss:0.00004, loss_test:0.07527, lr:9.23e-03, fs:0.79310 (r=0.697,p=0.920),  time:64.167, tt:4363.329\n",
      "Ep:68, loss:0.00003, loss_test:0.07625, lr:9.23e-03, fs:0.81111 (r=0.737,p=0.901),  time:64.185, tt:4428.735\n",
      "Ep:69, loss:0.00003, loss_test:0.07569, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.208, tt:4494.552\n",
      "Ep:70, loss:0.00003, loss_test:0.07545, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.241, tt:4561.082\n",
      "Ep:71, loss:0.00003, loss_test:0.07935, lr:9.23e-03, fs:0.80000 (r=0.707,p=0.921),  time:64.207, tt:4622.894\n",
      "Ep:72, loss:0.00003, loss_test:0.07527, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.185, tt:4685.505\n",
      "Ep:73, loss:0.00003, loss_test:0.07783, lr:9.23e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.155, tt:4747.478\n",
      "Ep:74, loss:0.00003, loss_test:0.07570, lr:9.23e-03, fs:0.82222 (r=0.747,p=0.914),  time:64.152, tt:4811.413\n",
      "Ep:75, loss:0.00003, loss_test:0.07510, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.195, tt:4878.803\n",
      "Ep:76, loss:0.00003, loss_test:0.07616, lr:9.23e-03, fs:0.80899 (r=0.727,p=0.911),  time:64.176, tt:4941.572\n",
      "Ep:77, loss:0.00003, loss_test:0.07320, lr:9.14e-03, fs:0.80899 (r=0.727,p=0.911),  time:64.203, tt:5007.803\n",
      "Ep:78, loss:0.00003, loss_test:0.07549, lr:9.04e-03, fs:0.80899 (r=0.727,p=0.911),  time:64.198, tt:5071.669\n",
      "Ep:79, loss:0.00003, loss_test:0.07673, lr:8.95e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.191, tt:5135.241\n",
      "Ep:80, loss:0.00003, loss_test:0.07599, lr:8.86e-03, fs:0.80899 (r=0.727,p=0.911),  time:64.190, tt:5199.417\n",
      "Ep:81, loss:0.00003, loss_test:0.07840, lr:8.78e-03, fs:0.80226 (r=0.717,p=0.910),  time:64.209, tt:5265.139\n",
      "Ep:82, loss:0.00002, loss_test:0.07753, lr:8.69e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.214, tt:5329.726\n",
      "Ep:83, loss:0.00002, loss_test:0.07736, lr:8.60e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.228, tt:5395.174\n",
      "Ep:84, loss:0.00002, loss_test:0.07647, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.229, tt:5459.488\n",
      "Ep:85, loss:0.00002, loss_test:0.07722, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.234, tt:5524.120\n",
      "Ep:86, loss:0.00002, loss_test:0.07697, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.247, tt:5589.494\n",
      "Ep:87, loss:0.00002, loss_test:0.07732, lr:8.26e-03, fs:0.80682 (r=0.717,p=0.922),  time:64.249, tt:5653.946\n",
      "Ep:88, loss:0.00002, loss_test:0.07732, lr:8.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.251, tt:5718.369\n",
      "Ep:89, loss:0.00002, loss_test:0.07553, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.244, tt:5781.964\n",
      "Ep:90, loss:0.00002, loss_test:0.07826, lr:8.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.238, tt:5845.626\n",
      "Ep:91, loss:0.00002, loss_test:0.07754, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.230, tt:5909.170\n",
      "Ep:92, loss:0.00002, loss_test:0.07585, lr:7.86e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.233, tt:5973.672\n",
      "Ep:93, loss:0.00002, loss_test:0.07723, lr:7.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.209, tt:6035.616\n",
      "Ep:94, loss:0.00002, loss_test:0.07671, lr:7.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.202, tt:6099.199\n",
      "Ep:95, loss:0.00002, loss_test:0.07798, lr:7.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.190, tt:6162.205\n",
      "Ep:96, loss:0.00002, loss_test:0.07736, lr:7.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.192, tt:6226.633\n",
      "Ep:97, loss:0.00002, loss_test:0.07710, lr:7.47e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.193, tt:6290.920\n",
      "Ep:98, loss:0.00002, loss_test:0.07855, lr:7.40e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.183, tt:6354.128\n",
      "Ep:99, loss:0.00002, loss_test:0.07677, lr:7.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.165, tt:6416.502\n",
      "Ep:100, loss:0.00002, loss_test:0.07872, lr:7.25e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.137, tt:6477.872\n",
      "Ep:101, loss:0.00002, loss_test:0.07697, lr:7.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.136, tt:6541.893\n",
      "Ep:102, loss:0.00002, loss_test:0.07810, lr:7.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.115, tt:6603.892\n",
      "Ep:103, loss:0.00002, loss_test:0.07669, lr:7.03e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.096, tt:6666.028\n",
      "Ep:104, loss:0.00002, loss_test:0.07756, lr:6.96e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.076, tt:6728.014\n",
      "Ep:105, loss:0.00002, loss_test:0.07849, lr:6.89e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.064, tt:6790.785\n",
      "Ep:106, loss:0.00002, loss_test:0.07767, lr:6.83e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.025, tt:6850.648\n",
      "Ep:107, loss:0.00002, loss_test:0.07840, lr:6.76e-03, fs:0.81356 (r=0.727,p=0.923),  time:64.013, tt:6913.444\n",
      "Ep:108, loss:0.00002, loss_test:0.07621, lr:6.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:63.989, tt:6974.827\n",
      "Ep:109, loss:0.00001, loss_test:0.07862, lr:6.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.992, tt:7039.153\n",
      "Ep:110, loss:0.00001, loss_test:0.07761, lr:6.56e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.988, tt:7102.673\n",
      "Ep:111, loss:0.00001, loss_test:0.07933, lr:6.49e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.984, tt:7166.195\n",
      "Ep:112, loss:0.00001, loss_test:0.07752, lr:6.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.980, tt:7229.755\n",
      "Ep:113, loss:0.00001, loss_test:0.07919, lr:6.36e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.954, tt:7290.802\n",
      "Ep:114, loss:0.00001, loss_test:0.07821, lr:6.30e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.952, tt:7354.436\n",
      "Ep:115, loss:0.00001, loss_test:0.07857, lr:6.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.949, tt:7418.090\n",
      "Ep:116, loss:0.00001, loss_test:0.07908, lr:6.17e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.931, tt:7479.945\n",
      "Ep:117, loss:0.00001, loss_test:0.07854, lr:6.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.933, tt:7544.072\n",
      "Ep:118, loss:0.00001, loss_test:0.07782, lr:6.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.925, tt:7607.059\n",
      "Ep:119, loss:0.00001, loss_test:0.07783, lr:5.99e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.902, tt:7668.226\n",
      "Ep:120, loss:0.00001, loss_test:0.07908, lr:5.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.905, tt:7732.493\n",
      "Ep:121, loss:0.00001, loss_test:0.07765, lr:5.87e-03, fs:0.81356 (r=0.727,p=0.923),  time:63.907, tt:7796.637\n",
      "Ep:122, loss:0.00001, loss_test:0.07808, lr:5.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.919, tt:7861.992\n",
      "Ep:123, loss:0.00001, loss_test:0.07957, lr:5.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.904, tt:7924.154\n",
      "Ep:124, loss:0.00001, loss_test:0.07821, lr:5.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.901, tt:7987.581\n",
      "Ep:125, loss:0.00001, loss_test:0.07907, lr:5.64e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.892, tt:8050.368\n",
      "Ep:126, loss:0.00001, loss_test:0.07905, lr:5.58e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.887, tt:8113.661\n",
      "Ep:127, loss:0.00001, loss_test:0.07844, lr:5.53e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.875, tt:8176.024\n",
      "Ep:128, loss:0.00001, loss_test:0.07897, lr:5.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.870, tt:8239.211\n",
      "Ep:129, loss:0.00001, loss_test:0.07896, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.873, tt:8303.455\n",
      "Ep:130, loss:0.00001, loss_test:0.07734, lr:5.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.862, tt:8365.925\n",
      "Ep:131, loss:0.00001, loss_test:0.07994, lr:5.31e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.877, tt:8431.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.07824, lr:5.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.849, tt:8491.892\n",
      "Ep:133, loss:0.00001, loss_test:0.07885, lr:5.20e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.836, tt:8553.983\n",
      "Ep:134, loss:0.00001, loss_test:0.07894, lr:5.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.828, tt:8616.799\n",
      "Ep:135, loss:0.00001, loss_test:0.07796, lr:5.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.814, tt:8678.710\n",
      "Ep:136, loss:0.00001, loss_test:0.07926, lr:5.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.791, tt:8739.376\n",
      "Ep:137, loss:0.00001, loss_test:0.07865, lr:5.00e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.780, tt:8801.573\n",
      "Ep:138, loss:0.00001, loss_test:0.07898, lr:4.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.774, tt:8864.595\n",
      "Ep:139, loss:0.00001, loss_test:0.07921, lr:4.90e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.774, tt:8928.320\n",
      "Ep:140, loss:0.00001, loss_test:0.07916, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.751, tt:8988.828\n",
      "Ep:141, loss:0.00001, loss_test:0.07892, lr:4.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.743, tt:9051.459\n",
      "Ep:142, loss:0.00001, loss_test:0.07913, lr:4.75e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.721, tt:9112.150\n",
      "Ep:143, loss:0.00001, loss_test:0.07932, lr:4.71e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.701, tt:9172.901\n",
      "Ep:144, loss:0.00001, loss_test:0.07853, lr:4.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:63.683, tt:9233.998\n",
      "Ep:145, loss:0.00001, loss_test:0.08015, lr:4.61e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.667, tt:9295.334\n",
      "Ep:146, loss:0.00001, loss_test:0.07942, lr:4.57e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.637, tt:9354.576\n",
      "Ep:147, loss:0.00001, loss_test:0.07913, lr:4.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.613, tt:9414.786\n",
      "Ep:148, loss:0.00001, loss_test:0.07946, lr:4.48e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.585, tt:9474.113\n",
      "Ep:149, loss:0.00001, loss_test:0.07955, lr:4.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:63.567, tt:9535.073\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 22\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14361, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.576, tt:59.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14108, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.211, tt:116.422\n",
      "Ep:2, loss:0.00055, loss_test:0.13581, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:57.374, tt:172.121\n",
      "Ep:3, loss:0.00051, loss_test:0.12417, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:58.446, tt:233.784\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.11982, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:59.618, tt:298.090\n",
      "Ep:5, loss:0.00045, loss_test:0.11642, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:60.153, tt:360.917\n",
      "Ep:6, loss:0.00043, loss_test:0.11359, lr:1.00e-02, fs:0.68519 (r=0.747,p=0.632),  time:60.627, tt:424.392\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.10987, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:60.932, tt:487.454\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.10731, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:61.097, tt:549.876\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.10489, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:61.208, tt:612.082\n",
      "Ep:10, loss:0.00035, loss_test:0.10272, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:61.464, tt:676.108\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.10114, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:61.658, tt:739.894\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.10098, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:61.801, tt:803.410\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.10244, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:62.038, tt:868.537\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.10220, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:62.177, tt:932.659\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.10295, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:62.202, tt:995.224\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.10236, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:62.487, tt:1062.282\n",
      "Ep:17, loss:0.00027, loss_test:0.10318, lr:1.00e-02, fs:0.78351 (r=0.768,p=0.800),  time:62.582, tt:1126.481\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00025, loss_test:0.10123, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:62.752, tt:1192.286\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.10221, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:62.839, tt:1256.782\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.10173, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:62.895, tt:1320.795\n",
      "Ep:21, loss:0.00022, loss_test:0.10074, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:62.880, tt:1383.352\n",
      "Ep:22, loss:0.00021, loss_test:0.10027, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:62.768, tt:1443.655\n",
      "Ep:23, loss:0.00020, loss_test:0.10053, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:62.751, tt:1506.019\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.09684, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:62.844, tt:1571.101\n",
      "Ep:25, loss:0.00019, loss_test:0.09679, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:62.858, tt:1634.301\n",
      "Ep:26, loss:0.00018, loss_test:0.09475, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:62.854, tt:1697.049\n",
      "Ep:27, loss:0.00017, loss_test:0.09658, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:62.811, tt:1758.713\n",
      "Ep:28, loss:0.00016, loss_test:0.09243, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:62.789, tt:1820.889\n",
      "Ep:29, loss:0.00015, loss_test:0.09396, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:62.747, tt:1882.403\n",
      "Ep:30, loss:0.00015, loss_test:0.09355, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:62.754, tt:1945.378\n",
      "Ep:31, loss:0.00014, loss_test:0.09368, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:62.747, tt:2007.906\n",
      "Ep:32, loss:0.00013, loss_test:0.09061, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:62.748, tt:2070.698\n",
      "Ep:33, loss:0.00012, loss_test:0.09220, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:62.803, tt:2135.292\n",
      "Ep:34, loss:0.00011, loss_test:0.09012, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:62.846, tt:2199.619\n",
      "Ep:35, loss:0.00011, loss_test:0.08676, lr:9.90e-03, fs:0.79096 (r=0.707,p=0.897),  time:62.903, tt:2264.522\n",
      "Ep:36, loss:0.00011, loss_test:0.08783, lr:9.80e-03, fs:0.78857 (r=0.697,p=0.908),  time:62.962, tt:2329.578\n",
      "Ep:37, loss:0.00010, loss_test:0.09024, lr:9.70e-03, fs:0.77907 (r=0.677,p=0.918),  time:63.019, tt:2394.705\n",
      "Ep:38, loss:0.00009, loss_test:0.08792, lr:9.61e-03, fs:0.77457 (r=0.677,p=0.905),  time:63.101, tt:2460.921\n",
      "Ep:39, loss:0.00009, loss_test:0.08252, lr:9.51e-03, fs:0.80663 (r=0.737,p=0.890),  time:63.146, tt:2525.849\n",
      "Ep:40, loss:0.00009, loss_test:0.08728, lr:9.41e-03, fs:0.77907 (r=0.677,p=0.918),  time:63.173, tt:2590.108\n",
      "Ep:41, loss:0.00008, loss_test:0.08652, lr:9.32e-03, fs:0.77907 (r=0.677,p=0.918),  time:63.224, tt:2655.423\n",
      "Ep:42, loss:0.00008, loss_test:0.08276, lr:9.23e-03, fs:0.79775 (r=0.717,p=0.899),  time:63.259, tt:2720.122\n",
      "Ep:43, loss:0.00008, loss_test:0.08598, lr:9.14e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.259, tt:2783.397\n",
      "Ep:44, loss:0.00007, loss_test:0.08823, lr:9.04e-03, fs:0.76471 (r=0.657,p=0.915),  time:63.305, tt:2848.740\n",
      "Ep:45, loss:0.00007, loss_test:0.08726, lr:8.95e-03, fs:0.77907 (r=0.677,p=0.918),  time:63.343, tt:2913.772\n",
      "Ep:46, loss:0.00007, loss_test:0.08507, lr:8.86e-03, fs:0.78613 (r=0.687,p=0.919),  time:63.370, tt:2978.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00007, loss_test:0.08477, lr:8.78e-03, fs:0.80663 (r=0.737,p=0.890),  time:63.399, tt:3043.138\n",
      "Ep:48, loss:0.00007, loss_test:0.08937, lr:8.69e-03, fs:0.78409 (r=0.697,p=0.896),  time:63.428, tt:3107.965\n",
      "Ep:49, loss:0.00006, loss_test:0.08672, lr:8.60e-03, fs:0.79096 (r=0.707,p=0.897),  time:63.432, tt:3171.583\n",
      "Ep:50, loss:0.00006, loss_test:0.08509, lr:8.51e-03, fs:0.77193 (r=0.667,p=0.917),  time:63.434, tt:3235.114\n",
      "Ep:51, loss:0.00006, loss_test:0.08218, lr:8.43e-03, fs:0.77907 (r=0.677,p=0.918),  time:63.445, tt:3299.157\n",
      "Ep:52, loss:0.00006, loss_test:0.08630, lr:8.35e-03, fs:0.77457 (r=0.677,p=0.905),  time:63.407, tt:3360.568\n",
      "Ep:53, loss:0.00005, loss_test:0.08586, lr:8.26e-03, fs:0.77457 (r=0.677,p=0.905),  time:63.388, tt:3422.935\n",
      "Ep:54, loss:0.00005, loss_test:0.08405, lr:8.18e-03, fs:0.78161 (r=0.687,p=0.907),  time:63.382, tt:3485.986\n",
      "Ep:55, loss:0.00005, loss_test:0.08626, lr:8.10e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.338, tt:3546.909\n",
      "Ep:56, loss:0.00005, loss_test:0.08517, lr:8.02e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.324, tt:3609.469\n",
      "Ep:57, loss:0.00005, loss_test:0.08300, lr:7.94e-03, fs:0.79545 (r=0.707,p=0.909),  time:63.294, tt:3671.054\n",
      "Ep:58, loss:0.00005, loss_test:0.08589, lr:7.86e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.301, tt:3734.765\n",
      "Ep:59, loss:0.00005, loss_test:0.08552, lr:7.78e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.234, tt:3794.036\n",
      "Ep:60, loss:0.00004, loss_test:0.08512, lr:7.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:63.228, tt:3856.880\n",
      "Ep:61, loss:0.00004, loss_test:0.08661, lr:7.62e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.189, tt:3917.719\n",
      "Ep:62, loss:0.00004, loss_test:0.08716, lr:7.55e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.190, tt:3980.957\n",
      "Ep:63, loss:0.00004, loss_test:0.08564, lr:7.47e-03, fs:0.77457 (r=0.677,p=0.905),  time:63.172, tt:4043.037\n",
      "Ep:64, loss:0.00004, loss_test:0.08453, lr:7.40e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.144, tt:4104.388\n",
      "Ep:65, loss:0.00004, loss_test:0.08756, lr:7.32e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.117, tt:4165.723\n",
      "Ep:66, loss:0.00004, loss_test:0.08790, lr:7.25e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.062, tt:4225.129\n",
      "Ep:67, loss:0.00004, loss_test:0.08598, lr:7.18e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.061, tt:4288.139\n",
      "Ep:68, loss:0.00004, loss_test:0.08801, lr:7.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.059, tt:4351.097\n",
      "Ep:69, loss:0.00004, loss_test:0.08819, lr:7.03e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.022, tt:4411.567\n",
      "Ep:70, loss:0.00004, loss_test:0.08736, lr:6.96e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.002, tt:4473.123\n",
      "Ep:71, loss:0.00003, loss_test:0.08721, lr:6.89e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.016, tt:4537.121\n",
      "Ep:72, loss:0.00003, loss_test:0.08752, lr:6.83e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.030, tt:4601.185\n",
      "Ep:73, loss:0.00003, loss_test:0.08865, lr:6.76e-03, fs:0.76744 (r=0.667,p=0.904),  time:63.000, tt:4662.000\n",
      "Ep:74, loss:0.00003, loss_test:0.08667, lr:6.69e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.972, tt:4722.901\n",
      "Ep:75, loss:0.00003, loss_test:0.09004, lr:6.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.962, tt:4785.095\n",
      "Ep:76, loss:0.00003, loss_test:0.08938, lr:6.56e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.945, tt:4846.733\n",
      "Ep:77, loss:0.00003, loss_test:0.08702, lr:6.49e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.933, tt:4908.796\n",
      "Ep:78, loss:0.00003, loss_test:0.08894, lr:6.43e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.915, tt:4970.316\n",
      "Ep:79, loss:0.00003, loss_test:0.08962, lr:6.36e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.873, tt:5029.875\n",
      "Ep:80, loss:0.00003, loss_test:0.08746, lr:6.30e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.843, tt:5090.310\n",
      "Ep:81, loss:0.00003, loss_test:0.09096, lr:6.24e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.824, tt:5151.574\n",
      "Ep:82, loss:0.00003, loss_test:0.08971, lr:6.17e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.805, tt:5212.828\n",
      "Ep:83, loss:0.00003, loss_test:0.08939, lr:6.11e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.806, tt:5275.727\n",
      "Ep:84, loss:0.00003, loss_test:0.08962, lr:6.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.792, tt:5337.351\n",
      "Ep:85, loss:0.00003, loss_test:0.09003, lr:5.99e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.774, tt:5398.606\n",
      "Ep:86, loss:0.00003, loss_test:0.08880, lr:5.93e-03, fs:0.76744 (r=0.667,p=0.904),  time:62.760, tt:5460.161\n",
      "Ep:87, loss:0.00003, loss_test:0.09026, lr:5.87e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.744, tt:5521.436\n",
      "Ep:88, loss:0.00003, loss_test:0.09067, lr:5.81e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.739, tt:5583.743\n",
      "Ep:89, loss:0.00003, loss_test:0.08986, lr:5.75e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.735, tt:5646.186\n",
      "Ep:90, loss:0.00003, loss_test:0.08969, lr:5.70e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.727, tt:5708.185\n",
      "Ep:91, loss:0.00003, loss_test:0.09149, lr:5.64e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.740, tt:5772.060\n",
      "Ep:92, loss:0.00003, loss_test:0.08945, lr:5.58e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.743, tt:5835.111\n",
      "Ep:93, loss:0.00002, loss_test:0.09158, lr:5.53e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.708, tt:5894.522\n",
      "Ep:94, loss:0.00002, loss_test:0.08927, lr:5.47e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.716, tt:5958.024\n",
      "Ep:95, loss:0.00002, loss_test:0.09055, lr:5.42e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.715, tt:6020.668\n",
      "Ep:96, loss:0.00002, loss_test:0.09061, lr:5.36e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.704, tt:6082.315\n",
      "Ep:97, loss:0.00002, loss_test:0.09062, lr:5.31e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.697, tt:6144.261\n",
      "Ep:98, loss:0.00002, loss_test:0.09122, lr:5.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.708, tt:6208.053\n",
      "Ep:99, loss:0.00002, loss_test:0.08986, lr:5.20e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.692, tt:6269.228\n",
      "Ep:100, loss:0.00002, loss_test:0.09199, lr:5.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.705, tt:6333.197\n",
      "Ep:101, loss:0.00002, loss_test:0.09103, lr:5.10e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.698, tt:6395.245\n",
      "Ep:102, loss:0.00002, loss_test:0.09003, lr:5.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.710, tt:6459.180\n",
      "Ep:103, loss:0.00002, loss_test:0.09303, lr:5.00e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.705, tt:6521.280\n",
      "Ep:104, loss:0.00002, loss_test:0.09072, lr:4.95e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.709, tt:6584.444\n",
      "Ep:105, loss:0.00002, loss_test:0.09110, lr:4.90e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.684, tt:6644.463\n",
      "Ep:106, loss:0.00002, loss_test:0.09296, lr:4.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.669, tt:6705.579\n",
      "Ep:107, loss:0.00002, loss_test:0.09029, lr:4.80e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.664, tt:6767.665\n",
      "Ep:108, loss:0.00002, loss_test:0.09151, lr:4.75e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.679, tt:6831.976\n",
      "Ep:109, loss:0.00002, loss_test:0.09224, lr:4.71e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.666, tt:6893.278\n",
      "Ep:110, loss:0.00002, loss_test:0.09060, lr:4.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:62.673, tt:6956.757\n",
      "Ep:111, loss:0.00002, loss_test:0.09224, lr:4.61e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.678, tt:7019.956\n",
      "Ep:112, loss:0.00002, loss_test:0.09189, lr:4.57e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.676, tt:7082.442\n",
      "Ep:113, loss:0.00002, loss_test:0.09058, lr:4.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.670, tt:7144.341\n",
      "Ep:114, loss:0.00002, loss_test:0.09192, lr:4.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.667, tt:7206.676\n",
      "Ep:115, loss:0.00002, loss_test:0.09164, lr:4.43e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.664, tt:7268.978\n",
      "Ep:116, loss:0.00002, loss_test:0.09101, lr:4.39e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.669, tt:7332.318\n",
      "Ep:117, loss:0.00002, loss_test:0.09294, lr:4.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.678, tt:7396.009\n",
      "Ep:118, loss:0.00002, loss_test:0.09089, lr:4.30e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.681, tt:7459.056\n",
      "Ep:119, loss:0.00002, loss_test:0.09248, lr:4.26e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.689, tt:7522.723\n",
      "Ep:120, loss:0.00002, loss_test:0.09110, lr:4.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.681, tt:7584.371\n",
      "Ep:121, loss:0.00002, loss_test:0.09251, lr:4.17e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.698, tt:7649.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00002, loss_test:0.09184, lr:4.13e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.709, tt:7713.155\n",
      "Ep:123, loss:0.00002, loss_test:0.09222, lr:4.09e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.716, tt:7776.731\n",
      "Ep:124, loss:0.00002, loss_test:0.09189, lr:4.05e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.717, tt:7839.623\n",
      "Ep:125, loss:0.00002, loss_test:0.09324, lr:4.01e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.714, tt:7901.922\n",
      "Ep:126, loss:0.00002, loss_test:0.09172, lr:3.97e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.739, tt:7967.802\n",
      "Ep:127, loss:0.00002, loss_test:0.09284, lr:3.93e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.740, tt:8030.765\n",
      "Ep:128, loss:0.00002, loss_test:0.09152, lr:3.89e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.739, tt:8093.356\n",
      "Ep:129, loss:0.00002, loss_test:0.09263, lr:3.85e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.743, tt:8156.595\n",
      "Ep:130, loss:0.00002, loss_test:0.09194, lr:3.81e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.742, tt:8219.230\n",
      "Ep:131, loss:0.00002, loss_test:0.09337, lr:3.77e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.743, tt:8282.029\n",
      "Ep:132, loss:0.00002, loss_test:0.09237, lr:3.73e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.745, tt:8345.124\n",
      "Ep:133, loss:0.00002, loss_test:0.09214, lr:3.70e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.750, tt:8408.488\n",
      "Ep:134, loss:0.00002, loss_test:0.09355, lr:3.66e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.746, tt:8470.671\n",
      "Ep:135, loss:0.00002, loss_test:0.09237, lr:3.62e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.747, tt:8533.571\n",
      "Ep:136, loss:0.00002, loss_test:0.09314, lr:3.59e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.739, tt:8595.253\n",
      "Ep:137, loss:0.00002, loss_test:0.09262, lr:3.55e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.733, tt:8657.172\n",
      "Ep:138, loss:0.00002, loss_test:0.09368, lr:3.52e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.740, tt:8720.867\n",
      "Ep:139, loss:0.00002, loss_test:0.09216, lr:3.48e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.759, tt:8786.202\n",
      "Ep:140, loss:0.00002, loss_test:0.09319, lr:3.45e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.758, tt:8848.841\n",
      "Ep:141, loss:0.00002, loss_test:0.09295, lr:3.41e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.773, tt:8913.816\n",
      "Ep:142, loss:0.00002, loss_test:0.09334, lr:3.38e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.784, tt:8978.048\n",
      "Ep:143, loss:0.00002, loss_test:0.09274, lr:3.34e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.794, tt:9042.343\n",
      "Ep:144, loss:0.00002, loss_test:0.09400, lr:3.31e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.807, tt:9107.073\n",
      "Ep:145, loss:0.00002, loss_test:0.09291, lr:3.28e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.815, tt:9171.009\n",
      "Ep:146, loss:0.00002, loss_test:0.09336, lr:3.24e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.822, tt:9234.848\n",
      "Ep:147, loss:0.00002, loss_test:0.09289, lr:3.21e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.838, tt:9300.046\n",
      "Ep:148, loss:0.00002, loss_test:0.09364, lr:3.18e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.847, tt:9364.157\n",
      "Ep:149, loss:0.00002, loss_test:0.09343, lr:3.15e-03, fs:0.75294 (r=0.646,p=0.901),  time:62.853, tt:9428.007\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 23\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14440, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.598, tt:56.598\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14226, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.054, tt:116.108\n",
      "Ep:2, loss:0.00054, loss_test:0.13705, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.013, tt:174.039\n",
      "Ep:3, loss:0.00051, loss_test:0.12429, lr:1.00e-02, fs:0.65385 (r=0.859,p=0.528),  time:59.230, tt:236.918\n",
      "Ep:4, loss:0.00046, loss_test:0.11433, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:60.515, tt:302.574\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.11624, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:61.403, tt:368.421\n",
      "Ep:6, loss:0.00042, loss_test:0.11018, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:62.159, tt:435.112\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.10744, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:62.647, tt:501.172\n",
      "Ep:8, loss:0.00037, loss_test:0.10700, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:63.084, tt:567.755\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10517, lr:1.00e-02, fs:0.68627 (r=0.707,p=0.667),  time:63.409, tt:634.088\n",
      "Ep:10, loss:0.00034, loss_test:0.10630, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:63.635, tt:699.988\n",
      "Ep:11, loss:0.00032, loss_test:0.10381, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:63.779, tt:765.352\n",
      "Ep:12, loss:0.00031, loss_test:0.10423, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:63.313, tt:823.067\n",
      "Ep:13, loss:0.00030, loss_test:0.10396, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:63.282, tt:885.951\n",
      "Ep:14, loss:0.00029, loss_test:0.10114, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:62.980, tt:944.696\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.10233, lr:1.00e-02, fs:0.71921 (r=0.737,p=0.702),  time:62.870, tt:1005.925\n",
      "Ep:16, loss:0.00026, loss_test:0.10127, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:62.646, tt:1064.978\n",
      "Ep:17, loss:0.00025, loss_test:0.10020, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:62.579, tt:1126.421\n",
      "Ep:18, loss:0.00024, loss_test:0.10211, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:62.479, tt:1187.106\n",
      "Ep:19, loss:0.00023, loss_test:0.09883, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:62.559, tt:1251.173\n",
      "Ep:20, loss:0.00022, loss_test:0.09936, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:62.640, tt:1315.440\n",
      "Ep:21, loss:0.00021, loss_test:0.09728, lr:1.00e-02, fs:0.74611 (r=0.727,p=0.766),  time:62.704, tt:1379.491\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.10268, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:62.604, tt:1439.900\n",
      "Ep:23, loss:0.00020, loss_test:0.09563, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:62.635, tt:1503.251\n",
      "Ep:24, loss:0.00019, loss_test:0.10009, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:62.783, tt:1569.566\n",
      "Ep:25, loss:0.00018, loss_test:0.09658, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:62.877, tt:1634.796\n",
      "Ep:26, loss:0.00017, loss_test:0.10343, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:62.934, tt:1699.207\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.10309, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:63.033, tt:1764.924\n",
      "Ep:28, loss:0.00015, loss_test:0.09697, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:63.106, tt:1830.070\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.10250, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:63.146, tt:1894.375\n",
      "Ep:30, loss:0.00014, loss_test:0.09951, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:63.249, tt:1960.722\n",
      "Ep:31, loss:0.00013, loss_test:0.09954, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:63.349, tt:2027.172\n",
      "Ep:32, loss:0.00013, loss_test:0.09972, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:63.346, tt:2090.403\n",
      "Ep:33, loss:0.00012, loss_test:0.10376, lr:1.00e-02, fs:0.74444 (r=0.677,p=0.827),  time:63.389, tt:2155.234\n",
      "Ep:34, loss:0.00011, loss_test:0.09428, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:63.450, tt:2220.733\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.10097, lr:1.00e-02, fs:0.75000 (r=0.667,p=0.857),  time:63.448, tt:2284.136\n",
      "Ep:36, loss:0.00010, loss_test:0.09999, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:63.494, tt:2349.279\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.09450, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:63.528, tt:2414.055\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.09898, lr:1.00e-02, fs:0.74157 (r=0.667,p=0.835),  time:63.564, tt:2478.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00009, loss_test:0.09803, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:63.621, tt:2544.859\n",
      "Ep:40, loss:0.00009, loss_test:0.09955, lr:1.00e-02, fs:0.72928 (r=0.667,p=0.805),  time:63.648, tt:2609.577\n",
      "Ep:41, loss:0.00008, loss_test:0.09542, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:63.690, tt:2674.977\n",
      "Ep:42, loss:0.00008, loss_test:0.09941, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:63.680, tt:2738.248\n",
      "Ep:43, loss:0.00008, loss_test:0.09591, lr:1.00e-02, fs:0.73743 (r=0.667,p=0.825),  time:63.687, tt:2802.207\n",
      "Ep:44, loss:0.00007, loss_test:0.09547, lr:1.00e-02, fs:0.75000 (r=0.667,p=0.857),  time:63.669, tt:2865.118\n",
      "Ep:45, loss:0.00007, loss_test:0.09671, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:63.682, tt:2929.358\n",
      "Ep:46, loss:0.00007, loss_test:0.10068, lr:1.00e-02, fs:0.75706 (r=0.677,p=0.859),  time:63.708, tt:2994.269\n",
      "Ep:47, loss:0.00007, loss_test:0.09758, lr:1.00e-02, fs:0.74713 (r=0.657,p=0.867),  time:63.643, tt:3054.863\n",
      "Ep:48, loss:0.00007, loss_test:0.09556, lr:1.00e-02, fs:0.71429 (r=0.606,p=0.870),  time:63.621, tt:3117.442\n",
      "Ep:49, loss:0.00006, loss_test:0.09928, lr:9.90e-03, fs:0.74444 (r=0.677,p=0.827),  time:63.645, tt:3182.273\n",
      "Ep:50, loss:0.00006, loss_test:0.09889, lr:9.80e-03, fs:0.74157 (r=0.667,p=0.835),  time:63.660, tt:3246.680\n",
      "Ep:51, loss:0.00006, loss_test:0.09526, lr:9.70e-03, fs:0.73743 (r=0.667,p=0.825),  time:63.659, tt:3310.271\n",
      "Ep:52, loss:0.00006, loss_test:0.10059, lr:9.61e-03, fs:0.74576 (r=0.667,p=0.846),  time:63.624, tt:3372.073\n",
      "Ep:53, loss:0.00006, loss_test:0.09824, lr:9.51e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.676, tt:3438.524\n",
      "Ep:54, loss:0.00005, loss_test:0.09656, lr:9.41e-03, fs:0.74713 (r=0.657,p=0.867),  time:63.696, tt:3503.288\n",
      "Ep:55, loss:0.00005, loss_test:0.09791, lr:9.32e-03, fs:0.71006 (r=0.606,p=0.857),  time:63.640, tt:3563.835\n",
      "Ep:56, loss:0.00005, loss_test:0.10190, lr:9.23e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.617, tt:3626.161\n",
      "Ep:57, loss:0.00005, loss_test:0.09823, lr:9.14e-03, fs:0.73988 (r=0.646,p=0.865),  time:63.626, tt:3690.300\n",
      "Ep:58, loss:0.00005, loss_test:0.09699, lr:9.04e-03, fs:0.74286 (r=0.657,p=0.855),  time:63.667, tt:3756.355\n",
      "Ep:59, loss:0.00005, loss_test:0.10047, lr:8.95e-03, fs:0.76836 (r=0.687,p=0.872),  time:63.634, tt:3818.044\n",
      "Ep:60, loss:0.00005, loss_test:0.09902, lr:8.86e-03, fs:0.72832 (r=0.636,p=0.851),  time:63.641, tt:3882.102\n",
      "Ep:61, loss:0.00005, loss_test:0.09848, lr:8.78e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.653, tt:3946.458\n",
      "Ep:62, loss:0.00004, loss_test:0.10141, lr:8.69e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.673, tt:4011.369\n",
      "Ep:63, loss:0.00004, loss_test:0.09752, lr:8.60e-03, fs:0.74713 (r=0.657,p=0.867),  time:63.657, tt:4074.035\n",
      "Ep:64, loss:0.00004, loss_test:0.10044, lr:8.51e-03, fs:0.73988 (r=0.646,p=0.865),  time:63.638, tt:4136.471\n",
      "Ep:65, loss:0.00004, loss_test:0.10001, lr:8.43e-03, fs:0.73256 (r=0.636,p=0.863),  time:63.686, tt:4203.262\n",
      "Ep:66, loss:0.00004, loss_test:0.09897, lr:8.35e-03, fs:0.73684 (r=0.636,p=0.875),  time:63.733, tt:4270.089\n",
      "Ep:67, loss:0.00004, loss_test:0.10122, lr:8.26e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.730, tt:4333.665\n",
      "Ep:68, loss:0.00004, loss_test:0.09830, lr:8.18e-03, fs:0.73988 (r=0.646,p=0.865),  time:63.771, tt:4400.184\n",
      "Ep:69, loss:0.00004, loss_test:0.10144, lr:8.10e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.781, tt:4464.658\n",
      "Ep:70, loss:0.00004, loss_test:0.10191, lr:8.02e-03, fs:0.69880 (r=0.586,p=0.866),  time:63.792, tt:4529.246\n",
      "Ep:71, loss:0.00004, loss_test:0.10046, lr:7.94e-03, fs:0.74118 (r=0.636,p=0.887),  time:63.808, tt:4594.173\n",
      "Ep:72, loss:0.00004, loss_test:0.10199, lr:7.86e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.805, tt:4657.784\n",
      "Ep:73, loss:0.00004, loss_test:0.10053, lr:7.78e-03, fs:0.73988 (r=0.646,p=0.865),  time:63.830, tt:4723.455\n",
      "Ep:74, loss:0.00004, loss_test:0.10082, lr:7.70e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.855, tt:4789.122\n",
      "Ep:75, loss:0.00003, loss_test:0.10327, lr:7.62e-03, fs:0.66667 (r=0.525,p=0.912),  time:63.844, tt:4852.149\n",
      "Ep:76, loss:0.00003, loss_test:0.09965, lr:7.55e-03, fs:0.70807 (r=0.576,p=0.919),  time:63.853, tt:4916.697\n",
      "Ep:77, loss:0.00003, loss_test:0.10108, lr:7.47e-03, fs:0.74390 (r=0.616,p=0.938),  time:63.845, tt:4979.928\n",
      "Ep:78, loss:0.00003, loss_test:0.10145, lr:7.40e-03, fs:0.73171 (r=0.606,p=0.923),  time:63.847, tt:5043.915\n",
      "Ep:79, loss:0.00003, loss_test:0.10201, lr:7.32e-03, fs:0.74390 (r=0.616,p=0.938),  time:63.880, tt:5110.397\n",
      "Ep:80, loss:0.00003, loss_test:0.10160, lr:7.25e-03, fs:0.76190 (r=0.646,p=0.928),  time:63.900, tt:5175.892\n",
      "Ep:81, loss:0.00003, loss_test:0.10271, lr:7.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:63.932, tt:5242.463\n",
      "Ep:82, loss:0.00003, loss_test:0.10155, lr:7.11e-03, fs:0.68790 (r=0.545,p=0.931),  time:63.935, tt:5306.590\n",
      "Ep:83, loss:0.00003, loss_test:0.10347, lr:7.03e-03, fs:0.70440 (r=0.566,p=0.933),  time:63.967, tt:5373.245\n",
      "Ep:84, loss:0.00003, loss_test:0.10193, lr:6.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:63.973, tt:5437.686\n",
      "Ep:85, loss:0.00003, loss_test:0.10269, lr:6.89e-03, fs:0.71250 (r=0.576,p=0.934),  time:63.985, tt:5502.745\n",
      "Ep:86, loss:0.00003, loss_test:0.10312, lr:6.83e-03, fs:0.67097 (r=0.525,p=0.929),  time:63.977, tt:5565.976\n",
      "Ep:87, loss:0.00003, loss_test:0.10293, lr:6.76e-03, fs:0.72050 (r=0.586,p=0.935),  time:63.975, tt:5629.843\n",
      "Ep:88, loss:0.00003, loss_test:0.10311, lr:6.69e-03, fs:0.73620 (r=0.606,p=0.938),  time:63.986, tt:5694.758\n",
      "Ep:89, loss:0.00003, loss_test:0.10456, lr:6.62e-03, fs:0.68790 (r=0.545,p=0.931),  time:64.003, tt:5760.280\n",
      "Ep:90, loss:0.00003, loss_test:0.10418, lr:6.56e-03, fs:0.66234 (r=0.515,p=0.927),  time:64.003, tt:5824.268\n",
      "Ep:91, loss:0.00003, loss_test:0.10308, lr:6.49e-03, fs:0.71250 (r=0.576,p=0.934),  time:64.016, tt:5889.433\n",
      "Ep:92, loss:0.00003, loss_test:0.10198, lr:6.43e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.032, tt:5954.981\n",
      "Ep:93, loss:0.00003, loss_test:0.10461, lr:6.36e-03, fs:0.67097 (r=0.525,p=0.929),  time:64.017, tt:6017.630\n",
      "Ep:94, loss:0.00002, loss_test:0.10414, lr:6.30e-03, fs:0.66234 (r=0.515,p=0.927),  time:64.023, tt:6082.193\n",
      "Ep:95, loss:0.00002, loss_test:0.10282, lr:6.24e-03, fs:0.70440 (r=0.566,p=0.933),  time:64.023, tt:6146.243\n",
      "Ep:96, loss:0.00002, loss_test:0.10520, lr:6.17e-03, fs:0.75152 (r=0.626,p=0.939),  time:64.030, tt:6210.926\n",
      "Ep:97, loss:0.00002, loss_test:0.10518, lr:6.11e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.028, tt:6274.741\n",
      "Ep:98, loss:0.00002, loss_test:0.10481, lr:6.05e-03, fs:0.65359 (r=0.505,p=0.926),  time:64.033, tt:6339.236\n",
      "Ep:99, loss:0.00002, loss_test:0.10586, lr:5.99e-03, fs:0.72050 (r=0.586,p=0.935),  time:64.024, tt:6402.367\n",
      "Ep:100, loss:0.00002, loss_test:0.10395, lr:5.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:64.041, tt:6468.180\n",
      "Ep:101, loss:0.00002, loss_test:0.10538, lr:5.87e-03, fs:0.66234 (r=0.515,p=0.927),  time:64.046, tt:6532.683\n",
      "Ep:102, loss:0.00002, loss_test:0.10488, lr:5.81e-03, fs:0.65359 (r=0.505,p=0.926),  time:64.040, tt:6596.138\n",
      "Ep:103, loss:0.00002, loss_test:0.10447, lr:5.75e-03, fs:0.75904 (r=0.636,p=0.940),  time:64.058, tt:6662.069\n",
      "Ep:104, loss:0.00002, loss_test:0.10589, lr:5.70e-03, fs:0.66234 (r=0.515,p=0.927),  time:64.052, tt:6725.427\n",
      "Ep:105, loss:0.00002, loss_test:0.10542, lr:5.64e-03, fs:0.65359 (r=0.505,p=0.926),  time:64.063, tt:6790.627\n",
      "Ep:106, loss:0.00002, loss_test:0.10660, lr:5.58e-03, fs:0.68790 (r=0.545,p=0.931),  time:64.071, tt:6855.581\n",
      "Ep:107, loss:0.00002, loss_test:0.10478, lr:5.53e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.064, tt:6918.883\n",
      "Ep:108, loss:0.00002, loss_test:0.10589, lr:5.47e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.061, tt:6982.625\n",
      "Ep:109, loss:0.00002, loss_test:0.10439, lr:5.42e-03, fs:0.67949 (r=0.535,p=0.930),  time:64.080, tt:7048.762\n",
      "Ep:110, loss:0.00002, loss_test:0.10558, lr:5.36e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.077, tt:7112.520\n",
      "Ep:111, loss:0.00002, loss_test:0.10680, lr:5.31e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.069, tt:7175.707\n",
      "Ep:112, loss:0.00002, loss_test:0.10602, lr:5.26e-03, fs:0.72500 (r=0.586,p=0.951),  time:64.047, tt:7237.354\n",
      "Ep:113, loss:0.00002, loss_test:0.10607, lr:5.20e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.032, tt:7299.661\n",
      "Ep:114, loss:0.00002, loss_test:0.10751, lr:5.15e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.045, tt:7365.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:115, loss:0.00002, loss_test:0.10802, lr:5.10e-03, fs:0.70064 (r=0.556,p=0.948),  time:64.041, tt:7428.734\n",
      "Ep:116, loss:0.00002, loss_test:0.10614, lr:5.05e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.047, tt:7493.501\n",
      "Ep:117, loss:0.00002, loss_test:0.10688, lr:5.00e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.072, tt:7560.461\n",
      "Ep:118, loss:0.00002, loss_test:0.10649, lr:4.95e-03, fs:0.72500 (r=0.586,p=0.951),  time:64.070, tt:7624.324\n",
      "Ep:119, loss:0.00002, loss_test:0.10765, lr:4.90e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.070, tt:7688.430\n",
      "Ep:120, loss:0.00002, loss_test:0.10763, lr:4.85e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.075, tt:7753.122\n",
      "Ep:121, loss:0.00002, loss_test:0.10663, lr:4.80e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.107, tt:7821.093\n",
      "Ep:122, loss:0.00002, loss_test:0.10707, lr:4.75e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.068, tt:7880.313\n",
      "Ep:123, loss:0.00002, loss_test:0.10841, lr:4.71e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.089, tt:7947.053\n",
      "Ep:124, loss:0.00002, loss_test:0.10575, lr:4.66e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.102, tt:8012.744\n",
      "Ep:125, loss:0.00002, loss_test:0.10817, lr:4.61e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.102, tt:8076.875\n",
      "Ep:126, loss:0.00002, loss_test:0.10833, lr:4.57e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.119, tt:8143.129\n",
      "Ep:127, loss:0.00002, loss_test:0.10810, lr:4.52e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.145, tt:8210.592\n",
      "Ep:128, loss:0.00002, loss_test:0.10710, lr:4.48e-03, fs:0.69231 (r=0.545,p=0.947),  time:64.149, tt:8275.158\n",
      "Ep:129, loss:0.00002, loss_test:0.10809, lr:4.43e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.154, tt:8340.053\n",
      "Ep:130, loss:0.00001, loss_test:0.10774, lr:4.39e-03, fs:0.67532 (r=0.525,p=0.945),  time:64.147, tt:8403.283\n",
      "Ep:131, loss:0.00001, loss_test:0.10709, lr:4.34e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.156, tt:8468.533\n",
      "Ep:132, loss:0.00001, loss_test:0.10834, lr:4.30e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.152, tt:8532.208\n",
      "Ep:133, loss:0.00001, loss_test:0.10737, lr:4.26e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.159, tt:8597.243\n",
      "Ep:134, loss:0.00001, loss_test:0.10969, lr:4.21e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.189, tt:8665.570\n",
      "Ep:137, loss:0.00001, loss_test:0.10793, lr:4.09e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.177, tt:8856.489\n",
      "Ep:138, loss:0.00001, loss_test:0.10766, lr:4.05e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.191, tt:8922.483\n",
      "Ep:139, loss:0.00001, loss_test:0.10896, lr:4.01e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.188, tt:8986.293\n",
      "Ep:140, loss:0.00001, loss_test:0.10786, lr:3.97e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.173, tt:9048.397\n",
      "Ep:141, loss:0.00001, loss_test:0.10949, lr:3.93e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.173, tt:9112.616\n",
      "Ep:142, loss:0.00001, loss_test:0.10826, lr:3.89e-03, fs:0.68387 (r=0.535,p=0.946),  time:64.177, tt:9177.328\n",
      "Ep:143, loss:0.00001, loss_test:0.10928, lr:3.85e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.179, tt:9241.751\n",
      "Ep:144, loss:0.00001, loss_test:0.10872, lr:3.81e-03, fs:0.70064 (r=0.556,p=0.948),  time:64.165, tt:9303.931\n",
      "Ep:145, loss:0.00001, loss_test:0.10872, lr:3.77e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.153, tt:9366.367\n",
      "Ep:146, loss:0.00001, loss_test:0.10886, lr:3.73e-03, fs:0.65789 (r=0.505,p=0.943),  time:64.147, tt:9429.634\n",
      "Ep:147, loss:0.00001, loss_test:0.10921, lr:3.70e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.108, tt:9487.986\n",
      "Ep:149, loss:0.00001, loss_test:0.10815, lr:3.62e-03, fs:0.66667 (r=0.515,p=0.944),  time:64.082, tt:9612.243\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 24\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14284, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.301, tt:56.301\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14017, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:59.426, tt:118.852\n",
      "Ep:2, loss:0.00055, loss_test:0.13412, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:58.466, tt:175.398\n",
      "Ep:3, loss:0.00052, loss_test:0.12081, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:58.885, tt:235.541\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.11328, lr:1.00e-02, fs:0.65327 (r=0.657,p=0.650),  time:60.303, tt:301.515\n",
      "Ep:5, loss:0.00045, loss_test:0.11027, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:60.426, tt:362.554\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.10615, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:60.883, tt:426.184\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00041, loss_test:0.10094, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:61.260, tt:490.081\n",
      "Ep:8, loss:0.00039, loss_test:0.09704, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:61.526, tt:553.732\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.09501, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:61.919, tt:619.186\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.09246, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:62.039, tt:682.428\n",
      "Ep:11, loss:0.00034, loss_test:0.09266, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:62.176, tt:746.117\n",
      "Ep:12, loss:0.00033, loss_test:0.09088, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:62.213, tt:808.769\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.09039, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:62.388, tt:873.435\n",
      "Ep:14, loss:0.00030, loss_test:0.09035, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:62.568, tt:938.525\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.08985, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:62.529, tt:1000.467\n",
      "Ep:16, loss:0.00027, loss_test:0.08943, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:62.571, tt:1063.706\n",
      "Ep:17, loss:0.00026, loss_test:0.08891, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:62.632, tt:1127.383\n",
      "Ep:18, loss:0.00025, loss_test:0.09101, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:62.713, tt:1191.554\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.09036, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:62.777, tt:1255.544\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00022, loss_test:0.08962, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:62.783, tt:1318.450\n",
      "Ep:21, loss:0.00021, loss_test:0.09123, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:62.841, tt:1382.501\n",
      "Ep:22, loss:0.00020, loss_test:0.09278, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:62.816, tt:1444.771\n",
      "Ep:23, loss:0.00019, loss_test:0.09240, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:62.885, tt:1509.238\n",
      "Ep:24, loss:0.00017, loss_test:0.09425, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:62.945, tt:1573.621\n",
      "Ep:25, loss:0.00017, loss_test:0.09248, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:62.912, tt:1635.717\n",
      "Ep:26, loss:0.00016, loss_test:0.09397, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:62.976, tt:1700.348\n",
      "Ep:27, loss:0.00015, loss_test:0.09104, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:63.019, tt:1764.543\n",
      "Ep:28, loss:0.00014, loss_test:0.09078, lr:1.00e-02, fs:0.77174 (r=0.717,p=0.835),  time:63.063, tt:1828.818\n",
      "Ep:29, loss:0.00013, loss_test:0.09151, lr:1.00e-02, fs:0.76023 (r=0.657,p=0.903),  time:63.071, tt:1892.137\n",
      "Ep:30, loss:0.00013, loss_test:0.09144, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:63.075, tt:1955.333\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.09094, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:63.095, tt:2019.027\n",
      "Ep:32, loss:0.00012, loss_test:0.09103, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:63.107, tt:2082.531\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.09304, lr:1.00e-02, fs:0.74854 (r=0.646,p=0.889),  time:63.158, tt:2147.362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00010, loss_test:0.09198, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:63.167, tt:2210.859\n",
      "Ep:35, loss:0.00010, loss_test:0.08895, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:63.203, tt:2275.322\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.09109, lr:1.00e-02, fs:0.75862 (r=0.667,p=0.880),  time:63.194, tt:2338.185\n",
      "Ep:37, loss:0.00009, loss_test:0.09046, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:63.238, tt:2403.049\n",
      "Ep:38, loss:0.00009, loss_test:0.09199, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:63.243, tt:2466.483\n",
      "Ep:39, loss:0.00009, loss_test:0.09386, lr:1.00e-02, fs:0.73988 (r=0.646,p=0.865),  time:63.197, tt:2527.898\n",
      "Ep:40, loss:0.00009, loss_test:0.09306, lr:1.00e-02, fs:0.74118 (r=0.636,p=0.887),  time:63.227, tt:2592.323\n",
      "Ep:41, loss:0.00009, loss_test:0.09151, lr:1.00e-02, fs:0.71605 (r=0.586,p=0.921),  time:63.250, tt:2656.487\n",
      "Ep:42, loss:0.00008, loss_test:0.09021, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:63.248, tt:2719.650\n",
      "Ep:43, loss:0.00007, loss_test:0.09008, lr:1.00e-02, fs:0.72093 (r=0.626,p=0.849),  time:63.281, tt:2784.377\n",
      "Ep:44, loss:0.00007, loss_test:0.09142, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:63.302, tt:2848.592\n",
      "Ep:45, loss:0.00007, loss_test:0.09050, lr:1.00e-02, fs:0.72832 (r=0.636,p=0.851),  time:63.301, tt:2911.832\n",
      "Ep:46, loss:0.00007, loss_test:0.09280, lr:1.00e-02, fs:0.71250 (r=0.576,p=0.934),  time:63.264, tt:2973.427\n",
      "Ep:47, loss:0.00007, loss_test:0.09017, lr:9.90e-03, fs:0.75429 (r=0.667,p=0.868),  time:63.238, tt:3035.425\n",
      "Ep:48, loss:0.00006, loss_test:0.09416, lr:9.80e-03, fs:0.75000 (r=0.636,p=0.913),  time:63.268, tt:3100.140\n",
      "Ep:49, loss:0.00006, loss_test:0.09134, lr:9.70e-03, fs:0.72941 (r=0.626,p=0.873),  time:63.264, tt:3163.191\n",
      "Ep:50, loss:0.00006, loss_test:0.09296, lr:9.61e-03, fs:0.73373 (r=0.626,p=0.886),  time:63.315, tt:3229.070\n",
      "Ep:51, loss:0.00006, loss_test:0.09501, lr:9.51e-03, fs:0.72393 (r=0.596,p=0.922),  time:63.291, tt:3291.145\n",
      "Ep:52, loss:0.00006, loss_test:0.08943, lr:9.41e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.301, tt:3354.935\n",
      "Ep:53, loss:0.00006, loss_test:0.09553, lr:9.32e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.300, tt:3418.184\n",
      "Ep:54, loss:0.00005, loss_test:0.09268, lr:9.23e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.315, tt:3482.319\n",
      "Ep:55, loss:0.00005, loss_test:0.09335, lr:9.14e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.333, tt:3546.666\n",
      "Ep:56, loss:0.00005, loss_test:0.09307, lr:9.04e-03, fs:0.71345 (r=0.616,p=0.847),  time:63.350, tt:3610.949\n",
      "Ep:57, loss:0.00005, loss_test:0.09310, lr:8.95e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.345, tt:3674.031\n",
      "Ep:58, loss:0.00005, loss_test:0.09195, lr:8.86e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.304, tt:3734.962\n",
      "Ep:59, loss:0.00005, loss_test:0.09523, lr:8.78e-03, fs:0.71951 (r=0.596,p=0.908),  time:63.292, tt:3797.524\n",
      "Ep:60, loss:0.00005, loss_test:0.09216, lr:8.69e-03, fs:0.72093 (r=0.626,p=0.849),  time:63.337, tt:3863.543\n",
      "Ep:61, loss:0.00005, loss_test:0.09647, lr:8.60e-03, fs:0.70370 (r=0.576,p=0.905),  time:63.325, tt:3926.146\n",
      "Ep:62, loss:0.00004, loss_test:0.09333, lr:8.51e-03, fs:0.71084 (r=0.596,p=0.881),  time:63.320, tt:3989.169\n",
      "Ep:63, loss:0.00004, loss_test:0.09336, lr:8.43e-03, fs:0.71084 (r=0.596,p=0.881),  time:63.294, tt:4050.832\n",
      "Ep:64, loss:0.00004, loss_test:0.09480, lr:8.35e-03, fs:0.70659 (r=0.596,p=0.868),  time:63.280, tt:4113.218\n",
      "Ep:65, loss:0.00004, loss_test:0.09553, lr:8.26e-03, fs:0.71084 (r=0.596,p=0.881),  time:63.272, tt:4175.941\n",
      "Ep:66, loss:0.00004, loss_test:0.09380, lr:8.18e-03, fs:0.71515 (r=0.596,p=0.894),  time:63.276, tt:4239.526\n",
      "Ep:67, loss:0.00004, loss_test:0.09389, lr:8.10e-03, fs:0.71084 (r=0.596,p=0.881),  time:63.222, tt:4299.064\n",
      "Ep:68, loss:0.00004, loss_test:0.09770, lr:8.02e-03, fs:0.71166 (r=0.586,p=0.906),  time:63.250, tt:4364.255\n",
      "Ep:69, loss:0.00004, loss_test:0.09274, lr:7.94e-03, fs:0.70238 (r=0.596,p=0.855),  time:63.294, tt:4430.566\n",
      "Ep:70, loss:0.00004, loss_test:0.09694, lr:7.86e-03, fs:0.71166 (r=0.586,p=0.906),  time:63.335, tt:4496.799\n",
      "Ep:71, loss:0.00004, loss_test:0.09519, lr:7.78e-03, fs:0.70303 (r=0.586,p=0.879),  time:63.345, tt:4560.829\n",
      "Ep:72, loss:0.00004, loss_test:0.09565, lr:7.70e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.371, tt:4626.117\n",
      "Ep:73, loss:0.00004, loss_test:0.09387, lr:7.62e-03, fs:0.69461 (r=0.586,p=0.853),  time:63.441, tt:4694.604\n",
      "Ep:74, loss:0.00004, loss_test:0.09757, lr:7.55e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.499, tt:4762.419\n",
      "Ep:75, loss:0.00003, loss_test:0.09426, lr:7.47e-03, fs:0.70303 (r=0.586,p=0.879),  time:63.541, tt:4829.087\n",
      "Ep:76, loss:0.00003, loss_test:0.09648, lr:7.40e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.632, tt:4899.691\n",
      "Ep:77, loss:0.00003, loss_test:0.09606, lr:7.32e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.683, tt:4967.267\n",
      "Ep:78, loss:0.00003, loss_test:0.09697, lr:7.25e-03, fs:0.70303 (r=0.586,p=0.879),  time:63.710, tt:5033.101\n",
      "Ep:79, loss:0.00003, loss_test:0.09638, lr:7.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.780, tt:5102.396\n",
      "Ep:80, loss:0.00003, loss_test:0.09688, lr:7.11e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.847, tt:5171.628\n",
      "Ep:81, loss:0.00003, loss_test:0.09687, lr:7.03e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.863, tt:5236.806\n",
      "Ep:82, loss:0.00003, loss_test:0.09468, lr:6.96e-03, fs:0.70303 (r=0.586,p=0.879),  time:63.919, tt:5305.272\n",
      "Ep:83, loss:0.00003, loss_test:0.09891, lr:6.89e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.954, tt:5372.139\n",
      "Ep:84, loss:0.00003, loss_test:0.09770, lr:6.83e-03, fs:0.70732 (r=0.586,p=0.892),  time:63.989, tt:5439.022\n",
      "Ep:85, loss:0.00003, loss_test:0.09520, lr:6.76e-03, fs:0.69880 (r=0.586,p=0.866),  time:64.036, tt:5507.121\n",
      "Ep:86, loss:0.00003, loss_test:0.09855, lr:6.69e-03, fs:0.69880 (r=0.586,p=0.866),  time:64.058, tt:5573.028\n",
      "Ep:87, loss:0.00003, loss_test:0.09665, lr:6.62e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.092, tt:5640.087\n",
      "Ep:88, loss:0.00003, loss_test:0.09794, lr:6.56e-03, fs:0.69880 (r=0.586,p=0.866),  time:64.133, tt:5707.879\n",
      "Ep:89, loss:0.00003, loss_test:0.09724, lr:6.49e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.171, tt:5775.374\n",
      "Ep:90, loss:0.00003, loss_test:0.09808, lr:6.43e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.197, tt:5841.885\n",
      "Ep:91, loss:0.00003, loss_test:0.09935, lr:6.36e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.253, tt:5911.316\n",
      "Ep:92, loss:0.00003, loss_test:0.09700, lr:6.30e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.290, tt:5979.003\n",
      "Ep:93, loss:0.00003, loss_test:0.09855, lr:6.24e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.341, tt:6048.015\n",
      "Ep:94, loss:0.00003, loss_test:0.09677, lr:6.17e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.368, tt:6114.993\n",
      "Ep:95, loss:0.00003, loss_test:0.09883, lr:6.11e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.419, tt:6184.223\n",
      "Ep:96, loss:0.00003, loss_test:0.09808, lr:6.05e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.444, tt:6251.071\n",
      "Ep:97, loss:0.00003, loss_test:0.09935, lr:5.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.501, tt:6321.081\n",
      "Ep:98, loss:0.00003, loss_test:0.09834, lr:5.93e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.535, tt:6388.941\n",
      "Ep:99, loss:0.00003, loss_test:0.09889, lr:5.87e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.596, tt:6459.627\n",
      "Ep:100, loss:0.00003, loss_test:0.09772, lr:5.81e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.644, tt:6529.046\n",
      "Ep:101, loss:0.00003, loss_test:0.09945, lr:5.75e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.668, tt:6596.104\n",
      "Ep:102, loss:0.00002, loss_test:0.09965, lr:5.70e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.696, tt:6663.708\n",
      "Ep:103, loss:0.00002, loss_test:0.09812, lr:5.64e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.730, tt:6731.891\n",
      "Ep:104, loss:0.00002, loss_test:0.09981, lr:5.58e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.790, tt:6802.966\n",
      "Ep:105, loss:0.00002, loss_test:0.09867, lr:5.53e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.837, tt:6872.720\n",
      "Ep:106, loss:0.00002, loss_test:0.09930, lr:5.47e-03, fs:0.70732 (r=0.586,p=0.892),  time:64.871, tt:6941.151\n",
      "Ep:107, loss:0.00002, loss_test:0.09976, lr:5.42e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.908, tt:7010.106\n",
      "Ep:108, loss:0.00002, loss_test:0.10028, lr:5.36e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.933, tt:7077.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00002, loss_test:0.09889, lr:5.31e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.965, tt:7146.162\n",
      "Ep:110, loss:0.00002, loss_test:0.10009, lr:5.26e-03, fs:0.70303 (r=0.586,p=0.879),  time:64.987, tt:7213.512\n",
      "Ep:111, loss:0.00002, loss_test:0.09970, lr:5.20e-03, fs:0.70732 (r=0.586,p=0.892),  time:65.012, tt:7281.356\n",
      "Ep:112, loss:0.00002, loss_test:0.09983, lr:5.15e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.042, tt:7349.712\n",
      "Ep:113, loss:0.00002, loss_test:0.10110, lr:5.10e-03, fs:0.70732 (r=0.586,p=0.892),  time:65.063, tt:7417.216\n",
      "Ep:114, loss:0.00002, loss_test:0.09951, lr:5.05e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.108, tt:7487.440\n",
      "Ep:115, loss:0.00002, loss_test:0.10131, lr:5.00e-03, fs:0.70732 (r=0.586,p=0.892),  time:65.138, tt:7555.963\n",
      "Ep:116, loss:0.00002, loss_test:0.09951, lr:4.95e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.185, tt:7626.682\n",
      "Ep:117, loss:0.00002, loss_test:0.10254, lr:4.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:65.228, tt:7696.900\n",
      "Ep:118, loss:0.00002, loss_test:0.09970, lr:4.85e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.256, tt:7765.468\n",
      "Ep:119, loss:0.00002, loss_test:0.10218, lr:4.80e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.285, tt:7834.172\n",
      "Ep:120, loss:0.00002, loss_test:0.10031, lr:4.75e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.298, tt:7901.046\n",
      "Ep:121, loss:0.00002, loss_test:0.10168, lr:4.71e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.326, tt:7969.720\n",
      "Ep:122, loss:0.00002, loss_test:0.10181, lr:4.66e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.357, tt:8038.875\n",
      "Ep:123, loss:0.00002, loss_test:0.10126, lr:4.61e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.380, tt:8107.062\n",
      "Ep:124, loss:0.00002, loss_test:0.10118, lr:4.57e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.427, tt:8178.426\n",
      "Ep:125, loss:0.00002, loss_test:0.10225, lr:4.52e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.464, tt:8248.442\n",
      "Ep:126, loss:0.00002, loss_test:0.10095, lr:4.48e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.483, tt:8316.349\n",
      "Ep:127, loss:0.00002, loss_test:0.10272, lr:4.43e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.523, tt:8387.007\n",
      "Ep:128, loss:0.00002, loss_test:0.10194, lr:4.39e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.567, tt:8458.105\n",
      "Ep:129, loss:0.00002, loss_test:0.10263, lr:4.34e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.627, tt:8531.449\n",
      "Ep:130, loss:0.00002, loss_test:0.10126, lr:4.30e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.681, tt:8604.252\n",
      "Ep:131, loss:0.00002, loss_test:0.10259, lr:4.26e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.728, tt:8676.111\n",
      "Ep:132, loss:0.00002, loss_test:0.10207, lr:4.21e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.778, tt:8748.446\n",
      "Ep:133, loss:0.00002, loss_test:0.10316, lr:4.17e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.825, tt:8820.576\n",
      "Ep:134, loss:0.00002, loss_test:0.10235, lr:4.13e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.864, tt:8891.612\n",
      "Ep:135, loss:0.00002, loss_test:0.10299, lr:4.09e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.900, tt:8962.335\n",
      "Ep:136, loss:0.00002, loss_test:0.10259, lr:4.05e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.925, tt:9031.737\n",
      "Ep:137, loss:0.00002, loss_test:0.10351, lr:4.01e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.952, tt:9101.321\n",
      "Ep:138, loss:0.00002, loss_test:0.10323, lr:3.97e-03, fs:0.70303 (r=0.586,p=0.879),  time:65.973, tt:9170.256\n",
      "Ep:140, loss:0.00002, loss_test:0.10378, lr:3.89e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.029, tt:9310.156\n",
      "Ep:141, loss:0.00002, loss_test:0.10304, lr:3.85e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.073, tt:9382.412\n",
      "Ep:142, loss:0.00002, loss_test:0.10430, lr:3.81e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.095, tt:9451.515\n",
      "Ep:143, loss:0.00002, loss_test:0.10338, lr:3.77e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.128, tt:9522.476\n",
      "Ep:144, loss:0.00002, loss_test:0.10450, lr:3.73e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.159, tt:9592.995\n",
      "Ep:145, loss:0.00002, loss_test:0.10394, lr:3.70e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.187, tt:9663.255\n",
      "Ep:146, loss:0.00002, loss_test:0.10493, lr:3.66e-03, fs:0.68712 (r=0.566,p=0.875),  time:66.184, tt:9729.021\n",
      "Ep:147, loss:0.00002, loss_test:0.10434, lr:3.62e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.211, tt:9799.292\n",
      "Ep:148, loss:0.00002, loss_test:0.10470, lr:3.59e-03, fs:0.70303 (r=0.586,p=0.879),  time:66.243, tt:9870.140\n",
      "Ep:149, loss:0.00002, loss_test:0.10508, lr:3.55e-03, fs:0.68712 (r=0.566,p=0.875),  time:66.267, tt:9940.095\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 25\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14420, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.565, tt:50.565\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14200, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:57.691, tt:115.381\n",
      "Ep:2, loss:0.00054, loss_test:0.13697, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.603, tt:175.808\n",
      "Ep:3, loss:0.00051, loss_test:0.12483, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:58.281, tt:233.125\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.11444, lr:1.00e-02, fs:0.67308 (r=0.707,p=0.642),  time:58.765, tt:293.827\n",
      "Ep:5, loss:0.00045, loss_test:0.11226, lr:1.00e-02, fs:0.68421 (r=0.788,p=0.605),  time:59.764, tt:358.582\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00043, loss_test:0.10675, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:60.551, tt:423.858\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.10220, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:61.047, tt:488.376\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.09931, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:60.840, tt:547.556\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.09667, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:61.270, tt:612.705\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00035, loss_test:0.09553, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:61.470, tt:676.170\n",
      "Ep:11, loss:0.00034, loss_test:0.09367, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:61.814, tt:741.773\n",
      "Ep:12, loss:0.00033, loss_test:0.09270, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:62.042, tt:806.547\n",
      "Ep:13, loss:0.00032, loss_test:0.09097, lr:1.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:62.036, tt:868.505\n",
      "Ep:14, loss:0.00030, loss_test:0.08988, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:62.037, tt:930.560\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.08832, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:61.995, tt:991.918\n",
      "Ep:16, loss:0.00028, loss_test:0.08695, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:62.168, tt:1056.860\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00027, loss_test:0.08571, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:62.245, tt:1120.415\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00026, loss_test:0.08408, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:62.266, tt:1183.059\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00025, loss_test:0.08284, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:62.579, tt:1251.588\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00024, loss_test:0.08035, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:62.899, tt:1320.883\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.07971, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:62.890, tt:1383.580\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.07865, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:62.957, tt:1448.009\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.07584, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:63.002, tt:1512.037\n",
      "Ep:24, loss:0.00019, loss_test:0.07505, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:62.959, tt:1573.976\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00018, loss_test:0.07433, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:62.570, tt:1626.813\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.07342, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:62.105, tt:1676.830\n",
      "Ep:27, loss:0.00017, loss_test:0.07235, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:61.723, tt:1728.233\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.07098, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:61.425, tt:1781.323\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.06898, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:61.302, tt:1839.073\n",
      "Ep:30, loss:0.00015, loss_test:0.07068, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:61.192, tt:1896.962\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.06808, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:61.102, tt:1955.262\n",
      "Ep:32, loss:0.00013, loss_test:0.06728, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:61.089, tt:2015.934\n",
      "Ep:33, loss:0.00013, loss_test:0.06534, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:61.060, tt:2076.025\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.06586, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:60.978, tt:2134.221\n",
      "Ep:35, loss:0.00012, loss_test:0.06495, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:60.942, tt:2193.929\n",
      "Ep:36, loss:0.00011, loss_test:0.06330, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:60.884, tt:2252.713\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06497, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:60.836, tt:2311.778\n",
      "Ep:38, loss:0.00010, loss_test:0.06475, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:60.821, tt:2372.016\n",
      "Ep:39, loss:0.00010, loss_test:0.06172, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:60.808, tt:2432.336\n",
      "Ep:40, loss:0.00009, loss_test:0.06209, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:60.794, tt:2492.556\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.06327, lr:1.00e-02, fs:0.91005 (r=0.869,p=0.956),  time:60.716, tt:2550.076\n",
      "Ep:42, loss:0.00008, loss_test:0.06156, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.618, tt:2606.588\n",
      "Ep:43, loss:0.00008, loss_test:0.06131, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:60.543, tt:2663.871\n",
      "Ep:44, loss:0.00008, loss_test:0.06376, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:60.495, tt:2722.295\n",
      "Ep:45, loss:0.00008, loss_test:0.06196, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:60.413, tt:2779.002\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.06032, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:60.417, tt:2839.618\n",
      "Ep:47, loss:0.00007, loss_test:0.06032, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:60.356, tt:2897.103\n",
      "Ep:48, loss:0.00007, loss_test:0.06041, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.362, tt:2957.762\n",
      "Ep:49, loss:0.00006, loss_test:0.06043, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.316, tt:3015.822\n",
      "Ep:50, loss:0.00006, loss_test:0.05949, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:60.296, tt:3075.072\n",
      "Ep:51, loss:0.00006, loss_test:0.06070, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.222, tt:3131.558\n",
      "Ep:52, loss:0.00006, loss_test:0.06248, lr:1.00e-02, fs:0.91489 (r=0.869,p=0.966),  time:60.155, tt:3188.197\n",
      "Ep:53, loss:0.00006, loss_test:0.05816, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.118, tt:3246.376\n",
      "Ep:54, loss:0.00006, loss_test:0.06132, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:60.098, tt:3305.366\n",
      "Ep:55, loss:0.00005, loss_test:0.06102, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:60.060, tt:3363.365\n",
      "Ep:56, loss:0.00005, loss_test:0.06020, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:60.039, tt:3422.218\n",
      "Ep:57, loss:0.00005, loss_test:0.06149, lr:9.90e-03, fs:0.87097 (r=0.818,p=0.931),  time:60.044, tt:3482.553\n",
      "Ep:58, loss:0.00005, loss_test:0.06013, lr:9.80e-03, fs:0.91579 (r=0.879,p=0.956),  time:60.083, tt:3544.916\n",
      "Ep:59, loss:0.00005, loss_test:0.06001, lr:9.70e-03, fs:0.90052 (r=0.869,p=0.935),  time:60.096, tt:3605.773\n",
      "Ep:60, loss:0.00004, loss_test:0.06013, lr:9.61e-03, fs:0.91005 (r=0.869,p=0.956),  time:60.074, tt:3664.491\n",
      "Ep:61, loss:0.00005, loss_test:0.06409, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:60.071, tt:3724.377\n",
      "Ep:62, loss:0.00004, loss_test:0.06139, lr:9.41e-03, fs:0.91579 (r=0.879,p=0.956),  time:60.088, tt:3785.573\n",
      "Ep:63, loss:0.00004, loss_test:0.06157, lr:9.32e-03, fs:0.91005 (r=0.869,p=0.956),  time:60.111, tt:3847.079\n",
      "Ep:64, loss:0.00004, loss_test:0.06162, lr:9.23e-03, fs:0.88889 (r=0.848,p=0.933),  time:60.085, tt:3905.514\n",
      "Ep:65, loss:0.00004, loss_test:0.06100, lr:9.14e-03, fs:0.91099 (r=0.879,p=0.946),  time:60.036, tt:3962.358\n",
      "Ep:66, loss:0.00004, loss_test:0.06314, lr:9.04e-03, fs:0.91489 (r=0.869,p=0.966),  time:59.996, tt:4019.743\n",
      "Ep:67, loss:0.00004, loss_test:0.06192, lr:8.95e-03, fs:0.87568 (r=0.818,p=0.942),  time:59.979, tt:4078.554\n",
      "Ep:68, loss:0.00004, loss_test:0.06625, lr:8.86e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.952, tt:4136.676\n",
      "Ep:69, loss:0.00003, loss_test:0.06340, lr:8.78e-03, fs:0.90909 (r=0.859,p=0.966),  time:59.941, tt:4195.894\n",
      "Ep:70, loss:0.00003, loss_test:0.06293, lr:8.69e-03, fs:0.90811 (r=0.848,p=0.977),  time:59.918, tt:4254.206\n",
      "Ep:71, loss:0.00003, loss_test:0.06295, lr:8.60e-03, fs:0.86339 (r=0.798,p=0.940),  time:59.876, tt:4311.105\n",
      "Ep:72, loss:0.00003, loss_test:0.06312, lr:8.51e-03, fs:0.92063 (r=0.879,p=0.967),  time:59.839, tt:4368.260\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.06668, lr:8.51e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.841, tt:4428.238\n",
      "Ep:74, loss:0.00003, loss_test:0.06279, lr:8.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:59.840, tt:4487.985\n",
      "Ep:75, loss:0.00003, loss_test:0.06429, lr:8.51e-03, fs:0.91489 (r=0.869,p=0.966),  time:59.825, tt:4546.672\n",
      "Ep:76, loss:0.00003, loss_test:0.06407, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:59.833, tt:4607.164\n",
      "Ep:77, loss:0.00003, loss_test:0.06406, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:59.831, tt:4666.830\n",
      "Ep:78, loss:0.00003, loss_test:0.06285, lr:8.51e-03, fs:0.91005 (r=0.869,p=0.956),  time:59.800, tt:4724.197\n",
      "Ep:79, loss:0.00003, loss_test:0.06474, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:59.788, tt:4783.051\n",
      "Ep:80, loss:0.00003, loss_test:0.06509, lr:8.51e-03, fs:0.86188 (r=0.788,p=0.951),  time:59.797, tt:4843.587\n",
      "Ep:81, loss:0.00002, loss_test:0.06429, lr:8.51e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.800, tt:4903.599\n",
      "Ep:82, loss:0.00002, loss_test:0.06543, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:59.793, tt:4962.805\n",
      "Ep:83, loss:0.00002, loss_test:0.06817, lr:8.51e-03, fs:0.83721 (r=0.727,p=0.986),  time:59.793, tt:5022.645\n",
      "Ep:84, loss:0.00002, loss_test:0.06568, lr:8.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.755, tt:5079.173\n",
      "Ep:85, loss:0.00002, loss_test:0.06626, lr:8.35e-03, fs:0.85714 (r=0.758,p=0.987),  time:59.718, tt:5135.751\n",
      "Ep:86, loss:0.00002, loss_test:0.06556, lr:8.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.717, tt:5195.351\n",
      "Ep:87, loss:0.00002, loss_test:0.06427, lr:8.18e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.711, tt:5254.602\n",
      "Ep:88, loss:0.00002, loss_test:0.06580, lr:8.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.708, tt:5314.053\n",
      "Ep:89, loss:0.00002, loss_test:0.06561, lr:8.02e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.678, tt:5371.004\n",
      "Ep:90, loss:0.00002, loss_test:0.06582, lr:7.94e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.641, tt:5427.301\n",
      "Ep:91, loss:0.00002, loss_test:0.06846, lr:7.86e-03, fs:0.86857 (r=0.768,p=1.000),  time:59.621, tt:5485.090\n",
      "Ep:92, loss:0.00002, loss_test:0.06707, lr:7.78e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.580, tt:5540.981\n",
      "Ep:93, loss:0.00002, loss_test:0.06667, lr:7.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.579, tt:5600.424\n",
      "Ep:94, loss:0.00002, loss_test:0.06582, lr:7.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.563, tt:5658.458\n",
      "Ep:95, loss:0.00002, loss_test:0.06679, lr:7.55e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.541, tt:5715.938\n",
      "Ep:96, loss:0.00002, loss_test:0.06845, lr:7.47e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.520, tt:5773.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00002, loss_test:0.06723, lr:7.40e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.490, tt:5830.004\n",
      "Ep:98, loss:0.00002, loss_test:0.06614, lr:7.32e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.494, tt:5889.919\n",
      "Ep:99, loss:0.00002, loss_test:0.06719, lr:7.25e-03, fs:0.85714 (r=0.758,p=0.987),  time:59.498, tt:5949.802\n",
      "Ep:100, loss:0.00002, loss_test:0.06801, lr:7.18e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.493, tt:6008.758\n",
      "Ep:101, loss:0.00002, loss_test:0.06893, lr:7.11e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.476, tt:6066.574\n",
      "Ep:102, loss:0.00002, loss_test:0.06565, lr:7.03e-03, fs:0.86034 (r=0.778,p=0.963),  time:59.472, tt:6125.668\n",
      "Ep:103, loss:0.00001, loss_test:0.06897, lr:6.96e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.458, tt:6183.595\n",
      "Ep:104, loss:0.00001, loss_test:0.06811, lr:6.89e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.448, tt:6242.006\n",
      "Ep:105, loss:0.00001, loss_test:0.06798, lr:6.83e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.447, tt:6301.329\n",
      "Ep:106, loss:0.00001, loss_test:0.06809, lr:6.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:59.435, tt:6359.501\n",
      "Ep:107, loss:0.00001, loss_test:0.06980, lr:6.69e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.398, tt:6415.009\n",
      "Ep:108, loss:0.00001, loss_test:0.06789, lr:6.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.390, tt:6473.550\n",
      "Ep:109, loss:0.00001, loss_test:0.06891, lr:6.56e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.387, tt:6532.557\n",
      "Ep:110, loss:0.00001, loss_test:0.06938, lr:6.49e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.372, tt:6590.328\n",
      "Ep:111, loss:0.00001, loss_test:0.06779, lr:6.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.369, tt:6649.287\n",
      "Ep:112, loss:0.00001, loss_test:0.06949, lr:6.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.378, tt:6709.723\n",
      "Ep:113, loss:0.00001, loss_test:0.06967, lr:6.30e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.348, tt:6765.622\n",
      "Ep:114, loss:0.00001, loss_test:0.06841, lr:6.24e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.341, tt:6824.224\n",
      "Ep:115, loss:0.00001, loss_test:0.07005, lr:6.17e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.337, tt:6883.063\n",
      "Ep:116, loss:0.00001, loss_test:0.06852, lr:6.11e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.309, tt:6939.194\n",
      "Ep:117, loss:0.00001, loss_test:0.06966, lr:6.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.299, tt:6997.253\n",
      "Ep:118, loss:0.00001, loss_test:0.07007, lr:5.99e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.288, tt:7055.262\n",
      "Ep:119, loss:0.00001, loss_test:0.06956, lr:5.93e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.302, tt:7116.234\n",
      "Ep:120, loss:0.00001, loss_test:0.06934, lr:5.87e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.287, tt:7173.786\n",
      "Ep:121, loss:0.00001, loss_test:0.06922, lr:5.81e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.273, tt:7231.354\n",
      "Ep:122, loss:0.00001, loss_test:0.06983, lr:5.75e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.284, tt:7291.881\n",
      "Ep:123, loss:0.00001, loss_test:0.06830, lr:5.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.248, tt:7346.708\n",
      "Ep:124, loss:0.00001, loss_test:0.06905, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.245, tt:7405.652\n",
      "Ep:125, loss:0.00001, loss_test:0.07051, lr:5.58e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.248, tt:7465.267\n",
      "Ep:126, loss:0.00001, loss_test:0.06813, lr:5.53e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.227, tt:7521.782\n",
      "Ep:127, loss:0.00001, loss_test:0.06939, lr:5.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.207, tt:7578.498\n",
      "Ep:128, loss:0.00001, loss_test:0.06987, lr:5.42e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.201, tt:7636.877\n",
      "Ep:129, loss:0.00001, loss_test:0.06959, lr:5.36e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.188, tt:7694.434\n",
      "Ep:130, loss:0.00001, loss_test:0.06992, lr:5.31e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.174, tt:7751.796\n",
      "Ep:131, loss:0.00001, loss_test:0.06867, lr:5.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.170, tt:7810.392\n",
      "Ep:132, loss:0.00001, loss_test:0.06997, lr:5.20e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.167, tt:7869.239\n",
      "Ep:133, loss:0.00001, loss_test:0.06962, lr:5.15e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.152, tt:7926.433\n",
      "Ep:134, loss:0.00001, loss_test:0.06916, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.130, tt:7982.601\n",
      "Ep:135, loss:0.00001, loss_test:0.06964, lr:5.05e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.133, tt:8042.036\n",
      "Ep:136, loss:0.00001, loss_test:0.06902, lr:5.00e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.132, tt:8101.043\n",
      "Ep:137, loss:0.00001, loss_test:0.06941, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.131, tt:8160.105\n",
      "Ep:138, loss:0.00001, loss_test:0.06913, lr:4.90e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.121, tt:8217.884\n",
      "Ep:139, loss:0.00001, loss_test:0.06901, lr:4.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.109, tt:8275.216\n",
      "Ep:140, loss:0.00001, loss_test:0.06912, lr:4.80e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.086, tt:8331.171\n",
      "Ep:141, loss:0.00001, loss_test:0.06916, lr:4.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.084, tt:8389.906\n",
      "Ep:142, loss:0.00001, loss_test:0.06900, lr:4.71e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.069, tt:8446.855\n",
      "Ep:143, loss:0.00001, loss_test:0.06914, lr:4.66e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.077, tt:8507.147\n",
      "Ep:144, loss:0.00001, loss_test:0.06977, lr:4.61e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.067, tt:8564.682\n",
      "Ep:145, loss:0.00001, loss_test:0.06888, lr:4.57e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.064, tt:8623.278\n",
      "Ep:146, loss:0.00001, loss_test:0.07025, lr:4.52e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.057, tt:8681.335\n",
      "Ep:147, loss:0.00001, loss_test:0.06908, lr:4.48e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.055, tt:8740.130\n",
      "Ep:148, loss:0.00001, loss_test:0.06970, lr:4.43e-03, fs:0.87006 (r=0.778,p=0.987),  time:59.049, tt:8798.230\n",
      "Ep:149, loss:0.00001, loss_test:0.06934, lr:4.39e-03, fs:0.86517 (r=0.778,p=0.975),  time:59.042, tt:8856.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 26\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14421, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.182, tt:49.182\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14197, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.675, tt:103.350\n",
      "Ep:2, loss:0.00055, loss_test:0.13708, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:52.334, tt:157.001\n",
      "Ep:3, loss:0.00052, loss_test:0.12540, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:52.413, tt:209.653\n",
      "Ep:4, loss:0.00048, loss_test:0.11687, lr:1.00e-02, fs:0.69608 (r=0.717,p=0.676),  time:53.685, tt:268.423\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.11527, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:54.751, tt:328.506\n",
      "Ep:6, loss:0.00043, loss_test:0.11288, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:55.292, tt:387.045\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.11099, lr:1.00e-02, fs:0.67980 (r=0.697,p=0.663),  time:55.644, tt:445.149\n",
      "Ep:8, loss:0.00038, loss_test:0.11016, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:56.074, tt:504.664\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.10816, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:56.401, tt:564.005\n",
      "Ep:10, loss:0.00034, loss_test:0.10761, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:56.664, tt:623.308\n",
      "Ep:11, loss:0.00033, loss_test:0.10979, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:56.944, tt:683.327\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.10902, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:57.213, tt:743.769\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00030, loss_test:0.10879, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:57.197, tt:800.759\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10989, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:57.346, tt:860.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00027, loss_test:0.10898, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:57.422, tt:918.756\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.10921, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:57.525, tt:977.930\n",
      "Ep:17, loss:0.00025, loss_test:0.10755, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:57.611, tt:1037.005\n",
      "Ep:18, loss:0.00024, loss_test:0.10775, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:57.724, tt:1096.753\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00023, loss_test:0.10581, lr:1.00e-02, fs:0.76684 (r=0.747,p=0.787),  time:57.789, tt:1155.774\n",
      "Ep:20, loss:0.00022, loss_test:0.10593, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:57.777, tt:1213.317\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10820, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:57.820, tt:1272.047\n",
      "Ep:22, loss:0.00020, loss_test:0.10710, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:57.716, tt:1327.459\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.10870, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:57.723, tt:1385.344\n",
      "Ep:24, loss:0.00019, loss_test:0.10701, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:57.642, tt:1441.056\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.10267, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:57.635, tt:1498.512\n",
      "Ep:26, loss:0.00017, loss_test:0.10391, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:57.553, tt:1553.932\n",
      "Ep:27, loss:0.00016, loss_test:0.10223, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:57.525, tt:1610.691\n",
      "Ep:28, loss:0.00015, loss_test:0.10281, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:57.535, tt:1668.514\n",
      "Ep:29, loss:0.00014, loss_test:0.10339, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:57.545, tt:1726.361\n",
      "Ep:30, loss:0.00013, loss_test:0.10211, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:57.554, tt:1784.160\n",
      "Ep:31, loss:0.00013, loss_test:0.10093, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:57.503, tt:1840.095\n",
      "Ep:32, loss:0.00012, loss_test:0.10221, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:57.440, tt:1895.514\n",
      "Ep:33, loss:0.00011, loss_test:0.09839, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:57.465, tt:1953.821\n",
      "Ep:34, loss:0.00011, loss_test:0.09884, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:57.488, tt:2012.073\n",
      "Ep:35, loss:0.00010, loss_test:0.10093, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:57.506, tt:2070.211\n",
      "Ep:36, loss:0.00010, loss_test:0.09901, lr:9.90e-03, fs:0.81967 (r=0.758,p=0.893),  time:57.516, tt:2128.089\n",
      "Ep:37, loss:0.00009, loss_test:0.09751, lr:9.80e-03, fs:0.80447 (r=0.727,p=0.900),  time:57.470, tt:2183.861\n",
      "Ep:38, loss:0.00009, loss_test:0.09767, lr:9.70e-03, fs:0.81768 (r=0.747,p=0.902),  time:57.474, tt:2241.477\n",
      "Ep:39, loss:0.00008, loss_test:0.09561, lr:9.61e-03, fs:0.77273 (r=0.687,p=0.883),  time:57.496, tt:2299.832\n",
      "Ep:40, loss:0.00008, loss_test:0.09734, lr:9.51e-03, fs:0.78409 (r=0.697,p=0.896),  time:57.537, tt:2359.015\n",
      "Ep:41, loss:0.00008, loss_test:0.09511, lr:9.41e-03, fs:0.80663 (r=0.737,p=0.890),  time:57.559, tt:2417.490\n",
      "Ep:42, loss:0.00007, loss_test:0.09790, lr:9.32e-03, fs:0.75145 (r=0.657,p=0.878),  time:57.534, tt:2473.957\n",
      "Ep:43, loss:0.00007, loss_test:0.09444, lr:9.23e-03, fs:0.73256 (r=0.636,p=0.863),  time:57.498, tt:2529.911\n",
      "Ep:44, loss:0.00007, loss_test:0.09470, lr:9.14e-03, fs:0.76571 (r=0.677,p=0.882),  time:57.435, tt:2584.570\n",
      "Ep:45, loss:0.00007, loss_test:0.09798, lr:9.04e-03, fs:0.79775 (r=0.717,p=0.899),  time:57.436, tt:2642.036\n",
      "Ep:46, loss:0.00006, loss_test:0.09608, lr:8.95e-03, fs:0.75581 (r=0.657,p=0.890),  time:57.441, tt:2699.736\n",
      "Ep:47, loss:0.00006, loss_test:0.09501, lr:8.86e-03, fs:0.76571 (r=0.677,p=0.882),  time:57.475, tt:2758.818\n",
      "Ep:48, loss:0.00006, loss_test:0.09682, lr:8.78e-03, fs:0.78409 (r=0.697,p=0.896),  time:57.494, tt:2817.207\n",
      "Ep:49, loss:0.00006, loss_test:0.09594, lr:8.69e-03, fs:0.76301 (r=0.667,p=0.892),  time:57.511, tt:2875.530\n",
      "Ep:50, loss:0.00006, loss_test:0.09441, lr:8.60e-03, fs:0.75862 (r=0.667,p=0.880),  time:57.519, tt:2933.488\n",
      "Ep:51, loss:0.00006, loss_test:0.09649, lr:8.51e-03, fs:0.77011 (r=0.677,p=0.893),  time:57.539, tt:2992.023\n",
      "Ep:52, loss:0.00005, loss_test:0.09806, lr:8.43e-03, fs:0.75145 (r=0.657,p=0.878),  time:57.563, tt:3050.862\n",
      "Ep:53, loss:0.00005, loss_test:0.09580, lr:8.35e-03, fs:0.79096 (r=0.707,p=0.897),  time:57.566, tt:3108.587\n",
      "Ep:54, loss:0.00005, loss_test:0.09883, lr:8.26e-03, fs:0.77714 (r=0.687,p=0.895),  time:57.606, tt:3168.354\n",
      "Ep:55, loss:0.00005, loss_test:0.09751, lr:8.18e-03, fs:0.79096 (r=0.707,p=0.897),  time:57.619, tt:3226.666\n",
      "Ep:56, loss:0.00005, loss_test:0.09856, lr:8.10e-03, fs:0.77011 (r=0.677,p=0.893),  time:57.681, tt:3287.811\n",
      "Ep:57, loss:0.00005, loss_test:0.09976, lr:8.02e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.659, tt:3344.223\n",
      "Ep:58, loss:0.00005, loss_test:0.09694, lr:7.94e-03, fs:0.74419 (r=0.646,p=0.877),  time:57.653, tt:3401.510\n",
      "Ep:59, loss:0.00004, loss_test:0.09852, lr:7.86e-03, fs:0.75581 (r=0.657,p=0.890),  time:57.631, tt:3457.854\n",
      "Ep:60, loss:0.00004, loss_test:0.09868, lr:7.78e-03, fs:0.75581 (r=0.657,p=0.890),  time:57.609, tt:3514.125\n",
      "Ep:61, loss:0.00004, loss_test:0.09751, lr:7.70e-03, fs:0.77011 (r=0.677,p=0.893),  time:57.635, tt:3573.365\n",
      "Ep:62, loss:0.00004, loss_test:0.10159, lr:7.62e-03, fs:0.75581 (r=0.657,p=0.890),  time:57.606, tt:3629.192\n",
      "Ep:63, loss:0.00004, loss_test:0.09920, lr:7.55e-03, fs:0.74118 (r=0.636,p=0.887),  time:57.583, tt:3685.322\n",
      "Ep:64, loss:0.00004, loss_test:0.10004, lr:7.47e-03, fs:0.72619 (r=0.616,p=0.884),  time:57.588, tt:3743.193\n",
      "Ep:65, loss:0.00004, loss_test:0.10005, lr:7.40e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.615, tt:3802.568\n",
      "Ep:66, loss:0.00004, loss_test:0.10114, lr:7.32e-03, fs:0.75581 (r=0.657,p=0.890),  time:57.610, tt:3859.854\n",
      "Ep:67, loss:0.00004, loss_test:0.09955, lr:7.25e-03, fs:0.74419 (r=0.646,p=0.877),  time:57.583, tt:3915.662\n",
      "Ep:68, loss:0.00004, loss_test:0.10127, lr:7.18e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.586, tt:3973.416\n",
      "Ep:69, loss:0.00004, loss_test:0.10162, lr:7.11e-03, fs:0.74118 (r=0.636,p=0.887),  time:57.621, tt:4033.495\n",
      "Ep:70, loss:0.00004, loss_test:0.10124, lr:7.03e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.627, tt:4091.513\n",
      "Ep:71, loss:0.00004, loss_test:0.10290, lr:6.96e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.607, tt:4147.727\n",
      "Ep:72, loss:0.00003, loss_test:0.10164, lr:6.89e-03, fs:0.72619 (r=0.616,p=0.884),  time:57.629, tt:4206.891\n",
      "Ep:73, loss:0.00003, loss_test:0.10231, lr:6.83e-03, fs:0.74118 (r=0.636,p=0.887),  time:57.658, tt:4266.656\n",
      "Ep:74, loss:0.00003, loss_test:0.10368, lr:6.76e-03, fs:0.74854 (r=0.646,p=0.889),  time:57.683, tt:4326.251\n",
      "Ep:75, loss:0.00003, loss_test:0.10070, lr:6.69e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.688, tt:4384.326\n",
      "Ep:76, loss:0.00003, loss_test:0.10489, lr:6.62e-03, fs:0.72289 (r=0.606,p=0.896),  time:57.696, tt:4442.585\n",
      "Ep:77, loss:0.00003, loss_test:0.10425, lr:6.56e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.677, tt:4498.805\n",
      "Ep:78, loss:0.00003, loss_test:0.10370, lr:6.49e-03, fs:0.72289 (r=0.606,p=0.896),  time:57.672, tt:4556.126\n",
      "Ep:79, loss:0.00003, loss_test:0.10386, lr:6.43e-03, fs:0.71515 (r=0.596,p=0.894),  time:57.713, tt:4617.016\n",
      "Ep:80, loss:0.00003, loss_test:0.10494, lr:6.36e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.735, tt:4676.504\n",
      "Ep:81, loss:0.00003, loss_test:0.10576, lr:6.30e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.737, tt:4734.473\n",
      "Ep:82, loss:0.00003, loss_test:0.10427, lr:6.24e-03, fs:0.71515 (r=0.596,p=0.894),  time:57.762, tt:4794.213\n",
      "Ep:83, loss:0.00003, loss_test:0.10575, lr:6.17e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.767, tt:4852.437\n",
      "Ep:84, loss:0.00003, loss_test:0.10458, lr:6.11e-03, fs:0.72289 (r=0.606,p=0.896),  time:57.742, tt:4908.048\n",
      "Ep:85, loss:0.00003, loss_test:0.10571, lr:6.05e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.750, tt:4966.458\n",
      "Ep:86, loss:0.00003, loss_test:0.10508, lr:5.99e-03, fs:0.67901 (r=0.556,p=0.873),  time:57.762, tt:5025.333\n",
      "Ep:87, loss:0.00003, loss_test:0.10650, lr:5.93e-03, fs:0.71084 (r=0.596,p=0.881),  time:57.790, tt:5085.491\n",
      "Ep:88, loss:0.00003, loss_test:0.10563, lr:5.87e-03, fs:0.67901 (r=0.556,p=0.873),  time:57.771, tt:5141.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00003, loss_test:0.10566, lr:5.81e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.763, tt:5198.655\n",
      "Ep:90, loss:0.00003, loss_test:0.10525, lr:5.75e-03, fs:0.67081 (r=0.545,p=0.871),  time:57.772, tt:5257.211\n",
      "Ep:91, loss:0.00003, loss_test:0.10671, lr:5.70e-03, fs:0.71084 (r=0.596,p=0.881),  time:57.795, tt:5317.144\n",
      "Ep:92, loss:0.00002, loss_test:0.10752, lr:5.64e-03, fs:0.70303 (r=0.586,p=0.879),  time:57.809, tt:5376.252\n",
      "Ep:93, loss:0.00002, loss_test:0.10518, lr:5.58e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.838, tt:5436.759\n",
      "Ep:94, loss:0.00002, loss_test:0.10739, lr:5.53e-03, fs:0.71429 (r=0.606,p=0.870),  time:57.856, tt:5496.343\n",
      "Ep:95, loss:0.00002, loss_test:0.10548, lr:5.47e-03, fs:0.66667 (r=0.545,p=0.857),  time:57.874, tt:5555.925\n",
      "Ep:96, loss:0.00002, loss_test:0.10852, lr:5.42e-03, fs:0.71856 (r=0.606,p=0.882),  time:57.874, tt:5613.821\n",
      "Ep:97, loss:0.00002, loss_test:0.10579, lr:5.36e-03, fs:0.71429 (r=0.606,p=0.870),  time:57.879, tt:5672.184\n",
      "Ep:98, loss:0.00002, loss_test:0.10704, lr:5.31e-03, fs:0.67081 (r=0.545,p=0.871),  time:57.867, tt:5728.879\n",
      "Ep:99, loss:0.00002, loss_test:0.10691, lr:5.26e-03, fs:0.71429 (r=0.606,p=0.870),  time:57.872, tt:5787.197\n",
      "Ep:100, loss:0.00002, loss_test:0.10627, lr:5.20e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.899, tt:5847.833\n",
      "Ep:101, loss:0.00002, loss_test:0.10647, lr:5.15e-03, fs:0.69880 (r=0.586,p=0.866),  time:57.910, tt:5906.775\n",
      "Ep:102, loss:0.00002, loss_test:0.10695, lr:5.10e-03, fs:0.68293 (r=0.566,p=0.862),  time:57.875, tt:5961.085\n",
      "Ep:103, loss:0.00002, loss_test:0.10736, lr:5.05e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.862, tt:6017.628\n",
      "Ep:104, loss:0.00002, loss_test:0.10650, lr:5.00e-03, fs:0.68293 (r=0.566,p=0.862),  time:57.857, tt:6075.011\n",
      "Ep:105, loss:0.00002, loss_test:0.10723, lr:4.95e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.879, tt:6135.154\n",
      "Ep:106, loss:0.00002, loss_test:0.10710, lr:4.90e-03, fs:0.68293 (r=0.566,p=0.862),  time:57.913, tt:6196.704\n",
      "Ep:107, loss:0.00002, loss_test:0.10646, lr:4.85e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.922, tt:6255.535\n",
      "Ep:108, loss:0.00002, loss_test:0.10804, lr:4.80e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.943, tt:6315.742\n",
      "Ep:109, loss:0.00002, loss_test:0.10666, lr:4.75e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.966, tt:6376.309\n",
      "Ep:110, loss:0.00002, loss_test:0.10719, lr:4.71e-03, fs:0.66667 (r=0.545,p=0.857),  time:57.966, tt:6434.229\n",
      "Ep:111, loss:0.00002, loss_test:0.10714, lr:4.66e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.981, tt:6493.868\n",
      "Ep:112, loss:0.00002, loss_test:0.10744, lr:4.61e-03, fs:0.67485 (r=0.556,p=0.859),  time:57.996, tt:6553.532\n",
      "Ep:113, loss:0.00002, loss_test:0.10740, lr:4.57e-03, fs:0.67485 (r=0.556,p=0.859),  time:58.012, tt:6613.347\n",
      "Ep:114, loss:0.00002, loss_test:0.10687, lr:4.52e-03, fs:0.68293 (r=0.566,p=0.862),  time:58.031, tt:6673.527\n",
      "Ep:115, loss:0.00002, loss_test:0.10729, lr:4.48e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.043, tt:6733.026\n",
      "Ep:116, loss:0.00002, loss_test:0.10696, lr:4.43e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.072, tt:6794.401\n",
      "Ep:117, loss:0.00002, loss_test:0.10915, lr:4.39e-03, fs:0.67485 (r=0.556,p=0.859),  time:58.078, tt:6853.172\n",
      "Ep:118, loss:0.00002, loss_test:0.10647, lr:4.34e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.079, tt:6911.459\n",
      "Ep:119, loss:0.00002, loss_test:0.10815, lr:4.30e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.076, tt:6969.112\n",
      "Ep:120, loss:0.00002, loss_test:0.10793, lr:4.26e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.071, tt:7026.553\n",
      "Ep:121, loss:0.00002, loss_test:0.10657, lr:4.21e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.077, tt:7085.452\n",
      "Ep:122, loss:0.00002, loss_test:0.10876, lr:4.17e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.074, tt:7143.050\n",
      "Ep:123, loss:0.00002, loss_test:0.10708, lr:4.13e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.077, tt:7201.485\n",
      "Ep:124, loss:0.00002, loss_test:0.10740, lr:4.09e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.056, tt:7257.049\n",
      "Ep:125, loss:0.00002, loss_test:0.10789, lr:4.05e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.053, tt:7314.652\n",
      "Ep:126, loss:0.00002, loss_test:0.10766, lr:4.01e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.064, tt:7374.111\n",
      "Ep:127, loss:0.00002, loss_test:0.10779, lr:3.97e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.091, tt:7435.658\n",
      "Ep:128, loss:0.00002, loss_test:0.10812, lr:3.93e-03, fs:0.67485 (r=0.556,p=0.859),  time:58.091, tt:7493.753\n",
      "Ep:129, loss:0.00002, loss_test:0.10718, lr:3.89e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.102, tt:7553.216\n",
      "Ep:130, loss:0.00002, loss_test:0.10701, lr:3.85e-03, fs:0.67485 (r=0.556,p=0.859),  time:58.109, tt:7612.263\n",
      "Ep:131, loss:0.00002, loss_test:0.10854, lr:3.81e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.113, tt:7670.891\n",
      "Ep:132, loss:0.00002, loss_test:0.10692, lr:3.77e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.108, tt:7728.325\n",
      "Ep:133, loss:0.00002, loss_test:0.10793, lr:3.73e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.126, tt:7788.939\n",
      "Ep:134, loss:0.00002, loss_test:0.10744, lr:3.70e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.111, tt:7844.955\n",
      "Ep:135, loss:0.00002, loss_test:0.10772, lr:3.66e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.119, tt:7904.251\n",
      "Ep:136, loss:0.00002, loss_test:0.10764, lr:3.62e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.136, tt:7964.565\n",
      "Ep:137, loss:0.00002, loss_test:0.10781, lr:3.59e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.120, tt:8020.605\n",
      "Ep:138, loss:0.00002, loss_test:0.10738, lr:3.55e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.126, tt:8079.556\n",
      "Ep:139, loss:0.00002, loss_test:0.10807, lr:3.52e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.129, tt:8138.084\n",
      "Ep:140, loss:0.00002, loss_test:0.10773, lr:3.48e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.144, tt:8198.326\n",
      "Ep:141, loss:0.00002, loss_test:0.10765, lr:3.45e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.143, tt:8256.329\n",
      "Ep:142, loss:0.00002, loss_test:0.10756, lr:3.41e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.162, tt:8317.185\n",
      "Ep:143, loss:0.00002, loss_test:0.10738, lr:3.38e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.179, tt:8377.761\n",
      "Ep:144, loss:0.00002, loss_test:0.10770, lr:3.34e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.179, tt:8435.980\n",
      "Ep:145, loss:0.00002, loss_test:0.10757, lr:3.31e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.152, tt:8490.149\n",
      "Ep:146, loss:0.00002, loss_test:0.10766, lr:3.28e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.143, tt:8547.079\n",
      "Ep:147, loss:0.00002, loss_test:0.10849, lr:3.24e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.157, tt:8607.218\n",
      "Ep:148, loss:0.00002, loss_test:0.10755, lr:3.21e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.142, tt:8663.210\n",
      "Ep:149, loss:0.00001, loss_test:0.10800, lr:3.18e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.113, tt:8716.886\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 27\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14307, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.375, tt:46.375\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14084, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.445, tt:100.889\n",
      "Ep:2, loss:0.00055, loss_test:0.13630, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:51.935, tt:155.806\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.12583, lr:1.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:52.230, tt:208.919\n",
      "Ep:4, loss:0.00047, loss_test:0.12305, lr:1.00e-02, fs:0.60870 (r=0.636,p=0.583),  time:53.204, tt:266.022\n",
      "Ep:5, loss:0.00044, loss_test:0.12148, lr:1.00e-02, fs:0.59361 (r=0.657,p=0.542),  time:53.994, tt:323.962\n",
      "Ep:6, loss:0.00042, loss_test:0.11804, lr:1.00e-02, fs:0.61395 (r=0.667,p=0.569),  time:54.692, tt:382.845\n",
      "Ep:7, loss:0.00040, loss_test:0.11329, lr:1.00e-02, fs:0.65025 (r=0.667,p=0.635),  time:55.337, tt:442.693\n",
      "Ep:8, loss:0.00038, loss_test:0.11309, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:55.824, tt:502.412\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00036, loss_test:0.11208, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:56.121, tt:561.214\n",
      "Ep:10, loss:0.00034, loss_test:0.10978, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:56.540, tt:621.937\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.10940, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:56.703, tt:680.439\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.11007, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:56.822, tt:738.682\n",
      "Ep:13, loss:0.00031, loss_test:0.10885, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:56.994, tt:797.921\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10816, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:56.986, tt:854.786\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.10621, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:57.161, tt:914.572\n",
      "Ep:16, loss:0.00027, loss_test:0.10379, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:57.319, tt:974.419\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.10355, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:57.593, tt:1036.675\n",
      "Ep:18, loss:0.00025, loss_test:0.10275, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:57.663, tt:1095.590\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.10038, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:57.849, tt:1156.983\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.09950, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:57.933, tt:1216.583\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.09835, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:58.049, tt:1277.087\n",
      "Ep:22, loss:0.00021, loss_test:0.09697, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:58.133, tt:1337.063\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.09559, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:58.181, tt:1396.355\n",
      "Ep:24, loss:0.00020, loss_test:0.09398, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:58.219, tt:1455.478\n",
      "Ep:25, loss:0.00019, loss_test:0.09248, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:58.125, tt:1511.257\n",
      "Ep:26, loss:0.00018, loss_test:0.09330, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:58.132, tt:1569.557\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00017, loss_test:0.09032, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:58.161, tt:1628.506\n",
      "Ep:28, loss:0.00016, loss_test:0.08850, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:58.161, tt:1686.678\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.09118, lr:1.00e-02, fs:0.86188 (r=0.788,p=0.951),  time:58.139, tt:1744.172\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.08689, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:58.160, tt:1802.973\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.08582, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:58.104, tt:1859.343\n",
      "Ep:32, loss:0.00013, loss_test:0.08634, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:58.051, tt:1915.686\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08743, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:57.970, tt:1970.973\n",
      "Ep:34, loss:0.00012, loss_test:0.08246, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:58.020, tt:2030.689\n",
      "Ep:35, loss:0.00011, loss_test:0.08305, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:58.044, tt:2089.589\n",
      "Ep:36, loss:0.00011, loss_test:0.08100, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:58.029, tt:2147.068\n",
      "Ep:37, loss:0.00010, loss_test:0.08082, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:57.993, tt:2203.742\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.07943, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:57.979, tt:2261.168\n",
      "Ep:39, loss:0.00009, loss_test:0.07844, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:58.030, tt:2321.215\n",
      "Ep:40, loss:0.00009, loss_test:0.07867, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:58.003, tt:2378.132\n",
      "Ep:41, loss:0.00008, loss_test:0.07825, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:58.057, tt:2438.411\n",
      "Ep:42, loss:0.00008, loss_test:0.07795, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:58.064, tt:2496.759\n",
      "Ep:43, loss:0.00008, loss_test:0.07852, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:58.033, tt:2553.451\n",
      "Ep:44, loss:0.00008, loss_test:0.07637, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:57.978, tt:2608.994\n",
      "Ep:45, loss:0.00007, loss_test:0.07495, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:58.025, tt:2669.142\n",
      "Ep:46, loss:0.00007, loss_test:0.07564, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:58.004, tt:2726.173\n",
      "Ep:47, loss:0.00006, loss_test:0.07470, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:57.999, tt:2783.961\n",
      "Ep:48, loss:0.00006, loss_test:0.07457, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:58.011, tt:2842.524\n",
      "Ep:49, loss:0.00006, loss_test:0.07457, lr:9.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:57.968, tt:2898.375\n",
      "Ep:50, loss:0.00006, loss_test:0.07342, lr:9.80e-03, fs:0.87568 (r=0.818,p=0.942),  time:57.936, tt:2954.723\n",
      "Ep:51, loss:0.00006, loss_test:0.07310, lr:9.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:57.909, tt:3011.287\n",
      "Ep:52, loss:0.00006, loss_test:0.07338, lr:9.61e-03, fs:0.88043 (r=0.818,p=0.953),  time:57.877, tt:3067.474\n",
      "Ep:53, loss:0.00005, loss_test:0.07358, lr:9.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.857, tt:3124.292\n",
      "Ep:54, loss:0.00005, loss_test:0.07424, lr:9.41e-03, fs:0.88649 (r=0.828,p=0.953),  time:57.812, tt:3179.653\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.07240, lr:9.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:57.771, tt:3235.171\n",
      "Ep:56, loss:0.00005, loss_test:0.07169, lr:9.41e-03, fs:0.87568 (r=0.818,p=0.942),  time:57.766, tt:3292.634\n",
      "Ep:57, loss:0.00005, loss_test:0.07345, lr:9.41e-03, fs:0.88043 (r=0.818,p=0.953),  time:57.791, tt:3351.866\n",
      "Ep:58, loss:0.00005, loss_test:0.07359, lr:9.41e-03, fs:0.86957 (r=0.808,p=0.941),  time:57.774, tt:3408.672\n",
      "Ep:59, loss:0.00005, loss_test:0.07229, lr:9.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.796, tt:3467.747\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00004, loss_test:0.07197, lr:9.41e-03, fs:0.88298 (r=0.838,p=0.933),  time:57.803, tt:3525.987\n",
      "Ep:61, loss:0.00004, loss_test:0.07291, lr:9.41e-03, fs:0.88172 (r=0.828,p=0.943),  time:57.827, tt:3585.266\n",
      "Ep:62, loss:0.00004, loss_test:0.07168, lr:9.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:57.834, tt:3643.562\n",
      "Ep:63, loss:0.00004, loss_test:0.07208, lr:9.41e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.839, tt:3701.709\n",
      "Ep:64, loss:0.00004, loss_test:0.07215, lr:9.41e-03, fs:0.88525 (r=0.818,p=0.964),  time:57.782, tt:3755.861\n",
      "Ep:65, loss:0.00004, loss_test:0.07204, lr:9.41e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.790, tt:3814.173\n",
      "Ep:66, loss:0.00004, loss_test:0.07109, lr:9.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.751, tt:3869.303\n",
      "Ep:67, loss:0.00004, loss_test:0.07225, lr:9.41e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.700, tt:3923.590\n",
      "Ep:68, loss:0.00004, loss_test:0.07228, lr:9.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.711, tt:3982.057\n",
      "Ep:69, loss:0.00004, loss_test:0.07102, lr:9.41e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.725, tt:4040.731\n",
      "Ep:70, loss:0.00003, loss_test:0.07263, lr:9.41e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.655, tt:4093.536\n",
      "Ep:71, loss:0.00003, loss_test:0.07167, lr:9.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.674, tt:4152.500\n",
      "Ep:72, loss:0.00003, loss_test:0.07010, lr:9.23e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.607, tt:4205.285\n",
      "Ep:73, loss:0.00003, loss_test:0.07101, lr:9.14e-03, fs:0.87432 (r=0.808,p=0.952),  time:57.548, tt:4258.560\n",
      "Ep:74, loss:0.00003, loss_test:0.07008, lr:9.04e-03, fs:0.87432 (r=0.808,p=0.952),  time:57.550, tt:4316.224\n",
      "Ep:75, loss:0.00003, loss_test:0.07107, lr:8.95e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.542, tt:4373.191\n",
      "Ep:76, loss:0.00003, loss_test:0.07316, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.544, tt:4430.895\n",
      "Ep:77, loss:0.00003, loss_test:0.07091, lr:8.78e-03, fs:0.88398 (r=0.808,p=0.976),  time:57.542, tt:4488.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:78, loss:0.00003, loss_test:0.07146, lr:8.69e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.533, tt:4545.076\n",
      "Ep:79, loss:0.00003, loss_test:0.07080, lr:8.60e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.532, tt:4602.562\n",
      "Ep:80, loss:0.00003, loss_test:0.07080, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.518, tt:4658.981\n",
      "Ep:81, loss:0.00002, loss_test:0.07139, lr:8.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.495, tt:4714.580\n",
      "Ep:82, loss:0.00002, loss_test:0.06968, lr:8.35e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.487, tt:4771.394\n",
      "Ep:83, loss:0.00002, loss_test:0.07016, lr:8.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.489, tt:4829.044\n",
      "Ep:84, loss:0.00002, loss_test:0.07187, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.483, tt:4886.027\n",
      "Ep:85, loss:0.00002, loss_test:0.07069, lr:8.10e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.479, tt:4943.169\n",
      "Ep:86, loss:0.00002, loss_test:0.06993, lr:8.02e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.438, tt:4997.147\n",
      "Ep:87, loss:0.00002, loss_test:0.07112, lr:7.94e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.422, tt:5053.175\n",
      "Ep:88, loss:0.00002, loss_test:0.07013, lr:7.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.379, tt:5106.703\n",
      "Ep:89, loss:0.00002, loss_test:0.07093, lr:7.78e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.363, tt:5162.686\n",
      "Ep:90, loss:0.00002, loss_test:0.06999, lr:7.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.376, tt:5221.210\n",
      "Ep:91, loss:0.00002, loss_test:0.07115, lr:7.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.335, tt:5274.821\n",
      "Ep:92, loss:0.00002, loss_test:0.07046, lr:7.55e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.331, tt:5331.756\n",
      "Ep:93, loss:0.00002, loss_test:0.06989, lr:7.47e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.319, tt:5387.963\n",
      "Ep:94, loss:0.00002, loss_test:0.07039, lr:7.40e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.295, tt:5442.979\n",
      "Ep:95, loss:0.00002, loss_test:0.07022, lr:7.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.270, tt:5497.963\n",
      "Ep:96, loss:0.00002, loss_test:0.07118, lr:7.25e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.276, tt:5555.794\n",
      "Ep:97, loss:0.00002, loss_test:0.07095, lr:7.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.292, tt:5614.656\n",
      "Ep:98, loss:0.00002, loss_test:0.07043, lr:7.11e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.294, tt:5672.107\n",
      "Ep:99, loss:0.00002, loss_test:0.07080, lr:7.03e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.294, tt:5729.354\n",
      "Ep:100, loss:0.00002, loss_test:0.07035, lr:6.96e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.287, tt:5785.943\n",
      "Ep:101, loss:0.00002, loss_test:0.07021, lr:6.89e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.278, tt:5842.377\n",
      "Ep:102, loss:0.00002, loss_test:0.07108, lr:6.83e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.277, tt:5899.536\n",
      "Ep:103, loss:0.00002, loss_test:0.07033, lr:6.76e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.283, tt:5957.471\n",
      "Ep:104, loss:0.00002, loss_test:0.07068, lr:6.69e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.278, tt:6014.145\n",
      "Ep:105, loss:0.00002, loss_test:0.07056, lr:6.62e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.266, tt:6070.181\n",
      "Ep:106, loss:0.00002, loss_test:0.07012, lr:6.56e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.260, tt:6126.845\n",
      "Ep:107, loss:0.00001, loss_test:0.07098, lr:6.49e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.256, tt:6183.604\n",
      "Ep:108, loss:0.00001, loss_test:0.07168, lr:6.43e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.278, tt:6243.259\n",
      "Ep:109, loss:0.00001, loss_test:0.07096, lr:6.36e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.294, tt:6302.310\n",
      "Ep:110, loss:0.00001, loss_test:0.07039, lr:6.30e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.297, tt:6360.009\n",
      "Ep:111, loss:0.00001, loss_test:0.07193, lr:6.24e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.307, tt:6418.382\n",
      "Ep:112, loss:0.00001, loss_test:0.07169, lr:6.17e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.320, tt:6477.165\n",
      "Ep:113, loss:0.00001, loss_test:0.07057, lr:6.11e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.332, tt:6535.836\n",
      "Ep:114, loss:0.00001, loss_test:0.07069, lr:6.05e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.355, tt:6595.871\n",
      "Ep:115, loss:0.00001, loss_test:0.07174, lr:5.99e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.369, tt:6654.747\n",
      "Ep:116, loss:0.00001, loss_test:0.07082, lr:5.93e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.403, tt:6716.171\n",
      "Ep:117, loss:0.00001, loss_test:0.07119, lr:5.87e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.423, tt:6775.863\n",
      "Ep:118, loss:0.00001, loss_test:0.07151, lr:5.81e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.435, tt:6834.755\n",
      "Ep:119, loss:0.00001, loss_test:0.07076, lr:5.75e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.445, tt:6893.391\n",
      "Ep:120, loss:0.00001, loss_test:0.07154, lr:5.70e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.461, tt:6952.818\n",
      "Ep:121, loss:0.00001, loss_test:0.07086, lr:5.64e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.487, tt:7013.448\n",
      "Ep:122, loss:0.00001, loss_test:0.07166, lr:5.58e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.506, tt:7073.267\n",
      "Ep:123, loss:0.00001, loss_test:0.07094, lr:5.53e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.509, tt:7131.083\n",
      "Ep:124, loss:0.00001, loss_test:0.07082, lr:5.47e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.517, tt:7189.630\n",
      "Ep:125, loss:0.00001, loss_test:0.07223, lr:5.42e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.518, tt:7247.237\n",
      "Ep:126, loss:0.00001, loss_test:0.07112, lr:5.36e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.532, tt:7306.519\n",
      "Ep:127, loss:0.00001, loss_test:0.07180, lr:5.31e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.552, tt:7366.619\n",
      "Ep:128, loss:0.00001, loss_test:0.07185, lr:5.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.541, tt:7422.761\n",
      "Ep:129, loss:0.00001, loss_test:0.07154, lr:5.20e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.564, tt:7483.380\n",
      "Ep:130, loss:0.00001, loss_test:0.07202, lr:5.15e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.558, tt:7540.104\n",
      "Ep:131, loss:0.00001, loss_test:0.07160, lr:5.10e-03, fs:0.87293 (r=0.798,p=0.963),  time:57.578, tt:7600.279\n",
      "Ep:132, loss:0.00001, loss_test:0.07210, lr:5.05e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.582, tt:7658.342\n",
      "Ep:133, loss:0.00001, loss_test:0.07163, lr:5.00e-03, fs:0.87293 (r=0.798,p=0.963),  time:57.616, tt:7720.497\n",
      "Ep:134, loss:0.00001, loss_test:0.07162, lr:4.95e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.637, tt:7780.956\n",
      "Ep:135, loss:0.00001, loss_test:0.07149, lr:4.90e-03, fs:0.87912 (r=0.808,p=0.964),  time:57.633, tt:7838.021\n",
      "Ep:136, loss:0.00001, loss_test:0.07193, lr:4.85e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.640, tt:7896.745\n",
      "Ep:137, loss:0.00001, loss_test:0.07161, lr:4.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:57.655, tt:7956.403\n",
      "Ep:138, loss:0.00001, loss_test:0.07191, lr:4.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:57.661, tt:8014.898\n",
      "Ep:139, loss:0.00001, loss_test:0.07189, lr:4.71e-03, fs:0.85393 (r=0.768,p=0.962),  time:57.669, tt:8073.630\n",
      "Ep:140, loss:0.00001, loss_test:0.07218, lr:4.66e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.675, tt:8132.112\n",
      "Ep:141, loss:0.00001, loss_test:0.07219, lr:4.61e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.696, tt:8192.899\n",
      "Ep:142, loss:0.00001, loss_test:0.07201, lr:4.57e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.724, tt:8254.590\n",
      "Ep:143, loss:0.00001, loss_test:0.07267, lr:4.52e-03, fs:0.86667 (r=0.788,p=0.963),  time:57.739, tt:8314.407\n",
      "Ep:144, loss:0.00001, loss_test:0.07247, lr:4.48e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.723, tt:8369.826\n",
      "Ep:145, loss:0.00001, loss_test:0.07179, lr:4.43e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.739, tt:8429.933\n",
      "Ep:146, loss:0.00001, loss_test:0.07255, lr:4.39e-03, fs:0.82759 (r=0.727,p=0.960),  time:57.762, tt:8490.955\n",
      "Ep:147, loss:0.00001, loss_test:0.07219, lr:4.34e-03, fs:0.83429 (r=0.737,p=0.961),  time:57.780, tt:8551.397\n",
      "Ep:148, loss:0.00001, loss_test:0.07211, lr:4.30e-03, fs:0.82081 (r=0.717,p=0.959),  time:57.772, tt:8608.089\n",
      "Ep:149, loss:0.00001, loss_test:0.07292, lr:4.26e-03, fs:0.79290 (r=0.677,p=0.957),  time:57.785, tt:8667.717\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 28\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14768, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.986, tt:52.986\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14663, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.066, tt:112.132\n",
      "Ep:2, loss:0.00055, loss_test:0.14428, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:56.336, tt:169.008\n",
      "Ep:3, loss:0.00052, loss_test:0.13719, lr:1.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:55.550, tt:222.199\n",
      "Ep:4, loss:0.00047, loss_test:0.12961, lr:1.00e-02, fs:0.59701 (r=0.606,p=0.588),  time:56.780, tt:283.898\n",
      "Ep:5, loss:0.00045, loss_test:0.12530, lr:1.00e-02, fs:0.62727 (r=0.697,p=0.570),  time:57.427, tt:344.562\n",
      "Ep:6, loss:0.00042, loss_test:0.12161, lr:1.00e-02, fs:0.64545 (r=0.717,p=0.587),  time:58.341, tt:408.389\n",
      "Ep:7, loss:0.00040, loss_test:0.11861, lr:1.00e-02, fs:0.64039 (r=0.657,p=0.625),  time:58.684, tt:469.473\n",
      "Ep:8, loss:0.00038, loss_test:0.11223, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:58.968, tt:530.708\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.11169, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:59.008, tt:590.079\n",
      "Ep:10, loss:0.00035, loss_test:0.11002, lr:1.00e-02, fs:0.67961 (r=0.707,p=0.654),  time:59.183, tt:651.012\n",
      "Ep:11, loss:0.00033, loss_test:0.10990, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:59.340, tt:712.074\n",
      "Ep:12, loss:0.00032, loss_test:0.10909, lr:1.00e-02, fs:0.65306 (r=0.646,p=0.660),  time:59.315, tt:771.097\n",
      "Ep:13, loss:0.00031, loss_test:0.10773, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:59.247, tt:829.456\n",
      "Ep:14, loss:0.00029, loss_test:0.10687, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:59.335, tt:890.024\n",
      "Ep:15, loss:0.00028, loss_test:0.10672, lr:1.00e-02, fs:0.67708 (r=0.657,p=0.699),  time:59.188, tt:947.003\n",
      "Ep:16, loss:0.00027, loss_test:0.10442, lr:1.00e-02, fs:0.67380 (r=0.636,p=0.716),  time:59.097, tt:1004.646\n",
      "Ep:17, loss:0.00026, loss_test:0.10371, lr:1.00e-02, fs:0.67368 (r=0.646,p=0.703),  time:59.018, tt:1062.317\n",
      "Ep:18, loss:0.00025, loss_test:0.10351, lr:1.00e-02, fs:0.67725 (r=0.646,p=0.711),  time:59.085, tt:1122.608\n",
      "Ep:19, loss:0.00024, loss_test:0.10143, lr:1.00e-02, fs:0.67027 (r=0.626,p=0.721),  time:59.188, tt:1183.767\n",
      "Ep:20, loss:0.00022, loss_test:0.10162, lr:9.90e-03, fs:0.68085 (r=0.646,p=0.719),  time:59.198, tt:1243.152\n",
      "Ep:21, loss:0.00021, loss_test:0.10110, lr:9.80e-03, fs:0.68478 (r=0.636,p=0.741),  time:59.236, tt:1303.183\n",
      "Ep:22, loss:0.00020, loss_test:0.09963, lr:9.70e-03, fs:0.67778 (r=0.616,p=0.753),  time:59.288, tt:1363.629\n",
      "Ep:23, loss:0.00019, loss_test:0.10229, lr:9.61e-03, fs:0.67836 (r=0.586,p=0.806),  time:59.212, tt:1421.092\n",
      "Ep:24, loss:0.00018, loss_test:0.09741, lr:9.51e-03, fs:0.71658 (r=0.677,p=0.761),  time:59.160, tt:1479.008\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.09855, lr:9.51e-03, fs:0.68966 (r=0.606,p=0.800),  time:59.159, tt:1538.129\n",
      "Ep:26, loss:0.00016, loss_test:0.09905, lr:9.51e-03, fs:0.67442 (r=0.586,p=0.795),  time:59.190, tt:1598.140\n",
      "Ep:27, loss:0.00016, loss_test:0.09747, lr:9.51e-03, fs:0.69767 (r=0.606,p=0.822),  time:59.191, tt:1657.339\n",
      "Ep:28, loss:0.00015, loss_test:0.09747, lr:9.51e-03, fs:0.68605 (r=0.596,p=0.808),  time:59.093, tt:1713.698\n",
      "Ep:29, loss:0.00014, loss_test:0.09703, lr:9.51e-03, fs:0.68966 (r=0.606,p=0.800),  time:59.126, tt:1773.794\n",
      "Ep:30, loss:0.00013, loss_test:0.09808, lr:9.51e-03, fs:0.72000 (r=0.636,p=0.829),  time:59.071, tt:1831.190\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09680, lr:9.51e-03, fs:0.74317 (r=0.687,p=0.810),  time:59.050, tt:1889.591\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.09832, lr:9.51e-03, fs:0.70115 (r=0.616,p=0.813),  time:59.029, tt:1947.969\n",
      "Ep:33, loss:0.00012, loss_test:0.09811, lr:9.51e-03, fs:0.67456 (r=0.576,p=0.814),  time:59.032, tt:2007.073\n",
      "Ep:34, loss:0.00011, loss_test:0.09748, lr:9.51e-03, fs:0.67857 (r=0.576,p=0.826),  time:59.046, tt:2066.609\n",
      "Ep:35, loss:0.00011, loss_test:0.09561, lr:9.51e-03, fs:0.70588 (r=0.606,p=0.845),  time:59.020, tt:2124.737\n",
      "Ep:36, loss:0.00010, loss_test:0.10061, lr:9.51e-03, fs:0.67066 (r=0.566,p=0.824),  time:58.998, tt:2182.907\n",
      "Ep:37, loss:0.00010, loss_test:0.09370, lr:9.51e-03, fs:0.72316 (r=0.646,p=0.821),  time:59.024, tt:2242.906\n",
      "Ep:38, loss:0.00009, loss_test:0.10160, lr:9.51e-03, fs:0.66667 (r=0.545,p=0.857),  time:58.974, tt:2299.997\n",
      "Ep:39, loss:0.00009, loss_test:0.09615, lr:9.51e-03, fs:0.72000 (r=0.636,p=0.829),  time:58.923, tt:2356.902\n",
      "Ep:40, loss:0.00009, loss_test:0.09813, lr:9.51e-03, fs:0.72414 (r=0.636,p=0.840),  time:58.912, tt:2415.402\n",
      "Ep:41, loss:0.00008, loss_test:0.09978, lr:9.51e-03, fs:0.70520 (r=0.616,p=0.824),  time:58.880, tt:2472.954\n",
      "Ep:42, loss:0.00008, loss_test:0.09791, lr:9.51e-03, fs:0.72316 (r=0.646,p=0.821),  time:58.895, tt:2532.469\n",
      "Ep:43, loss:0.00008, loss_test:0.10181, lr:9.41e-03, fs:0.70857 (r=0.626,p=0.816),  time:58.940, tt:2593.348\n",
      "Ep:44, loss:0.00008, loss_test:0.09755, lr:9.32e-03, fs:0.71591 (r=0.636,p=0.818),  time:59.020, tt:2655.903\n",
      "Ep:45, loss:0.00007, loss_test:0.09960, lr:9.23e-03, fs:0.73684 (r=0.636,p=0.875),  time:58.989, tt:2713.486\n",
      "Ep:46, loss:0.00007, loss_test:0.09852, lr:9.14e-03, fs:0.72414 (r=0.636,p=0.840),  time:58.955, tt:2770.905\n",
      "Ep:47, loss:0.00007, loss_test:0.10083, lr:9.04e-03, fs:0.72414 (r=0.636,p=0.840),  time:58.924, tt:2828.364\n",
      "Ep:48, loss:0.00007, loss_test:0.09957, lr:8.95e-03, fs:0.73256 (r=0.636,p=0.863),  time:58.935, tt:2887.815\n",
      "Ep:49, loss:0.00006, loss_test:0.10069, lr:8.86e-03, fs:0.72832 (r=0.636,p=0.851),  time:58.931, tt:2946.567\n",
      "Ep:50, loss:0.00006, loss_test:0.10066, lr:8.78e-03, fs:0.73256 (r=0.636,p=0.863),  time:58.939, tt:3005.874\n",
      "Ep:51, loss:0.00006, loss_test:0.10049, lr:8.69e-03, fs:0.72316 (r=0.646,p=0.821),  time:58.909, tt:3063.282\n",
      "Ep:52, loss:0.00006, loss_test:0.10043, lr:8.60e-03, fs:0.71508 (r=0.646,p=0.800),  time:58.916, tt:3122.532\n",
      "Ep:53, loss:0.00006, loss_test:0.10349, lr:8.51e-03, fs:0.71910 (r=0.646,p=0.810),  time:58.897, tt:3180.411\n",
      "Ep:54, loss:0.00006, loss_test:0.10205, lr:8.43e-03, fs:0.72727 (r=0.646,p=0.831),  time:58.903, tt:3239.683\n",
      "Ep:55, loss:0.00006, loss_test:0.10147, lr:8.35e-03, fs:0.73256 (r=0.636,p=0.863),  time:58.946, tt:3300.985\n",
      "Ep:56, loss:0.00005, loss_test:0.10188, lr:8.26e-03, fs:0.72316 (r=0.646,p=0.821),  time:59.028, tt:3364.613\n",
      "Ep:57, loss:0.00005, loss_test:0.10154, lr:8.18e-03, fs:0.73143 (r=0.646,p=0.842),  time:59.033, tt:3423.892\n",
      "Ep:58, loss:0.00005, loss_test:0.10357, lr:8.10e-03, fs:0.72515 (r=0.626,p=0.861),  time:58.996, tt:3480.744\n",
      "Ep:59, loss:0.00005, loss_test:0.10262, lr:8.02e-03, fs:0.73034 (r=0.657,p=0.823),  time:59.003, tt:3540.175\n",
      "Ep:60, loss:0.00005, loss_test:0.10378, lr:7.94e-03, fs:0.72832 (r=0.636,p=0.851),  time:58.939, tt:3595.299\n",
      "Ep:61, loss:0.00005, loss_test:0.10298, lr:7.86e-03, fs:0.72414 (r=0.636,p=0.840),  time:58.949, tt:3654.814\n",
      "Ep:62, loss:0.00005, loss_test:0.10388, lr:7.78e-03, fs:0.72000 (r=0.636,p=0.829),  time:58.914, tt:3711.581\n",
      "Ep:63, loss:0.00005, loss_test:0.10375, lr:7.70e-03, fs:0.73684 (r=0.636,p=0.875),  time:58.917, tt:3770.687\n",
      "Ep:64, loss:0.00004, loss_test:0.10394, lr:7.62e-03, fs:0.72316 (r=0.646,p=0.821),  time:58.914, tt:3829.394\n",
      "Ep:65, loss:0.00004, loss_test:0.10441, lr:7.55e-03, fs:0.74713 (r=0.657,p=0.867),  time:58.958, tt:3891.222\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.10363, lr:7.55e-03, fs:0.72832 (r=0.636,p=0.851),  time:58.978, tt:3951.547\n",
      "Ep:67, loss:0.00004, loss_test:0.10558, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:58.940, tt:4007.891\n",
      "Ep:68, loss:0.00004, loss_test:0.10531, lr:7.55e-03, fs:0.71429 (r=0.606,p=0.870),  time:58.982, tt:4069.742\n",
      "Ep:69, loss:0.00004, loss_test:0.10463, lr:7.55e-03, fs:0.73143 (r=0.646,p=0.842),  time:59.008, tt:4130.545\n",
      "Ep:70, loss:0.00004, loss_test:0.10730, lr:7.55e-03, fs:0.72189 (r=0.616,p=0.871),  time:59.064, tt:4193.512\n",
      "Ep:71, loss:0.00004, loss_test:0.10542, lr:7.55e-03, fs:0.72414 (r=0.636,p=0.840),  time:59.063, tt:4252.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00004, loss_test:0.10794, lr:7.55e-03, fs:0.70732 (r=0.586,p=0.892),  time:59.048, tt:4310.510\n",
      "Ep:73, loss:0.00004, loss_test:0.10576, lr:7.55e-03, fs:0.72189 (r=0.616,p=0.871),  time:59.050, tt:4369.736\n",
      "Ep:74, loss:0.00004, loss_test:0.10740, lr:7.55e-03, fs:0.71765 (r=0.616,p=0.859),  time:59.019, tt:4426.411\n",
      "Ep:75, loss:0.00004, loss_test:0.10688, lr:7.55e-03, fs:0.72189 (r=0.616,p=0.871),  time:59.009, tt:4484.707\n",
      "Ep:76, loss:0.00004, loss_test:0.10791, lr:7.55e-03, fs:0.70659 (r=0.596,p=0.868),  time:59.067, tt:4548.134\n",
      "Ep:77, loss:0.00004, loss_test:0.10727, lr:7.47e-03, fs:0.71429 (r=0.606,p=0.870),  time:59.105, tt:4610.220\n",
      "Ep:78, loss:0.00003, loss_test:0.10811, lr:7.40e-03, fs:0.70303 (r=0.586,p=0.879),  time:59.081, tt:4667.375\n",
      "Ep:79, loss:0.00003, loss_test:0.10767, lr:7.32e-03, fs:0.71429 (r=0.606,p=0.870),  time:59.067, tt:4725.366\n",
      "Ep:80, loss:0.00003, loss_test:0.10663, lr:7.25e-03, fs:0.72619 (r=0.616,p=0.884),  time:59.049, tt:4782.969\n",
      "Ep:81, loss:0.00003, loss_test:0.10938, lr:7.18e-03, fs:0.69091 (r=0.576,p=0.864),  time:59.011, tt:4838.880\n",
      "Ep:82, loss:0.00003, loss_test:0.10807, lr:7.11e-03, fs:0.70659 (r=0.596,p=0.868),  time:58.997, tt:4896.738\n",
      "Ep:83, loss:0.00003, loss_test:0.10796, lr:7.03e-03, fs:0.70238 (r=0.596,p=0.855),  time:59.011, tt:4956.954\n",
      "Ep:84, loss:0.00003, loss_test:0.11045, lr:6.96e-03, fs:0.68323 (r=0.556,p=0.887),  time:58.984, tt:5013.668\n",
      "Ep:85, loss:0.00003, loss_test:0.10773, lr:6.89e-03, fs:0.70303 (r=0.586,p=0.879),  time:58.938, tt:5068.662\n",
      "Ep:86, loss:0.00003, loss_test:0.11003, lr:6.83e-03, fs:0.69512 (r=0.576,p=0.877),  time:58.899, tt:5124.233\n",
      "Ep:87, loss:0.00003, loss_test:0.10817, lr:6.76e-03, fs:0.70659 (r=0.596,p=0.868),  time:58.928, tt:5185.636\n",
      "Ep:88, loss:0.00003, loss_test:0.11090, lr:6.69e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.904, tt:5242.459\n",
      "Ep:89, loss:0.00003, loss_test:0.10776, lr:6.62e-03, fs:0.71515 (r=0.596,p=0.894),  time:58.899, tt:5300.906\n",
      "Ep:90, loss:0.00003, loss_test:0.10862, lr:6.56e-03, fs:0.70732 (r=0.586,p=0.892),  time:58.882, tt:5358.293\n",
      "Ep:91, loss:0.00003, loss_test:0.10968, lr:6.49e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.825, tt:5411.856\n",
      "Ep:92, loss:0.00003, loss_test:0.11004, lr:6.43e-03, fs:0.69512 (r=0.576,p=0.877),  time:58.809, tt:5469.223\n",
      "Ep:93, loss:0.00003, loss_test:0.10994, lr:6.36e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.812, tt:5528.346\n",
      "Ep:94, loss:0.00003, loss_test:0.10920, lr:6.30e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.807, tt:5586.698\n",
      "Ep:95, loss:0.00003, loss_test:0.10983, lr:6.24e-03, fs:0.69136 (r=0.566,p=0.889),  time:58.798, tt:5644.640\n",
      "Ep:96, loss:0.00003, loss_test:0.10933, lr:6.17e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.834, tt:5706.895\n",
      "Ep:97, loss:0.00003, loss_test:0.11217, lr:6.11e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.828, tt:5765.176\n",
      "Ep:98, loss:0.00003, loss_test:0.10912, lr:6.05e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.824, tt:5823.618\n",
      "Ep:99, loss:0.00003, loss_test:0.11032, lr:5.99e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.821, tt:5882.133\n",
      "Ep:100, loss:0.00002, loss_test:0.11178, lr:5.93e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.782, tt:5936.995\n",
      "Ep:101, loss:0.00002, loss_test:0.10908, lr:5.87e-03, fs:0.69136 (r=0.566,p=0.889),  time:58.764, tt:5993.882\n",
      "Ep:102, loss:0.00002, loss_test:0.11162, lr:5.81e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.766, tt:6052.921\n",
      "Ep:103, loss:0.00002, loss_test:0.11120, lr:5.75e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.753, tt:6110.271\n",
      "Ep:104, loss:0.00002, loss_test:0.11058, lr:5.70e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.754, tt:6169.221\n",
      "Ep:105, loss:0.00002, loss_test:0.11183, lr:5.64e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.724, tt:6224.696\n",
      "Ep:106, loss:0.00002, loss_test:0.10990, lr:5.58e-03, fs:0.69136 (r=0.566,p=0.889),  time:58.737, tt:6284.898\n",
      "Ep:107, loss:0.00002, loss_test:0.11189, lr:5.53e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.733, tt:6343.145\n",
      "Ep:108, loss:0.00002, loss_test:0.10984, lr:5.47e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.762, tt:6405.028\n",
      "Ep:109, loss:0.00002, loss_test:0.11194, lr:5.42e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.781, tt:6465.876\n",
      "Ep:110, loss:0.00002, loss_test:0.11051, lr:5.36e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.778, tt:6524.386\n",
      "Ep:111, loss:0.00002, loss_test:0.11074, lr:5.31e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.782, tt:6583.533\n",
      "Ep:112, loss:0.00002, loss_test:0.11377, lr:5.26e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.813, tt:6645.840\n",
      "Ep:113, loss:0.00002, loss_test:0.10968, lr:5.20e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.873, tt:6711.527\n",
      "Ep:114, loss:0.00002, loss_test:0.11290, lr:5.15e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.872, tt:6770.326\n",
      "Ep:115, loss:0.00002, loss_test:0.11072, lr:5.10e-03, fs:0.69512 (r=0.576,p=0.877),  time:58.915, tt:6834.130\n",
      "Ep:116, loss:0.00002, loss_test:0.11112, lr:5.05e-03, fs:0.69939 (r=0.576,p=0.891),  time:58.974, tt:6899.903\n",
      "Ep:117, loss:0.00002, loss_test:0.11156, lr:5.00e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.025, tt:6964.958\n",
      "Ep:118, loss:0.00002, loss_test:0.11029, lr:4.95e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.072, tt:7029.624\n",
      "Ep:119, loss:0.00002, loss_test:0.11204, lr:4.90e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.093, tt:7091.213\n",
      "Ep:120, loss:0.00002, loss_test:0.11007, lr:4.85e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.158, tt:7158.112\n",
      "Ep:121, loss:0.00002, loss_test:0.11174, lr:4.80e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.215, tt:7224.183\n",
      "Ep:122, loss:0.00002, loss_test:0.11174, lr:4.75e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.264, tt:7289.443\n",
      "Ep:123, loss:0.00002, loss_test:0.11029, lr:4.71e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.302, tt:7353.445\n",
      "Ep:124, loss:0.00002, loss_test:0.11303, lr:4.66e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.333, tt:7416.649\n",
      "Ep:125, loss:0.00002, loss_test:0.11040, lr:4.61e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.403, tt:7484.816\n",
      "Ep:126, loss:0.00002, loss_test:0.11209, lr:4.57e-03, fs:0.69939 (r=0.576,p=0.891),  time:59.434, tt:7548.124\n",
      "Ep:127, loss:0.00002, loss_test:0.11176, lr:4.52e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.427, tt:7606.687\n",
      "Ep:128, loss:0.00002, loss_test:0.11183, lr:4.48e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.470, tt:7671.586\n",
      "Ep:129, loss:0.00002, loss_test:0.11145, lr:4.43e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.519, tt:7737.486\n",
      "Ep:130, loss:0.00002, loss_test:0.11177, lr:4.39e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.564, tt:7802.932\n",
      "Ep:131, loss:0.00002, loss_test:0.11169, lr:4.34e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.606, tt:7867.932\n",
      "Ep:132, loss:0.00002, loss_test:0.11201, lr:4.30e-03, fs:0.68712 (r=0.566,p=0.875),  time:59.656, tt:7934.296\n",
      "Ep:133, loss:0.00002, loss_test:0.11211, lr:4.26e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.692, tt:7998.734\n",
      "Ep:134, loss:0.00002, loss_test:0.11315, lr:4.21e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.741, tt:8064.995\n",
      "Ep:135, loss:0.00002, loss_test:0.11146, lr:4.17e-03, fs:0.68712 (r=0.566,p=0.875),  time:59.777, tt:8129.729\n",
      "Ep:136, loss:0.00002, loss_test:0.11318, lr:4.13e-03, fs:0.68712 (r=0.566,p=0.875),  time:59.828, tt:8196.470\n",
      "Ep:137, loss:0.00002, loss_test:0.11264, lr:4.09e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.862, tt:8260.897\n",
      "Ep:138, loss:0.00002, loss_test:0.11354, lr:4.05e-03, fs:0.69136 (r=0.566,p=0.889),  time:59.906, tt:8326.880\n",
      "Ep:139, loss:0.00002, loss_test:0.11112, lr:4.01e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.948, tt:8392.659\n",
      "Ep:140, loss:0.00002, loss_test:0.11454, lr:3.97e-03, fs:0.69512 (r=0.576,p=0.877),  time:59.985, tt:8457.871\n",
      "Ep:141, loss:0.00002, loss_test:0.11054, lr:3.93e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.019, tt:8522.762\n",
      "Ep:142, loss:0.00002, loss_test:0.11523, lr:3.89e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.042, tt:8586.038\n",
      "Ep:143, loss:0.00002, loss_test:0.11177, lr:3.85e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.057, tt:8648.276\n",
      "Ep:144, loss:0.00002, loss_test:0.11384, lr:3.81e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.100, tt:8714.491\n",
      "Ep:145, loss:0.00002, loss_test:0.11268, lr:3.77e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.134, tt:8779.602\n",
      "Ep:146, loss:0.00002, loss_test:0.11282, lr:3.73e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.183, tt:8846.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00002, loss_test:0.11349, lr:3.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.218, tt:8912.320\n",
      "Ep:148, loss:0.00002, loss_test:0.11316, lr:3.66e-03, fs:0.68712 (r=0.566,p=0.875),  time:60.222, tt:8973.086\n",
      "Ep:149, loss:0.00002, loss_test:0.11373, lr:3.62e-03, fs:0.69512 (r=0.576,p=0.877),  time:60.252, tt:9037.803\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 29\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14405, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:58.229, tt:58.229\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14184, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:60.584, tt:121.167\n",
      "Ep:2, loss:0.00055, loss_test:0.13690, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:61.869, tt:185.608\n",
      "Ep:3, loss:0.00052, loss_test:0.12427, lr:1.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:62.486, tt:249.945\n",
      "Ep:4, loss:0.00047, loss_test:0.11387, lr:1.00e-02, fs:0.69159 (r=0.747,p=0.643),  time:62.222, tt:311.110\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.11245, lr:1.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:63.151, tt:378.908\n",
      "Ep:6, loss:0.00042, loss_test:0.10719, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:63.381, tt:443.667\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.10231, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:63.702, tt:509.613\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00038, loss_test:0.09983, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:64.051, tt:576.459\n",
      "Ep:9, loss:0.00036, loss_test:0.09704, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:64.297, tt:642.975\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.09477, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:64.508, tt:709.588\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.09170, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:64.673, tt:776.077\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00032, loss_test:0.09097, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:64.869, tt:843.291\n",
      "Ep:13, loss:0.00030, loss_test:0.08834, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:64.982, tt:909.746\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.08724, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:65.064, tt:975.964\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.08512, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:65.279, tt:1044.457\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.08514, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:65.287, tt:1109.871\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.08255, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:65.410, tt:1177.372\n",
      "Ep:18, loss:0.00025, loss_test:0.08035, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:65.571, tt:1245.848\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.07907, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:65.580, tt:1311.597\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.08057, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:65.624, tt:1378.103\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.07707, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:65.694, tt:1445.267\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.07635, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:65.689, tt:1510.856\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00020, loss_test:0.07550, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:65.795, tt:1579.083\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00019, loss_test:0.07453, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:65.703, tt:1642.580\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.07294, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:65.787, tt:1710.449\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.07133, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:65.850, tt:1777.937\n",
      "Ep:27, loss:0.00016, loss_test:0.07127, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:65.949, tt:1846.561\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.07143, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:65.996, tt:1913.874\n",
      "Ep:29, loss:0.00015, loss_test:0.06913, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:65.903, tt:1977.101\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.07113, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:65.947, tt:2044.357\n",
      "Ep:31, loss:0.00013, loss_test:0.06938, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:65.850, tt:2107.213\n",
      "Ep:32, loss:0.00013, loss_test:0.06671, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:65.872, tt:2173.779\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.06709, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:65.867, tt:2239.467\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.06703, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:65.787, tt:2302.544\n",
      "Ep:35, loss:0.00011, loss_test:0.06610, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:65.814, tt:2369.292\n",
      "Ep:36, loss:0.00010, loss_test:0.06547, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:65.811, tt:2435.020\n",
      "Ep:37, loss:0.00009, loss_test:0.06470, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:65.752, tt:2498.559\n",
      "Ep:38, loss:0.00009, loss_test:0.06601, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:65.650, tt:2560.361\n",
      "Ep:39, loss:0.00009, loss_test:0.06301, lr:1.00e-02, fs:0.90256 (r=0.889,p=0.917),  time:65.597, tt:2623.896\n",
      "Ep:40, loss:0.00008, loss_test:0.06399, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:65.546, tt:2687.404\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06510, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:65.519, tt:2751.808\n",
      "Ep:42, loss:0.00008, loss_test:0.06334, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:65.443, tt:2814.040\n",
      "Ep:43, loss:0.00008, loss_test:0.06465, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:65.379, tt:2876.654\n",
      "Ep:44, loss:0.00007, loss_test:0.06331, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:65.344, tt:2940.478\n",
      "Ep:45, loss:0.00007, loss_test:0.06307, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:65.323, tt:3004.869\n",
      "Ep:46, loss:0.00006, loss_test:0.06106, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:65.291, tt:3068.663\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.06237, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:65.311, tt:3134.915\n",
      "Ep:48, loss:0.00006, loss_test:0.06185, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:65.336, tt:3201.458\n",
      "Ep:49, loss:0.00006, loss_test:0.06165, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:65.323, tt:3266.166\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.06224, lr:1.00e-02, fs:0.92784 (r=0.909,p=0.947),  time:65.288, tt:3329.688\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.06197, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:65.259, tt:3393.465\n",
      "Ep:52, loss:0.00005, loss_test:0.06110, lr:1.00e-02, fs:0.93194 (r=0.899,p=0.967),  time:65.285, tt:3460.087\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06174, lr:1.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:65.269, tt:3524.508\n",
      "Ep:54, loss:0.00005, loss_test:0.06100, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:65.262, tt:3589.398\n",
      "Ep:55, loss:0.00005, loss_test:0.05971, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:65.207, tt:3651.613\n",
      "Ep:56, loss:0.00005, loss_test:0.06117, lr:1.00e-02, fs:0.91282 (r=0.899,p=0.927),  time:65.227, tt:3717.952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00005, loss_test:0.06053, lr:1.00e-02, fs:0.93814 (r=0.919,p=0.958),  time:65.239, tt:3783.868\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.06079, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:65.237, tt:3848.962\n",
      "Ep:59, loss:0.00004, loss_test:0.05898, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:65.240, tt:3914.397\n",
      "Ep:60, loss:0.00004, loss_test:0.06119, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:65.248, tt:3980.104\n",
      "Ep:61, loss:0.00004, loss_test:0.06036, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:65.288, tt:4047.866\n",
      "Ep:62, loss:0.00004, loss_test:0.05922, lr:1.00e-02, fs:0.92386 (r=0.919,p=0.929),  time:65.273, tt:4112.181\n",
      "Ep:63, loss:0.00004, loss_test:0.06001, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:65.264, tt:4176.876\n",
      "Ep:64, loss:0.00004, loss_test:0.05986, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:65.258, tt:4241.771\n",
      "Ep:65, loss:0.00004, loss_test:0.06009, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:65.230, tt:4305.162\n",
      "Ep:66, loss:0.00004, loss_test:0.06032, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:65.216, tt:4369.467\n",
      "Ep:67, loss:0.00003, loss_test:0.06056, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:65.205, tt:4433.962\n",
      "Ep:68, loss:0.00003, loss_test:0.05913, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:65.169, tt:4496.657\n",
      "Ep:69, loss:0.00003, loss_test:0.05997, lr:9.90e-03, fs:0.93814 (r=0.919,p=0.958),  time:65.171, tt:4561.941\n",
      "Ep:70, loss:0.00003, loss_test:0.05971, lr:9.80e-03, fs:0.92857 (r=0.919,p=0.938),  time:65.178, tt:4627.648\n",
      "Ep:71, loss:0.00003, loss_test:0.05974, lr:9.70e-03, fs:0.93814 (r=0.919,p=0.958),  time:65.155, tt:4691.179\n",
      "Ep:72, loss:0.00003, loss_test:0.06086, lr:9.61e-03, fs:0.92228 (r=0.899,p=0.947),  time:65.158, tt:4756.514\n",
      "Ep:73, loss:0.00003, loss_test:0.06123, lr:9.51e-03, fs:0.90526 (r=0.869,p=0.945),  time:65.177, tt:4823.097\n",
      "Ep:74, loss:0.00003, loss_test:0.06172, lr:9.41e-03, fs:0.89947 (r=0.859,p=0.944),  time:65.190, tt:4889.283\n",
      "Ep:75, loss:0.00003, loss_test:0.06194, lr:9.32e-03, fs:0.92063 (r=0.879,p=0.967),  time:65.194, tt:4954.747\n",
      "Ep:76, loss:0.00003, loss_test:0.06287, lr:9.23e-03, fs:0.90909 (r=0.859,p=0.966),  time:65.203, tt:5020.617\n",
      "Ep:77, loss:0.00003, loss_test:0.06228, lr:9.14e-03, fs:0.89362 (r=0.848,p=0.944),  time:65.204, tt:5085.912\n",
      "Ep:78, loss:0.00003, loss_test:0.06205, lr:9.04e-03, fs:0.92632 (r=0.889,p=0.967),  time:65.167, tt:5148.226\n",
      "Ep:79, loss:0.00003, loss_test:0.06254, lr:8.95e-03, fs:0.91398 (r=0.859,p=0.977),  time:65.167, tt:5213.321\n",
      "Ep:80, loss:0.00003, loss_test:0.06107, lr:8.86e-03, fs:0.89947 (r=0.859,p=0.944),  time:65.110, tt:5273.929\n",
      "Ep:81, loss:0.00002, loss_test:0.06083, lr:8.78e-03, fs:0.91579 (r=0.879,p=0.956),  time:65.049, tt:5334.052\n",
      "Ep:82, loss:0.00002, loss_test:0.06134, lr:8.69e-03, fs:0.92632 (r=0.889,p=0.967),  time:64.983, tt:5393.555\n",
      "Ep:83, loss:0.00002, loss_test:0.06257, lr:8.60e-03, fs:0.90909 (r=0.859,p=0.966),  time:64.910, tt:5452.467\n",
      "Ep:84, loss:0.00002, loss_test:0.06262, lr:8.51e-03, fs:0.88043 (r=0.818,p=0.953),  time:64.828, tt:5510.375\n",
      "Ep:85, loss:0.00002, loss_test:0.06260, lr:8.43e-03, fs:0.90323 (r=0.848,p=0.966),  time:64.737, tt:5567.375\n",
      "Ep:86, loss:0.00002, loss_test:0.06214, lr:8.35e-03, fs:0.89840 (r=0.848,p=0.955),  time:64.663, tt:5625.651\n",
      "Ep:87, loss:0.00002, loss_test:0.06155, lr:8.26e-03, fs:0.90909 (r=0.859,p=0.966),  time:64.588, tt:5683.705\n",
      "Ep:88, loss:0.00002, loss_test:0.06227, lr:8.18e-03, fs:0.89730 (r=0.838,p=0.965),  time:64.502, tt:5740.672\n",
      "Ep:89, loss:0.00002, loss_test:0.06120, lr:8.10e-03, fs:0.90323 (r=0.848,p=0.966),  time:64.469, tt:5802.183\n",
      "Ep:90, loss:0.00002, loss_test:0.06223, lr:8.02e-03, fs:0.90323 (r=0.848,p=0.966),  time:64.389, tt:5859.362\n",
      "Ep:91, loss:0.00002, loss_test:0.06210, lr:7.94e-03, fs:0.90811 (r=0.848,p=0.977),  time:64.313, tt:5916.776\n",
      "Ep:92, loss:0.00002, loss_test:0.06308, lr:7.86e-03, fs:0.90811 (r=0.848,p=0.977),  time:64.264, tt:5976.508\n",
      "Ep:93, loss:0.00002, loss_test:0.06264, lr:7.78e-03, fs:0.89730 (r=0.838,p=0.965),  time:64.225, tt:6037.180\n",
      "Ep:94, loss:0.00002, loss_test:0.06197, lr:7.70e-03, fs:0.89730 (r=0.838,p=0.965),  time:64.150, tt:6094.291\n",
      "Ep:95, loss:0.00002, loss_test:0.06205, lr:7.62e-03, fs:0.90323 (r=0.848,p=0.966),  time:64.070, tt:6150.682\n",
      "Ep:96, loss:0.00002, loss_test:0.06196, lr:7.55e-03, fs:0.90323 (r=0.848,p=0.966),  time:64.016, tt:6209.504\n",
      "Ep:97, loss:0.00002, loss_test:0.06208, lr:7.47e-03, fs:0.90323 (r=0.848,p=0.966),  time:63.973, tt:6269.372\n",
      "Ep:98, loss:0.00002, loss_test:0.06233, lr:7.40e-03, fs:0.90323 (r=0.848,p=0.966),  time:63.883, tt:6324.448\n",
      "Ep:99, loss:0.00002, loss_test:0.06238, lr:7.32e-03, fs:0.90323 (r=0.848,p=0.966),  time:63.811, tt:6381.128\n",
      "Ep:100, loss:0.00002, loss_test:0.06117, lr:7.25e-03, fs:0.92632 (r=0.889,p=0.967),  time:63.765, tt:6440.286\n",
      "Ep:101, loss:0.00002, loss_test:0.06252, lr:7.18e-03, fs:0.90323 (r=0.848,p=0.966),  time:63.742, tt:6501.638\n",
      "Ep:102, loss:0.00002, loss_test:0.06330, lr:7.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:63.704, tt:6561.537\n",
      "Ep:103, loss:0.00002, loss_test:0.06355, lr:7.03e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.663, tt:6620.968\n",
      "Ep:104, loss:0.00002, loss_test:0.06202, lr:6.96e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.647, tt:6682.900\n",
      "Ep:105, loss:0.00002, loss_test:0.06342, lr:6.89e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.600, tt:6741.627\n",
      "Ep:106, loss:0.00002, loss_test:0.06251, lr:6.83e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.575, tt:6802.486\n",
      "Ep:107, loss:0.00002, loss_test:0.06367, lr:6.76e-03, fs:0.90217 (r=0.838,p=0.976),  time:63.529, tt:6861.184\n",
      "Ep:108, loss:0.00002, loss_test:0.06371, lr:6.69e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.475, tt:6918.737\n",
      "Ep:109, loss:0.00002, loss_test:0.06264, lr:6.62e-03, fs:0.88525 (r=0.818,p=0.964),  time:63.438, tt:6978.235\n",
      "Ep:110, loss:0.00002, loss_test:0.06383, lr:6.56e-03, fs:0.90217 (r=0.838,p=0.976),  time:63.404, tt:7037.827\n",
      "Ep:111, loss:0.00002, loss_test:0.06337, lr:6.49e-03, fs:0.90217 (r=0.838,p=0.976),  time:63.362, tt:7096.550\n",
      "Ep:112, loss:0.00002, loss_test:0.06305, lr:6.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.316, tt:7154.709\n",
      "Ep:113, loss:0.00001, loss_test:0.06318, lr:6.36e-03, fs:0.89730 (r=0.838,p=0.965),  time:63.280, tt:7213.898\n",
      "Ep:114, loss:0.00001, loss_test:0.06359, lr:6.30e-03, fs:0.90217 (r=0.838,p=0.976),  time:63.231, tt:7271.613\n",
      "Ep:115, loss:0.00001, loss_test:0.06399, lr:6.24e-03, fs:0.89130 (r=0.828,p=0.965),  time:63.191, tt:7330.148\n",
      "Ep:116, loss:0.00001, loss_test:0.06335, lr:6.17e-03, fs:0.90323 (r=0.848,p=0.966),  time:63.149, tt:7388.395\n",
      "Ep:117, loss:0.00001, loss_test:0.06497, lr:6.11e-03, fs:0.89617 (r=0.828,p=0.976),  time:63.109, tt:7446.822\n",
      "Ep:118, loss:0.00001, loss_test:0.06387, lr:6.05e-03, fs:0.88525 (r=0.818,p=0.964),  time:63.053, tt:7503.281\n",
      "Ep:119, loss:0.00001, loss_test:0.06412, lr:5.99e-03, fs:0.89130 (r=0.828,p=0.965),  time:63.010, tt:7561.236\n",
      "Ep:120, loss:0.00001, loss_test:0.06467, lr:5.93e-03, fs:0.87151 (r=0.788,p=0.975),  time:62.988, tt:7621.591\n",
      "Ep:121, loss:0.00001, loss_test:0.06456, lr:5.87e-03, fs:0.89617 (r=0.828,p=0.976),  time:62.960, tt:7681.074\n",
      "Ep:122, loss:0.00001, loss_test:0.06426, lr:5.81e-03, fs:0.87293 (r=0.798,p=0.963),  time:62.944, tt:7742.057\n",
      "Ep:123, loss:0.00001, loss_test:0.06464, lr:5.75e-03, fs:0.87778 (r=0.798,p=0.975),  time:62.907, tt:7800.524\n",
      "Ep:124, loss:0.00001, loss_test:0.06528, lr:5.70e-03, fs:0.89617 (r=0.828,p=0.976),  time:62.880, tt:7859.944\n",
      "Ep:125, loss:0.00001, loss_test:0.06402, lr:5.64e-03, fs:0.86667 (r=0.788,p=0.963),  time:62.877, tt:7922.482\n",
      "Ep:126, loss:0.00001, loss_test:0.06581, lr:5.58e-03, fs:0.83908 (r=0.737,p=0.973),  time:62.848, tt:7981.679\n",
      "Ep:127, loss:0.00001, loss_test:0.06549, lr:5.53e-03, fs:0.87151 (r=0.788,p=0.975),  time:62.810, tt:8039.625\n",
      "Ep:128, loss:0.00001, loss_test:0.06545, lr:5.47e-03, fs:0.83908 (r=0.737,p=0.973),  time:62.768, tt:8097.020\n",
      "Ep:129, loss:0.00001, loss_test:0.06528, lr:5.42e-03, fs:0.86517 (r=0.778,p=0.975),  time:62.749, tt:8157.307\n",
      "Ep:130, loss:0.00001, loss_test:0.06639, lr:5.36e-03, fs:0.84571 (r=0.747,p=0.974),  time:62.727, tt:8217.293\n",
      "Ep:131, loss:0.00001, loss_test:0.06549, lr:5.31e-03, fs:0.86517 (r=0.778,p=0.975),  time:62.693, tt:8275.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00001, loss_test:0.06681, lr:5.26e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.670, tt:8335.087\n",
      "Ep:133, loss:0.00001, loss_test:0.06564, lr:5.20e-03, fs:0.86517 (r=0.778,p=0.975),  time:62.639, tt:8393.590\n",
      "Ep:134, loss:0.00001, loss_test:0.06647, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.630, tt:8455.017\n",
      "Ep:135, loss:0.00001, loss_test:0.06595, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:62.614, tt:8515.501\n",
      "Ep:136, loss:0.00001, loss_test:0.06707, lr:5.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.602, tt:8576.507\n",
      "Ep:137, loss:0.00001, loss_test:0.06609, lr:5.00e-03, fs:0.84571 (r=0.747,p=0.974),  time:62.577, tt:8635.682\n",
      "Ep:138, loss:0.00001, loss_test:0.06651, lr:4.95e-03, fs:0.82558 (r=0.717,p=0.973),  time:62.574, tt:8697.790\n",
      "Ep:139, loss:0.00001, loss_test:0.06672, lr:4.90e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.556, tt:8757.853\n",
      "Ep:140, loss:0.00001, loss_test:0.06704, lr:4.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.533, tt:8817.176\n",
      "Ep:141, loss:0.00001, loss_test:0.06675, lr:4.80e-03, fs:0.81871 (r=0.707,p=0.972),  time:62.520, tt:8877.891\n",
      "Ep:142, loss:0.00001, loss_test:0.06794, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.452, tt:8930.618\n",
      "Ep:143, loss:0.00001, loss_test:0.06720, lr:4.71e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.380, tt:8982.719\n",
      "Ep:144, loss:0.00001, loss_test:0.06790, lr:4.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:62.319, tt:9036.182\n",
      "Ep:145, loss:0.00001, loss_test:0.06740, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.225, tt:9084.878\n",
      "Ep:146, loss:0.00001, loss_test:0.06784, lr:4.57e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.151, tt:9136.266\n",
      "Ep:147, loss:0.00001, loss_test:0.06767, lr:4.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:62.040, tt:9181.951\n",
      "Ep:148, loss:0.00001, loss_test:0.06794, lr:4.48e-03, fs:0.81176 (r=0.697,p=0.972),  time:61.940, tt:9229.122\n",
      "Ep:149, loss:0.00001, loss_test:0.06805, lr:4.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:61.752, tt:9262.761\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,150,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14179, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.305, tt:7.305\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14144, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.140, tt:16.279\n",
      "Ep:2, loss:0.00000, loss_test:0.14092, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.225, tt:27.674\n",
      "Ep:3, loss:0.00000, loss_test:0.14020, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.102, tt:40.408\n",
      "Ep:4, loss:0.00000, loss_test:0.13927, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:10.865, tt:54.326\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00000, loss_test:0.13805, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:11.551, tt:69.308\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00000, loss_test:0.13654, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:12.335, tt:86.342\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00000, loss_test:0.13466, lr:1.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:12.887, tt:103.095\n",
      "Ep:8, loss:0.00000, loss_test:0.13241, lr:1.00e-02, fs:0.68056 (r=0.990,p=0.519),  time:13.267, tt:119.407\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00000, loss_test:0.12993, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:13.555, tt:135.552\n",
      "Ep:10, loss:0.00000, loss_test:0.12737, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:13.882, tt:152.704\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00000, loss_test:0.12486, lr:1.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:14.092, tt:169.110\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00000, loss_test:0.12277, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:14.325, tt:186.223\n",
      "Ep:13, loss:0.00000, loss_test:0.12239, lr:1.00e-02, fs:0.68936 (r=0.818,p=0.596),  time:14.512, tt:203.166\n",
      "Ep:14, loss:0.00000, loss_test:0.12287, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:14.765, tt:221.481\n",
      "Ep:15, loss:0.00000, loss_test:0.12303, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:14.914, tt:238.616\n",
      "Ep:16, loss:0.00000, loss_test:0.12220, lr:1.00e-02, fs:0.65728 (r=0.707,p=0.614),  time:15.062, tt:256.052\n",
      "Ep:17, loss:0.00000, loss_test:0.12031, lr:1.00e-02, fs:0.66977 (r=0.727,p=0.621),  time:15.178, tt:273.213\n",
      "Ep:18, loss:0.00000, loss_test:0.11811, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:15.225, tt:289.284\n",
      "Ep:19, loss:0.00000, loss_test:0.11604, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:15.318, tt:306.355\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00000, loss_test:0.11439, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:15.397, tt:323.327\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00000, loss_test:0.11304, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:15.442, tt:339.725\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00000, loss_test:0.11170, lr:1.00e-02, fs:0.72646 (r=0.818,p=0.653),  time:15.552, tt:357.699\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.11039, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:15.597, tt:374.328\n",
      "Ep:24, loss:0.00000, loss_test:0.10960, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:15.640, tt:391.002\n",
      "Ep:25, loss:0.00000, loss_test:0.10909, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:15.713, tt:408.526\n",
      "Ep:26, loss:0.00000, loss_test:0.10832, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:15.769, tt:425.764\n",
      "Ep:27, loss:0.00000, loss_test:0.10749, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:15.827, tt:443.155\n",
      "Ep:28, loss:0.00000, loss_test:0.10656, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:15.872, tt:460.299\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.10567, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:15.917, tt:477.503\n",
      "Ep:30, loss:0.00000, loss_test:0.10485, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:15.953, tt:494.551\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.10398, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:15.975, tt:511.204\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00000, loss_test:0.10316, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:15.992, tt:527.749\n",
      "Ep:33, loss:0.00000, loss_test:0.10231, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:16.019, tt:544.648\n",
      "Ep:34, loss:0.00000, loss_test:0.10144, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:16.069, tt:562.427\n",
      "Ep:35, loss:0.00000, loss_test:0.10049, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:16.083, tt:578.987\n",
      "Ep:36, loss:0.00000, loss_test:0.09963, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:16.103, tt:595.826\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.09889, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:16.132, tt:613.013\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00000, loss_test:0.09827, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:16.190, tt:631.406\n",
      "Ep:39, loss:0.00000, loss_test:0.09774, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:16.243, tt:649.729\n",
      "Ep:40, loss:0.00000, loss_test:0.09733, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:16.275, tt:667.282\n",
      "Ep:41, loss:0.00000, loss_test:0.09694, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:16.284, tt:683.931\n",
      "Ep:42, loss:0.00000, loss_test:0.09654, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:16.276, tt:699.877\n",
      "Ep:43, loss:0.00000, loss_test:0.09609, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:16.314, tt:717.824\n",
      "Ep:44, loss:0.00000, loss_test:0.09572, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:16.327, tt:734.716\n",
      "Ep:45, loss:0.00000, loss_test:0.09546, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:16.343, tt:751.796\n",
      "Ep:46, loss:0.00000, loss_test:0.09532, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:16.370, tt:769.406\n",
      "Ep:47, loss:0.00000, loss_test:0.09533, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:16.388, tt:786.625\n",
      "Ep:48, loss:0.00000, loss_test:0.09535, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:16.410, tt:804.080\n",
      "Ep:49, loss:0.00000, loss_test:0.09517, lr:9.90e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.435, tt:821.748\n",
      "Ep:50, loss:0.00000, loss_test:0.09472, lr:9.80e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.444, tt:838.635\n",
      "Ep:51, loss:0.00000, loss_test:0.09423, lr:9.70e-03, fs:0.77228 (r=0.788,p=0.757),  time:16.442, tt:854.962\n",
      "Ep:52, loss:0.00000, loss_test:0.09384, lr:9.61e-03, fs:0.77833 (r=0.798,p=0.760),  time:16.471, tt:872.954\n",
      "Ep:53, loss:0.00000, loss_test:0.09356, lr:9.51e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.480, tt:889.946\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00000, loss_test:0.09334, lr:9.51e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.498, tt:907.373\n",
      "Ep:55, loss:0.00000, loss_test:0.09301, lr:9.51e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.499, tt:923.940\n",
      "Ep:56, loss:0.00000, loss_test:0.09253, lr:9.51e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.517, tt:941.463\n",
      "Ep:57, loss:0.00000, loss_test:0.09193, lr:9.51e-03, fs:0.78818 (r=0.808,p=0.769),  time:16.521, tt:958.226\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00000, loss_test:0.09138, lr:9.51e-03, fs:0.78818 (r=0.808,p=0.769),  time:16.506, tt:973.831\n",
      "Ep:59, loss:0.00000, loss_test:0.09108, lr:9.51e-03, fs:0.78818 (r=0.808,p=0.769),  time:16.527, tt:991.598\n",
      "Ep:60, loss:0.00000, loss_test:0.09100, lr:9.51e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.536, tt:1008.681\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00000, loss_test:0.09101, lr:9.51e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.540, tt:1025.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00000, loss_test:0.09087, lr:9.51e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.555, tt:1042.950\n",
      "Ep:63, loss:0.00000, loss_test:0.09047, lr:9.51e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.557, tt:1059.657\n",
      "Ep:64, loss:0.00000, loss_test:0.08997, lr:9.51e-03, fs:0.79397 (r=0.798,p=0.790),  time:16.560, tt:1076.373\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00000, loss_test:0.08951, lr:9.51e-03, fs:0.78788 (r=0.788,p=0.788),  time:16.547, tt:1092.114\n",
      "Ep:66, loss:0.00000, loss_test:0.08919, lr:9.51e-03, fs:0.78571 (r=0.778,p=0.794),  time:16.551, tt:1108.941\n",
      "Ep:67, loss:0.00000, loss_test:0.08897, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:16.553, tt:1125.605\n",
      "Ep:68, loss:0.00000, loss_test:0.08878, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:16.547, tt:1141.747\n",
      "Ep:69, loss:0.00000, loss_test:0.08847, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:16.542, tt:1157.950\n",
      "Ep:70, loss:0.00000, loss_test:0.08811, lr:9.51e-03, fs:0.77949 (r=0.768,p=0.792),  time:16.533, tt:1173.812\n",
      "Ep:71, loss:0.00000, loss_test:0.08775, lr:9.51e-03, fs:0.78756 (r=0.768,p=0.809),  time:16.527, tt:1189.935\n",
      "Ep:72, loss:0.00000, loss_test:0.08737, lr:9.51e-03, fs:0.78534 (r=0.758,p=0.815),  time:16.526, tt:1206.411\n",
      "Ep:73, loss:0.00000, loss_test:0.08705, lr:9.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.520, tt:1222.494\n",
      "Ep:74, loss:0.00000, loss_test:0.08680, lr:9.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.531, tt:1239.841\n",
      "Ep:75, loss:0.00000, loss_test:0.08645, lr:9.51e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.531, tt:1256.365\n",
      "Ep:76, loss:0.00000, loss_test:0.08607, lr:9.41e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.531, tt:1272.888\n",
      "Ep:77, loss:0.00000, loss_test:0.08583, lr:9.32e-03, fs:0.77660 (r=0.737,p=0.820),  time:16.540, tt:1290.120\n",
      "Ep:78, loss:0.00000, loss_test:0.08572, lr:9.23e-03, fs:0.78075 (r=0.737,p=0.830),  time:16.568, tt:1308.843\n",
      "Ep:79, loss:0.00000, loss_test:0.08564, lr:9.14e-03, fs:0.78075 (r=0.737,p=0.830),  time:16.575, tt:1326.039\n",
      "Ep:80, loss:0.00000, loss_test:0.08554, lr:9.04e-03, fs:0.78075 (r=0.737,p=0.830),  time:16.590, tt:1343.830\n",
      "Ep:81, loss:0.00000, loss_test:0.08545, lr:8.95e-03, fs:0.78075 (r=0.737,p=0.830),  time:16.597, tt:1360.926\n",
      "Ep:82, loss:0.00000, loss_test:0.08537, lr:8.86e-03, fs:0.78495 (r=0.737,p=0.839),  time:16.617, tt:1379.239\n",
      "Ep:83, loss:0.00000, loss_test:0.08530, lr:8.78e-03, fs:0.78495 (r=0.737,p=0.839),  time:16.630, tt:1396.918\n",
      "Ep:84, loss:0.00000, loss_test:0.08524, lr:8.69e-03, fs:0.78495 (r=0.737,p=0.839),  time:16.642, tt:1414.589\n",
      "Ep:85, loss:0.00000, loss_test:0.08510, lr:8.60e-03, fs:0.77838 (r=0.727,p=0.837),  time:16.655, tt:1432.342\n",
      "Ep:86, loss:0.00000, loss_test:0.08493, lr:8.51e-03, fs:0.77838 (r=0.727,p=0.837),  time:16.669, tt:1450.187\n",
      "Ep:87, loss:0.00000, loss_test:0.08474, lr:8.43e-03, fs:0.77838 (r=0.727,p=0.837),  time:16.706, tt:1470.155\n",
      "Ep:88, loss:0.00000, loss_test:0.08458, lr:8.35e-03, fs:0.77838 (r=0.727,p=0.837),  time:16.719, tt:1488.003\n",
      "Ep:89, loss:0.00000, loss_test:0.08447, lr:8.26e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.725, tt:1505.259\n",
      "Ep:90, loss:0.00000, loss_test:0.08439, lr:8.18e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.733, tt:1522.702\n",
      "Ep:91, loss:0.00000, loss_test:0.08430, lr:8.10e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.740, tt:1540.057\n",
      "Ep:92, loss:0.00000, loss_test:0.08423, lr:8.02e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.747, tt:1557.476\n",
      "Ep:93, loss:0.00000, loss_test:0.08410, lr:7.94e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.753, tt:1574.739\n",
      "Ep:94, loss:0.00000, loss_test:0.08394, lr:7.86e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.762, tt:1592.358\n",
      "Ep:95, loss:0.00000, loss_test:0.08379, lr:7.78e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.757, tt:1608.713\n",
      "Ep:96, loss:0.00000, loss_test:0.08366, lr:7.70e-03, fs:0.78022 (r=0.717,p=0.855),  time:16.755, tt:1625.214\n",
      "Ep:97, loss:0.00000, loss_test:0.08355, lr:7.62e-03, fs:0.77348 (r=0.707,p=0.854),  time:16.757, tt:1642.197\n",
      "Ep:98, loss:0.00000, loss_test:0.08341, lr:7.55e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.765, tt:1659.719\n",
      "Ep:99, loss:0.00000, loss_test:0.08331, lr:7.47e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.774, tt:1677.410\n",
      "Ep:100, loss:0.00000, loss_test:0.08327, lr:7.40e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.768, tt:1693.561\n",
      "Ep:101, loss:0.00000, loss_test:0.08320, lr:7.32e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.767, tt:1710.261\n",
      "Ep:102, loss:0.00000, loss_test:0.08309, lr:7.25e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.763, tt:1726.546\n",
      "Ep:103, loss:0.00000, loss_test:0.08302, lr:7.18e-03, fs:0.77778 (r=0.707,p=0.864),  time:16.764, tt:1743.473\n",
      "Ep:104, loss:0.00000, loss_test:0.08302, lr:7.11e-03, fs:0.78212 (r=0.707,p=0.875),  time:16.771, tt:1760.972\n",
      "Ep:105, loss:0.00000, loss_test:0.08310, lr:7.03e-03, fs:0.78652 (r=0.707,p=0.886),  time:16.781, tt:1778.803\n",
      "Ep:106, loss:0.00000, loss_test:0.08319, lr:6.96e-03, fs:0.78652 (r=0.707,p=0.886),  time:16.780, tt:1795.486\n",
      "Ep:107, loss:0.00000, loss_test:0.08317, lr:6.89e-03, fs:0.78652 (r=0.707,p=0.886),  time:16.783, tt:1812.561\n",
      "Ep:108, loss:0.00000, loss_test:0.08308, lr:6.83e-03, fs:0.78652 (r=0.707,p=0.886),  time:16.793, tt:1830.449\n",
      "Ep:109, loss:0.00000, loss_test:0.08301, lr:6.76e-03, fs:0.79096 (r=0.707,p=0.897),  time:16.808, tt:1848.848\n",
      "Ep:110, loss:0.00000, loss_test:0.08303, lr:6.69e-03, fs:0.79096 (r=0.707,p=0.897),  time:16.825, tt:1867.570\n",
      "Ep:111, loss:0.00000, loss_test:0.08312, lr:6.62e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.830, tt:1884.985\n",
      "Ep:112, loss:0.00000, loss_test:0.08314, lr:6.56e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.846, tt:1903.612\n",
      "Ep:113, loss:0.00000, loss_test:0.08306, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.856, tt:1921.627\n",
      "Ep:114, loss:0.00000, loss_test:0.08304, lr:6.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.870, tt:1940.090\n",
      "Ep:115, loss:0.00000, loss_test:0.08313, lr:6.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.877, tt:1957.754\n",
      "Ep:116, loss:0.00000, loss_test:0.08324, lr:6.30e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.890, tt:1976.073\n",
      "Ep:117, loss:0.00000, loss_test:0.08326, lr:6.24e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.901, tt:1994.273\n",
      "Ep:118, loss:0.00000, loss_test:0.08322, lr:6.17e-03, fs:0.77011 (r=0.677,p=0.893),  time:16.903, tt:2011.513\n",
      "Ep:119, loss:0.00000, loss_test:0.08317, lr:6.11e-03, fs:0.77011 (r=0.677,p=0.893),  time:16.909, tt:2029.028\n",
      "Ep:120, loss:0.00000, loss_test:0.08314, lr:6.05e-03, fs:0.77011 (r=0.677,p=0.893),  time:16.918, tt:2047.103\n",
      "Ep:121, loss:0.00000, loss_test:0.08321, lr:5.99e-03, fs:0.77011 (r=0.677,p=0.893),  time:16.926, tt:2064.974\n",
      "Ep:122, loss:0.00000, loss_test:0.08327, lr:5.93e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.932, tt:2082.593\n",
      "Ep:123, loss:0.00000, loss_test:0.08325, lr:5.87e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.934, tt:2099.789\n",
      "Ep:124, loss:0.00000, loss_test:0.08324, lr:5.81e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.938, tt:2117.209\n",
      "Ep:125, loss:0.00000, loss_test:0.08326, lr:5.75e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.937, tt:2134.081\n",
      "Ep:126, loss:0.00000, loss_test:0.08333, lr:5.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.937, tt:2151.035\n",
      "Ep:127, loss:0.00000, loss_test:0.08339, lr:5.64e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.937, tt:2167.993\n",
      "Ep:128, loss:0.00000, loss_test:0.08341, lr:5.58e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.939, tt:2185.156\n",
      "Ep:129, loss:0.00000, loss_test:0.08338, lr:5.53e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.940, tt:2202.208\n",
      "Ep:130, loss:0.00000, loss_test:0.08335, lr:5.47e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.945, tt:2219.766\n",
      "Ep:131, loss:0.00000, loss_test:0.08326, lr:5.42e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.943, tt:2236.514\n",
      "Ep:132, loss:0.00000, loss_test:0.08314, lr:5.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.943, tt:2253.401\n",
      "Ep:133, loss:0.00000, loss_test:0.08309, lr:5.31e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.945, tt:2270.684\n",
      "Ep:134, loss:0.00000, loss_test:0.08311, lr:5.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:16.946, tt:2287.699\n",
      "Ep:135, loss:0.00000, loss_test:0.08315, lr:5.20e-03, fs:0.77714 (r=0.687,p=0.895),  time:16.945, tt:2304.574\n",
      "Ep:136, loss:0.00000, loss_test:0.08314, lr:5.15e-03, fs:0.77714 (r=0.687,p=0.895),  time:16.950, tt:2322.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.08307, lr:5.10e-03, fs:0.77011 (r=0.677,p=0.893),  time:16.952, tt:2339.328\n",
      "Ep:138, loss:0.00000, loss_test:0.08300, lr:5.05e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.947, tt:2355.628\n",
      "Ep:139, loss:0.00000, loss_test:0.08296, lr:5.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.947, tt:2372.599\n",
      "Ep:140, loss:0.00000, loss_test:0.08297, lr:4.95e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.945, tt:2389.282\n",
      "Ep:141, loss:0.00000, loss_test:0.08304, lr:4.90e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.943, tt:2405.933\n",
      "Ep:142, loss:0.00000, loss_test:0.08314, lr:4.85e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.936, tt:2421.911\n",
      "Ep:143, loss:0.00000, loss_test:0.08320, lr:4.80e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.937, tt:2438.894\n",
      "Ep:144, loss:0.00000, loss_test:0.08321, lr:4.75e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.935, tt:2455.626\n",
      "Ep:145, loss:0.00000, loss_test:0.08318, lr:4.71e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.932, tt:2472.073\n",
      "Ep:146, loss:0.00000, loss_test:0.08311, lr:4.66e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.932, tt:2489.000\n",
      "Ep:147, loss:0.00000, loss_test:0.08307, lr:4.61e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.936, tt:2506.495\n",
      "Ep:148, loss:0.00000, loss_test:0.08307, lr:4.57e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.934, tt:2523.194\n",
      "Ep:149, loss:0.00000, loss_test:0.08312, lr:4.52e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.932, tt:2539.870\n",
      "Ep:150, loss:0.00000, loss_test:0.08320, lr:4.48e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.940, tt:2557.937\n",
      "Ep:151, loss:0.00000, loss_test:0.08329, lr:4.43e-03, fs:0.76023 (r=0.657,p=0.903),  time:16.938, tt:2574.548\n",
      "Ep:152, loss:0.00000, loss_test:0.08337, lr:4.39e-03, fs:0.76023 (r=0.657,p=0.903),  time:16.933, tt:2590.691\n",
      "Ep:153, loss:0.00000, loss_test:0.08344, lr:4.34e-03, fs:0.76023 (r=0.657,p=0.903),  time:16.932, tt:2607.554\n",
      "Ep:154, loss:0.00000, loss_test:0.08349, lr:4.30e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.934, tt:2624.761\n",
      "Ep:155, loss:0.00000, loss_test:0.08354, lr:4.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:16.935, tt:2641.877\n",
      "Ep:156, loss:0.00000, loss_test:0.08353, lr:4.21e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.930, tt:2657.932\n",
      "Ep:157, loss:0.00000, loss_test:0.08354, lr:4.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.926, tt:2674.323\n",
      "Ep:158, loss:0.00000, loss_test:0.08357, lr:4.13e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.925, tt:2691.022\n",
      "Ep:159, loss:0.00000, loss_test:0.08361, lr:4.09e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.922, tt:2707.525\n",
      "Ep:160, loss:0.00000, loss_test:0.08364, lr:4.05e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.921, tt:2724.216\n",
      "Ep:161, loss:0.00000, loss_test:0.08364, lr:4.01e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.914, tt:2740.048\n",
      "Ep:162, loss:0.00000, loss_test:0.08360, lr:3.97e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.916, tt:2757.351\n",
      "Ep:163, loss:0.00000, loss_test:0.08357, lr:3.93e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.915, tt:2774.067\n",
      "Ep:164, loss:0.00000, loss_test:0.08362, lr:3.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.916, tt:2791.177\n",
      "Ep:165, loss:0.00000, loss_test:0.08372, lr:3.85e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.918, tt:2808.353\n",
      "Ep:166, loss:0.00000, loss_test:0.08383, lr:3.81e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.918, tt:2825.380\n",
      "Ep:167, loss:0.00000, loss_test:0.08395, lr:3.77e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.922, tt:2842.847\n",
      "Ep:168, loss:0.00000, loss_test:0.08406, lr:3.73e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.913, tt:2858.354\n",
      "Ep:169, loss:0.00000, loss_test:0.08415, lr:3.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.909, tt:2874.581\n",
      "Ep:170, loss:0.00000, loss_test:0.08426, lr:3.66e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.904, tt:2890.559\n",
      "Ep:171, loss:0.00000, loss_test:0.08434, lr:3.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.905, tt:2907.734\n",
      "Ep:172, loss:0.00000, loss_test:0.08433, lr:3.59e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.904, tt:2924.476\n",
      "Ep:173, loss:0.00000, loss_test:0.08428, lr:3.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.905, tt:2941.433\n",
      "Ep:174, loss:0.00000, loss_test:0.08423, lr:3.52e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.903, tt:2958.056\n",
      "Ep:175, loss:0.00000, loss_test:0.08424, lr:3.48e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.902, tt:2974.723\n",
      "Ep:176, loss:0.00000, loss_test:0.08432, lr:3.45e-03, fs:0.76190 (r=0.646,p=0.928),  time:16.894, tt:2990.214\n",
      "Ep:177, loss:0.00000, loss_test:0.08442, lr:3.41e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.890, tt:3006.501\n",
      "Ep:178, loss:0.00000, loss_test:0.08453, lr:3.38e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.891, tt:3023.464\n",
      "Ep:179, loss:0.00000, loss_test:0.08461, lr:3.34e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.886, tt:3039.516\n",
      "Ep:180, loss:0.00000, loss_test:0.08469, lr:3.31e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.885, tt:3056.247\n",
      "Ep:181, loss:0.00000, loss_test:0.08476, lr:3.28e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.885, tt:3073.063\n",
      "Ep:182, loss:0.00000, loss_test:0.08485, lr:3.24e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.886, tt:3090.213\n",
      "Ep:183, loss:0.00000, loss_test:0.08495, lr:3.21e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.887, tt:3107.258\n",
      "Ep:184, loss:0.00000, loss_test:0.08503, lr:3.18e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.886, tt:3123.869\n",
      "Ep:185, loss:0.00000, loss_test:0.08508, lr:3.15e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.886, tt:3140.773\n",
      "Ep:186, loss:0.00000, loss_test:0.08518, lr:3.12e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.887, tt:3157.833\n",
      "Ep:187, loss:0.00000, loss_test:0.08529, lr:3.09e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.891, tt:3175.564\n",
      "Ep:188, loss:0.00000, loss_test:0.08542, lr:3.05e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.896, tt:3193.380\n",
      "Ep:189, loss:0.00000, loss_test:0.08552, lr:3.02e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.905, tt:3211.864\n",
      "Ep:190, loss:0.00000, loss_test:0.08561, lr:2.99e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.905, tt:3228.779\n",
      "Ep:191, loss:0.00000, loss_test:0.08568, lr:2.96e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.909, tt:3246.494\n",
      "Ep:192, loss:0.00000, loss_test:0.08574, lr:2.93e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.911, tt:3263.885\n",
      "Ep:193, loss:0.00000, loss_test:0.08579, lr:2.90e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.915, tt:3281.580\n",
      "Ep:194, loss:0.00000, loss_test:0.08584, lr:2.88e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.921, tt:3299.551\n",
      "Ep:195, loss:0.00000, loss_test:0.08591, lr:2.85e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.925, tt:3317.234\n",
      "Ep:196, loss:0.00000, loss_test:0.08597, lr:2.82e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.925, tt:3334.210\n",
      "Ep:197, loss:0.00000, loss_test:0.08605, lr:2.79e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.931, tt:3352.283\n",
      "Ep:198, loss:0.00000, loss_test:0.08617, lr:2.76e-03, fs:0.75904 (r=0.636,p=0.940),  time:16.938, tt:3370.614\n",
      "Ep:199, loss:0.00000, loss_test:0.08634, lr:2.73e-03, fs:0.76364 (r=0.636,p=0.955),  time:16.944, tt:3388.725\n",
      "Ep:200, loss:0.00000, loss_test:0.08648, lr:2.71e-03, fs:0.76364 (r=0.636,p=0.955),  time:16.947, tt:3406.308\n",
      "Ep:201, loss:0.00000, loss_test:0.08657, lr:2.68e-03, fs:0.76364 (r=0.636,p=0.955),  time:16.946, tt:3423.022\n",
      "Ep:202, loss:0.00000, loss_test:0.08665, lr:2.65e-03, fs:0.76364 (r=0.636,p=0.955),  time:16.951, tt:3440.958\n",
      "Ep:203, loss:0.00000, loss_test:0.08673, lr:2.63e-03, fs:0.75610 (r=0.626,p=0.954),  time:16.955, tt:3458.792\n",
      "Ep:204, loss:0.00000, loss_test:0.08683, lr:2.60e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.963, tt:3477.362\n",
      "Ep:205, loss:0.00000, loss_test:0.08692, lr:2.57e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.965, tt:3494.711\n",
      "Ep:206, loss:0.00000, loss_test:0.08700, lr:2.55e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.971, tt:3512.976\n",
      "Ep:207, loss:0.00000, loss_test:0.08704, lr:2.52e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.974, tt:3530.543\n",
      "Ep:208, loss:0.00000, loss_test:0.08705, lr:2.50e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.977, tt:3548.194\n",
      "Ep:209, loss:0.00000, loss_test:0.08706, lr:2.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.981, tt:3565.957\n",
      "Ep:210, loss:0.00000, loss_test:0.08710, lr:2.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:16.990, tt:3584.912\n",
      "Ep:211, loss:0.00000, loss_test:0.08713, lr:2.42e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.002, tt:3604.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.08715, lr:2.40e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.011, tt:3623.368\n",
      "Ep:213, loss:0.00000, loss_test:0.08717, lr:2.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.019, tt:3641.969\n",
      "Ep:214, loss:0.00000, loss_test:0.08719, lr:2.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.027, tt:3660.728\n",
      "Ep:215, loss:0.00000, loss_test:0.08722, lr:2.33e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.032, tt:3678.955\n",
      "Ep:216, loss:0.00000, loss_test:0.08724, lr:2.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.035, tt:3696.550\n",
      "Ep:217, loss:0.00000, loss_test:0.08730, lr:2.28e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.044, tt:3715.585\n",
      "Ep:218, loss:0.00000, loss_test:0.08738, lr:2.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.048, tt:3733.481\n",
      "Ep:219, loss:0.00000, loss_test:0.08748, lr:2.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.055, tt:3752.104\n",
      "Ep:220, loss:0.00000, loss_test:0.08755, lr:2.21e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.060, tt:3770.243\n",
      "Ep:221, loss:0.00000, loss_test:0.08761, lr:2.19e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.063, tt:3787.902\n",
      "Ep:222, loss:0.00000, loss_test:0.08763, lr:2.17e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.068, tt:3806.141\n",
      "Ep:223, loss:0.00000, loss_test:0.08766, lr:2.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.069, tt:3823.380\n",
      "Ep:224, loss:0.00000, loss_test:0.08770, lr:2.13e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.071, tt:3840.907\n",
      "Ep:225, loss:0.00000, loss_test:0.08775, lr:2.11e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.077, tt:3859.383\n",
      "Ep:226, loss:0.00000, loss_test:0.08777, lr:2.08e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.084, tt:3878.034\n",
      "Ep:227, loss:0.00000, loss_test:0.08778, lr:2.06e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.089, tt:3896.333\n",
      "Ep:228, loss:0.00000, loss_test:0.08778, lr:2.04e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.094, tt:3914.560\n",
      "Ep:229, loss:0.00000, loss_test:0.08779, lr:2.02e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.098, tt:3932.651\n",
      "Ep:230, loss:0.00000, loss_test:0.08782, lr:2.00e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.105, tt:3951.269\n",
      "Ep:231, loss:0.00000, loss_test:0.08785, lr:1.98e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.112, tt:3969.956\n",
      "Ep:232, loss:0.00000, loss_test:0.08786, lr:1.96e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.114, tt:3987.551\n",
      "Ep:233, loss:0.00000, loss_test:0.08788, lr:1.94e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.116, tt:4005.206\n",
      "Ep:234, loss:0.00000, loss_test:0.08789, lr:1.92e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.119, tt:4022.946\n",
      "Ep:235, loss:0.00000, loss_test:0.08789, lr:1.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.124, tt:4041.238\n",
      "Ep:236, loss:0.00000, loss_test:0.08787, lr:1.89e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.123, tt:4058.153\n",
      "Ep:237, loss:0.00000, loss_test:0.08786, lr:1.87e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.124, tt:4075.484\n",
      "Ep:238, loss:0.00000, loss_test:0.08784, lr:1.85e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.126, tt:4093.102\n",
      "Ep:239, loss:0.00000, loss_test:0.08786, lr:1.83e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.123, tt:4109.609\n",
      "Ep:240, loss:0.00000, loss_test:0.08790, lr:1.81e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.127, tt:4127.580\n",
      "Ep:241, loss:0.00000, loss_test:0.08794, lr:1.79e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.129, tt:4145.233\n",
      "Ep:242, loss:0.00000, loss_test:0.08798, lr:1.78e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.130, tt:4162.549\n",
      "Ep:243, loss:0.00000, loss_test:0.08803, lr:1.76e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.132, tt:4180.162\n",
      "Ep:244, loss:0.00000, loss_test:0.08805, lr:1.74e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.134, tt:4197.783\n",
      "Ep:245, loss:0.00000, loss_test:0.08806, lr:1.72e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.132, tt:4214.497\n",
      "Ep:246, loss:0.00000, loss_test:0.08808, lr:1.71e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.134, tt:4232.128\n",
      "Ep:247, loss:0.00000, loss_test:0.08810, lr:1.69e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.140, tt:4250.604\n",
      "Ep:248, loss:0.00000, loss_test:0.08811, lr:1.67e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.147, tt:4269.579\n",
      "Ep:249, loss:0.00000, loss_test:0.08813, lr:1.65e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.153, tt:4288.178\n",
      "Ep:250, loss:0.00000, loss_test:0.08816, lr:1.64e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.159, tt:4306.886\n",
      "Ep:251, loss:0.00000, loss_test:0.08821, lr:1.62e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.161, tt:4324.499\n",
      "Ep:252, loss:0.00000, loss_test:0.08825, lr:1.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.165, tt:4342.622\n",
      "Ep:253, loss:0.00000, loss_test:0.08829, lr:1.59e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.166, tt:4360.262\n",
      "Ep:254, loss:0.00000, loss_test:0.08832, lr:1.57e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.171, tt:4378.525\n",
      "Ep:255, loss:0.00000, loss_test:0.08832, lr:1.56e-03, fs:0.75309 (r=0.616,p=0.968),  time:17.177, tt:4397.419\n",
      "Ep:256, loss:0.00000, loss_test:0.08832, lr:1.54e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.184, tt:4416.226\n",
      "Ep:257, loss:0.00000, loss_test:0.08833, lr:1.53e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.185, tt:4433.683\n",
      "Ep:258, loss:0.00000, loss_test:0.08834, lr:1.51e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.185, tt:4450.814\n",
      "Ep:259, loss:0.00000, loss_test:0.08838, lr:1.50e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.189, tt:4469.237\n",
      "Ep:260, loss:0.00000, loss_test:0.08842, lr:1.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.194, tt:4487.540\n",
      "Ep:261, loss:0.00000, loss_test:0.08846, lr:1.47e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.198, tt:4505.827\n",
      "Ep:262, loss:0.00000, loss_test:0.08850, lr:1.45e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.205, tt:4525.036\n",
      "Ep:263, loss:0.00000, loss_test:0.08855, lr:1.44e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.214, tt:4544.479\n",
      "Ep:264, loss:0.00000, loss_test:0.08860, lr:1.42e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.221, tt:4563.574\n",
      "Ep:265, loss:0.00000, loss_test:0.08864, lr:1.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.227, tt:4582.393\n",
      "Ep:266, loss:0.00000, loss_test:0.08869, lr:1.39e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.231, tt:4600.619\n",
      "Ep:267, loss:0.00000, loss_test:0.08872, lr:1.38e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.232, tt:4618.134\n",
      "Ep:268, loss:0.00000, loss_test:0.08874, lr:1.37e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.237, tt:4636.834\n",
      "Ep:269, loss:0.00000, loss_test:0.08874, lr:1.35e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.245, tt:4656.052\n",
      "Ep:270, loss:0.00000, loss_test:0.08874, lr:1.34e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.247, tt:4673.982\n",
      "Ep:271, loss:0.00000, loss_test:0.08875, lr:1.33e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.252, tt:4692.457\n",
      "Ep:272, loss:0.00000, loss_test:0.08876, lr:1.31e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.258, tt:4711.324\n",
      "Ep:273, loss:0.00000, loss_test:0.08879, lr:1.30e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.260, tt:4729.336\n",
      "Ep:274, loss:0.00000, loss_test:0.08882, lr:1.29e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.267, tt:4748.295\n",
      "Ep:275, loss:0.00000, loss_test:0.08885, lr:1.27e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.272, tt:4767.147\n",
      "Ep:276, loss:0.00000, loss_test:0.08888, lr:1.26e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.276, tt:4785.394\n",
      "Ep:277, loss:0.00000, loss_test:0.08890, lr:1.25e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.277, tt:4802.996\n",
      "Ep:278, loss:0.00000, loss_test:0.08892, lr:1.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.272, tt:4818.975\n",
      "Ep:279, loss:0.00000, loss_test:0.08895, lr:1.22e-03, fs:0.76074 (r=0.626,p=0.969),  time:17.275, tt:4836.979\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 40000: \n",
      "Ep:0, loss:0.00000, loss_test:0.14469, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.864, tt:16.864\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00000, loss_test:0.14442, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.629, tt:33.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00000, loss_test:0.14401, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.005, tt:48.014\n",
      "Ep:3, loss:0.00000, loss_test:0.14343, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.905, tt:63.621\n",
      "Ep:4, loss:0.00000, loss_test:0.14267, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.807, tt:79.036\n",
      "Ep:5, loss:0.00000, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.012, tt:96.072\n",
      "Ep:6, loss:0.00000, loss_test:0.14045, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:16.300, tt:114.103\n",
      "Ep:7, loss:0.00000, loss_test:0.13888, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:16.549, tt:132.389\n",
      "Ep:8, loss:0.00000, loss_test:0.13694, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:16.708, tt:150.368\n",
      "Ep:9, loss:0.00000, loss_test:0.13456, lr:1.00e-02, fs:0.64085 (r=0.919,p=0.492),  time:16.881, tt:168.814\n",
      "Ep:10, loss:0.00000, loss_test:0.13166, lr:1.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:16.963, tt:186.597\n",
      "Ep:11, loss:0.00000, loss_test:0.12804, lr:1.00e-02, fs:0.64865 (r=0.848,p=0.525),  time:17.059, tt:204.712\n",
      "Ep:12, loss:0.00000, loss_test:0.12401, lr:9.90e-03, fs:0.67206 (r=0.838,p=0.561),  time:17.140, tt:222.819\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00000, loss_test:0.12040, lr:9.90e-03, fs:0.69333 (r=0.788,p=0.619),  time:17.129, tt:239.805\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00000, loss_test:0.11843, lr:9.90e-03, fs:0.69444 (r=0.758,p=0.641),  time:17.139, tt:257.092\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00000, loss_test:0.11713, lr:9.90e-03, fs:0.69565 (r=0.727,p=0.667),  time:17.137, tt:274.196\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00000, loss_test:0.11602, lr:9.90e-03, fs:0.68932 (r=0.717,p=0.664),  time:17.042, tt:289.718\n",
      "Ep:17, loss:0.00000, loss_test:0.11491, lr:9.90e-03, fs:0.70142 (r=0.747,p=0.661),  time:17.057, tt:307.034\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00000, loss_test:0.11385, lr:9.90e-03, fs:0.70642 (r=0.778,p=0.647),  time:17.035, tt:323.672\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00000, loss_test:0.11281, lr:9.90e-03, fs:0.71749 (r=0.808,p=0.645),  time:17.005, tt:340.105\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00000, loss_test:0.11152, lr:9.90e-03, fs:0.71111 (r=0.808,p=0.635),  time:16.986, tt:356.715\n",
      "Ep:21, loss:0.00000, loss_test:0.10987, lr:9.90e-03, fs:0.71429 (r=0.808,p=0.640),  time:16.979, tt:373.530\n",
      "Ep:22, loss:0.00000, loss_test:0.10785, lr:9.90e-03, fs:0.73733 (r=0.808,p=0.678),  time:16.953, tt:389.917\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00000, loss_test:0.10585, lr:9.90e-03, fs:0.73148 (r=0.798,p=0.675),  time:16.913, tt:405.923\n",
      "Ep:24, loss:0.00000, loss_test:0.10440, lr:9.90e-03, fs:0.74528 (r=0.798,p=0.699),  time:16.908, tt:422.694\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00000, loss_test:0.10341, lr:9.90e-03, fs:0.74757 (r=0.778,p=0.720),  time:16.904, tt:439.499\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00000, loss_test:0.10250, lr:9.90e-03, fs:0.74757 (r=0.778,p=0.720),  time:16.880, tt:455.756\n",
      "Ep:27, loss:0.00000, loss_test:0.10142, lr:9.90e-03, fs:0.74757 (r=0.778,p=0.720),  time:16.903, tt:473.283\n",
      "Ep:28, loss:0.00000, loss_test:0.10037, lr:9.90e-03, fs:0.74757 (r=0.778,p=0.720),  time:16.899, tt:490.070\n",
      "Ep:29, loss:0.00000, loss_test:0.09945, lr:9.90e-03, fs:0.77143 (r=0.818,p=0.730),  time:16.884, tt:506.532\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.09854, lr:9.90e-03, fs:0.77885 (r=0.818,p=0.743),  time:16.883, tt:523.383\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.09751, lr:9.90e-03, fs:0.77885 (r=0.818,p=0.743),  time:16.859, tt:539.476\n",
      "Ep:32, loss:0.00000, loss_test:0.09645, lr:9.90e-03, fs:0.78469 (r=0.828,p=0.745),  time:16.868, tt:556.631\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.09551, lr:9.90e-03, fs:0.78469 (r=0.828,p=0.745),  time:16.860, tt:573.232\n",
      "Ep:34, loss:0.00000, loss_test:0.09469, lr:9.90e-03, fs:0.77670 (r=0.808,p=0.748),  time:16.861, tt:590.139\n",
      "Ep:35, loss:0.00000, loss_test:0.09405, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:16.827, tt:605.766\n",
      "Ep:36, loss:0.00000, loss_test:0.09335, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:16.836, tt:622.945\n",
      "Ep:37, loss:0.00000, loss_test:0.09262, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:16.863, tt:640.784\n",
      "Ep:38, loss:0.00000, loss_test:0.09190, lr:9.90e-03, fs:0.76847 (r=0.788,p=0.750),  time:16.850, tt:657.132\n",
      "Ep:39, loss:0.00000, loss_test:0.09118, lr:9.90e-03, fs:0.77451 (r=0.798,p=0.752),  time:16.834, tt:673.360\n",
      "Ep:40, loss:0.00000, loss_test:0.09054, lr:9.90e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.823, tt:689.732\n",
      "Ep:41, loss:0.00000, loss_test:0.09000, lr:9.90e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.826, tt:706.695\n",
      "Ep:42, loss:0.00000, loss_test:0.08956, lr:9.90e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.812, tt:722.903\n",
      "Ep:43, loss:0.00000, loss_test:0.08909, lr:9.90e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.820, tt:740.068\n",
      "Ep:44, loss:0.00000, loss_test:0.08860, lr:9.80e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.835, tt:757.572\n",
      "Ep:45, loss:0.00000, loss_test:0.08812, lr:9.70e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.840, tt:774.653\n",
      "Ep:46, loss:0.00000, loss_test:0.08768, lr:9.61e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.846, tt:791.748\n",
      "Ep:47, loss:0.00000, loss_test:0.08730, lr:9.51e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.859, tt:809.223\n",
      "Ep:48, loss:0.00000, loss_test:0.08706, lr:9.41e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.870, tt:826.632\n",
      "Ep:49, loss:0.00000, loss_test:0.08693, lr:9.32e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.866, tt:843.283\n",
      "Ep:50, loss:0.00000, loss_test:0.08675, lr:9.23e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.872, tt:860.495\n",
      "Ep:51, loss:0.00000, loss_test:0.08649, lr:9.14e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.886, tt:878.092\n",
      "Ep:52, loss:0.00000, loss_test:0.08615, lr:9.04e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.894, tt:895.387\n",
      "Ep:53, loss:0.00000, loss_test:0.08581, lr:8.95e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.880, tt:911.530\n",
      "Ep:54, loss:0.00000, loss_test:0.08552, lr:8.86e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.898, tt:929.392\n",
      "Ep:55, loss:0.00000, loss_test:0.08526, lr:8.78e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.903, tt:946.565\n",
      "Ep:56, loss:0.00000, loss_test:0.08501, lr:8.69e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.908, tt:963.776\n",
      "Ep:57, loss:0.00000, loss_test:0.08471, lr:8.60e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.905, tt:980.495\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00000, loss_test:0.08436, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.921, tt:998.340\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00000, loss_test:0.08402, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.936, tt:1016.151\n",
      "Ep:60, loss:0.00000, loss_test:0.08372, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.943, tt:1033.546\n",
      "Ep:61, loss:0.00000, loss_test:0.08350, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.938, tt:1050.177\n",
      "Ep:62, loss:0.00000, loss_test:0.08327, lr:8.60e-03, fs:0.80000 (r=0.808,p=0.792),  time:16.928, tt:1066.452\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00000, loss_test:0.08297, lr:8.60e-03, fs:0.80402 (r=0.808,p=0.800),  time:16.927, tt:1083.347\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00000, loss_test:0.08262, lr:8.60e-03, fs:0.80402 (r=0.808,p=0.800),  time:16.940, tt:1101.085\n",
      "Ep:65, loss:0.00000, loss_test:0.08229, lr:8.60e-03, fs:0.80402 (r=0.808,p=0.800),  time:16.966, tt:1119.740\n",
      "Ep:66, loss:0.00000, loss_test:0.08200, lr:8.60e-03, fs:0.81000 (r=0.818,p=0.802),  time:16.983, tt:1137.875\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00000, loss_test:0.08174, lr:8.60e-03, fs:0.81407 (r=0.818,p=0.810),  time:17.008, tt:1156.516\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00000, loss_test:0.08153, lr:8.60e-03, fs:0.80808 (r=0.808,p=0.808),  time:17.019, tt:1174.324\n",
      "Ep:69, loss:0.00000, loss_test:0.08136, lr:8.60e-03, fs:0.80808 (r=0.808,p=0.808),  time:17.042, tt:1192.959\n",
      "Ep:70, loss:0.00000, loss_test:0.08118, lr:8.60e-03, fs:0.80808 (r=0.808,p=0.808),  time:17.063, tt:1211.458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00000, loss_test:0.08096, lr:8.60e-03, fs:0.80808 (r=0.808,p=0.808),  time:17.089, tt:1230.421\n",
      "Ep:72, loss:0.00000, loss_test:0.08073, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.100, tt:1248.291\n",
      "Ep:73, loss:0.00000, loss_test:0.08053, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.122, tt:1266.995\n",
      "Ep:74, loss:0.00000, loss_test:0.08034, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.155, tt:1286.631\n",
      "Ep:75, loss:0.00000, loss_test:0.08011, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.168, tt:1304.770\n",
      "Ep:76, loss:0.00000, loss_test:0.07986, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.188, tt:1323.510\n",
      "Ep:77, loss:0.00000, loss_test:0.07958, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.201, tt:1341.705\n",
      "Ep:78, loss:0.00000, loss_test:0.07933, lr:8.60e-03, fs:0.81218 (r=0.808,p=0.816),  time:17.219, tt:1360.297\n",
      "Ep:79, loss:0.00000, loss_test:0.07911, lr:8.51e-03, fs:0.81633 (r=0.808,p=0.825),  time:17.237, tt:1378.972\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00000, loss_test:0.07893, lr:8.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:17.258, tt:1397.928\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00000, loss_test:0.07874, lr:8.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:17.289, tt:1417.687\n",
      "Ep:82, loss:0.00000, loss_test:0.07857, lr:8.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:17.303, tt:1436.146\n",
      "Ep:83, loss:0.00000, loss_test:0.07843, lr:8.51e-03, fs:0.81865 (r=0.798,p=0.840),  time:17.310, tt:1454.001\n",
      "Ep:84, loss:0.00000, loss_test:0.07827, lr:8.51e-03, fs:0.82723 (r=0.798,p=0.859),  time:17.326, tt:1472.705\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00000, loss_test:0.07811, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.340, tt:1491.217\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00000, loss_test:0.07795, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.352, tt:1509.608\n",
      "Ep:87, loss:0.00000, loss_test:0.07771, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.364, tt:1527.999\n",
      "Ep:88, loss:0.00000, loss_test:0.07744, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.369, tt:1545.863\n",
      "Ep:89, loss:0.00000, loss_test:0.07715, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.378, tt:1564.064\n",
      "Ep:90, loss:0.00000, loss_test:0.07689, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.381, tt:1581.679\n",
      "Ep:91, loss:0.00000, loss_test:0.07672, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.379, tt:1598.838\n",
      "Ep:92, loss:0.00000, loss_test:0.07664, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.379, tt:1616.276\n",
      "Ep:93, loss:0.00000, loss_test:0.07657, lr:8.51e-03, fs:0.83158 (r=0.798,p=0.868),  time:17.382, tt:1633.934\n",
      "Ep:94, loss:0.00000, loss_test:0.07641, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.378, tt:1650.921\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00000, loss_test:0.07616, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.390, tt:1669.441\n",
      "Ep:96, loss:0.00000, loss_test:0.07587, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.415, tt:1689.212\n",
      "Ep:97, loss:0.00000, loss_test:0.07561, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.428, tt:1707.976\n",
      "Ep:98, loss:0.00000, loss_test:0.07542, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.446, tt:1727.188\n",
      "Ep:99, loss:0.00000, loss_test:0.07530, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.465, tt:1746.472\n",
      "Ep:100, loss:0.00000, loss_test:0.07516, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.472, tt:1764.720\n",
      "Ep:101, loss:0.00000, loss_test:0.07501, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.491, tt:1784.119\n",
      "Ep:102, loss:0.00000, loss_test:0.07493, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.510, tt:1803.543\n",
      "Ep:103, loss:0.00000, loss_test:0.07486, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.520, tt:1822.041\n",
      "Ep:104, loss:0.00000, loss_test:0.07474, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.522, tt:1839.828\n",
      "Ep:105, loss:0.00000, loss_test:0.07451, lr:8.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.532, tt:1858.355\n",
      "Ep:106, loss:0.00000, loss_test:0.07424, lr:8.43e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.544, tt:1877.195\n",
      "Ep:107, loss:0.00000, loss_test:0.07405, lr:8.35e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.572, tt:1897.739\n",
      "Ep:108, loss:0.00000, loss_test:0.07396, lr:8.26e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.578, tt:1916.030\n",
      "Ep:109, loss:0.00000, loss_test:0.07389, lr:8.18e-03, fs:0.83598 (r=0.798,p=0.878),  time:17.589, tt:1934.791\n",
      "Ep:110, loss:0.00000, loss_test:0.07372, lr:8.10e-03, fs:0.84211 (r=0.808,p=0.879),  time:17.604, tt:1954.030\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.07347, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.613, tt:1972.653\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.07324, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.620, tt:1991.061\n",
      "Ep:113, loss:0.00000, loss_test:0.07314, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.629, tt:2009.745\n",
      "Ep:114, loss:0.00000, loss_test:0.07305, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.635, tt:2027.996\n",
      "Ep:115, loss:0.00000, loss_test:0.07298, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.636, tt:2045.743\n",
      "Ep:116, loss:0.00000, loss_test:0.07286, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.648, tt:2064.799\n",
      "Ep:117, loss:0.00000, loss_test:0.07272, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.652, tt:2082.942\n",
      "Ep:118, loss:0.00000, loss_test:0.07260, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.651, tt:2100.520\n",
      "Ep:119, loss:0.00000, loss_test:0.07255, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.653, tt:2118.347\n",
      "Ep:120, loss:0.00000, loss_test:0.07251, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.656, tt:2136.414\n",
      "Ep:121, loss:0.00000, loss_test:0.07241, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.660, tt:2154.482\n",
      "Ep:122, loss:0.00000, loss_test:0.07225, lr:8.10e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.668, tt:2173.121\n",
      "Ep:123, loss:0.00000, loss_test:0.07213, lr:8.02e-03, fs:0.84817 (r=0.818,p=0.880),  time:17.677, tt:2191.893\n",
      "Ep:124, loss:0.00000, loss_test:0.07206, lr:7.94e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.691, tt:2211.312\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00000, loss_test:0.07196, lr:7.94e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.710, tt:2231.435\n",
      "Ep:126, loss:0.00000, loss_test:0.07178, lr:7.94e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.718, tt:2250.167\n",
      "Ep:127, loss:0.00000, loss_test:0.07161, lr:7.94e-03, fs:0.85263 (r=0.818,p=0.890),  time:17.729, tt:2269.299\n",
      "Ep:128, loss:0.00000, loss_test:0.07164, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.740, tt:2288.436\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00000, loss_test:0.07168, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.743, tt:2306.642\n",
      "Ep:130, loss:0.00000, loss_test:0.07166, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.750, tt:2325.194\n",
      "Ep:131, loss:0.00000, loss_test:0.07161, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.765, tt:2344.945\n",
      "Ep:132, loss:0.00000, loss_test:0.07160, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.773, tt:2363.864\n",
      "Ep:133, loss:0.00000, loss_test:0.07157, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.778, tt:2382.299\n",
      "Ep:134, loss:0.00000, loss_test:0.07150, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.779, tt:2400.226\n",
      "Ep:135, loss:0.00000, loss_test:0.07143, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.780, tt:2418.066\n",
      "Ep:136, loss:0.00000, loss_test:0.07137, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.794, tt:2437.837\n",
      "Ep:137, loss:0.00000, loss_test:0.07132, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.799, tt:2456.320\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00000, loss_test:0.07121, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.805, tt:2474.873\n",
      "Ep:139, loss:0.00000, loss_test:0.07115, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.815, tt:2494.093\n",
      "Ep:140, loss:0.00000, loss_test:0.07121, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.820, tt:2512.592\n",
      "Ep:141, loss:0.00000, loss_test:0.07128, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.821, tt:2530.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.07126, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.827, tt:2549.219\n",
      "Ep:143, loss:0.00000, loss_test:0.07115, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.828, tt:2567.215\n",
      "Ep:144, loss:0.00000, loss_test:0.07103, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.834, tt:2585.926\n",
      "Ep:145, loss:0.00000, loss_test:0.07096, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.836, tt:2604.126\n",
      "Ep:146, loss:0.00000, loss_test:0.07090, lr:7.94e-03, fs:0.85714 (r=0.818,p=0.900),  time:17.838, tt:2622.154\n",
      "Ep:147, loss:0.00000, loss_test:0.07084, lr:7.94e-03, fs:0.86170 (r=0.818,p=0.910),  time:17.842, tt:2640.558\n",
      "Ep:148, loss:0.00000, loss_test:0.07073, lr:7.94e-03, fs:0.86772 (r=0.828,p=0.911),  time:17.849, tt:2659.537\n",
      "##########Best model found so far##########\n",
      "Ep:149, loss:0.00000, loss_test:0.07068, lr:7.94e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.856, tt:2678.468\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00000, loss_test:0.07074, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.859, tt:2696.756\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00000, loss_test:0.07074, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.864, tt:2715.272\n",
      "Ep:152, loss:0.00000, loss_test:0.07057, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.872, tt:2734.376\n",
      "Ep:153, loss:0.00000, loss_test:0.07046, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.882, tt:2753.895\n",
      "Ep:154, loss:0.00000, loss_test:0.07049, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.891, tt:2773.129\n",
      "Ep:155, loss:0.00000, loss_test:0.07048, lr:7.94e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.896, tt:2791.733\n",
      "Ep:156, loss:0.00000, loss_test:0.07036, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.912, tt:2812.233\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00000, loss_test:0.07023, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.922, tt:2831.704\n",
      "Ep:158, loss:0.00000, loss_test:0.07019, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.936, tt:2851.872\n",
      "Ep:159, loss:0.00000, loss_test:0.07026, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.942, tt:2870.671\n",
      "Ep:160, loss:0.00000, loss_test:0.07030, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.949, tt:2889.803\n",
      "Ep:161, loss:0.00000, loss_test:0.07028, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.955, tt:2908.653\n",
      "Ep:162, loss:0.00000, loss_test:0.07026, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.958, tt:2927.092\n",
      "Ep:163, loss:0.00000, loss_test:0.07027, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.967, tt:2946.515\n",
      "Ep:164, loss:0.00000, loss_test:0.07024, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.970, tt:2965.087\n",
      "Ep:165, loss:0.00000, loss_test:0.07017, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.975, tt:2983.898\n",
      "Ep:166, loss:0.00000, loss_test:0.07015, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.985, tt:3003.430\n",
      "Ep:167, loss:0.00000, loss_test:0.07024, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.992, tt:3022.589\n",
      "Ep:168, loss:0.00000, loss_test:0.07030, lr:7.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.000, tt:3042.052\n",
      "Ep:169, loss:0.00000, loss_test:0.07025, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.004, tt:3060.634\n",
      "Ep:170, loss:0.00000, loss_test:0.07014, lr:7.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.005, tt:3078.805\n",
      "Ep:171, loss:0.00000, loss_test:0.07003, lr:7.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.008, tt:3097.452\n",
      "Ep:172, loss:0.00000, loss_test:0.06998, lr:7.55e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.015, tt:3116.548\n",
      "Ep:173, loss:0.00000, loss_test:0.06998, lr:7.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.015, tt:3134.539\n",
      "Ep:174, loss:0.00000, loss_test:0.07004, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.021, tt:3153.623\n",
      "Ep:175, loss:0.00000, loss_test:0.07000, lr:7.32e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.022, tt:3171.810\n",
      "Ep:176, loss:0.00000, loss_test:0.06995, lr:7.25e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.020, tt:3189.601\n",
      "Ep:177, loss:0.00000, loss_test:0.07002, lr:7.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.022, tt:3207.888\n",
      "Ep:178, loss:0.00000, loss_test:0.07010, lr:7.11e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.020, tt:3225.647\n",
      "Ep:179, loss:0.00000, loss_test:0.07009, lr:7.03e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.032, tt:3245.822\n",
      "Ep:180, loss:0.00000, loss_test:0.06999, lr:6.96e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.038, tt:3264.936\n",
      "Ep:181, loss:0.00000, loss_test:0.06991, lr:6.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.042, tt:3283.560\n",
      "Ep:182, loss:0.00000, loss_test:0.06989, lr:6.83e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.048, tt:3302.695\n",
      "Ep:183, loss:0.00000, loss_test:0.06988, lr:6.76e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.056, tt:3322.315\n",
      "Ep:184, loss:0.00000, loss_test:0.06984, lr:6.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.057, tt:3340.558\n",
      "Ep:185, loss:0.00000, loss_test:0.06977, lr:6.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.061, tt:3359.371\n",
      "Ep:186, loss:0.00000, loss_test:0.06969, lr:6.56e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.063, tt:3377.839\n",
      "Ep:187, loss:0.00000, loss_test:0.06960, lr:6.49e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.067, tt:3396.578\n",
      "Ep:188, loss:0.00000, loss_test:0.06950, lr:6.43e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.071, tt:3415.502\n",
      "Ep:189, loss:0.00000, loss_test:0.06945, lr:6.36e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.079, tt:3434.922\n",
      "Ep:190, loss:0.00000, loss_test:0.06942, lr:6.30e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.082, tt:3453.621\n",
      "Ep:191, loss:0.00000, loss_test:0.06946, lr:6.24e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.088, tt:3472.965\n",
      "Ep:192, loss:0.00000, loss_test:0.06949, lr:6.17e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.091, tt:3491.618\n",
      "Ep:193, loss:0.00000, loss_test:0.06952, lr:6.11e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.099, tt:3511.137\n",
      "Ep:194, loss:0.00000, loss_test:0.06953, lr:6.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.105, tt:3530.405\n",
      "Ep:195, loss:0.00000, loss_test:0.06945, lr:5.99e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.107, tt:3548.873\n",
      "Ep:196, loss:0.00000, loss_test:0.06937, lr:5.93e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.109, tt:3567.388\n",
      "Ep:197, loss:0.00000, loss_test:0.06936, lr:5.87e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.114, tt:3586.487\n",
      "Ep:198, loss:0.00000, loss_test:0.06939, lr:5.81e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.119, tt:3605.762\n",
      "Ep:199, loss:0.00000, loss_test:0.06940, lr:5.75e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.123, tt:3624.651\n",
      "Ep:200, loss:0.00000, loss_test:0.06941, lr:5.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.124, tt:3642.912\n",
      "Ep:201, loss:0.00000, loss_test:0.06945, lr:5.64e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.124, tt:3660.967\n",
      "Ep:202, loss:0.00000, loss_test:0.06953, lr:5.58e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.127, tt:3679.786\n",
      "Ep:203, loss:0.00000, loss_test:0.06958, lr:5.53e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.132, tt:3698.845\n",
      "Ep:204, loss:0.00000, loss_test:0.06950, lr:5.47e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.133, tt:3717.185\n",
      "Ep:205, loss:0.00000, loss_test:0.06940, lr:5.42e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.139, tt:3736.616\n",
      "Ep:206, loss:0.00000, loss_test:0.06940, lr:5.36e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.141, tt:3755.227\n",
      "Ep:207, loss:0.00000, loss_test:0.06947, lr:5.31e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.143, tt:3773.679\n",
      "Ep:208, loss:0.00000, loss_test:0.06947, lr:5.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.146, tt:3792.562\n",
      "Ep:209, loss:0.00000, loss_test:0.06940, lr:5.20e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.153, tt:3812.204\n",
      "Ep:210, loss:0.00000, loss_test:0.06936, lr:5.15e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.161, tt:3831.984\n",
      "Ep:211, loss:0.00000, loss_test:0.06939, lr:5.10e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.167, tt:3851.379\n",
      "Ep:212, loss:0.00000, loss_test:0.06945, lr:5.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.174, tt:3870.955\n",
      "Ep:213, loss:0.00000, loss_test:0.06946, lr:5.00e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.179, tt:3890.235\n",
      "Ep:214, loss:0.00000, loss_test:0.06942, lr:4.95e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.181, tt:3908.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:215, loss:0.00000, loss_test:0.06939, lr:4.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.188, tt:3928.553\n",
      "Ep:216, loss:0.00000, loss_test:0.06941, lr:4.85e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.194, tt:3948.084\n",
      "Ep:217, loss:0.00000, loss_test:0.06940, lr:4.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.201, tt:3967.836\n",
      "Ep:218, loss:0.00000, loss_test:0.06936, lr:4.75e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.207, tt:3987.351\n",
      "Ep:219, loss:0.00000, loss_test:0.06933, lr:4.71e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.212, tt:4006.602\n",
      "Ep:220, loss:0.00000, loss_test:0.06936, lr:4.66e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.215, tt:4025.422\n",
      "Ep:221, loss:0.00000, loss_test:0.06938, lr:4.61e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.220, tt:4044.789\n",
      "Ep:222, loss:0.00000, loss_test:0.06938, lr:4.57e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.230, tt:4065.249\n",
      "Ep:223, loss:0.00000, loss_test:0.06934, lr:4.52e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.239, tt:4085.592\n",
      "Ep:224, loss:0.00000, loss_test:0.06929, lr:4.48e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.242, tt:4104.467\n",
      "Ep:225, loss:0.00000, loss_test:0.06927, lr:4.43e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.251, tt:4124.670\n",
      "Ep:226, loss:0.00000, loss_test:0.06929, lr:4.39e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.260, tt:4144.949\n",
      "Ep:227, loss:0.00000, loss_test:0.06928, lr:4.34e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.260, tt:4163.385\n",
      "Ep:228, loss:0.00000, loss_test:0.06927, lr:4.30e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.265, tt:4182.708\n",
      "Ep:229, loss:0.00000, loss_test:0.06926, lr:4.26e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.263, tt:4200.388\n",
      "Ep:230, loss:0.00000, loss_test:0.06929, lr:4.21e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.264, tt:4218.973\n",
      "Ep:231, loss:0.00000, loss_test:0.06930, lr:4.17e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.265, tt:4237.496\n",
      "Ep:232, loss:0.00000, loss_test:0.06928, lr:4.13e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.267, tt:4256.207\n",
      "Ep:233, loss:0.00000, loss_test:0.06928, lr:4.09e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.272, tt:4275.668\n",
      "Ep:234, loss:0.00000, loss_test:0.06928, lr:4.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.275, tt:4294.731\n",
      "Ep:235, loss:0.00000, loss_test:0.06927, lr:4.01e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.284, tt:4315.043\n",
      "Ep:236, loss:0.00000, loss_test:0.06927, lr:3.97e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.290, tt:4334.718\n",
      "Ep:237, loss:0.00000, loss_test:0.06926, lr:3.93e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.296, tt:4354.565\n",
      "Ep:238, loss:0.00000, loss_test:0.06924, lr:3.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.300, tt:4373.592\n",
      "Ep:239, loss:0.00000, loss_test:0.06922, lr:3.85e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.305, tt:4393.088\n",
      "Ep:240, loss:0.00000, loss_test:0.06920, lr:3.81e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.304, tt:4411.366\n",
      "Ep:241, loss:0.00000, loss_test:0.06920, lr:3.77e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.308, tt:4430.426\n",
      "Ep:242, loss:0.00000, loss_test:0.06922, lr:3.73e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.310, tt:4449.293\n",
      "Ep:243, loss:0.00000, loss_test:0.06925, lr:3.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.313, tt:4468.473\n",
      "Ep:244, loss:0.00000, loss_test:0.06926, lr:3.66e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.318, tt:4487.852\n",
      "Ep:245, loss:0.00000, loss_test:0.06924, lr:3.62e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.315, tt:4505.560\n",
      "Ep:246, loss:0.00000, loss_test:0.06921, lr:3.59e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.314, tt:4523.482\n",
      "Ep:247, loss:0.00000, loss_test:0.06918, lr:3.55e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.313, tt:4541.745\n",
      "Ep:248, loss:0.00000, loss_test:0.06919, lr:3.52e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.311, tt:4559.419\n",
      "Ep:249, loss:0.00000, loss_test:0.06917, lr:3.48e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.310, tt:4577.450\n",
      "Ep:250, loss:0.00000, loss_test:0.06913, lr:3.45e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.313, tt:4596.522\n",
      "Ep:251, loss:0.00000, loss_test:0.06909, lr:3.41e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.313, tt:4614.973\n",
      "Ep:252, loss:0.00000, loss_test:0.06908, lr:3.38e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.315, tt:4633.600\n",
      "Ep:253, loss:0.00000, loss_test:0.06909, lr:3.34e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.313, tt:4651.520\n",
      "Ep:254, loss:0.00000, loss_test:0.06910, lr:3.31e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.314, tt:4669.963\n",
      "Ep:255, loss:0.00000, loss_test:0.06909, lr:3.28e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.320, tt:4689.889\n",
      "Ep:256, loss:0.00000, loss_test:0.06907, lr:3.24e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.324, tt:4709.172\n",
      "Ep:257, loss:0.00000, loss_test:0.06906, lr:3.21e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.324, tt:4727.684\n",
      "Ep:258, loss:0.00000, loss_test:0.06907, lr:3.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.327, tt:4746.819\n",
      "Ep:259, loss:0.00000, loss_test:0.06908, lr:3.15e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.330, tt:4765.809\n",
      "Ep:260, loss:0.00000, loss_test:0.06908, lr:3.12e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.337, tt:4785.909\n",
      "Ep:261, loss:0.00000, loss_test:0.06906, lr:3.09e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.339, tt:4804.925\n",
      "Ep:262, loss:0.00000, loss_test:0.06905, lr:3.05e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.342, tt:4824.006\n",
      "Ep:263, loss:0.00000, loss_test:0.06904, lr:3.02e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.347, tt:4843.725\n",
      "Ep:264, loss:0.00000, loss_test:0.06904, lr:2.99e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.353, tt:4863.588\n",
      "Ep:265, loss:0.00000, loss_test:0.06906, lr:2.96e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.360, tt:4883.767\n",
      "Ep:266, loss:0.00000, loss_test:0.06907, lr:2.93e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.364, tt:4903.102\n",
      "Ep:267, loss:0.00000, loss_test:0.06908, lr:2.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.364, tt:4921.657\n",
      "Ep:268, loss:0.00000, loss_test:0.06907, lr:2.88e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.368, tt:4940.936\n",
      "Ep:269, loss:0.00000, loss_test:0.06905, lr:2.85e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.374, tt:4960.923\n",
      "Ep:270, loss:0.00000, loss_test:0.06904, lr:2.82e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.376, tt:4979.983\n",
      "Ep:271, loss:0.00000, loss_test:0.06903, lr:2.79e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.381, tt:4999.726\n",
      "Ep:272, loss:0.00000, loss_test:0.06904, lr:2.76e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.384, tt:5018.789\n",
      "Ep:273, loss:0.00000, loss_test:0.06907, lr:2.73e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.387, tt:5037.956\n",
      "Ep:274, loss:0.00000, loss_test:0.06909, lr:2.71e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.393, tt:5058.088\n",
      "Ep:275, loss:0.00000, loss_test:0.06909, lr:2.68e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.399, tt:5078.151\n",
      "Ep:276, loss:0.00000, loss_test:0.06907, lr:2.65e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.397, tt:5095.891\n",
      "Ep:277, loss:0.00000, loss_test:0.06908, lr:2.63e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.397, tt:5114.254\n",
      "Ep:278, loss:0.00000, loss_test:0.06911, lr:2.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.399, tt:5133.319\n",
      "Ep:279, loss:0.00000, loss_test:0.06911, lr:2.57e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.392, tt:5149.863\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"5-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=40000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,280,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 15\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 512: \n",
      "Ep:0, loss:0.00112, loss_test:0.14443, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:20.066, tt:20.066\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00111, loss_test:0.14352, lr:4.00e-03, fs:0.67119 (r=1.000,p=0.505),  time:21.015, tt:42.030\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00109, loss_test:0.14190, lr:4.00e-03, fs:0.67119 (r=1.000,p=0.505),  time:21.461, tt:64.384\n",
      "Ep:3, loss:0.00106, loss_test:0.13920, lr:4.00e-03, fs:0.67128 (r=0.980,p=0.511),  time:21.461, tt:85.842\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00102, loss_test:0.13515, lr:4.00e-03, fs:0.64151 (r=0.859,p=0.512),  time:21.570, tt:107.852\n",
      "Ep:5, loss:0.00097, loss_test:0.13113, lr:4.00e-03, fs:0.60714 (r=0.687,p=0.544),  time:21.633, tt:129.798\n",
      "Ep:6, loss:0.00093, loss_test:0.12887, lr:4.00e-03, fs:0.61244 (r=0.646,p=0.582),  time:21.628, tt:151.395\n",
      "Ep:7, loss:0.00090, loss_test:0.12718, lr:4.00e-03, fs:0.60697 (r=0.616,p=0.598),  time:21.693, tt:173.545\n",
      "Ep:8, loss:0.00087, loss_test:0.12579, lr:4.00e-03, fs:0.61386 (r=0.626,p=0.602),  time:21.761, tt:195.845\n",
      "Ep:9, loss:0.00084, loss_test:0.12503, lr:4.00e-03, fs:0.62626 (r=0.626,p=0.626),  time:21.828, tt:218.283\n",
      "Ep:10, loss:0.00081, loss_test:0.12491, lr:4.00e-03, fs:0.57609 (r=0.535,p=0.624),  time:21.900, tt:240.898\n",
      "Ep:11, loss:0.00079, loss_test:0.12360, lr:4.00e-03, fs:0.58242 (r=0.535,p=0.639),  time:21.951, tt:263.411\n",
      "Ep:12, loss:0.00076, loss_test:0.12182, lr:4.00e-03, fs:0.59783 (r=0.556,p=0.647),  time:21.984, tt:285.793\n",
      "Ep:13, loss:0.00074, loss_test:0.12002, lr:4.00e-03, fs:0.60674 (r=0.545,p=0.684),  time:22.077, tt:309.073\n",
      "Ep:14, loss:0.00072, loss_test:0.11755, lr:4.00e-03, fs:0.60227 (r=0.535,p=0.688),  time:22.174, tt:332.608\n",
      "Ep:15, loss:0.00070, loss_test:0.11673, lr:3.96e-03, fs:0.60227 (r=0.535,p=0.688),  time:22.188, tt:355.013\n",
      "Ep:16, loss:0.00068, loss_test:0.11653, lr:3.92e-03, fs:0.61798 (r=0.556,p=0.696),  time:22.191, tt:377.245\n",
      "Ep:17, loss:0.00066, loss_test:0.11639, lr:3.88e-03, fs:0.60920 (r=0.535,p=0.707),  time:22.203, tt:399.647\n",
      "Ep:18, loss:0.00065, loss_test:0.11545, lr:3.84e-03, fs:0.59887 (r=0.535,p=0.679),  time:22.252, tt:422.784\n",
      "Ep:19, loss:0.00063, loss_test:0.11522, lr:3.80e-03, fs:0.62570 (r=0.566,p=0.700),  time:22.254, tt:445.078\n",
      "Ep:20, loss:0.00062, loss_test:0.11570, lr:3.77e-03, fs:0.65556 (r=0.596,p=0.728),  time:22.244, tt:467.129\n",
      "Ep:21, loss:0.00061, loss_test:0.11504, lr:3.73e-03, fs:0.62222 (r=0.566,p=0.691),  time:22.245, tt:489.384\n",
      "Ep:22, loss:0.00060, loss_test:0.11464, lr:3.69e-03, fs:0.65193 (r=0.596,p=0.720),  time:22.271, tt:512.238\n",
      "Ep:23, loss:0.00058, loss_test:0.11365, lr:3.65e-03, fs:0.65934 (r=0.606,p=0.723),  time:22.261, tt:534.270\n",
      "Ep:24, loss:0.00057, loss_test:0.11385, lr:3.62e-03, fs:0.66292 (r=0.596,p=0.747),  time:22.274, tt:556.839\n",
      "Ep:25, loss:0.00056, loss_test:0.11268, lr:3.58e-03, fs:0.67403 (r=0.616,p=0.744),  time:22.319, tt:580.304\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00055, loss_test:0.11322, lr:3.58e-03, fs:0.66292 (r=0.596,p=0.747),  time:22.321, tt:602.656\n",
      "Ep:27, loss:0.00054, loss_test:0.11220, lr:3.58e-03, fs:0.68132 (r=0.626,p=0.747),  time:22.322, tt:625.014\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00054, loss_test:0.11298, lr:3.58e-03, fs:0.67045 (r=0.596,p=0.766),  time:22.348, tt:648.101\n",
      "Ep:29, loss:0.00053, loss_test:0.11197, lr:3.58e-03, fs:0.68539 (r=0.616,p=0.772),  time:22.363, tt:670.895\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00052, loss_test:0.11190, lr:3.58e-03, fs:0.69274 (r=0.626,p=0.775),  time:22.351, tt:692.868\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00051, loss_test:0.11207, lr:3.58e-03, fs:0.68539 (r=0.616,p=0.772),  time:22.389, tt:716.447\n",
      "Ep:32, loss:0.00050, loss_test:0.11170, lr:3.58e-03, fs:0.69274 (r=0.626,p=0.775),  time:22.421, tt:739.889\n",
      "Ep:33, loss:0.00049, loss_test:0.11182, lr:3.58e-03, fs:0.68539 (r=0.616,p=0.772),  time:22.421, tt:762.305\n",
      "Ep:34, loss:0.00048, loss_test:0.11114, lr:3.58e-03, fs:0.69274 (r=0.626,p=0.775),  time:22.412, tt:784.434\n",
      "Ep:35, loss:0.00047, loss_test:0.11179, lr:3.58e-03, fs:0.68539 (r=0.616,p=0.772),  time:22.434, tt:807.636\n",
      "Ep:36, loss:0.00046, loss_test:0.11126, lr:3.58e-03, fs:0.69274 (r=0.626,p=0.775),  time:22.439, tt:830.248\n",
      "Ep:37, loss:0.00046, loss_test:0.11152, lr:3.58e-03, fs:0.68927 (r=0.616,p=0.782),  time:22.418, tt:851.871\n",
      "Ep:38, loss:0.00045, loss_test:0.11111, lr:3.58e-03, fs:0.70056 (r=0.626,p=0.795),  time:22.417, tt:874.244\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00044, loss_test:0.11086, lr:3.58e-03, fs:0.69663 (r=0.626,p=0.785),  time:22.431, tt:897.232\n",
      "Ep:40, loss:0.00043, loss_test:0.11178, lr:3.58e-03, fs:0.70857 (r=0.626,p=0.816),  time:22.437, tt:919.905\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00042, loss_test:0.11102, lr:3.58e-03, fs:0.70455 (r=0.626,p=0.805),  time:22.448, tt:942.815\n",
      "Ep:42, loss:0.00042, loss_test:0.11112, lr:3.58e-03, fs:0.71264 (r=0.626,p=0.827),  time:22.458, tt:965.674\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00041, loss_test:0.11045, lr:3.58e-03, fs:0.70455 (r=0.626,p=0.805),  time:22.476, tt:988.922\n",
      "Ep:44, loss:0.00040, loss_test:0.11045, lr:3.58e-03, fs:0.70787 (r=0.636,p=0.797),  time:22.475, tt:1011.377\n",
      "Ep:45, loss:0.00039, loss_test:0.11051, lr:3.58e-03, fs:0.70857 (r=0.626,p=0.816),  time:22.485, tt:1034.303\n",
      "Ep:46, loss:0.00038, loss_test:0.11024, lr:3.58e-03, fs:0.71264 (r=0.626,p=0.827),  time:22.495, tt:1057.272\n",
      "Ep:47, loss:0.00038, loss_test:0.10996, lr:3.58e-03, fs:0.70455 (r=0.626,p=0.805),  time:22.503, tt:1080.148\n",
      "Ep:48, loss:0.00037, loss_test:0.11039, lr:3.58e-03, fs:0.70175 (r=0.606,p=0.833),  time:22.502, tt:1102.580\n",
      "Ep:49, loss:0.00036, loss_test:0.10932, lr:3.58e-03, fs:0.71591 (r=0.636,p=0.818),  time:22.507, tt:1125.337\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00035, loss_test:0.11077, lr:3.58e-03, fs:0.69048 (r=0.586,p=0.841),  time:22.524, tt:1148.709\n",
      "Ep:51, loss:0.00034, loss_test:0.10886, lr:3.58e-03, fs:0.71111 (r=0.646,p=0.790),  time:22.529, tt:1171.503\n",
      "Ep:52, loss:0.00034, loss_test:0.11018, lr:3.58e-03, fs:0.67857 (r=0.576,p=0.826),  time:22.540, tt:1194.599\n",
      "Ep:53, loss:0.00033, loss_test:0.10905, lr:3.58e-03, fs:0.69412 (r=0.596,p=0.831),  time:22.534, tt:1216.830\n",
      "Ep:54, loss:0.00032, loss_test:0.10889, lr:3.58e-03, fs:0.68235 (r=0.586,p=0.817),  time:22.524, tt:1238.821\n",
      "Ep:55, loss:0.00032, loss_test:0.10883, lr:3.58e-03, fs:0.67456 (r=0.576,p=0.814),  time:22.542, tt:1262.329\n",
      "Ep:56, loss:0.00031, loss_test:0.11015, lr:3.58e-03, fs:0.67066 (r=0.566,p=0.824),  time:22.535, tt:1284.489\n",
      "Ep:57, loss:0.00030, loss_test:0.10802, lr:3.58e-03, fs:0.68208 (r=0.596,p=0.797),  time:22.536, tt:1307.099\n",
      "Ep:58, loss:0.00030, loss_test:0.10958, lr:3.58e-03, fs:0.66667 (r=0.566,p=0.812),  time:22.537, tt:1329.694\n",
      "Ep:59, loss:0.00029, loss_test:0.10957, lr:3.58e-03, fs:0.66272 (r=0.566,p=0.800),  time:22.543, tt:1352.584\n",
      "Ep:60, loss:0.00028, loss_test:0.10854, lr:3.58e-03, fs:0.67059 (r=0.576,p=0.803),  time:22.538, tt:1374.829\n",
      "Ep:61, loss:0.00028, loss_test:0.11057, lr:3.55e-03, fs:0.63354 (r=0.515,p=0.823),  time:22.535, tt:1397.157\n",
      "Ep:62, loss:0.00027, loss_test:0.10815, lr:3.51e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.533, tt:1419.601\n",
      "Ep:63, loss:0.00027, loss_test:0.10926, lr:3.47e-03, fs:0.65031 (r=0.535,p=0.828),  time:22.548, tt:1443.045\n",
      "Ep:64, loss:0.00026, loss_test:0.11078, lr:3.44e-03, fs:0.62500 (r=0.505,p=0.820),  time:22.555, tt:1466.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00025, loss_test:0.10742, lr:3.41e-03, fs:0.67059 (r=0.576,p=0.803),  time:22.549, tt:1488.215\n",
      "Ep:66, loss:0.00025, loss_test:0.10918, lr:3.37e-03, fs:0.63855 (r=0.535,p=0.791),  time:22.551, tt:1510.902\n",
      "Ep:67, loss:0.00024, loss_test:0.10948, lr:3.34e-03, fs:0.63804 (r=0.525,p=0.812),  time:22.545, tt:1533.055\n",
      "Ep:68, loss:0.00024, loss_test:0.10836, lr:3.30e-03, fs:0.65060 (r=0.545,p=0.806),  time:22.538, tt:1555.110\n",
      "Ep:69, loss:0.00024, loss_test:0.10813, lr:3.27e-03, fs:0.65882 (r=0.566,p=0.789),  time:22.542, tt:1577.918\n",
      "Ep:70, loss:0.00023, loss_test:0.10951, lr:3.24e-03, fs:0.63354 (r=0.515,p=0.823),  time:22.537, tt:1600.113\n",
      "Ep:71, loss:0.00023, loss_test:0.10878, lr:3.21e-03, fs:0.64242 (r=0.535,p=0.803),  time:22.548, tt:1623.464\n",
      "Ep:72, loss:0.00022, loss_test:0.10748, lr:3.17e-03, fs:0.64671 (r=0.545,p=0.794),  time:22.553, tt:1646.383\n",
      "Ep:73, loss:0.00022, loss_test:0.11034, lr:3.14e-03, fs:0.62893 (r=0.505,p=0.833),  time:22.558, tt:1669.275\n",
      "Ep:74, loss:0.00022, loss_test:0.10827, lr:3.11e-03, fs:0.63855 (r=0.535,p=0.791),  time:22.568, tt:1692.568\n",
      "Ep:75, loss:0.00021, loss_test:0.10941, lr:3.08e-03, fs:0.64242 (r=0.535,p=0.803),  time:22.565, tt:1714.939\n",
      "Ep:76, loss:0.00021, loss_test:0.10789, lr:3.05e-03, fs:0.64671 (r=0.545,p=0.794),  time:22.567, tt:1737.686\n",
      "Ep:77, loss:0.00020, loss_test:0.10957, lr:3.02e-03, fs:0.63415 (r=0.525,p=0.800),  time:22.567, tt:1760.226\n",
      "Ep:78, loss:0.00020, loss_test:0.10743, lr:2.99e-03, fs:0.64286 (r=0.545,p=0.783),  time:22.561, tt:1782.358\n",
      "Ep:79, loss:0.00020, loss_test:0.10862, lr:2.96e-03, fs:0.63415 (r=0.525,p=0.800),  time:22.568, tt:1805.405\n",
      "Ep:80, loss:0.00019, loss_test:0.10800, lr:2.93e-03, fs:0.65060 (r=0.545,p=0.806),  time:22.569, tt:1828.084\n",
      "Ep:81, loss:0.00019, loss_test:0.10811, lr:2.90e-03, fs:0.65060 (r=0.545,p=0.806),  time:22.565, tt:1850.364\n",
      "Ep:82, loss:0.00019, loss_test:0.10898, lr:2.87e-03, fs:0.63804 (r=0.525,p=0.812),  time:22.568, tt:1873.128\n",
      "Ep:83, loss:0.00018, loss_test:0.10722, lr:2.84e-03, fs:0.64671 (r=0.545,p=0.794),  time:22.569, tt:1895.812\n",
      "Ep:84, loss:0.00018, loss_test:0.10988, lr:2.81e-03, fs:0.64596 (r=0.525,p=0.839),  time:22.576, tt:1918.936\n",
      "Ep:85, loss:0.00018, loss_test:0.10683, lr:2.79e-03, fs:0.67059 (r=0.576,p=0.803),  time:22.571, tt:1941.107\n",
      "Ep:86, loss:0.00018, loss_test:0.11139, lr:2.76e-03, fs:0.64151 (r=0.515,p=0.850),  time:22.577, tt:1964.197\n",
      "Ep:87, loss:0.00017, loss_test:0.10679, lr:2.73e-03, fs:0.66272 (r=0.566,p=0.800),  time:22.581, tt:1987.136\n",
      "Ep:88, loss:0.00017, loss_test:0.11231, lr:2.70e-03, fs:0.64151 (r=0.515,p=0.850),  time:22.581, tt:2009.721\n",
      "Ep:89, loss:0.00017, loss_test:0.10637, lr:2.68e-03, fs:0.67836 (r=0.586,p=0.806),  time:22.579, tt:2032.114\n",
      "Ep:90, loss:0.00017, loss_test:0.11224, lr:2.65e-03, fs:0.64151 (r=0.515,p=0.850),  time:22.594, tt:2056.067\n",
      "Ep:91, loss:0.00017, loss_test:0.10833, lr:2.62e-03, fs:0.67066 (r=0.566,p=0.824),  time:22.591, tt:2078.363\n",
      "Ep:92, loss:0.00016, loss_test:0.11023, lr:2.60e-03, fs:0.64596 (r=0.525,p=0.839),  time:22.594, tt:2101.199\n",
      "Ep:93, loss:0.00016, loss_test:0.10853, lr:2.57e-03, fs:0.65455 (r=0.545,p=0.818),  time:22.604, tt:2124.782\n",
      "Ep:94, loss:0.00016, loss_test:0.11051, lr:2.54e-03, fs:0.64596 (r=0.525,p=0.839),  time:22.606, tt:2147.614\n",
      "Ep:95, loss:0.00015, loss_test:0.10819, lr:2.52e-03, fs:0.68639 (r=0.586,p=0.829),  time:22.614, tt:2170.986\n",
      "Ep:96, loss:0.00015, loss_test:0.11041, lr:2.49e-03, fs:0.64596 (r=0.525,p=0.839),  time:22.613, tt:2193.455\n",
      "Ep:97, loss:0.00015, loss_test:0.11035, lr:2.47e-03, fs:0.65432 (r=0.535,p=0.841),  time:22.613, tt:2216.086\n",
      "Ep:98, loss:0.00015, loss_test:0.10933, lr:2.44e-03, fs:0.66667 (r=0.556,p=0.833),  time:22.616, tt:2239.018\n",
      "Ep:99, loss:0.00015, loss_test:0.11104, lr:2.42e-03, fs:0.64596 (r=0.525,p=0.839),  time:22.592, tt:2259.196\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"16-16\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=512 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 15\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14239, lr:8.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:10.682, tt:10.682\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14118, lr:8.00e-03, fs:0.66892 (r=1.000,p=0.503),  time:10.775, tt:21.551\n",
      "Ep:2, loss:0.00027, loss_test:0.13909, lr:8.00e-03, fs:0.67119 (r=1.000,p=0.505),  time:10.805, tt:32.415\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13580, lr:8.00e-03, fs:0.66897 (r=0.980,p=0.508),  time:10.752, tt:43.009\n",
      "Ep:4, loss:0.00025, loss_test:0.13125, lr:8.00e-03, fs:0.68914 (r=0.929,p=0.548),  time:10.864, tt:54.321\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12635, lr:8.00e-03, fs:0.62832 (r=0.717,p=0.559),  time:10.890, tt:65.342\n",
      "Ep:6, loss:0.00023, loss_test:0.12574, lr:8.00e-03, fs:0.58947 (r=0.566,p=0.615),  time:10.897, tt:76.282\n",
      "Ep:7, loss:0.00022, loss_test:0.12739, lr:8.00e-03, fs:0.56140 (r=0.485,p=0.667),  time:10.895, tt:87.157\n",
      "Ep:8, loss:0.00022, loss_test:0.12514, lr:8.00e-03, fs:0.56044 (r=0.515,p=0.614),  time:10.870, tt:97.827\n",
      "Ep:9, loss:0.00021, loss_test:0.12241, lr:8.00e-03, fs:0.62745 (r=0.646,p=0.610),  time:10.935, tt:109.348\n",
      "Ep:10, loss:0.00021, loss_test:0.12066, lr:8.00e-03, fs:0.64762 (r=0.687,p=0.613),  time:10.936, tt:120.295\n",
      "Ep:11, loss:0.00020, loss_test:0.12011, lr:8.00e-03, fs:0.62626 (r=0.626,p=0.626),  time:10.982, tt:131.784\n",
      "Ep:12, loss:0.00020, loss_test:0.12102, lr:8.00e-03, fs:0.60773 (r=0.556,p=0.671),  time:11.039, tt:143.512\n",
      "Ep:13, loss:0.00019, loss_test:0.12010, lr:8.00e-03, fs:0.60109 (r=0.556,p=0.655),  time:11.249, tt:157.483\n",
      "Ep:14, loss:0.00019, loss_test:0.11875, lr:8.00e-03, fs:0.59574 (r=0.566,p=0.629),  time:11.567, tt:173.506\n",
      "Ep:15, loss:0.00018, loss_test:0.11800, lr:8.00e-03, fs:0.63265 (r=0.626,p=0.639),  time:12.249, tt:195.986\n",
      "Ep:16, loss:0.00018, loss_test:0.11811, lr:7.92e-03, fs:0.60317 (r=0.576,p=0.633),  time:12.900, tt:219.306\n",
      "Ep:17, loss:0.00018, loss_test:0.11799, lr:7.84e-03, fs:0.63492 (r=0.606,p=0.667),  time:13.511, tt:243.197\n",
      "Ep:18, loss:0.00017, loss_test:0.11769, lr:7.76e-03, fs:0.65241 (r=0.616,p=0.693),  time:13.988, tt:265.780\n",
      "Ep:19, loss:0.00017, loss_test:0.11697, lr:7.68e-03, fs:0.69744 (r=0.687,p=0.708),  time:14.389, tt:287.783\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.11665, lr:7.68e-03, fs:0.70769 (r=0.697,p=0.719),  time:14.841, tt:311.669\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.11633, lr:7.68e-03, fs:0.71503 (r=0.697,p=0.734),  time:15.284, tt:336.255\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.11591, lr:7.68e-03, fs:0.71204 (r=0.687,p=0.739),  time:15.777, tt:362.877\n",
      "Ep:23, loss:0.00015, loss_test:0.11546, lr:7.68e-03, fs:0.70833 (r=0.687,p=0.731),  time:16.332, tt:391.961\n",
      "Ep:24, loss:0.00015, loss_test:0.11532, lr:7.68e-03, fs:0.70213 (r=0.667,p=0.742),  time:16.762, tt:419.041\n",
      "Ep:25, loss:0.00015, loss_test:0.11506, lr:7.68e-03, fs:0.70213 (r=0.667,p=0.742),  time:17.256, tt:448.664\n",
      "Ep:26, loss:0.00015, loss_test:0.11481, lr:7.68e-03, fs:0.70213 (r=0.667,p=0.742),  time:17.701, tt:477.940\n",
      "Ep:27, loss:0.00014, loss_test:0.11427, lr:7.68e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.081, tt:506.262\n",
      "Ep:28, loss:0.00014, loss_test:0.11388, lr:7.68e-03, fs:0.70213 (r=0.667,p=0.742),  time:18.504, tt:536.604\n",
      "Ep:29, loss:0.00014, loss_test:0.11383, lr:7.68e-03, fs:0.70968 (r=0.667,p=0.759),  time:18.821, tt:564.620\n",
      "Ep:30, loss:0.00014, loss_test:0.11364, lr:7.68e-03, fs:0.70588 (r=0.667,p=0.750),  time:19.096, tt:591.978\n",
      "Ep:31, loss:0.00013, loss_test:0.11375, lr:7.68e-03, fs:0.70652 (r=0.657,p=0.765),  time:19.411, tt:621.161\n",
      "Ep:32, loss:0.00013, loss_test:0.11323, lr:7.68e-03, fs:0.71038 (r=0.657,p=0.774),  time:19.759, tt:652.052\n",
      "Ep:33, loss:0.00013, loss_test:0.11282, lr:7.61e-03, fs:0.70718 (r=0.646,p=0.780),  time:20.044, tt:681.506\n",
      "Ep:34, loss:0.00013, loss_test:0.11301, lr:7.53e-03, fs:0.68927 (r=0.616,p=0.782),  time:20.258, tt:709.014\n",
      "Ep:35, loss:0.00012, loss_test:0.11323, lr:7.46e-03, fs:0.71111 (r=0.646,p=0.790),  time:20.452, tt:736.258\n",
      "Ep:36, loss:0.00012, loss_test:0.11310, lr:7.38e-03, fs:0.71111 (r=0.646,p=0.790),  time:20.686, tt:765.398\n",
      "Ep:37, loss:0.00012, loss_test:0.11358, lr:7.31e-03, fs:0.65476 (r=0.556,p=0.797),  time:20.877, tt:793.341\n",
      "Ep:38, loss:0.00012, loss_test:0.11256, lr:7.24e-03, fs:0.69714 (r=0.616,p=0.803),  time:21.087, tt:822.412\n",
      "Ep:39, loss:0.00011, loss_test:0.11287, lr:7.16e-03, fs:0.68966 (r=0.606,p=0.800),  time:21.290, tt:851.610\n",
      "Ep:40, loss:0.00011, loss_test:0.11291, lr:7.09e-03, fs:0.67442 (r=0.586,p=0.795),  time:21.451, tt:879.490\n",
      "Ep:41, loss:0.00011, loss_test:0.11166, lr:7.02e-03, fs:0.68966 (r=0.606,p=0.800),  time:21.606, tt:907.447\n",
      "Ep:42, loss:0.00011, loss_test:0.11205, lr:6.95e-03, fs:0.68208 (r=0.596,p=0.797),  time:21.755, tt:935.471\n",
      "Ep:43, loss:0.00011, loss_test:0.11200, lr:6.88e-03, fs:0.68208 (r=0.596,p=0.797),  time:21.950, tt:965.811\n",
      "Ep:44, loss:0.00010, loss_test:0.11125, lr:6.81e-03, fs:0.68208 (r=0.596,p=0.797),  time:22.127, tt:995.726\n",
      "Ep:45, loss:0.00010, loss_test:0.11152, lr:6.74e-03, fs:0.67059 (r=0.576,p=0.803),  time:22.283, tt:1025.038\n",
      "Ep:46, loss:0.00010, loss_test:0.11132, lr:6.68e-03, fs:0.67059 (r=0.576,p=0.803),  time:22.411, tt:1053.321\n",
      "Ep:47, loss:0.00010, loss_test:0.11090, lr:6.61e-03, fs:0.67456 (r=0.576,p=0.814),  time:22.557, tt:1082.733\n",
      "Ep:48, loss:0.00010, loss_test:0.11143, lr:6.54e-03, fs:0.65868 (r=0.556,p=0.809),  time:22.719, tt:1113.252\n",
      "Ep:49, loss:0.00009, loss_test:0.11120, lr:6.48e-03, fs:0.65455 (r=0.545,p=0.818),  time:22.842, tt:1142.092\n",
      "Ep:50, loss:0.00009, loss_test:0.11022, lr:6.41e-03, fs:0.66272 (r=0.566,p=0.800),  time:22.947, tt:1170.292\n",
      "Ep:51, loss:0.00009, loss_test:0.11187, lr:6.35e-03, fs:0.64634 (r=0.535,p=0.815),  time:23.034, tt:1197.743\n",
      "Ep:52, loss:0.00009, loss_test:0.11144, lr:6.29e-03, fs:0.65455 (r=0.545,p=0.818),  time:23.153, tt:1227.086\n",
      "Ep:53, loss:0.00009, loss_test:0.11058, lr:6.22e-03, fs:0.65455 (r=0.545,p=0.818),  time:23.255, tt:1255.762\n",
      "Ep:54, loss:0.00009, loss_test:0.11085, lr:6.16e-03, fs:0.63804 (r=0.525,p=0.812),  time:23.357, tt:1284.646\n",
      "Ep:55, loss:0.00008, loss_test:0.11069, lr:6.10e-03, fs:0.65455 (r=0.545,p=0.818),  time:23.460, tt:1313.761\n",
      "Ep:56, loss:0.00008, loss_test:0.11027, lr:6.04e-03, fs:0.65455 (r=0.545,p=0.818),  time:23.561, tt:1342.958\n",
      "Ep:57, loss:0.00008, loss_test:0.11072, lr:5.98e-03, fs:0.63354 (r=0.515,p=0.823),  time:23.659, tt:1372.203\n",
      "Ep:58, loss:0.00008, loss_test:0.10998, lr:5.92e-03, fs:0.66265 (r=0.556,p=0.821),  time:23.740, tt:1400.687\n",
      "Ep:59, loss:0.00008, loss_test:0.11094, lr:5.86e-03, fs:0.64634 (r=0.535,p=0.815),  time:23.846, tt:1430.786\n",
      "Ep:60, loss:0.00008, loss_test:0.11018, lr:5.80e-03, fs:0.66265 (r=0.556,p=0.821),  time:23.913, tt:1458.708\n",
      "Ep:61, loss:0.00008, loss_test:0.11021, lr:5.74e-03, fs:0.62025 (r=0.495,p=0.831),  time:23.992, tt:1487.511\n",
      "Ep:62, loss:0.00008, loss_test:0.10989, lr:5.68e-03, fs:0.66265 (r=0.556,p=0.821),  time:24.074, tt:1516.673\n",
      "Ep:63, loss:0.00007, loss_test:0.11037, lr:5.63e-03, fs:0.61635 (r=0.495,p=0.817),  time:24.166, tt:1546.655\n",
      "Ep:64, loss:0.00007, loss_test:0.10966, lr:5.57e-03, fs:0.64634 (r=0.535,p=0.815),  time:24.268, tt:1577.408\n",
      "Ep:65, loss:0.00007, loss_test:0.11003, lr:5.52e-03, fs:0.65031 (r=0.535,p=0.828),  time:24.342, tt:1606.592\n",
      "Ep:66, loss:0.00007, loss_test:0.11030, lr:5.46e-03, fs:0.61250 (r=0.495,p=0.803),  time:24.404, tt:1635.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00007, loss_test:0.11017, lr:5.41e-03, fs:0.61250 (r=0.495,p=0.803),  time:24.479, tt:1664.590\n",
      "Ep:68, loss:0.00007, loss_test:0.10964, lr:5.35e-03, fs:0.63804 (r=0.525,p=0.812),  time:24.533, tt:1692.769\n",
      "Ep:69, loss:0.00007, loss_test:0.10953, lr:5.30e-03, fs:0.63291 (r=0.505,p=0.847),  time:24.618, tt:1723.237\n",
      "Ep:70, loss:0.00007, loss_test:0.10968, lr:5.25e-03, fs:0.62963 (r=0.515,p=0.810),  time:24.683, tt:1752.468\n",
      "Ep:71, loss:0.00007, loss_test:0.11059, lr:5.19e-03, fs:0.62025 (r=0.495,p=0.831),  time:24.729, tt:1780.504\n",
      "Ep:72, loss:0.00007, loss_test:0.11082, lr:5.14e-03, fs:0.61935 (r=0.485,p=0.857),  time:24.769, tt:1808.111\n",
      "Ep:73, loss:0.00006, loss_test:0.10912, lr:5.09e-03, fs:0.62577 (r=0.515,p=0.797),  time:24.836, tt:1837.854\n",
      "Ep:74, loss:0.00006, loss_test:0.11085, lr:5.04e-03, fs:0.61538 (r=0.485,p=0.842),  time:24.891, tt:1866.810\n",
      "Ep:75, loss:0.00006, loss_test:0.11131, lr:4.99e-03, fs:0.62420 (r=0.495,p=0.845),  time:24.937, tt:1895.233\n",
      "Ep:76, loss:0.00006, loss_test:0.11004, lr:4.94e-03, fs:0.62500 (r=0.505,p=0.820),  time:24.981, tt:1923.560\n",
      "Ep:77, loss:0.00006, loss_test:0.11074, lr:4.89e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.027, tt:1952.091\n",
      "Ep:78, loss:0.00006, loss_test:0.11102, lr:4.84e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.079, tt:1981.276\n",
      "Ep:79, loss:0.00006, loss_test:0.11033, lr:4.79e-03, fs:0.62500 (r=0.505,p=0.820),  time:25.136, tt:2010.883\n",
      "Ep:80, loss:0.00006, loss_test:0.11092, lr:4.74e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.169, tt:2038.686\n",
      "Ep:81, loss:0.00006, loss_test:0.11177, lr:4.70e-03, fs:0.59740 (r=0.465,p=0.836),  time:25.206, tt:2066.870\n",
      "Ep:82, loss:0.00006, loss_test:0.11076, lr:4.65e-03, fs:0.62893 (r=0.505,p=0.833),  time:25.244, tt:2095.221\n",
      "Ep:83, loss:0.00006, loss_test:0.11066, lr:4.60e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.304, tt:2125.545\n",
      "Ep:84, loss:0.00006, loss_test:0.11100, lr:4.56e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.356, tt:2155.294\n",
      "Ep:85, loss:0.00006, loss_test:0.11068, lr:4.51e-03, fs:0.61538 (r=0.485,p=0.842),  time:25.393, tt:2183.789\n",
      "Ep:86, loss:0.00006, loss_test:0.11087, lr:4.47e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.412, tt:2210.856\n",
      "Ep:87, loss:0.00005, loss_test:0.11171, lr:4.42e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.435, tt:2238.282\n",
      "Ep:88, loss:0.00005, loss_test:0.11010, lr:4.38e-03, fs:0.62420 (r=0.495,p=0.845),  time:25.490, tt:2268.622\n",
      "Ep:89, loss:0.00005, loss_test:0.11026, lr:4.33e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.538, tt:2298.409\n",
      "Ep:90, loss:0.00005, loss_test:0.11175, lr:4.29e-03, fs:0.59603 (r=0.455,p=0.865),  time:25.551, tt:2325.150\n",
      "Ep:91, loss:0.00005, loss_test:0.11014, lr:4.25e-03, fs:0.60256 (r=0.475,p=0.825),  time:25.573, tt:2352.686\n",
      "Ep:92, loss:0.00005, loss_test:0.11000, lr:4.20e-03, fs:0.60645 (r=0.475,p=0.839),  time:25.607, tt:2381.429\n",
      "Ep:93, loss:0.00005, loss_test:0.11064, lr:4.16e-03, fs:0.59603 (r=0.455,p=0.865),  time:25.644, tt:2410.501\n",
      "Ep:94, loss:0.00005, loss_test:0.11071, lr:4.12e-03, fs:0.58824 (r=0.455,p=0.833),  time:25.689, tt:2440.433\n",
      "Ep:95, loss:0.00005, loss_test:0.11044, lr:4.08e-03, fs:0.59740 (r=0.465,p=0.836),  time:25.706, tt:2467.744\n",
      "Ep:96, loss:0.00005, loss_test:0.11012, lr:4.04e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.735, tt:2496.304\n",
      "Ep:97, loss:0.00005, loss_test:0.11056, lr:4.00e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.755, tt:2523.997\n",
      "Ep:98, loss:0.00005, loss_test:0.11038, lr:3.96e-03, fs:0.58824 (r=0.455,p=0.833),  time:25.797, tt:2553.895\n",
      "Ep:99, loss:0.00005, loss_test:0.10998, lr:3.92e-03, fs:0.58824 (r=0.455,p=0.833),  time:25.847, tt:2584.670\n",
      "Ep:100, loss:0.00005, loss_test:0.11016, lr:3.88e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.875, tt:2613.324\n",
      "Ep:101, loss:0.00005, loss_test:0.11004, lr:3.84e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.902, tt:2642.037\n",
      "Ep:102, loss:0.00005, loss_test:0.11009, lr:3.80e-03, fs:0.58824 (r=0.455,p=0.833),  time:25.913, tt:2668.997\n",
      "Ep:103, loss:0.00005, loss_test:0.10984, lr:3.76e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.952, tt:2698.957\n",
      "Ep:104, loss:0.00005, loss_test:0.11012, lr:3.73e-03, fs:0.59211 (r=0.455,p=0.849),  time:25.997, tt:2729.720\n",
      "Ep:105, loss:0.00005, loss_test:0.11008, lr:3.69e-03, fs:0.59211 (r=0.455,p=0.849),  time:26.010, tt:2757.087\n",
      "Ep:106, loss:0.00004, loss_test:0.11017, lr:3.65e-03, fs:0.59211 (r=0.455,p=0.849),  time:26.020, tt:2784.109\n",
      "Ep:107, loss:0.00004, loss_test:0.11010, lr:3.62e-03, fs:0.59603 (r=0.455,p=0.865),  time:26.033, tt:2811.512\n",
      "Ep:108, loss:0.00004, loss_test:0.11077, lr:3.58e-03, fs:0.58667 (r=0.444,p=0.863),  time:26.097, tt:2844.579\n",
      "Ep:109, loss:0.00004, loss_test:0.10991, lr:3.54e-03, fs:0.58824 (r=0.455,p=0.833),  time:26.138, tt:2875.202\n",
      "Ep:110, loss:0.00004, loss_test:0.11017, lr:3.51e-03, fs:0.58667 (r=0.444,p=0.863),  time:26.158, tt:2903.549\n",
      "Ep:111, loss:0.00004, loss_test:0.11026, lr:3.47e-03, fs:0.58667 (r=0.444,p=0.863),  time:26.177, tt:2931.780\n",
      "Ep:112, loss:0.00004, loss_test:0.11010, lr:3.44e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.201, tt:2960.674\n",
      "Ep:113, loss:0.00004, loss_test:0.11026, lr:3.40e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.224, tt:2989.506\n",
      "Ep:114, loss:0.00004, loss_test:0.11041, lr:3.37e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.259, tt:3019.745\n",
      "Ep:115, loss:0.00004, loss_test:0.10992, lr:3.34e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.282, tt:3048.749\n",
      "Ep:116, loss:0.00004, loss_test:0.11052, lr:3.30e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.300, tt:3077.075\n",
      "Ep:117, loss:0.00004, loss_test:0.11062, lr:3.27e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.315, tt:3105.203\n",
      "Ep:118, loss:0.00004, loss_test:0.11009, lr:3.24e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.338, tt:3134.250\n",
      "Ep:119, loss:0.00004, loss_test:0.11025, lr:3.21e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.365, tt:3163.821\n",
      "Ep:120, loss:0.00004, loss_test:0.11103, lr:3.17e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.388, tt:3192.952\n",
      "Ep:121, loss:0.00004, loss_test:0.11039, lr:3.14e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.412, tt:3222.231\n",
      "Ep:122, loss:0.00004, loss_test:0.10981, lr:3.11e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.431, tt:3251.055\n",
      "Ep:123, loss:0.00004, loss_test:0.11048, lr:3.08e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.452, tt:3280.098\n",
      "Ep:124, loss:0.00004, loss_test:0.11065, lr:3.05e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.483, tt:3310.328\n",
      "Ep:125, loss:0.00004, loss_test:0.11029, lr:3.02e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.507, tt:3339.840\n",
      "Ep:126, loss:0.00004, loss_test:0.11130, lr:2.99e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.524, tt:3368.539\n",
      "Ep:127, loss:0.00004, loss_test:0.11102, lr:2.96e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.531, tt:3396.026\n",
      "Ep:128, loss:0.00004, loss_test:0.11019, lr:2.93e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.547, tt:3424.561\n",
      "Ep:129, loss:0.00004, loss_test:0.11086, lr:2.90e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.568, tt:3453.871\n",
      "Ep:130, loss:0.00004, loss_test:0.11132, lr:2.87e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.594, tt:3483.839\n",
      "Ep:131, loss:0.00004, loss_test:0.11079, lr:2.84e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.619, tt:3513.704\n",
      "Ep:132, loss:0.00004, loss_test:0.11070, lr:2.81e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.635, tt:3542.411\n",
      "Ep:133, loss:0.00004, loss_test:0.11098, lr:2.78e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.654, tt:3571.674\n",
      "Ep:134, loss:0.00004, loss_test:0.11123, lr:2.76e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.679, tt:3601.721\n",
      "Ep:135, loss:0.00004, loss_test:0.11059, lr:2.73e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.710, tt:3632.548\n",
      "Ep:136, loss:0.00004, loss_test:0.11107, lr:2.70e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.717, tt:3660.261\n",
      "Ep:137, loss:0.00004, loss_test:0.11173, lr:2.68e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.726, tt:3688.144\n",
      "Ep:138, loss:0.00004, loss_test:0.11101, lr:2.65e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.732, tt:3715.755\n",
      "Ep:139, loss:0.00004, loss_test:0.11110, lr:2.62e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.757, tt:3746.038\n",
      "Ep:140, loss:0.00004, loss_test:0.11146, lr:2.60e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.778, tt:3775.721\n",
      "Ep:141, loss:0.00003, loss_test:0.11132, lr:2.57e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.785, tt:3803.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00003, loss_test:0.11148, lr:2.54e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.786, tt:3830.417\n",
      "Ep:143, loss:0.00003, loss_test:0.11131, lr:2.52e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.797, tt:3858.801\n",
      "Ep:144, loss:0.00003, loss_test:0.11150, lr:2.49e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.822, tt:3889.132\n",
      "Ep:145, loss:0.00003, loss_test:0.11135, lr:2.47e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.840, tt:3918.603\n",
      "Ep:146, loss:0.00003, loss_test:0.11166, lr:2.44e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.859, tt:3948.258\n",
      "Ep:147, loss:0.00003, loss_test:0.11156, lr:2.42e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.869, tt:3976.635\n",
      "Ep:148, loss:0.00003, loss_test:0.11161, lr:2.40e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.888, tt:4006.316\n",
      "Ep:149, loss:0.00003, loss_test:0.11161, lr:2.37e-03, fs:0.58824 (r=0.455,p=0.833),  time:26.914, tt:4037.106\n",
      "Ep:150, loss:0.00003, loss_test:0.11159, lr:2.35e-03, fs:0.58824 (r=0.455,p=0.833),  time:26.939, tt:4067.854\n",
      "Ep:151, loss:0.00003, loss_test:0.11215, lr:2.32e-03, fs:0.58278 (r=0.444,p=0.846),  time:26.952, tt:4096.645\n",
      "Ep:152, loss:0.00003, loss_test:0.11185, lr:2.30e-03, fs:0.57895 (r=0.444,p=0.830),  time:26.969, tt:4126.252\n",
      "Ep:153, loss:0.00003, loss_test:0.11144, lr:2.28e-03, fs:0.58824 (r=0.455,p=0.833),  time:26.973, tt:4153.822\n",
      "Ep:154, loss:0.00003, loss_test:0.11229, lr:2.25e-03, fs:0.58667 (r=0.444,p=0.863),  time:26.992, tt:4183.702\n",
      "Ep:155, loss:0.00003, loss_test:0.11276, lr:2.23e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.023, tt:4215.559\n",
      "Ep:156, loss:0.00003, loss_test:0.11179, lr:2.21e-03, fs:0.58824 (r=0.455,p=0.833),  time:27.042, tt:4245.561\n",
      "Ep:157, loss:0.00003, loss_test:0.11155, lr:2.19e-03, fs:0.58824 (r=0.455,p=0.833),  time:27.042, tt:4272.641\n",
      "Ep:158, loss:0.00003, loss_test:0.11295, lr:2.17e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.054, tt:4301.652\n",
      "Ep:159, loss:0.00003, loss_test:0.11277, lr:2.14e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.065, tt:4330.475\n",
      "Ep:160, loss:0.00003, loss_test:0.11148, lr:2.12e-03, fs:0.57895 (r=0.444,p=0.830),  time:27.088, tt:4361.106\n",
      "Ep:161, loss:0.00003, loss_test:0.11229, lr:2.10e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.112, tt:4392.068\n",
      "Ep:162, loss:0.00003, loss_test:0.11281, lr:2.08e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.117, tt:4420.120\n",
      "Ep:163, loss:0.00003, loss_test:0.11187, lr:2.06e-03, fs:0.58824 (r=0.455,p=0.833),  time:27.140, tt:4451.003\n",
      "Ep:164, loss:0.00003, loss_test:0.11170, lr:2.04e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.154, tt:4480.451\n",
      "Ep:165, loss:0.00003, loss_test:0.11243, lr:2.02e-03, fs:0.59060 (r=0.444,p=0.880),  time:27.179, tt:4511.666\n",
      "Ep:166, loss:0.00003, loss_test:0.11226, lr:2.00e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.198, tt:4542.037\n",
      "Ep:167, loss:0.00003, loss_test:0.11152, lr:1.98e-03, fs:0.59211 (r=0.455,p=0.849),  time:27.214, tt:4572.017\n",
      "Ep:168, loss:0.00003, loss_test:0.11202, lr:1.96e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.221, tt:4600.393\n",
      "Ep:169, loss:0.00003, loss_test:0.11246, lr:1.94e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.227, tt:4628.608\n",
      "Ep:170, loss:0.00003, loss_test:0.11226, lr:1.92e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.236, tt:4657.307\n",
      "Ep:171, loss:0.00003, loss_test:0.11205, lr:1.90e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.259, tt:4688.503\n",
      "Ep:172, loss:0.00003, loss_test:0.11189, lr:1.88e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.276, tt:4718.686\n",
      "Ep:173, loss:0.00003, loss_test:0.11247, lr:1.86e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.287, tt:4748.001\n",
      "Ep:174, loss:0.00003, loss_test:0.11258, lr:1.84e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.296, tt:4776.801\n",
      "Ep:175, loss:0.00003, loss_test:0.11194, lr:1.83e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.315, tt:4807.415\n",
      "Ep:176, loss:0.00003, loss_test:0.11190, lr:1.81e-03, fs:0.58667 (r=0.444,p=0.863),  time:27.335, tt:4838.324\n",
      "Ep:177, loss:0.00003, loss_test:0.11240, lr:1.79e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.346, tt:4867.601\n",
      "Ep:178, loss:0.00003, loss_test:0.11239, lr:1.77e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.360, tt:4897.451\n",
      "Ep:179, loss:0.00003, loss_test:0.11182, lr:1.75e-03, fs:0.58278 (r=0.444,p=0.846),  time:27.341, tt:4921.366\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"16-16\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=8e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14510, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.893, tt:11.893\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14454, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.965, tt:27.930\n",
      "Ep:2, loss:0.00028, loss_test:0.14355, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.628, tt:49.885\n",
      "Ep:3, loss:0.00027, loss_test:0.14206, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.307, tt:77.230\n",
      "Ep:4, loss:0.00027, loss_test:0.13993, lr:1.00e-02, fs:0.64605 (r=0.949,p=0.490),  time:21.728, tt:108.641\n",
      "Ep:5, loss:0.00026, loss_test:0.13690, lr:1.00e-02, fs:0.63309 (r=0.889,p=0.492),  time:23.264, tt:139.584\n",
      "Ep:6, loss:0.00025, loss_test:0.13245, lr:1.00e-02, fs:0.63035 (r=0.818,p=0.513),  time:24.562, tt:171.936\n",
      "Ep:7, loss:0.00023, loss_test:0.12777, lr:1.00e-02, fs:0.62780 (r=0.707,p=0.565),  time:25.324, tt:202.591\n",
      "Ep:8, loss:0.00023, loss_test:0.12621, lr:1.00e-02, fs:0.60914 (r=0.606,p=0.612),  time:25.998, tt:233.978\n",
      "Ep:9, loss:0.00022, loss_test:0.12447, lr:1.00e-02, fs:0.61692 (r=0.626,p=0.608),  time:26.450, tt:264.501\n",
      "Ep:10, loss:0.00022, loss_test:0.12348, lr:1.00e-02, fs:0.63014 (r=0.697,p=0.575),  time:26.951, tt:296.464\n",
      "Ep:11, loss:0.00021, loss_test:0.12240, lr:1.00e-02, fs:0.65502 (r=0.758,p=0.577),  time:27.324, tt:327.887\n",
      "Ep:12, loss:0.00021, loss_test:0.12046, lr:9.90e-03, fs:0.65138 (r=0.717,p=0.597),  time:27.531, tt:357.907\n",
      "Ep:13, loss:0.00020, loss_test:0.11833, lr:9.80e-03, fs:0.63107 (r=0.657,p=0.607),  time:27.863, tt:390.087\n",
      "Ep:14, loss:0.00020, loss_test:0.11632, lr:9.70e-03, fs:0.64039 (r=0.657,p=0.625),  time:28.079, tt:421.186\n",
      "Ep:15, loss:0.00019, loss_test:0.11375, lr:9.61e-03, fs:0.61836 (r=0.646,p=0.593),  time:28.155, tt:450.482\n",
      "Ep:16, loss:0.00019, loss_test:0.11160, lr:9.51e-03, fs:0.64789 (r=0.697,p=0.605),  time:28.369, tt:482.270\n",
      "Ep:17, loss:0.00019, loss_test:0.10930, lr:9.41e-03, fs:0.65403 (r=0.697,p=0.616),  time:28.523, tt:513.421\n",
      "Ep:18, loss:0.00018, loss_test:0.10730, lr:9.32e-03, fs:0.66000 (r=0.667,p=0.653),  time:28.646, tt:544.265\n",
      "Ep:19, loss:0.00018, loss_test:0.10590, lr:9.23e-03, fs:0.63265 (r=0.626,p=0.639),  time:28.822, tt:576.444\n",
      "Ep:20, loss:0.00017, loss_test:0.10435, lr:9.14e-03, fs:0.68293 (r=0.707,p=0.660),  time:28.964, tt:608.252\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.10296, lr:9.14e-03, fs:0.69565 (r=0.727,p=0.667),  time:29.031, tt:638.682\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.10148, lr:9.14e-03, fs:0.70244 (r=0.727,p=0.679),  time:29.165, tt:670.788\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.10004, lr:9.14e-03, fs:0.70936 (r=0.727,p=0.692),  time:29.250, tt:701.994\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09871, lr:9.14e-03, fs:0.71287 (r=0.727,p=0.699),  time:29.311, tt:732.780\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.09772, lr:9.14e-03, fs:0.71287 (r=0.727,p=0.699),  time:29.384, tt:763.991\n",
      "Ep:26, loss:0.00015, loss_test:0.09640, lr:9.14e-03, fs:0.72906 (r=0.747,p=0.712),  time:29.438, tt:794.835\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09525, lr:9.14e-03, fs:0.73632 (r=0.747,p=0.725),  time:29.500, tt:826.001\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09478, lr:9.14e-03, fs:0.73367 (r=0.737,p=0.730),  time:29.621, tt:859.021\n",
      "Ep:29, loss:0.00015, loss_test:0.09439, lr:9.14e-03, fs:0.72821 (r=0.717,p=0.740),  time:29.670, tt:890.097\n",
      "Ep:30, loss:0.00014, loss_test:0.09364, lr:9.14e-03, fs:0.73196 (r=0.717,p=0.747),  time:29.747, tt:922.164\n",
      "Ep:31, loss:0.00014, loss_test:0.09337, lr:9.14e-03, fs:0.73846 (r=0.727,p=0.750),  time:29.810, tt:953.935\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.09304, lr:9.14e-03, fs:0.72251 (r=0.697,p=0.750),  time:29.826, tt:984.257\n",
      "Ep:33, loss:0.00014, loss_test:0.09252, lr:9.14e-03, fs:0.72632 (r=0.697,p=0.758),  time:29.839, tt:1014.513\n",
      "Ep:34, loss:0.00013, loss_test:0.09205, lr:9.14e-03, fs:0.72251 (r=0.697,p=0.750),  time:29.863, tt:1045.191\n",
      "Ep:35, loss:0.00013, loss_test:0.09122, lr:9.14e-03, fs:0.73298 (r=0.707,p=0.761),  time:29.917, tt:1077.023\n",
      "Ep:36, loss:0.00013, loss_test:0.09077, lr:9.14e-03, fs:0.73298 (r=0.707,p=0.761),  time:29.919, tt:1107.002\n",
      "Ep:37, loss:0.00013, loss_test:0.09072, lr:9.14e-03, fs:0.72632 (r=0.697,p=0.758),  time:29.928, tt:1137.258\n",
      "Ep:38, loss:0.00013, loss_test:0.09019, lr:9.14e-03, fs:0.74074 (r=0.707,p=0.778),  time:29.948, tt:1167.984\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00012, loss_test:0.08977, lr:9.14e-03, fs:0.73797 (r=0.697,p=0.784),  time:29.935, tt:1197.398\n",
      "Ep:40, loss:0.00012, loss_test:0.08946, lr:9.14e-03, fs:0.73797 (r=0.697,p=0.784),  time:29.980, tt:1229.177\n",
      "Ep:41, loss:0.00012, loss_test:0.08927, lr:9.14e-03, fs:0.73797 (r=0.697,p=0.784),  time:30.012, tt:1260.492\n",
      "Ep:42, loss:0.00012, loss_test:0.08900, lr:9.14e-03, fs:0.73118 (r=0.687,p=0.782),  time:30.029, tt:1291.243\n",
      "Ep:43, loss:0.00011, loss_test:0.08866, lr:9.14e-03, fs:0.72432 (r=0.677,p=0.779),  time:30.068, tt:1322.975\n",
      "Ep:44, loss:0.00011, loss_test:0.08876, lr:9.14e-03, fs:0.70718 (r=0.646,p=0.780),  time:30.068, tt:1353.054\n",
      "Ep:45, loss:0.00011, loss_test:0.08855, lr:9.14e-03, fs:0.72131 (r=0.667,p=0.786),  time:30.082, tt:1383.754\n",
      "Ep:46, loss:0.00011, loss_test:0.08878, lr:9.14e-03, fs:0.71429 (r=0.657,p=0.783),  time:30.067, tt:1413.140\n",
      "Ep:47, loss:0.00011, loss_test:0.08917, lr:9.14e-03, fs:0.70787 (r=0.636,p=0.797),  time:30.119, tt:1445.716\n",
      "Ep:48, loss:0.00010, loss_test:0.08835, lr:9.14e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.140, tt:1476.882\n",
      "Ep:49, loss:0.00010, loss_test:0.08894, lr:9.14e-03, fs:0.71111 (r=0.646,p=0.790),  time:30.172, tt:1508.606\n",
      "Ep:50, loss:0.00010, loss_test:0.08925, lr:9.04e-03, fs:0.71508 (r=0.646,p=0.800),  time:30.182, tt:1539.260\n",
      "Ep:51, loss:0.00010, loss_test:0.08850, lr:8.95e-03, fs:0.71823 (r=0.657,p=0.793),  time:30.191, tt:1569.924\n",
      "Ep:52, loss:0.00009, loss_test:0.08843, lr:8.86e-03, fs:0.72626 (r=0.657,p=0.812),  time:30.180, tt:1599.532\n",
      "Ep:53, loss:0.00009, loss_test:0.08923, lr:8.78e-03, fs:0.71591 (r=0.636,p=0.818),  time:30.201, tt:1630.867\n",
      "Ep:54, loss:0.00009, loss_test:0.08829, lr:8.69e-03, fs:0.72727 (r=0.646,p=0.831),  time:30.209, tt:1661.480\n",
      "Ep:55, loss:0.00009, loss_test:0.08831, lr:8.60e-03, fs:0.72727 (r=0.646,p=0.831),  time:30.227, tt:1692.715\n",
      "Ep:56, loss:0.00009, loss_test:0.08857, lr:8.51e-03, fs:0.72727 (r=0.646,p=0.831),  time:30.250, tt:1724.252\n",
      "Ep:57, loss:0.00008, loss_test:0.08836, lr:8.43e-03, fs:0.72727 (r=0.646,p=0.831),  time:30.264, tt:1755.335\n",
      "Ep:58, loss:0.00008, loss_test:0.08774, lr:8.35e-03, fs:0.73143 (r=0.646,p=0.842),  time:30.272, tt:1786.054\n",
      "Ep:59, loss:0.00008, loss_test:0.08843, lr:8.26e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.281, tt:1816.855\n",
      "Ep:60, loss:0.00008, loss_test:0.08855, lr:8.18e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.259, tt:1845.785\n",
      "Ep:61, loss:0.00008, loss_test:0.08725, lr:8.10e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.270, tt:1876.764\n",
      "Ep:62, loss:0.00007, loss_test:0.08822, lr:8.02e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.261, tt:1906.447\n",
      "Ep:63, loss:0.00007, loss_test:0.08837, lr:7.94e-03, fs:0.71264 (r=0.626,p=0.827),  time:30.264, tt:1936.910\n",
      "Ep:64, loss:0.00007, loss_test:0.08702, lr:7.86e-03, fs:0.70930 (r=0.616,p=0.836),  time:30.276, tt:1967.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00007, loss_test:0.08702, lr:7.78e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.301, tt:1999.897\n",
      "Ep:66, loss:0.00007, loss_test:0.08838, lr:7.70e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.301, tt:2030.200\n",
      "Ep:67, loss:0.00007, loss_test:0.08713, lr:7.62e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.293, tt:2059.919\n",
      "Ep:68, loss:0.00007, loss_test:0.08641, lr:7.55e-03, fs:0.72414 (r=0.636,p=0.840),  time:30.284, tt:2089.575\n",
      "Ep:69, loss:0.00006, loss_test:0.08694, lr:7.47e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.260, tt:2118.231\n",
      "Ep:70, loss:0.00006, loss_test:0.08636, lr:7.40e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.266, tt:2148.861\n",
      "Ep:71, loss:0.00006, loss_test:0.08612, lr:7.32e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.270, tt:2179.412\n",
      "Ep:72, loss:0.00006, loss_test:0.08664, lr:7.25e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.277, tt:2210.205\n",
      "Ep:73, loss:0.00006, loss_test:0.08490, lr:7.18e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.285, tt:2241.079\n",
      "Ep:74, loss:0.00006, loss_test:0.08624, lr:7.11e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.299, tt:2272.427\n",
      "Ep:75, loss:0.00006, loss_test:0.08575, lr:7.03e-03, fs:0.71345 (r=0.616,p=0.847),  time:30.301, tt:2302.848\n",
      "Ep:76, loss:0.00005, loss_test:0.08398, lr:6.96e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.292, tt:2332.494\n",
      "Ep:77, loss:0.00005, loss_test:0.08483, lr:6.89e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.304, tt:2363.677\n",
      "Ep:78, loss:0.00005, loss_test:0.08510, lr:6.83e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.302, tt:2393.842\n",
      "Ep:79, loss:0.00005, loss_test:0.08376, lr:6.76e-03, fs:0.73256 (r=0.636,p=0.863),  time:30.306, tt:2424.485\n",
      "Ep:80, loss:0.00005, loss_test:0.08430, lr:6.69e-03, fs:0.73256 (r=0.636,p=0.863),  time:30.319, tt:2455.852\n",
      "Ep:81, loss:0.00005, loss_test:0.08436, lr:6.62e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.323, tt:2486.463\n",
      "Ep:82, loss:0.00005, loss_test:0.08354, lr:6.56e-03, fs:0.73988 (r=0.646,p=0.865),  time:30.315, tt:2516.163\n",
      "Ep:83, loss:0.00005, loss_test:0.08391, lr:6.49e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.327, tt:2547.458\n",
      "Ep:84, loss:0.00005, loss_test:0.08369, lr:6.43e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.319, tt:2577.126\n",
      "Ep:85, loss:0.00005, loss_test:0.08354, lr:6.36e-03, fs:0.73988 (r=0.646,p=0.865),  time:30.337, tt:2608.941\n",
      "Ep:86, loss:0.00005, loss_test:0.08344, lr:6.30e-03, fs:0.72619 (r=0.616,p=0.884),  time:30.325, tt:2638.233\n",
      "Ep:87, loss:0.00004, loss_test:0.08322, lr:6.24e-03, fs:0.73256 (r=0.636,p=0.863),  time:30.332, tt:2669.210\n",
      "Ep:88, loss:0.00004, loss_test:0.08317, lr:6.17e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.324, tt:2698.857\n",
      "Ep:89, loss:0.00004, loss_test:0.08322, lr:6.11e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.314, tt:2728.277\n",
      "Ep:90, loss:0.00004, loss_test:0.08172, lr:6.05e-03, fs:0.73256 (r=0.636,p=0.863),  time:30.313, tt:2758.520\n",
      "Ep:91, loss:0.00004, loss_test:0.08220, lr:5.99e-03, fs:0.72941 (r=0.626,p=0.873),  time:30.313, tt:2788.836\n",
      "Ep:92, loss:0.00004, loss_test:0.08318, lr:5.93e-03, fs:0.72189 (r=0.616,p=0.871),  time:30.328, tt:2820.488\n",
      "Ep:93, loss:0.00004, loss_test:0.08156, lr:5.87e-03, fs:0.74556 (r=0.636,p=0.900),  time:30.317, tt:2849.807\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00004, loss_test:0.08267, lr:5.87e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.316, tt:2880.023\n",
      "Ep:95, loss:0.00004, loss_test:0.08292, lr:5.87e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.326, tt:2911.285\n",
      "Ep:96, loss:0.00004, loss_test:0.08150, lr:5.87e-03, fs:0.73054 (r=0.616,p=0.897),  time:30.333, tt:2942.320\n",
      "Ep:97, loss:0.00004, loss_test:0.08244, lr:5.87e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.338, tt:2973.140\n",
      "Ep:98, loss:0.00004, loss_test:0.08238, lr:5.87e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.340, tt:3003.695\n",
      "Ep:99, loss:0.00004, loss_test:0.08259, lr:5.87e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.343, tt:3034.310\n",
      "Ep:100, loss:0.00004, loss_test:0.08201, lr:5.87e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.328, tt:3063.109\n",
      "Ep:101, loss:0.00004, loss_test:0.08263, lr:5.87e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.340, tt:3094.633\n",
      "Ep:102, loss:0.00004, loss_test:0.08270, lr:5.87e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.349, tt:3125.987\n",
      "Ep:103, loss:0.00004, loss_test:0.08166, lr:5.87e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.359, tt:3157.291\n",
      "Ep:104, loss:0.00003, loss_test:0.08368, lr:5.87e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.367, tt:3188.572\n",
      "Ep:105, loss:0.00003, loss_test:0.08351, lr:5.81e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.362, tt:3218.390\n",
      "Ep:106, loss:0.00003, loss_test:0.08164, lr:5.75e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.349, tt:3247.333\n",
      "Ep:107, loss:0.00003, loss_test:0.08312, lr:5.70e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.338, tt:3276.508\n",
      "Ep:108, loss:0.00003, loss_test:0.08335, lr:5.64e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.341, tt:3307.192\n",
      "Ep:109, loss:0.00003, loss_test:0.08287, lr:5.58e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.344, tt:3337.835\n",
      "Ep:110, loss:0.00003, loss_test:0.08341, lr:5.53e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.348, tt:3368.614\n",
      "Ep:111, loss:0.00003, loss_test:0.08344, lr:5.47e-03, fs:0.72727 (r=0.606,p=0.909),  time:30.342, tt:3398.281\n",
      "Ep:112, loss:0.00003, loss_test:0.08382, lr:5.42e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.342, tt:3428.635\n",
      "Ep:113, loss:0.00003, loss_test:0.08255, lr:5.36e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.343, tt:3459.151\n",
      "Ep:114, loss:0.00003, loss_test:0.08305, lr:5.31e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.333, tt:3488.330\n",
      "Ep:115, loss:0.00003, loss_test:0.08434, lr:5.26e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.326, tt:3517.873\n",
      "Ep:116, loss:0.00003, loss_test:0.08300, lr:5.20e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.325, tt:3547.991\n",
      "Ep:117, loss:0.00003, loss_test:0.08310, lr:5.15e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.330, tt:3578.947\n",
      "Ep:118, loss:0.00003, loss_test:0.08439, lr:5.10e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.322, tt:3608.294\n",
      "Ep:119, loss:0.00003, loss_test:0.08404, lr:5.05e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.321, tt:3638.463\n",
      "Ep:120, loss:0.00003, loss_test:0.08382, lr:5.00e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.313, tt:3667.918\n",
      "Ep:121, loss:0.00003, loss_test:0.08426, lr:4.95e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.313, tt:3698.165\n",
      "Ep:122, loss:0.00003, loss_test:0.08385, lr:4.90e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.329, tt:3730.446\n",
      "Ep:123, loss:0.00003, loss_test:0.08464, lr:4.85e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.350, tt:3763.410\n",
      "Ep:124, loss:0.00003, loss_test:0.08448, lr:4.80e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.351, tt:3793.917\n",
      "Ep:125, loss:0.00003, loss_test:0.08437, lr:4.75e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.340, tt:3822.824\n",
      "Ep:126, loss:0.00003, loss_test:0.08515, lr:4.71e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.352, tt:3854.708\n",
      "Ep:127, loss:0.00003, loss_test:0.08544, lr:4.66e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.362, tt:3886.295\n",
      "Ep:128, loss:0.00003, loss_test:0.08501, lr:4.61e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.363, tt:3916.790\n",
      "Ep:129, loss:0.00003, loss_test:0.08555, lr:4.57e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.373, tt:3948.493\n",
      "Ep:130, loss:0.00002, loss_test:0.08612, lr:4.52e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.370, tt:3978.520\n",
      "Ep:131, loss:0.00002, loss_test:0.08440, lr:4.48e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.378, tt:4009.951\n",
      "Ep:132, loss:0.00002, loss_test:0.08580, lr:4.43e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.386, tt:4041.272\n",
      "Ep:133, loss:0.00002, loss_test:0.08625, lr:4.39e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.397, tt:4073.165\n",
      "Ep:134, loss:0.00002, loss_test:0.08555, lr:4.34e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.395, tt:4103.376\n",
      "Ep:135, loss:0.00002, loss_test:0.08603, lr:4.30e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.399, tt:4134.328\n",
      "Ep:136, loss:0.00002, loss_test:0.08629, lr:4.26e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.396, tt:4164.207\n",
      "Ep:137, loss:0.00002, loss_test:0.08621, lr:4.21e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.399, tt:4195.115\n",
      "Ep:138, loss:0.00002, loss_test:0.08669, lr:4.17e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.414, tt:4227.572\n",
      "Ep:139, loss:0.00002, loss_test:0.08643, lr:4.13e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.413, tt:4257.785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00002, loss_test:0.08636, lr:4.09e-03, fs:0.71429 (r=0.606,p=0.870),  time:30.423, tt:4289.700\n",
      "Ep:141, loss:0.00002, loss_test:0.08611, lr:4.05e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.431, tt:4321.263\n",
      "Ep:142, loss:0.00002, loss_test:0.08629, lr:4.01e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.435, tt:4352.236\n",
      "Ep:143, loss:0.00002, loss_test:0.08644, lr:3.97e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.442, tt:4383.597\n",
      "Ep:144, loss:0.00002, loss_test:0.08603, lr:3.93e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.454, tt:4415.878\n",
      "Ep:145, loss:0.00002, loss_test:0.08678, lr:3.89e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.455, tt:4446.485\n",
      "Ep:146, loss:0.00002, loss_test:0.08620, lr:3.85e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.452, tt:4476.485\n",
      "Ep:147, loss:0.00002, loss_test:0.08636, lr:3.81e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.451, tt:4506.675\n",
      "Ep:148, loss:0.00002, loss_test:0.08729, lr:3.77e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.460, tt:4538.498\n",
      "Ep:149, loss:0.00002, loss_test:0.08645, lr:3.73e-03, fs:0.71856 (r=0.606,p=0.882),  time:30.473, tt:4570.935\n",
      "Ep:150, loss:0.00002, loss_test:0.08685, lr:3.70e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.481, tt:4602.602\n",
      "Ep:151, loss:0.00002, loss_test:0.08698, lr:3.66e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.470, tt:4631.442\n",
      "Ep:152, loss:0.00002, loss_test:0.08605, lr:3.62e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.474, tt:4662.506\n",
      "Ep:153, loss:0.00002, loss_test:0.08635, lr:3.59e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.468, tt:4692.046\n",
      "Ep:154, loss:0.00002, loss_test:0.08724, lr:3.55e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.474, tt:4723.491\n",
      "Ep:155, loss:0.00002, loss_test:0.08666, lr:3.52e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.476, tt:4754.178\n",
      "Ep:156, loss:0.00002, loss_test:0.08629, lr:3.48e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.484, tt:4785.978\n",
      "Ep:157, loss:0.00002, loss_test:0.08690, lr:3.45e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.494, tt:4818.033\n",
      "Ep:158, loss:0.00002, loss_test:0.08638, lr:3.41e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.500, tt:4849.577\n",
      "Ep:159, loss:0.00002, loss_test:0.08622, lr:3.38e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.503, tt:4880.413\n",
      "Ep:160, loss:0.00002, loss_test:0.08662, lr:3.34e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.507, tt:4911.604\n",
      "Ep:161, loss:0.00002, loss_test:0.08656, lr:3.31e-03, fs:0.72289 (r=0.606,p=0.896),  time:30.504, tt:4941.572\n",
      "Ep:162, loss:0.00002, loss_test:0.08658, lr:3.28e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.500, tt:4971.451\n",
      "Ep:163, loss:0.00002, loss_test:0.08673, lr:3.24e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.505, tt:5002.878\n",
      "Ep:164, loss:0.00002, loss_test:0.08642, lr:3.21e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.514, tt:5034.762\n",
      "Ep:165, loss:0.00002, loss_test:0.08704, lr:3.18e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.516, tt:5065.592\n",
      "Ep:166, loss:0.00002, loss_test:0.08707, lr:3.15e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.523, tt:5097.356\n",
      "Ep:167, loss:0.00002, loss_test:0.08670, lr:3.12e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.523, tt:5127.879\n",
      "Ep:168, loss:0.00002, loss_test:0.08695, lr:3.09e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.525, tt:5158.655\n",
      "Ep:169, loss:0.00002, loss_test:0.08711, lr:3.05e-03, fs:0.71515 (r=0.596,p=0.894),  time:30.534, tt:5190.803\n",
      "Ep:170, loss:0.00002, loss_test:0.08685, lr:3.02e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.543, tt:5222.874\n",
      "Ep:171, loss:0.00002, loss_test:0.08694, lr:2.99e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.548, tt:5254.250\n",
      "Ep:172, loss:0.00002, loss_test:0.08696, lr:2.96e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.551, tt:5285.253\n",
      "Ep:173, loss:0.00002, loss_test:0.08707, lr:2.93e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.559, tt:5317.328\n",
      "Ep:174, loss:0.00002, loss_test:0.08766, lr:2.90e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.552, tt:5346.603\n",
      "Ep:175, loss:0.00002, loss_test:0.08732, lr:2.88e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.562, tt:5378.871\n",
      "Ep:176, loss:0.00002, loss_test:0.08674, lr:2.85e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.568, tt:5410.618\n",
      "Ep:177, loss:0.00002, loss_test:0.08754, lr:2.82e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.562, tt:5440.035\n",
      "Ep:178, loss:0.00002, loss_test:0.08779, lr:2.79e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.551, tt:5468.615\n",
      "Ep:179, loss:0.00002, loss_test:0.08708, lr:2.76e-03, fs:0.70732 (r=0.586,p=0.892),  time:30.560, tt:5500.791\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14341, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.564, tt:26.564\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14272, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.911, tt:53.822\n",
      "Ep:2, loss:0.00028, loss_test:0.14157, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.679, tt:80.038\n",
      "Ep:3, loss:0.00027, loss_test:0.13983, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.073, tt:108.293\n",
      "Ep:4, loss:0.00027, loss_test:0.13742, lr:1.00e-02, fs:0.65052 (r=0.949,p=0.495),  time:27.922, tt:139.608\n",
      "Ep:5, loss:0.00026, loss_test:0.13407, lr:1.00e-02, fs:0.64539 (r=0.919,p=0.497),  time:28.206, tt:169.238\n",
      "Ep:6, loss:0.00025, loss_test:0.12951, lr:1.00e-02, fs:0.66148 (r=0.859,p=0.538),  time:28.569, tt:199.985\n",
      "Ep:7, loss:0.00024, loss_test:0.12546, lr:1.00e-02, fs:0.60633 (r=0.677,p=0.549),  time:28.780, tt:230.244\n",
      "Ep:8, loss:0.00023, loss_test:0.12662, lr:1.00e-02, fs:0.57143 (r=0.525,p=0.627),  time:29.147, tt:262.323\n",
      "Ep:9, loss:0.00022, loss_test:0.12515, lr:1.00e-02, fs:0.56354 (r=0.515,p=0.622),  time:29.472, tt:294.723\n",
      "Ep:10, loss:0.00022, loss_test:0.12214, lr:1.00e-02, fs:0.59804 (r=0.616,p=0.581),  time:29.676, tt:326.437\n",
      "Ep:11, loss:0.00021, loss_test:0.12087, lr:1.00e-02, fs:0.62500 (r=0.657,p=0.596),  time:29.818, tt:357.813\n",
      "Ep:12, loss:0.00020, loss_test:0.11945, lr:9.90e-03, fs:0.57754 (r=0.545,p=0.614),  time:30.071, tt:390.920\n",
      "Ep:13, loss:0.00020, loss_test:0.11731, lr:9.80e-03, fs:0.58564 (r=0.535,p=0.646),  time:30.122, tt:421.714\n",
      "Ep:14, loss:0.00019, loss_test:0.11375, lr:9.70e-03, fs:0.60638 (r=0.576,p=0.640),  time:30.150, tt:452.245\n",
      "Ep:15, loss:0.00019, loss_test:0.11088, lr:9.61e-03, fs:0.66341 (r=0.687,p=0.642),  time:30.232, tt:483.704\n",
      "Ep:16, loss:0.00018, loss_test:0.10847, lr:9.51e-03, fs:0.68020 (r=0.677,p=0.684),  time:30.243, tt:514.139\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10650, lr:9.51e-03, fs:0.70103 (r=0.687,p=0.716),  time:30.341, tt:546.129\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.10435, lr:9.51e-03, fs:0.70707 (r=0.707,p=0.707),  time:30.360, tt:576.842\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10252, lr:9.51e-03, fs:0.70051 (r=0.697,p=0.704),  time:30.385, tt:607.700\n",
      "Ep:20, loss:0.00017, loss_test:0.10130, lr:9.51e-03, fs:0.72081 (r=0.717,p=0.724),  time:30.433, tt:639.088\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.10008, lr:9.51e-03, fs:0.72727 (r=0.727,p=0.727),  time:30.494, tt:670.857\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09837, lr:9.51e-03, fs:0.72727 (r=0.727,p=0.727),  time:30.507, tt:701.670\n",
      "Ep:23, loss:0.00016, loss_test:0.09697, lr:9.51e-03, fs:0.74000 (r=0.747,p=0.733),  time:30.560, tt:733.449\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.09600, lr:9.51e-03, fs:0.74000 (r=0.747,p=0.733),  time:30.546, tt:763.650\n",
      "Ep:25, loss:0.00015, loss_test:0.09496, lr:9.51e-03, fs:0.74000 (r=0.747,p=0.733),  time:30.554, tt:794.413\n",
      "Ep:26, loss:0.00015, loss_test:0.09341, lr:9.51e-03, fs:0.74877 (r=0.768,p=0.731),  time:30.536, tt:824.485\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09237, lr:9.51e-03, fs:0.74627 (r=0.758,p=0.735),  time:30.566, tt:855.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:28, loss:0.00014, loss_test:0.09156, lr:9.51e-03, fs:0.74627 (r=0.758,p=0.735),  time:30.592, tt:887.162\n",
      "Ep:29, loss:0.00014, loss_test:0.09023, lr:9.51e-03, fs:0.75248 (r=0.768,p=0.738),  time:30.597, tt:917.925\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08915, lr:9.51e-03, fs:0.76617 (r=0.778,p=0.755),  time:30.653, tt:950.230\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08917, lr:9.51e-03, fs:0.77157 (r=0.768,p=0.776),  time:30.683, tt:981.863\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08820, lr:9.51e-03, fs:0.77157 (r=0.768,p=0.776),  time:30.748, tt:1014.672\n",
      "Ep:33, loss:0.00013, loss_test:0.08729, lr:9.51e-03, fs:0.78788 (r=0.788,p=0.788),  time:30.776, tt:1046.392\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.08719, lr:9.51e-03, fs:0.78974 (r=0.778,p=0.802),  time:30.832, tt:1079.122\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08618, lr:9.51e-03, fs:0.78351 (r=0.768,p=0.800),  time:30.838, tt:1110.184\n",
      "Ep:36, loss:0.00012, loss_test:0.08502, lr:9.51e-03, fs:0.80612 (r=0.798,p=0.814),  time:30.791, tt:1139.267\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08449, lr:9.51e-03, fs:0.80000 (r=0.788,p=0.812),  time:30.772, tt:1169.345\n",
      "Ep:38, loss:0.00011, loss_test:0.08295, lr:9.51e-03, fs:0.81218 (r=0.808,p=0.816),  time:30.785, tt:1200.616\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08202, lr:9.51e-03, fs:0.81818 (r=0.818,p=0.818),  time:30.764, tt:1230.541\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.08262, lr:9.51e-03, fs:0.80208 (r=0.778,p=0.828),  time:30.816, tt:1263.442\n",
      "Ep:41, loss:0.00011, loss_test:0.08056, lr:9.51e-03, fs:0.81818 (r=0.818,p=0.818),  time:30.839, tt:1295.234\n",
      "Ep:42, loss:0.00010, loss_test:0.07993, lr:9.51e-03, fs:0.83077 (r=0.818,p=0.844),  time:30.858, tt:1326.910\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.08122, lr:9.51e-03, fs:0.80851 (r=0.768,p=0.854),  time:30.881, tt:1358.781\n",
      "Ep:44, loss:0.00010, loss_test:0.07900, lr:9.51e-03, fs:0.82474 (r=0.808,p=0.842),  time:30.905, tt:1390.729\n",
      "Ep:45, loss:0.00010, loss_test:0.07825, lr:9.51e-03, fs:0.82723 (r=0.798,p=0.859),  time:30.933, tt:1422.935\n",
      "Ep:46, loss:0.00009, loss_test:0.07929, lr:9.51e-03, fs:0.82723 (r=0.798,p=0.859),  time:30.960, tt:1455.126\n",
      "Ep:47, loss:0.00009, loss_test:0.07793, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:30.979, tt:1486.998\n",
      "Ep:48, loss:0.00009, loss_test:0.07776, lr:9.51e-03, fs:0.81675 (r=0.788,p=0.848),  time:30.973, tt:1517.677\n",
      "Ep:49, loss:0.00009, loss_test:0.07848, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.008, tt:1550.403\n",
      "Ep:50, loss:0.00008, loss_test:0.07658, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:31.021, tt:1582.092\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.07726, lr:9.51e-03, fs:0.81250 (r=0.788,p=0.839),  time:31.038, tt:1613.960\n",
      "Ep:52, loss:0.00008, loss_test:0.07646, lr:9.51e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.079, tt:1647.167\n",
      "Ep:53, loss:0.00008, loss_test:0.07589, lr:9.51e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.105, tt:1679.644\n",
      "Ep:54, loss:0.00007, loss_test:0.07658, lr:9.51e-03, fs:0.82105 (r=0.788,p=0.857),  time:31.090, tt:1709.931\n",
      "Ep:55, loss:0.00007, loss_test:0.07572, lr:9.51e-03, fs:0.83249 (r=0.828,p=0.837),  time:31.082, tt:1740.610\n",
      "Ep:56, loss:0.00007, loss_test:0.07685, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.107, tt:1773.116\n",
      "Ep:57, loss:0.00007, loss_test:0.07584, lr:9.51e-03, fs:0.82292 (r=0.798,p=0.849),  time:31.113, tt:1804.570\n",
      "Ep:58, loss:0.00007, loss_test:0.07499, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.111, tt:1835.550\n",
      "Ep:59, loss:0.00006, loss_test:0.07581, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.135, tt:1868.121\n",
      "Ep:60, loss:0.00006, loss_test:0.07441, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.155, tt:1900.457\n",
      "Ep:61, loss:0.00006, loss_test:0.07540, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.161, tt:1931.999\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.07471, lr:9.51e-03, fs:0.84848 (r=0.848,p=0.848),  time:31.174, tt:1963.936\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.07446, lr:9.51e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.148, tt:1993.465\n",
      "Ep:64, loss:0.00006, loss_test:0.07424, lr:9.51e-03, fs:0.83077 (r=0.818,p=0.844),  time:31.150, tt:2024.721\n",
      "Ep:65, loss:0.00006, loss_test:0.07445, lr:9.51e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.143, tt:2055.428\n",
      "Ep:66, loss:0.00005, loss_test:0.07309, lr:9.51e-03, fs:0.84422 (r=0.848,p=0.840),  time:31.153, tt:2087.235\n",
      "Ep:67, loss:0.00005, loss_test:0.07553, lr:9.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.162, tt:2118.982\n",
      "Ep:68, loss:0.00005, loss_test:0.07316, lr:9.51e-03, fs:0.85427 (r=0.859,p=0.850),  time:31.144, tt:2148.942\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.07465, lr:9.51e-03, fs:0.83598 (r=0.798,p=0.878),  time:31.132, tt:2179.236\n",
      "Ep:70, loss:0.00005, loss_test:0.07441, lr:9.51e-03, fs:0.84974 (r=0.828,p=0.872),  time:31.127, tt:2209.999\n",
      "Ep:71, loss:0.00005, loss_test:0.07275, lr:9.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.126, tt:2241.054\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00004, loss_test:0.07493, lr:9.51e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.118, tt:2271.643\n",
      "Ep:73, loss:0.00004, loss_test:0.07294, lr:9.51e-03, fs:0.88000 (r=0.889,p=0.871),  time:31.127, tt:2303.430\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.07333, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.106, tt:2332.939\n",
      "Ep:75, loss:0.00004, loss_test:0.07414, lr:9.51e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.111, tt:2364.458\n",
      "Ep:76, loss:0.00004, loss_test:0.07308, lr:9.51e-03, fs:0.88557 (r=0.899,p=0.873),  time:31.112, tt:2395.609\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.07482, lr:9.51e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.111, tt:2426.697\n",
      "Ep:78, loss:0.00004, loss_test:0.07266, lr:9.51e-03, fs:0.90000 (r=0.909,p=0.891),  time:31.119, tt:2458.391\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.07387, lr:9.51e-03, fs:0.85263 (r=0.818,p=0.890),  time:31.112, tt:2488.972\n",
      "Ep:80, loss:0.00004, loss_test:0.07459, lr:9.51e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.098, tt:2518.907\n",
      "Ep:81, loss:0.00004, loss_test:0.07332, lr:9.51e-03, fs:0.86598 (r=0.848,p=0.884),  time:31.113, tt:2551.230\n",
      "Ep:82, loss:0.00003, loss_test:0.07459, lr:9.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.110, tt:2582.145\n",
      "Ep:83, loss:0.00003, loss_test:0.07381, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.112, tt:2613.404\n",
      "Ep:84, loss:0.00003, loss_test:0.07280, lr:9.51e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.123, tt:2645.451\n",
      "Ep:85, loss:0.00003, loss_test:0.07497, lr:9.51e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.121, tt:2676.444\n",
      "Ep:86, loss:0.00003, loss_test:0.07337, lr:9.51e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.144, tt:2709.504\n",
      "Ep:87, loss:0.00003, loss_test:0.07338, lr:9.51e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.138, tt:2740.112\n",
      "Ep:88, loss:0.00003, loss_test:0.07472, lr:9.51e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.137, tt:2771.228\n",
      "Ep:89, loss:0.00003, loss_test:0.07286, lr:9.51e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.140, tt:2802.608\n",
      "Ep:90, loss:0.00003, loss_test:0.07383, lr:9.41e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.161, tt:2835.613\n",
      "Ep:91, loss:0.00003, loss_test:0.07435, lr:9.32e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.171, tt:2867.725\n",
      "Ep:92, loss:0.00003, loss_test:0.07303, lr:9.23e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.179, tt:2899.622\n",
      "Ep:93, loss:0.00003, loss_test:0.07372, lr:9.14e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.186, tt:2931.462\n",
      "Ep:94, loss:0.00003, loss_test:0.07363, lr:9.04e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.178, tt:2961.898\n",
      "Ep:95, loss:0.00003, loss_test:0.07421, lr:8.95e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.177, tt:2993.037\n",
      "Ep:96, loss:0.00003, loss_test:0.07422, lr:8.86e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.165, tt:3023.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00003, loss_test:0.07466, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.158, tt:3053.503\n",
      "Ep:98, loss:0.00002, loss_test:0.07366, lr:8.69e-03, fs:0.85106 (r=0.808,p=0.899),  time:31.165, tt:3085.318\n",
      "Ep:99, loss:0.00002, loss_test:0.07323, lr:8.60e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.185, tt:3118.474\n",
      "Ep:100, loss:0.00002, loss_test:0.07418, lr:8.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.179, tt:3149.046\n",
      "Ep:101, loss:0.00002, loss_test:0.07344, lr:8.43e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.183, tt:3180.657\n",
      "Ep:102, loss:0.00002, loss_test:0.07399, lr:8.35e-03, fs:0.81967 (r=0.758,p=0.893),  time:31.165, tt:3209.993\n",
      "Ep:103, loss:0.00002, loss_test:0.07355, lr:8.26e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.171, tt:3241.772\n",
      "Ep:104, loss:0.00002, loss_test:0.07409, lr:8.18e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.182, tt:3274.108\n",
      "Ep:105, loss:0.00002, loss_test:0.07430, lr:8.10e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.180, tt:3305.132\n",
      "Ep:106, loss:0.00002, loss_test:0.07334, lr:8.02e-03, fs:0.82979 (r=0.788,p=0.876),  time:31.182, tt:3336.451\n",
      "Ep:107, loss:0.00002, loss_test:0.07423, lr:7.94e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.174, tt:3366.805\n",
      "Ep:108, loss:0.00002, loss_test:0.07374, lr:7.86e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.159, tt:3396.312\n",
      "Ep:109, loss:0.00002, loss_test:0.07369, lr:7.78e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.165, tt:3428.171\n",
      "Ep:110, loss:0.00002, loss_test:0.07420, lr:7.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.154, tt:3458.131\n",
      "Ep:111, loss:0.00002, loss_test:0.07384, lr:7.62e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.150, tt:3488.774\n",
      "Ep:112, loss:0.00002, loss_test:0.07370, lr:7.55e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.152, tt:3520.161\n",
      "Ep:113, loss:0.00002, loss_test:0.07415, lr:7.47e-03, fs:0.82162 (r=0.768,p=0.884),  time:31.139, tt:3549.805\n",
      "Ep:114, loss:0.00002, loss_test:0.07314, lr:7.40e-03, fs:0.82162 (r=0.768,p=0.884),  time:31.153, tt:3582.601\n",
      "Ep:115, loss:0.00002, loss_test:0.07408, lr:7.32e-03, fs:0.80874 (r=0.747,p=0.881),  time:31.148, tt:3613.129\n",
      "Ep:116, loss:0.00002, loss_test:0.07400, lr:7.25e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.154, tt:3644.981\n",
      "Ep:117, loss:0.00002, loss_test:0.07435, lr:7.18e-03, fs:0.81967 (r=0.758,p=0.893),  time:31.153, tt:3676.032\n",
      "Ep:118, loss:0.00002, loss_test:0.07435, lr:7.11e-03, fs:0.79558 (r=0.727,p=0.878),  time:31.144, tt:3706.095\n",
      "Ep:119, loss:0.00002, loss_test:0.07450, lr:7.03e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.151, tt:3738.150\n",
      "Ep:120, loss:0.00002, loss_test:0.07453, lr:6.96e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.142, tt:3768.186\n",
      "Ep:121, loss:0.00002, loss_test:0.07340, lr:6.89e-03, fs:0.81522 (r=0.758,p=0.882),  time:31.152, tt:3800.605\n",
      "Ep:122, loss:0.00002, loss_test:0.07383, lr:6.83e-03, fs:0.81967 (r=0.758,p=0.893),  time:31.145, tt:3830.816\n",
      "Ep:123, loss:0.00002, loss_test:0.07429, lr:6.76e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.140, tt:3861.352\n",
      "Ep:124, loss:0.00002, loss_test:0.07381, lr:6.69e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:3892.279\n",
      "Ep:125, loss:0.00002, loss_test:0.07414, lr:6.62e-03, fs:0.80663 (r=0.737,p=0.890),  time:31.140, tt:3923.690\n",
      "Ep:126, loss:0.00002, loss_test:0.07376, lr:6.56e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.150, tt:3956.097\n",
      "Ep:127, loss:0.00002, loss_test:0.07358, lr:6.49e-03, fs:0.81081 (r=0.758,p=0.872),  time:31.157, tt:3988.101\n",
      "Ep:128, loss:0.00002, loss_test:0.07413, lr:6.43e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.140, tt:4017.092\n",
      "Ep:129, loss:0.00002, loss_test:0.07425, lr:6.36e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.145, tt:4048.855\n",
      "Ep:130, loss:0.00002, loss_test:0.07402, lr:6.30e-03, fs:0.80000 (r=0.727,p=0.889),  time:31.142, tt:4079.582\n",
      "Ep:131, loss:0.00002, loss_test:0.07382, lr:6.24e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.145, tt:4111.105\n",
      "Ep:132, loss:0.00002, loss_test:0.07416, lr:6.17e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.135, tt:4141.005\n",
      "Ep:133, loss:0.00002, loss_test:0.07419, lr:6.11e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.131, tt:4171.496\n",
      "Ep:134, loss:0.00002, loss_test:0.07439, lr:6.05e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.133, tt:4202.959\n",
      "Ep:135, loss:0.00002, loss_test:0.07385, lr:5.99e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.144, tt:4235.580\n",
      "Ep:136, loss:0.00001, loss_test:0.07314, lr:5.93e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.139, tt:4266.071\n",
      "Ep:137, loss:0.00001, loss_test:0.07455, lr:5.87e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.135, tt:4296.631\n",
      "Ep:138, loss:0.00001, loss_test:0.07423, lr:5.81e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.125, tt:4326.322\n",
      "Ep:139, loss:0.00001, loss_test:0.07345, lr:5.75e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.121, tt:4356.954\n",
      "Ep:140, loss:0.00001, loss_test:0.07452, lr:5.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.120, tt:4387.934\n",
      "Ep:141, loss:0.00001, loss_test:0.07446, lr:5.64e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.135, tt:4421.102\n",
      "Ep:142, loss:0.00001, loss_test:0.07362, lr:5.58e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.128, tt:4451.365\n",
      "Ep:143, loss:0.00001, loss_test:0.07367, lr:5.53e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.129, tt:4482.548\n",
      "Ep:144, loss:0.00001, loss_test:0.07418, lr:5.47e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.132, tt:4514.180\n",
      "Ep:145, loss:0.00001, loss_test:0.07389, lr:5.42e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:4546.076\n",
      "Ep:146, loss:0.00001, loss_test:0.07406, lr:5.36e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.142, tt:4577.869\n",
      "Ep:147, loss:0.00001, loss_test:0.07434, lr:5.31e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.136, tt:4608.180\n",
      "Ep:148, loss:0.00001, loss_test:0.07419, lr:5.26e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.135, tt:4639.147\n",
      "Ep:149, loss:0.00001, loss_test:0.07380, lr:5.20e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.141, tt:4671.096\n",
      "Ep:150, loss:0.00001, loss_test:0.07392, lr:5.15e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.128, tt:4700.367\n",
      "Ep:151, loss:0.00001, loss_test:0.07437, lr:5.10e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.141, tt:4733.474\n",
      "Ep:152, loss:0.00001, loss_test:0.07393, lr:5.05e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.143, tt:4764.835\n",
      "Ep:153, loss:0.00001, loss_test:0.07390, lr:5.00e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:4795.314\n",
      "Ep:154, loss:0.00001, loss_test:0.07438, lr:4.95e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:4826.453\n",
      "Ep:155, loss:0.00001, loss_test:0.07412, lr:4.90e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.139, tt:4857.613\n",
      "Ep:156, loss:0.00001, loss_test:0.07369, lr:4.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:4888.716\n",
      "Ep:157, loss:0.00001, loss_test:0.07419, lr:4.80e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.131, tt:4918.743\n",
      "Ep:158, loss:0.00001, loss_test:0.07419, lr:4.75e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.138, tt:4951.019\n",
      "Ep:159, loss:0.00001, loss_test:0.07414, lr:4.71e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.144, tt:4983.058\n",
      "Ep:160, loss:0.00001, loss_test:0.07447, lr:4.66e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.142, tt:5013.925\n",
      "Ep:161, loss:0.00001, loss_test:0.07430, lr:4.61e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.145, tt:5045.493\n",
      "Ep:162, loss:0.00001, loss_test:0.07430, lr:4.57e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.157, tt:5078.572\n",
      "Ep:163, loss:0.00001, loss_test:0.07399, lr:4.52e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.158, tt:5109.940\n",
      "Ep:164, loss:0.00001, loss_test:0.07376, lr:4.48e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.152, tt:5140.135\n",
      "Ep:165, loss:0.00001, loss_test:0.07439, lr:4.43e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.155, tt:5171.742\n",
      "Ep:166, loss:0.00001, loss_test:0.07432, lr:4.39e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.160, tt:5203.769\n",
      "Ep:167, loss:0.00001, loss_test:0.07406, lr:4.34e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.168, tt:5236.179\n",
      "Ep:168, loss:0.00001, loss_test:0.07423, lr:4.30e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.163, tt:5266.590\n",
      "Ep:169, loss:0.00001, loss_test:0.07422, lr:4.26e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.170, tt:5298.893\n",
      "Ep:170, loss:0.00001, loss_test:0.07423, lr:4.21e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.168, tt:5329.688\n",
      "Ep:171, loss:0.00001, loss_test:0.07427, lr:4.17e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.174, tt:5362.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:172, loss:0.00001, loss_test:0.07430, lr:4.13e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.175, tt:5393.339\n",
      "Ep:173, loss:0.00001, loss_test:0.07450, lr:4.09e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.179, tt:5425.063\n",
      "Ep:174, loss:0.00001, loss_test:0.07447, lr:4.05e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.185, tt:5457.362\n",
      "Ep:175, loss:0.00001, loss_test:0.07396, lr:4.01e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.186, tt:5488.773\n",
      "Ep:176, loss:0.00001, loss_test:0.07457, lr:3.97e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.186, tt:5519.945\n",
      "Ep:177, loss:0.00001, loss_test:0.07454, lr:3.93e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.177, tt:5549.417\n",
      "Ep:178, loss:0.00001, loss_test:0.07439, lr:3.89e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.161, tt:5577.884\n",
      "Ep:179, loss:0.00001, loss_test:0.07409, lr:3.85e-03, fs:0.80220 (r=0.737,p=0.880),  time:31.159, tt:5608.672\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14126, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:53.228, tt:53.228\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13720, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:53.445, tt:106.891\n",
      "Ep:2, loss:0.00053, loss_test:0.12810, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:56.234, tt:168.702\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.11612, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:57.909, tt:231.636\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00046, loss_test:0.11107, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:58.978, tt:294.889\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.10862, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:59.974, tt:359.843\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.10407, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:60.619, tt:424.333\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.10220, lr:1.00e-02, fs:0.73148 (r=0.798,p=0.675),  time:61.478, tt:491.823\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00037, loss_test:0.09969, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:61.435, tt:552.913\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00036, loss_test:0.09623, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:61.550, tt:615.499\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.09435, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:61.783, tt:679.609\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00033, loss_test:0.09237, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:62.133, tt:745.591\n",
      "Ep:12, loss:0.00031, loss_test:0.09090, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:62.389, tt:811.058\n",
      "Ep:13, loss:0.00030, loss_test:0.08890, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:62.586, tt:876.197\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.08652, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:62.632, tt:939.481\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.08472, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:62.656, tt:1002.494\n",
      "Ep:16, loss:0.00026, loss_test:0.08218, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:62.692, tt:1065.769\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.08196, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:62.825, tt:1130.849\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.08177, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:62.908, tt:1195.257\n",
      "Ep:19, loss:0.00023, loss_test:0.07890, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:63.035, tt:1260.699\n",
      "Ep:20, loss:0.00022, loss_test:0.07900, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:63.067, tt:1324.402\n",
      "Ep:21, loss:0.00021, loss_test:0.07761, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:63.140, tt:1389.078\n",
      "Ep:22, loss:0.00020, loss_test:0.08016, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:63.115, tt:1451.641\n",
      "Ep:23, loss:0.00018, loss_test:0.07932, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:63.247, tt:1517.924\n",
      "Ep:24, loss:0.00018, loss_test:0.07758, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:63.317, tt:1582.932\n",
      "Ep:25, loss:0.00017, loss_test:0.07902, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:63.416, tt:1648.811\n",
      "Ep:26, loss:0.00016, loss_test:0.07847, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:63.548, tt:1715.802\n",
      "Ep:27, loss:0.00015, loss_test:0.08084, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:63.673, tt:1782.854\n",
      "Ep:28, loss:0.00014, loss_test:0.07983, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:63.707, tt:1847.493\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.08168, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:63.866, tt:1915.987\n",
      "Ep:30, loss:0.00013, loss_test:0.08181, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:63.984, tt:1983.518\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07958, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:63.928, tt:2045.688\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08081, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:64.014, tt:2112.457\n",
      "Ep:33, loss:0.00010, loss_test:0.08056, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:64.045, tt:2177.522\n",
      "Ep:34, loss:0.00010, loss_test:0.08094, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:64.103, tt:2243.594\n",
      "Ep:35, loss:0.00010, loss_test:0.08038, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:64.112, tt:2308.045\n",
      "Ep:36, loss:0.00009, loss_test:0.07799, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:64.106, tt:2371.925\n",
      "Ep:37, loss:0.00009, loss_test:0.07890, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:64.135, tt:2437.149\n",
      "Ep:38, loss:0.00008, loss_test:0.07906, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:64.145, tt:2501.668\n",
      "Ep:39, loss:0.00008, loss_test:0.07800, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:64.134, tt:2565.368\n",
      "Ep:40, loss:0.00007, loss_test:0.07850, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:64.140, tt:2629.742\n",
      "Ep:41, loss:0.00007, loss_test:0.07910, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:64.119, tt:2693.006\n",
      "Ep:42, loss:0.00007, loss_test:0.08406, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:64.147, tt:2758.306\n",
      "Ep:43, loss:0.00007, loss_test:0.08288, lr:9.90e-03, fs:0.81319 (r=0.747,p=0.892),  time:64.215, tt:2825.453\n",
      "Ep:44, loss:0.00006, loss_test:0.07927, lr:9.80e-03, fs:0.81111 (r=0.737,p=0.901),  time:64.190, tt:2888.564\n",
      "Ep:45, loss:0.00006, loss_test:0.08341, lr:9.70e-03, fs:0.80000 (r=0.707,p=0.921),  time:64.208, tt:2953.587\n",
      "Ep:46, loss:0.00006, loss_test:0.08433, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:64.168, tt:3015.887\n",
      "Ep:47, loss:0.00005, loss_test:0.08089, lr:9.51e-03, fs:0.81111 (r=0.737,p=0.901),  time:64.168, tt:3080.078\n",
      "Ep:48, loss:0.00005, loss_test:0.08943, lr:9.41e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.195, tt:3145.565\n",
      "Ep:49, loss:0.00005, loss_test:0.08539, lr:9.32e-03, fs:0.78161 (r=0.687,p=0.907),  time:64.209, tt:3210.444\n",
      "Ep:50, loss:0.00005, loss_test:0.08307, lr:9.23e-03, fs:0.80447 (r=0.727,p=0.900),  time:64.216, tt:3275.015\n",
      "Ep:51, loss:0.00005, loss_test:0.08807, lr:9.14e-03, fs:0.77647 (r=0.667,p=0.930),  time:64.185, tt:3337.607\n",
      "Ep:52, loss:0.00005, loss_test:0.08722, lr:9.04e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.171, tt:3401.090\n",
      "Ep:53, loss:0.00005, loss_test:0.08741, lr:8.95e-03, fs:0.77193 (r=0.667,p=0.917),  time:64.143, tt:3463.741\n",
      "Ep:54, loss:0.00004, loss_test:0.08724, lr:8.86e-03, fs:0.75449 (r=0.636,p=0.926),  time:64.133, tt:3527.297\n",
      "Ep:55, loss:0.00004, loss_test:0.09083, lr:8.78e-03, fs:0.75294 (r=0.646,p=0.901),  time:64.148, tt:3592.274\n",
      "Ep:56, loss:0.00004, loss_test:0.08580, lr:8.69e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.165, tt:3657.401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00004, loss_test:0.08944, lr:8.60e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.194, tt:3723.272\n",
      "Ep:58, loss:0.00004, loss_test:0.08680, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.198, tt:3787.712\n",
      "Ep:59, loss:0.00004, loss_test:0.08471, lr:8.43e-03, fs:0.77193 (r=0.667,p=0.917),  time:64.199, tt:3851.944\n",
      "Ep:60, loss:0.00004, loss_test:0.09156, lr:8.35e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.210, tt:3916.839\n",
      "Ep:61, loss:0.00003, loss_test:0.08962, lr:8.26e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.201, tt:3980.459\n",
      "Ep:62, loss:0.00003, loss_test:0.08821, lr:8.18e-03, fs:0.75740 (r=0.646,p=0.914),  time:64.196, tt:4044.318\n",
      "Ep:63, loss:0.00003, loss_test:0.09231, lr:8.10e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.218, tt:4109.953\n",
      "Ep:64, loss:0.00003, loss_test:0.09218, lr:8.02e-03, fs:0.67925 (r=0.545,p=0.900),  time:64.213, tt:4173.825\n",
      "Ep:65, loss:0.00003, loss_test:0.09470, lr:7.94e-03, fs:0.68354 (r=0.545,p=0.915),  time:64.237, tt:4239.621\n",
      "Ep:66, loss:0.00003, loss_test:0.08759, lr:7.86e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.207, tt:4301.879\n",
      "Ep:67, loss:0.00003, loss_test:0.09229, lr:7.78e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.224, tt:4367.210\n",
      "Ep:68, loss:0.00003, loss_test:0.09075, lr:7.70e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.209, tt:4430.410\n",
      "Ep:69, loss:0.00003, loss_test:0.09038, lr:7.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.231, tt:4496.157\n",
      "Ep:70, loss:0.00003, loss_test:0.09136, lr:7.55e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.232, tt:4560.463\n",
      "Ep:71, loss:0.00003, loss_test:0.09064, lr:7.47e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.222, tt:4624.009\n",
      "Ep:72, loss:0.00002, loss_test:0.09425, lr:7.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.251, tt:4690.301\n",
      "Ep:73, loss:0.00002, loss_test:0.09300, lr:7.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.248, tt:4754.359\n",
      "Ep:74, loss:0.00002, loss_test:0.09022, lr:7.25e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.228, tt:4817.110\n",
      "Ep:75, loss:0.00002, loss_test:0.09411, lr:7.18e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.238, tt:4882.097\n",
      "Ep:76, loss:0.00002, loss_test:0.09283, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.239, tt:4946.431\n",
      "Ep:77, loss:0.00002, loss_test:0.09787, lr:7.03e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.234, tt:5010.270\n",
      "Ep:78, loss:0.00002, loss_test:0.09405, lr:6.96e-03, fs:0.64052 (r=0.495,p=0.907),  time:64.220, tt:5073.350\n",
      "Ep:79, loss:0.00002, loss_test:0.09860, lr:6.89e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.216, tt:5137.305\n",
      "Ep:80, loss:0.00002, loss_test:0.09212, lr:6.83e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.247, tt:5204.045\n",
      "Ep:81, loss:0.00002, loss_test:0.09476, lr:6.76e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.248, tt:5268.325\n",
      "Ep:82, loss:0.00002, loss_test:0.09522, lr:6.69e-03, fs:0.64052 (r=0.495,p=0.907),  time:64.235, tt:5331.520\n",
      "Ep:83, loss:0.00002, loss_test:0.09621, lr:6.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.241, tt:5396.206\n",
      "Ep:84, loss:0.00002, loss_test:0.09305, lr:6.56e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.248, tt:5461.117\n",
      "Ep:85, loss:0.00002, loss_test:0.09677, lr:6.49e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.268, tt:5527.031\n",
      "Ep:86, loss:0.00002, loss_test:0.09399, lr:6.43e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.262, tt:5590.773\n",
      "Ep:87, loss:0.00002, loss_test:0.09460, lr:6.36e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.267, tt:5655.470\n",
      "Ep:88, loss:0.00002, loss_test:0.09496, lr:6.30e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.277, tt:5720.671\n",
      "Ep:89, loss:0.00002, loss_test:0.09493, lr:6.24e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.284, tt:5785.535\n",
      "Ep:90, loss:0.00002, loss_test:0.09452, lr:6.17e-03, fs:0.76190 (r=0.646,p=0.928),  time:64.299, tt:5851.170\n",
      "Ep:91, loss:0.00002, loss_test:0.09544, lr:6.11e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.287, tt:5914.377\n",
      "Ep:92, loss:0.00002, loss_test:0.09502, lr:6.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:64.280, tt:5978.056\n",
      "Ep:93, loss:0.00002, loss_test:0.09564, lr:5.99e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.251, tt:6039.608\n",
      "Ep:94, loss:0.00002, loss_test:0.09611, lr:5.93e-03, fs:0.76647 (r=0.646,p=0.941),  time:64.253, tt:6104.020\n",
      "Ep:95, loss:0.00002, loss_test:0.09478, lr:5.87e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.265, tt:6169.448\n",
      "Ep:96, loss:0.00002, loss_test:0.09671, lr:5.81e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.270, tt:6234.199\n",
      "Ep:97, loss:0.00002, loss_test:0.09530, lr:5.75e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.278, tt:6299.238\n",
      "Ep:98, loss:0.00002, loss_test:0.09714, lr:5.70e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.273, tt:6363.026\n",
      "Ep:99, loss:0.00002, loss_test:0.09607, lr:5.64e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.261, tt:6426.116\n",
      "Ep:100, loss:0.00001, loss_test:0.09581, lr:5.58e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.282, tt:6492.472\n",
      "Ep:101, loss:0.00001, loss_test:0.09478, lr:5.53e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.256, tt:6554.075\n",
      "Ep:102, loss:0.00001, loss_test:0.09619, lr:5.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.265, tt:6619.338\n",
      "Ep:103, loss:0.00001, loss_test:0.09518, lr:5.42e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.267, tt:6683.717\n",
      "Ep:104, loss:0.00001, loss_test:0.09836, lr:5.36e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.270, tt:6748.341\n",
      "Ep:105, loss:0.00001, loss_test:0.09536, lr:5.31e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.256, tt:6811.097\n",
      "Ep:106, loss:0.00001, loss_test:0.09847, lr:5.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.255, tt:6875.296\n",
      "Ep:107, loss:0.00001, loss_test:0.09654, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.263, tt:6940.367\n",
      "Ep:108, loss:0.00001, loss_test:0.09718, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.271, tt:7005.530\n",
      "Ep:109, loss:0.00001, loss_test:0.09796, lr:5.10e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.284, tt:7071.294\n",
      "Ep:110, loss:0.00001, loss_test:0.09700, lr:5.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.264, tt:7133.325\n",
      "Ep:111, loss:0.00001, loss_test:0.09691, lr:5.00e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.266, tt:7197.756\n",
      "Ep:112, loss:0.00001, loss_test:0.09673, lr:4.95e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.275, tt:7263.039\n",
      "Ep:113, loss:0.00001, loss_test:0.09656, lr:4.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.273, tt:7327.178\n",
      "Ep:114, loss:0.00001, loss_test:0.09711, lr:4.85e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.267, tt:7390.709\n",
      "Ep:115, loss:0.00001, loss_test:0.09678, lr:4.80e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.249, tt:7452.876\n",
      "Ep:116, loss:0.00001, loss_test:0.09653, lr:4.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:64.255, tt:7517.855\n",
      "Ep:117, loss:0.00001, loss_test:0.09644, lr:4.71e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.247, tt:7581.139\n",
      "Ep:118, loss:0.00001, loss_test:0.09679, lr:4.66e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.214, tt:7641.408\n",
      "Ep:119, loss:0.00001, loss_test:0.09669, lr:4.61e-03, fs:0.77576 (r=0.646,p=0.970),  time:64.238, tt:7708.577\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14286, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:56.926, tt:56.926\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13896, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:56.645, tt:113.290\n",
      "Ep:2, loss:0.00052, loss_test:0.12961, lr:1.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:57.431, tt:172.292\n",
      "Ep:3, loss:0.00048, loss_test:0.12031, lr:1.00e-02, fs:0.65438 (r=0.717,p=0.602),  time:59.126, tt:236.504\n",
      "Ep:4, loss:0.00045, loss_test:0.11698, lr:1.00e-02, fs:0.62745 (r=0.646,p=0.610),  time:60.030, tt:300.151\n",
      "Ep:5, loss:0.00043, loss_test:0.11406, lr:1.00e-02, fs:0.64840 (r=0.717,p=0.592),  time:60.591, tt:363.546\n",
      "Ep:6, loss:0.00041, loss_test:0.11178, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:61.507, tt:430.549\n",
      "Ep:7, loss:0.00039, loss_test:0.11127, lr:1.00e-02, fs:0.67317 (r=0.697,p=0.651),  time:61.565, tt:492.516\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00037, loss_test:0.10707, lr:1.00e-02, fs:0.68657 (r=0.697,p=0.676),  time:62.181, tt:559.634\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.10588, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:62.245, tt:622.452\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.10383, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:62.613, tt:688.741\n",
      "Ep:11, loss:0.00031, loss_test:0.10249, lr:1.00e-02, fs:0.70051 (r=0.697,p=0.704),  time:62.936, tt:755.236\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.10181, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:63.158, tt:821.050\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.10247, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:63.297, tt:886.164\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.10118, lr:1.00e-02, fs:0.70833 (r=0.687,p=0.731),  time:63.485, tt:952.274\n",
      "Ep:15, loss:0.00026, loss_test:0.10176, lr:1.00e-02, fs:0.70103 (r=0.687,p=0.716),  time:63.610, tt:1017.758\n",
      "Ep:16, loss:0.00025, loss_test:0.10081, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:63.708, tt:1083.029\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.10020, lr:1.00e-02, fs:0.72727 (r=0.687,p=0.773),  time:63.823, tt:1148.819\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.09976, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:63.867, tt:1213.481\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.10036, lr:1.00e-02, fs:0.74725 (r=0.687,p=0.819),  time:63.937, tt:1278.749\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10077, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:64.019, tt:1344.398\n",
      "Ep:21, loss:0.00020, loss_test:0.09985, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:64.079, tt:1409.741\n",
      "Ep:22, loss:0.00019, loss_test:0.09977, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:64.078, tt:1473.797\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.10103, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:64.095, tt:1538.281\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09918, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:64.159, tt:1603.975\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.10182, lr:1.00e-02, fs:0.75281 (r=0.677,p=0.848),  time:64.172, tt:1668.467\n",
      "Ep:26, loss:0.00015, loss_test:0.10147, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:64.205, tt:1733.527\n",
      "Ep:27, loss:0.00014, loss_test:0.10103, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:64.265, tt:1799.423\n",
      "Ep:28, loss:0.00014, loss_test:0.09864, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:64.319, tt:1865.261\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.10278, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:64.275, tt:1928.239\n",
      "Ep:30, loss:0.00013, loss_test:0.10229, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:64.371, tt:1995.503\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.10229, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:64.359, tt:2059.488\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.09605, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:64.347, tt:2123.456\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.10428, lr:1.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:64.313, tt:2186.649\n",
      "Ep:34, loss:0.00010, loss_test:0.10144, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:64.369, tt:2252.926\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.10307, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:64.363, tt:2317.052\n",
      "Ep:36, loss:0.00009, loss_test:0.10210, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:64.434, tt:2384.045\n",
      "Ep:37, loss:0.00009, loss_test:0.10362, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:64.395, tt:2447.016\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.10677, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:64.374, tt:2510.575\n",
      "Ep:39, loss:0.00008, loss_test:0.10272, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:64.338, tt:2573.523\n",
      "Ep:40, loss:0.00008, loss_test:0.10157, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:64.396, tt:2640.253\n",
      "Ep:41, loss:0.00008, loss_test:0.10547, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:64.424, tt:2705.805\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.10467, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:64.371, tt:2767.950\n",
      "Ep:43, loss:0.00007, loss_test:0.10601, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:64.370, tt:2832.302\n",
      "Ep:44, loss:0.00007, loss_test:0.10592, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:64.420, tt:2898.910\n",
      "Ep:45, loss:0.00006, loss_test:0.10455, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:64.414, tt:2963.047\n",
      "Ep:46, loss:0.00006, loss_test:0.10513, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:64.452, tt:3029.260\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.11126, lr:1.00e-02, fs:0.81356 (r=0.727,p=0.923),  time:64.452, tt:3093.673\n",
      "Ep:48, loss:0.00006, loss_test:0.10408, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:64.446, tt:3157.864\n",
      "Ep:49, loss:0.00006, loss_test:0.10566, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:64.469, tt:3223.431\n",
      "Ep:50, loss:0.00006, loss_test:0.10977, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:64.501, tt:3289.543\n",
      "Ep:51, loss:0.00006, loss_test:0.10889, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:64.530, tt:3355.558\n",
      "Ep:52, loss:0.00006, loss_test:0.11331, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:64.531, tt:3420.137\n",
      "Ep:53, loss:0.00006, loss_test:0.11233, lr:1.00e-02, fs:0.80233 (r=0.697,p=0.945),  time:64.569, tt:3486.740\n",
      "Ep:54, loss:0.00005, loss_test:0.10839, lr:1.00e-02, fs:0.77108 (r=0.646,p=0.955),  time:64.625, tt:3554.383\n",
      "Ep:55, loss:0.00006, loss_test:0.11053, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:64.622, tt:3618.850\n",
      "Ep:56, loss:0.00005, loss_test:0.10290, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:64.666, tt:3685.938\n",
      "Ep:57, loss:0.00005, loss_test:0.10866, lr:1.00e-02, fs:0.78824 (r=0.677,p=0.944),  time:64.698, tt:3752.511\n",
      "Ep:58, loss:0.00004, loss_test:0.10623, lr:9.90e-03, fs:0.80460 (r=0.707,p=0.933),  time:64.701, tt:3817.370\n",
      "Ep:59, loss:0.00004, loss_test:0.10723, lr:9.80e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.690, tt:3881.429\n",
      "Ep:60, loss:0.00004, loss_test:0.10656, lr:9.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.645, tt:3943.352\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.10822, lr:9.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:64.659, tt:4008.837\n",
      "Ep:62, loss:0.00004, loss_test:0.10571, lr:9.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.696, tt:4075.829\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.10773, lr:9.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:64.718, tt:4141.950\n",
      "Ep:64, loss:0.00003, loss_test:0.10912, lr:9.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.723, tt:4206.965\n",
      "Ep:65, loss:0.00003, loss_test:0.10764, lr:9.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:64.680, tt:4268.856\n",
      "Ep:66, loss:0.00003, loss_test:0.10683, lr:9.70e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.670, tt:4332.879\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00003, loss_test:0.11087, lr:9.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:64.668, tt:4397.415\n",
      "Ep:68, loss:0.00003, loss_test:0.10549, lr:9.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:64.662, tt:4461.686\n",
      "Ep:69, loss:0.00003, loss_test:0.11032, lr:9.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:64.664, tt:4526.474\n",
      "Ep:70, loss:0.00003, loss_test:0.10992, lr:9.70e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.683, tt:4592.457\n",
      "Ep:71, loss:0.00003, loss_test:0.10822, lr:9.70e-03, fs:0.81395 (r=0.707,p=0.959),  time:64.698, tt:4658.261\n",
      "Ep:72, loss:0.00003, loss_test:0.10853, lr:9.70e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.678, tt:4721.464\n",
      "Ep:73, loss:0.00003, loss_test:0.11110, lr:9.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:64.670, tt:4785.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00003, loss_test:0.11060, lr:9.70e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.688, tt:4851.594\n",
      "Ep:75, loss:0.00003, loss_test:0.11224, lr:9.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:64.689, tt:4916.392\n",
      "Ep:76, loss:0.00002, loss_test:0.10977, lr:9.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.651, tt:4978.159\n",
      "Ep:77, loss:0.00002, loss_test:0.10913, lr:9.70e-03, fs:0.79290 (r=0.677,p=0.957),  time:64.652, tt:5042.870\n",
      "Ep:78, loss:0.00002, loss_test:0.11110, lr:9.61e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.646, tt:5107.025\n",
      "Ep:79, loss:0.00002, loss_test:0.11051, lr:9.51e-03, fs:0.72500 (r=0.586,p=0.951),  time:64.648, tt:5171.833\n",
      "Ep:80, loss:0.00002, loss_test:0.11045, lr:9.41e-03, fs:0.74074 (r=0.606,p=0.952),  time:64.647, tt:5236.436\n",
      "Ep:81, loss:0.00002, loss_test:0.11058, lr:9.32e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.642, tt:5300.675\n",
      "Ep:82, loss:0.00002, loss_test:0.11244, lr:9.23e-03, fs:0.71698 (r=0.576,p=0.950),  time:64.648, tt:5365.790\n",
      "Ep:83, loss:0.00002, loss_test:0.10884, lr:9.14e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.644, tt:5430.076\n",
      "Ep:84, loss:0.00002, loss_test:0.11250, lr:9.04e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.646, tt:5494.876\n",
      "Ep:85, loss:0.00002, loss_test:0.11160, lr:8.95e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.648, tt:5559.765\n",
      "Ep:86, loss:0.00002, loss_test:0.11151, lr:8.86e-03, fs:0.72956 (r=0.586,p=0.967),  time:64.646, tt:5624.205\n",
      "Ep:87, loss:0.00002, loss_test:0.11094, lr:8.78e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.670, tt:5690.978\n",
      "Ep:88, loss:0.00002, loss_test:0.11084, lr:8.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.651, tt:5753.900\n",
      "Ep:89, loss:0.00002, loss_test:0.11382, lr:8.60e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.671, tt:5820.404\n",
      "Ep:90, loss:0.00002, loss_test:0.11157, lr:8.51e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.663, tt:5884.339\n",
      "Ep:91, loss:0.00002, loss_test:0.11177, lr:8.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.661, tt:5948.799\n",
      "Ep:92, loss:0.00002, loss_test:0.11272, lr:8.35e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.670, tt:6014.282\n",
      "Ep:93, loss:0.00001, loss_test:0.11080, lr:8.26e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.666, tt:6078.622\n",
      "Ep:94, loss:0.00001, loss_test:0.11307, lr:8.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.665, tt:6143.201\n",
      "Ep:95, loss:0.00001, loss_test:0.11328, lr:8.10e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.679, tt:6209.200\n",
      "Ep:96, loss:0.00001, loss_test:0.11112, lr:8.02e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.687, tt:6274.676\n",
      "Ep:97, loss:0.00001, loss_test:0.11354, lr:7.94e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.690, tt:6339.668\n",
      "Ep:98, loss:0.00001, loss_test:0.11281, lr:7.86e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.678, tt:6403.083\n",
      "Ep:99, loss:0.00001, loss_test:0.11141, lr:7.78e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.670, tt:6467.034\n",
      "Ep:100, loss:0.00001, loss_test:0.11157, lr:7.70e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.678, tt:6532.522\n",
      "Ep:101, loss:0.00001, loss_test:0.11438, lr:7.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.664, tt:6595.714\n",
      "Ep:102, loss:0.00001, loss_test:0.11215, lr:7.55e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.664, tt:6660.365\n",
      "Ep:103, loss:0.00001, loss_test:0.11500, lr:7.47e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.673, tt:6725.976\n",
      "Ep:104, loss:0.00001, loss_test:0.11400, lr:7.40e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.678, tt:6791.223\n",
      "Ep:105, loss:0.00001, loss_test:0.11402, lr:7.32e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.676, tt:6855.663\n",
      "Ep:106, loss:0.00001, loss_test:0.11440, lr:7.25e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.668, tt:6919.529\n",
      "Ep:107, loss:0.00001, loss_test:0.11294, lr:7.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.671, tt:6984.453\n",
      "Ep:108, loss:0.00001, loss_test:0.11329, lr:7.11e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.669, tt:7048.904\n",
      "Ep:109, loss:0.00001, loss_test:0.11383, lr:7.03e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.672, tt:7113.935\n",
      "Ep:110, loss:0.00001, loss_test:0.11339, lr:6.96e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.649, tt:7176.062\n",
      "Ep:111, loss:0.00001, loss_test:0.11574, lr:6.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.643, tt:7240.022\n",
      "Ep:112, loss:0.00001, loss_test:0.11371, lr:6.83e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.631, tt:7303.305\n",
      "Ep:113, loss:0.00001, loss_test:0.11441, lr:6.76e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.628, tt:7367.604\n",
      "Ep:114, loss:0.00001, loss_test:0.11237, lr:6.69e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.648, tt:7434.524\n",
      "Ep:115, loss:0.00001, loss_test:0.11471, lr:6.62e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.660, tt:7500.616\n",
      "Ep:116, loss:0.00001, loss_test:0.11355, lr:6.56e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.659, tt:7565.131\n",
      "Ep:117, loss:0.00001, loss_test:0.11263, lr:6.49e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.648, tt:7628.502\n",
      "Ep:118, loss:0.00001, loss_test:0.11534, lr:6.43e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.648, tt:7693.125\n",
      "Ep:119, loss:0.00001, loss_test:0.11257, lr:6.36e-03, fs:0.72152 (r=0.576,p=0.966),  time:64.654, tt:7758.509\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00084, loss_test:0.13993, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:84.208, tt:84.208\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00080, loss_test:0.12955, lr:1.00e-02, fs:0.65169 (r=0.879,p=0.518),  time:87.560, tt:175.119\n",
      "Ep:2, loss:0.00072, loss_test:0.11953, lr:1.00e-02, fs:0.66079 (r=0.758,p=0.586),  time:89.775, tt:269.325\n",
      "Ep:3, loss:0.00066, loss_test:0.11252, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:91.320, tt:365.279\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00060, loss_test:0.10646, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:93.387, tt:466.933\n",
      "Ep:5, loss:0.00055, loss_test:0.10203, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:93.826, tt:562.956\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00052, loss_test:0.09772, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:94.613, tt:662.294\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00048, loss_test:0.09425, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:95.446, tt:763.567\n",
      "Ep:8, loss:0.00046, loss_test:0.09145, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:95.973, tt:863.755\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00043, loss_test:0.08924, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:96.172, tt:961.717\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00041, loss_test:0.08370, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:96.198, tt:1058.183\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00039, loss_test:0.08144, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:96.521, tt:1158.248\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00036, loss_test:0.07912, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:96.649, tt:1256.434\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00034, loss_test:0.07758, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:96.783, tt:1354.956\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00031, loss_test:0.07628, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:97.029, tt:1455.430\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00029, loss_test:0.07524, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:97.058, tt:1552.936\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.07339, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:97.257, tt:1653.374\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.07377, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:97.286, tt:1751.144\n",
      "Ep:18, loss:0.00022, loss_test:0.07178, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:97.478, tt:1852.079\n",
      "Ep:19, loss:0.00020, loss_test:0.07391, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:97.577, tt:1951.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:20, loss:0.00019, loss_test:0.07179, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:97.617, tt:2049.963\n",
      "Ep:21, loss:0.00017, loss_test:0.07301, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:97.692, tt:2149.234\n",
      "Ep:22, loss:0.00016, loss_test:0.07146, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:97.586, tt:2244.488\n",
      "Ep:23, loss:0.00014, loss_test:0.07169, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:97.670, tt:2344.079\n",
      "Ep:24, loss:0.00014, loss_test:0.07444, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:97.683, tt:2442.066\n",
      "Ep:25, loss:0.00013, loss_test:0.07148, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:97.723, tt:2540.809\n",
      "Ep:26, loss:0.00011, loss_test:0.07161, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:97.775, tt:2639.925\n",
      "Ep:27, loss:0.00011, loss_test:0.07333, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:97.820, tt:2738.968\n",
      "Ep:28, loss:0.00010, loss_test:0.07415, lr:9.90e-03, fs:0.86188 (r=0.788,p=0.951),  time:97.882, tt:2838.563\n",
      "Ep:29, loss:0.00009, loss_test:0.07217, lr:9.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:97.993, tt:2939.779\n",
      "Ep:30, loss:0.00009, loss_test:0.07393, lr:9.70e-03, fs:0.86188 (r=0.788,p=0.951),  time:98.096, tt:3040.974\n",
      "Ep:31, loss:0.00008, loss_test:0.07608, lr:9.61e-03, fs:0.86188 (r=0.788,p=0.951),  time:98.114, tt:3139.654\n",
      "Ep:32, loss:0.00007, loss_test:0.07362, lr:9.51e-03, fs:0.86188 (r=0.788,p=0.951),  time:98.148, tt:3238.882\n",
      "Ep:33, loss:0.00007, loss_test:0.07622, lr:9.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.082, tt:3334.804\n",
      "Ep:34, loss:0.00007, loss_test:0.07504, lr:9.32e-03, fs:0.85083 (r=0.778,p=0.939),  time:98.118, tt:3434.123\n",
      "Ep:35, loss:0.00006, loss_test:0.07604, lr:9.23e-03, fs:0.86188 (r=0.788,p=0.951),  time:98.191, tt:3534.874\n",
      "Ep:36, loss:0.00006, loss_test:0.07654, lr:9.14e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.209, tt:3633.741\n",
      "Ep:37, loss:0.00006, loss_test:0.08006, lr:9.04e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.155, tt:3729.896\n",
      "Ep:38, loss:0.00005, loss_test:0.07872, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.170, tt:3828.644\n",
      "Ep:39, loss:0.00005, loss_test:0.07850, lr:8.86e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.184, tt:3927.376\n",
      "Ep:40, loss:0.00005, loss_test:0.07796, lr:8.78e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.223, tt:4027.131\n",
      "Ep:41, loss:0.00004, loss_test:0.07977, lr:8.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.290, tt:4128.185\n",
      "Ep:42, loss:0.00004, loss_test:0.07886, lr:8.60e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.308, tt:4227.228\n",
      "Ep:43, loss:0.00004, loss_test:0.07773, lr:8.51e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.339, tt:4326.912\n",
      "Ep:44, loss:0.00004, loss_test:0.08353, lr:8.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:98.367, tt:4426.516\n",
      "Ep:45, loss:0.00003, loss_test:0.08048, lr:8.35e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.289, tt:4521.315\n",
      "Ep:46, loss:0.00003, loss_test:0.07956, lr:8.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:98.310, tt:4620.582\n",
      "Ep:47, loss:0.00003, loss_test:0.08264, lr:8.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.390, tt:4722.723\n",
      "Ep:48, loss:0.00003, loss_test:0.08185, lr:8.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.432, tt:4823.191\n",
      "Ep:49, loss:0.00003, loss_test:0.08386, lr:8.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.438, tt:4921.890\n",
      "Ep:50, loss:0.00003, loss_test:0.08280, lr:7.94e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.437, tt:5020.312\n",
      "Ep:51, loss:0.00003, loss_test:0.08208, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.440, tt:5118.879\n",
      "Ep:52, loss:0.00002, loss_test:0.08471, lr:7.78e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.466, tt:5218.676\n",
      "Ep:53, loss:0.00002, loss_test:0.08530, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.502, tt:5319.086\n",
      "Ep:54, loss:0.00002, loss_test:0.08455, lr:7.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.497, tt:5417.326\n",
      "Ep:55, loss:0.00002, loss_test:0.08540, lr:7.55e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.517, tt:5516.938\n",
      "Ep:56, loss:0.00002, loss_test:0.08637, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.537, tt:5616.585\n",
      "Ep:57, loss:0.00002, loss_test:0.08446, lr:7.40e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.552, tt:5716.032\n",
      "Ep:58, loss:0.00002, loss_test:0.08644, lr:7.32e-03, fs:0.86364 (r=0.768,p=0.987),  time:98.602, tt:5817.543\n",
      "Ep:59, loss:0.00002, loss_test:0.08539, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:98.609, tt:5916.539\n",
      "Ep:60, loss:0.00002, loss_test:0.08880, lr:7.18e-03, fs:0.84211 (r=0.727,p=1.000),  time:98.626, tt:6016.195\n",
      "Ep:61, loss:0.00002, loss_test:0.08863, lr:7.11e-03, fs:0.85714 (r=0.758,p=0.987),  time:98.655, tt:6116.586\n",
      "Ep:62, loss:0.00002, loss_test:0.08796, lr:7.03e-03, fs:0.85714 (r=0.758,p=0.987),  time:98.703, tt:6218.302\n",
      "Ep:63, loss:0.00001, loss_test:0.08853, lr:6.96e-03, fs:0.86207 (r=0.758,p=1.000),  time:98.762, tt:6320.778\n",
      "Ep:64, loss:0.00001, loss_test:0.08813, lr:6.89e-03, fs:0.86207 (r=0.758,p=1.000),  time:98.778, tt:6420.557\n",
      "Ep:65, loss:0.00001, loss_test:0.08807, lr:6.83e-03, fs:0.86207 (r=0.758,p=1.000),  time:98.811, tt:6521.500\n",
      "Ep:66, loss:0.00001, loss_test:0.08639, lr:6.76e-03, fs:0.85549 (r=0.747,p=1.000),  time:98.828, tt:6621.475\n",
      "Ep:67, loss:0.00001, loss_test:0.09040, lr:6.69e-03, fs:0.86207 (r=0.758,p=1.000),  time:98.825, tt:6720.108\n",
      "Ep:68, loss:0.00001, loss_test:0.08938, lr:6.62e-03, fs:0.83529 (r=0.717,p=1.000),  time:98.810, tt:6817.860\n",
      "Ep:69, loss:0.00001, loss_test:0.08885, lr:6.56e-03, fs:0.84211 (r=0.727,p=1.000),  time:98.810, tt:6916.673\n",
      "Ep:70, loss:0.00001, loss_test:0.08834, lr:6.49e-03, fs:0.83529 (r=0.717,p=1.000),  time:98.809, tt:7015.408\n",
      "Ep:71, loss:0.00001, loss_test:0.08884, lr:6.43e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.808, tt:7114.160\n",
      "Ep:72, loss:0.00001, loss_test:0.08976, lr:6.36e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.788, tt:7211.547\n",
      "Ep:73, loss:0.00001, loss_test:0.08861, lr:6.30e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.806, tt:7311.646\n",
      "Ep:74, loss:0.00001, loss_test:0.08826, lr:6.24e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.849, tt:7413.653\n",
      "Ep:75, loss:0.00001, loss_test:0.08975, lr:6.17e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.887, tt:7515.396\n",
      "Ep:76, loss:0.00001, loss_test:0.08864, lr:6.11e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.873, tt:7613.186\n",
      "Ep:77, loss:0.00001, loss_test:0.08990, lr:6.05e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.862, tt:7711.249\n",
      "Ep:78, loss:0.00001, loss_test:0.08925, lr:5.99e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.868, tt:7810.564\n",
      "Ep:79, loss:0.00001, loss_test:0.09075, lr:5.93e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.866, tt:7909.303\n",
      "Ep:80, loss:0.00001, loss_test:0.08985, lr:5.87e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.841, tt:8006.160\n",
      "Ep:81, loss:0.00001, loss_test:0.08949, lr:5.81e-03, fs:0.80723 (r=0.677,p=1.000),  time:98.854, tt:8106.048\n",
      "Ep:82, loss:0.00001, loss_test:0.09009, lr:5.75e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.835, tt:8203.319\n",
      "Ep:83, loss:0.00001, loss_test:0.09200, lr:5.70e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.798, tt:8299.023\n",
      "Ep:84, loss:0.00001, loss_test:0.09086, lr:5.64e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.796, tt:8397.665\n",
      "Ep:85, loss:0.00001, loss_test:0.09205, lr:5.58e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.826, tt:8499.022\n",
      "Ep:86, loss:0.00001, loss_test:0.08988, lr:5.53e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.819, tt:8597.224\n",
      "Ep:87, loss:0.00001, loss_test:0.09038, lr:5.47e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.777, tt:8692.407\n",
      "Ep:88, loss:0.00001, loss_test:0.09221, lr:5.42e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.756, tt:8789.263\n",
      "Ep:89, loss:0.00001, loss_test:0.09101, lr:5.36e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.724, tt:8885.203\n",
      "Ep:90, loss:0.00001, loss_test:0.09023, lr:5.31e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.723, tt:8983.778\n",
      "Ep:91, loss:0.00001, loss_test:0.09100, lr:5.26e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.733, tt:9083.434\n",
      "Ep:92, loss:0.00001, loss_test:0.09141, lr:5.20e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.763, tt:9184.921\n",
      "Ep:93, loss:0.00001, loss_test:0.08957, lr:5.15e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.759, tt:9283.340\n",
      "Ep:94, loss:0.00001, loss_test:0.09085, lr:5.10e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.757, tt:9381.879\n",
      "Ep:95, loss:0.00001, loss_test:0.09239, lr:5.05e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.753, tt:9480.254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00001, loss_test:0.09017, lr:5.00e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.762, tt:9579.889\n",
      "Ep:97, loss:0.00001, loss_test:0.09234, lr:4.95e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.732, tt:9675.708\n",
      "Ep:98, loss:0.00001, loss_test:0.09047, lr:4.90e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.676, tt:9768.968\n",
      "Ep:99, loss:0.00001, loss_test:0.09031, lr:4.85e-03, fs:0.80000 (r=0.667,p=1.000),  time:98.652, tt:9865.183\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 6\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 5328 Test samples: 198\n",
      "Train positive samples: 2664 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00083, loss_test:0.14374, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:84.626, tt:84.626\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00079, loss_test:0.13688, lr:1.00e-02, fs:0.62948 (r=0.798,p=0.520),  time:89.548, tt:179.096\n",
      "Ep:2, loss:0.00071, loss_test:0.13333, lr:1.00e-02, fs:0.63768 (r=0.667,p=0.611),  time:92.718, tt:278.155\n",
      "Ep:3, loss:0.00064, loss_test:0.12417, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:94.501, tt:378.005\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00059, loss_test:0.11707, lr:1.00e-02, fs:0.66667 (r=0.667,p=0.667),  time:95.226, tt:476.129\n",
      "Ep:5, loss:0.00054, loss_test:0.11303, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:95.665, tt:573.993\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00050, loss_test:0.10680, lr:1.00e-02, fs:0.73000 (r=0.737,p=0.723),  time:96.091, tt:672.639\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.10646, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:96.443, tt:771.541\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00044, loss_test:0.10384, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:96.356, tt:867.203\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00042, loss_test:0.10325, lr:1.00e-02, fs:0.76923 (r=0.758,p=0.781),  time:96.497, tt:964.973\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00039, loss_test:0.10297, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:96.621, tt:1062.835\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00036, loss_test:0.10153, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:96.848, tt:1162.177\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00034, loss_test:0.10072, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:96.827, tt:1258.747\n",
      "Ep:13, loss:0.00032, loss_test:0.10180, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:96.954, tt:1357.355\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00029, loss_test:0.10364, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:97.061, tt:1455.921\n",
      "Ep:15, loss:0.00027, loss_test:0.10478, lr:1.00e-02, fs:0.70732 (r=0.586,p=0.892),  time:97.216, tt:1555.452\n",
      "Ep:16, loss:0.00025, loss_test:0.10801, lr:1.00e-02, fs:0.69182 (r=0.556,p=0.917),  time:97.349, tt:1654.928\n",
      "Ep:17, loss:0.00023, loss_test:0.10748, lr:1.00e-02, fs:0.69620 (r=0.556,p=0.932),  time:97.388, tt:1752.979\n",
      "Ep:18, loss:0.00021, loss_test:0.10835, lr:1.00e-02, fs:0.69620 (r=0.556,p=0.932),  time:97.483, tt:1852.170\n",
      "Ep:19, loss:0.00019, loss_test:0.10458, lr:1.00e-02, fs:0.71166 (r=0.586,p=0.906),  time:97.549, tt:1950.977\n",
      "Ep:20, loss:0.00017, loss_test:0.10417, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:97.591, tt:2049.417\n",
      "Ep:21, loss:0.00015, loss_test:0.10689, lr:1.00e-02, fs:0.68387 (r=0.535,p=0.946),  time:97.540, tt:2145.871\n",
      "Ep:22, loss:0.00014, loss_test:0.10359, lr:1.00e-02, fs:0.73620 (r=0.606,p=0.938),  time:97.488, tt:2242.235\n",
      "Ep:23, loss:0.00013, loss_test:0.09969, lr:1.00e-02, fs:0.76190 (r=0.646,p=0.928),  time:97.579, tt:2341.901\n",
      "Ep:24, loss:0.00012, loss_test:0.10335, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:97.591, tt:2439.780\n",
      "Ep:25, loss:0.00011, loss_test:0.10694, lr:9.90e-03, fs:0.71250 (r=0.576,p=0.934),  time:97.669, tt:2539.383\n",
      "Ep:26, loss:0.00010, loss_test:0.10409, lr:9.80e-03, fs:0.73939 (r=0.616,p=0.924),  time:97.573, tt:2634.466\n",
      "Ep:27, loss:0.00010, loss_test:0.10484, lr:9.70e-03, fs:0.74074 (r=0.606,p=0.952),  time:97.573, tt:2732.033\n",
      "Ep:28, loss:0.00009, loss_test:0.10728, lr:9.61e-03, fs:0.70513 (r=0.556,p=0.965),  time:97.608, tt:2830.636\n",
      "Ep:29, loss:0.00009, loss_test:0.10638, lr:9.51e-03, fs:0.71338 (r=0.566,p=0.966),  time:97.632, tt:2928.959\n",
      "Ep:30, loss:0.00008, loss_test:0.10767, lr:9.41e-03, fs:0.70513 (r=0.556,p=0.965),  time:97.642, tt:3026.895\n",
      "Ep:31, loss:0.00008, loss_test:0.10771, lr:9.32e-03, fs:0.70513 (r=0.556,p=0.965),  time:97.631, tt:3124.198\n",
      "Ep:32, loss:0.00007, loss_test:0.10879, lr:9.23e-03, fs:0.70513 (r=0.556,p=0.965),  time:97.744, tt:3225.561\n",
      "Ep:33, loss:0.00007, loss_test:0.11038, lr:9.14e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.749, tt:3323.477\n",
      "Ep:34, loss:0.00007, loss_test:0.11107, lr:9.04e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.781, tt:3422.332\n",
      "Ep:35, loss:0.00006, loss_test:0.11300, lr:8.95e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.757, tt:3519.235\n",
      "Ep:36, loss:0.00006, loss_test:0.11155, lr:8.86e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.745, tt:3616.575\n",
      "Ep:37, loss:0.00005, loss_test:0.11533, lr:8.78e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.841, tt:3717.970\n",
      "Ep:38, loss:0.00005, loss_test:0.11613, lr:8.69e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.839, tt:3815.702\n",
      "Ep:39, loss:0.00005, loss_test:0.11480, lr:8.60e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.825, tt:3913.018\n",
      "Ep:40, loss:0.00005, loss_test:0.11464, lr:8.51e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.844, tt:4011.622\n",
      "Ep:41, loss:0.00004, loss_test:0.11437, lr:8.43e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.936, tt:4113.297\n",
      "Ep:42, loss:0.00004, loss_test:0.11891, lr:8.35e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.967, tt:4212.585\n",
      "Ep:43, loss:0.00004, loss_test:0.11790, lr:8.26e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.968, tt:4310.609\n",
      "Ep:44, loss:0.00004, loss_test:0.11964, lr:8.18e-03, fs:0.69281 (r=0.535,p=0.981),  time:97.935, tt:4407.060\n",
      "Ep:45, loss:0.00003, loss_test:0.11888, lr:8.10e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.961, tt:4506.208\n",
      "Ep:46, loss:0.00003, loss_test:0.11603, lr:8.02e-03, fs:0.68831 (r=0.535,p=0.964),  time:97.939, tt:4603.115\n",
      "Ep:47, loss:0.00003, loss_test:0.11699, lr:7.94e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.896, tt:4698.999\n",
      "Ep:48, loss:0.00003, loss_test:0.12040, lr:7.86e-03, fs:0.70130 (r=0.545,p=0.982),  time:97.892, tt:4796.691\n",
      "Ep:49, loss:0.00003, loss_test:0.12366, lr:7.78e-03, fs:0.63014 (r=0.465,p=0.979),  time:97.905, tt:4895.226\n",
      "Ep:50, loss:0.00003, loss_test:0.12345, lr:7.70e-03, fs:0.63014 (r=0.465,p=0.979),  time:97.904, tt:4993.101\n",
      "Ep:51, loss:0.00003, loss_test:0.12418, lr:7.62e-03, fs:0.63014 (r=0.465,p=0.979),  time:97.952, tt:5093.488\n",
      "Ep:52, loss:0.00002, loss_test:0.12482, lr:7.55e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.988, tt:5193.340\n",
      "Ep:53, loss:0.00002, loss_test:0.12618, lr:7.47e-03, fs:0.63014 (r=0.465,p=0.979),  time:97.998, tt:5291.915\n",
      "Ep:54, loss:0.00002, loss_test:0.12778, lr:7.40e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.044, tt:5392.422\n",
      "Ep:55, loss:0.00002, loss_test:0.12568, lr:7.32e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.073, tt:5492.070\n",
      "Ep:56, loss:0.00002, loss_test:0.12550, lr:7.25e-03, fs:0.63014 (r=0.465,p=0.979),  time:98.075, tt:5590.250\n",
      "Ep:57, loss:0.00002, loss_test:0.12796, lr:7.18e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.045, tt:5686.633\n",
      "Ep:58, loss:0.00002, loss_test:0.12764, lr:7.11e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.046, tt:5784.688\n",
      "Ep:59, loss:0.00002, loss_test:0.12848, lr:7.03e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.095, tt:5885.675\n",
      "Ep:60, loss:0.00002, loss_test:0.12889, lr:6.96e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.118, tt:5985.206\n",
      "Ep:61, loss:0.00002, loss_test:0.12840, lr:6.89e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.110, tt:6082.849\n",
      "Ep:62, loss:0.00001, loss_test:0.12896, lr:6.83e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.089, tt:6179.601\n",
      "Ep:63, loss:0.00001, loss_test:0.13237, lr:6.76e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.085, tt:6277.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.12879, lr:6.69e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.101, tt:6376.533\n",
      "Ep:65, loss:0.00001, loss_test:0.13029, lr:6.62e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.072, tt:6472.765\n",
      "Ep:66, loss:0.00001, loss_test:0.13160, lr:6.56e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.062, tt:6570.188\n",
      "Ep:67, loss:0.00001, loss_test:0.13191, lr:6.49e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.073, tt:6668.931\n",
      "Ep:68, loss:0.00001, loss_test:0.13114, lr:6.43e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.073, tt:6767.022\n",
      "Ep:69, loss:0.00001, loss_test:0.13440, lr:6.36e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.067, tt:6864.677\n",
      "Ep:70, loss:0.00001, loss_test:0.13044, lr:6.30e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.044, tt:6961.149\n",
      "Ep:71, loss:0.00001, loss_test:0.13116, lr:6.24e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.020, tt:7057.405\n",
      "Ep:72, loss:0.00001, loss_test:0.13110, lr:6.17e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.994, tt:7153.527\n",
      "Ep:73, loss:0.00001, loss_test:0.13202, lr:6.11e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.984, tt:7250.842\n",
      "Ep:74, loss:0.00001, loss_test:0.13300, lr:6.05e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.983, tt:7348.692\n",
      "Ep:75, loss:0.00001, loss_test:0.13038, lr:5.99e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.978, tt:7446.339\n",
      "Ep:76, loss:0.00001, loss_test:0.13201, lr:5.93e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.973, tt:7543.934\n",
      "Ep:77, loss:0.00001, loss_test:0.13149, lr:5.87e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.991, tt:7643.309\n",
      "Ep:78, loss:0.00001, loss_test:0.13205, lr:5.81e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.008, tt:7742.661\n",
      "Ep:79, loss:0.00001, loss_test:0.13331, lr:5.75e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.037, tt:7842.948\n",
      "Ep:80, loss:0.00001, loss_test:0.13232, lr:5.70e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.064, tt:7943.176\n",
      "Ep:81, loss:0.00001, loss_test:0.13370, lr:5.64e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.055, tt:8040.511\n",
      "Ep:82, loss:0.00001, loss_test:0.13264, lr:5.58e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.040, tt:8137.318\n",
      "Ep:83, loss:0.00001, loss_test:0.13436, lr:5.53e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.057, tt:8236.807\n",
      "Ep:84, loss:0.00001, loss_test:0.13484, lr:5.47e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.062, tt:8335.286\n",
      "Ep:85, loss:0.00001, loss_test:0.13570, lr:5.42e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.058, tt:8432.950\n",
      "Ep:86, loss:0.00001, loss_test:0.13435, lr:5.36e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.040, tt:8529.469\n",
      "Ep:87, loss:0.00001, loss_test:0.13510, lr:5.31e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.034, tt:8627.020\n",
      "Ep:88, loss:0.00001, loss_test:0.13462, lr:5.26e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.025, tt:8724.203\n",
      "Ep:89, loss:0.00001, loss_test:0.13471, lr:5.20e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.022, tt:8822.011\n",
      "Ep:90, loss:0.00001, loss_test:0.13524, lr:5.15e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.003, tt:8918.274\n",
      "Ep:91, loss:0.00001, loss_test:0.13602, lr:5.10e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.982, tt:9014.365\n",
      "Ep:92, loss:0.00001, loss_test:0.13518, lr:5.05e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.985, tt:9112.605\n",
      "Ep:93, loss:0.00001, loss_test:0.13530, lr:5.00e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.972, tt:9209.390\n",
      "Ep:94, loss:0.00001, loss_test:0.13536, lr:4.95e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.999, tt:9309.918\n",
      "Ep:95, loss:0.00001, loss_test:0.13560, lr:4.90e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.015, tt:9409.478\n",
      "Ep:96, loss:0.00001, loss_test:0.13513, lr:4.85e-03, fs:0.62069 (r=0.455,p=0.978),  time:98.031, tt:9508.984\n",
      "Ep:97, loss:0.00001, loss_test:0.13489, lr:4.80e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.987, tt:9602.687\n",
      "Ep:98, loss:0.00001, loss_test:0.13509, lr:4.75e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.995, tt:9701.541\n",
      "Ep:99, loss:0.00001, loss_test:0.13656, lr:4.71e-03, fs:0.62069 (r=0.455,p=0.978),  time:97.967, tt:9796.728\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.13916, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:101.117, tt:101.117\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.12597, lr:1.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:109.208, tt:218.415\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00085, loss_test:0.11067, lr:1.00e-02, fs:0.69231 (r=0.727,p=0.661),  time:111.587, tt:334.761\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00078, loss_test:0.09973, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:112.719, tt:450.876\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00070, loss_test:0.09379, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:113.817, tt:569.085\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00064, loss_test:0.08889, lr:1.00e-02, fs:0.74000 (r=0.747,p=0.733),  time:113.807, tt:682.844\n",
      "Ep:6, loss:0.00059, loss_test:0.08691, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:113.882, tt:797.175\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00055, loss_test:0.08596, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:113.855, tt:910.837\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00051, loss_test:0.08376, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:114.157, tt:1027.415\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00047, loss_test:0.08251, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:114.141, tt:1141.410\n",
      "Ep:10, loss:0.00044, loss_test:0.08155, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:114.189, tt:1256.077\n",
      "Ep:11, loss:0.00041, loss_test:0.08098, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:114.431, tt:1373.169\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00037, loss_test:0.07945, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:114.283, tt:1485.673\n",
      "Ep:13, loss:0.00034, loss_test:0.08161, lr:1.00e-02, fs:0.77596 (r=0.717,p=0.845),  time:114.431, tt:1602.028\n",
      "Ep:14, loss:0.00031, loss_test:0.08637, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:114.390, tt:1715.851\n",
      "Ep:15, loss:0.00029, loss_test:0.08086, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:114.450, tt:1831.203\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00026, loss_test:0.08936, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:114.459, tt:1945.796\n",
      "Ep:17, loss:0.00024, loss_test:0.09068, lr:1.00e-02, fs:0.74390 (r=0.616,p=0.938),  time:114.365, tt:2058.576\n",
      "Ep:18, loss:0.00022, loss_test:0.08285, lr:1.00e-02, fs:0.76471 (r=0.657,p=0.915),  time:114.314, tt:2171.959\n",
      "Ep:19, loss:0.00020, loss_test:0.09240, lr:1.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:114.274, tt:2285.486\n",
      "Ep:20, loss:0.00018, loss_test:0.08798, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:114.318, tt:2400.674\n",
      "Ep:21, loss:0.00017, loss_test:0.09161, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.456, tt:2518.026\n",
      "Ep:22, loss:0.00015, loss_test:0.09525, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.461, tt:2632.594\n",
      "Ep:23, loss:0.00014, loss_test:0.09221, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:114.558, tt:2749.394\n",
      "Ep:24, loss:0.00012, loss_test:0.09164, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:114.542, tt:2863.544\n",
      "Ep:25, loss:0.00012, loss_test:0.09229, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:114.471, tt:2976.240\n",
      "Ep:26, loss:0.00011, loss_test:0.09303, lr:1.00e-02, fs:0.77381 (r=0.657,p=0.942),  time:114.530, tt:3092.306\n",
      "Ep:27, loss:0.00010, loss_test:0.09727, lr:9.90e-03, fs:0.77844 (r=0.657,p=0.956),  time:114.543, tt:3207.210\n",
      "Ep:28, loss:0.00009, loss_test:0.10088, lr:9.80e-03, fs:0.77844 (r=0.657,p=0.956),  time:114.627, tt:3324.182\n",
      "Ep:29, loss:0.00008, loss_test:0.10230, lr:9.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.622, tt:3438.653\n",
      "Ep:30, loss:0.00008, loss_test:0.09723, lr:9.61e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.555, tt:3551.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:31, loss:0.00007, loss_test:0.10281, lr:9.51e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.573, tt:3666.338\n",
      "Ep:32, loss:0.00007, loss_test:0.10158, lr:9.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.717, tt:3785.674\n",
      "Ep:33, loss:0.00006, loss_test:0.10094, lr:9.32e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.774, tt:3902.325\n",
      "Ep:34, loss:0.00006, loss_test:0.10412, lr:9.23e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.734, tt:4015.685\n",
      "Ep:35, loss:0.00006, loss_test:0.10382, lr:9.14e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.726, tt:4130.149\n",
      "Ep:36, loss:0.00005, loss_test:0.10761, lr:9.04e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.688, tt:4243.464\n",
      "Ep:37, loss:0.00005, loss_test:0.10264, lr:8.95e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.732, tt:4359.823\n",
      "Ep:38, loss:0.00004, loss_test:0.10389, lr:8.86e-03, fs:0.78313 (r=0.657,p=0.970),  time:114.705, tt:4473.498\n",
      "Ep:39, loss:0.00004, loss_test:0.10862, lr:8.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.778, tt:4591.117\n",
      "Ep:40, loss:0.00004, loss_test:0.10643, lr:8.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.802, tt:4706.872\n",
      "Ep:41, loss:0.00003, loss_test:0.10802, lr:8.60e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.805, tt:4821.808\n",
      "Ep:42, loss:0.00003, loss_test:0.10564, lr:8.51e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.783, tt:4935.659\n",
      "Ep:43, loss:0.00003, loss_test:0.10943, lr:8.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.866, tt:5054.110\n",
      "Ep:44, loss:0.00003, loss_test:0.10436, lr:8.35e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.857, tt:5168.557\n",
      "Ep:45, loss:0.00003, loss_test:0.10783, lr:8.26e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.911, tt:5285.917\n",
      "Ep:46, loss:0.00002, loss_test:0.11245, lr:8.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.949, tt:5402.592\n",
      "Ep:47, loss:0.00002, loss_test:0.11047, lr:8.10e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.910, tt:5515.661\n",
      "Ep:48, loss:0.00002, loss_test:0.10721, lr:8.02e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.893, tt:5629.750\n",
      "Ep:49, loss:0.00002, loss_test:0.11000, lr:7.94e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.936, tt:5746.793\n",
      "Ep:50, loss:0.00002, loss_test:0.11135, lr:7.86e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.941, tt:5862.011\n",
      "Ep:51, loss:0.00002, loss_test:0.11048, lr:7.78e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.934, tt:5976.563\n",
      "Ep:52, loss:0.00002, loss_test:0.11131, lr:7.70e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.013, tt:6095.683\n",
      "Ep:53, loss:0.00002, loss_test:0.11183, lr:7.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.988, tt:6209.374\n",
      "Ep:54, loss:0.00002, loss_test:0.11324, lr:7.55e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.964, tt:6323.012\n",
      "Ep:55, loss:0.00002, loss_test:0.11152, lr:7.47e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.970, tt:6438.304\n",
      "Ep:56, loss:0.00001, loss_test:0.11445, lr:7.40e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.987, tt:6554.258\n",
      "Ep:57, loss:0.00001, loss_test:0.11507, lr:7.32e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.013, tt:6670.754\n",
      "Ep:58, loss:0.00001, loss_test:0.11267, lr:7.25e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.043, tt:6787.537\n",
      "Ep:59, loss:0.00001, loss_test:0.11320, lr:7.18e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.053, tt:6903.157\n",
      "Ep:60, loss:0.00001, loss_test:0.11373, lr:7.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.058, tt:7018.513\n",
      "Ep:61, loss:0.00001, loss_test:0.11247, lr:7.03e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.063, tt:7133.881\n",
      "Ep:62, loss:0.00001, loss_test:0.11390, lr:6.96e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.067, tt:7249.237\n",
      "Ep:63, loss:0.00001, loss_test:0.11279, lr:6.89e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.041, tt:7362.594\n",
      "Ep:64, loss:0.00001, loss_test:0.11373, lr:6.83e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.079, tt:7480.148\n",
      "Ep:65, loss:0.00001, loss_test:0.11474, lr:6.76e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.064, tt:7594.224\n",
      "Ep:66, loss:0.00001, loss_test:0.11330, lr:6.69e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.048, tt:7708.218\n",
      "Ep:67, loss:0.00001, loss_test:0.11366, lr:6.62e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.051, tt:7823.438\n",
      "Ep:68, loss:0.00001, loss_test:0.11218, lr:6.56e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.075, tt:7940.170\n",
      "Ep:69, loss:0.00001, loss_test:0.11298, lr:6.49e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.071, tt:8054.981\n",
      "Ep:70, loss:0.00001, loss_test:0.11309, lr:6.43e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.066, tt:8169.716\n",
      "Ep:71, loss:0.00001, loss_test:0.11291, lr:6.36e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.098, tt:8287.048\n",
      "Ep:72, loss:0.00001, loss_test:0.11488, lr:6.30e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.117, tt:8403.548\n",
      "Ep:73, loss:0.00001, loss_test:0.11559, lr:6.24e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.107, tt:8517.924\n",
      "Ep:74, loss:0.00001, loss_test:0.11474, lr:6.17e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.149, tt:8636.196\n",
      "Ep:75, loss:0.00001, loss_test:0.11471, lr:6.11e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.154, tt:8751.708\n",
      "Ep:76, loss:0.00001, loss_test:0.11406, lr:6.05e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.144, tt:8866.113\n",
      "Ep:77, loss:0.00001, loss_test:0.11498, lr:5.99e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.108, tt:8978.437\n",
      "Ep:78, loss:0.00001, loss_test:0.11425, lr:5.93e-03, fs:0.78788 (r=0.657,p=0.985),  time:115.096, tt:9092.588\n",
      "Ep:79, loss:0.00001, loss_test:0.11591, lr:5.87e-03, fs:0.78788 (r=0.657,p=0.985),  time:114.943, tt:9195.403\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14011, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:101.016, tt:101.016\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.12837, lr:1.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:107.351, tt:214.702\n",
      "Ep:2, loss:0.00085, loss_test:0.11140, lr:1.00e-02, fs:0.65347 (r=0.667,p=0.641),  time:110.175, tt:330.525\n",
      "Ep:3, loss:0.00077, loss_test:0.10490, lr:1.00e-02, fs:0.68000 (r=0.687,p=0.673),  time:111.502, tt:446.009\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00069, loss_test:0.10036, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:112.286, tt:561.430\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00063, loss_test:0.09669, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:112.869, tt:677.216\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00058, loss_test:0.09983, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:113.195, tt:792.366\n",
      "Ep:7, loss:0.00054, loss_test:0.09532, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:113.427, tt:907.413\n",
      "Ep:8, loss:0.00050, loss_test:0.09535, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:113.664, tt:1022.980\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00047, loss_test:0.09504, lr:1.00e-02, fs:0.74372 (r=0.747,p=0.740),  time:113.787, tt:1137.865\n",
      "Ep:10, loss:0.00043, loss_test:0.09463, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:114.065, tt:1254.717\n",
      "Ep:11, loss:0.00040, loss_test:0.09274, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:113.984, tt:1367.805\n",
      "Ep:12, loss:0.00038, loss_test:0.09162, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:114.023, tt:1482.304\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00035, loss_test:0.09255, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:114.256, tt:1599.582\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00032, loss_test:0.09111, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:114.418, tt:1716.272\n",
      "Ep:15, loss:0.00030, loss_test:0.08807, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:114.321, tt:1829.140\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.09168, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:114.503, tt:1946.554\n",
      "Ep:17, loss:0.00024, loss_test:0.08752, lr:1.00e-02, fs:0.76404 (r=0.687,p=0.861),  time:114.577, tt:2062.389\n",
      "Ep:18, loss:0.00022, loss_test:0.09124, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:114.592, tt:2177.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00020, loss_test:0.09002, lr:1.00e-02, fs:0.72941 (r=0.626,p=0.873),  time:114.696, tt:2293.919\n",
      "Ep:20, loss:0.00018, loss_test:0.08864, lr:1.00e-02, fs:0.72619 (r=0.616,p=0.884),  time:114.618, tt:2406.969\n",
      "Ep:21, loss:0.00017, loss_test:0.08798, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:114.521, tt:2519.455\n",
      "Ep:22, loss:0.00016, loss_test:0.09232, lr:1.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:114.568, tt:2635.053\n",
      "Ep:23, loss:0.00014, loss_test:0.09355, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:114.540, tt:2748.972\n",
      "Ep:24, loss:0.00013, loss_test:0.09503, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:114.590, tt:2864.747\n",
      "Ep:25, loss:0.00012, loss_test:0.09508, lr:1.00e-02, fs:0.73054 (r=0.616,p=0.897),  time:114.610, tt:2979.867\n",
      "Ep:26, loss:0.00011, loss_test:0.09483, lr:1.00e-02, fs:0.73494 (r=0.616,p=0.910),  time:114.603, tt:3094.274\n",
      "Ep:27, loss:0.00010, loss_test:0.09493, lr:9.90e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.587, tt:3208.441\n",
      "Ep:28, loss:0.00010, loss_test:0.09500, lr:9.80e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.652, tt:3324.920\n",
      "Ep:29, loss:0.00009, loss_test:0.10132, lr:9.70e-03, fs:0.73054 (r=0.616,p=0.897),  time:114.653, tt:3439.579\n",
      "Ep:30, loss:0.00009, loss_test:0.09794, lr:9.61e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.649, tt:3554.119\n",
      "Ep:31, loss:0.00008, loss_test:0.09958, lr:9.51e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.674, tt:3669.574\n",
      "Ep:32, loss:0.00007, loss_test:0.09540, lr:9.41e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.747, tt:3786.654\n",
      "Ep:33, loss:0.00007, loss_test:0.10102, lr:9.32e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.791, tt:3902.908\n",
      "Ep:34, loss:0.00006, loss_test:0.09817, lr:9.23e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.766, tt:4016.796\n",
      "Ep:35, loss:0.00006, loss_test:0.09971, lr:9.14e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.802, tt:4132.855\n",
      "Ep:36, loss:0.00006, loss_test:0.09833, lr:9.04e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.806, tt:4247.815\n",
      "Ep:37, loss:0.00005, loss_test:0.09985, lr:8.95e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.860, tt:4364.691\n",
      "Ep:38, loss:0.00005, loss_test:0.10063, lr:8.86e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.855, tt:4479.338\n",
      "Ep:39, loss:0.00005, loss_test:0.10387, lr:8.78e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.826, tt:4593.022\n",
      "Ep:40, loss:0.00005, loss_test:0.10231, lr:8.69e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.866, tt:4709.493\n",
      "Ep:41, loss:0.00005, loss_test:0.10020, lr:8.60e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.847, tt:4823.564\n",
      "Ep:42, loss:0.00004, loss_test:0.10125, lr:8.51e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.929, tt:4941.947\n",
      "Ep:43, loss:0.00004, loss_test:0.10134, lr:8.43e-03, fs:0.73494 (r=0.616,p=0.910),  time:114.946, tt:5057.627\n",
      "Ep:44, loss:0.00004, loss_test:0.10272, lr:8.35e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.948, tt:5172.671\n",
      "Ep:45, loss:0.00004, loss_test:0.09965, lr:8.26e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.919, tt:5286.282\n",
      "Ep:46, loss:0.00004, loss_test:0.10103, lr:8.18e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.946, tt:5402.473\n",
      "Ep:47, loss:0.00003, loss_test:0.10129, lr:8.10e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.908, tt:5515.572\n",
      "Ep:48, loss:0.00003, loss_test:0.10418, lr:8.02e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.956, tt:5632.859\n",
      "Ep:49, loss:0.00003, loss_test:0.10245, lr:7.94e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.912, tt:5745.598\n",
      "Ep:50, loss:0.00003, loss_test:0.10346, lr:7.86e-03, fs:0.74390 (r=0.616,p=0.938),  time:114.932, tt:5861.513\n",
      "Ep:51, loss:0.00003, loss_test:0.10378, lr:7.78e-03, fs:0.74847 (r=0.616,p=0.953),  time:114.917, tt:5975.664\n",
      "Ep:52, loss:0.00003, loss_test:0.10451, lr:7.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:114.953, tt:6092.531\n",
      "Ep:53, loss:0.00002, loss_test:0.10576, lr:7.62e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.991, tt:6209.515\n",
      "Ep:54, loss:0.00002, loss_test:0.10382, lr:7.55e-03, fs:0.75776 (r=0.616,p=0.984),  time:115.029, tt:6326.570\n",
      "Ep:55, loss:0.00002, loss_test:0.10237, lr:7.47e-03, fs:0.75776 (r=0.616,p=0.984),  time:115.006, tt:6440.309\n",
      "Ep:56, loss:0.00002, loss_test:0.10691, lr:7.40e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.974, tt:6553.499\n",
      "Ep:57, loss:0.00002, loss_test:0.10554, lr:7.32e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.968, tt:6668.163\n",
      "Ep:58, loss:0.00002, loss_test:0.10304, lr:7.25e-03, fs:0.75309 (r=0.616,p=0.968),  time:114.959, tt:6782.562\n",
      "Ep:59, loss:0.00002, loss_test:0.10660, lr:7.18e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.935, tt:6896.073\n",
      "Ep:60, loss:0.00002, loss_test:0.10284, lr:7.11e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.942, tt:7011.481\n",
      "Ep:61, loss:0.00002, loss_test:0.10431, lr:7.03e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.914, tt:7124.680\n",
      "Ep:62, loss:0.00002, loss_test:0.10551, lr:6.96e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.903, tt:7238.888\n",
      "Ep:63, loss:0.00002, loss_test:0.10265, lr:6.89e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.875, tt:7351.994\n",
      "Ep:64, loss:0.00002, loss_test:0.10408, lr:6.83e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.862, tt:7466.054\n",
      "Ep:65, loss:0.00002, loss_test:0.10388, lr:6.76e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.860, tt:7580.790\n",
      "Ep:66, loss:0.00001, loss_test:0.10539, lr:6.69e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.906, tt:7698.701\n",
      "Ep:67, loss:0.00001, loss_test:0.10432, lr:6.62e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.918, tt:7814.420\n",
      "Ep:68, loss:0.00001, loss_test:0.10384, lr:6.56e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.899, tt:7928.063\n",
      "Ep:69, loss:0.00001, loss_test:0.10450, lr:6.49e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.847, tt:8039.302\n",
      "Ep:70, loss:0.00001, loss_test:0.10519, lr:6.43e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.852, tt:8154.462\n",
      "Ep:71, loss:0.00001, loss_test:0.10536, lr:6.36e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.863, tt:8270.125\n",
      "Ep:72, loss:0.00001, loss_test:0.10338, lr:6.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.886, tt:8386.684\n",
      "Ep:73, loss:0.00001, loss_test:0.10428, lr:6.24e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.885, tt:8501.484\n",
      "Ep:74, loss:0.00001, loss_test:0.10409, lr:6.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.888, tt:8616.580\n",
      "Ep:75, loss:0.00001, loss_test:0.10491, lr:6.11e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.923, tt:8734.147\n",
      "Ep:76, loss:0.00001, loss_test:0.10525, lr:6.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.933, tt:8849.866\n",
      "Ep:77, loss:0.00001, loss_test:0.10305, lr:5.99e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.885, tt:8961.017\n",
      "Ep:78, loss:0.00001, loss_test:0.10469, lr:5.93e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.888, tt:9076.137\n",
      "Ep:79, loss:0.00001, loss_test:0.10420, lr:5.87e-03, fs:0.75776 (r=0.616,p=0.984),  time:114.787, tt:9182.928\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00124, loss_test:0.13190, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:136.384, tt:136.384\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00109, loss_test:0.10989, lr:1.00e-02, fs:0.64249 (r=0.626,p=0.660),  time:142.691, tt:285.382\n",
      "Ep:2, loss:0.00094, loss_test:0.10172, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:146.151, tt:438.453\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00083, loss_test:0.09390, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:146.886, tt:587.544\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00075, loss_test:0.08928, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:147.247, tt:736.233\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00068, loss_test:0.08502, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:147.570, tt:885.419\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00062, loss_test:0.08256, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:147.355, tt:1031.485\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00056, loss_test:0.08009, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:147.285, tt:1178.278\n",
      "Ep:8, loss:0.00051, loss_test:0.07965, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:147.551, tt:1327.961\n",
      "Ep:9, loss:0.00046, loss_test:0.07798, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:147.733, tt:1477.328\n",
      "Ep:10, loss:0.00042, loss_test:0.07830, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:147.801, tt:1625.806\n",
      "Ep:11, loss:0.00037, loss_test:0.07903, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:147.754, tt:1773.050\n",
      "Ep:12, loss:0.00033, loss_test:0.07983, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:147.984, tt:1923.793\n",
      "Ep:13, loss:0.00029, loss_test:0.08081, lr:1.00e-02, fs:0.78788 (r=0.657,p=0.985),  time:147.985, tt:2071.788\n",
      "Ep:14, loss:0.00026, loss_test:0.07947, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:148.011, tt:2220.163\n",
      "Ep:15, loss:0.00023, loss_test:0.08275, lr:1.00e-02, fs:0.76543 (r=0.626,p=0.984),  time:148.038, tt:2368.602\n",
      "Ep:16, loss:0.00020, loss_test:0.08509, lr:1.00e-02, fs:0.76074 (r=0.626,p=0.969),  time:148.025, tt:2516.433\n",
      "Ep:17, loss:0.00018, loss_test:0.08388, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:147.749, tt:2659.488\n",
      "Ep:18, loss:0.00017, loss_test:0.08290, lr:9.90e-03, fs:0.76074 (r=0.626,p=0.969),  time:147.296, tt:2798.624\n",
      "Ep:19, loss:0.00015, loss_test:0.08429, lr:9.80e-03, fs:0.77108 (r=0.646,p=0.955),  time:147.129, tt:2942.580\n",
      "Ep:20, loss:0.00014, loss_test:0.08500, lr:9.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:146.896, tt:3084.811\n",
      "Ep:21, loss:0.00013, loss_test:0.08750, lr:9.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:146.830, tt:3230.266\n",
      "Ep:22, loss:0.00012, loss_test:0.08551, lr:9.51e-03, fs:0.78049 (r=0.646,p=0.985),  time:146.870, tt:3378.005\n",
      "Ep:23, loss:0.00011, loss_test:0.08773, lr:9.41e-03, fs:0.76074 (r=0.626,p=0.969),  time:146.816, tt:3523.588\n",
      "Ep:24, loss:0.00010, loss_test:0.08750, lr:9.32e-03, fs:0.76829 (r=0.636,p=0.969),  time:146.768, tt:3669.191\n",
      "Ep:25, loss:0.00010, loss_test:0.08736, lr:9.23e-03, fs:0.76829 (r=0.636,p=0.969),  time:146.841, tt:3817.872\n",
      "Ep:26, loss:0.00009, loss_test:0.08824, lr:9.14e-03, fs:0.77576 (r=0.646,p=0.970),  time:146.799, tt:3963.570\n",
      "Ep:27, loss:0.00008, loss_test:0.08892, lr:9.04e-03, fs:0.77576 (r=0.646,p=0.970),  time:146.886, tt:4112.821\n",
      "Ep:28, loss:0.00008, loss_test:0.09230, lr:8.95e-03, fs:0.77778 (r=0.636,p=1.000),  time:146.902, tt:4260.154\n",
      "Ep:29, loss:0.00007, loss_test:0.08983, lr:8.86e-03, fs:0.77576 (r=0.646,p=0.970),  time:146.866, tt:4405.974\n",
      "Ep:30, loss:0.00007, loss_test:0.08881, lr:8.78e-03, fs:0.77576 (r=0.646,p=0.970),  time:146.983, tt:4556.479\n",
      "Ep:31, loss:0.00006, loss_test:0.09045, lr:8.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.004, tt:4704.131\n",
      "Ep:32, loss:0.00006, loss_test:0.09190, lr:8.60e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.034, tt:4852.123\n",
      "Ep:33, loss:0.00006, loss_test:0.09149, lr:8.51e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.053, tt:4999.810\n",
      "Ep:35, loss:0.00005, loss_test:0.09348, lr:8.35e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.044, tt:5293.587\n",
      "Ep:37, loss:0.00004, loss_test:0.09450, lr:8.18e-03, fs:0.78528 (r=0.646,p=1.000),  time:147.036, tt:5587.350\n",
      "Ep:38, loss:0.00004, loss_test:0.09356, lr:8.10e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.040, tt:5734.569\n",
      "Ep:39, loss:0.00004, loss_test:0.09332, lr:8.02e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.039, tt:5881.541\n",
      "Ep:40, loss:0.00004, loss_test:0.09448, lr:7.94e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.007, tt:6027.275\n",
      "Ep:41, loss:0.00004, loss_test:0.09383, lr:7.86e-03, fs:0.77576 (r=0.646,p=0.970),  time:147.049, tt:6176.051\n",
      "Ep:42, loss:0.00003, loss_test:0.09482, lr:7.78e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.008, tt:6321.338\n",
      "Ep:43, loss:0.00003, loss_test:0.09604, lr:7.70e-03, fs:0.78049 (r=0.646,p=0.985),  time:146.968, tt:6466.610\n",
      "Ep:44, loss:0.00003, loss_test:0.09433, lr:7.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.018, tt:6615.794\n",
      "Ep:45, loss:0.00003, loss_test:0.09555, lr:7.55e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.046, tt:6764.109\n",
      "Ep:46, loss:0.00003, loss_test:0.09539, lr:7.47e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.036, tt:6910.704\n",
      "Ep:47, loss:0.00003, loss_test:0.09695, lr:7.40e-03, fs:0.78528 (r=0.646,p=1.000),  time:147.101, tt:7060.851\n",
      "Ep:48, loss:0.00003, loss_test:0.09496, lr:7.32e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.085, tt:7207.176\n",
      "Ep:49, loss:0.00002, loss_test:0.09628, lr:7.25e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.122, tt:7356.092\n",
      "Ep:50, loss:0.00002, loss_test:0.09562, lr:7.18e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.137, tt:7503.980\n",
      "Ep:51, loss:0.00002, loss_test:0.09729, lr:7.11e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.164, tt:7652.535\n",
      "Ep:52, loss:0.00002, loss_test:0.09572, lr:7.03e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.175, tt:7800.293\n",
      "Ep:53, loss:0.00002, loss_test:0.09696, lr:6.96e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.115, tt:7944.236\n",
      "Ep:54, loss:0.00002, loss_test:0.09718, lr:6.89e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.085, tt:8089.655\n",
      "Ep:55, loss:0.00002, loss_test:0.09703, lr:6.83e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.094, tt:8237.243\n",
      "Ep:56, loss:0.00002, loss_test:0.09835, lr:6.76e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.091, tt:8384.178\n",
      "Ep:57, loss:0.00002, loss_test:0.09712, lr:6.69e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.107, tt:8532.220\n",
      "Ep:58, loss:0.00002, loss_test:0.09930, lr:6.62e-03, fs:0.78049 (r=0.646,p=0.985),  time:147.010, tt:8673.564\n",
      "Ep:59, loss:0.00002, loss_test:0.09799, lr:6.56e-03, fs:0.78049 (r=0.646,p=0.985),  time:146.858, tt:8811.451\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 10\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 8880 Test samples: 198\n",
      "Train positive samples: 4440 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00123, loss_test:0.13716, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:134.620, tt:134.620\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00107, loss_test:0.12374, lr:1.00e-02, fs:0.67337 (r=0.677,p=0.670),  time:141.871, tt:283.742\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00094, loss_test:0.11260, lr:1.00e-02, fs:0.64646 (r=0.646,p=0.646),  time:143.236, tt:429.709\n",
      "Ep:3, loss:0.00084, loss_test:0.10426, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:144.627, tt:578.508\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00075, loss_test:0.09667, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:145.431, tt:727.153\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00069, loss_test:0.09209, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:145.803, tt:874.816\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00062, loss_test:0.08754, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:145.639, tt:1019.470\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00057, loss_test:0.08662, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:146.390, tt:1171.121\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00052, loss_test:0.08170, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:146.507, tt:1318.559\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00046, loss_test:0.07902, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:147.061, tt:1470.613\n",
      "Ep:10, loss:0.00041, loss_test:0.07891, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:146.921, tt:1616.136\n",
      "Ep:11, loss:0.00036, loss_test:0.07943, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:147.099, tt:1765.187\n",
      "Ep:12, loss:0.00032, loss_test:0.07734, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:146.994, tt:1910.926\n",
      "Ep:13, loss:0.00029, loss_test:0.07617, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:147.185, tt:2060.594\n",
      "Ep:14, loss:0.00026, loss_test:0.07634, lr:1.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:147.219, tt:2208.292\n",
      "Ep:15, loss:0.00023, loss_test:0.07507, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:147.327, tt:2357.236\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00021, loss_test:0.07298, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:147.276, tt:2503.685\n",
      "Ep:17, loss:0.00019, loss_test:0.07398, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:147.240, tt:2650.315\n",
      "Ep:18, loss:0.00018, loss_test:0.07589, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:147.199, tt:2796.786\n",
      "Ep:19, loss:0.00017, loss_test:0.07445, lr:1.00e-02, fs:0.77647 (r=0.667,p=0.930),  time:147.169, tt:2943.373\n",
      "Ep:20, loss:0.00015, loss_test:0.07465, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:147.121, tt:3089.549\n",
      "Ep:21, loss:0.00014, loss_test:0.07391, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:147.126, tt:3236.769\n",
      "Ep:22, loss:0.00013, loss_test:0.07640, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:147.085, tt:3382.952\n",
      "Ep:23, loss:0.00012, loss_test:0.07541, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:147.063, tt:3529.507\n",
      "Ep:24, loss:0.00011, loss_test:0.07725, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:147.023, tt:3675.573\n",
      "Ep:25, loss:0.00011, loss_test:0.07608, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:146.970, tt:3821.216\n",
      "Ep:26, loss:0.00010, loss_test:0.07717, lr:1.00e-02, fs:0.75152 (r=0.626,p=0.939),  time:146.968, tt:3968.122\n",
      "Ep:27, loss:0.00009, loss_test:0.07957, lr:9.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:147.054, tt:4117.502\n",
      "Ep:28, loss:0.00008, loss_test:0.07908, lr:9.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:146.976, tt:4262.301\n",
      "Ep:29, loss:0.00008, loss_test:0.08129, lr:9.70e-03, fs:0.73750 (r=0.596,p=0.967),  time:146.938, tt:4408.137\n",
      "Ep:30, loss:0.00007, loss_test:0.07902, lr:9.61e-03, fs:0.73750 (r=0.596,p=0.967),  time:146.838, tt:4551.968\n",
      "Ep:31, loss:0.00007, loss_test:0.08157, lr:9.51e-03, fs:0.73750 (r=0.596,p=0.967),  time:146.903, tt:4700.908\n",
      "Ep:32, loss:0.00006, loss_test:0.08145, lr:9.41e-03, fs:0.73750 (r=0.596,p=0.967),  time:146.920, tt:4848.347\n",
      "Ep:33, loss:0.00006, loss_test:0.08194, lr:9.32e-03, fs:0.73750 (r=0.596,p=0.967),  time:146.903, tt:4994.701\n",
      "Ep:34, loss:0.00005, loss_test:0.08236, lr:9.23e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.000, tt:5145.012\n",
      "Ep:35, loss:0.00005, loss_test:0.08138, lr:9.14e-03, fs:0.73750 (r=0.596,p=0.967),  time:147.046, tt:5293.647\n",
      "Ep:36, loss:0.00005, loss_test:0.08292, lr:9.04e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.128, tt:5443.718\n",
      "Ep:37, loss:0.00004, loss_test:0.08043, lr:8.95e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.136, tt:5591.172\n",
      "Ep:38, loss:0.00004, loss_test:0.08305, lr:8.86e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.164, tt:5739.408\n",
      "Ep:39, loss:0.00004, loss_test:0.08398, lr:8.78e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.212, tt:5888.479\n",
      "Ep:40, loss:0.00004, loss_test:0.08280, lr:8.69e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.224, tt:6036.187\n",
      "Ep:41, loss:0.00003, loss_test:0.08536, lr:8.60e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.251, tt:6184.563\n",
      "Ep:42, loss:0.00003, loss_test:0.08331, lr:8.51e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.253, tt:6331.886\n",
      "Ep:43, loss:0.00003, loss_test:0.08766, lr:8.43e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.335, tt:6482.742\n",
      "Ep:44, loss:0.00003, loss_test:0.08588, lr:8.35e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.369, tt:6631.601\n",
      "Ep:45, loss:0.00003, loss_test:0.08389, lr:8.26e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.345, tt:6777.880\n",
      "Ep:46, loss:0.00003, loss_test:0.08604, lr:8.18e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.402, tt:6927.872\n",
      "Ep:47, loss:0.00002, loss_test:0.08494, lr:8.10e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.402, tt:7075.291\n",
      "Ep:48, loss:0.00002, loss_test:0.08407, lr:8.02e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.444, tt:7224.767\n",
      "Ep:49, loss:0.00002, loss_test:0.08643, lr:7.94e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.529, tt:7376.454\n",
      "Ep:50, loss:0.00002, loss_test:0.08447, lr:7.86e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.516, tt:7523.294\n",
      "Ep:51, loss:0.00002, loss_test:0.08581, lr:7.78e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.548, tt:7672.502\n",
      "Ep:52, loss:0.00002, loss_test:0.08455, lr:7.70e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.587, tt:7822.093\n",
      "Ep:53, loss:0.00002, loss_test:0.08461, lr:7.62e-03, fs:0.74684 (r=0.596,p=1.000),  time:147.614, tt:7971.168\n",
      "Ep:54, loss:0.00002, loss_test:0.08556, lr:7.55e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.651, tt:8120.799\n",
      "Ep:55, loss:0.00002, loss_test:0.08585, lr:7.47e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.650, tt:8268.415\n",
      "Ep:56, loss:0.00002, loss_test:0.08414, lr:7.40e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.671, tt:8417.269\n",
      "Ep:57, loss:0.00002, loss_test:0.08594, lr:7.32e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.724, tt:8567.981\n",
      "Ep:58, loss:0.00002, loss_test:0.08651, lr:7.25e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.673, tt:8712.736\n",
      "Ep:59, loss:0.00002, loss_test:0.08593, lr:7.18e-03, fs:0.74214 (r=0.596,p=0.983),  time:147.491, tt:8849.444\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00401, loss_test:0.10488, lr:1.00e-02, fs:0.70408 (r=0.697,p=0.711),  time:546.723, tt:546.723\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00256, loss_test:0.08536, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:559.830, tt:1119.661\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00174, loss_test:0.08340, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:562.530, tt:1687.590\n",
      "Ep:3, loss:0.00119, loss_test:0.08183, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:561.745, tt:2246.981\n",
      "Ep:4, loss:0.00081, loss_test:0.08458, lr:1.00e-02, fs:0.76744 (r=0.667,p=0.904),  time:562.862, tt:2814.312\n",
      "Ep:5, loss:0.00058, loss_test:0.08698, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:562.669, tt:3376.015\n",
      "Ep:6, loss:0.00042, loss_test:0.08894, lr:1.00e-02, fs:0.76364 (r=0.636,p=0.955),  time:562.626, tt:3938.383\n",
      "Ep:7, loss:0.00032, loss_test:0.09152, lr:1.00e-02, fs:0.76829 (r=0.636,p=0.969),  time:562.972, tt:4503.774\n",
      "Ep:8, loss:0.00024, loss_test:0.09307, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:562.975, tt:5066.779\n",
      "Ep:9, loss:0.00019, loss_test:0.09968, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:562.575, tt:5625.750\n",
      "Ep:10, loss:0.00014, loss_test:0.09914, lr:1.00e-02, fs:0.77301 (r=0.636,p=0.984),  time:562.165, tt:6183.813\n",
      "Ep:11, loss:0.00011, loss_test:0.09986, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:562.355, tt:6748.260\n",
      "Ep:12, loss:0.00009, loss_test:0.10191, lr:1.00e-02, fs:0.73418 (r=0.586,p=0.983),  time:562.518, tt:7312.740\n",
      "Ep:13, loss:0.00007, loss_test:0.10029, lr:9.90e-03, fs:0.73418 (r=0.586,p=0.983),  time:562.553, tt:7875.746\n",
      "Ep:14, loss:0.00006, loss_test:0.09867, lr:9.80e-03, fs:0.73418 (r=0.586,p=0.983),  time:562.160, tt:8432.393\n",
      "Ep:15, loss:0.00005, loss_test:0.09803, lr:9.70e-03, fs:0.73418 (r=0.586,p=0.983),  time:561.961, tt:8991.369\n",
      "Ep:16, loss:0.00004, loss_test:0.09687, lr:9.61e-03, fs:0.73418 (r=0.586,p=0.983),  time:561.287, tt:9541.876\n",
      "Ep:17, loss:0.00003, loss_test:0.09850, lr:9.51e-03, fs:0.73418 (r=0.586,p=0.983),  time:560.815, tt:10094.667\n",
      "Ep:18, loss:0.00003, loss_test:0.09860, lr:9.41e-03, fs:0.73418 (r=0.586,p=0.983),  time:560.224, tt:10644.263\n",
      "Ep:19, loss:0.00003, loss_test:0.09788, lr:9.32e-03, fs:0.73418 (r=0.586,p=0.983),  time:559.296, tt:11185.914\n",
      "Ep:20, loss:0.00002, loss_test:0.09909, lr:9.23e-03, fs:0.73418 (r=0.586,p=0.983),  time:559.234, tt:11743.911\n",
      "Ep:21, loss:0.00002, loss_test:0.09801, lr:9.14e-03, fs:0.73418 (r=0.586,p=0.983),  time:558.850, tt:12294.690\n",
      "Ep:22, loss:0.00002, loss_test:0.09906, lr:9.04e-03, fs:0.73418 (r=0.586,p=0.983),  time:558.610, tt:12848.021\n",
      "Ep:23, loss:0.00002, loss_test:0.09801, lr:8.95e-03, fs:0.73418 (r=0.586,p=0.983),  time:558.503, tt:13404.078\n",
      "Ep:24, loss:0.00002, loss_test:0.09872, lr:8.86e-03, fs:0.73418 (r=0.586,p=0.983),  time:558.230, tt:13955.751\n",
      "Ep:25, loss:0.00002, loss_test:0.09787, lr:8.78e-03, fs:0.73418 (r=0.586,p=0.983),  time:557.990, tt:14507.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00001, loss_test:0.09693, lr:8.69e-03, fs:0.73418 (r=0.586,p=0.983),  time:557.593, tt:15055.018\n",
      "Ep:27, loss:0.00001, loss_test:0.09764, lr:8.60e-03, fs:0.73418 (r=0.586,p=0.983),  time:556.953, tt:15594.687\n",
      "Ep:28, loss:0.00001, loss_test:0.09694, lr:8.51e-03, fs:0.73418 (r=0.586,p=0.983),  time:556.876, tt:16149.414\n",
      "Ep:29, loss:0.00001, loss_test:0.09662, lr:8.43e-03, fs:0.73418 (r=0.586,p=0.983),  time:556.186, tt:16685.593\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00401, loss_test:0.09908, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:527.843, tt:527.843\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00259, loss_test:0.07859, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:544.145, tt:1088.289\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00174, loss_test:0.07672, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:549.415, tt:1648.244\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00119, loss_test:0.07223, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:548.773, tt:2195.090\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00081, loss_test:0.07474, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:550.322, tt:2751.608\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00055, loss_test:0.07882, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:551.992, tt:3311.954\n",
      "Ep:6, loss:0.00040, loss_test:0.07444, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:552.954, tt:3870.681\n",
      "Ep:7, loss:0.00029, loss_test:0.08045, lr:1.00e-02, fs:0.79762 (r=0.677,p=0.971),  time:552.506, tt:4420.048\n",
      "Ep:8, loss:0.00022, loss_test:0.08336, lr:1.00e-02, fs:0.79042 (r=0.667,p=0.971),  time:552.422, tt:4971.799\n",
      "Ep:9, loss:0.00017, loss_test:0.08053, lr:1.00e-02, fs:0.82081 (r=0.717,p=0.959),  time:551.969, tt:5519.687\n",
      "Ep:10, loss:0.00013, loss_test:0.08238, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:551.885, tt:6070.735\n",
      "Ep:11, loss:0.00010, loss_test:0.07933, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:551.038, tt:6612.456\n",
      "Ep:12, loss:0.00008, loss_test:0.08138, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:551.213, tt:7165.767\n",
      "Ep:13, loss:0.00006, loss_test:0.08084, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:551.113, tt:7715.579\n",
      "Ep:14, loss:0.00005, loss_test:0.08236, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:551.267, tt:8269.010\n",
      "Ep:15, loss:0.00004, loss_test:0.08084, lr:1.00e-02, fs:0.82558 (r=0.717,p=0.973),  time:550.748, tt:8811.968\n",
      "Ep:16, loss:0.00004, loss_test:0.08205, lr:9.90e-03, fs:0.82558 (r=0.717,p=0.973),  time:550.697, tt:9361.850\n",
      "Ep:17, loss:0.00003, loss_test:0.08416, lr:9.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:550.409, tt:9907.354\n",
      "Ep:18, loss:0.00003, loss_test:0.08274, lr:9.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:549.856, tt:10447.272\n",
      "Ep:19, loss:0.00002, loss_test:0.08217, lr:9.61e-03, fs:0.82558 (r=0.717,p=0.973),  time:549.608, tt:10992.163\n",
      "Ep:20, loss:0.00002, loss_test:0.08154, lr:9.51e-03, fs:0.82558 (r=0.717,p=0.973),  time:549.761, tt:11544.983\n",
      "Ep:21, loss:0.00002, loss_test:0.08132, lr:9.41e-03, fs:0.82558 (r=0.717,p=0.973),  time:549.516, tt:12089.357\n",
      "Ep:22, loss:0.00002, loss_test:0.08122, lr:9.32e-03, fs:0.82558 (r=0.717,p=0.973),  time:549.211, tt:12631.853\n",
      "Ep:23, loss:0.00002, loss_test:0.08081, lr:9.23e-03, fs:0.82558 (r=0.717,p=0.973),  time:548.916, tt:13173.982\n",
      "Ep:24, loss:0.00002, loss_test:0.08205, lr:9.14e-03, fs:0.82558 (r=0.717,p=0.973),  time:548.529, tt:13713.213\n",
      "Ep:25, loss:0.00001, loss_test:0.08106, lr:9.04e-03, fs:0.82558 (r=0.717,p=0.973),  time:548.539, tt:14262.024\n",
      "Ep:26, loss:0.00001, loss_test:0.08109, lr:8.95e-03, fs:0.82558 (r=0.717,p=0.973),  time:548.167, tt:14800.500\n",
      "Ep:27, loss:0.00001, loss_test:0.08106, lr:8.86e-03, fs:0.82558 (r=0.717,p=0.973),  time:548.042, tt:15345.164\n",
      "Ep:28, loss:0.00001, loss_test:0.08063, lr:8.78e-03, fs:0.83041 (r=0.717,p=0.986),  time:547.923, tt:15889.759\n",
      "Ep:29, loss:0.00001, loss_test:0.08055, lr:8.69e-03, fs:0.83041 (r=0.717,p=0.986),  time:546.386, tt:16391.575\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,180,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,120,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,100,cv_number,6,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,80,cv_number,8,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,60,cv_number,10,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,0,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14279, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.677, tt:11.677\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14187, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.611, tt:25.221\n",
      "Ep:2, loss:0.00028, loss_test:0.14036, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:13.373, tt:40.118\n",
      "Ep:3, loss:0.00028, loss_test:0.13809, lr:1.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:14.287, tt:57.147\n",
      "Ep:4, loss:0.00027, loss_test:0.13465, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:15.895, tt:79.476\n",
      "Ep:5, loss:0.00026, loss_test:0.12995, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:17.920, tt:107.519\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12362, lr:1.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:19.443, tt:136.104\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11650, lr:1.00e-02, fs:0.67200 (r=0.848,p=0.556),  time:20.655, tt:165.242\n",
      "Ep:8, loss:0.00023, loss_test:0.11117, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:21.378, tt:192.398\n",
      "Ep:9, loss:0.00023, loss_test:0.10941, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:22.067, tt:220.667\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10855, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:22.598, tt:248.583\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10732, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:23.176, tt:278.117\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.10484, lr:1.00e-02, fs:0.67890 (r=0.747,p=0.622),  time:23.450, tt:304.851\n",
      "Ep:13, loss:0.00020, loss_test:0.10160, lr:1.00e-02, fs:0.69565 (r=0.727,p=0.667),  time:23.857, tt:334.003\n",
      "Ep:14, loss:0.00019, loss_test:0.09963, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:24.178, tt:362.667\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09830, lr:1.00e-02, fs:0.73636 (r=0.818,p=0.669),  time:24.415, tt:390.636\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09550, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:24.687, tt:419.673\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09370, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:24.824, tt:446.838\n",
      "Ep:18, loss:0.00017, loss_test:0.09317, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:25.002, tt:475.030\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09092, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:25.229, tt:504.578\n",
      "Ep:20, loss:0.00016, loss_test:0.08942, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:25.366, tt:532.678\n",
      "Ep:21, loss:0.00016, loss_test:0.08826, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:25.521, tt:561.466\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08642, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:25.663, tt:590.251\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08504, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:25.763, tt:618.309\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08384, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:25.909, tt:647.713\n",
      "Ep:25, loss:0.00014, loss_test:0.08234, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:25.990, tt:675.748\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08145, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:26.125, tt:705.365\n",
      "Ep:27, loss:0.00014, loss_test:0.08034, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:26.188, tt:733.261\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07914, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:26.267, tt:761.752\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07859, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:26.376, tt:791.290\n",
      "Ep:30, loss:0.00013, loss_test:0.07750, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:26.419, tt:818.977\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07650, lr:1.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:26.492, tt:847.741\n",
      "Ep:32, loss:0.00012, loss_test:0.07571, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:26.572, tt:876.875\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07490, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:26.555, tt:902.886\n",
      "Ep:34, loss:0.00011, loss_test:0.07415, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:26.560, tt:929.610\n",
      "Ep:35, loss:0.00011, loss_test:0.07311, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:26.596, tt:957.444\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07233, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:26.596, tt:984.050\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07179, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:26.558, tt:1009.218\n",
      "Ep:38, loss:0.00010, loss_test:0.07109, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:26.591, tt:1037.042\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07032, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:26.599, tt:1063.962\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.06955, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:26.606, tt:1090.862\n",
      "Ep:41, loss:0.00009, loss_test:0.06911, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:26.587, tt:1116.653\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.06840, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:26.598, tt:1143.718\n",
      "Ep:43, loss:0.00009, loss_test:0.06790, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:26.629, tt:1171.657\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.06752, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:26.697, tt:1201.362\n",
      "Ep:45, loss:0.00008, loss_test:0.06724, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:26.711, tt:1228.696\n",
      "Ep:46, loss:0.00008, loss_test:0.06646, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:26.741, tt:1256.819\n",
      "Ep:47, loss:0.00008, loss_test:0.06581, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:26.784, tt:1285.611\n",
      "Ep:48, loss:0.00008, loss_test:0.06553, lr:1.00e-02, fs:0.86957 (r=0.909,p=0.833),  time:26.812, tt:1313.798\n",
      "Ep:49, loss:0.00008, loss_test:0.06549, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:26.840, tt:1341.997\n",
      "Ep:50, loss:0.00007, loss_test:0.06473, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:26.869, tt:1370.300\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06424, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:26.854, tt:1396.402\n",
      "Ep:52, loss:0.00007, loss_test:0.06444, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:26.858, tt:1423.457\n",
      "Ep:53, loss:0.00007, loss_test:0.06359, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:26.881, tt:1451.560\n",
      "Ep:54, loss:0.00007, loss_test:0.06442, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:26.907, tt:1479.884\n",
      "Ep:55, loss:0.00007, loss_test:0.06325, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:26.929, tt:1508.046\n",
      "Ep:56, loss:0.00007, loss_test:0.06484, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:26.924, tt:1534.670\n",
      "Ep:57, loss:0.00007, loss_test:0.06242, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:26.917, tt:1561.177\n",
      "Ep:58, loss:0.00006, loss_test:0.06319, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:26.903, tt:1587.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00006, loss_test:0.06177, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:26.902, tt:1614.125\n",
      "Ep:60, loss:0.00006, loss_test:0.06269, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:26.898, tt:1640.748\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.06117, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:26.940, tt:1670.309\n",
      "Ep:62, loss:0.00006, loss_test:0.06176, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:26.973, tt:1699.280\n",
      "Ep:63, loss:0.00006, loss_test:0.06054, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:26.970, tt:1726.068\n",
      "Ep:64, loss:0.00006, loss_test:0.06023, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:26.988, tt:1754.208\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.06134, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:26.994, tt:1781.632\n",
      "Ep:66, loss:0.00005, loss_test:0.06010, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:27.020, tt:1810.363\n",
      "Ep:67, loss:0.00005, loss_test:0.06041, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:27.053, tt:1839.579\n",
      "Ep:68, loss:0.00005, loss_test:0.05942, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:27.074, tt:1868.103\n",
      "Ep:69, loss:0.00005, loss_test:0.05998, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:27.085, tt:1895.981\n",
      "Ep:70, loss:0.00005, loss_test:0.06114, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:27.081, tt:1922.759\n",
      "Ep:71, loss:0.00005, loss_test:0.05932, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:27.048, tt:1947.478\n",
      "Ep:72, loss:0.00005, loss_test:0.06075, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:27.035, tt:1973.590\n",
      "Ep:73, loss:0.00005, loss_test:0.05916, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:27.038, tt:2000.780\n",
      "Ep:74, loss:0.00004, loss_test:0.06049, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:27.060, tt:2029.499\n",
      "Ep:75, loss:0.00004, loss_test:0.05775, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:27.045, tt:2055.451\n",
      "Ep:76, loss:0.00004, loss_test:0.06200, lr:9.90e-03, fs:0.84043 (r=0.798,p=0.888),  time:27.043, tt:2082.310\n",
      "Ep:77, loss:0.00004, loss_test:0.05730, lr:9.80e-03, fs:0.89552 (r=0.909,p=0.882),  time:27.048, tt:2109.725\n",
      "Ep:78, loss:0.00004, loss_test:0.06020, lr:9.70e-03, fs:0.84817 (r=0.818,p=0.880),  time:27.023, tt:2134.795\n",
      "Ep:79, loss:0.00004, loss_test:0.05900, lr:9.61e-03, fs:0.85417 (r=0.828,p=0.882),  time:27.037, tt:2162.926\n",
      "Ep:80, loss:0.00004, loss_test:0.05833, lr:9.51e-03, fs:0.89447 (r=0.899,p=0.890),  time:27.048, tt:2190.918\n",
      "Ep:81, loss:0.00004, loss_test:0.05787, lr:9.41e-03, fs:0.86458 (r=0.838,p=0.892),  time:27.037, tt:2217.014\n",
      "Ep:82, loss:0.00004, loss_test:0.05980, lr:9.32e-03, fs:0.85106 (r=0.808,p=0.899),  time:27.040, tt:2244.305\n",
      "Ep:83, loss:0.00004, loss_test:0.05764, lr:9.23e-03, fs:0.87179 (r=0.859,p=0.885),  time:27.044, tt:2271.660\n",
      "Ep:84, loss:0.00004, loss_test:0.06048, lr:9.14e-03, fs:0.84043 (r=0.798,p=0.888),  time:27.067, tt:2300.720\n",
      "Ep:85, loss:0.00004, loss_test:0.05844, lr:9.04e-03, fs:0.85864 (r=0.828,p=0.891),  time:27.099, tt:2330.522\n",
      "Ep:86, loss:0.00004, loss_test:0.05769, lr:8.95e-03, fs:0.88776 (r=0.879,p=0.897),  time:27.104, tt:2358.053\n",
      "Ep:87, loss:0.00003, loss_test:0.05841, lr:8.86e-03, fs:0.86458 (r=0.838,p=0.892),  time:27.083, tt:2383.338\n",
      "Ep:88, loss:0.00003, loss_test:0.05982, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:27.072, tt:2409.407\n",
      "Ep:89, loss:0.00003, loss_test:0.05720, lr:8.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:27.084, tt:2437.526\n",
      "Ep:90, loss:0.00003, loss_test:0.05986, lr:8.60e-03, fs:0.84153 (r=0.778,p=0.917),  time:27.079, tt:2464.146\n",
      "Ep:91, loss:0.00003, loss_test:0.05819, lr:8.51e-03, fs:0.85263 (r=0.818,p=0.890),  time:27.090, tt:2492.266\n",
      "Ep:92, loss:0.00003, loss_test:0.05908, lr:8.43e-03, fs:0.83871 (r=0.788,p=0.897),  time:27.100, tt:2520.309\n",
      "Ep:93, loss:0.00003, loss_test:0.05870, lr:8.35e-03, fs:0.84946 (r=0.798,p=0.908),  time:27.123, tt:2549.532\n",
      "Ep:94, loss:0.00003, loss_test:0.05924, lr:8.26e-03, fs:0.83060 (r=0.768,p=0.905),  time:27.121, tt:2576.524\n",
      "Ep:95, loss:0.00003, loss_test:0.05929, lr:8.18e-03, fs:0.83696 (r=0.778,p=0.906),  time:27.132, tt:2604.691\n",
      "Ep:96, loss:0.00003, loss_test:0.05921, lr:8.10e-03, fs:0.81768 (r=0.747,p=0.902),  time:27.150, tt:2633.570\n",
      "Ep:97, loss:0.00003, loss_test:0.05929, lr:8.02e-03, fs:0.81111 (r=0.737,p=0.901),  time:27.135, tt:2659.237\n",
      "Ep:98, loss:0.00003, loss_test:0.05873, lr:7.94e-03, fs:0.84324 (r=0.788,p=0.907),  time:27.146, tt:2687.439\n",
      "Ep:99, loss:0.00003, loss_test:0.05834, lr:7.86e-03, fs:0.83060 (r=0.768,p=0.905),  time:27.155, tt:2715.487\n",
      "Ep:100, loss:0.00003, loss_test:0.05909, lr:7.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:27.166, tt:2743.774\n",
      "Ep:101, loss:0.00003, loss_test:0.05935, lr:7.70e-03, fs:0.79545 (r=0.707,p=0.909),  time:27.165, tt:2770.813\n",
      "Ep:102, loss:0.00003, loss_test:0.05895, lr:7.62e-03, fs:0.82022 (r=0.737,p=0.924),  time:27.174, tt:2798.882\n",
      "Ep:103, loss:0.00003, loss_test:0.05858, lr:7.55e-03, fs:0.84324 (r=0.788,p=0.907),  time:27.169, tt:2825.566\n",
      "Ep:104, loss:0.00003, loss_test:0.06038, lr:7.47e-03, fs:0.79769 (r=0.697,p=0.932),  time:27.178, tt:2853.698\n",
      "Ep:105, loss:0.00003, loss_test:0.05807, lr:7.40e-03, fs:0.84324 (r=0.788,p=0.907),  time:27.189, tt:2882.042\n",
      "Ep:106, loss:0.00002, loss_test:0.06092, lr:7.32e-03, fs:0.79070 (r=0.687,p=0.932),  time:27.195, tt:2909.869\n",
      "Ep:107, loss:0.00002, loss_test:0.05900, lr:7.25e-03, fs:0.80460 (r=0.707,p=0.933),  time:27.203, tt:2937.941\n",
      "Ep:108, loss:0.00002, loss_test:0.05922, lr:7.18e-03, fs:0.80000 (r=0.707,p=0.921),  time:27.214, tt:2966.356\n",
      "Ep:109, loss:0.00002, loss_test:0.05949, lr:7.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:27.235, tt:2995.807\n",
      "Ep:110, loss:0.00002, loss_test:0.06033, lr:7.03e-03, fs:0.79070 (r=0.687,p=0.932),  time:27.256, tt:3025.433\n",
      "Ep:111, loss:0.00002, loss_test:0.05804, lr:6.96e-03, fs:0.85405 (r=0.798,p=0.919),  time:27.271, tt:3054.313\n",
      "Ep:112, loss:0.00002, loss_test:0.06112, lr:6.89e-03, fs:0.79070 (r=0.687,p=0.932),  time:27.276, tt:3082.244\n",
      "Ep:113, loss:0.00002, loss_test:0.05904, lr:6.83e-03, fs:0.82682 (r=0.747,p=0.925),  time:27.286, tt:3110.635\n",
      "Ep:114, loss:0.00002, loss_test:0.06026, lr:6.76e-03, fs:0.78613 (r=0.687,p=0.919),  time:27.300, tt:3139.554\n",
      "Ep:115, loss:0.00002, loss_test:0.05923, lr:6.69e-03, fs:0.80000 (r=0.707,p=0.921),  time:27.317, tt:3168.753\n",
      "Ep:116, loss:0.00002, loss_test:0.05910, lr:6.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:27.356, tt:3200.660\n",
      "Ep:117, loss:0.00002, loss_test:0.05938, lr:6.56e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.394, tt:3232.506\n",
      "Ep:118, loss:0.00002, loss_test:0.06012, lr:6.49e-03, fs:0.79070 (r=0.687,p=0.932),  time:27.440, tt:3265.343\n",
      "Ep:119, loss:0.00002, loss_test:0.05855, lr:6.43e-03, fs:0.82222 (r=0.747,p=0.914),  time:27.460, tt:3295.154\n",
      "Ep:120, loss:0.00002, loss_test:0.06127, lr:6.36e-03, fs:0.79532 (r=0.687,p=0.944),  time:27.491, tt:3326.418\n",
      "Ep:121, loss:0.00002, loss_test:0.05971, lr:6.30e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.516, tt:3356.909\n",
      "Ep:122, loss:0.00002, loss_test:0.05896, lr:6.24e-03, fs:0.82955 (r=0.737,p=0.948),  time:27.550, tt:3388.677\n",
      "Ep:123, loss:0.00002, loss_test:0.05998, lr:6.17e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.569, tt:3418.532\n",
      "Ep:124, loss:0.00002, loss_test:0.05912, lr:6.11e-03, fs:0.80925 (r=0.707,p=0.946),  time:27.596, tt:3449.523\n",
      "Ep:125, loss:0.00002, loss_test:0.06026, lr:6.05e-03, fs:0.80702 (r=0.697,p=0.958),  time:27.619, tt:3479.955\n",
      "Ep:126, loss:0.00002, loss_test:0.05911, lr:5.99e-03, fs:0.80702 (r=0.697,p=0.958),  time:27.643, tt:3510.712\n",
      "Ep:127, loss:0.00002, loss_test:0.05871, lr:5.93e-03, fs:0.82955 (r=0.737,p=0.948),  time:27.665, tt:3541.075\n",
      "Ep:128, loss:0.00002, loss_test:0.05999, lr:5.87e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.687, tt:3571.577\n",
      "Ep:129, loss:0.00002, loss_test:0.05912, lr:5.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:27.712, tt:3602.497\n",
      "Ep:130, loss:0.00002, loss_test:0.05861, lr:5.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:27.748, tt:3635.032\n",
      "Ep:131, loss:0.00002, loss_test:0.06007, lr:5.70e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.779, tt:3666.775\n",
      "Ep:132, loss:0.00002, loss_test:0.05896, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:27.807, tt:3698.366\n",
      "Ep:133, loss:0.00002, loss_test:0.05912, lr:5.58e-03, fs:0.80233 (r=0.697,p=0.945),  time:27.833, tt:3729.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00002, loss_test:0.05952, lr:5.53e-03, fs:0.79532 (r=0.687,p=0.944),  time:27.868, tt:3762.227\n",
      "Ep:135, loss:0.00002, loss_test:0.05892, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:27.895, tt:3793.659\n",
      "Ep:136, loss:0.00002, loss_test:0.06098, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:27.933, tt:3826.758\n",
      "Ep:137, loss:0.00002, loss_test:0.05780, lr:5.36e-03, fs:0.84270 (r=0.758,p=0.949),  time:27.955, tt:3857.809\n",
      "Ep:138, loss:0.00002, loss_test:0.06043, lr:5.31e-03, fs:0.80000 (r=0.687,p=0.958),  time:27.978, tt:3888.899\n",
      "Ep:139, loss:0.00002, loss_test:0.05991, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:27.995, tt:3919.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14463, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.443, tt:32.443\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14386, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.171, tt:64.341\n",
      "Ep:2, loss:0.00028, loss_test:0.14260, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.208, tt:93.624\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.14064, lr:1.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:29.920, tt:119.681\n",
      "Ep:4, loss:0.00027, loss_test:0.13786, lr:1.00e-02, fs:0.63082 (r=0.889,p=0.489),  time:29.159, tt:145.793\n",
      "Ep:5, loss:0.00026, loss_test:0.13469, lr:1.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:29.442, tt:176.650\n",
      "Ep:6, loss:0.00025, loss_test:0.13063, lr:1.00e-02, fs:0.64286 (r=0.727,p=0.576),  time:29.661, tt:207.626\n",
      "Ep:7, loss:0.00023, loss_test:0.12839, lr:1.00e-02, fs:0.60825 (r=0.596,p=0.621),  time:30.170, tt:241.362\n",
      "Ep:8, loss:0.00022, loss_test:0.12633, lr:1.00e-02, fs:0.62766 (r=0.596,p=0.663),  time:30.408, tt:273.673\n",
      "Ep:9, loss:0.00022, loss_test:0.12453, lr:1.00e-02, fs:0.63388 (r=0.586,p=0.690),  time:30.488, tt:304.882\n",
      "Ep:10, loss:0.00021, loss_test:0.12327, lr:1.00e-02, fs:0.63043 (r=0.586,p=0.682),  time:30.650, tt:337.145\n",
      "Ep:11, loss:0.00020, loss_test:0.12278, lr:1.00e-02, fs:0.63736 (r=0.586,p=0.699),  time:30.805, tt:369.656\n",
      "Ep:12, loss:0.00020, loss_test:0.12158, lr:1.00e-02, fs:0.63218 (r=0.556,p=0.733),  time:30.945, tt:402.283\n",
      "Ep:13, loss:0.00019, loss_test:0.11907, lr:1.00e-02, fs:0.62857 (r=0.556,p=0.724),  time:30.952, tt:433.329\n",
      "Ep:14, loss:0.00019, loss_test:0.11704, lr:9.90e-03, fs:0.62570 (r=0.566,p=0.700),  time:31.153, tt:467.300\n",
      "Ep:15, loss:0.00018, loss_test:0.11585, lr:9.80e-03, fs:0.64088 (r=0.586,p=0.707),  time:31.168, tt:498.696\n",
      "Ep:16, loss:0.00018, loss_test:0.11508, lr:9.70e-03, fs:0.63687 (r=0.576,p=0.713),  time:31.199, tt:530.378\n",
      "Ep:17, loss:0.00017, loss_test:0.11445, lr:9.61e-03, fs:0.63687 (r=0.576,p=0.713),  time:31.174, tt:561.134\n",
      "Ep:18, loss:0.00017, loss_test:0.11320, lr:9.51e-03, fs:0.64804 (r=0.586,p=0.725),  time:31.251, tt:593.767\n",
      "Ep:19, loss:0.00016, loss_test:0.11221, lr:9.41e-03, fs:0.65537 (r=0.586,p=0.744),  time:31.280, tt:625.594\n",
      "Ep:20, loss:0.00016, loss_test:0.11157, lr:9.32e-03, fs:0.66298 (r=0.606,p=0.732),  time:31.325, tt:657.825\n",
      "Ep:21, loss:0.00015, loss_test:0.11038, lr:9.23e-03, fs:0.65143 (r=0.576,p=0.750),  time:31.366, tt:690.052\n",
      "Ep:22, loss:0.00015, loss_test:0.10900, lr:9.14e-03, fs:0.67816 (r=0.596,p=0.787),  time:31.347, tt:720.983\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.10834, lr:9.14e-03, fs:0.68539 (r=0.616,p=0.772),  time:31.348, tt:752.351\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.10866, lr:9.14e-03, fs:0.67816 (r=0.596,p=0.787),  time:31.350, tt:783.749\n",
      "Ep:25, loss:0.00014, loss_test:0.10820, lr:9.14e-03, fs:0.68208 (r=0.596,p=0.797),  time:31.348, tt:815.036\n",
      "Ep:26, loss:0.00013, loss_test:0.10786, lr:9.14e-03, fs:0.67836 (r=0.586,p=0.806),  time:31.382, tt:847.319\n",
      "Ep:27, loss:0.00013, loss_test:0.10718, lr:9.14e-03, fs:0.68571 (r=0.606,p=0.789),  time:31.375, tt:878.488\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.10705, lr:9.14e-03, fs:0.68605 (r=0.596,p=0.808),  time:31.408, tt:910.845\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.10648, lr:9.14e-03, fs:0.68208 (r=0.596,p=0.797),  time:31.433, tt:943.002\n",
      "Ep:30, loss:0.00012, loss_test:0.10674, lr:9.14e-03, fs:0.67836 (r=0.586,p=0.806),  time:31.457, tt:975.166\n",
      "Ep:31, loss:0.00012, loss_test:0.10548, lr:9.14e-03, fs:0.67442 (r=0.586,p=0.795),  time:31.514, tt:1008.433\n",
      "Ep:32, loss:0.00012, loss_test:0.10588, lr:9.14e-03, fs:0.67059 (r=0.576,p=0.803),  time:31.523, tt:1040.260\n",
      "Ep:33, loss:0.00011, loss_test:0.10500, lr:9.14e-03, fs:0.66667 (r=0.576,p=0.792),  time:31.476, tt:1070.179\n",
      "Ep:34, loss:0.00011, loss_test:0.10443, lr:9.14e-03, fs:0.66667 (r=0.576,p=0.792),  time:31.542, tt:1103.963\n",
      "Ep:35, loss:0.00011, loss_test:0.10565, lr:9.14e-03, fs:0.65868 (r=0.556,p=0.809),  time:31.548, tt:1135.718\n",
      "Ep:36, loss:0.00010, loss_test:0.10333, lr:9.14e-03, fs:0.65089 (r=0.556,p=0.786),  time:31.577, tt:1168.357\n",
      "Ep:37, loss:0.00010, loss_test:0.10460, lr:9.14e-03, fs:0.65060 (r=0.545,p=0.806),  time:31.557, tt:1199.151\n",
      "Ep:38, loss:0.00010, loss_test:0.10338, lr:9.14e-03, fs:0.65476 (r=0.556,p=0.797),  time:31.549, tt:1230.428\n",
      "Ep:39, loss:0.00010, loss_test:0.10507, lr:9.14e-03, fs:0.64242 (r=0.535,p=0.803),  time:31.579, tt:1263.156\n",
      "Ep:40, loss:0.00010, loss_test:0.10307, lr:9.04e-03, fs:0.65476 (r=0.556,p=0.797),  time:31.566, tt:1294.215\n",
      "Ep:41, loss:0.00009, loss_test:0.10414, lr:8.95e-03, fs:0.64634 (r=0.535,p=0.815),  time:31.613, tt:1327.726\n",
      "Ep:42, loss:0.00009, loss_test:0.10565, lr:8.86e-03, fs:0.65839 (r=0.535,p=0.855),  time:31.621, tt:1359.697\n",
      "Ep:43, loss:0.00009, loss_test:0.10229, lr:8.78e-03, fs:0.65476 (r=0.556,p=0.797),  time:31.633, tt:1391.836\n",
      "Ep:44, loss:0.00009, loss_test:0.10659, lr:8.69e-03, fs:0.63291 (r=0.505,p=0.847),  time:31.572, tt:1420.760\n",
      "Ep:45, loss:0.00009, loss_test:0.10186, lr:8.60e-03, fs:0.66272 (r=0.566,p=0.800),  time:31.573, tt:1452.336\n",
      "Ep:46, loss:0.00008, loss_test:0.10667, lr:8.51e-03, fs:0.64968 (r=0.515,p=0.879),  time:31.510, tt:1480.989\n",
      "Ep:47, loss:0.00008, loss_test:0.10560, lr:8.43e-03, fs:0.65409 (r=0.525,p=0.867),  time:31.510, tt:1512.477\n",
      "Ep:48, loss:0.00008, loss_test:0.10220, lr:8.35e-03, fs:0.65854 (r=0.545,p=0.831),  time:31.507, tt:1543.840\n",
      "Ep:49, loss:0.00008, loss_test:0.10910, lr:8.26e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.478, tt:1573.896\n",
      "Ep:50, loss:0.00008, loss_test:0.10388, lr:8.18e-03, fs:0.65839 (r=0.535,p=0.855),  time:31.448, tt:1603.828\n",
      "Ep:51, loss:0.00008, loss_test:0.10596, lr:8.10e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.434, tt:1634.583\n",
      "Ep:52, loss:0.00007, loss_test:0.10578, lr:8.02e-03, fs:0.65385 (r=0.515,p=0.895),  time:31.438, tt:1666.194\n",
      "Ep:53, loss:0.00007, loss_test:0.10291, lr:7.94e-03, fs:0.66250 (r=0.535,p=0.869),  time:31.427, tt:1697.045\n",
      "Ep:54, loss:0.00007, loss_test:0.10802, lr:7.86e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.426, tt:1728.447\n",
      "Ep:55, loss:0.00007, loss_test:0.10149, lr:7.78e-03, fs:0.65839 (r=0.535,p=0.855),  time:31.409, tt:1758.887\n",
      "Ep:56, loss:0.00007, loss_test:0.10759, lr:7.70e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.393, tt:1789.394\n",
      "Ep:57, loss:0.00007, loss_test:0.10483, lr:7.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.394, tt:1820.881\n",
      "Ep:58, loss:0.00007, loss_test:0.10239, lr:7.55e-03, fs:0.65409 (r=0.525,p=0.867),  time:31.402, tt:1852.732\n",
      "Ep:59, loss:0.00007, loss_test:0.10743, lr:7.47e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.395, tt:1883.723\n",
      "Ep:60, loss:0.00006, loss_test:0.10193, lr:7.40e-03, fs:0.65409 (r=0.525,p=0.867),  time:31.382, tt:1914.307\n",
      "Ep:61, loss:0.00006, loss_test:0.10398, lr:7.32e-03, fs:0.64968 (r=0.515,p=0.879),  time:31.396, tt:1946.553\n",
      "Ep:62, loss:0.00006, loss_test:0.10589, lr:7.25e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.397, tt:1978.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00006, loss_test:0.10171, lr:7.18e-03, fs:0.65409 (r=0.525,p=0.867),  time:31.426, tt:2011.284\n",
      "Ep:64, loss:0.00006, loss_test:0.10440, lr:7.11e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.418, tt:2042.143\n",
      "Ep:65, loss:0.00006, loss_test:0.10383, lr:7.03e-03, fs:0.65385 (r=0.515,p=0.895),  time:31.422, tt:2073.842\n",
      "Ep:66, loss:0.00006, loss_test:0.10301, lr:6.96e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.411, tt:2104.505\n",
      "Ep:67, loss:0.00006, loss_test:0.10376, lr:6.89e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.401, tt:2135.293\n",
      "Ep:68, loss:0.00006, loss_test:0.10399, lr:6.83e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.405, tt:2166.953\n",
      "Ep:69, loss:0.00006, loss_test:0.10255, lr:6.76e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.389, tt:2197.197\n",
      "Ep:70, loss:0.00006, loss_test:0.10494, lr:6.69e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.366, tt:2226.956\n",
      "Ep:71, loss:0.00005, loss_test:0.10430, lr:6.62e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.354, tt:2257.467\n",
      "Ep:72, loss:0.00005, loss_test:0.10168, lr:6.56e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.330, tt:2287.109\n",
      "Ep:73, loss:0.00005, loss_test:0.10450, lr:6.49e-03, fs:0.65806 (r=0.515,p=0.911),  time:31.321, tt:2317.723\n",
      "Ep:74, loss:0.00005, loss_test:0.10375, lr:6.43e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.299, tt:2347.402\n",
      "Ep:75, loss:0.00005, loss_test:0.10326, lr:6.36e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.280, tt:2377.277\n",
      "Ep:76, loss:0.00005, loss_test:0.10474, lr:6.30e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.283, tt:2408.816\n",
      "Ep:77, loss:0.00005, loss_test:0.10233, lr:6.24e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.273, tt:2439.296\n",
      "Ep:78, loss:0.00005, loss_test:0.10353, lr:6.17e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.270, tt:2470.367\n",
      "Ep:79, loss:0.00005, loss_test:0.10328, lr:6.11e-03, fs:0.64516 (r=0.505,p=0.893),  time:31.261, tt:2500.878\n",
      "Ep:80, loss:0.00005, loss_test:0.10290, lr:6.05e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.239, tt:2530.357\n",
      "Ep:81, loss:0.00005, loss_test:0.10272, lr:5.99e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.236, tt:2561.368\n",
      "Ep:82, loss:0.00005, loss_test:0.10385, lr:5.93e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.240, tt:2592.931\n",
      "Ep:83, loss:0.00005, loss_test:0.10382, lr:5.87e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.239, tt:2624.066\n",
      "Ep:84, loss:0.00005, loss_test:0.10021, lr:5.81e-03, fs:0.64151 (r=0.515,p=0.850),  time:31.240, tt:2655.417\n",
      "Ep:85, loss:0.00005, loss_test:0.10468, lr:5.75e-03, fs:0.65359 (r=0.505,p=0.926),  time:31.245, tt:2687.052\n",
      "Ep:86, loss:0.00005, loss_test:0.10325, lr:5.70e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.246, tt:2718.376\n",
      "Ep:87, loss:0.00005, loss_test:0.10204, lr:5.64e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.249, tt:2749.929\n",
      "Ep:88, loss:0.00004, loss_test:0.10382, lr:5.58e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.253, tt:2781.548\n",
      "Ep:89, loss:0.00004, loss_test:0.10315, lr:5.53e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.254, tt:2812.871\n",
      "Ep:90, loss:0.00004, loss_test:0.10186, lr:5.47e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.245, tt:2843.283\n",
      "Ep:91, loss:0.00004, loss_test:0.10277, lr:5.42e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.245, tt:2874.514\n",
      "Ep:92, loss:0.00004, loss_test:0.10246, lr:5.36e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.239, tt:2905.258\n",
      "Ep:93, loss:0.00004, loss_test:0.10341, lr:5.31e-03, fs:0.64103 (r=0.505,p=0.877),  time:31.226, tt:2935.229\n",
      "Ep:94, loss:0.00004, loss_test:0.10388, lr:5.26e-03, fs:0.64935 (r=0.505,p=0.909),  time:31.232, tt:2967.035\n",
      "Ep:95, loss:0.00004, loss_test:0.10179, lr:5.20e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.222, tt:2997.322\n",
      "Ep:96, loss:0.00004, loss_test:0.10310, lr:5.15e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.205, tt:3026.913\n",
      "Ep:97, loss:0.00004, loss_test:0.10398, lr:5.10e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.211, tt:3058.636\n",
      "Ep:98, loss:0.00004, loss_test:0.10219, lr:5.05e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.222, tt:3091.012\n",
      "Ep:99, loss:0.00004, loss_test:0.10304, lr:5.00e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.229, tt:3122.875\n",
      "Ep:100, loss:0.00004, loss_test:0.10391, lr:4.95e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.226, tt:3153.779\n",
      "Ep:101, loss:0.00004, loss_test:0.10289, lr:4.90e-03, fs:0.63636 (r=0.495,p=0.891),  time:31.227, tt:3185.204\n",
      "Ep:102, loss:0.00004, loss_test:0.10136, lr:4.85e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.240, tt:3217.680\n",
      "Ep:103, loss:0.00004, loss_test:0.10423, lr:4.80e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.220, tt:3246.847\n",
      "Ep:104, loss:0.00004, loss_test:0.10454, lr:4.75e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.220, tt:3278.082\n",
      "Ep:105, loss:0.00004, loss_test:0.10134, lr:4.71e-03, fs:0.63226 (r=0.495,p=0.875),  time:31.212, tt:3308.525\n",
      "Ep:106, loss:0.00004, loss_test:0.10297, lr:4.66e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.214, tt:3339.883\n",
      "Ep:107, loss:0.00004, loss_test:0.10441, lr:4.61e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.195, tt:3369.063\n",
      "Ep:108, loss:0.00004, loss_test:0.10078, lr:4.57e-03, fs:0.62821 (r=0.495,p=0.860),  time:31.181, tt:3398.704\n",
      "Ep:109, loss:0.00004, loss_test:0.10324, lr:4.52e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.176, tt:3429.339\n",
      "Ep:110, loss:0.00004, loss_test:0.10511, lr:4.48e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.174, tt:3460.344\n",
      "Ep:111, loss:0.00004, loss_test:0.10380, lr:4.43e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.181, tt:3492.234\n",
      "Ep:112, loss:0.00004, loss_test:0.10211, lr:4.39e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.180, tt:3523.358\n",
      "Ep:113, loss:0.00004, loss_test:0.10318, lr:4.34e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.187, tt:3555.309\n",
      "Ep:114, loss:0.00004, loss_test:0.10361, lr:4.30e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.178, tt:3585.512\n",
      "Ep:115, loss:0.00004, loss_test:0.10290, lr:4.26e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.161, tt:3614.682\n",
      "Ep:116, loss:0.00003, loss_test:0.10253, lr:4.21e-03, fs:0.63636 (r=0.495,p=0.891),  time:31.157, tt:3645.362\n",
      "Ep:117, loss:0.00003, loss_test:0.10322, lr:4.17e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.154, tt:3676.177\n",
      "Ep:118, loss:0.00003, loss_test:0.10420, lr:4.13e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.136, tt:3705.233\n",
      "Ep:119, loss:0.00003, loss_test:0.10252, lr:4.09e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.143, tt:3737.116\n",
      "Ep:120, loss:0.00003, loss_test:0.10295, lr:4.05e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.154, tt:3769.593\n",
      "Ep:121, loss:0.00003, loss_test:0.10325, lr:4.01e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.137, tt:3798.701\n",
      "Ep:122, loss:0.00003, loss_test:0.10369, lr:3.97e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.135, tt:3829.664\n",
      "Ep:123, loss:0.00003, loss_test:0.10371, lr:3.93e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.133, tt:3860.523\n",
      "Ep:124, loss:0.00003, loss_test:0.10302, lr:3.89e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.120, tt:3890.033\n",
      "Ep:125, loss:0.00003, loss_test:0.10432, lr:3.85e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.120, tt:3921.088\n",
      "Ep:126, loss:0.00003, loss_test:0.10415, lr:3.81e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.115, tt:3951.627\n",
      "Ep:127, loss:0.00003, loss_test:0.10275, lr:3.77e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.121, tt:3983.530\n",
      "Ep:128, loss:0.00003, loss_test:0.10327, lr:3.73e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.120, tt:4014.433\n",
      "Ep:129, loss:0.00003, loss_test:0.10530, lr:3.70e-03, fs:0.64474 (r=0.495,p=0.925),  time:31.127, tt:4046.457\n",
      "Ep:130, loss:0.00003, loss_test:0.10375, lr:3.66e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.130, tt:4078.055\n",
      "Ep:131, loss:0.00003, loss_test:0.10317, lr:3.62e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.128, tt:4108.890\n",
      "Ep:132, loss:0.00003, loss_test:0.10405, lr:3.59e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.133, tt:4140.682\n",
      "Ep:133, loss:0.00003, loss_test:0.10474, lr:3.55e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.152, tt:4174.345\n",
      "Ep:134, loss:0.00003, loss_test:0.10297, lr:3.52e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.147, tt:4204.893\n",
      "Ep:135, loss:0.00003, loss_test:0.10380, lr:3.48e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.142, tt:4235.344\n",
      "Ep:136, loss:0.00003, loss_test:0.10585, lr:3.45e-03, fs:0.64474 (r=0.495,p=0.925),  time:31.140, tt:4266.249\n",
      "Ep:137, loss:0.00003, loss_test:0.10436, lr:3.41e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.130, tt:4295.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00003, loss_test:0.10301, lr:3.38e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.104, tt:4323.492\n",
      "Ep:139, loss:0.00003, loss_test:0.10457, lr:3.34e-03, fs:0.64052 (r=0.495,p=0.907),  time:31.075, tt:4350.568\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"5-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,140,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 16\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 14208 Test samples: 198\n",
      "Train positive samples: 7104 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00188, loss_test:0.12205, lr:1.00e-02, fs:0.65532 (r=0.778,p=0.566),  time:238.042, tt:238.042\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00152, loss_test:0.10798, lr:1.00e-02, fs:0.63317 (r=0.636,p=0.630),  time:236.400, tt:472.801\n",
      "Ep:2, loss:0.00127, loss_test:0.10047, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:238.415, tt:715.244\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00110, loss_test:0.09446, lr:1.00e-02, fs:0.71658 (r=0.677,p=0.761),  time:237.234, tt:948.937\n",
      "Ep:4, loss:0.00096, loss_test:0.09242, lr:1.00e-02, fs:0.73224 (r=0.677,p=0.798),  time:236.711, tt:1183.557\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00082, loss_test:0.08533, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:235.841, tt:1415.044\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00070, loss_test:0.08493, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:235.834, tt:1650.842\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00058, loss_test:0.08522, lr:1.00e-02, fs:0.77457 (r=0.677,p=0.905),  time:235.655, tt:1885.240\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00048, loss_test:0.08502, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:235.252, tt:2117.264\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00040, loss_test:0.09215, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:235.397, tt:2353.966\n",
      "Ep:10, loss:0.00033, loss_test:0.08240, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:235.582, tt:2591.397\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00028, loss_test:0.08536, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:236.082, tt:2832.988\n",
      "Ep:12, loss:0.00023, loss_test:0.08607, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:235.867, tt:3066.276\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.08434, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:235.434, tt:3296.078\n",
      "Ep:14, loss:0.00017, loss_test:0.08358, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:235.008, tt:3525.117\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.08550, lr:1.00e-02, fs:0.81871 (r=0.707,p=0.972),  time:235.149, tt:3762.385\n",
      "Ep:16, loss:0.00013, loss_test:0.08805, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:234.929, tt:3993.793\n",
      "Ep:17, loss:0.00012, loss_test:0.08632, lr:1.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:234.908, tt:4228.339\n",
      "Ep:18, loss:0.00010, loss_test:0.09204, lr:1.00e-02, fs:0.79518 (r=0.667,p=0.985),  time:233.751, tt:4441.261\n",
      "Ep:19, loss:0.00009, loss_test:0.08875, lr:1.00e-02, fs:0.80240 (r=0.677,p=0.985),  time:232.661, tt:4653.213\n",
      "Ep:20, loss:0.00008, loss_test:0.09264, lr:1.00e-02, fs:0.78049 (r=0.646,p=0.985),  time:231.892, tt:4869.732\n",
      "Ep:21, loss:0.00007, loss_test:0.09309, lr:1.00e-02, fs:0.75776 (r=0.616,p=0.984),  time:231.083, tt:5083.827\n",
      "Ep:22, loss:0.00006, loss_test:0.09715, lr:1.00e-02, fs:0.75000 (r=0.606,p=0.984),  time:230.042, tt:5290.971\n",
      "Ep:23, loss:0.00006, loss_test:0.09678, lr:1.00e-02, fs:0.71429 (r=0.556,p=1.000),  time:229.109, tt:5498.626\n",
      "Ep:24, loss:0.00005, loss_test:0.09657, lr:1.00e-02, fs:0.76250 (r=0.616,p=1.000),  time:228.189, tt:5704.717\n",
      "Ep:25, loss:0.00004, loss_test:0.09725, lr:1.00e-02, fs:0.73077 (r=0.576,p=1.000),  time:227.454, tt:5913.801\n",
      "Ep:26, loss:0.00004, loss_test:0.09863, lr:9.90e-03, fs:0.71429 (r=0.556,p=1.000),  time:226.912, tt:6126.619\n",
      "Ep:27, loss:0.00003, loss_test:0.09898, lr:9.80e-03, fs:0.71429 (r=0.556,p=1.000),  time:226.383, tt:6338.710\n",
      "Ep:28, loss:0.00003, loss_test:0.09908, lr:9.70e-03, fs:0.71429 (r=0.556,p=1.000),  time:225.778, tt:6547.557\n",
      "Ep:29, loss:0.00003, loss_test:0.09986, lr:9.61e-03, fs:0.71429 (r=0.556,p=1.000),  time:221.833, tt:6654.985\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=16,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,30,cv_number,16,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.14650, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:81.008, tt:81.008\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00094, loss_test:0.14166, lr:1.00e-02, fs:0.61765 (r=0.848,p=0.486),  time:99.395, tt:198.790\n",
      "Ep:2, loss:0.00083, loss_test:0.13429, lr:1.00e-02, fs:0.63725 (r=0.657,p=0.619),  time:104.852, tt:314.557\n",
      "Ep:3, loss:0.00075, loss_test:0.12348, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:108.432, tt:433.728\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00068, loss_test:0.11861, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:110.028, tt:550.142\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00063, loss_test:0.11491, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:110.495, tt:662.967\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00058, loss_test:0.11016, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:111.451, tt:780.153\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00054, loss_test:0.10819, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:111.830, tt:894.639\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00050, loss_test:0.10471, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:112.362, tt:1011.261\n",
      "Ep:9, loss:0.00047, loss_test:0.10222, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:112.786, tt:1127.861\n",
      "Ep:10, loss:0.00044, loss_test:0.10009, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:113.144, tt:1244.583\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00041, loss_test:0.10052, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:113.352, tt:1360.221\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00038, loss_test:0.10028, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:113.733, tt:1478.534\n",
      "Ep:13, loss:0.00035, loss_test:0.09593, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:113.895, tt:1594.534\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00032, loss_test:0.09463, lr:1.00e-02, fs:0.76440 (r=0.737,p=0.793),  time:114.042, tt:1710.624\n",
      "Ep:15, loss:0.00030, loss_test:0.09232, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:114.269, tt:1828.296\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.09151, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:114.463, tt:1945.864\n",
      "Ep:17, loss:0.00025, loss_test:0.09588, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:114.592, tt:2062.648\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.09405, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:114.704, tt:2179.374\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.08812, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:114.819, tt:2296.371\n",
      "Ep:20, loss:0.00019, loss_test:0.08918, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:115.004, tt:2415.090\n",
      "Ep:21, loss:0.00017, loss_test:0.08717, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:115.056, tt:2531.236\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09194, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:115.093, tt:2647.150\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08712, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:115.144, tt:2763.444\n",
      "Ep:24, loss:0.00013, loss_test:0.08674, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:115.218, tt:2880.456\n",
      "Ep:25, loss:0.00012, loss_test:0.08805, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:115.318, tt:2998.264\n",
      "Ep:26, loss:0.00011, loss_test:0.08970, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:115.396, tt:3115.691\n",
      "Ep:27, loss:0.00010, loss_test:0.08596, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:115.406, tt:3231.366\n",
      "Ep:28, loss:0.00010, loss_test:0.08918, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:115.340, tt:3344.852\n",
      "Ep:29, loss:0.00009, loss_test:0.08904, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.432, tt:3462.951\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08863, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.405, tt:3577.561\n",
      "Ep:31, loss:0.00008, loss_test:0.08631, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:115.446, tt:3694.264\n",
      "Ep:32, loss:0.00008, loss_test:0.08921, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:115.557, tt:3813.384\n",
      "Ep:33, loss:0.00007, loss_test:0.09125, lr:1.00e-02, fs:0.83799 (r=0.758,p=0.938),  time:115.631, tt:3931.466\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.09009, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.658, tt:4048.023\n",
      "Ep:35, loss:0.00006, loss_test:0.08920, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.698, tt:4165.124\n",
      "Ep:36, loss:0.00006, loss_test:0.09283, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.689, tt:4280.480\n",
      "Ep:37, loss:0.00005, loss_test:0.09146, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.706, tt:4396.823\n",
      "Ep:38, loss:0.00005, loss_test:0.09170, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.676, tt:4511.350\n",
      "Ep:39, loss:0.00005, loss_test:0.08997, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.720, tt:4628.801\n",
      "Ep:40, loss:0.00005, loss_test:0.09349, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.753, tt:4745.868\n",
      "Ep:41, loss:0.00004, loss_test:0.09459, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:115.741, tt:4861.137\n",
      "Ep:43, loss:0.00004, loss_test:0.09456, lr:1.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:115.702, tt:5090.887\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.09798, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:115.731, tt:5207.915\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.09547, lr:1.00e-02, fs:0.84746 (r=0.758,p=0.962),  time:115.731, tt:5323.640\n",
      "Ep:46, loss:0.00003, loss_test:0.09836, lr:1.00e-02, fs:0.84571 (r=0.747,p=0.974),  time:115.782, tt:5441.735\n",
      "Ep:47, loss:0.00003, loss_test:0.09824, lr:1.00e-02, fs:0.85227 (r=0.758,p=0.974),  time:115.788, tt:5557.830\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.09929, lr:1.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:115.804, tt:5674.418\n",
      "Ep:49, loss:0.00003, loss_test:0.09955, lr:1.00e-02, fs:0.85057 (r=0.747,p=0.987),  time:115.799, tt:5789.965\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 8\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 7104 Test samples: 198\n",
      "Train positive samples: 3552 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 4096: \n",
      "Ep:0, loss:0.00007, loss_test:0.14707, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.417, tt:16.417\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.14668, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.170, tt:38.339\n",
      "Ep:2, loss:0.00007, loss_test:0.14604, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.784, tt:65.351\n",
      "Ep:3, loss:0.00007, loss_test:0.14504, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.142, tt:96.567\n",
      "Ep:4, loss:0.00007, loss_test:0.14360, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.869, tt:129.346\n",
      "Ep:5, loss:0.00007, loss_test:0.14141, lr:1.00e-02, fs:0.62937 (r=0.909,p=0.481),  time:26.857, tt:161.139\n",
      "Ep:6, loss:0.00006, loss_test:0.13801, lr:1.00e-02, fs:0.62271 (r=0.859,p=0.489),  time:27.728, tt:194.096\n",
      "Ep:7, loss:0.00006, loss_test:0.13411, lr:1.00e-02, fs:0.63813 (r=0.828,p=0.519),  time:28.027, tt:224.216\n",
      "Ep:8, loss:0.00006, loss_test:0.13149, lr:1.00e-02, fs:0.64545 (r=0.717,p=0.587),  time:28.366, tt:255.298\n",
      "Ep:9, loss:0.00006, loss_test:0.12983, lr:1.00e-02, fs:0.64322 (r=0.646,p=0.640),  time:28.792, tt:287.921\n",
      "Ep:10, loss:0.00006, loss_test:0.12730, lr:1.00e-02, fs:0.64646 (r=0.646,p=0.646),  time:29.205, tt:321.260\n",
      "Ep:11, loss:0.00005, loss_test:0.12340, lr:1.00e-02, fs:0.64706 (r=0.667,p=0.629),  time:29.459, tt:353.510\n",
      "Ep:12, loss:0.00005, loss_test:0.12064, lr:9.90e-03, fs:0.67907 (r=0.737,p=0.629),  time:29.792, tt:387.299\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00005, loss_test:0.11880, lr:9.90e-03, fs:0.67925 (r=0.727,p=0.637),  time:30.065, tt:420.916\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00005, loss_test:0.11765, lr:9.90e-03, fs:0.67961 (r=0.707,p=0.654),  time:30.227, tt:453.405\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00005, loss_test:0.11665, lr:9.90e-03, fs:0.69652 (r=0.707,p=0.686),  time:30.404, tt:486.467\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.11524, lr:9.90e-03, fs:0.68317 (r=0.697,p=0.670),  time:30.561, tt:519.540\n",
      "Ep:17, loss:0.00005, loss_test:0.11365, lr:9.90e-03, fs:0.69268 (r=0.717,p=0.670),  time:30.687, tt:552.367\n",
      "Ep:18, loss:0.00005, loss_test:0.11225, lr:9.90e-03, fs:0.68293 (r=0.707,p=0.660),  time:30.711, tt:583.501\n",
      "Ep:19, loss:0.00004, loss_test:0.11133, lr:9.90e-03, fs:0.68657 (r=0.697,p=0.676),  time:30.748, tt:614.968\n",
      "Ep:20, loss:0.00004, loss_test:0.11044, lr:9.90e-03, fs:0.69036 (r=0.687,p=0.694),  time:30.786, tt:646.511\n",
      "Ep:21, loss:0.00004, loss_test:0.10951, lr:9.90e-03, fs:0.69000 (r=0.697,p=0.683),  time:30.868, tt:679.090\n",
      "Ep:22, loss:0.00004, loss_test:0.10852, lr:9.90e-03, fs:0.68966 (r=0.707,p=0.673),  time:30.941, tt:711.648\n",
      "Ep:23, loss:0.00004, loss_test:0.10775, lr:9.90e-03, fs:0.69268 (r=0.717,p=0.670),  time:31.034, tt:744.819\n",
      "Ep:24, loss:0.00004, loss_test:0.10701, lr:9.90e-03, fs:0.68317 (r=0.697,p=0.670),  time:31.107, tt:777.686\n",
      "Ep:25, loss:0.00004, loss_test:0.10618, lr:9.90e-03, fs:0.68000 (r=0.687,p=0.673),  time:31.092, tt:808.398\n",
      "Ep:26, loss:0.00004, loss_test:0.10506, lr:9.90e-03, fs:0.68657 (r=0.697,p=0.676),  time:31.121, tt:840.269\n",
      "Ep:27, loss:0.00004, loss_test:0.10411, lr:9.80e-03, fs:0.68687 (r=0.687,p=0.687),  time:31.121, tt:871.397\n",
      "Ep:28, loss:0.00004, loss_test:0.10305, lr:9.70e-03, fs:0.69000 (r=0.697,p=0.683),  time:31.078, tt:901.268\n",
      "Ep:29, loss:0.00004, loss_test:0.10216, lr:9.61e-03, fs:0.68342 (r=0.687,p=0.680),  time:31.085, tt:932.562\n",
      "Ep:30, loss:0.00004, loss_test:0.10150, lr:9.51e-03, fs:0.68020 (r=0.677,p=0.684),  time:31.025, tt:961.774\n",
      "Ep:31, loss:0.00004, loss_test:0.10072, lr:9.41e-03, fs:0.68020 (r=0.677,p=0.684),  time:30.970, tt:991.036\n",
      "Ep:32, loss:0.00003, loss_test:0.09978, lr:9.32e-03, fs:0.69388 (r=0.687,p=0.701),  time:30.878, tt:1018.959\n",
      "Ep:33, loss:0.00003, loss_test:0.09890, lr:9.23e-03, fs:0.69697 (r=0.697,p=0.697),  time:30.783, tt:1046.631\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.09823, lr:9.23e-03, fs:0.70833 (r=0.687,p=0.731),  time:30.681, tt:1073.853\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.09757, lr:9.23e-03, fs:0.71875 (r=0.697,p=0.742),  time:30.555, tt:1099.997\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.09664, lr:9.23e-03, fs:0.71795 (r=0.707,p=0.729),  time:30.506, tt:1128.718\n",
      "Ep:37, loss:0.00003, loss_test:0.09575, lr:9.23e-03, fs:0.71795 (r=0.707,p=0.729),  time:30.509, tt:1159.354\n",
      "Ep:38, loss:0.00003, loss_test:0.09558, lr:9.23e-03, fs:0.72539 (r=0.707,p=0.745),  time:30.466, tt:1188.170\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.09445, lr:9.23e-03, fs:0.72821 (r=0.717,p=0.740),  time:30.446, tt:1217.844\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.09358, lr:9.23e-03, fs:0.73846 (r=0.727,p=0.750),  time:30.421, tt:1247.269\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.09369, lr:9.23e-03, fs:0.73958 (r=0.717,p=0.763),  time:30.375, tt:1275.750\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.09305, lr:9.23e-03, fs:0.73298 (r=0.707,p=0.761),  time:30.361, tt:1305.531\n",
      "Ep:43, loss:0.00003, loss_test:0.09253, lr:9.23e-03, fs:0.72917 (r=0.707,p=0.753),  time:30.326, tt:1334.352\n",
      "Ep:44, loss:0.00003, loss_test:0.09192, lr:9.23e-03, fs:0.72917 (r=0.707,p=0.753),  time:30.308, tt:1363.859\n",
      "Ep:45, loss:0.00003, loss_test:0.09152, lr:9.23e-03, fs:0.73684 (r=0.707,p=0.769),  time:30.272, tt:1392.525\n",
      "Ep:46, loss:0.00003, loss_test:0.09091, lr:9.23e-03, fs:0.73684 (r=0.707,p=0.769),  time:30.249, tt:1421.686\n",
      "Ep:47, loss:0.00003, loss_test:0.09038, lr:9.23e-03, fs:0.73684 (r=0.707,p=0.769),  time:30.237, tt:1451.379\n",
      "Ep:48, loss:0.00003, loss_test:0.09007, lr:9.23e-03, fs:0.73298 (r=0.707,p=0.761),  time:30.219, tt:1480.726\n",
      "Ep:49, loss:0.00002, loss_test:0.08997, lr:9.23e-03, fs:0.74074 (r=0.707,p=0.778),  time:30.137, tt:1506.841\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=8,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=4096 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,8,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 6400 Test samples: 198\n",
      "Train positive samples: 3200 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00099, loss_test:0.13991, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:65.787, tt:65.787\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00097, loss_test:0.13109, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:88.559, tt:177.117\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00090, loss_test:0.10578, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:96.446, tt:289.337\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00080, loss_test:0.09809, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:100.632, tt:402.527\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00074, loss_test:0.09072, lr:1.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:103.655, tt:518.273\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00068, loss_test:0.08560, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:105.727, tt:634.364\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00062, loss_test:0.08147, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:107.173, tt:750.214\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00058, loss_test:0.07794, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:108.033, tt:864.264\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00054, loss_test:0.07459, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:108.713, tt:978.413\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00050, loss_test:0.07152, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:109.349, tt:1093.485\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00047, loss_test:0.06874, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:109.728, tt:1207.007\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00043, loss_test:0.06707, lr:1.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:110.113, tt:1321.357\n",
      "Ep:12, loss:0.00040, loss_test:0.06491, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:110.543, tt:1437.053\n",
      "Ep:13, loss:0.00037, loss_test:0.06279, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:111.107, tt:1555.505\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00034, loss_test:0.06112, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:111.317, tt:1669.755\n",
      "Ep:15, loss:0.00030, loss_test:0.05909, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:111.430, tt:1782.880\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00028, loss_test:0.05717, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:111.709, tt:1899.046\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00025, loss_test:0.05593, lr:1.00e-02, fs:0.94118 (r=0.970,p=0.914),  time:111.922, tt:2014.588\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.05356, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:112.014, tt:2128.260\n",
      "Ep:19, loss:0.00021, loss_test:0.05416, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:112.210, tt:2244.195\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.05051, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:112.380, tt:2359.973\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.05273, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:112.543, tt:2475.938\n",
      "Ep:22, loss:0.00017, loss_test:0.04814, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:112.613, tt:2590.106\n",
      "Ep:23, loss:0.00015, loss_test:0.04927, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:112.645, tt:2703.474\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.04753, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:112.706, tt:2817.647\n",
      "Ep:25, loss:0.00013, loss_test:0.04731, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:112.787, tt:2932.470\n",
      "Ep:26, loss:0.00012, loss_test:0.04624, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:112.913, tt:3048.653\n",
      "Ep:27, loss:0.00011, loss_test:0.04559, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:113.064, tt:3165.793\n",
      "Ep:28, loss:0.00010, loss_test:0.04695, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:113.155, tt:3281.492\n",
      "Ep:29, loss:0.00009, loss_test:0.04454, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:113.212, tt:3396.351\n",
      "Ep:30, loss:0.00009, loss_test:0.04436, lr:1.00e-02, fs:0.96000 (r=0.970,p=0.950),  time:113.304, tt:3512.431\n",
      "Ep:31, loss:0.00008, loss_test:0.04425, lr:1.00e-02, fs:0.96970 (r=0.970,p=0.970),  time:113.407, tt:3629.014\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.04305, lr:1.00e-02, fs:0.96000 (r=0.970,p=0.950),  time:113.432, tt:3743.259\n",
      "Ep:33, loss:0.00007, loss_test:0.04463, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:113.496, tt:3858.863\n",
      "Ep:34, loss:0.00006, loss_test:0.04490, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.586, tt:3975.526\n",
      "Ep:35, loss:0.00006, loss_test:0.04371, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.618, tt:4090.254\n",
      "Ep:36, loss:0.00005, loss_test:0.04350, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.603, tt:4203.325\n",
      "Ep:37, loss:0.00005, loss_test:0.04649, lr:1.00e-02, fs:0.96447 (r=0.960,p=0.969),  time:113.689, tt:4320.168\n",
      "Ep:38, loss:0.00005, loss_test:0.04421, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.749, tt:4436.227\n",
      "Ep:39, loss:0.00004, loss_test:0.04508, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.868, tt:4554.706\n",
      "Ep:40, loss:0.00004, loss_test:0.04421, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.907, tt:4670.193\n",
      "Ep:41, loss:0.00004, loss_test:0.04435, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.894, tt:4783.564\n",
      "Ep:42, loss:0.00004, loss_test:0.04485, lr:1.00e-02, fs:0.95960 (r=0.960,p=0.960),  time:113.834, tt:4894.851\n",
      "Ep:43, loss:0.00003, loss_test:0.04438, lr:9.90e-03, fs:0.95960 (r=0.960,p=0.960),  time:113.885, tt:5010.950\n",
      "Ep:44, loss:0.00003, loss_test:0.04443, lr:9.80e-03, fs:0.95960 (r=0.960,p=0.960),  time:113.857, tt:5123.562\n",
      "Ep:45, loss:0.00003, loss_test:0.04481, lr:9.70e-03, fs:0.95960 (r=0.960,p=0.960),  time:113.937, tt:5241.085\n",
      "Ep:46, loss:0.00003, loss_test:0.04359, lr:9.61e-03, fs:0.95960 (r=0.960,p=0.960),  time:114.012, tt:5358.572\n",
      "Ep:47, loss:0.00002, loss_test:0.04425, lr:9.51e-03, fs:0.95960 (r=0.960,p=0.960),  time:114.041, tt:5473.955\n",
      "Ep:48, loss:0.00002, loss_test:0.04280, lr:9.41e-03, fs:0.95960 (r=0.960,p=0.960),  time:114.089, tt:5590.342\n",
      "Ep:49, loss:0.00002, loss_test:0.04492, lr:9.32e-03, fs:0.95960 (r=0.960,p=0.960),  time:113.978, tt:5698.919\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,50,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14291, lr:1.00e-02, fs:0.64384 (r=0.949,p=0.487),  time:11.749, tt:11.749\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14154, lr:1.00e-02, fs:0.64138 (r=0.939,p=0.487),  time:15.207, tt:30.414\n",
      "Ep:2, loss:0.00014, loss_test:0.13890, lr:1.00e-02, fs:0.65035 (r=0.939,p=0.497),  time:18.104, tt:54.313\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00013, loss_test:0.13455, lr:1.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:21.643, tt:86.571\n",
      "Ep:4, loss:0.00013, loss_test:0.13037, lr:1.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:23.922, tt:119.610\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00012, loss_test:0.13003, lr:1.00e-02, fs:0.65116 (r=0.707,p=0.603),  time:25.374, tt:152.244\n",
      "Ep:6, loss:0.00012, loss_test:0.12971, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:26.591, tt:186.135\n",
      "Ep:7, loss:0.00011, loss_test:0.12542, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:27.238, tt:217.906\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00011, loss_test:0.12230, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:27.804, tt:250.236\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.11941, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:28.327, tt:283.269\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00010, loss_test:0.11734, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:28.690, tt:315.587\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00010, loss_test:0.11474, lr:1.00e-02, fs:0.72637 (r=0.737,p=0.716),  time:28.861, tt:346.329\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00010, loss_test:0.11198, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:29.299, tt:380.881\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00009, loss_test:0.10985, lr:1.00e-02, fs:0.70000 (r=0.707,p=0.693),  time:29.556, tt:413.786\n",
      "Ep:14, loss:0.00009, loss_test:0.10808, lr:1.00e-02, fs:0.71795 (r=0.707,p=0.729),  time:29.837, tt:447.562\n",
      "Ep:15, loss:0.00009, loss_test:0.10585, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:30.014, tt:480.229\n",
      "Ep:16, loss:0.00009, loss_test:0.10398, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:30.177, tt:513.006\n",
      "Ep:17, loss:0.00008, loss_test:0.10256, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:30.284, tt:545.104\n",
      "Ep:18, loss:0.00008, loss_test:0.09992, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:30.340, tt:576.452\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.09818, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:30.560, tt:611.205\n",
      "Ep:20, loss:0.00008, loss_test:0.09710, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:30.612, tt:642.848\n",
      "Ep:21, loss:0.00008, loss_test:0.09510, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:30.706, tt:675.535\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00007, loss_test:0.09413, lr:1.00e-02, fs:0.73096 (r=0.727,p=0.735),  time:30.800, tt:708.399\n",
      "Ep:23, loss:0.00007, loss_test:0.09235, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:30.837, tt:740.090\n",
      "Ep:24, loss:0.00007, loss_test:0.09117, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:30.876, tt:771.909\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.09015, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:30.910, tt:803.654\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.08874, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.966, tt:836.070\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.08770, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.011, tt:868.303\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00006, loss_test:0.08630, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.077, tt:901.241\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00006, loss_test:0.08526, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.186, tt:935.577\n",
      "Ep:30, loss:0.00006, loss_test:0.08426, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:31.249, tt:968.725\n",
      "Ep:31, loss:0.00006, loss_test:0.08353, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.281, tt:1001.007\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.08260, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.358, tt:1034.803\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00006, loss_test:0.08192, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:31.435, tt:1068.780\n",
      "Ep:34, loss:0.00005, loss_test:0.08139, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:31.472, tt:1101.532\n",
      "Ep:35, loss:0.00005, loss_test:0.08072, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.491, tt:1133.688\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.08058, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:31.525, tt:1166.412\n",
      "Ep:37, loss:0.00005, loss_test:0.08005, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:31.604, tt:1200.967\n",
      "Ep:38, loss:0.00005, loss_test:0.08057, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:31.642, tt:1234.045\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07917, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:31.687, tt:1267.464\n",
      "Ep:40, loss:0.00005, loss_test:0.07959, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:31.732, tt:1300.996\n",
      "Ep:41, loss:0.00004, loss_test:0.07909, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:31.749, tt:1333.451\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00004, loss_test:0.07897, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:31.791, tt:1367.000\n",
      "Ep:43, loss:0.00004, loss_test:0.07781, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:31.828, tt:1400.428\n",
      "Ep:44, loss:0.00004, loss_test:0.07806, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:31.883, tt:1434.751\n",
      "Ep:45, loss:0.00004, loss_test:0.07769, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:31.899, tt:1467.365\n",
      "Ep:46, loss:0.00004, loss_test:0.07715, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:31.939, tt:1501.123\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.07705, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:31.959, tt:1534.014\n",
      "Ep:48, loss:0.00004, loss_test:0.07694, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.003, tt:1568.153\n",
      "Ep:49, loss:0.00004, loss_test:0.07674, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:32.020, tt:1600.979\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07563, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.073, tt:1635.728\n",
      "Ep:51, loss:0.00003, loss_test:0.07657, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:32.106, tt:1669.506\n",
      "Ep:52, loss:0.00003, loss_test:0.07587, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:32.129, tt:1702.829\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.07491, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:32.181, tt:1737.801\n",
      "Ep:54, loss:0.00003, loss_test:0.07550, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:32.197, tt:1770.832\n",
      "Ep:55, loss:0.00003, loss_test:0.07448, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:32.232, tt:1805.019\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.07403, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:32.257, tt:1838.625\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.07458, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.296, tt:1873.165\n",
      "Ep:58, loss:0.00003, loss_test:0.07488, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.302, tt:1905.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.07319, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.292, tt:1937.495\n",
      "Ep:60, loss:0.00003, loss_test:0.07452, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.343, tt:1972.927\n",
      "Ep:61, loss:0.00003, loss_test:0.07247, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:32.355, tt:2006.040\n",
      "Ep:62, loss:0.00003, loss_test:0.07392, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.369, tt:2039.267\n",
      "Ep:63, loss:0.00003, loss_test:0.07281, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.349, tt:2070.342\n",
      "Ep:64, loss:0.00002, loss_test:0.07239, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.341, tt:2102.188\n",
      "Ep:65, loss:0.00002, loss_test:0.07218, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.349, tt:2135.008\n",
      "Ep:66, loss:0.00002, loss_test:0.07215, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:32.354, tt:2167.699\n",
      "Ep:67, loss:0.00002, loss_test:0.07360, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:32.366, tt:2200.915\n",
      "Ep:68, loss:0.00002, loss_test:0.07176, lr:9.90e-03, fs:0.85106 (r=0.808,p=0.899),  time:32.380, tt:2234.243\n",
      "Ep:69, loss:0.00002, loss_test:0.07316, lr:9.80e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.396, tt:2267.710\n",
      "Ep:70, loss:0.00002, loss_test:0.07123, lr:9.70e-03, fs:0.85106 (r=0.808,p=0.899),  time:32.409, tt:2301.050\n",
      "Ep:71, loss:0.00002, loss_test:0.07304, lr:9.61e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.427, tt:2334.736\n",
      "Ep:72, loss:0.00002, loss_test:0.07122, lr:9.51e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.436, tt:2367.836\n",
      "Ep:73, loss:0.00002, loss_test:0.07448, lr:9.41e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.460, tt:2402.039\n",
      "Ep:74, loss:0.00002, loss_test:0.07083, lr:9.32e-03, fs:0.85106 (r=0.808,p=0.899),  time:32.468, tt:2435.100\n",
      "Ep:75, loss:0.00002, loss_test:0.07389, lr:9.23e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.473, tt:2467.926\n",
      "Ep:76, loss:0.00002, loss_test:0.07026, lr:9.14e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.504, tt:2502.844\n",
      "Ep:77, loss:0.00002, loss_test:0.07345, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.523, tt:2536.791\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.07006, lr:9.04e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.537, tt:2570.422\n",
      "Ep:79, loss:0.00002, loss_test:0.07346, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.559, tt:2604.694\n",
      "Ep:80, loss:0.00002, loss_test:0.07069, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.573, tt:2638.425\n",
      "Ep:81, loss:0.00002, loss_test:0.07352, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.592, tt:2672.556\n",
      "Ep:82, loss:0.00002, loss_test:0.07097, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.595, tt:2705.416\n",
      "Ep:83, loss:0.00002, loss_test:0.07241, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.613, tt:2739.469\n",
      "Ep:84, loss:0.00002, loss_test:0.07254, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.629, tt:2773.430\n",
      "Ep:85, loss:0.00002, loss_test:0.07300, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.644, tt:2807.353\n",
      "Ep:86, loss:0.00002, loss_test:0.07286, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.647, tt:2840.285\n",
      "Ep:87, loss:0.00001, loss_test:0.07209, lr:9.04e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.634, tt:2871.792\n",
      "Ep:88, loss:0.00001, loss_test:0.07351, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.632, tt:2904.287\n",
      "Ep:89, loss:0.00001, loss_test:0.07141, lr:8.95e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.625, tt:2936.268\n",
      "Ep:90, loss:0.00001, loss_test:0.07240, lr:8.86e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.622, tt:2968.632\n",
      "Ep:91, loss:0.00001, loss_test:0.06992, lr:8.78e-03, fs:0.86022 (r=0.808,p=0.920),  time:32.627, tt:3001.663\n",
      "Ep:92, loss:0.00001, loss_test:0.07350, lr:8.69e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.623, tt:3033.903\n",
      "Ep:93, loss:0.00001, loss_test:0.06996, lr:8.60e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.628, tt:3067.013\n",
      "Ep:94, loss:0.00001, loss_test:0.07323, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.645, tt:3101.240\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.07146, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.650, tt:3134.396\n",
      "Ep:96, loss:0.00001, loss_test:0.07284, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.651, tt:3167.142\n",
      "Ep:97, loss:0.00001, loss_test:0.07204, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.643, tt:3199.033\n",
      "Ep:98, loss:0.00001, loss_test:0.07214, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.651, tt:3232.464\n",
      "Ep:99, loss:0.00001, loss_test:0.07112, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.640, tt:3263.960\n",
      "Ep:100, loss:0.00001, loss_test:0.07191, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.641, tt:3296.712\n",
      "Ep:101, loss:0.00001, loss_test:0.07104, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.637, tt:3328.967\n",
      "Ep:102, loss:0.00001, loss_test:0.07159, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.638, tt:3361.734\n",
      "Ep:103, loss:0.00001, loss_test:0.07321, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.645, tt:3395.041\n",
      "Ep:104, loss:0.00001, loss_test:0.07111, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.652, tt:3428.436\n",
      "Ep:105, loss:0.00001, loss_test:0.07285, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.649, tt:3460.831\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.07035, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.651, tt:3493.677\n",
      "Ep:107, loss:0.00001, loss_test:0.07140, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.655, tt:3526.749\n",
      "Ep:108, loss:0.00001, loss_test:0.07211, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.655, tt:3559.347\n",
      "Ep:109, loss:0.00001, loss_test:0.07166, lr:8.51e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.656, tt:3592.126\n",
      "Ep:110, loss:0.00001, loss_test:0.07293, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.659, tt:3625.158\n",
      "Ep:111, loss:0.00001, loss_test:0.07316, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.663, tt:3658.277\n",
      "Ep:112, loss:0.00001, loss_test:0.07335, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.666, tt:3691.228\n",
      "Ep:113, loss:0.00001, loss_test:0.07049, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.680, tt:3725.572\n",
      "Ep:114, loss:0.00001, loss_test:0.07396, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.680, tt:3758.191\n",
      "Ep:115, loss:0.00001, loss_test:0.07072, lr:8.51e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.680, tt:3790.828\n",
      "Ep:116, loss:0.00001, loss_test:0.07654, lr:8.51e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.676, tt:3823.109\n",
      "Ep:117, loss:0.00001, loss_test:0.07119, lr:8.43e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.696, tt:3858.182\n",
      "Ep:118, loss:0.00001, loss_test:0.07424, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.709, tt:3892.369\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.07219, lr:8.35e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.717, tt:3926.087\n",
      "Ep:120, loss:0.00001, loss_test:0.07420, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.718, tt:3958.922\n",
      "Ep:121, loss:0.00001, loss_test:0.07438, lr:8.35e-03, fs:0.87912 (r=0.808,p=0.964),  time:32.718, tt:3991.633\n",
      "Ep:122, loss:0.00001, loss_test:0.07180, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.713, tt:4023.712\n",
      "Ep:123, loss:0.00001, loss_test:0.07447, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.710, tt:4056.076\n",
      "Ep:124, loss:0.00001, loss_test:0.07145, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.707, tt:4088.399\n",
      "Ep:125, loss:0.00001, loss_test:0.07508, lr:8.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.708, tt:4121.206\n",
      "Ep:126, loss:0.00001, loss_test:0.07171, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.695, tt:4152.205\n",
      "Ep:127, loss:0.00001, loss_test:0.07509, lr:8.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.704, tt:4186.084\n",
      "Ep:128, loss:0.00001, loss_test:0.07165, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.699, tt:4218.122\n",
      "Ep:129, loss:0.00001, loss_test:0.07490, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.695, tt:4250.369\n",
      "Ep:130, loss:0.00001, loss_test:0.07304, lr:8.26e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.687, tt:4281.997\n",
      "Ep:131, loss:0.00001, loss_test:0.07410, lr:8.18e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.687, tt:4314.652\n",
      "Ep:132, loss:0.00001, loss_test:0.07238, lr:8.10e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.694, tt:4348.351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.07469, lr:8.02e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.696, tt:4381.235\n",
      "Ep:134, loss:0.00001, loss_test:0.07288, lr:7.94e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.694, tt:4413.690\n",
      "Ep:135, loss:0.00001, loss_test:0.07525, lr:7.86e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.694, tt:4446.441\n",
      "Ep:136, loss:0.00001, loss_test:0.07410, lr:7.78e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.696, tt:4479.344\n",
      "Ep:137, loss:0.00001, loss_test:0.07467, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.699, tt:4512.508\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00001, loss_test:0.07570, lr:7.70e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.696, tt:4544.779\n",
      "Ep:139, loss:0.00001, loss_test:0.07289, lr:7.70e-03, fs:0.88398 (r=0.808,p=0.976),  time:32.694, tt:4577.166\n",
      "Ep:140, loss:0.00001, loss_test:0.07787, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.692, tt:4609.550\n",
      "Ep:141, loss:0.00001, loss_test:0.07337, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.689, tt:4641.829\n",
      "Ep:142, loss:0.00001, loss_test:0.07758, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.679, tt:4673.028\n",
      "Ep:143, loss:0.00001, loss_test:0.07581, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.679, tt:4705.710\n",
      "Ep:144, loss:0.00001, loss_test:0.07419, lr:7.70e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.683, tt:4738.979\n",
      "Ep:145, loss:0.00001, loss_test:0.07856, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.687, tt:4772.319\n",
      "Ep:146, loss:0.00000, loss_test:0.07393, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.679, tt:4803.863\n",
      "Ep:147, loss:0.00000, loss_test:0.07828, lr:7.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.681, tt:4836.782\n",
      "Ep:148, loss:0.00000, loss_test:0.07480, lr:7.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.687, tt:4870.415\n",
      "Ep:149, loss:0.00000, loss_test:0.07692, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.692, tt:4903.778\n",
      "Ep:150, loss:0.00000, loss_test:0.07848, lr:7.55e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.698, tt:4937.329\n",
      "Ep:151, loss:0.00000, loss_test:0.07409, lr:7.47e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.686, tt:4968.316\n",
      "Ep:152, loss:0.00000, loss_test:0.07918, lr:7.40e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.688, tt:5001.260\n",
      "Ep:153, loss:0.00000, loss_test:0.07606, lr:7.32e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.698, tt:5035.444\n",
      "Ep:154, loss:0.00000, loss_test:0.07683, lr:7.25e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.699, tt:5068.391\n",
      "Ep:155, loss:0.00000, loss_test:0.07940, lr:7.18e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.695, tt:5100.430\n",
      "Ep:156, loss:0.00000, loss_test:0.07531, lr:7.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.685, tt:5131.497\n",
      "Ep:157, loss:0.00000, loss_test:0.07813, lr:7.03e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.677, tt:5163.044\n",
      "Ep:158, loss:0.00000, loss_test:0.07655, lr:6.96e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.669, tt:5194.302\n",
      "Ep:159, loss:0.00000, loss_test:0.07628, lr:6.89e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.659, tt:5225.373\n",
      "Ep:160, loss:0.00000, loss_test:0.07818, lr:6.83e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.662, tt:5258.629\n",
      "Ep:161, loss:0.00000, loss_test:0.07551, lr:6.76e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.653, tt:5289.756\n",
      "Ep:162, loss:0.00000, loss_test:0.07820, lr:6.69e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.648, tt:5321.599\n",
      "Ep:163, loss:0.00000, loss_test:0.07719, lr:6.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.639, tt:5352.846\n",
      "Ep:164, loss:0.00000, loss_test:0.07665, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.639, tt:5385.499\n",
      "Ep:165, loss:0.00000, loss_test:0.07744, lr:6.49e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.633, tt:5417.018\n",
      "Ep:166, loss:0.00000, loss_test:0.07691, lr:6.43e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.622, tt:5447.939\n",
      "Ep:167, loss:0.00000, loss_test:0.07798, lr:6.36e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.626, tt:5481.096\n",
      "Ep:168, loss:0.00000, loss_test:0.07704, lr:6.30e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.621, tt:5512.875\n",
      "Ep:169, loss:0.00000, loss_test:0.07854, lr:6.24e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.608, tt:5543.370\n",
      "Ep:170, loss:0.00000, loss_test:0.07657, lr:6.17e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.609, tt:5576.126\n",
      "Ep:171, loss:0.00000, loss_test:0.07821, lr:6.11e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.606, tt:5608.160\n",
      "Ep:172, loss:0.00000, loss_test:0.07795, lr:6.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.600, tt:5639.731\n",
      "Ep:173, loss:0.00000, loss_test:0.07707, lr:5.99e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.593, tt:5671.198\n",
      "Ep:174, loss:0.00000, loss_test:0.07893, lr:5.93e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.596, tt:5704.273\n",
      "Ep:175, loss:0.00000, loss_test:0.07795, lr:5.87e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.591, tt:5736.092\n",
      "Ep:176, loss:0.00000, loss_test:0.07898, lr:5.81e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.585, tt:5767.620\n",
      "Ep:177, loss:0.00000, loss_test:0.07941, lr:5.75e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.580, tt:5799.158\n",
      "Ep:178, loss:0.00000, loss_test:0.07744, lr:5.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.576, tt:5831.177\n",
      "Ep:179, loss:0.00000, loss_test:0.07882, lr:5.64e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.575, tt:5863.464\n",
      "Ep:180, loss:0.00000, loss_test:0.07858, lr:5.58e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.561, tt:5893.615\n",
      "Ep:181, loss:0.00000, loss_test:0.07794, lr:5.53e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.562, tt:5926.270\n",
      "Ep:182, loss:0.00000, loss_test:0.07948, lr:5.47e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.560, tt:5958.392\n",
      "Ep:183, loss:0.00000, loss_test:0.07706, lr:5.42e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.557, tt:5990.431\n",
      "Ep:184, loss:0.00000, loss_test:0.07989, lr:5.36e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.545, tt:6020.766\n",
      "Ep:185, loss:0.00000, loss_test:0.07833, lr:5.31e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.539, tt:6052.312\n",
      "Ep:186, loss:0.00000, loss_test:0.07783, lr:5.26e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.530, tt:6083.136\n",
      "Ep:187, loss:0.00000, loss_test:0.07899, lr:5.20e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.522, tt:6114.083\n",
      "Ep:188, loss:0.00000, loss_test:0.07852, lr:5.15e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.510, tt:6144.435\n",
      "Ep:189, loss:0.00000, loss_test:0.07877, lr:5.10e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.500, tt:6174.917\n",
      "Ep:190, loss:0.00000, loss_test:0.08093, lr:5.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.496, tt:6206.659\n",
      "Ep:191, loss:0.00000, loss_test:0.07775, lr:5.00e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.501, tt:6240.182\n",
      "Ep:192, loss:0.00000, loss_test:0.07945, lr:4.95e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.497, tt:6271.905\n",
      "Ep:193, loss:0.00000, loss_test:0.07936, lr:4.90e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.482, tt:6301.556\n",
      "Ep:194, loss:0.00000, loss_test:0.07809, lr:4.85e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.481, tt:6333.759\n",
      "Ep:195, loss:0.00000, loss_test:0.07971, lr:4.80e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.497, tt:6369.343\n",
      "Ep:196, loss:0.00000, loss_test:0.07943, lr:4.75e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.492, tt:6400.867\n",
      "Ep:197, loss:0.00000, loss_test:0.07922, lr:4.71e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.488, tt:6432.678\n",
      "Ep:198, loss:0.00000, loss_test:0.08005, lr:4.66e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.488, tt:6465.068\n",
      "Ep:199, loss:0.00000, loss_test:0.07796, lr:4.61e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.485, tt:6496.969\n",
      "Ep:200, loss:0.00000, loss_test:0.08027, lr:4.57e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.475, tt:6527.460\n",
      "Ep:201, loss:0.00000, loss_test:0.08098, lr:4.52e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.471, tt:6559.216\n",
      "Ep:202, loss:0.00000, loss_test:0.07836, lr:4.48e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.471, tt:6591.538\n",
      "Ep:203, loss:0.00000, loss_test:0.07974, lr:4.43e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.449, tt:6619.645\n",
      "Ep:204, loss:0.00000, loss_test:0.07973, lr:4.39e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.424, tt:6646.956\n",
      "Ep:205, loss:0.00000, loss_test:0.07900, lr:4.34e-03, fs:0.88268 (r=0.798,p=0.988),  time:32.407, tt:6675.922\n",
      "Ep:206, loss:0.00000, loss_test:0.07915, lr:4.30e-03, fs:0.88889 (r=0.808,p=0.988),  time:32.394, tt:6705.541\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14402, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.796, tt:14.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14295, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.597, tt:41.194\n",
      "Ep:2, loss:0.00014, loss_test:0.14091, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.125, tt:72.374\n",
      "Ep:3, loss:0.00013, loss_test:0.13758, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:26.103, tt:104.412\n",
      "Ep:4, loss:0.00013, loss_test:0.13269, lr:1.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:27.557, tt:137.783\n",
      "Ep:5, loss:0.00012, loss_test:0.12727, lr:1.00e-02, fs:0.61803 (r=0.727,p=0.537),  time:28.488, tt:170.931\n",
      "Ep:6, loss:0.00011, loss_test:0.12567, lr:1.00e-02, fs:0.62802 (r=0.657,p=0.602),  time:28.970, tt:202.792\n",
      "Ep:7, loss:0.00011, loss_test:0.12470, lr:1.00e-02, fs:0.62687 (r=0.636,p=0.618),  time:29.351, tt:234.806\n",
      "Ep:8, loss:0.00011, loss_test:0.12302, lr:1.00e-02, fs:0.64762 (r=0.687,p=0.613),  time:29.805, tt:268.245\n",
      "Ep:9, loss:0.00011, loss_test:0.12172, lr:1.00e-02, fs:0.63594 (r=0.697,p=0.585),  time:30.044, tt:300.445\n",
      "Ep:10, loss:0.00010, loss_test:0.11993, lr:1.00e-02, fs:0.64789 (r=0.697,p=0.605),  time:30.244, tt:332.681\n",
      "Ep:11, loss:0.00010, loss_test:0.11769, lr:1.00e-02, fs:0.65000 (r=0.657,p=0.644),  time:30.347, tt:364.164\n",
      "Ep:12, loss:0.00010, loss_test:0.11654, lr:9.90e-03, fs:0.64286 (r=0.636,p=0.649),  time:30.505, tt:396.562\n",
      "Ep:13, loss:0.00010, loss_test:0.11486, lr:9.80e-03, fs:0.65657 (r=0.657,p=0.657),  time:30.573, tt:428.025\n",
      "Ep:14, loss:0.00009, loss_test:0.11336, lr:9.70e-03, fs:0.68966 (r=0.707,p=0.673),  time:30.624, tt:459.357\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00009, loss_test:0.11168, lr:9.70e-03, fs:0.66332 (r=0.667,p=0.660),  time:30.743, tt:491.889\n",
      "Ep:16, loss:0.00009, loss_test:0.11025, lr:9.70e-03, fs:0.66327 (r=0.657,p=0.670),  time:30.809, tt:523.761\n",
      "Ep:17, loss:0.00009, loss_test:0.10875, lr:9.70e-03, fs:0.69652 (r=0.707,p=0.686),  time:30.895, tt:556.104\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00008, loss_test:0.10762, lr:9.70e-03, fs:0.69903 (r=0.727,p=0.673),  time:30.956, tt:588.157\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.10617, lr:9.70e-03, fs:0.69307 (r=0.707,p=0.680),  time:30.999, tt:619.986\n",
      "Ep:20, loss:0.00008, loss_test:0.10486, lr:9.70e-03, fs:0.69388 (r=0.687,p=0.701),  time:31.030, tt:651.639\n",
      "Ep:21, loss:0.00008, loss_test:0.10351, lr:9.70e-03, fs:0.73171 (r=0.758,p=0.708),  time:31.016, tt:682.358\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.10253, lr:9.70e-03, fs:0.72362 (r=0.727,p=0.720),  time:31.088, tt:715.019\n",
      "Ep:23, loss:0.00007, loss_test:0.10177, lr:9.70e-03, fs:0.71429 (r=0.707,p=0.722),  time:31.233, tt:749.581\n",
      "Ep:24, loss:0.00007, loss_test:0.10029, lr:9.70e-03, fs:0.74877 (r=0.768,p=0.731),  time:31.283, tt:782.072\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.10005, lr:9.70e-03, fs:0.74877 (r=0.768,p=0.731),  time:31.358, tt:815.313\n",
      "Ep:26, loss:0.00007, loss_test:0.10002, lr:9.70e-03, fs:0.75000 (r=0.758,p=0.743),  time:31.394, tt:847.637\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00007, loss_test:0.09886, lr:9.70e-03, fs:0.75862 (r=0.778,p=0.740),  time:31.421, tt:879.785\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00007, loss_test:0.09809, lr:9.70e-03, fs:0.75377 (r=0.758,p=0.750),  time:31.517, tt:913.995\n",
      "Ep:29, loss:0.00007, loss_test:0.09738, lr:9.70e-03, fs:0.75377 (r=0.758,p=0.750),  time:31.510, tt:945.290\n",
      "Ep:30, loss:0.00006, loss_test:0.09706, lr:9.70e-03, fs:0.75377 (r=0.758,p=0.750),  time:31.542, tt:977.817\n",
      "Ep:31, loss:0.00006, loss_test:0.09640, lr:9.70e-03, fs:0.74747 (r=0.747,p=0.747),  time:31.607, tt:1011.420\n",
      "Ep:32, loss:0.00006, loss_test:0.09576, lr:9.70e-03, fs:0.75127 (r=0.747,p=0.755),  time:31.607, tt:1043.015\n",
      "Ep:33, loss:0.00006, loss_test:0.09567, lr:9.70e-03, fs:0.75127 (r=0.747,p=0.755),  time:31.624, tt:1075.226\n",
      "Ep:34, loss:0.00006, loss_test:0.09496, lr:9.70e-03, fs:0.75127 (r=0.747,p=0.755),  time:31.591, tt:1105.689\n",
      "Ep:35, loss:0.00006, loss_test:0.09472, lr:9.70e-03, fs:0.74872 (r=0.737,p=0.760),  time:31.648, tt:1139.344\n",
      "Ep:36, loss:0.00006, loss_test:0.09425, lr:9.70e-03, fs:0.75510 (r=0.747,p=0.763),  time:31.705, tt:1173.091\n",
      "Ep:37, loss:0.00006, loss_test:0.09354, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.731, tt:1205.787\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.09342, lr:9.70e-03, fs:0.75897 (r=0.747,p=0.771),  time:31.782, tt:1239.495\n",
      "Ep:39, loss:0.00005, loss_test:0.09251, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.798, tt:1271.906\n",
      "Ep:40, loss:0.00005, loss_test:0.09216, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.808, tt:1304.121\n",
      "Ep:41, loss:0.00005, loss_test:0.09187, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.840, tt:1337.284\n",
      "Ep:42, loss:0.00005, loss_test:0.09120, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.869, tt:1370.383\n",
      "Ep:43, loss:0.00005, loss_test:0.09090, lr:9.70e-03, fs:0.76923 (r=0.758,p=0.781),  time:31.864, tt:1402.022\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.09059, lr:9.70e-03, fs:0.76923 (r=0.758,p=0.781),  time:31.867, tt:1433.994\n",
      "Ep:45, loss:0.00005, loss_test:0.08987, lr:9.70e-03, fs:0.76531 (r=0.758,p=0.773),  time:31.882, tt:1466.577\n",
      "Ep:46, loss:0.00005, loss_test:0.08979, lr:9.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:31.904, tt:1499.477\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.08912, lr:9.70e-03, fs:0.78125 (r=0.758,p=0.806),  time:31.975, tt:1534.781\n",
      "Ep:48, loss:0.00004, loss_test:0.08853, lr:9.70e-03, fs:0.78534 (r=0.758,p=0.815),  time:31.969, tt:1566.472\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.08831, lr:9.70e-03, fs:0.78947 (r=0.758,p=0.824),  time:32.024, tt:1601.183\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.08821, lr:9.70e-03, fs:0.78947 (r=0.758,p=0.824),  time:32.041, tt:1634.097\n",
      "Ep:51, loss:0.00004, loss_test:0.08792, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.039, tt:1666.041\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.08749, lr:9.70e-03, fs:0.79581 (r=0.768,p=0.826),  time:32.048, tt:1698.545\n",
      "Ep:53, loss:0.00004, loss_test:0.08787, lr:9.70e-03, fs:0.79570 (r=0.747,p=0.851),  time:32.096, tt:1733.205\n",
      "Ep:54, loss:0.00004, loss_test:0.08698, lr:9.70e-03, fs:0.80423 (r=0.768,p=0.844),  time:32.131, tt:1767.217\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.08723, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:32.145, tt:1800.144\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00004, loss_test:0.08667, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.175, tt:1833.947\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.08712, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.129, tt:1863.487\n",
      "Ep:58, loss:0.00004, loss_test:0.08742, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.130, tt:1895.646\n",
      "Ep:59, loss:0.00003, loss_test:0.08586, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.138, tt:1928.292\n",
      "Ep:60, loss:0.00003, loss_test:0.08800, lr:9.70e-03, fs:0.80874 (r=0.747,p=0.881),  time:32.173, tt:1962.555\n",
      "Ep:61, loss:0.00003, loss_test:0.08518, lr:9.70e-03, fs:0.81283 (r=0.768,p=0.864),  time:32.199, tt:1996.366\n",
      "Ep:62, loss:0.00003, loss_test:0.08656, lr:9.70e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.224, tt:2030.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.08585, lr:9.70e-03, fs:0.81720 (r=0.768,p=0.874),  time:32.243, tt:2063.560\n",
      "Ep:64, loss:0.00003, loss_test:0.08553, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.243, tt:2095.797\n",
      "Ep:65, loss:0.00003, loss_test:0.08535, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.265, tt:2129.476\n",
      "Ep:66, loss:0.00003, loss_test:0.08621, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.283, tt:2162.968\n",
      "Ep:67, loss:0.00003, loss_test:0.08442, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.302, tt:2196.509\n",
      "Ep:68, loss:0.00003, loss_test:0.08688, lr:9.61e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.322, tt:2230.212\n",
      "Ep:69, loss:0.00003, loss_test:0.08484, lr:9.51e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.329, tt:2263.040\n",
      "Ep:70, loss:0.00003, loss_test:0.08523, lr:9.41e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.333, tt:2295.655\n",
      "Ep:71, loss:0.00003, loss_test:0.08529, lr:9.32e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.322, tt:2327.158\n",
      "Ep:72, loss:0.00003, loss_test:0.08436, lr:9.23e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.330, tt:2360.122\n",
      "Ep:73, loss:0.00003, loss_test:0.08615, lr:9.14e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.347, tt:2393.673\n",
      "Ep:74, loss:0.00003, loss_test:0.08399, lr:9.04e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.354, tt:2426.580\n",
      "Ep:75, loss:0.00002, loss_test:0.08642, lr:8.95e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.366, tt:2459.847\n",
      "Ep:76, loss:0.00002, loss_test:0.08470, lr:8.86e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.371, tt:2492.531\n",
      "Ep:77, loss:0.00002, loss_test:0.08557, lr:8.78e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.363, tt:2524.293\n",
      "Ep:78, loss:0.00002, loss_test:0.08549, lr:8.69e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.373, tt:2557.452\n",
      "Ep:79, loss:0.00002, loss_test:0.08471, lr:8.60e-03, fs:0.81081 (r=0.758,p=0.872),  time:32.376, tt:2590.110\n",
      "Ep:80, loss:0.00002, loss_test:0.08578, lr:8.51e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.359, tt:2621.085\n",
      "Ep:81, loss:0.00002, loss_test:0.08615, lr:8.43e-03, fs:0.80874 (r=0.747,p=0.881),  time:32.356, tt:2653.173\n",
      "Ep:82, loss:0.00002, loss_test:0.08502, lr:8.35e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.351, tt:2685.168\n",
      "Ep:83, loss:0.00002, loss_test:0.08569, lr:8.26e-03, fs:0.81522 (r=0.758,p=0.882),  time:32.339, tt:2716.479\n",
      "Ep:84, loss:0.00002, loss_test:0.08613, lr:8.18e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.339, tt:2748.814\n",
      "Ep:85, loss:0.00002, loss_test:0.08555, lr:8.10e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.345, tt:2781.645\n",
      "Ep:86, loss:0.00002, loss_test:0.08611, lr:8.02e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.345, tt:2814.000\n",
      "Ep:87, loss:0.00002, loss_test:0.08579, lr:7.94e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.341, tt:2846.018\n",
      "Ep:88, loss:0.00002, loss_test:0.08559, lr:7.86e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.332, tt:2877.533\n",
      "Ep:89, loss:0.00002, loss_test:0.08635, lr:7.78e-03, fs:0.81319 (r=0.747,p=0.892),  time:32.309, tt:2907.813\n",
      "Ep:90, loss:0.00002, loss_test:0.08566, lr:7.70e-03, fs:0.80874 (r=0.747,p=0.881),  time:32.307, tt:2939.913\n",
      "Ep:91, loss:0.00002, loss_test:0.08656, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.321, tt:2973.535\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.08601, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.331, tt:3006.788\n",
      "Ep:93, loss:0.00002, loss_test:0.08613, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.323, tt:3038.404\n",
      "Ep:94, loss:0.00002, loss_test:0.08544, lr:7.62e-03, fs:0.81768 (r=0.747,p=0.902),  time:32.325, tt:3070.848\n",
      "Ep:95, loss:0.00002, loss_test:0.08696, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.316, tt:3102.362\n",
      "Ep:96, loss:0.00002, loss_test:0.08511, lr:7.62e-03, fs:0.81967 (r=0.758,p=0.893),  time:32.302, tt:3133.251\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.08657, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.293, tt:3164.698\n",
      "Ep:98, loss:0.00002, loss_test:0.08603, lr:7.62e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.289, tt:3196.602\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.08634, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.284, tt:3228.425\n",
      "Ep:100, loss:0.00002, loss_test:0.08657, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.271, tt:3259.416\n",
      "Ep:101, loss:0.00002, loss_test:0.08661, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.272, tt:3291.718\n",
      "Ep:102, loss:0.00002, loss_test:0.08631, lr:7.62e-03, fs:0.81111 (r=0.737,p=0.901),  time:32.272, tt:3324.053\n",
      "Ep:103, loss:0.00002, loss_test:0.08672, lr:7.62e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.283, tt:3357.413\n",
      "Ep:104, loss:0.00002, loss_test:0.08789, lr:7.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:32.268, tt:3388.172\n",
      "Ep:105, loss:0.00002, loss_test:0.08534, lr:7.62e-03, fs:0.82418 (r=0.758,p=0.904),  time:32.264, tt:3420.033\n",
      "Ep:106, loss:0.00002, loss_test:0.08818, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.303, tt:3456.447\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.08623, lr:7.62e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.281, tt:3486.386\n",
      "Ep:108, loss:0.00001, loss_test:0.08715, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.268, tt:3517.188\n",
      "Ep:109, loss:0.00001, loss_test:0.08626, lr:7.62e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.250, tt:3547.506\n",
      "Ep:110, loss:0.00001, loss_test:0.08722, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.248, tt:3579.497\n",
      "Ep:111, loss:0.00001, loss_test:0.08754, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.246, tt:3611.513\n",
      "Ep:112, loss:0.00001, loss_test:0.08659, lr:7.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:32.244, tt:3643.585\n",
      "Ep:113, loss:0.00001, loss_test:0.08751, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.229, tt:3674.131\n",
      "Ep:114, loss:0.00001, loss_test:0.08573, lr:7.62e-03, fs:0.82222 (r=0.747,p=0.914),  time:32.232, tt:3706.691\n",
      "Ep:115, loss:0.00001, loss_test:0.08802, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.235, tt:3739.231\n",
      "Ep:116, loss:0.00001, loss_test:0.08561, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.241, tt:3772.170\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00001, loss_test:0.08806, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.247, tt:3805.177\n",
      "Ep:118, loss:0.00001, loss_test:0.08728, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.262, tt:3839.146\n",
      "Ep:119, loss:0.00001, loss_test:0.08695, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.243, tt:3869.208\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.08792, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.234, tt:3900.363\n",
      "Ep:121, loss:0.00001, loss_test:0.08669, lr:7.62e-03, fs:0.82682 (r=0.747,p=0.925),  time:32.229, tt:3931.898\n",
      "Ep:122, loss:0.00001, loss_test:0.08764, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.225, tt:3963.637\n",
      "Ep:123, loss:0.00001, loss_test:0.08677, lr:7.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.218, tt:3995.056\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.08723, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.224, tt:4027.990\n",
      "Ep:125, loss:0.00001, loss_test:0.08722, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.240, tt:4062.238\n",
      "Ep:126, loss:0.00001, loss_test:0.08797, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.248, tt:4095.538\n",
      "Ep:127, loss:0.00001, loss_test:0.08799, lr:7.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:32.259, tt:4129.153\n",
      "Ep:128, loss:0.00001, loss_test:0.08649, lr:7.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.251, tt:4160.396\n",
      "Ep:129, loss:0.00001, loss_test:0.08831, lr:7.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:32.253, tt:4192.880\n",
      "Ep:130, loss:0.00001, loss_test:0.08766, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.262, tt:4226.324\n",
      "Ep:131, loss:0.00001, loss_test:0.08740, lr:7.62e-03, fs:0.80233 (r=0.697,p=0.945),  time:32.270, tt:4259.598\n",
      "Ep:132, loss:0.00001, loss_test:0.08779, lr:7.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.269, tt:4291.717\n",
      "Ep:133, loss:0.00001, loss_test:0.08764, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.284, tt:4326.060\n",
      "Ep:134, loss:0.00001, loss_test:0.08786, lr:7.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.301, tt:4360.679\n",
      "Ep:135, loss:0.00001, loss_test:0.08682, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:32.304, tt:4393.376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00001, loss_test:0.08819, lr:7.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:32.307, tt:4426.007\n",
      "Ep:137, loss:0.00001, loss_test:0.08727, lr:7.40e-03, fs:0.81395 (r=0.707,p=0.959),  time:32.296, tt:4456.903\n",
      "Ep:138, loss:0.00001, loss_test:0.08797, lr:7.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.299, tt:4489.536\n",
      "Ep:139, loss:0.00001, loss_test:0.08777, lr:7.25e-03, fs:0.80000 (r=0.687,p=0.958),  time:32.305, tt:4522.643\n",
      "Ep:140, loss:0.00001, loss_test:0.08790, lr:7.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:32.307, tt:4555.246\n",
      "Ep:141, loss:0.00001, loss_test:0.08807, lr:7.11e-03, fs:0.80000 (r=0.687,p=0.958),  time:32.301, tt:4586.705\n",
      "Ep:142, loss:0.00001, loss_test:0.08784, lr:7.03e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.314, tt:4620.860\n",
      "Ep:143, loss:0.00001, loss_test:0.08894, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.307, tt:4652.205\n",
      "Ep:144, loss:0.00001, loss_test:0.08806, lr:6.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.314, tt:4685.592\n",
      "Ep:145, loss:0.00001, loss_test:0.08739, lr:6.83e-03, fs:0.81871 (r=0.707,p=0.972),  time:32.311, tt:4717.380\n",
      "Ep:146, loss:0.00001, loss_test:0.08969, lr:6.76e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.326, tt:4751.971\n",
      "Ep:147, loss:0.00001, loss_test:0.08789, lr:6.69e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.339, tt:4786.231\n",
      "Ep:148, loss:0.00001, loss_test:0.08828, lr:6.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.335, tt:4817.850\n",
      "Ep:149, loss:0.00001, loss_test:0.08975, lr:6.56e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.330, tt:4849.501\n",
      "Ep:150, loss:0.00001, loss_test:0.08799, lr:6.49e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.337, tt:4882.912\n",
      "Ep:151, loss:0.00001, loss_test:0.08929, lr:6.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.337, tt:4915.231\n",
      "Ep:152, loss:0.00001, loss_test:0.08841, lr:6.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.379, tt:4953.953\n",
      "Ep:153, loss:0.00001, loss_test:0.08867, lr:6.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.387, tt:4987.537\n",
      "Ep:154, loss:0.00001, loss_test:0.08876, lr:6.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.399, tt:5021.832\n",
      "Ep:155, loss:0.00001, loss_test:0.08825, lr:6.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.409, tt:5055.758\n",
      "Ep:156, loss:0.00001, loss_test:0.08955, lr:6.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.407, tt:5087.917\n",
      "Ep:157, loss:0.00001, loss_test:0.08845, lr:6.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.406, tt:5120.200\n",
      "Ep:158, loss:0.00001, loss_test:0.08923, lr:5.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.408, tt:5152.907\n",
      "Ep:159, loss:0.00001, loss_test:0.08921, lr:5.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.405, tt:5184.737\n",
      "Ep:160, loss:0.00001, loss_test:0.08913, lr:5.87e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.401, tt:5216.520\n",
      "Ep:161, loss:0.00001, loss_test:0.08927, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.401, tt:5248.982\n",
      "Ep:162, loss:0.00001, loss_test:0.08927, lr:5.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.402, tt:5281.509\n",
      "Ep:163, loss:0.00001, loss_test:0.08942, lr:5.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.401, tt:5313.831\n",
      "Ep:164, loss:0.00001, loss_test:0.08955, lr:5.64e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.398, tt:5345.699\n",
      "Ep:165, loss:0.00001, loss_test:0.08978, lr:5.58e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.403, tt:5378.929\n",
      "Ep:166, loss:0.00001, loss_test:0.08955, lr:5.53e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.401, tt:5410.928\n",
      "Ep:167, loss:0.00001, loss_test:0.08955, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.393, tt:5442.031\n",
      "Ep:168, loss:0.00001, loss_test:0.09009, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.385, tt:5473.009\n",
      "Ep:169, loss:0.00001, loss_test:0.08984, lr:5.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.382, tt:5504.901\n",
      "Ep:170, loss:0.00001, loss_test:0.08957, lr:5.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.380, tt:5536.904\n",
      "Ep:171, loss:0.00001, loss_test:0.09055, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.378, tt:5569.069\n",
      "Ep:172, loss:0.00001, loss_test:0.08999, lr:5.20e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.375, tt:5600.925\n",
      "Ep:173, loss:0.00001, loss_test:0.08976, lr:5.15e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.383, tt:5634.702\n",
      "Ep:174, loss:0.00001, loss_test:0.09078, lr:5.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.393, tt:5668.794\n",
      "Ep:175, loss:0.00001, loss_test:0.09022, lr:5.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.397, tt:5701.837\n",
      "Ep:176, loss:0.00001, loss_test:0.08997, lr:5.00e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.398, tt:5734.461\n",
      "Ep:177, loss:0.00001, loss_test:0.09052, lr:4.95e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.405, tt:5768.127\n",
      "Ep:178, loss:0.00001, loss_test:0.09067, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.404, tt:5800.394\n",
      "Ep:179, loss:0.00001, loss_test:0.09011, lr:4.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.409, tt:5833.646\n",
      "Ep:180, loss:0.00001, loss_test:0.09075, lr:4.80e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.402, tt:5864.713\n",
      "Ep:181, loss:0.00001, loss_test:0.09083, lr:4.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.405, tt:5897.665\n",
      "Ep:182, loss:0.00001, loss_test:0.09065, lr:4.71e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.412, tt:5931.328\n",
      "Ep:183, loss:0.00001, loss_test:0.09111, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.422, tt:5965.603\n",
      "Ep:184, loss:0.00001, loss_test:0.09037, lr:4.61e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.427, tt:5998.962\n",
      "Ep:185, loss:0.00001, loss_test:0.09128, lr:4.57e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.427, tt:6031.425\n",
      "Ep:186, loss:0.00001, loss_test:0.09138, lr:4.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.426, tt:6063.676\n",
      "Ep:187, loss:0.00001, loss_test:0.09047, lr:4.48e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.439, tt:6098.479\n",
      "Ep:188, loss:0.00001, loss_test:0.09137, lr:4.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.445, tt:6132.065\n",
      "Ep:189, loss:0.00001, loss_test:0.09218, lr:4.39e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.452, tt:6165.853\n",
      "Ep:190, loss:0.00001, loss_test:0.09085, lr:4.34e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.453, tt:6198.580\n",
      "Ep:191, loss:0.00001, loss_test:0.09128, lr:4.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.453, tt:6230.912\n",
      "Ep:192, loss:0.00001, loss_test:0.09192, lr:4.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.465, tt:6265.768\n",
      "Ep:193, loss:0.00001, loss_test:0.09137, lr:4.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.509, tt:6306.776\n",
      "Ep:194, loss:0.00001, loss_test:0.09141, lr:4.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.513, tt:6339.997\n",
      "Ep:195, loss:0.00001, loss_test:0.09172, lr:4.13e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.521, tt:6374.072\n",
      "Ep:196, loss:0.00001, loss_test:0.09175, lr:4.09e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.527, tt:6407.752\n",
      "Ep:197, loss:0.00001, loss_test:0.09165, lr:4.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.525, tt:6439.863\n",
      "Ep:198, loss:0.00001, loss_test:0.09174, lr:4.01e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.533, tt:6473.998\n",
      "Ep:199, loss:0.00001, loss_test:0.09162, lr:3.97e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.536, tt:6507.109\n",
      "Ep:200, loss:0.00001, loss_test:0.09211, lr:3.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.538, tt:6540.100\n",
      "Ep:201, loss:0.00001, loss_test:0.09159, lr:3.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.539, tt:6572.915\n",
      "Ep:202, loss:0.00001, loss_test:0.09208, lr:3.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.534, tt:6604.475\n",
      "Ep:203, loss:0.00001, loss_test:0.09201, lr:3.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.534, tt:6637.031\n",
      "Ep:204, loss:0.00001, loss_test:0.09188, lr:3.77e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.542, tt:6671.065\n",
      "Ep:205, loss:0.00001, loss_test:0.09205, lr:3.73e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.545, tt:6704.213\n",
      "Ep:206, loss:0.00001, loss_test:0.09182, lr:3.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:32.529, tt:6733.480\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14566, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.672, tt:45.672\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.14398, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:55.242, tt:110.484\n",
      "Ep:2, loss:0.00054, loss_test:0.14040, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:58.943, tt:176.828\n",
      "Ep:3, loss:0.00051, loss_test:0.13315, lr:1.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:60.376, tt:241.503\n",
      "Ep:4, loss:0.00047, loss_test:0.12653, lr:1.00e-02, fs:0.61111 (r=0.667,p=0.564),  time:61.277, tt:306.384\n",
      "Ep:5, loss:0.00045, loss_test:0.12197, lr:1.00e-02, fs:0.63063 (r=0.707,p=0.569),  time:62.194, tt:373.165\n",
      "Ep:6, loss:0.00043, loss_test:0.11827, lr:1.00e-02, fs:0.63594 (r=0.697,p=0.585),  time:62.568, tt:437.975\n",
      "Ep:7, loss:0.00041, loss_test:0.11526, lr:1.00e-02, fs:0.64322 (r=0.646,p=0.640),  time:63.003, tt:504.023\n",
      "Ep:8, loss:0.00039, loss_test:0.11060, lr:1.00e-02, fs:0.66346 (r=0.697,p=0.633),  time:63.298, tt:569.682\n",
      "Ep:9, loss:0.00037, loss_test:0.10747, lr:1.00e-02, fs:0.66321 (r=0.646,p=0.681),  time:63.343, tt:633.426\n",
      "Ep:10, loss:0.00036, loss_test:0.10410, lr:1.00e-02, fs:0.69652 (r=0.707,p=0.686),  time:63.572, tt:699.289\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.10182, lr:1.00e-02, fs:0.68421 (r=0.657,p=0.714),  time:63.836, tt:766.031\n",
      "Ep:12, loss:0.00032, loss_test:0.10073, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:64.171, tt:834.226\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00031, loss_test:0.09865, lr:1.00e-02, fs:0.71503 (r=0.697,p=0.734),  time:64.432, tt:902.045\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00030, loss_test:0.09835, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:64.632, tt:969.480\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00028, loss_test:0.09475, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:64.685, tt:1034.966\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00027, loss_test:0.09331, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:64.857, tt:1102.568\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00026, loss_test:0.09469, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:64.932, tt:1168.774\n",
      "Ep:18, loss:0.00025, loss_test:0.09175, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:64.908, tt:1233.253\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.09135, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:65.012, tt:1300.246\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.09137, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:64.962, tt:1364.203\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.08687, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:65.045, tt:1430.988\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00021, loss_test:0.08933, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:65.102, tt:1497.336\n",
      "Ep:23, loss:0.00020, loss_test:0.08771, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:65.116, tt:1562.795\n",
      "Ep:24, loss:0.00019, loss_test:0.08678, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:65.165, tt:1629.123\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.08559, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:65.155, tt:1694.022\n",
      "Ep:26, loss:0.00017, loss_test:0.08819, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:65.188, tt:1760.076\n",
      "Ep:27, loss:0.00017, loss_test:0.08801, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:65.229, tt:1826.404\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.08182, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:65.284, tt:1893.233\n",
      "Ep:29, loss:0.00015, loss_test:0.08476, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:65.288, tt:1958.644\n",
      "Ep:30, loss:0.00015, loss_test:0.08619, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:65.325, tt:2025.070\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.08303, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:65.282, tt:2089.028\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08472, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:65.168, tt:2150.540\n",
      "Ep:33, loss:0.00013, loss_test:0.08354, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:65.240, tt:2218.168\n",
      "Ep:34, loss:0.00012, loss_test:0.08139, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:65.252, tt:2283.824\n",
      "Ep:35, loss:0.00012, loss_test:0.08359, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:65.261, tt:2349.391\n",
      "Ep:36, loss:0.00012, loss_test:0.08391, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:65.309, tt:2416.445\n",
      "Ep:37, loss:0.00011, loss_test:0.08312, lr:1.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:65.299, tt:2481.359\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08480, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:65.358, tt:2548.977\n",
      "Ep:39, loss:0.00010, loss_test:0.08636, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:65.392, tt:2615.689\n",
      "Ep:40, loss:0.00010, loss_test:0.08243, lr:1.00e-02, fs:0.82955 (r=0.737,p=0.948),  time:65.498, tt:2685.437\n",
      "Ep:41, loss:0.00009, loss_test:0.08510, lr:1.00e-02, fs:0.81609 (r=0.717,p=0.947),  time:65.484, tt:2750.325\n",
      "Ep:42, loss:0.00009, loss_test:0.08414, lr:1.00e-02, fs:0.80702 (r=0.697,p=0.958),  time:65.548, tt:2818.556\n",
      "Ep:43, loss:0.00009, loss_test:0.08596, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:65.550, tt:2884.186\n",
      "Ep:44, loss:0.00008, loss_test:0.08219, lr:1.00e-02, fs:0.80925 (r=0.707,p=0.946),  time:65.588, tt:2951.473\n",
      "Ep:45, loss:0.00008, loss_test:0.08815, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:65.620, tt:3018.536\n",
      "Ep:46, loss:0.00008, loss_test:0.08676, lr:1.00e-02, fs:0.77844 (r=0.657,p=0.956),  time:65.607, tt:3083.511\n",
      "Ep:47, loss:0.00007, loss_test:0.08601, lr:1.00e-02, fs:0.79532 (r=0.687,p=0.944),  time:65.556, tt:3146.666\n",
      "Ep:48, loss:0.00007, loss_test:0.08670, lr:1.00e-02, fs:0.80000 (r=0.687,p=0.958),  time:65.565, tt:3212.697\n",
      "Ep:49, loss:0.00007, loss_test:0.08662, lr:9.90e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.625, tt:3281.240\n",
      "Ep:50, loss:0.00007, loss_test:0.08723, lr:9.80e-03, fs:0.78571 (r=0.667,p=0.957),  time:65.656, tt:3348.458\n",
      "Ep:51, loss:0.00006, loss_test:0.08696, lr:9.70e-03, fs:0.78571 (r=0.667,p=0.957),  time:65.655, tt:3414.055\n",
      "Ep:52, loss:0.00006, loss_test:0.08731, lr:9.61e-03, fs:0.78107 (r=0.667,p=0.943),  time:65.651, tt:3479.482\n",
      "Ep:53, loss:0.00006, loss_test:0.08684, lr:9.51e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.652, tt:3545.200\n",
      "Ep:54, loss:0.00006, loss_test:0.08824, lr:9.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.630, tt:3609.638\n",
      "Ep:55, loss:0.00006, loss_test:0.08706, lr:9.32e-03, fs:0.79042 (r=0.667,p=0.971),  time:65.614, tt:3674.406\n",
      "Ep:56, loss:0.00005, loss_test:0.08904, lr:9.23e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.595, tt:3738.901\n",
      "Ep:57, loss:0.00005, loss_test:0.08747, lr:9.14e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.626, tt:3806.330\n",
      "Ep:58, loss:0.00005, loss_test:0.09014, lr:9.04e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.646, tt:3873.112\n",
      "Ep:59, loss:0.00005, loss_test:0.09025, lr:8.95e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.750, tt:3945.015\n",
      "Ep:60, loss:0.00005, loss_test:0.08808, lr:8.86e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.798, tt:4013.702\n",
      "Ep:61, loss:0.00005, loss_test:0.09301, lr:8.78e-03, fs:0.78313 (r=0.657,p=0.970),  time:65.804, tt:4079.838\n",
      "Ep:62, loss:0.00005, loss_test:0.08998, lr:8.69e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.793, tt:4144.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00005, loss_test:0.09012, lr:8.60e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.836, tt:4213.535\n",
      "Ep:64, loss:0.00004, loss_test:0.09814, lr:8.51e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.824, tt:4278.579\n",
      "Ep:65, loss:0.00004, loss_test:0.08810, lr:8.43e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.854, tt:4346.354\n",
      "Ep:66, loss:0.00004, loss_test:0.09904, lr:8.35e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.854, tt:4412.200\n",
      "Ep:67, loss:0.00004, loss_test:0.08900, lr:8.26e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.846, tt:4477.501\n",
      "Ep:68, loss:0.00004, loss_test:0.09781, lr:8.18e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.815, tt:4541.255\n",
      "Ep:69, loss:0.00004, loss_test:0.09315, lr:8.10e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.833, tt:4608.298\n",
      "Ep:70, loss:0.00004, loss_test:0.09561, lr:8.02e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.829, tt:4673.825\n",
      "Ep:71, loss:0.00004, loss_test:0.09420, lr:7.94e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.797, tt:4737.387\n",
      "Ep:72, loss:0.00003, loss_test:0.09494, lr:7.86e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.759, tt:4800.419\n",
      "Ep:73, loss:0.00003, loss_test:0.09492, lr:7.78e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.734, tt:4864.318\n",
      "Ep:74, loss:0.00003, loss_test:0.09354, lr:7.70e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.779, tt:4933.426\n",
      "Ep:75, loss:0.00003, loss_test:0.09655, lr:7.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.774, tt:4998.842\n",
      "Ep:76, loss:0.00003, loss_test:0.09360, lr:7.55e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.784, tt:5065.336\n",
      "Ep:77, loss:0.00003, loss_test:0.09597, lr:7.47e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.798, tt:5132.222\n",
      "Ep:78, loss:0.00003, loss_test:0.09514, lr:7.40e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.807, tt:5198.737\n",
      "Ep:79, loss:0.00003, loss_test:0.09662, lr:7.32e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.822, tt:5265.756\n",
      "Ep:80, loss:0.00003, loss_test:0.09441, lr:7.25e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.818, tt:5331.285\n",
      "Ep:81, loss:0.00003, loss_test:0.09705, lr:7.18e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.798, tt:5395.423\n",
      "Ep:82, loss:0.00003, loss_test:0.09476, lr:7.11e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.808, tt:5462.086\n",
      "Ep:83, loss:0.00003, loss_test:0.09700, lr:7.03e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.844, tt:5530.890\n",
      "Ep:84, loss:0.00003, loss_test:0.09626, lr:6.96e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.867, tt:5598.705\n",
      "Ep:85, loss:0.00003, loss_test:0.09739, lr:6.89e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.866, tt:5664.455\n",
      "Ep:86, loss:0.00003, loss_test:0.09646, lr:6.83e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.884, tt:5731.930\n",
      "Ep:87, loss:0.00003, loss_test:0.09736, lr:6.76e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.876, tt:5797.092\n",
      "Ep:88, loss:0.00002, loss_test:0.09613, lr:6.69e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.896, tt:5864.744\n",
      "Ep:89, loss:0.00002, loss_test:0.09808, lr:6.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.894, tt:5930.495\n",
      "Ep:90, loss:0.00002, loss_test:0.09669, lr:6.56e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.883, tt:5995.349\n",
      "Ep:91, loss:0.00002, loss_test:0.09848, lr:6.49e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.878, tt:6060.813\n",
      "Ep:92, loss:0.00002, loss_test:0.09663, lr:6.43e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.876, tt:6126.508\n",
      "Ep:93, loss:0.00002, loss_test:0.09959, lr:6.36e-03, fs:0.77301 (r=0.636,p=0.984),  time:65.885, tt:6193.146\n",
      "Ep:94, loss:0.00002, loss_test:0.09720, lr:6.30e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.896, tt:6260.119\n",
      "Ep:95, loss:0.00002, loss_test:0.09953, lr:6.24e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.928, tt:6329.114\n",
      "Ep:96, loss:0.00002, loss_test:0.09812, lr:6.17e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.954, tt:6397.574\n",
      "Ep:97, loss:0.00002, loss_test:0.09946, lr:6.11e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.976, tt:6465.657\n",
      "Ep:98, loss:0.00002, loss_test:0.09925, lr:6.05e-03, fs:0.77301 (r=0.636,p=0.984),  time:66.012, tt:6535.227\n",
      "Ep:99, loss:0.00002, loss_test:0.09832, lr:5.99e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.013, tt:6601.266\n",
      "Ep:100, loss:0.00002, loss_test:0.10200, lr:5.93e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.004, tt:6666.444\n",
      "Ep:101, loss:0.00002, loss_test:0.09906, lr:5.87e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.011, tt:6733.119\n",
      "Ep:102, loss:0.00002, loss_test:0.10055, lr:5.81e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.001, tt:6798.070\n",
      "Ep:103, loss:0.00002, loss_test:0.09995, lr:5.75e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.024, tt:6866.513\n",
      "Ep:104, loss:0.00002, loss_test:0.10032, lr:5.70e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.042, tt:6934.414\n",
      "Ep:105, loss:0.00002, loss_test:0.10074, lr:5.64e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.025, tt:6998.649\n",
      "Ep:106, loss:0.00002, loss_test:0.10065, lr:5.58e-03, fs:0.76829 (r=0.636,p=0.969),  time:66.039, tt:7066.179\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14324, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:6.035, tt:6.035\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14297, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:6.394, tt:12.789\n",
      "Ep:2, loss:0.00014, loss_test:0.14255, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:6.713, tt:20.140\n",
      "Ep:3, loss:0.00014, loss_test:0.14196, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:7.463, tt:29.852\n",
      "Ep:4, loss:0.00014, loss_test:0.14117, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.027, tt:45.137\n",
      "Ep:5, loss:0.00014, loss_test:0.14018, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.961, tt:59.765\n",
      "Ep:6, loss:0.00014, loss_test:0.13895, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:10.723, tt:75.062\n",
      "Ep:7, loss:0.00013, loss_test:0.13745, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:11.205, tt:89.642\n",
      "Ep:8, loss:0.00013, loss_test:0.13561, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:11.722, tt:105.498\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00013, loss_test:0.13334, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:12.140, tt:121.404\n",
      "Ep:10, loss:0.00013, loss_test:0.13053, lr:1.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:12.428, tt:136.704\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00013, loss_test:0.12724, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:12.655, tt:151.854\n",
      "Ep:12, loss:0.00012, loss_test:0.12361, lr:1.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:12.941, tt:168.238\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00012, loss_test:0.12022, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:13.007, tt:182.095\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00011, loss_test:0.11774, lr:1.00e-02, fs:0.66372 (r=0.758,p=0.591),  time:13.186, tt:197.784\n",
      "Ep:15, loss:0.00011, loss_test:0.11620, lr:1.00e-02, fs:0.67907 (r=0.737,p=0.629),  time:13.486, tt:215.775\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00011, loss_test:0.11505, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:13.592, tt:231.068\n",
      "Ep:17, loss:0.00011, loss_test:0.11397, lr:1.00e-02, fs:0.67290 (r=0.727,p=0.626),  time:13.674, tt:246.135\n",
      "Ep:18, loss:0.00011, loss_test:0.11281, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:13.821, tt:262.590\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00011, loss_test:0.11236, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:13.922, tt:278.441\n",
      "Ep:20, loss:0.00011, loss_test:0.11220, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:13.991, tt:293.806\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.11136, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:14.039, tt:308.848\n",
      "Ep:22, loss:0.00010, loss_test:0.10954, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:14.006, tt:322.144\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.10772, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:14.037, tt:336.880\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.10658, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:14.099, tt:352.464\n",
      "Ep:25, loss:0.00010, loss_test:0.10577, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:14.105, tt:366.723\n",
      "Ep:26, loss:0.00010, loss_test:0.10495, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:14.131, tt:381.534\n",
      "Ep:27, loss:0.00010, loss_test:0.10419, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:14.162, tt:396.534\n",
      "Ep:28, loss:0.00009, loss_test:0.10375, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:14.198, tt:411.734\n",
      "Ep:29, loss:0.00009, loss_test:0.10325, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:14.230, tt:426.889\n",
      "Ep:30, loss:0.00009, loss_test:0.10227, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:14.242, tt:441.501\n",
      "Ep:31, loss:0.00009, loss_test:0.10103, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:14.268, tt:456.569\n",
      "Ep:32, loss:0.00009, loss_test:0.10017, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:14.282, tt:471.308\n",
      "Ep:33, loss:0.00009, loss_test:0.09954, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:14.264, tt:484.970\n",
      "Ep:34, loss:0.00009, loss_test:0.09925, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:14.290, tt:500.133\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.09916, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:14.277, tt:513.961\n",
      "Ep:36, loss:0.00008, loss_test:0.09882, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:14.291, tt:528.756\n",
      "Ep:37, loss:0.00008, loss_test:0.09808, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:14.276, tt:542.479\n",
      "Ep:38, loss:0.00008, loss_test:0.09717, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:14.241, tt:555.394\n",
      "Ep:39, loss:0.00008, loss_test:0.09668, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:14.246, tt:569.832\n",
      "Ep:40, loss:0.00008, loss_test:0.09628, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:14.217, tt:582.899\n",
      "Ep:41, loss:0.00008, loss_test:0.09596, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:14.233, tt:597.769\n",
      "Ep:42, loss:0.00008, loss_test:0.09582, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:14.221, tt:611.516\n",
      "Ep:43, loss:0.00008, loss_test:0.09560, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:14.215, tt:625.451\n",
      "Ep:44, loss:0.00008, loss_test:0.09516, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:14.220, tt:639.882\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.09478, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:14.196, tt:653.034\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.09441, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:14.213, tt:667.989\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.09390, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:14.228, tt:682.966\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.09345, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:14.252, tt:698.350\n",
      "Ep:49, loss:0.00007, loss_test:0.09296, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:14.270, tt:713.517\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.09250, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:14.269, tt:727.698\n",
      "Ep:51, loss:0.00007, loss_test:0.09202, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:14.281, tt:742.605\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.09150, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:14.280, tt:756.815\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.09093, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:14.305, tt:772.477\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.09028, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:14.317, tt:787.423\n",
      "Ep:55, loss:0.00006, loss_test:0.08966, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:14.332, tt:802.618\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.08919, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:14.303, tt:815.259\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.08883, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:14.322, tt:830.675\n",
      "Ep:58, loss:0.00006, loss_test:0.08857, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:14.331, tt:845.542\n",
      "Ep:59, loss:0.00006, loss_test:0.08838, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:14.318, tt:859.057\n",
      "Ep:60, loss:0.00006, loss_test:0.08812, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:14.339, tt:874.653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.08777, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:14.363, tt:890.500\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00006, loss_test:0.08744, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:14.360, tt:904.673\n",
      "Ep:63, loss:0.00006, loss_test:0.08717, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:14.365, tt:919.332\n",
      "Ep:64, loss:0.00006, loss_test:0.08695, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:14.369, tt:933.999\n",
      "Ep:65, loss:0.00006, loss_test:0.08672, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:14.377, tt:948.895\n",
      "Ep:66, loss:0.00006, loss_test:0.08642, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:14.377, tt:963.226\n",
      "Ep:67, loss:0.00006, loss_test:0.08612, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:14.384, tt:978.135\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.08582, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:14.384, tt:992.520\n",
      "Ep:69, loss:0.00005, loss_test:0.08556, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:14.393, tt:1007.528\n",
      "Ep:70, loss:0.00005, loss_test:0.08534, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:14.383, tt:1021.174\n",
      "Ep:71, loss:0.00005, loss_test:0.08501, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:14.386, tt:1035.825\n",
      "Ep:72, loss:0.00005, loss_test:0.08474, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:14.392, tt:1050.648\n",
      "Ep:73, loss:0.00005, loss_test:0.08449, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:14.424, tt:1067.399\n",
      "Ep:74, loss:0.00005, loss_test:0.08431, lr:1.00e-02, fs:0.77000 (r=0.778,p=0.762),  time:14.421, tt:1081.578\n",
      "Ep:75, loss:0.00005, loss_test:0.08417, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:14.413, tt:1095.411\n",
      "Ep:76, loss:0.00005, loss_test:0.08381, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:14.416, tt:1110.066\n",
      "Ep:77, loss:0.00005, loss_test:0.08351, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:14.415, tt:1124.348\n",
      "Ep:78, loss:0.00005, loss_test:0.08310, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:14.422, tt:1139.304\n",
      "Ep:79, loss:0.00005, loss_test:0.08287, lr:9.90e-03, fs:0.77387 (r=0.778,p=0.770),  time:14.429, tt:1154.331\n",
      "Ep:80, loss:0.00005, loss_test:0.08271, lr:9.80e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.442, tt:1169.766\n",
      "Ep:81, loss:0.00005, loss_test:0.08235, lr:9.70e-03, fs:0.77387 (r=0.778,p=0.770),  time:14.441, tt:1184.137\n",
      "Ep:82, loss:0.00005, loss_test:0.08205, lr:9.61e-03, fs:0.77387 (r=0.778,p=0.770),  time:14.451, tt:1199.403\n",
      "Ep:83, loss:0.00004, loss_test:0.08205, lr:9.51e-03, fs:0.77320 (r=0.758,p=0.789),  time:14.455, tt:1214.214\n",
      "Ep:84, loss:0.00004, loss_test:0.08197, lr:9.41e-03, fs:0.77320 (r=0.758,p=0.789),  time:14.465, tt:1229.507\n",
      "Ep:85, loss:0.00004, loss_test:0.08169, lr:9.32e-03, fs:0.76768 (r=0.768,p=0.768),  time:14.474, tt:1244.727\n",
      "Ep:86, loss:0.00004, loss_test:0.08165, lr:9.23e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.490, tt:1260.646\n",
      "Ep:87, loss:0.00004, loss_test:0.08152, lr:9.14e-03, fs:0.77949 (r=0.768,p=0.792),  time:14.490, tt:1275.117\n",
      "Ep:88, loss:0.00004, loss_test:0.08136, lr:9.04e-03, fs:0.77157 (r=0.768,p=0.776),  time:14.504, tt:1290.818\n",
      "Ep:89, loss:0.00004, loss_test:0.08122, lr:8.95e-03, fs:0.77387 (r=0.778,p=0.770),  time:14.513, tt:1306.153\n",
      "Ep:90, loss:0.00004, loss_test:0.08128, lr:8.86e-03, fs:0.78534 (r=0.758,p=0.815),  time:14.516, tt:1320.920\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00004, loss_test:0.08108, lr:8.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:14.513, tt:1335.193\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.08074, lr:8.86e-03, fs:0.78571 (r=0.778,p=0.794),  time:14.521, tt:1350.446\n",
      "Ep:93, loss:0.00004, loss_test:0.08071, lr:8.86e-03, fs:0.79381 (r=0.778,p=0.811),  time:14.527, tt:1365.531\n",
      "Ep:94, loss:0.00004, loss_test:0.08071, lr:8.86e-03, fs:0.79581 (r=0.768,p=0.826),  time:14.526, tt:1379.974\n",
      "Ep:95, loss:0.00004, loss_test:0.08058, lr:8.86e-03, fs:0.81250 (r=0.788,p=0.839),  time:14.535, tt:1395.405\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00004, loss_test:0.08036, lr:8.86e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.538, tt:1410.171\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00004, loss_test:0.08028, lr:8.86e-03, fs:0.81443 (r=0.798,p=0.832),  time:14.544, tt:1425.334\n",
      "Ep:98, loss:0.00004, loss_test:0.08008, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.560, tt:1441.421\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00004, loss_test:0.07988, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.569, tt:1456.861\n",
      "Ep:100, loss:0.00004, loss_test:0.07983, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.564, tt:1470.928\n",
      "Ep:101, loss:0.00004, loss_test:0.07982, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.564, tt:1485.524\n",
      "Ep:102, loss:0.00004, loss_test:0.07964, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.564, tt:1500.043\n",
      "Ep:103, loss:0.00004, loss_test:0.07946, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.570, tt:1515.306\n",
      "Ep:104, loss:0.00004, loss_test:0.07944, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.557, tt:1528.497\n",
      "Ep:105, loss:0.00003, loss_test:0.07926, lr:8.86e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.563, tt:1543.685\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.07926, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.568, tt:1558.785\n",
      "Ep:107, loss:0.00003, loss_test:0.07891, lr:8.86e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.578, tt:1574.399\n",
      "Ep:108, loss:0.00003, loss_test:0.07865, lr:8.86e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.573, tt:1588.503\n",
      "Ep:109, loss:0.00003, loss_test:0.07897, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.571, tt:1602.858\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00003, loss_test:0.07849, lr:8.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:14.566, tt:1616.772\n",
      "Ep:111, loss:0.00003, loss_test:0.07799, lr:8.86e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.557, tt:1630.395\n",
      "Ep:112, loss:0.00003, loss_test:0.07845, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.558, tt:1645.075\n",
      "Ep:113, loss:0.00003, loss_test:0.07858, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.559, tt:1659.674\n",
      "Ep:114, loss:0.00003, loss_test:0.07789, lr:8.86e-03, fs:0.82474 (r=0.808,p=0.842),  time:14.551, tt:1673.365\n",
      "Ep:115, loss:0.00003, loss_test:0.07806, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.552, tt:1688.000\n",
      "Ep:116, loss:0.00003, loss_test:0.07847, lr:8.86e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.560, tt:1703.571\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00003, loss_test:0.07792, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.564, tt:1718.570\n",
      "Ep:118, loss:0.00003, loss_test:0.07752, lr:8.86e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.561, tt:1732.764\n",
      "Ep:119, loss:0.00003, loss_test:0.07826, lr:8.86e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.563, tt:1747.523\n",
      "Ep:120, loss:0.00003, loss_test:0.07844, lr:8.86e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.565, tt:1762.418\n",
      "Ep:121, loss:0.00003, loss_test:0.07781, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.565, tt:1776.877\n",
      "Ep:122, loss:0.00003, loss_test:0.07766, lr:8.86e-03, fs:0.82902 (r=0.808,p=0.851),  time:14.570, tt:1792.136\n",
      "Ep:123, loss:0.00003, loss_test:0.07862, lr:8.86e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.585, tt:1808.499\n",
      "Ep:124, loss:0.00003, loss_test:0.07863, lr:8.86e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.596, tt:1824.510\n",
      "Ep:125, loss:0.00003, loss_test:0.07796, lr:8.86e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.601, tt:1839.664\n",
      "Ep:126, loss:0.00003, loss_test:0.07817, lr:8.86e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.608, tt:1855.226\n",
      "Ep:127, loss:0.00003, loss_test:0.07858, lr:8.86e-03, fs:0.82979 (r=0.788,p=0.876),  time:14.611, tt:1870.249\n",
      "Ep:128, loss:0.00003, loss_test:0.07820, lr:8.78e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.612, tt:1884.919\n",
      "Ep:129, loss:0.00003, loss_test:0.07773, lr:8.69e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.624, tt:1901.174\n",
      "Ep:130, loss:0.00003, loss_test:0.07834, lr:8.60e-03, fs:0.82979 (r=0.788,p=0.876),  time:14.634, tt:1917.044\n",
      "Ep:131, loss:0.00003, loss_test:0.07843, lr:8.51e-03, fs:0.82979 (r=0.788,p=0.876),  time:14.638, tt:1932.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00003, loss_test:0.07779, lr:8.43e-03, fs:0.82292 (r=0.798,p=0.849),  time:14.642, tt:1947.330\n",
      "Ep:133, loss:0.00003, loss_test:0.07793, lr:8.35e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.649, tt:1962.949\n",
      "Ep:134, loss:0.00003, loss_test:0.07820, lr:8.26e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.642, tt:1976.605\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00003, loss_test:0.07804, lr:8.26e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.650, tt:1992.456\n",
      "Ep:136, loss:0.00003, loss_test:0.07776, lr:8.26e-03, fs:0.83770 (r=0.808,p=0.870),  time:14.653, tt:2007.431\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00002, loss_test:0.07800, lr:8.26e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.656, tt:2022.597\n",
      "Ep:138, loss:0.00002, loss_test:0.07800, lr:8.26e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.666, tt:2038.580\n",
      "Ep:139, loss:0.00002, loss_test:0.07772, lr:8.26e-03, fs:0.83770 (r=0.808,p=0.870),  time:14.671, tt:2053.923\n",
      "Ep:140, loss:0.00002, loss_test:0.07779, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.675, tt:2069.223\n",
      "Ep:141, loss:0.00002, loss_test:0.07798, lr:8.26e-03, fs:0.82540 (r=0.788,p=0.867),  time:14.685, tt:2085.233\n",
      "Ep:142, loss:0.00002, loss_test:0.07786, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.683, tt:2099.693\n",
      "Ep:143, loss:0.00002, loss_test:0.07757, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.695, tt:2116.112\n",
      "Ep:144, loss:0.00002, loss_test:0.07772, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.697, tt:2131.035\n",
      "Ep:145, loss:0.00002, loss_test:0.07790, lr:8.26e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.702, tt:2146.482\n",
      "Ep:146, loss:0.00002, loss_test:0.07784, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.709, tt:2162.162\n",
      "Ep:147, loss:0.00002, loss_test:0.07773, lr:8.26e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.710, tt:2177.150\n",
      "Ep:148, loss:0.00002, loss_test:0.07784, lr:8.18e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.716, tt:2192.671\n",
      "Ep:149, loss:0.00002, loss_test:0.07782, lr:8.10e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.725, tt:2208.783\n",
      "Ep:150, loss:0.00002, loss_test:0.07754, lr:8.02e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.721, tt:2222.851\n",
      "Ep:151, loss:0.00002, loss_test:0.07774, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.731, tt:2239.054\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00002, loss_test:0.07776, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.723, tt:2252.563\n",
      "Ep:153, loss:0.00002, loss_test:0.07764, lr:7.94e-03, fs:0.83158 (r=0.798,p=0.868),  time:14.717, tt:2266.432\n",
      "Ep:154, loss:0.00002, loss_test:0.07770, lr:7.94e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.710, tt:2280.115\n",
      "Ep:155, loss:0.00002, loss_test:0.07798, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.708, tt:2294.451\n",
      "Ep:156, loss:0.00002, loss_test:0.07799, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.704, tt:2308.515\n",
      "Ep:157, loss:0.00002, loss_test:0.07777, lr:7.94e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.694, tt:2321.719\n",
      "Ep:158, loss:0.00002, loss_test:0.07788, lr:7.94e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.686, tt:2335.018\n",
      "Ep:159, loss:0.00002, loss_test:0.07792, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.681, tt:2349.021\n",
      "Ep:160, loss:0.00002, loss_test:0.07775, lr:7.94e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.672, tt:2362.180\n",
      "Ep:161, loss:0.00002, loss_test:0.07771, lr:7.94e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.669, tt:2376.400\n",
      "Ep:162, loss:0.00002, loss_test:0.07794, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.668, tt:2390.912\n",
      "##########Best model found so far##########\n",
      "Ep:163, loss:0.00002, loss_test:0.07790, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.651, tt:2402.727\n",
      "Ep:164, loss:0.00002, loss_test:0.07767, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.652, tt:2417.512\n",
      "Ep:165, loss:0.00002, loss_test:0.07752, lr:7.94e-03, fs:0.82723 (r=0.798,p=0.859),  time:14.648, tt:2431.554\n",
      "Ep:166, loss:0.00002, loss_test:0.07781, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.641, tt:2445.125\n",
      "Ep:167, loss:0.00002, loss_test:0.07797, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.632, tt:2458.181\n",
      "##########Best model found so far##########\n",
      "Ep:168, loss:0.00002, loss_test:0.07768, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.628, tt:2472.146\n",
      "Ep:169, loss:0.00002, loss_test:0.07755, lr:7.94e-03, fs:0.83598 (r=0.798,p=0.878),  time:14.628, tt:2486.836\n",
      "Ep:170, loss:0.00002, loss_test:0.07764, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.625, tt:2500.867\n",
      "Ep:171, loss:0.00002, loss_test:0.07778, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.623, tt:2515.170\n",
      "Ep:172, loss:0.00002, loss_test:0.07799, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.613, tt:2528.065\n",
      "Ep:173, loss:0.00002, loss_test:0.07803, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.610, tt:2542.225\n",
      "Ep:174, loss:0.00002, loss_test:0.07809, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.607, tt:2556.228\n",
      "Ep:175, loss:0.00002, loss_test:0.07821, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.603, tt:2570.160\n",
      "Ep:176, loss:0.00002, loss_test:0.07815, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.595, tt:2583.251\n",
      "Ep:177, loss:0.00002, loss_test:0.07801, lr:7.94e-03, fs:0.84043 (r=0.798,p=0.888),  time:14.591, tt:2597.127\n",
      "Ep:178, loss:0.00002, loss_test:0.07858, lr:7.94e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.585, tt:2610.765\n",
      "Ep:179, loss:0.00002, loss_test:0.07864, lr:7.86e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.581, tt:2624.537\n",
      "Ep:180, loss:0.00002, loss_test:0.07819, lr:7.78e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.575, tt:2638.057\n",
      "Ep:181, loss:0.00002, loss_test:0.07815, lr:7.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.565, tt:2650.913\n",
      "Ep:182, loss:0.00002, loss_test:0.07845, lr:7.62e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.563, tt:2664.979\n",
      "Ep:183, loss:0.00002, loss_test:0.07844, lr:7.55e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.562, tt:2679.331\n",
      "Ep:184, loss:0.00002, loss_test:0.07823, lr:7.47e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.554, tt:2692.474\n",
      "Ep:185, loss:0.00002, loss_test:0.07828, lr:7.40e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.556, tt:2707.387\n",
      "Ep:186, loss:0.00002, loss_test:0.07820, lr:7.32e-03, fs:0.84492 (r=0.798,p=0.898),  time:14.553, tt:2721.334\n",
      "Ep:187, loss:0.00002, loss_test:0.07817, lr:7.25e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.544, tt:2734.346\n",
      "Ep:188, loss:0.00002, loss_test:0.07797, lr:7.18e-03, fs:0.84656 (r=0.808,p=0.889),  time:14.544, tt:2748.849\n",
      "Ep:189, loss:0.00002, loss_test:0.07828, lr:7.11e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.541, tt:2762.756\n",
      "Ep:190, loss:0.00002, loss_test:0.07822, lr:7.03e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.532, tt:2775.639\n",
      "Ep:191, loss:0.00002, loss_test:0.07783, lr:6.96e-03, fs:0.85106 (r=0.808,p=0.899),  time:14.535, tt:2790.753\n",
      "##########Best model found so far##########\n",
      "Ep:192, loss:0.00002, loss_test:0.07783, lr:6.96e-03, fs:0.85106 (r=0.808,p=0.899),  time:14.532, tt:2804.594\n",
      "Ep:193, loss:0.00002, loss_test:0.07822, lr:6.96e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.527, tt:2818.325\n",
      "Ep:194, loss:0.00002, loss_test:0.07816, lr:6.96e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.518, tt:2831.024\n",
      "Ep:195, loss:0.00002, loss_test:0.07778, lr:6.96e-03, fs:0.85106 (r=0.808,p=0.899),  time:14.518, tt:2845.524\n",
      "Ep:196, loss:0.00002, loss_test:0.07815, lr:6.96e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.515, tt:2859.461\n",
      "Ep:197, loss:0.00002, loss_test:0.07821, lr:6.96e-03, fs:0.84946 (r=0.798,p=0.908),  time:14.510, tt:2872.972\n",
      "Ep:198, loss:0.00001, loss_test:0.07791, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.509, tt:2887.193\n",
      "##########Best model found so far##########\n",
      "Ep:199, loss:0.00001, loss_test:0.07773, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.506, tt:2901.105\n",
      "Ep:200, loss:0.00001, loss_test:0.07834, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.501, tt:2914.660\n",
      "Ep:201, loss:0.00001, loss_test:0.07845, lr:6.96e-03, fs:0.86022 (r=0.808,p=0.920),  time:14.494, tt:2927.867\n",
      "##########Best model found so far##########\n",
      "Ep:202, loss:0.00001, loss_test:0.07784, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.488, tt:2941.019\n",
      "Ep:203, loss:0.00001, loss_test:0.07755, lr:6.96e-03, fs:0.84211 (r=0.808,p=0.879),  time:14.480, tt:2953.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00001, loss_test:0.07819, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.469, tt:2966.065\n",
      "Ep:205, loss:0.00001, loss_test:0.07833, lr:6.96e-03, fs:0.85561 (r=0.808,p=0.909),  time:14.464, tt:2979.583\n",
      "Ep:206, loss:0.00001, loss_test:0.07791, lr:6.96e-03, fs:0.85106 (r=0.808,p=0.899),  time:14.461, tt:2993.370\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13978, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.574, tt:17.574\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13785, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.528, tt:45.056\n",
      "Ep:2, loss:0.00027, loss_test:0.13430, lr:1.00e-02, fs:0.67073 (r=1.000,p=0.505),  time:25.208, tt:75.624\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12861, lr:1.00e-02, fs:0.67500 (r=0.982,p=0.514),  time:26.993, tt:107.973\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12024, lr:1.00e-02, fs:0.71233 (r=0.945,p=0.571),  time:27.960, tt:139.802\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11100, lr:1.00e-02, fs:0.71212 (r=0.855,p=0.610),  time:28.753, tt:172.516\n",
      "Ep:6, loss:0.00023, loss_test:0.10697, lr:1.00e-02, fs:0.70000 (r=0.764,p=0.646),  time:29.017, tt:203.116\n",
      "Ep:7, loss:0.00023, loss_test:0.10365, lr:1.00e-02, fs:0.70690 (r=0.745,p=0.672),  time:29.133, tt:233.061\n",
      "Ep:8, loss:0.00022, loss_test:0.10113, lr:1.00e-02, fs:0.73333 (r=0.800,p=0.677),  time:29.409, tt:264.681\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09988, lr:1.00e-02, fs:0.75410 (r=0.836,p=0.687),  time:29.615, tt:296.153\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09648, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:29.819, tt:328.007\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09416, lr:1.00e-02, fs:0.77876 (r=0.800,p=0.759),  time:30.065, tt:360.779\n",
      "Ep:12, loss:0.00019, loss_test:0.09256, lr:1.00e-02, fs:0.80342 (r=0.855,p=0.758),  time:30.156, tt:392.024\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09116, lr:1.00e-02, fs:0.81034 (r=0.855,p=0.770),  time:30.325, tt:424.544\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.08849, lr:1.00e-02, fs:0.80702 (r=0.836,p=0.780),  time:30.429, tt:456.435\n",
      "Ep:15, loss:0.00018, loss_test:0.08635, lr:1.00e-02, fs:0.80702 (r=0.836,p=0.780),  time:30.355, tt:485.679\n",
      "Ep:16, loss:0.00017, loss_test:0.08454, lr:1.00e-02, fs:0.79310 (r=0.836,p=0.754),  time:30.510, tt:518.670\n",
      "Ep:17, loss:0.00017, loss_test:0.08229, lr:1.00e-02, fs:0.78632 (r=0.836,p=0.742),  time:30.488, tt:548.785\n",
      "Ep:18, loss:0.00016, loss_test:0.08104, lr:1.00e-02, fs:0.80000 (r=0.836,p=0.767),  time:30.567, tt:580.772\n",
      "Ep:19, loss:0.00016, loss_test:0.07977, lr:1.00e-02, fs:0.79310 (r=0.836,p=0.754),  time:30.659, tt:613.171\n",
      "Ep:20, loss:0.00015, loss_test:0.07814, lr:1.00e-02, fs:0.80702 (r=0.836,p=0.780),  time:30.694, tt:644.582\n",
      "Ep:21, loss:0.00015, loss_test:0.07628, lr:1.00e-02, fs:0.83478 (r=0.873,p=0.800),  time:30.744, tt:676.372\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07470, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:30.817, tt:708.782\n",
      "Ep:23, loss:0.00014, loss_test:0.07266, lr:1.00e-02, fs:0.85470 (r=0.909,p=0.806),  time:30.808, tt:739.384\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07127, lr:1.00e-02, fs:0.85000 (r=0.927,p=0.785),  time:30.815, tt:770.374\n",
      "Ep:25, loss:0.00014, loss_test:0.06979, lr:1.00e-02, fs:0.85714 (r=0.927,p=0.797),  time:30.862, tt:802.407\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.06848, lr:1.00e-02, fs:0.85000 (r=0.927,p=0.785),  time:30.934, tt:835.224\n",
      "Ep:27, loss:0.00013, loss_test:0.06757, lr:1.00e-02, fs:0.85950 (r=0.945,p=0.788),  time:30.891, tt:864.956\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.06627, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:30.923, tt:896.765\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.06508, lr:1.00e-02, fs:0.85950 (r=0.945,p=0.788),  time:30.919, tt:927.559\n",
      "Ep:30, loss:0.00012, loss_test:0.06343, lr:1.00e-02, fs:0.86667 (r=0.945,p=0.800),  time:30.922, tt:958.570\n",
      "Ep:31, loss:0.00012, loss_test:0.06221, lr:1.00e-02, fs:0.87603 (r=0.964,p=0.803),  time:30.835, tt:986.725\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.06103, lr:1.00e-02, fs:0.88333 (r=0.964,p=0.815),  time:30.852, tt:1018.121\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.05973, lr:1.00e-02, fs:0.89076 (r=0.964,p=0.828),  time:30.859, tt:1049.218\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00011, loss_test:0.05872, lr:1.00e-02, fs:0.89831 (r=0.964,p=0.841),  time:30.886, tt:1080.993\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.05750, lr:1.00e-02, fs:0.89076 (r=0.964,p=0.828),  time:30.861, tt:1110.985\n",
      "Ep:36, loss:0.00010, loss_test:0.05643, lr:1.00e-02, fs:0.89076 (r=0.964,p=0.828),  time:30.846, tt:1141.289\n",
      "Ep:37, loss:0.00010, loss_test:0.05526, lr:1.00e-02, fs:0.89076 (r=0.964,p=0.828),  time:30.861, tt:1172.717\n",
      "Ep:38, loss:0.00010, loss_test:0.05424, lr:1.00e-02, fs:0.90909 (r=1.000,p=0.833),  time:30.869, tt:1203.888\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.05323, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.910, tt:1236.404\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.05240, lr:1.00e-02, fs:0.90909 (r=1.000,p=0.833),  time:30.926, tt:1267.954\n",
      "Ep:41, loss:0.00009, loss_test:0.05027, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.939, tt:1299.418\n",
      "Ep:42, loss:0.00009, loss_test:0.04974, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.959, tt:1331.238\n",
      "Ep:43, loss:0.00009, loss_test:0.04889, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.958, tt:1362.157\n",
      "Ep:44, loss:0.00009, loss_test:0.04714, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.968, tt:1393.564\n",
      "Ep:45, loss:0.00008, loss_test:0.04604, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.948, tt:1423.623\n",
      "Ep:46, loss:0.00008, loss_test:0.04495, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.955, tt:1454.867\n",
      "Ep:47, loss:0.00008, loss_test:0.04364, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.932, tt:1484.739\n",
      "Ep:48, loss:0.00008, loss_test:0.04342, lr:1.00e-02, fs:0.91667 (r=1.000,p=0.846),  time:30.933, tt:1515.693\n",
      "Ep:49, loss:0.00008, loss_test:0.04132, lr:1.00e-02, fs:0.92437 (r=1.000,p=0.859),  time:30.913, tt:1545.672\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.04084, lr:1.00e-02, fs:0.92308 (r=0.982,p=0.871),  time:30.959, tt:1578.883\n",
      "Ep:51, loss:0.00007, loss_test:0.03947, lr:1.00e-02, fs:0.93913 (r=0.982,p=0.900),  time:31.007, tt:1612.358\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.03871, lr:1.00e-02, fs:0.93220 (r=1.000,p=0.873),  time:31.012, tt:1643.636\n",
      "Ep:53, loss:0.00007, loss_test:0.03766, lr:1.00e-02, fs:0.93913 (r=0.982,p=0.900),  time:31.001, tt:1674.080\n",
      "Ep:54, loss:0.00007, loss_test:0.03716, lr:1.00e-02, fs:0.94828 (r=1.000,p=0.902),  time:30.997, tt:1704.811\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00007, loss_test:0.03618, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:30.991, tt:1735.487\n",
      "Ep:56, loss:0.00007, loss_test:0.03544, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.009, tt:1767.542\n",
      "Ep:57, loss:0.00007, loss_test:0.03450, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:31.001, tt:1798.049\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.03396, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.003, tt:1829.169\n",
      "Ep:59, loss:0.00006, loss_test:0.03288, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:31.021, tt:1861.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00006, loss_test:0.03260, lr:1.00e-02, fs:0.95575 (r=0.982,p=0.931),  time:31.022, tt:1892.353\n",
      "Ep:61, loss:0.00006, loss_test:0.03140, lr:1.00e-02, fs:0.95575 (r=0.982,p=0.931),  time:31.025, tt:1923.525\n",
      "Ep:62, loss:0.00006, loss_test:0.03160, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.027, tt:1954.725\n",
      "Ep:63, loss:0.00006, loss_test:0.03063, lr:1.00e-02, fs:0.95575 (r=0.982,p=0.931),  time:31.023, tt:1985.492\n",
      "Ep:64, loss:0.00006, loss_test:0.02956, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.022, tt:2016.407\n",
      "Ep:65, loss:0.00006, loss_test:0.02891, lr:1.00e-02, fs:0.95575 (r=0.982,p=0.931),  time:31.025, tt:2047.658\n",
      "Ep:66, loss:0.00005, loss_test:0.02837, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.029, tt:2078.933\n",
      "Ep:67, loss:0.00005, loss_test:0.02829, lr:1.00e-02, fs:0.94737 (r=0.982,p=0.915),  time:31.045, tt:2111.051\n",
      "Ep:68, loss:0.00005, loss_test:0.02743, lr:1.00e-02, fs:0.95575 (r=0.982,p=0.931),  time:31.036, tt:2141.510\n",
      "Ep:69, loss:0.00005, loss_test:0.02757, lr:9.90e-03, fs:0.94737 (r=0.982,p=0.915),  time:31.032, tt:2172.214\n",
      "Ep:70, loss:0.00005, loss_test:0.02633, lr:9.80e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.040, tt:2203.827\n",
      "Ep:71, loss:0.00005, loss_test:0.02580, lr:9.70e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.047, tt:2235.379\n",
      "Ep:72, loss:0.00005, loss_test:0.02608, lr:9.61e-03, fs:0.94737 (r=0.982,p=0.915),  time:31.025, tt:2264.813\n",
      "Ep:73, loss:0.00005, loss_test:0.02512, lr:9.51e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.016, tt:2295.196\n",
      "Ep:74, loss:0.00005, loss_test:0.02533, lr:9.41e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.027, tt:2326.991\n",
      "Ep:75, loss:0.00005, loss_test:0.02464, lr:9.32e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.011, tt:2356.825\n",
      "Ep:76, loss:0.00005, loss_test:0.02402, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.030, tt:2389.300\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.02415, lr:9.23e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.023, tt:2419.763\n",
      "Ep:78, loss:0.00004, loss_test:0.02398, lr:9.23e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.031, tt:2451.475\n",
      "Ep:79, loss:0.00004, loss_test:0.02380, lr:9.23e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.025, tt:2482.003\n",
      "Ep:80, loss:0.00004, loss_test:0.02285, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.023, tt:2512.835\n",
      "Ep:81, loss:0.00004, loss_test:0.02224, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.023, tt:2543.847\n",
      "Ep:82, loss:0.00004, loss_test:0.02185, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.032, tt:2575.638\n",
      "Ep:83, loss:0.00004, loss_test:0.02182, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.042, tt:2607.545\n",
      "Ep:84, loss:0.00004, loss_test:0.02162, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.037, tt:2638.149\n",
      "Ep:85, loss:0.00004, loss_test:0.02118, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.038, tt:2669.283\n",
      "Ep:86, loss:0.00004, loss_test:0.02076, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.031, tt:2699.667\n",
      "Ep:87, loss:0.00004, loss_test:0.02092, lr:9.23e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.056, tt:2732.957\n",
      "Ep:88, loss:0.00004, loss_test:0.02080, lr:9.14e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.080, tt:2766.076\n",
      "Ep:89, loss:0.00004, loss_test:0.02060, lr:9.04e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.097, tt:2798.700\n",
      "Ep:90, loss:0.00004, loss_test:0.02028, lr:8.95e-03, fs:0.95575 (r=0.982,p=0.931),  time:31.087, tt:2828.924\n",
      "Ep:91, loss:0.00003, loss_test:0.01963, lr:8.86e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.081, tt:2859.441\n",
      "Ep:92, loss:0.00003, loss_test:0.01946, lr:8.78e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.093, tt:2891.611\n",
      "Ep:93, loss:0.00003, loss_test:0.01943, lr:8.69e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.088, tt:2922.271\n",
      "Ep:94, loss:0.00003, loss_test:0.01902, lr:8.60e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.101, tt:2954.620\n",
      "Ep:95, loss:0.00003, loss_test:0.01961, lr:8.51e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.130, tt:2988.466\n",
      "Ep:96, loss:0.00003, loss_test:0.01885, lr:8.43e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.178, tt:3024.290\n",
      "Ep:97, loss:0.00003, loss_test:0.01905, lr:8.35e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.197, tt:3057.328\n",
      "Ep:98, loss:0.00003, loss_test:0.01831, lr:8.26e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.215, tt:3090.296\n",
      "Ep:99, loss:0.00003, loss_test:0.01829, lr:8.18e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.219, tt:3121.907\n",
      "Ep:100, loss:0.00003, loss_test:0.01896, lr:8.10e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.236, tt:3154.886\n",
      "Ep:101, loss:0.00003, loss_test:0.01817, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.235, tt:3186.010\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00003, loss_test:0.01812, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.260, tt:3219.763\n",
      "Ep:103, loss:0.00003, loss_test:0.01761, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.254, tt:3250.368\n",
      "Ep:104, loss:0.00003, loss_test:0.01739, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.251, tt:3281.336\n",
      "Ep:105, loss:0.00003, loss_test:0.01730, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.265, tt:3314.077\n",
      "Ep:106, loss:0.00003, loss_test:0.01725, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.269, tt:3345.765\n",
      "Ep:107, loss:0.00002, loss_test:0.01699, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.272, tt:3377.368\n",
      "Ep:108, loss:0.00002, loss_test:0.01700, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.271, tt:3408.578\n",
      "Ep:109, loss:0.00002, loss_test:0.01676, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.289, tt:3441.833\n",
      "Ep:110, loss:0.00002, loss_test:0.01660, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.292, tt:3473.408\n",
      "Ep:111, loss:0.00002, loss_test:0.01640, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.274, tt:3502.706\n",
      "Ep:112, loss:0.00002, loss_test:0.01664, lr:8.02e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.287, tt:3535.374\n",
      "Ep:113, loss:0.00002, loss_test:0.01643, lr:7.94e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.292, tt:3567.325\n",
      "Ep:114, loss:0.00002, loss_test:0.01623, lr:7.86e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.308, tt:3600.400\n",
      "Ep:115, loss:0.00002, loss_test:0.01610, lr:7.78e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.318, tt:3632.831\n",
      "Ep:116, loss:0.00002, loss_test:0.01618, lr:7.70e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.325, tt:3664.974\n",
      "Ep:117, loss:0.00002, loss_test:0.01598, lr:7.62e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.314, tt:3695.065\n",
      "Ep:118, loss:0.00002, loss_test:0.01583, lr:7.55e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.321, tt:3727.231\n",
      "Ep:119, loss:0.00002, loss_test:0.01626, lr:7.47e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.312, tt:3757.418\n",
      "Ep:120, loss:0.00002, loss_test:0.01560, lr:7.40e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.304, tt:3787.778\n",
      "Ep:121, loss:0.00002, loss_test:0.01557, lr:7.32e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.299, tt:3818.501\n",
      "Ep:122, loss:0.00002, loss_test:0.01563, lr:7.25e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.333, tt:3853.936\n",
      "Ep:123, loss:0.00002, loss_test:0.01540, lr:7.18e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.321, tt:3883.840\n",
      "Ep:124, loss:0.00002, loss_test:0.01531, lr:7.11e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.303, tt:3912.920\n",
      "Ep:125, loss:0.00002, loss_test:0.01535, lr:7.03e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.310, tt:3945.035\n",
      "Ep:126, loss:0.00002, loss_test:0.01522, lr:6.96e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.308, tt:3976.150\n",
      "Ep:127, loss:0.00002, loss_test:0.01524, lr:6.89e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.307, tt:4007.297\n",
      "Ep:128, loss:0.00002, loss_test:0.01519, lr:6.83e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.314, tt:4039.501\n",
      "Ep:129, loss:0.00002, loss_test:0.01482, lr:6.76e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.318, tt:4071.344\n",
      "Ep:130, loss:0.00002, loss_test:0.01529, lr:6.69e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.314, tt:4102.081\n",
      "Ep:131, loss:0.00002, loss_test:0.01484, lr:6.62e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.305, tt:4132.231\n",
      "Ep:132, loss:0.00002, loss_test:0.01479, lr:6.56e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.306, tt:4163.666\n",
      "Ep:133, loss:0.00002, loss_test:0.01466, lr:6.49e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.293, tt:4193.257\n",
      "Ep:134, loss:0.00002, loss_test:0.01454, lr:6.43e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.296, tt:4224.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00002, loss_test:0.01470, lr:6.36e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.295, tt:4256.067\n",
      "Ep:136, loss:0.00002, loss_test:0.01451, lr:6.30e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.297, tt:4287.730\n",
      "Ep:137, loss:0.00001, loss_test:0.01457, lr:6.24e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.298, tt:4319.173\n",
      "Ep:138, loss:0.00001, loss_test:0.01423, lr:6.17e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.293, tt:4349.661\n",
      "Ep:139, loss:0.00001, loss_test:0.01449, lr:6.11e-03, fs:0.96429 (r=0.982,p=0.947),  time:31.293, tt:4381.032\n",
      "Ep:140, loss:0.00001, loss_test:0.01432, lr:6.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.297, tt:4412.822\n",
      "Ep:141, loss:0.00001, loss_test:0.01417, lr:5.99e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.291, tt:4443.257\n",
      "Ep:142, loss:0.00001, loss_test:0.01429, lr:5.93e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.290, tt:4474.500\n",
      "Ep:143, loss:0.00001, loss_test:0.01395, lr:5.87e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.304, tt:4507.800\n",
      "Ep:144, loss:0.00001, loss_test:0.01429, lr:5.81e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.311, tt:4540.084\n",
      "Ep:145, loss:0.00001, loss_test:0.01396, lr:5.75e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.325, tt:4573.395\n",
      "Ep:146, loss:0.00001, loss_test:0.01403, lr:5.70e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.334, tt:4606.026\n",
      "Ep:147, loss:0.00001, loss_test:0.01385, lr:5.64e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.340, tt:4638.281\n",
      "Ep:148, loss:0.00001, loss_test:0.01396, lr:5.58e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.348, tt:4670.823\n",
      "Ep:149, loss:0.00001, loss_test:0.01380, lr:5.53e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.342, tt:4701.328\n",
      "Ep:150, loss:0.00001, loss_test:0.01380, lr:5.47e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.348, tt:4733.592\n",
      "Ep:151, loss:0.00001, loss_test:0.01381, lr:5.42e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.339, tt:4763.595\n",
      "Ep:152, loss:0.00001, loss_test:0.01365, lr:5.36e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.341, tt:4795.176\n",
      "Ep:153, loss:0.00001, loss_test:0.01376, lr:5.31e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.356, tt:4828.856\n",
      "Ep:154, loss:0.00001, loss_test:0.01361, lr:5.26e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.358, tt:4860.451\n",
      "Ep:155, loss:0.00001, loss_test:0.01347, lr:5.20e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.352, tt:4890.870\n",
      "Ep:156, loss:0.00001, loss_test:0.01338, lr:5.15e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.345, tt:4921.214\n",
      "Ep:157, loss:0.00001, loss_test:0.01337, lr:5.10e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.342, tt:4952.029\n",
      "Ep:158, loss:0.00001, loss_test:0.01332, lr:5.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.370, tt:4987.840\n",
      "Ep:159, loss:0.00001, loss_test:0.01337, lr:5.00e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.368, tt:5018.944\n",
      "Ep:160, loss:0.00001, loss_test:0.01334, lr:4.95e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.378, tt:5051.915\n",
      "Ep:161, loss:0.00001, loss_test:0.01337, lr:4.90e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.370, tt:5081.895\n",
      "Ep:162, loss:0.00001, loss_test:0.01322, lr:4.85e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.374, tt:5113.979\n",
      "Ep:163, loss:0.00001, loss_test:0.01337, lr:4.80e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.373, tt:5145.203\n",
      "Ep:164, loss:0.00001, loss_test:0.01317, lr:4.75e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.371, tt:5176.179\n",
      "Ep:165, loss:0.00001, loss_test:0.01310, lr:4.71e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.369, tt:5207.185\n",
      "Ep:166, loss:0.00001, loss_test:0.01318, lr:4.66e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.370, tt:5238.763\n",
      "Ep:167, loss:0.00001, loss_test:0.01294, lr:4.61e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.373, tt:5270.742\n",
      "Ep:168, loss:0.00001, loss_test:0.01301, lr:4.57e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.366, tt:5300.809\n",
      "Ep:169, loss:0.00001, loss_test:0.01304, lr:4.52e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.366, tt:5332.201\n",
      "Ep:170, loss:0.00001, loss_test:0.01291, lr:4.48e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.352, tt:5361.229\n",
      "Ep:171, loss:0.00001, loss_test:0.01278, lr:4.43e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.358, tt:5393.605\n",
      "Ep:172, loss:0.00001, loss_test:0.01282, lr:4.39e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.355, tt:5424.497\n",
      "Ep:173, loss:0.00001, loss_test:0.01303, lr:4.34e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.347, tt:5454.380\n",
      "Ep:174, loss:0.00001, loss_test:0.01276, lr:4.30e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.346, tt:5485.487\n",
      "Ep:175, loss:0.00001, loss_test:0.01280, lr:4.26e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.347, tt:5517.035\n",
      "Ep:176, loss:0.00001, loss_test:0.01280, lr:4.21e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.345, tt:5548.134\n",
      "Ep:177, loss:0.00001, loss_test:0.01271, lr:4.17e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.346, tt:5579.525\n",
      "Ep:178, loss:0.00001, loss_test:0.01281, lr:4.13e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.349, tt:5611.408\n",
      "Ep:179, loss:0.00001, loss_test:0.01275, lr:4.09e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.349, tt:5642.871\n",
      "Ep:180, loss:0.00001, loss_test:0.01268, lr:4.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.353, tt:5674.806\n",
      "Ep:181, loss:0.00001, loss_test:0.01267, lr:4.01e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.354, tt:5706.404\n",
      "Ep:182, loss:0.00001, loss_test:0.01257, lr:3.97e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.346, tt:5736.299\n",
      "Ep:183, loss:0.00001, loss_test:0.01262, lr:3.93e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.345, tt:5767.534\n",
      "Ep:184, loss:0.00001, loss_test:0.01260, lr:3.89e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.366, tt:5802.637\n",
      "Ep:185, loss:0.00001, loss_test:0.01260, lr:3.85e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.368, tt:5834.418\n",
      "Ep:186, loss:0.00001, loss_test:0.01260, lr:3.81e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.358, tt:5863.900\n",
      "Ep:187, loss:0.00001, loss_test:0.01251, lr:3.77e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.353, tt:5894.436\n",
      "Ep:188, loss:0.00001, loss_test:0.01256, lr:3.73e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.359, tt:5926.923\n",
      "Ep:189, loss:0.00001, loss_test:0.01247, lr:3.70e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.363, tt:5958.959\n",
      "Ep:190, loss:0.00001, loss_test:0.01251, lr:3.66e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.365, tt:5990.715\n",
      "Ep:191, loss:0.00001, loss_test:0.01234, lr:3.62e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.358, tt:6020.765\n",
      "Ep:192, loss:0.00001, loss_test:0.01233, lr:3.59e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.355, tt:6051.556\n",
      "Ep:193, loss:0.00001, loss_test:0.01246, lr:3.55e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.352, tt:6082.199\n",
      "Ep:194, loss:0.00001, loss_test:0.01253, lr:3.52e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.346, tt:6112.525\n",
      "Ep:195, loss:0.00001, loss_test:0.01250, lr:3.48e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.341, tt:6142.864\n",
      "Ep:196, loss:0.00001, loss_test:0.01238, lr:3.45e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.331, tt:6172.281\n",
      "Ep:197, loss:0.00001, loss_test:0.01236, lr:3.41e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.322, tt:6201.736\n",
      "Ep:198, loss:0.00001, loss_test:0.01245, lr:3.38e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.316, tt:6231.946\n",
      "Ep:199, loss:0.00001, loss_test:0.01227, lr:3.34e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.315, tt:6262.905\n",
      "Ep:200, loss:0.00001, loss_test:0.01231, lr:3.31e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.314, tt:6294.175\n",
      "Ep:201, loss:0.00001, loss_test:0.01229, lr:3.28e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.304, tt:6323.460\n",
      "Ep:202, loss:0.00001, loss_test:0.01226, lr:3.24e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.306, tt:6355.027\n",
      "Ep:203, loss:0.00001, loss_test:0.01229, lr:3.21e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.311, tt:6387.401\n",
      "Ep:204, loss:0.00001, loss_test:0.01219, lr:3.18e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.310, tt:6418.520\n",
      "Ep:205, loss:0.00001, loss_test:0.01221, lr:3.15e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.322, tt:6452.255\n",
      "Ep:206, loss:0.00001, loss_test:0.01222, lr:3.12e-03, fs:0.97297 (r=0.982,p=0.964),  time:31.313, tt:6481.698\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13379, lr:1.00e-02, fs:0.66667 (r=0.982,p=0.505),  time:13.979, tt:13.979\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12954, lr:1.00e-02, fs:0.67500 (r=0.982,p=0.514),  time:18.855, tt:37.710\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12351, lr:1.00e-02, fs:0.70130 (r=0.982,p=0.545),  time:22.917, tt:68.752\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.11756, lr:1.00e-02, fs:0.73611 (r=0.964,p=0.596),  time:26.342, tt:105.369\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.11271, lr:1.00e-02, fs:0.70504 (r=0.891,p=0.583),  time:28.443, tt:142.216\n",
      "Ep:5, loss:0.00025, loss_test:0.10804, lr:1.00e-02, fs:0.72593 (r=0.891,p=0.613),  time:29.559, tt:177.355\n",
      "Ep:6, loss:0.00024, loss_test:0.10407, lr:1.00e-02, fs:0.74242 (r=0.891,p=0.636),  time:30.680, tt:214.763\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10061, lr:1.00e-02, fs:0.75758 (r=0.909,p=0.649),  time:31.605, tt:252.836\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.09756, lr:1.00e-02, fs:0.77863 (r=0.927,p=0.671),  time:32.088, tt:288.795\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.09363, lr:1.00e-02, fs:0.81250 (r=0.945,p=0.712),  time:32.597, tt:325.974\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.09045, lr:1.00e-02, fs:0.80952 (r=0.927,p=0.718),  time:33.147, tt:364.622\n",
      "Ep:11, loss:0.00021, loss_test:0.08814, lr:1.00e-02, fs:0.81301 (r=0.909,p=0.735),  time:33.506, tt:402.076\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.08645, lr:1.00e-02, fs:0.81301 (r=0.909,p=0.735),  time:33.602, tt:436.825\n",
      "Ep:13, loss:0.00019, loss_test:0.08499, lr:1.00e-02, fs:0.80645 (r=0.909,p=0.725),  time:33.767, tt:472.742\n",
      "Ep:14, loss:0.00019, loss_test:0.08346, lr:1.00e-02, fs:0.79032 (r=0.891,p=0.710),  time:34.050, tt:510.753\n",
      "Ep:15, loss:0.00018, loss_test:0.08216, lr:1.00e-02, fs:0.78689 (r=0.873,p=0.716),  time:34.225, tt:547.597\n",
      "Ep:16, loss:0.00017, loss_test:0.08066, lr:1.00e-02, fs:0.79675 (r=0.891,p=0.721),  time:34.425, tt:585.229\n",
      "Ep:17, loss:0.00017, loss_test:0.07933, lr:1.00e-02, fs:0.81600 (r=0.927,p=0.729),  time:34.590, tt:622.612\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.07738, lr:1.00e-02, fs:0.79675 (r=0.891,p=0.721),  time:34.696, tt:659.232\n",
      "Ep:19, loss:0.00016, loss_test:0.07497, lr:1.00e-02, fs:0.80000 (r=0.873,p=0.738),  time:34.781, tt:695.611\n",
      "Ep:20, loss:0.00015, loss_test:0.07264, lr:1.00e-02, fs:0.80000 (r=0.873,p=0.738),  time:34.867, tt:732.210\n",
      "Ep:21, loss:0.00015, loss_test:0.07042, lr:1.00e-02, fs:0.83051 (r=0.891,p=0.778),  time:34.958, tt:769.068\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.06825, lr:1.00e-02, fs:0.83051 (r=0.891,p=0.778),  time:35.102, tt:807.349\n",
      "Ep:23, loss:0.00014, loss_test:0.06616, lr:1.00e-02, fs:0.83051 (r=0.891,p=0.778),  time:35.163, tt:843.924\n",
      "Ep:24, loss:0.00013, loss_test:0.06440, lr:1.00e-02, fs:0.84483 (r=0.891,p=0.803),  time:35.171, tt:879.272\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.06277, lr:1.00e-02, fs:0.86667 (r=0.945,p=0.800),  time:35.243, tt:916.314\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.06031, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:35.291, tt:952.863\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.05825, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:35.351, tt:989.816\n",
      "Ep:28, loss:0.00011, loss_test:0.05679, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:35.535, tt:1030.511\n",
      "Ep:29, loss:0.00011, loss_test:0.05470, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:35.536, tt:1066.071\n",
      "Ep:30, loss:0.00011, loss_test:0.05322, lr:1.00e-02, fs:0.87395 (r=0.945,p=0.812),  time:35.567, tt:1102.562\n",
      "Ep:31, loss:0.00010, loss_test:0.05114, lr:1.00e-02, fs:0.88136 (r=0.945,p=0.825),  time:35.614, tt:1139.663\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.04938, lr:1.00e-02, fs:0.88333 (r=0.964,p=0.815),  time:35.668, tt:1177.056\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.04809, lr:1.00e-02, fs:0.89256 (r=0.982,p=0.818),  time:35.719, tt:1214.452\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.04714, lr:1.00e-02, fs:0.90598 (r=0.964,p=0.855),  time:35.745, tt:1251.072\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.04647, lr:1.00e-02, fs:0.90164 (r=1.000,p=0.821),  time:35.811, tt:1289.210\n",
      "Ep:36, loss:0.00009, loss_test:0.04414, lr:1.00e-02, fs:0.93220 (r=1.000,p=0.873),  time:35.877, tt:1327.434\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.04431, lr:1.00e-02, fs:0.89431 (r=1.000,p=0.809),  time:35.932, tt:1365.402\n",
      "Ep:38, loss:0.00008, loss_test:0.04144, lr:1.00e-02, fs:0.94017 (r=1.000,p=0.887),  time:35.913, tt:1400.622\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.04172, lr:1.00e-02, fs:0.90909 (r=1.000,p=0.833),  time:35.899, tt:1435.976\n",
      "Ep:40, loss:0.00008, loss_test:0.03875, lr:1.00e-02, fs:0.94017 (r=1.000,p=0.887),  time:35.925, tt:1472.936\n",
      "Ep:41, loss:0.00008, loss_test:0.03876, lr:1.00e-02, fs:0.93220 (r=1.000,p=0.873),  time:35.901, tt:1507.843\n",
      "Ep:42, loss:0.00007, loss_test:0.03747, lr:1.00e-02, fs:0.92437 (r=1.000,p=0.859),  time:35.933, tt:1545.126\n",
      "Ep:43, loss:0.00007, loss_test:0.03678, lr:1.00e-02, fs:0.94017 (r=1.000,p=0.887),  time:35.951, tt:1581.861\n",
      "Ep:44, loss:0.00007, loss_test:0.03580, lr:1.00e-02, fs:0.93220 (r=1.000,p=0.873),  time:35.996, tt:1619.837\n",
      "Ep:45, loss:0.00007, loss_test:0.03464, lr:1.00e-02, fs:0.94828 (r=1.000,p=0.902),  time:35.959, tt:1654.106\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.03381, lr:1.00e-02, fs:0.94017 (r=1.000,p=0.887),  time:35.944, tt:1689.347\n",
      "Ep:47, loss:0.00007, loss_test:0.03253, lr:1.00e-02, fs:0.94828 (r=1.000,p=0.902),  time:36.034, tt:1729.610\n",
      "Ep:48, loss:0.00006, loss_test:0.03088, lr:1.00e-02, fs:0.94828 (r=1.000,p=0.902),  time:36.075, tt:1767.673\n",
      "Ep:49, loss:0.00006, loss_test:0.03139, lr:1.00e-02, fs:0.94828 (r=1.000,p=0.902),  time:36.076, tt:1803.776\n",
      "Ep:50, loss:0.00006, loss_test:0.02959, lr:1.00e-02, fs:0.96491 (r=1.000,p=0.932),  time:36.105, tt:1841.375\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00006, loss_test:0.03220, lr:1.00e-02, fs:0.92437 (r=1.000,p=0.859),  time:36.124, tt:1878.423\n",
      "Ep:52, loss:0.00005, loss_test:0.02964, lr:1.00e-02, fs:0.97345 (r=1.000,p=0.948),  time:36.146, tt:1915.734\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.03010, lr:1.00e-02, fs:0.93220 (r=1.000,p=0.873),  time:36.140, tt:1951.560\n",
      "Ep:54, loss:0.00005, loss_test:0.02699, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:36.124, tt:1986.837\n",
      "Ep:55, loss:0.00005, loss_test:0.02720, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:36.130, tt:2023.252\n",
      "Ep:56, loss:0.00005, loss_test:0.02583, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:36.124, tt:2059.043\n",
      "Ep:57, loss:0.00005, loss_test:0.02676, lr:1.00e-02, fs:0.96491 (r=1.000,p=0.932),  time:36.149, tt:2096.662\n",
      "Ep:58, loss:0.00005, loss_test:0.02398, lr:1.00e-02, fs:0.95652 (r=1.000,p=0.917),  time:36.150, tt:2132.829\n",
      "Ep:59, loss:0.00004, loss_test:0.02436, lr:1.00e-02, fs:0.97345 (r=1.000,p=0.948),  time:36.149, tt:2168.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00005, loss_test:0.02268, lr:1.00e-02, fs:0.96491 (r=1.000,p=0.932),  time:36.180, tt:2279.338\n",
      "Ep:63, loss:0.00004, loss_test:0.02231, lr:1.00e-02, fs:0.96491 (r=1.000,p=0.932),  time:36.177, tt:2315.346\n",
      "Ep:64, loss:0.00004, loss_test:0.02179, lr:9.90e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.188, tt:2352.248\n",
      "Ep:65, loss:0.00004, loss_test:0.02223, lr:9.80e-03, fs:0.96491 (r=1.000,p=0.932),  time:36.207, tt:2389.687\n",
      "Ep:66, loss:0.00004, loss_test:0.01951, lr:9.70e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.210, tt:2426.102\n",
      "Ep:67, loss:0.00004, loss_test:0.01943, lr:9.61e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.211, tt:2462.316\n",
      "Ep:68, loss:0.00003, loss_test:0.02082, lr:9.51e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.228, tt:2499.727\n",
      "Ep:69, loss:0.00003, loss_test:0.01953, lr:9.41e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.240, tt:2536.794\n",
      "Ep:70, loss:0.00003, loss_test:0.01878, lr:9.32e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.240, tt:2573.030\n",
      "Ep:71, loss:0.00003, loss_test:0.01705, lr:9.23e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.251, tt:2610.096\n",
      "Ep:72, loss:0.00003, loss_test:0.01829, lr:9.14e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.258, tt:2646.814\n",
      "Ep:73, loss:0.00003, loss_test:0.01676, lr:9.04e-03, fs:0.96429 (r=0.982,p=0.947),  time:36.272, tt:2684.146\n",
      "Ep:74, loss:0.00003, loss_test:0.01812, lr:8.95e-03, fs:0.97345 (r=1.000,p=0.948),  time:36.275, tt:2720.629\n",
      "Ep:75, loss:0.00003, loss_test:0.01595, lr:8.86e-03, fs:0.96429 (r=0.982,p=0.947),  time:36.281, tt:2757.365\n",
      "Ep:76, loss:0.00003, loss_test:0.01630, lr:8.78e-03, fs:0.98214 (r=1.000,p=0.965),  time:36.258, tt:2791.857\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.01497, lr:8.78e-03, fs:0.98214 (r=1.000,p=0.965),  time:36.254, tt:2827.775\n",
      "Ep:78, loss:0.00002, loss_test:0.01556, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.256, tt:2864.243\n",
      "Ep:79, loss:0.00002, loss_test:0.01519, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.265, tt:2901.202\n",
      "Ep:80, loss:0.00002, loss_test:0.01631, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.263, tt:2937.297\n",
      "Ep:81, loss:0.00002, loss_test:0.01413, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.272, tt:2974.270\n",
      "Ep:82, loss:0.00002, loss_test:0.01496, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.280, tt:3011.232\n",
      "Ep:83, loss:0.00002, loss_test:0.01376, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.301, tt:3049.283\n",
      "Ep:84, loss:0.00002, loss_test:0.01496, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.321, tt:3087.263\n",
      "Ep:85, loss:0.00002, loss_test:0.01375, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.324, tt:3123.844\n",
      "Ep:86, loss:0.00002, loss_test:0.01484, lr:8.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.321, tt:3159.903\n",
      "Ep:87, loss:0.00002, loss_test:0.01489, lr:8.78e-03, fs:0.98214 (r=1.000,p=0.965),  time:36.331, tt:3197.119\n",
      "Ep:88, loss:0.00002, loss_test:0.01330, lr:8.69e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.342, tt:3234.465\n",
      "Ep:89, loss:0.00002, loss_test:0.01378, lr:8.60e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.358, tt:3272.249\n",
      "Ep:90, loss:0.00002, loss_test:0.01290, lr:8.51e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.371, tt:3309.732\n",
      "Ep:91, loss:0.00002, loss_test:0.01302, lr:8.43e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.372, tt:3346.180\n",
      "Ep:92, loss:0.00002, loss_test:0.01374, lr:8.35e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.356, tt:3381.127\n",
      "Ep:93, loss:0.00002, loss_test:0.01234, lr:8.26e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.351, tt:3417.031\n",
      "Ep:94, loss:0.00002, loss_test:0.01239, lr:8.18e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.361, tt:3454.302\n",
      "Ep:95, loss:0.00002, loss_test:0.01244, lr:8.10e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.362, tt:3490.707\n",
      "Ep:96, loss:0.00002, loss_test:0.01191, lr:8.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.357, tt:3526.595\n",
      "Ep:97, loss:0.00002, loss_test:0.01387, lr:7.94e-03, fs:0.96429 (r=0.982,p=0.947),  time:36.369, tt:3564.193\n",
      "Ep:98, loss:0.00002, loss_test:0.01183, lr:7.86e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.361, tt:3599.696\n",
      "Ep:99, loss:0.00002, loss_test:0.01262, lr:7.78e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.388, tt:3638.799\n",
      "Ep:100, loss:0.00002, loss_test:0.01249, lr:7.70e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.395, tt:3675.919\n",
      "Ep:101, loss:0.00001, loss_test:0.01192, lr:7.62e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.407, tt:3713.522\n",
      "Ep:102, loss:0.00002, loss_test:0.01315, lr:7.55e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.401, tt:3749.277\n",
      "Ep:103, loss:0.00002, loss_test:0.01134, lr:7.47e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.402, tt:3785.812\n",
      "Ep:104, loss:0.00001, loss_test:0.01173, lr:7.40e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.418, tt:3823.935\n",
      "Ep:105, loss:0.00001, loss_test:0.01191, lr:7.32e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.442, tt:3862.838\n",
      "Ep:106, loss:0.00001, loss_test:0.01156, lr:7.25e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.451, tt:3900.209\n",
      "Ep:107, loss:0.00001, loss_test:0.01161, lr:7.18e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.473, tt:3939.072\n",
      "Ep:108, loss:0.00001, loss_test:0.01191, lr:7.11e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.496, tt:3978.091\n",
      "Ep:109, loss:0.00001, loss_test:0.01121, lr:7.03e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.497, tt:4014.710\n",
      "Ep:110, loss:0.00001, loss_test:0.01129, lr:6.96e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.517, tt:4053.401\n",
      "Ep:111, loss:0.00001, loss_test:0.01150, lr:6.89e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.503, tt:4088.329\n",
      "Ep:112, loss:0.00001, loss_test:0.01076, lr:6.83e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.489, tt:4123.249\n",
      "Ep:113, loss:0.00001, loss_test:0.01130, lr:6.76e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.493, tt:4160.244\n",
      "Ep:114, loss:0.00001, loss_test:0.01069, lr:6.69e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.507, tt:4198.335\n",
      "Ep:115, loss:0.00001, loss_test:0.01098, lr:6.62e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.488, tt:4232.600\n",
      "Ep:116, loss:0.00001, loss_test:0.01066, lr:6.56e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.486, tt:4268.819\n",
      "Ep:117, loss:0.00001, loss_test:0.01067, lr:6.49e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.476, tt:4304.174\n",
      "Ep:118, loss:0.00001, loss_test:0.01129, lr:6.43e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.468, tt:4339.729\n",
      "Ep:119, loss:0.00001, loss_test:0.01065, lr:6.36e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.461, tt:4375.357\n",
      "Ep:120, loss:0.00001, loss_test:0.01052, lr:6.30e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.435, tt:4408.619\n",
      "Ep:121, loss:0.00001, loss_test:0.01106, lr:6.24e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.482, tt:4450.837\n",
      "Ep:122, loss:0.00001, loss_test:0.01047, lr:6.17e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.475, tt:4486.412\n",
      "Ep:123, loss:0.00001, loss_test:0.01036, lr:6.11e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.468, tt:4522.035\n",
      "Ep:124, loss:0.00001, loss_test:0.01096, lr:6.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.478, tt:4559.753\n",
      "Ep:125, loss:0.00001, loss_test:0.01017, lr:5.99e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.463, tt:4594.286\n",
      "Ep:126, loss:0.00001, loss_test:0.01057, lr:5.93e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.452, tt:4629.428\n",
      "Ep:127, loss:0.00001, loss_test:0.01044, lr:5.87e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.445, tt:4664.916\n",
      "Ep:128, loss:0.00001, loss_test:0.01020, lr:5.81e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.439, tt:4700.672\n",
      "Ep:129, loss:0.00001, loss_test:0.01071, lr:5.75e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.440, tt:4737.174\n",
      "Ep:130, loss:0.00001, loss_test:0.01011, lr:5.70e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.446, tt:4774.385\n",
      "Ep:131, loss:0.00001, loss_test:0.00995, lr:5.64e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.448, tt:4811.120\n",
      "Ep:132, loss:0.00001, loss_test:0.01058, lr:5.58e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.438, tt:4846.287\n",
      "Ep:133, loss:0.00001, loss_test:0.00996, lr:5.53e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.442, tt:4883.234\n",
      "Ep:134, loss:0.00001, loss_test:0.01025, lr:5.47e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.425, tt:4917.434\n",
      "Ep:135, loss:0.00001, loss_test:0.01042, lr:5.42e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.415, tt:4952.502\n",
      "Ep:136, loss:0.00001, loss_test:0.00992, lr:5.36e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.400, tt:4986.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.01037, lr:5.31e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.402, tt:5023.430\n",
      "Ep:138, loss:0.00001, loss_test:0.01001, lr:5.26e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.408, tt:5060.734\n",
      "Ep:139, loss:0.00001, loss_test:0.01016, lr:5.20e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.431, tt:5100.393\n",
      "Ep:140, loss:0.00001, loss_test:0.00994, lr:5.15e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.417, tt:5134.727\n",
      "Ep:141, loss:0.00001, loss_test:0.01042, lr:5.10e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.404, tt:5169.432\n",
      "Ep:142, loss:0.00001, loss_test:0.00980, lr:5.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.403, tt:5205.659\n",
      "Ep:143, loss:0.00001, loss_test:0.01035, lr:5.00e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.408, tt:5242.734\n",
      "Ep:144, loss:0.00001, loss_test:0.00989, lr:4.95e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.402, tt:5278.349\n",
      "Ep:145, loss:0.00001, loss_test:0.01032, lr:4.90e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.400, tt:5314.412\n",
      "Ep:146, loss:0.00001, loss_test:0.00968, lr:4.85e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.405, tt:5351.527\n",
      "Ep:147, loss:0.00001, loss_test:0.01029, lr:4.80e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.395, tt:5386.447\n",
      "Ep:148, loss:0.00001, loss_test:0.00970, lr:4.75e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.388, tt:5421.798\n",
      "Ep:149, loss:0.00001, loss_test:0.01027, lr:4.71e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.380, tt:5456.957\n",
      "Ep:150, loss:0.00001, loss_test:0.00959, lr:4.66e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.365, tt:5491.168\n",
      "Ep:151, loss:0.00001, loss_test:0.01013, lr:4.61e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.367, tt:5527.851\n",
      "Ep:152, loss:0.00001, loss_test:0.00978, lr:4.57e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.362, tt:5563.429\n",
      "Ep:153, loss:0.00001, loss_test:0.00965, lr:4.52e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.364, tt:5600.073\n",
      "Ep:154, loss:0.00001, loss_test:0.00993, lr:4.48e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.367, tt:5636.889\n",
      "Ep:155, loss:0.00001, loss_test:0.00977, lr:4.43e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.367, tt:5673.241\n",
      "Ep:156, loss:0.00001, loss_test:0.00978, lr:4.39e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.369, tt:5709.985\n",
      "Ep:157, loss:0.00001, loss_test:0.00979, lr:4.34e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.376, tt:5747.441\n",
      "Ep:158, loss:0.00001, loss_test:0.00982, lr:4.30e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.411, tt:5789.274\n",
      "Ep:159, loss:0.00001, loss_test:0.00952, lr:4.26e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.414, tt:5826.224\n",
      "Ep:160, loss:0.00001, loss_test:0.00992, lr:4.21e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.425, tt:5864.355\n",
      "Ep:161, loss:0.00001, loss_test:0.00946, lr:4.17e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.441, tt:5903.371\n",
      "Ep:162, loss:0.00001, loss_test:0.00974, lr:4.13e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.443, tt:5940.234\n",
      "Ep:163, loss:0.00001, loss_test:0.00942, lr:4.09e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.438, tt:5975.905\n",
      "Ep:164, loss:0.00001, loss_test:0.00977, lr:4.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.444, tt:6013.335\n",
      "Ep:165, loss:0.00001, loss_test:0.00923, lr:4.01e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.442, tt:6049.296\n",
      "Ep:166, loss:0.00001, loss_test:0.00930, lr:3.97e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.442, tt:6085.815\n",
      "Ep:167, loss:0.00001, loss_test:0.00955, lr:3.93e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.444, tt:6122.583\n",
      "Ep:168, loss:0.00001, loss_test:0.00932, lr:3.89e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.439, tt:6158.214\n",
      "Ep:169, loss:0.00001, loss_test:0.00967, lr:3.85e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.434, tt:6193.809\n",
      "Ep:170, loss:0.00001, loss_test:0.00923, lr:3.81e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.430, tt:6229.485\n",
      "Ep:171, loss:0.00001, loss_test:0.00965, lr:3.77e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.435, tt:6266.844\n",
      "Ep:172, loss:0.00001, loss_test:0.00913, lr:3.73e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.441, tt:6304.319\n",
      "Ep:173, loss:0.00001, loss_test:0.00911, lr:3.70e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.425, tt:6337.960\n",
      "Ep:174, loss:0.00001, loss_test:0.00960, lr:3.66e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.431, tt:6375.508\n",
      "Ep:175, loss:0.00001, loss_test:0.00928, lr:3.62e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.424, tt:6410.597\n",
      "Ep:176, loss:0.00001, loss_test:0.00960, lr:3.59e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.424, tt:6446.972\n",
      "Ep:177, loss:0.00001, loss_test:0.00917, lr:3.55e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.422, tt:6483.139\n",
      "Ep:178, loss:0.00001, loss_test:0.00912, lr:3.52e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.419, tt:6518.921\n",
      "Ep:179, loss:0.00001, loss_test:0.00974, lr:3.48e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.425, tt:6556.500\n",
      "Ep:180, loss:0.00001, loss_test:0.00908, lr:3.45e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.434, tt:6594.550\n",
      "Ep:181, loss:0.00001, loss_test:0.00936, lr:3.41e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.439, tt:6631.904\n",
      "Ep:182, loss:0.00001, loss_test:0.00930, lr:3.38e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.448, tt:6669.950\n",
      "Ep:183, loss:0.00001, loss_test:0.00910, lr:3.34e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.443, tt:6705.602\n",
      "Ep:184, loss:0.00001, loss_test:0.00949, lr:3.31e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.449, tt:6743.096\n",
      "Ep:185, loss:0.00001, loss_test:0.00920, lr:3.28e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.456, tt:6780.883\n",
      "Ep:186, loss:0.00001, loss_test:0.00927, lr:3.24e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.471, tt:6820.127\n",
      "Ep:187, loss:0.00001, loss_test:0.00946, lr:3.21e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.479, tt:6858.026\n",
      "Ep:188, loss:0.00001, loss_test:0.00911, lr:3.18e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.481, tt:6894.998\n",
      "Ep:189, loss:0.00001, loss_test:0.00926, lr:3.15e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.489, tt:6932.858\n",
      "Ep:190, loss:0.00001, loss_test:0.00946, lr:3.12e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.490, tt:6969.559\n",
      "Ep:191, loss:0.00001, loss_test:0.00909, lr:3.09e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.496, tt:7007.259\n",
      "Ep:192, loss:0.00001, loss_test:0.00927, lr:3.05e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.503, tt:7045.070\n",
      "Ep:193, loss:0.00001, loss_test:0.00905, lr:3.02e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.516, tt:7084.163\n",
      "Ep:194, loss:0.00001, loss_test:0.00901, lr:2.99e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.526, tt:7122.543\n",
      "Ep:195, loss:0.00001, loss_test:0.00952, lr:2.96e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.525, tt:7158.994\n",
      "Ep:196, loss:0.00001, loss_test:0.00896, lr:2.93e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.536, tt:7197.509\n",
      "Ep:197, loss:0.00001, loss_test:0.00912, lr:2.90e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.544, tt:7235.772\n",
      "Ep:198, loss:0.00001, loss_test:0.00934, lr:2.88e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.553, tt:7273.992\n",
      "Ep:199, loss:0.00001, loss_test:0.00903, lr:2.85e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.555, tt:7310.964\n",
      "Ep:200, loss:0.00001, loss_test:0.00912, lr:2.82e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.552, tt:7346.959\n",
      "Ep:201, loss:0.00001, loss_test:0.00921, lr:2.79e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.557, tt:7384.422\n",
      "Ep:202, loss:0.00001, loss_test:0.00902, lr:2.76e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.558, tt:7421.358\n",
      "Ep:203, loss:0.00001, loss_test:0.00912, lr:2.73e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.556, tt:7457.364\n",
      "Ep:204, loss:0.00001, loss_test:0.00908, lr:2.71e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.562, tt:7495.285\n",
      "Ep:205, loss:0.00001, loss_test:0.00891, lr:2.68e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.562, tt:7531.684\n",
      "Ep:206, loss:0.00001, loss_test:0.00922, lr:2.65e-03, fs:0.97297 (r=0.982,p=0.964),  time:36.560, tt:7567.915\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 110\n",
      "Train positive samples: 977 Test positive samples: 55\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02489, lr:6.00e-02, fs:0.65041 (r=0.727,p=0.588),  time:32.985, tt:32.985\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02482, lr:6.00e-02, fs:0.67081 (r=0.982,p=0.509),  time:33.143, tt:66.287\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02789, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.736, tt:95.207\n",
      "Ep:3, loss:0.00006, loss_test:0.02841, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.276, tt:121.105\n",
      "Ep:4, loss:0.00006, loss_test:0.02821, lr:6.00e-02, fs:0.67073 (r=1.000,p=0.505),  time:30.478, tt:152.388\n",
      "Ep:5, loss:0.00006, loss_test:0.02749, lr:6.00e-02, fs:0.67081 (r=0.982,p=0.509),  time:30.907, tt:185.444\n",
      "Ep:6, loss:0.00005, loss_test:0.02651, lr:6.00e-02, fs:0.67500 (r=0.982,p=0.514),  time:31.413, tt:219.892\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02558, lr:6.00e-02, fs:0.68790 (r=0.982,p=0.529),  time:31.881, tt:255.052\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00005, loss_test:0.02493, lr:6.00e-02, fs:0.67974 (r=0.945,p=0.531),  time:32.381, tt:291.433\n",
      "Ep:9, loss:0.00005, loss_test:0.02437, lr:6.00e-02, fs:0.69333 (r=0.945,p=0.547),  time:32.402, tt:324.022\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00005, loss_test:0.02383, lr:6.00e-02, fs:0.70199 (r=0.964,p=0.552),  time:32.339, tt:355.724\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00005, loss_test:0.02323, lr:6.00e-02, fs:0.70199 (r=0.964,p=0.552),  time:32.200, tt:386.397\n",
      "Ep:12, loss:0.00005, loss_test:0.02265, lr:6.00e-02, fs:0.69737 (r=0.964,p=0.546),  time:32.130, tt:417.695\n",
      "Ep:13, loss:0.00005, loss_test:0.02202, lr:6.00e-02, fs:0.70199 (r=0.964,p=0.552),  time:32.335, tt:452.696\n",
      "Ep:14, loss:0.00005, loss_test:0.02126, lr:6.00e-02, fs:0.70199 (r=0.964,p=0.552),  time:32.432, tt:486.473\n",
      "Ep:15, loss:0.00005, loss_test:0.02049, lr:6.00e-02, fs:0.71141 (r=0.964,p=0.564),  time:32.555, tt:520.879\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.01970, lr:6.00e-02, fs:0.71622 (r=0.964,p=0.570),  time:32.680, tt:555.554\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01913, lr:6.00e-02, fs:0.72603 (r=0.964,p=0.582),  time:32.849, tt:591.281\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01874, lr:6.00e-02, fs:0.73973 (r=0.982,p=0.593),  time:33.034, tt:627.651\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01844, lr:6.00e-02, fs:0.73469 (r=0.982,p=0.587),  time:33.128, tt:662.569\n",
      "Ep:20, loss:0.00004, loss_test:0.01816, lr:6.00e-02, fs:0.72973 (r=0.982,p=0.581),  time:33.240, tt:698.033\n",
      "Ep:21, loss:0.00004, loss_test:0.01787, lr:6.00e-02, fs:0.72973 (r=0.982,p=0.581),  time:33.353, tt:733.770\n",
      "Ep:22, loss:0.00004, loss_test:0.01749, lr:6.00e-02, fs:0.73469 (r=0.982,p=0.587),  time:33.454, tt:769.451\n",
      "Ep:23, loss:0.00004, loss_test:0.01711, lr:6.00e-02, fs:0.73103 (r=0.964,p=0.589),  time:33.527, tt:804.658\n",
      "Ep:24, loss:0.00004, loss_test:0.01674, lr:6.00e-02, fs:0.74286 (r=0.945,p=0.612),  time:33.661, tt:841.522\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01638, lr:6.00e-02, fs:0.76812 (r=0.964,p=0.639),  time:33.699, tt:876.171\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01613, lr:6.00e-02, fs:0.75714 (r=0.964,p=0.624),  time:33.744, tt:911.075\n",
      "Ep:27, loss:0.00004, loss_test:0.01589, lr:6.00e-02, fs:0.75714 (r=0.964,p=0.624),  time:33.774, tt:945.669\n",
      "Ep:28, loss:0.00003, loss_test:0.01563, lr:6.00e-02, fs:0.75714 (r=0.964,p=0.624),  time:33.837, tt:981.261\n",
      "Ep:29, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.78261 (r=0.982,p=0.651),  time:33.859, tt:1015.768\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.79137 (r=1.000,p=0.655),  time:33.858, tt:1049.610\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01509, lr:6.00e-02, fs:0.79137 (r=1.000,p=0.655),  time:33.913, tt:1085.222\n",
      "Ep:32, loss:0.00003, loss_test:0.01489, lr:6.00e-02, fs:0.78261 (r=0.982,p=0.651),  time:33.968, tt:1120.951\n",
      "Ep:33, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.78261 (r=0.982,p=0.651),  time:33.979, tt:1155.277\n",
      "Ep:34, loss:0.00003, loss_test:0.01453, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:33.990, tt:1189.637\n",
      "Ep:35, loss:0.00003, loss_test:0.01447, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:34.012, tt:1224.425\n",
      "Ep:36, loss:0.00003, loss_test:0.01435, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:34.013, tt:1258.469\n",
      "Ep:37, loss:0.00003, loss_test:0.01399, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:34.046, tt:1293.750\n",
      "Ep:38, loss:0.00003, loss_test:0.01371, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:34.055, tt:1328.138\n",
      "Ep:39, loss:0.00003, loss_test:0.01354, lr:6.00e-02, fs:0.78832 (r=0.982,p=0.659),  time:34.093, tt:1363.706\n",
      "Ep:40, loss:0.00003, loss_test:0.01324, lr:6.00e-02, fs:0.79412 (r=0.982,p=0.667),  time:34.135, tt:1399.534\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01299, lr:6.00e-02, fs:0.80597 (r=0.982,p=0.684),  time:34.170, tt:1435.160\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01278, lr:6.00e-02, fs:0.81203 (r=0.982,p=0.692),  time:34.207, tt:1470.886\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.82090 (r=1.000,p=0.696),  time:34.253, tt:1507.143\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01202, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.271, tt:1542.194\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.288, tt:1577.256\n",
      "Ep:46, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.292, tt:1611.720\n",
      "Ep:47, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.257, tt:1644.352\n",
      "Ep:48, loss:0.00002, loss_test:0.01073, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.262, tt:1678.821\n",
      "Ep:49, loss:0.00002, loss_test:0.01050, lr:6.00e-02, fs:0.82707 (r=1.000,p=0.705),  time:34.279, tt:1713.958\n",
      "Ep:50, loss:0.00002, loss_test:0.01009, lr:6.00e-02, fs:0.83333 (r=1.000,p=0.714),  time:34.278, tt:1748.190\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.00980, lr:6.00e-02, fs:0.83969 (r=1.000,p=0.724),  time:34.323, tt:1784.804\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.00967, lr:6.00e-02, fs:0.83969 (r=1.000,p=0.724),  time:34.338, tt:1819.915\n",
      "Ep:53, loss:0.00002, loss_test:0.00950, lr:6.00e-02, fs:0.84615 (r=1.000,p=0.733),  time:34.331, tt:1853.897\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.00899, lr:6.00e-02, fs:0.83721 (r=0.982,p=0.730),  time:34.333, tt:1888.327\n",
      "Ep:55, loss:0.00002, loss_test:0.00897, lr:6.00e-02, fs:0.84615 (r=1.000,p=0.733),  time:34.324, tt:1922.118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00015, loss_test:0.02435, lr:6.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:11.308, tt:11.308\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02670, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:13.218, tt:26.436\n",
      "Ep:2, loss:0.00005, loss_test:0.02930, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.697, tt:47.092\n",
      "Ep:3, loss:0.00006, loss_test:0.03055, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.501, tt:74.004\n",
      "Ep:4, loss:0.00006, loss_test:0.03079, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.233, tt:106.165\n",
      "Ep:5, loss:0.00006, loss_test:0.03029, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:22.993, tt:137.960\n",
      "Ep:6, loss:0.00006, loss_test:0.02937, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:24.171, tt:169.198\n",
      "Ep:7, loss:0.00006, loss_test:0.02811, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:25.211, tt:201.691\n",
      "Ep:8, loss:0.00005, loss_test:0.02683, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:25.949, tt:233.539\n",
      "Ep:9, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:26.322, tt:263.216\n",
      "Ep:10, loss:0.00005, loss_test:0.02535, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:26.828, tt:295.113\n",
      "Ep:11, loss:0.00005, loss_test:0.02509, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:27.182, tt:326.188\n",
      "Ep:12, loss:0.00005, loss_test:0.02492, lr:5.94e-02, fs:0.65399 (r=0.869,p=0.524),  time:27.570, tt:358.415\n",
      "Ep:13, loss:0.00005, loss_test:0.02476, lr:5.88e-02, fs:0.65660 (r=0.879,p=0.524),  time:27.855, tt:389.965\n",
      "Ep:14, loss:0.00005, loss_test:0.02477, lr:5.82e-02, fs:0.66182 (r=0.919,p=0.517),  time:28.107, tt:421.602\n",
      "Ep:15, loss:0.00005, loss_test:0.02469, lr:5.76e-02, fs:0.65704 (r=0.919,p=0.511),  time:28.298, tt:452.764\n",
      "Ep:16, loss:0.00005, loss_test:0.02438, lr:5.71e-02, fs:0.66667 (r=0.919,p=0.523),  time:28.418, tt:483.103\n",
      "Ep:17, loss:0.00005, loss_test:0.02399, lr:5.65e-02, fs:0.66914 (r=0.909,p=0.529),  time:28.659, tt:515.855\n",
      "Ep:18, loss:0.00005, loss_test:0.02374, lr:5.59e-02, fs:0.65900 (r=0.869,p=0.531),  time:28.713, tt:545.552\n",
      "Ep:19, loss:0.00005, loss_test:0.02348, lr:5.54e-02, fs:0.65385 (r=0.859,p=0.528),  time:28.776, tt:575.516\n",
      "Ep:20, loss:0.00004, loss_test:0.02326, lr:5.48e-02, fs:0.66409 (r=0.869,p=0.537),  time:28.859, tt:606.045\n",
      "Ep:21, loss:0.00004, loss_test:0.02306, lr:5.43e-02, fs:0.67433 (r=0.889,p=0.543),  time:28.970, tt:637.344\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.02285, lr:5.43e-02, fs:0.67433 (r=0.889,p=0.543),  time:29.055, tt:668.263\n",
      "Ep:23, loss:0.00004, loss_test:0.02266, lr:5.43e-02, fs:0.67194 (r=0.859,p=0.552),  time:29.197, tt:700.736\n",
      "Ep:24, loss:0.00004, loss_test:0.02248, lr:5.43e-02, fs:0.67200 (r=0.848,p=0.556),  time:29.235, tt:730.872\n",
      "Ep:25, loss:0.00004, loss_test:0.02230, lr:5.43e-02, fs:0.66403 (r=0.848,p=0.545),  time:29.274, tt:761.123\n",
      "Ep:26, loss:0.00004, loss_test:0.02214, lr:5.43e-02, fs:0.66142 (r=0.848,p=0.542),  time:29.355, tt:792.572\n",
      "Ep:27, loss:0.00004, loss_test:0.02196, lr:5.43e-02, fs:0.66403 (r=0.848,p=0.545),  time:29.390, tt:822.928\n",
      "Ep:28, loss:0.00004, loss_test:0.02182, lr:5.43e-02, fs:0.66135 (r=0.838,p=0.546),  time:29.406, tt:852.776\n",
      "Ep:29, loss:0.00004, loss_test:0.02176, lr:5.43e-02, fs:0.66397 (r=0.828,p=0.554),  time:29.454, tt:883.625\n",
      "Ep:30, loss:0.00004, loss_test:0.02169, lr:5.43e-02, fs:0.65574 (r=0.808,p=0.552),  time:29.460, tt:913.270\n",
      "Ep:31, loss:0.00004, loss_test:0.02160, lr:5.43e-02, fs:0.65844 (r=0.808,p=0.556),  time:29.452, tt:942.474\n",
      "Ep:32, loss:0.00004, loss_test:0.02142, lr:5.43e-02, fs:0.65574 (r=0.808,p=0.552),  time:29.462, tt:972.259\n",
      "Ep:33, loss:0.00003, loss_test:0.02118, lr:5.37e-02, fs:0.66667 (r=0.828,p=0.558),  time:29.482, tt:1002.395\n",
      "Ep:34, loss:0.00003, loss_test:0.02102, lr:5.32e-02, fs:0.67480 (r=0.838,p=0.565),  time:29.462, tt:1031.161\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.02080, lr:5.32e-02, fs:0.67480 (r=0.838,p=0.565),  time:29.481, tt:1061.301\n",
      "Ep:36, loss:0.00003, loss_test:0.02047, lr:5.32e-02, fs:0.67755 (r=0.838,p=0.568),  time:29.469, tt:1090.350\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.02014, lr:5.32e-02, fs:0.67742 (r=0.848,p=0.564),  time:29.479, tt:1120.219\n",
      "Ep:38, loss:0.00003, loss_test:0.01992, lr:5.32e-02, fs:0.67742 (r=0.848,p=0.564),  time:29.473, tt:1149.440\n",
      "Ep:39, loss:0.00003, loss_test:0.01978, lr:5.32e-02, fs:0.67206 (r=0.838,p=0.561),  time:29.452, tt:1178.076\n",
      "Ep:40, loss:0.00003, loss_test:0.01967, lr:5.32e-02, fs:0.66667 (r=0.828,p=0.558),  time:29.456, tt:1207.700\n",
      "Ep:41, loss:0.00003, loss_test:0.01962, lr:5.32e-02, fs:0.66667 (r=0.828,p=0.558),  time:29.496, tt:1238.834\n",
      "Ep:42, loss:0.00003, loss_test:0.01940, lr:5.32e-02, fs:0.66939 (r=0.828,p=0.562),  time:29.515, tt:1269.142\n",
      "Ep:43, loss:0.00003, loss_test:0.01930, lr:5.32e-02, fs:0.67490 (r=0.828,p=0.569),  time:29.521, tt:1298.921\n",
      "Ep:44, loss:0.00003, loss_test:0.01908, lr:5.32e-02, fs:0.66667 (r=0.818,p=0.562),  time:29.545, tt:1329.542\n",
      "Ep:45, loss:0.00003, loss_test:0.01899, lr:5.32e-02, fs:0.67220 (r=0.818,p=0.570),  time:29.620, tt:1362.525\n",
      "Ep:46, loss:0.00003, loss_test:0.01878, lr:5.32e-02, fs:0.68354 (r=0.818,p=0.587),  time:29.649, tt:1393.491\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01875, lr:5.32e-02, fs:0.68067 (r=0.818,p=0.583),  time:29.673, tt:1424.322\n",
      "Ep:48, loss:0.00003, loss_test:0.01855, lr:5.32e-02, fs:0.68103 (r=0.798,p=0.594),  time:29.730, tt:1456.764\n",
      "Ep:49, loss:0.00003, loss_test:0.01852, lr:5.32e-02, fs:0.68696 (r=0.798,p=0.603),  time:29.755, tt:1487.748\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01839, lr:5.32e-02, fs:0.68996 (r=0.798,p=0.608),  time:29.794, tt:1519.510\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01814, lr:5.32e-02, fs:0.69298 (r=0.798,p=0.612),  time:29.842, tt:1551.760\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01800, lr:5.32e-02, fs:0.69298 (r=0.798,p=0.612),  time:29.892, tt:1584.259\n",
      "Ep:53, loss:0.00002, loss_test:0.01783, lr:5.32e-02, fs:0.70270 (r=0.788,p=0.634),  time:29.904, tt:1614.791\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01763, lr:5.32e-02, fs:0.70852 (r=0.798,p=0.637),  time:29.929, tt:1646.079\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01768, lr:5.32e-02, fs:0.71171 (r=0.798,p=0.642),  time:29.971, tt:1678.350\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01751, lr:5.32e-02, fs:0.71889 (r=0.788,p=0.661),  time:29.987, tt:1709.241\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.01752, lr:5.32e-02, fs:0.72222 (r=0.788,p=0.667),  time:29.963, tt:1737.859\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01729, lr:5.32e-02, fs:0.72897 (r=0.788,p=0.678),  time:29.991, tt:1769.480\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.01727, lr:5.32e-02, fs:0.71560 (r=0.788,p=0.655),  time:30.014, tt:1800.868\n",
      "Ep:60, loss:0.00002, loss_test:0.01713, lr:5.32e-02, fs:0.72897 (r=0.788,p=0.678),  time:30.044, tt:1832.693\n",
      "Ep:61, loss:0.00002, loss_test:0.01720, lr:5.32e-02, fs:0.73239 (r=0.788,p=0.684),  time:30.060, tt:1863.744\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.01692, lr:5.32e-02, fs:0.72897 (r=0.788,p=0.678),  time:30.071, tt:1894.470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00002, loss_test:0.01652, lr:5.32e-02, fs:0.72558 (r=0.788,p=0.672),  time:30.077, tt:1924.914\n",
      "Ep:64, loss:0.00002, loss_test:0.01685, lr:5.32e-02, fs:0.73239 (r=0.788,p=0.684),  time:30.096, tt:1956.244\n",
      "Ep:65, loss:0.00002, loss_test:0.01664, lr:5.32e-02, fs:0.73585 (r=0.788,p=0.690),  time:30.115, tt:1987.592\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.01631, lr:5.32e-02, fs:0.74178 (r=0.798,p=0.693),  time:30.127, tt:2018.490\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.01680, lr:5.32e-02, fs:0.76415 (r=0.818,p=0.717),  time:30.152, tt:2050.315\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01633, lr:5.32e-02, fs:0.75238 (r=0.798,p=0.712),  time:30.156, tt:2080.763\n",
      "Ep:69, loss:0.00002, loss_test:0.01665, lr:5.32e-02, fs:0.76995 (r=0.828,p=0.719),  time:30.181, tt:2112.677\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00002, loss_test:0.01621, lr:5.32e-02, fs:0.77725 (r=0.828,p=0.732),  time:30.191, tt:2143.564\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.01683, lr:5.32e-02, fs:0.78469 (r=0.828,p=0.745),  time:30.198, tt:2174.243\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00002, loss_test:0.01584, lr:5.32e-02, fs:0.78095 (r=0.828,p=0.739),  time:30.234, tt:2207.103\n",
      "Ep:73, loss:0.00002, loss_test:0.01711, lr:5.32e-02, fs:0.78302 (r=0.838,p=0.735),  time:30.215, tt:2235.929\n",
      "Ep:74, loss:0.00002, loss_test:0.01612, lr:5.32e-02, fs:0.77725 (r=0.828,p=0.732),  time:30.221, tt:2266.604\n",
      "Ep:75, loss:0.00002, loss_test:0.01654, lr:5.32e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.237, tt:2297.996\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01697, lr:5.32e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.235, tt:2328.129\n",
      "Ep:77, loss:0.00001, loss_test:0.01589, lr:5.32e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.241, tt:2358.830\n",
      "Ep:78, loss:0.00001, loss_test:0.01704, lr:5.32e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.254, tt:2390.083\n",
      "Ep:79, loss:0.00001, loss_test:0.01611, lr:5.32e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.257, tt:2420.535\n",
      "Ep:80, loss:0.00001, loss_test:0.01669, lr:5.32e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.259, tt:2450.947\n",
      "Ep:81, loss:0.00001, loss_test:0.01664, lr:5.32e-02, fs:0.79426 (r=0.838,p=0.755),  time:30.243, tt:2479.925\n",
      "Ep:82, loss:0.00001, loss_test:0.01600, lr:5.32e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.254, tt:2511.064\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01686, lr:5.32e-02, fs:0.79048 (r=0.838,p=0.748),  time:30.260, tt:2541.810\n",
      "Ep:84, loss:0.00001, loss_test:0.01617, lr:5.32e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.267, tt:2572.697\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01733, lr:5.32e-02, fs:0.78673 (r=0.838,p=0.741),  time:30.293, tt:2605.208\n",
      "Ep:86, loss:0.00001, loss_test:0.01600, lr:5.32e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.293, tt:2635.453\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01803, lr:5.32e-02, fs:0.80583 (r=0.838,p=0.776),  time:30.280, tt:2664.628\n",
      "Ep:88, loss:0.00001, loss_test:0.01647, lr:5.32e-02, fs:0.82178 (r=0.838,p=0.806),  time:30.289, tt:2695.698\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01876, lr:5.32e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.286, tt:2725.747\n",
      "Ep:90, loss:0.00001, loss_test:0.01610, lr:5.32e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.313, tt:2758.504\n",
      "Ep:91, loss:0.00001, loss_test:0.01800, lr:5.32e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.311, tt:2788.586\n",
      "Ep:92, loss:0.00001, loss_test:0.01612, lr:5.32e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.331, tt:2820.780\n",
      "Ep:93, loss:0.00001, loss_test:0.01778, lr:5.32e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.337, tt:2851.664\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01838, lr:5.32e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.332, tt:2881.551\n",
      "Ep:95, loss:0.00001, loss_test:0.01765, lr:5.32e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.310, tt:2909.736\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.02039, lr:5.32e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.329, tt:2941.944\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01760, lr:5.32e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.335, tt:2972.843\n",
      "Ep:98, loss:0.00001, loss_test:0.02096, lr:5.32e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.348, tt:3004.427\n",
      "Ep:99, loss:0.00001, loss_test:0.01896, lr:5.32e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.360, tt:3036.006\n",
      "Ep:100, loss:0.00001, loss_test:0.02148, lr:5.32e-02, fs:0.81592 (r=0.828,p=0.804),  time:30.380, tt:3068.376\n",
      "Ep:101, loss:0.00001, loss_test:0.01912, lr:5.32e-02, fs:0.83000 (r=0.838,p=0.822),  time:30.388, tt:3099.565\n",
      "Ep:102, loss:0.00001, loss_test:0.01811, lr:5.32e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.396, tt:3130.787\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.02002, lr:5.32e-02, fs:0.83000 (r=0.838,p=0.822),  time:30.404, tt:3162.048\n",
      "Ep:104, loss:0.00001, loss_test:0.01914, lr:5.32e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.386, tt:3190.495\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.02027, lr:5.32e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.407, tt:3223.164\n",
      "Ep:106, loss:0.00001, loss_test:0.02037, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.400, tt:3252.843\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.02193, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.390, tt:3282.160\n",
      "Ep:108, loss:0.00001, loss_test:0.02021, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.387, tt:3312.180\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00001, loss_test:0.02315, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.381, tt:3341.913\n",
      "Ep:110, loss:0.00001, loss_test:0.02089, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.389, tt:3373.172\n",
      "Ep:111, loss:0.00001, loss_test:0.02268, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.371, tt:3401.517\n",
      "Ep:112, loss:0.00001, loss_test:0.02047, lr:5.32e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.371, tt:3431.885\n",
      "Ep:113, loss:0.00001, loss_test:0.02283, lr:5.32e-02, fs:0.83249 (r=0.828,p=0.837),  time:30.362, tt:3461.255\n",
      "Ep:114, loss:0.00001, loss_test:0.02097, lr:5.32e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.360, tt:3491.401\n",
      "Ep:115, loss:0.00001, loss_test:0.02154, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.352, tt:3520.877\n",
      "Ep:116, loss:0.00001, loss_test:0.02154, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.339, tt:3549.689\n",
      "Ep:117, loss:0.00001, loss_test:0.02332, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.337, tt:3579.797\n",
      "Ep:118, loss:0.00001, loss_test:0.02302, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.337, tt:3610.153\n",
      "Ep:119, loss:0.00001, loss_test:0.02435, lr:5.32e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.349, tt:3641.900\n",
      "Ep:120, loss:0.00000, loss_test:0.02341, lr:5.27e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.352, tt:3672.551\n",
      "Ep:121, loss:0.00000, loss_test:0.02505, lr:5.21e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.359, tt:3703.856\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00000, loss_test:0.02365, lr:5.21e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.366, tt:3735.043\n",
      "Ep:123, loss:0.00001, loss_test:0.02630, lr:5.21e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.380, tt:3767.163\n",
      "Ep:124, loss:0.00000, loss_test:0.02426, lr:5.21e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.378, tt:3797.298\n",
      "Ep:125, loss:0.00000, loss_test:0.02536, lr:5.21e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.396, tt:3829.880\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.02515, lr:5.21e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.391, tt:3859.625\n",
      "Ep:127, loss:0.00000, loss_test:0.02605, lr:5.21e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.400, tt:3891.238\n",
      "Ep:128, loss:0.00000, loss_test:0.02410, lr:5.21e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.400, tt:3921.662\n",
      "Ep:129, loss:0.00000, loss_test:0.02481, lr:5.21e-02, fs:0.81915 (r=0.778,p=0.865),  time:30.397, tt:3951.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.02354, lr:5.21e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.399, tt:3982.276\n",
      "Ep:131, loss:0.00000, loss_test:0.02576, lr:5.21e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.403, tt:4013.174\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00000, loss_test:0.02379, lr:5.21e-02, fs:0.86598 (r=0.848,p=0.884),  time:30.422, tt:4046.099\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00000, loss_test:0.02663, lr:5.21e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.419, tt:4076.100\n",
      "Ep:134, loss:0.00000, loss_test:0.02529, lr:5.21e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.421, tt:4106.778\n",
      "Ep:135, loss:0.00000, loss_test:0.02745, lr:5.21e-02, fs:0.82162 (r=0.768,p=0.884),  time:30.431, tt:4138.669\n",
      "Ep:136, loss:0.00000, loss_test:0.02429, lr:5.21e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.441, tt:4170.357\n",
      "Ep:137, loss:0.00000, loss_test:0.02633, lr:5.21e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.447, tt:4201.727\n",
      "Ep:138, loss:0.00000, loss_test:0.02515, lr:5.21e-02, fs:0.82979 (r=0.788,p=0.876),  time:30.454, tt:4233.112\n",
      "Ep:139, loss:0.00000, loss_test:0.02642, lr:5.21e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.463, tt:4264.852\n",
      "Ep:140, loss:0.00000, loss_test:0.02626, lr:5.21e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.472, tt:4296.605\n",
      "Ep:141, loss:0.00000, loss_test:0.02640, lr:5.21e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.479, tt:4328.057\n",
      "Ep:142, loss:0.00000, loss_test:0.02529, lr:5.21e-02, fs:0.83938 (r=0.818,p=0.862),  time:30.488, tt:4359.737\n",
      "Ep:143, loss:0.00000, loss_test:0.02566, lr:5.21e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.490, tt:4390.539\n",
      "Ep:144, loss:0.00000, loss_test:0.02661, lr:5.16e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.496, tt:4421.863\n",
      "Ep:145, loss:0.00000, loss_test:0.02698, lr:5.11e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.500, tt:4453.033\n",
      "Ep:146, loss:0.00000, loss_test:0.02675, lr:5.06e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.513, tt:4485.446\n",
      "Ep:147, loss:0.00000, loss_test:0.02743, lr:5.01e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.525, tt:4517.711\n",
      "Ep:148, loss:0.00000, loss_test:0.02733, lr:4.96e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.535, tt:4549.759\n",
      "Ep:149, loss:0.00000, loss_test:0.02821, lr:4.91e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.537, tt:4580.487\n",
      "Ep:150, loss:0.00000, loss_test:0.02759, lr:4.86e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.548, tt:4612.815\n",
      "Ep:151, loss:0.00000, loss_test:0.02771, lr:4.81e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.548, tt:4643.272\n",
      "Ep:152, loss:0.00000, loss_test:0.02774, lr:4.76e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.553, tt:4674.605\n",
      "Ep:153, loss:0.00000, loss_test:0.02850, lr:4.71e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.557, tt:4705.775\n",
      "Ep:154, loss:0.00000, loss_test:0.02775, lr:4.67e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.567, tt:4737.904\n",
      "Ep:155, loss:0.00000, loss_test:0.02845, lr:4.62e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.566, tt:4768.312\n",
      "Ep:156, loss:0.00000, loss_test:0.02765, lr:4.57e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.563, tt:4798.426\n",
      "Ep:157, loss:0.00000, loss_test:0.02869, lr:4.53e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.559, tt:4828.293\n",
      "Ep:158, loss:0.00000, loss_test:0.02858, lr:4.48e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.555, tt:4858.273\n",
      "Ep:159, loss:0.00000, loss_test:0.02940, lr:4.44e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.550, tt:4888.070\n",
      "Ep:160, loss:0.00000, loss_test:0.02860, lr:4.39e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.547, tt:4918.028\n",
      "Ep:161, loss:0.00000, loss_test:0.02928, lr:4.35e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.547, tt:4948.668\n",
      "Ep:162, loss:0.00000, loss_test:0.02901, lr:4.31e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.551, tt:4979.833\n",
      "Ep:163, loss:0.00000, loss_test:0.02899, lr:4.26e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.559, tt:5011.695\n",
      "Ep:164, loss:0.00000, loss_test:0.02886, lr:4.22e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.566, tt:5043.409\n",
      "Ep:165, loss:0.00000, loss_test:0.02895, lr:4.18e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.564, tt:5073.669\n",
      "Ep:166, loss:0.00000, loss_test:0.02894, lr:4.14e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.565, tt:5104.309\n",
      "Ep:167, loss:0.00000, loss_test:0.02896, lr:4.10e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.567, tt:5135.255\n",
      "Ep:168, loss:0.00000, loss_test:0.02920, lr:4.05e-02, fs:0.85405 (r=0.798,p=0.919),  time:30.581, tt:5168.187\n",
      "Ep:169, loss:0.00000, loss_test:0.02953, lr:4.01e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.579, tt:5198.391\n",
      "Ep:170, loss:0.00000, loss_test:0.02935, lr:3.97e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.579, tt:5229.002\n",
      "Ep:171, loss:0.00000, loss_test:0.02934, lr:3.93e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.585, tt:5260.586\n",
      "Ep:172, loss:0.00000, loss_test:0.02967, lr:3.89e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.590, tt:5291.988\n",
      "Ep:173, loss:0.00000, loss_test:0.02929, lr:3.86e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.593, tt:5323.102\n",
      "Ep:174, loss:0.00000, loss_test:0.02975, lr:3.82e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.595, tt:5354.056\n",
      "Ep:175, loss:0.00000, loss_test:0.03028, lr:3.78e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.595, tt:5384.781\n",
      "Ep:176, loss:0.00000, loss_test:0.02941, lr:3.74e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.605, tt:5417.105\n",
      "Ep:177, loss:0.00000, loss_test:0.03015, lr:3.70e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.611, tt:5448.753\n",
      "Ep:178, loss:0.00000, loss_test:0.03027, lr:3.67e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.608, tt:5478.919\n",
      "Ep:179, loss:0.00000, loss_test:0.02961, lr:3.63e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.607, tt:5509.214\n",
      "Ep:180, loss:0.00000, loss_test:0.03046, lr:3.59e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.614, tt:5541.096\n",
      "Ep:181, loss:0.00000, loss_test:0.03043, lr:3.56e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.614, tt:5571.678\n",
      "Ep:182, loss:0.00000, loss_test:0.03051, lr:3.52e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.612, tt:5602.027\n",
      "Ep:183, loss:0.00000, loss_test:0.02969, lr:3.49e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.604, tt:5631.049\n",
      "Ep:184, loss:0.00000, loss_test:0.03082, lr:3.45e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.607, tt:5662.305\n",
      "Ep:185, loss:0.00000, loss_test:0.03052, lr:3.42e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.608, tt:5693.141\n",
      "Ep:186, loss:0.00000, loss_test:0.03123, lr:3.38e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.609, tt:5723.845\n",
      "Ep:187, loss:0.00000, loss_test:0.03098, lr:3.35e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.614, tt:5755.384\n",
      "Ep:188, loss:0.00000, loss_test:0.03080, lr:3.32e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.622, tt:5787.606\n",
      "Ep:189, loss:0.00000, loss_test:0.03131, lr:3.28e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.620, tt:5817.733\n",
      "Ep:190, loss:0.00000, loss_test:0.03120, lr:3.25e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.619, tt:5848.264\n",
      "Ep:191, loss:0.00000, loss_test:0.03089, lr:3.22e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.617, tt:5878.413\n",
      "Ep:192, loss:0.00000, loss_test:0.03156, lr:3.19e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.618, tt:5909.233\n",
      "Ep:193, loss:0.00000, loss_test:0.03140, lr:3.15e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.609, tt:5938.233\n",
      "Ep:194, loss:0.00000, loss_test:0.03124, lr:3.12e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.606, tt:5968.109\n",
      "Ep:195, loss:0.00000, loss_test:0.03178, lr:3.09e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.609, tt:5999.418\n",
      "Ep:196, loss:0.00000, loss_test:0.03147, lr:3.06e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.603, tt:6028.748\n",
      "Ep:197, loss:0.00000, loss_test:0.03161, lr:3.03e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.601, tt:6058.964\n",
      "Ep:198, loss:0.00000, loss_test:0.03201, lr:3.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.608, tt:6090.904\n",
      "Ep:199, loss:0.00000, loss_test:0.03164, lr:2.97e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.597, tt:6119.433\n",
      "Ep:200, loss:0.00000, loss_test:0.03216, lr:2.94e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.604, tt:6151.392\n",
      "Ep:201, loss:0.00000, loss_test:0.03184, lr:2.91e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.601, tt:6181.374\n",
      "Ep:202, loss:0.00000, loss_test:0.03209, lr:2.88e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.600, tt:6211.855\n",
      "Ep:203, loss:0.00000, loss_test:0.03203, lr:2.85e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.592, tt:6240.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.03216, lr:2.82e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.594, tt:6271.844\n",
      "Ep:205, loss:0.00000, loss_test:0.03227, lr:2.80e-02, fs:0.85083 (r=0.778,p=0.939),  time:30.597, tt:6302.992\n",
      "Ep:206, loss:0.00000, loss_test:0.03192, lr:2.77e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.597, tt:6333.652\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13261, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:25.649, tt:25.649\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13079, lr:1.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:26.701, tt:53.401\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12916, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:26.674, tt:80.022\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12807, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:25.805, tt:103.222\n",
      "Ep:4, loss:0.00025, loss_test:0.12718, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:26.841, tt:134.204\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12667, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:26.941, tt:161.643\n",
      "Ep:6, loss:0.00025, loss_test:0.12653, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:27.417, tt:191.920\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.12640, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:27.925, tt:223.404\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12566, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:28.255, tt:254.298\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.12464, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:28.556, tt:285.562\n",
      "Ep:10, loss:0.00024, loss_test:0.12389, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:28.870, tt:317.567\n",
      "Ep:11, loss:0.00024, loss_test:0.12321, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:29.139, tt:349.673\n",
      "Ep:12, loss:0.00023, loss_test:0.12298, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:29.330, tt:381.285\n",
      "Ep:13, loss:0.00023, loss_test:0.12247, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:29.564, tt:413.893\n",
      "Ep:14, loss:0.00022, loss_test:0.12150, lr:1.00e-02, fs:0.65546 (r=0.788,p=0.561),  time:29.740, tt:446.093\n",
      "Ep:15, loss:0.00022, loss_test:0.11915, lr:1.00e-02, fs:0.66387 (r=0.798,p=0.568),  time:29.888, tt:478.207\n",
      "Ep:16, loss:0.00021, loss_test:0.11875, lr:1.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:30.023, tt:510.391\n",
      "Ep:17, loss:0.00021, loss_test:0.11737, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:30.143, tt:542.572\n",
      "Ep:18, loss:0.00020, loss_test:0.11493, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:30.286, tt:575.433\n",
      "Ep:19, loss:0.00020, loss_test:0.11242, lr:1.00e-02, fs:0.67841 (r=0.778,p=0.602),  time:30.271, tt:605.423\n",
      "Ep:20, loss:0.00019, loss_test:0.11029, lr:9.90e-03, fs:0.68161 (r=0.768,p=0.613),  time:30.394, tt:638.272\n",
      "Ep:21, loss:0.00019, loss_test:0.10847, lr:9.80e-03, fs:0.68837 (r=0.747,p=0.638),  time:30.436, tt:669.596\n",
      "Ep:22, loss:0.00018, loss_test:0.10606, lr:9.70e-03, fs:0.69767 (r=0.758,p=0.647),  time:30.487, tt:701.194\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.10547, lr:9.70e-03, fs:0.71845 (r=0.747,p=0.692),  time:30.551, tt:733.217\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.10257, lr:9.70e-03, fs:0.72464 (r=0.758,p=0.694),  time:30.632, tt:765.806\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.10199, lr:9.70e-03, fs:0.72195 (r=0.747,p=0.698),  time:30.688, tt:797.896\n",
      "Ep:26, loss:0.00016, loss_test:0.10188, lr:9.70e-03, fs:0.71845 (r=0.747,p=0.692),  time:30.752, tt:830.292\n",
      "Ep:27, loss:0.00015, loss_test:0.10103, lr:9.70e-03, fs:0.71498 (r=0.747,p=0.685),  time:30.818, tt:862.908\n",
      "Ep:28, loss:0.00014, loss_test:0.10079, lr:9.70e-03, fs:0.73430 (r=0.768,p=0.704),  time:30.864, tt:895.045\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09827, lr:9.70e-03, fs:0.73430 (r=0.768,p=0.704),  time:30.929, tt:927.863\n",
      "Ep:30, loss:0.00013, loss_test:0.09771, lr:9.70e-03, fs:0.74038 (r=0.778,p=0.706),  time:30.996, tt:960.876\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.09671, lr:9.70e-03, fs:0.76190 (r=0.808,p=0.721),  time:31.021, tt:992.658\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.09820, lr:9.70e-03, fs:0.75598 (r=0.798,p=0.718),  time:31.043, tt:1024.426\n",
      "Ep:33, loss:0.00012, loss_test:0.09554, lr:9.70e-03, fs:0.73239 (r=0.788,p=0.684),  time:31.101, tt:1057.435\n",
      "Ep:34, loss:0.00012, loss_test:0.09379, lr:9.70e-03, fs:0.78261 (r=0.818,p=0.750),  time:31.103, tt:1088.604\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.09323, lr:9.70e-03, fs:0.78261 (r=0.818,p=0.750),  time:31.157, tt:1121.665\n",
      "Ep:36, loss:0.00010, loss_test:0.08951, lr:9.70e-03, fs:0.77358 (r=0.828,p=0.726),  time:31.204, tt:1154.547\n",
      "Ep:37, loss:0.00010, loss_test:0.09553, lr:9.70e-03, fs:0.77885 (r=0.818,p=0.743),  time:31.245, tt:1187.301\n",
      "Ep:38, loss:0.00010, loss_test:0.08940, lr:9.70e-03, fs:0.80000 (r=0.828,p=0.774),  time:31.287, tt:1220.181\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.09057, lr:9.70e-03, fs:0.78469 (r=0.828,p=0.745),  time:31.321, tt:1252.833\n",
      "Ep:40, loss:0.00010, loss_test:0.08797, lr:9.70e-03, fs:0.80976 (r=0.838,p=0.783),  time:31.358, tt:1285.688\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.08386, lr:9.70e-03, fs:0.76636 (r=0.828,p=0.713),  time:31.346, tt:1316.531\n",
      "Ep:42, loss:0.00009, loss_test:0.08746, lr:9.70e-03, fs:0.81773 (r=0.838,p=0.798),  time:31.406, tt:1350.471\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.08507, lr:9.70e-03, fs:0.81188 (r=0.828,p=0.796),  time:31.419, tt:1382.455\n",
      "Ep:44, loss:0.00008, loss_test:0.07996, lr:9.70e-03, fs:0.81951 (r=0.848,p=0.792),  time:31.484, tt:1416.796\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.08502, lr:9.70e-03, fs:0.84974 (r=0.828,p=0.872),  time:31.514, tt:1449.638\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.08026, lr:9.70e-03, fs:0.80383 (r=0.848,p=0.764),  time:31.523, tt:1481.576\n",
      "Ep:47, loss:0.00007, loss_test:0.08523, lr:9.70e-03, fs:0.83838 (r=0.838,p=0.838),  time:31.543, tt:1514.056\n",
      "Ep:48, loss:0.00006, loss_test:0.08106, lr:9.70e-03, fs:0.84000 (r=0.848,p=0.832),  time:31.590, tt:1547.917\n",
      "Ep:49, loss:0.00007, loss_test:0.08126, lr:9.70e-03, fs:0.82759 (r=0.848,p=0.808),  time:31.595, tt:1579.765\n",
      "Ep:50, loss:0.00007, loss_test:0.08160, lr:9.70e-03, fs:0.83417 (r=0.838,p=0.830),  time:31.612, tt:1612.203\n",
      "Ep:51, loss:0.00006, loss_test:0.08228, lr:9.70e-03, fs:0.85279 (r=0.848,p=0.857),  time:31.614, tt:1643.952\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.07888, lr:9.70e-03, fs:0.82178 (r=0.838,p=0.806),  time:31.648, tt:1677.319\n",
      "Ep:53, loss:0.00005, loss_test:0.08386, lr:9.70e-03, fs:0.83582 (r=0.848,p=0.824),  time:31.668, tt:1710.073\n",
      "Ep:54, loss:0.00006, loss_test:0.08056, lr:9.70e-03, fs:0.83168 (r=0.848,p=0.816),  time:31.699, tt:1743.444\n",
      "Ep:55, loss:0.00005, loss_test:0.07800, lr:9.70e-03, fs:0.84422 (r=0.848,p=0.840),  time:31.708, tt:1775.622\n",
      "Ep:56, loss:0.00005, loss_test:0.07727, lr:9.70e-03, fs:0.83582 (r=0.848,p=0.824),  time:31.735, tt:1808.896\n",
      "Ep:57, loss:0.00005, loss_test:0.08418, lr:9.70e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.744, tt:1841.145\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.07771, lr:9.70e-03, fs:0.83582 (r=0.848,p=0.824),  time:31.756, tt:1873.591\n",
      "Ep:59, loss:0.00005, loss_test:0.07841, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.777, tt:1906.632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.08080, lr:9.70e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.798, tt:1939.684\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.07809, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.824, tt:1973.087\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.07506, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.825, tt:2005.000\n",
      "Ep:63, loss:0.00004, loss_test:0.07625, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.824, tt:2036.756\n",
      "Ep:64, loss:0.00004, loss_test:0.08867, lr:9.70e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.833, tt:2069.153\n",
      "Ep:65, loss:0.00004, loss_test:0.07519, lr:9.70e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.827, tt:2100.561\n",
      "Ep:66, loss:0.00003, loss_test:0.08002, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.838, tt:2133.161\n",
      "Ep:67, loss:0.00003, loss_test:0.07445, lr:9.70e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.840, tt:2165.130\n",
      "Ep:68, loss:0.00003, loss_test:0.08153, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.836, tt:2196.666\n",
      "Ep:69, loss:0.00003, loss_test:0.07704, lr:9.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:31.834, tt:2228.364\n",
      "Ep:70, loss:0.00003, loss_test:0.07818, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.858, tt:2261.939\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.07914, lr:9.70e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.861, tt:2293.983\n",
      "Ep:72, loss:0.00002, loss_test:0.07982, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.863, tt:2325.997\n",
      "Ep:73, loss:0.00002, loss_test:0.07850, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.841, tt:2356.249\n",
      "Ep:74, loss:0.00003, loss_test:0.07732, lr:9.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:31.864, tt:2389.822\n",
      "Ep:75, loss:0.00002, loss_test:0.07858, lr:9.70e-03, fs:0.86154 (r=0.848,p=0.875),  time:31.855, tt:2420.997\n",
      "Ep:76, loss:0.00003, loss_test:0.08138, lr:9.70e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.831, tt:2451.013\n",
      "Ep:77, loss:0.00003, loss_test:0.07621, lr:9.70e-03, fs:0.87047 (r=0.848,p=0.894),  time:31.824, tt:2482.236\n",
      "Ep:78, loss:0.00003, loss_test:0.08235, lr:9.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.808, tt:2512.794\n",
      "Ep:79, loss:0.00003, loss_test:0.07990, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.809, tt:2544.752\n",
      "Ep:80, loss:0.00003, loss_test:0.07888, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.804, tt:2576.156\n",
      "Ep:81, loss:0.00002, loss_test:0.08445, lr:9.70e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.796, tt:2607.257\n",
      "Ep:82, loss:0.00003, loss_test:0.07473, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.778, tt:2637.545\n",
      "Ep:83, loss:0.00003, loss_test:0.07954, lr:9.51e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.776, tt:2669.143\n",
      "Ep:84, loss:0.00003, loss_test:0.07953, lr:9.41e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.793, tt:2702.432\n",
      "Ep:85, loss:0.00003, loss_test:0.07545, lr:9.32e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.800, tt:2734.798\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.08536, lr:9.32e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.807, tt:2767.186\n",
      "Ep:87, loss:0.00003, loss_test:0.07435, lr:9.32e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.795, tt:2797.978\n",
      "Ep:88, loss:0.00002, loss_test:0.07788, lr:9.32e-03, fs:0.86598 (r=0.848,p=0.884),  time:31.792, tt:2829.494\n",
      "Ep:89, loss:0.00002, loss_test:0.07627, lr:9.32e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.805, tt:2862.462\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00002, loss_test:0.07569, lr:9.32e-03, fs:0.88421 (r=0.848,p=0.923),  time:31.816, tt:2895.240\n",
      "Ep:91, loss:0.00002, loss_test:0.07669, lr:9.32e-03, fs:0.87958 (r=0.848,p=0.913),  time:31.834, tt:2928.756\n",
      "Ep:92, loss:0.00002, loss_test:0.08180, lr:9.32e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.875, tt:2964.352\n",
      "Ep:93, loss:0.00002, loss_test:0.07538, lr:9.32e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.909, tt:2999.470\n",
      "Ep:94, loss:0.00002, loss_test:0.08164, lr:9.32e-03, fs:0.87097 (r=0.818,p=0.931),  time:31.958, tt:3035.989\n",
      "Ep:95, loss:0.00002, loss_test:0.08115, lr:9.32e-03, fs:0.86631 (r=0.818,p=0.920),  time:31.975, tt:3069.606\n",
      "Ep:96, loss:0.00001, loss_test:0.07981, lr:9.32e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.000, tt:3103.964\n",
      "Ep:97, loss:0.00001, loss_test:0.07850, lr:9.32e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.067, tt:3142.589\n",
      "Ep:98, loss:0.00001, loss_test:0.08181, lr:9.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.094, tt:3177.294\n",
      "Ep:99, loss:0.00001, loss_test:0.08164, lr:9.32e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.132, tt:3213.163\n",
      "Ep:100, loss:0.00001, loss_test:0.07697, lr:9.32e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.162, tt:3248.358\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.08040, lr:9.32e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.193, tt:3283.638\n",
      "Ep:102, loss:0.00001, loss_test:0.08159, lr:9.32e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.221, tt:3318.782\n",
      "Ep:103, loss:0.00001, loss_test:0.08165, lr:9.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.263, tt:3355.393\n",
      "Ep:104, loss:0.00001, loss_test:0.07840, lr:9.32e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.287, tt:3390.093\n",
      "Ep:105, loss:0.00001, loss_test:0.08202, lr:9.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.321, tt:3426.020\n",
      "Ep:106, loss:0.00001, loss_test:0.08249, lr:9.32e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.349, tt:3461.327\n",
      "Ep:107, loss:0.00001, loss_test:0.08226, lr:9.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:32.374, tt:3496.442\n",
      "Ep:108, loss:0.00001, loss_test:0.08036, lr:9.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.387, tt:3530.194\n",
      "Ep:109, loss:0.00001, loss_test:0.07938, lr:9.32e-03, fs:0.84946 (r=0.798,p=0.908),  time:32.401, tt:3564.067\n",
      "Ep:110, loss:0.00001, loss_test:0.07936, lr:9.32e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.413, tt:3597.861\n",
      "Ep:111, loss:0.00001, loss_test:0.08211, lr:9.32e-03, fs:0.84783 (r=0.788,p=0.918),  time:32.439, tt:3633.217\n",
      "Ep:112, loss:0.00001, loss_test:0.07967, lr:9.23e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.472, tt:3669.339\n",
      "Ep:113, loss:0.00001, loss_test:0.08418, lr:9.14e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.508, tt:3705.909\n",
      "Ep:114, loss:0.00001, loss_test:0.08131, lr:9.04e-03, fs:0.83978 (r=0.768,p=0.927),  time:32.534, tt:3741.398\n",
      "Ep:115, loss:0.00001, loss_test:0.08554, lr:8.95e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.568, tt:3777.901\n",
      "Ep:116, loss:0.00001, loss_test:0.07973, lr:8.86e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.609, tt:3815.291\n",
      "Ep:117, loss:0.00001, loss_test:0.08520, lr:8.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.640, tt:3851.481\n",
      "Ep:118, loss:0.00001, loss_test:0.08064, lr:8.69e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.662, tt:3886.835\n",
      "Ep:119, loss:0.00001, loss_test:0.08402, lr:8.60e-03, fs:0.82486 (r=0.737,p=0.936),  time:32.697, tt:3923.683\n",
      "Ep:120, loss:0.00001, loss_test:0.08664, lr:8.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.717, tt:3958.747\n",
      "Ep:121, loss:0.00001, loss_test:0.08298, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.742, tt:3994.518\n",
      "Ep:122, loss:0.00001, loss_test:0.08173, lr:8.35e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.761, tt:4029.651\n",
      "Ep:123, loss:0.00001, loss_test:0.08510, lr:8.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.794, tt:4066.416\n",
      "Ep:124, loss:0.00001, loss_test:0.08247, lr:8.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:32.812, tt:4101.493\n",
      "Ep:125, loss:0.00001, loss_test:0.08610, lr:8.10e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.843, tt:4138.181\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00001, loss_test:0.08621, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.871, tt:4174.591\n",
      "Ep:127, loss:0.00001, loss_test:0.08193, lr:8.10e-03, fs:0.83146 (r=0.747,p=0.937),  time:32.896, tt:4210.706\n",
      "Ep:128, loss:0.00001, loss_test:0.08545, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.924, tt:4247.150\n",
      "Ep:129, loss:0.00001, loss_test:0.08486, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.943, tt:4282.647\n",
      "Ep:130, loss:0.00001, loss_test:0.08757, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.963, tt:4318.204\n",
      "Ep:131, loss:0.00001, loss_test:0.08423, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:32.982, tt:4353.609\n",
      "Ep:132, loss:0.00000, loss_test:0.08549, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.003, tt:4389.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.08536, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.021, tt:4424.795\n",
      "Ep:134, loss:0.00000, loss_test:0.08465, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.048, tt:4461.491\n",
      "Ep:135, loss:0.00000, loss_test:0.08495, lr:8.10e-03, fs:0.82286 (r=0.727,p=0.947),  time:33.067, tt:4497.167\n",
      "Ep:136, loss:0.00000, loss_test:0.08531, lr:8.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.091, tt:4533.507\n",
      "Ep:137, loss:0.00000, loss_test:0.08406, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.103, tt:4568.208\n",
      "Ep:138, loss:0.00000, loss_test:0.08313, lr:7.94e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.118, tt:4603.335\n",
      "Ep:139, loss:0.00000, loss_test:0.08354, lr:7.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.147, tt:4640.592\n",
      "Ep:140, loss:0.00000, loss_test:0.08537, lr:7.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.167, tt:4676.544\n",
      "Ep:141, loss:0.00000, loss_test:0.08549, lr:7.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.199, tt:4714.325\n",
      "Ep:142, loss:0.00000, loss_test:0.08421, lr:7.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.217, tt:4749.973\n",
      "Ep:143, loss:0.00000, loss_test:0.08329, lr:7.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.241, tt:4786.707\n",
      "Ep:144, loss:0.00000, loss_test:0.08329, lr:7.47e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.265, tt:4823.360\n",
      "Ep:145, loss:0.00000, loss_test:0.08502, lr:7.40e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.285, tt:4859.540\n",
      "Ep:146, loss:0.00000, loss_test:0.08457, lr:7.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.303, tt:4895.544\n",
      "Ep:147, loss:0.00000, loss_test:0.08557, lr:7.25e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.317, tt:4930.861\n",
      "Ep:148, loss:0.00000, loss_test:0.08583, lr:7.18e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.337, tt:4967.206\n",
      "Ep:149, loss:0.00000, loss_test:0.08531, lr:7.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.357, tt:5003.529\n",
      "Ep:150, loss:0.00000, loss_test:0.08517, lr:7.03e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.372, tt:5039.193\n",
      "Ep:151, loss:0.00000, loss_test:0.08531, lr:6.96e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.393, tt:5075.664\n",
      "Ep:152, loss:0.00000, loss_test:0.08399, lr:6.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.408, tt:5111.496\n",
      "Ep:153, loss:0.00000, loss_test:0.08493, lr:6.83e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.434, tt:5148.781\n",
      "Ep:154, loss:0.00000, loss_test:0.08487, lr:6.76e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.453, tt:5185.252\n",
      "Ep:155, loss:0.00000, loss_test:0.08560, lr:6.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.462, tt:5220.127\n",
      "Ep:156, loss:0.00000, loss_test:0.08428, lr:6.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.477, tt:5255.874\n",
      "Ep:157, loss:0.00000, loss_test:0.08400, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.502, tt:5293.237\n",
      "Ep:158, loss:0.00000, loss_test:0.08601, lr:6.49e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.522, tt:5330.037\n",
      "Ep:159, loss:0.00000, loss_test:0.08404, lr:6.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.538, tt:5366.109\n",
      "Ep:160, loss:0.00000, loss_test:0.08454, lr:6.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.562, tt:5403.490\n",
      "Ep:161, loss:0.00000, loss_test:0.08485, lr:6.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.583, tt:5440.385\n",
      "Ep:162, loss:0.00000, loss_test:0.08409, lr:6.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.599, tt:5476.616\n",
      "Ep:163, loss:0.00000, loss_test:0.08457, lr:6.17e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.613, tt:5512.532\n",
      "Ep:164, loss:0.00000, loss_test:0.08407, lr:6.11e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.640, tt:5550.680\n",
      "Ep:165, loss:0.00000, loss_test:0.08471, lr:6.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.654, tt:5586.610\n",
      "Ep:166, loss:0.00000, loss_test:0.08443, lr:5.99e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.672, tt:5623.188\n",
      "Ep:167, loss:0.00000, loss_test:0.08328, lr:5.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.690, tt:5659.945\n",
      "Ep:168, loss:0.00000, loss_test:0.08495, lr:5.87e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.703, tt:5695.793\n",
      "Ep:169, loss:0.00000, loss_test:0.08585, lr:5.81e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.717, tt:5731.891\n",
      "Ep:170, loss:0.00000, loss_test:0.08529, lr:5.75e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.740, tt:5769.559\n",
      "Ep:171, loss:0.00000, loss_test:0.08434, lr:5.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.755, tt:5805.788\n",
      "Ep:172, loss:0.00000, loss_test:0.08438, lr:5.64e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.778, tt:5843.619\n",
      "Ep:173, loss:0.00000, loss_test:0.08497, lr:5.58e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.794, tt:5880.163\n",
      "Ep:174, loss:0.00000, loss_test:0.08510, lr:5.53e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.813, tt:5917.349\n",
      "Ep:175, loss:0.00000, loss_test:0.08405, lr:5.47e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.830, tt:5954.084\n",
      "Ep:176, loss:0.00000, loss_test:0.08530, lr:5.42e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.843, tt:5990.123\n",
      "Ep:177, loss:0.00000, loss_test:0.08471, lr:5.36e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.860, tt:6027.070\n",
      "Ep:178, loss:0.00000, loss_test:0.08487, lr:5.31e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.879, tt:6064.355\n",
      "Ep:179, loss:0.00000, loss_test:0.08417, lr:5.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.889, tt:6100.063\n",
      "Ep:180, loss:0.00000, loss_test:0.08423, lr:5.20e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.903, tt:6136.525\n",
      "Ep:181, loss:0.00000, loss_test:0.08374, lr:5.15e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.912, tt:6171.985\n",
      "Ep:182, loss:0.00000, loss_test:0.08409, lr:5.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.927, tt:6208.670\n",
      "Ep:183, loss:0.00000, loss_test:0.08396, lr:5.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.947, tt:6246.306\n",
      "Ep:184, loss:0.00000, loss_test:0.08358, lr:5.00e-03, fs:0.81356 (r=0.727,p=0.923),  time:33.964, tt:6283.318\n",
      "Ep:185, loss:0.00000, loss_test:0.08415, lr:4.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.979, tt:6320.044\n",
      "Ep:186, loss:0.00000, loss_test:0.08362, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:33.995, tt:6357.062\n",
      "Ep:187, loss:0.00000, loss_test:0.08405, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.005, tt:6392.986\n",
      "Ep:188, loss:0.00000, loss_test:0.08372, lr:4.80e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.015, tt:6428.910\n",
      "Ep:189, loss:0.00000, loss_test:0.08373, lr:4.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.024, tt:6464.531\n",
      "Ep:190, loss:0.00000, loss_test:0.08393, lr:4.71e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.039, tt:6501.459\n",
      "Ep:191, loss:0.00000, loss_test:0.08352, lr:4.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.054, tt:6538.422\n",
      "Ep:192, loss:0.00000, loss_test:0.08340, lr:4.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.065, tt:6574.557\n",
      "Ep:193, loss:0.00000, loss_test:0.08310, lr:4.57e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.078, tt:6611.067\n",
      "Ep:194, loss:0.00000, loss_test:0.08385, lr:4.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.092, tt:6647.961\n",
      "Ep:195, loss:0.00000, loss_test:0.08369, lr:4.48e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.113, tt:6686.229\n",
      "Ep:196, loss:0.00000, loss_test:0.08381, lr:4.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.127, tt:6723.101\n",
      "Ep:197, loss:0.00000, loss_test:0.08398, lr:4.39e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.140, tt:6759.718\n",
      "Ep:198, loss:0.00000, loss_test:0.08302, lr:4.34e-03, fs:0.81818 (r=0.727,p=0.935),  time:34.149, tt:6795.730\n",
      "Ep:199, loss:0.00000, loss_test:0.08359, lr:4.30e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.156, tt:6831.260\n",
      "Ep:200, loss:0.00000, loss_test:0.08315, lr:4.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:34.167, tt:6867.611\n",
      "Ep:201, loss:0.00000, loss_test:0.08287, lr:4.21e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.175, tt:6903.408\n",
      "Ep:202, loss:0.00000, loss_test:0.08327, lr:4.17e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.184, tt:6939.302\n",
      "Ep:203, loss:0.00000, loss_test:0.08297, lr:4.13e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.195, tt:6975.740\n",
      "Ep:204, loss:0.00000, loss_test:0.08292, lr:4.09e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.211, tt:7013.196\n",
      "Ep:205, loss:0.00000, loss_test:0.08259, lr:4.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.224, tt:7050.128\n",
      "Ep:206, loss:0.00000, loss_test:0.08253, lr:4.01e-03, fs:0.82286 (r=0.727,p=0.947),  time:34.239, tt:7087.375\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02650, lr:6.00e-02, fs:0.63478 (r=0.737,p=0.557),  time:27.448, tt:27.448\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02543, lr:6.00e-02, fs:0.64583 (r=0.939,p=0.492),  time:28.414, tt:56.829\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02724, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.505, tt:82.514\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02638, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:27.550, tt:110.201\n",
      "Ep:4, loss:0.00005, loss_test:0.02558, lr:6.00e-02, fs:0.64057 (r=0.909,p=0.495),  time:28.606, tt:143.028\n",
      "Ep:5, loss:0.00005, loss_test:0.02514, lr:6.00e-02, fs:0.64727 (r=0.899,p=0.506),  time:29.631, tt:177.786\n",
      "Ep:6, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.62963 (r=0.859,p=0.497),  time:30.547, tt:213.826\n",
      "Ep:7, loss:0.00005, loss_test:0.02473, lr:6.00e-02, fs:0.62963 (r=0.859,p=0.497),  time:31.044, tt:248.351\n",
      "Ep:8, loss:0.00005, loss_test:0.02443, lr:6.00e-02, fs:0.63971 (r=0.879,p=0.503),  time:31.616, tt:284.542\n",
      "Ep:9, loss:0.00005, loss_test:0.02422, lr:6.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:31.982, tt:319.819\n",
      "Ep:10, loss:0.00005, loss_test:0.02394, lr:6.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:32.397, tt:356.370\n",
      "Ep:11, loss:0.00005, loss_test:0.02321, lr:6.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:32.649, tt:391.786\n",
      "Ep:12, loss:0.00004, loss_test:0.02240, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:32.906, tt:427.774\n",
      "Ep:13, loss:0.00004, loss_test:0.02173, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:33.065, tt:462.908\n",
      "Ep:14, loss:0.00004, loss_test:0.02111, lr:5.94e-02, fs:0.65683 (r=0.899,p=0.517),  time:33.275, tt:499.119\n",
      "Ep:15, loss:0.00004, loss_test:0.02061, lr:5.88e-02, fs:0.66912 (r=0.919,p=0.526),  time:33.482, tt:535.717\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02002, lr:5.88e-02, fs:0.67658 (r=0.919,p=0.535),  time:33.577, tt:570.804\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01962, lr:5.88e-02, fs:0.68657 (r=0.929,p=0.544),  time:33.659, tt:605.869\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01923, lr:5.88e-02, fs:0.68939 (r=0.919,p=0.552),  time:33.837, tt:642.899\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01887, lr:5.88e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.067, tt:681.337\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01865, lr:5.88e-02, fs:0.70543 (r=0.919,p=0.572),  time:34.127, tt:716.669\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01848, lr:5.88e-02, fs:0.71042 (r=0.929,p=0.575),  time:34.192, tt:752.224\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01834, lr:5.88e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.244, tt:787.602\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01831, lr:5.88e-02, fs:0.72065 (r=0.899,p=0.601),  time:34.307, tt:823.372\n",
      "Ep:24, loss:0.00003, loss_test:0.01834, lr:5.88e-02, fs:0.71255 (r=0.889,p=0.595),  time:34.393, tt:859.821\n",
      "Ep:25, loss:0.00003, loss_test:0.01835, lr:5.88e-02, fs:0.71020 (r=0.879,p=0.596),  time:34.473, tt:896.286\n",
      "Ep:26, loss:0.00003, loss_test:0.01844, lr:5.88e-02, fs:0.70588 (r=0.848,p=0.604),  time:34.529, tt:932.292\n",
      "Ep:27, loss:0.00003, loss_test:0.01837, lr:5.88e-02, fs:0.68908 (r=0.828,p=0.590),  time:34.588, tt:968.462\n",
      "Ep:28, loss:0.00003, loss_test:0.01849, lr:5.88e-02, fs:0.69492 (r=0.828,p=0.599),  time:34.624, tt:1004.086\n",
      "Ep:29, loss:0.00003, loss_test:0.01868, lr:5.88e-02, fs:0.69492 (r=0.828,p=0.599),  time:34.666, tt:1039.974\n",
      "Ep:30, loss:0.00003, loss_test:0.01875, lr:5.88e-02, fs:0.70339 (r=0.838,p=0.606),  time:34.751, tt:1077.283\n",
      "Ep:31, loss:0.00003, loss_test:0.01879, lr:5.88e-02, fs:0.70742 (r=0.818,p=0.623),  time:34.762, tt:1112.375\n",
      "Ep:32, loss:0.00003, loss_test:0.01841, lr:5.88e-02, fs:0.70386 (r=0.828,p=0.612),  time:34.805, tt:1148.569\n",
      "Ep:33, loss:0.00002, loss_test:0.01858, lr:5.88e-02, fs:0.71681 (r=0.818,p=0.638),  time:34.877, tt:1185.833\n",
      "Ep:34, loss:0.00002, loss_test:0.01841, lr:5.82e-02, fs:0.71930 (r=0.828,p=0.636),  time:34.868, tt:1220.389\n",
      "Ep:35, loss:0.00002, loss_test:0.01835, lr:5.76e-02, fs:0.71930 (r=0.828,p=0.636),  time:34.920, tt:1257.117\n",
      "Ep:36, loss:0.00002, loss_test:0.01829, lr:5.71e-02, fs:0.71930 (r=0.828,p=0.636),  time:34.970, tt:1293.881\n",
      "Ep:37, loss:0.00002, loss_test:0.01833, lr:5.65e-02, fs:0.71749 (r=0.808,p=0.645),  time:34.991, tt:1329.669\n",
      "Ep:38, loss:0.00002, loss_test:0.01845, lr:5.59e-02, fs:0.71171 (r=0.798,p=0.642),  time:34.990, tt:1364.613\n",
      "Ep:39, loss:0.00002, loss_test:0.01840, lr:5.54e-02, fs:0.71818 (r=0.798,p=0.653),  time:34.985, tt:1399.401\n",
      "Ep:40, loss:0.00002, loss_test:0.01801, lr:5.48e-02, fs:0.71171 (r=0.798,p=0.642),  time:34.998, tt:1434.917\n",
      "Ep:41, loss:0.00002, loss_test:0.01811, lr:5.43e-02, fs:0.71493 (r=0.798,p=0.648),  time:34.978, tt:1469.090\n",
      "Ep:42, loss:0.00002, loss_test:0.01829, lr:5.37e-02, fs:0.72897 (r=0.788,p=0.678),  time:34.991, tt:1504.611\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01816, lr:5.37e-02, fs:0.72897 (r=0.788,p=0.678),  time:35.006, tt:1540.274\n",
      "Ep:44, loss:0.00002, loss_test:0.01801, lr:5.37e-02, fs:0.72558 (r=0.788,p=0.672),  time:34.995, tt:1574.762\n",
      "Ep:45, loss:0.00002, loss_test:0.01864, lr:5.37e-02, fs:0.73832 (r=0.798,p=0.687),  time:34.999, tt:1609.969\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01809, lr:5.37e-02, fs:0.73239 (r=0.788,p=0.684),  time:34.999, tt:1644.961\n",
      "Ep:47, loss:0.00002, loss_test:0.01848, lr:5.37e-02, fs:0.73239 (r=0.788,p=0.684),  time:34.989, tt:1679.456\n",
      "Ep:48, loss:0.00002, loss_test:0.01879, lr:5.37e-02, fs:0.75238 (r=0.798,p=0.712),  time:34.996, tt:1714.796\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01795, lr:5.37e-02, fs:0.73934 (r=0.788,p=0.696),  time:35.008, tt:1750.391\n",
      "Ep:50, loss:0.00002, loss_test:0.01916, lr:5.37e-02, fs:0.76190 (r=0.808,p=0.721),  time:34.988, tt:1784.381\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01899, lr:5.37e-02, fs:0.76923 (r=0.808,p=0.734),  time:34.983, tt:1819.117\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01832, lr:5.37e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.994, tt:1854.692\n",
      "Ep:53, loss:0.00001, loss_test:0.01908, lr:5.37e-02, fs:0.77295 (r=0.808,p=0.741),  time:34.951, tt:1887.338\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01875, lr:5.37e-02, fs:0.77451 (r=0.798,p=0.752),  time:34.926, tt:1920.940\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01855, lr:5.37e-02, fs:0.76471 (r=0.788,p=0.743),  time:34.896, tt:1954.168\n",
      "Ep:56, loss:0.00001, loss_test:0.02003, lr:5.37e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.877, tt:1987.987\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.02046, lr:5.37e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.872, tt:2022.598\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.02032, lr:5.37e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.917, tt:2060.111\n",
      "Ep:59, loss:0.00001, loss_test:0.01973, lr:5.37e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.910, tt:2094.573\n",
      "Ep:60, loss:0.00001, loss_test:0.01998, lr:5.37e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.910, tt:2129.512\n",
      "Ep:61, loss:0.00001, loss_test:0.02172, lr:5.37e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.908, tt:2164.316\n",
      "Ep:62, loss:0.00001, loss_test:0.02253, lr:5.37e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.901, tt:2198.791\n",
      "Ep:63, loss:0.00001, loss_test:0.02084, lr:5.37e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.913, tt:2234.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.02009, lr:5.37e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.916, tt:2269.529\n",
      "Ep:65, loss:0.00001, loss_test:0.02203, lr:5.37e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.918, tt:2304.601\n",
      "Ep:66, loss:0.00001, loss_test:0.02418, lr:5.37e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.905, tt:2338.639\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02240, lr:5.37e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.896, tt:2372.911\n",
      "Ep:68, loss:0.00001, loss_test:0.02154, lr:5.37e-02, fs:0.78392 (r=0.788,p=0.780),  time:34.908, tt:2408.671\n",
      "Ep:69, loss:0.00001, loss_test:0.02132, lr:5.37e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.907, tt:2443.464\n",
      "Ep:70, loss:0.00001, loss_test:0.02540, lr:5.37e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.899, tt:2477.819\n",
      "Ep:71, loss:0.00001, loss_test:0.02433, lr:5.37e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.901, tt:2512.889\n",
      "Ep:72, loss:0.00001, loss_test:0.02249, lr:5.37e-02, fs:0.77833 (r=0.798,p=0.760),  time:34.885, tt:2546.591\n",
      "Ep:73, loss:0.00001, loss_test:0.02786, lr:5.37e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.877, tt:2580.930\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.02625, lr:5.37e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.885, tt:2616.408\n",
      "Ep:75, loss:0.00001, loss_test:0.02310, lr:5.37e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.877, tt:2650.620\n",
      "Ep:76, loss:0.00001, loss_test:0.02331, lr:5.37e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.877, tt:2685.540\n",
      "Ep:77, loss:0.00001, loss_test:0.02539, lr:5.37e-02, fs:0.79798 (r=0.798,p=0.798),  time:34.868, tt:2719.689\n",
      "Ep:78, loss:0.00001, loss_test:0.02553, lr:5.37e-02, fs:0.78607 (r=0.798,p=0.775),  time:34.858, tt:2753.766\n",
      "Ep:79, loss:0.00001, loss_test:0.02409, lr:5.37e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.862, tt:2788.953\n",
      "Ep:80, loss:0.00001, loss_test:0.02513, lr:5.37e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.870, tt:2824.498\n",
      "Ep:81, loss:0.00001, loss_test:0.02876, lr:5.37e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.882, tt:2860.298\n",
      "Ep:82, loss:0.00001, loss_test:0.02583, lr:5.37e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.893, tt:2896.122\n",
      "Ep:83, loss:0.00001, loss_test:0.02447, lr:5.37e-02, fs:0.79381 (r=0.778,p=0.811),  time:34.895, tt:2931.155\n",
      "Ep:84, loss:0.00001, loss_test:0.02999, lr:5.37e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.894, tt:2966.014\n",
      "Ep:85, loss:0.00001, loss_test:0.02845, lr:5.32e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.884, tt:2999.995\n",
      "Ep:86, loss:0.00001, loss_test:0.02427, lr:5.27e-02, fs:0.78571 (r=0.778,p=0.794),  time:34.864, tt:3033.125\n",
      "Ep:87, loss:0.00001, loss_test:0.02955, lr:5.21e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.847, tt:3066.522\n",
      "Ep:88, loss:0.00001, loss_test:0.02563, lr:5.16e-02, fs:0.79381 (r=0.778,p=0.811),  time:34.892, tt:3105.362\n",
      "Ep:89, loss:0.00001, loss_test:0.02789, lr:5.11e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.900, tt:3140.967\n",
      "Ep:90, loss:0.00001, loss_test:0.02747, lr:5.06e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.910, tt:3176.850\n",
      "Ep:91, loss:0.00001, loss_test:0.02813, lr:5.01e-02, fs:0.79000 (r=0.798,p=0.782),  time:34.916, tt:3212.312\n",
      "Ep:92, loss:0.00001, loss_test:0.02930, lr:4.96e-02, fs:0.79397 (r=0.798,p=0.790),  time:34.946, tt:3249.960\n",
      "Ep:93, loss:0.00001, loss_test:0.02710, lr:4.91e-02, fs:0.79188 (r=0.788,p=0.796),  time:34.958, tt:3286.088\n",
      "Ep:94, loss:0.00001, loss_test:0.03158, lr:4.86e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.953, tt:3320.508\n",
      "Ep:95, loss:0.00000, loss_test:0.02910, lr:4.81e-02, fs:0.79592 (r=0.788,p=0.804),  time:34.961, tt:3356.256\n",
      "Ep:96, loss:0.00000, loss_test:0.03136, lr:4.76e-02, fs:0.80612 (r=0.798,p=0.814),  time:34.962, tt:3391.268\n",
      "Ep:97, loss:0.00000, loss_test:0.02948, lr:4.71e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.942, tt:3424.273\n",
      "Ep:98, loss:0.00000, loss_test:0.03238, lr:4.67e-02, fs:0.81865 (r=0.798,p=0.840),  time:34.939, tt:3458.927\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00000, loss_test:0.03239, lr:4.67e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.942, tt:3494.158\n",
      "Ep:100, loss:0.00000, loss_test:0.03114, lr:4.67e-02, fs:0.80208 (r=0.778,p=0.828),  time:34.953, tt:3530.262\n",
      "Ep:101, loss:0.00000, loss_test:0.03272, lr:4.67e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.955, tt:3565.421\n",
      "Ep:102, loss:0.00000, loss_test:0.03480, lr:4.67e-02, fs:0.82292 (r=0.798,p=0.849),  time:34.946, tt:3599.457\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00000, loss_test:0.03126, lr:4.67e-02, fs:0.79581 (r=0.768,p=0.826),  time:34.947, tt:3634.481\n",
      "Ep:104, loss:0.00000, loss_test:0.03320, lr:4.67e-02, fs:0.80000 (r=0.768,p=0.835),  time:34.936, tt:3668.261\n",
      "Ep:105, loss:0.00000, loss_test:0.03426, lr:4.67e-02, fs:0.81865 (r=0.798,p=0.840),  time:34.925, tt:3702.042\n",
      "Ep:106, loss:0.00000, loss_test:0.03425, lr:4.67e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.912, tt:3735.610\n",
      "Ep:107, loss:0.00000, loss_test:0.03180, lr:4.67e-02, fs:0.80423 (r=0.768,p=0.844),  time:34.899, tt:3769.117\n",
      "Ep:108, loss:0.00000, loss_test:0.03252, lr:4.67e-02, fs:0.79787 (r=0.758,p=0.843),  time:34.901, tt:3804.189\n",
      "Ep:109, loss:0.00000, loss_test:0.03743, lr:4.67e-02, fs:0.83158 (r=0.798,p=0.868),  time:34.896, tt:3838.560\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.03401, lr:4.67e-02, fs:0.82292 (r=0.798,p=0.849),  time:34.890, tt:3872.794\n",
      "Ep:111, loss:0.00000, loss_test:0.03193, lr:4.67e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.888, tt:3907.498\n",
      "Ep:112, loss:0.00000, loss_test:0.03536, lr:4.67e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.893, tt:3942.903\n",
      "Ep:113, loss:0.00000, loss_test:0.03515, lr:4.67e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.900, tt:3978.575\n",
      "Ep:114, loss:0.00000, loss_test:0.03462, lr:4.67e-02, fs:0.80645 (r=0.758,p=0.862),  time:34.903, tt:4013.815\n",
      "Ep:115, loss:0.00000, loss_test:0.03417, lr:4.67e-02, fs:0.80214 (r=0.758,p=0.852),  time:34.902, tt:4048.604\n",
      "Ep:116, loss:0.00000, loss_test:0.03691, lr:4.67e-02, fs:0.83158 (r=0.798,p=0.868),  time:34.899, tt:4083.190\n",
      "Ep:117, loss:0.00000, loss_test:0.03690, lr:4.67e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.894, tt:4117.546\n",
      "Ep:118, loss:0.00000, loss_test:0.03368, lr:4.67e-02, fs:0.80645 (r=0.758,p=0.862),  time:34.883, tt:4151.052\n",
      "Ep:119, loss:0.00000, loss_test:0.03496, lr:4.67e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.886, tt:4186.267\n",
      "Ep:120, loss:0.00000, loss_test:0.03750, lr:4.67e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.876, tt:4219.971\n",
      "Ep:121, loss:0.00000, loss_test:0.03708, lr:4.62e-02, fs:0.81481 (r=0.778,p=0.856),  time:34.870, tt:4254.081\n",
      "Ep:122, loss:0.00000, loss_test:0.03594, lr:4.57e-02, fs:0.80000 (r=0.747,p=0.860),  time:34.881, tt:4290.400\n",
      "Ep:123, loss:0.00000, loss_test:0.03439, lr:4.53e-02, fs:0.80435 (r=0.747,p=0.871),  time:34.871, tt:4323.990\n",
      "Ep:124, loss:0.00000, loss_test:0.03833, lr:4.48e-02, fs:0.81283 (r=0.768,p=0.864),  time:34.861, tt:4357.641\n",
      "Ep:125, loss:0.00000, loss_test:0.03769, lr:4.44e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.860, tt:4392.378\n",
      "Ep:126, loss:0.00000, loss_test:0.03614, lr:4.39e-02, fs:0.80874 (r=0.747,p=0.881),  time:34.853, tt:4426.317\n",
      "Ep:127, loss:0.00000, loss_test:0.03521, lr:4.35e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.846, tt:4460.332\n",
      "Ep:128, loss:0.00000, loss_test:0.03791, lr:4.31e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.830, tt:4493.038\n",
      "Ep:129, loss:0.00000, loss_test:0.03863, lr:4.26e-02, fs:0.81522 (r=0.758,p=0.882),  time:34.828, tt:4527.611\n",
      "Ep:130, loss:0.00000, loss_test:0.03542, lr:4.22e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.833, tt:4563.092\n",
      "Ep:131, loss:0.00000, loss_test:0.03679, lr:4.18e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.829, tt:4597.491\n",
      "Ep:132, loss:0.00000, loss_test:0.03788, lr:4.14e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.833, tt:4632.751\n",
      "Ep:133, loss:0.00000, loss_test:0.03795, lr:4.10e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.825, tt:4666.561\n",
      "Ep:134, loss:0.00000, loss_test:0.03865, lr:4.05e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.815, tt:4699.971\n",
      "Ep:135, loss:0.00000, loss_test:0.03717, lr:4.01e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.810, tt:4734.116\n",
      "Ep:136, loss:0.00000, loss_test:0.03810, lr:3.97e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.817, tt:4769.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.03926, lr:3.93e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.834, tt:4807.073\n",
      "Ep:138, loss:0.00000, loss_test:0.03926, lr:3.89e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.838, tt:4842.532\n",
      "Ep:139, loss:0.00000, loss_test:0.03777, lr:3.86e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.836, tt:4877.090\n",
      "Ep:140, loss:0.00000, loss_test:0.03751, lr:3.82e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.847, tt:4913.358\n",
      "Ep:141, loss:0.00000, loss_test:0.04016, lr:3.78e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.856, tt:4949.510\n",
      "Ep:142, loss:0.00000, loss_test:0.03834, lr:3.74e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.863, tt:4985.338\n",
      "Ep:143, loss:0.00000, loss_test:0.03983, lr:3.70e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.866, tt:5020.714\n",
      "Ep:144, loss:0.00000, loss_test:0.03966, lr:3.67e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.875, tt:5056.902\n",
      "Ep:145, loss:0.00000, loss_test:0.03893, lr:3.63e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.882, tt:5092.810\n",
      "Ep:146, loss:0.00000, loss_test:0.03981, lr:3.59e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.884, tt:5127.911\n",
      "Ep:147, loss:0.00000, loss_test:0.03976, lr:3.56e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.884, tt:5162.781\n",
      "Ep:148, loss:0.00000, loss_test:0.04187, lr:3.52e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.882, tt:5197.453\n",
      "Ep:149, loss:0.00000, loss_test:0.03917, lr:3.49e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.870, tt:5230.553\n",
      "Ep:150, loss:0.00000, loss_test:0.03972, lr:3.45e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.864, tt:5264.496\n",
      "Ep:151, loss:0.00000, loss_test:0.04066, lr:3.42e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.864, tt:5299.396\n",
      "Ep:152, loss:0.00000, loss_test:0.04032, lr:3.38e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.861, tt:5333.802\n",
      "Ep:153, loss:0.00000, loss_test:0.04003, lr:3.35e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.862, tt:5368.807\n",
      "Ep:154, loss:0.00000, loss_test:0.04107, lr:3.32e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.866, tt:5404.166\n",
      "Ep:155, loss:0.00000, loss_test:0.04297, lr:3.28e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.857, tt:5437.745\n",
      "Ep:156, loss:0.00000, loss_test:0.03950, lr:3.25e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.855, tt:5472.212\n",
      "Ep:157, loss:0.00000, loss_test:0.04111, lr:3.22e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.866, tt:5508.760\n",
      "Ep:158, loss:0.00000, loss_test:0.04117, lr:3.19e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.865, tt:5543.520\n",
      "Ep:159, loss:0.00000, loss_test:0.04124, lr:3.15e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.866, tt:5578.565\n",
      "Ep:160, loss:0.00000, loss_test:0.04138, lr:3.12e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.873, tt:5614.624\n",
      "Ep:161, loss:0.00000, loss_test:0.04067, lr:3.09e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.874, tt:5649.521\n",
      "Ep:162, loss:0.00000, loss_test:0.04146, lr:3.06e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.882, tt:5685.806\n",
      "Ep:163, loss:0.00000, loss_test:0.04270, lr:3.03e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.890, tt:5721.978\n",
      "Ep:164, loss:0.00000, loss_test:0.04134, lr:3.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.887, tt:5756.285\n",
      "Ep:165, loss:0.00000, loss_test:0.04122, lr:2.97e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.886, tt:5791.115\n",
      "Ep:166, loss:0.00000, loss_test:0.04341, lr:2.94e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.891, tt:5826.829\n",
      "Ep:167, loss:0.00000, loss_test:0.04118, lr:2.91e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.897, tt:5862.756\n",
      "Ep:168, loss:0.00000, loss_test:0.04229, lr:2.88e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.903, tt:5898.640\n",
      "Ep:169, loss:0.00000, loss_test:0.04258, lr:2.85e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.915, tt:5935.520\n",
      "Ep:170, loss:0.00000, loss_test:0.04189, lr:2.82e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.918, tt:5970.920\n",
      "Ep:171, loss:0.00000, loss_test:0.04212, lr:2.80e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.921, tt:6006.481\n",
      "Ep:172, loss:0.00000, loss_test:0.04325, lr:2.77e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.924, tt:6041.870\n",
      "Ep:173, loss:0.00000, loss_test:0.04198, lr:2.74e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.931, tt:6077.933\n",
      "Ep:174, loss:0.00000, loss_test:0.04264, lr:2.71e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.934, tt:6113.420\n",
      "Ep:175, loss:0.00000, loss_test:0.04305, lr:2.69e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.938, tt:6149.174\n",
      "Ep:176, loss:0.00000, loss_test:0.04279, lr:2.66e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.943, tt:6184.908\n",
      "Ep:177, loss:0.00000, loss_test:0.04345, lr:2.63e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.944, tt:6220.025\n",
      "Ep:178, loss:0.00000, loss_test:0.04329, lr:2.61e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.943, tt:6254.755\n",
      "Ep:179, loss:0.00000, loss_test:0.04244, lr:2.58e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.949, tt:6290.880\n",
      "Ep:180, loss:0.00000, loss_test:0.04343, lr:2.55e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.954, tt:6326.692\n",
      "Ep:181, loss:0.00000, loss_test:0.04276, lr:2.53e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.967, tt:6364.011\n",
      "Ep:182, loss:0.00000, loss_test:0.04341, lr:2.50e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.956, tt:6397.035\n",
      "Ep:183, loss:0.00000, loss_test:0.04389, lr:2.48e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.965, tt:6433.476\n",
      "Ep:184, loss:0.00000, loss_test:0.04281, lr:2.45e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.963, tt:6468.087\n",
      "Ep:185, loss:0.00000, loss_test:0.04432, lr:2.43e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.965, tt:6503.504\n",
      "Ep:186, loss:0.00000, loss_test:0.04275, lr:2.40e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.965, tt:6538.404\n",
      "Ep:187, loss:0.00000, loss_test:0.04361, lr:2.38e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.967, tt:6573.825\n",
      "Ep:188, loss:0.00000, loss_test:0.04343, lr:2.36e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.974, tt:6610.079\n",
      "Ep:189, loss:0.00000, loss_test:0.04303, lr:2.33e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.978, tt:6645.849\n",
      "Ep:190, loss:0.00000, loss_test:0.04405, lr:2.31e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.981, tt:6681.409\n",
      "Ep:191, loss:0.00000, loss_test:0.04333, lr:2.29e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.987, tt:6717.433\n",
      "Ep:192, loss:0.00000, loss_test:0.04387, lr:2.26e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.983, tt:6751.712\n",
      "Ep:193, loss:0.00000, loss_test:0.04376, lr:2.24e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.979, tt:6785.910\n",
      "Ep:194, loss:0.00000, loss_test:0.04388, lr:2.22e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.977, tt:6820.542\n",
      "Ep:195, loss:0.00000, loss_test:0.04385, lr:2.20e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.975, tt:6855.166\n",
      "Ep:196, loss:0.00000, loss_test:0.04397, lr:2.17e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.971, tt:6889.382\n",
      "Ep:197, loss:0.00000, loss_test:0.04430, lr:2.15e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.968, tt:6923.611\n",
      "Ep:198, loss:0.00000, loss_test:0.04370, lr:2.13e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.966, tt:6958.299\n",
      "Ep:199, loss:0.00000, loss_test:0.04468, lr:2.11e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.962, tt:6992.317\n",
      "Ep:200, loss:0.00000, loss_test:0.04333, lr:2.09e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.961, tt:7027.119\n",
      "Ep:201, loss:0.00000, loss_test:0.04452, lr:2.07e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.979, tt:7065.691\n",
      "Ep:202, loss:0.00000, loss_test:0.04385, lr:2.05e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.977, tt:7100.287\n",
      "Ep:203, loss:0.00000, loss_test:0.04430, lr:2.03e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.983, tt:7136.432\n",
      "Ep:204, loss:0.00000, loss_test:0.04424, lr:2.01e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.986, tt:7172.136\n",
      "Ep:205, loss:0.00000, loss_test:0.04424, lr:1.99e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.988, tt:7207.578\n",
      "Ep:206, loss:0.00000, loss_test:0.04464, lr:1.97e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.991, tt:7243.067\n",
      "Ep:207, loss:0.00000, loss_test:0.04390, lr:1.95e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.987, tt:7277.279\n",
      "Ep:208, loss:0.00000, loss_test:0.04492, lr:1.93e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.991, tt:7313.199\n",
      "Ep:209, loss:0.00000, loss_test:0.04369, lr:1.91e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.995, tt:7349.043\n",
      "Ep:210, loss:0.00000, loss_test:0.04494, lr:1.89e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.992, tt:7383.209\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00026, loss_test:0.13217, lr:1.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:28.248, tt:28.248\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13092, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:29.894, tt:59.787\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12987, lr:1.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:30.069, tt:90.208\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12936, lr:1.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:30.479, tt:121.916\n",
      "Ep:4, loss:0.00026, loss_test:0.12923, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:31.649, tt:158.244\n",
      "Ep:5, loss:0.00025, loss_test:0.12897, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:32.515, tt:195.093\n",
      "Ep:6, loss:0.00025, loss_test:0.12862, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:32.903, tt:230.318\n",
      "Ep:7, loss:0.00025, loss_test:0.12821, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:33.546, tt:268.364\n",
      "Ep:8, loss:0.00025, loss_test:0.12725, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:33.769, tt:303.922\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12639, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:34.314, tt:343.139\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.12542, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:34.515, tt:379.667\n",
      "Ep:11, loss:0.00024, loss_test:0.12497, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:34.592, tt:415.105\n",
      "Ep:12, loss:0.00024, loss_test:0.12390, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:34.608, tt:449.905\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.12215, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:34.734, tt:486.276\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.12071, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:34.838, tt:522.568\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.11947, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:34.957, tt:559.305\n",
      "Ep:16, loss:0.00023, loss_test:0.11661, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:34.989, tt:594.813\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.11524, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:35.002, tt:630.041\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.11352, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:35.060, tt:666.142\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.11047, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:35.074, tt:701.486\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10853, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:35.072, tt:736.502\n",
      "Ep:21, loss:0.00020, loss_test:0.10623, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:35.020, tt:770.431\n",
      "Ep:22, loss:0.00019, loss_test:0.10380, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:35.054, tt:806.235\n",
      "Ep:23, loss:0.00018, loss_test:0.10373, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:35.067, tt:841.618\n",
      "Ep:24, loss:0.00018, loss_test:0.10089, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:35.087, tt:877.183\n",
      "Ep:25, loss:0.00017, loss_test:0.10110, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:35.128, tt:913.315\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.10056, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:35.122, tt:948.302\n",
      "Ep:27, loss:0.00016, loss_test:0.09937, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:35.185, tt:985.194\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00015, loss_test:0.09790, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:35.189, tt:1020.482\n",
      "Ep:29, loss:0.00015, loss_test:0.09470, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:35.230, tt:1056.898\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09551, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:35.240, tt:1092.455\n",
      "Ep:31, loss:0.00014, loss_test:0.08938, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:35.265, tt:1128.493\n",
      "Ep:32, loss:0.00013, loss_test:0.09416, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:35.304, tt:1165.033\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08590, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.380, tt:1202.920\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.09017, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.455, tt:1240.916\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08541, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:35.478, tt:1277.197\n",
      "Ep:36, loss:0.00012, loss_test:0.08726, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.500, tt:1313.489\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.08683, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:35.522, tt:1349.836\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08108, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:35.565, tt:1387.036\n",
      "Ep:39, loss:0.00010, loss_test:0.08069, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:35.558, tt:1422.305\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08943, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:35.563, tt:1458.099\n",
      "Ep:41, loss:0.00010, loss_test:0.08745, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.543, tt:1492.799\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08296, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:35.558, tt:1529.001\n",
      "Ep:43, loss:0.00009, loss_test:0.09173, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:35.566, tt:1564.914\n",
      "Ep:44, loss:0.00010, loss_test:0.08213, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:35.589, tt:1601.502\n",
      "Ep:45, loss:0.00009, loss_test:0.08088, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:35.596, tt:1637.431\n",
      "Ep:46, loss:0.00008, loss_test:0.08687, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.631, tt:1674.680\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07364, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:35.604, tt:1708.992\n",
      "Ep:48, loss:0.00008, loss_test:0.08454, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.635, tt:1746.122\n",
      "Ep:49, loss:0.00008, loss_test:0.08377, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:35.651, tt:1782.539\n",
      "Ep:50, loss:0.00007, loss_test:0.07767, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:35.653, tt:1818.321\n",
      "Ep:51, loss:0.00007, loss_test:0.07973, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.657, tt:1854.146\n",
      "Ep:52, loss:0.00007, loss_test:0.06767, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.661, tt:1890.021\n",
      "Ep:53, loss:0.00008, loss_test:0.08458, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:35.695, tt:1927.505\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.08019, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:35.721, tt:1964.634\n",
      "Ep:55, loss:0.00006, loss_test:0.07673, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:35.709, tt:1999.698\n",
      "Ep:56, loss:0.00007, loss_test:0.06957, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:35.728, tt:2036.520\n",
      "Ep:57, loss:0.00006, loss_test:0.10515, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.738, tt:2072.799\n",
      "Ep:58, loss:0.00007, loss_test:0.07609, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.747, tt:2109.063\n",
      "Ep:59, loss:0.00006, loss_test:0.07252, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.763, tt:2145.772\n",
      "Ep:60, loss:0.00006, loss_test:0.08332, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:35.768, tt:2181.839\n",
      "Ep:61, loss:0.00005, loss_test:0.07414, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:35.765, tt:2217.409\n",
      "Ep:62, loss:0.00006, loss_test:0.07618, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.760, tt:2252.898\n",
      "Ep:63, loss:0.00006, loss_test:0.06673, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:35.750, tt:2288.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00005, loss_test:0.09449, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:35.730, tt:2322.428\n",
      "Ep:65, loss:0.00005, loss_test:0.07361, lr:9.90e-03, fs:0.81443 (r=0.798,p=0.832),  time:35.725, tt:2357.852\n",
      "Ep:66, loss:0.00005, loss_test:0.08096, lr:9.80e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.743, tt:2394.758\n",
      "Ep:67, loss:0.00004, loss_test:0.08783, lr:9.70e-03, fs:0.81081 (r=0.758,p=0.872),  time:35.758, tt:2431.511\n",
      "Ep:68, loss:0.00004, loss_test:0.08130, lr:9.61e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.765, tt:2467.791\n",
      "Ep:69, loss:0.00004, loss_test:0.07091, lr:9.51e-03, fs:0.79558 (r=0.727,p=0.878),  time:35.755, tt:2502.879\n",
      "Ep:70, loss:0.00004, loss_test:0.07208, lr:9.41e-03, fs:0.82162 (r=0.768,p=0.884),  time:35.727, tt:2536.636\n",
      "Ep:71, loss:0.00004, loss_test:0.07123, lr:9.32e-03, fs:0.80000 (r=0.727,p=0.889),  time:35.731, tt:2572.604\n",
      "Ep:72, loss:0.00004, loss_test:0.09444, lr:9.23e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.750, tt:2609.728\n",
      "Ep:73, loss:0.00004, loss_test:0.09438, lr:9.14e-03, fs:0.81720 (r=0.768,p=0.874),  time:35.763, tt:2646.456\n",
      "Ep:74, loss:0.00004, loss_test:0.06792, lr:9.04e-03, fs:0.79121 (r=0.727,p=0.867),  time:35.764, tt:2682.262\n",
      "Ep:75, loss:0.00004, loss_test:0.09681, lr:8.95e-03, fs:0.82873 (r=0.758,p=0.915),  time:35.779, tt:2719.184\n",
      "Ep:76, loss:0.00004, loss_test:0.07436, lr:8.86e-03, fs:0.79781 (r=0.737,p=0.869),  time:35.779, tt:2755.008\n",
      "Ep:77, loss:0.00004, loss_test:0.07954, lr:8.78e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.774, tt:2790.391\n",
      "Ep:78, loss:0.00003, loss_test:0.08727, lr:8.69e-03, fs:0.81915 (r=0.778,p=0.865),  time:35.771, tt:2825.947\n",
      "Ep:79, loss:0.00004, loss_test:0.08294, lr:8.60e-03, fs:0.80000 (r=0.727,p=0.889),  time:35.769, tt:2861.559\n",
      "Ep:80, loss:0.00003, loss_test:0.07771, lr:8.51e-03, fs:0.81720 (r=0.768,p=0.874),  time:35.776, tt:2897.855\n",
      "Ep:81, loss:0.00003, loss_test:0.08233, lr:8.43e-03, fs:0.79121 (r=0.727,p=0.867),  time:35.773, tt:2933.347\n",
      "Ep:82, loss:0.00003, loss_test:0.07514, lr:8.35e-03, fs:0.82796 (r=0.778,p=0.885),  time:35.806, tt:2971.886\n",
      "Ep:83, loss:0.00003, loss_test:0.06979, lr:8.26e-03, fs:0.80000 (r=0.727,p=0.889),  time:35.807, tt:3007.793\n",
      "Ep:84, loss:0.00003, loss_test:0.09259, lr:8.18e-03, fs:0.80663 (r=0.737,p=0.890),  time:35.814, tt:3044.179\n",
      "Ep:85, loss:0.00003, loss_test:0.06550, lr:8.10e-03, fs:0.80663 (r=0.737,p=0.890),  time:35.820, tt:3080.479\n",
      "Ep:86, loss:0.00003, loss_test:0.08647, lr:8.02e-03, fs:0.83243 (r=0.778,p=0.895),  time:35.814, tt:3115.778\n",
      "Ep:87, loss:0.00003, loss_test:0.07273, lr:7.94e-03, fs:0.80000 (r=0.727,p=0.889),  time:35.823, tt:3152.398\n",
      "Ep:88, loss:0.00003, loss_test:0.07599, lr:7.86e-03, fs:0.80663 (r=0.737,p=0.890),  time:35.823, tt:3188.229\n",
      "Ep:89, loss:0.00002, loss_test:0.08228, lr:7.78e-03, fs:0.80220 (r=0.737,p=0.880),  time:35.819, tt:3223.705\n",
      "Ep:90, loss:0.00002, loss_test:0.07371, lr:7.70e-03, fs:0.81111 (r=0.737,p=0.901),  time:35.800, tt:3257.783\n",
      "Ep:91, loss:0.00002, loss_test:0.07713, lr:7.62e-03, fs:0.80000 (r=0.727,p=0.889),  time:35.789, tt:3292.624\n",
      "Ep:92, loss:0.00002, loss_test:0.07786, lr:7.55e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.780, tt:3327.527\n",
      "Ep:93, loss:0.00002, loss_test:0.08325, lr:7.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.769, tt:3362.279\n",
      "Ep:94, loss:0.00002, loss_test:0.07269, lr:7.40e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.774, tt:3398.484\n",
      "Ep:95, loss:0.00002, loss_test:0.07917, lr:7.32e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.776, tt:3434.530\n",
      "Ep:96, loss:0.00002, loss_test:0.07462, lr:7.25e-03, fs:0.80899 (r=0.727,p=0.911),  time:35.798, tt:3472.438\n",
      "Ep:97, loss:0.00002, loss_test:0.07732, lr:7.18e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.791, tt:3507.541\n",
      "Ep:98, loss:0.00002, loss_test:0.07978, lr:7.11e-03, fs:0.80899 (r=0.727,p=0.911),  time:35.798, tt:3544.018\n",
      "Ep:99, loss:0.00002, loss_test:0.08122, lr:7.03e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.789, tt:3578.947\n",
      "Ep:100, loss:0.00002, loss_test:0.07619, lr:6.96e-03, fs:0.80899 (r=0.727,p=0.911),  time:35.790, tt:3614.813\n",
      "Ep:101, loss:0.00002, loss_test:0.08136, lr:6.89e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.786, tt:3650.154\n",
      "Ep:102, loss:0.00002, loss_test:0.09612, lr:6.83e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.782, tt:3685.546\n",
      "Ep:103, loss:0.00002, loss_test:0.07095, lr:6.76e-03, fs:0.81356 (r=0.727,p=0.923),  time:35.774, tt:3720.517\n",
      "Ep:104, loss:0.00002, loss_test:0.09257, lr:6.69e-03, fs:0.82486 (r=0.737,p=0.936),  time:35.760, tt:3754.813\n",
      "Ep:105, loss:0.00002, loss_test:0.08545, lr:6.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:35.762, tt:3790.797\n",
      "Ep:106, loss:0.00002, loss_test:0.08880, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.756, tt:3825.914\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.08782, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.746, tt:3860.610\n",
      "Ep:108, loss:0.00002, loss_test:0.07468, lr:6.56e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.728, tt:3894.308\n",
      "Ep:109, loss:0.00002, loss_test:0.09456, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.724, tt:3929.691\n",
      "Ep:110, loss:0.00002, loss_test:0.09013, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.717, tt:3964.630\n",
      "Ep:111, loss:0.00002, loss_test:0.06810, lr:6.56e-03, fs:0.80899 (r=0.727,p=0.911),  time:35.729, tt:4001.609\n",
      "Ep:112, loss:0.00002, loss_test:0.10283, lr:6.56e-03, fs:0.79070 (r=0.687,p=0.932),  time:35.741, tt:4038.704\n",
      "Ep:113, loss:0.00002, loss_test:0.07664, lr:6.56e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.750, tt:4075.467\n",
      "Ep:114, loss:0.00002, loss_test:0.09276, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.754, tt:4111.715\n",
      "Ep:115, loss:0.00002, loss_test:0.09468, lr:6.56e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.757, tt:4147.764\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00002, loss_test:0.07851, lr:6.56e-03, fs:0.81356 (r=0.727,p=0.923),  time:35.749, tt:4182.654\n",
      "Ep:117, loss:0.00002, loss_test:0.10057, lr:6.56e-03, fs:0.79769 (r=0.697,p=0.932),  time:35.748, tt:4218.291\n",
      "Ep:118, loss:0.00002, loss_test:0.07993, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.746, tt:4253.762\n",
      "Ep:119, loss:0.00002, loss_test:0.09213, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.750, tt:4289.963\n",
      "Ep:120, loss:0.00002, loss_test:0.08525, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.753, tt:4326.089\n",
      "Ep:121, loss:0.00002, loss_test:0.08950, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.766, tt:4363.436\n",
      "Ep:122, loss:0.00001, loss_test:0.09094, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.772, tt:4400.010\n",
      "Ep:123, loss:0.00001, loss_test:0.09144, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.769, tt:4435.342\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.09025, lr:6.56e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.771, tt:4471.419\n",
      "Ep:125, loss:0.00001, loss_test:0.09314, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.770, tt:4507.065\n",
      "Ep:126, loss:0.00001, loss_test:0.08746, lr:6.56e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.765, tt:4542.137\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.09351, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.769, tt:4578.480\n",
      "Ep:128, loss:0.00001, loss_test:0.09978, lr:6.56e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.776, tt:4615.067\n",
      "Ep:129, loss:0.00001, loss_test:0.09782, lr:6.56e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.771, tt:4650.167\n",
      "Ep:130, loss:0.00001, loss_test:0.09594, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.773, tt:4686.266\n",
      "Ep:131, loss:0.00001, loss_test:0.09590, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.781, tt:4723.040\n",
      "Ep:132, loss:0.00001, loss_test:0.10147, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.779, tt:4758.624\n",
      "Ep:133, loss:0.00001, loss_test:0.10146, lr:6.56e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.791, tt:4795.960\n",
      "Ep:134, loss:0.00001, loss_test:0.10093, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.800, tt:4833.039\n",
      "Ep:135, loss:0.00001, loss_test:0.10084, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.814, tt:4870.661\n",
      "Ep:136, loss:0.00001, loss_test:0.10843, lr:6.56e-03, fs:0.81143 (r=0.717,p=0.934),  time:35.810, tt:4905.993\n",
      "Ep:137, loss:0.00001, loss_test:0.10720, lr:6.56e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.827, tt:4944.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.09866, lr:6.49e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.831, tt:4980.467\n",
      "Ep:139, loss:0.00001, loss_test:0.09431, lr:6.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.835, tt:5016.911\n",
      "Ep:140, loss:0.00001, loss_test:0.10097, lr:6.36e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.839, tt:5053.313\n",
      "Ep:141, loss:0.00001, loss_test:0.10590, lr:6.30e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.846, tt:5090.194\n",
      "Ep:142, loss:0.00001, loss_test:0.10852, lr:6.24e-03, fs:0.77381 (r=0.657,p=0.942),  time:35.856, tt:5127.426\n",
      "Ep:143, loss:0.00001, loss_test:0.10473, lr:6.17e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.866, tt:5164.713\n",
      "Ep:144, loss:0.00001, loss_test:0.09706, lr:6.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:35.868, tt:5200.908\n",
      "Ep:145, loss:0.00001, loss_test:0.09847, lr:6.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:35.887, tt:5239.442\n",
      "Ep:146, loss:0.00001, loss_test:0.11380, lr:5.99e-03, fs:0.75610 (r=0.626,p=0.954),  time:35.897, tt:5276.819\n",
      "Ep:147, loss:0.00002, loss_test:0.10816, lr:5.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:35.905, tt:5313.913\n",
      "Ep:148, loss:0.00001, loss_test:0.09659, lr:5.87e-03, fs:0.80952 (r=0.687,p=0.986),  time:35.911, tt:5350.702\n",
      "Ep:149, loss:0.00001, loss_test:0.10688, lr:5.81e-03, fs:0.78363 (r=0.677,p=0.931),  time:35.917, tt:5387.559\n",
      "Ep:150, loss:0.00002, loss_test:0.09056, lr:5.75e-03, fs:0.82353 (r=0.707,p=0.986),  time:35.920, tt:5423.867\n",
      "Ep:151, loss:0.00001, loss_test:0.11519, lr:5.70e-03, fs:0.73939 (r=0.616,p=0.924),  time:35.923, tt:5460.270\n",
      "Ep:152, loss:0.00001, loss_test:0.08618, lr:5.64e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.918, tt:5495.508\n",
      "Ep:153, loss:0.00001, loss_test:0.11055, lr:5.58e-03, fs:0.79775 (r=0.717,p=0.899),  time:35.920, tt:5531.621\n",
      "Ep:154, loss:0.00001, loss_test:0.09670, lr:5.53e-03, fs:0.77844 (r=0.657,p=0.956),  time:35.925, tt:5568.397\n",
      "Ep:155, loss:0.00001, loss_test:0.11027, lr:5.47e-03, fs:0.78613 (r=0.687,p=0.919),  time:35.931, tt:5605.251\n",
      "Ep:156, loss:0.00001, loss_test:0.09963, lr:5.42e-03, fs:0.77576 (r=0.646,p=0.970),  time:35.927, tt:5640.555\n",
      "Ep:157, loss:0.00001, loss_test:0.10598, lr:5.36e-03, fs:0.78788 (r=0.657,p=0.985),  time:35.928, tt:5676.658\n",
      "Ep:158, loss:0.00001, loss_test:0.10779, lr:5.31e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.924, tt:5711.907\n",
      "Ep:159, loss:0.00001, loss_test:0.09677, lr:5.26e-03, fs:0.82955 (r=0.737,p=0.948),  time:35.925, tt:5748.017\n",
      "Ep:160, loss:0.00001, loss_test:0.11122, lr:5.20e-03, fs:0.81395 (r=0.707,p=0.959),  time:35.930, tt:5784.712\n",
      "Ep:161, loss:0.00001, loss_test:0.09874, lr:5.15e-03, fs:0.80000 (r=0.687,p=0.958),  time:35.935, tt:5821.462\n",
      "Ep:162, loss:0.00001, loss_test:0.10884, lr:5.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.932, tt:5856.857\n",
      "Ep:163, loss:0.00001, loss_test:0.10222, lr:5.05e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.930, tt:5892.569\n",
      "Ep:164, loss:0.00001, loss_test:0.10842, lr:5.00e-03, fs:0.75309 (r=0.616,p=0.968),  time:35.942, tt:5930.373\n",
      "Ep:165, loss:0.00001, loss_test:0.10172, lr:4.95e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.945, tt:5966.856\n",
      "Ep:166, loss:0.00001, loss_test:0.10634, lr:4.90e-03, fs:0.75000 (r=0.606,p=0.984),  time:35.952, tt:6003.954\n",
      "Ep:167, loss:0.00000, loss_test:0.10245, lr:4.85e-03, fs:0.76543 (r=0.626,p=0.984),  time:35.952, tt:6039.984\n",
      "Ep:168, loss:0.00000, loss_test:0.10699, lr:4.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.956, tt:6076.504\n",
      "Ep:169, loss:0.00000, loss_test:0.10079, lr:4.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.961, tt:6113.433\n",
      "Ep:170, loss:0.00000, loss_test:0.10551, lr:4.71e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.971, tt:6151.127\n",
      "Ep:171, loss:0.00000, loss_test:0.10333, lr:4.66e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.974, tt:6187.459\n",
      "Ep:172, loss:0.00000, loss_test:0.10388, lr:4.61e-03, fs:0.76074 (r=0.626,p=0.969),  time:35.971, tt:6222.940\n",
      "Ep:173, loss:0.00000, loss_test:0.10402, lr:4.57e-03, fs:0.82759 (r=0.727,p=0.960),  time:35.978, tt:6260.130\n",
      "Ep:174, loss:0.00000, loss_test:0.10237, lr:4.52e-03, fs:0.79762 (r=0.677,p=0.971),  time:35.983, tt:6297.087\n",
      "Ep:175, loss:0.00000, loss_test:0.10716, lr:4.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:35.990, tt:6334.164\n",
      "Ep:176, loss:0.00000, loss_test:0.10150, lr:4.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.997, tt:6371.427\n",
      "Ep:177, loss:0.00000, loss_test:0.10405, lr:4.39e-03, fs:0.78313 (r=0.657,p=0.970),  time:36.000, tt:6407.927\n",
      "Ep:178, loss:0.00000, loss_test:0.10528, lr:4.34e-03, fs:0.76829 (r=0.636,p=0.969),  time:36.000, tt:6443.965\n",
      "Ep:179, loss:0.00000, loss_test:0.10536, lr:4.30e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.001, tt:6480.224\n",
      "Ep:180, loss:0.00000, loss_test:0.10610, lr:4.26e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.001, tt:6516.111\n",
      "Ep:181, loss:0.00000, loss_test:0.10371, lr:4.21e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.001, tt:6552.244\n",
      "Ep:182, loss:0.00000, loss_test:0.10490, lr:4.17e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.003, tt:6588.523\n",
      "Ep:183, loss:0.00000, loss_test:0.10615, lr:4.13e-03, fs:0.77576 (r=0.646,p=0.970),  time:36.012, tt:6626.291\n",
      "Ep:184, loss:0.00000, loss_test:0.10294, lr:4.09e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.006, tt:6661.076\n",
      "Ep:185, loss:0.00000, loss_test:0.10430, lr:4.05e-03, fs:0.75309 (r=0.616,p=0.968),  time:36.003, tt:6696.623\n",
      "Ep:186, loss:0.00000, loss_test:0.10433, lr:4.01e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.004, tt:6732.790\n",
      "Ep:187, loss:0.00000, loss_test:0.10175, lr:3.97e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.013, tt:6770.438\n",
      "Ep:188, loss:0.00000, loss_test:0.10607, lr:3.93e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.039, tt:6811.439\n",
      "Ep:189, loss:0.00000, loss_test:0.10369, lr:3.89e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.038, tt:6847.277\n",
      "Ep:190, loss:0.00000, loss_test:0.10524, lr:3.85e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.040, tt:6883.680\n",
      "Ep:191, loss:0.00000, loss_test:0.10375, lr:3.81e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.046, tt:6920.828\n",
      "Ep:192, loss:0.00000, loss_test:0.10432, lr:3.77e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.045, tt:6956.690\n",
      "Ep:193, loss:0.00000, loss_test:0.10243, lr:3.73e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.046, tt:6992.916\n",
      "Ep:194, loss:0.00000, loss_test:0.10525, lr:3.70e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.049, tt:7029.538\n",
      "Ep:195, loss:0.00000, loss_test:0.10257, lr:3.66e-03, fs:0.77301 (r=0.636,p=0.984),  time:36.051, tt:7065.946\n",
      "Ep:196, loss:0.00000, loss_test:0.10415, lr:3.62e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.052, tt:7102.289\n",
      "Ep:197, loss:0.00000, loss_test:0.10273, lr:3.59e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.046, tt:7137.160\n",
      "Ep:198, loss:0.00000, loss_test:0.10553, lr:3.55e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.044, tt:7172.744\n",
      "Ep:199, loss:0.00000, loss_test:0.10228, lr:3.52e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.047, tt:7209.437\n",
      "Ep:200, loss:0.00000, loss_test:0.10884, lr:3.48e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.045, tt:7245.029\n",
      "Ep:201, loss:0.00000, loss_test:0.10117, lr:3.45e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.043, tt:7280.672\n",
      "Ep:202, loss:0.00000, loss_test:0.10407, lr:3.41e-03, fs:0.74534 (r=0.606,p=0.968),  time:36.043, tt:7316.653\n",
      "Ep:203, loss:0.00000, loss_test:0.10441, lr:3.38e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.045, tt:7353.229\n",
      "Ep:204, loss:0.00000, loss_test:0.10495, lr:3.34e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.048, tt:7389.885\n",
      "Ep:205, loss:0.00000, loss_test:0.10303, lr:3.31e-03, fs:0.75000 (r=0.606,p=0.984),  time:36.051, tt:7426.550\n",
      "Ep:206, loss:0.00000, loss_test:0.10147, lr:3.28e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.051, tt:7462.581\n",
      "Ep:207, loss:0.00000, loss_test:0.10708, lr:3.24e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.055, tt:7499.525\n",
      "Ep:208, loss:0.00000, loss_test:0.10277, lr:3.21e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.059, tt:7536.390\n",
      "Ep:209, loss:0.00000, loss_test:0.10240, lr:3.18e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.060, tt:7572.579\n",
      "Ep:210, loss:0.00000, loss_test:0.10429, lr:3.15e-03, fs:0.75472 (r=0.606,p=1.000),  time:36.056, tt:7607.917\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02410, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:24.145, tt:24.145\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02569, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:25.893, tt:51.786\n",
      "Ep:2, loss:0.00005, loss_test:0.02681, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:27.178, tt:81.534\n",
      "Ep:3, loss:0.00005, loss_test:0.02637, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:27.602, tt:110.407\n",
      "Ep:4, loss:0.00005, loss_test:0.02569, lr:6.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:28.427, tt:142.133\n",
      "Ep:5, loss:0.00005, loss_test:0.02510, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:29.689, tt:178.132\n",
      "Ep:6, loss:0.00005, loss_test:0.02471, lr:6.00e-02, fs:0.63941 (r=0.869,p=0.506),  time:30.406, tt:212.840\n",
      "Ep:7, loss:0.00005, loss_test:0.02420, lr:6.00e-02, fs:0.63910 (r=0.859,p=0.509),  time:31.033, tt:248.264\n",
      "Ep:8, loss:0.00005, loss_test:0.02366, lr:6.00e-02, fs:0.64179 (r=0.869,p=0.509),  time:31.372, tt:282.345\n",
      "Ep:9, loss:0.00005, loss_test:0.02322, lr:6.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:31.736, tt:317.362\n",
      "Ep:10, loss:0.00004, loss_test:0.02265, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:32.048, tt:352.526\n",
      "Ep:11, loss:0.00004, loss_test:0.02173, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:32.254, tt:387.052\n",
      "Ep:12, loss:0.00004, loss_test:0.02092, lr:5.94e-02, fs:0.67681 (r=0.899,p=0.543),  time:32.504, tt:422.548\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02053, lr:5.94e-02, fs:0.67717 (r=0.869,p=0.555),  time:32.742, tt:458.384\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02030, lr:5.94e-02, fs:0.70370 (r=0.960,p=0.556),  time:32.853, tt:492.792\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02022, lr:5.94e-02, fs:0.70330 (r=0.970,p=0.552),  time:33.011, tt:528.171\n",
      "Ep:16, loss:0.00004, loss_test:0.01972, lr:5.94e-02, fs:0.70849 (r=0.970,p=0.558),  time:33.000, tt:560.997\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01919, lr:5.94e-02, fs:0.71698 (r=0.960,p=0.572),  time:33.115, tt:596.062\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01887, lr:5.94e-02, fs:0.71538 (r=0.939,p=0.578),  time:33.205, tt:630.896\n",
      "Ep:19, loss:0.00004, loss_test:0.01868, lr:5.94e-02, fs:0.71756 (r=0.949,p=0.577),  time:33.295, tt:665.890\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01855, lr:5.94e-02, fs:0.71375 (r=0.970,p=0.565),  time:33.455, tt:702.562\n",
      "Ep:21, loss:0.00003, loss_test:0.01829, lr:5.94e-02, fs:0.71538 (r=0.939,p=0.578),  time:33.589, tt:738.969\n",
      "Ep:22, loss:0.00003, loss_test:0.01824, lr:5.94e-02, fs:0.69672 (r=0.859,p=0.586),  time:33.622, tt:773.305\n",
      "Ep:23, loss:0.00003, loss_test:0.01829, lr:5.94e-02, fs:0.68333 (r=0.828,p=0.582),  time:33.707, tt:808.958\n",
      "Ep:24, loss:0.00003, loss_test:0.01858, lr:5.94e-02, fs:0.69136 (r=0.848,p=0.583),  time:33.705, tt:842.627\n",
      "Ep:25, loss:0.00003, loss_test:0.01875, lr:5.94e-02, fs:0.70085 (r=0.828,p=0.607),  time:33.806, tt:878.950\n",
      "Ep:26, loss:0.00003, loss_test:0.01884, lr:5.94e-02, fs:0.71930 (r=0.828,p=0.636),  time:33.813, tt:912.938\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01891, lr:5.94e-02, fs:0.70996 (r=0.828,p=0.621),  time:33.819, tt:946.922\n",
      "Ep:28, loss:0.00003, loss_test:0.01908, lr:5.94e-02, fs:0.71053 (r=0.818,p=0.628),  time:33.902, tt:983.151\n",
      "Ep:29, loss:0.00003, loss_test:0.01904, lr:5.94e-02, fs:0.71681 (r=0.818,p=0.638),  time:33.939, tt:1018.183\n",
      "Ep:30, loss:0.00003, loss_test:0.01901, lr:5.94e-02, fs:0.71681 (r=0.818,p=0.638),  time:34.005, tt:1054.152\n",
      "Ep:31, loss:0.00003, loss_test:0.01884, lr:5.94e-02, fs:0.71366 (r=0.818,p=0.633),  time:34.036, tt:1089.140\n",
      "Ep:32, loss:0.00003, loss_test:0.01882, lr:5.94e-02, fs:0.72321 (r=0.818,p=0.648),  time:34.089, tt:1124.935\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01881, lr:5.94e-02, fs:0.72973 (r=0.818,p=0.659),  time:34.116, tt:1159.951\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01873, lr:5.94e-02, fs:0.72646 (r=0.818,p=0.653),  time:34.117, tt:1194.108\n",
      "Ep:35, loss:0.00002, loss_test:0.01871, lr:5.94e-02, fs:0.72146 (r=0.798,p=0.658),  time:34.158, tt:1229.697\n",
      "Ep:36, loss:0.00002, loss_test:0.01841, lr:5.94e-02, fs:0.71818 (r=0.798,p=0.653),  time:34.171, tt:1264.341\n",
      "Ep:37, loss:0.00002, loss_test:0.01829, lr:5.94e-02, fs:0.72146 (r=0.798,p=0.658),  time:34.171, tt:1298.496\n",
      "Ep:38, loss:0.00002, loss_test:0.01817, lr:5.94e-02, fs:0.72146 (r=0.798,p=0.658),  time:34.210, tt:1334.174\n",
      "Ep:39, loss:0.00002, loss_test:0.01810, lr:5.94e-02, fs:0.73832 (r=0.798,p=0.687),  time:34.263, tt:1370.538\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01802, lr:5.94e-02, fs:0.72222 (r=0.788,p=0.667),  time:34.370, tt:1409.164\n",
      "Ep:41, loss:0.00002, loss_test:0.01837, lr:5.94e-02, fs:0.73585 (r=0.788,p=0.690),  time:34.394, tt:1444.530\n",
      "Ep:42, loss:0.00002, loss_test:0.01846, lr:5.94e-02, fs:0.74178 (r=0.798,p=0.693),  time:34.377, tt:1478.225\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01824, lr:5.94e-02, fs:0.73239 (r=0.788,p=0.684),  time:34.386, tt:1512.967\n",
      "Ep:44, loss:0.00002, loss_test:0.01850, lr:5.94e-02, fs:0.74038 (r=0.778,p=0.706),  time:34.403, tt:1548.151\n",
      "Ep:45, loss:0.00002, loss_test:0.01916, lr:5.94e-02, fs:0.74882 (r=0.798,p=0.705),  time:34.440, tt:1584.257\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01859, lr:5.94e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.477, tt:1620.396\n",
      "Ep:47, loss:0.00002, loss_test:0.01874, lr:5.94e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.516, tt:1656.748\n",
      "Ep:48, loss:0.00002, loss_test:0.01924, lr:5.94e-02, fs:0.75598 (r=0.798,p=0.718),  time:34.542, tt:1692.544\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01885, lr:5.94e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.548, tt:1727.424\n",
      "Ep:50, loss:0.00002, loss_test:0.01888, lr:5.94e-02, fs:0.75362 (r=0.788,p=0.722),  time:34.557, tt:1762.427\n",
      "Ep:51, loss:0.00002, loss_test:0.01944, lr:5.94e-02, fs:0.75362 (r=0.788,p=0.722),  time:34.572, tt:1797.747\n",
      "Ep:52, loss:0.00001, loss_test:0.01988, lr:5.94e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.594, tt:1833.494\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01963, lr:5.94e-02, fs:0.75000 (r=0.788,p=0.716),  time:34.604, tt:1868.598\n",
      "Ep:54, loss:0.00001, loss_test:0.01974, lr:5.94e-02, fs:0.75000 (r=0.788,p=0.716),  time:34.603, tt:1903.172\n",
      "Ep:55, loss:0.00001, loss_test:0.02132, lr:5.94e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.624, tt:1938.967\n",
      "Ep:56, loss:0.00001, loss_test:0.01980, lr:5.94e-02, fs:0.74641 (r=0.788,p=0.709),  time:34.644, tt:1974.734\n",
      "Ep:57, loss:0.00001, loss_test:0.02030, lr:5.94e-02, fs:0.75728 (r=0.788,p=0.729),  time:34.657, tt:2010.122\n",
      "Ep:58, loss:0.00001, loss_test:0.02024, lr:5.94e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.663, tt:2045.134\n",
      "Ep:59, loss:0.00001, loss_test:0.02254, lr:5.94e-02, fs:0.77612 (r=0.788,p=0.765),  time:34.666, tt:2079.990\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.02039, lr:5.94e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.676, tt:2115.261\n",
      "Ep:61, loss:0.00001, loss_test:0.02031, lr:5.94e-02, fs:0.74757 (r=0.778,p=0.720),  time:34.710, tt:2152.021\n",
      "Ep:62, loss:0.00001, loss_test:0.02150, lr:5.94e-02, fs:0.76617 (r=0.778,p=0.755),  time:34.716, tt:2187.133\n",
      "Ep:63, loss:0.00001, loss_test:0.02289, lr:5.94e-02, fs:0.77228 (r=0.788,p=0.757),  time:34.717, tt:2221.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.02255, lr:5.94e-02, fs:0.76098 (r=0.788,p=0.736),  time:34.715, tt:2256.498\n",
      "Ep:65, loss:0.00001, loss_test:0.02459, lr:5.94e-02, fs:0.75510 (r=0.747,p=0.763),  time:34.735, tt:2292.507\n",
      "Ep:66, loss:0.00001, loss_test:0.02458, lr:5.94e-02, fs:0.76768 (r=0.768,p=0.768),  time:34.711, tt:2325.607\n",
      "Ep:67, loss:0.00001, loss_test:0.02464, lr:5.94e-02, fs:0.75377 (r=0.758,p=0.750),  time:34.715, tt:2360.594\n",
      "Ep:68, loss:0.00001, loss_test:0.02435, lr:5.94e-02, fs:0.74227 (r=0.727,p=0.758),  time:34.711, tt:2395.080\n",
      "Ep:69, loss:0.00001, loss_test:0.02350, lr:5.94e-02, fs:0.72727 (r=0.727,p=0.727),  time:34.716, tt:2430.148\n",
      "Ep:70, loss:0.00001, loss_test:0.02674, lr:5.94e-02, fs:0.76923 (r=0.758,p=0.781),  time:34.728, tt:2465.676\n",
      "Ep:71, loss:0.00001, loss_test:0.02509, lr:5.88e-02, fs:0.75000 (r=0.758,p=0.743),  time:34.728, tt:2500.444\n",
      "Ep:72, loss:0.00001, loss_test:0.02334, lr:5.82e-02, fs:0.73367 (r=0.737,p=0.730),  time:34.722, tt:2534.740\n",
      "Ep:73, loss:0.00001, loss_test:0.02446, lr:5.76e-02, fs:0.78173 (r=0.778,p=0.786),  time:34.719, tt:2569.236\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.02189, lr:5.76e-02, fs:0.74372 (r=0.747,p=0.740),  time:34.711, tt:2603.343\n",
      "Ep:75, loss:0.00001, loss_test:0.02341, lr:5.76e-02, fs:0.76531 (r=0.758,p=0.773),  time:34.710, tt:2637.985\n",
      "Ep:76, loss:0.00001, loss_test:0.02349, lr:5.76e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.704, tt:2672.171\n",
      "Ep:77, loss:0.00001, loss_test:0.02408, lr:5.76e-02, fs:0.77387 (r=0.778,p=0.770),  time:34.686, tt:2705.482\n",
      "Ep:78, loss:0.00001, loss_test:0.02669, lr:5.76e-02, fs:0.76142 (r=0.758,p=0.765),  time:34.682, tt:2739.897\n",
      "Ep:79, loss:0.00001, loss_test:0.02536, lr:5.76e-02, fs:0.74490 (r=0.737,p=0.753),  time:34.686, tt:2774.861\n",
      "Ep:80, loss:0.00001, loss_test:0.02885, lr:5.76e-02, fs:0.75648 (r=0.737,p=0.777),  time:34.677, tt:2808.837\n",
      "Ep:81, loss:0.00001, loss_test:0.02834, lr:5.76e-02, fs:0.75000 (r=0.727,p=0.774),  time:34.674, tt:2843.251\n",
      "Ep:82, loss:0.00001, loss_test:0.02871, lr:5.76e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.679, tt:2878.370\n",
      "Ep:83, loss:0.00001, loss_test:0.03194, lr:5.76e-02, fs:0.76190 (r=0.727,p=0.800),  time:34.694, tt:2914.262\n",
      "Ep:84, loss:0.00001, loss_test:0.03040, lr:5.76e-02, fs:0.75393 (r=0.727,p=0.783),  time:34.690, tt:2948.636\n",
      "Ep:85, loss:0.00001, loss_test:0.03051, lr:5.71e-02, fs:0.77005 (r=0.727,p=0.818),  time:34.680, tt:2982.464\n",
      "Ep:86, loss:0.00001, loss_test:0.03221, lr:5.65e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.679, tt:3017.100\n",
      "Ep:87, loss:0.00001, loss_test:0.03308, lr:5.59e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.689, tt:3052.624\n",
      "Ep:88, loss:0.00001, loss_test:0.03348, lr:5.54e-02, fs:0.77005 (r=0.727,p=0.818),  time:34.670, tt:3085.593\n",
      "Ep:89, loss:0.00001, loss_test:0.03445, lr:5.48e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.681, tt:3121.265\n",
      "Ep:90, loss:0.00000, loss_test:0.03548, lr:5.43e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.696, tt:3157.372\n",
      "Ep:91, loss:0.00000, loss_test:0.03680, lr:5.37e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.698, tt:3192.242\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00000, loss_test:0.03744, lr:5.37e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.688, tt:3226.004\n",
      "Ep:93, loss:0.00000, loss_test:0.03671, lr:5.37e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.693, tt:3261.176\n",
      "Ep:94, loss:0.00001, loss_test:0.03339, lr:5.37e-02, fs:0.74033 (r=0.677,p=0.817),  time:34.679, tt:3294.541\n",
      "Ep:95, loss:0.00001, loss_test:0.03359, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.692, tt:3330.387\n",
      "Ep:96, loss:0.00001, loss_test:0.03202, lr:5.37e-02, fs:0.76596 (r=0.727,p=0.809),  time:34.685, tt:3364.403\n",
      "Ep:97, loss:0.00000, loss_test:0.03156, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.702, tt:3400.832\n",
      "Ep:98, loss:0.00000, loss_test:0.03782, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.715, tt:3436.832\n",
      "Ep:99, loss:0.00000, loss_test:0.03698, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.725, tt:3472.488\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.03524, lr:5.37e-02, fs:0.75138 (r=0.687,p=0.829),  time:34.730, tt:3507.686\n",
      "Ep:101, loss:0.00001, loss_test:0.03783, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.735, tt:3542.989\n",
      "Ep:102, loss:0.00001, loss_test:0.03426, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.739, tt:3578.078\n",
      "Ep:103, loss:0.00001, loss_test:0.03414, lr:5.37e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.743, tt:3613.230\n",
      "Ep:104, loss:0.00000, loss_test:0.03786, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.753, tt:3649.030\n",
      "Ep:105, loss:0.00000, loss_test:0.03617, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.753, tt:3683.819\n",
      "Ep:106, loss:0.00000, loss_test:0.04001, lr:5.37e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.759, tt:3719.172\n",
      "Ep:107, loss:0.00000, loss_test:0.03898, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.764, tt:3754.529\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.03899, lr:5.37e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.777, tt:3790.704\n",
      "Ep:109, loss:0.00000, loss_test:0.04257, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.789, tt:3826.753\n",
      "Ep:110, loss:0.00000, loss_test:0.04044, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.787, tt:3861.345\n",
      "Ep:111, loss:0.00000, loss_test:0.04163, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.807, tt:3898.407\n",
      "Ep:112, loss:0.00000, loss_test:0.04423, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.813, tt:3933.863\n",
      "Ep:113, loss:0.00000, loss_test:0.04091, lr:5.37e-02, fs:0.75706 (r=0.677,p=0.859),  time:34.815, tt:3968.956\n",
      "Ep:114, loss:0.00000, loss_test:0.04424, lr:5.37e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.817, tt:4003.987\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.04293, lr:5.37e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.834, tt:4040.704\n",
      "Ep:116, loss:0.00000, loss_test:0.04379, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.841, tt:4076.418\n",
      "Ep:117, loss:0.00000, loss_test:0.04607, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.843, tt:4111.453\n",
      "Ep:118, loss:0.00000, loss_test:0.04189, lr:5.37e-02, fs:0.76136 (r=0.677,p=0.870),  time:34.857, tt:4147.932\n",
      "Ep:119, loss:0.00000, loss_test:0.04510, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.875, tt:4184.984\n",
      "Ep:120, loss:0.00000, loss_test:0.04456, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.876, tt:4219.938\n",
      "Ep:121, loss:0.00000, loss_test:0.04370, lr:5.37e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.893, tt:4256.962\n",
      "Ep:122, loss:0.00000, loss_test:0.04815, lr:5.37e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.911, tt:4294.109\n",
      "Ep:123, loss:0.00000, loss_test:0.04555, lr:5.37e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.922, tt:4330.330\n",
      "Ep:124, loss:0.00000, loss_test:0.04705, lr:5.37e-02, fs:0.77778 (r=0.707,p=0.864),  time:34.949, tt:4368.677\n",
      "Ep:125, loss:0.00000, loss_test:0.04771, lr:5.37e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.957, tt:4404.618\n",
      "Ep:126, loss:0.00000, loss_test:0.04565, lr:5.32e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.969, tt:4441.080\n",
      "Ep:127, loss:0.00000, loss_test:0.04894, lr:5.27e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.982, tt:4477.756\n",
      "Ep:128, loss:0.00000, loss_test:0.04836, lr:5.21e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.994, tt:4514.275\n",
      "Ep:129, loss:0.00000, loss_test:0.04985, lr:5.16e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.988, tt:4548.451\n",
      "Ep:130, loss:0.00000, loss_test:0.05053, lr:5.11e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.989, tt:4583.615\n",
      "Ep:131, loss:0.00000, loss_test:0.04996, lr:5.06e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.995, tt:4619.311\n",
      "Ep:132, loss:0.00000, loss_test:0.05076, lr:5.01e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.987, tt:4653.297\n",
      "Ep:133, loss:0.00000, loss_test:0.05091, lr:4.96e-02, fs:0.75429 (r=0.667,p=0.868),  time:34.989, tt:4688.577\n",
      "Ep:134, loss:0.00000, loss_test:0.05299, lr:4.91e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.999, tt:4724.894\n",
      "Ep:135, loss:0.00000, loss_test:0.05320, lr:4.86e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.991, tt:4758.799\n",
      "Ep:136, loss:0.00000, loss_test:0.05254, lr:4.81e-02, fs:0.75145 (r=0.657,p=0.878),  time:35.005, tt:4795.659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.05381, lr:4.76e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.009, tt:4831.207\n",
      "Ep:138, loss:0.00000, loss_test:0.05520, lr:4.71e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.004, tt:4865.497\n",
      "Ep:139, loss:0.00000, loss_test:0.05513, lr:4.67e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.005, tt:4900.638\n",
      "Ep:140, loss:0.00000, loss_test:0.05354, lr:4.62e-02, fs:0.73810 (r=0.626,p=0.899),  time:35.004, tt:4935.526\n",
      "Ep:141, loss:0.00000, loss_test:0.05524, lr:4.57e-02, fs:0.77907 (r=0.677,p=0.918),  time:35.009, tt:4971.226\n",
      "Ep:142, loss:0.00000, loss_test:0.05605, lr:4.53e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.019, tt:5007.713\n",
      "Ep:143, loss:0.00000, loss_test:0.05463, lr:4.48e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.021, tt:5043.011\n",
      "Ep:144, loss:0.00000, loss_test:0.05636, lr:4.44e-02, fs:0.72619 (r=0.616,p=0.884),  time:35.030, tt:5079.279\n",
      "Ep:145, loss:0.00000, loss_test:0.05730, lr:4.39e-02, fs:0.74251 (r=0.626,p=0.912),  time:35.032, tt:5114.609\n",
      "Ep:146, loss:0.00000, loss_test:0.05687, lr:4.35e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.033, tt:5149.796\n",
      "Ep:147, loss:0.00000, loss_test:0.05773, lr:4.31e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.040, tt:5185.923\n",
      "Ep:148, loss:0.00000, loss_test:0.05755, lr:4.26e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.052, tt:5222.807\n",
      "Ep:149, loss:0.00000, loss_test:0.05842, lr:4.22e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.056, tt:5258.433\n",
      "Ep:150, loss:0.00000, loss_test:0.05840, lr:4.18e-02, fs:0.72289 (r=0.606,p=0.896),  time:35.059, tt:5293.933\n",
      "Ep:151, loss:0.00000, loss_test:0.05911, lr:4.14e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.060, tt:5329.157\n",
      "Ep:152, loss:0.00000, loss_test:0.05989, lr:4.10e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.066, tt:5365.063\n",
      "Ep:153, loss:0.00000, loss_test:0.05876, lr:4.05e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.066, tt:5400.182\n",
      "Ep:154, loss:0.00000, loss_test:0.05969, lr:4.01e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.078, tt:5437.167\n",
      "Ep:155, loss:0.00000, loss_test:0.06065, lr:3.97e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.089, tt:5473.887\n",
      "Ep:156, loss:0.00000, loss_test:0.05993, lr:3.93e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.110, tt:5512.278\n",
      "Ep:157, loss:0.00000, loss_test:0.06054, lr:3.89e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.125, tt:5549.768\n",
      "Ep:158, loss:0.00000, loss_test:0.06112, lr:3.86e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.144, tt:5587.829\n",
      "Ep:159, loss:0.00000, loss_test:0.06057, lr:3.82e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.152, tt:5624.367\n",
      "Ep:160, loss:0.00000, loss_test:0.06055, lr:3.78e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.172, tt:5662.700\n",
      "Ep:161, loss:0.00000, loss_test:0.06160, lr:3.74e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.187, tt:5700.338\n",
      "Ep:162, loss:0.00000, loss_test:0.06105, lr:3.70e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.192, tt:5736.287\n",
      "Ep:163, loss:0.00000, loss_test:0.06119, lr:3.67e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.188, tt:5770.779\n",
      "Ep:164, loss:0.00000, loss_test:0.06219, lr:3.63e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.188, tt:5805.939\n",
      "Ep:165, loss:0.00000, loss_test:0.06257, lr:3.59e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.185, tt:5840.785\n",
      "Ep:166, loss:0.00000, loss_test:0.06215, lr:3.56e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.192, tt:5877.065\n",
      "Ep:167, loss:0.00000, loss_test:0.06295, lr:3.52e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.196, tt:5912.918\n",
      "Ep:168, loss:0.00000, loss_test:0.06377, lr:3.49e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.207, tt:5949.982\n",
      "Ep:169, loss:0.00000, loss_test:0.06303, lr:3.45e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.219, tt:5987.198\n",
      "Ep:170, loss:0.00000, loss_test:0.06407, lr:3.42e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.226, tt:6023.618\n",
      "Ep:171, loss:0.00000, loss_test:0.06402, lr:3.38e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.241, tt:6061.437\n",
      "Ep:172, loss:0.00000, loss_test:0.06390, lr:3.35e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.250, tt:6098.297\n",
      "Ep:173, loss:0.00000, loss_test:0.06455, lr:3.32e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.252, tt:6133.761\n",
      "Ep:174, loss:0.00000, loss_test:0.06502, lr:3.28e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.266, tt:6171.522\n",
      "Ep:175, loss:0.00000, loss_test:0.06483, lr:3.25e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.269, tt:6207.372\n",
      "Ep:176, loss:0.00000, loss_test:0.06505, lr:3.22e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.279, tt:6244.364\n",
      "Ep:177, loss:0.00000, loss_test:0.06522, lr:3.19e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.271, tt:6278.244\n",
      "Ep:178, loss:0.00000, loss_test:0.06539, lr:3.15e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.285, tt:6316.029\n",
      "Ep:179, loss:0.00000, loss_test:0.06575, lr:3.12e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.286, tt:6351.476\n",
      "Ep:180, loss:0.00000, loss_test:0.06552, lr:3.09e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.291, tt:6387.665\n",
      "Ep:181, loss:0.00000, loss_test:0.06607, lr:3.06e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.293, tt:6423.385\n",
      "Ep:182, loss:0.00000, loss_test:0.06624, lr:3.03e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.296, tt:6459.242\n",
      "Ep:183, loss:0.00000, loss_test:0.06591, lr:3.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.294, tt:6494.141\n",
      "Ep:184, loss:0.00000, loss_test:0.06620, lr:2.97e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.288, tt:6528.364\n",
      "Ep:185, loss:0.00000, loss_test:0.06691, lr:2.94e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.288, tt:6563.546\n",
      "Ep:186, loss:0.00000, loss_test:0.06648, lr:2.91e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.290, tt:6599.281\n",
      "Ep:187, loss:0.00000, loss_test:0.06639, lr:2.88e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.291, tt:6634.780\n",
      "Ep:188, loss:0.00000, loss_test:0.06694, lr:2.85e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.292, tt:6670.196\n",
      "Ep:189, loss:0.00000, loss_test:0.06689, lr:2.82e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.292, tt:6705.542\n",
      "Ep:190, loss:0.00000, loss_test:0.06728, lr:2.80e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.297, tt:6741.671\n",
      "Ep:191, loss:0.00000, loss_test:0.06734, lr:2.77e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.295, tt:6776.725\n",
      "Ep:192, loss:0.00000, loss_test:0.06713, lr:2.74e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.295, tt:6811.910\n",
      "Ep:193, loss:0.00000, loss_test:0.06784, lr:2.71e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.299, tt:6847.973\n",
      "Ep:194, loss:0.00000, loss_test:0.06760, lr:2.69e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.300, tt:6883.566\n",
      "Ep:195, loss:0.00000, loss_test:0.06775, lr:2.66e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.301, tt:6918.978\n",
      "Ep:196, loss:0.00000, loss_test:0.06821, lr:2.63e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.302, tt:6954.457\n",
      "Ep:197, loss:0.00000, loss_test:0.06735, lr:2.61e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.299, tt:6989.276\n",
      "Ep:198, loss:0.00000, loss_test:0.06844, lr:2.58e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.301, tt:7024.806\n",
      "Ep:199, loss:0.00000, loss_test:0.06792, lr:2.55e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.297, tt:7059.333\n",
      "Ep:200, loss:0.00000, loss_test:0.06838, lr:2.53e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.302, tt:7095.636\n",
      "Ep:201, loss:0.00000, loss_test:0.06831, lr:2.50e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.307, tt:7132.062\n",
      "Ep:202, loss:0.00000, loss_test:0.06866, lr:2.48e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.312, tt:7168.306\n",
      "Ep:203, loss:0.00000, loss_test:0.06837, lr:2.45e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.311, tt:7203.522\n",
      "Ep:204, loss:0.00000, loss_test:0.06862, lr:2.43e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.314, tt:7239.454\n",
      "Ep:205, loss:0.00000, loss_test:0.06853, lr:2.40e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.304, tt:7272.550\n",
      "Ep:206, loss:0.00000, loss_test:0.06882, lr:2.38e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.303, tt:7307.654\n",
      "Ep:207, loss:0.00000, loss_test:0.06864, lr:2.36e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.300, tt:7342.448\n",
      "Ep:208, loss:0.00000, loss_test:0.06877, lr:2.33e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.301, tt:7377.830\n",
      "Ep:209, loss:0.00000, loss_test:0.06900, lr:2.31e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.299, tt:7412.739\n",
      "Ep:210, loss:0.00000, loss_test:0.06894, lr:2.29e-02, fs:0.73171 (r=0.606,p=0.923),  time:35.306, tt:7449.665\n",
      "Ep:211, loss:0.00000, loss_test:0.06922, lr:2.26e-02, fs:0.72727 (r=0.606,p=0.909),  time:35.302, tt:7483.931\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13462, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:32.697, tt:32.697\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13321, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:32.197, tt:64.394\n",
      "Ep:2, loss:0.00026, loss_test:0.13205, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:32.511, tt:97.534\n",
      "Ep:3, loss:0.00026, loss_test:0.13101, lr:1.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:31.388, tt:125.554\n",
      "Ep:4, loss:0.00026, loss_test:0.12993, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:32.082, tt:160.410\n",
      "Ep:5, loss:0.00026, loss_test:0.12832, lr:1.00e-02, fs:0.66926 (r=0.869,p=0.544),  time:32.275, tt:193.650\n",
      "Ep:6, loss:0.00026, loss_test:0.12681, lr:1.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:32.989, tt:230.927\n",
      "Ep:7, loss:0.00025, loss_test:0.12576, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:33.257, tt:266.059\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12515, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:33.853, tt:304.681\n",
      "Ep:9, loss:0.00025, loss_test:0.12469, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:34.008, tt:340.075\n",
      "Ep:10, loss:0.00025, loss_test:0.12434, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.434, tt:378.779\n",
      "Ep:11, loss:0.00025, loss_test:0.12396, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.619, tt:415.425\n",
      "Ep:12, loss:0.00025, loss_test:0.12348, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.789, tt:452.254\n",
      "Ep:13, loss:0.00025, loss_test:0.12284, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.838, tt:487.729\n",
      "Ep:14, loss:0.00024, loss_test:0.12213, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:34.928, tt:523.923\n",
      "Ep:15, loss:0.00024, loss_test:0.12099, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:35.108, tt:561.724\n",
      "Ep:16, loss:0.00024, loss_test:0.11969, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:35.197, tt:598.357\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.11841, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:35.333, tt:635.996\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.11693, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:35.335, tt:671.371\n",
      "Ep:19, loss:0.00023, loss_test:0.11553, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:35.371, tt:707.430\n",
      "Ep:20, loss:0.00022, loss_test:0.11397, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:35.342, tt:742.174\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.11100, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:35.311, tt:776.832\n",
      "Ep:22, loss:0.00022, loss_test:0.10947, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:35.430, tt:814.885\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.10782, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:35.463, tt:851.113\n",
      "Ep:24, loss:0.00021, loss_test:0.10665, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:35.461, tt:886.522\n",
      "Ep:25, loss:0.00020, loss_test:0.10404, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:35.548, tt:924.237\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00020, loss_test:0.10251, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:35.584, tt:960.754\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.10118, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:35.586, tt:996.406\n",
      "Ep:28, loss:0.00019, loss_test:0.10018, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:35.617, tt:1032.882\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00019, loss_test:0.09837, lr:1.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:35.793, tt:1073.793\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00018, loss_test:0.09730, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:35.815, tt:1110.264\n",
      "Ep:31, loss:0.00018, loss_test:0.09608, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:35.779, tt:1144.928\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00017, loss_test:0.09517, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:35.775, tt:1180.562\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.09395, lr:1.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:35.825, tt:1218.064\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00017, loss_test:0.09308, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:35.838, tt:1254.339\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00016, loss_test:0.09128, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:35.804, tt:1288.943\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00015, loss_test:0.08973, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:35.801, tt:1324.638\n",
      "Ep:37, loss:0.00015, loss_test:0.09226, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:35.779, tt:1359.614\n",
      "Ep:38, loss:0.00015, loss_test:0.09432, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:35.743, tt:1393.987\n",
      "Ep:39, loss:0.00015, loss_test:0.09113, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:35.719, tt:1428.743\n",
      "Ep:40, loss:0.00014, loss_test:0.08760, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:35.686, tt:1463.132\n",
      "Ep:41, loss:0.00013, loss_test:0.08664, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:35.704, tt:1499.571\n",
      "Ep:42, loss:0.00013, loss_test:0.08819, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:35.707, tt:1535.411\n",
      "Ep:43, loss:0.00013, loss_test:0.08888, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:35.698, tt:1570.719\n",
      "Ep:44, loss:0.00012, loss_test:0.08469, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:35.735, tt:1608.079\n",
      "Ep:45, loss:0.00012, loss_test:0.08496, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:35.763, tt:1645.113\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00011, loss_test:0.08261, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:35.732, tt:1679.388\n",
      "Ep:47, loss:0.00011, loss_test:0.08120, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:35.723, tt:1714.684\n",
      "Ep:48, loss:0.00010, loss_test:0.08266, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:35.724, tt:1750.466\n",
      "Ep:49, loss:0.00010, loss_test:0.08263, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:35.730, tt:1786.502\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00011, loss_test:0.08231, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:35.713, tt:1821.369\n",
      "Ep:51, loss:0.00010, loss_test:0.08181, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:35.748, tt:1858.882\n",
      "Ep:52, loss:0.00010, loss_test:0.08648, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:35.746, tt:1894.554\n",
      "Ep:53, loss:0.00011, loss_test:0.08276, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:35.738, tt:1929.859\n",
      "Ep:54, loss:0.00010, loss_test:0.08619, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:35.766, tt:1967.120\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00010, loss_test:0.07372, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:35.744, tt:2001.671\n",
      "Ep:56, loss:0.00009, loss_test:0.07314, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.745, tt:2037.447\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00009, loss_test:0.07696, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:35.750, tt:2073.493\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00008, loss_test:0.07493, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.766, tt:2110.174\n",
      "Ep:59, loss:0.00008, loss_test:0.08068, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.785, tt:2147.094\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00008, loss_test:0.07244, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:35.779, tt:2182.492\n",
      "Ep:61, loss:0.00007, loss_test:0.07433, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.760, tt:2217.112\n",
      "Ep:62, loss:0.00007, loss_test:0.07728, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:35.767, tt:2253.342\n",
      "Ep:63, loss:0.00006, loss_test:0.07310, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:35.805, tt:2291.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00006, loss_test:0.08002, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.815, tt:2327.995\n",
      "Ep:65, loss:0.00006, loss_test:0.07642, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:35.806, tt:2363.224\n",
      "Ep:66, loss:0.00006, loss_test:0.07898, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.799, tt:2398.533\n",
      "Ep:67, loss:0.00006, loss_test:0.07895, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.823, tt:2435.989\n",
      "Ep:68, loss:0.00006, loss_test:0.07987, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.849, tt:2473.585\n",
      "Ep:69, loss:0.00006, loss_test:0.07555, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.866, tt:2510.600\n",
      "Ep:70, loss:0.00005, loss_test:0.07801, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.863, tt:2546.248\n",
      "Ep:71, loss:0.00005, loss_test:0.08156, lr:9.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.876, tt:2583.095\n",
      "Ep:72, loss:0.00005, loss_test:0.07369, lr:9.80e-03, fs:0.81967 (r=0.758,p=0.893),  time:35.897, tt:2620.459\n",
      "Ep:73, loss:0.00005, loss_test:0.08657, lr:9.70e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.927, tt:2658.584\n",
      "Ep:74, loss:0.00004, loss_test:0.07648, lr:9.61e-03, fs:0.83243 (r=0.778,p=0.895),  time:35.937, tt:2695.240\n",
      "Ep:75, loss:0.00004, loss_test:0.07583, lr:9.51e-03, fs:0.83333 (r=0.758,p=0.926),  time:35.933, tt:2730.878\n",
      "Ep:76, loss:0.00004, loss_test:0.07956, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:35.944, tt:2767.675\n",
      "Ep:77, loss:0.00004, loss_test:0.07691, lr:9.32e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.961, tt:2804.954\n",
      "Ep:78, loss:0.00004, loss_test:0.07829, lr:9.23e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.968, tt:2841.460\n",
      "Ep:79, loss:0.00004, loss_test:0.07929, lr:9.14e-03, fs:0.82222 (r=0.747,p=0.914),  time:35.949, tt:2875.918\n",
      "Ep:80, loss:0.00004, loss_test:0.07459, lr:9.04e-03, fs:0.81564 (r=0.737,p=0.912),  time:35.940, tt:2911.126\n",
      "Ep:81, loss:0.00004, loss_test:0.07934, lr:8.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.958, tt:2948.526\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.08192, lr:8.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:35.969, tt:2985.437\n",
      "Ep:83, loss:0.00004, loss_test:0.07976, lr:8.95e-03, fs:0.81356 (r=0.727,p=0.923),  time:35.987, tt:3022.940\n",
      "Ep:84, loss:0.00004, loss_test:0.07971, lr:8.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:35.994, tt:3059.487\n",
      "Ep:85, loss:0.00003, loss_test:0.08652, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:36.008, tt:3096.714\n",
      "Ep:86, loss:0.00003, loss_test:0.07820, lr:8.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:36.012, tt:3133.080\n",
      "Ep:87, loss:0.00003, loss_test:0.08531, lr:8.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:36.016, tt:3169.384\n",
      "Ep:88, loss:0.00003, loss_test:0.08888, lr:8.95e-03, fs:0.83908 (r=0.737,p=0.973),  time:36.022, tt:3205.939\n",
      "Ep:89, loss:0.00003, loss_test:0.07652, lr:8.95e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.031, tt:3242.821\n",
      "Ep:90, loss:0.00003, loss_test:0.08484, lr:8.95e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.033, tt:3278.962\n",
      "Ep:91, loss:0.00003, loss_test:0.08623, lr:8.95e-03, fs:0.82682 (r=0.747,p=0.925),  time:36.025, tt:3314.310\n",
      "Ep:92, loss:0.00003, loss_test:0.08196, lr:8.95e-03, fs:0.82486 (r=0.737,p=0.936),  time:36.038, tt:3351.518\n",
      "Ep:93, loss:0.00003, loss_test:0.08282, lr:8.86e-03, fs:0.78824 (r=0.677,p=0.944),  time:36.027, tt:3386.573\n",
      "Ep:94, loss:0.00003, loss_test:0.08538, lr:8.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.030, tt:3422.883\n",
      "Ep:95, loss:0.00002, loss_test:0.08061, lr:8.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:36.038, tt:3459.636\n",
      "Ep:96, loss:0.00002, loss_test:0.08196, lr:8.60e-03, fs:0.82955 (r=0.737,p=0.948),  time:36.036, tt:3495.496\n",
      "Ep:97, loss:0.00002, loss_test:0.08553, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.042, tt:3532.141\n",
      "Ep:98, loss:0.00002, loss_test:0.08619, lr:8.43e-03, fs:0.74847 (r=0.616,p=0.953),  time:36.057, tt:3569.602\n",
      "Ep:99, loss:0.00002, loss_test:0.08784, lr:8.35e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.068, tt:3606.806\n",
      "Ep:100, loss:0.00002, loss_test:0.08487, lr:8.26e-03, fs:0.80000 (r=0.687,p=0.958),  time:36.064, tt:3642.459\n",
      "Ep:101, loss:0.00002, loss_test:0.08939, lr:8.18e-03, fs:0.78824 (r=0.677,p=0.944),  time:36.068, tt:3678.928\n",
      "Ep:102, loss:0.00002, loss_test:0.08709, lr:8.10e-03, fs:0.76647 (r=0.646,p=0.941),  time:36.079, tt:3716.112\n",
      "Ep:103, loss:0.00002, loss_test:0.09008, lr:8.02e-03, fs:0.83429 (r=0.737,p=0.961),  time:36.075, tt:3751.851\n",
      "Ep:104, loss:0.00002, loss_test:0.08744, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:36.073, tt:3787.648\n",
      "Ep:105, loss:0.00002, loss_test:0.08053, lr:7.86e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.087, tt:3825.275\n",
      "Ep:106, loss:0.00002, loss_test:0.08844, lr:7.78e-03, fs:0.78571 (r=0.667,p=0.957),  time:36.093, tt:3861.968\n",
      "Ep:107, loss:0.00002, loss_test:0.08608, lr:7.70e-03, fs:0.81818 (r=0.727,p=0.935),  time:36.097, tt:3898.510\n",
      "Ep:108, loss:0.00002, loss_test:0.08844, lr:7.62e-03, fs:0.76364 (r=0.636,p=0.955),  time:36.102, tt:3935.150\n",
      "Ep:109, loss:0.00002, loss_test:0.09040, lr:7.55e-03, fs:0.79532 (r=0.687,p=0.944),  time:36.108, tt:3971.834\n",
      "Ep:110, loss:0.00002, loss_test:0.09483, lr:7.47e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.112, tt:4008.395\n",
      "Ep:111, loss:0.00002, loss_test:0.09103, lr:7.40e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.118, tt:4045.202\n",
      "Ep:112, loss:0.00002, loss_test:0.09038, lr:7.32e-03, fs:0.75610 (r=0.626,p=0.954),  time:36.116, tt:4081.162\n",
      "Ep:113, loss:0.00001, loss_test:0.09150, lr:7.25e-03, fs:0.75152 (r=0.626,p=0.939),  time:36.111, tt:4116.706\n",
      "Ep:114, loss:0.00001, loss_test:0.08936, lr:7.18e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.103, tt:4151.818\n",
      "Ep:115, loss:0.00001, loss_test:0.09056, lr:7.11e-03, fs:0.75152 (r=0.626,p=0.939),  time:36.115, tt:4189.342\n",
      "Ep:116, loss:0.00001, loss_test:0.09114, lr:7.03e-03, fs:0.75610 (r=0.626,p=0.954),  time:36.163, tt:4231.097\n",
      "Ep:117, loss:0.00001, loss_test:0.09033, lr:6.96e-03, fs:0.75152 (r=0.626,p=0.939),  time:36.161, tt:4267.048\n",
      "Ep:118, loss:0.00001, loss_test:0.09031, lr:6.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:36.152, tt:4302.070\n",
      "Ep:119, loss:0.00001, loss_test:0.09526, lr:6.83e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.152, tt:4338.254\n",
      "Ep:120, loss:0.00001, loss_test:0.09065, lr:6.76e-03, fs:0.74074 (r=0.606,p=0.952),  time:36.157, tt:4374.999\n",
      "Ep:121, loss:0.00001, loss_test:0.09248, lr:6.69e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.151, tt:4410.372\n",
      "Ep:122, loss:0.00001, loss_test:0.09532, lr:6.62e-03, fs:0.77844 (r=0.657,p=0.956),  time:36.137, tt:4444.872\n",
      "Ep:123, loss:0.00001, loss_test:0.08829, lr:6.56e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.131, tt:4480.184\n",
      "Ep:124, loss:0.00001, loss_test:0.09405, lr:6.49e-03, fs:0.74847 (r=0.616,p=0.953),  time:36.120, tt:4515.034\n",
      "Ep:125, loss:0.00001, loss_test:0.09452, lr:6.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.118, tt:4550.830\n",
      "Ep:126, loss:0.00001, loss_test:0.09074, lr:6.36e-03, fs:0.74074 (r=0.606,p=0.952),  time:36.111, tt:4586.090\n",
      "Ep:127, loss:0.00001, loss_test:0.09839, lr:6.30e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.106, tt:4621.518\n",
      "Ep:128, loss:0.00001, loss_test:0.09517, lr:6.24e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.113, tt:4658.530\n",
      "Ep:129, loss:0.00001, loss_test:0.09487, lr:6.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.104, tt:4693.543\n",
      "Ep:130, loss:0.00001, loss_test:0.09897, lr:6.11e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.111, tt:4730.554\n",
      "Ep:131, loss:0.00001, loss_test:0.09028, lr:6.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:36.109, tt:4766.427\n",
      "Ep:132, loss:0.00001, loss_test:0.10180, lr:5.99e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.103, tt:4801.747\n",
      "Ep:133, loss:0.00001, loss_test:0.09503, lr:5.93e-03, fs:0.74074 (r=0.606,p=0.952),  time:36.107, tt:4838.299\n",
      "Ep:134, loss:0.00001, loss_test:0.09856, lr:5.87e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.109, tt:4874.650\n",
      "Ep:135, loss:0.00001, loss_test:0.09768, lr:5.81e-03, fs:0.74074 (r=0.606,p=0.952),  time:36.127, tt:4913.262\n",
      "Ep:136, loss:0.00001, loss_test:0.10200, lr:5.75e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.126, tt:4949.207\n",
      "Ep:137, loss:0.00001, loss_test:0.09751, lr:5.70e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.143, tt:4987.771\n",
      "Ep:138, loss:0.00001, loss_test:0.09951, lr:5.64e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.140, tt:5023.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00001, loss_test:0.09961, lr:5.58e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.137, tt:5059.112\n",
      "Ep:140, loss:0.00001, loss_test:0.10202, lr:5.53e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.133, tt:5094.820\n",
      "Ep:141, loss:0.00001, loss_test:0.09968, lr:5.47e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.136, tt:5131.381\n",
      "Ep:142, loss:0.00001, loss_test:0.10029, lr:5.42e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.140, tt:5168.037\n",
      "Ep:143, loss:0.00001, loss_test:0.10001, lr:5.36e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.143, tt:5204.588\n",
      "Ep:144, loss:0.00001, loss_test:0.09917, lr:5.31e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.147, tt:5241.245\n",
      "Ep:145, loss:0.00001, loss_test:0.10164, lr:5.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.154, tt:5278.491\n",
      "Ep:146, loss:0.00001, loss_test:0.09856, lr:5.20e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.150, tt:5314.019\n",
      "Ep:147, loss:0.00001, loss_test:0.10134, lr:5.15e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.147, tt:5349.719\n",
      "Ep:148, loss:0.00001, loss_test:0.09942, lr:5.10e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.149, tt:5386.251\n",
      "Ep:149, loss:0.00001, loss_test:0.10072, lr:5.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.139, tt:5420.815\n",
      "Ep:150, loss:0.00001, loss_test:0.09908, lr:5.00e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.143, tt:5457.653\n",
      "Ep:151, loss:0.00001, loss_test:0.10131, lr:4.95e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.140, tt:5493.351\n",
      "Ep:152, loss:0.00001, loss_test:0.09905, lr:4.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.142, tt:5529.719\n",
      "Ep:153, loss:0.00001, loss_test:0.09977, lr:4.85e-03, fs:0.74390 (r=0.616,p=0.938),  time:36.140, tt:5565.507\n",
      "Ep:154, loss:0.00001, loss_test:0.09978, lr:4.80e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.133, tt:5600.545\n",
      "Ep:155, loss:0.00001, loss_test:0.09989, lr:4.75e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.148, tt:5639.163\n",
      "Ep:156, loss:0.00001, loss_test:0.10164, lr:4.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.146, tt:5674.919\n",
      "Ep:157, loss:0.00001, loss_test:0.09926, lr:4.66e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.146, tt:5711.022\n",
      "Ep:158, loss:0.00000, loss_test:0.10093, lr:4.61e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.147, tt:5747.337\n",
      "Ep:159, loss:0.00000, loss_test:0.09984, lr:4.57e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.144, tt:5783.018\n",
      "Ep:160, loss:0.00000, loss_test:0.10117, lr:4.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.141, tt:5818.640\n",
      "Ep:161, loss:0.00000, loss_test:0.09994, lr:4.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.139, tt:5854.570\n",
      "Ep:162, loss:0.00000, loss_test:0.10188, lr:4.43e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.137, tt:5890.253\n",
      "Ep:163, loss:0.00000, loss_test:0.10031, lr:4.39e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.140, tt:5926.961\n",
      "Ep:164, loss:0.00000, loss_test:0.10169, lr:4.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.140, tt:5963.171\n",
      "Ep:165, loss:0.00000, loss_test:0.10158, lr:4.30e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.138, tt:5998.838\n",
      "Ep:166, loss:0.00000, loss_test:0.10178, lr:4.26e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.150, tt:6036.975\n",
      "Ep:167, loss:0.00000, loss_test:0.10105, lr:4.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.150, tt:6073.186\n",
      "Ep:168, loss:0.00000, loss_test:0.10302, lr:4.17e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.156, tt:6110.434\n",
      "Ep:169, loss:0.00000, loss_test:0.10125, lr:4.13e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.165, tt:6148.033\n",
      "Ep:170, loss:0.00000, loss_test:0.10163, lr:4.09e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.171, tt:6185.168\n",
      "Ep:171, loss:0.00000, loss_test:0.10180, lr:4.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.171, tt:6221.396\n",
      "Ep:172, loss:0.00000, loss_test:0.10190, lr:4.01e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.176, tt:6258.488\n",
      "Ep:173, loss:0.00000, loss_test:0.10114, lr:3.97e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.175, tt:6294.516\n",
      "Ep:174, loss:0.00000, loss_test:0.10308, lr:3.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.185, tt:6332.336\n",
      "Ep:175, loss:0.00000, loss_test:0.09895, lr:3.89e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.190, tt:6369.406\n",
      "Ep:176, loss:0.00000, loss_test:0.10362, lr:3.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.187, tt:6405.131\n",
      "Ep:177, loss:0.00000, loss_test:0.10095, lr:3.81e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.198, tt:6443.187\n",
      "Ep:178, loss:0.00000, loss_test:0.10250, lr:3.77e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.205, tt:6480.698\n",
      "Ep:179, loss:0.00000, loss_test:0.10133, lr:3.73e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.212, tt:6518.075\n",
      "Ep:180, loss:0.00000, loss_test:0.10106, lr:3.70e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.212, tt:6554.281\n",
      "Ep:181, loss:0.00000, loss_test:0.10056, lr:3.66e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.207, tt:6589.681\n",
      "Ep:182, loss:0.00000, loss_test:0.10182, lr:3.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.216, tt:6627.614\n",
      "Ep:183, loss:0.00000, loss_test:0.10071, lr:3.59e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.222, tt:6664.859\n",
      "Ep:184, loss:0.00000, loss_test:0.10183, lr:3.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.227, tt:6701.911\n",
      "Ep:185, loss:0.00000, loss_test:0.10051, lr:3.52e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.230, tt:6738.797\n",
      "Ep:186, loss:0.00000, loss_test:0.10024, lr:3.48e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.233, tt:6775.607\n",
      "Ep:187, loss:0.00000, loss_test:0.10090, lr:3.45e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.229, tt:6811.094\n",
      "Ep:188, loss:0.00000, loss_test:0.10091, lr:3.41e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.233, tt:6848.106\n",
      "Ep:189, loss:0.00000, loss_test:0.10056, lr:3.38e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.227, tt:6883.095\n",
      "Ep:190, loss:0.00000, loss_test:0.10106, lr:3.34e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.219, tt:6917.808\n",
      "Ep:191, loss:0.00000, loss_test:0.10196, lr:3.31e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.217, tt:6953.650\n",
      "Ep:192, loss:0.00000, loss_test:0.10050, lr:3.28e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.220, tt:6990.373\n",
      "Ep:193, loss:0.00000, loss_test:0.10284, lr:3.24e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.223, tt:7027.204\n",
      "Ep:194, loss:0.00000, loss_test:0.10103, lr:3.21e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.223, tt:7063.467\n",
      "Ep:195, loss:0.00000, loss_test:0.10120, lr:3.18e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.221, tt:7099.331\n",
      "Ep:196, loss:0.00000, loss_test:0.10164, lr:3.15e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.223, tt:7135.837\n",
      "Ep:197, loss:0.00000, loss_test:0.10085, lr:3.12e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.224, tt:7172.344\n",
      "Ep:198, loss:0.00000, loss_test:0.10129, lr:3.09e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.220, tt:7207.780\n",
      "Ep:199, loss:0.00000, loss_test:0.10085, lr:3.05e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.216, tt:7243.192\n",
      "Ep:200, loss:0.00000, loss_test:0.10144, lr:3.02e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.209, tt:7278.106\n",
      "Ep:201, loss:0.00000, loss_test:0.10154, lr:2.99e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.203, tt:7313.002\n",
      "Ep:202, loss:0.00000, loss_test:0.10095, lr:2.96e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.203, tt:7349.238\n",
      "Ep:203, loss:0.00000, loss_test:0.10186, lr:2.93e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.209, tt:7386.574\n",
      "Ep:204, loss:0.00000, loss_test:0.10159, lr:2.90e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.206, tt:7422.206\n",
      "Ep:205, loss:0.00000, loss_test:0.10076, lr:2.88e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.204, tt:7458.109\n",
      "Ep:206, loss:0.00000, loss_test:0.10093, lr:2.85e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.201, tt:7493.627\n",
      "Ep:207, loss:0.00000, loss_test:0.10111, lr:2.82e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.205, tt:7530.654\n",
      "Ep:208, loss:0.00000, loss_test:0.10038, lr:2.79e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.212, tt:7568.270\n",
      "Ep:209, loss:0.00000, loss_test:0.10115, lr:2.76e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.210, tt:7604.006\n",
      "Ep:210, loss:0.00000, loss_test:0.10064, lr:2.73e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.214, tt:7641.234\n",
      "Ep:211, loss:0.00000, loss_test:0.10117, lr:2.71e-03, fs:0.73620 (r=0.606,p=0.938),  time:36.215, tt:7677.654\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02936, lr:6.00e-02, fs:0.63436 (r=0.727,p=0.562),  time:28.355, tt:28.355\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02415, lr:6.00e-02, fs:0.63469 (r=0.869,p=0.500),  time:28.162, tt:56.323\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02639, lr:6.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:27.054, tt:81.161\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02640, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:27.015, tt:108.062\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02485, lr:6.00e-02, fs:0.64516 (r=0.909,p=0.500),  time:28.145, tt:140.724\n",
      "Ep:5, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:29.001, tt:174.003\n",
      "Ep:6, loss:0.00005, loss_test:0.02425, lr:6.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:29.935, tt:209.548\n",
      "Ep:7, loss:0.00005, loss_test:0.02409, lr:6.00e-02, fs:0.64662 (r=0.869,p=0.515),  time:30.428, tt:243.425\n",
      "Ep:8, loss:0.00005, loss_test:0.02404, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:30.953, tt:278.581\n",
      "Ep:9, loss:0.00005, loss_test:0.02389, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:31.396, tt:313.965\n",
      "Ep:10, loss:0.00005, loss_test:0.02351, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:31.746, tt:349.205\n",
      "Ep:11, loss:0.00005, loss_test:0.02305, lr:6.00e-02, fs:0.64925 (r=0.879,p=0.515),  time:32.084, tt:385.009\n",
      "Ep:12, loss:0.00004, loss_test:0.02266, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:32.299, tt:419.887\n",
      "Ep:13, loss:0.00004, loss_test:0.02222, lr:6.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:32.500, tt:454.998\n",
      "Ep:14, loss:0.00004, loss_test:0.02170, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:32.664, tt:489.964\n",
      "Ep:15, loss:0.00004, loss_test:0.02119, lr:5.94e-02, fs:0.67681 (r=0.899,p=0.543),  time:32.867, tt:525.873\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.02067, lr:5.94e-02, fs:0.67939 (r=0.899,p=0.546),  time:32.989, tt:560.815\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.02008, lr:5.94e-02, fs:0.68726 (r=0.899,p=0.556),  time:33.155, tt:596.790\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01946, lr:5.94e-02, fs:0.68750 (r=0.889,p=0.561),  time:33.281, tt:632.346\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01884, lr:5.94e-02, fs:0.69020 (r=0.889,p=0.564),  time:33.328, tt:666.570\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01820, lr:5.94e-02, fs:0.69565 (r=0.889,p=0.571),  time:33.406, tt:701.529\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01754, lr:5.94e-02, fs:0.71146 (r=0.909,p=0.584),  time:33.489, tt:736.763\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01686, lr:5.94e-02, fs:0.73092 (r=0.919,p=0.607),  time:33.516, tt:770.866\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01616, lr:5.94e-02, fs:0.73896 (r=0.929,p=0.613),  time:33.609, tt:806.607\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01556, lr:5.94e-02, fs:0.75806 (r=0.949,p=0.631),  time:33.725, tt:843.134\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01505, lr:5.94e-02, fs:0.77419 (r=0.970,p=0.644),  time:33.769, tt:877.984\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01453, lr:5.94e-02, fs:0.78088 (r=0.990,p=0.645),  time:33.882, tt:914.819\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01402, lr:5.94e-02, fs:0.77778 (r=0.990,p=0.641),  time:33.956, tt:950.778\n",
      "Ep:28, loss:0.00003, loss_test:0.01356, lr:5.94e-02, fs:0.79352 (r=0.990,p=0.662),  time:34.013, tt:986.384\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01320, lr:5.94e-02, fs:0.80658 (r=0.990,p=0.681),  time:34.065, tt:1021.946\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01283, lr:5.94e-02, fs:0.80833 (r=0.980,p=0.688),  time:34.115, tt:1057.557\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01250, lr:5.94e-02, fs:0.82700 (r=0.990,p=0.710),  time:34.182, tt:1093.825\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01224, lr:5.94e-02, fs:0.82353 (r=0.990,p=0.705),  time:34.207, tt:1128.830\n",
      "Ep:33, loss:0.00002, loss_test:0.01201, lr:5.94e-02, fs:0.83761 (r=0.990,p=0.726),  time:34.231, tt:1163.837\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01185, lr:5.94e-02, fs:0.83262 (r=0.980,p=0.724),  time:34.286, tt:1200.002\n",
      "Ep:35, loss:0.00002, loss_test:0.01160, lr:5.94e-02, fs:0.82906 (r=0.980,p=0.719),  time:34.277, tt:1233.988\n",
      "Ep:36, loss:0.00002, loss_test:0.01136, lr:5.94e-02, fs:0.83983 (r=0.980,p=0.735),  time:34.319, tt:1269.786\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01123, lr:5.94e-02, fs:0.85463 (r=0.980,p=0.758),  time:34.311, tt:1303.804\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01113, lr:5.94e-02, fs:0.86222 (r=0.980,p=0.770),  time:34.316, tt:1338.316\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01113, lr:5.94e-02, fs:0.87892 (r=0.990,p=0.790),  time:34.349, tt:1373.940\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01111, lr:5.94e-02, fs:0.88288 (r=0.990,p=0.797),  time:34.335, tt:1407.746\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01101, lr:5.94e-02, fs:0.90000 (r=1.000,p=0.818),  time:34.318, tt:1441.349\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01100, lr:5.94e-02, fs:0.90000 (r=1.000,p=0.818),  time:34.317, tt:1475.620\n",
      "Ep:43, loss:0.00001, loss_test:0.01085, lr:5.94e-02, fs:0.90411 (r=1.000,p=0.825),  time:34.282, tt:1508.426\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01073, lr:5.94e-02, fs:0.91244 (r=1.000,p=0.839),  time:34.283, tt:1542.716\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01083, lr:5.94e-02, fs:0.89302 (r=0.970,p=0.828),  time:34.264, tt:1576.144\n",
      "Ep:46, loss:0.00001, loss_test:0.01076, lr:5.94e-02, fs:0.89815 (r=0.980,p=0.829),  time:34.278, tt:1611.058\n",
      "Ep:47, loss:0.00001, loss_test:0.01081, lr:5.94e-02, fs:0.89720 (r=0.970,p=0.835),  time:34.288, tt:1645.824\n",
      "Ep:48, loss:0.00001, loss_test:0.01068, lr:5.94e-02, fs:0.88785 (r=0.960,p=0.826),  time:34.262, tt:1678.860\n",
      "Ep:49, loss:0.00001, loss_test:0.01082, lr:5.94e-02, fs:0.87081 (r=0.919,p=0.827),  time:34.273, tt:1713.649\n",
      "Ep:50, loss:0.00001, loss_test:0.01089, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:34.239, tt:1746.209\n",
      "Ep:51, loss:0.00001, loss_test:0.01099, lr:5.94e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.203, tt:1778.563\n",
      "Ep:52, loss:0.00001, loss_test:0.01098, lr:5.94e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.194, tt:1812.264\n",
      "Ep:53, loss:0.00001, loss_test:0.01113, lr:5.94e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.206, tt:1847.115\n",
      "Ep:54, loss:0.00001, loss_test:0.01109, lr:5.94e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.198, tt:1880.876\n",
      "Ep:55, loss:0.00001, loss_test:0.01120, lr:5.94e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.166, tt:1913.311\n",
      "Ep:56, loss:0.00001, loss_test:0.01116, lr:5.88e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.164, tt:1947.350\n",
      "Ep:57, loss:0.00001, loss_test:0.01145, lr:5.82e-02, fs:0.80851 (r=0.768,p=0.854),  time:34.159, tt:1981.215\n",
      "Ep:58, loss:0.00001, loss_test:0.01135, lr:5.76e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.145, tt:2014.557\n",
      "Ep:59, loss:0.00001, loss_test:0.01157, lr:5.71e-02, fs:0.79348 (r=0.737,p=0.859),  time:34.131, tt:2047.848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01153, lr:5.65e-02, fs:0.80220 (r=0.737,p=0.880),  time:34.114, tt:2080.949\n",
      "Ep:61, loss:0.00001, loss_test:0.01153, lr:5.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.095, tt:2113.908\n",
      "Ep:62, loss:0.00000, loss_test:0.01173, lr:5.54e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.084, tt:2147.264\n",
      "Ep:63, loss:0.00000, loss_test:0.01183, lr:5.48e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.083, tt:2181.328\n",
      "Ep:64, loss:0.00000, loss_test:0.01211, lr:5.43e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.067, tt:2214.372\n",
      "Ep:65, loss:0.00000, loss_test:0.01196, lr:5.37e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.049, tt:2247.257\n",
      "Ep:66, loss:0.00000, loss_test:0.01233, lr:5.32e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.033, tt:2280.182\n",
      "Ep:67, loss:0.00000, loss_test:0.01231, lr:5.27e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.029, tt:2313.939\n",
      "Ep:68, loss:0.00000, loss_test:0.01247, lr:5.21e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.997, tt:2345.813\n",
      "Ep:69, loss:0.00000, loss_test:0.01249, lr:5.16e-02, fs:0.80682 (r=0.717,p=0.922),  time:33.982, tt:2378.719\n",
      "Ep:70, loss:0.00000, loss_test:0.01277, lr:5.11e-02, fs:0.80899 (r=0.727,p=0.911),  time:33.977, tt:2412.359\n",
      "Ep:71, loss:0.00000, loss_test:0.01280, lr:5.06e-02, fs:0.81356 (r=0.727,p=0.923),  time:33.977, tt:2446.333\n",
      "Ep:72, loss:0.00000, loss_test:0.01286, lr:5.01e-02, fs:0.81143 (r=0.717,p=0.934),  time:33.984, tt:2480.804\n",
      "Ep:73, loss:0.00000, loss_test:0.01303, lr:4.96e-02, fs:0.80682 (r=0.717,p=0.922),  time:33.981, tt:2514.592\n",
      "Ep:74, loss:0.00000, loss_test:0.01314, lr:4.91e-02, fs:0.80000 (r=0.707,p=0.921),  time:33.976, tt:2548.228\n",
      "Ep:75, loss:0.00000, loss_test:0.01332, lr:4.86e-02, fs:0.80000 (r=0.707,p=0.921),  time:33.964, tt:2581.289\n",
      "Ep:76, loss:0.00000, loss_test:0.01340, lr:4.81e-02, fs:0.80682 (r=0.717,p=0.922),  time:33.961, tt:2615.018\n",
      "Ep:77, loss:0.00000, loss_test:0.01356, lr:4.76e-02, fs:0.78613 (r=0.687,p=0.919),  time:33.959, tt:2648.808\n",
      "Ep:78, loss:0.00000, loss_test:0.01362, lr:4.71e-02, fs:0.78613 (r=0.687,p=0.919),  time:33.967, tt:2683.386\n",
      "Ep:79, loss:0.00000, loss_test:0.01380, lr:4.67e-02, fs:0.77647 (r=0.667,p=0.930),  time:33.954, tt:2716.350\n",
      "Ep:80, loss:0.00000, loss_test:0.01380, lr:4.62e-02, fs:0.74699 (r=0.626,p=0.925),  time:33.960, tt:2750.758\n",
      "Ep:81, loss:0.00000, loss_test:0.01394, lr:4.57e-02, fs:0.73939 (r=0.616,p=0.924),  time:33.951, tt:2783.970\n",
      "Ep:82, loss:0.00000, loss_test:0.01421, lr:4.53e-02, fs:0.74699 (r=0.626,p=0.925),  time:33.944, tt:2817.350\n",
      "Ep:83, loss:0.00000, loss_test:0.01407, lr:4.48e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.933, tt:2850.392\n",
      "Ep:84, loss:0.00000, loss_test:0.01433, lr:4.44e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.939, tt:2884.836\n",
      "Ep:85, loss:0.00000, loss_test:0.01440, lr:4.39e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.929, tt:2917.903\n",
      "Ep:86, loss:0.00000, loss_test:0.01454, lr:4.35e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.920, tt:2951.049\n",
      "Ep:87, loss:0.00000, loss_test:0.01450, lr:4.31e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.898, tt:2983.021\n",
      "Ep:88, loss:0.00000, loss_test:0.01465, lr:4.26e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.890, tt:3016.214\n",
      "Ep:89, loss:0.00000, loss_test:0.01479, lr:4.22e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.904, tt:3051.364\n",
      "Ep:90, loss:0.00000, loss_test:0.01482, lr:4.18e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.911, tt:3085.861\n",
      "Ep:91, loss:0.00000, loss_test:0.01502, lr:4.14e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.904, tt:3119.185\n",
      "Ep:92, loss:0.00000, loss_test:0.01500, lr:4.10e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.905, tt:3153.201\n",
      "Ep:93, loss:0.00000, loss_test:0.01516, lr:4.05e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.898, tt:3186.434\n",
      "Ep:94, loss:0.00000, loss_test:0.01524, lr:4.01e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.895, tt:3220.070\n",
      "Ep:95, loss:0.00000, loss_test:0.01536, lr:3.97e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.894, tt:3253.856\n",
      "Ep:96, loss:0.00000, loss_test:0.01548, lr:3.93e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.903, tt:3288.564\n",
      "Ep:97, loss:0.00000, loss_test:0.01545, lr:3.89e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.900, tt:3322.173\n",
      "Ep:98, loss:0.00000, loss_test:0.01566, lr:3.86e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.890, tt:3355.082\n",
      "Ep:99, loss:0.00000, loss_test:0.01567, lr:3.82e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.870, tt:3386.978\n",
      "Ep:100, loss:0.00000, loss_test:0.01574, lr:3.78e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.884, tt:3422.234\n",
      "Ep:101, loss:0.00000, loss_test:0.01592, lr:3.74e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.869, tt:3454.675\n",
      "Ep:102, loss:0.00000, loss_test:0.01590, lr:3.70e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.863, tt:3487.883\n",
      "Ep:103, loss:0.00000, loss_test:0.01606, lr:3.67e-02, fs:0.73171 (r=0.606,p=0.923),  time:33.858, tt:3521.187\n",
      "Ep:104, loss:0.00000, loss_test:0.01600, lr:3.63e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.862, tt:3555.501\n",
      "Ep:105, loss:0.00000, loss_test:0.01620, lr:3.59e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.865, tt:3589.682\n",
      "Ep:106, loss:0.00000, loss_test:0.01623, lr:3.56e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.858, tt:3622.823\n",
      "Ep:107, loss:0.00000, loss_test:0.01634, lr:3.52e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.851, tt:3655.943\n",
      "Ep:108, loss:0.00000, loss_test:0.01632, lr:3.49e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.839, tt:3688.402\n",
      "Ep:109, loss:0.00000, loss_test:0.01641, lr:3.45e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.834, tt:3721.701\n",
      "Ep:110, loss:0.00000, loss_test:0.01653, lr:3.42e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.826, tt:3754.653\n",
      "Ep:111, loss:0.00000, loss_test:0.01651, lr:3.38e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.822, tt:3788.097\n",
      "Ep:112, loss:0.00000, loss_test:0.01668, lr:3.35e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.837, tt:3823.632\n",
      "Ep:113, loss:0.00000, loss_test:0.01668, lr:3.32e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.837, tt:3857.440\n",
      "Ep:114, loss:0.00000, loss_test:0.01684, lr:3.28e-02, fs:0.73620 (r=0.606,p=0.938),  time:33.839, tt:3891.455\n",
      "Ep:115, loss:0.00000, loss_test:0.01679, lr:3.25e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.833, tt:3924.617\n",
      "Ep:116, loss:0.00000, loss_test:0.01692, lr:3.22e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.839, tt:3959.154\n",
      "Ep:117, loss:0.00000, loss_test:0.01694, lr:3.19e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.833, tt:3992.344\n",
      "Ep:118, loss:0.00000, loss_test:0.01705, lr:3.15e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.823, tt:4024.948\n",
      "Ep:119, loss:0.00000, loss_test:0.01703, lr:3.12e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.821, tt:4058.533\n",
      "Ep:120, loss:0.00000, loss_test:0.01717, lr:3.09e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.807, tt:4090.604\n",
      "Ep:121, loss:0.00000, loss_test:0.01720, lr:3.06e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.810, tt:4124.784\n",
      "Ep:122, loss:0.00000, loss_test:0.01723, lr:3.03e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.805, tt:4158.057\n",
      "Ep:123, loss:0.00000, loss_test:0.01726, lr:3.00e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.805, tt:4191.858\n",
      "Ep:124, loss:0.00000, loss_test:0.01734, lr:2.97e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.791, tt:4223.866\n",
      "Ep:125, loss:0.00000, loss_test:0.01736, lr:2.94e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.778, tt:4256.049\n",
      "Ep:126, loss:0.00000, loss_test:0.01743, lr:2.91e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.780, tt:4290.069\n",
      "Ep:127, loss:0.00000, loss_test:0.01744, lr:2.88e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.776, tt:4323.284\n",
      "Ep:128, loss:0.00000, loss_test:0.01758, lr:2.85e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.773, tt:4356.660\n",
      "Ep:129, loss:0.00000, loss_test:0.01758, lr:2.82e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.765, tt:4389.395\n",
      "Ep:130, loss:0.00000, loss_test:0.01762, lr:2.80e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.748, tt:4421.020\n",
      "Ep:131, loss:0.00000, loss_test:0.01766, lr:2.77e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.736, tt:4453.142\n",
      "Ep:132, loss:0.00000, loss_test:0.01774, lr:2.74e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.756, tt:4489.587\n",
      "Ep:133, loss:0.00000, loss_test:0.01772, lr:2.71e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.749, tt:4522.431\n",
      "Ep:134, loss:0.00000, loss_test:0.01783, lr:2.69e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.741, tt:4555.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.01786, lr:2.66e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.747, tt:4589.624\n",
      "Ep:136, loss:0.00000, loss_test:0.01792, lr:2.63e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.751, tt:4623.944\n",
      "Ep:137, loss:0.00000, loss_test:0.01792, lr:2.61e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.745, tt:4656.864\n",
      "Ep:138, loss:0.00000, loss_test:0.01801, lr:2.58e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.745, tt:4690.502\n",
      "Ep:139, loss:0.00000, loss_test:0.01799, lr:2.55e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.750, tt:4724.965\n",
      "Ep:140, loss:0.00000, loss_test:0.01805, lr:2.53e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.754, tt:4759.307\n",
      "Ep:141, loss:0.00000, loss_test:0.01806, lr:2.50e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.746, tt:4791.942\n",
      "Ep:142, loss:0.00000, loss_test:0.01812, lr:2.48e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.741, tt:4824.902\n",
      "Ep:143, loss:0.00000, loss_test:0.01818, lr:2.45e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.737, tt:4858.135\n",
      "Ep:144, loss:0.00000, loss_test:0.01817, lr:2.43e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.733, tt:4891.311\n",
      "Ep:145, loss:0.00000, loss_test:0.01825, lr:2.40e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.731, tt:4924.655\n",
      "Ep:146, loss:0.00000, loss_test:0.01823, lr:2.38e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.725, tt:4957.569\n",
      "Ep:147, loss:0.00000, loss_test:0.01832, lr:2.36e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.722, tt:4990.859\n",
      "Ep:148, loss:0.00000, loss_test:0.01830, lr:2.33e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.731, tt:5025.851\n",
      "Ep:149, loss:0.00000, loss_test:0.01838, lr:2.31e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.730, tt:5059.524\n",
      "Ep:150, loss:0.00000, loss_test:0.01840, lr:2.29e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.716, tt:5091.055\n",
      "Ep:151, loss:0.00000, loss_test:0.01846, lr:2.26e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.720, tt:5125.432\n",
      "Ep:152, loss:0.00000, loss_test:0.01845, lr:2.24e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.726, tt:5160.044\n",
      "Ep:153, loss:0.00000, loss_test:0.01851, lr:2.22e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.730, tt:5194.428\n",
      "Ep:154, loss:0.00000, loss_test:0.01854, lr:2.20e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.734, tt:5228.782\n",
      "Ep:155, loss:0.00000, loss_test:0.01856, lr:2.17e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.741, tt:5263.670\n",
      "Ep:156, loss:0.00000, loss_test:0.01860, lr:2.15e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.752, tt:5299.129\n",
      "Ep:157, loss:0.00000, loss_test:0.01863, lr:2.13e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.761, tt:5334.259\n",
      "Ep:158, loss:0.00000, loss_test:0.01868, lr:2.11e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.763, tt:5368.282\n",
      "Ep:159, loss:0.00000, loss_test:0.01870, lr:2.09e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.766, tt:5402.529\n",
      "Ep:160, loss:0.00000, loss_test:0.01873, lr:2.07e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.775, tt:5437.755\n",
      "Ep:161, loss:0.00000, loss_test:0.01876, lr:2.05e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.776, tt:5471.750\n",
      "Ep:162, loss:0.00000, loss_test:0.01879, lr:2.03e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.783, tt:5506.609\n",
      "Ep:163, loss:0.00000, loss_test:0.01882, lr:2.01e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.790, tt:5541.573\n",
      "Ep:164, loss:0.00000, loss_test:0.01883, lr:1.99e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.798, tt:5576.627\n",
      "Ep:165, loss:0.00000, loss_test:0.01889, lr:1.97e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.808, tt:5612.067\n",
      "Ep:166, loss:0.00000, loss_test:0.01887, lr:1.95e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.821, tt:5648.131\n",
      "Ep:167, loss:0.00000, loss_test:0.01892, lr:1.93e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.832, tt:5683.855\n",
      "Ep:168, loss:0.00000, loss_test:0.01893, lr:1.91e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.836, tt:5718.220\n",
      "Ep:169, loss:0.00000, loss_test:0.01897, lr:1.89e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.839, tt:5752.632\n",
      "Ep:170, loss:0.00000, loss_test:0.01897, lr:1.87e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.840, tt:5786.565\n",
      "Ep:171, loss:0.00000, loss_test:0.01897, lr:1.85e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.845, tt:5821.350\n",
      "Ep:172, loss:0.00000, loss_test:0.01903, lr:1.83e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.852, tt:5856.386\n",
      "Ep:173, loss:0.00000, loss_test:0.01904, lr:1.81e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.852, tt:5890.262\n",
      "Ep:174, loss:0.00000, loss_test:0.01910, lr:1.80e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.860, tt:5925.482\n",
      "Ep:175, loss:0.00000, loss_test:0.01907, lr:1.78e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.861, tt:5959.483\n",
      "Ep:176, loss:0.00000, loss_test:0.01911, lr:1.76e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.864, tt:5993.931\n",
      "Ep:177, loss:0.00000, loss_test:0.01912, lr:1.74e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.876, tt:6029.909\n",
      "Ep:178, loss:0.00000, loss_test:0.01914, lr:1.73e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.889, tt:6066.050\n",
      "Ep:179, loss:0.00000, loss_test:0.01916, lr:1.71e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.908, tt:6103.521\n",
      "Ep:180, loss:0.00000, loss_test:0.01918, lr:1.69e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.920, tt:6139.458\n",
      "Ep:181, loss:0.00000, loss_test:0.01920, lr:1.67e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.922, tt:6173.789\n",
      "Ep:182, loss:0.00000, loss_test:0.01922, lr:1.66e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.930, tt:6209.149\n",
      "Ep:183, loss:0.00000, loss_test:0.01923, lr:1.64e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.932, tt:6243.490\n",
      "Ep:184, loss:0.00000, loss_test:0.01928, lr:1.62e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.937, tt:6278.334\n",
      "Ep:185, loss:0.00000, loss_test:0.01928, lr:1.61e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.942, tt:6313.158\n",
      "Ep:186, loss:0.00000, loss_test:0.01930, lr:1.59e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.960, tt:6350.558\n",
      "Ep:187, loss:0.00000, loss_test:0.01930, lr:1.58e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.959, tt:6384.367\n",
      "Ep:188, loss:0.00000, loss_test:0.01931, lr:1.56e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.959, tt:6418.220\n",
      "Ep:189, loss:0.00000, loss_test:0.01935, lr:1.54e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.961, tt:6452.533\n",
      "Ep:190, loss:0.00000, loss_test:0.01936, lr:1.53e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.974, tt:6489.062\n",
      "Ep:191, loss:0.00000, loss_test:0.01938, lr:1.51e-02, fs:0.74074 (r=0.606,p=0.952),  time:33.996, tt:6527.157\n",
      "Ep:192, loss:0.00000, loss_test:0.01941, lr:1.50e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.013, tt:6564.589\n",
      "Ep:193, loss:0.00000, loss_test:0.01941, lr:1.48e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.037, tt:6603.160\n",
      "Ep:194, loss:0.00000, loss_test:0.01943, lr:1.47e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.063, tt:6642.237\n",
      "Ep:195, loss:0.00000, loss_test:0.01945, lr:1.45e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.072, tt:6678.077\n",
      "Ep:196, loss:0.00000, loss_test:0.01945, lr:1.44e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.082, tt:6714.085\n",
      "Ep:197, loss:0.00000, loss_test:0.01948, lr:1.43e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.087, tt:6749.316\n",
      "Ep:198, loss:0.00000, loss_test:0.01949, lr:1.41e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.090, tt:6783.988\n",
      "Ep:199, loss:0.00000, loss_test:0.01950, lr:1.40e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.097, tt:6819.467\n",
      "Ep:200, loss:0.00000, loss_test:0.01952, lr:1.38e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.101, tt:6854.220\n",
      "Ep:201, loss:0.00000, loss_test:0.01953, lr:1.37e-02, fs:0.74074 (r=0.606,p=0.952),  time:34.110, tt:6890.218\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13877, lr:1.00e-02, fs:0.65724 (r=0.939,p=0.505),  time:27.386, tt:27.386\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13734, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:29.328, tt:58.656\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13565, lr:1.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:31.146, tt:93.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00027, loss_test:0.13385, lr:1.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:30.398, tt:121.592\n",
      "Ep:4, loss:0.00026, loss_test:0.13200, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:30.484, tt:152.422\n",
      "Ep:5, loss:0.00026, loss_test:0.13057, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:31.244, tt:187.464\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12932, lr:1.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:32.052, tt:224.361\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.12798, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:32.491, tt:259.930\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.12661, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:32.932, tt:296.387\n",
      "Ep:9, loss:0.00025, loss_test:0.12553, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:33.166, tt:331.658\n",
      "Ep:10, loss:0.00025, loss_test:0.12461, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:33.489, tt:368.383\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.12373, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:33.684, tt:404.212\n",
      "Ep:12, loss:0.00025, loss_test:0.12289, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:33.914, tt:440.879\n",
      "Ep:13, loss:0.00025, loss_test:0.12207, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.043, tt:476.602\n",
      "Ep:14, loss:0.00024, loss_test:0.12120, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.138, tt:512.074\n",
      "Ep:15, loss:0.00024, loss_test:0.12015, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:34.163, tt:546.610\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.11902, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:34.315, tt:583.355\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.11782, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:34.620, tt:623.156\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00024, loss_test:0.11658, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:34.662, tt:658.571\n",
      "Ep:19, loss:0.00023, loss_test:0.11519, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:34.748, tt:694.964\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.11362, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.866, tt:732.191\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.11226, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.937, tt:768.621\n",
      "Ep:22, loss:0.00022, loss_test:0.11095, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:35.008, tt:805.186\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00022, loss_test:0.10984, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:35.033, tt:840.797\n",
      "Ep:24, loss:0.00022, loss_test:0.10826, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:35.054, tt:876.341\n",
      "Ep:25, loss:0.00021, loss_test:0.10671, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:35.066, tt:911.721\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00021, loss_test:0.10504, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:35.110, tt:947.969\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00021, loss_test:0.10316, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:35.127, tt:983.570\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00020, loss_test:0.10114, lr:1.00e-02, fs:0.73469 (r=0.909,p=0.616),  time:35.133, tt:1018.871\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00020, loss_test:0.09895, lr:1.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:35.189, tt:1055.682\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00019, loss_test:0.09673, lr:1.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:35.197, tt:1091.110\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00018, loss_test:0.09414, lr:1.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:35.246, tt:1127.888\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.09200, lr:1.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:35.308, tt:1165.160\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00017, loss_test:0.09024, lr:1.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:35.299, tt:1200.164\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00016, loss_test:0.08877, lr:1.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:35.344, tt:1237.024\n",
      "Ep:35, loss:0.00015, loss_test:0.08716, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:35.317, tt:1271.399\n",
      "Ep:36, loss:0.00015, loss_test:0.08637, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:35.354, tt:1308.097\n",
      "Ep:37, loss:0.00014, loss_test:0.08487, lr:1.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:35.342, tt:1342.999\n",
      "Ep:38, loss:0.00013, loss_test:0.08424, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:35.341, tt:1378.309\n",
      "Ep:39, loss:0.00012, loss_test:0.08303, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:35.351, tt:1414.022\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00012, loss_test:0.08661, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:35.352, tt:1449.416\n",
      "Ep:41, loss:0.00011, loss_test:0.08031, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:35.328, tt:1483.788\n",
      "Ep:42, loss:0.00011, loss_test:0.07753, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:35.349, tt:1519.991\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.08661, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:35.372, tt:1556.379\n",
      "Ep:44, loss:0.00010, loss_test:0.07395, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:35.377, tt:1591.974\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.07877, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:35.414, tt:1629.044\n",
      "Ep:46, loss:0.00009, loss_test:0.08025, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:35.410, tt:1664.280\n",
      "Ep:47, loss:0.00008, loss_test:0.07360, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:35.460, tt:1702.102\n",
      "Ep:48, loss:0.00008, loss_test:0.08257, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:35.490, tt:1738.996\n",
      "Ep:49, loss:0.00007, loss_test:0.07462, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:35.516, tt:1775.816\n",
      "Ep:50, loss:0.00007, loss_test:0.08028, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:35.521, tt:1811.576\n",
      "Ep:51, loss:0.00006, loss_test:0.07424, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.546, tt:1848.382\n",
      "Ep:52, loss:0.00006, loss_test:0.07613, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:35.564, tt:1884.897\n",
      "Ep:53, loss:0.00006, loss_test:0.07642, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.570, tt:1920.758\n",
      "Ep:54, loss:0.00005, loss_test:0.07753, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:35.589, tt:1957.407\n",
      "Ep:55, loss:0.00005, loss_test:0.08124, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.593, tt:1993.235\n",
      "Ep:56, loss:0.00005, loss_test:0.08021, lr:9.90e-03, fs:0.81319 (r=0.747,p=0.892),  time:35.579, tt:2028.008\n",
      "Ep:57, loss:0.00005, loss_test:0.07441, lr:9.80e-03, fs:0.80874 (r=0.747,p=0.881),  time:35.574, tt:2063.275\n",
      "Ep:58, loss:0.00004, loss_test:0.07965, lr:9.70e-03, fs:0.82609 (r=0.768,p=0.894),  time:35.572, tt:2098.727\n",
      "Ep:59, loss:0.00004, loss_test:0.07351, lr:9.61e-03, fs:0.80874 (r=0.747,p=0.881),  time:35.613, tt:2136.756\n",
      "Ep:60, loss:0.00004, loss_test:0.07990, lr:9.51e-03, fs:0.81768 (r=0.747,p=0.902),  time:35.637, tt:2173.835\n",
      "Ep:61, loss:0.00004, loss_test:0.08122, lr:9.41e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.660, tt:2210.943\n",
      "Ep:62, loss:0.00003, loss_test:0.07915, lr:9.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.663, tt:2246.748\n",
      "Ep:63, loss:0.00003, loss_test:0.08427, lr:9.23e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.656, tt:2281.956\n",
      "Ep:64, loss:0.00003, loss_test:0.07766, lr:9.14e-03, fs:0.83146 (r=0.747,p=0.937),  time:35.673, tt:2318.774\n",
      "Ep:65, loss:0.00003, loss_test:0.08054, lr:9.04e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.668, tt:2354.066\n",
      "Ep:66, loss:0.00003, loss_test:0.08359, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:35.668, tt:2389.765\n",
      "Ep:67, loss:0.00003, loss_test:0.07804, lr:8.86e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.668, tt:2425.443\n",
      "Ep:68, loss:0.00003, loss_test:0.08478, lr:8.78e-03, fs:0.84270 (r=0.758,p=0.949),  time:35.659, tt:2460.460\n",
      "Ep:69, loss:0.00003, loss_test:0.08122, lr:8.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.671, tt:2496.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00002, loss_test:0.08319, lr:8.60e-03, fs:0.83616 (r=0.747,p=0.949),  time:35.691, tt:2534.078\n",
      "Ep:71, loss:0.00002, loss_test:0.08335, lr:8.51e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.706, tt:2570.817\n",
      "Ep:72, loss:0.00002, loss_test:0.08268, lr:8.43e-03, fs:0.83429 (r=0.737,p=0.961),  time:35.704, tt:2606.420\n",
      "Ep:73, loss:0.00002, loss_test:0.08497, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.680, tt:2640.355\n",
      "Ep:74, loss:0.00002, loss_test:0.08557, lr:8.26e-03, fs:0.83429 (r=0.737,p=0.961),  time:35.681, tt:2676.076\n",
      "Ep:75, loss:0.00002, loss_test:0.08202, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.680, tt:2711.700\n",
      "Ep:76, loss:0.00002, loss_test:0.08855, lr:8.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.674, tt:2746.871\n",
      "Ep:77, loss:0.00002, loss_test:0.08827, lr:8.02e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.686, tt:2783.533\n",
      "Ep:78, loss:0.00002, loss_test:0.08666, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.699, tt:2820.194\n",
      "Ep:79, loss:0.00002, loss_test:0.08417, lr:7.86e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.692, tt:2855.398\n",
      "Ep:80, loss:0.00002, loss_test:0.08915, lr:7.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.663, tt:2888.722\n",
      "Ep:81, loss:0.00002, loss_test:0.08404, lr:7.70e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.659, tt:2924.040\n",
      "Ep:82, loss:0.00002, loss_test:0.08993, lr:7.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.665, tt:2960.231\n",
      "Ep:83, loss:0.00002, loss_test:0.08577, lr:7.55e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.646, tt:2994.226\n",
      "Ep:84, loss:0.00002, loss_test:0.08934, lr:7.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:35.641, tt:3029.497\n",
      "Ep:85, loss:0.00002, loss_test:0.09293, lr:7.40e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.625, tt:3063.756\n",
      "Ep:86, loss:0.00002, loss_test:0.08879, lr:7.32e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.612, tt:3098.209\n",
      "Ep:87, loss:0.00002, loss_test:0.09235, lr:7.25e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.615, tt:3134.077\n",
      "Ep:88, loss:0.00001, loss_test:0.08605, lr:7.18e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.597, tt:3168.124\n",
      "Ep:89, loss:0.00001, loss_test:0.09325, lr:7.11e-03, fs:0.84571 (r=0.747,p=0.974),  time:35.599, tt:3203.905\n",
      "Ep:90, loss:0.00001, loss_test:0.08860, lr:7.03e-03, fs:0.84091 (r=0.747,p=0.961),  time:35.605, tt:3240.044\n",
      "Ep:91, loss:0.00001, loss_test:0.09190, lr:6.96e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.594, tt:3274.693\n",
      "Ep:92, loss:0.00001, loss_test:0.09621, lr:6.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.597, tt:3310.529\n",
      "Ep:93, loss:0.00001, loss_test:0.08786, lr:6.83e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.601, tt:3346.488\n",
      "Ep:94, loss:0.00001, loss_test:0.09309, lr:6.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.619, tt:3383.824\n",
      "Ep:95, loss:0.00001, loss_test:0.09176, lr:6.69e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.638, tt:3421.230\n",
      "Ep:96, loss:0.00001, loss_test:0.09003, lr:6.62e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.639, tt:3456.938\n",
      "Ep:97, loss:0.00001, loss_test:0.09459, lr:6.56e-03, fs:0.84746 (r=0.758,p=0.962),  time:35.668, tt:3495.489\n",
      "Ep:98, loss:0.00001, loss_test:0.09835, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.674, tt:3531.689\n",
      "Ep:99, loss:0.00001, loss_test:0.09378, lr:6.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:35.669, tt:3566.866\n",
      "Ep:100, loss:0.00001, loss_test:0.09537, lr:6.36e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.667, tt:3602.385\n",
      "Ep:101, loss:0.00001, loss_test:0.09227, lr:6.30e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.681, tt:3639.420\n",
      "Ep:102, loss:0.00001, loss_test:0.09541, lr:6.24e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.688, tt:3675.838\n",
      "##########Best model found so far##########\n",
      "Ep:103, loss:0.00001, loss_test:0.09347, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.748, tt:3717.822\n",
      "Ep:104, loss:0.00001, loss_test:0.09515, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:35.771, tt:3756.001\n",
      "Ep:105, loss:0.00001, loss_test:0.09543, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.798, tt:3794.600\n",
      "Ep:106, loss:0.00001, loss_test:0.09407, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.818, tt:3832.549\n",
      "Ep:107, loss:0.00001, loss_test:0.09618, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.827, tt:3869.285\n",
      "Ep:108, loss:0.00001, loss_test:0.09605, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.833, tt:3905.744\n",
      "Ep:109, loss:0.00001, loss_test:0.09722, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.854, tt:3943.906\n",
      "Ep:110, loss:0.00001, loss_test:0.10054, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.848, tt:3979.115\n",
      "Ep:111, loss:0.00001, loss_test:0.09497, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.847, tt:4014.906\n",
      "Ep:112, loss:0.00001, loss_test:0.09740, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.834, tt:4049.234\n",
      "Ep:113, loss:0.00001, loss_test:0.09799, lr:6.24e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.828, tt:4084.389\n",
      "Ep:114, loss:0.00001, loss_test:0.09368, lr:6.17e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.836, tt:4121.138\n",
      "Ep:115, loss:0.00001, loss_test:0.09572, lr:6.11e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.834, tt:4156.722\n",
      "Ep:116, loss:0.00001, loss_test:0.09702, lr:6.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.832, tt:4192.402\n",
      "Ep:117, loss:0.00001, loss_test:0.09709, lr:5.99e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.833, tt:4228.257\n",
      "Ep:118, loss:0.00001, loss_test:0.09598, lr:5.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.836, tt:4264.498\n",
      "Ep:119, loss:0.00001, loss_test:0.09652, lr:5.87e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.846, tt:4301.549\n",
      "Ep:120, loss:0.00001, loss_test:0.09472, lr:5.81e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.843, tt:4337.060\n",
      "Ep:121, loss:0.00001, loss_test:0.09827, lr:5.75e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.840, tt:4372.430\n",
      "Ep:122, loss:0.00001, loss_test:0.09720, lr:5.70e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.841, tt:4408.409\n",
      "Ep:123, loss:0.00001, loss_test:0.09577, lr:5.64e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.836, tt:4443.666\n",
      "Ep:124, loss:0.00001, loss_test:0.09610, lr:5.58e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.832, tt:4478.951\n",
      "Ep:125, loss:0.00001, loss_test:0.09639, lr:5.53e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.832, tt:4514.840\n",
      "Ep:126, loss:0.00000, loss_test:0.09352, lr:5.47e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.832, tt:4550.668\n",
      "Ep:127, loss:0.00000, loss_test:0.09634, lr:5.42e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.828, tt:4585.998\n",
      "Ep:128, loss:0.00000, loss_test:0.09737, lr:5.36e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.833, tt:4622.442\n",
      "Ep:129, loss:0.00000, loss_test:0.09677, lr:5.31e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.829, tt:4657.782\n",
      "Ep:130, loss:0.00000, loss_test:0.09891, lr:5.26e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.825, tt:4693.075\n",
      "Ep:131, loss:0.00000, loss_test:0.09518, lr:5.20e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.825, tt:4728.961\n",
      "Ep:132, loss:0.00000, loss_test:0.09448, lr:5.15e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.826, tt:4764.870\n",
      "Ep:133, loss:0.00000, loss_test:0.09568, lr:5.10e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.831, tt:4801.294\n",
      "Ep:134, loss:0.00000, loss_test:0.09676, lr:5.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.830, tt:4837.064\n",
      "Ep:135, loss:0.00000, loss_test:0.09526, lr:5.00e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.833, tt:4873.256\n",
      "Ep:136, loss:0.00000, loss_test:0.09824, lr:4.95e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.856, tt:4912.247\n",
      "Ep:137, loss:0.00000, loss_test:0.09634, lr:4.90e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.853, tt:4947.779\n",
      "Ep:138, loss:0.00000, loss_test:0.09552, lr:4.85e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.857, tt:4984.057\n",
      "Ep:139, loss:0.00000, loss_test:0.09860, lr:4.80e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.852, tt:5019.331\n",
      "Ep:140, loss:0.00000, loss_test:0.09896, lr:4.75e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.861, tt:5056.347\n",
      "Ep:141, loss:0.00000, loss_test:0.09610, lr:4.71e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.865, tt:5092.824\n",
      "Ep:142, loss:0.00000, loss_test:0.09788, lr:4.66e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.857, tt:5127.613\n",
      "Ep:143, loss:0.00000, loss_test:0.10149, lr:4.61e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.868, tt:5164.952\n",
      "Ep:144, loss:0.00000, loss_test:0.09840, lr:4.57e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.867, tt:5200.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:145, loss:0.00000, loss_test:0.09496, lr:4.52e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.864, tt:5236.089\n",
      "Ep:146, loss:0.00000, loss_test:0.09598, lr:4.48e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.864, tt:5272.045\n",
      "Ep:147, loss:0.00000, loss_test:0.09664, lr:4.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.862, tt:5307.504\n",
      "Ep:148, loss:0.00000, loss_test:0.09526, lr:4.39e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.852, tt:5341.936\n",
      "Ep:149, loss:0.00000, loss_test:0.09576, lr:4.34e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.849, tt:5377.312\n",
      "Ep:150, loss:0.00000, loss_test:0.09947, lr:4.30e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.844, tt:5412.420\n",
      "Ep:151, loss:0.00000, loss_test:0.09773, lr:4.26e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.847, tt:5448.717\n",
      "Ep:152, loss:0.00000, loss_test:0.09540, lr:4.21e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.843, tt:5483.965\n",
      "Ep:153, loss:0.00000, loss_test:0.09730, lr:4.17e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.840, tt:5519.304\n",
      "Ep:156, loss:0.00000, loss_test:0.09439, lr:4.05e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.835, tt:5626.085\n",
      "Ep:157, loss:0.00000, loss_test:0.09568, lr:4.01e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.831, tt:5661.243\n",
      "Ep:158, loss:0.00000, loss_test:0.09567, lr:3.97e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.817, tt:5694.937\n",
      "Ep:159, loss:0.00000, loss_test:0.09523, lr:3.93e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.807, tt:5729.186\n",
      "Ep:160, loss:0.00000, loss_test:0.09526, lr:3.89e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.820, tt:5767.043\n",
      "Ep:161, loss:0.00000, loss_test:0.09508, lr:3.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.814, tt:5801.814\n",
      "Ep:162, loss:0.00000, loss_test:0.09543, lr:3.81e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.805, tt:5836.234\n",
      "Ep:163, loss:0.00000, loss_test:0.09587, lr:3.77e-03, fs:0.82558 (r=0.717,p=0.973),  time:35.802, tt:5871.457\n",
      "Ep:164, loss:0.00000, loss_test:0.09551, lr:3.73e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.802, tt:5907.409\n",
      "Ep:165, loss:0.00000, loss_test:0.09603, lr:3.70e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.796, tt:5942.155\n",
      "Ep:166, loss:0.00000, loss_test:0.09487, lr:3.66e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.799, tt:5978.443\n",
      "Ep:167, loss:0.00000, loss_test:0.09475, lr:3.62e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.796, tt:6013.660\n",
      "Ep:168, loss:0.00000, loss_test:0.09563, lr:3.59e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.795, tt:6049.366\n",
      "Ep:169, loss:0.00000, loss_test:0.09544, lr:3.55e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.786, tt:6083.685\n",
      "Ep:170, loss:0.00000, loss_test:0.09491, lr:3.52e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.779, tt:6118.231\n",
      "Ep:171, loss:0.00000, loss_test:0.09492, lr:3.48e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.772, tt:6152.856\n",
      "Ep:172, loss:0.00000, loss_test:0.09621, lr:3.45e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.773, tt:6188.709\n",
      "Ep:173, loss:0.00000, loss_test:0.09664, lr:3.41e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.767, tt:6223.544\n",
      "Ep:174, loss:0.00000, loss_test:0.09540, lr:3.38e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.764, tt:6258.788\n",
      "Ep:175, loss:0.00000, loss_test:0.09534, lr:3.34e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.758, tt:6293.320\n",
      "Ep:176, loss:0.00000, loss_test:0.09569, lr:3.31e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.758, tt:6329.093\n",
      "Ep:177, loss:0.00000, loss_test:0.09479, lr:3.28e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.742, tt:6362.145\n",
      "Ep:178, loss:0.00000, loss_test:0.09424, lr:3.24e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.738, tt:6397.072\n",
      "Ep:179, loss:0.00000, loss_test:0.09601, lr:3.21e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.727, tt:6430.932\n",
      "Ep:180, loss:0.00000, loss_test:0.09744, lr:3.18e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.721, tt:6465.459\n",
      "Ep:181, loss:0.00000, loss_test:0.09707, lr:3.15e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.712, tt:6499.534\n",
      "Ep:182, loss:0.00000, loss_test:0.09552, lr:3.12e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.708, tt:6534.483\n",
      "Ep:183, loss:0.00000, loss_test:0.09618, lr:3.09e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.701, tt:6568.968\n",
      "Ep:184, loss:0.00000, loss_test:0.09629, lr:3.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.709, tt:6606.137\n",
      "Ep:185, loss:0.00000, loss_test:0.09558, lr:3.02e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.707, tt:6641.484\n",
      "Ep:186, loss:0.00000, loss_test:0.09500, lr:2.99e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.698, tt:6675.437\n",
      "Ep:187, loss:0.00000, loss_test:0.09452, lr:2.96e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.703, tt:6712.121\n",
      "Ep:188, loss:0.00000, loss_test:0.09543, lr:2.93e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.700, tt:6747.337\n",
      "Ep:189, loss:0.00000, loss_test:0.09583, lr:2.90e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.695, tt:6782.136\n",
      "Ep:190, loss:0.00000, loss_test:0.09511, lr:2.88e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.692, tt:6817.174\n",
      "Ep:191, loss:0.00000, loss_test:0.09528, lr:2.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.688, tt:6852.140\n",
      "Ep:192, loss:0.00000, loss_test:0.09539, lr:2.82e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.693, tt:6888.828\n",
      "Ep:193, loss:0.00000, loss_test:0.09496, lr:2.79e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.688, tt:6923.528\n",
      "Ep:194, loss:0.00000, loss_test:0.09495, lr:2.76e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.688, tt:6959.161\n",
      "Ep:195, loss:0.00000, loss_test:0.09501, lr:2.73e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.691, tt:6995.356\n",
      "Ep:196, loss:0.00000, loss_test:0.09508, lr:2.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.691, tt:7031.080\n",
      "Ep:197, loss:0.00000, loss_test:0.09556, lr:2.68e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.690, tt:7066.563\n",
      "Ep:198, loss:0.00000, loss_test:0.09569, lr:2.65e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.692, tt:7102.684\n",
      "Ep:199, loss:0.00000, loss_test:0.09524, lr:2.63e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.696, tt:7139.101\n",
      "Ep:200, loss:0.00000, loss_test:0.09504, lr:2.60e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.696, tt:7174.823\n",
      "Ep:201, loss:0.00000, loss_test:0.09526, lr:2.57e-03, fs:0.83041 (r=0.717,p=0.986),  time:35.691, tt:7209.501\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02573, lr:6.00e-02, fs:0.66383 (r=0.788,p=0.574),  time:23.686, tt:23.686\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02417, lr:6.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:24.014, tt:48.029\n",
      "Ep:2, loss:0.00005, loss_test:0.02656, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.886, tt:71.659\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02684, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.766, tt:95.064\n",
      "Ep:4, loss:0.00005, loss_test:0.02643, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:23.385, tt:116.926\n",
      "Ep:5, loss:0.00005, loss_test:0.02578, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:23.563, tt:141.378\n",
      "Ep:6, loss:0.00005, loss_test:0.02523, lr:6.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:23.907, tt:167.350\n",
      "Ep:7, loss:0.00005, loss_test:0.02484, lr:6.00e-02, fs:0.65185 (r=0.889,p=0.515),  time:24.854, tt:198.835\n",
      "Ep:8, loss:0.00005, loss_test:0.02454, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:25.425, tt:228.827\n",
      "Ep:9, loss:0.00005, loss_test:0.02425, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:25.844, tt:258.440\n",
      "Ep:10, loss:0.00005, loss_test:0.02393, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:26.188, tt:288.067\n",
      "Ep:11, loss:0.00005, loss_test:0.02362, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:26.554, tt:318.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00004, loss_test:0.02329, lr:6.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:26.888, tt:349.550\n",
      "Ep:13, loss:0.00004, loss_test:0.02305, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:27.100, tt:379.405\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02277, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:27.263, tt:408.942\n",
      "Ep:15, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:27.453, tt:439.243\n",
      "Ep:16, loss:0.00004, loss_test:0.02229, lr:6.00e-02, fs:0.66923 (r=0.879,p=0.540),  time:27.647, tt:470.003\n",
      "Ep:17, loss:0.00004, loss_test:0.02205, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:27.814, tt:500.647\n",
      "Ep:18, loss:0.00004, loss_test:0.02183, lr:6.00e-02, fs:0.67181 (r=0.879,p=0.544),  time:27.883, tt:529.780\n",
      "Ep:19, loss:0.00004, loss_test:0.02160, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:27.974, tt:559.480\n",
      "Ep:20, loss:0.00004, loss_test:0.02138, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:28.027, tt:588.562\n",
      "Ep:21, loss:0.00004, loss_test:0.02120, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:28.070, tt:617.549\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.02101, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:28.186, tt:648.284\n",
      "Ep:23, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:28.305, tt:679.331\n",
      "Ep:24, loss:0.00004, loss_test:0.02064, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:28.371, tt:709.286\n",
      "Ep:25, loss:0.00004, loss_test:0.02044, lr:6.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:28.493, tt:740.823\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:28.558, tt:771.063\n",
      "Ep:27, loss:0.00004, loss_test:0.01984, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:28.614, tt:801.184\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:28.653, tt:830.951\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00004, loss_test:0.01919, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:28.708, tt:861.243\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01886, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:28.815, tt:893.256\n",
      "Ep:31, loss:0.00003, loss_test:0.01850, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:28.860, tt:923.527\n",
      "Ep:32, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:28.871, tt:952.727\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01789, lr:6.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:28.930, tt:983.603\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01754, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:28.962, tt:1013.654\n",
      "Ep:35, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:29.034, tt:1045.215\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:29.086, tt:1076.188\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:29.120, tt:1106.561\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:29.169, tt:1137.585\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:29.208, tt:1168.330\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:29.270, tt:1200.062\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:29.268, tt:1229.254\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.266, tt:1258.436\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01475, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:29.278, tt:1288.229\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01457, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:29.281, tt:1317.627\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01431, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:29.277, tt:1346.757\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:29.274, tt:1375.902\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01395, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:29.269, tt:1404.903\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:29.270, tt:1434.222\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:29.280, tt:1463.998\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:29.301, tt:1494.348\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:29.335, tt:1525.415\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:29.333, tt:1554.668\n",
      "Ep:53, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:29.352, tt:1584.993\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:29.370, tt:1615.361\n",
      "Ep:55, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.84956 (r=0.970,p=0.756),  time:29.401, tt:1646.445\n",
      "Ep:56, loss:0.00001, loss_test:0.01253, lr:6.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:29.428, tt:1677.374\n",
      "Ep:57, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:29.442, tt:1707.659\n",
      "Ep:58, loss:0.00001, loss_test:0.01230, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:29.440, tt:1736.959\n",
      "Ep:59, loss:0.00001, loss_test:0.01226, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:29.446, tt:1766.759\n",
      "Ep:60, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:29.468, tt:1797.525\n",
      "Ep:61, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:29.478, tt:1827.612\n",
      "Ep:62, loss:0.00001, loss_test:0.01225, lr:6.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:29.497, tt:1858.290\n",
      "Ep:63, loss:0.00001, loss_test:0.01240, lr:6.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:29.492, tt:1887.491\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:29.507, tt:1917.933\n",
      "Ep:65, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:29.525, tt:1948.629\n",
      "Ep:66, loss:0.00001, loss_test:0.01284, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.544, tt:1979.471\n",
      "Ep:67, loss:0.00001, loss_test:0.01317, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:29.549, tt:2009.314\n",
      "Ep:68, loss:0.00001, loss_test:0.01325, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:29.571, tt:2040.372\n",
      "Ep:69, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:29.577, tt:2070.403\n",
      "Ep:70, loss:0.00001, loss_test:0.01367, lr:6.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:29.581, tt:2100.282\n",
      "Ep:71, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:29.591, tt:2130.550\n",
      "Ep:72, loss:0.00001, loss_test:0.01501, lr:6.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:29.593, tt:2160.319\n",
      "Ep:73, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:29.603, tt:2190.643\n",
      "Ep:74, loss:0.00001, loss_test:0.01394, lr:6.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:29.604, tt:2220.327\n",
      "Ep:75, loss:0.00001, loss_test:0.01449, lr:5.94e-02, fs:0.78302 (r=0.838,p=0.735),  time:29.606, tt:2250.079\n",
      "Ep:76, loss:0.00001, loss_test:0.01380, lr:5.88e-02, fs:0.77778 (r=0.778,p=0.778),  time:29.584, tt:2277.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00001, loss_test:0.01460, lr:5.82e-02, fs:0.79227 (r=0.828,p=0.759),  time:29.588, tt:2307.846\n",
      "Ep:78, loss:0.00001, loss_test:0.01392, lr:5.76e-02, fs:0.77157 (r=0.768,p=0.776),  time:29.602, tt:2338.574\n",
      "Ep:79, loss:0.00001, loss_test:0.01382, lr:5.71e-02, fs:0.79412 (r=0.818,p=0.771),  time:29.606, tt:2368.480\n",
      "Ep:80, loss:0.00001, loss_test:0.01439, lr:5.65e-02, fs:0.75648 (r=0.737,p=0.777),  time:29.595, tt:2397.184\n",
      "Ep:81, loss:0.00001, loss_test:0.01419, lr:5.59e-02, fs:0.75000 (r=0.727,p=0.774),  time:29.591, tt:2426.448\n",
      "Ep:82, loss:0.00001, loss_test:0.01478, lr:5.54e-02, fs:0.70968 (r=0.667,p=0.759),  time:29.594, tt:2456.335\n",
      "Ep:83, loss:0.00001, loss_test:0.01446, lr:5.48e-02, fs:0.73913 (r=0.687,p=0.800),  time:29.607, tt:2486.971\n",
      "Ep:84, loss:0.00001, loss_test:0.01506, lr:5.43e-02, fs:0.68889 (r=0.626,p=0.765),  time:29.615, tt:2517.296\n",
      "Ep:85, loss:0.00001, loss_test:0.01474, lr:5.37e-02, fs:0.66667 (r=0.596,p=0.756),  time:29.619, tt:2547.231\n",
      "Ep:86, loss:0.00001, loss_test:0.01541, lr:5.32e-02, fs:0.66292 (r=0.596,p=0.747),  time:29.630, tt:2577.777\n",
      "Ep:87, loss:0.00000, loss_test:0.01454, lr:5.27e-02, fs:0.69318 (r=0.616,p=0.792),  time:29.656, tt:2609.722\n",
      "Ep:88, loss:0.00000, loss_test:0.01605, lr:5.21e-02, fs:0.67045 (r=0.596,p=0.766),  time:29.673, tt:2640.875\n",
      "Ep:89, loss:0.00000, loss_test:0.01485, lr:5.16e-02, fs:0.68539 (r=0.616,p=0.772),  time:29.669, tt:2670.245\n",
      "Ep:90, loss:0.00000, loss_test:0.01577, lr:5.11e-02, fs:0.67429 (r=0.596,p=0.776),  time:29.683, tt:2701.130\n",
      "Ep:91, loss:0.00000, loss_test:0.01581, lr:5.06e-02, fs:0.68571 (r=0.606,p=0.789),  time:29.698, tt:2732.198\n",
      "Ep:92, loss:0.00000, loss_test:0.01624, lr:5.01e-02, fs:0.68571 (r=0.606,p=0.789),  time:29.710, tt:2763.049\n",
      "Ep:93, loss:0.00000, loss_test:0.01590, lr:4.96e-02, fs:0.65896 (r=0.576,p=0.770),  time:29.702, tt:2791.949\n",
      "Ep:94, loss:0.00000, loss_test:0.01672, lr:4.91e-02, fs:0.67052 (r=0.586,p=0.784),  time:29.719, tt:2823.297\n",
      "Ep:95, loss:0.00000, loss_test:0.01626, lr:4.86e-02, fs:0.66279 (r=0.576,p=0.781),  time:29.724, tt:2853.469\n",
      "Ep:96, loss:0.00000, loss_test:0.01749, lr:4.81e-02, fs:0.67836 (r=0.586,p=0.806),  time:29.742, tt:2884.953\n",
      "Ep:97, loss:0.00000, loss_test:0.01700, lr:4.76e-02, fs:0.67442 (r=0.586,p=0.795),  time:29.759, tt:2916.406\n",
      "Ep:98, loss:0.00000, loss_test:0.01707, lr:4.71e-02, fs:0.67059 (r=0.576,p=0.803),  time:29.782, tt:2948.431\n",
      "Ep:99, loss:0.00000, loss_test:0.01781, lr:4.67e-02, fs:0.68235 (r=0.586,p=0.817),  time:29.788, tt:2978.788\n",
      "Ep:100, loss:0.00000, loss_test:0.01721, lr:4.62e-02, fs:0.66667 (r=0.576,p=0.792),  time:29.793, tt:3009.099\n",
      "Ep:101, loss:0.00000, loss_test:0.01818, lr:4.57e-02, fs:0.68235 (r=0.586,p=0.817),  time:29.803, tt:3039.919\n",
      "Ep:102, loss:0.00000, loss_test:0.01834, lr:4.53e-02, fs:0.68235 (r=0.586,p=0.817),  time:29.822, tt:3071.639\n",
      "Ep:103, loss:0.00000, loss_test:0.01780, lr:4.48e-02, fs:0.67066 (r=0.566,p=0.824),  time:29.843, tt:3103.630\n",
      "Ep:104, loss:0.00000, loss_test:0.01886, lr:4.44e-02, fs:0.68235 (r=0.586,p=0.817),  time:29.860, tt:3135.263\n",
      "Ep:105, loss:0.00000, loss_test:0.01835, lr:4.39e-02, fs:0.67456 (r=0.576,p=0.814),  time:29.879, tt:3167.144\n",
      "Ep:106, loss:0.00000, loss_test:0.01843, lr:4.35e-02, fs:0.68263 (r=0.576,p=0.838),  time:29.883, tt:3197.481\n",
      "Ep:107, loss:0.00000, loss_test:0.01942, lr:4.31e-02, fs:0.69048 (r=0.586,p=0.841),  time:29.895, tt:3228.637\n",
      "Ep:108, loss:0.00000, loss_test:0.01783, lr:4.26e-02, fs:0.68263 (r=0.576,p=0.838),  time:29.900, tt:3259.059\n",
      "Ep:109, loss:0.00000, loss_test:0.02017, lr:4.22e-02, fs:0.68639 (r=0.586,p=0.829),  time:29.919, tt:3291.110\n",
      "Ep:110, loss:0.00000, loss_test:0.01804, lr:4.18e-02, fs:0.67470 (r=0.566,p=0.836),  time:29.941, tt:3323.406\n",
      "Ep:111, loss:0.00000, loss_test:0.02030, lr:4.14e-02, fs:0.69048 (r=0.586,p=0.841),  time:29.957, tt:3355.134\n",
      "Ep:112, loss:0.00000, loss_test:0.01881, lr:4.10e-02, fs:0.67470 (r=0.566,p=0.836),  time:29.964, tt:3385.966\n",
      "Ep:113, loss:0.00000, loss_test:0.01945, lr:4.05e-02, fs:0.68263 (r=0.576,p=0.838),  time:29.979, tt:3417.598\n",
      "Ep:114, loss:0.00000, loss_test:0.01986, lr:4.01e-02, fs:0.68263 (r=0.576,p=0.838),  time:29.980, tt:3447.753\n",
      "Ep:115, loss:0.00000, loss_test:0.01970, lr:3.97e-02, fs:0.67470 (r=0.566,p=0.836),  time:29.978, tt:3477.450\n",
      "Ep:116, loss:0.00000, loss_test:0.02074, lr:3.93e-02, fs:0.69048 (r=0.586,p=0.841),  time:30.000, tt:3509.958\n",
      "Ep:117, loss:0.00000, loss_test:0.01959, lr:3.89e-02, fs:0.68293 (r=0.566,p=0.862),  time:30.010, tt:3541.122\n",
      "Ep:118, loss:0.00000, loss_test:0.02098, lr:3.86e-02, fs:0.69048 (r=0.586,p=0.841),  time:30.014, tt:3571.696\n",
      "Ep:119, loss:0.00000, loss_test:0.02019, lr:3.82e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.026, tt:3603.064\n",
      "Ep:120, loss:0.00000, loss_test:0.02116, lr:3.78e-02, fs:0.69048 (r=0.586,p=0.841),  time:30.041, tt:3635.011\n",
      "Ep:121, loss:0.00000, loss_test:0.02027, lr:3.74e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.042, tt:3665.116\n",
      "Ep:122, loss:0.00000, loss_test:0.02118, lr:3.70e-02, fs:0.68263 (r=0.576,p=0.838),  time:30.052, tt:3696.382\n",
      "Ep:123, loss:0.00000, loss_test:0.02083, lr:3.67e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.055, tt:3726.856\n",
      "Ep:124, loss:0.00000, loss_test:0.02090, lr:3.63e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.070, tt:3758.713\n",
      "Ep:125, loss:0.00000, loss_test:0.02183, lr:3.59e-02, fs:0.68263 (r=0.576,p=0.838),  time:30.077, tt:3789.661\n",
      "Ep:126, loss:0.00000, loss_test:0.02073, lr:3.56e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.080, tt:3820.133\n",
      "Ep:127, loss:0.00000, loss_test:0.02256, lr:3.52e-02, fs:0.69048 (r=0.586,p=0.841),  time:30.090, tt:3851.584\n",
      "Ep:128, loss:0.00000, loss_test:0.02081, lr:3.49e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.096, tt:3882.417\n",
      "Ep:129, loss:0.00000, loss_test:0.02271, lr:3.45e-02, fs:0.68263 (r=0.576,p=0.838),  time:30.100, tt:3912.957\n",
      "Ep:130, loss:0.00000, loss_test:0.02117, lr:3.42e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.109, tt:3944.296\n",
      "Ep:131, loss:0.00000, loss_test:0.02273, lr:3.38e-02, fs:0.68263 (r=0.576,p=0.838),  time:30.116, tt:3975.280\n",
      "Ep:132, loss:0.00000, loss_test:0.02138, lr:3.35e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.126, tt:4006.742\n",
      "Ep:133, loss:0.00000, loss_test:0.02281, lr:3.32e-02, fs:0.68675 (r=0.576,p=0.851),  time:30.133, tt:4037.867\n",
      "Ep:134, loss:0.00000, loss_test:0.02219, lr:3.28e-02, fs:0.68293 (r=0.566,p=0.862),  time:30.136, tt:4068.363\n",
      "Ep:135, loss:0.00000, loss_test:0.02259, lr:3.25e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.141, tt:4099.175\n",
      "Ep:136, loss:0.00000, loss_test:0.02254, lr:3.22e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.142, tt:4129.486\n",
      "Ep:137, loss:0.00000, loss_test:0.02270, lr:3.19e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.143, tt:4159.698\n",
      "Ep:138, loss:0.00000, loss_test:0.02270, lr:3.15e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.150, tt:4190.781\n",
      "Ep:139, loss:0.00000, loss_test:0.02290, lr:3.12e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.152, tt:4221.249\n",
      "Ep:140, loss:0.00000, loss_test:0.02289, lr:3.09e-02, fs:0.67879 (r=0.566,p=0.848),  time:30.153, tt:4251.616\n",
      "Ep:141, loss:0.00000, loss_test:0.02313, lr:3.06e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.154, tt:4281.852\n",
      "Ep:142, loss:0.00000, loss_test:0.02307, lr:3.03e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.169, tt:4314.208\n",
      "Ep:143, loss:0.00000, loss_test:0.02353, lr:3.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:30.174, tt:4345.043\n",
      "Ep:144, loss:0.00000, loss_test:0.02346, lr:2.97e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.173, tt:4375.125\n",
      "Ep:145, loss:0.00000, loss_test:0.02383, lr:2.94e-02, fs:0.68293 (r=0.566,p=0.862),  time:30.172, tt:4405.061\n",
      "Ep:146, loss:0.00000, loss_test:0.02352, lr:2.91e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.179, tt:4436.362\n",
      "Ep:147, loss:0.00000, loss_test:0.02401, lr:2.88e-02, fs:0.68293 (r=0.566,p=0.862),  time:30.174, tt:4465.812\n",
      "Ep:148, loss:0.00000, loss_test:0.02377, lr:2.85e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.181, tt:4496.971\n",
      "Ep:149, loss:0.00000, loss_test:0.02425, lr:2.82e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.186, tt:4527.933\n",
      "Ep:150, loss:0.00000, loss_test:0.02396, lr:2.80e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.196, tt:4559.535\n",
      "Ep:151, loss:0.00000, loss_test:0.02445, lr:2.77e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.188, tt:4588.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.02418, lr:2.74e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.185, tt:4618.320\n",
      "Ep:153, loss:0.00000, loss_test:0.02465, lr:2.71e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.190, tt:4649.229\n",
      "Ep:154, loss:0.00000, loss_test:0.02412, lr:2.69e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.185, tt:4678.610\n",
      "Ep:155, loss:0.00000, loss_test:0.02469, lr:2.66e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.194, tt:4710.216\n",
      "Ep:156, loss:0.00000, loss_test:0.02434, lr:2.63e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.196, tt:4740.834\n",
      "Ep:157, loss:0.00000, loss_test:0.02485, lr:2.61e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.196, tt:4770.922\n",
      "Ep:158, loss:0.00000, loss_test:0.02452, lr:2.58e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.188, tt:4799.964\n",
      "Ep:159, loss:0.00000, loss_test:0.02515, lr:2.55e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.172, tt:4827.531\n",
      "Ep:160, loss:0.00000, loss_test:0.02457, lr:2.53e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.177, tt:4858.506\n",
      "Ep:161, loss:0.00000, loss_test:0.02520, lr:2.50e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.171, tt:4887.714\n",
      "Ep:162, loss:0.00000, loss_test:0.02473, lr:2.48e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.168, tt:4917.454\n",
      "Ep:163, loss:0.00000, loss_test:0.02531, lr:2.45e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.167, tt:4947.381\n",
      "Ep:164, loss:0.00000, loss_test:0.02503, lr:2.43e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.157, tt:4975.973\n",
      "Ep:165, loss:0.00000, loss_test:0.02510, lr:2.40e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.161, tt:5006.672\n",
      "Ep:166, loss:0.00000, loss_test:0.02545, lr:2.38e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.157, tt:5036.211\n",
      "Ep:167, loss:0.00000, loss_test:0.02496, lr:2.36e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.148, tt:5064.843\n",
      "Ep:168, loss:0.00000, loss_test:0.02582, lr:2.33e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.150, tt:5095.430\n",
      "Ep:169, loss:0.00000, loss_test:0.02495, lr:2.31e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.146, tt:5124.871\n",
      "Ep:170, loss:0.00000, loss_test:0.02590, lr:2.29e-02, fs:0.68712 (r=0.566,p=0.875),  time:30.147, tt:5155.080\n",
      "Ep:171, loss:0.00000, loss_test:0.02523, lr:2.26e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.140, tt:5184.043\n",
      "Ep:172, loss:0.00000, loss_test:0.02593, lr:2.24e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.142, tt:5214.592\n",
      "Ep:173, loss:0.00000, loss_test:0.02555, lr:2.22e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.137, tt:5243.923\n",
      "Ep:174, loss:0.00000, loss_test:0.02556, lr:2.20e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.140, tt:5274.430\n",
      "Ep:175, loss:0.00000, loss_test:0.02613, lr:2.17e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.132, tt:5303.250\n",
      "Ep:176, loss:0.00000, loss_test:0.02561, lr:2.15e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.121, tt:5331.424\n",
      "Ep:177, loss:0.00000, loss_test:0.02605, lr:2.13e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.123, tt:5361.903\n",
      "Ep:178, loss:0.00000, loss_test:0.02577, lr:2.11e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.129, tt:5393.032\n",
      "Ep:179, loss:0.00000, loss_test:0.02630, lr:2.09e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.124, tt:5422.379\n",
      "Ep:180, loss:0.00000, loss_test:0.02604, lr:2.07e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.110, tt:5449.920\n",
      "Ep:181, loss:0.00000, loss_test:0.02614, lr:2.05e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.101, tt:5478.404\n",
      "Ep:182, loss:0.00000, loss_test:0.02632, lr:2.03e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.105, tt:5509.234\n",
      "Ep:183, loss:0.00000, loss_test:0.02608, lr:2.01e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.099, tt:5538.148\n",
      "Ep:184, loss:0.00000, loss_test:0.02653, lr:1.99e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.102, tt:5568.944\n",
      "Ep:185, loss:0.00000, loss_test:0.02619, lr:1.97e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.103, tt:5599.222\n",
      "Ep:186, loss:0.00000, loss_test:0.02650, lr:1.95e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.102, tt:5629.119\n",
      "Ep:187, loss:0.00000, loss_test:0.02644, lr:1.93e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.096, tt:5658.091\n",
      "Ep:188, loss:0.00000, loss_test:0.02646, lr:1.91e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.091, tt:5687.219\n",
      "Ep:189, loss:0.00000, loss_test:0.02664, lr:1.89e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.095, tt:5717.975\n",
      "Ep:190, loss:0.00000, loss_test:0.02657, lr:1.87e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.096, tt:5748.309\n",
      "Ep:191, loss:0.00000, loss_test:0.02660, lr:1.85e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.089, tt:5777.037\n",
      "Ep:192, loss:0.00000, loss_test:0.02670, lr:1.83e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.083, tt:5806.053\n",
      "Ep:193, loss:0.00000, loss_test:0.02675, lr:1.81e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.083, tt:5836.080\n",
      "Ep:194, loss:0.00000, loss_test:0.02675, lr:1.80e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.078, tt:5865.263\n",
      "Ep:195, loss:0.00000, loss_test:0.02681, lr:1.78e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.081, tt:5895.915\n",
      "Ep:196, loss:0.00000, loss_test:0.02697, lr:1.76e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.075, tt:5924.840\n",
      "Ep:197, loss:0.00000, loss_test:0.02678, lr:1.74e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.078, tt:5955.416\n",
      "Ep:198, loss:0.00000, loss_test:0.02704, lr:1.73e-02, fs:0.69136 (r=0.566,p=0.889),  time:30.078, tt:5985.600\n",
      "Ep:199, loss:0.00000, loss_test:0.02689, lr:1.71e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.080, tt:6016.057\n",
      "Ep:200, loss:0.00000, loss_test:0.02695, lr:1.69e-02, fs:0.69565 (r=0.566,p=0.903),  time:30.076, tt:6045.269\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13172, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:29.663, tt:29.663\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12946, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:28.342, tt:56.685\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12942, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:28.194, tt:84.583\n",
      "Ep:3, loss:0.00026, loss_test:0.13012, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:27.735, tt:110.938\n",
      "Ep:4, loss:0.00026, loss_test:0.12973, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:27.425, tt:137.127\n",
      "Ep:5, loss:0.00026, loss_test:0.12825, lr:1.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:27.038, tt:162.230\n",
      "Ep:6, loss:0.00026, loss_test:0.12684, lr:1.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:27.216, tt:190.513\n",
      "Ep:7, loss:0.00025, loss_test:0.12596, lr:1.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:27.711, tt:221.685\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.12541, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:27.955, tt:251.597\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.12423, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:28.213, tt:282.133\n",
      "Ep:10, loss:0.00025, loss_test:0.12294, lr:1.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:28.497, tt:313.468\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00025, loss_test:0.12195, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:28.881, tt:346.577\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.12097, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:28.946, tt:376.297\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.11996, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.011, tt:406.150\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00024, loss_test:0.11904, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.151, tt:437.265\n",
      "Ep:15, loss:0.00024, loss_test:0.11783, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:29.213, tt:467.401\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.11658, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:29.355, tt:499.031\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.11543, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:29.390, tt:529.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00023, loss_test:0.11364, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:29.433, tt:559.224\n",
      "Ep:19, loss:0.00023, loss_test:0.11170, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:29.513, tt:590.261\n",
      "Ep:20, loss:0.00023, loss_test:0.11042, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:29.618, tt:621.979\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00022, loss_test:0.10960, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:29.630, tt:651.870\n",
      "Ep:22, loss:0.00022, loss_test:0.10864, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:29.642, tt:681.764\n",
      "Ep:23, loss:0.00022, loss_test:0.10724, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:29.698, tt:712.753\n",
      "Ep:24, loss:0.00022, loss_test:0.10625, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:29.727, tt:743.187\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00021, loss_test:0.10537, lr:1.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:29.731, tt:772.998\n",
      "Ep:26, loss:0.00021, loss_test:0.10419, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:29.784, tt:804.166\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00021, loss_test:0.10316, lr:1.00e-02, fs:0.72269 (r=0.869,p=0.619),  time:29.824, tt:835.070\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00021, loss_test:0.10227, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:29.803, tt:864.276\n",
      "Ep:29, loss:0.00020, loss_test:0.10103, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:29.833, tt:894.994\n",
      "Ep:30, loss:0.00020, loss_test:0.10005, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:29.870, tt:925.959\n",
      "Ep:31, loss:0.00020, loss_test:0.09884, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:29.942, tt:958.131\n",
      "Ep:32, loss:0.00019, loss_test:0.09741, lr:1.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:29.987, tt:989.580\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00019, loss_test:0.09591, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:30.022, tt:1020.756\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00019, loss_test:0.09427, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:30.030, tt:1051.043\n",
      "Ep:35, loss:0.00018, loss_test:0.09232, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:30.073, tt:1082.631\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00018, loss_test:0.09023, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:30.051, tt:1111.891\n",
      "Ep:37, loss:0.00017, loss_test:0.08874, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:30.079, tt:1143.019\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00017, loss_test:0.08772, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:30.060, tt:1172.323\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00017, loss_test:0.08501, lr:1.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:30.105, tt:1204.215\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00016, loss_test:0.08510, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:30.142, tt:1235.815\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00016, loss_test:0.08286, lr:1.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:30.159, tt:1266.668\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00016, loss_test:0.08477, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:30.188, tt:1298.078\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00015, loss_test:0.08290, lr:1.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:30.186, tt:1328.166\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00015, loss_test:0.08083, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:30.201, tt:1359.052\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00014, loss_test:0.08362, lr:1.00e-02, fs:0.76793 (r=0.919,p=0.659),  time:30.248, tt:1391.399\n",
      "Ep:46, loss:0.00014, loss_test:0.07902, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.282, tt:1423.234\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00013, loss_test:0.07632, lr:1.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:30.296, tt:1454.213\n",
      "Ep:48, loss:0.00013, loss_test:0.07382, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:30.306, tt:1484.985\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00012, loss_test:0.07256, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:30.306, tt:1515.298\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00011, loss_test:0.07377, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.300, tt:1545.323\n",
      "Ep:51, loss:0.00012, loss_test:0.07670, lr:1.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:30.297, tt:1575.464\n",
      "Ep:52, loss:0.00011, loss_test:0.07192, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:30.298, tt:1605.787\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00011, loss_test:0.06916, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:30.299, tt:1636.141\n",
      "Ep:54, loss:0.00010, loss_test:0.06588, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:30.310, tt:1667.030\n",
      "Ep:55, loss:0.00010, loss_test:0.06776, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:30.316, tt:1697.690\n",
      "Ep:56, loss:0.00009, loss_test:0.06778, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:30.316, tt:1727.995\n",
      "Ep:57, loss:0.00009, loss_test:0.06812, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:30.325, tt:1758.858\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00009, loss_test:0.06648, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.349, tt:1790.604\n",
      "Ep:59, loss:0.00009, loss_test:0.06202, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.355, tt:1821.294\n",
      "Ep:60, loss:0.00008, loss_test:0.06482, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.357, tt:1851.764\n",
      "Ep:61, loss:0.00008, loss_test:0.06117, lr:1.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:30.380, tt:1883.589\n",
      "Ep:62, loss:0.00007, loss_test:0.06571, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:30.388, tt:1914.459\n",
      "Ep:63, loss:0.00007, loss_test:0.06070, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:30.418, tt:1946.755\n",
      "Ep:64, loss:0.00007, loss_test:0.06427, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.448, tt:1979.127\n",
      "Ep:65, loss:0.00007, loss_test:0.05729, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:30.470, tt:2011.003\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.06312, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.495, tt:2043.175\n",
      "Ep:67, loss:0.00006, loss_test:0.06096, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:30.503, tt:2074.177\n",
      "Ep:68, loss:0.00006, loss_test:0.06321, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.511, tt:2105.266\n",
      "Ep:69, loss:0.00005, loss_test:0.05676, lr:1.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:30.512, tt:2135.842\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.06050, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.515, tt:2166.563\n",
      "Ep:71, loss:0.00005, loss_test:0.06443, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.521, tt:2197.491\n",
      "Ep:72, loss:0.00005, loss_test:0.06064, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:30.524, tt:2228.230\n",
      "Ep:73, loss:0.00005, loss_test:0.05925, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.525, tt:2258.850\n",
      "Ep:74, loss:0.00005, loss_test:0.06177, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.529, tt:2289.641\n",
      "Ep:75, loss:0.00004, loss_test:0.06492, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:30.554, tt:2322.089\n",
      "Ep:76, loss:0.00004, loss_test:0.06364, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.555, tt:2352.771\n",
      "Ep:77, loss:0.00004, loss_test:0.06297, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.566, tt:2384.183\n",
      "Ep:78, loss:0.00004, loss_test:0.06409, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:30.603, tt:2417.674\n",
      "Ep:79, loss:0.00003, loss_test:0.06453, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.614, tt:2449.101\n",
      "Ep:80, loss:0.00003, loss_test:0.06166, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:30.604, tt:2478.930\n",
      "Ep:81, loss:0.00003, loss_test:0.06800, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.620, tt:2510.866\n",
      "Ep:82, loss:0.00003, loss_test:0.06357, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.636, tt:2542.808\n",
      "Ep:83, loss:0.00003, loss_test:0.06497, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.634, tt:2573.276\n",
      "Ep:84, loss:0.00003, loss_test:0.06877, lr:9.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:30.627, tt:2603.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:85, loss:0.00003, loss_test:0.06592, lr:9.51e-03, fs:0.81564 (r=0.737,p=0.912),  time:30.639, tt:2634.972\n",
      "Ep:86, loss:0.00003, loss_test:0.07435, lr:9.41e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.634, tt:2665.161\n",
      "Ep:87, loss:0.00003, loss_test:0.06675, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:30.636, tt:2695.945\n",
      "Ep:88, loss:0.00003, loss_test:0.07090, lr:9.23e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.650, tt:2727.843\n",
      "Ep:89, loss:0.00003, loss_test:0.07022, lr:9.14e-03, fs:0.83616 (r=0.747,p=0.949),  time:30.646, tt:2758.118\n",
      "Ep:90, loss:0.00003, loss_test:0.06383, lr:9.04e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.658, tt:2789.839\n",
      "Ep:91, loss:0.00002, loss_test:0.07363, lr:8.95e-03, fs:0.84270 (r=0.758,p=0.949),  time:30.670, tt:2821.597\n",
      "Ep:92, loss:0.00002, loss_test:0.06811, lr:8.86e-03, fs:0.83799 (r=0.758,p=0.938),  time:30.684, tt:2853.639\n",
      "Ep:93, loss:0.00002, loss_test:0.06827, lr:8.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.688, tt:2884.707\n",
      "Ep:94, loss:0.00002, loss_test:0.06769, lr:8.69e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.683, tt:2914.871\n",
      "Ep:95, loss:0.00002, loss_test:0.06999, lr:8.60e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.696, tt:2946.863\n",
      "Ep:96, loss:0.00002, loss_test:0.06731, lr:8.51e-03, fs:0.84091 (r=0.747,p=0.961),  time:30.699, tt:2977.773\n",
      "Ep:97, loss:0.00002, loss_test:0.07645, lr:8.43e-03, fs:0.79070 (r=0.687,p=0.932),  time:30.703, tt:3008.896\n",
      "Ep:98, loss:0.00002, loss_test:0.06518, lr:8.35e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.720, tt:3041.247\n",
      "Ep:99, loss:0.00002, loss_test:0.07369, lr:8.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:30.734, tt:3073.358\n",
      "Ep:100, loss:0.00002, loss_test:0.06758, lr:8.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.743, tt:3105.037\n",
      "Ep:101, loss:0.00002, loss_test:0.07759, lr:8.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.750, tt:3136.538\n",
      "Ep:102, loss:0.00002, loss_test:0.07289, lr:8.02e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.757, tt:3167.949\n",
      "Ep:103, loss:0.00002, loss_test:0.07615, lr:7.94e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.757, tt:3198.685\n",
      "Ep:104, loss:0.00002, loss_test:0.07512, lr:7.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:30.766, tt:3230.399\n",
      "Ep:105, loss:0.00002, loss_test:0.07241, lr:7.78e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.774, tt:3261.996\n",
      "Ep:106, loss:0.00002, loss_test:0.07148, lr:7.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:30.797, tt:3295.265\n",
      "Ep:107, loss:0.00002, loss_test:0.07817, lr:7.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.786, tt:3324.937\n",
      "Ep:108, loss:0.00002, loss_test:0.07421, lr:7.55e-03, fs:0.74251 (r=0.626,p=0.912),  time:30.788, tt:3355.945\n",
      "Ep:109, loss:0.00002, loss_test:0.08037, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.782, tt:3385.976\n",
      "Ep:110, loss:0.00002, loss_test:0.07781, lr:7.40e-03, fs:0.74390 (r=0.616,p=0.938),  time:30.785, tt:3417.092\n",
      "Ep:111, loss:0.00002, loss_test:0.07646, lr:7.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.784, tt:3447.758\n",
      "Ep:112, loss:0.00001, loss_test:0.07921, lr:7.25e-03, fs:0.75610 (r=0.626,p=0.954),  time:30.786, tt:3478.829\n",
      "Ep:113, loss:0.00001, loss_test:0.07671, lr:7.18e-03, fs:0.83978 (r=0.768,p=0.927),  time:30.783, tt:3509.306\n",
      "Ep:114, loss:0.00001, loss_test:0.08281, lr:7.11e-03, fs:0.75610 (r=0.626,p=0.954),  time:30.787, tt:3540.555\n",
      "Ep:115, loss:0.00001, loss_test:0.08039, lr:7.03e-03, fs:0.84444 (r=0.768,p=0.938),  time:30.787, tt:3571.275\n",
      "Ep:116, loss:0.00001, loss_test:0.08130, lr:6.96e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.788, tt:3602.237\n",
      "Ep:117, loss:0.00001, loss_test:0.08062, lr:6.89e-03, fs:0.82486 (r=0.737,p=0.936),  time:30.790, tt:3633.190\n",
      "Ep:118, loss:0.00001, loss_test:0.08497, lr:6.83e-03, fs:0.81818 (r=0.727,p=0.935),  time:30.794, tt:3664.457\n",
      "Ep:119, loss:0.00001, loss_test:0.08332, lr:6.76e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.797, tt:3695.593\n",
      "Ep:120, loss:0.00001, loss_test:0.08332, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.799, tt:3726.660\n",
      "Ep:121, loss:0.00001, loss_test:0.08215, lr:6.62e-03, fs:0.74699 (r=0.626,p=0.925),  time:30.800, tt:3757.580\n",
      "Ep:122, loss:0.00001, loss_test:0.08156, lr:6.56e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.803, tt:3788.808\n",
      "Ep:123, loss:0.00001, loss_test:0.08366, lr:6.49e-03, fs:0.75152 (r=0.626,p=0.939),  time:30.800, tt:3819.142\n",
      "Ep:124, loss:0.00001, loss_test:0.08195, lr:6.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:30.806, tt:3850.757\n",
      "Ep:125, loss:0.00001, loss_test:0.08587, lr:6.36e-03, fs:0.83429 (r=0.737,p=0.961),  time:30.816, tt:3882.783\n",
      "Ep:126, loss:0.00001, loss_test:0.08056, lr:6.30e-03, fs:0.76364 (r=0.636,p=0.955),  time:30.814, tt:3913.342\n",
      "Ep:127, loss:0.00001, loss_test:0.08511, lr:6.24e-03, fs:0.82955 (r=0.737,p=0.948),  time:30.820, tt:3944.994\n",
      "Ep:128, loss:0.00001, loss_test:0.08373, lr:6.17e-03, fs:0.80240 (r=0.677,p=0.985),  time:30.818, tt:3975.585\n",
      "Ep:129, loss:0.00001, loss_test:0.08589, lr:6.11e-03, fs:0.84916 (r=0.768,p=0.950),  time:30.826, tt:4007.348\n",
      "Ep:130, loss:0.00001, loss_test:0.08302, lr:6.05e-03, fs:0.84746 (r=0.758,p=0.962),  time:30.839, tt:4039.965\n",
      "Ep:131, loss:0.00001, loss_test:0.08522, lr:5.99e-03, fs:0.82286 (r=0.727,p=0.947),  time:30.843, tt:4071.221\n",
      "Ep:132, loss:0.00001, loss_test:0.08326, lr:5.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.848, tt:4102.804\n",
      "Ep:133, loss:0.00001, loss_test:0.08518, lr:5.87e-03, fs:0.84746 (r=0.758,p=0.962),  time:30.858, tt:4135.017\n",
      "Ep:134, loss:0.00001, loss_test:0.08572, lr:5.81e-03, fs:0.85714 (r=0.758,p=0.987),  time:30.847, tt:4164.340\n",
      "Ep:135, loss:0.00001, loss_test:0.08362, lr:5.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.849, tt:4195.423\n",
      "Ep:136, loss:0.00001, loss_test:0.08602, lr:5.70e-03, fs:0.85714 (r=0.758,p=0.987),  time:30.840, tt:4225.026\n",
      "Ep:137, loss:0.00001, loss_test:0.08213, lr:5.64e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.837, tt:4255.486\n",
      "Ep:138, loss:0.00001, loss_test:0.08595, lr:5.58e-03, fs:0.85057 (r=0.747,p=0.987),  time:30.840, tt:4286.691\n",
      "Ep:139, loss:0.00001, loss_test:0.08313, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.835, tt:4316.834\n",
      "Ep:140, loss:0.00001, loss_test:0.08444, lr:5.47e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.827, tt:4346.561\n",
      "Ep:141, loss:0.00001, loss_test:0.08597, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.825, tt:4377.206\n",
      "Ep:142, loss:0.00001, loss_test:0.08376, lr:5.36e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.824, tt:4407.846\n",
      "Ep:143, loss:0.00001, loss_test:0.08675, lr:5.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.815, tt:4437.346\n",
      "Ep:144, loss:0.00001, loss_test:0.08452, lr:5.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.810, tt:4467.508\n",
      "Ep:145, loss:0.00001, loss_test:0.08551, lr:5.20e-03, fs:0.86857 (r=0.768,p=1.000),  time:30.808, tt:4497.977\n",
      "Ep:146, loss:0.00001, loss_test:0.08531, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.803, tt:4528.082\n",
      "Ep:147, loss:0.00001, loss_test:0.08456, lr:5.10e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.803, tt:4558.817\n",
      "Ep:148, loss:0.00001, loss_test:0.08703, lr:5.05e-03, fs:0.83908 (r=0.737,p=0.973),  time:30.809, tt:4590.486\n",
      "Ep:149, loss:0.00001, loss_test:0.08540, lr:5.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.807, tt:4621.030\n",
      "Ep:150, loss:0.00001, loss_test:0.08705, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.820, tt:4653.785\n",
      "Ep:151, loss:0.00001, loss_test:0.08595, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.835, tt:4686.891\n",
      "Ep:152, loss:0.00001, loss_test:0.08416, lr:4.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:30.846, tt:4719.489\n",
      "Ep:153, loss:0.00001, loss_test:0.08562, lr:4.80e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.857, tt:4751.938\n",
      "Ep:154, loss:0.00001, loss_test:0.08650, lr:4.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.846, tt:4781.116\n",
      "Ep:155, loss:0.00001, loss_test:0.08664, lr:4.71e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.832, tt:4809.771\n",
      "Ep:156, loss:0.00001, loss_test:0.08516, lr:4.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.818, tt:4838.495\n",
      "Ep:157, loss:0.00001, loss_test:0.08523, lr:4.61e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.823, tt:4870.067\n",
      "Ep:158, loss:0.00001, loss_test:0.08571, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.823, tt:4900.887\n",
      "Ep:159, loss:0.00001, loss_test:0.08612, lr:4.52e-03, fs:0.85876 (r=0.768,p=0.974),  time:30.817, tt:4930.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:160, loss:0.00000, loss_test:0.08528, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.819, tt:4961.870\n",
      "Ep:161, loss:0.00000, loss_test:0.08431, lr:4.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.810, tt:4991.270\n",
      "Ep:162, loss:0.00000, loss_test:0.08623, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.802, tt:5020.748\n",
      "Ep:163, loss:0.00000, loss_test:0.08622, lr:4.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.804, tt:5051.890\n",
      "Ep:164, loss:0.00000, loss_test:0.08599, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.796, tt:5081.388\n",
      "Ep:165, loss:0.00000, loss_test:0.08722, lr:4.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.800, tt:5112.732\n",
      "Ep:166, loss:0.00000, loss_test:0.08526, lr:4.21e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.801, tt:5143.847\n",
      "Ep:167, loss:0.00000, loss_test:0.08566, lr:4.17e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.799, tt:5174.183\n",
      "Ep:168, loss:0.00000, loss_test:0.08646, lr:4.13e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.797, tt:5204.687\n",
      "Ep:169, loss:0.00000, loss_test:0.08452, lr:4.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.799, tt:5235.913\n",
      "Ep:170, loss:0.00000, loss_test:0.08637, lr:4.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.801, tt:5266.964\n",
      "Ep:171, loss:0.00000, loss_test:0.08602, lr:4.01e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.797, tt:5297.112\n",
      "Ep:172, loss:0.00000, loss_test:0.08476, lr:3.97e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.803, tt:5328.932\n",
      "Ep:173, loss:0.00000, loss_test:0.08630, lr:3.93e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.798, tt:5358.793\n",
      "Ep:174, loss:0.00000, loss_test:0.08661, lr:3.89e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.803, tt:5390.526\n",
      "Ep:175, loss:0.00000, loss_test:0.08566, lr:3.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.812, tt:5422.922\n",
      "Ep:176, loss:0.00000, loss_test:0.08561, lr:3.81e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.819, tt:5454.946\n",
      "Ep:177, loss:0.00000, loss_test:0.08760, lr:3.77e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.830, tt:5487.773\n",
      "Ep:178, loss:0.00000, loss_test:0.08723, lr:3.73e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.840, tt:5520.397\n",
      "Ep:179, loss:0.00000, loss_test:0.08541, lr:3.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.845, tt:5552.184\n",
      "Ep:180, loss:0.00000, loss_test:0.08581, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.853, tt:5584.326\n",
      "Ep:181, loss:0.00000, loss_test:0.08584, lr:3.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.856, tt:5615.766\n",
      "Ep:182, loss:0.00000, loss_test:0.08526, lr:3.59e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.856, tt:5646.711\n",
      "Ep:183, loss:0.00000, loss_test:0.08700, lr:3.55e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.856, tt:5677.569\n",
      "Ep:184, loss:0.00000, loss_test:0.08708, lr:3.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.865, tt:5710.088\n",
      "Ep:185, loss:0.00000, loss_test:0.08500, lr:3.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.865, tt:5740.840\n",
      "Ep:186, loss:0.00000, loss_test:0.08647, lr:3.45e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.866, tt:5772.032\n",
      "Ep:187, loss:0.00000, loss_test:0.08749, lr:3.41e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.871, tt:5803.695\n",
      "Ep:188, loss:0.00000, loss_test:0.08495, lr:3.38e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.877, tt:5835.667\n",
      "Ep:189, loss:0.00000, loss_test:0.08641, lr:3.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.877, tt:5866.723\n",
      "Ep:190, loss:0.00000, loss_test:0.08756, lr:3.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.880, tt:5898.033\n",
      "Ep:191, loss:0.00000, loss_test:0.08768, lr:3.28e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.881, tt:5929.196\n",
      "Ep:192, loss:0.00000, loss_test:0.08646, lr:3.24e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.890, tt:5961.852\n",
      "Ep:193, loss:0.00000, loss_test:0.08608, lr:3.21e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.889, tt:5992.378\n",
      "Ep:194, loss:0.00000, loss_test:0.08641, lr:3.18e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.883, tt:6022.104\n",
      "Ep:195, loss:0.00000, loss_test:0.08720, lr:3.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.888, tt:6053.989\n",
      "Ep:196, loss:0.00000, loss_test:0.08727, lr:3.12e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.885, tt:6084.414\n",
      "Ep:197, loss:0.00000, loss_test:0.08561, lr:3.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.882, tt:6114.734\n",
      "Ep:198, loss:0.00000, loss_test:0.08587, lr:3.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.883, tt:6145.766\n",
      "Ep:199, loss:0.00000, loss_test:0.08771, lr:3.02e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.882, tt:6176.311\n",
      "Ep:200, loss:0.00000, loss_test:0.08627, lr:2.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:30.886, tt:6208.034\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02003, lr:6.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:24.992, tt:24.992\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02233, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.721, tt:47.443\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02424, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.215, tt:69.645\n",
      "Ep:3, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.350, tt:93.400\n",
      "Ep:4, loss:0.00005, loss_test:0.02420, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.822, tt:114.108\n",
      "Ep:5, loss:0.00005, loss_test:0.02308, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.441, tt:140.647\n",
      "Ep:6, loss:0.00004, loss_test:0.02175, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:24.157, tt:169.099\n",
      "Ep:7, loss:0.00004, loss_test:0.02052, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:25.047, tt:200.373\n",
      "Ep:8, loss:0.00004, loss_test:0.01978, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:25.621, tt:230.588\n",
      "Ep:9, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:26.257, tt:262.568\n",
      "Ep:10, loss:0.00004, loss_test:0.01946, lr:6.00e-02, fs:0.64435 (r=0.778,p=0.550),  time:26.638, tt:293.015\n",
      "Ep:11, loss:0.00004, loss_test:0.01921, lr:6.00e-02, fs:0.64167 (r=0.778,p=0.546),  time:26.876, tt:322.510\n",
      "Ep:12, loss:0.00003, loss_test:0.01894, lr:6.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:27.194, tt:353.517\n",
      "Ep:13, loss:0.00003, loss_test:0.01880, lr:5.94e-02, fs:0.65863 (r=0.828,p=0.547),  time:27.467, tt:384.535\n",
      "Ep:14, loss:0.00003, loss_test:0.01867, lr:5.88e-02, fs:0.66135 (r=0.838,p=0.546),  time:27.675, tt:415.119\n",
      "Ep:15, loss:0.00003, loss_test:0.01861, lr:5.82e-02, fs:0.66932 (r=0.848,p=0.553),  time:27.852, tt:445.634\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01863, lr:5.82e-02, fs:0.66667 (r=0.828,p=0.558),  time:28.068, tt:477.148\n",
      "Ep:17, loss:0.00003, loss_test:0.01866, lr:5.82e-02, fs:0.67769 (r=0.828,p=0.573),  time:28.272, tt:508.903\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01864, lr:5.82e-02, fs:0.68619 (r=0.828,p=0.586),  time:28.397, tt:539.534\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01858, lr:5.82e-02, fs:0.68644 (r=0.818,p=0.591),  time:28.525, tt:570.496\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01847, lr:5.82e-02, fs:0.68966 (r=0.808,p=0.602),  time:28.658, tt:601.826\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01833, lr:5.82e-02, fs:0.70175 (r=0.808,p=0.620),  time:28.788, tt:633.342\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01817, lr:5.82e-02, fs:0.70796 (r=0.808,p=0.630),  time:28.842, tt:663.356\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01799, lr:5.82e-02, fs:0.71429 (r=0.808,p=0.640),  time:28.898, tt:693.544\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00003, loss_test:0.01787, lr:5.82e-02, fs:0.71429 (r=0.808,p=0.640),  time:29.011, tt:725.269\n",
      "Ep:25, loss:0.00003, loss_test:0.01777, lr:5.82e-02, fs:0.71171 (r=0.798,p=0.642),  time:29.077, tt:756.005\n",
      "Ep:26, loss:0.00003, loss_test:0.01768, lr:5.82e-02, fs:0.72072 (r=0.808,p=0.650),  time:29.154, tt:787.148\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01761, lr:5.82e-02, fs:0.71493 (r=0.798,p=0.648),  time:29.203, tt:817.682\n",
      "Ep:28, loss:0.00002, loss_test:0.01754, lr:5.82e-02, fs:0.71493 (r=0.798,p=0.648),  time:29.279, tt:849.093\n",
      "Ep:29, loss:0.00002, loss_test:0.01744, lr:5.82e-02, fs:0.71818 (r=0.798,p=0.653),  time:29.331, tt:879.932\n",
      "Ep:30, loss:0.00002, loss_test:0.01736, lr:5.82e-02, fs:0.72146 (r=0.798,p=0.658),  time:29.401, tt:911.441\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01729, lr:5.82e-02, fs:0.72811 (r=0.798,p=0.669),  time:29.497, tt:943.892\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01720, lr:5.82e-02, fs:0.74419 (r=0.808,p=0.690),  time:29.504, tt:973.630\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01710, lr:5.82e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.520, tt:1003.695\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01700, lr:5.82e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.554, tt:1034.407\n",
      "Ep:35, loss:0.00002, loss_test:0.01690, lr:5.82e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.604, tt:1065.741\n",
      "Ep:36, loss:0.00002, loss_test:0.01683, lr:5.82e-02, fs:0.74766 (r=0.808,p=0.696),  time:29.609, tt:1095.551\n",
      "Ep:37, loss:0.00002, loss_test:0.01679, lr:5.82e-02, fs:0.75117 (r=0.808,p=0.702),  time:29.691, tt:1128.266\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01673, lr:5.82e-02, fs:0.75472 (r=0.808,p=0.708),  time:29.728, tt:1159.403\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01669, lr:5.82e-02, fs:0.75472 (r=0.808,p=0.708),  time:29.774, tt:1190.975\n",
      "Ep:40, loss:0.00002, loss_test:0.01663, lr:5.82e-02, fs:0.75829 (r=0.808,p=0.714),  time:29.790, tt:1221.369\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01658, lr:5.82e-02, fs:0.76555 (r=0.808,p=0.727),  time:29.837, tt:1253.142\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01655, lr:5.82e-02, fs:0.76555 (r=0.808,p=0.727),  time:29.886, tt:1285.116\n",
      "Ep:43, loss:0.00002, loss_test:0.01651, lr:5.82e-02, fs:0.77143 (r=0.818,p=0.730),  time:29.914, tt:1316.235\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01645, lr:5.82e-02, fs:0.76777 (r=0.818,p=0.723),  time:29.942, tt:1347.381\n",
      "Ep:45, loss:0.00002, loss_test:0.01636, lr:5.82e-02, fs:0.77143 (r=0.818,p=0.730),  time:29.990, tt:1379.536\n",
      "Ep:46, loss:0.00002, loss_test:0.01638, lr:5.82e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.018, tt:1410.847\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01638, lr:5.82e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.029, tt:1441.416\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01633, lr:5.82e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.089, tt:1474.383\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01628, lr:5.82e-02, fs:0.79227 (r=0.828,p=0.759),  time:30.116, tt:1505.788\n",
      "Ep:50, loss:0.00002, loss_test:0.01625, lr:5.82e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.153, tt:1537.826\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01622, lr:5.82e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.165, tt:1568.568\n",
      "Ep:52, loss:0.00002, loss_test:0.01626, lr:5.82e-02, fs:0.79612 (r=0.828,p=0.766),  time:30.165, tt:1598.755\n",
      "Ep:53, loss:0.00002, loss_test:0.01625, lr:5.82e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.172, tt:1629.262\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01623, lr:5.82e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.179, tt:1659.838\n",
      "Ep:55, loss:0.00002, loss_test:0.01621, lr:5.82e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.193, tt:1690.813\n",
      "Ep:56, loss:0.00002, loss_test:0.01624, lr:5.82e-02, fs:0.80000 (r=0.828,p=0.774),  time:30.209, tt:1721.900\n",
      "Ep:57, loss:0.00002, loss_test:0.01628, lr:5.82e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.238, tt:1753.787\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01622, lr:5.82e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.264, tt:1785.596\n",
      "Ep:59, loss:0.00002, loss_test:0.01621, lr:5.82e-02, fs:0.80392 (r=0.828,p=0.781),  time:30.319, tt:1819.167\n",
      "Ep:60, loss:0.00002, loss_test:0.01621, lr:5.82e-02, fs:0.80976 (r=0.838,p=0.783),  time:30.339, tt:1850.661\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.01620, lr:5.82e-02, fs:0.81373 (r=0.838,p=0.790),  time:30.371, tt:1882.973\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01617, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.389, tt:1914.495\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01620, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.398, tt:1945.484\n",
      "Ep:64, loss:0.00001, loss_test:0.01625, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.437, tt:1978.422\n",
      "Ep:65, loss:0.00001, loss_test:0.01628, lr:5.82e-02, fs:0.81773 (r=0.838,p=0.798),  time:30.460, tt:2010.380\n",
      "Ep:66, loss:0.00001, loss_test:0.01627, lr:5.82e-02, fs:0.82353 (r=0.848,p=0.800),  time:30.482, tt:2042.311\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01631, lr:5.82e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.490, tt:2073.341\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01637, lr:5.82e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.499, tt:2104.401\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01635, lr:5.82e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.512, tt:2135.834\n",
      "Ep:70, loss:0.00001, loss_test:0.01635, lr:5.82e-02, fs:0.83582 (r=0.848,p=0.824),  time:30.498, tt:2165.360\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01644, lr:5.82e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.529, tt:2198.100\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01656, lr:5.82e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.550, tt:2230.140\n",
      "Ep:73, loss:0.00001, loss_test:0.01657, lr:5.82e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.573, tt:2262.416\n",
      "Ep:74, loss:0.00001, loss_test:0.01652, lr:5.82e-02, fs:0.84000 (r=0.848,p=0.832),  time:30.581, tt:2293.596\n",
      "Ep:75, loss:0.00001, loss_test:0.01654, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.599, tt:2325.552\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01661, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.593, tt:2355.667\n",
      "Ep:77, loss:0.00001, loss_test:0.01669, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.595, tt:2386.402\n",
      "Ep:78, loss:0.00001, loss_test:0.01679, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.608, tt:2418.055\n",
      "Ep:79, loss:0.00001, loss_test:0.01680, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.616, tt:2449.244\n",
      "Ep:80, loss:0.00001, loss_test:0.01684, lr:5.82e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.649, tt:2482.535\n",
      "Ep:81, loss:0.00001, loss_test:0.01687, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.659, tt:2514.066\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01690, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.657, tt:2544.492\n",
      "Ep:83, loss:0.00001, loss_test:0.01694, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.675, tt:2576.691\n",
      "Ep:84, loss:0.00001, loss_test:0.01699, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.675, tt:2607.334\n",
      "Ep:85, loss:0.00001, loss_test:0.01702, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.678, tt:2638.294\n",
      "Ep:86, loss:0.00001, loss_test:0.01708, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.682, tt:2669.372\n",
      "Ep:87, loss:0.00001, loss_test:0.01719, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.700, tt:2701.608\n",
      "Ep:88, loss:0.00001, loss_test:0.01723, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.699, tt:2732.225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00001, loss_test:0.01731, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.692, tt:2762.292\n",
      "Ep:90, loss:0.00001, loss_test:0.01728, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.698, tt:2793.536\n",
      "Ep:91, loss:0.00001, loss_test:0.01738, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.709, tt:2825.235\n",
      "Ep:92, loss:0.00001, loss_test:0.01741, lr:5.82e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.727, tt:2857.578\n",
      "Ep:93, loss:0.00001, loss_test:0.01745, lr:5.76e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.722, tt:2887.841\n",
      "Ep:94, loss:0.00001, loss_test:0.01750, lr:5.71e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.723, tt:2918.696\n",
      "Ep:95, loss:0.00001, loss_test:0.01756, lr:5.65e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.734, tt:2950.479\n",
      "Ep:96, loss:0.00001, loss_test:0.01763, lr:5.59e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.734, tt:2981.151\n",
      "Ep:97, loss:0.00001, loss_test:0.01769, lr:5.54e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.764, tt:3014.861\n",
      "Ep:98, loss:0.00001, loss_test:0.01773, lr:5.48e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.763, tt:3045.564\n",
      "Ep:99, loss:0.00001, loss_test:0.01782, lr:5.43e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.773, tt:3077.264\n",
      "Ep:100, loss:0.00001, loss_test:0.01788, lr:5.37e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.767, tt:3107.431\n",
      "Ep:101, loss:0.00001, loss_test:0.01791, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.777, tt:3139.283\n",
      "Ep:102, loss:0.00001, loss_test:0.01797, lr:5.27e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.770, tt:3169.355\n",
      "Ep:103, loss:0.00001, loss_test:0.01809, lr:5.21e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.778, tt:3200.902\n",
      "Ep:104, loss:0.00001, loss_test:0.01815, lr:5.16e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.800, tt:3233.991\n",
      "Ep:105, loss:0.00001, loss_test:0.01816, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.816, tt:3266.490\n",
      "Ep:106, loss:0.00001, loss_test:0.01824, lr:5.06e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.812, tt:3296.876\n",
      "Ep:107, loss:0.00001, loss_test:0.01828, lr:5.01e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.822, tt:3328.763\n",
      "Ep:108, loss:0.00001, loss_test:0.01834, lr:4.96e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.820, tt:3359.373\n",
      "Ep:109, loss:0.00001, loss_test:0.01839, lr:4.91e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.834, tt:3391.793\n",
      "Ep:110, loss:0.00001, loss_test:0.01843, lr:4.86e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.830, tt:3422.168\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01848, lr:4.86e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.840, tt:3454.109\n",
      "Ep:112, loss:0.00001, loss_test:0.01852, lr:4.86e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.828, tt:3483.550\n",
      "Ep:113, loss:0.00001, loss_test:0.01857, lr:4.86e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.839, tt:3515.628\n",
      "Ep:114, loss:0.00001, loss_test:0.01869, lr:4.86e-02, fs:0.85279 (r=0.848,p=0.857),  time:30.839, tt:3546.490\n",
      "Ep:115, loss:0.00001, loss_test:0.01875, lr:4.86e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.846, tt:3578.141\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01879, lr:4.86e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.848, tt:3609.191\n",
      "Ep:117, loss:0.00001, loss_test:0.01880, lr:4.86e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.843, tt:3639.525\n",
      "Ep:118, loss:0.00001, loss_test:0.01896, lr:4.86e-02, fs:0.85714 (r=0.848,p=0.866),  time:30.864, tt:3672.761\n",
      "Ep:119, loss:0.00001, loss_test:0.01899, lr:4.86e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.861, tt:3703.336\n",
      "Ep:120, loss:0.00001, loss_test:0.01906, lr:4.86e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.862, tt:3734.247\n",
      "Ep:121, loss:0.00001, loss_test:0.01912, lr:4.86e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.861, tt:3765.066\n",
      "Ep:122, loss:0.00001, loss_test:0.01918, lr:4.86e-02, fs:0.85128 (r=0.838,p=0.865),  time:30.864, tt:3796.269\n",
      "Ep:123, loss:0.00001, loss_test:0.01924, lr:4.86e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.863, tt:3827.060\n",
      "Ep:124, loss:0.00001, loss_test:0.01931, lr:4.86e-02, fs:0.85567 (r=0.838,p=0.874),  time:30.856, tt:3857.059\n",
      "Ep:125, loss:0.00001, loss_test:0.01929, lr:4.86e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.858, tt:3888.129\n",
      "Ep:126, loss:0.00001, loss_test:0.01940, lr:4.86e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.867, tt:3920.084\n",
      "Ep:127, loss:0.00001, loss_test:0.01957, lr:4.81e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.863, tt:3950.463\n",
      "Ep:128, loss:0.00001, loss_test:0.01958, lr:4.76e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.861, tt:3981.041\n",
      "Ep:129, loss:0.00001, loss_test:0.01962, lr:4.71e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.875, tt:4013.752\n",
      "Ep:130, loss:0.00001, loss_test:0.01977, lr:4.67e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.882, tt:4045.495\n",
      "Ep:131, loss:0.00001, loss_test:0.01977, lr:4.62e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.879, tt:4075.998\n",
      "Ep:132, loss:0.00001, loss_test:0.01978, lr:4.57e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.880, tt:4107.021\n",
      "Ep:133, loss:0.00001, loss_test:0.01991, lr:4.53e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.888, tt:4138.984\n",
      "Ep:134, loss:0.00001, loss_test:0.01998, lr:4.48e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.891, tt:4170.259\n",
      "Ep:135, loss:0.00001, loss_test:0.01998, lr:4.44e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.891, tt:4201.110\n",
      "Ep:136, loss:0.00001, loss_test:0.02001, lr:4.39e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.893, tt:4232.316\n",
      "Ep:137, loss:0.00001, loss_test:0.02009, lr:4.35e-02, fs:0.83158 (r=0.798,p=0.868),  time:30.903, tt:4264.575\n",
      "Ep:138, loss:0.00001, loss_test:0.02015, lr:4.31e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.896, tt:4294.555\n",
      "Ep:139, loss:0.00001, loss_test:0.02019, lr:4.26e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.891, tt:4324.673\n",
      "Ep:140, loss:0.00001, loss_test:0.02021, lr:4.22e-02, fs:0.83598 (r=0.798,p=0.878),  time:30.916, tt:4359.120\n",
      "Ep:141, loss:0.00001, loss_test:0.02031, lr:4.18e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.918, tt:4390.343\n",
      "Ep:142, loss:0.00001, loss_test:0.02038, lr:4.14e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.925, tt:4422.225\n",
      "Ep:143, loss:0.00001, loss_test:0.02045, lr:4.10e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.937, tt:4454.972\n",
      "Ep:144, loss:0.00001, loss_test:0.02050, lr:4.05e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.942, tt:4486.640\n",
      "Ep:145, loss:0.00001, loss_test:0.02054, lr:4.01e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.948, tt:4518.435\n",
      "Ep:146, loss:0.00001, loss_test:0.02057, lr:3.97e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.952, tt:4549.890\n",
      "Ep:147, loss:0.00001, loss_test:0.02062, lr:3.93e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.960, tt:4582.085\n",
      "Ep:148, loss:0.00001, loss_test:0.02069, lr:3.89e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.957, tt:4612.581\n",
      "Ep:149, loss:0.00001, loss_test:0.02071, lr:3.86e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.948, tt:4642.206\n",
      "Ep:150, loss:0.00001, loss_test:0.02075, lr:3.82e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.951, tt:4673.617\n",
      "Ep:151, loss:0.00001, loss_test:0.02081, lr:3.78e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.945, tt:4703.580\n",
      "Ep:152, loss:0.00001, loss_test:0.02084, lr:3.74e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.941, tt:4734.047\n",
      "Ep:153, loss:0.00001, loss_test:0.02094, lr:3.70e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.940, tt:4764.802\n",
      "Ep:154, loss:0.00001, loss_test:0.02097, lr:3.67e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.932, tt:4794.454\n",
      "Ep:155, loss:0.00001, loss_test:0.02099, lr:3.63e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.927, tt:4824.629\n",
      "Ep:156, loss:0.00001, loss_test:0.02107, lr:3.59e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.925, tt:4855.187\n",
      "Ep:157, loss:0.00001, loss_test:0.02110, lr:3.56e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.919, tt:4885.266\n",
      "Ep:158, loss:0.00001, loss_test:0.02113, lr:3.52e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.918, tt:4915.923\n",
      "Ep:159, loss:0.00001, loss_test:0.02117, lr:3.49e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.918, tt:4946.867\n",
      "Ep:160, loss:0.00001, loss_test:0.02122, lr:3.45e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.914, tt:4977.226\n",
      "Ep:161, loss:0.00001, loss_test:0.02126, lr:3.42e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.916, tt:5008.317\n",
      "Ep:162, loss:0.00001, loss_test:0.02131, lr:3.38e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.915, tt:5039.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:163, loss:0.00001, loss_test:0.02132, lr:3.35e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.911, tt:5069.344\n",
      "Ep:164, loss:0.00001, loss_test:0.02138, lr:3.32e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.909, tt:5100.022\n",
      "Ep:165, loss:0.00001, loss_test:0.02140, lr:3.28e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.903, tt:5129.888\n",
      "Ep:166, loss:0.00001, loss_test:0.02142, lr:3.25e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.905, tt:5161.211\n",
      "Ep:167, loss:0.00001, loss_test:0.02149, lr:3.22e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.910, tt:5192.852\n",
      "Ep:168, loss:0.00001, loss_test:0.02153, lr:3.19e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.907, tt:5223.291\n",
      "Ep:169, loss:0.00001, loss_test:0.02159, lr:3.15e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.897, tt:5252.533\n",
      "Ep:170, loss:0.00001, loss_test:0.02161, lr:3.12e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.898, tt:5283.527\n",
      "Ep:171, loss:0.00001, loss_test:0.02166, lr:3.09e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.898, tt:5314.523\n",
      "Ep:172, loss:0.00001, loss_test:0.02171, lr:3.06e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.893, tt:5344.466\n",
      "Ep:173, loss:0.00001, loss_test:0.02175, lr:3.03e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.887, tt:5374.257\n",
      "Ep:174, loss:0.00001, loss_test:0.02173, lr:3.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.884, tt:5404.704\n",
      "Ep:175, loss:0.00001, loss_test:0.02180, lr:2.97e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.884, tt:5435.651\n",
      "Ep:176, loss:0.00001, loss_test:0.02185, lr:2.94e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.889, tt:5467.375\n",
      "Ep:177, loss:0.00001, loss_test:0.02186, lr:2.91e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.903, tt:5500.729\n",
      "Ep:178, loss:0.00001, loss_test:0.02190, lr:2.88e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.913, tt:5533.385\n",
      "Ep:179, loss:0.00000, loss_test:0.02199, lr:2.85e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.914, tt:5564.444\n",
      "Ep:180, loss:0.00000, loss_test:0.02197, lr:2.82e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.914, tt:5595.471\n",
      "Ep:181, loss:0.00000, loss_test:0.02202, lr:2.80e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.919, tt:5627.218\n",
      "Ep:182, loss:0.00000, loss_test:0.02209, lr:2.77e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.920, tt:5658.414\n",
      "Ep:183, loss:0.00000, loss_test:0.02211, lr:2.74e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.917, tt:5688.797\n",
      "Ep:184, loss:0.00000, loss_test:0.02213, lr:2.71e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.910, tt:5718.343\n",
      "Ep:185, loss:0.00000, loss_test:0.02216, lr:2.69e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.914, tt:5750.053\n",
      "Ep:186, loss:0.00000, loss_test:0.02218, lr:2.66e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.917, tt:5781.439\n",
      "Ep:187, loss:0.00000, loss_test:0.02222, lr:2.63e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.922, tt:5813.314\n",
      "Ep:188, loss:0.00000, loss_test:0.02225, lr:2.61e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.926, tt:5844.953\n",
      "Ep:189, loss:0.00000, loss_test:0.02228, lr:2.58e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.923, tt:5875.424\n",
      "Ep:190, loss:0.00000, loss_test:0.02231, lr:2.55e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.923, tt:5906.243\n",
      "Ep:191, loss:0.00000, loss_test:0.02233, lr:2.53e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.922, tt:5936.982\n",
      "Ep:192, loss:0.00000, loss_test:0.02234, lr:2.50e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.918, tt:5967.247\n",
      "Ep:193, loss:0.00000, loss_test:0.02242, lr:2.48e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.921, tt:5998.671\n",
      "Ep:194, loss:0.00000, loss_test:0.02246, lr:2.45e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.921, tt:6029.546\n",
      "Ep:195, loss:0.00000, loss_test:0.02246, lr:2.43e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.919, tt:6060.032\n",
      "Ep:196, loss:0.00000, loss_test:0.02246, lr:2.40e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.920, tt:6091.223\n",
      "Ep:197, loss:0.00000, loss_test:0.02254, lr:2.38e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.920, tt:6122.067\n",
      "Ep:198, loss:0.00000, loss_test:0.02258, lr:2.36e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.922, tt:6153.414\n",
      "Ep:199, loss:0.00000, loss_test:0.02258, lr:2.33e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.925, tt:6185.100\n",
      "Ep:200, loss:0.00000, loss_test:0.02258, lr:2.31e-02, fs:0.84153 (r=0.778,p=0.917),  time:30.921, tt:6215.056\n",
      "Ep:201, loss:0.00000, loss_test:0.02262, lr:2.29e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.916, tt:6245.011\n",
      "Ep:202, loss:0.00000, loss_test:0.02268, lr:2.26e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.912, tt:6275.170\n",
      "Ep:203, loss:0.00000, loss_test:0.02268, lr:2.24e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.915, tt:6306.725\n",
      "Ep:204, loss:0.00000, loss_test:0.02269, lr:2.22e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.905, tt:6335.498\n",
      "Ep:205, loss:0.00000, loss_test:0.02275, lr:2.20e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.907, tt:6366.889\n",
      "Ep:206, loss:0.00000, loss_test:0.02280, lr:2.17e-02, fs:0.84615 (r=0.778,p=0.928),  time:30.895, tt:6395.364\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14450, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.422, tt:29.422\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14404, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.046, tt:60.091\n",
      "Ep:2, loss:0.00028, loss_test:0.14331, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.729, tt:95.186\n",
      "Ep:3, loss:0.00028, loss_test:0.14228, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.871, tt:119.484\n",
      "Ep:4, loss:0.00028, loss_test:0.14085, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:28.795, tt:143.973\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00028, loss_test:0.13891, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:28.658, tt:171.950\n",
      "Ep:6, loss:0.00027, loss_test:0.13617, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:28.838, tt:201.869\n",
      "Ep:7, loss:0.00027, loss_test:0.13217, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.201, tt:233.608\n",
      "Ep:8, loss:0.00026, loss_test:0.12582, lr:1.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:29.535, tt:265.811\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11789, lr:1.00e-02, fs:0.66383 (r=0.788,p=0.574),  time:29.848, tt:298.485\n",
      "Ep:10, loss:0.00023, loss_test:0.11366, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:30.181, tt:331.991\n",
      "Ep:11, loss:0.00023, loss_test:0.11245, lr:1.00e-02, fs:0.66337 (r=0.677,p=0.650),  time:30.410, tt:364.918\n",
      "Ep:12, loss:0.00022, loss_test:0.11073, lr:1.00e-02, fs:0.67633 (r=0.707,p=0.648),  time:30.587, tt:397.627\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00021, loss_test:0.11034, lr:1.00e-02, fs:0.67593 (r=0.737,p=0.624),  time:30.678, tt:429.488\n",
      "Ep:14, loss:0.00021, loss_test:0.10681, lr:1.00e-02, fs:0.69524 (r=0.737,p=0.658),  time:30.704, tt:460.557\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10510, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:30.745, tt:491.917\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.10374, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:30.831, tt:524.122\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10246, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:30.920, tt:556.568\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10131, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:30.954, tt:588.130\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10053, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:31.103, tt:622.052\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09981, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:31.173, tt:654.629\n",
      "Ep:21, loss:0.00016, loss_test:0.09997, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:31.184, tt:686.046\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09829, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:31.318, tt:720.310\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:23, loss:0.00015, loss_test:0.09752, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:31.345, tt:752.280\n",
      "Ep:24, loss:0.00015, loss_test:0.09800, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:31.365, tt:784.116\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09563, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:31.408, tt:816.598\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.09492, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:31.457, tt:849.347\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09495, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:31.471, tt:881.199\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09340, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.599, tt:916.363\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09230, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:31.570, tt:947.087\n",
      "Ep:30, loss:0.00012, loss_test:0.09218, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:31.600, tt:979.587\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.09061, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:31.628, tt:1012.095\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.09041, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.614, tt:1043.276\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08939, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.627, tt:1075.302\n",
      "Ep:34, loss:0.00011, loss_test:0.08938, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:31.576, tt:1105.149\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.09043, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:31.586, tt:1137.105\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08790, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.598, tt:1169.130\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.08986, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.628, tt:1201.845\n",
      "Ep:38, loss:0.00010, loss_test:0.08760, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:31.626, tt:1233.400\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08694, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:31.665, tt:1266.601\n",
      "Ep:40, loss:0.00009, loss_test:0.08856, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.680, tt:1298.896\n",
      "Ep:41, loss:0.00009, loss_test:0.08616, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.680, tt:1330.579\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.08662, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.659, tt:1361.339\n",
      "Ep:45, loss:0.00008, loss_test:0.08607, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.662, tt:1456.469\n",
      "Ep:46, loss:0.00008, loss_test:0.08508, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.685, tt:1489.192\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.08543, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.701, tt:1521.661\n",
      "Ep:48, loss:0.00008, loss_test:0.08494, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.711, tt:1553.820\n",
      "Ep:49, loss:0.00008, loss_test:0.08533, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.755, tt:1587.763\n",
      "Ep:50, loss:0.00007, loss_test:0.08457, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.790, tt:1621.315\n",
      "Ep:51, loss:0.00007, loss_test:0.08407, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.842, tt:1655.806\n",
      "Ep:52, loss:0.00007, loss_test:0.08547, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:31.844, tt:1687.740\n",
      "Ep:53, loss:0.00007, loss_test:0.08339, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:31.840, tt:1719.347\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.08513, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.840, tt:1751.218\n",
      "Ep:55, loss:0.00007, loss_test:0.08403, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.843, tt:1783.186\n",
      "Ep:56, loss:0.00006, loss_test:0.08353, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:31.863, tt:1816.170\n",
      "Ep:57, loss:0.00006, loss_test:0.08498, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:31.881, tt:1849.121\n",
      "Ep:58, loss:0.00006, loss_test:0.08272, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:31.905, tt:1882.389\n",
      "Ep:59, loss:0.00006, loss_test:0.08375, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:31.906, tt:1914.375\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.08527, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.931, tt:1947.801\n",
      "Ep:61, loss:0.00006, loss_test:0.08228, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.932, tt:1979.784\n",
      "Ep:62, loss:0.00006, loss_test:0.08747, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.935, tt:2011.896\n",
      "Ep:63, loss:0.00006, loss_test:0.08229, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.941, tt:2044.247\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.08522, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.930, tt:2075.429\n",
      "Ep:65, loss:0.00005, loss_test:0.08540, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.954, tt:2108.979\n",
      "Ep:66, loss:0.00005, loss_test:0.08299, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:31.959, tt:2141.281\n",
      "Ep:67, loss:0.00005, loss_test:0.08403, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:31.990, tt:2175.336\n",
      "Ep:68, loss:0.00005, loss_test:0.08396, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.990, tt:2207.308\n",
      "Ep:69, loss:0.00005, loss_test:0.08281, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:31.979, tt:2238.539\n",
      "Ep:70, loss:0.00005, loss_test:0.08252, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.981, tt:2270.654\n",
      "Ep:71, loss:0.00005, loss_test:0.08168, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:31.970, tt:2301.869\n",
      "Ep:72, loss:0.00005, loss_test:0.08515, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.957, tt:2332.897\n",
      "Ep:73, loss:0.00004, loss_test:0.08280, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.962, tt:2365.189\n",
      "Ep:74, loss:0.00004, loss_test:0.08228, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.975, tt:2398.120\n",
      "Ep:75, loss:0.00004, loss_test:0.08463, lr:9.90e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.981, tt:2430.547\n",
      "Ep:76, loss:0.00004, loss_test:0.08057, lr:9.80e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.980, tt:2462.466\n",
      "Ep:77, loss:0.00004, loss_test:0.08359, lr:9.70e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.970, tt:2493.669\n",
      "Ep:78, loss:0.00004, loss_test:0.08182, lr:9.61e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.004, tt:2528.299\n",
      "Ep:79, loss:0.00004, loss_test:0.08250, lr:9.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:32.008, tt:2560.666\n",
      "Ep:80, loss:0.00004, loss_test:0.08188, lr:9.41e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.047, tt:2595.785\n",
      "Ep:81, loss:0.00004, loss_test:0.08042, lr:9.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.033, tt:2626.739\n",
      "Ep:82, loss:0.00004, loss_test:0.08144, lr:9.23e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.015, tt:2657.258\n",
      "Ep:83, loss:0.00004, loss_test:0.08117, lr:9.14e-03, fs:0.85246 (r=0.788,p=0.929),  time:32.011, tt:2688.936\n",
      "Ep:84, loss:0.00003, loss_test:0.08189, lr:9.04e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.996, tt:2719.699\n",
      "Ep:85, loss:0.00003, loss_test:0.08003, lr:8.95e-03, fs:0.87097 (r=0.818,p=0.931),  time:32.004, tt:2752.369\n",
      "Ep:86, loss:0.00003, loss_test:0.08078, lr:8.86e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.992, tt:2783.305\n",
      "Ep:87, loss:0.00003, loss_test:0.08110, lr:8.78e-03, fs:0.87701 (r=0.828,p=0.932),  time:31.999, tt:2815.944\n",
      "Ep:88, loss:0.00003, loss_test:0.07889, lr:8.69e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.009, tt:2848.768\n",
      "Ep:89, loss:0.00003, loss_test:0.08097, lr:8.60e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.010, tt:2880.927\n",
      "Ep:90, loss:0.00003, loss_test:0.08073, lr:8.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.986, tt:2910.703\n",
      "Ep:91, loss:0.00003, loss_test:0.07897, lr:8.43e-03, fs:0.87568 (r=0.818,p=0.942),  time:31.979, tt:2942.074\n",
      "Ep:92, loss:0.00003, loss_test:0.08166, lr:8.35e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.969, tt:2973.160\n",
      "Ep:93, loss:0.00003, loss_test:0.07927, lr:8.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.949, tt:3003.196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:94, loss:0.00003, loss_test:0.08102, lr:8.18e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.950, tt:3035.227\n",
      "Ep:95, loss:0.00003, loss_test:0.08032, lr:8.10e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.956, tt:3067.808\n",
      "Ep:96, loss:0.00003, loss_test:0.07927, lr:8.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.957, tt:3099.800\n",
      "Ep:97, loss:0.00003, loss_test:0.08192, lr:7.94e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.960, tt:3132.075\n",
      "Ep:98, loss:0.00003, loss_test:0.07854, lr:7.86e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.958, tt:3163.873\n",
      "Ep:99, loss:0.00003, loss_test:0.08040, lr:7.78e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.957, tt:3195.697\n",
      "Ep:100, loss:0.00003, loss_test:0.08026, lr:7.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.948, tt:3226.714\n",
      "Ep:101, loss:0.00002, loss_test:0.07841, lr:7.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.934, tt:3257.258\n",
      "Ep:102, loss:0.00002, loss_test:0.08147, lr:7.55e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.931, tt:3288.921\n",
      "Ep:103, loss:0.00002, loss_test:0.07841, lr:7.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.928, tt:3320.488\n",
      "Ep:104, loss:0.00002, loss_test:0.07984, lr:7.40e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.932, tt:3352.875\n",
      "Ep:105, loss:0.00002, loss_test:0.08057, lr:7.32e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.958, tt:3387.550\n",
      "Ep:106, loss:0.00002, loss_test:0.07788, lr:7.25e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.967, tt:3420.498\n",
      "Ep:107, loss:0.00002, loss_test:0.08039, lr:7.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.983, tt:3454.189\n",
      "Ep:108, loss:0.00002, loss_test:0.08061, lr:7.11e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.985, tt:3486.369\n",
      "Ep:109, loss:0.00002, loss_test:0.07786, lr:7.03e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.995, tt:3519.428\n",
      "Ep:110, loss:0.00002, loss_test:0.08075, lr:6.96e-03, fs:0.85714 (r=0.788,p=0.940),  time:31.982, tt:3549.955\n",
      "Ep:111, loss:0.00002, loss_test:0.07990, lr:6.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.020, tt:3586.218\n",
      "Ep:112, loss:0.00002, loss_test:0.07826, lr:6.83e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.009, tt:3616.993\n",
      "Ep:113, loss:0.00002, loss_test:0.08067, lr:6.76e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.013, tt:3649.521\n",
      "Ep:114, loss:0.00002, loss_test:0.08028, lr:6.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.019, tt:3682.196\n",
      "Ep:115, loss:0.00002, loss_test:0.07839, lr:6.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.000, tt:3712.031\n",
      "Ep:116, loss:0.00002, loss_test:0.07955, lr:6.56e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.990, tt:3742.875\n",
      "Ep:117, loss:0.00002, loss_test:0.07936, lr:6.49e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.003, tt:3776.342\n",
      "Ep:118, loss:0.00002, loss_test:0.07893, lr:6.43e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.002, tt:3808.192\n",
      "Ep:119, loss:0.00002, loss_test:0.07972, lr:6.36e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.003, tt:3840.403\n",
      "Ep:120, loss:0.00002, loss_test:0.07936, lr:6.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.010, tt:3873.213\n",
      "Ep:121, loss:0.00002, loss_test:0.07897, lr:6.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:32.009, tt:3905.097\n",
      "Ep:122, loss:0.00002, loss_test:0.07926, lr:6.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.014, tt:3937.664\n",
      "Ep:123, loss:0.00002, loss_test:0.07929, lr:6.11e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.013, tt:3969.668\n",
      "Ep:124, loss:0.00002, loss_test:0.07949, lr:6.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.000, tt:3999.986\n",
      "Ep:125, loss:0.00002, loss_test:0.07929, lr:5.99e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.013, tt:4033.694\n",
      "Ep:126, loss:0.00002, loss_test:0.07911, lr:5.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.018, tt:4066.333\n",
      "Ep:127, loss:0.00002, loss_test:0.08058, lr:5.87e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.024, tt:4099.052\n",
      "Ep:128, loss:0.00002, loss_test:0.08046, lr:5.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.015, tt:4129.923\n",
      "Ep:129, loss:0.00002, loss_test:0.07906, lr:5.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.017, tt:4162.262\n",
      "Ep:130, loss:0.00002, loss_test:0.07965, lr:5.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.017, tt:4194.217\n",
      "Ep:131, loss:0.00002, loss_test:0.07993, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.006, tt:4224.829\n",
      "Ep:132, loss:0.00002, loss_test:0.08000, lr:5.58e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.997, tt:4255.539\n",
      "Ep:133, loss:0.00002, loss_test:0.08008, lr:5.53e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.971, tt:4284.166\n",
      "Ep:134, loss:0.00002, loss_test:0.07982, lr:5.47e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.978, tt:4317.041\n",
      "Ep:135, loss:0.00002, loss_test:0.07994, lr:5.42e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.981, tt:4349.400\n",
      "Ep:136, loss:0.00002, loss_test:0.08087, lr:5.36e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.974, tt:4380.495\n",
      "Ep:137, loss:0.00002, loss_test:0.07944, lr:5.31e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.959, tt:4410.306\n",
      "Ep:138, loss:0.00002, loss_test:0.08060, lr:5.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.964, tt:4443.061\n",
      "Ep:139, loss:0.00002, loss_test:0.08077, lr:5.20e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.964, tt:4474.994\n",
      "Ep:140, loss:0.00002, loss_test:0.07976, lr:5.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.967, tt:4507.376\n",
      "Ep:141, loss:0.00002, loss_test:0.08044, lr:5.10e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.973, tt:4540.200\n",
      "Ep:142, loss:0.00001, loss_test:0.08056, lr:5.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.976, tt:4572.619\n",
      "Ep:143, loss:0.00001, loss_test:0.07975, lr:5.00e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.984, tt:4605.635\n",
      "Ep:144, loss:0.00001, loss_test:0.08044, lr:4.95e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.990, tt:4638.500\n",
      "Ep:145, loss:0.00001, loss_test:0.08084, lr:4.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.003, tt:4672.398\n",
      "Ep:146, loss:0.00001, loss_test:0.08011, lr:4.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.001, tt:4704.153\n",
      "Ep:147, loss:0.00001, loss_test:0.08061, lr:4.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.000, tt:4736.013\n",
      "Ep:148, loss:0.00001, loss_test:0.08121, lr:4.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.001, tt:4768.091\n",
      "Ep:149, loss:0.00001, loss_test:0.08047, lr:4.71e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.004, tt:4800.578\n",
      "Ep:150, loss:0.00001, loss_test:0.08057, lr:4.66e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.994, tt:4831.025\n",
      "Ep:151, loss:0.00001, loss_test:0.08109, lr:4.61e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.988, tt:4862.173\n",
      "Ep:152, loss:0.00001, loss_test:0.08029, lr:4.57e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.983, tt:4893.426\n",
      "Ep:153, loss:0.00001, loss_test:0.08102, lr:4.52e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.981, tt:4925.057\n",
      "Ep:154, loss:0.00001, loss_test:0.08126, lr:4.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.975, tt:4956.135\n",
      "Ep:155, loss:0.00001, loss_test:0.08044, lr:4.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.966, tt:4986.642\n",
      "Ep:156, loss:0.00001, loss_test:0.08128, lr:4.39e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.961, tt:5017.834\n",
      "Ep:157, loss:0.00001, loss_test:0.08074, lr:4.34e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.963, tt:5050.161\n",
      "Ep:158, loss:0.00001, loss_test:0.08090, lr:4.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.972, tt:5083.472\n",
      "Ep:159, loss:0.00001, loss_test:0.08186, lr:4.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.961, tt:5113.839\n",
      "Ep:160, loss:0.00001, loss_test:0.08076, lr:4.21e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.960, tt:5145.546\n",
      "Ep:161, loss:0.00001, loss_test:0.08095, lr:4.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.957, tt:5177.036\n",
      "Ep:162, loss:0.00001, loss_test:0.08166, lr:4.13e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.956, tt:5208.784\n",
      "Ep:163, loss:0.00001, loss_test:0.08100, lr:4.09e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.953, tt:5240.279\n",
      "Ep:164, loss:0.00001, loss_test:0.08122, lr:4.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.947, tt:5271.295\n",
      "Ep:165, loss:0.00001, loss_test:0.08128, lr:4.01e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.937, tt:5301.539\n",
      "Ep:166, loss:0.00001, loss_test:0.08122, lr:3.97e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.934, tt:5332.944\n",
      "Ep:167, loss:0.00001, loss_test:0.08130, lr:3.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.927, tt:5363.767\n",
      "Ep:168, loss:0.00001, loss_test:0.08120, lr:3.89e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.930, tt:5396.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:169, loss:0.00001, loss_test:0.08161, lr:3.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.931, tt:5428.258\n",
      "Ep:170, loss:0.00001, loss_test:0.08120, lr:3.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.924, tt:5458.961\n",
      "Ep:171, loss:0.00001, loss_test:0.08147, lr:3.77e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.926, tt:5491.187\n",
      "Ep:172, loss:0.00001, loss_test:0.08157, lr:3.73e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.922, tt:5522.563\n",
      "Ep:173, loss:0.00001, loss_test:0.08129, lr:3.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.909, tt:5552.174\n",
      "Ep:174, loss:0.00001, loss_test:0.08098, lr:3.66e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.908, tt:5583.913\n",
      "Ep:175, loss:0.00001, loss_test:0.08152, lr:3.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.905, tt:5615.273\n",
      "Ep:176, loss:0.00001, loss_test:0.08171, lr:3.59e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.907, tt:5647.569\n",
      "Ep:177, loss:0.00001, loss_test:0.08127, lr:3.55e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.909, tt:5679.880\n",
      "Ep:178, loss:0.00001, loss_test:0.08180, lr:3.52e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.912, tt:5712.272\n",
      "Ep:179, loss:0.00001, loss_test:0.08180, lr:3.48e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.916, tt:5744.799\n",
      "Ep:180, loss:0.00001, loss_test:0.08128, lr:3.45e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.914, tt:5776.378\n",
      "Ep:181, loss:0.00001, loss_test:0.08157, lr:3.41e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.916, tt:5808.713\n",
      "Ep:182, loss:0.00001, loss_test:0.08174, lr:3.38e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.910, tt:5839.476\n",
      "Ep:183, loss:0.00001, loss_test:0.08145, lr:3.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.900, tt:5869.563\n",
      "Ep:184, loss:0.00001, loss_test:0.08196, lr:3.31e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.897, tt:5900.902\n",
      "Ep:185, loss:0.00001, loss_test:0.08182, lr:3.28e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.887, tt:5930.908\n",
      "Ep:186, loss:0.00001, loss_test:0.08162, lr:3.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.871, tt:5959.967\n",
      "Ep:187, loss:0.00001, loss_test:0.08184, lr:3.21e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.869, tt:5991.342\n",
      "Ep:188, loss:0.00001, loss_test:0.08167, lr:3.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.867, tt:6022.890\n",
      "Ep:189, loss:0.00001, loss_test:0.08231, lr:3.15e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.870, tt:6055.227\n",
      "Ep:190, loss:0.00001, loss_test:0.08209, lr:3.12e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.877, tt:6088.539\n",
      "Ep:191, loss:0.00001, loss_test:0.08166, lr:3.09e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.878, tt:6120.572\n",
      "Ep:192, loss:0.00001, loss_test:0.08219, lr:3.05e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.883, tt:6153.335\n",
      "Ep:193, loss:0.00001, loss_test:0.08269, lr:3.02e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.884, tt:6185.570\n",
      "Ep:194, loss:0.00001, loss_test:0.08214, lr:2.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.902, tt:6220.877\n",
      "Ep:195, loss:0.00001, loss_test:0.08168, lr:2.96e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.903, tt:6252.909\n",
      "Ep:196, loss:0.00001, loss_test:0.08270, lr:2.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.899, tt:6284.176\n",
      "Ep:197, loss:0.00001, loss_test:0.08268, lr:2.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.895, tt:6315.295\n",
      "Ep:198, loss:0.00001, loss_test:0.08199, lr:2.88e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.892, tt:6346.562\n",
      "Ep:199, loss:0.00001, loss_test:0.08251, lr:2.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.889, tt:6377.790\n",
      "Ep:200, loss:0.00001, loss_test:0.08282, lr:2.82e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.889, tt:6409.681\n",
      "Ep:201, loss:0.00001, loss_test:0.08225, lr:2.79e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.888, tt:6441.416\n",
      "Ep:202, loss:0.00001, loss_test:0.08232, lr:2.76e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.892, tt:6474.062\n",
      "Ep:203, loss:0.00001, loss_test:0.08284, lr:2.73e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.887, tt:6504.946\n",
      "Ep:204, loss:0.00001, loss_test:0.08271, lr:2.71e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.885, tt:6536.342\n",
      "Ep:205, loss:0.00001, loss_test:0.08208, lr:2.68e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.885, tt:6568.321\n",
      "Ep:206, loss:0.00001, loss_test:0.08242, lr:2.65e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.882, tt:6599.579\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01942, lr:6.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:27.157, tt:27.157\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02077, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:27.608, tt:55.216\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02216, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.599, tt:79.798\n",
      "Ep:3, loss:0.00004, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.455, tt:101.818\n",
      "Ep:4, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.180, tt:120.898\n",
      "Ep:5, loss:0.00004, loss_test:0.01952, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:24.291, tt:145.748\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01855, lr:6.00e-02, fs:0.68364 (r=0.949,p=0.534),  time:24.269, tt:169.880\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:24.721, tt:197.764\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01797, lr:6.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:25.106, tt:225.954\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01768, lr:6.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:25.753, tt:257.530\n",
      "Ep:10, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:26.395, tt:290.341\n",
      "Ep:11, loss:0.00003, loss_test:0.01719, lr:6.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:26.855, tt:322.255\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:27.183, tt:353.374\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01684, lr:6.00e-02, fs:0.73282 (r=0.970,p=0.589),  time:27.465, tt:384.512\n",
      "Ep:14, loss:0.00003, loss_test:0.01665, lr:6.00e-02, fs:0.73152 (r=0.949,p=0.595),  time:27.722, tt:415.832\n",
      "Ep:15, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:27.966, tt:447.459\n",
      "Ep:16, loss:0.00003, loss_test:0.01650, lr:6.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:28.194, tt:479.290\n",
      "Ep:17, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:28.461, tt:512.298\n",
      "Ep:18, loss:0.00003, loss_test:0.01627, lr:6.00e-02, fs:0.73191 (r=0.869,p=0.632),  time:28.525, tt:541.982\n",
      "Ep:19, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.73109 (r=0.879,p=0.626),  time:28.706, tt:574.128\n",
      "Ep:20, loss:0.00003, loss_test:0.01605, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:28.896, tt:606.811\n",
      "Ep:21, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:29.009, tt:638.202\n",
      "Ep:22, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:29.176, tt:671.041\n",
      "Ep:23, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:29.241, tt:701.792\n",
      "Ep:24, loss:0.00002, loss_test:0.01597, lr:5.94e-02, fs:0.73778 (r=0.838,p=0.659),  time:29.375, tt:734.364\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01592, lr:5.94e-02, fs:0.73874 (r=0.828,p=0.667),  time:29.437, tt:765.352\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00002, loss_test:0.01587, lr:5.94e-02, fs:0.74545 (r=0.828,p=0.678),  time:29.501, tt:796.534\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01580, lr:5.94e-02, fs:0.74208 (r=0.828,p=0.672),  time:29.604, tt:828.914\n",
      "Ep:28, loss:0.00002, loss_test:0.01575, lr:5.94e-02, fs:0.74208 (r=0.828,p=0.672),  time:29.656, tt:860.019\n",
      "Ep:29, loss:0.00002, loss_test:0.01571, lr:5.94e-02, fs:0.74545 (r=0.828,p=0.678),  time:29.752, tt:892.559\n",
      "Ep:30, loss:0.00002, loss_test:0.01572, lr:5.94e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.767, tt:922.766\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01568, lr:5.94e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.759, tt:952.290\n",
      "Ep:32, loss:0.00002, loss_test:0.01563, lr:5.94e-02, fs:0.75349 (r=0.818,p=0.698),  time:29.781, tt:982.769\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01560, lr:5.94e-02, fs:0.75349 (r=0.818,p=0.698),  time:29.784, tt:1012.654\n",
      "Ep:34, loss:0.00002, loss_test:0.01558, lr:5.94e-02, fs:0.75349 (r=0.818,p=0.698),  time:29.808, tt:1043.273\n",
      "Ep:35, loss:0.00002, loss_test:0.01558, lr:5.94e-02, fs:0.76056 (r=0.818,p=0.711),  time:29.903, tt:1076.491\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01557, lr:5.94e-02, fs:0.76056 (r=0.818,p=0.711),  time:29.960, tt:1108.532\n",
      "Ep:37, loss:0.00002, loss_test:0.01552, lr:5.94e-02, fs:0.76056 (r=0.818,p=0.711),  time:30.025, tt:1140.963\n",
      "Ep:38, loss:0.00002, loss_test:0.01551, lr:5.94e-02, fs:0.76777 (r=0.818,p=0.723),  time:30.059, tt:1172.317\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01551, lr:5.94e-02, fs:0.77512 (r=0.818,p=0.736),  time:30.077, tt:1203.066\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01551, lr:5.94e-02, fs:0.77885 (r=0.818,p=0.743),  time:30.118, tt:1234.840\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01549, lr:5.94e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.146, tt:1266.128\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01545, lr:5.94e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.184, tt:1297.932\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01547, lr:5.94e-02, fs:0.78261 (r=0.818,p=0.750),  time:30.218, tt:1329.591\n",
      "Ep:44, loss:0.00002, loss_test:0.01548, lr:5.94e-02, fs:0.78641 (r=0.818,p=0.757),  time:30.221, tt:1359.946\n",
      "Ep:45, loss:0.00002, loss_test:0.01545, lr:5.94e-02, fs:0.79024 (r=0.818,p=0.764),  time:30.234, tt:1390.757\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01545, lr:5.94e-02, fs:0.79803 (r=0.818,p=0.779),  time:30.245, tt:1421.497\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01548, lr:5.94e-02, fs:0.79803 (r=0.818,p=0.779),  time:30.250, tt:1452.001\n",
      "Ep:48, loss:0.00002, loss_test:0.01553, lr:5.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.276, tt:1483.545\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01559, lr:5.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.305, tt:1515.257\n",
      "Ep:50, loss:0.00002, loss_test:0.01553, lr:5.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.331, tt:1546.884\n",
      "Ep:51, loss:0.00002, loss_test:0.01556, lr:5.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.357, tt:1578.567\n",
      "Ep:52, loss:0.00002, loss_test:0.01555, lr:5.94e-02, fs:0.80198 (r=0.818,p=0.786),  time:30.345, tt:1608.293\n",
      "Ep:53, loss:0.00002, loss_test:0.01566, lr:5.94e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.336, tt:1638.126\n",
      "Ep:54, loss:0.00002, loss_test:0.01570, lr:5.94e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.340, tt:1668.677\n",
      "Ep:55, loss:0.00002, loss_test:0.01568, lr:5.94e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.362, tt:1700.250\n",
      "Ep:56, loss:0.00001, loss_test:0.01571, lr:5.94e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.388, tt:1732.109\n",
      "Ep:57, loss:0.00001, loss_test:0.01571, lr:5.94e-02, fs:0.79381 (r=0.778,p=0.811),  time:30.404, tt:1763.450\n",
      "Ep:58, loss:0.00001, loss_test:0.01581, lr:5.94e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.418, tt:1794.661\n",
      "Ep:59, loss:0.00001, loss_test:0.01583, lr:5.94e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.425, tt:1825.488\n",
      "Ep:60, loss:0.00001, loss_test:0.01587, lr:5.88e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.411, tt:1855.073\n",
      "Ep:61, loss:0.00001, loss_test:0.01593, lr:5.82e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.404, tt:1885.069\n",
      "Ep:62, loss:0.00001, loss_test:0.01597, lr:5.76e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.388, tt:1914.440\n",
      "Ep:63, loss:0.00001, loss_test:0.01600, lr:5.71e-02, fs:0.79365 (r=0.758,p=0.833),  time:30.379, tt:1944.231\n",
      "Ep:64, loss:0.00001, loss_test:0.01602, lr:5.65e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.373, tt:1974.267\n",
      "Ep:65, loss:0.00001, loss_test:0.01610, lr:5.59e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.380, tt:2005.111\n",
      "Ep:66, loss:0.00001, loss_test:0.01611, lr:5.54e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.404, tt:2037.098\n",
      "Ep:67, loss:0.00001, loss_test:0.01618, lr:5.48e-02, fs:0.78947 (r=0.758,p=0.824),  time:30.413, tt:2068.073\n",
      "Ep:68, loss:0.00001, loss_test:0.01622, lr:5.43e-02, fs:0.78307 (r=0.747,p=0.822),  time:30.420, tt:2098.969\n",
      "Ep:69, loss:0.00001, loss_test:0.01630, lr:5.37e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.444, tt:2131.056\n",
      "Ep:70, loss:0.00001, loss_test:0.01634, lr:5.32e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.443, tt:2161.423\n",
      "Ep:71, loss:0.00001, loss_test:0.01644, lr:5.27e-02, fs:0.77660 (r=0.737,p=0.820),  time:30.445, tt:2192.034\n",
      "Ep:72, loss:0.00001, loss_test:0.01644, lr:5.21e-02, fs:0.78075 (r=0.737,p=0.830),  time:30.463, tt:2223.780\n",
      "Ep:73, loss:0.00001, loss_test:0.01648, lr:5.16e-02, fs:0.76757 (r=0.717,p=0.826),  time:30.470, tt:2254.764\n",
      "Ep:74, loss:0.00001, loss_test:0.01653, lr:5.11e-02, fs:0.76087 (r=0.707,p=0.824),  time:30.464, tt:2284.772\n",
      "Ep:75, loss:0.00001, loss_test:0.01661, lr:5.06e-02, fs:0.75410 (r=0.697,p=0.821),  time:30.470, tt:2315.752\n",
      "Ep:76, loss:0.00001, loss_test:0.01666, lr:5.01e-02, fs:0.75410 (r=0.697,p=0.821),  time:30.493, tt:2347.939\n",
      "Ep:77, loss:0.00001, loss_test:0.01672, lr:4.96e-02, fs:0.75410 (r=0.697,p=0.821),  time:30.495, tt:2378.610\n",
      "Ep:78, loss:0.00001, loss_test:0.01681, lr:4.91e-02, fs:0.75824 (r=0.697,p=0.831),  time:30.489, tt:2408.655\n",
      "Ep:79, loss:0.00001, loss_test:0.01682, lr:4.86e-02, fs:0.75138 (r=0.687,p=0.829),  time:30.497, tt:2439.746\n",
      "Ep:80, loss:0.00001, loss_test:0.01688, lr:4.81e-02, fs:0.75556 (r=0.687,p=0.840),  time:30.499, tt:2470.381\n",
      "Ep:81, loss:0.00001, loss_test:0.01698, lr:4.76e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.517, tt:2502.383\n",
      "Ep:82, loss:0.00001, loss_test:0.01701, lr:4.71e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.520, tt:2533.184\n",
      "Ep:83, loss:0.00001, loss_test:0.01709, lr:4.67e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.517, tt:2563.390\n",
      "Ep:84, loss:0.00001, loss_test:0.01715, lr:4.62e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.501, tt:2592.596\n",
      "Ep:85, loss:0.00001, loss_test:0.01718, lr:4.57e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.497, tt:2622.719\n",
      "Ep:86, loss:0.00001, loss_test:0.01720, lr:4.53e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.494, tt:2652.954\n",
      "Ep:87, loss:0.00001, loss_test:0.01729, lr:4.48e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.492, tt:2683.326\n",
      "Ep:88, loss:0.00001, loss_test:0.01733, lr:4.44e-02, fs:0.74860 (r=0.677,p=0.838),  time:30.499, tt:2714.397\n",
      "Ep:89, loss:0.00001, loss_test:0.01737, lr:4.39e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.501, tt:2745.103\n",
      "Ep:90, loss:0.00001, loss_test:0.01746, lr:4.35e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.502, tt:2775.658\n",
      "Ep:91, loss:0.00001, loss_test:0.01750, lr:4.31e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.495, tt:2805.573\n",
      "Ep:92, loss:0.00001, loss_test:0.01754, lr:4.26e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.493, tt:2835.816\n",
      "Ep:93, loss:0.00001, loss_test:0.01757, lr:4.22e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.484, tt:2865.511\n",
      "Ep:94, loss:0.00001, loss_test:0.01768, lr:4.18e-02, fs:0.75281 (r=0.677,p=0.848),  time:30.482, tt:2895.794\n",
      "Ep:95, loss:0.00001, loss_test:0.01775, lr:4.14e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.475, tt:2925.597\n",
      "Ep:96, loss:0.00001, loss_test:0.01781, lr:4.10e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.452, tt:2953.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00001, loss_test:0.01784, lr:4.05e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.449, tt:2984.013\n",
      "Ep:98, loss:0.00001, loss_test:0.01788, lr:4.01e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.439, tt:3013.491\n",
      "Ep:99, loss:0.00001, loss_test:0.01796, lr:3.97e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.460, tt:3045.983\n",
      "Ep:100, loss:0.00001, loss_test:0.01797, lr:3.93e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.463, tt:3076.726\n",
      "Ep:101, loss:0.00001, loss_test:0.01801, lr:3.89e-02, fs:0.75706 (r=0.677,p=0.859),  time:30.462, tt:3107.078\n",
      "Ep:102, loss:0.00001, loss_test:0.01807, lr:3.86e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.467, tt:3138.070\n",
      "Ep:103, loss:0.00001, loss_test:0.01812, lr:3.82e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.468, tt:3168.709\n",
      "Ep:104, loss:0.00001, loss_test:0.01818, lr:3.78e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.474, tt:3199.765\n",
      "Ep:105, loss:0.00001, loss_test:0.01823, lr:3.74e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.481, tt:3230.967\n",
      "Ep:106, loss:0.00001, loss_test:0.01826, lr:3.70e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.505, tt:3264.066\n",
      "Ep:107, loss:0.00001, loss_test:0.01832, lr:3.67e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.492, tt:3293.149\n",
      "Ep:108, loss:0.00001, loss_test:0.01839, lr:3.63e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.491, tt:3323.548\n",
      "Ep:109, loss:0.00001, loss_test:0.01843, lr:3.59e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.491, tt:3353.985\n",
      "Ep:110, loss:0.00001, loss_test:0.01847, lr:3.56e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.483, tt:3383.645\n",
      "Ep:111, loss:0.00001, loss_test:0.01855, lr:3.52e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.490, tt:3414.867\n",
      "Ep:112, loss:0.00001, loss_test:0.01858, lr:3.49e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.482, tt:3444.491\n",
      "Ep:113, loss:0.00001, loss_test:0.01862, lr:3.45e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.480, tt:3474.712\n",
      "Ep:114, loss:0.00001, loss_test:0.01864, lr:3.42e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.465, tt:3503.476\n",
      "Ep:115, loss:0.00001, loss_test:0.01869, lr:3.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.453, tt:3532.551\n",
      "Ep:116, loss:0.00001, loss_test:0.01876, lr:3.35e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.450, tt:3562.605\n",
      "Ep:117, loss:0.00001, loss_test:0.01881, lr:3.32e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.447, tt:3592.773\n",
      "Ep:118, loss:0.00001, loss_test:0.01886, lr:3.28e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.452, tt:3623.800\n",
      "Ep:119, loss:0.00001, loss_test:0.01891, lr:3.25e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.457, tt:3654.818\n",
      "Ep:120, loss:0.00001, loss_test:0.01895, lr:3.22e-02, fs:0.77193 (r=0.667,p=0.917),  time:30.466, tt:3686.433\n",
      "Ep:121, loss:0.00001, loss_test:0.01901, lr:3.19e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.463, tt:3716.440\n",
      "Ep:122, loss:0.00001, loss_test:0.01903, lr:3.15e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.466, tt:3747.303\n",
      "Ep:123, loss:0.00001, loss_test:0.01906, lr:3.12e-02, fs:0.76471 (r=0.657,p=0.915),  time:30.463, tt:3777.438\n",
      "Ep:124, loss:0.00001, loss_test:0.01911, lr:3.09e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.451, tt:3806.424\n",
      "Ep:125, loss:0.00001, loss_test:0.01913, lr:3.06e-02, fs:0.76923 (r=0.657,p=0.929),  time:30.461, tt:3838.120\n",
      "Ep:126, loss:0.00001, loss_test:0.01919, lr:3.03e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.468, tt:3869.379\n",
      "Ep:127, loss:0.00001, loss_test:0.01922, lr:3.00e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.463, tt:3899.259\n",
      "Ep:128, loss:0.00001, loss_test:0.01924, lr:2.97e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.478, tt:3931.631\n",
      "Ep:129, loss:0.00001, loss_test:0.01924, lr:2.94e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.494, tt:3964.249\n",
      "Ep:130, loss:0.00001, loss_test:0.01927, lr:2.91e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.482, tt:3993.108\n",
      "Ep:131, loss:0.00001, loss_test:0.01933, lr:2.88e-02, fs:0.76647 (r=0.646,p=0.941),  time:30.479, tt:4023.262\n",
      "Ep:132, loss:0.00001, loss_test:0.01939, lr:2.85e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.481, tt:4054.033\n",
      "Ep:133, loss:0.00001, loss_test:0.01945, lr:2.82e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.469, tt:4082.900\n",
      "Ep:134, loss:0.00001, loss_test:0.01947, lr:2.80e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.469, tt:4113.278\n",
      "Ep:135, loss:0.00001, loss_test:0.01949, lr:2.77e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.467, tt:4143.469\n",
      "Ep:136, loss:0.00001, loss_test:0.01955, lr:2.74e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.461, tt:4173.153\n",
      "Ep:137, loss:0.00001, loss_test:0.01960, lr:2.71e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.466, tt:4204.288\n",
      "Ep:138, loss:0.00001, loss_test:0.01964, lr:2.69e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.460, tt:4233.871\n",
      "Ep:139, loss:0.00001, loss_test:0.01967, lr:2.66e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.454, tt:4263.558\n",
      "Ep:140, loss:0.00001, loss_test:0.01967, lr:2.63e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.450, tt:4293.382\n",
      "Ep:141, loss:0.00001, loss_test:0.01969, lr:2.61e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.446, tt:4323.333\n",
      "Ep:142, loss:0.00001, loss_test:0.01972, lr:2.58e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.440, tt:4352.980\n",
      "Ep:143, loss:0.00001, loss_test:0.01977, lr:2.55e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.421, tt:4380.560\n",
      "Ep:144, loss:0.00001, loss_test:0.01979, lr:2.53e-02, fs:0.77108 (r=0.646,p=0.955),  time:30.426, tt:4411.787\n",
      "Ep:145, loss:0.00001, loss_test:0.01981, lr:2.50e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.422, tt:4441.666\n",
      "Ep:146, loss:0.00001, loss_test:0.01985, lr:2.48e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.428, tt:4472.846\n",
      "Ep:147, loss:0.00001, loss_test:0.01991, lr:2.45e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.418, tt:4501.840\n",
      "Ep:148, loss:0.00001, loss_test:0.01997, lr:2.43e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.400, tt:4529.626\n",
      "Ep:149, loss:0.00001, loss_test:0.01999, lr:2.40e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.394, tt:4559.157\n",
      "Ep:150, loss:0.00001, loss_test:0.02000, lr:2.38e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.377, tt:4586.992\n",
      "Ep:151, loss:0.00001, loss_test:0.02002, lr:2.36e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.366, tt:4615.631\n",
      "Ep:152, loss:0.00001, loss_test:0.02004, lr:2.33e-02, fs:0.76364 (r=0.636,p=0.955),  time:30.374, tt:4647.277\n",
      "Ep:153, loss:0.00001, loss_test:0.02010, lr:2.31e-02, fs:0.75610 (r=0.626,p=0.954),  time:30.376, tt:4677.899\n",
      "Ep:154, loss:0.00001, loss_test:0.02012, lr:2.29e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.369, tt:4707.154\n",
      "Ep:155, loss:0.00001, loss_test:0.02011, lr:2.26e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.377, tt:4738.874\n",
      "Ep:156, loss:0.00001, loss_test:0.02015, lr:2.24e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.380, tt:4769.688\n",
      "Ep:157, loss:0.00001, loss_test:0.02019, lr:2.22e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.388, tt:4801.371\n",
      "Ep:158, loss:0.00001, loss_test:0.02022, lr:2.20e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.391, tt:4832.174\n",
      "Ep:159, loss:0.00001, loss_test:0.02026, lr:2.17e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.382, tt:4861.069\n",
      "Ep:160, loss:0.00001, loss_test:0.02028, lr:2.15e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.381, tt:4891.292\n",
      "Ep:161, loss:0.00001, loss_test:0.02029, lr:2.13e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.393, tt:4923.608\n",
      "Ep:162, loss:0.00001, loss_test:0.02031, lr:2.11e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.389, tt:4953.366\n",
      "Ep:163, loss:0.00001, loss_test:0.02034, lr:2.09e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.397, tt:4985.164\n",
      "Ep:164, loss:0.00001, loss_test:0.02037, lr:2.07e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.401, tt:5016.178\n",
      "Ep:165, loss:0.00001, loss_test:0.02042, lr:2.05e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.402, tt:5046.775\n",
      "Ep:166, loss:0.00001, loss_test:0.02045, lr:2.03e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.406, tt:5077.750\n",
      "Ep:167, loss:0.00001, loss_test:0.02046, lr:2.01e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.401, tt:5107.317\n",
      "Ep:168, loss:0.00001, loss_test:0.02049, lr:1.99e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.399, tt:5137.479\n",
      "Ep:169, loss:0.00001, loss_test:0.02055, lr:1.97e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.394, tt:5166.966\n",
      "Ep:170, loss:0.00001, loss_test:0.02057, lr:1.95e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.384, tt:5195.616\n",
      "Ep:171, loss:0.00001, loss_test:0.02059, lr:1.93e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.385, tt:5226.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:172, loss:0.00001, loss_test:0.02061, lr:1.91e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.387, tt:5256.954\n",
      "Ep:173, loss:0.00001, loss_test:0.02064, lr:1.89e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.385, tt:5287.033\n",
      "Ep:174, loss:0.00001, loss_test:0.02063, lr:1.87e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.392, tt:5318.565\n",
      "Ep:175, loss:0.00001, loss_test:0.02065, lr:1.85e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.392, tt:5348.903\n",
      "Ep:176, loss:0.00001, loss_test:0.02068, lr:1.83e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.398, tt:5380.530\n",
      "Ep:177, loss:0.00001, loss_test:0.02072, lr:1.81e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.400, tt:5411.142\n",
      "Ep:178, loss:0.00001, loss_test:0.02075, lr:1.80e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.398, tt:5441.300\n",
      "Ep:179, loss:0.00001, loss_test:0.02076, lr:1.78e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.393, tt:5470.815\n",
      "Ep:180, loss:0.00001, loss_test:0.02079, lr:1.76e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.391, tt:5500.789\n",
      "Ep:181, loss:0.00001, loss_test:0.02081, lr:1.74e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.392, tt:5531.393\n",
      "Ep:182, loss:0.00001, loss_test:0.02082, lr:1.73e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.379, tt:5559.305\n",
      "Ep:183, loss:0.00001, loss_test:0.02084, lr:1.71e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.372, tt:5588.397\n",
      "Ep:184, loss:0.00001, loss_test:0.02088, lr:1.69e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.365, tt:5617.584\n",
      "Ep:185, loss:0.00001, loss_test:0.02090, lr:1.67e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.362, tt:5647.330\n",
      "Ep:186, loss:0.00001, loss_test:0.02093, lr:1.66e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.360, tt:5677.231\n",
      "Ep:187, loss:0.00001, loss_test:0.02094, lr:1.64e-02, fs:0.74847 (r=0.616,p=0.953),  time:30.353, tt:5706.417\n",
      "Ep:188, loss:0.00001, loss_test:0.02095, lr:1.62e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.361, tt:5738.196\n",
      "Ep:189, loss:0.00001, loss_test:0.02099, lr:1.61e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.361, tt:5768.603\n",
      "Ep:190, loss:0.00001, loss_test:0.02100, lr:1.59e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.362, tt:5799.133\n",
      "Ep:191, loss:0.00001, loss_test:0.02102, lr:1.58e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.364, tt:5829.816\n",
      "Ep:192, loss:0.00001, loss_test:0.02104, lr:1.56e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.369, tt:5861.310\n",
      "Ep:193, loss:0.00001, loss_test:0.02106, lr:1.54e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.366, tt:5890.986\n",
      "Ep:194, loss:0.00001, loss_test:0.02107, lr:1.53e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.366, tt:5921.361\n",
      "Ep:195, loss:0.00001, loss_test:0.02109, lr:1.51e-02, fs:0.75309 (r=0.616,p=0.968),  time:30.356, tt:5949.708\n",
      "Ep:196, loss:0.00001, loss_test:0.02112, lr:1.50e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.351, tt:5979.167\n",
      "Ep:197, loss:0.00001, loss_test:0.02113, lr:1.48e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.348, tt:6008.956\n",
      "Ep:198, loss:0.00001, loss_test:0.02115, lr:1.47e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.346, tt:6038.947\n",
      "Ep:199, loss:0.00001, loss_test:0.02117, lr:1.45e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.343, tt:6068.579\n",
      "Ep:200, loss:0.00001, loss_test:0.02119, lr:1.44e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.341, tt:6098.558\n",
      "Ep:201, loss:0.00001, loss_test:0.02119, lr:1.43e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.331, tt:6126.960\n",
      "Ep:202, loss:0.00001, loss_test:0.02122, lr:1.41e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.331, tt:6157.146\n",
      "Ep:203, loss:0.00001, loss_test:0.02124, lr:1.40e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.329, tt:6187.129\n",
      "Ep:204, loss:0.00001, loss_test:0.02126, lr:1.38e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.318, tt:6215.161\n",
      "Ep:205, loss:0.00001, loss_test:0.02127, lr:1.37e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.318, tt:6245.449\n",
      "Ep:206, loss:0.00001, loss_test:0.02130, lr:1.36e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.320, tt:6276.165\n",
      "Ep:207, loss:0.00001, loss_test:0.02131, lr:1.34e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.317, tt:6305.913\n",
      "Ep:208, loss:0.00001, loss_test:0.02132, lr:1.33e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.321, tt:6337.052\n",
      "Ep:209, loss:0.00001, loss_test:0.02134, lr:1.32e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.320, tt:6367.192\n",
      "Ep:210, loss:0.00001, loss_test:0.02135, lr:1.30e-02, fs:0.74534 (r=0.606,p=0.968),  time:30.320, tt:6397.472\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14197, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.975, tt:31.975\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14082, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.467, tt:60.933\n",
      "Ep:2, loss:0.00028, loss_test:0.13876, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.767, tt:92.300\n",
      "Ep:3, loss:0.00027, loss_test:0.13548, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.015, tt:120.060\n",
      "Ep:4, loss:0.00026, loss_test:0.13041, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.683, tt:148.415\n",
      "Ep:5, loss:0.00025, loss_test:0.12337, lr:1.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:29.961, tt:179.763\n",
      "Ep:6, loss:0.00024, loss_test:0.11633, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:29.831, tt:208.818\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11265, lr:1.00e-02, fs:0.68519 (r=0.747,p=0.632),  time:30.148, tt:241.184\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11145, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:30.519, tt:274.674\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11071, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:30.568, tt:305.679\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10852, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:30.813, tt:338.940\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10650, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:30.955, tt:371.457\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10585, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:31.173, tt:405.251\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10483, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:31.353, tt:438.936\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10344, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:31.503, tt:472.538\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10176, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:31.593, tt:505.492\n",
      "Ep:16, loss:0.00018, loss_test:0.10022, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:31.702, tt:538.935\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09885, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:31.784, tt:572.120\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09787, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:31.857, tt:605.274\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09697, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:32.123, tt:642.455\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.09592, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:32.185, tt:675.890\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09459, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:32.261, tt:709.737\n",
      "Ep:22, loss:0.00015, loss_test:0.09362, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:32.318, tt:743.322\n",
      "Ep:23, loss:0.00015, loss_test:0.09294, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:32.422, tt:778.129\n",
      "Ep:24, loss:0.00015, loss_test:0.09277, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:32.457, tt:811.413\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09224, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:32.512, tt:845.301\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00014, loss_test:0.09195, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:32.526, tt:878.212\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09108, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:32.562, tt:911.729\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.09052, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:32.632, tt:946.330\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08974, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:32.719, tt:981.576\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.08877, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:32.757, tt:1015.479\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08803, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:32.706, tt:1046.591\n",
      "Ep:32, loss:0.00012, loss_test:0.08757, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:32.723, tt:1079.857\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08751, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:32.723, tt:1112.586\n",
      "Ep:34, loss:0.00012, loss_test:0.08709, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:32.719, tt:1145.169\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08710, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:32.730, tt:1178.286\n",
      "Ep:36, loss:0.00011, loss_test:0.08630, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:32.750, tt:1211.765\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08614, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:32.754, tt:1244.666\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.08574, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:32.768, tt:1277.967\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08600, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:32.770, tt:1310.817\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08452, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:32.749, tt:1342.714\n",
      "Ep:41, loss:0.00010, loss_test:0.08526, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:32.716, tt:1374.056\n",
      "Ep:42, loss:0.00010, loss_test:0.08533, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:32.728, tt:1407.315\n",
      "Ep:43, loss:0.00010, loss_test:0.08428, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:32.743, tt:1440.698\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.08406, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:32.765, tt:1474.421\n",
      "Ep:45, loss:0.00009, loss_test:0.08447, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:32.775, tt:1507.632\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.08369, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.757, tt:1539.573\n",
      "Ep:47, loss:0.00009, loss_test:0.08366, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:32.749, tt:1571.964\n",
      "Ep:48, loss:0.00009, loss_test:0.08297, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:32.740, tt:1604.279\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.08269, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:32.758, tt:1637.891\n",
      "Ep:50, loss:0.00009, loss_test:0.08248, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:32.782, tt:1671.871\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.08379, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:32.780, tt:1704.578\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.08043, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:32.769, tt:1736.762\n",
      "Ep:53, loss:0.00008, loss_test:0.08195, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:32.768, tt:1769.488\n",
      "Ep:54, loss:0.00008, loss_test:0.08048, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:32.776, tt:1802.672\n",
      "Ep:55, loss:0.00008, loss_test:0.08303, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:32.779, tt:1835.612\n",
      "Ep:56, loss:0.00008, loss_test:0.07931, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:32.776, tt:1868.243\n",
      "Ep:57, loss:0.00008, loss_test:0.08184, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:32.752, tt:1899.589\n",
      "Ep:58, loss:0.00007, loss_test:0.07977, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:32.738, tt:1931.520\n",
      "Ep:59, loss:0.00007, loss_test:0.07911, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:32.719, tt:1963.124\n",
      "Ep:60, loss:0.00007, loss_test:0.08025, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:32.711, tt:1995.392\n",
      "Ep:61, loss:0.00007, loss_test:0.07977, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:32.720, tt:2028.621\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.07738, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:32.736, tt:2062.383\n",
      "Ep:63, loss:0.00007, loss_test:0.07938, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:32.708, tt:2093.330\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00007, loss_test:0.07680, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:32.697, tt:2125.284\n",
      "Ep:65, loss:0.00006, loss_test:0.07820, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:32.692, tt:2157.654\n",
      "Ep:66, loss:0.00006, loss_test:0.07661, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:32.670, tt:2188.915\n",
      "Ep:67, loss:0.00006, loss_test:0.07723, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:32.667, tt:2221.365\n",
      "Ep:68, loss:0.00006, loss_test:0.07672, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:32.657, tt:2253.344\n",
      "Ep:69, loss:0.00006, loss_test:0.07735, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:32.644, tt:2285.066\n",
      "Ep:70, loss:0.00006, loss_test:0.07464, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:32.627, tt:2316.513\n",
      "Ep:71, loss:0.00006, loss_test:0.07783, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:32.628, tt:2349.188\n",
      "Ep:72, loss:0.00006, loss_test:0.07392, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:32.611, tt:2380.574\n",
      "Ep:73, loss:0.00006, loss_test:0.07652, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:32.614, tt:2413.423\n",
      "Ep:74, loss:0.00005, loss_test:0.07357, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:32.607, tt:2445.499\n",
      "Ep:75, loss:0.00005, loss_test:0.07688, lr:9.90e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.617, tt:2478.906\n",
      "Ep:76, loss:0.00005, loss_test:0.07442, lr:9.80e-03, fs:0.86010 (r=0.838,p=0.883),  time:32.611, tt:2511.025\n",
      "Ep:77, loss:0.00005, loss_test:0.07557, lr:9.70e-03, fs:0.86598 (r=0.848,p=0.884),  time:32.612, tt:2543.768\n",
      "Ep:78, loss:0.00005, loss_test:0.07534, lr:9.61e-03, fs:0.85263 (r=0.818,p=0.890),  time:32.632, tt:2577.888\n",
      "Ep:79, loss:0.00005, loss_test:0.07428, lr:9.51e-03, fs:0.86154 (r=0.848,p=0.875),  time:32.635, tt:2610.812\n",
      "Ep:80, loss:0.00005, loss_test:0.07699, lr:9.41e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.645, tt:2644.215\n",
      "Ep:81, loss:0.00005, loss_test:0.07375, lr:9.32e-03, fs:0.86458 (r=0.838,p=0.892),  time:32.655, tt:2677.719\n",
      "Ep:82, loss:0.00005, loss_test:0.07450, lr:9.23e-03, fs:0.87047 (r=0.848,p=0.894),  time:32.646, tt:2709.656\n",
      "Ep:83, loss:0.00005, loss_test:0.07574, lr:9.14e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.640, tt:2741.799\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.07459, lr:9.14e-03, fs:0.85714 (r=0.848,p=0.866),  time:32.631, tt:2773.612\n",
      "Ep:85, loss:0.00005, loss_test:0.07530, lr:9.14e-03, fs:0.86170 (r=0.818,p=0.910),  time:32.623, tt:2805.559\n",
      "Ep:86, loss:0.00005, loss_test:0.07365, lr:9.14e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.611, tt:2837.114\n",
      "Ep:87, loss:0.00005, loss_test:0.07288, lr:9.14e-03, fs:0.87047 (r=0.848,p=0.894),  time:32.607, tt:2869.385\n",
      "Ep:88, loss:0.00005, loss_test:0.07586, lr:9.14e-03, fs:0.86170 (r=0.818,p=0.910),  time:32.580, tt:2899.656\n",
      "Ep:89, loss:0.00005, loss_test:0.07377, lr:9.14e-03, fs:0.86598 (r=0.848,p=0.884),  time:32.577, tt:2931.967\n",
      "Ep:90, loss:0.00005, loss_test:0.07440, lr:9.14e-03, fs:0.86170 (r=0.818,p=0.910),  time:32.567, tt:2963.564\n",
      "Ep:91, loss:0.00004, loss_test:0.07658, lr:9.14e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.571, tt:2996.558\n",
      "Ep:92, loss:0.00004, loss_test:0.07147, lr:9.14e-03, fs:0.86010 (r=0.838,p=0.883),  time:32.584, tt:3030.317\n",
      "Ep:93, loss:0.00004, loss_test:0.07781, lr:9.14e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.565, tt:3061.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:94, loss:0.00004, loss_test:0.07095, lr:9.14e-03, fs:0.85417 (r=0.828,p=0.882),  time:32.575, tt:3094.603\n",
      "Ep:95, loss:0.00004, loss_test:0.07463, lr:9.04e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.559, tt:3125.627\n",
      "Ep:96, loss:0.00004, loss_test:0.07269, lr:8.95e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.565, tt:3158.793\n",
      "Ep:97, loss:0.00004, loss_test:0.07409, lr:8.86e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.572, tt:3192.044\n",
      "Ep:98, loss:0.00004, loss_test:0.07337, lr:8.78e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.561, tt:3223.551\n",
      "Ep:99, loss:0.00004, loss_test:0.07407, lr:8.69e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.556, tt:3255.622\n",
      "Ep:100, loss:0.00004, loss_test:0.07483, lr:8.60e-03, fs:0.86772 (r=0.828,p=0.911),  time:32.556, tt:3288.130\n",
      "Ep:101, loss:0.00004, loss_test:0.07288, lr:8.51e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.551, tt:3320.157\n",
      "Ep:102, loss:0.00004, loss_test:0.07448, lr:8.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.548, tt:3352.473\n",
      "Ep:103, loss:0.00004, loss_test:0.07422, lr:8.35e-03, fs:0.86772 (r=0.828,p=0.911),  time:32.529, tt:3383.060\n",
      "Ep:104, loss:0.00004, loss_test:0.07587, lr:8.26e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.520, tt:3414.642\n",
      "Ep:105, loss:0.00004, loss_test:0.07306, lr:8.18e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.519, tt:3446.993\n",
      "Ep:106, loss:0.00004, loss_test:0.07581, lr:8.10e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.517, tt:3479.356\n",
      "Ep:107, loss:0.00004, loss_test:0.07294, lr:8.02e-03, fs:0.86772 (r=0.828,p=0.911),  time:32.492, tt:3509.127\n",
      "Ep:108, loss:0.00003, loss_test:0.07433, lr:7.94e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.499, tt:3542.355\n",
      "Ep:109, loss:0.00003, loss_test:0.07414, lr:7.86e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.486, tt:3573.461\n",
      "Ep:110, loss:0.00003, loss_test:0.07413, lr:7.78e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.476, tt:3604.828\n",
      "Ep:111, loss:0.00003, loss_test:0.07380, lr:7.70e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.460, tt:3635.523\n",
      "Ep:112, loss:0.00003, loss_test:0.07438, lr:7.62e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.462, tt:3668.207\n",
      "Ep:113, loss:0.00003, loss_test:0.07551, lr:7.55e-03, fs:0.87500 (r=0.848,p=0.903),  time:32.464, tt:3700.924\n",
      "Ep:114, loss:0.00003, loss_test:0.07396, lr:7.47e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.457, tt:3732.503\n",
      "Ep:115, loss:0.00003, loss_test:0.07535, lr:7.40e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.458, tt:3765.134\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00003, loss_test:0.07390, lr:7.40e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.455, tt:3797.245\n",
      "Ep:117, loss:0.00003, loss_test:0.07524, lr:7.40e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.451, tt:3829.169\n",
      "Ep:118, loss:0.00003, loss_test:0.07483, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.429, tt:3859.042\n",
      "Ep:119, loss:0.00003, loss_test:0.07482, lr:7.40e-03, fs:0.88298 (r=0.838,p=0.933),  time:32.416, tt:3889.961\n",
      "Ep:120, loss:0.00003, loss_test:0.07655, lr:7.40e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.417, tt:3922.509\n",
      "Ep:121, loss:0.00003, loss_test:0.07609, lr:7.40e-03, fs:0.88298 (r=0.838,p=0.933),  time:32.425, tt:3955.832\n",
      "Ep:122, loss:0.00003, loss_test:0.07561, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.438, tt:3989.920\n",
      "Ep:123, loss:0.00003, loss_test:0.07589, lr:7.40e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.442, tt:4022.768\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00003, loss_test:0.07472, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.441, tt:4055.170\n",
      "Ep:125, loss:0.00003, loss_test:0.07763, lr:7.40e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.433, tt:4086.590\n",
      "Ep:126, loss:0.00003, loss_test:0.07606, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.438, tt:4119.644\n",
      "Ep:127, loss:0.00003, loss_test:0.07653, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.438, tt:4152.026\n",
      "Ep:128, loss:0.00003, loss_test:0.07580, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.430, tt:4183.427\n",
      "Ep:129, loss:0.00003, loss_test:0.07784, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.426, tt:4215.373\n",
      "Ep:130, loss:0.00003, loss_test:0.07501, lr:7.40e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.422, tt:4247.309\n",
      "Ep:131, loss:0.00003, loss_test:0.07849, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.415, tt:4278.761\n",
      "Ep:132, loss:0.00003, loss_test:0.07777, lr:7.40e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.401, tt:4309.280\n",
      "Ep:133, loss:0.00003, loss_test:0.07634, lr:7.40e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.394, tt:4340.752\n",
      "Ep:134, loss:0.00003, loss_test:0.07839, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.377, tt:4370.961\n",
      "Ep:135, loss:0.00003, loss_test:0.07770, lr:7.32e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.379, tt:4403.530\n",
      "Ep:136, loss:0.00003, loss_test:0.07366, lr:7.25e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.371, tt:4434.798\n",
      "Ep:137, loss:0.00003, loss_test:0.07912, lr:7.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.361, tt:4465.800\n",
      "Ep:138, loss:0.00003, loss_test:0.07611, lr:7.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.349, tt:4496.563\n",
      "Ep:139, loss:0.00002, loss_test:0.07605, lr:7.03e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.345, tt:4528.334\n",
      "Ep:140, loss:0.00002, loss_test:0.07828, lr:6.96e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.336, tt:4559.414\n",
      "Ep:141, loss:0.00002, loss_test:0.07659, lr:6.89e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.324, tt:4589.975\n",
      "Ep:142, loss:0.00002, loss_test:0.07555, lr:6.83e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.329, tt:4622.986\n",
      "Ep:143, loss:0.00002, loss_test:0.07784, lr:6.76e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.319, tt:4653.989\n",
      "Ep:144, loss:0.00002, loss_test:0.07626, lr:6.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.319, tt:4686.280\n",
      "Ep:145, loss:0.00002, loss_test:0.07507, lr:6.62e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.318, tt:4718.422\n",
      "Ep:146, loss:0.00002, loss_test:0.07860, lr:6.56e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.315, tt:4750.233\n",
      "Ep:147, loss:0.00002, loss_test:0.07580, lr:6.49e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.309, tt:4781.708\n",
      "Ep:148, loss:0.00002, loss_test:0.07613, lr:6.43e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.299, tt:4812.578\n",
      "Ep:149, loss:0.00002, loss_test:0.07669, lr:6.36e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.300, tt:4844.965\n",
      "Ep:150, loss:0.00002, loss_test:0.07695, lr:6.30e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.282, tt:4874.606\n",
      "Ep:151, loss:0.00002, loss_test:0.07532, lr:6.24e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.264, tt:4904.123\n",
      "Ep:152, loss:0.00002, loss_test:0.07662, lr:6.17e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.263, tt:4936.275\n",
      "Ep:153, loss:0.00002, loss_test:0.07746, lr:6.11e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.255, tt:4967.221\n",
      "Ep:154, loss:0.00002, loss_test:0.07541, lr:6.05e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.248, tt:4998.364\n",
      "Ep:155, loss:0.00002, loss_test:0.07802, lr:5.99e-03, fs:0.88770 (r=0.838,p=0.943),  time:32.245, tt:5030.230\n",
      "Ep:156, loss:0.00002, loss_test:0.07639, lr:5.93e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.243, tt:5062.189\n",
      "Ep:157, loss:0.00002, loss_test:0.07723, lr:5.87e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.243, tt:5094.349\n",
      "Ep:158, loss:0.00002, loss_test:0.07619, lr:5.81e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.226, tt:5123.980\n",
      "Ep:159, loss:0.00002, loss_test:0.07625, lr:5.75e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.224, tt:5155.887\n",
      "Ep:160, loss:0.00002, loss_test:0.07672, lr:5.70e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.215, tt:5186.646\n",
      "Ep:161, loss:0.00002, loss_test:0.07520, lr:5.64e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.207, tt:5217.572\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00002, loss_test:0.07876, lr:5.64e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.206, tt:5249.582\n",
      "Ep:163, loss:0.00002, loss_test:0.07576, lr:5.64e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.200, tt:5280.718\n",
      "Ep:164, loss:0.00002, loss_test:0.07551, lr:5.64e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.189, tt:5311.141\n",
      "Ep:165, loss:0.00002, loss_test:0.07753, lr:5.64e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.197, tt:5344.648\n",
      "Ep:166, loss:0.00002, loss_test:0.07603, lr:5.64e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.199, tt:5377.274\n",
      "Ep:167, loss:0.00002, loss_test:0.07607, lr:5.64e-03, fs:0.89362 (r=0.848,p=0.944),  time:32.190, tt:5407.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00002, loss_test:0.07628, lr:5.64e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.188, tt:5439.725\n",
      "Ep:169, loss:0.00002, loss_test:0.07597, lr:5.64e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.192, tt:5472.668\n",
      "Ep:170, loss:0.00002, loss_test:0.07586, lr:5.64e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.186, tt:5503.871\n",
      "Ep:171, loss:0.00002, loss_test:0.07679, lr:5.64e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.183, tt:5535.438\n",
      "Ep:172, loss:0.00002, loss_test:0.07646, lr:5.64e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.178, tt:5566.789\n",
      "Ep:173, loss:0.00002, loss_test:0.07612, lr:5.58e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.176, tt:5598.565\n",
      "Ep:174, loss:0.00002, loss_test:0.07693, lr:5.53e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.178, tt:5631.157\n",
      "Ep:175, loss:0.00002, loss_test:0.07533, lr:5.47e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.178, tt:5663.259\n",
      "Ep:176, loss:0.00001, loss_test:0.07676, lr:5.42e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.185, tt:5696.718\n",
      "Ep:177, loss:0.00001, loss_test:0.07671, lr:5.36e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.178, tt:5727.629\n",
      "Ep:178, loss:0.00001, loss_test:0.07602, lr:5.31e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.185, tt:5761.144\n",
      "Ep:179, loss:0.00001, loss_test:0.07605, lr:5.26e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.189, tt:5794.022\n",
      "Ep:180, loss:0.00001, loss_test:0.07589, lr:5.20e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.184, tt:5825.262\n",
      "Ep:181, loss:0.00001, loss_test:0.07680, lr:5.15e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.179, tt:5856.504\n",
      "Ep:182, loss:0.00001, loss_test:0.07705, lr:5.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.173, tt:5887.604\n",
      "Ep:183, loss:0.00001, loss_test:0.07580, lr:5.05e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.169, tt:5919.155\n",
      "Ep:184, loss:0.00001, loss_test:0.07701, lr:5.00e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.170, tt:5951.542\n",
      "Ep:185, loss:0.00001, loss_test:0.07683, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.162, tt:5982.185\n",
      "Ep:186, loss:0.00001, loss_test:0.07642, lr:4.90e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.164, tt:6014.719\n",
      "Ep:187, loss:0.00001, loss_test:0.07787, lr:4.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.164, tt:6046.814\n",
      "Ep:188, loss:0.00001, loss_test:0.07607, lr:4.80e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.157, tt:6077.629\n",
      "Ep:189, loss:0.00001, loss_test:0.07721, lr:4.75e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.151, tt:6108.769\n",
      "Ep:190, loss:0.00001, loss_test:0.07727, lr:4.71e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.153, tt:6141.162\n",
      "Ep:191, loss:0.00001, loss_test:0.07746, lr:4.66e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.170, tt:6176.604\n",
      "Ep:192, loss:0.00001, loss_test:0.07621, lr:4.61e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.158, tt:6206.579\n",
      "Ep:193, loss:0.00001, loss_test:0.07732, lr:4.57e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.150, tt:6237.005\n",
      "Ep:194, loss:0.00001, loss_test:0.07736, lr:4.52e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.136, tt:6266.548\n",
      "Ep:195, loss:0.00001, loss_test:0.07718, lr:4.48e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.139, tt:6299.251\n",
      "Ep:196, loss:0.00001, loss_test:0.07687, lr:4.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.138, tt:6331.098\n",
      "Ep:197, loss:0.00001, loss_test:0.07687, lr:4.39e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.131, tt:6361.929\n",
      "Ep:198, loss:0.00001, loss_test:0.07744, lr:4.34e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.133, tt:6394.408\n",
      "Ep:199, loss:0.00001, loss_test:0.07644, lr:4.30e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.126, tt:6425.182\n",
      "Ep:200, loss:0.00001, loss_test:0.07733, lr:4.26e-03, fs:0.86813 (r=0.798,p=0.952),  time:32.122, tt:6456.595\n",
      "Ep:201, loss:0.00001, loss_test:0.07702, lr:4.21e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.112, tt:6486.697\n",
      "Ep:202, loss:0.00001, loss_test:0.07668, lr:4.17e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.111, tt:6518.613\n",
      "Ep:203, loss:0.00001, loss_test:0.07712, lr:4.13e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.113, tt:6550.980\n",
      "Ep:204, loss:0.00001, loss_test:0.07698, lr:4.09e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.105, tt:6581.539\n",
      "Ep:205, loss:0.00001, loss_test:0.07653, lr:4.05e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.108, tt:6614.182\n",
      "Ep:206, loss:0.00001, loss_test:0.07741, lr:4.01e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.106, tt:6645.864\n",
      "Ep:207, loss:0.00001, loss_test:0.07750, lr:3.97e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.104, tt:6677.554\n",
      "Ep:208, loss:0.00001, loss_test:0.07634, lr:3.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.106, tt:6710.205\n",
      "Ep:209, loss:0.00001, loss_test:0.07739, lr:3.89e-03, fs:0.89247 (r=0.838,p=0.954),  time:32.104, tt:6741.872\n",
      "Ep:210, loss:0.00001, loss_test:0.07771, lr:3.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:32.105, tt:6774.236\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02003, lr:6.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:28.135, tt:28.135\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:27.664, tt:55.328\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02295, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.604, tt:79.811\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02312, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.207, tt:100.826\n",
      "Ep:4, loss:0.00004, loss_test:0.02240, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.046, tt:120.229\n",
      "Ep:5, loss:0.00004, loss_test:0.02115, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:23.448, tt:140.688\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:24.072, tt:168.505\n",
      "Ep:7, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.67164 (r=0.909,p=0.533),  time:25.051, tt:200.407\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01852, lr:6.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:25.663, tt:230.968\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:25.857, tt:258.571\n",
      "Ep:10, loss:0.00004, loss_test:0.01783, lr:6.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:26.120, tt:287.318\n",
      "Ep:11, loss:0.00003, loss_test:0.01745, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:26.333, tt:316.001\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:26.623, tt:346.094\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:26.836, tt:375.702\n",
      "Ep:14, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.72797 (r=0.960,p=0.586),  time:27.062, tt:405.937\n",
      "Ep:15, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:27.237, tt:435.796\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:27.469, tt:466.976\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:27.583, tt:496.488\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01692, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:27.735, tt:526.973\n",
      "Ep:19, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:27.864, tt:557.283\n",
      "Ep:20, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.73913 (r=0.859,p=0.649),  time:27.996, tt:587.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:28.096, tt:618.109\n",
      "Ep:22, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:28.199, tt:648.588\n",
      "Ep:23, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:28.297, tt:679.131\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:28.359, tt:708.984\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01647, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:28.446, tt:739.605\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01636, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:28.530, tt:770.310\n",
      "Ep:27, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:28.627, tt:801.569\n",
      "Ep:28, loss:0.00002, loss_test:0.01621, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:28.647, tt:830.761\n",
      "Ep:29, loss:0.00002, loss_test:0.01616, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:28.674, tt:860.212\n",
      "Ep:30, loss:0.00002, loss_test:0.01610, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:28.745, tt:891.102\n",
      "Ep:31, loss:0.00002, loss_test:0.01602, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:28.838, tt:922.809\n",
      "Ep:32, loss:0.00002, loss_test:0.01595, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:28.855, tt:952.220\n",
      "Ep:33, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:28.973, tt:985.081\n",
      "Ep:34, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:28.978, tt:1014.216\n",
      "Ep:35, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:29.019, tt:1044.667\n",
      "Ep:36, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:29.106, tt:1076.929\n",
      "Ep:37, loss:0.00002, loss_test:0.01589, lr:5.94e-02, fs:0.74419 (r=0.808,p=0.690),  time:29.113, tt:1106.286\n",
      "Ep:38, loss:0.00002, loss_test:0.01578, lr:5.88e-02, fs:0.74419 (r=0.808,p=0.690),  time:29.162, tt:1137.333\n",
      "Ep:39, loss:0.00002, loss_test:0.01570, lr:5.82e-02, fs:0.75117 (r=0.808,p=0.702),  time:29.198, tt:1167.926\n",
      "Ep:40, loss:0.00002, loss_test:0.01568, lr:5.76e-02, fs:0.75829 (r=0.808,p=0.714),  time:29.224, tt:1198.197\n",
      "Ep:41, loss:0.00002, loss_test:0.01568, lr:5.71e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.263, tt:1229.036\n",
      "Ep:42, loss:0.00002, loss_test:0.01564, lr:5.65e-02, fs:0.75598 (r=0.798,p=0.718),  time:29.308, tt:1260.235\n",
      "Ep:43, loss:0.00002, loss_test:0.01558, lr:5.59e-02, fs:0.75962 (r=0.798,p=0.725),  time:29.331, tt:1290.582\n",
      "Ep:44, loss:0.00002, loss_test:0.01556, lr:5.54e-02, fs:0.75362 (r=0.788,p=0.722),  time:29.324, tt:1319.578\n",
      "Ep:45, loss:0.00002, loss_test:0.01556, lr:5.48e-02, fs:0.75728 (r=0.788,p=0.729),  time:29.319, tt:1348.681\n",
      "Ep:46, loss:0.00002, loss_test:0.01553, lr:5.43e-02, fs:0.76699 (r=0.798,p=0.738),  time:29.310, tt:1377.592\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01552, lr:5.43e-02, fs:0.76098 (r=0.788,p=0.736),  time:29.341, tt:1408.369\n",
      "Ep:48, loss:0.00002, loss_test:0.01547, lr:5.43e-02, fs:0.76847 (r=0.788,p=0.750),  time:29.373, tt:1439.257\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01542, lr:5.43e-02, fs:0.77612 (r=0.788,p=0.765),  time:29.410, tt:1470.524\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01538, lr:5.43e-02, fs:0.77612 (r=0.788,p=0.765),  time:29.435, tt:1501.170\n",
      "Ep:51, loss:0.00002, loss_test:0.01539, lr:5.43e-02, fs:0.78000 (r=0.788,p=0.772),  time:29.462, tt:1532.017\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01542, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.491, tt:1563.042\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01539, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.506, tt:1593.332\n",
      "Ep:54, loss:0.00002, loss_test:0.01535, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.519, tt:1623.544\n",
      "Ep:55, loss:0.00002, loss_test:0.01538, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.496, tt:1651.771\n",
      "Ep:56, loss:0.00002, loss_test:0.01539, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.503, tt:1681.686\n",
      "Ep:57, loss:0.00002, loss_test:0.01539, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.502, tt:1711.097\n",
      "Ep:58, loss:0.00002, loss_test:0.01536, lr:5.43e-02, fs:0.79188 (r=0.788,p=0.796),  time:29.505, tt:1740.780\n",
      "Ep:59, loss:0.00002, loss_test:0.01544, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:29.538, tt:1772.275\n",
      "Ep:60, loss:0.00001, loss_test:0.01543, lr:5.43e-02, fs:0.78571 (r=0.778,p=0.794),  time:29.552, tt:1802.678\n",
      "Ep:61, loss:0.00001, loss_test:0.01543, lr:5.43e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.573, tt:1833.522\n",
      "Ep:62, loss:0.00001, loss_test:0.01548, lr:5.43e-02, fs:0.78974 (r=0.778,p=0.802),  time:29.566, tt:1862.677\n",
      "Ep:63, loss:0.00001, loss_test:0.01544, lr:5.43e-02, fs:0.78351 (r=0.768,p=0.800),  time:29.577, tt:1892.912\n",
      "Ep:64, loss:0.00001, loss_test:0.01545, lr:5.37e-02, fs:0.77720 (r=0.758,p=0.798),  time:29.599, tt:1923.955\n",
      "Ep:65, loss:0.00001, loss_test:0.01546, lr:5.32e-02, fs:0.78125 (r=0.758,p=0.806),  time:29.583, tt:1952.510\n",
      "Ep:66, loss:0.00001, loss_test:0.01547, lr:5.27e-02, fs:0.78125 (r=0.758,p=0.806),  time:29.584, tt:1982.149\n",
      "Ep:67, loss:0.00001, loss_test:0.01545, lr:5.21e-02, fs:0.78125 (r=0.758,p=0.806),  time:29.624, tt:2014.403\n",
      "Ep:68, loss:0.00001, loss_test:0.01540, lr:5.16e-02, fs:0.78534 (r=0.758,p=0.815),  time:29.643, tt:2045.395\n",
      "Ep:69, loss:0.00001, loss_test:0.01548, lr:5.11e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.649, tt:2075.447\n",
      "Ep:70, loss:0.00001, loss_test:0.01551, lr:5.06e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.672, tt:2106.717\n",
      "Ep:71, loss:0.00001, loss_test:0.01548, lr:5.01e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.700, tt:2138.373\n",
      "Ep:72, loss:0.00001, loss_test:0.01555, lr:4.96e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.707, tt:2168.623\n",
      "Ep:73, loss:0.00001, loss_test:0.01558, lr:4.91e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.722, tt:2199.426\n",
      "Ep:74, loss:0.00001, loss_test:0.01559, lr:4.86e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.750, tt:2231.270\n",
      "Ep:75, loss:0.00001, loss_test:0.01557, lr:4.81e-02, fs:0.79365 (r=0.758,p=0.833),  time:29.768, tt:2262.388\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01556, lr:4.81e-02, fs:0.78947 (r=0.758,p=0.824),  time:29.794, tt:2294.126\n",
      "Ep:77, loss:0.00001, loss_test:0.01558, lr:4.81e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.808, tt:2325.046\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01561, lr:4.81e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.828, tt:2356.426\n",
      "Ep:79, loss:0.00001, loss_test:0.01565, lr:4.81e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.841, tt:2387.295\n",
      "Ep:80, loss:0.00001, loss_test:0.01566, lr:4.81e-02, fs:0.79787 (r=0.758,p=0.843),  time:29.844, tt:2417.342\n",
      "Ep:81, loss:0.00001, loss_test:0.01571, lr:4.81e-02, fs:0.80645 (r=0.758,p=0.862),  time:29.852, tt:2447.824\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01572, lr:4.81e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.859, tt:2478.327\n",
      "Ep:83, loss:0.00001, loss_test:0.01576, lr:4.81e-02, fs:0.79121 (r=0.727,p=0.867),  time:29.864, tt:2508.595\n",
      "Ep:84, loss:0.00001, loss_test:0.01574, lr:4.81e-02, fs:0.78453 (r=0.717,p=0.866),  time:29.868, tt:2538.774\n",
      "Ep:85, loss:0.00001, loss_test:0.01575, lr:4.81e-02, fs:0.78889 (r=0.717,p=0.877),  time:29.884, tt:2570.029\n",
      "Ep:86, loss:0.00001, loss_test:0.01577, lr:4.81e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.887, tt:2600.133\n",
      "Ep:87, loss:0.00001, loss_test:0.01574, lr:4.81e-02, fs:0.78212 (r=0.707,p=0.875),  time:29.914, tt:2632.421\n",
      "Ep:88, loss:0.00001, loss_test:0.01585, lr:4.81e-02, fs:0.77528 (r=0.697,p=0.873),  time:29.939, tt:2664.545\n",
      "Ep:89, loss:0.00001, loss_test:0.01583, lr:4.81e-02, fs:0.76836 (r=0.687,p=0.872),  time:29.962, tt:2696.600\n",
      "Ep:90, loss:0.00001, loss_test:0.01584, lr:4.81e-02, fs:0.76836 (r=0.687,p=0.872),  time:29.975, tt:2727.747\n",
      "Ep:91, loss:0.00001, loss_test:0.01591, lr:4.81e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.983, tt:2758.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:92, loss:0.00001, loss_test:0.01594, lr:4.81e-02, fs:0.76136 (r=0.677,p=0.870),  time:29.996, tt:2789.585\n",
      "Ep:93, loss:0.00001, loss_test:0.01591, lr:4.76e-02, fs:0.76136 (r=0.677,p=0.870),  time:30.005, tt:2820.440\n",
      "Ep:94, loss:0.00001, loss_test:0.01593, lr:4.71e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.015, tt:2851.441\n",
      "Ep:95, loss:0.00001, loss_test:0.01596, lr:4.67e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.033, tt:2883.165\n",
      "Ep:96, loss:0.00001, loss_test:0.01599, lr:4.62e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.030, tt:2912.908\n",
      "Ep:97, loss:0.00001, loss_test:0.01600, lr:4.57e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.043, tt:2944.226\n",
      "Ep:98, loss:0.00001, loss_test:0.01603, lr:4.53e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.041, tt:2974.052\n",
      "Ep:99, loss:0.00001, loss_test:0.01610, lr:4.48e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.058, tt:3005.811\n",
      "Ep:100, loss:0.00001, loss_test:0.01609, lr:4.44e-02, fs:0.76571 (r=0.677,p=0.882),  time:30.072, tt:3037.226\n",
      "Ep:101, loss:0.00001, loss_test:0.01611, lr:4.39e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.067, tt:3066.841\n",
      "Ep:102, loss:0.00001, loss_test:0.01614, lr:4.35e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.078, tt:3098.016\n",
      "Ep:103, loss:0.00001, loss_test:0.01616, lr:4.31e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.094, tt:3129.771\n",
      "Ep:104, loss:0.00001, loss_test:0.01614, lr:4.26e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.095, tt:3160.010\n",
      "Ep:105, loss:0.00001, loss_test:0.01615, lr:4.22e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.095, tt:3190.045\n",
      "Ep:106, loss:0.00001, loss_test:0.01621, lr:4.18e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.098, tt:3220.515\n",
      "Ep:107, loss:0.00001, loss_test:0.01619, lr:4.14e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.097, tt:3250.443\n",
      "Ep:108, loss:0.00001, loss_test:0.01622, lr:4.10e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.101, tt:3280.965\n",
      "Ep:109, loss:0.00001, loss_test:0.01629, lr:4.05e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.117, tt:3312.867\n",
      "Ep:110, loss:0.00001, loss_test:0.01628, lr:4.01e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.124, tt:3343.801\n",
      "Ep:111, loss:0.00001, loss_test:0.01629, lr:3.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.103, tt:3371.572\n",
      "Ep:112, loss:0.00001, loss_test:0.01631, lr:3.93e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.099, tt:3401.174\n",
      "Ep:113, loss:0.00001, loss_test:0.01638, lr:3.89e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.101, tt:3431.562\n",
      "Ep:114, loss:0.00001, loss_test:0.01640, lr:3.86e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.090, tt:3460.324\n",
      "Ep:115, loss:0.00001, loss_test:0.01645, lr:3.82e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.083, tt:3489.633\n",
      "Ep:116, loss:0.00001, loss_test:0.01646, lr:3.78e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.070, tt:3518.155\n",
      "Ep:117, loss:0.00001, loss_test:0.01643, lr:3.74e-02, fs:0.77457 (r=0.677,p=0.905),  time:30.068, tt:3548.033\n",
      "Ep:118, loss:0.00001, loss_test:0.01650, lr:3.70e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.053, tt:3576.284\n",
      "Ep:119, loss:0.00001, loss_test:0.01652, lr:3.67e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.053, tt:3606.364\n",
      "Ep:120, loss:0.00001, loss_test:0.01650, lr:3.63e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.048, tt:3635.795\n",
      "Ep:121, loss:0.00001, loss_test:0.01654, lr:3.59e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.036, tt:3664.349\n",
      "Ep:122, loss:0.00001, loss_test:0.01655, lr:3.56e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.030, tt:3693.648\n",
      "Ep:123, loss:0.00001, loss_test:0.01657, lr:3.52e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.031, tt:3723.862\n",
      "Ep:124, loss:0.00001, loss_test:0.01664, lr:3.49e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.025, tt:3753.178\n",
      "Ep:125, loss:0.00001, loss_test:0.01664, lr:3.45e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.023, tt:3782.898\n",
      "Ep:126, loss:0.00001, loss_test:0.01666, lr:3.42e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.032, tt:3814.056\n",
      "Ep:127, loss:0.00001, loss_test:0.01668, lr:3.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.045, tt:3845.780\n",
      "Ep:128, loss:0.00001, loss_test:0.01667, lr:3.35e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.053, tt:3876.795\n",
      "Ep:129, loss:0.00001, loss_test:0.01670, lr:3.32e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.060, tt:3907.846\n",
      "Ep:130, loss:0.00001, loss_test:0.01674, lr:3.28e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.067, tt:3938.801\n",
      "Ep:131, loss:0.00001, loss_test:0.01676, lr:3.25e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.099, tt:3973.129\n",
      "Ep:132, loss:0.00001, loss_test:0.01679, lr:3.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.101, tt:4003.489\n",
      "Ep:133, loss:0.00001, loss_test:0.01676, lr:3.19e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.105, tt:4034.043\n",
      "Ep:134, loss:0.00001, loss_test:0.01681, lr:3.15e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.120, tt:4066.171\n",
      "Ep:135, loss:0.00001, loss_test:0.01683, lr:3.12e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.118, tt:4096.057\n",
      "Ep:136, loss:0.00001, loss_test:0.01684, lr:3.09e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.128, tt:4127.489\n",
      "Ep:137, loss:0.00001, loss_test:0.01688, lr:3.06e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.121, tt:4156.671\n",
      "Ep:138, loss:0.00001, loss_test:0.01686, lr:3.03e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.119, tt:4186.523\n",
      "Ep:139, loss:0.00001, loss_test:0.01687, lr:3.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.114, tt:4216.021\n",
      "Ep:140, loss:0.00001, loss_test:0.01690, lr:2.97e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.116, tt:4246.372\n",
      "Ep:141, loss:0.00001, loss_test:0.01693, lr:2.94e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.120, tt:4276.988\n",
      "Ep:142, loss:0.00001, loss_test:0.01695, lr:2.91e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.122, tt:4307.447\n",
      "Ep:143, loss:0.00001, loss_test:0.01699, lr:2.88e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.128, tt:4338.435\n",
      "Ep:144, loss:0.00001, loss_test:0.01702, lr:2.85e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.125, tt:4368.159\n",
      "Ep:145, loss:0.00001, loss_test:0.01704, lr:2.82e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.133, tt:4399.463\n",
      "Ep:146, loss:0.00001, loss_test:0.01704, lr:2.80e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.144, tt:4431.204\n",
      "Ep:147, loss:0.00001, loss_test:0.01708, lr:2.77e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.145, tt:4461.504\n",
      "Ep:148, loss:0.00001, loss_test:0.01709, lr:2.74e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.140, tt:4490.803\n",
      "Ep:149, loss:0.00001, loss_test:0.01712, lr:2.71e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.147, tt:4522.065\n",
      "Ep:150, loss:0.00001, loss_test:0.01712, lr:2.69e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.145, tt:4551.862\n",
      "Ep:151, loss:0.00001, loss_test:0.01714, lr:2.66e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.142, tt:4581.579\n",
      "Ep:152, loss:0.00001, loss_test:0.01712, lr:2.63e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.135, tt:4610.625\n",
      "Ep:153, loss:0.00001, loss_test:0.01713, lr:2.61e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.133, tt:4640.516\n",
      "Ep:154, loss:0.00001, loss_test:0.01716, lr:2.58e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.128, tt:4669.770\n",
      "Ep:155, loss:0.00001, loss_test:0.01722, lr:2.55e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.131, tt:4700.493\n",
      "Ep:156, loss:0.00001, loss_test:0.01721, lr:2.53e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.130, tt:4730.416\n",
      "Ep:157, loss:0.00001, loss_test:0.01720, lr:2.50e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.137, tt:4761.664\n",
      "Ep:158, loss:0.00001, loss_test:0.01720, lr:2.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.149, tt:4793.615\n",
      "Ep:159, loss:0.00001, loss_test:0.01726, lr:2.45e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.156, tt:4824.945\n",
      "Ep:160, loss:0.00001, loss_test:0.01729, lr:2.43e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.158, tt:4855.440\n",
      "Ep:161, loss:0.00001, loss_test:0.01733, lr:2.40e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.161, tt:4886.018\n",
      "Ep:162, loss:0.00001, loss_test:0.01731, lr:2.38e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.163, tt:4916.618\n",
      "Ep:163, loss:0.00001, loss_test:0.01729, lr:2.36e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.163, tt:4946.773\n",
      "Ep:164, loss:0.00001, loss_test:0.01733, lr:2.33e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.167, tt:4977.560\n",
      "Ep:165, loss:0.00001, loss_test:0.01735, lr:2.31e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.165, tt:5007.358\n",
      "Ep:166, loss:0.00001, loss_test:0.01735, lr:2.29e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.164, tt:5037.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:167, loss:0.00001, loss_test:0.01735, lr:2.26e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.169, tt:5068.371\n",
      "Ep:168, loss:0.00001, loss_test:0.01740, lr:2.24e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.178, tt:5100.036\n",
      "Ep:169, loss:0.00001, loss_test:0.01743, lr:2.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.184, tt:5131.299\n",
      "Ep:170, loss:0.00001, loss_test:0.01746, lr:2.20e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.194, tt:5163.236\n",
      "Ep:171, loss:0.00001, loss_test:0.01745, lr:2.17e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.203, tt:5194.915\n",
      "Ep:172, loss:0.00001, loss_test:0.01745, lr:2.15e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.209, tt:5226.128\n",
      "Ep:173, loss:0.00001, loss_test:0.01746, lr:2.13e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.211, tt:5256.698\n",
      "Ep:174, loss:0.00001, loss_test:0.01749, lr:2.11e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.232, tt:5290.524\n",
      "Ep:175, loss:0.00001, loss_test:0.01749, lr:2.09e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.235, tt:5321.279\n",
      "Ep:176, loss:0.00001, loss_test:0.01751, lr:2.07e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.241, tt:5352.726\n",
      "Ep:177, loss:0.00001, loss_test:0.01753, lr:2.05e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.241, tt:5382.913\n",
      "Ep:178, loss:0.00001, loss_test:0.01756, lr:2.03e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.235, tt:5412.048\n",
      "Ep:179, loss:0.00001, loss_test:0.01758, lr:2.01e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.230, tt:5441.421\n",
      "Ep:180, loss:0.00001, loss_test:0.01760, lr:1.99e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.222, tt:5470.243\n",
      "Ep:181, loss:0.00001, loss_test:0.01764, lr:1.97e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.221, tt:5500.202\n",
      "Ep:182, loss:0.00001, loss_test:0.01766, lr:1.95e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.227, tt:5531.474\n",
      "Ep:183, loss:0.00001, loss_test:0.01764, lr:1.93e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.227, tt:5561.697\n",
      "Ep:184, loss:0.00001, loss_test:0.01765, lr:1.91e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.227, tt:5592.028\n",
      "Ep:185, loss:0.00001, loss_test:0.01771, lr:1.89e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.229, tt:5622.620\n",
      "Ep:186, loss:0.00001, loss_test:0.01772, lr:1.87e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.240, tt:5654.895\n",
      "Ep:187, loss:0.00001, loss_test:0.01770, lr:1.85e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.242, tt:5685.565\n",
      "Ep:188, loss:0.00001, loss_test:0.01770, lr:1.83e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.251, tt:5717.444\n",
      "Ep:189, loss:0.00001, loss_test:0.01773, lr:1.81e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.255, tt:5748.476\n",
      "Ep:190, loss:0.00001, loss_test:0.01777, lr:1.80e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.253, tt:5778.414\n",
      "Ep:191, loss:0.00001, loss_test:0.01778, lr:1.78e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.255, tt:5808.958\n",
      "Ep:192, loss:0.00001, loss_test:0.01779, lr:1.76e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.253, tt:5838.913\n",
      "Ep:193, loss:0.00001, loss_test:0.01780, lr:1.74e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.261, tt:5870.673\n",
      "Ep:194, loss:0.00001, loss_test:0.01779, lr:1.73e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.269, tt:5902.494\n",
      "Ep:195, loss:0.00001, loss_test:0.01782, lr:1.71e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.272, tt:5933.349\n",
      "Ep:196, loss:0.00001, loss_test:0.01783, lr:1.69e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.271, tt:5963.448\n",
      "Ep:197, loss:0.00001, loss_test:0.01784, lr:1.67e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.270, tt:5993.385\n",
      "Ep:198, loss:0.00001, loss_test:0.01784, lr:1.66e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.265, tt:6022.749\n",
      "Ep:199, loss:0.00001, loss_test:0.01788, lr:1.64e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.268, tt:6053.700\n",
      "Ep:200, loss:0.00001, loss_test:0.01791, lr:1.62e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.264, tt:6083.050\n",
      "Ep:201, loss:0.00001, loss_test:0.01790, lr:1.61e-02, fs:0.78363 (r=0.677,p=0.931),  time:30.266, tt:6113.806\n",
      "Ep:202, loss:0.00001, loss_test:0.01789, lr:1.59e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.266, tt:6143.940\n",
      "Ep:203, loss:0.00001, loss_test:0.01791, lr:1.58e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.265, tt:6174.048\n",
      "Ep:204, loss:0.00001, loss_test:0.01794, lr:1.56e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.264, tt:6204.168\n",
      "Ep:205, loss:0.00001, loss_test:0.01795, lr:1.54e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.257, tt:6232.844\n",
      "Ep:206, loss:0.00001, loss_test:0.01798, lr:1.53e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.257, tt:6263.154\n",
      "Ep:207, loss:0.00001, loss_test:0.01797, lr:1.51e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.261, tt:6294.232\n",
      "Ep:208, loss:0.00001, loss_test:0.01799, lr:1.50e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.263, tt:6325.003\n",
      "Ep:209, loss:0.00001, loss_test:0.01800, lr:1.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.268, tt:6356.358\n",
      "Ep:210, loss:0.00001, loss_test:0.01803, lr:1.47e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.269, tt:6386.829\n",
      "Ep:211, loss:0.00001, loss_test:0.01804, lr:1.45e-02, fs:0.77907 (r=0.677,p=0.918),  time:30.270, tt:6417.251\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14337, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.867, tt:32.867\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14261, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.281, tt:62.561\n",
      "Ep:2, loss:0.00028, loss_test:0.14128, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.497, tt:91.492\n",
      "Ep:3, loss:0.00028, loss_test:0.13917, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.333, tt:121.332\n",
      "Ep:4, loss:0.00027, loss_test:0.13586, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.641, tt:148.207\n",
      "Ep:5, loss:0.00026, loss_test:0.13081, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:30.122, tt:180.730\n",
      "Ep:6, loss:0.00025, loss_test:0.12356, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:30.077, tt:210.539\n",
      "Ep:7, loss:0.00024, loss_test:0.11576, lr:1.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:30.426, tt:243.410\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11222, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:30.426, tt:273.830\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11127, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:30.578, tt:305.776\n",
      "Ep:10, loss:0.00022, loss_test:0.11184, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:30.696, tt:337.655\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10477, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:31.375, tt:470.618\n",
      "Ep:15, loss:0.00020, loss_test:0.10398, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:31.347, tt:501.546\n",
      "Ep:16, loss:0.00019, loss_test:0.10289, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:31.373, tt:533.336\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00019, loss_test:0.10151, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:31.408, tt:565.342\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.10017, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:31.453, tt:597.615\n",
      "Ep:19, loss:0.00018, loss_test:0.09865, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:31.465, tt:629.294\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09718, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:31.425, tt:659.928\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00017, loss_test:0.09634, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:31.421, tt:691.253\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09546, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:31.506, tt:724.648\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09481, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:31.537, tt:756.881\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09448, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:31.595, tt:789.867\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00015, loss_test:0.09412, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:31.650, tt:822.887\n",
      "Ep:26, loss:0.00015, loss_test:0.09348, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:31.630, tt:854.014\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.09292, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:31.600, tt:884.789\n",
      "Ep:28, loss:0.00014, loss_test:0.09192, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:31.615, tt:916.828\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.09115, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:31.645, tt:949.336\n",
      "Ep:30, loss:0.00014, loss_test:0.09051, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:31.659, tt:981.420\n",
      "Ep:31, loss:0.00013, loss_test:0.09037, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:31.731, tt:1015.379\n",
      "Ep:32, loss:0.00013, loss_test:0.08956, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:31.705, tt:1046.254\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.08882, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:31.704, tt:1077.934\n",
      "Ep:34, loss:0.00013, loss_test:0.08797, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:31.678, tt:1108.728\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08689, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:31.679, tt:1140.457\n",
      "Ep:36, loss:0.00012, loss_test:0.08638, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.770, tt:1175.504\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.08570, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.791, tt:1208.056\n",
      "Ep:38, loss:0.00012, loss_test:0.08496, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:31.802, tt:1240.295\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00011, loss_test:0.08463, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:31.771, tt:1270.853\n",
      "Ep:40, loss:0.00011, loss_test:0.08373, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:31.784, tt:1303.152\n",
      "Ep:41, loss:0.00011, loss_test:0.08327, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.763, tt:1334.039\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.08306, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:31.766, tt:1365.922\n",
      "Ep:43, loss:0.00011, loss_test:0.08196, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:31.781, tt:1398.353\n",
      "Ep:44, loss:0.00010, loss_test:0.08174, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.738, tt:1428.212\n",
      "Ep:45, loss:0.00010, loss_test:0.08091, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.711, tt:1458.704\n",
      "Ep:46, loss:0.00010, loss_test:0.08107, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.716, tt:1490.630\n",
      "Ep:47, loss:0.00010, loss_test:0.07967, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.705, tt:1521.853\n",
      "Ep:48, loss:0.00010, loss_test:0.07982, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:31.670, tt:1551.825\n",
      "Ep:49, loss:0.00010, loss_test:0.07916, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.607, tt:1580.332\n",
      "Ep:50, loss:0.00009, loss_test:0.07891, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:31.586, tt:1610.887\n",
      "Ep:51, loss:0.00009, loss_test:0.07900, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.587, tt:1642.499\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00009, loss_test:0.07751, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.616, tt:1675.665\n",
      "Ep:53, loss:0.00009, loss_test:0.07813, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.635, tt:1708.291\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00009, loss_test:0.07623, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.623, tt:1739.275\n",
      "Ep:55, loss:0.00009, loss_test:0.07762, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.603, tt:1769.766\n",
      "Ep:56, loss:0.00008, loss_test:0.07610, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.585, tt:1800.317\n",
      "Ep:57, loss:0.00008, loss_test:0.07661, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.635, tt:1834.816\n",
      "Ep:58, loss:0.00008, loss_test:0.07628, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.655, tt:1867.642\n",
      "Ep:59, loss:0.00008, loss_test:0.07459, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.640, tt:1898.381\n",
      "Ep:60, loss:0.00008, loss_test:0.07716, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.655, tt:1930.976\n",
      "Ep:61, loss:0.00008, loss_test:0.07347, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:31.641, tt:1961.739\n",
      "Ep:62, loss:0.00008, loss_test:0.07680, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:31.637, tt:1993.134\n",
      "Ep:63, loss:0.00008, loss_test:0.07320, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.631, tt:2024.377\n",
      "Ep:64, loss:0.00007, loss_test:0.07437, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.638, tt:2056.496\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00007, loss_test:0.07269, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.636, tt:2087.958\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00007, loss_test:0.07217, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.623, tt:2118.766\n",
      "Ep:67, loss:0.00007, loss_test:0.07310, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.606, tt:2149.222\n",
      "Ep:68, loss:0.00007, loss_test:0.07115, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.601, tt:2180.440\n",
      "Ep:69, loss:0.00007, loss_test:0.07293, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:31.582, tt:2210.744\n",
      "Ep:70, loss:0.00007, loss_test:0.07186, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.560, tt:2240.786\n",
      "Ep:71, loss:0.00007, loss_test:0.07155, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.562, tt:2272.433\n",
      "Ep:72, loss:0.00007, loss_test:0.07089, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.564, tt:2304.164\n",
      "Ep:73, loss:0.00006, loss_test:0.07164, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:31.572, tt:2336.307\n",
      "Ep:74, loss:0.00006, loss_test:0.06934, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.601, tt:2370.039\n",
      "Ep:75, loss:0.00006, loss_test:0.07103, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.601, tt:2401.653\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00006, loss_test:0.07071, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.609, tt:2433.916\n",
      "Ep:77, loss:0.00006, loss_test:0.06837, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.623, tt:2466.619\n",
      "Ep:78, loss:0.00006, loss_test:0.06971, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:31.653, tt:2500.626\n",
      "Ep:79, loss:0.00006, loss_test:0.07027, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:31.659, tt:2532.736\n",
      "Ep:80, loss:0.00006, loss_test:0.06873, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.678, tt:2565.891\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00006, loss_test:0.07038, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:31.682, tt:2597.904\n",
      "Ep:82, loss:0.00006, loss_test:0.06650, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.680, tt:2629.455\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00006, loss_test:0.06911, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.685, tt:2661.530\n",
      "Ep:84, loss:0.00006, loss_test:0.06559, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:31.701, tt:2694.597\n",
      "Ep:85, loss:0.00005, loss_test:0.07238, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:31.705, tt:2726.597\n",
      "Ep:86, loss:0.00005, loss_test:0.06502, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:31.713, tt:2759.035\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00005, loss_test:0.07044, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:31.701, tt:2789.671\n",
      "Ep:88, loss:0.00005, loss_test:0.06634, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.730, tt:2823.950\n",
      "Ep:89, loss:0.00005, loss_test:0.06855, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.752, tt:2857.649\n",
      "Ep:90, loss:0.00005, loss_test:0.06721, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.765, tt:2890.605\n",
      "Ep:91, loss:0.00005, loss_test:0.06868, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.758, tt:2921.727\n",
      "Ep:92, loss:0.00005, loss_test:0.06588, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:31.777, tt:2955.227\n",
      "Ep:93, loss:0.00005, loss_test:0.06807, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.774, tt:2986.770\n",
      "Ep:94, loss:0.00005, loss_test:0.06633, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.775, tt:3018.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:95, loss:0.00005, loss_test:0.06742, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.770, tt:3049.959\n",
      "Ep:96, loss:0.00005, loss_test:0.06724, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:31.785, tt:3083.139\n",
      "Ep:97, loss:0.00005, loss_test:0.06813, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.788, tt:3115.258\n",
      "Ep:98, loss:0.00004, loss_test:0.06709, lr:9.90e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.771, tt:3145.325\n",
      "Ep:99, loss:0.00004, loss_test:0.06829, lr:9.80e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.770, tt:3177.044\n",
      "Ep:100, loss:0.00004, loss_test:0.06404, lr:9.70e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.772, tt:3209.020\n",
      "Ep:101, loss:0.00004, loss_test:0.07014, lr:9.61e-03, fs:0.83333 (r=0.808,p=0.860),  time:31.764, tt:3239.915\n",
      "Ep:102, loss:0.00004, loss_test:0.06180, lr:9.51e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.766, tt:3271.917\n",
      "Ep:103, loss:0.00004, loss_test:0.07124, lr:9.41e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.765, tt:3303.551\n",
      "Ep:104, loss:0.00004, loss_test:0.06291, lr:9.32e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.779, tt:3336.758\n",
      "Ep:105, loss:0.00004, loss_test:0.06890, lr:9.23e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.784, tt:3369.090\n",
      "Ep:106, loss:0.00004, loss_test:0.06478, lr:9.14e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.788, tt:3401.331\n",
      "Ep:107, loss:0.00004, loss_test:0.06890, lr:9.04e-03, fs:0.81481 (r=0.778,p=0.856),  time:31.783, tt:3432.518\n",
      "Ep:108, loss:0.00004, loss_test:0.06344, lr:8.95e-03, fs:0.84211 (r=0.808,p=0.879),  time:31.771, tt:3463.088\n",
      "Ep:109, loss:0.00004, loss_test:0.06870, lr:8.86e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.762, tt:3493.839\n",
      "Ep:110, loss:0.00004, loss_test:0.06378, lr:8.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:31.768, tt:3526.202\n",
      "Ep:111, loss:0.00004, loss_test:0.06688, lr:8.69e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.765, tt:3557.705\n",
      "Ep:112, loss:0.00004, loss_test:0.06642, lr:8.60e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.761, tt:3589.044\n",
      "Ep:113, loss:0.00004, loss_test:0.06595, lr:8.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.755, tt:3620.047\n",
      "Ep:114, loss:0.00004, loss_test:0.06614, lr:8.43e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.763, tt:3652.750\n",
      "Ep:115, loss:0.00004, loss_test:0.06562, lr:8.35e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.758, tt:3683.933\n",
      "Ep:116, loss:0.00004, loss_test:0.06538, lr:8.26e-03, fs:0.83422 (r=0.788,p=0.886),  time:31.752, tt:3714.929\n",
      "Ep:117, loss:0.00004, loss_test:0.06507, lr:8.18e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.734, tt:3744.620\n",
      "Ep:118, loss:0.00003, loss_test:0.06659, lr:8.10e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.716, tt:3774.247\n",
      "Ep:119, loss:0.00003, loss_test:0.06376, lr:8.02e-03, fs:0.82979 (r=0.788,p=0.876),  time:31.723, tt:3806.789\n",
      "Ep:120, loss:0.00003, loss_test:0.06522, lr:7.94e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.728, tt:3839.116\n",
      "Ep:121, loss:0.00003, loss_test:0.06412, lr:7.86e-03, fs:0.82796 (r=0.778,p=0.885),  time:31.731, tt:3871.159\n",
      "Ep:122, loss:0.00003, loss_test:0.06585, lr:7.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:31.731, tt:3902.910\n",
      "Ep:123, loss:0.00003, loss_test:0.06491, lr:7.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.735, tt:3935.185\n",
      "Ep:124, loss:0.00003, loss_test:0.06486, lr:7.62e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.732, tt:3966.528\n",
      "Ep:125, loss:0.00003, loss_test:0.06474, lr:7.55e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.745, tt:3999.907\n",
      "Ep:126, loss:0.00003, loss_test:0.06504, lr:7.47e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.747, tt:4031.861\n",
      "Ep:127, loss:0.00003, loss_test:0.06519, lr:7.40e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.738, tt:4062.493\n",
      "Ep:128, loss:0.00003, loss_test:0.06471, lr:7.32e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.738, tt:4094.152\n",
      "Ep:129, loss:0.00003, loss_test:0.06532, lr:7.25e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.733, tt:4125.244\n",
      "Ep:130, loss:0.00003, loss_test:0.06396, lr:7.18e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.733, tt:4157.083\n",
      "Ep:131, loss:0.00003, loss_test:0.06488, lr:7.11e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.737, tt:4189.318\n",
      "Ep:132, loss:0.00003, loss_test:0.06609, lr:7.03e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.727, tt:4219.633\n",
      "Ep:133, loss:0.00003, loss_test:0.06528, lr:6.96e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.733, tt:4252.193\n",
      "Ep:134, loss:0.00003, loss_test:0.06465, lr:6.89e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.738, tt:4284.636\n",
      "Ep:135, loss:0.00003, loss_test:0.06382, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.757, tt:4318.931\n",
      "Ep:136, loss:0.00003, loss_test:0.06536, lr:6.76e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.758, tt:4350.826\n",
      "Ep:137, loss:0.00003, loss_test:0.06464, lr:6.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.747, tt:4381.052\n",
      "Ep:138, loss:0.00003, loss_test:0.06504, lr:6.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.762, tt:4414.867\n",
      "Ep:139, loss:0.00003, loss_test:0.06444, lr:6.56e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.752, tt:4445.223\n",
      "Ep:140, loss:0.00003, loss_test:0.06542, lr:6.49e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.749, tt:4476.644\n",
      "Ep:141, loss:0.00003, loss_test:0.06487, lr:6.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.753, tt:4508.864\n",
      "Ep:142, loss:0.00003, loss_test:0.06428, lr:6.36e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.752, tt:4540.487\n",
      "Ep:143, loss:0.00003, loss_test:0.06567, lr:6.30e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.740, tt:4570.566\n",
      "Ep:144, loss:0.00003, loss_test:0.06373, lr:6.24e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.743, tt:4602.716\n",
      "Ep:145, loss:0.00003, loss_test:0.06582, lr:6.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.737, tt:4633.655\n",
      "Ep:146, loss:0.00003, loss_test:0.06401, lr:6.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.728, tt:4664.062\n",
      "Ep:147, loss:0.00003, loss_test:0.06429, lr:6.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.726, tt:4695.496\n",
      "Ep:148, loss:0.00003, loss_test:0.06433, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.725, tt:4727.078\n",
      "Ep:149, loss:0.00003, loss_test:0.06544, lr:5.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.717, tt:4757.557\n",
      "Ep:150, loss:0.00002, loss_test:0.06368, lr:5.87e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.705, tt:4787.483\n",
      "Ep:151, loss:0.00003, loss_test:0.06598, lr:5.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.724, tt:4822.117\n",
      "Ep:152, loss:0.00002, loss_test:0.06425, lr:5.75e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.718, tt:4852.928\n",
      "Ep:153, loss:0.00002, loss_test:0.06494, lr:5.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.721, tt:4885.028\n",
      "Ep:154, loss:0.00002, loss_test:0.06504, lr:5.64e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.721, tt:4916.766\n",
      "Ep:155, loss:0.00002, loss_test:0.06384, lr:5.58e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.724, tt:4948.902\n",
      "Ep:156, loss:0.00002, loss_test:0.06497, lr:5.53e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.724, tt:4980.593\n",
      "Ep:157, loss:0.00002, loss_test:0.06389, lr:5.47e-03, fs:0.84153 (r=0.778,p=0.917),  time:31.725, tt:5012.556\n",
      "Ep:158, loss:0.00002, loss_test:0.06608, lr:5.42e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.720, tt:5043.442\n",
      "Ep:159, loss:0.00002, loss_test:0.06358, lr:5.36e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.709, tt:5073.386\n",
      "Ep:160, loss:0.00002, loss_test:0.06533, lr:5.31e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.713, tt:5105.777\n",
      "Ep:161, loss:0.00002, loss_test:0.06361, lr:5.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.709, tt:5136.864\n",
      "Ep:162, loss:0.00002, loss_test:0.06658, lr:5.20e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.705, tt:5167.907\n",
      "Ep:163, loss:0.00002, loss_test:0.06392, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.705, tt:5199.634\n",
      "Ep:164, loss:0.00002, loss_test:0.06503, lr:5.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.707, tt:5231.713\n",
      "Ep:165, loss:0.00002, loss_test:0.06516, lr:5.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.707, tt:5263.295\n",
      "Ep:166, loss:0.00002, loss_test:0.06458, lr:5.00e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.704, tt:5294.535\n",
      "Ep:167, loss:0.00002, loss_test:0.06456, lr:4.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.689, tt:5323.830\n",
      "Ep:168, loss:0.00002, loss_test:0.06466, lr:4.90e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.683, tt:5354.449\n",
      "Ep:169, loss:0.00002, loss_test:0.06421, lr:4.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.679, tt:5385.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:170, loss:0.00002, loss_test:0.06450, lr:4.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.674, tt:5416.180\n",
      "Ep:171, loss:0.00002, loss_test:0.06464, lr:4.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.666, tt:5446.616\n",
      "Ep:172, loss:0.00002, loss_test:0.06345, lr:4.71e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.676, tt:5479.927\n",
      "Ep:173, loss:0.00002, loss_test:0.06508, lr:4.66e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.672, tt:5511.002\n",
      "Ep:174, loss:0.00002, loss_test:0.06407, lr:4.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.662, tt:5540.821\n",
      "Ep:175, loss:0.00002, loss_test:0.06372, lr:4.57e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.661, tt:5572.273\n",
      "Ep:176, loss:0.00002, loss_test:0.06460, lr:4.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.657, tt:5603.248\n",
      "Ep:177, loss:0.00002, loss_test:0.06521, lr:4.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.653, tt:5634.249\n",
      "Ep:178, loss:0.00002, loss_test:0.06382, lr:4.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.651, tt:5665.472\n",
      "Ep:179, loss:0.00002, loss_test:0.06437, lr:4.39e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.644, tt:5695.851\n",
      "Ep:180, loss:0.00002, loss_test:0.06483, lr:4.34e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.640, tt:5726.925\n",
      "Ep:181, loss:0.00002, loss_test:0.06383, lr:4.30e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.641, tt:5758.683\n",
      "Ep:182, loss:0.00002, loss_test:0.06498, lr:4.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.646, tt:5791.231\n",
      "Ep:183, loss:0.00002, loss_test:0.06388, lr:4.21e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.645, tt:5822.605\n",
      "Ep:184, loss:0.00002, loss_test:0.06424, lr:4.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.644, tt:5854.075\n",
      "Ep:185, loss:0.00002, loss_test:0.06449, lr:4.13e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.645, tt:5885.947\n",
      "Ep:186, loss:0.00002, loss_test:0.06431, lr:4.09e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.637, tt:5916.126\n",
      "Ep:187, loss:0.00002, loss_test:0.06379, lr:4.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.638, tt:5947.948\n",
      "Ep:188, loss:0.00002, loss_test:0.06475, lr:4.01e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.630, tt:5978.115\n",
      "Ep:189, loss:0.00002, loss_test:0.06406, lr:3.97e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.629, tt:6009.501\n",
      "Ep:190, loss:0.00002, loss_test:0.06363, lr:3.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.624, tt:6040.248\n",
      "Ep:191, loss:0.00002, loss_test:0.06477, lr:3.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.622, tt:6071.364\n",
      "Ep:192, loss:0.00002, loss_test:0.06383, lr:3.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.627, tt:6104.056\n",
      "Ep:193, loss:0.00002, loss_test:0.06349, lr:3.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.617, tt:6133.656\n",
      "Ep:194, loss:0.00002, loss_test:0.06467, lr:3.77e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.629, tt:6167.580\n",
      "Ep:195, loss:0.00002, loss_test:0.06398, lr:3.73e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.625, tt:6198.479\n",
      "Ep:196, loss:0.00002, loss_test:0.06375, lr:3.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.622, tt:6229.454\n",
      "Ep:197, loss:0.00002, loss_test:0.06464, lr:3.66e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.613, tt:6259.419\n",
      "Ep:198, loss:0.00002, loss_test:0.06347, lr:3.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.601, tt:6288.682\n",
      "Ep:199, loss:0.00002, loss_test:0.06473, lr:3.59e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.597, tt:6319.388\n",
      "Ep:200, loss:0.00002, loss_test:0.06475, lr:3.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.594, tt:6350.487\n",
      "Ep:201, loss:0.00002, loss_test:0.06356, lr:3.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.593, tt:6381.695\n",
      "Ep:202, loss:0.00002, loss_test:0.06394, lr:3.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.594, tt:6413.682\n",
      "Ep:203, loss:0.00002, loss_test:0.06491, lr:3.45e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.588, tt:6443.929\n",
      "Ep:204, loss:0.00002, loss_test:0.06496, lr:3.41e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.591, tt:6476.224\n",
      "Ep:205, loss:0.00002, loss_test:0.06273, lr:3.38e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.591, tt:6507.741\n",
      "Ep:206, loss:0.00002, loss_test:0.06498, lr:3.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.596, tt:6540.429\n",
      "Ep:207, loss:0.00002, loss_test:0.06476, lr:3.31e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.600, tt:6572.844\n",
      "Ep:208, loss:0.00002, loss_test:0.06296, lr:3.28e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.603, tt:6604.931\n",
      "Ep:209, loss:0.00002, loss_test:0.06426, lr:3.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.602, tt:6636.419\n",
      "Ep:210, loss:0.00002, loss_test:0.06454, lr:3.21e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.604, tt:6668.497\n",
      "Ep:211, loss:0.00002, loss_test:0.06358, lr:3.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.600, tt:6699.291\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02048, lr:6.00e-02, fs:0.63256 (r=0.687,p=0.586),  time:29.708, tt:29.708\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.301, tt:56.602\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02419, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.463, tt:82.388\n",
      "Ep:3, loss:0.00005, loss_test:0.02569, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.073, tt:100.291\n",
      "Ep:4, loss:0.00005, loss_test:0.02612, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.384, tt:121.918\n",
      "Ep:5, loss:0.00005, loss_test:0.02586, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.718, tt:148.309\n",
      "Ep:6, loss:0.00005, loss_test:0.02514, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.102, tt:175.712\n",
      "Ep:7, loss:0.00005, loss_test:0.02408, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.511, tt:204.091\n",
      "Ep:8, loss:0.00005, loss_test:0.02272, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.895, tt:233.054\n",
      "Ep:9, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.389, tt:263.889\n",
      "Ep:10, loss:0.00004, loss_test:0.01986, lr:6.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:26.636, tt:293.001\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01892, lr:6.00e-02, fs:0.68148 (r=0.929,p=0.538),  time:26.834, tt:322.011\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.65354 (r=0.838,p=0.535),  time:27.017, tt:351.225\n",
      "Ep:13, loss:0.00004, loss_test:0.01862, lr:6.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:27.301, tt:382.211\n",
      "Ep:14, loss:0.00004, loss_test:0.01842, lr:6.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:27.559, tt:413.381\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:27.722, tt:443.560\n",
      "Ep:16, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:27.892, tt:474.159\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.71094 (r=0.919,p=0.580),  time:28.034, tt:504.614\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01635, lr:6.00e-02, fs:0.72388 (r=0.980,p=0.574),  time:28.165, tt:535.132\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.71324 (r=0.980,p=0.561),  time:28.273, tt:565.450\n",
      "Ep:20, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.72659 (r=0.980,p=0.577),  time:28.465, tt:597.765\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.74903 (r=0.980,p=0.606),  time:28.572, tt:628.594\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01512, lr:6.00e-02, fs:0.76800 (r=0.970,p=0.636),  time:28.678, tt:659.596\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01490, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:28.708, tt:688.996\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01473, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:28.798, tt:719.961\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01457, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:28.911, tt:751.692\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01441, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:28.983, tt:782.538\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01424, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:29.058, tt:813.625\n",
      "Ep:28, loss:0.00003, loss_test:0.01407, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:29.120, tt:844.468\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:29.219, tt:876.569\n",
      "Ep:30, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.81172 (r=0.980,p=0.693),  time:29.245, tt:906.584\n",
      "Ep:31, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.81857 (r=0.980,p=0.703),  time:29.280, tt:936.975\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01350, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:29.327, tt:967.806\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:29.374, tt:998.702\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:29.417, tt:1029.579\n",
      "Ep:35, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:29.454, tt:1060.355\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:29.521, tt:1092.262\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:29.550, tt:1122.916\n",
      "Ep:38, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:29.589, tt:1153.971\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01263, lr:6.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:29.628, tt:1185.111\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01252, lr:6.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:29.651, tt:1215.682\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01242, lr:6.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:29.692, tt:1247.059\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:29.713, tt:1277.674\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:29.750, tt:1308.982\n",
      "Ep:44, loss:0.00002, loss_test:0.01213, lr:6.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:29.813, tt:1341.601\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:29.852, tt:1373.179\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01195, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:29.883, tt:1404.518\n",
      "Ep:47, loss:0.00002, loss_test:0.01187, lr:6.00e-02, fs:0.88073 (r=0.970,p=0.807),  time:29.912, tt:1435.761\n",
      "Ep:48, loss:0.00002, loss_test:0.01179, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:29.920, tt:1466.100\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01171, lr:6.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:29.938, tt:1496.912\n",
      "Ep:50, loss:0.00002, loss_test:0.01164, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:29.951, tt:1527.515\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01158, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:29.936, tt:1556.695\n",
      "Ep:52, loss:0.00002, loss_test:0.01153, lr:6.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:29.960, tt:1587.870\n",
      "Ep:53, loss:0.00002, loss_test:0.01148, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:29.978, tt:1618.828\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01144, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:29.999, tt:1649.943\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01140, lr:6.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:30.019, tt:1681.071\n",
      "Ep:56, loss:0.00001, loss_test:0.01135, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.035, tt:1711.973\n",
      "Ep:57, loss:0.00001, loss_test:0.01131, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.032, tt:1741.836\n",
      "Ep:58, loss:0.00001, loss_test:0.01127, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.019, tt:1771.115\n",
      "Ep:59, loss:0.00001, loss_test:0.01125, lr:6.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:30.036, tt:1802.178\n",
      "Ep:60, loss:0.00001, loss_test:0.01122, lr:6.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:30.053, tt:1833.204\n",
      "Ep:61, loss:0.00001, loss_test:0.01118, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:30.056, tt:1863.487\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01115, lr:6.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:30.038, tt:1892.403\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01112, lr:6.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:30.041, tt:1922.616\n",
      "Ep:64, loss:0.00001, loss_test:0.01110, lr:6.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:30.038, tt:1952.499\n",
      "Ep:65, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.91626 (r=0.939,p=0.894),  time:30.062, tt:1984.062\n",
      "Ep:66, loss:0.00001, loss_test:0.01104, lr:6.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:30.030, tt:2011.981\n",
      "Ep:67, loss:0.00001, loss_test:0.01100, lr:6.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:30.029, tt:2041.953\n",
      "Ep:68, loss:0.00001, loss_test:0.01097, lr:6.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:30.040, tt:2072.763\n",
      "Ep:69, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:30.019, tt:2101.354\n",
      "Ep:70, loss:0.00001, loss_test:0.01094, lr:6.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:30.017, tt:2131.190\n",
      "Ep:71, loss:0.00001, loss_test:0.01093, lr:6.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:30.037, tt:2162.657\n",
      "Ep:72, loss:0.00001, loss_test:0.01090, lr:6.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:30.033, tt:2192.438\n",
      "Ep:73, loss:0.00001, loss_test:0.01089, lr:6.00e-02, fs:0.91000 (r=0.919,p=0.901),  time:30.037, tt:2222.752\n",
      "Ep:74, loss:0.00001, loss_test:0.01087, lr:5.94e-02, fs:0.91000 (r=0.919,p=0.901),  time:30.039, tt:2252.947\n",
      "Ep:75, loss:0.00001, loss_test:0.01087, lr:5.88e-02, fs:0.91000 (r=0.919,p=0.901),  time:30.040, tt:2283.002\n",
      "Ep:76, loss:0.00001, loss_test:0.01087, lr:5.82e-02, fs:0.91919 (r=0.919,p=0.919),  time:30.029, tt:2312.217\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01086, lr:5.82e-02, fs:0.92386 (r=0.919,p=0.929),  time:30.043, tt:2343.389\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01084, lr:5.82e-02, fs:0.92386 (r=0.919,p=0.929),  time:30.053, tt:2374.167\n",
      "Ep:79, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.92857 (r=0.919,p=0.938),  time:30.058, tt:2404.655\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.92857 (r=0.919,p=0.938),  time:30.051, tt:2434.126\n",
      "Ep:81, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.92308 (r=0.909,p=0.938),  time:30.055, tt:2464.469\n",
      "Ep:82, loss:0.00001, loss_test:0.01081, lr:5.82e-02, fs:0.90625 (r=0.879,p=0.935),  time:30.059, tt:2494.901\n",
      "Ep:83, loss:0.00001, loss_test:0.01080, lr:5.82e-02, fs:0.89583 (r=0.869,p=0.925),  time:30.066, tt:2525.566\n",
      "Ep:84, loss:0.00001, loss_test:0.01081, lr:5.82e-02, fs:0.90052 (r=0.869,p=0.935),  time:30.072, tt:2556.089\n",
      "Ep:85, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.90052 (r=0.869,p=0.935),  time:30.068, tt:2585.848\n",
      "Ep:86, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:30.071, tt:2616.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:87, loss:0.00001, loss_test:0.01082, lr:5.82e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.089, tt:2647.816\n",
      "Ep:88, loss:0.00001, loss_test:0.01081, lr:5.82e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.105, tt:2679.384\n",
      "Ep:89, loss:0.00001, loss_test:0.01081, lr:5.82e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.125, tt:2711.292\n",
      "Ep:90, loss:0.00001, loss_test:0.01080, lr:5.82e-02, fs:0.87831 (r=0.838,p=0.922),  time:30.115, tt:2740.491\n",
      "Ep:91, loss:0.00001, loss_test:0.01080, lr:5.76e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.126, tt:2771.600\n",
      "Ep:92, loss:0.00001, loss_test:0.01081, lr:5.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.132, tt:2802.295\n",
      "Ep:93, loss:0.00001, loss_test:0.01082, lr:5.65e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.143, tt:2833.485\n",
      "Ep:94, loss:0.00001, loss_test:0.01082, lr:5.59e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.161, tt:2865.264\n",
      "Ep:95, loss:0.00001, loss_test:0.01083, lr:5.54e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.165, tt:2895.859\n",
      "Ep:96, loss:0.00001, loss_test:0.01084, lr:5.48e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.167, tt:2926.162\n",
      "Ep:97, loss:0.00001, loss_test:0.01085, lr:5.43e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.177, tt:2957.369\n",
      "Ep:98, loss:0.00001, loss_test:0.01086, lr:5.37e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.175, tt:2987.328\n",
      "Ep:99, loss:0.00001, loss_test:0.01088, lr:5.32e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.171, tt:3017.135\n",
      "Ep:100, loss:0.00001, loss_test:0.01087, lr:5.27e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.186, tt:3048.770\n",
      "Ep:101, loss:0.00001, loss_test:0.01087, lr:5.21e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.190, tt:3079.330\n",
      "Ep:102, loss:0.00001, loss_test:0.01088, lr:5.16e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.192, tt:3109.802\n",
      "Ep:103, loss:0.00001, loss_test:0.01087, lr:5.11e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.191, tt:3139.895\n",
      "Ep:104, loss:0.00001, loss_test:0.01088, lr:5.06e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.196, tt:3170.578\n",
      "Ep:105, loss:0.00001, loss_test:0.01089, lr:5.01e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.195, tt:3200.681\n",
      "Ep:106, loss:0.00001, loss_test:0.01090, lr:4.96e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.191, tt:3230.481\n",
      "Ep:107, loss:0.00001, loss_test:0.01092, lr:4.91e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.193, tt:3260.895\n",
      "Ep:108, loss:0.00001, loss_test:0.01092, lr:4.86e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.200, tt:3291.815\n",
      "Ep:109, loss:0.00001, loss_test:0.01093, lr:4.81e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.214, tt:3323.570\n",
      "Ep:110, loss:0.00001, loss_test:0.01093, lr:4.76e-02, fs:0.88298 (r=0.838,p=0.933),  time:30.207, tt:3352.989\n",
      "Ep:111, loss:0.00001, loss_test:0.01094, lr:4.71e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.210, tt:3383.525\n",
      "Ep:112, loss:0.00001, loss_test:0.01096, lr:4.67e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.194, tt:3411.933\n",
      "Ep:113, loss:0.00001, loss_test:0.01097, lr:4.62e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.212, tt:3444.151\n",
      "Ep:114, loss:0.00001, loss_test:0.01097, lr:4.57e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.211, tt:3474.283\n",
      "Ep:115, loss:0.00001, loss_test:0.01099, lr:4.53e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.208, tt:3504.134\n",
      "Ep:116, loss:0.00001, loss_test:0.01100, lr:4.48e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.216, tt:3535.229\n",
      "Ep:117, loss:0.00001, loss_test:0.01101, lr:4.44e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.229, tt:3567.004\n",
      "Ep:118, loss:0.00001, loss_test:0.01103, lr:4.39e-02, fs:0.89247 (r=0.838,p=0.954),  time:30.239, tt:3598.465\n",
      "Ep:119, loss:0.00001, loss_test:0.01102, lr:4.35e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.237, tt:3628.396\n",
      "Ep:120, loss:0.00001, loss_test:0.01103, lr:4.31e-02, fs:0.88770 (r=0.838,p=0.943),  time:30.244, tt:3659.491\n",
      "Ep:121, loss:0.00001, loss_test:0.01105, lr:4.26e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.256, tt:3691.244\n",
      "Ep:122, loss:0.00001, loss_test:0.01106, lr:4.22e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.265, tt:3722.634\n",
      "Ep:123, loss:0.00001, loss_test:0.01107, lr:4.18e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.268, tt:3753.258\n",
      "Ep:124, loss:0.00001, loss_test:0.01109, lr:4.14e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.283, tt:3785.337\n",
      "Ep:125, loss:0.00001, loss_test:0.01109, lr:4.10e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.282, tt:3815.577\n",
      "Ep:126, loss:0.00001, loss_test:0.01109, lr:4.05e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.289, tt:3846.747\n",
      "Ep:127, loss:0.00001, loss_test:0.01109, lr:4.01e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.291, tt:3877.230\n",
      "Ep:128, loss:0.00001, loss_test:0.01110, lr:3.97e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.302, tt:3908.945\n",
      "Ep:129, loss:0.00001, loss_test:0.01111, lr:3.93e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.304, tt:3939.561\n",
      "Ep:130, loss:0.00001, loss_test:0.01113, lr:3.89e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.307, tt:3970.207\n",
      "Ep:131, loss:0.00001, loss_test:0.01114, lr:3.86e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.313, tt:4001.344\n",
      "Ep:132, loss:0.00001, loss_test:0.01115, lr:3.82e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.313, tt:4031.616\n",
      "Ep:133, loss:0.00001, loss_test:0.01116, lr:3.78e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.315, tt:4062.147\n",
      "Ep:134, loss:0.00001, loss_test:0.01116, lr:3.74e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.331, tt:4094.635\n",
      "Ep:135, loss:0.00001, loss_test:0.01116, lr:3.70e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.335, tt:4125.557\n",
      "Ep:136, loss:0.00001, loss_test:0.01118, lr:3.67e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.334, tt:4155.732\n",
      "Ep:137, loss:0.00001, loss_test:0.01118, lr:3.63e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.345, tt:4187.635\n",
      "Ep:138, loss:0.00001, loss_test:0.01119, lr:3.59e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.351, tt:4218.778\n",
      "Ep:139, loss:0.00001, loss_test:0.01120, lr:3.56e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.355, tt:4249.686\n",
      "Ep:140, loss:0.00001, loss_test:0.01121, lr:3.52e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.353, tt:4279.801\n",
      "Ep:141, loss:0.00001, loss_test:0.01121, lr:3.49e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.351, tt:4309.875\n",
      "Ep:142, loss:0.00001, loss_test:0.01123, lr:3.45e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.353, tt:4340.523\n",
      "Ep:143, loss:0.00001, loss_test:0.01123, lr:3.42e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.365, tt:4372.530\n",
      "Ep:144, loss:0.00001, loss_test:0.01125, lr:3.38e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.368, tt:4403.296\n",
      "Ep:145, loss:0.00001, loss_test:0.01126, lr:3.35e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.371, tt:4434.119\n",
      "Ep:146, loss:0.00001, loss_test:0.01126, lr:3.32e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.364, tt:4463.550\n",
      "Ep:147, loss:0.00001, loss_test:0.01127, lr:3.28e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.390, tt:4497.731\n",
      "Ep:148, loss:0.00001, loss_test:0.01127, lr:3.25e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.392, tt:4528.418\n",
      "Ep:149, loss:0.00001, loss_test:0.01129, lr:3.22e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.383, tt:4557.453\n",
      "Ep:150, loss:0.00001, loss_test:0.01129, lr:3.19e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.382, tt:4587.732\n",
      "Ep:151, loss:0.00000, loss_test:0.01130, lr:3.15e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.381, tt:4617.895\n",
      "Ep:152, loss:0.00000, loss_test:0.01131, lr:3.12e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.370, tt:4646.614\n",
      "Ep:153, loss:0.00000, loss_test:0.01132, lr:3.09e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.369, tt:4676.809\n",
      "Ep:154, loss:0.00000, loss_test:0.01132, lr:3.06e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.365, tt:4706.511\n",
      "Ep:155, loss:0.00000, loss_test:0.01133, lr:3.03e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.365, tt:4737.013\n",
      "Ep:156, loss:0.00000, loss_test:0.01134, lr:3.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.364, tt:4767.221\n",
      "Ep:157, loss:0.00000, loss_test:0.01135, lr:2.97e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.362, tt:4797.224\n",
      "Ep:158, loss:0.00000, loss_test:0.01136, lr:2.94e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.358, tt:4826.940\n",
      "Ep:159, loss:0.00000, loss_test:0.01137, lr:2.91e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.352, tt:4856.287\n",
      "Ep:160, loss:0.00000, loss_test:0.01138, lr:2.88e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.354, tt:4886.975\n",
      "Ep:161, loss:0.00000, loss_test:0.01138, lr:2.85e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.356, tt:4917.606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:162, loss:0.00000, loss_test:0.01140, lr:2.82e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.356, tt:4948.101\n",
      "Ep:163, loss:0.00000, loss_test:0.01140, lr:2.80e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.353, tt:4977.823\n",
      "Ep:164, loss:0.00000, loss_test:0.01141, lr:2.77e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.352, tt:5007.997\n",
      "Ep:165, loss:0.00000, loss_test:0.01141, lr:2.74e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.348, tt:5037.776\n",
      "Ep:166, loss:0.00000, loss_test:0.01142, lr:2.71e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.346, tt:5067.839\n",
      "Ep:167, loss:0.00000, loss_test:0.01143, lr:2.69e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.343, tt:5097.558\n",
      "Ep:168, loss:0.00000, loss_test:0.01144, lr:2.66e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.342, tt:5127.801\n",
      "Ep:169, loss:0.00000, loss_test:0.01145, lr:2.63e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.348, tt:5159.193\n",
      "Ep:170, loss:0.00000, loss_test:0.01146, lr:2.61e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.345, tt:5188.960\n",
      "Ep:171, loss:0.00000, loss_test:0.01147, lr:2.58e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.345, tt:5219.355\n",
      "Ep:172, loss:0.00000, loss_test:0.01147, lr:2.55e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.337, tt:5248.364\n",
      "Ep:173, loss:0.00000, loss_test:0.01148, lr:2.53e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.336, tt:5278.395\n",
      "Ep:174, loss:0.00000, loss_test:0.01149, lr:2.50e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.332, tt:5308.148\n",
      "Ep:175, loss:0.00000, loss_test:0.01150, lr:2.48e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.334, tt:5338.860\n",
      "Ep:176, loss:0.00000, loss_test:0.01151, lr:2.45e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.331, tt:5368.635\n",
      "Ep:177, loss:0.00000, loss_test:0.01151, lr:2.43e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.331, tt:5398.834\n",
      "Ep:178, loss:0.00000, loss_test:0.01152, lr:2.40e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.319, tt:5427.109\n",
      "Ep:179, loss:0.00000, loss_test:0.01153, lr:2.38e-02, fs:0.88172 (r=0.828,p=0.943),  time:30.314, tt:5456.471\n",
      "Ep:180, loss:0.00000, loss_test:0.01154, lr:2.36e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.318, tt:5487.517\n",
      "Ep:181, loss:0.00000, loss_test:0.01155, lr:2.33e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.323, tt:5518.752\n",
      "Ep:182, loss:0.00000, loss_test:0.01156, lr:2.31e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.321, tt:5548.728\n",
      "Ep:183, loss:0.00000, loss_test:0.01157, lr:2.29e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.322, tt:5579.191\n",
      "Ep:184, loss:0.00000, loss_test:0.01158, lr:2.26e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.316, tt:5608.402\n",
      "Ep:185, loss:0.00000, loss_test:0.01158, lr:2.24e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.316, tt:5638.841\n",
      "Ep:186, loss:0.00000, loss_test:0.01159, lr:2.22e-02, fs:0.88043 (r=0.818,p=0.953),  time:30.324, tt:5670.543\n",
      "Ep:187, loss:0.00000, loss_test:0.01160, lr:2.20e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.326, tt:5701.236\n",
      "Ep:188, loss:0.00000, loss_test:0.01160, lr:2.17e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.330, tt:5732.339\n",
      "Ep:189, loss:0.00000, loss_test:0.01160, lr:2.15e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.332, tt:5763.141\n",
      "Ep:190, loss:0.00000, loss_test:0.01162, lr:2.13e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.339, tt:5794.819\n",
      "Ep:191, loss:0.00000, loss_test:0.01162, lr:2.11e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.335, tt:5824.329\n",
      "Ep:192, loss:0.00000, loss_test:0.01163, lr:2.09e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.335, tt:5854.562\n",
      "Ep:193, loss:0.00000, loss_test:0.01163, lr:2.07e-02, fs:0.87432 (r=0.808,p=0.952),  time:30.333, tt:5884.681\n",
      "Ep:194, loss:0.00000, loss_test:0.01165, lr:2.05e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.338, tt:5915.844\n",
      "Ep:195, loss:0.00000, loss_test:0.01165, lr:2.03e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.342, tt:5946.938\n",
      "Ep:196, loss:0.00000, loss_test:0.01166, lr:2.01e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.342, tt:5977.453\n",
      "Ep:197, loss:0.00000, loss_test:0.01167, lr:1.99e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.341, tt:6007.591\n",
      "Ep:198, loss:0.00000, loss_test:0.01167, lr:1.97e-02, fs:0.86813 (r=0.798,p=0.952),  time:30.337, tt:6037.106\n",
      "Ep:199, loss:0.00000, loss_test:0.01168, lr:1.95e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.337, tt:6067.401\n",
      "Ep:200, loss:0.00000, loss_test:0.01169, lr:1.93e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.346, tt:6099.512\n",
      "Ep:201, loss:0.00000, loss_test:0.01169, lr:1.91e-02, fs:0.85556 (r=0.778,p=0.951),  time:30.349, tt:6130.444\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14032, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.535, tt:30.535\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13922, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.899, tt:61.797\n",
      "Ep:2, loss:0.00028, loss_test:0.13739, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.608, tt:88.824\n",
      "Ep:3, loss:0.00027, loss_test:0.13459, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:29.036, tt:116.143\n",
      "Ep:4, loss:0.00026, loss_test:0.13041, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:28.253, tt:141.266\n",
      "Ep:5, loss:0.00026, loss_test:0.12490, lr:1.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:28.638, tt:171.826\n",
      "Ep:6, loss:0.00024, loss_test:0.11961, lr:1.00e-02, fs:0.66964 (r=0.758,p=0.600),  time:28.763, tt:201.341\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11763, lr:1.00e-02, fs:0.64615 (r=0.636,p=0.656),  time:28.979, tt:231.831\n",
      "Ep:8, loss:0.00023, loss_test:0.11615, lr:1.00e-02, fs:0.65934 (r=0.606,p=0.723),  time:29.041, tt:261.366\n",
      "Ep:9, loss:0.00022, loss_test:0.11335, lr:1.00e-02, fs:0.66316 (r=0.636,p=0.692),  time:29.403, tt:294.029\n",
      "Ep:10, loss:0.00021, loss_test:0.11117, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:29.900, tt:328.900\n",
      "Ep:11, loss:0.00021, loss_test:0.10853, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:30.012, tt:360.139\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10611, lr:1.00e-02, fs:0.69430 (r=0.677,p=0.713),  time:29.941, tt:389.238\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10403, lr:1.00e-02, fs:0.71277 (r=0.677,p=0.753),  time:29.991, tt:419.872\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10161, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:30.079, tt:451.182\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09911, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:30.131, tt:482.096\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09665, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:30.215, tt:513.653\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09426, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:30.391, tt:547.043\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09195, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:30.533, tt:580.128\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09017, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:30.606, tt:612.118\n",
      "Ep:20, loss:0.00015, loss_test:0.08869, lr:1.00e-02, fs:0.80220 (r=0.737,p=0.880),  time:30.633, tt:643.294\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08675, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:30.727, tt:676.003\n",
      "Ep:22, loss:0.00014, loss_test:0.08485, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:30.795, tt:708.278\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08324, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:30.765, tt:738.370\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.08180, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:30.833, tt:770.823\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07991, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:30.908, tt:803.604\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:26, loss:0.00012, loss_test:0.07853, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.927, tt:835.030\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07761, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.993, tt:867.791\n",
      "Ep:28, loss:0.00011, loss_test:0.07611, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.996, tt:898.878\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.07470, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.024, tt:930.734\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.07315, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:31.055, tt:962.711\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.07226, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:31.059, tt:993.889\n",
      "Ep:32, loss:0.00010, loss_test:0.07114, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:31.044, tt:1024.460\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07038, lr:1.00e-02, fs:0.88043 (r=0.818,p=0.953),  time:31.091, tt:1057.093\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.06945, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:31.063, tt:1087.202\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06859, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:31.062, tt:1118.231\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.06785, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:31.092, tt:1150.397\n",
      "Ep:37, loss:0.00008, loss_test:0.06715, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:31.100, tt:1181.785\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.06628, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:31.091, tt:1212.530\n",
      "Ep:39, loss:0.00008, loss_test:0.06566, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:31.093, tt:1243.733\n",
      "Ep:40, loss:0.00008, loss_test:0.06520, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:31.087, tt:1274.547\n",
      "Ep:41, loss:0.00007, loss_test:0.06452, lr:1.00e-02, fs:0.92228 (r=0.899,p=0.947),  time:31.145, tt:1308.106\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.06382, lr:1.00e-02, fs:0.93194 (r=0.899,p=0.967),  time:31.118, tt:1338.075\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.06348, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:31.101, tt:1368.463\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.06276, lr:1.00e-02, fs:0.94241 (r=0.909,p=0.978),  time:31.109, tt:1399.898\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06224, lr:1.00e-02, fs:0.93750 (r=0.909,p=0.968),  time:31.126, tt:1431.814\n",
      "Ep:46, loss:0.00006, loss_test:0.06187, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:31.152, tt:1464.127\n",
      "Ep:47, loss:0.00006, loss_test:0.06129, lr:1.00e-02, fs:0.94241 (r=0.909,p=0.978),  time:31.186, tt:1496.911\n",
      "Ep:48, loss:0.00006, loss_test:0.06082, lr:1.00e-02, fs:0.94241 (r=0.909,p=0.978),  time:31.202, tt:1528.892\n",
      "Ep:49, loss:0.00006, loss_test:0.06070, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:31.196, tt:1559.802\n",
      "Ep:50, loss:0.00006, loss_test:0.05987, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:31.193, tt:1590.833\n",
      "Ep:51, loss:0.00006, loss_test:0.05920, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:31.241, tt:1624.552\n",
      "Ep:52, loss:0.00006, loss_test:0.05885, lr:1.00e-02, fs:0.93684 (r=0.899,p=0.978),  time:31.253, tt:1656.415\n",
      "Ep:53, loss:0.00005, loss_test:0.05875, lr:1.00e-02, fs:0.92473 (r=0.869,p=0.989),  time:31.268, tt:1688.479\n",
      "Ep:54, loss:0.00005, loss_test:0.05784, lr:1.00e-02, fs:0.94792 (r=0.919,p=0.978),  time:31.260, tt:1719.315\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.05794, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:31.259, tt:1750.500\n",
      "Ep:56, loss:0.00005, loss_test:0.05759, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:31.239, tt:1780.647\n",
      "Ep:57, loss:0.00005, loss_test:0.05698, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:31.255, tt:1812.783\n",
      "Ep:58, loss:0.00005, loss_test:0.05693, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:31.249, tt:1843.698\n",
      "Ep:59, loss:0.00005, loss_test:0.05620, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:31.247, tt:1874.839\n",
      "Ep:60, loss:0.00005, loss_test:0.05572, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:31.240, tt:1905.667\n",
      "Ep:61, loss:0.00004, loss_test:0.05590, lr:1.00e-02, fs:0.93548 (r=0.879,p=1.000),  time:31.205, tt:1934.726\n",
      "Ep:62, loss:0.00004, loss_test:0.05498, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:31.191, tt:1965.054\n",
      "Ep:63, loss:0.00004, loss_test:0.05483, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:31.181, tt:1995.606\n",
      "Ep:64, loss:0.00004, loss_test:0.05443, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:31.205, tt:2028.326\n",
      "Ep:65, loss:0.00004, loss_test:0.05398, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:31.203, tt:2059.377\n",
      "Ep:66, loss:0.00004, loss_test:0.05383, lr:9.90e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.217, tt:2091.516\n",
      "Ep:67, loss:0.00004, loss_test:0.05322, lr:9.80e-03, fs:0.94681 (r=0.899,p=1.000),  time:31.219, tt:2122.896\n",
      "Ep:68, loss:0.00004, loss_test:0.05329, lr:9.70e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.221, tt:2154.276\n",
      "Ep:69, loss:0.00004, loss_test:0.05324, lr:9.61e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.250, tt:2187.479\n",
      "Ep:70, loss:0.00004, loss_test:0.05260, lr:9.51e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.276, tt:2220.623\n",
      "Ep:71, loss:0.00003, loss_test:0.05212, lr:9.41e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.301, tt:2253.690\n",
      "Ep:72, loss:0.00003, loss_test:0.05215, lr:9.32e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.338, tt:2287.666\n",
      "Ep:73, loss:0.00003, loss_test:0.05199, lr:9.23e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.338, tt:2318.994\n",
      "Ep:74, loss:0.00003, loss_test:0.05193, lr:9.14e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.358, tt:2351.824\n",
      "Ep:75, loss:0.00003, loss_test:0.05203, lr:9.04e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.340, tt:2381.844\n",
      "Ep:76, loss:0.00003, loss_test:0.05142, lr:8.95e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.340, tt:2413.198\n",
      "Ep:77, loss:0.00003, loss_test:0.05154, lr:8.86e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.314, tt:2442.473\n",
      "Ep:78, loss:0.00003, loss_test:0.05118, lr:8.78e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.302, tt:2472.860\n",
      "Ep:79, loss:0.00003, loss_test:0.05083, lr:8.69e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.288, tt:2503.080\n",
      "Ep:80, loss:0.00003, loss_test:0.05085, lr:8.60e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.272, tt:2533.072\n",
      "Ep:81, loss:0.00003, loss_test:0.05067, lr:8.51e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.274, tt:2564.499\n",
      "Ep:82, loss:0.00003, loss_test:0.05061, lr:8.43e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.271, tt:2595.454\n",
      "Ep:83, loss:0.00003, loss_test:0.05068, lr:8.35e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.266, tt:2626.345\n",
      "Ep:84, loss:0.00003, loss_test:0.05041, lr:8.26e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.275, tt:2658.380\n",
      "Ep:85, loss:0.00003, loss_test:0.05026, lr:8.18e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.273, tt:2689.494\n",
      "Ep:86, loss:0.00003, loss_test:0.05011, lr:8.10e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.297, tt:2722.838\n",
      "Ep:87, loss:0.00003, loss_test:0.04996, lr:8.02e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.309, tt:2755.205\n",
      "Ep:88, loss:0.00002, loss_test:0.04972, lr:7.94e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.347, tt:2789.865\n",
      "Ep:89, loss:0.00002, loss_test:0.05005, lr:7.86e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.352, tt:2821.704\n",
      "Ep:90, loss:0.00002, loss_test:0.04981, lr:7.78e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.350, tt:2852.824\n",
      "Ep:91, loss:0.00002, loss_test:0.04977, lr:7.70e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.359, tt:2885.056\n",
      "Ep:92, loss:0.00002, loss_test:0.04974, lr:7.62e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.375, tt:2917.883\n",
      "Ep:93, loss:0.00002, loss_test:0.04935, lr:7.55e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.388, tt:2950.425\n",
      "Ep:94, loss:0.00002, loss_test:0.04946, lr:7.47e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.380, tt:2981.073\n",
      "Ep:95, loss:0.00002, loss_test:0.04924, lr:7.40e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.386, tt:3013.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:96, loss:0.00002, loss_test:0.04921, lr:7.32e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.376, tt:3043.490\n",
      "Ep:97, loss:0.00002, loss_test:0.04926, lr:7.25e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.381, tt:3075.381\n",
      "Ep:98, loss:0.00002, loss_test:0.04915, lr:7.18e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.383, tt:3106.961\n",
      "Ep:99, loss:0.00002, loss_test:0.04914, lr:7.11e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.370, tt:3137.014\n",
      "Ep:100, loss:0.00002, loss_test:0.04898, lr:7.03e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.372, tt:3168.524\n",
      "Ep:101, loss:0.00002, loss_test:0.04892, lr:6.96e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.365, tt:3199.238\n",
      "Ep:102, loss:0.00002, loss_test:0.04924, lr:6.89e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.357, tt:3229.758\n",
      "Ep:103, loss:0.00002, loss_test:0.04885, lr:6.83e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.355, tt:3260.961\n",
      "Ep:104, loss:0.00002, loss_test:0.04873, lr:6.76e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.357, tt:3292.444\n",
      "Ep:105, loss:0.00002, loss_test:0.04894, lr:6.69e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.353, tt:3323.436\n",
      "Ep:106, loss:0.00002, loss_test:0.04889, lr:6.62e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.350, tt:3354.487\n",
      "Ep:107, loss:0.00002, loss_test:0.04850, lr:6.56e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.342, tt:3384.986\n",
      "Ep:108, loss:0.00002, loss_test:0.04865, lr:6.49e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.347, tt:3416.833\n",
      "Ep:109, loss:0.00002, loss_test:0.04860, lr:6.43e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.372, tt:3450.886\n",
      "Ep:110, loss:0.00002, loss_test:0.04854, lr:6.36e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.365, tt:3481.564\n",
      "Ep:111, loss:0.00002, loss_test:0.04867, lr:6.30e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.381, tt:3514.664\n",
      "Ep:112, loss:0.00002, loss_test:0.04843, lr:6.24e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.383, tt:3546.323\n",
      "Ep:113, loss:0.00002, loss_test:0.04847, lr:6.17e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.382, tt:3577.599\n",
      "Ep:114, loss:0.00002, loss_test:0.04881, lr:6.11e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.392, tt:3610.090\n",
      "Ep:115, loss:0.00002, loss_test:0.04850, lr:6.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.398, tt:3642.134\n",
      "Ep:116, loss:0.00002, loss_test:0.04833, lr:5.99e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.399, tt:3673.733\n",
      "Ep:117, loss:0.00002, loss_test:0.04833, lr:5.93e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.402, tt:3705.481\n",
      "Ep:118, loss:0.00002, loss_test:0.04829, lr:5.87e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.405, tt:3737.229\n",
      "Ep:119, loss:0.00002, loss_test:0.04822, lr:5.81e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.407, tt:3768.841\n",
      "Ep:120, loss:0.00002, loss_test:0.04819, lr:5.75e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.420, tt:3801.809\n",
      "Ep:121, loss:0.00002, loss_test:0.04823, lr:5.70e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.429, tt:3834.286\n",
      "Ep:122, loss:0.00002, loss_test:0.04829, lr:5.64e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.445, tt:3867.784\n",
      "Ep:123, loss:0.00002, loss_test:0.04815, lr:5.58e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.450, tt:3899.811\n",
      "Ep:124, loss:0.00002, loss_test:0.04817, lr:5.53e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.443, tt:3930.419\n",
      "Ep:125, loss:0.00002, loss_test:0.04815, lr:5.47e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.434, tt:3960.635\n",
      "Ep:126, loss:0.00002, loss_test:0.04799, lr:5.42e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.401, tt:3987.877\n",
      "Ep:127, loss:0.00002, loss_test:0.04809, lr:5.36e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.410, tt:4020.420\n",
      "Ep:128, loss:0.00002, loss_test:0.04782, lr:5.31e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.417, tt:4052.847\n",
      "Ep:129, loss:0.00002, loss_test:0.04796, lr:5.26e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.424, tt:4085.183\n",
      "Ep:130, loss:0.00001, loss_test:0.04814, lr:5.20e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.422, tt:4116.222\n",
      "Ep:131, loss:0.00001, loss_test:0.04799, lr:5.15e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.416, tt:4146.869\n",
      "Ep:132, loss:0.00001, loss_test:0.04763, lr:5.10e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.429, tt:4180.049\n",
      "Ep:133, loss:0.00001, loss_test:0.04794, lr:5.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.435, tt:4212.288\n",
      "Ep:134, loss:0.00001, loss_test:0.04782, lr:5.00e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.433, tt:4243.436\n",
      "Ep:135, loss:0.00001, loss_test:0.04761, lr:4.95e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.460, tt:4278.623\n",
      "Ep:136, loss:0.00001, loss_test:0.04778, lr:4.90e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.455, tt:4309.381\n",
      "Ep:137, loss:0.00001, loss_test:0.04777, lr:4.85e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.444, tt:4339.313\n",
      "Ep:138, loss:0.00001, loss_test:0.04748, lr:4.80e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.435, tt:4369.478\n",
      "Ep:139, loss:0.00001, loss_test:0.04762, lr:4.75e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.425, tt:4399.446\n",
      "Ep:140, loss:0.00001, loss_test:0.04738, lr:4.71e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.430, tt:4431.664\n",
      "Ep:141, loss:0.00001, loss_test:0.04740, lr:4.66e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.432, tt:4463.340\n",
      "Ep:142, loss:0.00001, loss_test:0.04757, lr:4.61e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.427, tt:4494.127\n",
      "Ep:143, loss:0.00001, loss_test:0.04772, lr:4.57e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.429, tt:4525.731\n",
      "Ep:144, loss:0.00001, loss_test:0.04750, lr:4.52e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.427, tt:4556.929\n",
      "Ep:145, loss:0.00001, loss_test:0.04745, lr:4.48e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.421, tt:4587.496\n",
      "Ep:146, loss:0.00001, loss_test:0.04778, lr:4.43e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.414, tt:4617.803\n",
      "Ep:147, loss:0.00001, loss_test:0.04760, lr:4.39e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.405, tt:4647.978\n",
      "Ep:148, loss:0.00001, loss_test:0.04724, lr:4.34e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.408, tt:4679.858\n",
      "Ep:149, loss:0.00001, loss_test:0.04755, lr:4.30e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.408, tt:4711.150\n",
      "Ep:150, loss:0.00001, loss_test:0.04759, lr:4.26e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.411, tt:4743.022\n",
      "Ep:151, loss:0.00001, loss_test:0.04732, lr:4.21e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.409, tt:4774.241\n",
      "Ep:152, loss:0.00001, loss_test:0.04728, lr:4.17e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.416, tt:4806.652\n",
      "Ep:153, loss:0.00001, loss_test:0.04753, lr:4.13e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.418, tt:4838.430\n",
      "Ep:154, loss:0.00001, loss_test:0.04746, lr:4.09e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.423, tt:4870.493\n",
      "Ep:155, loss:0.00001, loss_test:0.04719, lr:4.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.422, tt:4901.856\n",
      "Ep:156, loss:0.00001, loss_test:0.04744, lr:4.01e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.433, tt:4935.019\n",
      "Ep:157, loss:0.00001, loss_test:0.04740, lr:3.97e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.435, tt:4966.733\n",
      "Ep:158, loss:0.00001, loss_test:0.04730, lr:3.93e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.442, tt:4999.316\n",
      "Ep:159, loss:0.00001, loss_test:0.04727, lr:3.89e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.441, tt:5030.537\n",
      "Ep:160, loss:0.00001, loss_test:0.04726, lr:3.85e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.436, tt:5061.255\n",
      "Ep:161, loss:0.00001, loss_test:0.04728, lr:3.81e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.439, tt:5093.171\n",
      "Ep:162, loss:0.00001, loss_test:0.04729, lr:3.77e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.430, tt:5123.034\n",
      "Ep:163, loss:0.00001, loss_test:0.04734, lr:3.73e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.432, tt:5154.928\n",
      "Ep:164, loss:0.00001, loss_test:0.04728, lr:3.70e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.432, tt:5186.222\n",
      "Ep:165, loss:0.00001, loss_test:0.04716, lr:3.66e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.426, tt:5216.732\n",
      "Ep:166, loss:0.00001, loss_test:0.04725, lr:3.62e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.424, tt:5247.787\n",
      "Ep:167, loss:0.00001, loss_test:0.04730, lr:3.59e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.430, tt:5280.255\n",
      "Ep:168, loss:0.00001, loss_test:0.04725, lr:3.55e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.425, tt:5310.862\n",
      "Ep:169, loss:0.00001, loss_test:0.04734, lr:3.52e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.415, tt:5340.569\n",
      "Ep:170, loss:0.00001, loss_test:0.04752, lr:3.48e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.414, tt:5371.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:171, loss:0.00001, loss_test:0.04741, lr:3.45e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.418, tt:5403.850\n",
      "Ep:172, loss:0.00001, loss_test:0.04723, lr:3.41e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.420, tt:5435.589\n",
      "Ep:173, loss:0.00001, loss_test:0.04732, lr:3.38e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.411, tt:5465.437\n",
      "Ep:174, loss:0.00001, loss_test:0.04744, lr:3.34e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.409, tt:5496.636\n",
      "Ep:175, loss:0.00001, loss_test:0.04735, lr:3.31e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.409, tt:5528.055\n",
      "Ep:176, loss:0.00001, loss_test:0.04718, lr:3.28e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.402, tt:5558.098\n",
      "Ep:177, loss:0.00001, loss_test:0.04726, lr:3.24e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.392, tt:5587.802\n",
      "Ep:178, loss:0.00001, loss_test:0.04742, lr:3.21e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.388, tt:5618.480\n",
      "Ep:179, loss:0.00001, loss_test:0.04740, lr:3.18e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.385, tt:5649.387\n",
      "Ep:180, loss:0.00001, loss_test:0.04717, lr:3.15e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.385, tt:5680.706\n",
      "Ep:181, loss:0.00001, loss_test:0.04732, lr:3.12e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.390, tt:5712.998\n",
      "Ep:182, loss:0.00001, loss_test:0.04730, lr:3.09e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.396, tt:5745.492\n",
      "Ep:183, loss:0.00001, loss_test:0.04730, lr:3.05e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.391, tt:5775.903\n",
      "Ep:184, loss:0.00001, loss_test:0.04729, lr:3.02e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.395, tt:5807.987\n",
      "Ep:185, loss:0.00001, loss_test:0.04731, lr:2.99e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.396, tt:5839.658\n",
      "Ep:186, loss:0.00001, loss_test:0.04737, lr:2.96e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.396, tt:5871.072\n",
      "Ep:187, loss:0.00001, loss_test:0.04731, lr:2.93e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.402, tt:5903.491\n",
      "Ep:188, loss:0.00001, loss_test:0.04733, lr:2.90e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.400, tt:5934.688\n",
      "Ep:189, loss:0.00001, loss_test:0.04737, lr:2.88e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.408, tt:5967.583\n",
      "Ep:190, loss:0.00001, loss_test:0.04740, lr:2.85e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.423, tt:6001.887\n",
      "Ep:191, loss:0.00001, loss_test:0.04732, lr:2.82e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.433, tt:6035.217\n",
      "Ep:192, loss:0.00001, loss_test:0.04736, lr:2.79e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.437, tt:6067.303\n",
      "Ep:193, loss:0.00001, loss_test:0.04738, lr:2.76e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.445, tt:6100.426\n",
      "Ep:194, loss:0.00001, loss_test:0.04722, lr:2.73e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.445, tt:6131.757\n",
      "Ep:195, loss:0.00001, loss_test:0.04741, lr:2.71e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.437, tt:6161.652\n",
      "Ep:196, loss:0.00001, loss_test:0.04749, lr:2.68e-03, fs:0.92973 (r=0.869,p=1.000),  time:31.435, tt:6192.708\n",
      "Ep:197, loss:0.00001, loss_test:0.04733, lr:2.65e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.446, tt:6226.283\n",
      "Ep:198, loss:0.00001, loss_test:0.04728, lr:2.63e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.444, tt:6257.426\n",
      "Ep:199, loss:0.00001, loss_test:0.04735, lr:2.60e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.446, tt:6289.188\n",
      "Ep:200, loss:0.00001, loss_test:0.04734, lr:2.57e-03, fs:0.93548 (r=0.879,p=1.000),  time:31.445, tt:6320.420\n",
      "Ep:201, loss:0.00001, loss_test:0.04734, lr:2.55e-03, fs:0.94118 (r=0.889,p=1.000),  time:31.444, tt:6351.687\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02013, lr:6.00e-02, fs:0.63025 (r=0.758,p=0.540),  time:21.948, tt:21.948\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:22.475, tt:44.949\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02368, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.403, tt:67.210\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02433, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.327, tt:89.308\n",
      "Ep:4, loss:0.00005, loss_test:0.02398, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.921, tt:109.603\n",
      "Ep:5, loss:0.00005, loss_test:0.02292, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.800, tt:130.797\n",
      "Ep:6, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.761, tt:152.325\n",
      "Ep:7, loss:0.00004, loss_test:0.02031, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:21.581, tt:172.645\n",
      "Ep:8, loss:0.00004, loss_test:0.01966, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:21.875, tt:196.872\n",
      "Ep:9, loss:0.00004, loss_test:0.01974, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:22.116, tt:221.159\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01986, lr:6.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:22.429, tt:246.717\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01938, lr:6.00e-02, fs:0.68619 (r=0.828,p=0.586),  time:22.794, tt:273.526\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:22.945, tt:298.291\n",
      "Ep:13, loss:0.00003, loss_test:0.01823, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:23.066, tt:322.919\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01797, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:23.184, tt:347.760\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:23.286, tt:372.569\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01726, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:23.443, tt:398.528\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.70635 (r=0.899,p=0.582),  time:23.630, tt:425.337\n",
      "Ep:18, loss:0.00003, loss_test:0.01679, lr:6.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:23.615, tt:448.683\n",
      "Ep:19, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:23.708, tt:474.156\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.73029 (r=0.889,p=0.620),  time:23.866, tt:501.194\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01620, lr:6.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:23.920, tt:526.241\n",
      "Ep:22, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:23.953, tt:550.924\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:24.085, tt:578.050\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01565, lr:6.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:24.141, tt:603.536\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:24.220, tt:629.713\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01542, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:24.276, tt:655.459\n",
      "Ep:27, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:24.334, tt:681.362\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01512, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:24.342, tt:705.920\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01497, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:24.408, tt:732.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:24.486, tt:759.065\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:24.487, tt:783.581\n",
      "Ep:32, loss:0.00002, loss_test:0.01468, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:24.568, tt:810.749\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:24.579, tt:835.682\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:24.563, tt:859.719\n",
      "Ep:35, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:24.601, tt:885.619\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:24.571, tt:909.140\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:24.580, tt:934.046\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:24.636, tt:960.805\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:24.676, tt:987.043\n",
      "Ep:40, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:24.704, tt:1012.844\n",
      "Ep:41, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:24.703, tt:1037.511\n",
      "Ep:42, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.84163 (r=0.939,p=0.762),  time:24.714, tt:1062.702\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:24.744, tt:1088.742\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:24.757, tt:1114.063\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:24.792, tt:1140.452\n",
      "Ep:46, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:24.812, tt:1166.159\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:24.843, tt:1192.460\n",
      "Ep:48, loss:0.00002, loss_test:0.01319, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:24.835, tt:1216.896\n",
      "Ep:49, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:24.856, tt:1242.800\n",
      "Ep:50, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:24.864, tt:1268.087\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:24.887, tt:1294.129\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:24.880, tt:1318.636\n",
      "Ep:53, loss:0.00001, loss_test:0.01290, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:24.883, tt:1343.659\n",
      "Ep:54, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:24.864, tt:1367.495\n",
      "Ep:55, loss:0.00001, loss_test:0.01279, lr:6.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:24.891, tt:1393.906\n",
      "Ep:56, loss:0.00001, loss_test:0.01277, lr:6.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:24.902, tt:1419.434\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:24.931, tt:1445.978\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:24.990, tt:1474.428\n",
      "Ep:59, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:24.981, tt:1498.881\n",
      "Ep:60, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:25.006, tt:1525.359\n",
      "Ep:61, loss:0.00001, loss_test:0.01251, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:25.030, tt:1551.838\n",
      "Ep:62, loss:0.00001, loss_test:0.01248, lr:6.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:25.037, tt:1577.350\n",
      "Ep:63, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:25.088, tt:1605.633\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01242, lr:6.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:25.114, tt:1632.406\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01236, lr:6.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:25.149, tt:1659.862\n",
      "Ep:66, loss:0.00001, loss_test:0.01235, lr:6.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:25.167, tt:1686.169\n",
      "Ep:67, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:25.188, tt:1712.800\n",
      "Ep:68, loss:0.00001, loss_test:0.01225, lr:6.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:25.209, tt:1739.390\n",
      "Ep:69, loss:0.00001, loss_test:0.01221, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:25.227, tt:1765.861\n",
      "Ep:70, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:25.239, tt:1791.999\n",
      "Ep:71, loss:0.00001, loss_test:0.01216, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:25.232, tt:1816.723\n",
      "Ep:72, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:25.232, tt:1841.918\n",
      "Ep:73, loss:0.00001, loss_test:0.01216, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:25.217, tt:1866.066\n",
      "Ep:74, loss:0.00001, loss_test:0.01211, lr:6.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:25.223, tt:1891.741\n",
      "Ep:75, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:25.236, tt:1917.928\n",
      "Ep:76, loss:0.00001, loss_test:0.01207, lr:5.94e-02, fs:0.88660 (r=0.869,p=0.905),  time:25.254, tt:1944.589\n",
      "Ep:77, loss:0.00001, loss_test:0.01205, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:25.244, tt:1969.048\n",
      "Ep:78, loss:0.00001, loss_test:0.01203, lr:5.82e-02, fs:0.87500 (r=0.848,p=0.903),  time:25.252, tt:1994.879\n",
      "Ep:79, loss:0.00001, loss_test:0.01202, lr:5.76e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.260, tt:2020.784\n",
      "Ep:80, loss:0.00001, loss_test:0.01197, lr:5.71e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.275, tt:2047.307\n",
      "Ep:81, loss:0.00001, loss_test:0.01198, lr:5.65e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.265, tt:2071.691\n",
      "Ep:82, loss:0.00001, loss_test:0.01196, lr:5.59e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.281, tt:2098.308\n",
      "Ep:83, loss:0.00001, loss_test:0.01194, lr:5.54e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.285, tt:2123.959\n",
      "Ep:84, loss:0.00001, loss_test:0.01191, lr:5.48e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.304, tt:2150.850\n",
      "Ep:85, loss:0.00001, loss_test:0.01194, lr:5.43e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.307, tt:2176.397\n",
      "Ep:86, loss:0.00001, loss_test:0.01196, lr:5.37e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.297, tt:2200.852\n",
      "Ep:87, loss:0.00001, loss_test:0.01193, lr:5.32e-02, fs:0.87368 (r=0.838,p=0.912),  time:25.304, tt:2226.779\n",
      "Ep:88, loss:0.00001, loss_test:0.01190, lr:5.27e-02, fs:0.86911 (r=0.838,p=0.902),  time:25.309, tt:2252.505\n",
      "Ep:89, loss:0.00001, loss_test:0.01189, lr:5.21e-02, fs:0.86772 (r=0.828,p=0.911),  time:25.308, tt:2277.764\n",
      "Ep:90, loss:0.00001, loss_test:0.01190, lr:5.16e-02, fs:0.87234 (r=0.828,p=0.921),  time:25.303, tt:2302.557\n",
      "Ep:91, loss:0.00001, loss_test:0.01187, lr:5.11e-02, fs:0.87234 (r=0.828,p=0.921),  time:25.287, tt:2326.423\n",
      "Ep:92, loss:0.00001, loss_test:0.01187, lr:5.06e-02, fs:0.87701 (r=0.828,p=0.932),  time:25.297, tt:2352.576\n",
      "Ep:93, loss:0.00001, loss_test:0.01191, lr:5.01e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.281, tt:2376.428\n",
      "Ep:94, loss:0.00001, loss_test:0.01190, lr:4.96e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.291, tt:2402.639\n",
      "Ep:95, loss:0.00001, loss_test:0.01185, lr:4.91e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.291, tt:2427.930\n",
      "Ep:96, loss:0.00001, loss_test:0.01183, lr:4.86e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.293, tt:2453.457\n",
      "Ep:97, loss:0.00001, loss_test:0.01183, lr:4.81e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.294, tt:2478.844\n",
      "Ep:98, loss:0.00001, loss_test:0.01181, lr:4.76e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.303, tt:2505.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:99, loss:0.00001, loss_test:0.01182, lr:4.71e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.309, tt:2530.871\n",
      "Ep:100, loss:0.00001, loss_test:0.01182, lr:4.67e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.313, tt:2556.574\n",
      "Ep:101, loss:0.00001, loss_test:0.01181, lr:4.62e-02, fs:0.87097 (r=0.818,p=0.931),  time:25.310, tt:2581.622\n",
      "Ep:102, loss:0.00001, loss_test:0.01184, lr:4.57e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.317, tt:2607.668\n",
      "Ep:103, loss:0.00001, loss_test:0.01184, lr:4.53e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.314, tt:2632.647\n",
      "Ep:104, loss:0.00001, loss_test:0.01182, lr:4.48e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.320, tt:2658.555\n",
      "Ep:105, loss:0.00001, loss_test:0.01181, lr:4.44e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.322, tt:2684.139\n",
      "Ep:106, loss:0.00001, loss_test:0.01181, lr:4.39e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.331, tt:2710.435\n",
      "Ep:107, loss:0.00001, loss_test:0.01181, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.325, tt:2735.079\n",
      "Ep:108, loss:0.00001, loss_test:0.01181, lr:4.31e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.329, tt:2760.863\n",
      "Ep:109, loss:0.00001, loss_test:0.01182, lr:4.26e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.337, tt:2787.054\n",
      "Ep:110, loss:0.00001, loss_test:0.01182, lr:4.22e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.367, tt:2815.710\n",
      "Ep:111, loss:0.00001, loss_test:0.01181, lr:4.18e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.392, tt:2843.897\n",
      "Ep:112, loss:0.00001, loss_test:0.01181, lr:4.14e-02, fs:0.87432 (r=0.808,p=0.952),  time:25.391, tt:2869.227\n",
      "Ep:113, loss:0.00001, loss_test:0.01180, lr:4.10e-02, fs:0.87432 (r=0.808,p=0.952),  time:25.403, tt:2895.934\n",
      "Ep:114, loss:0.00001, loss_test:0.01180, lr:4.05e-02, fs:0.87432 (r=0.808,p=0.952),  time:25.421, tt:2923.398\n",
      "Ep:115, loss:0.00001, loss_test:0.01179, lr:4.01e-02, fs:0.87432 (r=0.808,p=0.952),  time:25.423, tt:2949.045\n",
      "Ep:116, loss:0.00001, loss_test:0.01181, lr:3.97e-02, fs:0.87432 (r=0.808,p=0.952),  time:25.427, tt:2975.004\n",
      "Ep:117, loss:0.00001, loss_test:0.01181, lr:3.93e-02, fs:0.87912 (r=0.808,p=0.964),  time:25.428, tt:3000.509\n",
      "Ep:118, loss:0.00001, loss_test:0.01181, lr:3.89e-02, fs:0.87912 (r=0.808,p=0.964),  time:25.438, tt:3027.064\n",
      "Ep:119, loss:0.00001, loss_test:0.01181, lr:3.86e-02, fs:0.87912 (r=0.808,p=0.964),  time:25.446, tt:3053.506\n",
      "Ep:120, loss:0.00001, loss_test:0.01180, lr:3.82e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.447, tt:3079.032\n",
      "Ep:121, loss:0.00001, loss_test:0.01180, lr:3.78e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.455, tt:3105.523\n",
      "Ep:122, loss:0.00001, loss_test:0.01180, lr:3.74e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.452, tt:3130.581\n",
      "Ep:123, loss:0.00001, loss_test:0.01181, lr:3.70e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.464, tt:3157.593\n",
      "Ep:124, loss:0.00001, loss_test:0.01182, lr:3.67e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.470, tt:3183.689\n",
      "Ep:125, loss:0.00001, loss_test:0.01181, lr:3.63e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.465, tt:3208.607\n",
      "Ep:126, loss:0.00001, loss_test:0.01182, lr:3.59e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.471, tt:3234.782\n",
      "Ep:127, loss:0.00001, loss_test:0.01182, lr:3.56e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.471, tt:3260.305\n",
      "Ep:128, loss:0.00001, loss_test:0.01181, lr:3.52e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.470, tt:3285.661\n",
      "Ep:129, loss:0.00001, loss_test:0.01180, lr:3.49e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.460, tt:3309.844\n",
      "Ep:130, loss:0.00001, loss_test:0.01181, lr:3.45e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.449, tt:3333.871\n",
      "Ep:131, loss:0.00001, loss_test:0.01180, lr:3.42e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.451, tt:3359.597\n",
      "Ep:132, loss:0.00001, loss_test:0.01182, lr:3.38e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.447, tt:3384.441\n",
      "Ep:133, loss:0.00001, loss_test:0.01183, lr:3.35e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.441, tt:3409.143\n",
      "Ep:134, loss:0.00001, loss_test:0.01184, lr:3.32e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.442, tt:3434.638\n",
      "Ep:135, loss:0.00001, loss_test:0.01184, lr:3.28e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.437, tt:3459.458\n",
      "Ep:136, loss:0.00001, loss_test:0.01183, lr:3.25e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.451, tt:3486.786\n",
      "Ep:137, loss:0.00001, loss_test:0.01183, lr:3.22e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.459, tt:3513.349\n",
      "Ep:138, loss:0.00001, loss_test:0.01183, lr:3.19e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.464, tt:3539.453\n",
      "Ep:139, loss:0.00001, loss_test:0.01183, lr:3.15e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.472, tt:3566.101\n",
      "Ep:140, loss:0.00001, loss_test:0.01183, lr:3.12e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.471, tt:3591.473\n",
      "Ep:141, loss:0.00001, loss_test:0.01184, lr:3.09e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.483, tt:3618.560\n",
      "Ep:142, loss:0.00001, loss_test:0.01185, lr:3.06e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.493, tt:3645.469\n",
      "Ep:143, loss:0.00001, loss_test:0.01186, lr:3.03e-02, fs:0.88889 (r=0.808,p=0.988),  time:25.497, tt:3671.527\n",
      "Ep:144, loss:0.00001, loss_test:0.01185, lr:3.00e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.487, tt:3695.546\n",
      "Ep:145, loss:0.00001, loss_test:0.01184, lr:2.97e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.472, tt:3718.957\n",
      "Ep:146, loss:0.00001, loss_test:0.01183, lr:2.94e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.482, tt:3745.785\n",
      "Ep:147, loss:0.00001, loss_test:0.01184, lr:2.91e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.485, tt:3771.728\n",
      "Ep:148, loss:0.00001, loss_test:0.01185, lr:2.88e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.490, tt:3798.020\n",
      "Ep:149, loss:0.00000, loss_test:0.01185, lr:2.85e-02, fs:0.88398 (r=0.808,p=0.976),  time:25.485, tt:3822.760\n",
      "Ep:150, loss:0.00000, loss_test:0.01185, lr:2.82e-02, fs:0.88889 (r=0.808,p=0.988),  time:25.490, tt:3848.963\n",
      "Ep:151, loss:0.00000, loss_test:0.01186, lr:2.80e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.492, tt:3874.774\n",
      "Ep:152, loss:0.00000, loss_test:0.01186, lr:2.77e-02, fs:0.88889 (r=0.808,p=0.988),  time:25.500, tt:3901.427\n",
      "Ep:153, loss:0.00000, loss_test:0.01186, lr:2.74e-02, fs:0.88889 (r=0.808,p=0.988),  time:25.495, tt:3926.182\n",
      "Ep:154, loss:0.00000, loss_test:0.01186, lr:2.71e-02, fs:0.88889 (r=0.808,p=0.988),  time:25.492, tt:3951.200\n",
      "Ep:155, loss:0.00000, loss_test:0.01187, lr:2.69e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.494, tt:3977.015\n",
      "Ep:156, loss:0.00000, loss_test:0.01188, lr:2.66e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.490, tt:4001.981\n",
      "Ep:157, loss:0.00000, loss_test:0.01188, lr:2.63e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.495, tt:4028.205\n",
      "Ep:158, loss:0.00000, loss_test:0.01189, lr:2.61e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.500, tt:4054.472\n",
      "Ep:159, loss:0.00000, loss_test:0.01189, lr:2.58e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.507, tt:4081.067\n",
      "Ep:160, loss:0.00000, loss_test:0.01189, lr:2.55e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.515, tt:4107.851\n",
      "Ep:161, loss:0.00000, loss_test:0.01190, lr:2.53e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.518, tt:4133.873\n",
      "Ep:162, loss:0.00000, loss_test:0.01189, lr:2.50e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.547, tt:4164.212\n",
      "Ep:163, loss:0.00000, loss_test:0.01189, lr:2.48e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.545, tt:4189.355\n",
      "Ep:164, loss:0.00000, loss_test:0.01189, lr:2.45e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.545, tt:4214.865\n",
      "Ep:165, loss:0.00000, loss_test:0.01190, lr:2.43e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.547, tt:4240.804\n",
      "Ep:166, loss:0.00000, loss_test:0.01190, lr:2.40e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.551, tt:4267.042\n",
      "Ep:167, loss:0.00000, loss_test:0.01190, lr:2.38e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.562, tt:4294.405\n",
      "Ep:168, loss:0.00000, loss_test:0.01190, lr:2.36e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.565, tt:4320.476\n",
      "Ep:169, loss:0.00000, loss_test:0.01191, lr:2.33e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.566, tt:4346.146\n",
      "Ep:170, loss:0.00000, loss_test:0.01191, lr:2.31e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.574, tt:4373.162\n",
      "Ep:171, loss:0.00000, loss_test:0.01191, lr:2.29e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.571, tt:4398.274\n",
      "Ep:172, loss:0.00000, loss_test:0.01191, lr:2.26e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.567, tt:4423.030\n",
      "Ep:173, loss:0.00000, loss_test:0.01191, lr:2.24e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.562, tt:4447.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:174, loss:0.00000, loss_test:0.01192, lr:2.22e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.562, tt:4473.414\n",
      "Ep:175, loss:0.00000, loss_test:0.01192, lr:2.20e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.563, tt:4499.165\n",
      "Ep:176, loss:0.00000, loss_test:0.01193, lr:2.17e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.560, tt:4524.180\n",
      "Ep:177, loss:0.00000, loss_test:0.01192, lr:2.15e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.560, tt:4549.607\n",
      "Ep:178, loss:0.00000, loss_test:0.01193, lr:2.13e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.559, tt:4575.019\n",
      "Ep:179, loss:0.00000, loss_test:0.01193, lr:2.11e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.565, tt:4601.741\n",
      "Ep:180, loss:0.00000, loss_test:0.01194, lr:2.09e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.567, tt:4627.708\n",
      "Ep:181, loss:0.00000, loss_test:0.01195, lr:2.07e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.571, tt:4653.894\n",
      "Ep:182, loss:0.00000, loss_test:0.01195, lr:2.05e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.580, tt:4681.150\n",
      "Ep:183, loss:0.00000, loss_test:0.01195, lr:2.03e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.579, tt:4706.622\n",
      "Ep:184, loss:0.00000, loss_test:0.01196, lr:2.01e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.578, tt:4731.996\n",
      "Ep:185, loss:0.00000, loss_test:0.01197, lr:1.99e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.577, tt:4757.267\n",
      "Ep:186, loss:0.00000, loss_test:0.01197, lr:1.97e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.583, tt:4784.059\n",
      "Ep:187, loss:0.00000, loss_test:0.01197, lr:1.95e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.582, tt:4809.326\n",
      "Ep:188, loss:0.00000, loss_test:0.01197, lr:1.93e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.595, tt:4837.495\n",
      "Ep:189, loss:0.00000, loss_test:0.01197, lr:1.91e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.598, tt:4863.625\n",
      "Ep:190, loss:0.00000, loss_test:0.01197, lr:1.89e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.590, tt:4887.753\n",
      "Ep:191, loss:0.00000, loss_test:0.01198, lr:1.87e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.589, tt:4913.168\n",
      "Ep:192, loss:0.00000, loss_test:0.01198, lr:1.85e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.584, tt:4937.779\n",
      "Ep:193, loss:0.00000, loss_test:0.01198, lr:1.83e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.584, tt:4963.242\n",
      "Ep:194, loss:0.00000, loss_test:0.01198, lr:1.81e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.587, tt:4989.461\n",
      "Ep:195, loss:0.00000, loss_test:0.01198, lr:1.80e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.588, tt:5015.199\n",
      "Ep:196, loss:0.00000, loss_test:0.01198, lr:1.78e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.583, tt:5039.826\n",
      "Ep:197, loss:0.00000, loss_test:0.01199, lr:1.76e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.584, tt:5065.533\n",
      "Ep:198, loss:0.00000, loss_test:0.01199, lr:1.74e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.583, tt:5090.935\n",
      "Ep:199, loss:0.00000, loss_test:0.01199, lr:1.73e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.586, tt:5117.169\n",
      "Ep:200, loss:0.00000, loss_test:0.01200, lr:1.71e-02, fs:0.89385 (r=0.808,p=1.000),  time:25.581, tt:5141.776\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13681, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:27.960, tt:27.960\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13451, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:26.215, tt:52.430\n",
      "Ep:2, loss:0.00026, loss_test:0.13031, lr:1.00e-02, fs:0.67368 (r=0.970,p=0.516),  time:25.404, tt:76.213\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12438, lr:1.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:25.246, tt:100.984\n",
      "Ep:4, loss:0.00024, loss_test:0.11959, lr:1.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:25.424, tt:127.121\n",
      "Ep:5, loss:0.00023, loss_test:0.11831, lr:1.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:25.199, tt:151.194\n",
      "Ep:6, loss:0.00023, loss_test:0.11697, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:25.314, tt:177.200\n",
      "Ep:7, loss:0.00022, loss_test:0.11470, lr:1.00e-02, fs:0.66094 (r=0.778,p=0.575),  time:25.114, tt:200.911\n",
      "Ep:8, loss:0.00022, loss_test:0.11396, lr:1.00e-02, fs:0.65833 (r=0.798,p=0.560),  time:25.141, tt:226.266\n",
      "Ep:9, loss:0.00022, loss_test:0.11111, lr:1.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:25.026, tt:250.262\n",
      "Ep:10, loss:0.00021, loss_test:0.10826, lr:1.00e-02, fs:0.69683 (r=0.778,p=0.631),  time:25.108, tt:276.193\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10666, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:25.273, tt:303.275\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10513, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:25.641, tt:333.338\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.10357, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:25.643, tt:359.007\n",
      "Ep:14, loss:0.00019, loss_test:0.10193, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:25.622, tt:384.328\n",
      "Ep:15, loss:0.00019, loss_test:0.10102, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:25.827, tt:413.231\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10012, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:25.925, tt:440.723\n",
      "Ep:17, loss:0.00018, loss_test:0.09869, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:26.001, tt:468.018\n",
      "Ep:18, loss:0.00017, loss_test:0.09738, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:26.034, tt:494.637\n",
      "Ep:19, loss:0.00017, loss_test:0.09639, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:26.073, tt:521.469\n",
      "Ep:20, loss:0.00017, loss_test:0.09504, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:26.127, tt:548.668\n",
      "Ep:21, loss:0.00016, loss_test:0.09341, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:26.236, tt:577.195\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.09230, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:26.295, tt:604.796\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09110, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:26.363, tt:632.722\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08953, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:26.424, tt:660.596\n",
      "Ep:25, loss:0.00014, loss_test:0.08875, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:26.436, tt:687.331\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08796, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:26.494, tt:715.326\n",
      "Ep:27, loss:0.00013, loss_test:0.08687, lr:1.00e-02, fs:0.78212 (r=0.707,p=0.875),  time:26.536, tt:743.009\n",
      "Ep:28, loss:0.00013, loss_test:0.08601, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:26.544, tt:769.784\n",
      "Ep:29, loss:0.00013, loss_test:0.08486, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:26.552, tt:796.571\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08425, lr:1.00e-02, fs:0.79096 (r=0.707,p=0.897),  time:26.563, tt:823.467\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08356, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:26.601, tt:851.228\n",
      "Ep:32, loss:0.00011, loss_test:0.08248, lr:1.00e-02, fs:0.79775 (r=0.717,p=0.899),  time:26.605, tt:877.979\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08223, lr:1.00e-02, fs:0.78857 (r=0.697,p=0.908),  time:26.635, tt:905.574\n",
      "Ep:34, loss:0.00011, loss_test:0.08145, lr:1.00e-02, fs:0.78652 (r=0.707,p=0.886),  time:26.649, tt:932.725\n",
      "Ep:35, loss:0.00010, loss_test:0.08067, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:26.660, tt:959.762\n",
      "Ep:36, loss:0.00010, loss_test:0.08001, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:26.710, tt:988.286\n",
      "Ep:37, loss:0.00010, loss_test:0.07970, lr:1.00e-02, fs:0.78409 (r=0.697,p=0.896),  time:26.661, tt:1013.129\n",
      "Ep:38, loss:0.00010, loss_test:0.07916, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:26.643, tt:1039.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:39, loss:0.00009, loss_test:0.07849, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:26.668, tt:1066.736\n",
      "Ep:40, loss:0.00009, loss_test:0.07809, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:26.691, tt:1094.319\n",
      "Ep:41, loss:0.00009, loss_test:0.07699, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:26.696, tt:1121.223\n",
      "Ep:42, loss:0.00009, loss_test:0.07682, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:26.708, tt:1148.433\n",
      "Ep:43, loss:0.00008, loss_test:0.07696, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:26.695, tt:1174.581\n",
      "Ep:44, loss:0.00008, loss_test:0.07602, lr:9.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:26.725, tt:1202.629\n",
      "Ep:45, loss:0.00008, loss_test:0.07577, lr:9.80e-03, fs:0.79532 (r=0.687,p=0.944),  time:26.714, tt:1228.861\n",
      "Ep:46, loss:0.00008, loss_test:0.07470, lr:9.70e-03, fs:0.78857 (r=0.697,p=0.908),  time:26.686, tt:1254.229\n",
      "Ep:47, loss:0.00008, loss_test:0.07540, lr:9.61e-03, fs:0.79070 (r=0.687,p=0.932),  time:26.690, tt:1281.123\n",
      "Ep:48, loss:0.00007, loss_test:0.07416, lr:9.51e-03, fs:0.79310 (r=0.697,p=0.920),  time:26.722, tt:1309.378\n",
      "Ep:49, loss:0.00007, loss_test:0.07405, lr:9.41e-03, fs:0.79769 (r=0.697,p=0.932),  time:26.718, tt:1335.921\n",
      "Ep:50, loss:0.00007, loss_test:0.07344, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.741, tt:1363.786\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.07272, lr:9.32e-03, fs:0.79769 (r=0.697,p=0.932),  time:26.731, tt:1390.006\n",
      "Ep:52, loss:0.00007, loss_test:0.07287, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.740, tt:1417.234\n",
      "Ep:53, loss:0.00007, loss_test:0.07239, lr:9.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:26.742, tt:1444.081\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07235, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.720, tt:1469.617\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.07150, lr:9.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:26.724, tt:1496.570\n",
      "Ep:56, loss:0.00006, loss_test:0.07239, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.705, tt:1522.190\n",
      "Ep:57, loss:0.00006, loss_test:0.07171, lr:9.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:26.705, tt:1548.881\n",
      "Ep:58, loss:0.00006, loss_test:0.07107, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.723, tt:1576.660\n",
      "Ep:59, loss:0.00006, loss_test:0.07170, lr:9.32e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.735, tt:1604.080\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00006, loss_test:0.07205, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.734, tt:1630.755\n",
      "Ep:61, loss:0.00006, loss_test:0.07045, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.783, tt:1660.566\n",
      "Ep:62, loss:0.00006, loss_test:0.07088, lr:9.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:26.801, tt:1688.455\n",
      "Ep:63, loss:0.00005, loss_test:0.06966, lr:9.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:26.814, tt:1716.122\n",
      "Ep:64, loss:0.00005, loss_test:0.07006, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.814, tt:1742.905\n",
      "Ep:65, loss:0.00005, loss_test:0.06974, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.798, tt:1768.700\n",
      "Ep:66, loss:0.00005, loss_test:0.06961, lr:9.32e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.815, tt:1796.616\n",
      "Ep:67, loss:0.00005, loss_test:0.06937, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.834, tt:1824.720\n",
      "Ep:68, loss:0.00005, loss_test:0.06857, lr:9.32e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.841, tt:1852.020\n",
      "Ep:69, loss:0.00005, loss_test:0.06930, lr:9.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:26.833, tt:1878.299\n",
      "Ep:70, loss:0.00005, loss_test:0.06783, lr:9.32e-03, fs:0.83146 (r=0.747,p=0.937),  time:26.815, tt:1903.858\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00005, loss_test:0.06908, lr:9.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:26.823, tt:1931.232\n",
      "Ep:72, loss:0.00005, loss_test:0.06657, lr:9.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:26.822, tt:1957.999\n",
      "Ep:73, loss:0.00004, loss_test:0.06845, lr:9.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:26.831, tt:1985.464\n",
      "Ep:74, loss:0.00004, loss_test:0.06867, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.828, tt:2012.071\n",
      "Ep:75, loss:0.00004, loss_test:0.06529, lr:9.32e-03, fs:0.83146 (r=0.747,p=0.937),  time:26.846, tt:2040.291\n",
      "Ep:76, loss:0.00004, loss_test:0.06846, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.844, tt:2067.011\n",
      "Ep:77, loss:0.00004, loss_test:0.06645, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:26.847, tt:2094.074\n",
      "Ep:78, loss:0.00004, loss_test:0.06592, lr:9.32e-03, fs:0.80925 (r=0.707,p=0.946),  time:26.846, tt:2120.820\n",
      "Ep:79, loss:0.00004, loss_test:0.06773, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.857, tt:2148.561\n",
      "Ep:80, loss:0.00004, loss_test:0.06624, lr:9.32e-03, fs:0.82682 (r=0.747,p=0.925),  time:26.836, tt:2173.704\n",
      "Ep:81, loss:0.00004, loss_test:0.06585, lr:9.32e-03, fs:0.80233 (r=0.697,p=0.945),  time:26.841, tt:2200.992\n",
      "Ep:82, loss:0.00004, loss_test:0.06663, lr:9.23e-03, fs:0.80702 (r=0.697,p=0.958),  time:26.837, tt:2227.499\n",
      "Ep:83, loss:0.00004, loss_test:0.06547, lr:9.14e-03, fs:0.82955 (r=0.737,p=0.948),  time:26.840, tt:2254.582\n",
      "Ep:84, loss:0.00004, loss_test:0.06616, lr:9.04e-03, fs:0.80925 (r=0.707,p=0.946),  time:26.843, tt:2281.685\n",
      "Ep:85, loss:0.00004, loss_test:0.06654, lr:8.95e-03, fs:0.81395 (r=0.707,p=0.959),  time:26.850, tt:2309.100\n",
      "Ep:86, loss:0.00004, loss_test:0.06443, lr:8.86e-03, fs:0.82486 (r=0.737,p=0.936),  time:26.865, tt:2337.241\n",
      "Ep:87, loss:0.00003, loss_test:0.06648, lr:8.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.868, tt:2364.352\n",
      "Ep:88, loss:0.00003, loss_test:0.06614, lr:8.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:26.876, tt:2391.939\n",
      "Ep:89, loss:0.00003, loss_test:0.06387, lr:8.60e-03, fs:0.82955 (r=0.737,p=0.948),  time:26.881, tt:2419.299\n",
      "Ep:90, loss:0.00003, loss_test:0.06663, lr:8.51e-03, fs:0.82955 (r=0.737,p=0.948),  time:26.893, tt:2447.234\n",
      "Ep:91, loss:0.00003, loss_test:0.06587, lr:8.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.899, tt:2474.681\n",
      "Ep:92, loss:0.00003, loss_test:0.06442, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.903, tt:2501.996\n",
      "Ep:93, loss:0.00003, loss_test:0.06661, lr:8.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.910, tt:2529.551\n",
      "Ep:94, loss:0.00003, loss_test:0.06456, lr:8.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.903, tt:2555.770\n",
      "Ep:95, loss:0.00003, loss_test:0.06468, lr:8.10e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.917, tt:2584.029\n",
      "Ep:96, loss:0.00003, loss_test:0.06589, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:26.931, tt:2612.284\n",
      "Ep:97, loss:0.00003, loss_test:0.06442, lr:7.94e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.931, tt:2639.228\n",
      "Ep:98, loss:0.00003, loss_test:0.06448, lr:7.86e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.934, tt:2666.479\n",
      "Ep:99, loss:0.00003, loss_test:0.06522, lr:7.78e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.933, tt:2693.342\n",
      "Ep:100, loss:0.00003, loss_test:0.06466, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.935, tt:2720.478\n",
      "Ep:101, loss:0.00003, loss_test:0.06411, lr:7.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.951, tt:2748.968\n",
      "Ep:102, loss:0.00003, loss_test:0.06451, lr:7.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.949, tt:2775.751\n",
      "Ep:103, loss:0.00003, loss_test:0.06399, lr:7.47e-03, fs:0.82955 (r=0.737,p=0.948),  time:26.944, tt:2802.218\n",
      "Ep:104, loss:0.00003, loss_test:0.06436, lr:7.40e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.946, tt:2829.377\n",
      "Ep:105, loss:0.00003, loss_test:0.06421, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.949, tt:2856.585\n",
      "Ep:106, loss:0.00003, loss_test:0.06444, lr:7.25e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.950, tt:2883.660\n",
      "Ep:107, loss:0.00003, loss_test:0.06364, lr:7.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.946, tt:2910.202\n",
      "Ep:108, loss:0.00003, loss_test:0.06429, lr:7.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.956, tt:2938.193\n",
      "Ep:109, loss:0.00002, loss_test:0.06478, lr:7.03e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.952, tt:2964.744\n",
      "Ep:110, loss:0.00002, loss_test:0.06299, lr:6.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.963, tt:2992.932\n",
      "Ep:111, loss:0.00002, loss_test:0.06442, lr:6.89e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.973, tt:3020.984\n",
      "Ep:112, loss:0.00002, loss_test:0.06402, lr:6.83e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.961, tt:3046.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:113, loss:0.00002, loss_test:0.06431, lr:6.76e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.964, tt:3073.847\n",
      "Ep:114, loss:0.00002, loss_test:0.06422, lr:6.69e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.964, tt:3100.834\n",
      "Ep:115, loss:0.00002, loss_test:0.06334, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:26.969, tt:3128.461\n",
      "Ep:116, loss:0.00002, loss_test:0.06444, lr:6.56e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.965, tt:3154.860\n",
      "Ep:117, loss:0.00002, loss_test:0.06420, lr:6.49e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.964, tt:3181.735\n",
      "Ep:118, loss:0.00002, loss_test:0.06357, lr:6.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:26.961, tt:3208.396\n",
      "Ep:119, loss:0.00002, loss_test:0.06457, lr:6.36e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.949, tt:3233.855\n",
      "Ep:120, loss:0.00002, loss_test:0.06385, lr:6.30e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.947, tt:3260.614\n",
      "Ep:121, loss:0.00002, loss_test:0.06373, lr:6.24e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.948, tt:3287.717\n",
      "Ep:122, loss:0.00002, loss_test:0.06422, lr:6.17e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.951, tt:3314.975\n",
      "Ep:123, loss:0.00002, loss_test:0.06420, lr:6.11e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.949, tt:3341.670\n",
      "Ep:124, loss:0.00002, loss_test:0.06363, lr:6.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.945, tt:3368.101\n",
      "Ep:125, loss:0.00002, loss_test:0.06457, lr:5.99e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.928, tt:3392.897\n",
      "Ep:126, loss:0.00002, loss_test:0.06461, lr:5.93e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.939, tt:3421.292\n",
      "Ep:127, loss:0.00002, loss_test:0.06342, lr:5.87e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.941, tt:3448.466\n",
      "Ep:128, loss:0.00002, loss_test:0.06485, lr:5.81e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.940, tt:3475.206\n",
      "Ep:129, loss:0.00002, loss_test:0.06412, lr:5.75e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.946, tt:3502.942\n",
      "Ep:130, loss:0.00002, loss_test:0.06357, lr:5.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.946, tt:3529.934\n",
      "Ep:131, loss:0.00002, loss_test:0.06453, lr:5.64e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.954, tt:3557.913\n",
      "Ep:132, loss:0.00002, loss_test:0.06408, lr:5.58e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.969, tt:3586.937\n",
      "Ep:133, loss:0.00002, loss_test:0.06430, lr:5.53e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.974, tt:3614.525\n",
      "Ep:134, loss:0.00002, loss_test:0.06429, lr:5.47e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.965, tt:3640.275\n",
      "Ep:135, loss:0.00002, loss_test:0.06364, lr:5.42e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.981, tt:3669.350\n",
      "Ep:136, loss:0.00002, loss_test:0.06403, lr:5.36e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.976, tt:3695.695\n",
      "Ep:137, loss:0.00002, loss_test:0.06424, lr:5.31e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.973, tt:3722.262\n",
      "Ep:138, loss:0.00002, loss_test:0.06388, lr:5.26e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.980, tt:3750.283\n",
      "Ep:139, loss:0.00002, loss_test:0.06422, lr:5.20e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.990, tt:3778.578\n",
      "Ep:140, loss:0.00002, loss_test:0.06382, lr:5.15e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.989, tt:3805.486\n",
      "Ep:141, loss:0.00002, loss_test:0.06359, lr:5.10e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.988, tt:3832.351\n",
      "Ep:142, loss:0.00002, loss_test:0.06422, lr:5.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.974, tt:3857.252\n",
      "Ep:143, loss:0.00002, loss_test:0.06416, lr:5.00e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.972, tt:3883.927\n",
      "Ep:144, loss:0.00002, loss_test:0.06396, lr:4.95e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.979, tt:3911.962\n",
      "Ep:145, loss:0.00002, loss_test:0.06379, lr:4.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.982, tt:3939.346\n",
      "Ep:146, loss:0.00002, loss_test:0.06440, lr:4.85e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.973, tt:3965.101\n",
      "Ep:147, loss:0.00002, loss_test:0.06406, lr:4.80e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.973, tt:3992.057\n",
      "Ep:148, loss:0.00002, loss_test:0.06401, lr:4.75e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.988, tt:4021.156\n",
      "Ep:149, loss:0.00002, loss_test:0.06381, lr:4.71e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.993, tt:4048.898\n",
      "Ep:150, loss:0.00002, loss_test:0.06435, lr:4.66e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.988, tt:4075.197\n",
      "Ep:151, loss:0.00002, loss_test:0.06419, lr:4.61e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.989, tt:4102.347\n",
      "Ep:152, loss:0.00002, loss_test:0.06357, lr:4.57e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.981, tt:4128.073\n",
      "Ep:153, loss:0.00002, loss_test:0.06422, lr:4.52e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.981, tt:4155.004\n",
      "Ep:154, loss:0.00002, loss_test:0.06427, lr:4.48e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.972, tt:4180.736\n",
      "Ep:155, loss:0.00002, loss_test:0.06333, lr:4.43e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.966, tt:4206.729\n",
      "Ep:156, loss:0.00002, loss_test:0.06410, lr:4.39e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.974, tt:4234.873\n",
      "Ep:157, loss:0.00002, loss_test:0.06410, lr:4.34e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.972, tt:4261.500\n",
      "Ep:158, loss:0.00002, loss_test:0.06397, lr:4.30e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.979, tt:4289.610\n",
      "Ep:159, loss:0.00002, loss_test:0.06470, lr:4.26e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.985, tt:4317.600\n",
      "Ep:160, loss:0.00001, loss_test:0.06340, lr:4.21e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.982, tt:4344.131\n",
      "Ep:161, loss:0.00001, loss_test:0.06421, lr:4.17e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.980, tt:4370.742\n",
      "Ep:162, loss:0.00001, loss_test:0.06405, lr:4.13e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.982, tt:4398.078\n",
      "Ep:163, loss:0.00001, loss_test:0.06377, lr:4.09e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.984, tt:4425.345\n",
      "Ep:164, loss:0.00001, loss_test:0.06444, lr:4.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.989, tt:4453.104\n",
      "Ep:165, loss:0.00001, loss_test:0.06389, lr:4.01e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.995, tt:4481.142\n",
      "Ep:166, loss:0.00001, loss_test:0.06376, lr:3.97e-03, fs:0.82081 (r=0.717,p=0.959),  time:26.996, tt:4508.269\n",
      "Ep:167, loss:0.00001, loss_test:0.06466, lr:3.93e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.002, tt:4536.392\n",
      "Ep:168, loss:0.00001, loss_test:0.06399, lr:3.89e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.006, tt:4564.042\n",
      "Ep:169, loss:0.00001, loss_test:0.06367, lr:3.85e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.016, tt:4592.722\n",
      "Ep:170, loss:0.00001, loss_test:0.06456, lr:3.81e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.024, tt:4621.073\n",
      "Ep:171, loss:0.00001, loss_test:0.06394, lr:3.77e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.025, tt:4648.240\n",
      "Ep:172, loss:0.00001, loss_test:0.06411, lr:3.73e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.029, tt:4675.959\n",
      "Ep:173, loss:0.00001, loss_test:0.06440, lr:3.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.035, tt:4704.010\n",
      "Ep:174, loss:0.00001, loss_test:0.06364, lr:3.66e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.037, tt:4731.416\n",
      "Ep:175, loss:0.00001, loss_test:0.06410, lr:3.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.043, tt:4759.512\n",
      "Ep:176, loss:0.00001, loss_test:0.06523, lr:3.59e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.047, tt:4787.331\n",
      "Ep:177, loss:0.00001, loss_test:0.06435, lr:3.55e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.045, tt:4813.929\n",
      "Ep:178, loss:0.00001, loss_test:0.06370, lr:3.52e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.047, tt:4841.432\n",
      "Ep:179, loss:0.00001, loss_test:0.06467, lr:3.48e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.046, tt:4868.359\n",
      "Ep:180, loss:0.00001, loss_test:0.06441, lr:3.45e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.047, tt:4895.590\n",
      "Ep:181, loss:0.00001, loss_test:0.06372, lr:3.41e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.054, tt:4923.745\n",
      "Ep:182, loss:0.00001, loss_test:0.06433, lr:3.38e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.060, tt:4951.912\n",
      "Ep:183, loss:0.00001, loss_test:0.06471, lr:3.34e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.075, tt:4981.827\n",
      "Ep:184, loss:0.00001, loss_test:0.06408, lr:3.31e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.078, tt:5009.445\n",
      "Ep:185, loss:0.00001, loss_test:0.06394, lr:3.28e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.070, tt:5034.944\n",
      "Ep:186, loss:0.00001, loss_test:0.06447, lr:3.24e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.062, tt:5060.503\n",
      "Ep:187, loss:0.00001, loss_test:0.06417, lr:3.21e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.053, tt:5085.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:188, loss:0.00001, loss_test:0.06414, lr:3.18e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.053, tt:5112.926\n",
      "Ep:189, loss:0.00001, loss_test:0.06445, lr:3.15e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.058, tt:5140.952\n",
      "Ep:190, loss:0.00001, loss_test:0.06386, lr:3.12e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.062, tt:5168.816\n",
      "Ep:191, loss:0.00001, loss_test:0.06411, lr:3.09e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.066, tt:5196.726\n",
      "Ep:192, loss:0.00001, loss_test:0.06445, lr:3.05e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.076, tt:5225.610\n",
      "Ep:193, loss:0.00001, loss_test:0.06401, lr:3.02e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.080, tt:5253.441\n",
      "Ep:194, loss:0.00001, loss_test:0.06416, lr:2.99e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.072, tt:5279.025\n",
      "Ep:195, loss:0.00001, loss_test:0.06427, lr:2.96e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.075, tt:5306.656\n",
      "Ep:196, loss:0.00001, loss_test:0.06423, lr:2.93e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.078, tt:5334.316\n",
      "Ep:197, loss:0.00001, loss_test:0.06428, lr:2.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.075, tt:5360.938\n",
      "Ep:198, loss:0.00001, loss_test:0.06428, lr:2.88e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.078, tt:5388.493\n",
      "Ep:199, loss:0.00001, loss_test:0.06403, lr:2.85e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.069, tt:5413.839\n",
      "Ep:200, loss:0.00001, loss_test:0.06397, lr:2.82e-03, fs:0.82081 (r=0.717,p=0.959),  time:27.071, tt:5441.291\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02156, lr:6.00e-02, fs:0.66426 (r=0.929,p=0.517),  time:31.336, tt:31.336\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02679, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.345, tt:60.691\n",
      "Ep:2, loss:0.00005, loss_test:0.02954, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.523, tt:91.570\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00006, loss_test:0.03039, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.365, tt:121.459\n",
      "Ep:4, loss:0.00006, loss_test:0.03004, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.434, tt:147.170\n",
      "Ep:5, loss:0.00006, loss_test:0.02898, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.478, tt:176.865\n",
      "Ep:6, loss:0.00006, loss_test:0.02725, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.555, tt:206.889\n",
      "Ep:7, loss:0.00005, loss_test:0.02518, lr:6.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:29.946, tt:239.568\n",
      "Ep:8, loss:0.00005, loss_test:0.02325, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:30.306, tt:272.755\n",
      "Ep:9, loss:0.00005, loss_test:0.02217, lr:6.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:30.545, tt:305.454\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:30.715, tt:337.867\n",
      "Ep:11, loss:0.00004, loss_test:0.02144, lr:6.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:31.062, tt:372.742\n",
      "Ep:12, loss:0.00004, loss_test:0.02132, lr:6.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:31.437, tt:408.686\n",
      "Ep:13, loss:0.00004, loss_test:0.02140, lr:6.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:31.653, tt:443.137\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02115, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:31.735, tt:476.022\n",
      "Ep:15, loss:0.00004, loss_test:0.02085, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:31.958, tt:511.327\n",
      "Ep:16, loss:0.00004, loss_test:0.02073, lr:6.00e-02, fs:0.65587 (r=0.818,p=0.547),  time:32.103, tt:545.747\n",
      "Ep:17, loss:0.00004, loss_test:0.02058, lr:6.00e-02, fs:0.66393 (r=0.818,p=0.559),  time:32.302, tt:581.441\n",
      "Ep:18, loss:0.00004, loss_test:0.02036, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:32.390, tt:615.402\n",
      "Ep:19, loss:0.00004, loss_test:0.02017, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:32.492, tt:649.844\n",
      "Ep:20, loss:0.00004, loss_test:0.01989, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:32.640, tt:685.444\n",
      "Ep:21, loss:0.00003, loss_test:0.01968, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:32.793, tt:721.438\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01944, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:32.880, tt:756.236\n",
      "Ep:23, loss:0.00003, loss_test:0.01928, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:32.965, tt:791.165\n",
      "Ep:24, loss:0.00003, loss_test:0.01913, lr:6.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:33.060, tt:826.512\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01893, lr:6.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:33.100, tt:860.590\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01863, lr:6.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:33.146, tt:894.941\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01837, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:33.179, tt:928.999\n",
      "Ep:28, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:33.137, tt:960.962\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01804, lr:6.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:33.150, tt:994.491\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01784, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:33.157, tt:1027.854\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01762, lr:6.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:33.204, tt:1062.514\n",
      "Ep:32, loss:0.00003, loss_test:0.01745, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:33.186, tt:1095.145\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01727, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:33.177, tt:1128.005\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01709, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:33.246, tt:1163.616\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01695, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:33.246, tt:1196.853\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:33.250, tt:1230.241\n",
      "Ep:37, loss:0.00002, loss_test:0.01659, lr:6.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:33.322, tt:1266.244\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01660, lr:6.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:33.329, tt:1299.838\n",
      "Ep:39, loss:0.00002, loss_test:0.01656, lr:6.00e-02, fs:0.74766 (r=0.808,p=0.696),  time:33.370, tt:1334.801\n",
      "Ep:40, loss:0.00002, loss_test:0.01642, lr:6.00e-02, fs:0.75472 (r=0.808,p=0.708),  time:33.399, tt:1369.361\n",
      "Ep:41, loss:0.00002, loss_test:0.01632, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:33.426, tt:1403.899\n",
      "Ep:42, loss:0.00002, loss_test:0.01628, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.451, tt:1438.393\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01617, lr:6.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:33.486, tt:1473.400\n",
      "Ep:44, loss:0.00002, loss_test:0.01619, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.505, tt:1507.740\n",
      "Ep:45, loss:0.00002, loss_test:0.01624, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.507, tt:1541.327\n",
      "Ep:46, loss:0.00002, loss_test:0.01617, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.531, tt:1575.947\n",
      "Ep:47, loss:0.00002, loss_test:0.01628, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.558, tt:1610.803\n",
      "Ep:48, loss:0.00002, loss_test:0.01625, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:33.577, tt:1645.270\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00002, loss_test:0.01624, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:33.599, tt:1679.934\n",
      "Ep:50, loss:0.00002, loss_test:0.01609, lr:6.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:33.598, tt:1713.492\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01628, lr:6.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:33.609, tt:1747.664\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01607, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:33.606, tt:1781.119\n",
      "Ep:53, loss:0.00002, loss_test:0.01611, lr:6.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:33.587, tt:1813.675\n",
      "Ep:54, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:33.578, tt:1846.799\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01631, lr:6.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:33.578, tt:1880.344\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01623, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:33.576, tt:1913.851\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01626, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:33.593, tt:1948.403\n",
      "Ep:58, loss:0.00001, loss_test:0.01618, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:33.614, tt:1983.198\n",
      "Ep:59, loss:0.00001, loss_test:0.01642, lr:6.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:33.651, tt:2019.079\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01651, lr:6.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:33.673, tt:2054.023\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01636, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:33.669, tt:2087.509\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:33.656, tt:2120.353\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01659, lr:6.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:33.679, tt:2155.481\n",
      "Ep:64, loss:0.00001, loss_test:0.01700, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:33.687, tt:2189.655\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01672, lr:6.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:33.691, tt:2223.622\n",
      "Ep:66, loss:0.00001, loss_test:0.01727, lr:6.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:33.719, tt:2259.190\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01725, lr:6.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:33.723, tt:2293.141\n",
      "Ep:68, loss:0.00001, loss_test:0.01760, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.730, tt:2327.380\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01743, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.746, tt:2362.246\n",
      "Ep:70, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:33.780, tt:2398.385\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01802, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:33.787, tt:2432.676\n",
      "Ep:72, loss:0.00001, loss_test:0.01817, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:33.803, tt:2467.638\n",
      "Ep:73, loss:0.00001, loss_test:0.01837, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:33.809, tt:2501.878\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01860, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:33.807, tt:2535.510\n",
      "Ep:75, loss:0.00001, loss_test:0.01899, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:33.832, tt:2571.241\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01907, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:33.850, tt:2606.416\n",
      "Ep:77, loss:0.00001, loss_test:0.01958, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:33.886, tt:2643.139\n",
      "Ep:78, loss:0.00001, loss_test:0.01943, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:33.904, tt:2678.441\n",
      "Ep:79, loss:0.00001, loss_test:0.01998, lr:6.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:33.930, tt:2714.420\n",
      "Ep:80, loss:0.00001, loss_test:0.02008, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:33.953, tt:2750.169\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.02010, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:33.981, tt:2786.473\n",
      "Ep:82, loss:0.00001, loss_test:0.02102, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.012, tt:2822.969\n",
      "Ep:83, loss:0.00001, loss_test:0.02039, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.039, tt:2859.252\n",
      "Ep:84, loss:0.00001, loss_test:0.02172, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.067, tt:2895.707\n",
      "Ep:85, loss:0.00001, loss_test:0.02066, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.074, tt:2930.363\n",
      "Ep:86, loss:0.00001, loss_test:0.02228, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.083, tt:2965.239\n",
      "Ep:87, loss:0.00001, loss_test:0.02125, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.109, tt:3001.625\n",
      "Ep:88, loss:0.00001, loss_test:0.02294, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.129, tt:3037.510\n",
      "Ep:89, loss:0.00001, loss_test:0.02160, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.158, tt:3074.236\n",
      "Ep:90, loss:0.00001, loss_test:0.02328, lr:6.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.174, tt:3109.826\n",
      "Ep:91, loss:0.00001, loss_test:0.02310, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.195, tt:3145.960\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.02364, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.214, tt:3181.914\n",
      "Ep:93, loss:0.00001, loss_test:0.02393, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.231, tt:3217.692\n",
      "Ep:94, loss:0.00001, loss_test:0.02365, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.257, tt:3254.435\n",
      "Ep:95, loss:0.00001, loss_test:0.02440, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.261, tt:3289.022\n",
      "Ep:96, loss:0.00001, loss_test:0.02405, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.272, tt:3324.393\n",
      "Ep:97, loss:0.00001, loss_test:0.02504, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.280, tt:3359.443\n",
      "Ep:98, loss:0.00001, loss_test:0.02495, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.282, tt:3393.894\n",
      "Ep:99, loss:0.00001, loss_test:0.02510, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.292, tt:3429.207\n",
      "Ep:100, loss:0.00001, loss_test:0.02613, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.297, tt:3464.026\n",
      "Ep:101, loss:0.00001, loss_test:0.02504, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.322, tt:3500.838\n",
      "Ep:102, loss:0.00001, loss_test:0.02605, lr:6.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.333, tt:3536.345\n",
      "Ep:103, loss:0.00001, loss_test:0.02591, lr:5.94e-02, fs:0.86154 (r=0.848,p=0.875),  time:34.348, tt:3572.167\n",
      "Ep:104, loss:0.00001, loss_test:0.02672, lr:5.88e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.357, tt:3607.503\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.02693, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.368, tt:3643.011\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00000, loss_test:0.02688, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.379, tt:3678.541\n",
      "Ep:107, loss:0.00000, loss_test:0.02727, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.401, tt:3715.315\n",
      "Ep:108, loss:0.00000, loss_test:0.02727, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.422, tt:3751.953\n",
      "Ep:109, loss:0.00000, loss_test:0.02804, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.446, tt:3789.009\n",
      "Ep:110, loss:0.00000, loss_test:0.02817, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.459, tt:3825.004\n",
      "Ep:111, loss:0.00000, loss_test:0.02836, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.505, tt:3864.594\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.02882, lr:5.88e-02, fs:0.87368 (r=0.838,p=0.912),  time:34.519, tt:3900.635\n",
      "Ep:113, loss:0.00000, loss_test:0.02830, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.508, tt:3933.938\n",
      "Ep:114, loss:0.00000, loss_test:0.02904, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.525, tt:3970.345\n",
      "Ep:115, loss:0.00000, loss_test:0.02918, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.523, tt:4004.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00000, loss_test:0.02906, lr:5.88e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.520, tt:4038.895\n",
      "Ep:117, loss:0.00000, loss_test:0.02951, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.515, tt:4072.804\n",
      "Ep:118, loss:0.00000, loss_test:0.02971, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.524, tt:4108.340\n",
      "Ep:119, loss:0.00000, loss_test:0.02981, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.520, tt:4142.442\n",
      "Ep:120, loss:0.00000, loss_test:0.03020, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.509, tt:4175.632\n",
      "Ep:121, loss:0.00000, loss_test:0.02994, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.507, tt:4209.900\n",
      "Ep:122, loss:0.00000, loss_test:0.03089, lr:5.88e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.523, tt:4246.339\n",
      "Ep:123, loss:0.00000, loss_test:0.03084, lr:5.82e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.527, tt:4281.363\n",
      "Ep:124, loss:0.00000, loss_test:0.03070, lr:5.76e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.534, tt:4316.798\n",
      "Ep:125, loss:0.00000, loss_test:0.03100, lr:5.71e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.559, tt:4354.461\n",
      "Ep:126, loss:0.00000, loss_test:0.03141, lr:5.65e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.562, tt:4389.428\n",
      "Ep:127, loss:0.00000, loss_test:0.03133, lr:5.59e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.566, tt:4424.432\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.03154, lr:5.59e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.579, tt:4460.752\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00000, loss_test:0.03170, lr:5.59e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.590, tt:4496.637\n",
      "Ep:130, loss:0.00000, loss_test:0.03186, lr:5.59e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.589, tt:4531.108\n",
      "Ep:131, loss:0.00000, loss_test:0.03210, lr:5.59e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.596, tt:4566.639\n",
      "Ep:132, loss:0.00000, loss_test:0.03249, lr:5.59e-02, fs:0.88889 (r=0.848,p=0.933),  time:34.597, tt:4601.398\n",
      "Ep:133, loss:0.00000, loss_test:0.03205, lr:5.59e-02, fs:0.88421 (r=0.848,p=0.923),  time:34.597, tt:4636.033\n",
      "Ep:134, loss:0.00000, loss_test:0.03235, lr:5.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.611, tt:4672.548\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00000, loss_test:0.03236, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.658, tt:4713.464\n",
      "Ep:136, loss:0.00000, loss_test:0.03246, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.670, tt:4749.831\n",
      "Ep:137, loss:0.00000, loss_test:0.03261, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.686, tt:4786.636\n",
      "Ep:138, loss:0.00000, loss_test:0.03338, lr:5.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.703, tt:4823.647\n",
      "Ep:139, loss:0.00000, loss_test:0.03263, lr:5.59e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.718, tt:4860.454\n",
      "Ep:140, loss:0.00000, loss_test:0.03352, lr:5.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.733, tt:4897.321\n",
      "Ep:141, loss:0.00000, loss_test:0.03347, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.720, tt:4930.218\n",
      "Ep:142, loss:0.00000, loss_test:0.03361, lr:5.59e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.733, tt:4966.780\n",
      "Ep:143, loss:0.00000, loss_test:0.03353, lr:5.59e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.743, tt:5003.040\n",
      "Ep:144, loss:0.00000, loss_test:0.03394, lr:5.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.758, tt:5039.966\n",
      "Ep:145, loss:0.00000, loss_test:0.03396, lr:5.59e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.779, tt:5077.721\n",
      "Ep:146, loss:0.00000, loss_test:0.03425, lr:5.54e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.793, tt:5114.545\n",
      "Ep:147, loss:0.00000, loss_test:0.03431, lr:5.48e-02, fs:0.89840 (r=0.848,p=0.955),  time:34.807, tt:5151.371\n",
      "Ep:148, loss:0.00000, loss_test:0.03429, lr:5.43e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.813, tt:5187.101\n",
      "Ep:149, loss:0.00000, loss_test:0.03437, lr:5.37e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.820, tt:5223.043\n",
      "Ep:150, loss:0.00000, loss_test:0.03486, lr:5.32e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.830, tt:5259.311\n",
      "Ep:151, loss:0.00000, loss_test:0.03461, lr:5.27e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.831, tt:5294.303\n",
      "Ep:152, loss:0.00000, loss_test:0.03448, lr:5.21e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.838, tt:5330.165\n",
      "Ep:153, loss:0.00000, loss_test:0.03474, lr:5.16e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.838, tt:5365.026\n",
      "Ep:154, loss:0.00000, loss_test:0.03502, lr:5.11e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.838, tt:5399.946\n",
      "Ep:155, loss:0.00000, loss_test:0.03528, lr:5.06e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.846, tt:5436.014\n",
      "Ep:156, loss:0.00000, loss_test:0.03529, lr:5.01e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.854, tt:5472.155\n",
      "Ep:157, loss:0.00000, loss_test:0.03538, lr:4.96e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.864, tt:5508.475\n",
      "Ep:158, loss:0.00000, loss_test:0.03537, lr:4.91e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.866, tt:5543.753\n",
      "Ep:159, loss:0.00000, loss_test:0.03558, lr:4.86e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.869, tt:5579.062\n",
      "Ep:160, loss:0.00000, loss_test:0.03565, lr:4.81e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.866, tt:5613.360\n",
      "Ep:161, loss:0.00000, loss_test:0.03588, lr:4.76e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.859, tt:5647.176\n",
      "Ep:162, loss:0.00000, loss_test:0.03601, lr:4.71e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.861, tt:5682.361\n",
      "Ep:163, loss:0.00000, loss_test:0.03602, lr:4.67e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.858, tt:5716.688\n",
      "Ep:164, loss:0.00000, loss_test:0.03620, lr:4.62e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.875, tt:5754.318\n",
      "Ep:165, loss:0.00000, loss_test:0.03625, lr:4.57e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.876, tt:5789.467\n",
      "Ep:166, loss:0.00000, loss_test:0.03631, lr:4.53e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.884, tt:5825.599\n",
      "Ep:167, loss:0.00000, loss_test:0.03651, lr:4.48e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.895, tt:5862.361\n",
      "Ep:168, loss:0.00000, loss_test:0.03643, lr:4.44e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.890, tt:5896.366\n",
      "Ep:169, loss:0.00000, loss_test:0.03669, lr:4.39e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.895, tt:5932.148\n",
      "Ep:170, loss:0.00000, loss_test:0.03662, lr:4.35e-02, fs:0.87432 (r=0.808,p=0.952),  time:34.901, tt:5967.999\n",
      "Ep:171, loss:0.00000, loss_test:0.03689, lr:4.31e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.901, tt:6002.898\n",
      "Ep:172, loss:0.00000, loss_test:0.03674, lr:4.26e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.905, tt:6038.641\n",
      "Ep:173, loss:0.00000, loss_test:0.03690, lr:4.22e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.913, tt:6074.940\n",
      "Ep:174, loss:0.00000, loss_test:0.03692, lr:4.18e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.918, tt:6110.572\n",
      "Ep:175, loss:0.00000, loss_test:0.03706, lr:4.14e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.918, tt:6145.539\n",
      "Ep:176, loss:0.00000, loss_test:0.03718, lr:4.10e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.923, tt:6181.342\n",
      "Ep:177, loss:0.00000, loss_test:0.03715, lr:4.05e-02, fs:0.86188 (r=0.788,p=0.951),  time:34.920, tt:6215.811\n",
      "Ep:178, loss:0.00000, loss_test:0.03731, lr:4.01e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.918, tt:6250.235\n",
      "Ep:179, loss:0.00000, loss_test:0.03721, lr:3.97e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.916, tt:6284.833\n",
      "Ep:180, loss:0.00000, loss_test:0.03732, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.922, tt:6320.933\n",
      "Ep:181, loss:0.00000, loss_test:0.03733, lr:3.89e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.915, tt:6354.444\n",
      "Ep:182, loss:0.00000, loss_test:0.03739, lr:3.86e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.921, tt:6390.494\n",
      "Ep:183, loss:0.00000, loss_test:0.03746, lr:3.82e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.927, tt:6426.646\n",
      "Ep:184, loss:0.00000, loss_test:0.03756, lr:3.78e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.936, tt:6463.134\n",
      "Ep:185, loss:0.00000, loss_test:0.03765, lr:3.74e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.935, tt:6497.878\n",
      "Ep:186, loss:0.00000, loss_test:0.03764, lr:3.70e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.934, tt:6532.574\n",
      "Ep:187, loss:0.00000, loss_test:0.03765, lr:3.67e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.932, tt:6567.178\n",
      "Ep:188, loss:0.00000, loss_test:0.03765, lr:3.63e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.950, tt:6605.520\n",
      "Ep:189, loss:0.00000, loss_test:0.03786, lr:3.59e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.944, tt:6639.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:190, loss:0.00000, loss_test:0.03788, lr:3.56e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.934, tt:6672.471\n",
      "Ep:191, loss:0.00000, loss_test:0.03789, lr:3.52e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.936, tt:6707.696\n",
      "Ep:192, loss:0.00000, loss_test:0.03784, lr:3.49e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.930, tt:6741.526\n",
      "Ep:193, loss:0.00000, loss_test:0.03795, lr:3.45e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.922, tt:6774.962\n",
      "Ep:194, loss:0.00000, loss_test:0.03800, lr:3.42e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.917, tt:6808.805\n",
      "Ep:195, loss:0.00000, loss_test:0.03805, lr:3.38e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.928, tt:6845.813\n",
      "Ep:196, loss:0.00000, loss_test:0.03813, lr:3.35e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.929, tt:6881.109\n",
      "Ep:197, loss:0.00000, loss_test:0.03829, lr:3.32e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.935, tt:6917.179\n",
      "Ep:198, loss:0.00000, loss_test:0.03821, lr:3.28e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.935, tt:6952.002\n",
      "Ep:199, loss:0.00000, loss_test:0.03821, lr:3.25e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.945, tt:6989.020\n",
      "Ep:200, loss:0.00000, loss_test:0.03832, lr:3.22e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.951, tt:7025.127\n",
      "Ep:201, loss:0.00000, loss_test:0.03833, lr:3.19e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.959, tt:7061.690\n",
      "Ep:202, loss:0.00000, loss_test:0.03841, lr:3.15e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.970, tt:7098.822\n",
      "Ep:203, loss:0.00000, loss_test:0.03840, lr:3.12e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.976, tt:7135.083\n",
      "Ep:204, loss:0.00000, loss_test:0.03853, lr:3.09e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.978, tt:7170.438\n",
      "Ep:205, loss:0.00000, loss_test:0.03862, lr:3.06e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.983, tt:7206.573\n",
      "Ep:206, loss:0.00000, loss_test:0.03853, lr:3.03e-02, fs:0.85556 (r=0.778,p=0.951),  time:34.993, tt:7243.596\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13799, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:34.487, tt:34.487\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13543, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:33.261, tt:66.521\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13152, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:32.713, tt:98.138\n",
      "Ep:3, loss:0.00026, loss_test:0.12700, lr:1.00e-02, fs:0.66667 (r=0.879,p=0.537),  time:32.628, tt:130.513\n",
      "Ep:4, loss:0.00025, loss_test:0.12413, lr:1.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:32.906, tt:164.528\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12305, lr:1.00e-02, fs:0.67480 (r=0.838,p=0.565),  time:33.093, tt:198.560\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12195, lr:1.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:32.737, tt:229.161\n",
      "Ep:7, loss:0.00023, loss_test:0.11976, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:32.862, tt:262.896\n",
      "Ep:8, loss:0.00023, loss_test:0.11785, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:32.886, tt:295.975\n",
      "Ep:9, loss:0.00022, loss_test:0.11667, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:33.008, tt:330.083\n",
      "Ep:10, loss:0.00021, loss_test:0.11507, lr:1.00e-02, fs:0.68142 (r=0.778,p=0.606),  time:33.170, tt:364.870\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.11348, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:33.424, tt:401.084\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.11215, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:33.636, tt:437.265\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.11042, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:33.855, tt:473.968\n",
      "Ep:14, loss:0.00019, loss_test:0.10838, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:33.960, tt:509.395\n",
      "Ep:15, loss:0.00018, loss_test:0.10628, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:34.112, tt:545.786\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10421, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:34.281, tt:582.780\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.10244, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:34.405, tt:619.288\n",
      "Ep:18, loss:0.00017, loss_test:0.10054, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:34.471, tt:654.948\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09875, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:34.561, tt:691.225\n",
      "Ep:20, loss:0.00016, loss_test:0.09775, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:34.694, tt:728.565\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09646, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:34.712, tt:763.668\n",
      "Ep:22, loss:0.00015, loss_test:0.09561, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:34.735, tt:798.912\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09432, lr:1.00e-02, fs:0.70647 (r=0.717,p=0.696),  time:34.804, tt:835.301\n",
      "Ep:24, loss:0.00014, loss_test:0.09308, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:34.757, tt:868.919\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09251, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:34.795, tt:904.663\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09139, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:34.770, tt:938.796\n",
      "Ep:27, loss:0.00013, loss_test:0.09000, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:34.861, tt:976.095\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08975, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:34.886, tt:1011.702\n",
      "Ep:29, loss:0.00012, loss_test:0.08867, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:34.976, tt:1049.277\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08822, lr:1.00e-02, fs:0.76382 (r=0.768,p=0.760),  time:34.891, tt:1081.607\n",
      "Ep:31, loss:0.00012, loss_test:0.08726, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.886, tt:1116.363\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08669, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:34.939, tt:1152.994\n",
      "Ep:33, loss:0.00011, loss_test:0.08531, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:35.034, tt:1191.146\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08511, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:35.061, tt:1227.148\n",
      "Ep:35, loss:0.00010, loss_test:0.08433, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:35.074, tt:1262.675\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08371, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.152, tt:1300.624\n",
      "Ep:37, loss:0.00010, loss_test:0.08202, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:35.149, tt:1335.649\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08219, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.157, tt:1371.112\n",
      "Ep:39, loss:0.00009, loss_test:0.08003, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.152, tt:1406.079\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.08292, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:35.170, tt:1441.979\n",
      "Ep:41, loss:0.00009, loss_test:0.07930, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:35.187, tt:1477.866\n",
      "Ep:42, loss:0.00008, loss_test:0.08145, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:35.218, tt:1514.353\n",
      "Ep:43, loss:0.00008, loss_test:0.07910, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.297, tt:1553.055\n",
      "Ep:44, loss:0.00008, loss_test:0.07961, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:35.320, tt:1589.404\n",
      "Ep:45, loss:0.00008, loss_test:0.07880, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.341, tt:1625.683\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00007, loss_test:0.08043, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.374, tt:1662.595\n",
      "Ep:47, loss:0.00007, loss_test:0.07781, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:35.398, tt:1699.118\n",
      "Ep:48, loss:0.00007, loss_test:0.07748, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:35.434, tt:1736.259\n",
      "Ep:49, loss:0.00007, loss_test:0.07692, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.464, tt:1773.210\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00007, loss_test:0.07588, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:35.464, tt:1808.663\n",
      "Ep:51, loss:0.00006, loss_test:0.07479, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.500, tt:1845.979\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.07667, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:35.532, tt:1883.196\n",
      "Ep:53, loss:0.00006, loss_test:0.07565, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.558, tt:1920.127\n",
      "Ep:54, loss:0.00006, loss_test:0.07463, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:35.584, tt:1957.104\n",
      "Ep:55, loss:0.00006, loss_test:0.07848, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:35.599, tt:1993.560\n",
      "Ep:56, loss:0.00006, loss_test:0.07541, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:35.624, tt:2030.593\n",
      "Ep:57, loss:0.00006, loss_test:0.07645, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:35.620, tt:2065.984\n",
      "Ep:58, loss:0.00005, loss_test:0.07461, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:35.613, tt:2101.138\n",
      "Ep:59, loss:0.00005, loss_test:0.07703, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.607, tt:2136.392\n",
      "Ep:60, loss:0.00005, loss_test:0.07370, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.645, tt:2174.362\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.07701, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.645, tt:2209.984\n",
      "Ep:62, loss:0.00005, loss_test:0.07624, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.664, tt:2246.864\n",
      "Ep:63, loss:0.00005, loss_test:0.07446, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.684, tt:2283.761\n",
      "Ep:64, loss:0.00005, loss_test:0.07716, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:35.709, tt:2321.116\n",
      "Ep:65, loss:0.00005, loss_test:0.07435, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.754, tt:2359.795\n",
      "Ep:66, loss:0.00004, loss_test:0.07666, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.767, tt:2396.393\n",
      "Ep:67, loss:0.00004, loss_test:0.07789, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.774, tt:2432.652\n",
      "Ep:68, loss:0.00004, loss_test:0.07593, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.778, tt:2468.681\n",
      "Ep:69, loss:0.00004, loss_test:0.07910, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:35.796, tt:2505.750\n",
      "Ep:70, loss:0.00004, loss_test:0.07595, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.789, tt:2541.049\n",
      "Ep:71, loss:0.00004, loss_test:0.07840, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.780, tt:2576.139\n",
      "Ep:72, loss:0.00004, loss_test:0.07639, lr:9.90e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.777, tt:2611.714\n",
      "Ep:73, loss:0.00004, loss_test:0.07688, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.793, tt:2648.665\n",
      "Ep:74, loss:0.00004, loss_test:0.07842, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.811, tt:2685.796\n",
      "Ep:75, loss:0.00003, loss_test:0.07643, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.820, tt:2722.344\n",
      "Ep:76, loss:0.00003, loss_test:0.07854, lr:9.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.820, tt:2758.108\n",
      "Ep:77, loss:0.00003, loss_test:0.07623, lr:9.41e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.833, tt:2794.995\n",
      "Ep:78, loss:0.00003, loss_test:0.07996, lr:9.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.843, tt:2831.562\n",
      "Ep:79, loss:0.00003, loss_test:0.08038, lr:9.23e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.842, tt:2867.334\n",
      "Ep:80, loss:0.00003, loss_test:0.07952, lr:9.14e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.862, tt:2904.801\n",
      "Ep:81, loss:0.00003, loss_test:0.08191, lr:9.04e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.893, tt:2943.196\n",
      "Ep:82, loss:0.00003, loss_test:0.08026, lr:8.95e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.902, tt:2979.836\n",
      "Ep:83, loss:0.00003, loss_test:0.08000, lr:8.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.924, tt:3017.586\n",
      "Ep:84, loss:0.00003, loss_test:0.08074, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.922, tt:3053.362\n",
      "Ep:85, loss:0.00003, loss_test:0.07785, lr:8.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.925, tt:3089.517\n",
      "Ep:86, loss:0.00003, loss_test:0.07911, lr:8.60e-03, fs:0.84153 (r=0.778,p=0.917),  time:35.924, tt:3125.364\n",
      "Ep:87, loss:0.00003, loss_test:0.08081, lr:8.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.942, tt:3162.899\n",
      "Ep:88, loss:0.00002, loss_test:0.07858, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.957, tt:3200.134\n",
      "Ep:89, loss:0.00002, loss_test:0.08088, lr:8.35e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.956, tt:3236.053\n",
      "Ep:90, loss:0.00002, loss_test:0.08261, lr:8.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:35.972, tt:3273.437\n",
      "Ep:91, loss:0.00002, loss_test:0.07901, lr:8.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.969, tt:3309.119\n",
      "Ep:92, loss:0.00002, loss_test:0.08195, lr:8.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.955, tt:3343.838\n",
      "Ep:93, loss:0.00002, loss_test:0.08044, lr:8.02e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.958, tt:3380.005\n",
      "Ep:94, loss:0.00002, loss_test:0.07957, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.964, tt:3416.555\n",
      "Ep:95, loss:0.00002, loss_test:0.08032, lr:7.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:35.992, tt:3455.236\n",
      "Ep:96, loss:0.00002, loss_test:0.08401, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:35.998, tt:3491.809\n",
      "Ep:97, loss:0.00002, loss_test:0.07682, lr:7.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.026, tt:3530.521\n",
      "Ep:98, loss:0.00002, loss_test:0.08147, lr:7.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.019, tt:3565.863\n",
      "Ep:99, loss:0.00002, loss_test:0.07985, lr:7.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.035, tt:3603.524\n",
      "Ep:100, loss:0.00002, loss_test:0.07886, lr:7.47e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.045, tt:3640.514\n",
      "Ep:101, loss:0.00002, loss_test:0.07986, lr:7.40e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.043, tt:3676.370\n",
      "Ep:102, loss:0.00002, loss_test:0.07924, lr:7.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.048, tt:3712.958\n",
      "Ep:103, loss:0.00002, loss_test:0.07961, lr:7.25e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.050, tt:3749.245\n",
      "Ep:104, loss:0.00002, loss_test:0.07815, lr:7.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.070, tt:3787.383\n",
      "Ep:105, loss:0.00002, loss_test:0.08181, lr:7.11e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.084, tt:3824.942\n",
      "Ep:106, loss:0.00002, loss_test:0.07862, lr:7.03e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.085, tt:3861.122\n",
      "Ep:107, loss:0.00002, loss_test:0.08066, lr:6.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.064, tt:3894.910\n",
      "Ep:108, loss:0.00002, loss_test:0.07887, lr:6.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.077, tt:3932.406\n",
      "Ep:109, loss:0.00002, loss_test:0.07968, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.082, tt:3968.966\n",
      "Ep:110, loss:0.00002, loss_test:0.07917, lr:6.76e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.077, tt:4004.593\n",
      "Ep:111, loss:0.00002, loss_test:0.07822, lr:6.69e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.082, tt:4041.205\n",
      "Ep:112, loss:0.00002, loss_test:0.07992, lr:6.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.074, tt:4076.360\n",
      "Ep:113, loss:0.00002, loss_test:0.08048, lr:6.56e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.064, tt:4111.322\n",
      "Ep:114, loss:0.00002, loss_test:0.07811, lr:6.49e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.058, tt:4146.616\n",
      "Ep:115, loss:0.00002, loss_test:0.07876, lr:6.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.063, tt:4183.282\n",
      "Ep:116, loss:0.00002, loss_test:0.08057, lr:6.36e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.063, tt:4219.341\n",
      "Ep:117, loss:0.00001, loss_test:0.07645, lr:6.30e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.077, tt:4257.062\n",
      "Ep:118, loss:0.00001, loss_test:0.07852, lr:6.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.068, tt:4292.130\n",
      "Ep:119, loss:0.00001, loss_test:0.07841, lr:6.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.078, tt:4329.317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00001, loss_test:0.07813, lr:6.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.083, tt:4366.063\n",
      "Ep:121, loss:0.00001, loss_test:0.07757, lr:6.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.087, tt:4402.623\n",
      "Ep:122, loss:0.00001, loss_test:0.07734, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.086, tt:4438.549\n",
      "Ep:123, loss:0.00001, loss_test:0.07831, lr:5.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.087, tt:4474.740\n",
      "Ep:124, loss:0.00001, loss_test:0.07745, lr:5.87e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.095, tt:4511.819\n",
      "Ep:125, loss:0.00001, loss_test:0.07800, lr:5.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.099, tt:4548.475\n",
      "Ep:126, loss:0.00001, loss_test:0.07764, lr:5.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.104, tt:4585.256\n",
      "Ep:127, loss:0.00001, loss_test:0.07760, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.105, tt:4621.491\n",
      "Ep:128, loss:0.00001, loss_test:0.07772, lr:5.64e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.108, tt:4657.967\n",
      "Ep:129, loss:0.00001, loss_test:0.07794, lr:5.58e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.103, tt:4693.356\n",
      "Ep:130, loss:0.00001, loss_test:0.07763, lr:5.53e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.104, tt:4729.663\n",
      "Ep:131, loss:0.00001, loss_test:0.07735, lr:5.47e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.098, tt:4764.966\n",
      "Ep:132, loss:0.00001, loss_test:0.07826, lr:5.42e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.109, tt:4802.524\n",
      "Ep:133, loss:0.00001, loss_test:0.07759, lr:5.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.108, tt:4838.456\n",
      "Ep:134, loss:0.00001, loss_test:0.07876, lr:5.31e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.110, tt:4874.788\n",
      "Ep:135, loss:0.00001, loss_test:0.07636, lr:5.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.124, tt:4912.868\n",
      "Ep:136, loss:0.00001, loss_test:0.07786, lr:5.20e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.130, tt:4949.831\n",
      "Ep:137, loss:0.00001, loss_test:0.07848, lr:5.15e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.145, tt:4987.953\n",
      "Ep:138, loss:0.00001, loss_test:0.07711, lr:5.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.145, tt:5024.192\n",
      "Ep:139, loss:0.00001, loss_test:0.07790, lr:5.05e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.147, tt:5060.583\n",
      "Ep:140, loss:0.00001, loss_test:0.07663, lr:5.00e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.152, tt:5097.418\n",
      "Ep:141, loss:0.00001, loss_test:0.07851, lr:4.95e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.144, tt:5132.444\n",
      "Ep:142, loss:0.00001, loss_test:0.07652, lr:4.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.141, tt:5168.212\n",
      "Ep:143, loss:0.00001, loss_test:0.07683, lr:4.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.147, tt:5205.156\n",
      "Ep:144, loss:0.00001, loss_test:0.07683, lr:4.80e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.140, tt:5240.331\n",
      "Ep:145, loss:0.00001, loss_test:0.07651, lr:4.75e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.142, tt:5276.666\n",
      "Ep:146, loss:0.00001, loss_test:0.07625, lr:4.71e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.130, tt:5311.122\n",
      "Ep:147, loss:0.00001, loss_test:0.07569, lr:4.66e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.134, tt:5347.869\n",
      "Ep:148, loss:0.00001, loss_test:0.07719, lr:4.61e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.133, tt:5383.808\n",
      "Ep:149, loss:0.00001, loss_test:0.07598, lr:4.57e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.141, tt:5421.180\n",
      "Ep:150, loss:0.00001, loss_test:0.07657, lr:4.52e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.130, tt:5455.671\n",
      "Ep:151, loss:0.00001, loss_test:0.07674, lr:4.48e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.129, tt:5491.573\n",
      "Ep:152, loss:0.00001, loss_test:0.07779, lr:4.43e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.125, tt:5527.124\n",
      "Ep:153, loss:0.00001, loss_test:0.07659, lr:4.39e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.130, tt:5563.946\n",
      "Ep:154, loss:0.00001, loss_test:0.07684, lr:4.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.131, tt:5600.349\n",
      "Ep:155, loss:0.00001, loss_test:0.07725, lr:4.30e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.131, tt:5636.416\n",
      "Ep:156, loss:0.00001, loss_test:0.07718, lr:4.26e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.123, tt:5671.279\n",
      "Ep:157, loss:0.00001, loss_test:0.07591, lr:4.21e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.131, tt:5708.695\n",
      "Ep:158, loss:0.00001, loss_test:0.07633, lr:4.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.127, tt:5744.185\n",
      "Ep:159, loss:0.00001, loss_test:0.07638, lr:4.13e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.127, tt:5780.311\n",
      "Ep:160, loss:0.00001, loss_test:0.07717, lr:4.09e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.127, tt:5816.366\n",
      "Ep:161, loss:0.00001, loss_test:0.07608, lr:4.05e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.129, tt:5852.902\n",
      "Ep:162, loss:0.00001, loss_test:0.07567, lr:4.01e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.131, tt:5889.409\n",
      "Ep:163, loss:0.00001, loss_test:0.07680, lr:3.97e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.132, tt:5925.697\n",
      "Ep:164, loss:0.00001, loss_test:0.07655, lr:3.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.123, tt:5960.243\n",
      "Ep:165, loss:0.00001, loss_test:0.07592, lr:3.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.125, tt:5996.681\n",
      "Ep:166, loss:0.00001, loss_test:0.07687, lr:3.85e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.132, tt:6033.985\n",
      "Ep:167, loss:0.00001, loss_test:0.07660, lr:3.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.126, tt:6069.159\n",
      "Ep:168, loss:0.00001, loss_test:0.07747, lr:3.77e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.121, tt:6104.422\n",
      "Ep:169, loss:0.00001, loss_test:0.07576, lr:3.73e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.120, tt:6140.370\n",
      "Ep:170, loss:0.00001, loss_test:0.07681, lr:3.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.118, tt:6176.127\n",
      "Ep:171, loss:0.00001, loss_test:0.07636, lr:3.66e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.111, tt:6211.023\n",
      "Ep:172, loss:0.00001, loss_test:0.07646, lr:3.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.111, tt:6247.245\n",
      "Ep:173, loss:0.00001, loss_test:0.07648, lr:3.59e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.117, tt:6284.293\n",
      "Ep:174, loss:0.00001, loss_test:0.07625, lr:3.55e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.125, tt:6321.826\n",
      "Ep:175, loss:0.00001, loss_test:0.07640, lr:3.52e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.119, tt:6356.897\n",
      "Ep:176, loss:0.00001, loss_test:0.07616, lr:3.48e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.117, tt:6392.724\n",
      "Ep:177, loss:0.00001, loss_test:0.07629, lr:3.45e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.126, tt:6430.391\n",
      "Ep:178, loss:0.00001, loss_test:0.07628, lr:3.41e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.125, tt:6466.369\n",
      "Ep:179, loss:0.00001, loss_test:0.07663, lr:3.38e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.113, tt:6500.385\n",
      "Ep:180, loss:0.00001, loss_test:0.07650, lr:3.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.117, tt:6537.140\n",
      "Ep:181, loss:0.00001, loss_test:0.07699, lr:3.31e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.114, tt:6572.767\n",
      "Ep:182, loss:0.00001, loss_test:0.07674, lr:3.28e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.112, tt:6608.431\n",
      "Ep:183, loss:0.00001, loss_test:0.07671, lr:3.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.113, tt:6644.737\n",
      "Ep:184, loss:0.00001, loss_test:0.07695, lr:3.21e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.114, tt:6681.085\n",
      "Ep:185, loss:0.00001, loss_test:0.07659, lr:3.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.111, tt:6716.668\n",
      "Ep:186, loss:0.00001, loss_test:0.07756, lr:3.15e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.112, tt:6752.886\n",
      "Ep:187, loss:0.00001, loss_test:0.07637, lr:3.12e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.103, tt:6787.317\n",
      "Ep:188, loss:0.00001, loss_test:0.07690, lr:3.09e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.096, tt:6822.188\n",
      "Ep:189, loss:0.00001, loss_test:0.07727, lr:3.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.097, tt:6858.428\n",
      "Ep:190, loss:0.00001, loss_test:0.07657, lr:3.02e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.096, tt:6894.428\n",
      "Ep:191, loss:0.00001, loss_test:0.07767, lr:2.99e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.097, tt:6930.634\n",
      "Ep:192, loss:0.00001, loss_test:0.07708, lr:2.96e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.095, tt:6966.360\n",
      "Ep:193, loss:0.00001, loss_test:0.07638, lr:2.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.092, tt:7001.778\n",
      "Ep:194, loss:0.00001, loss_test:0.07692, lr:2.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.097, tt:7038.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00001, loss_test:0.07666, lr:2.88e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.099, tt:7075.443\n",
      "Ep:196, loss:0.00001, loss_test:0.07686, lr:2.85e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.097, tt:7111.202\n",
      "Ep:197, loss:0.00001, loss_test:0.07630, lr:2.82e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.096, tt:7146.961\n",
      "Ep:198, loss:0.00001, loss_test:0.07733, lr:2.79e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.100, tt:7183.936\n",
      "Ep:199, loss:0.00001, loss_test:0.07745, lr:2.76e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.100, tt:7220.070\n",
      "Ep:200, loss:0.00001, loss_test:0.07678, lr:2.73e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.103, tt:7256.798\n",
      "Ep:201, loss:0.00001, loss_test:0.07715, lr:2.71e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.104, tt:7293.088\n",
      "Ep:202, loss:0.00001, loss_test:0.07649, lr:2.68e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.113, tt:7331.019\n",
      "Ep:203, loss:0.00001, loss_test:0.07754, lr:2.65e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.116, tt:7367.572\n",
      "Ep:204, loss:0.00001, loss_test:0.07706, lr:2.63e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.111, tt:7402.815\n",
      "Ep:205, loss:0.00001, loss_test:0.07655, lr:2.60e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.109, tt:7438.441\n",
      "Ep:206, loss:0.00001, loss_test:0.07737, lr:2.57e-03, fs:0.85556 (r=0.778,p=0.951),  time:36.105, tt:7473.640\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02147, lr:6.00e-02, fs:0.64341 (r=0.838,p=0.522),  time:32.272, tt:32.272\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02439, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.187, tt:62.375\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02646, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.810, tt:92.429\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02638, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.140, tt:120.560\n",
      "Ep:4, loss:0.00005, loss_test:0.02526, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:29.527, tt:147.635\n",
      "Ep:5, loss:0.00005, loss_test:0.02351, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:29.726, tt:178.354\n",
      "Ep:6, loss:0.00005, loss_test:0.02192, lr:6.00e-02, fs:0.64748 (r=0.909,p=0.503),  time:29.956, tt:209.690\n",
      "Ep:7, loss:0.00004, loss_test:0.02109, lr:6.00e-02, fs:0.65134 (r=0.859,p=0.525),  time:29.894, tt:239.152\n",
      "Ep:8, loss:0.00004, loss_test:0.02038, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:29.868, tt:268.811\n",
      "Ep:9, loss:0.00004, loss_test:0.01981, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:29.992, tt:299.919\n",
      "Ep:10, loss:0.00004, loss_test:0.01949, lr:6.00e-02, fs:0.68345 (r=0.960,p=0.531),  time:29.985, tt:329.839\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01905, lr:6.00e-02, fs:0.70036 (r=0.980,p=0.545),  time:30.167, tt:362.003\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01850, lr:6.00e-02, fs:0.70849 (r=0.970,p=0.558),  time:30.538, tt:396.999\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01803, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:30.909, tt:432.720\n",
      "Ep:14, loss:0.00004, loss_test:0.01779, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:31.115, tt:466.720\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.71146 (r=0.909,p=0.584),  time:31.179, tt:498.857\n",
      "Ep:16, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:31.375, tt:533.371\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:31.511, tt:567.206\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:31.694, tt:602.192\n",
      "Ep:19, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.71369 (r=0.869,p=0.606),  time:31.837, tt:636.736\n",
      "Ep:20, loss:0.00003, loss_test:0.01743, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:31.903, tt:669.964\n",
      "Ep:21, loss:0.00003, loss_test:0.01743, lr:6.00e-02, fs:0.69787 (r=0.828,p=0.603),  time:32.005, tt:704.099\n",
      "Ep:22, loss:0.00003, loss_test:0.01738, lr:6.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:32.117, tt:738.687\n",
      "Ep:23, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:32.228, tt:773.471\n",
      "Ep:24, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:32.269, tt:806.734\n",
      "Ep:25, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:32.295, tt:839.670\n",
      "Ep:26, loss:0.00003, loss_test:0.01675, lr:6.00e-02, fs:0.71304 (r=0.828,p=0.626),  time:32.322, tt:872.692\n",
      "Ep:27, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:32.414, tt:907.579\n",
      "Ep:28, loss:0.00002, loss_test:0.01659, lr:6.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:32.479, tt:941.878\n",
      "Ep:29, loss:0.00002, loss_test:0.01645, lr:5.94e-02, fs:0.71681 (r=0.818,p=0.638),  time:32.522, tt:975.673\n",
      "Ep:30, loss:0.00002, loss_test:0.01636, lr:5.88e-02, fs:0.72321 (r=0.818,p=0.648),  time:32.649, tt:1012.104\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01621, lr:5.88e-02, fs:0.72646 (r=0.818,p=0.653),  time:32.675, tt:1045.602\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01606, lr:5.88e-02, fs:0.72646 (r=0.818,p=0.653),  time:32.776, tt:1081.602\n",
      "Ep:33, loss:0.00002, loss_test:0.01603, lr:5.88e-02, fs:0.72973 (r=0.818,p=0.659),  time:32.810, tt:1115.546\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01614, lr:5.88e-02, fs:0.73973 (r=0.818,p=0.675),  time:32.846, tt:1149.614\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01614, lr:5.88e-02, fs:0.75000 (r=0.818,p=0.692),  time:32.852, tt:1182.681\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01617, lr:5.88e-02, fs:0.74419 (r=0.808,p=0.690),  time:32.859, tt:1215.794\n",
      "Ep:37, loss:0.00002, loss_test:0.01617, lr:5.88e-02, fs:0.74766 (r=0.808,p=0.696),  time:32.945, tt:1251.921\n",
      "Ep:38, loss:0.00002, loss_test:0.01625, lr:5.88e-02, fs:0.75117 (r=0.808,p=0.702),  time:32.975, tt:1286.024\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01622, lr:5.88e-02, fs:0.75117 (r=0.808,p=0.702),  time:33.008, tt:1320.336\n",
      "Ep:40, loss:0.00002, loss_test:0.01621, lr:5.88e-02, fs:0.75829 (r=0.808,p=0.714),  time:33.016, tt:1353.663\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01624, lr:5.88e-02, fs:0.76190 (r=0.808,p=0.721),  time:33.059, tt:1388.491\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01621, lr:5.88e-02, fs:0.77295 (r=0.808,p=0.741),  time:33.099, tt:1423.248\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01617, lr:5.88e-02, fs:0.76699 (r=0.798,p=0.738),  time:33.136, tt:1457.979\n",
      "Ep:44, loss:0.00002, loss_test:0.01617, lr:5.88e-02, fs:0.76699 (r=0.798,p=0.738),  time:33.165, tt:1492.442\n",
      "Ep:45, loss:0.00002, loss_test:0.01614, lr:5.88e-02, fs:0.76699 (r=0.798,p=0.738),  time:33.201, tt:1527.238\n",
      "Ep:46, loss:0.00002, loss_test:0.01612, lr:5.88e-02, fs:0.77073 (r=0.798,p=0.745),  time:33.251, tt:1562.819\n",
      "Ep:47, loss:0.00002, loss_test:0.01609, lr:5.88e-02, fs:0.78218 (r=0.798,p=0.767),  time:33.299, tt:1598.349\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01620, lr:5.88e-02, fs:0.77612 (r=0.788,p=0.765),  time:33.277, tt:1630.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00002, loss_test:0.01622, lr:5.88e-02, fs:0.79397 (r=0.798,p=0.790),  time:33.309, tt:1665.450\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01629, lr:5.88e-02, fs:0.79000 (r=0.798,p=0.782),  time:33.337, tt:1700.181\n",
      "Ep:51, loss:0.00002, loss_test:0.01621, lr:5.88e-02, fs:0.79000 (r=0.798,p=0.782),  time:33.308, tt:1732.040\n",
      "Ep:52, loss:0.00001, loss_test:0.01646, lr:5.88e-02, fs:0.79000 (r=0.798,p=0.782),  time:33.345, tt:1767.302\n",
      "Ep:53, loss:0.00001, loss_test:0.01632, lr:5.88e-02, fs:0.79397 (r=0.798,p=0.790),  time:33.398, tt:1803.508\n",
      "Ep:54, loss:0.00001, loss_test:0.01654, lr:5.88e-02, fs:0.79397 (r=0.798,p=0.790),  time:33.439, tt:1839.160\n",
      "Ep:55, loss:0.00001, loss_test:0.01660, lr:5.88e-02, fs:0.79397 (r=0.798,p=0.790),  time:33.471, tt:1874.350\n",
      "Ep:56, loss:0.00001, loss_test:0.01663, lr:5.88e-02, fs:0.80203 (r=0.798,p=0.806),  time:33.468, tt:1907.661\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01657, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.498, tt:1942.908\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01713, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:33.527, tt:1978.108\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01686, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.509, tt:2010.520\n",
      "Ep:60, loss:0.00001, loss_test:0.01715, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:33.489, tt:2042.846\n",
      "Ep:61, loss:0.00001, loss_test:0.01704, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.475, tt:2075.441\n",
      "Ep:62, loss:0.00001, loss_test:0.01719, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.482, tt:2109.357\n",
      "Ep:63, loss:0.00001, loss_test:0.01735, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.464, tt:2141.686\n",
      "Ep:64, loss:0.00001, loss_test:0.01746, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.488, tt:2176.726\n",
      "Ep:65, loss:0.00001, loss_test:0.01764, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:33.491, tt:2210.381\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01748, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.490, tt:2243.843\n",
      "Ep:67, loss:0.00001, loss_test:0.01766, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.504, tt:2278.293\n",
      "Ep:68, loss:0.00001, loss_test:0.01779, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.497, tt:2311.316\n",
      "Ep:69, loss:0.00001, loss_test:0.01774, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.533, tt:2347.288\n",
      "Ep:70, loss:0.00001, loss_test:0.01821, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:33.548, tt:2381.934\n",
      "Ep:71, loss:0.00001, loss_test:0.01815, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.567, tt:2416.801\n",
      "Ep:72, loss:0.00001, loss_test:0.01838, lr:5.88e-02, fs:0.80612 (r=0.798,p=0.814),  time:33.618, tt:2454.096\n",
      "Ep:73, loss:0.00001, loss_test:0.01854, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:33.626, tt:2488.328\n",
      "Ep:74, loss:0.00001, loss_test:0.01863, lr:5.88e-02, fs:0.81026 (r=0.798,p=0.823),  time:33.633, tt:2522.474\n",
      "Ep:75, loss:0.00001, loss_test:0.01906, lr:5.88e-02, fs:0.81443 (r=0.798,p=0.832),  time:33.654, tt:2557.742\n",
      "Ep:76, loss:0.00001, loss_test:0.01871, lr:5.88e-02, fs:0.80000 (r=0.788,p=0.812),  time:33.684, tt:2593.693\n",
      "Ep:77, loss:0.00001, loss_test:0.01942, lr:5.82e-02, fs:0.81250 (r=0.788,p=0.839),  time:33.693, tt:2628.068\n",
      "Ep:78, loss:0.00001, loss_test:0.01935, lr:5.76e-02, fs:0.80208 (r=0.778,p=0.828),  time:33.709, tt:2662.992\n",
      "Ep:79, loss:0.00001, loss_test:0.01970, lr:5.71e-02, fs:0.80628 (r=0.778,p=0.837),  time:33.731, tt:2698.520\n",
      "Ep:80, loss:0.00001, loss_test:0.01990, lr:5.65e-02, fs:0.80208 (r=0.778,p=0.828),  time:33.769, tt:2735.254\n",
      "Ep:81, loss:0.00001, loss_test:0.02025, lr:5.59e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.829, tt:2773.970\n",
      "Ep:82, loss:0.00001, loss_test:0.02008, lr:5.54e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.858, tt:2810.188\n",
      "Ep:83, loss:0.00001, loss_test:0.02035, lr:5.48e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.866, tt:2844.738\n",
      "Ep:84, loss:0.00001, loss_test:0.02100, lr:5.43e-02, fs:0.80423 (r=0.768,p=0.844),  time:33.907, tt:2882.096\n",
      "Ep:85, loss:0.00001, loss_test:0.02075, lr:5.37e-02, fs:0.80000 (r=0.768,p=0.835),  time:33.925, tt:2917.588\n",
      "Ep:86, loss:0.00001, loss_test:0.02094, lr:5.32e-02, fs:0.80423 (r=0.768,p=0.844),  time:33.945, tt:2953.234\n",
      "Ep:87, loss:0.00001, loss_test:0.02136, lr:5.27e-02, fs:0.80423 (r=0.768,p=0.844),  time:33.965, tt:2988.961\n",
      "Ep:88, loss:0.00001, loss_test:0.02128, lr:5.21e-02, fs:0.78075 (r=0.737,p=0.830),  time:33.958, tt:3022.236\n",
      "Ep:89, loss:0.00001, loss_test:0.02169, lr:5.16e-02, fs:0.79570 (r=0.747,p=0.851),  time:33.968, tt:3057.096\n",
      "Ep:90, loss:0.00001, loss_test:0.02184, lr:5.11e-02, fs:0.78495 (r=0.737,p=0.839),  time:33.965, tt:3090.845\n",
      "Ep:91, loss:0.00001, loss_test:0.02165, lr:5.06e-02, fs:0.78495 (r=0.737,p=0.839),  time:33.986, tt:3126.698\n",
      "Ep:92, loss:0.00001, loss_test:0.02227, lr:5.01e-02, fs:0.79570 (r=0.747,p=0.851),  time:34.020, tt:3163.862\n",
      "Ep:93, loss:0.00001, loss_test:0.02235, lr:4.96e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.020, tt:3197.864\n",
      "Ep:94, loss:0.00001, loss_test:0.02252, lr:4.91e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.028, tt:3232.698\n",
      "Ep:95, loss:0.00001, loss_test:0.02291, lr:4.86e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.037, tt:3267.578\n",
      "Ep:96, loss:0.00001, loss_test:0.02314, lr:4.81e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.049, tt:3302.769\n",
      "Ep:97, loss:0.00001, loss_test:0.02309, lr:4.76e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.071, tt:3338.974\n",
      "Ep:98, loss:0.00001, loss_test:0.02323, lr:4.71e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.064, tt:3372.314\n",
      "Ep:99, loss:0.00001, loss_test:0.02371, lr:4.67e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.080, tt:3407.974\n",
      "Ep:100, loss:0.00001, loss_test:0.02356, lr:4.62e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.079, tt:3441.970\n",
      "Ep:101, loss:0.00001, loss_test:0.02412, lr:4.57e-02, fs:0.78261 (r=0.727,p=0.847),  time:34.103, tt:3478.506\n",
      "Ep:102, loss:0.00001, loss_test:0.02430, lr:4.53e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.107, tt:3512.991\n",
      "Ep:103, loss:0.00001, loss_test:0.02402, lr:4.48e-02, fs:0.77838 (r=0.727,p=0.837),  time:34.125, tt:3548.975\n",
      "Ep:104, loss:0.00001, loss_test:0.02470, lr:4.44e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.128, tt:3583.397\n",
      "Ep:105, loss:0.00001, loss_test:0.02468, lr:4.39e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.130, tt:3617.813\n",
      "Ep:106, loss:0.00000, loss_test:0.02457, lr:4.35e-02, fs:0.77348 (r=0.707,p=0.854),  time:34.141, tt:3653.064\n",
      "Ep:107, loss:0.00000, loss_test:0.02505, lr:4.31e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.140, tt:3687.086\n",
      "Ep:108, loss:0.00000, loss_test:0.02497, lr:4.26e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.146, tt:3721.953\n",
      "Ep:109, loss:0.00000, loss_test:0.02490, lr:4.22e-02, fs:0.77174 (r=0.717,p=0.835),  time:34.157, tt:3757.276\n",
      "Ep:110, loss:0.00000, loss_test:0.02571, lr:4.18e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.153, tt:3790.999\n",
      "Ep:111, loss:0.00000, loss_test:0.02559, lr:4.14e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.160, tt:3825.939\n",
      "Ep:112, loss:0.00000, loss_test:0.02558, lr:4.10e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.173, tt:3861.497\n",
      "Ep:113, loss:0.00000, loss_test:0.02634, lr:4.05e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.196, tt:3898.368\n",
      "Ep:114, loss:0.00000, loss_test:0.02581, lr:4.01e-02, fs:0.78022 (r=0.717,p=0.855),  time:34.210, tt:3934.119\n",
      "Ep:115, loss:0.00000, loss_test:0.02636, lr:3.97e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.210, tt:3968.345\n",
      "Ep:116, loss:0.00000, loss_test:0.02640, lr:3.93e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.227, tt:4004.609\n",
      "Ep:117, loss:0.00000, loss_test:0.02617, lr:3.89e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.234, tt:4039.564\n",
      "Ep:118, loss:0.00000, loss_test:0.02697, lr:3.86e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.242, tt:4074.792\n",
      "Ep:119, loss:0.00000, loss_test:0.02615, lr:3.82e-02, fs:0.76404 (r=0.687,p=0.861),  time:34.243, tt:4109.196\n",
      "Ep:120, loss:0.00000, loss_test:0.02692, lr:3.78e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.247, tt:4143.880\n",
      "Ep:121, loss:0.00000, loss_test:0.02694, lr:3.74e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.279, tt:4182.071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00000, loss_test:0.02697, lr:3.70e-02, fs:0.78453 (r=0.717,p=0.866),  time:34.289, tt:4217.502\n",
      "Ep:123, loss:0.00000, loss_test:0.02754, lr:3.67e-02, fs:0.79121 (r=0.727,p=0.867),  time:34.283, tt:4251.102\n",
      "Ep:124, loss:0.00000, loss_test:0.02697, lr:3.63e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.302, tt:4287.753\n",
      "Ep:125, loss:0.00000, loss_test:0.02771, lr:3.59e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.317, tt:4323.984\n",
      "Ep:126, loss:0.00000, loss_test:0.02724, lr:3.56e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.325, tt:4359.219\n",
      "Ep:127, loss:0.00000, loss_test:0.02770, lr:3.52e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.335, tt:4394.906\n",
      "Ep:128, loss:0.00000, loss_test:0.02781, lr:3.49e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.339, tt:4429.708\n",
      "Ep:129, loss:0.00000, loss_test:0.02786, lr:3.45e-02, fs:0.78212 (r=0.707,p=0.875),  time:34.347, tt:4465.110\n",
      "Ep:130, loss:0.00000, loss_test:0.02819, lr:3.42e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.352, tt:4500.090\n",
      "Ep:131, loss:0.00000, loss_test:0.02815, lr:3.38e-02, fs:0.77273 (r=0.687,p=0.883),  time:34.359, tt:4535.330\n",
      "Ep:132, loss:0.00000, loss_test:0.02831, lr:3.35e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.367, tt:4570.759\n",
      "Ep:133, loss:0.00000, loss_test:0.02852, lr:3.32e-02, fs:0.78889 (r=0.717,p=0.877),  time:34.371, tt:4605.681\n",
      "Ep:134, loss:0.00000, loss_test:0.02848, lr:3.28e-02, fs:0.77528 (r=0.697,p=0.873),  time:34.366, tt:4639.464\n",
      "Ep:135, loss:0.00000, loss_test:0.02865, lr:3.25e-02, fs:0.76836 (r=0.687,p=0.872),  time:34.370, tt:4674.332\n",
      "Ep:136, loss:0.00000, loss_test:0.02896, lr:3.22e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.380, tt:4710.059\n",
      "Ep:137, loss:0.00000, loss_test:0.02888, lr:3.19e-02, fs:0.75145 (r=0.657,p=0.878),  time:34.375, tt:4743.711\n",
      "Ep:138, loss:0.00000, loss_test:0.02909, lr:3.15e-02, fs:0.76136 (r=0.677,p=0.870),  time:34.371, tt:4777.511\n",
      "Ep:139, loss:0.00000, loss_test:0.02924, lr:3.12e-02, fs:0.74713 (r=0.657,p=0.867),  time:34.379, tt:4812.990\n",
      "Ep:140, loss:0.00000, loss_test:0.02921, lr:3.09e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.392, tt:4849.210\n",
      "Ep:141, loss:0.00000, loss_test:0.02946, lr:3.06e-02, fs:0.72515 (r=0.626,p=0.861),  time:34.395, tt:4884.149\n",
      "Ep:142, loss:0.00000, loss_test:0.02945, lr:3.03e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.407, tt:4920.257\n",
      "Ep:143, loss:0.00000, loss_test:0.02938, lr:3.00e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.413, tt:4955.424\n",
      "Ep:144, loss:0.00000, loss_test:0.02951, lr:2.97e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.424, tt:4991.508\n",
      "Ep:145, loss:0.00000, loss_test:0.02953, lr:2.94e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.429, tt:5026.598\n",
      "Ep:146, loss:0.00000, loss_test:0.02954, lr:2.91e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.441, tt:5062.789\n",
      "Ep:147, loss:0.00000, loss_test:0.02975, lr:2.88e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.453, tt:5099.027\n",
      "Ep:148, loss:0.00000, loss_test:0.02976, lr:2.85e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.456, tt:5133.971\n",
      "Ep:149, loss:0.00000, loss_test:0.02999, lr:2.82e-02, fs:0.71765 (r=0.616,p=0.859),  time:34.458, tt:5168.722\n",
      "Ep:150, loss:0.00000, loss_test:0.02991, lr:2.80e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.462, tt:5203.768\n",
      "Ep:151, loss:0.00000, loss_test:0.03005, lr:2.77e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.468, tt:5239.080\n",
      "Ep:152, loss:0.00000, loss_test:0.02992, lr:2.74e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.465, tt:5273.150\n",
      "Ep:153, loss:0.00000, loss_test:0.03031, lr:2.71e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.472, tt:5308.741\n",
      "Ep:154, loss:0.00000, loss_test:0.03029, lr:2.69e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.493, tt:5346.430\n",
      "Ep:155, loss:0.00000, loss_test:0.03026, lr:2.66e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.499, tt:5381.802\n",
      "Ep:156, loss:0.00000, loss_test:0.03071, lr:2.63e-02, fs:0.72941 (r=0.626,p=0.873),  time:34.505, tt:5417.360\n",
      "Ep:157, loss:0.00000, loss_test:0.03015, lr:2.61e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.507, tt:5452.154\n",
      "Ep:158, loss:0.00000, loss_test:0.03087, lr:2.58e-02, fs:0.74419 (r=0.646,p=0.877),  time:34.508, tt:5486.839\n",
      "Ep:159, loss:0.00000, loss_test:0.03030, lr:2.55e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.519, tt:5523.086\n",
      "Ep:160, loss:0.00000, loss_test:0.03078, lr:2.53e-02, fs:0.72189 (r=0.616,p=0.871),  time:34.528, tt:5558.965\n",
      "Ep:161, loss:0.00000, loss_test:0.03058, lr:2.50e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.522, tt:5592.612\n",
      "Ep:162, loss:0.00000, loss_test:0.03084, lr:2.48e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.522, tt:5627.091\n",
      "Ep:163, loss:0.00000, loss_test:0.03052, lr:2.45e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.524, tt:5661.930\n",
      "Ep:164, loss:0.00000, loss_test:0.03097, lr:2.43e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.528, tt:5697.128\n",
      "Ep:165, loss:0.00000, loss_test:0.03086, lr:2.40e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.534, tt:5732.611\n",
      "Ep:166, loss:0.00000, loss_test:0.03121, lr:2.38e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.542, tt:5768.551\n",
      "Ep:167, loss:0.00000, loss_test:0.03090, lr:2.36e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.545, tt:5803.622\n",
      "Ep:168, loss:0.00000, loss_test:0.03122, lr:2.33e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.550, tt:5838.945\n",
      "Ep:169, loss:0.00000, loss_test:0.03107, lr:2.31e-02, fs:0.71429 (r=0.606,p=0.870),  time:34.551, tt:5873.597\n",
      "Ep:170, loss:0.00000, loss_test:0.03141, lr:2.29e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.560, tt:5909.684\n",
      "Ep:171, loss:0.00000, loss_test:0.03145, lr:2.26e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.566, tt:5945.436\n",
      "Ep:172, loss:0.00000, loss_test:0.03132, lr:2.24e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.573, tt:5981.102\n",
      "Ep:173, loss:0.00000, loss_test:0.03151, lr:2.22e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.576, tt:6016.157\n",
      "Ep:174, loss:0.00000, loss_test:0.03134, lr:2.20e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.585, tt:6052.403\n",
      "Ep:175, loss:0.00000, loss_test:0.03157, lr:2.17e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.595, tt:6088.689\n",
      "Ep:176, loss:0.00000, loss_test:0.03153, lr:2.15e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.605, tt:6125.092\n",
      "Ep:177, loss:0.00000, loss_test:0.03180, lr:2.13e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.606, tt:6159.819\n",
      "Ep:178, loss:0.00000, loss_test:0.03150, lr:2.11e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.616, tt:6196.214\n",
      "Ep:179, loss:0.00000, loss_test:0.03181, lr:2.09e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.625, tt:6232.537\n",
      "Ep:180, loss:0.00000, loss_test:0.03161, lr:2.07e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.629, tt:6267.803\n",
      "Ep:181, loss:0.00000, loss_test:0.03183, lr:2.05e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.629, tt:6302.542\n",
      "Ep:182, loss:0.00000, loss_test:0.03170, lr:2.03e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.634, tt:6338.082\n",
      "Ep:183, loss:0.00000, loss_test:0.03193, lr:2.01e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.646, tt:6374.790\n",
      "Ep:184, loss:0.00000, loss_test:0.03185, lr:1.99e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.647, tt:6409.744\n",
      "Ep:185, loss:0.00000, loss_test:0.03198, lr:1.97e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.645, tt:6443.963\n",
      "Ep:186, loss:0.00000, loss_test:0.03194, lr:1.95e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.647, tt:6478.963\n",
      "Ep:187, loss:0.00000, loss_test:0.03192, lr:1.93e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.660, tt:6516.039\n",
      "Ep:188, loss:0.00000, loss_test:0.03219, lr:1.91e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.671, tt:6552.905\n",
      "Ep:189, loss:0.00000, loss_test:0.03205, lr:1.89e-02, fs:0.71856 (r=0.606,p=0.882),  time:34.685, tt:6590.135\n",
      "Ep:190, loss:0.00000, loss_test:0.03224, lr:1.87e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.685, tt:6624.914\n",
      "Ep:191, loss:0.00000, loss_test:0.03212, lr:1.85e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.689, tt:6660.260\n",
      "Ep:192, loss:0.00000, loss_test:0.03231, lr:1.83e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.690, tt:6695.200\n",
      "Ep:193, loss:0.00000, loss_test:0.03231, lr:1.81e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.694, tt:6730.544\n",
      "Ep:194, loss:0.00000, loss_test:0.03232, lr:1.80e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.695, tt:6765.569\n",
      "Ep:195, loss:0.00000, loss_test:0.03242, lr:1.78e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.694, tt:6800.092\n",
      "Ep:196, loss:0.00000, loss_test:0.03246, lr:1.76e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.698, tt:6835.530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.03250, lr:1.74e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.694, tt:6869.455\n",
      "Ep:198, loss:0.00000, loss_test:0.03249, lr:1.73e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.692, tt:6903.675\n",
      "Ep:199, loss:0.00000, loss_test:0.03243, lr:1.71e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.683, tt:6936.618\n",
      "Ep:200, loss:0.00000, loss_test:0.03255, lr:1.69e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.679, tt:6970.479\n",
      "Ep:201, loss:0.00000, loss_test:0.03254, lr:1.67e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.676, tt:7004.637\n",
      "Ep:202, loss:0.00000, loss_test:0.03265, lr:1.66e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.678, tt:7039.680\n",
      "Ep:203, loss:0.00000, loss_test:0.03257, lr:1.64e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.689, tt:7076.656\n",
      "Ep:204, loss:0.00000, loss_test:0.03282, lr:1.62e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.685, tt:7110.444\n",
      "Ep:205, loss:0.00000, loss_test:0.03262, lr:1.61e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.676, tt:7143.331\n",
      "Ep:206, loss:0.00000, loss_test:0.03279, lr:1.59e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.675, tt:7177.816\n",
      "Ep:207, loss:0.00000, loss_test:0.03268, lr:1.58e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.673, tt:7211.987\n",
      "Ep:208, loss:0.00000, loss_test:0.03280, lr:1.56e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.665, tt:7244.894\n",
      "Ep:209, loss:0.00000, loss_test:0.03287, lr:1.54e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.669, tt:7280.529\n",
      "Ep:210, loss:0.00000, loss_test:0.03283, lr:1.53e-02, fs:0.72289 (r=0.606,p=0.896),  time:34.673, tt:7315.975\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13757, lr:1.00e-02, fs:0.64336 (r=0.929,p=0.492),  time:35.996, tt:35.996\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.13290, lr:1.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:37.026, tt:74.052\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12722, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:36.290, tt:108.871\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12442, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:35.847, tt:143.388\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12273, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:35.596, tt:177.981\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12132, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:36.053, tt:216.315\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11977, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:35.690, tt:249.827\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11756, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:35.366, tt:282.931\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11522, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:35.293, tt:317.637\n",
      "Ep:9, loss:0.00022, loss_test:0.11269, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:35.611, tt:356.108\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11051, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:35.533, tt:390.865\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10893, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:35.634, tt:427.609\n",
      "Ep:12, loss:0.00020, loss_test:0.10650, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:35.584, tt:462.592\n",
      "Ep:13, loss:0.00020, loss_test:0.10473, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:35.756, tt:500.580\n",
      "Ep:14, loss:0.00019, loss_test:0.10371, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:35.915, tt:538.730\n",
      "Ep:15, loss:0.00018, loss_test:0.10121, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:35.900, tt:574.394\n",
      "Ep:16, loss:0.00018, loss_test:0.09946, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:35.944, tt:611.047\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09847, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:36.064, tt:649.148\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09723, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:36.170, tt:687.232\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.09619, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:36.257, tt:725.131\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09518, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:36.242, tt:761.083\n",
      "Ep:21, loss:0.00015, loss_test:0.09362, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:36.306, tt:798.732\n",
      "Ep:22, loss:0.00014, loss_test:0.09267, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:36.407, tt:837.363\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09236, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:36.382, tt:873.173\n",
      "Ep:24, loss:0.00014, loss_test:0.09163, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:36.371, tt:909.281\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.09043, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:36.366, tt:945.517\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08963, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:36.359, tt:981.696\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.08763, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:36.360, tt:1018.070\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.08543, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:36.367, tt:1054.635\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08511, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:36.352, tt:1090.563\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08367, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:36.339, tt:1126.496\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08186, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:36.293, tt:1161.361\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08022, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:36.235, tt:1195.756\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.08013, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:36.215, tt:1231.315\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07927, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:36.163, tt:1265.706\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07684, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:36.198, tt:1303.121\n",
      "Ep:36, loss:0.00009, loss_test:0.08076, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:36.163, tt:1338.047\n",
      "Ep:37, loss:0.00009, loss_test:0.07303, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:36.114, tt:1372.327\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07674, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:36.092, tt:1407.570\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07476, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:36.081, tt:1443.236\n",
      "Ep:40, loss:0.00008, loss_test:0.06990, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:36.023, tt:1476.924\n",
      "Ep:41, loss:0.00008, loss_test:0.07168, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.996, tt:1511.815\n",
      "Ep:42, loss:0.00008, loss_test:0.06844, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.003, tt:1548.115\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06966, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.003, tt:1584.148\n",
      "Ep:44, loss:0.00007, loss_test:0.07036, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.985, tt:1619.308\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00007, loss_test:0.06814, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.956, tt:1653.966\n",
      "Ep:46, loss:0.00007, loss_test:0.06680, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.923, tt:1688.394\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06651, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.916, tt:1723.973\n",
      "Ep:48, loss:0.00007, loss_test:0.06804, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.889, tt:1758.573\n",
      "Ep:49, loss:0.00006, loss_test:0.06403, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.870, tt:1793.476\n",
      "Ep:50, loss:0.00006, loss_test:0.06461, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.880, tt:1829.887\n",
      "Ep:51, loss:0.00006, loss_test:0.06515, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.900, tt:1866.799\n",
      "Ep:52, loss:0.00006, loss_test:0.06326, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.871, tt:1901.152\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.06309, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:35.863, tt:1936.604\n",
      "Ep:54, loss:0.00006, loss_test:0.07247, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.826, tt:1970.434\n",
      "Ep:55, loss:0.00007, loss_test:0.06518, lr:1.00e-02, fs:0.85246 (r=0.788,p=0.929),  time:35.804, tt:2005.009\n",
      "Ep:56, loss:0.00006, loss_test:0.06049, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.808, tt:2041.070\n",
      "Ep:57, loss:0.00006, loss_test:0.06802, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:35.812, tt:2077.080\n",
      "Ep:58, loss:0.00006, loss_test:0.06203, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:35.802, tt:2112.331\n",
      "Ep:59, loss:0.00005, loss_test:0.06187, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.777, tt:2146.617\n",
      "Ep:60, loss:0.00005, loss_test:0.06250, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:35.749, tt:2180.704\n",
      "Ep:61, loss:0.00005, loss_test:0.05909, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.742, tt:2215.982\n",
      "Ep:62, loss:0.00005, loss_test:0.06093, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.718, tt:2250.265\n",
      "Ep:63, loss:0.00005, loss_test:0.05902, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.685, tt:2283.871\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00005, loss_test:0.06086, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:35.674, tt:2318.829\n",
      "Ep:65, loss:0.00005, loss_test:0.06171, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:35.681, tt:2354.936\n",
      "Ep:66, loss:0.00005, loss_test:0.06270, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.675, tt:2390.220\n",
      "Ep:67, loss:0.00004, loss_test:0.06073, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:35.688, tt:2426.816\n",
      "Ep:68, loss:0.00004, loss_test:0.06147, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.676, tt:2461.671\n",
      "Ep:69, loss:0.00005, loss_test:0.06728, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:35.653, tt:2495.707\n",
      "Ep:70, loss:0.00005, loss_test:0.05996, lr:1.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:35.666, tt:2532.261\n",
      "Ep:71, loss:0.00004, loss_test:0.06159, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:35.693, tt:2569.895\n",
      "Ep:72, loss:0.00005, loss_test:0.07956, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:35.688, tt:2605.213\n",
      "Ep:73, loss:0.00005, loss_test:0.05577, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:35.695, tt:2641.442\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.06924, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.704, tt:2677.763\n",
      "Ep:75, loss:0.00005, loss_test:0.05876, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.693, tt:2712.687\n",
      "Ep:76, loss:0.00004, loss_test:0.05766, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.702, tt:2749.059\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.06557, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.702, tt:2784.756\n",
      "Ep:78, loss:0.00004, loss_test:0.05703, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:35.701, tt:2820.368\n",
      "Ep:79, loss:0.00004, loss_test:0.06025, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.711, tt:2856.868\n",
      "Ep:80, loss:0.00004, loss_test:0.06159, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:35.728, tt:2893.979\n",
      "Ep:81, loss:0.00004, loss_test:0.06169, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.735, tt:2930.250\n",
      "Ep:82, loss:0.00004, loss_test:0.05568, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:35.740, tt:2966.401\n",
      "Ep:83, loss:0.00004, loss_test:0.05972, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.750, tt:3002.976\n",
      "Ep:84, loss:0.00003, loss_test:0.05950, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.756, tt:3039.272\n",
      "Ep:85, loss:0.00003, loss_test:0.05857, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.766, tt:3075.835\n",
      "Ep:86, loss:0.00003, loss_test:0.05926, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:35.791, tt:3113.781\n",
      "Ep:87, loss:0.00003, loss_test:0.05847, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.819, tt:3152.099\n",
      "Ep:88, loss:0.00003, loss_test:0.05690, lr:9.90e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.841, tt:3189.879\n",
      "Ep:89, loss:0.00003, loss_test:0.05714, lr:9.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.845, tt:3226.058\n",
      "Ep:90, loss:0.00003, loss_test:0.05944, lr:9.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.856, tt:3262.861\n",
      "Ep:91, loss:0.00003, loss_test:0.05501, lr:9.61e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.869, tt:3299.961\n",
      "Ep:92, loss:0.00003, loss_test:0.05966, lr:9.51e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.879, tt:3336.771\n",
      "Ep:93, loss:0.00003, loss_test:0.05585, lr:9.41e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.885, tt:3373.146\n",
      "Ep:94, loss:0.00003, loss_test:0.05805, lr:9.32e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.886, tt:3409.183\n",
      "Ep:95, loss:0.00002, loss_test:0.05445, lr:9.23e-03, fs:0.85083 (r=0.778,p=0.939),  time:35.865, tt:3443.010\n",
      "Ep:96, loss:0.00002, loss_test:0.05929, lr:9.14e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.851, tt:3477.570\n",
      "Ep:97, loss:0.00002, loss_test:0.05228, lr:9.04e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.862, tt:3514.512\n",
      "Ep:98, loss:0.00002, loss_test:0.05949, lr:8.95e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.862, tt:3550.367\n",
      "Ep:99, loss:0.00002, loss_test:0.05486, lr:8.86e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.858, tt:3585.810\n",
      "Ep:100, loss:0.00002, loss_test:0.05374, lr:8.78e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.864, tt:3622.281\n",
      "Ep:101, loss:0.00002, loss_test:0.05895, lr:8.69e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.857, tt:3657.437\n",
      "Ep:102, loss:0.00002, loss_test:0.05557, lr:8.60e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.845, tt:3692.009\n",
      "Ep:103, loss:0.00002, loss_test:0.05468, lr:8.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:35.846, tt:3728.004\n",
      "Ep:104, loss:0.00002, loss_test:0.05647, lr:8.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.854, tt:3764.702\n",
      "Ep:105, loss:0.00002, loss_test:0.05351, lr:8.35e-03, fs:0.86813 (r=0.798,p=0.952),  time:35.855, tt:3800.589\n",
      "Ep:106, loss:0.00002, loss_test:0.05915, lr:8.26e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.844, tt:3835.328\n",
      "Ep:107, loss:0.00002, loss_test:0.05574, lr:8.18e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.849, tt:3871.698\n",
      "Ep:108, loss:0.00002, loss_test:0.05665, lr:8.10e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.838, tt:3906.344\n",
      "Ep:109, loss:0.00002, loss_test:0.05433, lr:8.02e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.833, tt:3941.675\n",
      "Ep:110, loss:0.00002, loss_test:0.05840, lr:7.94e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.841, tt:3978.390\n",
      "Ep:111, loss:0.00002, loss_test:0.05347, lr:7.86e-03, fs:0.89130 (r=0.828,p=0.965),  time:35.842, tt:4014.252\n",
      "Ep:112, loss:0.00002, loss_test:0.05894, lr:7.78e-03, fs:0.86667 (r=0.788,p=0.963),  time:35.844, tt:4050.335\n",
      "Ep:113, loss:0.00002, loss_test:0.05508, lr:7.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.859, tt:4087.877\n",
      "Ep:114, loss:0.00002, loss_test:0.05667, lr:7.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.880, tt:4126.155\n",
      "Ep:115, loss:0.00002, loss_test:0.05543, lr:7.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.878, tt:4161.809\n",
      "Ep:116, loss:0.00002, loss_test:0.05897, lr:7.47e-03, fs:0.85227 (r=0.758,p=0.974),  time:35.888, tt:4198.940\n",
      "Ep:117, loss:0.00002, loss_test:0.05611, lr:7.40e-03, fs:0.86188 (r=0.788,p=0.951),  time:35.895, tt:4235.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:118, loss:0.00002, loss_test:0.05735, lr:7.32e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.900, tt:4272.070\n",
      "Ep:119, loss:0.00002, loss_test:0.05573, lr:7.25e-03, fs:0.88043 (r=0.818,p=0.953),  time:35.911, tt:4309.295\n",
      "Ep:120, loss:0.00002, loss_test:0.05947, lr:7.18e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.928, tt:4347.234\n",
      "Ep:121, loss:0.00002, loss_test:0.05419, lr:7.11e-03, fs:0.89247 (r=0.838,p=0.954),  time:35.943, tt:4385.037\n",
      "Ep:122, loss:0.00001, loss_test:0.05687, lr:7.03e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.953, tt:4422.263\n",
      "Ep:123, loss:0.00001, loss_test:0.05608, lr:6.96e-03, fs:0.85556 (r=0.778,p=0.951),  time:35.949, tt:4457.709\n",
      "Ep:124, loss:0.00001, loss_test:0.05568, lr:6.89e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.954, tt:4494.206\n",
      "Ep:125, loss:0.00001, loss_test:0.05633, lr:6.83e-03, fs:0.86034 (r=0.778,p=0.963),  time:35.965, tt:4531.550\n",
      "Ep:126, loss:0.00001, loss_test:0.05564, lr:6.76e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.974, tt:4568.732\n",
      "Ep:127, loss:0.00001, loss_test:0.05603, lr:6.69e-03, fs:0.89730 (r=0.838,p=0.965),  time:35.982, tt:4605.711\n",
      "Ep:128, loss:0.00001, loss_test:0.05507, lr:6.62e-03, fs:0.86517 (r=0.778,p=0.975),  time:35.979, tt:4641.348\n",
      "Ep:129, loss:0.00001, loss_test:0.05698, lr:6.56e-03, fs:0.87778 (r=0.798,p=0.975),  time:35.995, tt:4679.412\n",
      "Ep:130, loss:0.00001, loss_test:0.05447, lr:6.49e-03, fs:0.87151 (r=0.788,p=0.975),  time:36.009, tt:4717.187\n",
      "Ep:131, loss:0.00001, loss_test:0.05694, lr:6.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.002, tt:4752.295\n",
      "Ep:132, loss:0.00001, loss_test:0.05484, lr:6.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.008, tt:4789.099\n",
      "Ep:133, loss:0.00001, loss_test:0.05697, lr:6.30e-03, fs:0.87778 (r=0.798,p=0.975),  time:36.023, tt:4827.031\n",
      "Ep:134, loss:0.00001, loss_test:0.05494, lr:6.24e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.010, tt:4861.284\n",
      "Ep:135, loss:0.00001, loss_test:0.05678, lr:6.17e-03, fs:0.87778 (r=0.798,p=0.975),  time:36.014, tt:4897.943\n",
      "Ep:136, loss:0.00001, loss_test:0.05453, lr:6.11e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.010, tt:4933.334\n",
      "Ep:137, loss:0.00001, loss_test:0.05636, lr:6.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.020, tt:4970.801\n",
      "Ep:138, loss:0.00001, loss_test:0.05593, lr:5.99e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.016, tt:5006.158\n",
      "Ep:139, loss:0.00001, loss_test:0.05599, lr:5.93e-03, fs:0.88525 (r=0.818,p=0.964),  time:36.048, tt:5046.669\n",
      "Ep:140, loss:0.00001, loss_test:0.05537, lr:5.87e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.052, tt:5083.391\n",
      "Ep:141, loss:0.00001, loss_test:0.05617, lr:5.81e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.056, tt:5120.005\n",
      "Ep:142, loss:0.00001, loss_test:0.05544, lr:5.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.057, tt:5156.107\n",
      "Ep:143, loss:0.00001, loss_test:0.05529, lr:5.70e-03, fs:0.87151 (r=0.788,p=0.975),  time:36.072, tt:5194.310\n",
      "Ep:144, loss:0.00001, loss_test:0.05566, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.069, tt:5230.064\n",
      "Ep:145, loss:0.00001, loss_test:0.05620, lr:5.58e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.074, tt:5266.768\n",
      "Ep:146, loss:0.00001, loss_test:0.05508, lr:5.53e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.079, tt:5303.655\n",
      "Ep:147, loss:0.00001, loss_test:0.05604, lr:5.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.081, tt:5339.982\n",
      "Ep:148, loss:0.00001, loss_test:0.05661, lr:5.42e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.090, tt:5377.394\n",
      "Ep:149, loss:0.00001, loss_test:0.05443, lr:5.36e-03, fs:0.90811 (r=0.848,p=0.977),  time:36.085, tt:5412.821\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00001, loss_test:0.05613, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.088, tt:5449.266\n",
      "Ep:151, loss:0.00001, loss_test:0.05546, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.088, tt:5485.371\n",
      "Ep:152, loss:0.00001, loss_test:0.05571, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.103, tt:5523.691\n",
      "Ep:153, loss:0.00001, loss_test:0.05581, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.107, tt:5560.483\n",
      "Ep:154, loss:0.00001, loss_test:0.05495, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.108, tt:5596.687\n",
      "Ep:155, loss:0.00001, loss_test:0.05574, lr:5.36e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.104, tt:5632.218\n",
      "Ep:156, loss:0.00001, loss_test:0.05488, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.116, tt:5670.289\n",
      "Ep:157, loss:0.00001, loss_test:0.05697, lr:5.36e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.120, tt:5706.891\n",
      "Ep:158, loss:0.00001, loss_test:0.05488, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.123, tt:5743.501\n",
      "Ep:159, loss:0.00001, loss_test:0.05601, lr:5.36e-03, fs:0.89011 (r=0.818,p=0.976),  time:36.119, tt:5779.094\n",
      "Ep:160, loss:0.00001, loss_test:0.05488, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.127, tt:5816.426\n",
      "Ep:161, loss:0.00001, loss_test:0.05706, lr:5.31e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.121, tt:5851.585\n",
      "Ep:162, loss:0.00001, loss_test:0.05497, lr:5.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.128, tt:5888.899\n",
      "Ep:163, loss:0.00001, loss_test:0.05610, lr:5.20e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.133, tt:5925.810\n",
      "Ep:164, loss:0.00001, loss_test:0.05572, lr:5.15e-03, fs:0.87778 (r=0.798,p=0.975),  time:36.134, tt:5962.157\n",
      "Ep:165, loss:0.00001, loss_test:0.05543, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.135, tt:5998.411\n",
      "Ep:166, loss:0.00001, loss_test:0.05583, lr:5.05e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.130, tt:6033.684\n",
      "Ep:167, loss:0.00001, loss_test:0.05507, lr:5.00e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.140, tt:6071.518\n",
      "Ep:168, loss:0.00001, loss_test:0.05579, lr:4.95e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.142, tt:6107.946\n",
      "Ep:169, loss:0.00001, loss_test:0.05491, lr:4.90e-03, fs:0.87151 (r=0.788,p=0.975),  time:36.144, tt:6144.398\n",
      "Ep:170, loss:0.00001, loss_test:0.05596, lr:4.85e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.152, tt:6181.913\n",
      "Ep:171, loss:0.00001, loss_test:0.05531, lr:4.80e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.160, tt:6219.504\n",
      "Ep:172, loss:0.00001, loss_test:0.05578, lr:4.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.161, tt:6255.885\n",
      "Ep:173, loss:0.00001, loss_test:0.05560, lr:4.71e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.164, tt:6292.456\n",
      "Ep:174, loss:0.00001, loss_test:0.05503, lr:4.66e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.165, tt:6328.918\n",
      "Ep:175, loss:0.00001, loss_test:0.05612, lr:4.61e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.169, tt:6365.825\n",
      "Ep:176, loss:0.00001, loss_test:0.05529, lr:4.57e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.167, tt:6401.542\n",
      "Ep:177, loss:0.00001, loss_test:0.05575, lr:4.52e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.179, tt:6439.777\n",
      "Ep:178, loss:0.00001, loss_test:0.05493, lr:4.48e-03, fs:0.86517 (r=0.778,p=0.975),  time:36.182, tt:6476.553\n",
      "Ep:179, loss:0.00001, loss_test:0.05580, lr:4.43e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.179, tt:6512.260\n",
      "Ep:180, loss:0.00001, loss_test:0.05649, lr:4.39e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.180, tt:6548.580\n",
      "Ep:181, loss:0.00001, loss_test:0.05544, lr:4.34e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.186, tt:6585.904\n",
      "Ep:182, loss:0.00001, loss_test:0.05584, lr:4.30e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.189, tt:6622.604\n",
      "Ep:183, loss:0.00001, loss_test:0.05553, lr:4.26e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.180, tt:6657.202\n",
      "Ep:184, loss:0.00001, loss_test:0.05557, lr:4.21e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.190, tt:6695.058\n",
      "Ep:185, loss:0.00001, loss_test:0.05561, lr:4.17e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.198, tt:6732.886\n",
      "Ep:186, loss:0.00001, loss_test:0.05559, lr:4.13e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.205, tt:6770.329\n",
      "Ep:187, loss:0.00001, loss_test:0.05566, lr:4.09e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.200, tt:6805.675\n",
      "Ep:188, loss:0.00001, loss_test:0.05548, lr:4.05e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.197, tt:6841.255\n",
      "Ep:189, loss:0.00001, loss_test:0.05637, lr:4.01e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.199, tt:6877.747\n",
      "Ep:190, loss:0.00001, loss_test:0.05563, lr:3.97e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.203, tt:6914.751\n",
      "Ep:191, loss:0.00001, loss_test:0.05608, lr:3.93e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.210, tt:6952.370\n",
      "Ep:192, loss:0.00001, loss_test:0.05571, lr:3.89e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.212, tt:6989.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:193, loss:0.00001, loss_test:0.05549, lr:3.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:36.210, tt:7024.746\n",
      "Ep:194, loss:0.00001, loss_test:0.05613, lr:3.81e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.223, tt:7063.486\n",
      "Ep:195, loss:0.00001, loss_test:0.05594, lr:3.77e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.222, tt:7099.608\n",
      "Ep:196, loss:0.00001, loss_test:0.05524, lr:3.73e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.224, tt:7136.196\n",
      "Ep:197, loss:0.00001, loss_test:0.05652, lr:3.70e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.227, tt:7172.912\n",
      "Ep:198, loss:0.00001, loss_test:0.05707, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.234, tt:7210.591\n",
      "Ep:199, loss:0.00001, loss_test:0.05585, lr:3.62e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.230, tt:7246.079\n",
      "Ep:200, loss:0.00001, loss_test:0.05657, lr:3.59e-03, fs:0.81657 (r=0.697,p=0.986),  time:36.232, tt:7282.599\n",
      "Ep:201, loss:0.00001, loss_test:0.05692, lr:3.55e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.238, tt:7320.134\n",
      "Ep:202, loss:0.00001, loss_test:0.05550, lr:3.52e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.238, tt:7356.318\n",
      "Ep:203, loss:0.00001, loss_test:0.05651, lr:3.48e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.234, tt:7391.838\n",
      "Ep:204, loss:0.00001, loss_test:0.05662, lr:3.45e-03, fs:0.83041 (r=0.717,p=0.986),  time:36.235, tt:7428.081\n",
      "Ep:205, loss:0.00001, loss_test:0.05571, lr:3.41e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.235, tt:7464.333\n",
      "Ep:206, loss:0.00001, loss_test:0.05699, lr:3.38e-03, fs:0.86364 (r=0.768,p=0.987),  time:36.238, tt:7501.216\n",
      "Ep:207, loss:0.00001, loss_test:0.05661, lr:3.34e-03, fs:0.85714 (r=0.758,p=0.987),  time:36.239, tt:7537.642\n",
      "Ep:208, loss:0.00001, loss_test:0.05577, lr:3.31e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.240, tt:7574.169\n",
      "Ep:209, loss:0.00001, loss_test:0.05680, lr:3.28e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.237, tt:7609.778\n",
      "Ep:210, loss:0.00001, loss_test:0.05597, lr:3.24e-03, fs:0.87006 (r=0.778,p=0.987),  time:36.234, tt:7645.381\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02149, lr:6.00e-02, fs:0.64368 (r=0.848,p=0.519),  time:32.415, tt:32.415\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02376, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.520, tt:65.041\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.093, tt:96.278\n",
      "Ep:3, loss:0.00005, loss_test:0.02591, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.002, tt:124.009\n",
      "Ep:4, loss:0.00005, loss_test:0.02479, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.414, tt:157.068\n",
      "Ep:5, loss:0.00005, loss_test:0.02302, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:30.889, tt:185.332\n",
      "Ep:6, loss:0.00004, loss_test:0.02124, lr:6.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:30.341, tt:212.384\n",
      "Ep:7, loss:0.00004, loss_test:0.02016, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:30.177, tt:241.415\n",
      "Ep:8, loss:0.00004, loss_test:0.01964, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:30.589, tt:275.303\n",
      "Ep:9, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.66412 (r=0.879,p=0.534),  time:30.773, tt:307.730\n",
      "Ep:10, loss:0.00004, loss_test:0.01896, lr:6.00e-02, fs:0.69853 (r=0.960,p=0.549),  time:30.912, tt:340.029\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.70803 (r=0.980,p=0.554),  time:30.807, tt:369.689\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01833, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:30.954, tt:402.407\n",
      "Ep:13, loss:0.00004, loss_test:0.01802, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:31.092, tt:435.285\n",
      "Ep:14, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.69767 (r=0.909,p=0.566),  time:31.375, tt:470.624\n",
      "Ep:15, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:31.551, tt:504.816\n",
      "Ep:16, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:31.791, tt:540.447\n",
      "Ep:17, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:31.843, tt:573.174\n",
      "Ep:18, loss:0.00003, loss_test:0.01790, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:32.004, tt:608.085\n",
      "Ep:19, loss:0.00003, loss_test:0.01787, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:32.163, tt:643.252\n",
      "Ep:20, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:32.287, tt:678.019\n",
      "Ep:21, loss:0.00003, loss_test:0.01767, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:32.425, tt:713.354\n",
      "Ep:22, loss:0.00003, loss_test:0.01748, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:32.513, tt:747.797\n",
      "Ep:23, loss:0.00003, loss_test:0.01733, lr:5.94e-02, fs:0.69421 (r=0.848,p=0.587),  time:32.614, tt:782.735\n",
      "Ep:24, loss:0.00003, loss_test:0.01716, lr:5.88e-02, fs:0.69710 (r=0.848,p=0.592),  time:32.664, tt:816.590\n",
      "Ep:25, loss:0.00003, loss_test:0.01700, lr:5.82e-02, fs:0.69748 (r=0.838,p=0.597),  time:32.786, tt:852.444\n",
      "Ep:26, loss:0.00002, loss_test:0.01696, lr:5.76e-02, fs:0.70042 (r=0.838,p=0.601),  time:32.928, tt:889.052\n",
      "Ep:27, loss:0.00002, loss_test:0.01692, lr:5.71e-02, fs:0.70940 (r=0.838,p=0.615),  time:33.048, tt:925.352\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01683, lr:5.71e-02, fs:0.71245 (r=0.838,p=0.619),  time:33.118, tt:960.420\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01673, lr:5.71e-02, fs:0.71053 (r=0.818,p=0.628),  time:33.206, tt:996.173\n",
      "Ep:30, loss:0.00002, loss_test:0.01669, lr:5.71e-02, fs:0.71681 (r=0.818,p=0.638),  time:33.307, tt:1032.520\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01650, lr:5.71e-02, fs:0.72000 (r=0.818,p=0.643),  time:33.384, tt:1068.295\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01647, lr:5.71e-02, fs:0.72000 (r=0.818,p=0.643),  time:33.430, tt:1103.178\n",
      "Ep:33, loss:0.00002, loss_test:0.01652, lr:5.71e-02, fs:0.72321 (r=0.818,p=0.648),  time:33.474, tt:1138.105\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01647, lr:5.71e-02, fs:0.72973 (r=0.818,p=0.659),  time:33.541, tt:1173.946\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01634, lr:5.71e-02, fs:0.73543 (r=0.828,p=0.661),  time:33.600, tt:1209.584\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01632, lr:5.71e-02, fs:0.74208 (r=0.828,p=0.672),  time:33.650, tt:1245.041\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01624, lr:5.71e-02, fs:0.74208 (r=0.828,p=0.672),  time:33.731, tt:1281.797\n",
      "Ep:38, loss:0.00002, loss_test:0.01621, lr:5.71e-02, fs:0.74545 (r=0.828,p=0.678),  time:33.793, tt:1317.927\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01611, lr:5.71e-02, fs:0.75576 (r=0.828,p=0.695),  time:33.845, tt:1353.818\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01600, lr:5.71e-02, fs:0.75576 (r=0.828,p=0.695),  time:33.920, tt:1390.717\n",
      "Ep:41, loss:0.00002, loss_test:0.01592, lr:5.71e-02, fs:0.75926 (r=0.828,p=0.701),  time:33.959, tt:1426.296\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01582, lr:5.71e-02, fs:0.75576 (r=0.828,p=0.695),  time:34.012, tt:1462.536\n",
      "Ep:43, loss:0.00002, loss_test:0.01577, lr:5.71e-02, fs:0.76279 (r=0.828,p=0.707),  time:34.029, tt:1497.278\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00002, loss_test:0.01577, lr:5.71e-02, fs:0.76995 (r=0.828,p=0.719),  time:34.083, tt:1533.723\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01574, lr:5.71e-02, fs:0.76995 (r=0.828,p=0.719),  time:34.103, tt:1568.733\n",
      "Ep:46, loss:0.00001, loss_test:0.01571, lr:5.71e-02, fs:0.77358 (r=0.828,p=0.726),  time:34.131, tt:1604.144\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01566, lr:5.71e-02, fs:0.77143 (r=0.818,p=0.730),  time:34.125, tt:1637.988\n",
      "Ep:48, loss:0.00001, loss_test:0.01568, lr:5.71e-02, fs:0.78095 (r=0.828,p=0.739),  time:34.136, tt:1672.675\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01567, lr:5.71e-02, fs:0.77885 (r=0.818,p=0.743),  time:34.166, tt:1708.309\n",
      "Ep:50, loss:0.00001, loss_test:0.01568, lr:5.71e-02, fs:0.78261 (r=0.818,p=0.750),  time:34.184, tt:1743.385\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01567, lr:5.71e-02, fs:0.78641 (r=0.818,p=0.757),  time:34.199, tt:1778.353\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01582, lr:5.71e-02, fs:0.78431 (r=0.808,p=0.762),  time:34.263, tt:1815.956\n",
      "Ep:53, loss:0.00001, loss_test:0.01594, lr:5.71e-02, fs:0.78431 (r=0.808,p=0.762),  time:34.331, tt:1853.851\n",
      "Ep:54, loss:0.00001, loss_test:0.01599, lr:5.71e-02, fs:0.78818 (r=0.808,p=0.769),  time:34.360, tt:1889.786\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01611, lr:5.71e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.392, tt:1925.972\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01617, lr:5.71e-02, fs:0.79208 (r=0.808,p=0.777),  time:34.411, tt:1961.411\n",
      "Ep:57, loss:0.00001, loss_test:0.01616, lr:5.71e-02, fs:0.79602 (r=0.808,p=0.784),  time:34.435, tt:1997.210\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01639, lr:5.71e-02, fs:0.79602 (r=0.808,p=0.784),  time:34.436, tt:2031.705\n",
      "Ep:59, loss:0.00001, loss_test:0.01636, lr:5.71e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.472, tt:2068.292\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01647, lr:5.71e-02, fs:0.79602 (r=0.808,p=0.784),  time:34.481, tt:2103.335\n",
      "Ep:61, loss:0.00001, loss_test:0.01649, lr:5.71e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.490, tt:2138.407\n",
      "Ep:62, loss:0.00001, loss_test:0.01660, lr:5.71e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.501, tt:2173.538\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01683, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.538, tt:2210.444\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01684, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.541, tt:2245.132\n",
      "Ep:65, loss:0.00001, loss_test:0.01691, lr:5.71e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.561, tt:2281.042\n",
      "Ep:66, loss:0.00001, loss_test:0.01708, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.571, tt:2316.237\n",
      "Ep:67, loss:0.00001, loss_test:0.01724, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.602, tt:2352.952\n",
      "Ep:68, loss:0.00001, loss_test:0.01723, lr:5.71e-02, fs:0.81633 (r=0.808,p=0.825),  time:34.641, tt:2390.228\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01747, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.656, tt:2425.954\n",
      "Ep:70, loss:0.00001, loss_test:0.01773, lr:5.71e-02, fs:0.81633 (r=0.808,p=0.825),  time:34.685, tt:2462.601\n",
      "Ep:71, loss:0.00001, loss_test:0.01782, lr:5.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:34.698, tt:2498.244\n",
      "Ep:72, loss:0.00001, loss_test:0.01789, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.705, tt:2533.472\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01794, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.721, tt:2569.346\n",
      "Ep:74, loss:0.00001, loss_test:0.01821, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.728, tt:2604.593\n",
      "Ep:75, loss:0.00001, loss_test:0.01846, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.761, tt:2641.832\n",
      "Ep:76, loss:0.00001, loss_test:0.01841, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.795, tt:2679.239\n",
      "Ep:77, loss:0.00001, loss_test:0.01869, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.849, tt:2718.189\n",
      "Ep:78, loss:0.00001, loss_test:0.01895, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.860, tt:2753.954\n",
      "Ep:79, loss:0.00001, loss_test:0.01889, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.887, tt:2790.925\n",
      "Ep:80, loss:0.00001, loss_test:0.01919, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.904, tt:2827.241\n",
      "Ep:81, loss:0.00001, loss_test:0.01925, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.920, tt:2863.445\n",
      "Ep:82, loss:0.00001, loss_test:0.01949, lr:5.71e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.926, tt:2898.852\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01975, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.951, tt:2935.921\n",
      "Ep:84, loss:0.00001, loss_test:0.01959, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.955, tt:2971.132\n",
      "Ep:85, loss:0.00001, loss_test:0.01990, lr:5.71e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.962, tt:3006.732\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.02006, lr:5.71e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.984, tt:3043.595\n",
      "Ep:87, loss:0.00001, loss_test:0.02006, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.990, tt:3079.086\n",
      "Ep:88, loss:0.00001, loss_test:0.02045, lr:5.71e-02, fs:0.82474 (r=0.808,p=0.842),  time:35.000, tt:3115.014\n",
      "Ep:89, loss:0.00001, loss_test:0.02060, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:35.003, tt:3150.306\n",
      "Ep:90, loss:0.00001, loss_test:0.02098, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.976, tt:3182.775\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.02083, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.964, tt:3216.706\n",
      "Ep:92, loss:0.00001, loss_test:0.02107, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.951, tt:3250.477\n",
      "Ep:93, loss:0.00001, loss_test:0.02136, lr:5.71e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.943, tt:3284.632\n",
      "Ep:94, loss:0.00000, loss_test:0.02150, lr:5.71e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.929, tt:3318.229\n",
      "Ep:95, loss:0.00000, loss_test:0.02196, lr:5.71e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.931, tt:3353.419\n",
      "Ep:96, loss:0.00000, loss_test:0.02195, lr:5.71e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.919, tt:3387.131\n",
      "Ep:97, loss:0.00000, loss_test:0.02206, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.886, tt:3418.865\n",
      "Ep:98, loss:0.00000, loss_test:0.02234, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.868, tt:3451.965\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00000, loss_test:0.02276, lr:5.71e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.864, tt:3486.391\n",
      "Ep:100, loss:0.00000, loss_test:0.02258, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.859, tt:3520.765\n",
      "Ep:101, loss:0.00000, loss_test:0.02279, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.842, tt:3553.856\n",
      "Ep:102, loss:0.00000, loss_test:0.02310, lr:5.71e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.832, tt:3587.700\n",
      "Ep:103, loss:0.00000, loss_test:0.02322, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.831, tt:3622.431\n",
      "Ep:104, loss:0.00000, loss_test:0.02292, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.839, tt:3658.070\n",
      "Ep:105, loss:0.00000, loss_test:0.02352, lr:5.71e-02, fs:0.83077 (r=0.818,p=0.844),  time:34.840, tt:3693.026\n",
      "Ep:106, loss:0.00000, loss_test:0.02392, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.828, tt:3726.565\n",
      "Ep:107, loss:0.00000, loss_test:0.02330, lr:5.71e-02, fs:0.83770 (r=0.808,p=0.870),  time:34.841, tt:3762.811\n",
      "Ep:108, loss:0.00000, loss_test:0.02400, lr:5.71e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.824, tt:3795.781\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.02415, lr:5.71e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.833, tt:3831.660\n",
      "Ep:110, loss:0.00000, loss_test:0.02408, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.836, tt:3866.798\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.02464, lr:5.71e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.839, tt:3901.924\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:112, loss:0.00000, loss_test:0.02458, lr:5.71e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.837, tt:3936.589\n",
      "Ep:113, loss:0.00000, loss_test:0.02445, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.842, tt:3972.011\n",
      "Ep:114, loss:0.00000, loss_test:0.02486, lr:5.71e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.843, tt:4006.890\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.02494, lr:5.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.843, tt:4041.808\n",
      "Ep:116, loss:0.00000, loss_test:0.02479, lr:5.71e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.844, tt:4076.715\n",
      "Ep:117, loss:0.00000, loss_test:0.02511, lr:5.71e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.838, tt:4110.924\n",
      "Ep:118, loss:0.00000, loss_test:0.02537, lr:5.71e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.832, tt:4145.056\n",
      "Ep:119, loss:0.00000, loss_test:0.02509, lr:5.71e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.835, tt:4180.247\n",
      "Ep:120, loss:0.00000, loss_test:0.02516, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.826, tt:4213.921\n",
      "Ep:121, loss:0.00000, loss_test:0.02568, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.839, tt:4250.300\n",
      "Ep:122, loss:0.00000, loss_test:0.02589, lr:5.71e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.838, tt:4285.044\n",
      "Ep:123, loss:0.00000, loss_test:0.02585, lr:5.71e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.832, tt:4319.204\n",
      "Ep:124, loss:0.00000, loss_test:0.02584, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.825, tt:4353.091\n",
      "Ep:125, loss:0.00000, loss_test:0.02596, lr:5.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.830, tt:4388.586\n",
      "Ep:126, loss:0.00000, loss_test:0.02601, lr:5.65e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.852, tt:4426.193\n",
      "Ep:127, loss:0.00000, loss_test:0.02628, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.849, tt:4460.653\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.02629, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.856, tt:4496.480\n",
      "Ep:129, loss:0.00000, loss_test:0.02608, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.850, tt:4530.520\n",
      "Ep:130, loss:0.00000, loss_test:0.02673, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.871, tt:4568.148\n",
      "Ep:131, loss:0.00000, loss_test:0.02670, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.870, tt:4602.866\n",
      "Ep:132, loss:0.00000, loss_test:0.02587, lr:5.59e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.868, tt:4637.475\n",
      "Ep:133, loss:0.00000, loss_test:0.02666, lr:5.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.867, tt:4672.179\n",
      "Ep:134, loss:0.00000, loss_test:0.02669, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.878, tt:4708.467\n",
      "Ep:135, loss:0.00000, loss_test:0.02620, lr:5.59e-02, fs:0.85714 (r=0.818,p=0.900),  time:34.873, tt:4742.794\n",
      "Ep:136, loss:0.00000, loss_test:0.02674, lr:5.59e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.876, tt:4778.072\n",
      "Ep:137, loss:0.00000, loss_test:0.02711, lr:5.59e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.881, tt:4813.599\n",
      "Ep:138, loss:0.00000, loss_test:0.02697, lr:5.59e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.895, tt:4850.349\n",
      "Ep:139, loss:0.00000, loss_test:0.02669, lr:5.54e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.895, tt:4885.264\n",
      "Ep:140, loss:0.00000, loss_test:0.02731, lr:5.48e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.904, tt:4921.433\n",
      "Ep:141, loss:0.00000, loss_test:0.02751, lr:5.43e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.903, tt:4956.241\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00000, loss_test:0.02722, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.906, tt:4991.623\n",
      "Ep:143, loss:0.00000, loss_test:0.02745, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.914, tt:5027.658\n",
      "Ep:144, loss:0.00000, loss_test:0.02744, lr:5.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.926, tt:5064.250\n",
      "Ep:145, loss:0.00000, loss_test:0.02749, lr:5.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.931, tt:5099.895\n",
      "Ep:146, loss:0.00000, loss_test:0.02797, lr:5.43e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.928, tt:5134.362\n",
      "Ep:147, loss:0.00000, loss_test:0.02790, lr:5.43e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.927, tt:5169.234\n",
      "Ep:148, loss:0.00000, loss_test:0.02749, lr:5.43e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.918, tt:5202.796\n",
      "Ep:149, loss:0.00000, loss_test:0.02830, lr:5.43e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.937, tt:5240.499\n",
      "Ep:150, loss:0.00000, loss_test:0.02812, lr:5.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.928, tt:5274.105\n",
      "Ep:151, loss:0.00000, loss_test:0.02762, lr:5.43e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.927, tt:5308.972\n",
      "Ep:152, loss:0.00000, loss_test:0.02837, lr:5.43e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.931, tt:5344.491\n",
      "##########Best model found so far##########\n",
      "Ep:153, loss:0.00000, loss_test:0.02828, lr:5.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.931, tt:5379.388\n",
      "Ep:154, loss:0.00000, loss_test:0.02785, lr:5.43e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.932, tt:5414.392\n",
      "Ep:155, loss:0.00000, loss_test:0.02823, lr:5.43e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.931, tt:5449.163\n",
      "Ep:156, loss:0.00000, loss_test:0.02831, lr:5.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.931, tt:5484.241\n",
      "Ep:157, loss:0.00000, loss_test:0.02829, lr:5.43e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.940, tt:5520.589\n",
      "Ep:158, loss:0.00000, loss_test:0.02814, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.935, tt:5554.631\n",
      "Ep:159, loss:0.00000, loss_test:0.02850, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.930, tt:5588.790\n",
      "Ep:160, loss:0.00000, loss_test:0.02843, lr:5.43e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.924, tt:5622.761\n",
      "Ep:161, loss:0.00000, loss_test:0.02817, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.916, tt:5656.417\n",
      "Ep:162, loss:0.00000, loss_test:0.02845, lr:5.43e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.909, tt:5690.189\n",
      "Ep:163, loss:0.00000, loss_test:0.02840, lr:5.43e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.912, tt:5725.559\n",
      "Ep:164, loss:0.00000, loss_test:0.02828, lr:5.37e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.911, tt:5760.235\n",
      "Ep:165, loss:0.00000, loss_test:0.02902, lr:5.32e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.910, tt:5795.132\n",
      "Ep:166, loss:0.00000, loss_test:0.02867, lr:5.27e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.916, tt:5830.933\n",
      "Ep:167, loss:0.00000, loss_test:0.02888, lr:5.21e-02, fs:0.87958 (r=0.848,p=0.913),  time:34.909, tt:5864.762\n",
      "Ep:168, loss:0.00000, loss_test:0.02890, lr:5.16e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.911, tt:5899.882\n",
      "Ep:169, loss:0.00000, loss_test:0.02848, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.916, tt:5935.692\n",
      "Ep:170, loss:0.00000, loss_test:0.02906, lr:5.06e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.926, tt:5972.282\n",
      "Ep:171, loss:0.00000, loss_test:0.02883, lr:5.01e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.929, tt:6007.769\n",
      "Ep:172, loss:0.00000, loss_test:0.02913, lr:4.96e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.927, tt:6042.353\n",
      "Ep:173, loss:0.00000, loss_test:0.02873, lr:4.91e-02, fs:0.86598 (r=0.848,p=0.884),  time:34.931, tt:6078.068\n",
      "Ep:174, loss:0.00000, loss_test:0.02947, lr:4.86e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.930, tt:6112.714\n",
      "Ep:175, loss:0.00000, loss_test:0.02905, lr:4.81e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.928, tt:6147.412\n",
      "Ep:176, loss:0.00000, loss_test:0.02862, lr:4.76e-02, fs:0.86598 (r=0.848,p=0.884),  time:34.928, tt:6182.318\n",
      "Ep:177, loss:0.00000, loss_test:0.02975, lr:4.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.931, tt:6217.801\n",
      "Ep:178, loss:0.00000, loss_test:0.02852, lr:4.67e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.937, tt:6253.745\n",
      "Ep:179, loss:0.00000, loss_test:0.02941, lr:4.62e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.943, tt:6289.652\n",
      "Ep:180, loss:0.00000, loss_test:0.02921, lr:4.57e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.946, tt:6325.138\n",
      "Ep:181, loss:0.00000, loss_test:0.02878, lr:4.53e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.958, tt:6362.310\n",
      "Ep:182, loss:0.00000, loss_test:0.02980, lr:4.48e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.953, tt:6396.475\n",
      "Ep:183, loss:0.00000, loss_test:0.02889, lr:4.44e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.949, tt:6430.565\n",
      "Ep:184, loss:0.00000, loss_test:0.02947, lr:4.39e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.949, tt:6465.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:185, loss:0.00000, loss_test:0.02948, lr:4.35e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.948, tt:6500.318\n",
      "Ep:186, loss:0.00000, loss_test:0.02919, lr:4.31e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.939, tt:6533.624\n",
      "Ep:187, loss:0.00000, loss_test:0.02975, lr:4.26e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.938, tt:6568.336\n",
      "Ep:188, loss:0.00000, loss_test:0.02928, lr:4.22e-02, fs:0.87500 (r=0.848,p=0.903),  time:34.941, tt:6603.827\n",
      "Ep:189, loss:0.00000, loss_test:0.02968, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.948, tt:6640.034\n",
      "Ep:190, loss:0.00000, loss_test:0.02990, lr:4.14e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.945, tt:6674.468\n",
      "Ep:191, loss:0.00000, loss_test:0.02947, lr:4.10e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.942, tt:6708.888\n",
      "Ep:192, loss:0.00000, loss_test:0.03014, lr:4.05e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.965, tt:6748.263\n",
      "Ep:193, loss:0.00000, loss_test:0.02934, lr:4.01e-02, fs:0.86316 (r=0.828,p=0.901),  time:34.966, tt:6783.365\n",
      "Ep:194, loss:0.00000, loss_test:0.03012, lr:3.97e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.970, tt:6819.064\n",
      "Ep:195, loss:0.00000, loss_test:0.02978, lr:3.93e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.965, tt:6853.234\n",
      "Ep:196, loss:0.00000, loss_test:0.02987, lr:3.89e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.962, tt:6887.478\n",
      "Ep:197, loss:0.00000, loss_test:0.03005, lr:3.86e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.958, tt:6921.613\n",
      "Ep:198, loss:0.00000, loss_test:0.02974, lr:3.82e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.955, tt:6956.023\n",
      "Ep:199, loss:0.00000, loss_test:0.03018, lr:3.78e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.959, tt:6991.758\n",
      "Ep:200, loss:0.00000, loss_test:0.02995, lr:3.74e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.963, tt:7027.472\n",
      "Ep:201, loss:0.00000, loss_test:0.03009, lr:3.70e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.962, tt:7062.339\n",
      "Ep:202, loss:0.00000, loss_test:0.03004, lr:3.67e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.951, tt:7095.135\n",
      "Ep:203, loss:0.00000, loss_test:0.03006, lr:3.63e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.943, tt:7128.333\n",
      "Ep:204, loss:0.00000, loss_test:0.03012, lr:3.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.945, tt:7163.721\n",
      "Ep:205, loss:0.00000, loss_test:0.03001, lr:3.56e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.944, tt:7198.528\n",
      "Ep:206, loss:0.00000, loss_test:0.03031, lr:3.52e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.943, tt:7233.270\n",
      "Ep:207, loss:0.00000, loss_test:0.02994, lr:3.49e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.949, tt:7269.400\n",
      "Ep:208, loss:0.00000, loss_test:0.03036, lr:3.45e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.962, tt:7306.972\n",
      "Ep:209, loss:0.00000, loss_test:0.02996, lr:3.42e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.949, tt:7339.368\n",
      "Ep:210, loss:0.00000, loss_test:0.03052, lr:3.38e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.949, tt:7374.336\n",
      "Ep:211, loss:0.00000, loss_test:0.02998, lr:3.35e-02, fs:0.86911 (r=0.838,p=0.902),  time:34.956, tt:7410.595\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13928, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:34.980, tt:34.980\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13714, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:35.005, tt:70.009\n",
      "Ep:2, loss:0.00027, loss_test:0.13376, lr:1.00e-02, fs:0.63799 (r=0.899,p=0.494),  time:34.469, tt:103.408\n",
      "Ep:3, loss:0.00026, loss_test:0.12878, lr:1.00e-02, fs:0.64151 (r=0.859,p=0.512),  time:34.448, tt:137.791\n",
      "Ep:4, loss:0.00025, loss_test:0.12484, lr:1.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:33.782, tt:168.911\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12265, lr:1.00e-02, fs:0.68050 (r=0.828,p=0.577),  time:33.446, tt:200.676\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12150, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:33.982, tt:237.871\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12010, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:34.402, tt:275.215\n",
      "Ep:8, loss:0.00024, loss_test:0.11827, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:34.643, tt:311.786\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11571, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:34.493, tt:344.928\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00023, loss_test:0.11420, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:34.533, tt:379.865\n",
      "Ep:11, loss:0.00022, loss_test:0.11320, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:34.488, tt:413.856\n",
      "Ep:12, loss:0.00021, loss_test:0.11157, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:34.703, tt:451.143\n",
      "Ep:13, loss:0.00021, loss_test:0.11007, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:34.749, tt:486.485\n",
      "Ep:14, loss:0.00020, loss_test:0.10884, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:34.888, tt:523.323\n",
      "Ep:15, loss:0.00020, loss_test:0.10724, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:35.020, tt:560.319\n",
      "Ep:16, loss:0.00019, loss_test:0.10569, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:35.131, tt:597.230\n",
      "Ep:17, loss:0.00018, loss_test:0.10393, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:35.356, tt:636.412\n",
      "Ep:18, loss:0.00018, loss_test:0.10230, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:35.357, tt:671.783\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.10099, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:35.440, tt:708.796\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.09978, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:35.482, tt:745.126\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09845, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:35.506, tt:781.127\n",
      "Ep:22, loss:0.00016, loss_test:0.09733, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:35.630, tt:819.495\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09621, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:35.707, tt:856.975\n",
      "Ep:24, loss:0.00015, loss_test:0.09508, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:35.715, tt:892.885\n",
      "Ep:25, loss:0.00015, loss_test:0.09391, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:35.730, tt:928.968\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.09263, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:35.763, tt:965.595\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00014, loss_test:0.09167, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:35.788, tt:1002.054\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.09049, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:35.852, tt:1039.716\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.08944, lr:1.00e-02, fs:0.75962 (r=0.798,p=0.725),  time:35.895, tt:1076.851\n",
      "Ep:30, loss:0.00013, loss_test:0.08878, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:35.914, tt:1113.327\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.08790, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:35.939, tt:1150.050\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08753, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:35.940, tt:1186.006\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.08630, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:35.939, tt:1221.932\n",
      "Ep:34, loss:0.00012, loss_test:0.08603, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:35.929, tt:1257.499\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08465, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.946, tt:1294.040\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08368, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:36.003, tt:1332.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:37, loss:0.00011, loss_test:0.08398, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.998, tt:1367.929\n",
      "Ep:38, loss:0.00011, loss_test:0.08354, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:36.015, tt:1404.580\n",
      "Ep:39, loss:0.00011, loss_test:0.08232, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:36.029, tt:1441.179\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08269, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:36.031, tt:1477.277\n",
      "Ep:41, loss:0.00010, loss_test:0.08229, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:36.033, tt:1513.401\n",
      "Ep:42, loss:0.00010, loss_test:0.08261, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:36.019, tt:1548.833\n",
      "Ep:43, loss:0.00010, loss_test:0.08034, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:36.021, tt:1584.913\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.08117, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:36.028, tt:1621.241\n",
      "Ep:45, loss:0.00009, loss_test:0.07990, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:36.027, tt:1657.244\n",
      "Ep:46, loss:0.00009, loss_test:0.07835, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:36.051, tt:1694.375\n",
      "Ep:47, loss:0.00009, loss_test:0.08083, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:36.078, tt:1731.737\n",
      "Ep:48, loss:0.00009, loss_test:0.08097, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:36.093, tt:1768.535\n",
      "Ep:49, loss:0.00008, loss_test:0.08008, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:36.093, tt:1804.660\n",
      "Ep:50, loss:0.00008, loss_test:0.07857, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:36.092, tt:1840.715\n",
      "Ep:51, loss:0.00008, loss_test:0.08034, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:36.082, tt:1876.285\n",
      "Ep:52, loss:0.00008, loss_test:0.07939, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:36.108, tt:1913.703\n",
      "Ep:53, loss:0.00008, loss_test:0.07872, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.095, tt:1949.123\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07881, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.144, tt:1987.912\n",
      "Ep:55, loss:0.00007, loss_test:0.07652, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.178, tt:2025.967\n",
      "Ep:56, loss:0.00007, loss_test:0.07847, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:36.159, tt:2061.039\n",
      "Ep:57, loss:0.00007, loss_test:0.07809, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:36.149, tt:2096.658\n",
      "Ep:58, loss:0.00007, loss_test:0.07768, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:36.110, tt:2130.519\n",
      "Ep:59, loss:0.00006, loss_test:0.07956, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:36.123, tt:2167.376\n",
      "Ep:60, loss:0.00006, loss_test:0.07381, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:36.122, tt:2203.447\n",
      "Ep:61, loss:0.00007, loss_test:0.07187, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:36.107, tt:2238.611\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.07938, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:36.100, tt:2274.316\n",
      "Ep:63, loss:0.00007, loss_test:0.07383, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:36.077, tt:2308.935\n",
      "Ep:64, loss:0.00006, loss_test:0.07556, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.092, tt:2345.961\n",
      "Ep:65, loss:0.00006, loss_test:0.07231, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:36.101, tt:2382.693\n",
      "Ep:66, loss:0.00006, loss_test:0.07186, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.110, tt:2419.378\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00006, loss_test:0.07599, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:36.099, tt:2454.724\n",
      "Ep:68, loss:0.00006, loss_test:0.07686, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.107, tt:2491.411\n",
      "Ep:69, loss:0.00006, loss_test:0.07275, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:36.093, tt:2526.532\n",
      "Ep:70, loss:0.00005, loss_test:0.07644, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.098, tt:2562.963\n",
      "Ep:71, loss:0.00006, loss_test:0.07490, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:36.082, tt:2597.922\n",
      "Ep:72, loss:0.00005, loss_test:0.07095, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:36.079, tt:2633.767\n",
      "Ep:73, loss:0.00005, loss_test:0.07612, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:36.067, tt:2668.963\n",
      "Ep:74, loss:0.00005, loss_test:0.07238, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.060, tt:2704.536\n",
      "Ep:75, loss:0.00005, loss_test:0.07627, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.051, tt:2739.863\n",
      "Ep:76, loss:0.00005, loss_test:0.07480, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:36.050, tt:2775.887\n",
      "Ep:77, loss:0.00005, loss_test:0.07511, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:36.048, tt:2811.739\n",
      "Ep:78, loss:0.00004, loss_test:0.07502, lr:9.90e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.046, tt:2847.628\n",
      "Ep:79, loss:0.00004, loss_test:0.07365, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:36.054, tt:2884.342\n",
      "Ep:80, loss:0.00004, loss_test:0.07453, lr:9.70e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.044, tt:2919.597\n",
      "Ep:81, loss:0.00004, loss_test:0.07834, lr:9.61e-03, fs:0.79793 (r=0.778,p=0.819),  time:36.033, tt:2954.669\n",
      "Ep:82, loss:0.00005, loss_test:0.07613, lr:9.51e-03, fs:0.80829 (r=0.788,p=0.830),  time:36.044, tt:2991.658\n",
      "Ep:83, loss:0.00004, loss_test:0.07310, lr:9.41e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.035, tt:3026.901\n",
      "Ep:84, loss:0.00004, loss_test:0.07556, lr:9.32e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.013, tt:3061.109\n",
      "Ep:85, loss:0.00004, loss_test:0.07522, lr:9.23e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.009, tt:3096.766\n",
      "Ep:86, loss:0.00004, loss_test:0.07589, lr:9.14e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.022, tt:3133.905\n",
      "Ep:87, loss:0.00004, loss_test:0.07225, lr:9.04e-03, fs:0.81915 (r=0.778,p=0.865),  time:36.022, tt:3169.910\n",
      "Ep:88, loss:0.00004, loss_test:0.07495, lr:8.95e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.028, tt:3206.522\n",
      "Ep:89, loss:0.00004, loss_test:0.07775, lr:8.86e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.027, tt:3242.405\n",
      "Ep:90, loss:0.00004, loss_test:0.07691, lr:8.78e-03, fs:0.80208 (r=0.778,p=0.828),  time:36.041, tt:3279.736\n",
      "Ep:91, loss:0.00004, loss_test:0.07292, lr:8.69e-03, fs:0.81915 (r=0.778,p=0.865),  time:36.047, tt:3316.320\n",
      "Ep:92, loss:0.00004, loss_test:0.07703, lr:8.60e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.009, tt:3348.852\n",
      "Ep:93, loss:0.00004, loss_test:0.07560, lr:8.51e-03, fs:0.80208 (r=0.778,p=0.828),  time:35.984, tt:3382.507\n",
      "Ep:94, loss:0.00003, loss_test:0.07539, lr:8.43e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.994, tt:3419.425\n",
      "Ep:95, loss:0.00003, loss_test:0.07560, lr:8.35e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.003, tt:3456.249\n",
      "Ep:96, loss:0.00003, loss_test:0.07606, lr:8.26e-03, fs:0.81481 (r=0.778,p=0.856),  time:35.990, tt:3491.040\n",
      "Ep:97, loss:0.00003, loss_test:0.07592, lr:8.18e-03, fs:0.81915 (r=0.778,p=0.865),  time:35.983, tt:3526.332\n",
      "Ep:98, loss:0.00003, loss_test:0.07505, lr:8.10e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.986, tt:3562.648\n",
      "Ep:99, loss:0.00003, loss_test:0.07712, lr:8.02e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.000, tt:3600.045\n",
      "Ep:100, loss:0.00003, loss_test:0.07583, lr:7.94e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.001, tt:3636.123\n",
      "Ep:101, loss:0.00003, loss_test:0.07228, lr:7.86e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.006, tt:3672.563\n",
      "Ep:102, loss:0.00003, loss_test:0.07518, lr:7.78e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.010, tt:3708.999\n",
      "Ep:103, loss:0.00003, loss_test:0.07636, lr:7.70e-03, fs:0.81481 (r=0.778,p=0.856),  time:36.007, tt:3744.683\n",
      "Ep:104, loss:0.00003, loss_test:0.07575, lr:7.62e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.986, tt:3778.506\n",
      "Ep:105, loss:0.00003, loss_test:0.07140, lr:7.55e-03, fs:0.82353 (r=0.778,p=0.875),  time:35.998, tt:3815.829\n",
      "Ep:106, loss:0.00003, loss_test:0.07594, lr:7.47e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.015, tt:3853.555\n",
      "Ep:107, loss:0.00003, loss_test:0.07493, lr:7.40e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.011, tt:3889.214\n",
      "Ep:108, loss:0.00003, loss_test:0.07436, lr:7.32e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.013, tt:3925.425\n",
      "Ep:109, loss:0.00003, loss_test:0.07581, lr:7.25e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.027, tt:3963.001\n",
      "Ep:110, loss:0.00003, loss_test:0.07477, lr:7.18e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.027, tt:3998.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:111, loss:0.00003, loss_test:0.07474, lr:7.11e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.036, tt:4036.088\n",
      "Ep:112, loss:0.00003, loss_test:0.07818, lr:7.03e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.044, tt:4072.939\n",
      "Ep:113, loss:0.00003, loss_test:0.07213, lr:6.96e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.058, tt:4110.557\n",
      "Ep:114, loss:0.00003, loss_test:0.07896, lr:6.89e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.074, tt:4148.460\n",
      "Ep:115, loss:0.00003, loss_test:0.07272, lr:6.83e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.078, tt:4185.102\n",
      "Ep:116, loss:0.00003, loss_test:0.07397, lr:6.76e-03, fs:0.83696 (r=0.778,p=0.906),  time:36.095, tt:4223.069\n",
      "Ep:117, loss:0.00003, loss_test:0.07722, lr:6.69e-03, fs:0.81053 (r=0.778,p=0.846),  time:36.108, tt:4260.696\n",
      "Ep:118, loss:0.00003, loss_test:0.07050, lr:6.62e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.111, tt:4297.158\n",
      "Ep:119, loss:0.00003, loss_test:0.07581, lr:6.56e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.120, tt:4334.437\n",
      "Ep:120, loss:0.00003, loss_test:0.07027, lr:6.49e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.139, tt:4372.820\n",
      "Ep:121, loss:0.00003, loss_test:0.07334, lr:6.43e-03, fs:0.82796 (r=0.778,p=0.885),  time:36.155, tt:4410.871\n",
      "Ep:122, loss:0.00003, loss_test:0.07269, lr:6.36e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.164, tt:4448.179\n",
      "Ep:123, loss:0.00003, loss_test:0.07503, lr:6.30e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.175, tt:4485.683\n",
      "Ep:124, loss:0.00003, loss_test:0.07170, lr:6.24e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.187, tt:4523.426\n",
      "Ep:125, loss:0.00003, loss_test:0.07558, lr:6.17e-03, fs:0.82353 (r=0.778,p=0.875),  time:36.190, tt:4559.997\n",
      "Ep:126, loss:0.00002, loss_test:0.07038, lr:6.11e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.205, tt:4598.040\n",
      "Ep:127, loss:0.00003, loss_test:0.07600, lr:6.05e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.222, tt:4636.363\n",
      "Ep:128, loss:0.00002, loss_test:0.07225, lr:5.99e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.236, tt:4674.442\n",
      "Ep:129, loss:0.00002, loss_test:0.07235, lr:5.93e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.244, tt:4711.722\n",
      "Ep:130, loss:0.00002, loss_test:0.07370, lr:5.87e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.250, tt:4748.784\n",
      "Ep:131, loss:0.00002, loss_test:0.07369, lr:5.81e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.257, tt:4785.981\n",
      "Ep:132, loss:0.00002, loss_test:0.07290, lr:5.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.267, tt:4823.560\n",
      "Ep:133, loss:0.00002, loss_test:0.07287, lr:5.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.266, tt:4859.664\n",
      "Ep:134, loss:0.00002, loss_test:0.07239, lr:5.64e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.280, tt:4897.862\n",
      "Ep:135, loss:0.00002, loss_test:0.07213, lr:5.58e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.276, tt:4933.513\n",
      "Ep:136, loss:0.00002, loss_test:0.07220, lr:5.53e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.280, tt:4970.416\n",
      "Ep:137, loss:0.00002, loss_test:0.07279, lr:5.47e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.291, tt:5008.107\n",
      "Ep:138, loss:0.00002, loss_test:0.07084, lr:5.42e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.285, tt:5043.596\n",
      "Ep:139, loss:0.00002, loss_test:0.07352, lr:5.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.281, tt:5079.403\n",
      "Ep:140, loss:0.00002, loss_test:0.07263, lr:5.31e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.292, tt:5117.181\n",
      "Ep:141, loss:0.00002, loss_test:0.07273, lr:5.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.302, tt:5154.880\n",
      "Ep:142, loss:0.00002, loss_test:0.07231, lr:5.20e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.312, tt:5192.602\n",
      "Ep:143, loss:0.00002, loss_test:0.07226, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.323, tt:5230.573\n",
      "Ep:144, loss:0.00002, loss_test:0.07348, lr:5.10e-03, fs:0.83243 (r=0.778,p=0.895),  time:36.322, tt:5266.641\n",
      "Ep:145, loss:0.00002, loss_test:0.07097, lr:5.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.327, tt:5303.673\n",
      "Ep:146, loss:0.00002, loss_test:0.07332, lr:5.00e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.334, tt:5341.052\n",
      "Ep:147, loss:0.00002, loss_test:0.07112, lr:4.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.336, tt:5377.736\n",
      "Ep:148, loss:0.00002, loss_test:0.07305, lr:4.90e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.337, tt:5414.283\n",
      "Ep:149, loss:0.00002, loss_test:0.07044, lr:4.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.349, tt:5452.421\n",
      "Ep:150, loss:0.00002, loss_test:0.07306, lr:4.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.351, tt:5489.028\n",
      "Ep:151, loss:0.00002, loss_test:0.07109, lr:4.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.365, tt:5527.422\n",
      "Ep:152, loss:0.00002, loss_test:0.07119, lr:4.71e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.372, tt:5564.857\n",
      "Ep:153, loss:0.00002, loss_test:0.07275, lr:4.66e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.385, tt:5603.303\n",
      "Ep:154, loss:0.00002, loss_test:0.07064, lr:4.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.388, tt:5640.154\n",
      "Ep:155, loss:0.00002, loss_test:0.07282, lr:4.57e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.383, tt:5675.795\n",
      "Ep:156, loss:0.00002, loss_test:0.07086, lr:4.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.392, tt:5713.557\n",
      "Ep:157, loss:0.00002, loss_test:0.07170, lr:4.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.400, tt:5751.213\n",
      "Ep:158, loss:0.00002, loss_test:0.07239, lr:4.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.409, tt:5788.964\n",
      "Ep:159, loss:0.00002, loss_test:0.06918, lr:4.39e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.422, tt:5827.540\n",
      "Ep:160, loss:0.00002, loss_test:0.07307, lr:4.34e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.427, tt:5864.765\n",
      "Ep:161, loss:0.00002, loss_test:0.07073, lr:4.30e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.430, tt:5901.668\n",
      "Ep:162, loss:0.00002, loss_test:0.07109, lr:4.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.437, tt:5939.311\n",
      "Ep:163, loss:0.00002, loss_test:0.07184, lr:4.21e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.446, tt:5977.223\n",
      "Ep:164, loss:0.00002, loss_test:0.07055, lr:4.17e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.446, tt:6013.554\n",
      "Ep:165, loss:0.00002, loss_test:0.07163, lr:4.13e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.452, tt:6051.090\n",
      "Ep:166, loss:0.00002, loss_test:0.06986, lr:4.09e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.457, tt:6088.285\n",
      "Ep:167, loss:0.00002, loss_test:0.07174, lr:4.05e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.454, tt:6124.343\n",
      "Ep:168, loss:0.00002, loss_test:0.07123, lr:4.01e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.451, tt:6160.194\n",
      "Ep:169, loss:0.00002, loss_test:0.07143, lr:3.97e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.455, tt:6197.288\n",
      "Ep:170, loss:0.00002, loss_test:0.07058, lr:3.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.468, tt:6235.982\n",
      "Ep:171, loss:0.00002, loss_test:0.07028, lr:3.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.461, tt:6271.303\n",
      "Ep:172, loss:0.00002, loss_test:0.07098, lr:3.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.463, tt:6308.017\n",
      "Ep:173, loss:0.00002, loss_test:0.06984, lr:3.81e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.467, tt:6345.175\n",
      "Ep:174, loss:0.00002, loss_test:0.07019, lr:3.77e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.465, tt:6381.354\n",
      "Ep:175, loss:0.00002, loss_test:0.07035, lr:3.73e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.469, tt:6418.501\n",
      "Ep:176, loss:0.00002, loss_test:0.07035, lr:3.70e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.464, tt:6454.125\n",
      "Ep:177, loss:0.00002, loss_test:0.06922, lr:3.66e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.467, tt:6491.076\n",
      "Ep:178, loss:0.00002, loss_test:0.07072, lr:3.62e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.467, tt:6527.505\n",
      "Ep:179, loss:0.00002, loss_test:0.06954, lr:3.59e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.464, tt:6563.440\n",
      "Ep:180, loss:0.00002, loss_test:0.06906, lr:3.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.455, tt:6598.436\n",
      "Ep:181, loss:0.00002, loss_test:0.07024, lr:3.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.454, tt:6634.614\n",
      "Ep:182, loss:0.00002, loss_test:0.06909, lr:3.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.452, tt:6670.793\n",
      "Ep:183, loss:0.00002, loss_test:0.07019, lr:3.45e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.446, tt:6706.107\n",
      "Ep:184, loss:0.00001, loss_test:0.06860, lr:3.41e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.431, tt:6739.762\n",
      "Ep:185, loss:0.00001, loss_test:0.06937, lr:3.38e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.434, tt:6776.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:186, loss:0.00001, loss_test:0.07003, lr:3.34e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.426, tt:6811.748\n",
      "Ep:187, loss:0.00001, loss_test:0.06908, lr:3.31e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.430, tt:6848.798\n",
      "Ep:188, loss:0.00001, loss_test:0.06960, lr:3.28e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.435, tt:6886.290\n",
      "Ep:189, loss:0.00001, loss_test:0.06945, lr:3.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.419, tt:6919.618\n",
      "Ep:190, loss:0.00001, loss_test:0.06918, lr:3.21e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.417, tt:6955.717\n",
      "Ep:191, loss:0.00001, loss_test:0.06882, lr:3.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.423, tt:6993.121\n",
      "Ep:192, loss:0.00001, loss_test:0.06960, lr:3.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.413, tt:7027.764\n",
      "Ep:193, loss:0.00001, loss_test:0.06875, lr:3.12e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.417, tt:7064.970\n",
      "Ep:194, loss:0.00001, loss_test:0.06994, lr:3.09e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.418, tt:7101.502\n",
      "Ep:195, loss:0.00001, loss_test:0.06903, lr:3.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.414, tt:7137.200\n",
      "Ep:196, loss:0.00001, loss_test:0.06887, lr:3.02e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.422, tt:7175.144\n",
      "Ep:197, loss:0.00001, loss_test:0.06936, lr:2.99e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.414, tt:7209.983\n",
      "Ep:198, loss:0.00001, loss_test:0.06972, lr:2.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.415, tt:7246.570\n",
      "Ep:199, loss:0.00001, loss_test:0.06907, lr:2.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.411, tt:7282.240\n",
      "Ep:200, loss:0.00001, loss_test:0.06920, lr:2.90e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.403, tt:7317.057\n",
      "Ep:201, loss:0.00001, loss_test:0.07040, lr:2.88e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.408, tt:7354.383\n",
      "Ep:202, loss:0.00001, loss_test:0.06865, lr:2.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.403, tt:7389.770\n",
      "Ep:203, loss:0.00001, loss_test:0.06867, lr:2.82e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.410, tt:7427.538\n",
      "Ep:204, loss:0.00001, loss_test:0.07030, lr:2.79e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.417, tt:7465.486\n",
      "Ep:205, loss:0.00001, loss_test:0.06814, lr:2.76e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.418, tt:7502.093\n",
      "Ep:206, loss:0.00001, loss_test:0.06952, lr:2.73e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.421, tt:7539.227\n",
      "Ep:207, loss:0.00001, loss_test:0.06966, lr:2.71e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.416, tt:7574.543\n",
      "Ep:208, loss:0.00001, loss_test:0.06834, lr:2.68e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.415, tt:7610.731\n",
      "Ep:209, loss:0.00001, loss_test:0.06863, lr:2.65e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.421, tt:7648.466\n",
      "Ep:210, loss:0.00001, loss_test:0.06928, lr:2.63e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.416, tt:7683.796\n",
      "Ep:211, loss:0.00001, loss_test:0.06845, lr:2.60e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.414, tt:7719.689\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.02359, lr:6.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:33.534, tt:33.534\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02306, lr:6.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:33.429, tt:66.859\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02715, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.182, tt:99.547\n",
      "Ep:3, loss:0.00005, loss_test:0.02893, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.161, tt:128.644\n",
      "Ep:4, loss:0.00006, loss_test:0.02954, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.055, tt:155.275\n",
      "Ep:5, loss:0.00006, loss_test:0.02929, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.432, tt:182.590\n",
      "Ep:6, loss:0.00006, loss_test:0.02844, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.949, tt:216.644\n",
      "Ep:7, loss:0.00005, loss_test:0.02706, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.565, tt:252.520\n",
      "Ep:8, loss:0.00005, loss_test:0.02553, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:31.954, tt:287.584\n",
      "Ep:9, loss:0.00005, loss_test:0.02400, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:32.152, tt:321.523\n",
      "Ep:10, loss:0.00005, loss_test:0.02293, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:31.942, tt:351.359\n",
      "Ep:11, loss:0.00005, loss_test:0.02241, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:31.704, tt:380.445\n",
      "Ep:12, loss:0.00005, loss_test:0.02208, lr:6.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:31.879, tt:414.432\n",
      "Ep:13, loss:0.00004, loss_test:0.02159, lr:5.94e-02, fs:0.66667 (r=0.838,p=0.553),  time:32.092, tt:449.282\n",
      "Ep:14, loss:0.00004, loss_test:0.02116, lr:5.88e-02, fs:0.64865 (r=0.848,p=0.525),  time:32.223, tt:483.346\n",
      "Ep:15, loss:0.00004, loss_test:0.02083, lr:5.82e-02, fs:0.65649 (r=0.869,p=0.528),  time:32.424, tt:518.784\n",
      "Ep:16, loss:0.00004, loss_test:0.02046, lr:5.76e-02, fs:0.67164 (r=0.909,p=0.533),  time:32.627, tt:554.651\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01999, lr:5.76e-02, fs:0.66415 (r=0.889,p=0.530),  time:32.741, tt:589.340\n",
      "Ep:18, loss:0.00004, loss_test:0.01947, lr:5.76e-02, fs:0.64368 (r=0.848,p=0.519),  time:32.770, tt:622.631\n",
      "Ep:19, loss:0.00004, loss_test:0.01894, lr:5.76e-02, fs:0.64314 (r=0.828,p=0.526),  time:32.913, tt:658.260\n",
      "Ep:20, loss:0.00004, loss_test:0.01845, lr:5.76e-02, fs:0.64542 (r=0.818,p=0.533),  time:33.023, tt:693.484\n",
      "Ep:21, loss:0.00004, loss_test:0.01798, lr:5.76e-02, fs:0.65854 (r=0.818,p=0.551),  time:33.117, tt:728.571\n",
      "Ep:22, loss:0.00004, loss_test:0.01751, lr:5.76e-02, fs:0.67213 (r=0.828,p=0.566),  time:33.334, tt:766.674\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01707, lr:5.76e-02, fs:0.69388 (r=0.859,p=0.582),  time:33.384, tt:801.227\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01668, lr:5.76e-02, fs:0.70204 (r=0.869,p=0.589),  time:33.452, tt:836.299\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01633, lr:5.76e-02, fs:0.70732 (r=0.879,p=0.592),  time:33.534, tt:871.887\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01598, lr:5.76e-02, fs:0.71020 (r=0.879,p=0.596),  time:33.578, tt:906.611\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01561, lr:5.76e-02, fs:0.71901 (r=0.879,p=0.608),  time:33.618, tt:941.309\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01522, lr:5.76e-02, fs:0.73859 (r=0.899,p=0.627),  time:33.644, tt:975.663\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01482, lr:5.76e-02, fs:0.75000 (r=0.909,p=0.638),  time:33.666, tt:1009.969\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01446, lr:5.76e-02, fs:0.75630 (r=0.909,p=0.647),  time:33.684, tt:1044.207\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01416, lr:5.76e-02, fs:0.76793 (r=0.919,p=0.659),  time:33.641, tt:1076.501\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01385, lr:5.76e-02, fs:0.77119 (r=0.919,p=0.664),  time:33.660, tt:1110.782\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01359, lr:5.76e-02, fs:0.78298 (r=0.929,p=0.676),  time:33.709, tt:1146.122\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01333, lr:5.76e-02, fs:0.81034 (r=0.949,p=0.707),  time:33.683, tt:1178.903\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01309, lr:5.76e-02, fs:0.80687 (r=0.949,p=0.701),  time:33.697, tt:1213.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:36, loss:0.00002, loss_test:0.01285, lr:5.76e-02, fs:0.81385 (r=0.949,p=0.712),  time:33.717, tt:1247.511\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01264, lr:5.76e-02, fs:0.81385 (r=0.949,p=0.712),  time:33.690, tt:1280.215\n",
      "Ep:38, loss:0.00002, loss_test:0.01245, lr:5.76e-02, fs:0.82251 (r=0.960,p=0.720),  time:33.708, tt:1314.609\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01227, lr:5.76e-02, fs:0.82969 (r=0.960,p=0.731),  time:33.754, tt:1350.144\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01213, lr:5.76e-02, fs:0.83333 (r=0.960,p=0.736),  time:33.816, tt:1386.470\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01202, lr:5.76e-02, fs:0.84444 (r=0.960,p=0.754),  time:33.797, tt:1419.468\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01189, lr:5.76e-02, fs:0.84444 (r=0.960,p=0.754),  time:33.823, tt:1454.395\n",
      "Ep:43, loss:0.00002, loss_test:0.01180, lr:5.76e-02, fs:0.84685 (r=0.949,p=0.764),  time:33.864, tt:1489.994\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01173, lr:5.76e-02, fs:0.85455 (r=0.949,p=0.777),  time:33.930, tt:1526.837\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01170, lr:5.76e-02, fs:0.86636 (r=0.949,p=0.797),  time:33.972, tt:1562.713\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01166, lr:5.76e-02, fs:0.86636 (r=0.949,p=0.797),  time:33.995, tt:1597.751\n",
      "Ep:47, loss:0.00001, loss_test:0.01165, lr:5.76e-02, fs:0.86512 (r=0.939,p=0.802),  time:34.014, tt:1632.659\n",
      "Ep:48, loss:0.00001, loss_test:0.01170, lr:5.76e-02, fs:0.86916 (r=0.939,p=0.809),  time:34.015, tt:1666.758\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01176, lr:5.76e-02, fs:0.86916 (r=0.939,p=0.809),  time:34.025, tt:1701.235\n",
      "Ep:50, loss:0.00001, loss_test:0.01174, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:34.049, tt:1736.486\n",
      "Ep:51, loss:0.00001, loss_test:0.01176, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:34.042, tt:1770.199\n",
      "Ep:52, loss:0.00001, loss_test:0.01180, lr:5.76e-02, fs:0.85446 (r=0.919,p=0.798),  time:34.028, tt:1803.477\n",
      "Ep:53, loss:0.00001, loss_test:0.01189, lr:5.76e-02, fs:0.85849 (r=0.919,p=0.805),  time:34.017, tt:1836.944\n",
      "Ep:54, loss:0.00001, loss_test:0.01191, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:34.033, tt:1871.838\n",
      "Ep:55, loss:0.00001, loss_test:0.01194, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:34.038, tt:1906.134\n",
      "Ep:56, loss:0.00001, loss_test:0.01202, lr:5.76e-02, fs:0.86256 (r=0.919,p=0.812),  time:34.093, tt:1943.325\n",
      "Ep:57, loss:0.00001, loss_test:0.01207, lr:5.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.102, tt:1977.923\n",
      "Ep:58, loss:0.00001, loss_test:0.01213, lr:5.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.157, tt:2015.239\n",
      "Ep:59, loss:0.00001, loss_test:0.01220, lr:5.76e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.176, tt:2050.545\n",
      "Ep:60, loss:0.00001, loss_test:0.01229, lr:5.71e-02, fs:0.81951 (r=0.848,p=0.792),  time:34.145, tt:2082.869\n",
      "Ep:61, loss:0.00001, loss_test:0.01240, lr:5.65e-02, fs:0.80788 (r=0.828,p=0.788),  time:34.131, tt:2116.149\n",
      "Ep:62, loss:0.00001, loss_test:0.01247, lr:5.59e-02, fs:0.80000 (r=0.808,p=0.792),  time:34.117, tt:2149.397\n",
      "Ep:63, loss:0.00001, loss_test:0.01252, lr:5.54e-02, fs:0.80402 (r=0.808,p=0.800),  time:34.146, tt:2185.315\n",
      "Ep:64, loss:0.00001, loss_test:0.01261, lr:5.48e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.150, tt:2219.755\n",
      "Ep:65, loss:0.00001, loss_test:0.01273, lr:5.43e-02, fs:0.80808 (r=0.808,p=0.808),  time:34.167, tt:2255.042\n",
      "Ep:66, loss:0.00001, loss_test:0.01280, lr:5.37e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.180, tt:2290.061\n",
      "Ep:67, loss:0.00001, loss_test:0.01285, lr:5.32e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.196, tt:2325.314\n",
      "Ep:68, loss:0.00001, loss_test:0.01289, lr:5.27e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.191, tt:2359.212\n",
      "Ep:69, loss:0.00001, loss_test:0.01299, lr:5.21e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.190, tt:2393.288\n",
      "Ep:70, loss:0.00001, loss_test:0.01308, lr:5.16e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.252, tt:2431.859\n",
      "Ep:71, loss:0.00001, loss_test:0.01315, lr:5.11e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.256, tt:2466.401\n",
      "Ep:72, loss:0.00001, loss_test:0.01323, lr:5.06e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.255, tt:2500.598\n",
      "Ep:73, loss:0.00001, loss_test:0.01331, lr:5.01e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.266, tt:2535.650\n",
      "Ep:74, loss:0.00001, loss_test:0.01338, lr:4.96e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.285, tt:2571.381\n",
      "Ep:75, loss:0.00001, loss_test:0.01346, lr:4.91e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.295, tt:2606.408\n",
      "Ep:76, loss:0.00001, loss_test:0.01355, lr:4.86e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.305, tt:2641.454\n",
      "Ep:77, loss:0.00001, loss_test:0.01360, lr:4.81e-02, fs:0.81675 (r=0.788,p=0.848),  time:34.331, tt:2677.813\n",
      "Ep:78, loss:0.00001, loss_test:0.01371, lr:4.76e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.349, tt:2713.599\n",
      "Ep:79, loss:0.00001, loss_test:0.01382, lr:4.71e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.356, tt:2748.454\n",
      "Ep:80, loss:0.00001, loss_test:0.01388, lr:4.67e-02, fs:0.81915 (r=0.778,p=0.865),  time:34.387, tt:2785.326\n",
      "Ep:81, loss:0.00001, loss_test:0.01396, lr:4.62e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.395, tt:2820.365\n",
      "Ep:82, loss:0.00001, loss_test:0.01405, lr:4.57e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.413, tt:2856.300\n",
      "Ep:83, loss:0.00001, loss_test:0.01414, lr:4.53e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.411, tt:2890.550\n",
      "Ep:84, loss:0.00001, loss_test:0.01419, lr:4.48e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.423, tt:2925.965\n",
      "Ep:85, loss:0.00001, loss_test:0.01428, lr:4.44e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.433, tt:2961.252\n",
      "Ep:86, loss:0.00001, loss_test:0.01435, lr:4.39e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.440, tt:2996.275\n",
      "Ep:87, loss:0.00001, loss_test:0.01445, lr:4.35e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.417, tt:3028.654\n",
      "Ep:88, loss:0.00001, loss_test:0.01450, lr:4.31e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.411, tt:3062.586\n",
      "Ep:89, loss:0.00001, loss_test:0.01456, lr:4.26e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.422, tt:3097.941\n",
      "Ep:90, loss:0.00000, loss_test:0.01463, lr:4.22e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.416, tt:3131.835\n",
      "Ep:91, loss:0.00000, loss_test:0.01473, lr:4.18e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.402, tt:3165.002\n",
      "Ep:92, loss:0.00000, loss_test:0.01473, lr:4.14e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.409, tt:3200.017\n",
      "Ep:93, loss:0.00000, loss_test:0.01479, lr:4.10e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.408, tt:3234.319\n",
      "Ep:94, loss:0.00000, loss_test:0.01498, lr:4.05e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.398, tt:3267.854\n",
      "Ep:95, loss:0.00000, loss_test:0.01499, lr:4.01e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.402, tt:3302.594\n",
      "Ep:96, loss:0.00000, loss_test:0.01492, lr:3.97e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.400, tt:3336.809\n",
      "Ep:97, loss:0.00000, loss_test:0.01511, lr:3.93e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.416, tt:3372.760\n",
      "Ep:98, loss:0.00000, loss_test:0.01509, lr:3.89e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.428, tt:3408.335\n",
      "Ep:99, loss:0.00000, loss_test:0.01507, lr:3.86e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.430, tt:3442.956\n",
      "Ep:100, loss:0.00000, loss_test:0.01526, lr:3.82e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.423, tt:3476.747\n",
      "Ep:101, loss:0.00000, loss_test:0.01525, lr:3.78e-02, fs:0.81319 (r=0.747,p=0.892),  time:34.431, tt:3511.994\n",
      "Ep:102, loss:0.00000, loss_test:0.01525, lr:3.74e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.430, tt:3546.270\n",
      "Ep:103, loss:0.00000, loss_test:0.01534, lr:3.70e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.434, tt:3581.095\n",
      "Ep:104, loss:0.00000, loss_test:0.01547, lr:3.67e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.430, tt:3615.106\n",
      "Ep:105, loss:0.00000, loss_test:0.01543, lr:3.63e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.429, tt:3649.514\n",
      "Ep:106, loss:0.00000, loss_test:0.01554, lr:3.59e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.435, tt:3684.530\n",
      "Ep:107, loss:0.00000, loss_test:0.01568, lr:3.56e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.449, tt:3720.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:108, loss:0.00000, loss_test:0.01563, lr:3.52e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.454, tt:3755.469\n",
      "Ep:109, loss:0.00000, loss_test:0.01567, lr:3.49e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.464, tt:3790.992\n",
      "Ep:110, loss:0.00000, loss_test:0.01582, lr:3.45e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.478, tt:3827.096\n",
      "Ep:111, loss:0.00000, loss_test:0.01578, lr:3.42e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.486, tt:3862.452\n",
      "Ep:112, loss:0.00000, loss_test:0.01585, lr:3.38e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.511, tt:3899.768\n",
      "Ep:113, loss:0.00000, loss_test:0.01597, lr:3.35e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.521, tt:3935.406\n",
      "Ep:114, loss:0.00000, loss_test:0.01600, lr:3.32e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.532, tt:3971.129\n",
      "Ep:115, loss:0.00000, loss_test:0.01601, lr:3.28e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.533, tt:4005.774\n",
      "Ep:116, loss:0.00000, loss_test:0.01613, lr:3.25e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.543, tt:4041.529\n",
      "Ep:117, loss:0.00000, loss_test:0.01615, lr:3.22e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.554, tt:4077.421\n",
      "Ep:118, loss:0.00000, loss_test:0.01618, lr:3.19e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.555, tt:4112.093\n",
      "Ep:119, loss:0.00000, loss_test:0.01629, lr:3.15e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.554, tt:4146.437\n",
      "Ep:120, loss:0.00000, loss_test:0.01632, lr:3.12e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.560, tt:4181.808\n",
      "Ep:121, loss:0.00000, loss_test:0.01634, lr:3.09e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.549, tt:4214.966\n",
      "Ep:122, loss:0.00000, loss_test:0.01644, lr:3.06e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.558, tt:4250.629\n",
      "Ep:123, loss:0.00000, loss_test:0.01647, lr:3.03e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.568, tt:4286.492\n",
      "Ep:124, loss:0.00000, loss_test:0.01651, lr:3.00e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.562, tt:4320.291\n",
      "Ep:125, loss:0.00000, loss_test:0.01660, lr:2.97e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.559, tt:4354.434\n",
      "Ep:126, loss:0.00000, loss_test:0.01663, lr:2.94e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.556, tt:4388.561\n",
      "Ep:127, loss:0.00000, loss_test:0.01664, lr:2.91e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.554, tt:4422.872\n",
      "Ep:128, loss:0.00000, loss_test:0.01671, lr:2.88e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.548, tt:4456.728\n",
      "Ep:129, loss:0.00000, loss_test:0.01677, lr:2.85e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.539, tt:4490.119\n",
      "Ep:130, loss:0.00000, loss_test:0.01673, lr:2.82e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.544, tt:4525.216\n",
      "Ep:131, loss:0.00000, loss_test:0.01683, lr:2.80e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.553, tt:4561.047\n",
      "Ep:132, loss:0.00000, loss_test:0.01696, lr:2.77e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.551, tt:4595.346\n",
      "Ep:133, loss:0.00000, loss_test:0.01688, lr:2.74e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.532, tt:4627.346\n",
      "Ep:134, loss:0.00000, loss_test:0.01689, lr:2.71e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.540, tt:4662.928\n",
      "Ep:135, loss:0.00000, loss_test:0.01707, lr:2.69e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.530, tt:4696.139\n",
      "Ep:136, loss:0.00000, loss_test:0.01711, lr:2.66e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.519, tt:4729.102\n",
      "Ep:137, loss:0.00000, loss_test:0.01697, lr:2.63e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.523, tt:4764.236\n",
      "Ep:138, loss:0.00000, loss_test:0.01712, lr:2.61e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.517, tt:4797.797\n",
      "Ep:139, loss:0.00000, loss_test:0.01728, lr:2.58e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.515, tt:4832.068\n",
      "Ep:140, loss:0.00000, loss_test:0.01719, lr:2.55e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.518, tt:4867.070\n",
      "Ep:141, loss:0.00000, loss_test:0.01722, lr:2.53e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.522, tt:4902.116\n",
      "Ep:142, loss:0.00000, loss_test:0.01738, lr:2.50e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.508, tt:4934.707\n",
      "Ep:143, loss:0.00000, loss_test:0.01732, lr:2.48e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.499, tt:4967.874\n",
      "Ep:144, loss:0.00000, loss_test:0.01735, lr:2.45e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.496, tt:5001.861\n",
      "Ep:145, loss:0.00000, loss_test:0.01746, lr:2.43e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.495, tt:5036.328\n",
      "Ep:146, loss:0.00000, loss_test:0.01750, lr:2.40e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.480, tt:5068.488\n",
      "Ep:147, loss:0.00000, loss_test:0.01750, lr:2.38e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.471, tt:5101.759\n",
      "Ep:148, loss:0.00000, loss_test:0.01752, lr:2.36e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.484, tt:5138.185\n",
      "Ep:149, loss:0.00000, loss_test:0.01761, lr:2.33e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.482, tt:5172.264\n",
      "Ep:150, loss:0.00000, loss_test:0.01765, lr:2.31e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.489, tt:5207.796\n",
      "Ep:151, loss:0.00000, loss_test:0.01767, lr:2.29e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.491, tt:5242.594\n",
      "Ep:152, loss:0.00000, loss_test:0.01774, lr:2.26e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.482, tt:5275.766\n",
      "Ep:153, loss:0.00000, loss_test:0.01776, lr:2.24e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.487, tt:5311.040\n",
      "Ep:154, loss:0.00000, loss_test:0.01777, lr:2.22e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.485, tt:5345.152\n",
      "Ep:155, loss:0.00000, loss_test:0.01786, lr:2.20e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.490, tt:5380.507\n",
      "Ep:156, loss:0.00000, loss_test:0.01787, lr:2.17e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.493, tt:5415.437\n",
      "Ep:157, loss:0.00000, loss_test:0.01790, lr:2.15e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.496, tt:5450.427\n",
      "Ep:158, loss:0.00000, loss_test:0.01796, lr:2.13e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.506, tt:5486.426\n",
      "Ep:159, loss:0.00000, loss_test:0.01801, lr:2.11e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.504, tt:5520.593\n",
      "Ep:160, loss:0.00000, loss_test:0.01801, lr:2.09e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.507, tt:5555.565\n",
      "Ep:161, loss:0.00000, loss_test:0.01806, lr:2.07e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.508, tt:5590.329\n",
      "Ep:162, loss:0.00000, loss_test:0.01811, lr:2.05e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.502, tt:5623.816\n",
      "Ep:163, loss:0.00000, loss_test:0.01811, lr:2.03e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.497, tt:5657.503\n",
      "Ep:164, loss:0.00000, loss_test:0.01817, lr:2.01e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.492, tt:5691.201\n",
      "Ep:165, loss:0.00000, loss_test:0.01823, lr:1.99e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.491, tt:5725.543\n",
      "Ep:166, loss:0.00000, loss_test:0.01824, lr:1.97e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.511, tt:5763.323\n",
      "Ep:167, loss:0.00000, loss_test:0.01826, lr:1.95e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.512, tt:5798.053\n",
      "Ep:168, loss:0.00000, loss_test:0.01831, lr:1.93e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.510, tt:5832.225\n",
      "Ep:169, loss:0.00000, loss_test:0.01833, lr:1.91e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.519, tt:5868.266\n",
      "Ep:170, loss:0.00000, loss_test:0.01838, lr:1.89e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.530, tt:5904.693\n",
      "Ep:171, loss:0.00000, loss_test:0.01841, lr:1.87e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.527, tt:5938.717\n",
      "Ep:172, loss:0.00000, loss_test:0.01841, lr:1.85e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.528, tt:5973.361\n",
      "Ep:173, loss:0.00000, loss_test:0.01848, lr:1.83e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.529, tt:6008.028\n",
      "Ep:174, loss:0.00000, loss_test:0.01851, lr:1.81e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.532, tt:6043.148\n",
      "Ep:175, loss:0.00000, loss_test:0.01854, lr:1.80e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.533, tt:6077.890\n",
      "Ep:176, loss:0.00000, loss_test:0.01854, lr:1.78e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.540, tt:6113.557\n",
      "Ep:177, loss:0.00000, loss_test:0.01860, lr:1.76e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.545, tt:6149.099\n",
      "Ep:178, loss:0.00000, loss_test:0.01863, lr:1.74e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.553, tt:6184.918\n",
      "Ep:179, loss:0.00000, loss_test:0.01865, lr:1.73e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.544, tt:6217.862\n",
      "Ep:180, loss:0.00000, loss_test:0.01866, lr:1.71e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.548, tt:6253.153\n",
      "Ep:181, loss:0.00000, loss_test:0.01869, lr:1.69e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.550, tt:6288.119\n",
      "Ep:182, loss:0.00000, loss_test:0.01872, lr:1.67e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.556, tt:6323.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:183, loss:0.00000, loss_test:0.01879, lr:1.66e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.557, tt:6358.573\n",
      "Ep:184, loss:0.00000, loss_test:0.01879, lr:1.64e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.560, tt:6393.632\n",
      "Ep:185, loss:0.00000, loss_test:0.01879, lr:1.62e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.564, tt:6428.866\n",
      "Ep:186, loss:0.00000, loss_test:0.01885, lr:1.61e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.568, tt:6464.144\n",
      "Ep:187, loss:0.00000, loss_test:0.01885, lr:1.59e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.574, tt:6499.911\n",
      "Ep:188, loss:0.00000, loss_test:0.01890, lr:1.58e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.576, tt:6534.857\n",
      "Ep:189, loss:0.00000, loss_test:0.01894, lr:1.56e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.574, tt:6568.988\n",
      "Ep:190, loss:0.00000, loss_test:0.01889, lr:1.54e-02, fs:0.80682 (r=0.717,p=0.922),  time:34.585, tt:6605.675\n",
      "Ep:191, loss:0.00000, loss_test:0.01891, lr:1.53e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.576, tt:6638.658\n",
      "Ep:192, loss:0.00000, loss_test:0.01902, lr:1.51e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.567, tt:6671.363\n",
      "Ep:193, loss:0.00000, loss_test:0.01904, lr:1.50e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.561, tt:6704.894\n",
      "Ep:194, loss:0.00000, loss_test:0.01901, lr:1.48e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.557, tt:6738.586\n",
      "Ep:195, loss:0.00000, loss_test:0.01902, lr:1.47e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.548, tt:6771.370\n",
      "Ep:196, loss:0.00000, loss_test:0.01908, lr:1.45e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.552, tt:6806.733\n",
      "Ep:197, loss:0.00000, loss_test:0.01911, lr:1.44e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.546, tt:6840.088\n",
      "Ep:198, loss:0.00000, loss_test:0.01911, lr:1.43e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.540, tt:6873.386\n",
      "Ep:199, loss:0.00000, loss_test:0.01914, lr:1.41e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.537, tt:6907.374\n",
      "Ep:200, loss:0.00000, loss_test:0.01916, lr:1.40e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.537, tt:6941.855\n",
      "Ep:201, loss:0.00000, loss_test:0.01919, lr:1.38e-02, fs:0.81143 (r=0.717,p=0.934),  time:34.539, tt:6976.949\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13532, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:37.380, tt:37.380\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13278, lr:1.00e-02, fs:0.64982 (r=0.909,p=0.506),  time:36.549, tt:73.098\n",
      "Ep:2, loss:0.00026, loss_test:0.12879, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:36.522, tt:109.565\n",
      "Ep:3, loss:0.00026, loss_test:0.12549, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:35.787, tt:143.148\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12352, lr:1.00e-02, fs:0.67717 (r=0.869,p=0.555),  time:35.320, tt:176.598\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12159, lr:1.00e-02, fs:0.68273 (r=0.859,p=0.567),  time:35.336, tt:212.017\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11989, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:35.586, tt:249.105\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11823, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:35.597, tt:284.776\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11658, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:35.835, tt:322.515\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11506, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.992, tt:359.921\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11359, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:35.890, tt:394.793\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.11215, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:35.959, tt:431.507\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00023, loss_test:0.11034, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:36.234, tt:471.040\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10829, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:36.407, tt:509.698\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00022, loss_test:0.10625, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:36.581, tt:548.708\n",
      "Ep:15, loss:0.00021, loss_test:0.10449, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:36.897, tt:590.348\n",
      "Ep:16, loss:0.00021, loss_test:0.10261, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:36.992, tt:628.862\n",
      "Ep:17, loss:0.00020, loss_test:0.10040, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:37.102, tt:667.834\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00020, loss_test:0.09835, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:37.179, tt:706.407\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.09642, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:37.257, tt:745.134\n",
      "Ep:20, loss:0.00019, loss_test:0.09436, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:37.346, tt:784.268\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.09195, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:37.451, tt:823.916\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.08975, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:37.539, tt:863.398\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08767, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:37.546, tt:901.094\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08492, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:37.676, tt:941.907\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08261, lr:1.00e-02, fs:0.78378 (r=0.879,p=0.707),  time:37.753, tt:981.570\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.08051, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:37.764, tt:1019.621\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00015, loss_test:0.07863, lr:1.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:37.766, tt:1057.457\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07720, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:37.769, tt:1095.302\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00014, loss_test:0.07561, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:37.785, tt:1133.545\n",
      "Ep:30, loss:0.00013, loss_test:0.07452, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:37.790, tt:1171.485\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.07377, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:37.771, tt:1208.680\n",
      "Ep:32, loss:0.00012, loss_test:0.07234, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:37.672, tt:1243.167\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07248, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:37.660, tt:1280.453\n",
      "Ep:34, loss:0.00011, loss_test:0.06988, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:37.620, tt:1316.708\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07102, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:37.625, tt:1354.506\n",
      "Ep:36, loss:0.00010, loss_test:0.06775, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:37.613, tt:1391.675\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06952, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:37.586, tt:1428.249\n",
      "Ep:38, loss:0.00010, loss_test:0.06606, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:37.583, tt:1465.722\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06936, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:37.527, tt:1501.074\n",
      "Ep:40, loss:0.00009, loss_test:0.06582, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:37.463, tt:1535.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:41, loss:0.00008, loss_test:0.06606, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:37.441, tt:1572.532\n",
      "Ep:42, loss:0.00008, loss_test:0.06669, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:37.456, tt:1610.627\n",
      "Ep:43, loss:0.00007, loss_test:0.06325, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:37.426, tt:1646.744\n",
      "Ep:44, loss:0.00007, loss_test:0.06397, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:37.379, tt:1682.036\n",
      "Ep:45, loss:0.00007, loss_test:0.06525, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:37.330, tt:1717.184\n",
      "Ep:46, loss:0.00007, loss_test:0.06245, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:37.326, tt:1754.335\n",
      "Ep:47, loss:0.00006, loss_test:0.06380, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:37.285, tt:1789.670\n",
      "Ep:48, loss:0.00006, loss_test:0.06061, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:37.233, tt:1824.402\n",
      "Ep:49, loss:0.00006, loss_test:0.06551, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:37.179, tt:1858.929\n",
      "Ep:50, loss:0.00006, loss_test:0.06077, lr:9.90e-03, fs:0.86772 (r=0.828,p=0.911),  time:37.143, tt:1894.288\n",
      "Ep:51, loss:0.00005, loss_test:0.06473, lr:9.80e-03, fs:0.82162 (r=0.768,p=0.884),  time:37.100, tt:1929.201\n",
      "Ep:52, loss:0.00005, loss_test:0.06046, lr:9.70e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.060, tt:1964.181\n",
      "Ep:53, loss:0.00005, loss_test:0.06283, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:37.043, tt:2000.328\n",
      "Ep:54, loss:0.00005, loss_test:0.06286, lr:9.51e-03, fs:0.82609 (r=0.768,p=0.894),  time:37.050, tt:2037.727\n",
      "Ep:55, loss:0.00005, loss_test:0.06183, lr:9.41e-03, fs:0.82796 (r=0.778,p=0.885),  time:37.059, tt:2075.278\n",
      "Ep:56, loss:0.00004, loss_test:0.06072, lr:9.32e-03, fs:0.85714 (r=0.818,p=0.900),  time:37.063, tt:2112.601\n",
      "Ep:57, loss:0.00004, loss_test:0.06529, lr:9.23e-03, fs:0.82162 (r=0.768,p=0.884),  time:37.068, tt:2149.936\n",
      "Ep:58, loss:0.00004, loss_test:0.05955, lr:9.14e-03, fs:0.86486 (r=0.808,p=0.930),  time:37.057, tt:2186.341\n",
      "Ep:59, loss:0.00004, loss_test:0.06475, lr:9.04e-03, fs:0.80220 (r=0.737,p=0.880),  time:37.072, tt:2224.296\n",
      "Ep:60, loss:0.00004, loss_test:0.05988, lr:8.95e-03, fs:0.86170 (r=0.818,p=0.910),  time:37.059, tt:2260.599\n",
      "Ep:61, loss:0.00004, loss_test:0.06450, lr:8.86e-03, fs:0.80663 (r=0.737,p=0.890),  time:37.045, tt:2296.811\n",
      "Ep:62, loss:0.00004, loss_test:0.06079, lr:8.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:37.040, tt:2333.537\n",
      "Ep:63, loss:0.00004, loss_test:0.06334, lr:8.69e-03, fs:0.80220 (r=0.737,p=0.880),  time:37.038, tt:2370.448\n",
      "Ep:64, loss:0.00004, loss_test:0.06187, lr:8.60e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.022, tt:2406.455\n",
      "Ep:65, loss:0.00003, loss_test:0.06242, lr:8.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.035, tt:2444.300\n",
      "Ep:66, loss:0.00003, loss_test:0.06157, lr:8.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.041, tt:2481.724\n",
      "Ep:67, loss:0.00003, loss_test:0.06335, lr:8.35e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.047, tt:2519.172\n",
      "Ep:68, loss:0.00003, loss_test:0.06185, lr:8.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.050, tt:2556.483\n",
      "Ep:69, loss:0.00003, loss_test:0.06310, lr:8.18e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.041, tt:2592.895\n",
      "Ep:70, loss:0.00003, loss_test:0.06251, lr:8.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.044, tt:2630.111\n",
      "Ep:71, loss:0.00003, loss_test:0.06128, lr:8.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:37.047, tt:2667.394\n",
      "Ep:72, loss:0.00003, loss_test:0.06278, lr:7.94e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.039, tt:2703.835\n",
      "Ep:73, loss:0.00003, loss_test:0.06157, lr:7.86e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.038, tt:2740.814\n",
      "Ep:74, loss:0.00003, loss_test:0.06455, lr:7.78e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.026, tt:2776.935\n",
      "Ep:75, loss:0.00003, loss_test:0.06206, lr:7.70e-03, fs:0.79775 (r=0.717,p=0.899),  time:37.041, tt:2815.130\n",
      "Ep:76, loss:0.00003, loss_test:0.06334, lr:7.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:37.027, tt:2851.096\n",
      "Ep:77, loss:0.00003, loss_test:0.06204, lr:7.55e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.013, tt:2887.016\n",
      "Ep:78, loss:0.00003, loss_test:0.06278, lr:7.47e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.985, tt:2921.851\n",
      "Ep:79, loss:0.00003, loss_test:0.06231, lr:7.40e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.001, tt:2960.055\n",
      "Ep:80, loss:0.00002, loss_test:0.06311, lr:7.32e-03, fs:0.80447 (r=0.727,p=0.900),  time:36.997, tt:2996.721\n",
      "Ep:81, loss:0.00002, loss_test:0.06156, lr:7.25e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.980, tt:3032.320\n",
      "Ep:82, loss:0.00002, loss_test:0.06325, lr:7.18e-03, fs:0.81111 (r=0.737,p=0.901),  time:36.985, tt:3069.775\n",
      "Ep:83, loss:0.00002, loss_test:0.06152, lr:7.11e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.991, tt:3107.205\n",
      "Ep:84, loss:0.00002, loss_test:0.06304, lr:7.03e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.009, tt:3145.736\n",
      "Ep:85, loss:0.00002, loss_test:0.06224, lr:6.96e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.008, tt:3182.648\n",
      "Ep:86, loss:0.00002, loss_test:0.06248, lr:6.89e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.019, tt:3220.688\n",
      "Ep:87, loss:0.00002, loss_test:0.06219, lr:6.83e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.030, tt:3258.670\n",
      "Ep:88, loss:0.00002, loss_test:0.06364, lr:6.76e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.027, tt:3295.409\n",
      "Ep:89, loss:0.00002, loss_test:0.06177, lr:6.69e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.078, tt:3336.992\n",
      "Ep:90, loss:0.00002, loss_test:0.06328, lr:6.62e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.073, tt:3373.615\n",
      "Ep:91, loss:0.00002, loss_test:0.06132, lr:6.56e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.081, tt:3411.434\n",
      "Ep:92, loss:0.00002, loss_test:0.06309, lr:6.49e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.091, tt:3449.426\n",
      "Ep:93, loss:0.00002, loss_test:0.06192, lr:6.43e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.091, tt:3486.508\n",
      "Ep:94, loss:0.00002, loss_test:0.06210, lr:6.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.092, tt:3523.783\n",
      "Ep:95, loss:0.00002, loss_test:0.06181, lr:6.30e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.097, tt:3561.294\n",
      "Ep:96, loss:0.00002, loss_test:0.06183, lr:6.24e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.093, tt:3598.036\n",
      "Ep:97, loss:0.00002, loss_test:0.06110, lr:6.17e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.093, tt:3635.129\n",
      "Ep:98, loss:0.00002, loss_test:0.06370, lr:6.11e-03, fs:0.81564 (r=0.737,p=0.912),  time:37.096, tt:3672.475\n",
      "Ep:99, loss:0.00002, loss_test:0.06062, lr:6.05e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.092, tt:3709.231\n",
      "Ep:100, loss:0.00002, loss_test:0.06297, lr:5.99e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.073, tt:3744.418\n",
      "Ep:101, loss:0.00002, loss_test:0.06321, lr:5.93e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.044, tt:3778.493\n",
      "Ep:102, loss:0.00002, loss_test:0.06076, lr:5.87e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.041, tt:3815.176\n",
      "Ep:103, loss:0.00002, loss_test:0.06361, lr:5.81e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.039, tt:3852.087\n",
      "Ep:104, loss:0.00002, loss_test:0.06105, lr:5.75e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.042, tt:3889.445\n",
      "Ep:105, loss:0.00002, loss_test:0.06208, lr:5.70e-03, fs:0.80226 (r=0.717,p=0.910),  time:37.028, tt:3924.944\n",
      "Ep:106, loss:0.00002, loss_test:0.06266, lr:5.64e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.014, tt:3960.543\n",
      "Ep:107, loss:0.00002, loss_test:0.06071, lr:5.58e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.016, tt:3997.714\n",
      "Ep:108, loss:0.00002, loss_test:0.06209, lr:5.53e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.020, tt:4035.200\n",
      "Ep:109, loss:0.00002, loss_test:0.06193, lr:5.47e-03, fs:0.80899 (r=0.727,p=0.911),  time:37.009, tt:4070.959\n",
      "Ep:110, loss:0.00002, loss_test:0.06112, lr:5.42e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.002, tt:4107.269\n",
      "Ep:111, loss:0.00002, loss_test:0.06191, lr:5.36e-03, fs:0.80226 (r=0.717,p=0.910),  time:36.995, tt:4143.449\n",
      "Ep:112, loss:0.00002, loss_test:0.06065, lr:5.31e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.966, tt:4177.180\n",
      "Ep:113, loss:0.00002, loss_test:0.06179, lr:5.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:36.985, tt:4216.275\n",
      "Ep:114, loss:0.00002, loss_test:0.06107, lr:5.20e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.991, tt:4253.970\n",
      "Ep:115, loss:0.00002, loss_test:0.06063, lr:5.15e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.992, tt:4291.058\n",
      "Ep:116, loss:0.00002, loss_test:0.06164, lr:5.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.990, tt:4327.865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:117, loss:0.00002, loss_test:0.06073, lr:5.05e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.989, tt:4364.756\n",
      "Ep:118, loss:0.00002, loss_test:0.06123, lr:5.00e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.976, tt:4400.151\n",
      "Ep:119, loss:0.00002, loss_test:0.06015, lr:4.95e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.991, tt:4438.878\n",
      "Ep:120, loss:0.00001, loss_test:0.06142, lr:4.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.994, tt:4476.300\n",
      "Ep:121, loss:0.00001, loss_test:0.06051, lr:4.85e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.006, tt:4514.679\n",
      "Ep:122, loss:0.00001, loss_test:0.06104, lr:4.80e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.001, tt:4551.107\n",
      "Ep:123, loss:0.00001, loss_test:0.06049, lr:4.75e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.003, tt:4588.350\n",
      "Ep:124, loss:0.00001, loss_test:0.06160, lr:4.71e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.985, tt:4623.138\n",
      "Ep:125, loss:0.00001, loss_test:0.06069, lr:4.66e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.994, tt:4661.285\n",
      "Ep:126, loss:0.00001, loss_test:0.06135, lr:4.61e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.981, tt:4696.633\n",
      "Ep:127, loss:0.00001, loss_test:0.06235, lr:4.57e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.987, tt:4734.317\n",
      "Ep:128, loss:0.00001, loss_test:0.05978, lr:4.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.981, tt:4770.533\n",
      "Ep:129, loss:0.00001, loss_test:0.06175, lr:4.48e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.980, tt:4807.364\n",
      "Ep:130, loss:0.00001, loss_test:0.06058, lr:4.43e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.978, tt:4844.099\n",
      "Ep:131, loss:0.00001, loss_test:0.06022, lr:4.39e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.972, tt:4880.361\n",
      "Ep:132, loss:0.00001, loss_test:0.06305, lr:4.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:36.984, tt:4918.907\n",
      "Ep:133, loss:0.00001, loss_test:0.05992, lr:4.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.990, tt:4956.721\n",
      "Ep:134, loss:0.00001, loss_test:0.06125, lr:4.26e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.990, tt:4993.652\n",
      "Ep:135, loss:0.00001, loss_test:0.06113, lr:4.21e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.002, tt:5032.321\n",
      "Ep:136, loss:0.00001, loss_test:0.05991, lr:4.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.001, tt:5069.180\n",
      "Ep:137, loss:0.00001, loss_test:0.06154, lr:4.13e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.995, tt:5105.246\n",
      "Ep:138, loss:0.00001, loss_test:0.06056, lr:4.09e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.995, tt:5142.269\n",
      "Ep:139, loss:0.00001, loss_test:0.06025, lr:4.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.000, tt:5180.056\n",
      "Ep:140, loss:0.00001, loss_test:0.06162, lr:4.01e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.993, tt:5216.004\n",
      "Ep:141, loss:0.00001, loss_test:0.06042, lr:3.97e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.993, tt:5253.023\n",
      "Ep:142, loss:0.00001, loss_test:0.05994, lr:3.93e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.999, tt:5290.893\n",
      "Ep:143, loss:0.00001, loss_test:0.06108, lr:3.89e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.001, tt:5328.207\n",
      "Ep:144, loss:0.00001, loss_test:0.06034, lr:3.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.982, tt:5362.343\n",
      "Ep:145, loss:0.00001, loss_test:0.06062, lr:3.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.985, tt:5399.821\n",
      "Ep:146, loss:0.00001, loss_test:0.06037, lr:3.77e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.967, tt:5434.192\n",
      "Ep:147, loss:0.00001, loss_test:0.06042, lr:3.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.961, tt:5470.286\n",
      "Ep:148, loss:0.00001, loss_test:0.06106, lr:3.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.958, tt:5506.783\n",
      "Ep:149, loss:0.00001, loss_test:0.05996, lr:3.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.949, tt:5542.389\n",
      "Ep:150, loss:0.00001, loss_test:0.06095, lr:3.62e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.938, tt:5577.653\n",
      "Ep:151, loss:0.00001, loss_test:0.06042, lr:3.59e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.931, tt:5613.575\n",
      "Ep:152, loss:0.00001, loss_test:0.06006, lr:3.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.919, tt:5648.631\n",
      "Ep:153, loss:0.00001, loss_test:0.06089, lr:3.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.914, tt:5684.828\n",
      "Ep:154, loss:0.00001, loss_test:0.06029, lr:3.48e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.910, tt:5720.983\n",
      "Ep:155, loss:0.00001, loss_test:0.06017, lr:3.45e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.893, tt:5755.278\n",
      "Ep:156, loss:0.00001, loss_test:0.06043, lr:3.41e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.886, tt:5791.036\n",
      "Ep:157, loss:0.00001, loss_test:0.06020, lr:3.38e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.888, tt:5828.323\n",
      "Ep:158, loss:0.00001, loss_test:0.06066, lr:3.34e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.883, tt:5864.343\n",
      "Ep:159, loss:0.00001, loss_test:0.06088, lr:3.31e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.876, tt:5900.235\n",
      "Ep:160, loss:0.00001, loss_test:0.05958, lr:3.28e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.877, tt:5937.122\n",
      "Ep:161, loss:0.00001, loss_test:0.06107, lr:3.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.874, tt:5973.641\n",
      "Ep:162, loss:0.00001, loss_test:0.06074, lr:3.21e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.862, tt:6008.496\n",
      "Ep:163, loss:0.00001, loss_test:0.05985, lr:3.18e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.854, tt:6043.999\n",
      "Ep:164, loss:0.00001, loss_test:0.06062, lr:3.15e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.836, tt:6077.974\n",
      "Ep:165, loss:0.00001, loss_test:0.06038, lr:3.12e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.841, tt:6115.621\n",
      "Ep:166, loss:0.00001, loss_test:0.06035, lr:3.09e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.841, tt:6152.512\n",
      "Ep:167, loss:0.00001, loss_test:0.06004, lr:3.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.838, tt:6188.715\n",
      "Ep:168, loss:0.00001, loss_test:0.06025, lr:3.02e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.833, tt:6224.799\n",
      "Ep:169, loss:0.00001, loss_test:0.06066, lr:2.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.825, tt:6260.306\n",
      "Ep:170, loss:0.00001, loss_test:0.06026, lr:2.96e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.831, tt:6298.141\n",
      "Ep:171, loss:0.00001, loss_test:0.05990, lr:2.93e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.824, tt:6333.683\n",
      "Ep:172, loss:0.00001, loss_test:0.06032, lr:2.90e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.819, tt:6369.673\n",
      "Ep:173, loss:0.00001, loss_test:0.06054, lr:2.88e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.809, tt:6404.795\n",
      "Ep:174, loss:0.00001, loss_test:0.06027, lr:2.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.799, tt:6439.890\n",
      "Ep:175, loss:0.00001, loss_test:0.06013, lr:2.82e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.794, tt:6475.706\n",
      "Ep:176, loss:0.00001, loss_test:0.06067, lr:2.79e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.795, tt:6512.697\n",
      "Ep:177, loss:0.00001, loss_test:0.06030, lr:2.76e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.788, tt:6548.233\n",
      "Ep:178, loss:0.00001, loss_test:0.06004, lr:2.73e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.785, tt:6584.460\n",
      "Ep:179, loss:0.00001, loss_test:0.06078, lr:2.71e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.783, tt:6621.007\n",
      "Ep:180, loss:0.00001, loss_test:0.05999, lr:2.68e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.786, tt:6658.286\n",
      "Ep:181, loss:0.00001, loss_test:0.06054, lr:2.65e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.790, tt:6695.869\n",
      "Ep:182, loss:0.00001, loss_test:0.06017, lr:2.63e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.789, tt:6732.344\n",
      "Ep:183, loss:0.00001, loss_test:0.06011, lr:2.60e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.787, tt:6768.724\n",
      "Ep:184, loss:0.00001, loss_test:0.06045, lr:2.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.786, tt:6805.442\n",
      "Ep:185, loss:0.00001, loss_test:0.06001, lr:2.55e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.783, tt:6841.654\n",
      "Ep:186, loss:0.00001, loss_test:0.06015, lr:2.52e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.779, tt:6877.614\n",
      "Ep:187, loss:0.00001, loss_test:0.06020, lr:2.50e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.776, tt:6913.900\n",
      "Ep:188, loss:0.00001, loss_test:0.06055, lr:2.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.777, tt:6950.802\n",
      "Ep:189, loss:0.00001, loss_test:0.05985, lr:2.45e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.772, tt:6986.697\n",
      "Ep:190, loss:0.00001, loss_test:0.06085, lr:2.42e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.780, tt:7025.020\n",
      "Ep:191, loss:0.00001, loss_test:0.06024, lr:2.40e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.779, tt:7061.647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:192, loss:0.00001, loss_test:0.05996, lr:2.38e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.773, tt:7097.129\n",
      "Ep:193, loss:0.00001, loss_test:0.06152, lr:2.35e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.775, tt:7134.372\n",
      "Ep:194, loss:0.00001, loss_test:0.06008, lr:2.33e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.776, tt:7171.415\n",
      "Ep:195, loss:0.00001, loss_test:0.05979, lr:2.31e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.782, tt:7209.195\n",
      "Ep:196, loss:0.00001, loss_test:0.06095, lr:2.28e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.778, tt:7245.256\n",
      "Ep:197, loss:0.00001, loss_test:0.06054, lr:2.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.772, tt:7280.860\n",
      "Ep:198, loss:0.00001, loss_test:0.06016, lr:2.24e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.767, tt:7316.568\n",
      "Ep:199, loss:0.00001, loss_test:0.06038, lr:2.21e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.768, tt:7353.625\n",
      "Ep:200, loss:0.00001, loss_test:0.06036, lr:2.19e-03, fs:0.80682 (r=0.717,p=0.922),  time:36.769, tt:7390.491\n",
      "Ep:201, loss:0.00001, loss_test:0.06029, lr:2.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:36.771, tt:7427.763\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02302, lr:6.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:24.920, tt:24.920\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:23.862, tt:47.724\n",
      "Ep:2, loss:0.00005, loss_test:0.02880, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.184, tt:72.552\n",
      "Ep:3, loss:0.00006, loss_test:0.03018, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.175, tt:96.698\n",
      "Ep:4, loss:0.00006, loss_test:0.03027, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.547, tt:117.733\n",
      "Ep:5, loss:0.00006, loss_test:0.02961, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.332, tt:139.992\n",
      "Ep:6, loss:0.00006, loss_test:0.02865, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.656, tt:165.591\n",
      "Ep:7, loss:0.00005, loss_test:0.02728, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.343, tt:194.741\n",
      "Ep:8, loss:0.00005, loss_test:0.02575, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:25.013, tt:225.113\n",
      "Ep:9, loss:0.00005, loss_test:0.02432, lr:6.00e-02, fs:0.64516 (r=0.909,p=0.500),  time:25.451, tt:254.513\n",
      "Ep:10, loss:0.00005, loss_test:0.02358, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:25.680, tt:282.476\n",
      "Ep:11, loss:0.00004, loss_test:0.02361, lr:6.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:25.743, tt:308.917\n",
      "Ep:12, loss:0.00004, loss_test:0.02340, lr:5.94e-02, fs:0.66393 (r=0.818,p=0.559),  time:25.794, tt:335.321\n",
      "Ep:13, loss:0.00004, loss_test:0.02260, lr:5.88e-02, fs:0.67480 (r=0.838,p=0.565),  time:25.883, tt:362.359\n",
      "Ep:14, loss:0.00004, loss_test:0.02206, lr:5.82e-02, fs:0.66667 (r=0.869,p=0.541),  time:25.963, tt:389.442\n",
      "Ep:15, loss:0.00004, loss_test:0.02192, lr:5.76e-02, fs:0.66409 (r=0.869,p=0.537),  time:26.127, tt:418.040\n",
      "Ep:16, loss:0.00004, loss_test:0.02178, lr:5.71e-02, fs:0.67433 (r=0.889,p=0.543),  time:26.350, tt:447.955\n",
      "Ep:17, loss:0.00004, loss_test:0.02165, lr:5.65e-02, fs:0.66409 (r=0.869,p=0.537),  time:26.514, tt:477.251\n",
      "Ep:18, loss:0.00004, loss_test:0.02162, lr:5.59e-02, fs:0.66667 (r=0.869,p=0.541),  time:26.678, tt:506.890\n",
      "Ep:19, loss:0.00004, loss_test:0.02154, lr:5.54e-02, fs:0.66929 (r=0.859,p=0.548),  time:26.836, tt:536.725\n",
      "Ep:20, loss:0.00004, loss_test:0.02135, lr:5.48e-02, fs:0.66667 (r=0.859,p=0.545),  time:27.012, tt:567.249\n",
      "Ep:21, loss:0.00004, loss_test:0.02113, lr:5.43e-02, fs:0.66148 (r=0.859,p=0.538),  time:27.103, tt:596.260\n",
      "Ep:22, loss:0.00004, loss_test:0.02097, lr:5.37e-02, fs:0.66148 (r=0.859,p=0.538),  time:27.289, tt:627.656\n",
      "Ep:23, loss:0.00004, loss_test:0.02082, lr:5.32e-02, fs:0.66406 (r=0.859,p=0.541),  time:27.378, tt:657.079\n",
      "Ep:24, loss:0.00004, loss_test:0.02075, lr:5.27e-02, fs:0.66667 (r=0.848,p=0.549),  time:27.498, tt:687.443\n",
      "Ep:25, loss:0.00004, loss_test:0.02062, lr:5.21e-02, fs:0.66667 (r=0.848,p=0.549),  time:27.606, tt:717.762\n",
      "Ep:26, loss:0.00004, loss_test:0.02039, lr:5.16e-02, fs:0.66667 (r=0.848,p=0.549),  time:27.751, tt:749.285\n",
      "Ep:27, loss:0.00004, loss_test:0.02020, lr:5.11e-02, fs:0.66929 (r=0.859,p=0.548),  time:27.810, tt:778.676\n",
      "Ep:28, loss:0.00004, loss_test:0.02004, lr:5.06e-02, fs:0.67194 (r=0.859,p=0.552),  time:27.871, tt:808.265\n",
      "Ep:29, loss:0.00004, loss_test:0.01989, lr:5.01e-02, fs:0.66667 (r=0.848,p=0.549),  time:27.911, tt:837.332\n",
      "Ep:30, loss:0.00004, loss_test:0.01969, lr:4.96e-02, fs:0.67194 (r=0.859,p=0.552),  time:28.009, tt:868.268\n",
      "Ep:31, loss:0.00004, loss_test:0.01952, lr:4.91e-02, fs:0.67984 (r=0.869,p=0.558),  time:28.015, tt:896.495\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00004, loss_test:0.01934, lr:4.91e-02, fs:0.67984 (r=0.869,p=0.558),  time:28.072, tt:926.379\n",
      "Ep:33, loss:0.00003, loss_test:0.01915, lr:4.91e-02, fs:0.68254 (r=0.869,p=0.562),  time:28.113, tt:955.827\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01893, lr:4.91e-02, fs:0.68273 (r=0.859,p=0.567),  time:28.176, tt:986.153\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01874, lr:4.91e-02, fs:0.68273 (r=0.859,p=0.567),  time:28.182, tt:1014.551\n",
      "Ep:36, loss:0.00003, loss_test:0.01848, lr:4.91e-02, fs:0.67742 (r=0.848,p=0.564),  time:28.211, tt:1043.818\n",
      "Ep:37, loss:0.00003, loss_test:0.01826, lr:4.91e-02, fs:0.68273 (r=0.859,p=0.567),  time:28.225, tt:1072.550\n",
      "Ep:38, loss:0.00003, loss_test:0.01808, lr:4.91e-02, fs:0.68548 (r=0.859,p=0.570),  time:28.252, tt:1101.835\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01787, lr:4.91e-02, fs:0.69355 (r=0.869,p=0.577),  time:28.283, tt:1131.317\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01760, lr:4.91e-02, fs:0.71200 (r=0.899,p=0.589),  time:28.310, tt:1160.696\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01732, lr:4.91e-02, fs:0.72000 (r=0.909,p=0.596),  time:28.329, tt:1189.835\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01716, lr:4.91e-02, fs:0.71255 (r=0.889,p=0.595),  time:28.312, tt:1217.414\n",
      "Ep:43, loss:0.00003, loss_test:0.01689, lr:4.91e-02, fs:0.72358 (r=0.899,p=0.605),  time:28.338, tt:1246.889\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01662, lr:4.91e-02, fs:0.73171 (r=0.909,p=0.612),  time:28.369, tt:1276.624\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01637, lr:4.91e-02, fs:0.73469 (r=0.909,p=0.616),  time:28.379, tt:1305.413\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00003, loss_test:0.01625, lr:4.91e-02, fs:0.74074 (r=0.909,p=0.625),  time:28.408, tt:1335.165\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01591, lr:4.91e-02, fs:0.75519 (r=0.919,p=0.641),  time:28.396, tt:1362.999\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01578, lr:4.91e-02, fs:0.75424 (r=0.899,p=0.650),  time:28.406, tt:1391.908\n",
      "Ep:49, loss:0.00003, loss_test:0.01572, lr:4.91e-02, fs:0.76793 (r=0.919,p=0.659),  time:28.422, tt:1421.089\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01562, lr:4.91e-02, fs:0.77778 (r=0.919,p=0.674),  time:28.422, tt:1449.511\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01535, lr:4.91e-02, fs:0.78298 (r=0.929,p=0.676),  time:28.456, tt:1479.709\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00002, loss_test:0.01533, lr:4.91e-02, fs:0.77922 (r=0.909,p=0.682),  time:28.479, tt:1509.370\n",
      "Ep:53, loss:0.00002, loss_test:0.01525, lr:4.91e-02, fs:0.77922 (r=0.909,p=0.682),  time:28.516, tt:1539.857\n",
      "Ep:54, loss:0.00002, loss_test:0.01506, lr:4.91e-02, fs:0.79130 (r=0.919,p=0.695),  time:28.534, tt:1569.371\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01504, lr:4.91e-02, fs:0.79825 (r=0.919,p=0.705),  time:28.563, tt:1599.539\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01506, lr:4.91e-02, fs:0.78947 (r=0.909,p=0.698),  time:28.595, tt:1629.914\n",
      "Ep:57, loss:0.00002, loss_test:0.01487, lr:4.91e-02, fs:0.78070 (r=0.899,p=0.690),  time:28.604, tt:1659.005\n",
      "Ep:58, loss:0.00002, loss_test:0.01485, lr:4.91e-02, fs:0.79111 (r=0.899,p=0.706),  time:28.618, tt:1688.440\n",
      "Ep:59, loss:0.00002, loss_test:0.01471, lr:4.91e-02, fs:0.79464 (r=0.899,p=0.712),  time:28.640, tt:1718.400\n",
      "Ep:60, loss:0.00002, loss_test:0.01460, lr:4.91e-02, fs:0.78222 (r=0.889,p=0.698),  time:28.665, tt:1748.595\n",
      "Ep:61, loss:0.00002, loss_test:0.01462, lr:4.91e-02, fs:0.78924 (r=0.889,p=0.710),  time:28.710, tt:1779.992\n",
      "Ep:62, loss:0.00002, loss_test:0.01461, lr:4.91e-02, fs:0.78140 (r=0.848,p=0.724),  time:28.747, tt:1811.054\n",
      "Ep:63, loss:0.00002, loss_test:0.01463, lr:4.91e-02, fs:0.77934 (r=0.838,p=0.728),  time:28.776, tt:1841.669\n",
      "Ep:64, loss:0.00002, loss_test:0.01462, lr:4.91e-02, fs:0.77570 (r=0.838,p=0.722),  time:28.799, tt:1871.964\n",
      "Ep:65, loss:0.00002, loss_test:0.01460, lr:4.91e-02, fs:0.78302 (r=0.838,p=0.735),  time:28.820, tt:1902.108\n",
      "Ep:66, loss:0.00002, loss_test:0.01462, lr:4.91e-02, fs:0.77358 (r=0.828,p=0.726),  time:28.835, tt:1931.924\n",
      "Ep:67, loss:0.00002, loss_test:0.01470, lr:4.86e-02, fs:0.78095 (r=0.828,p=0.739),  time:28.843, tt:1961.328\n",
      "Ep:68, loss:0.00001, loss_test:0.01474, lr:4.81e-02, fs:0.78302 (r=0.838,p=0.735),  time:28.868, tt:1991.878\n",
      "Ep:69, loss:0.00001, loss_test:0.01471, lr:4.76e-02, fs:0.78302 (r=0.838,p=0.735),  time:28.873, tt:2021.129\n",
      "Ep:70, loss:0.00001, loss_test:0.01483, lr:4.71e-02, fs:0.77934 (r=0.838,p=0.728),  time:28.886, tt:2050.928\n",
      "Ep:71, loss:0.00001, loss_test:0.01466, lr:4.67e-02, fs:0.78302 (r=0.838,p=0.735),  time:28.896, tt:2080.490\n",
      "Ep:72, loss:0.00001, loss_test:0.01492, lr:4.62e-02, fs:0.78673 (r=0.838,p=0.741),  time:28.908, tt:2110.249\n",
      "Ep:73, loss:0.00001, loss_test:0.01495, lr:4.57e-02, fs:0.79048 (r=0.838,p=0.748),  time:28.933, tt:2141.066\n",
      "Ep:74, loss:0.00001, loss_test:0.01492, lr:4.53e-02, fs:0.79048 (r=0.838,p=0.748),  time:28.966, tt:2172.417\n",
      "Ep:75, loss:0.00001, loss_test:0.01497, lr:4.48e-02, fs:0.79048 (r=0.838,p=0.748),  time:29.019, tt:2205.463\n",
      "Ep:76, loss:0.00001, loss_test:0.01491, lr:4.44e-02, fs:0.79048 (r=0.838,p=0.748),  time:29.038, tt:2235.950\n",
      "Ep:77, loss:0.00001, loss_test:0.01513, lr:4.39e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.040, tt:2265.117\n",
      "Ep:78, loss:0.00001, loss_test:0.01508, lr:4.35e-02, fs:0.79048 (r=0.838,p=0.748),  time:29.053, tt:2295.190\n",
      "Ep:79, loss:0.00001, loss_test:0.01518, lr:4.31e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.067, tt:2325.333\n",
      "Ep:80, loss:0.00001, loss_test:0.01524, lr:4.26e-02, fs:0.79426 (r=0.838,p=0.755),  time:29.086, tt:2355.992\n",
      "Ep:81, loss:0.00001, loss_test:0.01532, lr:4.22e-02, fs:0.79808 (r=0.838,p=0.761),  time:29.092, tt:2385.540\n",
      "Ep:82, loss:0.00001, loss_test:0.01529, lr:4.18e-02, fs:0.80193 (r=0.838,p=0.769),  time:29.117, tt:2416.747\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01556, lr:4.18e-02, fs:0.79808 (r=0.838,p=0.761),  time:29.131, tt:2446.992\n",
      "Ep:84, loss:0.00001, loss_test:0.01533, lr:4.18e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.146, tt:2477.369\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01560, lr:4.18e-02, fs:0.80583 (r=0.838,p=0.776),  time:29.149, tt:2506.774\n",
      "Ep:86, loss:0.00001, loss_test:0.01567, lr:4.18e-02, fs:0.81773 (r=0.838,p=0.798),  time:29.160, tt:2536.936\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01563, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.163, tt:2566.346\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01599, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.170, tt:2596.108\n",
      "Ep:89, loss:0.00001, loss_test:0.01575, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.163, tt:2624.687\n",
      "Ep:90, loss:0.00001, loss_test:0.01586, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.164, tt:2653.895\n",
      "Ep:91, loss:0.00001, loss_test:0.01614, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.169, tt:2683.522\n",
      "Ep:92, loss:0.00001, loss_test:0.01586, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.175, tt:2713.267\n",
      "Ep:93, loss:0.00001, loss_test:0.01644, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.172, tt:2742.171\n",
      "Ep:94, loss:0.00001, loss_test:0.01611, lr:4.18e-02, fs:0.82178 (r=0.838,p=0.806),  time:29.183, tt:2772.426\n",
      "Ep:95, loss:0.00001, loss_test:0.01623, lr:4.18e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.190, tt:2802.225\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01663, lr:4.18e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.206, tt:2832.972\n",
      "Ep:97, loss:0.00001, loss_test:0.01615, lr:4.18e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.223, tt:2863.826\n",
      "Ep:98, loss:0.00001, loss_test:0.01672, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.248, tt:2895.557\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01675, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.268, tt:2926.787\n",
      "Ep:100, loss:0.00001, loss_test:0.01654, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.278, tt:2957.087\n",
      "Ep:101, loss:0.00001, loss_test:0.01709, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.288, tt:2987.353\n",
      "Ep:102, loss:0.00001, loss_test:0.01675, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.301, tt:3017.961\n",
      "Ep:103, loss:0.00001, loss_test:0.01701, lr:4.18e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.301, tt:3047.350\n",
      "Ep:104, loss:0.00001, loss_test:0.01722, lr:4.18e-02, fs:0.83838 (r=0.838,p=0.838),  time:29.302, tt:3076.745\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01710, lr:4.18e-02, fs:0.83838 (r=0.838,p=0.838),  time:29.316, tt:3107.493\n",
      "Ep:106, loss:0.00001, loss_test:0.01739, lr:4.18e-02, fs:0.83838 (r=0.838,p=0.838),  time:29.326, tt:3137.848\n",
      "Ep:107, loss:0.00001, loss_test:0.01732, lr:4.18e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.329, tt:3167.559\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01746, lr:4.18e-02, fs:0.84264 (r=0.838,p=0.847),  time:29.329, tt:3196.831\n",
      "Ep:109, loss:0.00001, loss_test:0.01748, lr:4.18e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.343, tt:3227.699\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.01782, lr:4.18e-02, fs:0.85128 (r=0.838,p=0.865),  time:29.355, tt:3258.420\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01773, lr:4.18e-02, fs:0.84694 (r=0.838,p=0.856),  time:29.349, tt:3287.143\n",
      "Ep:112, loss:0.00001, loss_test:0.01777, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.352, tt:3316.773\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00001, loss_test:0.01804, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.348, tt:3345.718\n",
      "Ep:114, loss:0.00001, loss_test:0.01796, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.347, tt:3374.919\n",
      "Ep:115, loss:0.00001, loss_test:0.01832, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.334, tt:3402.762\n",
      "Ep:116, loss:0.00001, loss_test:0.01796, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.334, tt:3432.050\n",
      "Ep:117, loss:0.00001, loss_test:0.01852, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.334, tt:3461.387\n",
      "Ep:118, loss:0.00001, loss_test:0.01823, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.328, tt:3489.984\n",
      "Ep:119, loss:0.00001, loss_test:0.01843, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:29.325, tt:3518.942\n",
      "Ep:120, loss:0.00001, loss_test:0.01863, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.328, tt:3548.683\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.01840, lr:4.18e-02, fs:0.86010 (r=0.838,p=0.883),  time:29.343, tt:3579.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00001, loss_test:0.01909, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.338, tt:3608.553\n",
      "Ep:123, loss:0.00001, loss_test:0.01891, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.338, tt:3637.855\n",
      "Ep:124, loss:0.00001, loss_test:0.01922, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.339, tt:3667.383\n",
      "Ep:125, loss:0.00001, loss_test:0.01878, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.344, tt:3697.321\n",
      "Ep:126, loss:0.00001, loss_test:0.01929, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.347, tt:3727.029\n",
      "Ep:127, loss:0.00001, loss_test:0.01925, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.344, tt:3756.060\n",
      "Ep:128, loss:0.00001, loss_test:0.01940, lr:4.18e-02, fs:0.86911 (r=0.838,p=0.902),  time:29.342, tt:3785.159\n",
      "Ep:129, loss:0.00001, loss_test:0.01962, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.346, tt:3814.930\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00001, loss_test:0.01948, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.353, tt:3845.288\n",
      "Ep:131, loss:0.00001, loss_test:0.01976, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.357, tt:3875.131\n",
      "Ep:132, loss:0.00001, loss_test:0.01964, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.361, tt:3904.996\n",
      "Ep:133, loss:0.00000, loss_test:0.01999, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.365, tt:3934.874\n",
      "Ep:134, loss:0.00000, loss_test:0.02003, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.367, tt:3964.603\n",
      "Ep:135, loss:0.00000, loss_test:0.01994, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.370, tt:3994.275\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.02031, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.368, tt:4023.381\n",
      "Ep:137, loss:0.00000, loss_test:0.02007, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.374, tt:4053.564\n",
      "Ep:138, loss:0.00000, loss_test:0.02044, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.385, tt:4084.455\n",
      "Ep:139, loss:0.00000, loss_test:0.02038, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.378, tt:4112.878\n",
      "Ep:140, loss:0.00000, loss_test:0.02055, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.385, tt:4143.281\n",
      "Ep:141, loss:0.00000, loss_test:0.02073, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.384, tt:4172.472\n",
      "Ep:142, loss:0.00000, loss_test:0.02076, lr:4.18e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.380, tt:4201.402\n",
      "Ep:143, loss:0.00000, loss_test:0.02112, lr:4.18e-02, fs:0.86772 (r=0.828,p=0.911),  time:29.386, tt:4231.544\n",
      "Ep:144, loss:0.00000, loss_test:0.02065, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.395, tt:4262.275\n",
      "Ep:145, loss:0.00000, loss_test:0.02155, lr:4.18e-02, fs:0.84324 (r=0.788,p=0.907),  time:29.404, tt:4293.026\n",
      "Ep:146, loss:0.00000, loss_test:0.02089, lr:4.18e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.401, tt:4321.988\n",
      "Ep:147, loss:0.00000, loss_test:0.02159, lr:4.14e-02, fs:0.86022 (r=0.808,p=0.920),  time:29.397, tt:4350.688\n",
      "Ep:148, loss:0.00000, loss_test:0.02102, lr:4.10e-02, fs:0.87368 (r=0.838,p=0.912),  time:29.401, tt:4380.816\n",
      "Ep:149, loss:0.00000, loss_test:0.02145, lr:4.05e-02, fs:0.86631 (r=0.818,p=0.920),  time:29.408, tt:4411.263\n",
      "Ep:150, loss:0.00000, loss_test:0.02147, lr:4.01e-02, fs:0.87831 (r=0.838,p=0.922),  time:29.417, tt:4441.958\n",
      "Ep:151, loss:0.00000, loss_test:0.02164, lr:3.97e-02, fs:0.85405 (r=0.798,p=0.919),  time:29.416, tt:4471.265\n",
      "Ep:152, loss:0.00000, loss_test:0.02185, lr:3.93e-02, fs:0.87234 (r=0.828,p=0.921),  time:29.424, tt:4501.892\n",
      "Ep:153, loss:0.00000, loss_test:0.02165, lr:3.89e-02, fs:0.87234 (r=0.828,p=0.921),  time:29.436, tt:4533.195\n",
      "Ep:154, loss:0.00000, loss_test:0.02219, lr:3.86e-02, fs:0.84783 (r=0.788,p=0.918),  time:29.438, tt:4562.843\n",
      "Ep:155, loss:0.00000, loss_test:0.02179, lr:3.82e-02, fs:0.87701 (r=0.828,p=0.932),  time:29.451, tt:4594.298\n",
      "Ep:156, loss:0.00000, loss_test:0.02244, lr:3.78e-02, fs:0.82022 (r=0.737,p=0.924),  time:29.456, tt:4624.513\n",
      "Ep:157, loss:0.00000, loss_test:0.02205, lr:3.74e-02, fs:0.87568 (r=0.818,p=0.942),  time:29.453, tt:4653.544\n",
      "Ep:158, loss:0.00000, loss_test:0.02263, lr:3.70e-02, fs:0.82486 (r=0.737,p=0.936),  time:29.460, tt:4684.167\n",
      "Ep:159, loss:0.00000, loss_test:0.02234, lr:3.67e-02, fs:0.85714 (r=0.788,p=0.940),  time:29.460, tt:4713.576\n",
      "Ep:160, loss:0.00000, loss_test:0.02254, lr:3.63e-02, fs:0.86957 (r=0.808,p=0.941),  time:29.460, tt:4743.079\n",
      "Ep:161, loss:0.00000, loss_test:0.02272, lr:3.59e-02, fs:0.83146 (r=0.747,p=0.937),  time:29.455, tt:4771.642\n",
      "Ep:162, loss:0.00000, loss_test:0.02262, lr:3.56e-02, fs:0.83146 (r=0.747,p=0.937),  time:29.454, tt:4800.930\n",
      "Ep:163, loss:0.00000, loss_test:0.02295, lr:3.52e-02, fs:0.81818 (r=0.727,p=0.935),  time:29.458, tt:4831.157\n",
      "Ep:164, loss:0.00000, loss_test:0.02274, lr:3.49e-02, fs:0.84444 (r=0.768,p=0.938),  time:29.461, tt:4861.146\n",
      "Ep:165, loss:0.00000, loss_test:0.02313, lr:3.45e-02, fs:0.81818 (r=0.727,p=0.935),  time:29.469, tt:4891.880\n",
      "Ep:166, loss:0.00000, loss_test:0.02292, lr:3.42e-02, fs:0.81143 (r=0.717,p=0.934),  time:29.478, tt:4922.855\n",
      "Ep:167, loss:0.00000, loss_test:0.02329, lr:3.38e-02, fs:0.82486 (r=0.737,p=0.936),  time:29.480, tt:4952.694\n",
      "Ep:168, loss:0.00000, loss_test:0.02336, lr:3.35e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.476, tt:4981.461\n",
      "Ep:169, loss:0.00000, loss_test:0.02328, lr:3.32e-02, fs:0.80460 (r=0.707,p=0.933),  time:29.484, tt:5012.270\n",
      "Ep:170, loss:0.00000, loss_test:0.02342, lr:3.28e-02, fs:0.81818 (r=0.727,p=0.935),  time:29.483, tt:5041.577\n",
      "Ep:171, loss:0.00000, loss_test:0.02342, lr:3.25e-02, fs:0.80925 (r=0.707,p=0.946),  time:29.484, tt:5071.328\n",
      "Ep:172, loss:0.00000, loss_test:0.02359, lr:3.22e-02, fs:0.82081 (r=0.717,p=0.959),  time:29.492, tt:5102.189\n",
      "Ep:173, loss:0.00000, loss_test:0.02369, lr:3.19e-02, fs:0.80000 (r=0.687,p=0.958),  time:29.505, tt:5133.933\n",
      "Ep:174, loss:0.00000, loss_test:0.02364, lr:3.15e-02, fs:0.83429 (r=0.737,p=0.961),  time:29.509, tt:5164.127\n",
      "Ep:175, loss:0.00000, loss_test:0.02386, lr:3.12e-02, fs:0.80000 (r=0.687,p=0.958),  time:29.515, tt:5194.583\n",
      "Ep:176, loss:0.00000, loss_test:0.02365, lr:3.09e-02, fs:0.82081 (r=0.717,p=0.959),  time:29.522, tt:5225.455\n",
      "Ep:177, loss:0.00000, loss_test:0.02395, lr:3.06e-02, fs:0.80000 (r=0.687,p=0.958),  time:29.525, tt:5255.482\n",
      "Ep:178, loss:0.00000, loss_test:0.02385, lr:3.03e-02, fs:0.80702 (r=0.697,p=0.958),  time:29.530, tt:5285.820\n",
      "Ep:179, loss:0.00000, loss_test:0.02430, lr:3.00e-02, fs:0.78571 (r=0.667,p=0.957),  time:29.535, tt:5316.343\n",
      "Ep:180, loss:0.00000, loss_test:0.02393, lr:2.97e-02, fs:0.80000 (r=0.687,p=0.958),  time:29.544, tt:5347.415\n",
      "Ep:181, loss:0.00000, loss_test:0.02423, lr:2.94e-02, fs:0.79290 (r=0.677,p=0.957),  time:29.549, tt:5377.990\n",
      "Ep:182, loss:0.00000, loss_test:0.02428, lr:2.91e-02, fs:0.78571 (r=0.667,p=0.957),  time:29.556, tt:5408.820\n",
      "Ep:183, loss:0.00000, loss_test:0.02413, lr:2.88e-02, fs:0.80000 (r=0.687,p=0.958),  time:29.556, tt:5438.299\n",
      "Ep:184, loss:0.00000, loss_test:0.02448, lr:2.85e-02, fs:0.78571 (r=0.667,p=0.957),  time:29.557, tt:5468.053\n",
      "Ep:185, loss:0.00000, loss_test:0.02445, lr:2.82e-02, fs:0.78571 (r=0.667,p=0.957),  time:29.569, tt:5499.849\n",
      "Ep:186, loss:0.00000, loss_test:0.02456, lr:2.80e-02, fs:0.78571 (r=0.667,p=0.957),  time:29.571, tt:5529.699\n",
      "Ep:187, loss:0.00000, loss_test:0.02466, lr:2.77e-02, fs:0.77844 (r=0.657,p=0.956),  time:29.575, tt:5560.063\n",
      "Ep:188, loss:0.00000, loss_test:0.02472, lr:2.74e-02, fs:0.77844 (r=0.657,p=0.956),  time:29.588, tt:5592.135\n",
      "Ep:189, loss:0.00000, loss_test:0.02455, lr:2.71e-02, fs:0.76364 (r=0.636,p=0.955),  time:29.589, tt:5621.990\n",
      "Ep:190, loss:0.00000, loss_test:0.02489, lr:2.69e-02, fs:0.76364 (r=0.636,p=0.955),  time:29.599, tt:5653.407\n",
      "Ep:191, loss:0.00000, loss_test:0.02466, lr:2.66e-02, fs:0.75610 (r=0.626,p=0.954),  time:29.606, tt:5684.311\n",
      "Ep:192, loss:0.00000, loss_test:0.02498, lr:2.63e-02, fs:0.75610 (r=0.626,p=0.954),  time:29.614, tt:5715.555\n",
      "Ep:193, loss:0.00000, loss_test:0.02494, lr:2.61e-02, fs:0.74847 (r=0.616,p=0.953),  time:29.618, tt:5745.957\n",
      "Ep:194, loss:0.00000, loss_test:0.02501, lr:2.58e-02, fs:0.73292 (r=0.596,p=0.952),  time:29.614, tt:5774.805\n",
      "Ep:195, loss:0.00000, loss_test:0.02512, lr:2.55e-02, fs:0.73292 (r=0.596,p=0.952),  time:29.636, tt:5808.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00000, loss_test:0.02505, lr:2.53e-02, fs:0.71698 (r=0.576,p=0.950),  time:29.646, tt:5840.183\n",
      "Ep:197, loss:0.00000, loss_test:0.02524, lr:2.50e-02, fs:0.71698 (r=0.576,p=0.950),  time:29.645, tt:5869.634\n",
      "Ep:198, loss:0.00000, loss_test:0.02530, lr:2.48e-02, fs:0.70886 (r=0.566,p=0.949),  time:29.647, tt:5899.825\n",
      "Ep:199, loss:0.00000, loss_test:0.02535, lr:2.45e-02, fs:0.70886 (r=0.566,p=0.949),  time:29.654, tt:5930.720\n",
      "Ep:200, loss:0.00000, loss_test:0.02549, lr:2.43e-02, fs:0.70064 (r=0.556,p=0.948),  time:29.660, tt:5961.560\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13371, lr:1.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:29.916, tt:29.916\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13143, lr:1.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:29.687, tt:59.373\n",
      "Ep:2, loss:0.00026, loss_test:0.12842, lr:1.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:29.316, tt:87.949\n",
      "Ep:3, loss:0.00026, loss_test:0.12558, lr:1.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:29.096, tt:116.386\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12355, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:28.859, tt:144.295\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12229, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:28.341, tt:170.045\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12124, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:28.096, tt:196.675\n",
      "Ep:7, loss:0.00025, loss_test:0.12016, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:28.183, tt:225.464\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11901, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:28.771, tt:258.937\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11748, lr:1.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:29.113, tt:291.126\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.11575, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:29.395, tt:323.347\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11406, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:29.539, tt:354.466\n",
      "Ep:12, loss:0.00023, loss_test:0.11246, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:29.550, tt:384.153\n",
      "Ep:13, loss:0.00023, loss_test:0.11114, lr:1.00e-02, fs:0.68595 (r=0.838,p=0.580),  time:29.612, tt:414.570\n",
      "Ep:14, loss:0.00023, loss_test:0.10980, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:29.650, tt:444.745\n",
      "Ep:15, loss:0.00022, loss_test:0.10843, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:29.861, tt:477.769\n",
      "Ep:16, loss:0.00022, loss_test:0.10688, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:29.959, tt:509.300\n",
      "Ep:17, loss:0.00022, loss_test:0.10535, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:30.128, tt:542.310\n",
      "Ep:18, loss:0.00021, loss_test:0.10385, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:30.259, tt:574.912\n",
      "Ep:19, loss:0.00021, loss_test:0.10235, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:30.312, tt:606.247\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.10013, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:30.400, tt:638.395\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.09775, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:30.477, tt:670.504\n",
      "Ep:22, loss:0.00019, loss_test:0.09561, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:30.597, tt:703.736\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00019, loss_test:0.09366, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:30.680, tt:736.331\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00018, loss_test:0.09141, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:30.755, tt:768.880\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.08924, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:30.761, tt:799.798\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.08699, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:30.824, tt:832.251\n",
      "Ep:27, loss:0.00017, loss_test:0.08411, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:30.879, tt:864.622\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00016, loss_test:0.08185, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:30.960, tt:897.839\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00016, loss_test:0.08004, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:30.967, tt:929.004\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00015, loss_test:0.07794, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:30.931, tt:958.861\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.07552, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.965, tt:990.869\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.07297, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:31.011, tt:1023.374\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07187, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:31.045, tt:1055.522\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00013, loss_test:0.06943, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:31.090, tt:1088.137\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.06880, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:31.155, tt:1121.564\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00012, loss_test:0.06590, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:31.171, tt:1153.335\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.06541, lr:1.00e-02, fs:0.86916 (r=0.939,p=0.809),  time:31.203, tt:1185.727\n",
      "Ep:38, loss:0.00011, loss_test:0.06306, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:31.222, tt:1217.666\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.06188, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:31.236, tt:1249.446\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.06008, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:31.272, tt:1282.141\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.05855, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:31.285, tt:1313.974\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.05810, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:31.287, tt:1345.323\n",
      "Ep:43, loss:0.00009, loss_test:0.05716, lr:1.00e-02, fs:0.89623 (r=0.960,p=0.841),  time:31.306, tt:1377.486\n",
      "Ep:44, loss:0.00008, loss_test:0.05641, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:31.306, tt:1408.775\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.05458, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:31.340, tt:1441.649\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00008, loss_test:0.05368, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:31.351, tt:1473.503\n",
      "Ep:47, loss:0.00008, loss_test:0.05281, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:31.352, tt:1504.904\n",
      "Ep:48, loss:0.00007, loss_test:0.05470, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.388, tt:1538.020\n",
      "Ep:49, loss:0.00007, loss_test:0.05115, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.415, tt:1570.752\n",
      "Ep:50, loss:0.00007, loss_test:0.05372, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:31.441, tt:1603.487\n",
      "Ep:51, loss:0.00007, loss_test:0.05183, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.471, tt:1636.486\n",
      "Ep:52, loss:0.00007, loss_test:0.05104, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:31.490, tt:1668.969\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.05122, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:31.526, tt:1702.418\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00006, loss_test:0.05255, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.555, tt:1735.540\n",
      "Ep:55, loss:0.00006, loss_test:0.04778, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:31.552, tt:1766.925\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.05018, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:31.572, tt:1799.615\n",
      "Ep:57, loss:0.00006, loss_test:0.05275, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.563, tt:1830.627\n",
      "Ep:58, loss:0.00005, loss_test:0.04745, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:31.545, tt:1861.167\n",
      "Ep:59, loss:0.00005, loss_test:0.05371, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.535, tt:1892.077\n",
      "Ep:60, loss:0.00005, loss_test:0.04989, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.510, tt:1922.092\n",
      "Ep:61, loss:0.00005, loss_test:0.04907, lr:1.00e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.507, tt:1953.404\n",
      "Ep:62, loss:0.00005, loss_test:0.04986, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:31.500, tt:1984.499\n",
      "Ep:63, loss:0.00005, loss_test:0.04795, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:31.492, tt:2015.517\n",
      "Ep:64, loss:0.00005, loss_test:0.04776, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:31.507, tt:2047.949\n",
      "Ep:65, loss:0.00005, loss_test:0.04971, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.502, tt:2079.105\n",
      "Ep:66, loss:0.00004, loss_test:0.05306, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.522, tt:2112.000\n",
      "Ep:67, loss:0.00004, loss_test:0.04733, lr:9.90e-03, fs:0.91542 (r=0.929,p=0.902),  time:31.541, tt:2144.801\n",
      "Ep:68, loss:0.00004, loss_test:0.04997, lr:9.80e-03, fs:0.87755 (r=0.869,p=0.887),  time:31.554, tt:2177.248\n",
      "Ep:69, loss:0.00004, loss_test:0.04850, lr:9.70e-03, fs:0.90909 (r=0.909,p=0.909),  time:31.540, tt:2207.803\n",
      "Ep:70, loss:0.00004, loss_test:0.04977, lr:9.61e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.567, tt:2241.259\n",
      "Ep:71, loss:0.00004, loss_test:0.04753, lr:9.51e-03, fs:0.90640 (r=0.929,p=0.885),  time:31.563, tt:2272.538\n",
      "Ep:72, loss:0.00004, loss_test:0.05077, lr:9.41e-03, fs:0.88889 (r=0.889,p=0.889),  time:31.566, tt:2304.354\n",
      "Ep:73, loss:0.00004, loss_test:0.04699, lr:9.32e-03, fs:0.93939 (r=0.939,p=0.939),  time:31.593, tt:2337.850\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.05436, lr:9.32e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.599, tt:2369.889\n",
      "Ep:75, loss:0.00004, loss_test:0.04560, lr:9.32e-03, fs:0.93137 (r=0.960,p=0.905),  time:31.620, tt:2403.085\n",
      "Ep:76, loss:0.00004, loss_test:0.05374, lr:9.32e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.621, tt:2434.814\n",
      "Ep:77, loss:0.00004, loss_test:0.04661, lr:9.32e-03, fs:0.94000 (r=0.949,p=0.931),  time:31.611, tt:2465.645\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.05147, lr:9.32e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.617, tt:2497.752\n",
      "Ep:79, loss:0.00003, loss_test:0.04589, lr:9.32e-03, fs:0.92462 (r=0.929,p=0.920),  time:31.598, tt:2527.824\n",
      "Ep:80, loss:0.00003, loss_test:0.05363, lr:9.32e-03, fs:0.82609 (r=0.768,p=0.894),  time:31.633, tt:2562.272\n",
      "Ep:81, loss:0.00004, loss_test:0.05264, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.624, tt:2593.164\n",
      "Ep:82, loss:0.00003, loss_test:0.04912, lr:9.32e-03, fs:0.87500 (r=0.848,p=0.903),  time:31.624, tt:2624.807\n",
      "Ep:83, loss:0.00003, loss_test:0.04818, lr:9.32e-03, fs:0.92857 (r=0.919,p=0.938),  time:31.627, tt:2656.659\n",
      "Ep:84, loss:0.00003, loss_test:0.05205, lr:9.32e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.620, tt:2687.682\n",
      "Ep:85, loss:0.00003, loss_test:0.04524, lr:9.32e-03, fs:0.92683 (r=0.960,p=0.896),  time:31.603, tt:2717.877\n",
      "Ep:86, loss:0.00003, loss_test:0.05615, lr:9.32e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.589, tt:2748.256\n",
      "Ep:87, loss:0.00003, loss_test:0.04729, lr:9.32e-03, fs:0.93878 (r=0.929,p=0.948),  time:31.579, tt:2778.977\n",
      "Ep:88, loss:0.00003, loss_test:0.05237, lr:9.32e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.587, tt:2811.212\n",
      "Ep:89, loss:0.00003, loss_test:0.04990, lr:9.23e-03, fs:0.92063 (r=0.879,p=0.967),  time:31.585, tt:2842.655\n",
      "Ep:90, loss:0.00003, loss_test:0.05113, lr:9.14e-03, fs:0.83243 (r=0.778,p=0.895),  time:31.568, tt:2872.710\n",
      "Ep:91, loss:0.00003, loss_test:0.04839, lr:9.04e-03, fs:0.91005 (r=0.869,p=0.956),  time:31.566, tt:2904.046\n",
      "Ep:92, loss:0.00003, loss_test:0.05195, lr:8.95e-03, fs:0.83060 (r=0.768,p=0.905),  time:31.551, tt:2934.270\n",
      "Ep:93, loss:0.00002, loss_test:0.04830, lr:8.86e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.551, tt:2965.798\n",
      "Ep:94, loss:0.00002, loss_test:0.05217, lr:8.78e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.545, tt:2996.770\n",
      "Ep:95, loss:0.00002, loss_test:0.04893, lr:8.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.553, tt:3029.093\n",
      "Ep:96, loss:0.00002, loss_test:0.04957, lr:8.60e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.545, tt:3059.819\n",
      "Ep:97, loss:0.00002, loss_test:0.04945, lr:8.51e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.544, tt:3091.318\n",
      "Ep:98, loss:0.00002, loss_test:0.05155, lr:8.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.538, tt:3122.230\n",
      "Ep:99, loss:0.00002, loss_test:0.05020, lr:8.35e-03, fs:0.83516 (r=0.768,p=0.916),  time:31.539, tt:3153.891\n",
      "Ep:100, loss:0.00002, loss_test:0.04978, lr:8.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.534, tt:3184.894\n",
      "Ep:101, loss:0.00002, loss_test:0.05193, lr:8.18e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.544, tt:3217.451\n",
      "Ep:102, loss:0.00002, loss_test:0.04834, lr:8.10e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.525, tt:3247.101\n",
      "Ep:103, loss:0.00002, loss_test:0.05382, lr:8.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.517, tt:3277.732\n",
      "Ep:104, loss:0.00002, loss_test:0.04843, lr:7.94e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.502, tt:3307.719\n",
      "Ep:105, loss:0.00002, loss_test:0.05334, lr:7.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.493, tt:3338.301\n",
      "Ep:106, loss:0.00002, loss_test:0.04954, lr:7.78e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.502, tt:3370.700\n",
      "Ep:107, loss:0.00002, loss_test:0.05116, lr:7.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.493, tt:3401.215\n",
      "Ep:108, loss:0.00002, loss_test:0.04984, lr:7.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.495, tt:3432.930\n",
      "Ep:109, loss:0.00002, loss_test:0.04953, lr:7.55e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.493, tt:3464.277\n",
      "Ep:110, loss:0.00002, loss_test:0.04959, lr:7.47e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.469, tt:3493.036\n",
      "Ep:111, loss:0.00002, loss_test:0.04952, lr:7.40e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.462, tt:3523.769\n",
      "Ep:112, loss:0.00002, loss_test:0.04933, lr:7.32e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.459, tt:3554.875\n",
      "Ep:113, loss:0.00002, loss_test:0.04887, lr:7.25e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.444, tt:3584.622\n",
      "Ep:114, loss:0.00002, loss_test:0.05043, lr:7.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.446, tt:3616.269\n",
      "Ep:115, loss:0.00002, loss_test:0.04857, lr:7.11e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.466, tt:3650.080\n",
      "Ep:116, loss:0.00002, loss_test:0.05010, lr:7.03e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.450, tt:3679.601\n",
      "Ep:117, loss:0.00002, loss_test:0.04993, lr:6.96e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.451, tt:3711.179\n",
      "Ep:118, loss:0.00002, loss_test:0.05088, lr:6.89e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.442, tt:3741.594\n",
      "Ep:119, loss:0.00002, loss_test:0.04987, lr:6.83e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.434, tt:3772.125\n",
      "Ep:120, loss:0.00001, loss_test:0.05027, lr:6.76e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.440, tt:3804.200\n",
      "Ep:121, loss:0.00001, loss_test:0.05038, lr:6.69e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.441, tt:3835.756\n",
      "Ep:122, loss:0.00001, loss_test:0.04963, lr:6.62e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.434, tt:3866.415\n",
      "Ep:123, loss:0.00001, loss_test:0.05094, lr:6.56e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.452, tt:3900.023\n",
      "Ep:124, loss:0.00001, loss_test:0.04883, lr:6.49e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.449, tt:3931.122\n",
      "Ep:125, loss:0.00001, loss_test:0.05152, lr:6.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.452, tt:3962.945\n",
      "Ep:126, loss:0.00001, loss_test:0.04967, lr:6.36e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.455, tt:3994.757\n",
      "Ep:127, loss:0.00001, loss_test:0.05098, lr:6.30e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.454, tt:4026.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00001, loss_test:0.05114, lr:6.24e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.445, tt:4056.392\n",
      "Ep:129, loss:0.00001, loss_test:0.04971, lr:6.17e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.445, tt:4087.891\n",
      "Ep:130, loss:0.00001, loss_test:0.05118, lr:6.11e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.433, tt:4117.747\n",
      "Ep:131, loss:0.00001, loss_test:0.05007, lr:6.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.427, tt:4148.386\n",
      "Ep:132, loss:0.00001, loss_test:0.05212, lr:5.99e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.421, tt:4178.938\n",
      "Ep:133, loss:0.00001, loss_test:0.04982, lr:5.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.423, tt:4210.628\n",
      "Ep:134, loss:0.00001, loss_test:0.05191, lr:5.87e-03, fs:0.83978 (r=0.768,p=0.927),  time:31.404, tt:4239.583\n",
      "Ep:135, loss:0.00001, loss_test:0.05011, lr:5.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.381, tt:4267.770\n",
      "Ep:136, loss:0.00001, loss_test:0.05177, lr:5.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.376, tt:4298.466\n",
      "Ep:137, loss:0.00001, loss_test:0.05095, lr:5.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.362, tt:4327.914\n",
      "Ep:138, loss:0.00001, loss_test:0.05039, lr:5.64e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.350, tt:4357.696\n",
      "Ep:139, loss:0.00001, loss_test:0.05288, lr:5.58e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.333, tt:4386.619\n",
      "Ep:140, loss:0.00001, loss_test:0.05041, lr:5.53e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.333, tt:4417.971\n",
      "Ep:141, loss:0.00001, loss_test:0.05233, lr:5.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.326, tt:4448.298\n",
      "Ep:142, loss:0.00001, loss_test:0.04988, lr:5.42e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.322, tt:4478.981\n",
      "Ep:143, loss:0.00001, loss_test:0.05252, lr:5.36e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.310, tt:4508.617\n",
      "Ep:144, loss:0.00001, loss_test:0.05030, lr:5.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.299, tt:4538.320\n",
      "Ep:145, loss:0.00001, loss_test:0.05103, lr:5.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.293, tt:4568.728\n",
      "Ep:146, loss:0.00001, loss_test:0.05246, lr:5.20e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.293, tt:4600.126\n",
      "Ep:147, loss:0.00001, loss_test:0.04995, lr:5.15e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.296, tt:4631.798\n",
      "Ep:148, loss:0.00001, loss_test:0.05360, lr:5.10e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.288, tt:4661.949\n",
      "Ep:149, loss:0.00001, loss_test:0.05102, lr:5.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.290, tt:4693.472\n",
      "Ep:150, loss:0.00001, loss_test:0.05127, lr:5.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.286, tt:4724.251\n",
      "Ep:151, loss:0.00001, loss_test:0.05096, lr:4.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.280, tt:4754.583\n",
      "Ep:152, loss:0.00001, loss_test:0.05074, lr:4.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.269, tt:4784.225\n",
      "Ep:153, loss:0.00001, loss_test:0.05232, lr:4.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.270, tt:4815.528\n",
      "Ep:154, loss:0.00001, loss_test:0.05071, lr:4.80e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.269, tt:4846.735\n",
      "Ep:155, loss:0.00001, loss_test:0.05319, lr:4.75e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.263, tt:4877.012\n",
      "Ep:156, loss:0.00001, loss_test:0.05045, lr:4.71e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.257, tt:4907.288\n",
      "Ep:157, loss:0.00001, loss_test:0.05234, lr:4.66e-03, fs:0.84444 (r=0.768,p=0.938),  time:31.235, tt:4935.163\n",
      "Ep:158, loss:0.00001, loss_test:0.05233, lr:4.61e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.220, tt:4963.994\n",
      "Ep:159, loss:0.00001, loss_test:0.05104, lr:4.57e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.217, tt:4994.733\n",
      "Ep:160, loss:0.00001, loss_test:0.05218, lr:4.52e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.208, tt:5024.564\n",
      "Ep:161, loss:0.00001, loss_test:0.05144, lr:4.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.210, tt:5056.033\n",
      "Ep:162, loss:0.00001, loss_test:0.05127, lr:4.43e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.211, tt:5087.396\n",
      "Ep:163, loss:0.00001, loss_test:0.05162, lr:4.39e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.214, tt:5119.163\n",
      "Ep:164, loss:0.00001, loss_test:0.05187, lr:4.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.213, tt:5150.098\n",
      "Ep:165, loss:0.00001, loss_test:0.05127, lr:4.30e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.219, tt:5182.298\n",
      "Ep:166, loss:0.00001, loss_test:0.05130, lr:4.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.227, tt:5214.865\n",
      "Ep:167, loss:0.00001, loss_test:0.05209, lr:4.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.242, tt:5248.623\n",
      "Ep:168, loss:0.00001, loss_test:0.05142, lr:4.17e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.251, tt:5281.370\n",
      "Ep:169, loss:0.00001, loss_test:0.05162, lr:4.13e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.257, tt:5313.697\n",
      "Ep:170, loss:0.00001, loss_test:0.05228, lr:4.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.260, tt:5345.392\n",
      "Ep:171, loss:0.00001, loss_test:0.05173, lr:4.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.256, tt:5376.102\n",
      "Ep:172, loss:0.00001, loss_test:0.05199, lr:4.01e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.266, tt:5409.074\n",
      "Ep:173, loss:0.00001, loss_test:0.05212, lr:3.97e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.268, tt:5440.570\n",
      "Ep:174, loss:0.00001, loss_test:0.05141, lr:3.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.269, tt:5472.056\n",
      "Ep:175, loss:0.00001, loss_test:0.05227, lr:3.89e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.270, tt:5503.475\n",
      "Ep:176, loss:0.00001, loss_test:0.05158, lr:3.85e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.274, tt:5535.563\n",
      "Ep:177, loss:0.00001, loss_test:0.05218, lr:3.81e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.276, tt:5567.175\n",
      "Ep:178, loss:0.00001, loss_test:0.05139, lr:3.77e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.279, tt:5598.913\n",
      "Ep:179, loss:0.00001, loss_test:0.05074, lr:3.73e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.283, tt:5630.941\n",
      "Ep:180, loss:0.00001, loss_test:0.05286, lr:3.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.282, tt:5662.111\n",
      "Ep:181, loss:0.00001, loss_test:0.05105, lr:3.66e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.284, tt:5693.662\n",
      "Ep:182, loss:0.00001, loss_test:0.05118, lr:3.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.285, tt:5725.133\n",
      "Ep:183, loss:0.00001, loss_test:0.05372, lr:3.59e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.284, tt:5756.285\n",
      "Ep:184, loss:0.00001, loss_test:0.05060, lr:3.55e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.276, tt:5786.013\n",
      "Ep:185, loss:0.00001, loss_test:0.05152, lr:3.52e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.282, tt:5818.488\n",
      "Ep:186, loss:0.00001, loss_test:0.05338, lr:3.48e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.276, tt:5848.706\n",
      "Ep:187, loss:0.00001, loss_test:0.05087, lr:3.45e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.278, tt:5880.205\n",
      "Ep:188, loss:0.00001, loss_test:0.05163, lr:3.41e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.282, tt:5912.257\n",
      "Ep:189, loss:0.00001, loss_test:0.05350, lr:3.38e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.285, tt:5944.236\n",
      "Ep:190, loss:0.00001, loss_test:0.05116, lr:3.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.293, tt:5976.919\n",
      "Ep:191, loss:0.00001, loss_test:0.05155, lr:3.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.298, tt:6009.131\n",
      "Ep:192, loss:0.00001, loss_test:0.05306, lr:3.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.305, tt:6041.799\n",
      "Ep:193, loss:0.00001, loss_test:0.05153, lr:3.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.307, tt:6073.583\n",
      "Ep:194, loss:0.00001, loss_test:0.05134, lr:3.21e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.301, tt:6103.750\n",
      "Ep:195, loss:0.00001, loss_test:0.05314, lr:3.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.304, tt:6135.621\n",
      "Ep:196, loss:0.00001, loss_test:0.05211, lr:3.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.305, tt:6167.108\n",
      "Ep:197, loss:0.00001, loss_test:0.05124, lr:3.12e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.303, tt:6197.953\n",
      "Ep:198, loss:0.00001, loss_test:0.05239, lr:3.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.308, tt:6230.220\n",
      "Ep:199, loss:0.00001, loss_test:0.05270, lr:3.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.316, tt:6263.148\n",
      "Ep:200, loss:0.00001, loss_test:0.05140, lr:3.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.319, tt:6295.089\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.01947, lr:6.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:14.928, tt:14.928\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02447, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.529, tt:37.057\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02755, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.418, tt:64.255\n",
      "Ep:3, loss:0.00005, loss_test:0.02867, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.540, tt:98.158\n",
      "Ep:4, loss:0.00006, loss_test:0.02882, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.195, tt:135.977\n",
      "Ep:5, loss:0.00006, loss_test:0.02832, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.458, tt:176.750\n",
      "Ep:6, loss:0.00005, loss_test:0.02719, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.093, tt:217.651\n",
      "Ep:7, loss:0.00005, loss_test:0.02553, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.198, tt:257.584\n",
      "Ep:8, loss:0.00005, loss_test:0.02352, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.913, tt:296.220\n",
      "Ep:9, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:33.770, tt:337.695\n",
      "Ep:10, loss:0.00004, loss_test:0.02014, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:34.464, tt:379.106\n",
      "Ep:11, loss:0.00004, loss_test:0.01958, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:34.953, tt:419.430\n",
      "Ep:12, loss:0.00004, loss_test:0.01944, lr:6.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:35.623, tt:463.102\n",
      "Ep:13, loss:0.00004, loss_test:0.01874, lr:5.94e-02, fs:0.66390 (r=0.808,p=0.563),  time:35.933, tt:503.058\n",
      "Ep:14, loss:0.00004, loss_test:0.01780, lr:5.88e-02, fs:0.67470 (r=0.848,p=0.560),  time:36.211, tt:543.158\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01730, lr:5.88e-02, fs:0.67939 (r=0.899,p=0.546),  time:36.289, tt:580.628\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01698, lr:5.88e-02, fs:0.69663 (r=0.939,p=0.554),  time:36.500, tt:620.499\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01655, lr:5.88e-02, fs:0.70455 (r=0.939,p=0.564),  time:36.878, tt:663.798\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01611, lr:5.88e-02, fs:0.71875 (r=0.929,p=0.586),  time:36.978, tt:702.581\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01577, lr:5.88e-02, fs:0.73387 (r=0.919,p=0.611),  time:37.124, tt:742.470\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01554, lr:5.88e-02, fs:0.74074 (r=0.909,p=0.625),  time:37.301, tt:783.317\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01534, lr:5.88e-02, fs:0.74790 (r=0.899,p=0.640),  time:37.501, tt:825.017\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01511, lr:5.88e-02, fs:0.75745 (r=0.899,p=0.654),  time:37.644, tt:865.801\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01488, lr:5.88e-02, fs:0.75833 (r=0.919,p=0.645),  time:37.728, tt:905.465\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01469, lr:5.88e-02, fs:0.75519 (r=0.919,p=0.641),  time:37.886, tt:947.139\n",
      "Ep:25, loss:0.00003, loss_test:0.01451, lr:5.88e-02, fs:0.76271 (r=0.909,p=0.657),  time:37.983, tt:987.568\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01432, lr:5.88e-02, fs:0.78970 (r=0.929,p=0.687),  time:38.103, tt:1028.773\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01416, lr:5.88e-02, fs:0.81057 (r=0.929,p=0.719),  time:38.191, tt:1069.360\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01401, lr:5.88e-02, fs:0.80717 (r=0.909,p=0.726),  time:38.270, tt:1109.821\n",
      "Ep:29, loss:0.00002, loss_test:0.01385, lr:5.88e-02, fs:0.83408 (r=0.939,p=0.750),  time:38.365, tt:1150.958\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01367, lr:5.88e-02, fs:0.85068 (r=0.949,p=0.770),  time:38.455, tt:1192.093\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01349, lr:5.88e-02, fs:0.84545 (r=0.939,p=0.769),  time:38.565, tt:1234.084\n",
      "Ep:32, loss:0.00002, loss_test:0.01332, lr:5.88e-02, fs:0.84932 (r=0.939,p=0.775),  time:38.610, tt:1274.138\n",
      "Ep:33, loss:0.00002, loss_test:0.01318, lr:5.88e-02, fs:0.85185 (r=0.929,p=0.786),  time:38.606, tt:1312.621\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01305, lr:5.88e-02, fs:0.84651 (r=0.919,p=0.784),  time:38.663, tt:1353.202\n",
      "Ep:35, loss:0.00002, loss_test:0.01293, lr:5.88e-02, fs:0.85446 (r=0.919,p=0.798),  time:38.744, tt:1394.789\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01284, lr:5.88e-02, fs:0.85446 (r=0.919,p=0.798),  time:38.766, tt:1434.352\n",
      "Ep:37, loss:0.00002, loss_test:0.01276, lr:5.88e-02, fs:0.85849 (r=0.919,p=0.805),  time:38.855, tt:1476.499\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01269, lr:5.88e-02, fs:0.86667 (r=0.919,p=0.820),  time:38.879, tt:1516.291\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01260, lr:5.88e-02, fs:0.86667 (r=0.919,p=0.820),  time:38.939, tt:1557.573\n",
      "Ep:40, loss:0.00002, loss_test:0.01251, lr:5.88e-02, fs:0.86124 (r=0.909,p=0.818),  time:38.930, tt:1596.140\n",
      "Ep:41, loss:0.00002, loss_test:0.01244, lr:5.88e-02, fs:0.86124 (r=0.909,p=0.818),  time:38.938, tt:1635.403\n",
      "Ep:42, loss:0.00002, loss_test:0.01238, lr:5.88e-02, fs:0.86538 (r=0.909,p=0.826),  time:39.064, tt:1679.738\n",
      "Ep:43, loss:0.00002, loss_test:0.01234, lr:5.88e-02, fs:0.86829 (r=0.899,p=0.840),  time:39.086, tt:1719.780\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01231, lr:5.88e-02, fs:0.86829 (r=0.899,p=0.840),  time:39.145, tt:1761.505\n",
      "Ep:45, loss:0.00001, loss_test:0.01226, lr:5.88e-02, fs:0.87255 (r=0.899,p=0.848),  time:39.180, tt:1802.274\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01221, lr:5.88e-02, fs:0.87685 (r=0.899,p=0.856),  time:39.208, tt:1842.764\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01217, lr:5.88e-02, fs:0.87685 (r=0.899,p=0.856),  time:39.206, tt:1881.867\n",
      "Ep:48, loss:0.00001, loss_test:0.01213, lr:5.88e-02, fs:0.88119 (r=0.899,p=0.864),  time:39.248, tt:1923.161\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01212, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:39.277, tt:1963.837\n",
      "Ep:50, loss:0.00001, loss_test:0.01213, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:39.304, tt:2004.491\n",
      "Ep:51, loss:0.00001, loss_test:0.01214, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:39.328, tt:2045.058\n",
      "Ep:52, loss:0.00001, loss_test:0.01214, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:39.342, tt:2085.135\n",
      "Ep:53, loss:0.00001, loss_test:0.01213, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:39.387, tt:2126.902\n",
      "Ep:54, loss:0.00001, loss_test:0.01215, lr:5.88e-02, fs:0.87879 (r=0.879,p=0.879),  time:39.408, tt:2167.437\n",
      "Ep:55, loss:0.00001, loss_test:0.01216, lr:5.88e-02, fs:0.88325 (r=0.879,p=0.888),  time:39.523, tt:2213.313\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01217, lr:5.88e-02, fs:0.88325 (r=0.879,p=0.888),  time:39.516, tt:2252.412\n",
      "Ep:57, loss:0.00001, loss_test:0.01217, lr:5.88e-02, fs:0.88776 (r=0.879,p=0.897),  time:39.534, tt:2292.991\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00001, loss_test:0.01220, lr:5.88e-02, fs:0.88776 (r=0.879,p=0.897),  time:39.544, tt:2333.092\n",
      "Ep:59, loss:0.00001, loss_test:0.01222, lr:5.88e-02, fs:0.88205 (r=0.869,p=0.896),  time:39.565, tt:2373.870\n",
      "Ep:60, loss:0.00001, loss_test:0.01226, lr:5.88e-02, fs:0.88205 (r=0.869,p=0.896),  time:39.583, tt:2414.569\n",
      "Ep:61, loss:0.00001, loss_test:0.01231, lr:5.88e-02, fs:0.88083 (r=0.859,p=0.904),  time:39.605, tt:2455.541\n",
      "Ep:62, loss:0.00001, loss_test:0.01236, lr:5.88e-02, fs:0.88083 (r=0.859,p=0.904),  time:39.625, tt:2496.372\n",
      "Ep:63, loss:0.00001, loss_test:0.01238, lr:5.88e-02, fs:0.86911 (r=0.838,p=0.902),  time:39.599, tt:2534.311\n",
      "Ep:64, loss:0.00001, loss_test:0.01244, lr:5.88e-02, fs:0.86911 (r=0.838,p=0.902),  time:39.612, tt:2574.766\n",
      "Ep:65, loss:0.00001, loss_test:0.01246, lr:5.88e-02, fs:0.86316 (r=0.828,p=0.901),  time:39.589, tt:2612.869\n",
      "Ep:66, loss:0.00001, loss_test:0.01250, lr:5.88e-02, fs:0.86170 (r=0.818,p=0.910),  time:39.589, tt:2652.474\n",
      "Ep:67, loss:0.00001, loss_test:0.01258, lr:5.88e-02, fs:0.85561 (r=0.808,p=0.909),  time:39.574, tt:2691.011\n",
      "Ep:68, loss:0.00001, loss_test:0.01265, lr:5.88e-02, fs:0.84783 (r=0.788,p=0.918),  time:39.600, tt:2732.389\n",
      "Ep:69, loss:0.00001, loss_test:0.01268, lr:5.82e-02, fs:0.84153 (r=0.778,p=0.917),  time:39.627, tt:2773.908\n",
      "Ep:70, loss:0.00001, loss_test:0.01273, lr:5.76e-02, fs:0.84153 (r=0.778,p=0.917),  time:39.642, tt:2814.583\n",
      "Ep:71, loss:0.00001, loss_test:0.01280, lr:5.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.637, tt:2853.860\n",
      "Ep:72, loss:0.00001, loss_test:0.01284, lr:5.65e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.677, tt:2896.399\n",
      "Ep:73, loss:0.00001, loss_test:0.01292, lr:5.59e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.696, tt:2937.518\n",
      "Ep:74, loss:0.00001, loss_test:0.01300, lr:5.54e-02, fs:0.83516 (r=0.768,p=0.916),  time:39.707, tt:2978.057\n",
      "Ep:75, loss:0.00001, loss_test:0.01309, lr:5.48e-02, fs:0.83978 (r=0.768,p=0.927),  time:39.701, tt:3017.267\n",
      "Ep:76, loss:0.00001, loss_test:0.01315, lr:5.43e-02, fs:0.83978 (r=0.768,p=0.927),  time:39.715, tt:3058.071\n",
      "Ep:77, loss:0.00001, loss_test:0.01320, lr:5.37e-02, fs:0.83978 (r=0.768,p=0.927),  time:39.711, tt:3097.436\n",
      "Ep:78, loss:0.00001, loss_test:0.01327, lr:5.32e-02, fs:0.83978 (r=0.768,p=0.927),  time:39.704, tt:3136.600\n",
      "Ep:79, loss:0.00001, loss_test:0.01335, lr:5.27e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.727, tt:3178.197\n",
      "Ep:80, loss:0.00001, loss_test:0.01344, lr:5.21e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.737, tt:3218.680\n",
      "Ep:81, loss:0.00001, loss_test:0.01351, lr:5.16e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.753, tt:3259.767\n",
      "Ep:82, loss:0.00001, loss_test:0.01359, lr:5.11e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.759, tt:3300.033\n",
      "Ep:83, loss:0.00001, loss_test:0.01366, lr:5.06e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.773, tt:3340.939\n",
      "Ep:84, loss:0.00001, loss_test:0.01373, lr:5.01e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.764, tt:3379.897\n",
      "Ep:85, loss:0.00001, loss_test:0.01382, lr:4.96e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.754, tt:3418.845\n",
      "Ep:86, loss:0.00001, loss_test:0.01387, lr:4.91e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.740, tt:3457.389\n",
      "Ep:87, loss:0.00001, loss_test:0.01395, lr:4.86e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.719, tt:3495.241\n",
      "Ep:88, loss:0.00001, loss_test:0.01403, lr:4.81e-02, fs:0.84444 (r=0.768,p=0.938),  time:39.720, tt:3535.039\n",
      "Ep:89, loss:0.00001, loss_test:0.01413, lr:4.76e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.732, tt:3575.886\n",
      "Ep:90, loss:0.00001, loss_test:0.01421, lr:4.71e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.746, tt:3616.853\n",
      "Ep:91, loss:0.00001, loss_test:0.01428, lr:4.67e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.760, tt:3657.910\n",
      "Ep:92, loss:0.00001, loss_test:0.01435, lr:4.62e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.788, tt:3700.273\n",
      "Ep:93, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.778, tt:3739.176\n",
      "Ep:94, loss:0.00001, loss_test:0.01451, lr:4.53e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.776, tt:3778.723\n",
      "Ep:95, loss:0.00001, loss_test:0.01458, lr:4.48e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.773, tt:3818.211\n",
      "Ep:96, loss:0.00001, loss_test:0.01464, lr:4.44e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.768, tt:3857.526\n",
      "Ep:97, loss:0.00001, loss_test:0.01472, lr:4.39e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.748, tt:3895.312\n",
      "Ep:98, loss:0.00000, loss_test:0.01479, lr:4.35e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.750, tt:3935.256\n",
      "Ep:99, loss:0.00000, loss_test:0.01488, lr:4.31e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.741, tt:3974.071\n",
      "Ep:100, loss:0.00000, loss_test:0.01495, lr:4.26e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.745, tt:4014.294\n",
      "Ep:101, loss:0.00000, loss_test:0.01503, lr:4.22e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.746, tt:4054.058\n",
      "Ep:102, loss:0.00000, loss_test:0.01512, lr:4.18e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.750, tt:4094.201\n",
      "Ep:103, loss:0.00000, loss_test:0.01521, lr:4.14e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.763, tt:4135.389\n",
      "Ep:104, loss:0.00000, loss_test:0.01527, lr:4.10e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.770, tt:4175.844\n",
      "Ep:105, loss:0.00000, loss_test:0.01533, lr:4.05e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.788, tt:4217.503\n",
      "Ep:106, loss:0.00000, loss_test:0.01540, lr:4.01e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.789, tt:4257.461\n",
      "Ep:107, loss:0.00000, loss_test:0.01547, lr:3.97e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.792, tt:4297.487\n",
      "Ep:108, loss:0.00000, loss_test:0.01555, lr:3.93e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.795, tt:4337.629\n",
      "Ep:109, loss:0.00000, loss_test:0.01562, lr:3.89e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.789, tt:4376.747\n",
      "Ep:110, loss:0.00000, loss_test:0.01568, lr:3.86e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.797, tt:4417.459\n",
      "Ep:111, loss:0.00000, loss_test:0.01575, lr:3.82e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.801, tt:4457.765\n",
      "Ep:112, loss:0.00000, loss_test:0.01582, lr:3.78e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.797, tt:4497.047\n",
      "Ep:113, loss:0.00000, loss_test:0.01587, lr:3.74e-02, fs:0.84916 (r=0.768,p=0.950),  time:39.832, tt:4540.824\n",
      "Ep:114, loss:0.00000, loss_test:0.01595, lr:3.70e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.825, tt:4579.867\n",
      "Ep:115, loss:0.00000, loss_test:0.01603, lr:3.67e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.824, tt:4619.572\n",
      "Ep:116, loss:0.00000, loss_test:0.01608, lr:3.63e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.831, tt:4660.171\n",
      "Ep:117, loss:0.00000, loss_test:0.01614, lr:3.59e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.832, tt:4700.229\n",
      "Ep:118, loss:0.00000, loss_test:0.01620, lr:3.56e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.857, tt:4743.041\n",
      "Ep:119, loss:0.00000, loss_test:0.01626, lr:3.52e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.882, tt:4785.816\n",
      "Ep:120, loss:0.00000, loss_test:0.01634, lr:3.49e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.910, tt:4829.052\n",
      "Ep:121, loss:0.00000, loss_test:0.01638, lr:3.45e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.931, tt:4871.627\n",
      "Ep:122, loss:0.00000, loss_test:0.01644, lr:3.42e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.952, tt:4914.103\n",
      "Ep:123, loss:0.00000, loss_test:0.01648, lr:3.38e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.969, tt:4956.108\n",
      "Ep:124, loss:0.00000, loss_test:0.01655, lr:3.35e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.977, tt:4997.118\n",
      "Ep:125, loss:0.00000, loss_test:0.01661, lr:3.32e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.985, tt:5038.117\n",
      "Ep:126, loss:0.00000, loss_test:0.01668, lr:3.28e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.990, tt:5078.730\n",
      "Ep:127, loss:0.00000, loss_test:0.01672, lr:3.25e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.990, tt:5118.660\n",
      "Ep:128, loss:0.00000, loss_test:0.01676, lr:3.22e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.987, tt:5158.327\n",
      "Ep:129, loss:0.00000, loss_test:0.01682, lr:3.19e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.994, tt:5199.270\n",
      "Ep:130, loss:0.00000, loss_test:0.01687, lr:3.15e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.983, tt:5237.789\n",
      "Ep:131, loss:0.00000, loss_test:0.01692, lr:3.12e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.977, tt:5276.961\n",
      "Ep:132, loss:0.00000, loss_test:0.01699, lr:3.09e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.984, tt:5317.820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.01703, lr:3.06e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.984, tt:5357.896\n",
      "Ep:134, loss:0.00000, loss_test:0.01709, lr:3.03e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.982, tt:5397.555\n",
      "Ep:135, loss:0.00000, loss_test:0.01714, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.987, tt:5438.214\n",
      "Ep:136, loss:0.00000, loss_test:0.01719, lr:2.97e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.982, tt:5477.470\n",
      "Ep:137, loss:0.00000, loss_test:0.01724, lr:2.94e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.988, tt:5518.361\n",
      "Ep:138, loss:0.00000, loss_test:0.01729, lr:2.91e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.000, tt:5560.045\n",
      "Ep:139, loss:0.00000, loss_test:0.01735, lr:2.88e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.989, tt:5598.479\n",
      "Ep:140, loss:0.00000, loss_test:0.01740, lr:2.85e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.993, tt:5639.009\n",
      "Ep:141, loss:0.00000, loss_test:0.01744, lr:2.82e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.989, tt:5678.508\n",
      "Ep:142, loss:0.00000, loss_test:0.01749, lr:2.80e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.982, tt:5717.478\n",
      "Ep:143, loss:0.00000, loss_test:0.01753, lr:2.77e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.969, tt:5755.577\n",
      "Ep:144, loss:0.00000, loss_test:0.01759, lr:2.74e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.971, tt:5795.868\n",
      "Ep:145, loss:0.00000, loss_test:0.01763, lr:2.71e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.984, tt:5837.682\n",
      "Ep:146, loss:0.00000, loss_test:0.01767, lr:2.69e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.997, tt:5879.605\n",
      "Ep:147, loss:0.00000, loss_test:0.01771, lr:2.66e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.007, tt:5921.008\n",
      "Ep:148, loss:0.00000, loss_test:0.01777, lr:2.63e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.008, tt:5961.206\n",
      "Ep:149, loss:0.00000, loss_test:0.01781, lr:2.61e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.002, tt:6000.354\n",
      "Ep:150, loss:0.00000, loss_test:0.01784, lr:2.58e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.993, tt:6038.886\n",
      "Ep:151, loss:0.00000, loss_test:0.01788, lr:2.55e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.993, tt:6078.985\n",
      "Ep:152, loss:0.00000, loss_test:0.01792, lr:2.53e-02, fs:0.85393 (r=0.768,p=0.962),  time:39.996, tt:6119.352\n",
      "Ep:153, loss:0.00000, loss_test:0.01796, lr:2.50e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.003, tt:6160.487\n",
      "Ep:154, loss:0.00000, loss_test:0.01800, lr:2.48e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.017, tt:6202.605\n",
      "Ep:155, loss:0.00000, loss_test:0.01804, lr:2.45e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.026, tt:6244.052\n",
      "Ep:156, loss:0.00000, loss_test:0.01807, lr:2.43e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.042, tt:6286.607\n",
      "Ep:157, loss:0.00000, loss_test:0.01812, lr:2.40e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.038, tt:6326.043\n",
      "Ep:158, loss:0.00000, loss_test:0.01815, lr:2.38e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.034, tt:6365.358\n",
      "Ep:159, loss:0.00000, loss_test:0.01820, lr:2.36e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.065, tt:6410.469\n",
      "Ep:160, loss:0.00000, loss_test:0.01823, lr:2.33e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.064, tt:6450.232\n",
      "Ep:161, loss:0.00000, loss_test:0.01827, lr:2.31e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.059, tt:6489.500\n",
      "Ep:162, loss:0.00000, loss_test:0.01830, lr:2.29e-02, fs:0.85393 (r=0.768,p=0.962),  time:40.062, tt:6530.145\n",
      "Ep:163, loss:0.00000, loss_test:0.01834, lr:2.26e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.062, tt:6570.141\n",
      "Ep:164, loss:0.00000, loss_test:0.01837, lr:2.24e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.056, tt:6609.197\n",
      "Ep:165, loss:0.00000, loss_test:0.01841, lr:2.22e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.041, tt:6646.731\n",
      "Ep:166, loss:0.00000, loss_test:0.01845, lr:2.20e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.034, tt:6685.661\n",
      "Ep:167, loss:0.00000, loss_test:0.01847, lr:2.17e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.039, tt:6726.617\n",
      "Ep:168, loss:0.00000, loss_test:0.01850, lr:2.15e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.050, tt:6768.515\n",
      "Ep:169, loss:0.00000, loss_test:0.01854, lr:2.13e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.050, tt:6808.430\n",
      "Ep:170, loss:0.00000, loss_test:0.01857, lr:2.11e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.055, tt:6849.426\n",
      "Ep:171, loss:0.00000, loss_test:0.01860, lr:2.09e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.062, tt:6890.587\n",
      "Ep:172, loss:0.00000, loss_test:0.01863, lr:2.07e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.057, tt:6929.905\n",
      "Ep:173, loss:0.00000, loss_test:0.01867, lr:2.05e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.036, tt:6966.276\n",
      "Ep:174, loss:0.00000, loss_test:0.01869, lr:2.03e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.036, tt:7006.347\n",
      "Ep:175, loss:0.00000, loss_test:0.01872, lr:2.01e-02, fs:0.84746 (r=0.758,p=0.962),  time:40.028, tt:7044.922\n",
      "Ep:176, loss:0.00000, loss_test:0.01875, lr:1.99e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.023, tt:7084.116\n",
      "Ep:177, loss:0.00000, loss_test:0.01878, lr:1.97e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.023, tt:7124.128\n",
      "Ep:178, loss:0.00000, loss_test:0.01881, lr:1.95e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.017, tt:7162.964\n",
      "Ep:179, loss:0.00000, loss_test:0.01884, lr:1.93e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.011, tt:7202.008\n",
      "Ep:180, loss:0.00000, loss_test:0.01886, lr:1.91e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.032, tt:7245.876\n",
      "Ep:181, loss:0.00000, loss_test:0.01889, lr:1.89e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.034, tt:7286.147\n",
      "Ep:182, loss:0.00000, loss_test:0.01893, lr:1.87e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.032, tt:7325.775\n",
      "Ep:183, loss:0.00000, loss_test:0.01894, lr:1.85e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.030, tt:7365.570\n",
      "Ep:184, loss:0.00000, loss_test:0.01897, lr:1.83e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.026, tt:7404.772\n",
      "Ep:185, loss:0.00000, loss_test:0.01899, lr:1.81e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.019, tt:7443.598\n",
      "Ep:186, loss:0.00000, loss_test:0.01902, lr:1.80e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.012, tt:7482.177\n",
      "Ep:187, loss:0.00000, loss_test:0.01905, lr:1.78e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.008, tt:7521.466\n",
      "Ep:188, loss:0.00000, loss_test:0.01907, lr:1.76e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.006, tt:7561.225\n",
      "Ep:189, loss:0.00000, loss_test:0.01910, lr:1.74e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.009, tt:7601.762\n",
      "Ep:190, loss:0.00000, loss_test:0.01912, lr:1.73e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.014, tt:7642.617\n",
      "Ep:191, loss:0.00000, loss_test:0.01916, lr:1.71e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.017, tt:7683.316\n",
      "Ep:192, loss:0.00000, loss_test:0.01918, lr:1.69e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.020, tt:7723.849\n",
      "Ep:193, loss:0.00000, loss_test:0.01920, lr:1.67e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.026, tt:7765.138\n",
      "Ep:194, loss:0.00000, loss_test:0.01922, lr:1.66e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.032, tt:7806.316\n",
      "Ep:195, loss:0.00000, loss_test:0.01925, lr:1.64e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.025, tt:7844.922\n",
      "Ep:196, loss:0.00000, loss_test:0.01927, lr:1.62e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.017, tt:7883.406\n",
      "Ep:197, loss:0.00000, loss_test:0.01930, lr:1.61e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.015, tt:7922.926\n",
      "Ep:198, loss:0.00000, loss_test:0.01931, lr:1.59e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.009, tt:7961.753\n",
      "Ep:199, loss:0.00000, loss_test:0.01934, lr:1.58e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.008, tt:8001.699\n",
      "Ep:200, loss:0.00000, loss_test:0.01936, lr:1.56e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.009, tt:8041.742\n",
      "Ep:201, loss:0.00000, loss_test:0.01938, lr:1.54e-02, fs:0.84091 (r=0.747,p=0.961),  time:40.039, tt:8087.830\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14024, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.820, tt:38.820\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.13871, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.804, tt:69.607\n",
      "Ep:2, loss:0.00027, loss_test:0.13600, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:33.803, tt:101.410\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13130, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:33.382, tt:133.528\n",
      "Ep:4, loss:0.00026, loss_test:0.12351, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:35.134, tt:175.672\n",
      "Ep:5, loss:0.00024, loss_test:0.11704, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:36.259, tt:217.556\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11300, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:36.695, tt:256.868\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10880, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:37.078, tt:296.625\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10571, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:37.569, tt:338.125\n",
      "Ep:9, loss:0.00021, loss_test:0.10011, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:37.917, tt:379.172\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09618, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:38.228, tt:420.507\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09316, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:38.464, tt:461.573\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09080, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:38.725, tt:503.425\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.08786, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:38.975, tt:545.653\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.08528, lr:1.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:39.180, tt:587.697\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.08292, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:39.427, tt:630.829\n",
      "Ep:16, loss:0.00015, loss_test:0.08056, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:39.605, tt:673.293\n",
      "Ep:17, loss:0.00014, loss_test:0.07868, lr:1.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:39.784, tt:716.112\n",
      "Ep:18, loss:0.00013, loss_test:0.07702, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:39.927, tt:758.620\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00013, loss_test:0.07528, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:40.132, tt:802.650\n",
      "Ep:20, loss:0.00012, loss_test:0.07354, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:40.198, tt:844.161\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07190, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.338, tt:887.440\n",
      "Ep:22, loss:0.00011, loss_test:0.07060, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:40.450, tt:930.347\n",
      "Ep:23, loss:0.00010, loss_test:0.06939, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:40.553, tt:973.262\n",
      "Ep:24, loss:0.00010, loss_test:0.06823, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:40.622, tt:1015.546\n",
      "Ep:25, loss:0.00010, loss_test:0.06719, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:40.680, tt:1057.669\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.06617, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.796, tt:1101.495\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.06517, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:40.813, tt:1142.757\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.06421, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:40.865, tt:1185.087\n",
      "Ep:29, loss:0.00008, loss_test:0.06361, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:40.927, tt:1227.798\n",
      "Ep:30, loss:0.00008, loss_test:0.06288, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:40.979, tt:1270.345\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.06212, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:40.987, tt:1311.575\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.06125, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:40.999, tt:1352.960\n",
      "Ep:33, loss:0.00007, loss_test:0.06012, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:41.047, tt:1395.587\n",
      "Ep:34, loss:0.00006, loss_test:0.05943, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:41.051, tt:1436.783\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.05937, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:41.046, tt:1477.655\n",
      "Ep:36, loss:0.00006, loss_test:0.05848, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:41.094, tt:1520.482\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.05762, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:41.069, tt:1560.637\n",
      "Ep:38, loss:0.00005, loss_test:0.05754, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:41.024, tt:1599.932\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.05641, lr:1.00e-02, fs:0.90722 (r=0.889,p=0.926),  time:41.061, tt:1642.447\n",
      "Ep:40, loss:0.00005, loss_test:0.05603, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:41.098, tt:1685.002\n",
      "Ep:41, loss:0.00005, loss_test:0.05618, lr:1.00e-02, fs:0.91667 (r=0.889,p=0.946),  time:41.097, tt:1726.077\n",
      "Ep:42, loss:0.00004, loss_test:0.05520, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:41.090, tt:1766.849\n",
      "Ep:43, loss:0.00004, loss_test:0.05471, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:41.110, tt:1808.825\n",
      "Ep:44, loss:0.00004, loss_test:0.05465, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:41.082, tt:1848.675\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.05390, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:41.118, tt:1891.426\n",
      "Ep:46, loss:0.00004, loss_test:0.05387, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:41.132, tt:1933.209\n",
      "Ep:47, loss:0.00004, loss_test:0.05340, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:41.111, tt:1973.317\n",
      "Ep:48, loss:0.00003, loss_test:0.05297, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.078, tt:2012.800\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.05322, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:41.085, tt:2054.253\n",
      "Ep:50, loss:0.00003, loss_test:0.05280, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.102, tt:2096.181\n",
      "Ep:51, loss:0.00003, loss_test:0.05225, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.077, tt:2135.991\n",
      "Ep:52, loss:0.00003, loss_test:0.05291, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.062, tt:2176.306\n",
      "Ep:53, loss:0.00003, loss_test:0.05267, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.055, tt:2216.973\n",
      "Ep:54, loss:0.00003, loss_test:0.05236, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.111, tt:2261.118\n",
      "Ep:55, loss:0.00003, loss_test:0.05199, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.115, tt:2302.441\n",
      "Ep:56, loss:0.00003, loss_test:0.05130, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.113, tt:2343.431\n",
      "Ep:57, loss:0.00002, loss_test:0.05181, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.137, tt:2385.917\n",
      "Ep:58, loss:0.00002, loss_test:0.05098, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.146, tt:2427.596\n",
      "Ep:59, loss:0.00002, loss_test:0.05175, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.152, tt:2469.097\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.05092, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.177, tt:2511.786\n",
      "Ep:61, loss:0.00002, loss_test:0.05078, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:41.187, tt:2553.617\n",
      "Ep:62, loss:0.00002, loss_test:0.05137, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.204, tt:2595.873\n",
      "Ep:63, loss:0.00002, loss_test:0.05062, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.248, tt:2639.851\n",
      "Ep:64, loss:0.00002, loss_test:0.05079, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.262, tt:2682.038\n",
      "Ep:65, loss:0.00002, loss_test:0.05108, lr:1.00e-02, fs:0.94118 (r=0.889,p=1.000),  time:41.273, tt:2723.986\n",
      "Ep:66, loss:0.00002, loss_test:0.04996, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.308, tt:2767.654\n",
      "Ep:67, loss:0.00002, loss_test:0.05032, lr:1.00e-02, fs:0.93548 (r=0.879,p=1.000),  time:41.391, tt:2814.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00002, loss_test:0.04987, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.393, tt:2856.102\n",
      "Ep:69, loss:0.00001, loss_test:0.05080, lr:1.00e-02, fs:0.93617 (r=0.889,p=0.989),  time:41.411, tt:2898.789\n",
      "Ep:70, loss:0.00001, loss_test:0.05050, lr:1.00e-02, fs:0.93048 (r=0.879,p=0.989),  time:41.423, tt:2941.032\n",
      "Ep:71, loss:0.00001, loss_test:0.04925, lr:9.90e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.450, tt:2984.366\n",
      "Ep:72, loss:0.00001, loss_test:0.05085, lr:9.80e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.451, tt:3025.905\n",
      "Ep:73, loss:0.00001, loss_test:0.04987, lr:9.70e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.472, tt:3068.963\n",
      "Ep:74, loss:0.00001, loss_test:0.04994, lr:9.61e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.478, tt:3110.816\n",
      "Ep:75, loss:0.00001, loss_test:0.05076, lr:9.51e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.497, tt:3153.756\n",
      "Ep:76, loss:0.00001, loss_test:0.04959, lr:9.41e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.490, tt:3194.735\n",
      "Ep:77, loss:0.00001, loss_test:0.04961, lr:9.32e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.481, tt:3235.548\n",
      "Ep:78, loss:0.00001, loss_test:0.05047, lr:9.23e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.501, tt:3278.540\n",
      "Ep:79, loss:0.00001, loss_test:0.04939, lr:9.14e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.517, tt:3321.327\n",
      "Ep:80, loss:0.00001, loss_test:0.04974, lr:9.04e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.548, tt:3365.410\n",
      "Ep:81, loss:0.00001, loss_test:0.04981, lr:8.95e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.551, tt:3407.200\n",
      "Ep:82, loss:0.00001, loss_test:0.04981, lr:8.86e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.542, tt:3447.993\n",
      "Ep:83, loss:0.00001, loss_test:0.05014, lr:8.78e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.543, tt:3489.591\n",
      "Ep:84, loss:0.00001, loss_test:0.04940, lr:8.69e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.538, tt:3530.755\n",
      "Ep:85, loss:0.00001, loss_test:0.04905, lr:8.60e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.549, tt:3573.252\n",
      "Ep:86, loss:0.00001, loss_test:0.05036, lr:8.51e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.572, tt:3616.772\n",
      "Ep:87, loss:0.00001, loss_test:0.05067, lr:8.43e-03, fs:0.91892 (r=0.859,p=0.988),  time:41.644, tt:3664.686\n",
      "Ep:88, loss:0.00001, loss_test:0.04887, lr:8.35e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.645, tt:3706.385\n",
      "Ep:89, loss:0.00001, loss_test:0.05005, lr:8.26e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.655, tt:3748.980\n",
      "Ep:90, loss:0.00001, loss_test:0.05051, lr:8.18e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.704, tt:3795.043\n",
      "Ep:91, loss:0.00001, loss_test:0.04884, lr:8.10e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.749, tt:3840.950\n",
      "Ep:92, loss:0.00001, loss_test:0.04947, lr:8.02e-03, fs:0.93048 (r=0.879,p=0.989),  time:41.800, tt:3887.401\n",
      "Ep:93, loss:0.00001, loss_test:0.04961, lr:7.94e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.840, tt:3932.999\n",
      "Ep:94, loss:0.00001, loss_test:0.04902, lr:7.86e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.890, tt:3979.549\n",
      "Ep:95, loss:0.00001, loss_test:0.04959, lr:7.78e-03, fs:0.93617 (r=0.889,p=0.989),  time:41.927, tt:4025.018\n",
      "Ep:96, loss:0.00001, loss_test:0.04965, lr:7.70e-03, fs:0.92473 (r=0.869,p=0.989),  time:41.969, tt:4070.992\n",
      "Ep:97, loss:0.00001, loss_test:0.04931, lr:7.62e-03, fs:0.92473 (r=0.869,p=0.989),  time:42.008, tt:4116.787\n",
      "Ep:98, loss:0.00001, loss_test:0.05011, lr:7.55e-03, fs:0.92473 (r=0.869,p=0.989),  time:42.010, tt:4158.979\n",
      "Ep:99, loss:0.00001, loss_test:0.04925, lr:7.47e-03, fs:0.93048 (r=0.879,p=0.989),  time:42.018, tt:4201.814\n",
      "Ep:100, loss:0.00001, loss_test:0.04922, lr:7.40e-03, fs:0.91892 (r=0.859,p=0.988),  time:42.036, tt:4245.681\n",
      "Ep:101, loss:0.00001, loss_test:0.04988, lr:7.32e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.082, tt:4292.372\n",
      "Ep:102, loss:0.00001, loss_test:0.04914, lr:7.25e-03, fs:0.92473 (r=0.869,p=0.989),  time:42.094, tt:4335.668\n",
      "Ep:103, loss:0.00000, loss_test:0.04985, lr:7.18e-03, fs:0.91892 (r=0.859,p=0.988),  time:42.126, tt:4381.079\n",
      "Ep:104, loss:0.00000, loss_test:0.04992, lr:7.11e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.137, tt:4424.358\n",
      "Ep:105, loss:0.00000, loss_test:0.04903, lr:7.03e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.161, tt:4469.113\n",
      "Ep:106, loss:0.00000, loss_test:0.04975, lr:6.96e-03, fs:0.91892 (r=0.859,p=0.988),  time:42.220, tt:4517.519\n",
      "Ep:107, loss:0.00000, loss_test:0.05062, lr:6.89e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.242, tt:4562.178\n",
      "Ep:108, loss:0.00000, loss_test:0.04974, lr:6.83e-03, fs:0.88889 (r=0.808,p=0.988),  time:42.257, tt:4605.972\n",
      "Ep:109, loss:0.00000, loss_test:0.04913, lr:6.76e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.265, tt:4649.136\n",
      "Ep:110, loss:0.00000, loss_test:0.04995, lr:6.69e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.271, tt:4692.122\n",
      "Ep:111, loss:0.00000, loss_test:0.04952, lr:6.62e-03, fs:0.90110 (r=0.828,p=0.988),  time:42.272, tt:4734.479\n",
      "Ep:112, loss:0.00000, loss_test:0.04913, lr:6.56e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.285, tt:4778.254\n",
      "Ep:113, loss:0.00000, loss_test:0.04945, lr:6.49e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.276, tt:4819.446\n",
      "Ep:114, loss:0.00000, loss_test:0.04966, lr:6.43e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.302, tt:4864.713\n",
      "Ep:115, loss:0.00000, loss_test:0.04940, lr:6.36e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.307, tt:4907.636\n",
      "Ep:116, loss:0.00000, loss_test:0.04954, lr:6.30e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.316, tt:4950.967\n",
      "Ep:117, loss:0.00000, loss_test:0.04961, lr:6.24e-03, fs:0.85714 (r=0.758,p=0.987),  time:42.340, tt:4996.120\n",
      "Ep:118, loss:0.00000, loss_test:0.04947, lr:6.17e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.349, tt:5039.523\n",
      "Ep:119, loss:0.00000, loss_test:0.04924, lr:6.11e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.355, tt:5082.546\n",
      "Ep:120, loss:0.00000, loss_test:0.04922, lr:6.05e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.357, tt:5125.233\n",
      "Ep:121, loss:0.00000, loss_test:0.04907, lr:5.99e-03, fs:0.91304 (r=0.848,p=0.988),  time:42.367, tt:5168.817\n",
      "Ep:122, loss:0.00000, loss_test:0.04937, lr:5.93e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.390, tt:5213.937\n",
      "Ep:123, loss:0.00000, loss_test:0.04915, lr:5.87e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.409, tt:5258.723\n",
      "Ep:124, loss:0.00000, loss_test:0.04918, lr:5.81e-03, fs:0.90710 (r=0.838,p=0.988),  time:42.397, tt:5299.570\n",
      "Ep:125, loss:0.00000, loss_test:0.04960, lr:5.75e-03, fs:0.84393 (r=0.737,p=0.986),  time:42.397, tt:5342.079\n",
      "Ep:126, loss:0.00000, loss_test:0.04940, lr:5.70e-03, fs:0.85057 (r=0.747,p=0.987),  time:42.405, tt:5385.462\n",
      "Ep:127, loss:0.00000, loss_test:0.04917, lr:5.64e-03, fs:0.90110 (r=0.828,p=0.988),  time:42.393, tt:5426.265\n",
      "Ep:128, loss:0.00000, loss_test:0.04951, lr:5.58e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.391, tt:5468.451\n",
      "Ep:129, loss:0.00000, loss_test:0.04994, lr:5.53e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.391, tt:5510.876\n",
      "Ep:130, loss:0.00000, loss_test:0.04950, lr:5.47e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.391, tt:5553.202\n",
      "Ep:131, loss:0.00000, loss_test:0.04926, lr:5.42e-03, fs:0.90110 (r=0.828,p=0.988),  time:42.390, tt:5595.481\n",
      "Ep:132, loss:0.00000, loss_test:0.04914, lr:5.36e-03, fs:0.90110 (r=0.828,p=0.988),  time:42.374, tt:5635.781\n",
      "Ep:133, loss:0.00000, loss_test:0.04926, lr:5.31e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.365, tt:5676.930\n",
      "Ep:134, loss:0.00000, loss_test:0.04991, lr:5.26e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.363, tt:5718.972\n",
      "Ep:135, loss:0.00000, loss_test:0.04959, lr:5.20e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.354, tt:5760.107\n",
      "Ep:136, loss:0.00000, loss_test:0.04899, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:42.350, tt:5801.914\n",
      "Ep:137, loss:0.00000, loss_test:0.04970, lr:5.10e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.349, tt:5844.192\n",
      "Ep:138, loss:0.00000, loss_test:0.04989, lr:5.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.349, tt:5886.577\n",
      "Ep:139, loss:0.00000, loss_test:0.04929, lr:5.00e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.339, tt:5927.520\n",
      "Ep:140, loss:0.00000, loss_test:0.04927, lr:4.95e-03, fs:0.84393 (r=0.737,p=0.986),  time:42.339, tt:5969.733\n",
      "Ep:141, loss:0.00000, loss_test:0.05002, lr:4.90e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.337, tt:6011.920\n",
      "Ep:142, loss:0.00000, loss_test:0.04992, lr:4.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.331, tt:6053.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.04919, lr:4.80e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.331, tt:6095.633\n",
      "Ep:144, loss:0.00000, loss_test:0.04953, lr:4.75e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.323, tt:6136.815\n",
      "Ep:145, loss:0.00000, loss_test:0.04971, lr:4.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.318, tt:6178.458\n",
      "Ep:146, loss:0.00000, loss_test:0.04942, lr:4.66e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.320, tt:6221.030\n",
      "Ep:147, loss:0.00000, loss_test:0.04916, lr:4.61e-03, fs:0.84393 (r=0.737,p=0.986),  time:42.321, tt:6263.441\n",
      "Ep:148, loss:0.00000, loss_test:0.04931, lr:4.57e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.331, tt:6307.352\n",
      "Ep:149, loss:0.00000, loss_test:0.04942, lr:4.52e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.313, tt:6346.927\n",
      "Ep:150, loss:0.00000, loss_test:0.04910, lr:4.48e-03, fs:0.85057 (r=0.747,p=0.987),  time:42.308, tt:6388.507\n",
      "Ep:151, loss:0.00000, loss_test:0.04949, lr:4.43e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.288, tt:6427.754\n",
      "Ep:152, loss:0.00000, loss_test:0.04985, lr:4.39e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.278, tt:6468.573\n",
      "Ep:153, loss:0.00000, loss_test:0.04942, lr:4.34e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.280, tt:6511.060\n",
      "Ep:154, loss:0.00000, loss_test:0.04911, lr:4.30e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.276, tt:6552.729\n",
      "Ep:155, loss:0.00000, loss_test:0.04925, lr:4.26e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.273, tt:6594.532\n",
      "Ep:156, loss:0.00000, loss_test:0.04926, lr:4.21e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.280, tt:6637.884\n",
      "Ep:157, loss:0.00000, loss_test:0.04909, lr:4.17e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.270, tt:6678.689\n",
      "Ep:158, loss:0.00000, loss_test:0.04912, lr:4.13e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.271, tt:6721.017\n",
      "Ep:159, loss:0.00000, loss_test:0.04910, lr:4.09e-03, fs:0.83721 (r=0.727,p=0.986),  time:42.269, tt:6763.087\n",
      "Ep:160, loss:0.00000, loss_test:0.04908, lr:4.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.263, tt:6804.405\n",
      "Ep:161, loss:0.00000, loss_test:0.04906, lr:4.01e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.260, tt:6846.172\n",
      "Ep:162, loss:0.00000, loss_test:0.04917, lr:3.97e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.249, tt:6886.567\n",
      "Ep:163, loss:0.00000, loss_test:0.04918, lr:3.93e-03, fs:0.85714 (r=0.758,p=0.987),  time:42.244, tt:6928.010\n",
      "Ep:164, loss:0.00000, loss_test:0.04904, lr:3.89e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.231, tt:6968.193\n",
      "Ep:165, loss:0.00000, loss_test:0.04930, lr:3.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.220, tt:7008.561\n",
      "Ep:166, loss:0.00000, loss_test:0.04957, lr:3.81e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.205, tt:7048.272\n",
      "Ep:167, loss:0.00000, loss_test:0.04931, lr:3.77e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.198, tt:7089.292\n",
      "Ep:168, loss:0.00000, loss_test:0.04887, lr:3.73e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.188, tt:7129.783\n",
      "Ep:169, loss:0.00000, loss_test:0.04925, lr:3.70e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.187, tt:7171.837\n",
      "Ep:170, loss:0.00000, loss_test:0.04944, lr:3.66e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.182, tt:7213.056\n",
      "Ep:171, loss:0.00000, loss_test:0.04910, lr:3.62e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.184, tt:7255.591\n",
      "Ep:172, loss:0.00000, loss_test:0.04885, lr:3.59e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.176, tt:7296.521\n",
      "Ep:173, loss:0.00000, loss_test:0.04915, lr:3.55e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.165, tt:7336.729\n",
      "Ep:174, loss:0.00000, loss_test:0.04941, lr:3.52e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.159, tt:7377.828\n",
      "Ep:175, loss:0.00000, loss_test:0.04918, lr:3.48e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.146, tt:7417.609\n",
      "Ep:176, loss:0.00000, loss_test:0.04899, lr:3.45e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.133, tt:7457.580\n",
      "Ep:177, loss:0.00000, loss_test:0.04909, lr:3.41e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.124, tt:7497.993\n",
      "Ep:178, loss:0.00000, loss_test:0.04900, lr:3.38e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.118, tt:7539.156\n",
      "Ep:179, loss:0.00000, loss_test:0.04910, lr:3.34e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.117, tt:7581.035\n",
      "Ep:180, loss:0.00000, loss_test:0.04916, lr:3.31e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.112, tt:7622.313\n",
      "Ep:181, loss:0.00000, loss_test:0.04905, lr:3.28e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.098, tt:7661.905\n",
      "Ep:182, loss:0.00000, loss_test:0.04896, lr:3.24e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.130, tt:7709.784\n",
      "Ep:183, loss:0.00000, loss_test:0.04903, lr:3.21e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.132, tt:7752.251\n",
      "Ep:184, loss:0.00000, loss_test:0.04898, lr:3.18e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.122, tt:7792.513\n",
      "Ep:185, loss:0.00000, loss_test:0.04894, lr:3.15e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.122, tt:7834.638\n",
      "Ep:186, loss:0.00000, loss_test:0.04902, lr:3.12e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.121, tt:7876.674\n",
      "Ep:187, loss:0.00000, loss_test:0.04914, lr:3.09e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.127, tt:7919.913\n",
      "Ep:188, loss:0.00000, loss_test:0.04912, lr:3.05e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.139, tt:7964.269\n",
      "Ep:189, loss:0.00000, loss_test:0.04888, lr:3.02e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.146, tt:8007.777\n",
      "Ep:190, loss:0.00000, loss_test:0.04913, lr:2.99e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.151, tt:8050.770\n",
      "Ep:191, loss:0.00000, loss_test:0.04936, lr:2.96e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.152, tt:8093.157\n",
      "Ep:192, loss:0.00000, loss_test:0.04922, lr:2.93e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.155, tt:8135.852\n",
      "Ep:193, loss:0.00000, loss_test:0.04891, lr:2.90e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.160, tt:8178.970\n",
      "Ep:194, loss:0.00000, loss_test:0.04909, lr:2.88e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.170, tt:8223.159\n",
      "Ep:195, loss:0.00000, loss_test:0.04926, lr:2.85e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.179, tt:8267.141\n",
      "Ep:196, loss:0.00000, loss_test:0.04921, lr:2.82e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.171, tt:8307.606\n",
      "Ep:197, loss:0.00000, loss_test:0.04900, lr:2.79e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.169, tt:8349.477\n",
      "Ep:198, loss:0.00000, loss_test:0.04886, lr:2.76e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.168, tt:8391.403\n",
      "Ep:199, loss:0.00000, loss_test:0.04898, lr:2.73e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.172, tt:8434.482\n",
      "Ep:200, loss:0.00000, loss_test:0.04892, lr:2.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.176, tt:8477.340\n",
      "Ep:201, loss:0.00000, loss_test:0.04884, lr:2.68e-03, fs:0.83041 (r=0.717,p=0.986),  time:42.166, tt:8517.603\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02020, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:24.774, tt:24.774\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02451, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.213, tt:46.426\n",
      "Ep:2, loss:0.00005, loss_test:0.02672, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.323, tt:66.970\n",
      "Ep:3, loss:0.00005, loss_test:0.02697, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.020, tt:96.079\n",
      "Ep:4, loss:0.00005, loss_test:0.02598, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.178, tt:125.890\n",
      "Ep:5, loss:0.00005, loss_test:0.02436, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.610, tt:159.660\n",
      "Ep:6, loss:0.00005, loss_test:0.02241, lr:6.00e-02, fs:0.67577 (r=1.000,p=0.510),  time:27.703, tt:193.923\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02087, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:28.718, tt:229.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00004, loss_test:0.02038, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:29.409, tt:264.683\n",
      "Ep:9, loss:0.00004, loss_test:0.02050, lr:6.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:29.870, tt:298.698\n",
      "Ep:10, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:30.192, tt:332.117\n",
      "Ep:11, loss:0.00004, loss_test:0.01940, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:30.526, tt:366.309\n",
      "Ep:12, loss:0.00004, loss_test:0.01908, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:30.775, tt:400.078\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.69663 (r=0.939,p=0.554),  time:31.029, tt:434.399\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01873, lr:6.00e-02, fs:0.69403 (r=0.939,p=0.550),  time:31.196, tt:467.947\n",
      "Ep:15, loss:0.00004, loss_test:0.01821, lr:6.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:31.370, tt:501.914\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01779, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:31.568, tt:536.650\n",
      "Ep:17, loss:0.00003, loss_test:0.01755, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:31.738, tt:571.282\n",
      "Ep:18, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:31.838, tt:604.918\n",
      "Ep:19, loss:0.00003, loss_test:0.01683, lr:6.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:31.963, tt:639.256\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:32.023, tt:672.489\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01609, lr:6.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:32.162, tt:707.570\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:32.203, tt:740.662\n",
      "Ep:23, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:32.477, tt:779.456\n",
      "Ep:24, loss:0.00003, loss_test:0.01529, lr:6.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:32.512, tt:812.796\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01504, lr:6.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:32.498, tt:844.949\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01473, lr:6.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:32.502, tt:877.561\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01447, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:32.519, tt:910.521\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:32.611, tt:945.712\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:32.716, tt:981.491\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:32.777, tt:1016.096\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01392, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:32.811, tt:1049.954\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01368, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:32.837, tt:1083.630\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:32.899, tt:1118.568\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:32.963, tt:1153.712\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:33.032, tt:1189.167\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01320, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:33.089, tt:1224.302\n",
      "Ep:37, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:33.143, tt:1259.417\n",
      "Ep:38, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:33.147, tt:1292.722\n",
      "Ep:39, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:33.170, tt:1326.786\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:33.178, tt:1360.283\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01266, lr:6.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:33.193, tt:1394.091\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:33.198, tt:1427.499\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01242, lr:6.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:33.175, tt:1459.710\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01237, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:33.164, tt:1492.382\n",
      "Ep:45, loss:0.00002, loss_test:0.01231, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:33.179, tt:1526.229\n",
      "Ep:46, loss:0.00001, loss_test:0.01224, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:33.204, tt:1560.595\n",
      "Ep:47, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:33.188, tt:1593.046\n",
      "Ep:48, loss:0.00001, loss_test:0.01211, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:33.219, tt:1627.752\n",
      "Ep:49, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:33.233, tt:1661.651\n",
      "Ep:50, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:33.232, tt:1694.809\n",
      "Ep:51, loss:0.00001, loss_test:0.01201, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:33.222, tt:1727.537\n",
      "Ep:52, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:33.224, tt:1760.860\n",
      "Ep:53, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:33.242, tt:1795.077\n",
      "Ep:54, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:33.267, tt:1829.695\n",
      "Ep:55, loss:0.00001, loss_test:0.01188, lr:5.94e-02, fs:0.84314 (r=0.869,p=0.819),  time:33.296, tt:1864.554\n",
      "Ep:56, loss:0.00001, loss_test:0.01187, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:33.269, tt:1896.316\n",
      "Ep:57, loss:0.00001, loss_test:0.01185, lr:5.82e-02, fs:0.85000 (r=0.859,p=0.842),  time:33.294, tt:1931.080\n",
      "Ep:58, loss:0.00001, loss_test:0.01187, lr:5.76e-02, fs:0.85000 (r=0.859,p=0.842),  time:33.278, tt:1963.375\n",
      "Ep:59, loss:0.00001, loss_test:0.01184, lr:5.71e-02, fs:0.85427 (r=0.859,p=0.850),  time:33.280, tt:1996.799\n",
      "Ep:60, loss:0.00001, loss_test:0.01186, lr:5.65e-02, fs:0.85427 (r=0.859,p=0.850),  time:33.295, tt:2031.011\n",
      "Ep:61, loss:0.00001, loss_test:0.01184, lr:5.59e-02, fs:0.85859 (r=0.859,p=0.859),  time:33.317, tt:2065.681\n",
      "Ep:62, loss:0.00001, loss_test:0.01183, lr:5.54e-02, fs:0.86294 (r=0.859,p=0.867),  time:33.318, tt:2099.009\n",
      "Ep:63, loss:0.00001, loss_test:0.01184, lr:5.48e-02, fs:0.86735 (r=0.859,p=0.876),  time:33.350, tt:2134.424\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01194, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.353, tt:2167.971\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01194, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.383, tt:2203.281\n",
      "Ep:66, loss:0.00001, loss_test:0.01197, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.401, tt:2237.888\n",
      "Ep:67, loss:0.00001, loss_test:0.01198, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.399, tt:2271.151\n",
      "Ep:68, loss:0.00001, loss_test:0.01201, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.417, tt:2305.742\n",
      "Ep:69, loss:0.00001, loss_test:0.01208, lr:5.48e-02, fs:0.87047 (r=0.848,p=0.894),  time:33.413, tt:2338.897\n",
      "Ep:70, loss:0.00001, loss_test:0.01203, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:33.428, tt:2373.415\n",
      "Ep:71, loss:0.00001, loss_test:0.01206, lr:5.48e-02, fs:0.88083 (r=0.859,p=0.904),  time:33.461, tt:2409.170\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01208, lr:5.48e-02, fs:0.88083 (r=0.859,p=0.904),  time:33.467, tt:2443.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00001, loss_test:0.01216, lr:5.48e-02, fs:0.89005 (r=0.859,p=0.924),  time:33.472, tt:2476.924\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01217, lr:5.48e-02, fs:0.89005 (r=0.859,p=0.924),  time:33.485, tt:2511.358\n",
      "Ep:75, loss:0.00001, loss_test:0.01220, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.486, tt:2544.924\n",
      "Ep:76, loss:0.00001, loss_test:0.01222, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.507, tt:2580.028\n",
      "Ep:77, loss:0.00001, loss_test:0.01222, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.517, tt:2614.314\n",
      "Ep:78, loss:0.00001, loss_test:0.01224, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.521, tt:2648.174\n",
      "Ep:79, loss:0.00001, loss_test:0.01230, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.531, tt:2682.516\n",
      "Ep:80, loss:0.00001, loss_test:0.01232, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.545, tt:2717.119\n",
      "Ep:81, loss:0.00001, loss_test:0.01229, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.552, tt:2751.273\n",
      "Ep:82, loss:0.00001, loss_test:0.01236, lr:5.48e-02, fs:0.88421 (r=0.848,p=0.923),  time:33.560, tt:2785.481\n",
      "Ep:83, loss:0.00001, loss_test:0.01240, lr:5.48e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.578, tt:2820.587\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01241, lr:5.48e-02, fs:0.89840 (r=0.848,p=0.955),  time:33.577, tt:2854.059\n",
      "Ep:85, loss:0.00001, loss_test:0.01242, lr:5.48e-02, fs:0.89362 (r=0.848,p=0.944),  time:33.575, tt:2887.423\n",
      "Ep:86, loss:0.00001, loss_test:0.01249, lr:5.48e-02, fs:0.89362 (r=0.848,p=0.944),  time:33.580, tt:2921.496\n",
      "Ep:87, loss:0.00001, loss_test:0.01254, lr:5.48e-02, fs:0.89247 (r=0.838,p=0.954),  time:33.597, tt:2956.535\n",
      "Ep:88, loss:0.00001, loss_test:0.01251, lr:5.48e-02, fs:0.89247 (r=0.838,p=0.954),  time:33.583, tt:2988.867\n",
      "Ep:89, loss:0.00001, loss_test:0.01254, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.612, tt:3025.062\n",
      "Ep:90, loss:0.00001, loss_test:0.01258, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.624, tt:3059.757\n",
      "Ep:91, loss:0.00001, loss_test:0.01261, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.635, tt:3094.444\n",
      "Ep:92, loss:0.00001, loss_test:0.01263, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.640, tt:3128.555\n",
      "Ep:93, loss:0.00001, loss_test:0.01273, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.654, tt:3163.439\n",
      "Ep:94, loss:0.00001, loss_test:0.01271, lr:5.48e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.662, tt:3197.907\n",
      "Ep:95, loss:0.00001, loss_test:0.01282, lr:5.43e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.667, tt:3232.050\n",
      "Ep:96, loss:0.00001, loss_test:0.01281, lr:5.37e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.667, tt:3265.681\n",
      "Ep:97, loss:0.00001, loss_test:0.01285, lr:5.32e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.679, tt:3300.564\n",
      "Ep:98, loss:0.00001, loss_test:0.01291, lr:5.27e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.675, tt:3333.795\n",
      "Ep:99, loss:0.00001, loss_test:0.01290, lr:5.21e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.680, tt:3368.002\n",
      "Ep:100, loss:0.00000, loss_test:0.01293, lr:5.16e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.686, tt:3402.329\n",
      "Ep:101, loss:0.00000, loss_test:0.01299, lr:5.11e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.700, tt:3437.400\n",
      "Ep:102, loss:0.00000, loss_test:0.01302, lr:5.06e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.716, tt:3472.699\n",
      "Ep:103, loss:0.00000, loss_test:0.01299, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.716, tt:3506.475\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00000, loss_test:0.01307, lr:5.01e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.729, tt:3541.528\n",
      "Ep:105, loss:0.00000, loss_test:0.01308, lr:5.01e-02, fs:0.89730 (r=0.838,p=0.965),  time:33.734, tt:3575.795\n",
      "Ep:106, loss:0.00000, loss_test:0.01315, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.742, tt:3610.350\n",
      "Ep:107, loss:0.00000, loss_test:0.01317, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.787, tt:3649.013\n",
      "Ep:108, loss:0.00000, loss_test:0.01320, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.779, tt:3681.963\n",
      "Ep:109, loss:0.00000, loss_test:0.01326, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.791, tt:3717.039\n",
      "Ep:110, loss:0.00000, loss_test:0.01325, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.795, tt:3751.270\n",
      "Ep:111, loss:0.00000, loss_test:0.01331, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.811, tt:3786.796\n",
      "Ep:112, loss:0.00000, loss_test:0.01334, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.815, tt:3821.100\n",
      "Ep:113, loss:0.00000, loss_test:0.01344, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.828, tt:3856.420\n",
      "Ep:114, loss:0.00000, loss_test:0.01344, lr:5.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.836, tt:3891.175\n",
      "Ep:115, loss:0.00000, loss_test:0.01343, lr:4.96e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.826, tt:3923.761\n",
      "Ep:116, loss:0.00000, loss_test:0.01351, lr:4.91e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.844, tt:3959.696\n",
      "Ep:117, loss:0.00000, loss_test:0.01352, lr:4.86e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.859, tt:3995.335\n",
      "Ep:118, loss:0.00000, loss_test:0.01358, lr:4.81e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.876, tt:4031.294\n",
      "Ep:119, loss:0.00000, loss_test:0.01360, lr:4.76e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.875, tt:4065.021\n",
      "Ep:120, loss:0.00000, loss_test:0.01360, lr:4.71e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.885, tt:4100.077\n",
      "Ep:121, loss:0.00000, loss_test:0.01366, lr:4.67e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.890, tt:4134.588\n",
      "Ep:122, loss:0.00000, loss_test:0.01372, lr:4.62e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.898, tt:4169.435\n",
      "Ep:123, loss:0.00000, loss_test:0.01373, lr:4.57e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.898, tt:4203.361\n",
      "Ep:124, loss:0.00000, loss_test:0.01371, lr:4.53e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.901, tt:4237.681\n",
      "Ep:125, loss:0.00000, loss_test:0.01371, lr:4.48e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.914, tt:4273.198\n",
      "Ep:126, loss:0.00000, loss_test:0.01377, lr:4.44e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.916, tt:4307.297\n",
      "Ep:127, loss:0.00000, loss_test:0.01380, lr:4.39e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.920, tt:4341.771\n",
      "Ep:128, loss:0.00000, loss_test:0.01382, lr:4.35e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.919, tt:4375.551\n",
      "Ep:129, loss:0.00000, loss_test:0.01385, lr:4.31e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.919, tt:4409.418\n",
      "Ep:130, loss:0.00000, loss_test:0.01391, lr:4.26e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.913, tt:4442.557\n",
      "Ep:131, loss:0.00000, loss_test:0.01390, lr:4.22e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.931, tt:4478.902\n",
      "Ep:132, loss:0.00000, loss_test:0.01394, lr:4.18e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.945, tt:4514.750\n",
      "Ep:133, loss:0.00000, loss_test:0.01400, lr:4.14e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.963, tt:4551.000\n",
      "Ep:134, loss:0.00000, loss_test:0.01403, lr:4.10e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.975, tt:4586.572\n",
      "Ep:135, loss:0.00000, loss_test:0.01400, lr:4.05e-02, fs:0.90217 (r=0.838,p=0.976),  time:33.992, tt:4622.848\n",
      "Ep:136, loss:0.00000, loss_test:0.01404, lr:4.01e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.002, tt:4658.343\n",
      "Ep:137, loss:0.00000, loss_test:0.01412, lr:3.97e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.045, tt:4698.271\n",
      "Ep:138, loss:0.00000, loss_test:0.01411, lr:3.93e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.060, tt:4734.286\n",
      "Ep:139, loss:0.00000, loss_test:0.01411, lr:3.89e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.064, tt:4768.934\n",
      "Ep:140, loss:0.00000, loss_test:0.01415, lr:3.86e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.075, tt:4804.633\n",
      "Ep:141, loss:0.00000, loss_test:0.01418, lr:3.82e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.082, tt:4839.681\n",
      "Ep:142, loss:0.00000, loss_test:0.01419, lr:3.78e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.087, tt:4874.389\n",
      "Ep:143, loss:0.00000, loss_test:0.01419, lr:3.74e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.091, tt:4909.172\n",
      "Ep:144, loss:0.00000, loss_test:0.01420, lr:3.70e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.101, tt:4944.631\n",
      "Ep:145, loss:0.00000, loss_test:0.01424, lr:3.67e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.114, tt:4980.666\n",
      "Ep:146, loss:0.00000, loss_test:0.01429, lr:3.63e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.117, tt:5015.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.01429, lr:3.59e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.123, tt:5050.227\n",
      "Ep:148, loss:0.00000, loss_test:0.01433, lr:3.56e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.118, tt:5083.529\n",
      "Ep:149, loss:0.00000, loss_test:0.01433, lr:3.52e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.113, tt:5116.984\n",
      "Ep:150, loss:0.00000, loss_test:0.01435, lr:3.49e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.120, tt:5152.059\n",
      "Ep:151, loss:0.00000, loss_test:0.01438, lr:3.45e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.126, tt:5187.115\n",
      "Ep:152, loss:0.00000, loss_test:0.01439, lr:3.42e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.134, tt:5222.575\n",
      "Ep:153, loss:0.00000, loss_test:0.01442, lr:3.38e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.132, tt:5256.386\n",
      "Ep:154, loss:0.00000, loss_test:0.01443, lr:3.35e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.127, tt:5289.705\n",
      "Ep:155, loss:0.00000, loss_test:0.01445, lr:3.32e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.129, tt:5324.092\n",
      "Ep:156, loss:0.00000, loss_test:0.01448, lr:3.28e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.124, tt:5357.467\n",
      "Ep:157, loss:0.00000, loss_test:0.01451, lr:3.25e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.131, tt:5392.666\n",
      "Ep:158, loss:0.00000, loss_test:0.01451, lr:3.22e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.130, tt:5426.734\n",
      "Ep:159, loss:0.00000, loss_test:0.01453, lr:3.19e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.130, tt:5460.817\n",
      "Ep:160, loss:0.00000, loss_test:0.01453, lr:3.15e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.133, tt:5495.480\n",
      "Ep:161, loss:0.00000, loss_test:0.01456, lr:3.12e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.136, tt:5529.976\n",
      "Ep:162, loss:0.00000, loss_test:0.01457, lr:3.09e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.134, tt:5563.898\n",
      "Ep:163, loss:0.00000, loss_test:0.01458, lr:3.06e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.136, tt:5598.274\n",
      "Ep:164, loss:0.00000, loss_test:0.01463, lr:3.03e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.135, tt:5632.345\n",
      "Ep:165, loss:0.00000, loss_test:0.01463, lr:3.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.141, tt:5667.449\n",
      "Ep:166, loss:0.00000, loss_test:0.01464, lr:2.97e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.139, tt:5701.258\n",
      "Ep:167, loss:0.00000, loss_test:0.01466, lr:2.94e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.132, tt:5734.257\n",
      "Ep:168, loss:0.00000, loss_test:0.01465, lr:2.91e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.125, tt:5767.124\n",
      "Ep:169, loss:0.00000, loss_test:0.01469, lr:2.88e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.121, tt:5800.544\n",
      "Ep:170, loss:0.00000, loss_test:0.01471, lr:2.85e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.118, tt:5834.191\n",
      "Ep:171, loss:0.00000, loss_test:0.01473, lr:2.82e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.120, tt:5868.614\n",
      "Ep:172, loss:0.00000, loss_test:0.01476, lr:2.80e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.113, tt:5901.625\n",
      "Ep:173, loss:0.00000, loss_test:0.01476, lr:2.77e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.110, tt:5935.140\n",
      "Ep:174, loss:0.00000, loss_test:0.01477, lr:2.74e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.121, tt:5971.103\n",
      "Ep:175, loss:0.00000, loss_test:0.01478, lr:2.71e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.127, tt:6006.266\n",
      "Ep:176, loss:0.00000, loss_test:0.01481, lr:2.69e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.130, tt:6041.051\n",
      "Ep:177, loss:0.00000, loss_test:0.01479, lr:2.66e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.134, tt:6075.768\n",
      "Ep:178, loss:0.00000, loss_test:0.01481, lr:2.63e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.139, tt:6110.802\n",
      "Ep:179, loss:0.00000, loss_test:0.01485, lr:2.61e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.145, tt:6146.078\n",
      "Ep:180, loss:0.00000, loss_test:0.01486, lr:2.58e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.145, tt:6180.277\n",
      "Ep:181, loss:0.00000, loss_test:0.01486, lr:2.55e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.145, tt:6214.305\n",
      "Ep:182, loss:0.00000, loss_test:0.01484, lr:2.53e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.152, tt:6249.864\n",
      "Ep:183, loss:0.00000, loss_test:0.01486, lr:2.50e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.160, tt:6285.431\n",
      "Ep:184, loss:0.00000, loss_test:0.01489, lr:2.48e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.162, tt:6319.918\n",
      "Ep:185, loss:0.00000, loss_test:0.01491, lr:2.45e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.167, tt:6355.025\n",
      "Ep:186, loss:0.00000, loss_test:0.01493, lr:2.43e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.172, tt:6390.144\n",
      "Ep:187, loss:0.00000, loss_test:0.01492, lr:2.40e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.177, tt:6425.307\n",
      "Ep:188, loss:0.00000, loss_test:0.01493, lr:2.38e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.181, tt:6460.166\n",
      "Ep:189, loss:0.00000, loss_test:0.01495, lr:2.36e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.187, tt:6495.453\n",
      "Ep:190, loss:0.00000, loss_test:0.01496, lr:2.33e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.190, tt:6530.236\n",
      "Ep:191, loss:0.00000, loss_test:0.01495, lr:2.31e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.193, tt:6565.148\n",
      "Ep:192, loss:0.00000, loss_test:0.01498, lr:2.29e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.194, tt:6599.484\n",
      "Ep:193, loss:0.00000, loss_test:0.01501, lr:2.26e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.195, tt:6633.833\n",
      "Ep:194, loss:0.00000, loss_test:0.01501, lr:2.24e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.193, tt:6667.632\n",
      "Ep:195, loss:0.00000, loss_test:0.01501, lr:2.22e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.196, tt:6702.365\n",
      "Ep:196, loss:0.00000, loss_test:0.01502, lr:2.20e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.195, tt:6736.372\n",
      "Ep:197, loss:0.00000, loss_test:0.01504, lr:2.17e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.194, tt:6770.319\n",
      "Ep:198, loss:0.00000, loss_test:0.01505, lr:2.15e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.194, tt:6804.634\n",
      "Ep:199, loss:0.00000, loss_test:0.01505, lr:2.13e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.197, tt:6839.434\n",
      "Ep:200, loss:0.00000, loss_test:0.01504, lr:2.11e-02, fs:0.90217 (r=0.838,p=0.976),  time:34.207, tt:6875.555\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13899, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.355, tt:31.355\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13639, lr:1.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:31.514, tt:63.028\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13137, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:29.862, tt:89.587\n",
      "Ep:3, loss:0.00026, loss_test:0.12465, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:29.503, tt:118.013\n",
      "Ep:4, loss:0.00024, loss_test:0.12116, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:29.533, tt:147.665\n",
      "Ep:5, loss:0.00024, loss_test:0.11937, lr:1.00e-02, fs:0.66960 (r=0.768,p=0.594),  time:30.339, tt:182.036\n",
      "Ep:6, loss:0.00023, loss_test:0.11607, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:31.234, tt:218.635\n",
      "Ep:7, loss:0.00023, loss_test:0.11385, lr:1.00e-02, fs:0.67782 (r=0.818,p=0.579),  time:31.949, tt:255.594\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10940, lr:1.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:32.215, tt:289.933\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10654, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:32.528, tt:325.281\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10442, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:32.676, tt:359.440\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10227, lr:1.00e-02, fs:0.70485 (r=0.808,p=0.625),  time:32.857, tt:394.285\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09921, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:32.988, tt:428.844\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09709, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:33.126, tt:463.761\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00018, loss_test:0.09491, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:33.390, tt:500.848\n",
      "Ep:15, loss:0.00018, loss_test:0.09225, lr:1.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:33.607, tt:537.719\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08955, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:33.633, tt:571.755\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08740, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:33.659, tt:605.859\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.08512, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:33.694, tt:640.193\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08293, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:33.643, tt:672.860\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08095, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:33.675, tt:707.177\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07912, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:33.692, tt:741.229\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.07723, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:33.689, tt:774.853\n",
      "Ep:23, loss:0.00013, loss_test:0.07560, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:33.698, tt:808.740\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07474, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:33.713, tt:842.832\n",
      "Ep:25, loss:0.00011, loss_test:0.07257, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:33.708, tt:876.413\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07232, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:33.742, tt:911.044\n",
      "Ep:27, loss:0.00010, loss_test:0.07027, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:33.823, tt:947.051\n",
      "Ep:28, loss:0.00010, loss_test:0.06993, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:33.811, tt:980.529\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.06715, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:33.906, tt:1017.183\n",
      "Ep:30, loss:0.00009, loss_test:0.06582, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:33.911, tt:1051.253\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06505, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:33.946, tt:1086.256\n",
      "Ep:32, loss:0.00008, loss_test:0.06409, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:33.984, tt:1121.462\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.06296, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:34.096, tt:1159.275\n",
      "Ep:34, loss:0.00007, loss_test:0.06171, lr:1.00e-02, fs:0.92784 (r=0.909,p=0.947),  time:34.108, tt:1193.763\n",
      "Ep:35, loss:0.00007, loss_test:0.06099, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:34.163, tt:1229.878\n",
      "Ep:36, loss:0.00006, loss_test:0.05941, lr:1.00e-02, fs:0.92708 (r=0.899,p=0.957),  time:34.225, tt:1266.308\n",
      "Ep:37, loss:0.00006, loss_test:0.05889, lr:1.00e-02, fs:0.91979 (r=0.869,p=0.977),  time:34.268, tt:1302.195\n",
      "Ep:38, loss:0.00006, loss_test:0.05828, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:34.339, tt:1339.202\n",
      "Ep:39, loss:0.00006, loss_test:0.05751, lr:1.00e-02, fs:0.92063 (r=0.879,p=0.967),  time:34.344, tt:1373.773\n",
      "Ep:40, loss:0.00005, loss_test:0.05761, lr:1.00e-02, fs:0.92147 (r=0.889,p=0.957),  time:34.403, tt:1410.527\n",
      "Ep:41, loss:0.00005, loss_test:0.05731, lr:1.00e-02, fs:0.93122 (r=0.889,p=0.978),  time:34.462, tt:1447.390\n",
      "Ep:42, loss:0.00005, loss_test:0.05610, lr:1.00e-02, fs:0.92632 (r=0.889,p=0.967),  time:34.487, tt:1482.929\n",
      "Ep:43, loss:0.00005, loss_test:0.05640, lr:1.00e-02, fs:0.92473 (r=0.869,p=0.989),  time:34.570, tt:1521.092\n",
      "Ep:44, loss:0.00004, loss_test:0.05543, lr:9.90e-03, fs:0.93750 (r=0.909,p=0.968),  time:34.587, tt:1556.430\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.05595, lr:9.90e-03, fs:0.93048 (r=0.879,p=0.989),  time:34.647, tt:1593.761\n",
      "Ep:46, loss:0.00004, loss_test:0.05541, lr:9.90e-03, fs:0.90710 (r=0.838,p=0.988),  time:34.715, tt:1631.603\n",
      "Ep:47, loss:0.00004, loss_test:0.05408, lr:9.90e-03, fs:0.93684 (r=0.899,p=0.978),  time:34.783, tt:1669.607\n",
      "Ep:48, loss:0.00004, loss_test:0.05442, lr:9.90e-03, fs:0.89385 (r=0.808,p=1.000),  time:34.840, tt:1707.178\n",
      "Ep:49, loss:0.00004, loss_test:0.05543, lr:9.90e-03, fs:0.91892 (r=0.859,p=0.988),  time:34.877, tt:1743.865\n",
      "Ep:50, loss:0.00003, loss_test:0.05280, lr:9.90e-03, fs:0.91398 (r=0.859,p=0.977),  time:34.925, tt:1781.188\n",
      "Ep:51, loss:0.00003, loss_test:0.05308, lr:9.90e-03, fs:0.91304 (r=0.848,p=0.988),  time:35.107, tt:1825.576\n",
      "Ep:52, loss:0.00003, loss_test:0.05160, lr:9.90e-03, fs:0.93750 (r=0.909,p=0.968),  time:35.176, tt:1864.304\n",
      "Ep:53, loss:0.00003, loss_test:0.05502, lr:9.90e-03, fs:0.88889 (r=0.808,p=0.988),  time:35.202, tt:1900.913\n",
      "Ep:54, loss:0.00003, loss_test:0.05099, lr:9.90e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.223, tt:1937.280\n",
      "Ep:55, loss:0.00003, loss_test:0.05329, lr:9.90e-03, fs:0.89503 (r=0.818,p=0.988),  time:35.253, tt:1974.160\n",
      "Ep:56, loss:0.00003, loss_test:0.05131, lr:9.80e-03, fs:0.92632 (r=0.889,p=0.967),  time:35.274, tt:2010.619\n",
      "Ep:57, loss:0.00002, loss_test:0.05252, lr:9.70e-03, fs:0.88889 (r=0.808,p=0.988),  time:35.370, tt:2051.444\n",
      "Ep:58, loss:0.00002, loss_test:0.05041, lr:9.61e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.382, tt:2087.544\n",
      "Ep:59, loss:0.00002, loss_test:0.05276, lr:9.51e-03, fs:0.89503 (r=0.818,p=0.988),  time:35.382, tt:2122.913\n",
      "Ep:60, loss:0.00002, loss_test:0.04994, lr:9.41e-03, fs:0.92063 (r=0.879,p=0.967),  time:35.380, tt:2158.200\n",
      "Ep:61, loss:0.00002, loss_test:0.05231, lr:9.32e-03, fs:0.87640 (r=0.788,p=0.987),  time:35.376, tt:2193.331\n",
      "Ep:62, loss:0.00002, loss_test:0.05024, lr:9.23e-03, fs:0.92063 (r=0.879,p=0.967),  time:35.394, tt:2229.803\n",
      "Ep:63, loss:0.00002, loss_test:0.05186, lr:9.14e-03, fs:0.89617 (r=0.828,p=0.976),  time:35.373, tt:2263.843\n",
      "Ep:64, loss:0.00002, loss_test:0.04988, lr:9.04e-03, fs:0.88525 (r=0.818,p=0.964),  time:35.388, tt:2300.222\n",
      "Ep:65, loss:0.00002, loss_test:0.05150, lr:8.95e-03, fs:0.91892 (r=0.859,p=0.988),  time:35.389, tt:2335.689\n",
      "Ep:66, loss:0.00002, loss_test:0.05061, lr:8.86e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.371, tt:2369.849\n",
      "Ep:67, loss:0.00002, loss_test:0.05110, lr:8.78e-03, fs:0.92553 (r=0.879,p=0.978),  time:35.371, tt:2405.259\n",
      "Ep:68, loss:0.00002, loss_test:0.04900, lr:8.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:35.380, tt:2441.251\n",
      "Ep:69, loss:0.00002, loss_test:0.05076, lr:8.60e-03, fs:0.89617 (r=0.828,p=0.976),  time:35.378, tt:2476.494\n",
      "Ep:70, loss:0.00002, loss_test:0.05067, lr:8.51e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.359, tt:2510.505\n",
      "Ep:71, loss:0.00002, loss_test:0.04939, lr:8.43e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.365, tt:2546.304\n",
      "Ep:72, loss:0.00001, loss_test:0.04991, lr:8.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:35.366, tt:2581.686\n",
      "Ep:73, loss:0.00001, loss_test:0.04987, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.354, tt:2616.226\n",
      "Ep:74, loss:0.00001, loss_test:0.04989, lr:8.18e-03, fs:0.90811 (r=0.848,p=0.977),  time:35.357, tt:2651.781\n",
      "Ep:75, loss:0.00001, loss_test:0.04974, lr:8.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.340, tt:2685.812\n",
      "Ep:76, loss:0.00001, loss_test:0.05109, lr:8.02e-03, fs:0.90217 (r=0.838,p=0.976),  time:35.368, tt:2723.362\n",
      "Ep:77, loss:0.00001, loss_test:0.04887, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.360, tt:2758.117\n",
      "Ep:78, loss:0.00001, loss_test:0.05004, lr:7.86e-03, fs:0.87006 (r=0.778,p=0.987),  time:35.361, tt:2793.480\n",
      "Ep:79, loss:0.00001, loss_test:0.05040, lr:7.78e-03, fs:0.87151 (r=0.788,p=0.975),  time:35.356, tt:2828.496\n",
      "Ep:80, loss:0.00001, loss_test:0.04951, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.332, tt:2861.855\n",
      "Ep:81, loss:0.00001, loss_test:0.05002, lr:7.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.338, tt:2897.703\n",
      "Ep:82, loss:0.00001, loss_test:0.05011, lr:7.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.329, tt:2932.306\n",
      "Ep:83, loss:0.00001, loss_test:0.05048, lr:7.47e-03, fs:0.88398 (r=0.808,p=0.976),  time:35.319, tt:2966.781\n",
      "Ep:84, loss:0.00001, loss_test:0.04937, lr:7.40e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.316, tt:3001.869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:85, loss:0.00001, loss_test:0.05036, lr:7.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.325, tt:3037.933\n",
      "Ep:86, loss:0.00001, loss_test:0.05069, lr:7.25e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.328, tt:3073.500\n",
      "Ep:87, loss:0.00001, loss_test:0.05069, lr:7.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.336, tt:3109.527\n",
      "Ep:88, loss:0.00001, loss_test:0.04955, lr:7.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:35.338, tt:3145.073\n",
      "Ep:89, loss:0.00001, loss_test:0.04958, lr:7.03e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.337, tt:3180.356\n",
      "Ep:90, loss:0.00001, loss_test:0.05050, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.346, tt:3216.451\n",
      "Ep:91, loss:0.00001, loss_test:0.05020, lr:6.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.332, tt:3250.566\n",
      "Ep:92, loss:0.00001, loss_test:0.05089, lr:6.83e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.333, tt:3285.954\n",
      "Ep:93, loss:0.00001, loss_test:0.05004, lr:6.76e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.351, tt:3322.984\n",
      "Ep:94, loss:0.00001, loss_test:0.05054, lr:6.69e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.349, tt:3358.112\n",
      "Ep:95, loss:0.00001, loss_test:0.05120, lr:6.62e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.349, tt:3393.515\n",
      "Ep:96, loss:0.00001, loss_test:0.04993, lr:6.56e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.346, tt:3428.519\n",
      "Ep:97, loss:0.00001, loss_test:0.05097, lr:6.49e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.332, tt:3462.522\n",
      "Ep:98, loss:0.00001, loss_test:0.05130, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.320, tt:3496.675\n",
      "Ep:99, loss:0.00001, loss_test:0.05057, lr:6.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.306, tt:3530.584\n",
      "Ep:100, loss:0.00001, loss_test:0.05155, lr:6.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.292, tt:3564.494\n",
      "Ep:101, loss:0.00001, loss_test:0.05137, lr:6.24e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.284, tt:3598.956\n",
      "Ep:102, loss:0.00001, loss_test:0.05127, lr:6.17e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.280, tt:3633.875\n",
      "Ep:103, loss:0.00001, loss_test:0.05121, lr:6.11e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.269, tt:3667.966\n",
      "Ep:104, loss:0.00001, loss_test:0.05242, lr:6.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.298, tt:3706.317\n",
      "Ep:105, loss:0.00001, loss_test:0.05169, lr:5.99e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.294, tt:3741.172\n",
      "Ep:106, loss:0.00001, loss_test:0.05103, lr:5.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.284, tt:3775.399\n",
      "Ep:107, loss:0.00001, loss_test:0.05215, lr:5.87e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.259, tt:3807.999\n",
      "Ep:108, loss:0.00001, loss_test:0.05108, lr:5.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.247, tt:3841.878\n",
      "Ep:109, loss:0.00001, loss_test:0.05130, lr:5.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.235, tt:3875.857\n",
      "Ep:110, loss:0.00001, loss_test:0.05145, lr:5.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.221, tt:3909.515\n",
      "Ep:111, loss:0.00001, loss_test:0.05147, lr:5.64e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.205, tt:3942.967\n",
      "Ep:112, loss:0.00000, loss_test:0.05147, lr:5.58e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.210, tt:3978.750\n",
      "Ep:113, loss:0.00000, loss_test:0.05116, lr:5.53e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.207, tt:4013.612\n",
      "Ep:114, loss:0.00000, loss_test:0.05149, lr:5.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.207, tt:4048.779\n",
      "Ep:115, loss:0.00000, loss_test:0.05113, lr:5.42e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.204, tt:4083.661\n",
      "Ep:116, loss:0.00000, loss_test:0.05093, lr:5.36e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.202, tt:4118.648\n",
      "Ep:117, loss:0.00000, loss_test:0.05172, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.191, tt:4152.585\n",
      "Ep:118, loss:0.00000, loss_test:0.05188, lr:5.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.169, tt:4185.143\n",
      "Ep:119, loss:0.00000, loss_test:0.05156, lr:5.20e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.165, tt:4219.801\n",
      "Ep:120, loss:0.00000, loss_test:0.05133, lr:5.15e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.135, tt:4251.351\n",
      "Ep:121, loss:0.00000, loss_test:0.05168, lr:5.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.095, tt:4281.534\n",
      "Ep:122, loss:0.00000, loss_test:0.05166, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:35.052, tt:4311.443\n",
      "Ep:123, loss:0.00000, loss_test:0.05142, lr:5.00e-03, fs:0.85876 (r=0.768,p=0.974),  time:35.010, tt:4341.229\n",
      "Ep:124, loss:0.00000, loss_test:0.05133, lr:4.95e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.968, tt:4371.028\n",
      "Ep:125, loss:0.00000, loss_test:0.05198, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.940, tt:4402.463\n",
      "Ep:126, loss:0.00000, loss_test:0.05213, lr:4.85e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.912, tt:4433.826\n",
      "Ep:127, loss:0.00000, loss_test:0.05137, lr:4.80e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.893, tt:4466.261\n",
      "Ep:128, loss:0.00000, loss_test:0.05115, lr:4.75e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.838, tt:4494.062\n",
      "Ep:129, loss:0.00000, loss_test:0.05155, lr:4.71e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.788, tt:4522.409\n",
      "Ep:130, loss:0.00000, loss_test:0.05171, lr:4.66e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.769, tt:4554.681\n",
      "Ep:131, loss:0.00000, loss_test:0.05127, lr:4.61e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.737, tt:4585.348\n",
      "Ep:132, loss:0.00000, loss_test:0.05135, lr:4.57e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.698, tt:4614.804\n",
      "Ep:133, loss:0.00000, loss_test:0.05145, lr:4.52e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.675, tt:4646.511\n",
      "Ep:134, loss:0.00000, loss_test:0.05126, lr:4.48e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.654, tt:4678.351\n",
      "Ep:135, loss:0.00000, loss_test:0.05116, lr:4.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:34.634, tt:4710.161\n",
      "Ep:136, loss:0.00000, loss_test:0.05111, lr:4.39e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.594, tt:4739.400\n",
      "Ep:137, loss:0.00000, loss_test:0.05080, lr:4.34e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.571, tt:4770.778\n",
      "Ep:138, loss:0.00000, loss_test:0.05129, lr:4.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.549, tt:4802.309\n",
      "Ep:139, loss:0.00000, loss_test:0.05129, lr:4.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.538, tt:4835.276\n",
      "Ep:140, loss:0.00000, loss_test:0.05119, lr:4.21e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.518, tt:4867.017\n",
      "Ep:141, loss:0.00000, loss_test:0.05176, lr:4.17e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.493, tt:4897.980\n",
      "Ep:142, loss:0.00000, loss_test:0.05159, lr:4.13e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.478, tt:4930.295\n",
      "Ep:143, loss:0.00000, loss_test:0.05095, lr:4.09e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.461, tt:4962.405\n",
      "Ep:144, loss:0.00000, loss_test:0.05094, lr:4.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.452, tt:4995.567\n",
      "Ep:145, loss:0.00000, loss_test:0.05118, lr:4.01e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.443, tt:5028.649\n",
      "Ep:146, loss:0.00000, loss_test:0.05117, lr:3.97e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.428, tt:5060.849\n",
      "Ep:147, loss:0.00000, loss_test:0.05118, lr:3.93e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.413, tt:5093.056\n",
      "Ep:148, loss:0.00000, loss_test:0.05107, lr:3.89e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.408, tt:5126.743\n",
      "Ep:149, loss:0.00000, loss_test:0.05108, lr:3.85e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.397, tt:5159.568\n",
      "Ep:150, loss:0.00000, loss_test:0.05106, lr:3.81e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.393, tt:5193.387\n",
      "Ep:151, loss:0.00000, loss_test:0.05103, lr:3.77e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.384, tt:5226.402\n",
      "Ep:152, loss:0.00000, loss_test:0.05119, lr:3.73e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.372, tt:5258.981\n",
      "Ep:153, loss:0.00000, loss_test:0.05101, lr:3.70e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.360, tt:5291.437\n",
      "Ep:154, loss:0.00000, loss_test:0.05083, lr:3.66e-03, fs:0.86364 (r=0.768,p=0.987),  time:34.344, tt:5323.279\n",
      "Ep:155, loss:0.00000, loss_test:0.05140, lr:3.62e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.327, tt:5354.949\n",
      "Ep:156, loss:0.00000, loss_test:0.05161, lr:3.59e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.308, tt:5386.312\n",
      "Ep:157, loss:0.00000, loss_test:0.05122, lr:3.55e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.282, tt:5416.486\n",
      "Ep:158, loss:0.00000, loss_test:0.05088, lr:3.52e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.258, tt:5446.965\n",
      "Ep:159, loss:0.00000, loss_test:0.05102, lr:3.48e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.232, tt:5477.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:160, loss:0.00000, loss_test:0.05150, lr:3.45e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.216, tt:5508.815\n",
      "Ep:161, loss:0.00000, loss_test:0.05142, lr:3.41e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.195, tt:5539.566\n",
      "Ep:162, loss:0.00000, loss_test:0.05118, lr:3.38e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.176, tt:5570.656\n",
      "Ep:163, loss:0.00000, loss_test:0.05113, lr:3.34e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.157, tt:5601.743\n",
      "Ep:164, loss:0.00000, loss_test:0.05131, lr:3.31e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.139, tt:5632.946\n",
      "Ep:165, loss:0.00000, loss_test:0.05127, lr:3.28e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.130, tt:5665.590\n",
      "Ep:166, loss:0.00000, loss_test:0.05110, lr:3.24e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.119, tt:5697.861\n",
      "Ep:167, loss:0.00000, loss_test:0.05092, lr:3.21e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.110, tt:5730.428\n",
      "Ep:168, loss:0.00000, loss_test:0.05105, lr:3.18e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.098, tt:5762.592\n",
      "Ep:169, loss:0.00000, loss_test:0.05119, lr:3.15e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.086, tt:5794.586\n",
      "Ep:170, loss:0.00000, loss_test:0.05115, lr:3.12e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.059, tt:5824.037\n",
      "Ep:171, loss:0.00000, loss_test:0.05103, lr:3.09e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.035, tt:5854.104\n",
      "Ep:172, loss:0.00000, loss_test:0.05101, lr:3.05e-03, fs:0.86857 (r=0.768,p=1.000),  time:34.016, tt:5884.711\n",
      "Ep:173, loss:0.00000, loss_test:0.05104, lr:3.02e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.984, tt:5913.186\n",
      "Ep:174, loss:0.00000, loss_test:0.05132, lr:2.99e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.954, tt:5941.926\n",
      "Ep:175, loss:0.00000, loss_test:0.05135, lr:2.96e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.935, tt:5972.629\n",
      "Ep:176, loss:0.00000, loss_test:0.05115, lr:2.93e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.919, tt:6003.609\n",
      "Ep:177, loss:0.00000, loss_test:0.05108, lr:2.90e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.909, tt:6035.745\n",
      "Ep:178, loss:0.00000, loss_test:0.05094, lr:2.88e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.893, tt:6066.816\n",
      "Ep:179, loss:0.00000, loss_test:0.05110, lr:2.85e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.869, tt:6096.411\n",
      "Ep:180, loss:0.00000, loss_test:0.05103, lr:2.82e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.849, tt:6126.759\n",
      "Ep:181, loss:0.00000, loss_test:0.05092, lr:2.79e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.826, tt:6156.351\n",
      "Ep:182, loss:0.00000, loss_test:0.05119, lr:2.76e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.798, tt:6185.119\n",
      "Ep:183, loss:0.00000, loss_test:0.05125, lr:2.73e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.773, tt:6214.199\n",
      "Ep:184, loss:0.00000, loss_test:0.05108, lr:2.71e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.741, tt:6242.134\n",
      "Ep:185, loss:0.00000, loss_test:0.05105, lr:2.68e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.727, tt:6273.238\n",
      "Ep:186, loss:0.00000, loss_test:0.05114, lr:2.65e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.704, tt:6302.618\n",
      "Ep:187, loss:0.00000, loss_test:0.05112, lr:2.63e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.695, tt:6334.602\n",
      "Ep:188, loss:0.00000, loss_test:0.05107, lr:2.60e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.676, tt:6364.853\n",
      "Ep:189, loss:0.00000, loss_test:0.05122, lr:2.57e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.657, tt:6394.816\n",
      "Ep:190, loss:0.00000, loss_test:0.05117, lr:2.55e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.635, tt:6424.224\n",
      "Ep:191, loss:0.00000, loss_test:0.05095, lr:2.52e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.615, tt:6454.003\n",
      "Ep:192, loss:0.00000, loss_test:0.05097, lr:2.50e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.594, tt:6483.594\n",
      "Ep:193, loss:0.00000, loss_test:0.05130, lr:2.47e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.577, tt:6514.013\n",
      "Ep:194, loss:0.00000, loss_test:0.05129, lr:2.45e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.565, tt:6545.112\n",
      "Ep:195, loss:0.00000, loss_test:0.05116, lr:2.42e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.546, tt:6574.943\n",
      "Ep:196, loss:0.00000, loss_test:0.05120, lr:2.40e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.536, tt:6606.522\n",
      "Ep:197, loss:0.00000, loss_test:0.05127, lr:2.38e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.520, tt:6636.993\n",
      "Ep:198, loss:0.00000, loss_test:0.05111, lr:2.35e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.514, tt:6669.266\n",
      "Ep:199, loss:0.00000, loss_test:0.05112, lr:2.33e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.505, tt:6700.905\n",
      "Ep:200, loss:0.00000, loss_test:0.05119, lr:2.31e-03, fs:0.86857 (r=0.768,p=1.000),  time:33.504, tt:6734.269\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02034, lr:6.00e-02, fs:0.64435 (r=0.885,p=0.507),  time:17.263, tt:17.263\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02247, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.887, tt:41.773\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02372, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.845, tt:71.536\n",
      "Ep:3, loss:0.00005, loss_test:0.02354, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.526, tt:110.103\n",
      "Ep:4, loss:0.00005, loss_test:0.02254, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:30.222, tt:151.110\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02110, lr:6.00e-02, fs:0.65882 (r=0.966,p=0.500),  time:31.837, tt:191.022\n",
      "Ep:6, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.64348 (r=0.851,p=0.517),  time:33.096, tt:231.669\n",
      "Ep:7, loss:0.00004, loss_test:0.02013, lr:6.00e-02, fs:0.67633 (r=0.805,p=0.583),  time:34.066, tt:272.527\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02086, lr:6.00e-02, fs:0.68041 (r=0.759,p=0.617),  time:34.775, tt:312.979\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.67708 (r=0.747,p=0.619),  time:35.337, tt:353.372\n",
      "Ep:10, loss:0.00003, loss_test:0.02061, lr:6.00e-02, fs:0.68020 (r=0.770,p=0.609),  time:35.791, tt:393.699\n",
      "Ep:11, loss:0.00003, loss_test:0.02019, lr:6.00e-02, fs:0.68627 (r=0.805,p=0.598),  time:36.366, tt:436.397\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.02012, lr:6.00e-02, fs:0.67943 (r=0.816,p=0.582),  time:36.682, tt:476.860\n",
      "Ep:13, loss:0.00003, loss_test:0.02038, lr:6.00e-02, fs:0.68269 (r=0.816,p=0.587),  time:36.988, tt:517.826\n",
      "Ep:14, loss:0.00003, loss_test:0.02103, lr:6.00e-02, fs:0.70000 (r=0.805,p=0.619),  time:37.219, tt:558.291\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.02201, lr:6.00e-02, fs:0.70103 (r=0.782,p=0.636),  time:37.389, tt:598.230\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.02290, lr:6.00e-02, fs:0.70157 (r=0.770,p=0.644),  time:37.642, tt:639.909\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.02322, lr:6.00e-02, fs:0.69841 (r=0.759,p=0.647),  time:37.846, tt:681.224\n",
      "Ep:18, loss:0.00003, loss_test:0.02272, lr:6.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:38.025, tt:722.466\n",
      "Ep:19, loss:0.00003, loss_test:0.02220, lr:6.00e-02, fs:0.68394 (r=0.759,p=0.623),  time:38.139, tt:762.771\n",
      "Ep:20, loss:0.00003, loss_test:0.02198, lr:6.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:38.259, tt:803.430\n",
      "Ep:21, loss:0.00003, loss_test:0.02199, lr:6.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:38.375, tt:844.240\n",
      "Ep:22, loss:0.00002, loss_test:0.02231, lr:6.00e-02, fs:0.69892 (r=0.747,p=0.657),  time:38.479, tt:885.006\n",
      "Ep:23, loss:0.00002, loss_test:0.02258, lr:6.00e-02, fs:0.71038 (r=0.747,p=0.677),  time:38.542, tt:925.008\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.02265, lr:6.00e-02, fs:0.72222 (r=0.747,p=0.699),  time:38.659, tt:966.482\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.02245, lr:6.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:38.902, tt:1011.453\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.02216, lr:6.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:39.096, tt:1055.597\n",
      "Ep:27, loss:0.00002, loss_test:0.02190, lr:6.00e-02, fs:0.72626 (r=0.747,p=0.707),  time:39.172, tt:1096.805\n",
      "Ep:28, loss:0.00002, loss_test:0.02192, lr:6.00e-02, fs:0.73446 (r=0.747,p=0.722),  time:39.241, tt:1138.002\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.02203, lr:6.00e-02, fs:0.73864 (r=0.747,p=0.730),  time:39.335, tt:1180.042\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.02214, lr:6.00e-02, fs:0.73864 (r=0.747,p=0.730),  time:39.437, tt:1222.556\n",
      "Ep:31, loss:0.00002, loss_test:0.02207, lr:6.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:39.516, tt:1264.509\n",
      "Ep:32, loss:0.00002, loss_test:0.02197, lr:6.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:39.504, tt:1303.628\n",
      "Ep:33, loss:0.00002, loss_test:0.02188, lr:6.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:39.543, tt:1344.456\n",
      "Ep:34, loss:0.00002, loss_test:0.02186, lr:6.00e-02, fs:0.73864 (r=0.747,p=0.730),  time:39.619, tt:1386.671\n",
      "Ep:35, loss:0.00002, loss_test:0.02199, lr:6.00e-02, fs:0.74286 (r=0.747,p=0.739),  time:39.679, tt:1428.450\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.02204, lr:6.00e-02, fs:0.74286 (r=0.747,p=0.739),  time:39.768, tt:1471.417\n",
      "Ep:37, loss:0.00002, loss_test:0.02204, lr:6.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:39.890, tt:1515.837\n",
      "Ep:38, loss:0.00002, loss_test:0.02193, lr:6.00e-02, fs:0.73563 (r=0.736,p=0.736),  time:39.950, tt:1558.052\n",
      "Ep:39, loss:0.00002, loss_test:0.02192, lr:6.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:39.983, tt:1599.339\n",
      "Ep:40, loss:0.00002, loss_test:0.02193, lr:6.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:40.036, tt:1641.468\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.02199, lr:6.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:40.097, tt:1684.078\n",
      "Ep:42, loss:0.00002, loss_test:0.02199, lr:6.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:40.108, tt:1724.625\n",
      "Ep:43, loss:0.00002, loss_test:0.02191, lr:6.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:40.166, tt:1767.313\n",
      "Ep:44, loss:0.00002, loss_test:0.02200, lr:6.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:40.197, tt:1808.851\n",
      "Ep:45, loss:0.00002, loss_test:0.02194, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.219, tt:1850.067\n",
      "Ep:46, loss:0.00002, loss_test:0.02197, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.238, tt:1891.194\n",
      "Ep:47, loss:0.00001, loss_test:0.02204, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.281, tt:1933.498\n",
      "Ep:48, loss:0.00001, loss_test:0.02205, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.301, tt:1974.766\n",
      "Ep:49, loss:0.00001, loss_test:0.02192, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.359, tt:2017.937\n",
      "Ep:50, loss:0.00001, loss_test:0.02193, lr:6.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.360, tt:2058.382\n",
      "Ep:51, loss:0.00001, loss_test:0.02183, lr:6.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.416, tt:2101.610\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.02171, lr:6.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.414, tt:2141.933\n",
      "Ep:53, loss:0.00001, loss_test:0.02169, lr:6.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:40.452, tt:2184.396\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.02165, lr:6.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:40.443, tt:2224.361\n",
      "Ep:55, loss:0.00001, loss_test:0.02167, lr:6.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:40.482, tt:2267.016\n",
      "Ep:56, loss:0.00001, loss_test:0.02168, lr:6.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:40.492, tt:2308.050\n",
      "Ep:57, loss:0.00001, loss_test:0.02173, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.524, tt:2350.413\n",
      "Ep:58, loss:0.00001, loss_test:0.02163, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.524, tt:2390.920\n",
      "Ep:59, loss:0.00001, loss_test:0.02156, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.537, tt:2432.226\n",
      "Ep:60, loss:0.00001, loss_test:0.02161, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.551, tt:2473.589\n",
      "Ep:61, loss:0.00001, loss_test:0.02153, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.593, tt:2516.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.02155, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.640, tt:2560.312\n",
      "Ep:63, loss:0.00001, loss_test:0.02156, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.658, tt:2602.120\n",
      "Ep:64, loss:0.00001, loss_test:0.02154, lr:6.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.677, tt:2644.008\n",
      "Ep:65, loss:0.00001, loss_test:0.02147, lr:5.94e-02, fs:0.74390 (r=0.701,p=0.792),  time:40.667, tt:2684.048\n",
      "Ep:66, loss:0.00001, loss_test:0.02152, lr:5.88e-02, fs:0.74847 (r=0.701,p=0.803),  time:40.658, tt:2724.110\n",
      "Ep:67, loss:0.00001, loss_test:0.02153, lr:5.82e-02, fs:0.74847 (r=0.701,p=0.803),  time:40.659, tt:2764.802\n",
      "Ep:68, loss:0.00001, loss_test:0.02149, lr:5.76e-02, fs:0.75309 (r=0.701,p=0.813),  time:40.662, tt:2805.669\n",
      "Ep:69, loss:0.00001, loss_test:0.02145, lr:5.71e-02, fs:0.75309 (r=0.701,p=0.813),  time:40.700, tt:2849.008\n",
      "Ep:70, loss:0.00001, loss_test:0.02143, lr:5.65e-02, fs:0.75309 (r=0.701,p=0.813),  time:40.701, tt:2889.760\n",
      "Ep:71, loss:0.00001, loss_test:0.02142, lr:5.59e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.707, tt:2930.916\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.02147, lr:5.59e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.712, tt:2971.981\n",
      "Ep:73, loss:0.00001, loss_test:0.02150, lr:5.59e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.702, tt:3011.959\n",
      "Ep:74, loss:0.00001, loss_test:0.02149, lr:5.59e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.713, tt:3053.455\n",
      "Ep:75, loss:0.00001, loss_test:0.02147, lr:5.59e-02, fs:0.76250 (r=0.701,p=0.836),  time:40.728, tt:3095.294\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.02145, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.712, tt:3134.842\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.02152, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.736, tt:3177.398\n",
      "Ep:78, loss:0.00001, loss_test:0.02144, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.730, tt:3217.706\n",
      "Ep:79, loss:0.00001, loss_test:0.02149, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.703, tt:3256.242\n",
      "Ep:80, loss:0.00001, loss_test:0.02157, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.708, tt:3297.377\n",
      "Ep:81, loss:0.00001, loss_test:0.02158, lr:5.59e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.697, tt:3337.173\n",
      "Ep:82, loss:0.00001, loss_test:0.02161, lr:5.59e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.694, tt:3377.585\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.02166, lr:5.59e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.680, tt:3417.079\n",
      "Ep:84, loss:0.00001, loss_test:0.02170, lr:5.59e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.652, tt:3455.427\n",
      "Ep:85, loss:0.00001, loss_test:0.02173, lr:5.59e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.643, tt:3495.336\n",
      "Ep:86, loss:0.00001, loss_test:0.02170, lr:5.59e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.637, tt:3535.428\n",
      "Ep:87, loss:0.00001, loss_test:0.02185, lr:5.59e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.746, tt:3585.623\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.02186, lr:5.59e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.735, tt:3625.412\n",
      "Ep:89, loss:0.00001, loss_test:0.02182, lr:5.59e-02, fs:0.77707 (r=0.701,p=0.871),  time:40.731, tt:3665.807\n",
      "Ep:90, loss:0.00001, loss_test:0.02191, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.751, tt:3708.298\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.02205, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.739, tt:3748.031\n",
      "Ep:92, loss:0.00001, loss_test:0.02192, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.720, tt:3786.994\n",
      "Ep:93, loss:0.00001, loss_test:0.02199, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.699, tt:3825.669\n",
      "Ep:94, loss:0.00001, loss_test:0.02201, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.681, tt:3864.720\n",
      "Ep:95, loss:0.00001, loss_test:0.02194, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.661, tt:3903.435\n",
      "Ep:96, loss:0.00001, loss_test:0.02206, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.655, tt:3943.542\n",
      "Ep:97, loss:0.00001, loss_test:0.02211, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.643, tt:3982.988\n",
      "Ep:98, loss:0.00001, loss_test:0.02204, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.630, tt:4022.399\n",
      "Ep:99, loss:0.00001, loss_test:0.02219, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.600, tt:4060.015\n",
      "Ep:100, loss:0.00001, loss_test:0.02211, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.591, tt:4099.665\n",
      "Ep:101, loss:0.00001, loss_test:0.02206, lr:5.59e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.563, tt:4137.426\n",
      "Ep:102, loss:0.00001, loss_test:0.02226, lr:5.54e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.533, tt:4174.889\n",
      "Ep:103, loss:0.00001, loss_test:0.02227, lr:5.48e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.526, tt:4214.680\n",
      "Ep:104, loss:0.00001, loss_test:0.02225, lr:5.43e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.504, tt:4252.933\n",
      "Ep:105, loss:0.00001, loss_test:0.02220, lr:5.37e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.501, tt:4293.144\n",
      "Ep:106, loss:0.00001, loss_test:0.02227, lr:5.32e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.478, tt:4331.153\n",
      "Ep:107, loss:0.00001, loss_test:0.02239, lr:5.27e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.477, tt:4371.552\n",
      "Ep:108, loss:0.00001, loss_test:0.02246, lr:5.21e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.529, tt:4417.658\n",
      "Ep:109, loss:0.00001, loss_test:0.02256, lr:5.16e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.513, tt:4456.394\n",
      "Ep:110, loss:0.00001, loss_test:0.02255, lr:5.11e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.510, tt:4496.638\n",
      "Ep:111, loss:0.00000, loss_test:0.02249, lr:5.06e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.505, tt:4536.525\n",
      "Ep:112, loss:0.00000, loss_test:0.02256, lr:5.01e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.484, tt:4574.708\n",
      "Ep:113, loss:0.00000, loss_test:0.02260, lr:4.96e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.480, tt:4614.738\n",
      "Ep:114, loss:0.00000, loss_test:0.02263, lr:4.91e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.468, tt:4653.806\n",
      "Ep:115, loss:0.00000, loss_test:0.02267, lr:4.86e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.464, tt:4693.801\n",
      "Ep:116, loss:0.00000, loss_test:0.02277, lr:4.81e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.458, tt:4733.557\n",
      "Ep:117, loss:0.00000, loss_test:0.02276, lr:4.76e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.453, tt:4773.441\n",
      "Ep:118, loss:0.00000, loss_test:0.02280, lr:4.71e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.445, tt:4812.979\n",
      "Ep:119, loss:0.00000, loss_test:0.02285, lr:4.67e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.430, tt:4851.594\n",
      "Ep:120, loss:0.00000, loss_test:0.02287, lr:4.62e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.427, tt:4891.686\n",
      "Ep:121, loss:0.00000, loss_test:0.02287, lr:4.57e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.432, tt:4932.738\n",
      "Ep:122, loss:0.00000, loss_test:0.02291, lr:4.53e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.418, tt:4971.379\n",
      "Ep:123, loss:0.00000, loss_test:0.02300, lr:4.48e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.421, tt:5012.191\n",
      "Ep:124, loss:0.00000, loss_test:0.02312, lr:4.44e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.420, tt:5052.454\n",
      "Ep:125, loss:0.00000, loss_test:0.02307, lr:4.39e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.410, tt:5091.604\n",
      "Ep:126, loss:0.00000, loss_test:0.02303, lr:4.35e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.419, tt:5133.271\n",
      "Ep:127, loss:0.00000, loss_test:0.02313, lr:4.31e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.417, tt:5173.409\n",
      "Ep:128, loss:0.00000, loss_test:0.02321, lr:4.26e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.417, tt:5213.797\n",
      "Ep:129, loss:0.00000, loss_test:0.02320, lr:4.22e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.420, tt:5254.665\n",
      "Ep:130, loss:0.00000, loss_test:0.02319, lr:4.18e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.403, tt:5292.744\n",
      "Ep:131, loss:0.00000, loss_test:0.02327, lr:4.14e-02, fs:0.78205 (r=0.701,p=0.884),  time:40.384, tt:5330.662\n",
      "Ep:132, loss:0.00000, loss_test:0.02328, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.374, tt:5369.680\n",
      "##########Best model found so far##########\n",
      "Ep:133, loss:0.00000, loss_test:0.02329, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.381, tt:5411.105\n",
      "Ep:134, loss:0.00000, loss_test:0.02332, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.371, tt:5450.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.02337, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.364, tt:5489.508\n",
      "Ep:136, loss:0.00000, loss_test:0.02345, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.343, tt:5527.047\n",
      "Ep:137, loss:0.00000, loss_test:0.02349, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.347, tt:5567.946\n",
      "Ep:138, loss:0.00000, loss_test:0.02345, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.346, tt:5608.114\n",
      "Ep:139, loss:0.00000, loss_test:0.02355, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.343, tt:5648.076\n",
      "Ep:140, loss:0.00000, loss_test:0.02357, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.351, tt:5689.423\n",
      "Ep:141, loss:0.00000, loss_test:0.02364, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.340, tt:5728.246\n",
      "Ep:142, loss:0.00000, loss_test:0.02361, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.335, tt:5767.885\n",
      "Ep:143, loss:0.00000, loss_test:0.02361, lr:4.10e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.334, tt:5808.134\n",
      "Ep:144, loss:0.00000, loss_test:0.02369, lr:4.05e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.343, tt:5849.805\n",
      "Ep:145, loss:0.00000, loss_test:0.02371, lr:4.01e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.339, tt:5889.540\n",
      "Ep:146, loss:0.00000, loss_test:0.02371, lr:3.97e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.349, tt:5931.331\n",
      "Ep:147, loss:0.00000, loss_test:0.02376, lr:3.93e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.335, tt:5969.563\n",
      "Ep:148, loss:0.00000, loss_test:0.02382, lr:3.89e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.335, tt:6009.921\n",
      "Ep:149, loss:0.00000, loss_test:0.02386, lr:3.86e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.379, tt:6056.804\n",
      "Ep:150, loss:0.00000, loss_test:0.02388, lr:3.82e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.381, tt:6097.551\n",
      "Ep:151, loss:0.00000, loss_test:0.02384, lr:3.78e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.388, tt:6139.026\n",
      "Ep:152, loss:0.00000, loss_test:0.02391, lr:3.74e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.402, tt:6181.515\n",
      "Ep:153, loss:0.00000, loss_test:0.02401, lr:3.70e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.404, tt:6222.205\n",
      "Ep:154, loss:0.00000, loss_test:0.02399, lr:3.67e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.417, tt:6264.657\n",
      "Ep:155, loss:0.00000, loss_test:0.02399, lr:3.63e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.426, tt:6306.412\n",
      "Ep:156, loss:0.00000, loss_test:0.02401, lr:3.59e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.428, tt:6347.158\n",
      "Ep:157, loss:0.00000, loss_test:0.02407, lr:3.56e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.440, tt:6389.491\n",
      "Ep:158, loss:0.00000, loss_test:0.02412, lr:3.52e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.433, tt:6428.821\n",
      "Ep:159, loss:0.00000, loss_test:0.02415, lr:3.49e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.447, tt:6471.547\n",
      "Ep:160, loss:0.00000, loss_test:0.02414, lr:3.45e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.458, tt:6513.730\n",
      "Ep:161, loss:0.00000, loss_test:0.02417, lr:3.42e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.462, tt:6554.885\n",
      "Ep:162, loss:0.00000, loss_test:0.02419, lr:3.38e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.474, tt:6597.327\n",
      "Ep:163, loss:0.00000, loss_test:0.02422, lr:3.35e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.479, tt:6638.481\n",
      "Ep:164, loss:0.00000, loss_test:0.02422, lr:3.32e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.487, tt:6680.380\n",
      "Ep:165, loss:0.00000, loss_test:0.02424, lr:3.28e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.489, tt:6721.099\n",
      "Ep:166, loss:0.00000, loss_test:0.02430, lr:3.25e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.491, tt:6761.984\n",
      "Ep:167, loss:0.00000, loss_test:0.02430, lr:3.22e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.499, tt:6803.807\n",
      "Ep:168, loss:0.00000, loss_test:0.02433, lr:3.19e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.511, tt:6846.284\n",
      "Ep:169, loss:0.00000, loss_test:0.02437, lr:3.15e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.517, tt:6887.859\n",
      "Ep:170, loss:0.00000, loss_test:0.02442, lr:3.12e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.548, tt:6933.773\n",
      "Ep:171, loss:0.00000, loss_test:0.02445, lr:3.09e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.558, tt:6975.924\n",
      "Ep:172, loss:0.00000, loss_test:0.02446, lr:3.06e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.573, tt:7019.203\n",
      "Ep:173, loss:0.00000, loss_test:0.02445, lr:3.03e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.578, tt:7060.594\n",
      "Ep:174, loss:0.00000, loss_test:0.02446, lr:3.00e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.592, tt:7103.622\n",
      "Ep:175, loss:0.00000, loss_test:0.02449, lr:2.97e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.597, tt:7145.112\n",
      "Ep:176, loss:0.00000, loss_test:0.02454, lr:2.94e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.604, tt:7186.881\n",
      "Ep:177, loss:0.00000, loss_test:0.02456, lr:2.91e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.610, tt:7228.547\n",
      "Ep:178, loss:0.00000, loss_test:0.02461, lr:2.88e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.608, tt:7268.878\n",
      "Ep:179, loss:0.00000, loss_test:0.02461, lr:2.85e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.611, tt:7310.060\n",
      "Ep:180, loss:0.00000, loss_test:0.02463, lr:2.82e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.628, tt:7353.684\n",
      "Ep:181, loss:0.00000, loss_test:0.02468, lr:2.80e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.629, tt:7394.499\n",
      "Ep:182, loss:0.00000, loss_test:0.02474, lr:2.77e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.642, tt:7437.522\n",
      "Ep:183, loss:0.00000, loss_test:0.02473, lr:2.74e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.649, tt:7479.353\n",
      "Ep:184, loss:0.00000, loss_test:0.02475, lr:2.71e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.658, tt:7521.722\n",
      "Ep:185, loss:0.00000, loss_test:0.02476, lr:2.69e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.656, tt:7562.000\n",
      "Ep:186, loss:0.00000, loss_test:0.02478, lr:2.66e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.659, tt:7603.265\n",
      "Ep:187, loss:0.00000, loss_test:0.02482, lr:2.63e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.669, tt:7645.693\n",
      "Ep:188, loss:0.00000, loss_test:0.02482, lr:2.61e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.674, tt:7687.312\n",
      "Ep:189, loss:0.00000, loss_test:0.02481, lr:2.58e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.682, tt:7729.488\n",
      "Ep:190, loss:0.00000, loss_test:0.02488, lr:2.55e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.722, tt:7777.896\n",
      "Ep:191, loss:0.00000, loss_test:0.02492, lr:2.53e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.721, tt:7818.356\n",
      "Ep:192, loss:0.00000, loss_test:0.02493, lr:2.50e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.722, tt:7859.256\n",
      "Ep:193, loss:0.00000, loss_test:0.02493, lr:2.48e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.722, tt:7900.004\n",
      "Ep:194, loss:0.00000, loss_test:0.02495, lr:2.45e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.733, tt:7942.974\n",
      "Ep:195, loss:0.00000, loss_test:0.02496, lr:2.43e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.737, tt:7984.472\n",
      "Ep:196, loss:0.00000, loss_test:0.02500, lr:2.40e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.744, tt:8026.567\n",
      "Ep:197, loss:0.00000, loss_test:0.02501, lr:2.38e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.754, tt:8069.297\n",
      "Ep:198, loss:0.00000, loss_test:0.02503, lr:2.36e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.764, tt:8112.015\n",
      "Ep:199, loss:0.00000, loss_test:0.02505, lr:2.33e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.762, tt:8152.475\n",
      "Ep:200, loss:0.00000, loss_test:0.02508, lr:2.31e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.757, tt:8192.246\n",
      "Ep:201, loss:0.00000, loss_test:0.02510, lr:2.29e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.767, tt:8235.024\n",
      "Ep:202, loss:0.00000, loss_test:0.02512, lr:2.26e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.754, tt:8273.066\n",
      "Ep:203, loss:0.00000, loss_test:0.02514, lr:2.24e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.764, tt:8315.797\n",
      "Ep:204, loss:0.00000, loss_test:0.02515, lr:2.22e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.758, tt:8355.341\n",
      "Ep:205, loss:0.00000, loss_test:0.02518, lr:2.20e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.762, tt:8397.000\n",
      "Ep:206, loss:0.00000, loss_test:0.02519, lr:2.17e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.770, tt:8439.403\n",
      "Ep:207, loss:0.00000, loss_test:0.02521, lr:2.15e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.769, tt:8479.878\n",
      "Ep:208, loss:0.00000, loss_test:0.02522, lr:2.13e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.779, tt:8522.917\n",
      "Ep:209, loss:0.00000, loss_test:0.02523, lr:2.11e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.783, tt:8564.343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.02525, lr:2.09e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.780, tt:8604.657\n",
      "Ep:211, loss:0.00000, loss_test:0.02525, lr:2.07e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.784, tt:8646.252\n",
      "Ep:212, loss:0.00000, loss_test:0.02528, lr:2.05e-02, fs:0.78710 (r=0.701,p=0.897),  time:40.769, tt:8683.876\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14348, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.311, tt:40.311\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14243, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.611, tt:67.222\n",
      "Ep:2, loss:0.00028, loss_test:0.14054, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.870, tt:107.609\n",
      "Ep:3, loss:0.00027, loss_test:0.13738, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:37.725, tt:150.899\n",
      "Ep:4, loss:0.00027, loss_test:0.13213, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:38.596, tt:192.978\n",
      "Ep:5, loss:0.00026, loss_test:0.12441, lr:1.00e-02, fs:0.68880 (r=0.954,p=0.539),  time:39.034, tt:234.207\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11508, lr:1.00e-02, fs:0.69652 (r=0.805,p=0.614),  time:39.656, tt:277.591\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11493, lr:1.00e-02, fs:0.64740 (r=0.644,p=0.651),  time:40.242, tt:321.939\n",
      "Ep:8, loss:0.00022, loss_test:0.11159, lr:1.00e-02, fs:0.65143 (r=0.655,p=0.648),  time:40.706, tt:366.351\n",
      "Ep:9, loss:0.00021, loss_test:0.10874, lr:1.00e-02, fs:0.68889 (r=0.713,p=0.667),  time:40.865, tt:408.647\n",
      "Ep:10, loss:0.00021, loss_test:0.10610, lr:1.00e-02, fs:0.68571 (r=0.690,p=0.682),  time:41.091, tt:452.006\n",
      "Ep:11, loss:0.00020, loss_test:0.10616, lr:1.00e-02, fs:0.65882 (r=0.644,p=0.675),  time:41.290, tt:495.486\n",
      "Ep:12, loss:0.00019, loss_test:0.10415, lr:1.00e-02, fs:0.66279 (r=0.655,p=0.671),  time:41.213, tt:535.773\n",
      "Ep:13, loss:0.00018, loss_test:0.10270, lr:1.00e-02, fs:0.67052 (r=0.667,p=0.674),  time:41.298, tt:578.168\n",
      "Ep:14, loss:0.00017, loss_test:0.10331, lr:1.00e-02, fs:0.67857 (r=0.655,p=0.704),  time:41.619, tt:624.290\n",
      "Ep:15, loss:0.00017, loss_test:0.10015, lr:1.00e-02, fs:0.69006 (r=0.678,p=0.702),  time:41.825, tt:669.201\n",
      "Ep:16, loss:0.00016, loss_test:0.09924, lr:1.00e-02, fs:0.70175 (r=0.690,p=0.714),  time:41.894, tt:712.193\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09875, lr:1.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:41.953, tt:755.145\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09829, lr:1.00e-02, fs:0.72189 (r=0.701,p=0.744),  time:42.061, tt:799.152\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09914, lr:1.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:42.124, tt:842.478\n",
      "Ep:20, loss:0.00014, loss_test:0.09684, lr:1.00e-02, fs:0.71345 (r=0.701,p=0.726),  time:42.148, tt:885.108\n",
      "Ep:21, loss:0.00013, loss_test:0.09616, lr:1.00e-02, fs:0.72619 (r=0.701,p=0.753),  time:42.144, tt:927.160\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09576, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:42.152, tt:969.491\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.09488, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:42.168, tt:1012.043\n",
      "Ep:24, loss:0.00012, loss_test:0.09387, lr:1.00e-02, fs:0.72619 (r=0.701,p=0.753),  time:42.178, tt:1054.438\n",
      "Ep:25, loss:0.00011, loss_test:0.09497, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:42.263, tt:1098.845\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.09396, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:42.293, tt:1141.913\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.09257, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:42.307, tt:1184.584\n",
      "Ep:28, loss:0.00010, loss_test:0.09422, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:42.341, tt:1227.884\n",
      "Ep:29, loss:0.00009, loss_test:0.09230, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:42.316, tt:1269.486\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.09416, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:42.299, tt:1311.256\n",
      "Ep:31, loss:0.00009, loss_test:0.09171, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:42.272, tt:1352.706\n",
      "Ep:32, loss:0.00009, loss_test:0.09339, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:42.283, tt:1395.349\n",
      "Ep:33, loss:0.00008, loss_test:0.09235, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:42.244, tt:1436.300\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.09317, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:42.284, tt:1479.924\n",
      "Ep:35, loss:0.00007, loss_test:0.09183, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:42.291, tt:1522.473\n",
      "Ep:36, loss:0.00007, loss_test:0.09217, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:42.295, tt:1564.897\n",
      "Ep:37, loss:0.00007, loss_test:0.09175, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:42.273, tt:1606.380\n",
      "Ep:38, loss:0.00007, loss_test:0.09166, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:42.226, tt:1646.823\n",
      "Ep:39, loss:0.00006, loss_test:0.09218, lr:1.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:42.246, tt:1689.829\n",
      "Ep:40, loss:0.00006, loss_test:0.09255, lr:1.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:42.178, tt:1729.318\n",
      "Ep:41, loss:0.00006, loss_test:0.09000, lr:1.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:42.147, tt:1770.157\n",
      "Ep:42, loss:0.00006, loss_test:0.09256, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:42.166, tt:1813.132\n",
      "Ep:43, loss:0.00005, loss_test:0.09017, lr:1.00e-02, fs:0.76190 (r=0.736,p=0.790),  time:42.152, tt:1854.684\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.09349, lr:1.00e-02, fs:0.73885 (r=0.667,p=0.829),  time:42.156, tt:1897.032\n",
      "Ep:45, loss:0.00005, loss_test:0.08834, lr:1.00e-02, fs:0.75740 (r=0.736,p=0.780),  time:42.156, tt:1939.164\n",
      "Ep:46, loss:0.00005, loss_test:0.09448, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.134, tt:1980.283\n",
      "Ep:47, loss:0.00005, loss_test:0.08866, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:42.164, tt:2023.859\n",
      "Ep:48, loss:0.00005, loss_test:0.09363, lr:1.00e-02, fs:0.73885 (r=0.667,p=0.829),  time:42.196, tt:2067.614\n",
      "Ep:49, loss:0.00004, loss_test:0.09242, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.173, tt:2108.629\n",
      "Ep:50, loss:0.00004, loss_test:0.09095, lr:1.00e-02, fs:0.73418 (r=0.667,p=0.817),  time:42.208, tt:2152.595\n",
      "Ep:51, loss:0.00004, loss_test:0.09241, lr:1.00e-02, fs:0.72727 (r=0.644,p=0.836),  time:42.189, tt:2193.811\n",
      "Ep:52, loss:0.00004, loss_test:0.09188, lr:1.00e-02, fs:0.72500 (r=0.667,p=0.795),  time:42.211, tt:2237.171\n",
      "Ep:53, loss:0.00004, loss_test:0.09412, lr:1.00e-02, fs:0.73548 (r=0.655,p=0.838),  time:42.214, tt:2279.549\n",
      "Ep:54, loss:0.00004, loss_test:0.08778, lr:1.00e-02, fs:0.75904 (r=0.724,p=0.797),  time:42.187, tt:2320.296\n",
      "Ep:55, loss:0.00004, loss_test:0.09519, lr:9.90e-03, fs:0.73684 (r=0.644,p=0.862),  time:42.166, tt:2361.303\n",
      "Ep:56, loss:0.00003, loss_test:0.08875, lr:9.80e-03, fs:0.72611 (r=0.655,p=0.814),  time:42.143, tt:2402.124\n",
      "Ep:57, loss:0.00003, loss_test:0.09258, lr:9.70e-03, fs:0.72727 (r=0.644,p=0.836),  time:42.117, tt:2442.763\n",
      "Ep:58, loss:0.00003, loss_test:0.08887, lr:9.61e-03, fs:0.75159 (r=0.678,p=0.843),  time:42.096, tt:2483.686\n",
      "Ep:59, loss:0.00003, loss_test:0.09347, lr:9.51e-03, fs:0.74172 (r=0.644,p=0.875),  time:42.082, tt:2524.905\n",
      "Ep:60, loss:0.00003, loss_test:0.08615, lr:9.41e-03, fs:0.73077 (r=0.655,p=0.826),  time:42.051, tt:2565.142\n",
      "Ep:61, loss:0.00003, loss_test:0.09176, lr:9.32e-03, fs:0.74172 (r=0.644,p=0.875),  time:42.059, tt:2607.687\n",
      "Ep:62, loss:0.00003, loss_test:0.08698, lr:9.23e-03, fs:0.73077 (r=0.655,p=0.826),  time:42.072, tt:2650.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00002, loss_test:0.09238, lr:9.14e-03, fs:0.74667 (r=0.644,p=0.889),  time:42.037, tt:2690.346\n",
      "Ep:64, loss:0.00002, loss_test:0.08752, lr:9.04e-03, fs:0.72727 (r=0.644,p=0.836),  time:42.010, tt:2730.678\n",
      "Ep:65, loss:0.00002, loss_test:0.08969, lr:8.95e-03, fs:0.73684 (r=0.644,p=0.862),  time:42.016, tt:2773.084\n",
      "Ep:66, loss:0.00002, loss_test:0.08763, lr:8.86e-03, fs:0.77707 (r=0.701,p=0.871),  time:42.030, tt:2816.039\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.08883, lr:8.86e-03, fs:0.74172 (r=0.644,p=0.875),  time:42.023, tt:2857.536\n",
      "Ep:68, loss:0.00002, loss_test:0.08856, lr:8.86e-03, fs:0.75817 (r=0.667,p=0.879),  time:41.992, tt:2897.438\n",
      "Ep:69, loss:0.00002, loss_test:0.08777, lr:8.86e-03, fs:0.76316 (r=0.667,p=0.892),  time:41.976, tt:2938.321\n",
      "Ep:70, loss:0.00002, loss_test:0.08956, lr:8.86e-03, fs:0.75168 (r=0.644,p=0.903),  time:41.970, tt:2979.860\n",
      "Ep:71, loss:0.00002, loss_test:0.08842, lr:8.86e-03, fs:0.76129 (r=0.678,p=0.868),  time:41.949, tt:3020.318\n",
      "Ep:72, loss:0.00002, loss_test:0.08987, lr:8.86e-03, fs:0.75497 (r=0.655,p=0.891),  time:41.955, tt:3062.722\n",
      "Ep:73, loss:0.00002, loss_test:0.08854, lr:8.86e-03, fs:0.76623 (r=0.678,p=0.881),  time:41.963, tt:3105.240\n",
      "Ep:74, loss:0.00002, loss_test:0.08961, lr:8.86e-03, fs:0.75168 (r=0.644,p=0.903),  time:41.993, tt:3149.499\n",
      "Ep:75, loss:0.00002, loss_test:0.08919, lr:8.86e-03, fs:0.74667 (r=0.644,p=0.889),  time:42.003, tt:3192.229\n",
      "Ep:76, loss:0.00002, loss_test:0.08856, lr:8.86e-03, fs:0.76000 (r=0.655,p=0.905),  time:42.038, tt:3236.932\n",
      "Ep:77, loss:0.00001, loss_test:0.08941, lr:8.86e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.074, tt:3281.735\n",
      "Ep:78, loss:0.00001, loss_test:0.08895, lr:8.78e-03, fs:0.76129 (r=0.678,p=0.868),  time:42.085, tt:3324.753\n",
      "Ep:79, loss:0.00001, loss_test:0.09009, lr:8.69e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.067, tt:3365.377\n",
      "Ep:80, loss:0.00001, loss_test:0.09011, lr:8.60e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.082, tt:3408.639\n",
      "Ep:81, loss:0.00001, loss_test:0.08991, lr:8.51e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.084, tt:3450.914\n",
      "Ep:82, loss:0.00001, loss_test:0.09036, lr:8.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.102, tt:3494.436\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.09095, lr:8.43e-03, fs:0.75497 (r=0.655,p=0.891),  time:42.117, tt:3537.816\n",
      "Ep:84, loss:0.00001, loss_test:0.09236, lr:8.43e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.139, tt:3581.793\n",
      "Ep:85, loss:0.00001, loss_test:0.09253, lr:8.43e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.135, tt:3623.589\n",
      "Ep:86, loss:0.00001, loss_test:0.09036, lr:8.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.147, tt:3666.751\n",
      "Ep:87, loss:0.00001, loss_test:0.09334, lr:8.43e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.147, tt:3708.958\n",
      "Ep:88, loss:0.00001, loss_test:0.09190, lr:8.43e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.175, tt:3753.532\n",
      "Ep:89, loss:0.00001, loss_test:0.09191, lr:8.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.178, tt:3795.995\n",
      "Ep:90, loss:0.00001, loss_test:0.09354, lr:8.43e-03, fs:0.76510 (r=0.655,p=0.919),  time:42.178, tt:3838.166\n",
      "Ep:91, loss:0.00001, loss_test:0.09305, lr:8.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.166, tt:3879.312\n",
      "Ep:92, loss:0.00001, loss_test:0.09356, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.179, tt:3922.655\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.09572, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.181, tt:3964.987\n",
      "Ep:94, loss:0.00001, loss_test:0.09446, lr:8.43e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.180, tt:4007.054\n",
      "Ep:95, loss:0.00001, loss_test:0.09387, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.191, tt:4050.370\n",
      "Ep:96, loss:0.00001, loss_test:0.09744, lr:8.43e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.199, tt:4093.324\n",
      "Ep:97, loss:0.00001, loss_test:0.09275, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.244, tt:4139.915\n",
      "Ep:98, loss:0.00001, loss_test:0.09774, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.243, tt:4182.025\n",
      "Ep:99, loss:0.00001, loss_test:0.09380, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.231, tt:4223.060\n",
      "Ep:100, loss:0.00001, loss_test:0.09789, lr:8.43e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.213, tt:4263.539\n",
      "Ep:101, loss:0.00001, loss_test:0.09533, lr:8.43e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.195, tt:4303.914\n",
      "Ep:102, loss:0.00001, loss_test:0.09653, lr:8.43e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.181, tt:4344.673\n",
      "Ep:103, loss:0.00001, loss_test:0.09746, lr:8.43e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.184, tt:4387.115\n",
      "Ep:104, loss:0.00001, loss_test:0.09608, lr:8.35e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.198, tt:4430.773\n",
      "Ep:105, loss:0.00001, loss_test:0.09969, lr:8.26e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.197, tt:4472.891\n",
      "Ep:106, loss:0.00001, loss_test:0.09504, lr:8.18e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.189, tt:4514.233\n",
      "Ep:107, loss:0.00001, loss_test:0.09854, lr:8.10e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.178, tt:4555.196\n",
      "Ep:108, loss:0.00001, loss_test:0.09670, lr:8.02e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.159, tt:4595.307\n",
      "Ep:109, loss:0.00001, loss_test:0.09770, lr:7.94e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.142, tt:4635.596\n",
      "Ep:110, loss:0.00001, loss_test:0.09669, lr:7.86e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.133, tt:4676.707\n",
      "Ep:111, loss:0.00001, loss_test:0.09625, lr:7.78e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.122, tt:4717.655\n",
      "Ep:112, loss:0.00001, loss_test:0.09862, lr:7.70e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.127, tt:4760.337\n",
      "Ep:113, loss:0.00001, loss_test:0.09870, lr:7.62e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.125, tt:4802.238\n",
      "Ep:114, loss:0.00001, loss_test:0.09779, lr:7.55e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.124, tt:4844.218\n",
      "Ep:115, loss:0.00001, loss_test:0.09743, lr:7.47e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.131, tt:4887.192\n",
      "Ep:116, loss:0.00001, loss_test:0.09980, lr:7.40e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.122, tt:4928.260\n",
      "Ep:117, loss:0.00001, loss_test:0.09690, lr:7.32e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.137, tt:4972.122\n",
      "Ep:118, loss:0.00001, loss_test:0.10045, lr:7.25e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.134, tt:5013.959\n",
      "Ep:119, loss:0.00001, loss_test:0.09822, lr:7.18e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.126, tt:5055.155\n",
      "Ep:120, loss:0.00001, loss_test:0.09777, lr:7.11e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.134, tt:5098.157\n",
      "Ep:121, loss:0.00001, loss_test:0.09871, lr:7.03e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.131, tt:5140.039\n",
      "Ep:122, loss:0.00001, loss_test:0.09790, lr:6.96e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.143, tt:5183.567\n",
      "Ep:123, loss:0.00000, loss_test:0.09918, lr:6.89e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.148, tt:5226.301\n",
      "Ep:124, loss:0.00000, loss_test:0.09834, lr:6.83e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.146, tt:5268.284\n",
      "Ep:125, loss:0.00000, loss_test:0.09867, lr:6.76e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.153, tt:5311.260\n",
      "Ep:126, loss:0.00000, loss_test:0.09820, lr:6.69e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.139, tt:5351.666\n",
      "Ep:127, loss:0.00000, loss_test:0.09745, lr:6.62e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.143, tt:5394.263\n",
      "Ep:128, loss:0.00000, loss_test:0.09897, lr:6.56e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.148, tt:5437.111\n",
      "Ep:129, loss:0.00000, loss_test:0.09842, lr:6.49e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.162, tt:5481.037\n",
      "Ep:130, loss:0.00000, loss_test:0.09854, lr:6.43e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.162, tt:5523.208\n",
      "Ep:131, loss:0.00000, loss_test:0.09731, lr:6.36e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.165, tt:5565.811\n",
      "Ep:132, loss:0.00000, loss_test:0.10159, lr:6.30e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.175, tt:5609.232\n",
      "Ep:133, loss:0.00000, loss_test:0.09939, lr:6.24e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.192, tt:5653.780\n",
      "Ep:134, loss:0.00000, loss_test:0.09886, lr:6.17e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.181, tt:5694.454\n",
      "Ep:135, loss:0.00000, loss_test:0.09885, lr:6.11e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.159, tt:5733.653\n",
      "Ep:136, loss:0.00000, loss_test:0.09999, lr:6.05e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.151, tt:5774.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.10009, lr:5.99e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.156, tt:5817.519\n",
      "Ep:138, loss:0.00000, loss_test:0.09928, lr:5.93e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.157, tt:5859.819\n",
      "Ep:139, loss:0.00000, loss_test:0.09907, lr:5.87e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.156, tt:5901.822\n",
      "Ep:140, loss:0.00000, loss_test:0.09970, lr:5.81e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.164, tt:5945.065\n",
      "Ep:141, loss:0.00000, loss_test:0.09859, lr:5.75e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.163, tt:5987.211\n",
      "Ep:142, loss:0.00000, loss_test:0.09900, lr:5.70e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.188, tt:6032.907\n",
      "Ep:143, loss:0.00000, loss_test:0.09839, lr:5.64e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.206, tt:6077.632\n",
      "Ep:144, loss:0.00000, loss_test:0.09950, lr:5.58e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.205, tt:6119.755\n",
      "Ep:145, loss:0.00000, loss_test:0.09950, lr:5.53e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.210, tt:6162.628\n",
      "Ep:146, loss:0.00000, loss_test:0.09871, lr:5.47e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.223, tt:6206.713\n",
      "Ep:147, loss:0.00000, loss_test:0.09916, lr:5.42e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.222, tt:6248.901\n",
      "Ep:148, loss:0.00000, loss_test:0.09830, lr:5.36e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.231, tt:6292.371\n",
      "Ep:149, loss:0.00000, loss_test:0.09926, lr:5.31e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.246, tt:6336.914\n",
      "Ep:150, loss:0.00000, loss_test:0.09901, lr:5.26e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.244, tt:6378.849\n",
      "Ep:151, loss:0.00000, loss_test:0.09921, lr:5.20e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.252, tt:6422.266\n",
      "Ep:152, loss:0.00000, loss_test:0.09901, lr:5.15e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.251, tt:6464.451\n",
      "Ep:153, loss:0.00000, loss_test:0.09831, lr:5.10e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.247, tt:6506.104\n",
      "Ep:154, loss:0.00000, loss_test:0.09905, lr:5.05e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.258, tt:6550.062\n",
      "Ep:155, loss:0.00000, loss_test:0.09959, lr:5.00e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.260, tt:6592.622\n",
      "Ep:156, loss:0.00000, loss_test:0.09897, lr:4.95e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.271, tt:6636.538\n",
      "Ep:157, loss:0.00000, loss_test:0.09897, lr:4.90e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.283, tt:6680.684\n",
      "Ep:158, loss:0.00000, loss_test:0.09950, lr:4.85e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.290, tt:6724.135\n",
      "Ep:159, loss:0.00000, loss_test:0.09902, lr:4.80e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.296, tt:6767.332\n",
      "Ep:160, loss:0.00000, loss_test:0.09900, lr:4.75e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.306, tt:6811.203\n",
      "Ep:161, loss:0.00000, loss_test:0.09993, lr:4.71e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.307, tt:6853.795\n",
      "Ep:162, loss:0.00000, loss_test:0.09906, lr:4.66e-03, fs:0.78146 (r=0.678,p=0.922),  time:42.314, tt:6897.134\n",
      "Ep:163, loss:0.00000, loss_test:0.09960, lr:4.61e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.325, tt:6941.245\n",
      "Ep:164, loss:0.00000, loss_test:0.09931, lr:4.57e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.333, tt:6984.867\n",
      "Ep:165, loss:0.00000, loss_test:0.09911, lr:4.52e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.341, tt:7028.609\n",
      "Ep:166, loss:0.00000, loss_test:0.09969, lr:4.48e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.337, tt:7070.250\n",
      "Ep:167, loss:0.00000, loss_test:0.09957, lr:4.43e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.327, tt:7110.933\n",
      "Ep:168, loss:0.00000, loss_test:0.09952, lr:4.39e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.327, tt:7153.331\n",
      "Ep:169, loss:0.00000, loss_test:0.09945, lr:4.34e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.340, tt:7197.877\n",
      "Ep:170, loss:0.00000, loss_test:0.09941, lr:4.30e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.343, tt:7240.677\n",
      "Ep:171, loss:0.00000, loss_test:0.09960, lr:4.26e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.350, tt:7284.128\n",
      "Ep:172, loss:0.00000, loss_test:0.09940, lr:4.21e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.348, tt:7326.143\n",
      "Ep:173, loss:0.00000, loss_test:0.09970, lr:4.17e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.347, tt:7368.363\n",
      "Ep:174, loss:0.00000, loss_test:0.09987, lr:4.13e-03, fs:0.75676 (r=0.644,p=0.918),  time:42.347, tt:7410.641\n",
      "Ep:175, loss:0.00000, loss_test:0.09919, lr:4.09e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.352, tt:7453.903\n",
      "Ep:176, loss:0.00000, loss_test:0.10042, lr:4.05e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.351, tt:7496.125\n",
      "Ep:177, loss:0.00000, loss_test:0.10032, lr:4.01e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.345, tt:7537.452\n",
      "Ep:178, loss:0.00000, loss_test:0.09991, lr:3.97e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.330, tt:7577.032\n",
      "Ep:179, loss:0.00000, loss_test:0.09995, lr:3.93e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.333, tt:7619.878\n",
      "Ep:180, loss:0.00000, loss_test:0.09976, lr:3.89e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.332, tt:7662.049\n",
      "Ep:181, loss:0.00000, loss_test:0.10049, lr:3.85e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.331, tt:7704.277\n",
      "Ep:182, loss:0.00000, loss_test:0.10009, lr:3.81e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.340, tt:7748.240\n",
      "Ep:183, loss:0.00000, loss_test:0.09977, lr:3.77e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.345, tt:7791.464\n",
      "Ep:184, loss:0.00000, loss_test:0.10000, lr:3.73e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.344, tt:7833.719\n",
      "Ep:185, loss:0.00000, loss_test:0.10031, lr:3.70e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.341, tt:7875.442\n",
      "Ep:186, loss:0.00000, loss_test:0.09971, lr:3.66e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.349, tt:7919.223\n",
      "Ep:187, loss:0.00000, loss_test:0.10081, lr:3.62e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.342, tt:7960.354\n",
      "Ep:188, loss:0.00000, loss_test:0.10116, lr:3.59e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.351, tt:8004.369\n",
      "Ep:189, loss:0.00000, loss_test:0.10075, lr:3.55e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.358, tt:8048.023\n",
      "Ep:190, loss:0.00000, loss_test:0.10100, lr:3.52e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.353, tt:8089.485\n",
      "Ep:191, loss:0.00000, loss_test:0.10053, lr:3.48e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.356, tt:8132.315\n",
      "Ep:192, loss:0.00000, loss_test:0.10052, lr:3.45e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.357, tt:8174.918\n",
      "Ep:193, loss:0.00000, loss_test:0.10077, lr:3.41e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.365, tt:8218.774\n",
      "Ep:194, loss:0.00000, loss_test:0.10104, lr:3.38e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.374, tt:8262.913\n",
      "Ep:195, loss:0.00000, loss_test:0.10076, lr:3.34e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.376, tt:8305.776\n",
      "Ep:196, loss:0.00000, loss_test:0.10039, lr:3.31e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.387, tt:8350.291\n",
      "Ep:197, loss:0.00000, loss_test:0.10025, lr:3.28e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.393, tt:8393.814\n",
      "Ep:198, loss:0.00000, loss_test:0.10093, lr:3.24e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.376, tt:8432.825\n",
      "Ep:199, loss:0.00000, loss_test:0.10134, lr:3.21e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.368, tt:8473.544\n",
      "Ep:200, loss:0.00000, loss_test:0.10090, lr:3.18e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.371, tt:8516.540\n",
      "Ep:201, loss:0.00000, loss_test:0.10061, lr:3.15e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.368, tt:8558.410\n",
      "Ep:202, loss:0.00000, loss_test:0.10053, lr:3.12e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.369, tt:8600.808\n",
      "Ep:203, loss:0.00000, loss_test:0.10052, lr:3.09e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.368, tt:8643.134\n",
      "Ep:204, loss:0.00000, loss_test:0.10041, lr:3.05e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.367, tt:8685.159\n",
      "Ep:205, loss:0.00000, loss_test:0.10057, lr:3.02e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.363, tt:8726.787\n",
      "Ep:206, loss:0.00000, loss_test:0.10076, lr:2.99e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.358, tt:8768.173\n",
      "Ep:207, loss:0.00000, loss_test:0.10031, lr:2.96e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.346, tt:8807.980\n",
      "Ep:208, loss:0.00000, loss_test:0.10052, lr:2.93e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.343, tt:8849.688\n",
      "Ep:209, loss:0.00000, loss_test:0.10079, lr:2.90e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.339, tt:8891.287\n",
      "Ep:210, loss:0.00000, loss_test:0.10037, lr:2.88e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.324, tt:8930.310\n",
      "Ep:211, loss:0.00000, loss_test:0.10006, lr:2.85e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.314, tt:8970.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:212, loss:0.00000, loss_test:0.10053, lr:2.82e-03, fs:0.76190 (r=0.644,p=0.933),  time:42.286, tt:9006.970\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01989, lr:6.00e-02, fs:0.66939 (r=0.943,p=0.519),  time:28.931, tt:28.931\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02272, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:29.037, tt:58.075\n",
      "Ep:2, loss:0.00005, loss_test:0.02361, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.070, tt:93.210\n",
      "Ep:3, loss:0.00005, loss_test:0.02283, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.843, tt:135.372\n",
      "Ep:4, loss:0.00004, loss_test:0.02115, lr:6.00e-02, fs:0.67188 (r=0.989,p=0.509),  time:35.258, tt:176.288\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01967, lr:6.00e-02, fs:0.68000 (r=0.977,p=0.521),  time:36.219, tt:217.312\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01923, lr:6.00e-02, fs:0.66953 (r=0.897,p=0.534),  time:36.579, tt:256.052\n",
      "Ep:7, loss:0.00004, loss_test:0.01958, lr:6.00e-02, fs:0.66029 (r=0.793,p=0.566),  time:37.351, tt:298.812\n",
      "Ep:8, loss:0.00004, loss_test:0.01954, lr:6.00e-02, fs:0.65700 (r=0.782,p=0.567),  time:37.595, tt:338.355\n",
      "Ep:9, loss:0.00003, loss_test:0.01922, lr:6.00e-02, fs:0.66960 (r=0.874,p=0.543),  time:38.095, tt:380.955\n",
      "Ep:10, loss:0.00003, loss_test:0.01924, lr:6.00e-02, fs:0.67227 (r=0.920,p=0.530),  time:38.287, tt:421.159\n",
      "Ep:11, loss:0.00003, loss_test:0.01926, lr:6.00e-02, fs:0.67769 (r=0.943,p=0.529),  time:38.565, tt:462.780\n",
      "Ep:12, loss:0.00003, loss_test:0.01916, lr:6.00e-02, fs:0.67544 (r=0.885,p=0.546),  time:38.746, tt:503.700\n",
      "Ep:13, loss:0.00003, loss_test:0.01919, lr:6.00e-02, fs:0.67907 (r=0.839,p=0.570),  time:39.028, tt:546.392\n",
      "Ep:14, loss:0.00003, loss_test:0.01920, lr:6.00e-02, fs:0.66995 (r=0.782,p=0.586),  time:39.188, tt:587.823\n",
      "Ep:15, loss:0.00003, loss_test:0.01908, lr:6.00e-02, fs:0.64646 (r=0.736,p=0.577),  time:39.244, tt:627.906\n",
      "Ep:16, loss:0.00003, loss_test:0.01888, lr:6.00e-02, fs:0.65672 (r=0.759,p=0.579),  time:39.391, tt:669.653\n",
      "Ep:17, loss:0.00003, loss_test:0.01874, lr:5.94e-02, fs:0.66010 (r=0.770,p=0.578),  time:39.585, tt:712.528\n",
      "Ep:18, loss:0.00003, loss_test:0.01868, lr:5.88e-02, fs:0.67308 (r=0.805,p=0.579),  time:39.556, tt:751.560\n",
      "Ep:19, loss:0.00003, loss_test:0.01869, lr:5.82e-02, fs:0.66995 (r=0.782,p=0.586),  time:39.543, tt:790.857\n",
      "Ep:20, loss:0.00003, loss_test:0.01874, lr:5.76e-02, fs:0.67337 (r=0.770,p=0.598),  time:39.618, tt:831.971\n",
      "Ep:21, loss:0.00003, loss_test:0.01875, lr:5.71e-02, fs:0.67005 (r=0.759,p=0.600),  time:39.674, tt:872.827\n",
      "Ep:22, loss:0.00003, loss_test:0.01866, lr:5.65e-02, fs:0.67692 (r=0.759,p=0.611),  time:39.753, tt:914.327\n",
      "Ep:23, loss:0.00002, loss_test:0.01856, lr:5.59e-02, fs:0.69110 (r=0.759,p=0.635),  time:39.742, tt:953.799\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01852, lr:5.59e-02, fs:0.69474 (r=0.759,p=0.641),  time:39.721, tt:993.021\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01844, lr:5.59e-02, fs:0.69110 (r=0.759,p=0.635),  time:39.719, tt:1032.693\n",
      "Ep:26, loss:0.00002, loss_test:0.01841, lr:5.59e-02, fs:0.70588 (r=0.759,p=0.660),  time:39.732, tt:1072.775\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01837, lr:5.59e-02, fs:0.70968 (r=0.759,p=0.667),  time:39.686, tt:1111.206\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01832, lr:5.59e-02, fs:0.70968 (r=0.759,p=0.667),  time:39.739, tt:1152.427\n",
      "Ep:29, loss:0.00002, loss_test:0.01824, lr:5.59e-02, fs:0.71351 (r=0.759,p=0.673),  time:39.762, tt:1192.865\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01817, lr:5.59e-02, fs:0.71351 (r=0.759,p=0.673),  time:39.654, tt:1229.274\n",
      "Ep:31, loss:0.00002, loss_test:0.01817, lr:5.59e-02, fs:0.72340 (r=0.782,p=0.673),  time:39.637, tt:1268.396\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01817, lr:5.59e-02, fs:0.72727 (r=0.782,p=0.680),  time:39.627, tt:1307.675\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01805, lr:5.59e-02, fs:0.72727 (r=0.782,p=0.680),  time:39.566, tt:1345.250\n",
      "Ep:34, loss:0.00002, loss_test:0.01803, lr:5.59e-02, fs:0.73118 (r=0.782,p=0.687),  time:39.603, tt:1386.109\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01796, lr:5.59e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.592, tt:1425.296\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01790, lr:5.59e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.586, tt:1464.697\n",
      "Ep:37, loss:0.00002, loss_test:0.01785, lr:5.59e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.566, tt:1503.524\n",
      "Ep:38, loss:0.00002, loss_test:0.01781, lr:5.59e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.573, tt:1543.335\n",
      "Ep:39, loss:0.00002, loss_test:0.01778, lr:5.59e-02, fs:0.73913 (r=0.782,p=0.701),  time:39.583, tt:1583.325\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01766, lr:5.59e-02, fs:0.73913 (r=0.782,p=0.701),  time:39.601, tt:1623.653\n",
      "Ep:41, loss:0.00002, loss_test:0.01757, lr:5.59e-02, fs:0.73913 (r=0.782,p=0.701),  time:39.571, tt:1661.980\n",
      "Ep:42, loss:0.00002, loss_test:0.01755, lr:5.59e-02, fs:0.73514 (r=0.782,p=0.694),  time:39.606, tt:1703.044\n",
      "Ep:43, loss:0.00002, loss_test:0.01745, lr:5.59e-02, fs:0.72826 (r=0.770,p=0.691),  time:39.580, tt:1741.529\n",
      "Ep:44, loss:0.00002, loss_test:0.01735, lr:5.59e-02, fs:0.72826 (r=0.770,p=0.691),  time:39.586, tt:1781.373\n",
      "Ep:45, loss:0.00002, loss_test:0.01724, lr:5.59e-02, fs:0.73224 (r=0.770,p=0.698),  time:39.606, tt:1821.883\n",
      "Ep:46, loss:0.00002, loss_test:0.01717, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.644, tt:1863.262\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01711, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.671, tt:1904.221\n",
      "Ep:48, loss:0.00002, loss_test:0.01701, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.671, tt:1943.896\n",
      "Ep:49, loss:0.00002, loss_test:0.01700, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.665, tt:1983.230\n",
      "Ep:50, loss:0.00002, loss_test:0.01690, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.651, tt:2022.219\n",
      "Ep:51, loss:0.00002, loss_test:0.01679, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.628, tt:2060.670\n",
      "Ep:52, loss:0.00002, loss_test:0.01682, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.585, tt:2098.000\n",
      "Ep:53, loss:0.00001, loss_test:0.01675, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.617, tt:2139.315\n",
      "Ep:54, loss:0.00001, loss_test:0.01661, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.620, tt:2179.126\n",
      "Ep:55, loss:0.00001, loss_test:0.01655, lr:5.59e-02, fs:0.74444 (r=0.770,p=0.720),  time:39.650, tt:2220.397\n",
      "Ep:56, loss:0.00001, loss_test:0.01653, lr:5.59e-02, fs:0.74860 (r=0.770,p=0.728),  time:39.631, tt:2258.947\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01646, lr:5.59e-02, fs:0.75281 (r=0.770,p=0.736),  time:39.613, tt:2297.540\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01641, lr:5.59e-02, fs:0.75706 (r=0.770,p=0.744),  time:39.583, tt:2335.410\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01634, lr:5.59e-02, fs:0.75000 (r=0.759,p=0.742),  time:39.609, tt:2376.556\n",
      "Ep:60, loss:0.00001, loss_test:0.01629, lr:5.59e-02, fs:0.75000 (r=0.759,p=0.742),  time:39.612, tt:2416.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01623, lr:5.59e-02, fs:0.75000 (r=0.759,p=0.742),  time:39.616, tt:2456.222\n",
      "Ep:62, loss:0.00001, loss_test:0.01621, lr:5.59e-02, fs:0.73988 (r=0.736,p=0.744),  time:39.616, tt:2495.809\n",
      "Ep:63, loss:0.00001, loss_test:0.01613, lr:5.59e-02, fs:0.74419 (r=0.736,p=0.753),  time:39.665, tt:2538.557\n",
      "Ep:64, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.74419 (r=0.736,p=0.753),  time:39.705, tt:2580.807\n",
      "Ep:65, loss:0.00001, loss_test:0.01603, lr:5.59e-02, fs:0.74854 (r=0.736,p=0.762),  time:39.695, tt:2619.854\n",
      "Ep:66, loss:0.00001, loss_test:0.01600, lr:5.59e-02, fs:0.74854 (r=0.736,p=0.762),  time:39.699, tt:2659.841\n",
      "Ep:67, loss:0.00001, loss_test:0.01594, lr:5.59e-02, fs:0.74854 (r=0.736,p=0.762),  time:39.686, tt:2698.669\n",
      "Ep:68, loss:0.00001, loss_test:0.01588, lr:5.59e-02, fs:0.74854 (r=0.736,p=0.762),  time:39.673, tt:2737.431\n",
      "Ep:69, loss:0.00001, loss_test:0.01583, lr:5.59e-02, fs:0.74118 (r=0.724,p=0.759),  time:39.690, tt:2778.326\n",
      "Ep:70, loss:0.00001, loss_test:0.01576, lr:5.54e-02, fs:0.74556 (r=0.724,p=0.768),  time:39.696, tt:2818.403\n",
      "Ep:71, loss:0.00001, loss_test:0.01577, lr:5.48e-02, fs:0.74556 (r=0.724,p=0.768),  time:39.695, tt:2858.047\n",
      "Ep:72, loss:0.00001, loss_test:0.01573, lr:5.43e-02, fs:0.74556 (r=0.724,p=0.768),  time:39.713, tt:2899.026\n",
      "Ep:73, loss:0.00001, loss_test:0.01561, lr:5.37e-02, fs:0.74556 (r=0.724,p=0.768),  time:39.695, tt:2937.409\n",
      "Ep:74, loss:0.00001, loss_test:0.01562, lr:5.32e-02, fs:0.74556 (r=0.724,p=0.768),  time:39.711, tt:2978.343\n",
      "Ep:75, loss:0.00001, loss_test:0.01562, lr:5.27e-02, fs:0.73810 (r=0.713,p=0.765),  time:39.708, tt:3017.795\n",
      "Ep:76, loss:0.00001, loss_test:0.01565, lr:5.21e-02, fs:0.73810 (r=0.713,p=0.765),  time:39.706, tt:3057.391\n",
      "Ep:77, loss:0.00001, loss_test:0.01559, lr:5.16e-02, fs:0.73810 (r=0.713,p=0.765),  time:39.704, tt:3096.895\n",
      "Ep:78, loss:0.00001, loss_test:0.01553, lr:5.11e-02, fs:0.74251 (r=0.713,p=0.775),  time:39.709, tt:3136.982\n",
      "Ep:79, loss:0.00001, loss_test:0.01558, lr:5.06e-02, fs:0.73810 (r=0.713,p=0.765),  time:39.691, tt:3175.319\n",
      "Ep:80, loss:0.00001, loss_test:0.01556, lr:5.01e-02, fs:0.74251 (r=0.713,p=0.775),  time:39.690, tt:3214.909\n",
      "Ep:81, loss:0.00001, loss_test:0.01557, lr:4.96e-02, fs:0.74251 (r=0.713,p=0.775),  time:39.667, tt:3252.672\n",
      "Ep:82, loss:0.00001, loss_test:0.01556, lr:4.91e-02, fs:0.74699 (r=0.713,p=0.785),  time:39.664, tt:3292.104\n",
      "Ep:83, loss:0.00001, loss_test:0.01548, lr:4.86e-02, fs:0.74699 (r=0.713,p=0.785),  time:39.652, tt:3330.780\n",
      "Ep:84, loss:0.00001, loss_test:0.01544, lr:4.81e-02, fs:0.74251 (r=0.713,p=0.775),  time:39.637, tt:3369.148\n",
      "Ep:85, loss:0.00001, loss_test:0.01548, lr:4.76e-02, fs:0.75610 (r=0.713,p=0.805),  time:39.624, tt:3407.658\n",
      "Ep:86, loss:0.00001, loss_test:0.01547, lr:4.71e-02, fs:0.75152 (r=0.713,p=0.795),  time:39.630, tt:3447.835\n",
      "Ep:87, loss:0.00001, loss_test:0.01544, lr:4.67e-02, fs:0.75152 (r=0.713,p=0.795),  time:39.634, tt:3487.802\n",
      "Ep:88, loss:0.00001, loss_test:0.01542, lr:4.62e-02, fs:0.75610 (r=0.713,p=0.805),  time:39.641, tt:3528.036\n",
      "Ep:89, loss:0.00001, loss_test:0.01541, lr:4.57e-02, fs:0.75610 (r=0.713,p=0.805),  time:39.658, tt:3569.251\n",
      "Ep:90, loss:0.00001, loss_test:0.01542, lr:4.53e-02, fs:0.75610 (r=0.713,p=0.805),  time:39.671, tt:3610.103\n",
      "Ep:91, loss:0.00001, loss_test:0.01538, lr:4.48e-02, fs:0.76074 (r=0.713,p=0.816),  time:39.678, tt:3650.398\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01542, lr:4.48e-02, fs:0.76074 (r=0.713,p=0.816),  time:39.681, tt:3690.289\n",
      "Ep:93, loss:0.00001, loss_test:0.01544, lr:4.48e-02, fs:0.76074 (r=0.713,p=0.816),  time:39.686, tt:3730.456\n",
      "Ep:94, loss:0.00001, loss_test:0.01539, lr:4.48e-02, fs:0.76074 (r=0.713,p=0.816),  time:39.673, tt:3768.940\n",
      "Ep:95, loss:0.00001, loss_test:0.01541, lr:4.48e-02, fs:0.76074 (r=0.713,p=0.816),  time:39.662, tt:3807.574\n",
      "Ep:96, loss:0.00001, loss_test:0.01542, lr:4.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:39.657, tt:3846.717\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01544, lr:4.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:39.680, tt:3888.602\n",
      "Ep:98, loss:0.00001, loss_test:0.01543, lr:4.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:39.666, tt:3926.920\n",
      "Ep:99, loss:0.00001, loss_test:0.01543, lr:4.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:39.657, tt:3965.691\n",
      "Ep:100, loss:0.00001, loss_test:0.01547, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.676, tt:4007.257\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01542, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.650, tt:4044.317\n",
      "Ep:102, loss:0.00001, loss_test:0.01549, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.658, tt:4084.756\n",
      "Ep:103, loss:0.00001, loss_test:0.01552, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.651, tt:4123.672\n",
      "Ep:104, loss:0.00001, loss_test:0.01545, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.655, tt:4163.735\n",
      "Ep:105, loss:0.00001, loss_test:0.01547, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.649, tt:4202.795\n",
      "Ep:106, loss:0.00001, loss_test:0.01542, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.654, tt:4242.995\n",
      "Ep:107, loss:0.00001, loss_test:0.01546, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.661, tt:4283.350\n",
      "Ep:108, loss:0.00001, loss_test:0.01542, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.667, tt:4323.681\n",
      "Ep:109, loss:0.00001, loss_test:0.01541, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.671, tt:4363.765\n",
      "Ep:110, loss:0.00001, loss_test:0.01546, lr:4.48e-02, fs:0.76543 (r=0.713,p=0.827),  time:39.663, tt:4402.564\n",
      "Ep:111, loss:0.00001, loss_test:0.01557, lr:4.48e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.653, tt:4441.083\n",
      "Ep:112, loss:0.00001, loss_test:0.01552, lr:4.44e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.662, tt:4481.822\n",
      "Ep:113, loss:0.00001, loss_test:0.01552, lr:4.39e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.666, tt:4521.892\n",
      "Ep:114, loss:0.00001, loss_test:0.01546, lr:4.35e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.662, tt:4561.118\n",
      "Ep:115, loss:0.00001, loss_test:0.01551, lr:4.31e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.660, tt:4600.562\n",
      "Ep:116, loss:0.00001, loss_test:0.01552, lr:4.26e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.659, tt:4640.056\n",
      "Ep:117, loss:0.00001, loss_test:0.01556, lr:4.22e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.660, tt:4679.884\n",
      "Ep:118, loss:0.00001, loss_test:0.01558, lr:4.18e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.635, tt:4716.511\n",
      "Ep:119, loss:0.00001, loss_test:0.01557, lr:4.14e-02, fs:0.77019 (r=0.713,p=0.838),  time:39.637, tt:4756.450\n",
      "Ep:120, loss:0.00001, loss_test:0.01559, lr:4.10e-02, fs:0.77500 (r=0.713,p=0.849),  time:39.642, tt:4796.673\n",
      "##########Best model found so far##########\n",
      "Ep:121, loss:0.00001, loss_test:0.01560, lr:4.10e-02, fs:0.77987 (r=0.713,p=0.861),  time:39.634, tt:4835.333\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.01560, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.622, tt:4873.511\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00001, loss_test:0.01561, lr:4.10e-02, fs:0.77987 (r=0.713,p=0.861),  time:39.604, tt:4910.927\n",
      "Ep:124, loss:0.00001, loss_test:0.01569, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.606, tt:4950.805\n",
      "Ep:125, loss:0.00001, loss_test:0.01569, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.592, tt:4988.552\n",
      "Ep:126, loss:0.00001, loss_test:0.01569, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.594, tt:5028.488\n",
      "Ep:127, loss:0.00001, loss_test:0.01570, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.577, tt:5065.915\n",
      "Ep:128, loss:0.00001, loss_test:0.01576, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.571, tt:5104.672\n",
      "Ep:129, loss:0.00001, loss_test:0.01583, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.585, tt:5146.064\n",
      "Ep:130, loss:0.00001, loss_test:0.01582, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.598, tt:5187.342\n",
      "Ep:131, loss:0.00001, loss_test:0.01583, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.588, tt:5225.590\n",
      "Ep:132, loss:0.00001, loss_test:0.01587, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.595, tt:5266.161\n",
      "Ep:133, loss:0.00001, loss_test:0.01589, lr:4.10e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.606, tt:5307.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.01589, lr:4.05e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.604, tt:5346.543\n",
      "Ep:135, loss:0.00001, loss_test:0.01592, lr:4.01e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.612, tt:5387.210\n",
      "Ep:136, loss:0.00000, loss_test:0.01598, lr:3.97e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.609, tt:5426.477\n",
      "Ep:137, loss:0.00000, loss_test:0.01601, lr:3.93e-02, fs:0.78481 (r=0.713,p=0.873),  time:39.608, tt:5465.885\n",
      "Ep:138, loss:0.00000, loss_test:0.01602, lr:3.89e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.622, tt:5507.523\n",
      "Ep:139, loss:0.00000, loss_test:0.01603, lr:3.86e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.611, tt:5545.587\n",
      "Ep:140, loss:0.00000, loss_test:0.01606, lr:3.82e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.612, tt:5585.334\n",
      "Ep:141, loss:0.00000, loss_test:0.01608, lr:3.78e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.613, tt:5625.002\n",
      "Ep:142, loss:0.00000, loss_test:0.01612, lr:3.74e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.613, tt:5664.715\n",
      "Ep:143, loss:0.00000, loss_test:0.01616, lr:3.70e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.611, tt:5704.025\n",
      "Ep:144, loss:0.00000, loss_test:0.01619, lr:3.67e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.615, tt:5744.220\n",
      "Ep:145, loss:0.00000, loss_test:0.01616, lr:3.63e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.633, tt:5786.425\n",
      "Ep:146, loss:0.00000, loss_test:0.01622, lr:3.59e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.638, tt:5826.793\n",
      "Ep:147, loss:0.00000, loss_test:0.01629, lr:3.56e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.673, tt:5871.553\n",
      "Ep:148, loss:0.00000, loss_test:0.01630, lr:3.52e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.673, tt:5911.315\n",
      "Ep:149, loss:0.00000, loss_test:0.01631, lr:3.49e-02, fs:0.77707 (r=0.701,p=0.871),  time:39.675, tt:5951.297\n",
      "Ep:150, loss:0.00000, loss_test:0.01635, lr:3.45e-02, fs:0.76923 (r=0.690,p=0.870),  time:39.657, tt:5988.229\n",
      "Ep:151, loss:0.00000, loss_test:0.01638, lr:3.42e-02, fs:0.76923 (r=0.690,p=0.870),  time:39.679, tt:6031.276\n",
      "Ep:152, loss:0.00000, loss_test:0.01645, lr:3.38e-02, fs:0.76129 (r=0.678,p=0.868),  time:39.670, tt:6069.564\n",
      "Ep:153, loss:0.00000, loss_test:0.01643, lr:3.35e-02, fs:0.76923 (r=0.690,p=0.870),  time:39.671, tt:6109.371\n",
      "Ep:154, loss:0.00000, loss_test:0.01644, lr:3.32e-02, fs:0.76129 (r=0.678,p=0.868),  time:39.688, tt:6151.604\n",
      "Ep:155, loss:0.00000, loss_test:0.01648, lr:3.28e-02, fs:0.76129 (r=0.678,p=0.868),  time:39.678, tt:6189.814\n",
      "Ep:156, loss:0.00000, loss_test:0.01654, lr:3.25e-02, fs:0.76129 (r=0.678,p=0.868),  time:39.677, tt:6229.217\n",
      "Ep:157, loss:0.00000, loss_test:0.01654, lr:3.22e-02, fs:0.75325 (r=0.667,p=0.866),  time:39.685, tt:6270.223\n",
      "Ep:158, loss:0.00000, loss_test:0.01657, lr:3.19e-02, fs:0.75325 (r=0.667,p=0.866),  time:39.691, tt:6310.885\n",
      "Ep:159, loss:0.00000, loss_test:0.01663, lr:3.15e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.705, tt:6352.817\n",
      "Ep:160, loss:0.00000, loss_test:0.01663, lr:3.12e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.699, tt:6391.521\n",
      "Ep:161, loss:0.00000, loss_test:0.01663, lr:3.09e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.703, tt:6431.829\n",
      "Ep:162, loss:0.00000, loss_test:0.01667, lr:3.06e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.715, tt:6473.492\n",
      "Ep:163, loss:0.00000, loss_test:0.01671, lr:3.03e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.723, tt:6514.508\n",
      "Ep:164, loss:0.00000, loss_test:0.01668, lr:3.00e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.732, tt:6555.795\n",
      "Ep:165, loss:0.00000, loss_test:0.01670, lr:2.97e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.745, tt:6597.666\n",
      "Ep:166, loss:0.00000, loss_test:0.01672, lr:2.94e-02, fs:0.75817 (r=0.667,p=0.879),  time:39.745, tt:6637.353\n",
      "Ep:167, loss:0.00000, loss_test:0.01677, lr:2.91e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.760, tt:6679.696\n",
      "Ep:168, loss:0.00000, loss_test:0.01679, lr:2.88e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.785, tt:6723.603\n",
      "Ep:169, loss:0.00000, loss_test:0.01680, lr:2.85e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.788, tt:6764.017\n",
      "Ep:170, loss:0.00000, loss_test:0.01685, lr:2.82e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.792, tt:6804.374\n",
      "Ep:171, loss:0.00000, loss_test:0.01688, lr:2.80e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.790, tt:6843.854\n",
      "Ep:172, loss:0.00000, loss_test:0.01688, lr:2.77e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.795, tt:6884.512\n",
      "Ep:173, loss:0.00000, loss_test:0.01687, lr:2.74e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.800, tt:6925.195\n",
      "Ep:174, loss:0.00000, loss_test:0.01693, lr:2.71e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.798, tt:6964.721\n",
      "Ep:175, loss:0.00000, loss_test:0.01696, lr:2.69e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.803, tt:7005.364\n",
      "Ep:176, loss:0.00000, loss_test:0.01696, lr:2.66e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.799, tt:7044.504\n",
      "Ep:177, loss:0.00000, loss_test:0.01700, lr:2.63e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.809, tt:7086.023\n",
      "Ep:178, loss:0.00000, loss_test:0.01701, lr:2.61e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.818, tt:7127.420\n",
      "Ep:179, loss:0.00000, loss_test:0.01700, lr:2.58e-02, fs:0.75000 (r=0.655,p=0.877),  time:39.826, tt:7168.619\n",
      "Ep:180, loss:0.00000, loss_test:0.01706, lr:2.55e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.836, tt:7210.341\n",
      "Ep:181, loss:0.00000, loss_test:0.01710, lr:2.53e-02, fs:0.74172 (r=0.644,p=0.875),  time:39.842, tt:7251.180\n",
      "Ep:182, loss:0.00000, loss_test:0.01711, lr:2.50e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.843, tt:7291.318\n",
      "Ep:183, loss:0.00000, loss_test:0.01711, lr:2.48e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.852, tt:7332.695\n",
      "Ep:184, loss:0.00000, loss_test:0.01712, lr:2.45e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.858, tt:7373.743\n",
      "Ep:185, loss:0.00000, loss_test:0.01714, lr:2.43e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.867, tt:7415.265\n",
      "Ep:186, loss:0.00000, loss_test:0.01717, lr:2.40e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.872, tt:7456.140\n",
      "Ep:187, loss:0.00000, loss_test:0.01721, lr:2.38e-02, fs:0.74667 (r=0.644,p=0.889),  time:39.871, tt:7495.790\n",
      "Ep:188, loss:0.00000, loss_test:0.01722, lr:2.36e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.868, tt:7535.060\n",
      "Ep:189, loss:0.00000, loss_test:0.01723, lr:2.33e-02, fs:0.75168 (r=0.644,p=0.903),  time:39.860, tt:7573.376\n",
      "Ep:190, loss:0.00000, loss_test:0.01723, lr:2.31e-02, fs:0.75168 (r=0.644,p=0.903),  time:39.858, tt:7612.883\n",
      "Ep:191, loss:0.00000, loss_test:0.01725, lr:2.29e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.845, tt:7650.175\n",
      "Ep:192, loss:0.00000, loss_test:0.01726, lr:2.26e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.852, tt:7691.482\n",
      "Ep:193, loss:0.00000, loss_test:0.01731, lr:2.24e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.852, tt:7731.221\n",
      "Ep:194, loss:0.00000, loss_test:0.01732, lr:2.22e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.854, tt:7771.480\n",
      "Ep:195, loss:0.00000, loss_test:0.01733, lr:2.20e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.846, tt:7809.731\n",
      "Ep:196, loss:0.00000, loss_test:0.01735, lr:2.17e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.847, tt:7849.770\n",
      "Ep:197, loss:0.00000, loss_test:0.01739, lr:2.15e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.847, tt:7889.779\n",
      "Ep:198, loss:0.00000, loss_test:0.01739, lr:2.13e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.852, tt:7930.593\n",
      "Ep:199, loss:0.00000, loss_test:0.01741, lr:2.11e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.860, tt:7971.972\n",
      "Ep:200, loss:0.00000, loss_test:0.01742, lr:2.09e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.864, tt:8012.731\n",
      "Ep:201, loss:0.00000, loss_test:0.01744, lr:2.07e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.861, tt:8052.008\n",
      "Ep:202, loss:0.00000, loss_test:0.01745, lr:2.05e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.854, tt:8090.428\n",
      "Ep:203, loss:0.00000, loss_test:0.01748, lr:2.03e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.851, tt:8129.667\n",
      "Ep:204, loss:0.00000, loss_test:0.01749, lr:2.01e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.858, tt:8170.906\n",
      "Ep:205, loss:0.00000, loss_test:0.01751, lr:1.99e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.849, tt:8208.836\n",
      "Ep:206, loss:0.00000, loss_test:0.01753, lr:1.97e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.852, tt:8249.424\n",
      "Ep:207, loss:0.00000, loss_test:0.01754, lr:1.95e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.846, tt:8287.874\n",
      "Ep:208, loss:0.00000, loss_test:0.01753, lr:1.93e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.840, tt:8326.480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.01756, lr:1.91e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.830, tt:8364.380\n",
      "Ep:210, loss:0.00000, loss_test:0.01760, lr:1.89e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.837, tt:8405.506\n",
      "Ep:211, loss:0.00000, loss_test:0.01759, lr:1.87e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.839, tt:8445.808\n",
      "Ep:212, loss:0.00000, loss_test:0.01763, lr:1.85e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.825, tt:8482.644\n",
      "Ep:213, loss:0.00000, loss_test:0.01765, lr:1.83e-02, fs:0.75676 (r=0.644,p=0.918),  time:39.801, tt:8517.388\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14117, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:34.269, tt:34.269\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13959, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.885, tt:65.771\n",
      "Ep:2, loss:0.00027, loss_test:0.13676, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:33.982, tt:101.946\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13195, lr:1.00e-02, fs:0.66929 (r=0.977,p=0.509),  time:34.136, tt:136.543\n",
      "Ep:4, loss:0.00026, loss_test:0.12517, lr:1.00e-02, fs:0.68619 (r=0.943,p=0.539),  time:35.318, tt:176.590\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11843, lr:1.00e-02, fs:0.68900 (r=0.828,p=0.590),  time:36.489, tt:218.933\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11850, lr:1.00e-02, fs:0.65241 (r=0.701,p=0.610),  time:37.386, tt:261.699\n",
      "Ep:7, loss:0.00022, loss_test:0.11771, lr:1.00e-02, fs:0.64894 (r=0.701,p=0.604),  time:37.750, tt:302.002\n",
      "Ep:8, loss:0.00022, loss_test:0.11600, lr:1.00e-02, fs:0.69524 (r=0.839,p=0.593),  time:38.116, tt:343.046\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11265, lr:1.00e-02, fs:0.71000 (r=0.816,p=0.628),  time:38.342, tt:383.418\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11011, lr:1.00e-02, fs:0.68852 (r=0.724,p=0.656),  time:38.630, tt:424.932\n",
      "Ep:11, loss:0.00020, loss_test:0.10977, lr:1.00e-02, fs:0.70652 (r=0.747,p=0.670),  time:38.850, tt:466.200\n",
      "Ep:12, loss:0.00019, loss_test:0.10883, lr:1.00e-02, fs:0.70526 (r=0.770,p=0.650),  time:39.038, tt:507.492\n",
      "Ep:13, loss:0.00018, loss_test:0.10575, lr:1.00e-02, fs:0.70718 (r=0.736,p=0.681),  time:39.108, tt:547.508\n",
      "Ep:14, loss:0.00018, loss_test:0.10450, lr:1.00e-02, fs:0.68605 (r=0.678,p=0.694),  time:39.378, tt:590.667\n",
      "Ep:15, loss:0.00017, loss_test:0.10343, lr:1.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:39.542, tt:632.678\n",
      "Ep:16, loss:0.00017, loss_test:0.10204, lr:1.00e-02, fs:0.70857 (r=0.713,p=0.705),  time:39.807, tt:676.726\n",
      "Ep:17, loss:0.00016, loss_test:0.10100, lr:1.00e-02, fs:0.70588 (r=0.690,p=0.723),  time:39.899, tt:718.184\n",
      "Ep:18, loss:0.00015, loss_test:0.10063, lr:1.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:39.975, tt:759.521\n",
      "Ep:19, loss:0.00015, loss_test:0.09994, lr:1.00e-02, fs:0.70930 (r=0.701,p=0.718),  time:40.010, tt:800.207\n",
      "Ep:20, loss:0.00014, loss_test:0.09927, lr:1.00e-02, fs:0.70930 (r=0.701,p=0.718),  time:40.092, tt:841.927\n",
      "Ep:21, loss:0.00014, loss_test:0.09923, lr:9.90e-03, fs:0.71591 (r=0.724,p=0.708),  time:40.146, tt:883.216\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.09862, lr:9.90e-03, fs:0.72093 (r=0.713,p=0.729),  time:40.242, tt:925.556\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09747, lr:9.90e-03, fs:0.72832 (r=0.724,p=0.733),  time:40.287, tt:966.895\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.09790, lr:9.90e-03, fs:0.73684 (r=0.724,p=0.750),  time:40.453, tt:1011.333\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.09762, lr:9.90e-03, fs:0.74251 (r=0.713,p=0.775),  time:40.519, tt:1053.503\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.09495, lr:9.90e-03, fs:0.75429 (r=0.759,p=0.750),  time:40.544, tt:1094.698\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.09702, lr:9.90e-03, fs:0.73939 (r=0.701,p=0.782),  time:40.646, tt:1138.081\n",
      "Ep:28, loss:0.00011, loss_test:0.09255, lr:9.90e-03, fs:0.79096 (r=0.805,p=0.778),  time:40.673, tt:1179.512\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.09311, lr:9.90e-03, fs:0.76923 (r=0.747,p=0.793),  time:40.831, tt:1224.916\n",
      "Ep:30, loss:0.00011, loss_test:0.09316, lr:9.90e-03, fs:0.77647 (r=0.759,p=0.795),  time:40.889, tt:1267.564\n",
      "Ep:31, loss:0.00010, loss_test:0.09042, lr:9.90e-03, fs:0.79070 (r=0.782,p=0.800),  time:40.975, tt:1311.202\n",
      "Ep:32, loss:0.00010, loss_test:0.08981, lr:9.90e-03, fs:0.77647 (r=0.759,p=0.795),  time:41.021, tt:1353.698\n",
      "Ep:33, loss:0.00010, loss_test:0.09041, lr:9.90e-03, fs:0.78049 (r=0.736,p=0.831),  time:41.048, tt:1395.643\n",
      "Ep:34, loss:0.00009, loss_test:0.08752, lr:9.90e-03, fs:0.78107 (r=0.759,p=0.805),  time:41.095, tt:1438.322\n",
      "Ep:35, loss:0.00009, loss_test:0.08724, lr:9.90e-03, fs:0.76923 (r=0.747,p=0.793),  time:41.168, tt:1482.039\n",
      "Ep:36, loss:0.00009, loss_test:0.08740, lr:9.90e-03, fs:0.78528 (r=0.736,p=0.842),  time:41.240, tt:1525.886\n",
      "Ep:37, loss:0.00009, loss_test:0.08656, lr:9.90e-03, fs:0.78049 (r=0.736,p=0.831),  time:41.300, tt:1569.397\n",
      "Ep:38, loss:0.00008, loss_test:0.08938, lr:9.90e-03, fs:0.79503 (r=0.736,p=0.865),  time:41.346, tt:1612.507\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.08516, lr:9.90e-03, fs:0.78363 (r=0.770,p=0.798),  time:41.381, tt:1655.238\n",
      "Ep:40, loss:0.00008, loss_test:0.08894, lr:9.90e-03, fs:0.76250 (r=0.701,p=0.836),  time:41.428, tt:1698.553\n",
      "Ep:41, loss:0.00007, loss_test:0.08572, lr:9.90e-03, fs:0.79518 (r=0.759,p=0.835),  time:41.468, tt:1741.671\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.08728, lr:9.90e-03, fs:0.76829 (r=0.724,p=0.818),  time:41.483, tt:1783.776\n",
      "Ep:43, loss:0.00007, loss_test:0.08705, lr:9.90e-03, fs:0.80723 (r=0.770,p=0.848),  time:41.522, tt:1826.955\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.08724, lr:9.90e-03, fs:0.77108 (r=0.736,p=0.810),  time:41.514, tt:1868.115\n",
      "Ep:45, loss:0.00007, loss_test:0.08666, lr:9.90e-03, fs:0.80723 (r=0.770,p=0.848),  time:41.550, tt:1911.308\n",
      "Ep:46, loss:0.00006, loss_test:0.08644, lr:9.90e-03, fs:0.79012 (r=0.736,p=0.853),  time:41.567, tt:1953.670\n",
      "Ep:47, loss:0.00006, loss_test:0.08516, lr:9.90e-03, fs:0.80000 (r=0.759,p=0.846),  time:41.599, tt:1996.734\n",
      "Ep:48, loss:0.00006, loss_test:0.08843, lr:9.90e-03, fs:0.77215 (r=0.701,p=0.859),  time:41.594, tt:2038.128\n",
      "Ep:49, loss:0.00006, loss_test:0.08458, lr:9.90e-03, fs:0.78528 (r=0.736,p=0.842),  time:41.595, tt:2079.756\n",
      "Ep:50, loss:0.00005, loss_test:0.08642, lr:9.90e-03, fs:0.76730 (r=0.701,p=0.847),  time:41.602, tt:2121.696\n",
      "Ep:51, loss:0.00005, loss_test:0.08513, lr:9.90e-03, fs:0.79755 (r=0.747,p=0.855),  time:41.626, tt:2164.535\n",
      "Ep:52, loss:0.00005, loss_test:0.08794, lr:9.90e-03, fs:0.77215 (r=0.701,p=0.859),  time:41.696, tt:2209.886\n",
      "Ep:53, loss:0.00005, loss_test:0.08329, lr:9.90e-03, fs:0.80240 (r=0.770,p=0.838),  time:41.722, tt:2252.982\n",
      "Ep:54, loss:0.00005, loss_test:0.08930, lr:9.90e-03, fs:0.76129 (r=0.678,p=0.868),  time:41.747, tt:2296.098\n",
      "Ep:55, loss:0.00005, loss_test:0.08293, lr:9.80e-03, fs:0.79268 (r=0.747,p=0.844),  time:41.756, tt:2338.325\n",
      "Ep:56, loss:0.00005, loss_test:0.08766, lr:9.70e-03, fs:0.81481 (r=0.759,p=0.880),  time:41.794, tt:2382.238\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00004, loss_test:0.08433, lr:9.70e-03, fs:0.78481 (r=0.713,p=0.873),  time:41.769, tt:2422.581\n",
      "Ep:58, loss:0.00004, loss_test:0.08497, lr:9.70e-03, fs:0.80745 (r=0.747,p=0.878),  time:41.783, tt:2465.181\n",
      "Ep:59, loss:0.00004, loss_test:0.08762, lr:9.70e-03, fs:0.77419 (r=0.690,p=0.882),  time:41.809, tt:2508.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00004, loss_test:0.08546, lr:9.70e-03, fs:0.78981 (r=0.713,p=0.886),  time:41.822, tt:2551.166\n",
      "Ep:61, loss:0.00004, loss_test:0.08629, lr:9.70e-03, fs:0.77707 (r=0.701,p=0.871),  time:41.846, tt:2594.445\n",
      "Ep:62, loss:0.00004, loss_test:0.08640, lr:9.70e-03, fs:0.78710 (r=0.701,p=0.897),  time:41.845, tt:2636.256\n",
      "Ep:63, loss:0.00004, loss_test:0.08495, lr:9.70e-03, fs:0.78481 (r=0.713,p=0.873),  time:41.849, tt:2678.352\n",
      "Ep:64, loss:0.00004, loss_test:0.08562, lr:9.70e-03, fs:0.77707 (r=0.701,p=0.871),  time:41.860, tt:2720.904\n",
      "Ep:65, loss:0.00003, loss_test:0.08578, lr:9.70e-03, fs:0.81250 (r=0.747,p=0.890),  time:41.867, tt:2763.222\n",
      "Ep:66, loss:0.00003, loss_test:0.08658, lr:9.70e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.895, tt:2806.981\n",
      "Ep:67, loss:0.00003, loss_test:0.08543, lr:9.70e-03, fs:0.78710 (r=0.701,p=0.897),  time:41.908, tt:2849.763\n",
      "Ep:68, loss:0.00003, loss_test:0.08656, lr:9.61e-03, fs:0.78710 (r=0.701,p=0.897),  time:41.905, tt:2891.451\n",
      "Ep:69, loss:0.00003, loss_test:0.08475, lr:9.51e-03, fs:0.78710 (r=0.701,p=0.897),  time:41.923, tt:2934.607\n",
      "Ep:70, loss:0.00003, loss_test:0.08556, lr:9.41e-03, fs:0.77922 (r=0.690,p=0.896),  time:41.947, tt:2978.234\n",
      "Ep:71, loss:0.00003, loss_test:0.08395, lr:9.32e-03, fs:0.78710 (r=0.701,p=0.897),  time:41.981, tt:3022.614\n",
      "Ep:72, loss:0.00003, loss_test:0.08877, lr:9.23e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.993, tt:3065.488\n",
      "Ep:73, loss:0.00003, loss_test:0.08402, lr:9.14e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.999, tt:3107.960\n",
      "Ep:74, loss:0.00002, loss_test:0.08749, lr:9.04e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.001, tt:3150.078\n",
      "Ep:75, loss:0.00002, loss_test:0.08531, lr:8.95e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.008, tt:3192.630\n",
      "Ep:76, loss:0.00002, loss_test:0.08679, lr:8.86e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.034, tt:3236.586\n",
      "Ep:77, loss:0.00002, loss_test:0.08771, lr:8.78e-03, fs:0.74667 (r=0.644,p=0.889),  time:42.029, tt:3278.230\n",
      "Ep:78, loss:0.00002, loss_test:0.09043, lr:8.69e-03, fs:0.79739 (r=0.701,p=0.924),  time:42.035, tt:3320.801\n",
      "Ep:79, loss:0.00002, loss_test:0.09037, lr:8.60e-03, fs:0.68085 (r=0.552,p=0.889),  time:42.032, tt:3362.579\n",
      "Ep:80, loss:0.00002, loss_test:0.08778, lr:8.51e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.077, tt:3408.210\n",
      "Ep:81, loss:0.00002, loss_test:0.09191, lr:8.43e-03, fs:0.69014 (r=0.563,p=0.891),  time:42.078, tt:3450.363\n",
      "Ep:82, loss:0.00002, loss_test:0.08790, lr:8.35e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.052, tt:3490.354\n",
      "Ep:83, loss:0.00002, loss_test:0.09269, lr:8.26e-03, fs:0.67626 (r=0.540,p=0.904),  time:42.050, tt:3532.192\n",
      "Ep:84, loss:0.00002, loss_test:0.08684, lr:8.18e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.050, tt:3574.228\n",
      "Ep:85, loss:0.00002, loss_test:0.09294, lr:8.10e-03, fs:0.71724 (r=0.598,p=0.897),  time:42.046, tt:3615.939\n",
      "Ep:86, loss:0.00002, loss_test:0.08655, lr:8.02e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.040, tt:3657.481\n",
      "Ep:87, loss:0.00002, loss_test:0.09066, lr:7.94e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.040, tt:3699.557\n",
      "Ep:88, loss:0.00002, loss_test:0.09019, lr:7.86e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.044, tt:3741.945\n",
      "Ep:89, loss:0.00002, loss_test:0.08810, lr:7.78e-03, fs:0.79221 (r=0.701,p=0.910),  time:42.017, tt:3781.532\n",
      "Ep:90, loss:0.00002, loss_test:0.09248, lr:7.70e-03, fs:0.78947 (r=0.690,p=0.923),  time:42.001, tt:3822.115\n",
      "Ep:91, loss:0.00002, loss_test:0.08883, lr:7.62e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.977, tt:3861.893\n",
      "Ep:92, loss:0.00001, loss_test:0.09044, lr:7.55e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.957, tt:3901.977\n",
      "Ep:93, loss:0.00001, loss_test:0.09205, lr:7.47e-03, fs:0.78146 (r=0.678,p=0.922),  time:41.947, tt:3943.031\n",
      "Ep:94, loss:0.00001, loss_test:0.08863, lr:7.40e-03, fs:0.76000 (r=0.655,p=0.905),  time:41.933, tt:3983.673\n",
      "Ep:95, loss:0.00001, loss_test:0.09190, lr:7.32e-03, fs:0.74324 (r=0.632,p=0.902),  time:41.919, tt:4024.251\n",
      "Ep:96, loss:0.00001, loss_test:0.09018, lr:7.25e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.913, tt:4065.584\n",
      "Ep:97, loss:0.00001, loss_test:0.09029, lr:7.18e-03, fs:0.76000 (r=0.655,p=0.905),  time:41.902, tt:4106.435\n",
      "Ep:98, loss:0.00001, loss_test:0.08968, lr:7.11e-03, fs:0.77632 (r=0.678,p=0.908),  time:41.887, tt:4146.850\n",
      "Ep:99, loss:0.00001, loss_test:0.08876, lr:7.03e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.896, tt:4189.573\n",
      "Ep:100, loss:0.00001, loss_test:0.08892, lr:6.96e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.886, tt:4230.500\n",
      "Ep:101, loss:0.00001, loss_test:0.09013, lr:6.89e-03, fs:0.76000 (r=0.655,p=0.905),  time:41.864, tt:4270.095\n",
      "Ep:102, loss:0.00001, loss_test:0.09038, lr:6.83e-03, fs:0.73469 (r=0.621,p=0.900),  time:41.837, tt:4309.250\n",
      "Ep:103, loss:0.00001, loss_test:0.09041, lr:6.76e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.809, tt:4348.156\n",
      "Ep:104, loss:0.00001, loss_test:0.08932, lr:6.69e-03, fs:0.79739 (r=0.701,p=0.924),  time:41.808, tt:4389.862\n",
      "Ep:105, loss:0.00001, loss_test:0.09118, lr:6.62e-03, fs:0.69065 (r=0.552,p=0.923),  time:41.814, tt:4432.322\n",
      "Ep:106, loss:0.00001, loss_test:0.09099, lr:6.56e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.802, tt:4472.799\n",
      "Ep:107, loss:0.00001, loss_test:0.09073, lr:6.49e-03, fs:0.68571 (r=0.552,p=0.906),  time:41.810, tt:4515.511\n",
      "Ep:108, loss:0.00001, loss_test:0.08963, lr:6.43e-03, fs:0.79221 (r=0.701,p=0.910),  time:41.800, tt:4556.150\n",
      "Ep:109, loss:0.00001, loss_test:0.09176, lr:6.36e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.778, tt:4595.615\n",
      "Ep:110, loss:0.00001, loss_test:0.08995, lr:6.30e-03, fs:0.78431 (r=0.690,p=0.909),  time:41.776, tt:4637.149\n",
      "Ep:111, loss:0.00001, loss_test:0.09054, lr:6.24e-03, fs:0.77333 (r=0.667,p=0.921),  time:41.767, tt:4677.869\n",
      "Ep:112, loss:0.00001, loss_test:0.09027, lr:6.17e-03, fs:0.73103 (r=0.609,p=0.914),  time:41.756, tt:4718.456\n",
      "Ep:113, loss:0.00001, loss_test:0.09177, lr:6.11e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.753, tt:4759.791\n",
      "Ep:114, loss:0.00001, loss_test:0.08965, lr:6.05e-03, fs:0.73973 (r=0.621,p=0.915),  time:41.756, tt:4801.926\n",
      "Ep:115, loss:0.00001, loss_test:0.09145, lr:5.99e-03, fs:0.80000 (r=0.690,p=0.952),  time:41.742, tt:4842.034\n",
      "Ep:116, loss:0.00001, loss_test:0.09126, lr:5.93e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.718, tt:4880.974\n",
      "Ep:117, loss:0.00001, loss_test:0.09079, lr:5.87e-03, fs:0.80795 (r=0.701,p=0.953),  time:41.716, tt:4922.441\n",
      "Ep:118, loss:0.00001, loss_test:0.09182, lr:5.81e-03, fs:0.76712 (r=0.644,p=0.949),  time:41.707, tt:4963.084\n",
      "Ep:119, loss:0.00001, loss_test:0.09272, lr:5.75e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.715, tt:5005.764\n",
      "Ep:120, loss:0.00001, loss_test:0.09222, lr:5.70e-03, fs:0.78378 (r=0.667,p=0.951),  time:41.700, tt:5045.750\n",
      "Ep:121, loss:0.00001, loss_test:0.09251, lr:5.64e-03, fs:0.69565 (r=0.552,p=0.941),  time:41.694, tt:5086.637\n",
      "Ep:122, loss:0.00001, loss_test:0.09354, lr:5.58e-03, fs:0.74126 (r=0.609,p=0.946),  time:41.692, tt:5128.131\n",
      "Ep:123, loss:0.00001, loss_test:0.09352, lr:5.53e-03, fs:0.69565 (r=0.552,p=0.941),  time:41.684, tt:5168.853\n",
      "Ep:124, loss:0.00001, loss_test:0.09376, lr:5.47e-03, fs:0.75000 (r=0.621,p=0.947),  time:41.688, tt:5210.939\n",
      "Ep:125, loss:0.00001, loss_test:0.09286, lr:5.42e-03, fs:0.75862 (r=0.632,p=0.948),  time:41.681, tt:5251.869\n",
      "Ep:126, loss:0.00001, loss_test:0.09513, lr:5.36e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.682, tt:5293.643\n",
      "Ep:127, loss:0.00001, loss_test:0.09549, lr:5.31e-03, fs:0.69565 (r=0.552,p=0.941),  time:41.682, tt:5335.270\n",
      "Ep:128, loss:0.00001, loss_test:0.09466, lr:5.26e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.692, tt:5378.308\n",
      "Ep:129, loss:0.00001, loss_test:0.09629, lr:5.20e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.690, tt:5419.675\n",
      "Ep:130, loss:0.00001, loss_test:0.09647, lr:5.15e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.694, tt:5461.849\n",
      "Ep:131, loss:0.00001, loss_test:0.09452, lr:5.10e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.693, tt:5503.505\n",
      "Ep:132, loss:0.00001, loss_test:0.09826, lr:5.05e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.694, tt:5545.318\n",
      "Ep:133, loss:0.00001, loss_test:0.09685, lr:5.00e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.698, tt:5587.533\n",
      "Ep:134, loss:0.00001, loss_test:0.09671, lr:4.95e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.687, tt:5627.755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.09890, lr:4.90e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.698, tt:5670.954\n",
      "Ep:136, loss:0.00001, loss_test:0.09720, lr:4.85e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.709, tt:5714.196\n",
      "Ep:137, loss:0.00001, loss_test:0.09729, lr:4.80e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.709, tt:5755.781\n",
      "Ep:138, loss:0.00001, loss_test:0.09921, lr:4.75e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.709, tt:5797.544\n",
      "Ep:139, loss:0.00001, loss_test:0.09767, lr:4.71e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.706, tt:5838.791\n",
      "Ep:140, loss:0.00001, loss_test:0.09764, lr:4.66e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.702, tt:5880.010\n",
      "Ep:141, loss:0.00001, loss_test:0.09836, lr:4.61e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.697, tt:5920.938\n",
      "Ep:142, loss:0.00001, loss_test:0.09858, lr:4.57e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.695, tt:5962.324\n",
      "Ep:143, loss:0.00001, loss_test:0.09768, lr:4.52e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.676, tt:6001.374\n",
      "Ep:144, loss:0.00001, loss_test:0.09784, lr:4.48e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.656, tt:6040.095\n",
      "Ep:145, loss:0.00001, loss_test:0.09821, lr:4.43e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.650, tt:6080.849\n",
      "Ep:146, loss:0.00001, loss_test:0.09733, lr:4.39e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.667, tt:6125.100\n",
      "Ep:147, loss:0.00000, loss_test:0.09885, lr:4.34e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.677, tt:6168.180\n",
      "Ep:148, loss:0.00000, loss_test:0.09757, lr:4.30e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.680, tt:6210.382\n",
      "Ep:149, loss:0.00000, loss_test:0.09708, lr:4.26e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.701, tt:6255.090\n",
      "Ep:150, loss:0.00000, loss_test:0.09887, lr:4.21e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.703, tt:6297.140\n",
      "Ep:151, loss:0.00000, loss_test:0.09741, lr:4.17e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.701, tt:6338.484\n",
      "Ep:152, loss:0.00000, loss_test:0.09698, lr:4.13e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.683, tt:6377.488\n",
      "Ep:153, loss:0.00000, loss_test:0.09684, lr:4.09e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.678, tt:6418.470\n",
      "Ep:154, loss:0.00000, loss_test:0.09872, lr:4.05e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.665, tt:6458.050\n",
      "Ep:155, loss:0.00000, loss_test:0.09745, lr:4.01e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.670, tt:6500.573\n",
      "Ep:156, loss:0.00000, loss_test:0.09826, lr:3.97e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.669, tt:6542.084\n",
      "Ep:157, loss:0.00000, loss_test:0.09916, lr:3.93e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.663, tt:6582.794\n",
      "Ep:158, loss:0.00000, loss_test:0.09730, lr:3.89e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.661, tt:6624.070\n",
      "Ep:159, loss:0.00000, loss_test:0.09707, lr:3.85e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.667, tt:6666.694\n",
      "Ep:160, loss:0.00000, loss_test:0.09836, lr:3.81e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.660, tt:6707.278\n",
      "Ep:161, loss:0.00000, loss_test:0.09704, lr:3.77e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.671, tt:6750.684\n",
      "Ep:162, loss:0.00000, loss_test:0.09708, lr:3.73e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.669, tt:6792.119\n",
      "Ep:163, loss:0.00000, loss_test:0.09697, lr:3.70e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.664, tt:6832.925\n",
      "Ep:164, loss:0.00000, loss_test:0.09752, lr:3.66e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.672, tt:6875.805\n",
      "Ep:165, loss:0.00000, loss_test:0.09659, lr:3.62e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.673, tt:6917.703\n",
      "Ep:166, loss:0.00000, loss_test:0.09755, lr:3.59e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.679, tt:6960.399\n",
      "Ep:167, loss:0.00000, loss_test:0.09828, lr:3.55e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.691, tt:7004.046\n",
      "Ep:168, loss:0.00000, loss_test:0.09702, lr:3.52e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.684, tt:7044.673\n",
      "Ep:169, loss:0.00000, loss_test:0.09806, lr:3.48e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.701, tt:7089.217\n",
      "Ep:170, loss:0.00000, loss_test:0.09842, lr:3.45e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.703, tt:7131.180\n",
      "Ep:171, loss:0.00000, loss_test:0.09709, lr:3.41e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.693, tt:7171.215\n",
      "Ep:172, loss:0.00000, loss_test:0.09735, lr:3.38e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.685, tt:7211.584\n",
      "Ep:173, loss:0.00000, loss_test:0.09789, lr:3.34e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.682, tt:7252.661\n",
      "Ep:174, loss:0.00000, loss_test:0.09726, lr:3.31e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.679, tt:7293.875\n",
      "Ep:175, loss:0.00000, loss_test:0.09760, lr:3.28e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.689, tt:7337.212\n",
      "Ep:176, loss:0.00000, loss_test:0.09722, lr:3.24e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.687, tt:7378.656\n",
      "Ep:177, loss:0.00000, loss_test:0.09716, lr:3.21e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.701, tt:7422.695\n",
      "Ep:178, loss:0.00000, loss_test:0.09775, lr:3.18e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.697, tt:7463.809\n",
      "Ep:179, loss:0.00000, loss_test:0.09697, lr:3.15e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.699, tt:7505.878\n",
      "Ep:180, loss:0.00000, loss_test:0.09750, lr:3.12e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.695, tt:7546.824\n",
      "Ep:181, loss:0.00000, loss_test:0.09767, lr:3.09e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.691, tt:7587.823\n",
      "Ep:182, loss:0.00000, loss_test:0.09620, lr:3.05e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.700, tt:7631.042\n",
      "Ep:183, loss:0.00000, loss_test:0.09728, lr:3.02e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.704, tt:7673.624\n",
      "Ep:184, loss:0.00000, loss_test:0.09739, lr:2.99e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.698, tt:7714.048\n",
      "Ep:185, loss:0.00000, loss_test:0.09701, lr:2.96e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.701, tt:7756.344\n",
      "Ep:186, loss:0.00000, loss_test:0.09690, lr:2.93e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.693, tt:7796.547\n",
      "Ep:187, loss:0.00000, loss_test:0.09667, lr:2.90e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.691, tt:7837.843\n",
      "Ep:188, loss:0.00000, loss_test:0.09661, lr:2.88e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.689, tt:7879.246\n",
      "Ep:189, loss:0.00000, loss_test:0.09703, lr:2.85e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.683, tt:7919.773\n",
      "Ep:190, loss:0.00000, loss_test:0.09698, lr:2.82e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.694, tt:7963.511\n",
      "Ep:191, loss:0.00000, loss_test:0.09738, lr:2.79e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.688, tt:8004.102\n",
      "Ep:192, loss:0.00000, loss_test:0.09655, lr:2.76e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.679, tt:8044.108\n",
      "Ep:193, loss:0.00000, loss_test:0.09675, lr:2.73e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.683, tt:8086.589\n",
      "Ep:194, loss:0.00000, loss_test:0.09703, lr:2.71e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.679, tt:8127.391\n",
      "Ep:195, loss:0.00000, loss_test:0.09677, lr:2.68e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.685, tt:8170.313\n",
      "Ep:196, loss:0.00000, loss_test:0.09633, lr:2.65e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.689, tt:8212.708\n",
      "Ep:197, loss:0.00000, loss_test:0.09724, lr:2.63e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.682, tt:8253.073\n",
      "Ep:198, loss:0.00000, loss_test:0.09682, lr:2.60e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.678, tt:8293.996\n",
      "Ep:199, loss:0.00000, loss_test:0.09621, lr:2.57e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.677, tt:8335.495\n",
      "Ep:200, loss:0.00000, loss_test:0.09677, lr:2.55e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.679, tt:8377.447\n",
      "Ep:201, loss:0.00000, loss_test:0.09700, lr:2.52e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.686, tt:8420.565\n",
      "Ep:202, loss:0.00000, loss_test:0.09629, lr:2.50e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.693, tt:8463.610\n",
      "Ep:203, loss:0.00000, loss_test:0.09694, lr:2.47e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.695, tt:8505.764\n",
      "Ep:204, loss:0.00000, loss_test:0.09730, lr:2.45e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.702, tt:8548.963\n",
      "Ep:205, loss:0.00000, loss_test:0.09652, lr:2.42e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.696, tt:8589.457\n",
      "Ep:206, loss:0.00000, loss_test:0.09645, lr:2.40e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.702, tt:8632.256\n",
      "Ep:207, loss:0.00000, loss_test:0.09687, lr:2.38e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.702, tt:8674.043\n",
      "Ep:208, loss:0.00000, loss_test:0.09650, lr:2.35e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.709, tt:8717.162\n",
      "Ep:209, loss:0.00000, loss_test:0.09653, lr:2.33e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.715, tt:8760.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09654, lr:2.31e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.730, tt:8805.103\n",
      "Ep:211, loss:0.00000, loss_test:0.09664, lr:2.28e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.736, tt:8848.052\n",
      "Ep:212, loss:0.00000, loss_test:0.09630, lr:2.26e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.742, tt:8891.052\n",
      "Ep:213, loss:0.00000, loss_test:0.09619, lr:2.24e-03, fs:0.67647 (r=0.529,p=0.939),  time:41.738, tt:8931.986\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02087, lr:6.00e-02, fs:0.60987 (r=0.782,p=0.500),  time:31.897, tt:31.897\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02207, lr:6.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:32.046, tt:64.092\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02270, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.668, tt:101.005\n",
      "Ep:3, loss:0.00004, loss_test:0.02177, lr:6.00e-02, fs:0.67442 (r=1.000,p=0.509),  time:33.910, tt:135.640\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02039, lr:6.00e-02, fs:0.67200 (r=0.966,p=0.515),  time:34.796, tt:173.980\n",
      "Ep:5, loss:0.00004, loss_test:0.01993, lr:6.00e-02, fs:0.64574 (r=0.828,p=0.529),  time:36.009, tt:216.055\n",
      "Ep:6, loss:0.00003, loss_test:0.02070, lr:6.00e-02, fs:0.63959 (r=0.724,p=0.573),  time:36.879, tt:258.154\n",
      "Ep:7, loss:0.00003, loss_test:0.02087, lr:6.00e-02, fs:0.61376 (r=0.667,p=0.569),  time:37.656, tt:301.248\n",
      "Ep:8, loss:0.00003, loss_test:0.02034, lr:6.00e-02, fs:0.63366 (r=0.736,p=0.557),  time:37.971, tt:341.735\n",
      "Ep:9, loss:0.00003, loss_test:0.01990, lr:6.00e-02, fs:0.64545 (r=0.816,p=0.534),  time:38.232, tt:382.322\n",
      "Ep:10, loss:0.00003, loss_test:0.01976, lr:6.00e-02, fs:0.65471 (r=0.839,p=0.537),  time:38.412, tt:422.533\n",
      "Ep:11, loss:0.00003, loss_test:0.01980, lr:6.00e-02, fs:0.65438 (r=0.816,p=0.546),  time:38.663, tt:463.960\n",
      "Ep:12, loss:0.00003, loss_test:0.02013, lr:6.00e-02, fs:0.66010 (r=0.770,p=0.578),  time:38.733, tt:503.523\n",
      "Ep:13, loss:0.00003, loss_test:0.02064, lr:6.00e-02, fs:0.66667 (r=0.736,p=0.610),  time:38.930, tt:545.022\n",
      "Ep:14, loss:0.00003, loss_test:0.02094, lr:6.00e-02, fs:0.67016 (r=0.736,p=0.615),  time:39.259, tt:588.892\n",
      "Ep:15, loss:0.00003, loss_test:0.02074, lr:5.94e-02, fs:0.67708 (r=0.747,p=0.619),  time:39.739, tt:635.823\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.02046, lr:5.94e-02, fs:0.70408 (r=0.793,p=0.633),  time:39.711, tt:675.087\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.02038, lr:5.94e-02, fs:0.70051 (r=0.793,p=0.627),  time:39.788, tt:716.175\n",
      "Ep:18, loss:0.00002, loss_test:0.02056, lr:5.94e-02, fs:0.70408 (r=0.793,p=0.633),  time:39.816, tt:756.497\n",
      "Ep:19, loss:0.00002, loss_test:0.02106, lr:5.94e-02, fs:0.70833 (r=0.782,p=0.648),  time:39.797, tt:795.933\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.02152, lr:5.94e-02, fs:0.70899 (r=0.770,p=0.657),  time:39.835, tt:836.542\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.02155, lr:5.94e-02, fs:0.71658 (r=0.770,p=0.670),  time:39.839, tt:876.461\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.02132, lr:5.94e-02, fs:0.71277 (r=0.770,p=0.663),  time:39.837, tt:916.243\n",
      "Ep:23, loss:0.00002, loss_test:0.02112, lr:5.94e-02, fs:0.71277 (r=0.770,p=0.663),  time:39.939, tt:958.526\n",
      "Ep:24, loss:0.00002, loss_test:0.02123, lr:5.94e-02, fs:0.72131 (r=0.759,p=0.688),  time:39.881, tt:997.022\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.02140, lr:5.94e-02, fs:0.72222 (r=0.747,p=0.699),  time:39.910, tt:1037.663\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.02148, lr:5.94e-02, fs:0.72626 (r=0.747,p=0.707),  time:39.951, tt:1078.689\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.02144, lr:5.94e-02, fs:0.72626 (r=0.747,p=0.707),  time:40.018, tt:1120.512\n",
      "Ep:28, loss:0.00002, loss_test:0.02138, lr:5.94e-02, fs:0.73743 (r=0.759,p=0.717),  time:40.083, tt:1162.396\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.02143, lr:5.94e-02, fs:0.73743 (r=0.759,p=0.717),  time:40.073, tt:1202.200\n",
      "Ep:30, loss:0.00002, loss_test:0.02154, lr:5.94e-02, fs:0.74157 (r=0.759,p=0.725),  time:40.057, tt:1241.772\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.02152, lr:5.94e-02, fs:0.73446 (r=0.747,p=0.722),  time:40.084, tt:1282.678\n",
      "Ep:32, loss:0.00002, loss_test:0.02147, lr:5.94e-02, fs:0.73864 (r=0.747,p=0.730),  time:40.076, tt:1322.497\n",
      "Ep:33, loss:0.00002, loss_test:0.02143, lr:5.94e-02, fs:0.74286 (r=0.747,p=0.739),  time:40.113, tt:1363.836\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.02140, lr:5.94e-02, fs:0.74286 (r=0.747,p=0.739),  time:40.199, tt:1406.952\n",
      "Ep:35, loss:0.00002, loss_test:0.02136, lr:5.94e-02, fs:0.73988 (r=0.736,p=0.744),  time:40.199, tt:1447.156\n",
      "Ep:36, loss:0.00002, loss_test:0.02145, lr:5.94e-02, fs:0.73988 (r=0.736,p=0.744),  time:40.196, tt:1487.256\n",
      "Ep:37, loss:0.00002, loss_test:0.02146, lr:5.94e-02, fs:0.74854 (r=0.736,p=0.762),  time:40.248, tt:1529.439\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.02147, lr:5.94e-02, fs:0.74854 (r=0.736,p=0.762),  time:40.264, tt:1570.282\n",
      "Ep:39, loss:0.00002, loss_test:0.02147, lr:5.94e-02, fs:0.75294 (r=0.736,p=0.771),  time:40.306, tt:1612.249\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.02140, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.305, tt:1652.489\n",
      "Ep:41, loss:0.00001, loss_test:0.02132, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.366, tt:1695.367\n",
      "Ep:42, loss:0.00001, loss_test:0.02133, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.389, tt:1736.737\n",
      "Ep:43, loss:0.00001, loss_test:0.02146, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.428, tt:1778.836\n",
      "Ep:44, loss:0.00001, loss_test:0.02149, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.435, tt:1819.555\n",
      "Ep:45, loss:0.00001, loss_test:0.02137, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.471, tt:1861.674\n",
      "Ep:46, loss:0.00001, loss_test:0.02145, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.488, tt:1902.941\n",
      "Ep:47, loss:0.00001, loss_test:0.02154, lr:5.94e-02, fs:0.74556 (r=0.724,p=0.768),  time:40.524, tt:1945.168\n",
      "Ep:48, loss:0.00001, loss_test:0.02147, lr:5.94e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.536, tt:1986.288\n",
      "Ep:49, loss:0.00001, loss_test:0.02150, lr:5.94e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.549, tt:2027.451\n",
      "Ep:50, loss:0.00001, loss_test:0.02147, lr:5.94e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.576, tt:2069.374\n",
      "Ep:51, loss:0.00001, loss_test:0.02144, lr:5.88e-02, fs:0.75000 (r=0.724,p=0.778),  time:40.580, tt:2110.166\n",
      "Ep:52, loss:0.00001, loss_test:0.02160, lr:5.82e-02, fs:0.75904 (r=0.724,p=0.797),  time:40.607, tt:2152.146\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.02175, lr:5.82e-02, fs:0.76364 (r=0.724,p=0.808),  time:40.605, tt:2192.661\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.02168, lr:5.82e-02, fs:0.76364 (r=0.724,p=0.808),  time:40.635, tt:2234.910\n",
      "Ep:55, loss:0.00001, loss_test:0.02165, lr:5.82e-02, fs:0.76364 (r=0.724,p=0.808),  time:40.645, tt:2276.130\n",
      "Ep:56, loss:0.00001, loss_test:0.02175, lr:5.82e-02, fs:0.76364 (r=0.724,p=0.808),  time:40.624, tt:2315.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.02198, lr:5.82e-02, fs:0.76829 (r=0.724,p=0.818),  time:40.645, tt:2357.436\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.02197, lr:5.82e-02, fs:0.76074 (r=0.713,p=0.816),  time:40.667, tt:2399.329\n",
      "Ep:59, loss:0.00001, loss_test:0.02203, lr:5.82e-02, fs:0.76074 (r=0.713,p=0.816),  time:40.692, tt:2441.502\n",
      "Ep:60, loss:0.00001, loss_test:0.02215, lr:5.82e-02, fs:0.76829 (r=0.724,p=0.818),  time:40.696, tt:2482.457\n",
      "Ep:61, loss:0.00001, loss_test:0.02213, lr:5.82e-02, fs:0.76829 (r=0.724,p=0.818),  time:40.683, tt:2522.316\n",
      "Ep:62, loss:0.00001, loss_test:0.02237, lr:5.82e-02, fs:0.76074 (r=0.713,p=0.816),  time:40.695, tt:2563.807\n",
      "Ep:63, loss:0.00001, loss_test:0.02255, lr:5.82e-02, fs:0.76074 (r=0.713,p=0.816),  time:40.697, tt:2604.594\n",
      "Ep:64, loss:0.00001, loss_test:0.02257, lr:5.82e-02, fs:0.75309 (r=0.701,p=0.813),  time:40.706, tt:2645.917\n",
      "Ep:65, loss:0.00001, loss_test:0.02268, lr:5.82e-02, fs:0.75776 (r=0.701,p=0.824),  time:40.724, tt:2687.764\n",
      "Ep:66, loss:0.00001, loss_test:0.02274, lr:5.82e-02, fs:0.77019 (r=0.713,p=0.838),  time:40.776, tt:2731.967\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.02289, lr:5.82e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.789, tt:2773.666\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.02299, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.803, tt:2815.393\n",
      "Ep:69, loss:0.00001, loss_test:0.02298, lr:5.82e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.823, tt:2857.578\n",
      "Ep:70, loss:0.00001, loss_test:0.02316, lr:5.82e-02, fs:0.77500 (r=0.713,p=0.849),  time:40.817, tt:2897.973\n",
      "Ep:71, loss:0.00001, loss_test:0.02316, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.824, tt:2939.320\n",
      "Ep:72, loss:0.00001, loss_test:0.02335, lr:5.82e-02, fs:0.77215 (r=0.701,p=0.859),  time:40.820, tt:2979.866\n",
      "Ep:73, loss:0.00001, loss_test:0.02338, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.823, tt:3020.906\n",
      "Ep:74, loss:0.00001, loss_test:0.02364, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.831, tt:3062.301\n",
      "Ep:75, loss:0.00001, loss_test:0.02356, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.847, tt:3104.393\n",
      "Ep:76, loss:0.00001, loss_test:0.02384, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.866, tt:3146.687\n",
      "Ep:77, loss:0.00001, loss_test:0.02395, lr:5.82e-02, fs:0.76730 (r=0.701,p=0.847),  time:40.890, tt:3189.442\n",
      "Ep:78, loss:0.00001, loss_test:0.02413, lr:5.82e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.918, tt:3232.537\n",
      "Ep:79, loss:0.00001, loss_test:0.02419, lr:5.76e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.948, tt:3275.836\n",
      "Ep:80, loss:0.00001, loss_test:0.02435, lr:5.71e-02, fs:0.75641 (r=0.678,p=0.855),  time:40.964, tt:3318.059\n",
      "Ep:81, loss:0.00001, loss_test:0.02441, lr:5.65e-02, fs:0.75325 (r=0.667,p=0.866),  time:40.960, tt:3358.723\n",
      "Ep:82, loss:0.00001, loss_test:0.02465, lr:5.59e-02, fs:0.74026 (r=0.655,p=0.851),  time:40.935, tt:3397.622\n",
      "Ep:83, loss:0.00001, loss_test:0.02491, lr:5.54e-02, fs:0.73684 (r=0.644,p=0.862),  time:40.927, tt:3437.869\n",
      "Ep:84, loss:0.00001, loss_test:0.02488, lr:5.48e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.924, tt:3478.525\n",
      "Ep:85, loss:0.00001, loss_test:0.02498, lr:5.43e-02, fs:0.74510 (r=0.655,p=0.864),  time:40.932, tt:3520.132\n",
      "Ep:86, loss:0.00001, loss_test:0.02537, lr:5.37e-02, fs:0.74667 (r=0.644,p=0.889),  time:40.949, tt:3562.543\n",
      "Ep:87, loss:0.00001, loss_test:0.02534, lr:5.32e-02, fs:0.74172 (r=0.644,p=0.875),  time:40.950, tt:3603.614\n",
      "Ep:88, loss:0.00001, loss_test:0.02548, lr:5.27e-02, fs:0.73826 (r=0.632,p=0.887),  time:40.934, tt:3643.149\n",
      "Ep:89, loss:0.00001, loss_test:0.02568, lr:5.21e-02, fs:0.72603 (r=0.609,p=0.898),  time:40.941, tt:3684.699\n",
      "Ep:90, loss:0.00001, loss_test:0.02563, lr:5.16e-02, fs:0.72109 (r=0.609,p=0.883),  time:40.949, tt:3726.318\n",
      "Ep:91, loss:0.00001, loss_test:0.02586, lr:5.11e-02, fs:0.72603 (r=0.609,p=0.898),  time:40.978, tt:3770.000\n",
      "Ep:92, loss:0.00001, loss_test:0.02602, lr:5.06e-02, fs:0.70833 (r=0.586,p=0.895),  time:40.999, tt:3812.947\n",
      "Ep:93, loss:0.00001, loss_test:0.02614, lr:5.01e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.008, tt:3854.779\n",
      "Ep:94, loss:0.00001, loss_test:0.02626, lr:4.96e-02, fs:0.70833 (r=0.586,p=0.895),  time:41.001, tt:3895.083\n",
      "Ep:95, loss:0.00001, loss_test:0.02639, lr:4.91e-02, fs:0.69930 (r=0.575,p=0.893),  time:41.014, tt:3937.308\n",
      "Ep:96, loss:0.00001, loss_test:0.02655, lr:4.86e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.040, tt:3980.876\n",
      "Ep:97, loss:0.00001, loss_test:0.02683, lr:4.81e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.060, tt:4023.891\n",
      "Ep:98, loss:0.00001, loss_test:0.02674, lr:4.76e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.070, tt:4065.886\n",
      "Ep:99, loss:0.00001, loss_test:0.02696, lr:4.71e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.057, tt:4105.738\n",
      "Ep:100, loss:0.00001, loss_test:0.02704, lr:4.67e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.066, tt:4147.652\n",
      "Ep:101, loss:0.00000, loss_test:0.02714, lr:4.62e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.117, tt:4193.931\n",
      "Ep:102, loss:0.00000, loss_test:0.02731, lr:4.57e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.148, tt:4238.269\n",
      "Ep:103, loss:0.00000, loss_test:0.02747, lr:4.53e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.184, tt:4283.118\n",
      "Ep:104, loss:0.00000, loss_test:0.02767, lr:4.48e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.213, tt:4327.382\n",
      "Ep:105, loss:0.00000, loss_test:0.02752, lr:4.44e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.244, tt:4371.912\n",
      "Ep:106, loss:0.00000, loss_test:0.02772, lr:4.39e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.264, tt:4415.271\n",
      "Ep:107, loss:0.00000, loss_test:0.02808, lr:4.35e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.274, tt:4457.561\n",
      "Ep:108, loss:0.00000, loss_test:0.02798, lr:4.31e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.285, tt:4500.071\n",
      "Ep:109, loss:0.00000, loss_test:0.02826, lr:4.26e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.302, tt:4543.270\n",
      "Ep:110, loss:0.00000, loss_test:0.02850, lr:4.22e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.316, tt:4586.120\n",
      "Ep:111, loss:0.00000, loss_test:0.02831, lr:4.18e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.328, tt:4628.788\n",
      "Ep:112, loss:0.00000, loss_test:0.02856, lr:4.14e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.346, tt:4672.071\n",
      "Ep:113, loss:0.00000, loss_test:0.02874, lr:4.10e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.349, tt:4713.763\n",
      "Ep:114, loss:0.00000, loss_test:0.02871, lr:4.05e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.335, tt:4753.541\n",
      "Ep:115, loss:0.00000, loss_test:0.02879, lr:4.01e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.344, tt:4795.892\n",
      "Ep:116, loss:0.00000, loss_test:0.02896, lr:3.97e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.342, tt:4836.978\n",
      "Ep:117, loss:0.00000, loss_test:0.02900, lr:3.93e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.347, tt:4878.911\n",
      "Ep:118, loss:0.00000, loss_test:0.02913, lr:3.89e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.344, tt:4919.970\n",
      "Ep:119, loss:0.00000, loss_test:0.02938, lr:3.86e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.337, tt:4960.456\n",
      "Ep:120, loss:0.00000, loss_test:0.02927, lr:3.82e-02, fs:0.68571 (r=0.552,p=0.906),  time:41.353, tt:5003.724\n",
      "Ep:121, loss:0.00000, loss_test:0.02950, lr:3.78e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.369, tt:5046.977\n",
      "Ep:122, loss:0.00000, loss_test:0.02961, lr:3.74e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.372, tt:5088.736\n",
      "Ep:123, loss:0.00000, loss_test:0.02960, lr:3.70e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.362, tt:5128.907\n",
      "Ep:124, loss:0.00000, loss_test:0.02997, lr:3.67e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.363, tt:5170.362\n",
      "Ep:125, loss:0.00000, loss_test:0.02985, lr:3.63e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.383, tt:5214.281\n",
      "Ep:126, loss:0.00000, loss_test:0.02993, lr:3.59e-02, fs:0.67626 (r=0.540,p=0.904),  time:41.364, tt:5253.189\n",
      "Ep:127, loss:0.00000, loss_test:0.03014, lr:3.56e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.367, tt:5294.979\n",
      "Ep:128, loss:0.00000, loss_test:0.03019, lr:3.52e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.358, tt:5335.238\n",
      "Ep:129, loss:0.00000, loss_test:0.03025, lr:3.49e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.355, tt:5376.177\n",
      "Ep:130, loss:0.00000, loss_test:0.03048, lr:3.45e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.355, tt:5417.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.03040, lr:3.42e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.343, tt:5457.291\n",
      "Ep:132, loss:0.00000, loss_test:0.03059, lr:3.38e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.349, tt:5499.421\n",
      "Ep:133, loss:0.00000, loss_test:0.03067, lr:3.35e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.348, tt:5540.648\n",
      "Ep:134, loss:0.00000, loss_test:0.03074, lr:3.32e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.343, tt:5581.260\n",
      "Ep:135, loss:0.00000, loss_test:0.03073, lr:3.28e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.358, tt:5624.710\n",
      "Ep:136, loss:0.00000, loss_test:0.03091, lr:3.25e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.382, tt:5669.284\n",
      "Ep:137, loss:0.00000, loss_test:0.03086, lr:3.22e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.391, tt:5711.998\n",
      "Ep:138, loss:0.00000, loss_test:0.03108, lr:3.19e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.394, tt:5753.801\n",
      "Ep:139, loss:0.00000, loss_test:0.03110, lr:3.15e-02, fs:0.66667 (r=0.529,p=0.902),  time:41.389, tt:5794.466\n",
      "Ep:140, loss:0.00000, loss_test:0.03107, lr:3.12e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.392, tt:5836.217\n",
      "Ep:141, loss:0.00000, loss_test:0.03132, lr:3.09e-02, fs:0.65693 (r=0.517,p=0.900),  time:41.389, tt:5877.212\n",
      "Ep:142, loss:0.00000, loss_test:0.03128, lr:3.06e-02, fs:0.64706 (r=0.506,p=0.898),  time:41.395, tt:5919.503\n",
      "Ep:143, loss:0.00000, loss_test:0.03139, lr:3.03e-02, fs:0.64706 (r=0.506,p=0.898),  time:41.397, tt:5961.103\n",
      "Ep:144, loss:0.00000, loss_test:0.03162, lr:3.00e-02, fs:0.63704 (r=0.494,p=0.896),  time:41.415, tt:6005.121\n",
      "Ep:145, loss:0.00000, loss_test:0.03150, lr:2.97e-02, fs:0.64706 (r=0.506,p=0.898),  time:41.424, tt:6047.862\n",
      "Ep:146, loss:0.00000, loss_test:0.03158, lr:2.94e-02, fs:0.63704 (r=0.494,p=0.896),  time:41.432, tt:6090.562\n",
      "Ep:147, loss:0.00000, loss_test:0.03178, lr:2.91e-02, fs:0.62687 (r=0.483,p=0.894),  time:41.426, tt:6131.108\n",
      "Ep:148, loss:0.00000, loss_test:0.03172, lr:2.88e-02, fs:0.64706 (r=0.506,p=0.898),  time:41.431, tt:6173.145\n",
      "Ep:149, loss:0.00000, loss_test:0.03188, lr:2.85e-02, fs:0.62687 (r=0.483,p=0.894),  time:41.421, tt:6213.092\n",
      "Ep:150, loss:0.00000, loss_test:0.03188, lr:2.82e-02, fs:0.62687 (r=0.483,p=0.894),  time:41.420, tt:6254.391\n",
      "Ep:151, loss:0.00000, loss_test:0.03188, lr:2.80e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.420, tt:6295.894\n",
      "Ep:152, loss:0.00000, loss_test:0.03207, lr:2.77e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.415, tt:6336.444\n",
      "Ep:153, loss:0.00000, loss_test:0.03204, lr:2.74e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.405, tt:6376.426\n",
      "Ep:154, loss:0.00000, loss_test:0.03213, lr:2.71e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.398, tt:6416.654\n",
      "Ep:155, loss:0.00000, loss_test:0.03220, lr:2.69e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.400, tt:6458.397\n",
      "Ep:156, loss:0.00000, loss_test:0.03215, lr:2.66e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.410, tt:6501.430\n",
      "Ep:157, loss:0.00000, loss_test:0.03233, lr:2.63e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.419, tt:6544.260\n",
      "Ep:158, loss:0.00000, loss_test:0.03240, lr:2.61e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.423, tt:6586.235\n",
      "Ep:159, loss:0.00000, loss_test:0.03235, lr:2.58e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.442, tt:6630.666\n",
      "Ep:160, loss:0.00000, loss_test:0.03249, lr:2.55e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.459, tt:6674.842\n",
      "Ep:161, loss:0.00000, loss_test:0.03255, lr:2.53e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.461, tt:6716.641\n",
      "Ep:162, loss:0.00000, loss_test:0.03251, lr:2.50e-02, fs:0.61654 (r=0.471,p=0.891),  time:41.483, tt:6761.687\n",
      "Ep:163, loss:0.00000, loss_test:0.03269, lr:2.48e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.496, tt:6805.318\n",
      "Ep:164, loss:0.00000, loss_test:0.03274, lr:2.45e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.501, tt:6847.661\n",
      "Ep:165, loss:0.00000, loss_test:0.03270, lr:2.43e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.507, tt:6890.243\n",
      "Ep:166, loss:0.00000, loss_test:0.03286, lr:2.40e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.520, tt:6933.819\n",
      "Ep:167, loss:0.00000, loss_test:0.03284, lr:2.38e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.519, tt:6975.125\n",
      "Ep:168, loss:0.00000, loss_test:0.03285, lr:2.36e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.536, tt:7019.508\n",
      "Ep:169, loss:0.00000, loss_test:0.03302, lr:2.33e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.544, tt:7062.422\n",
      "Ep:170, loss:0.00000, loss_test:0.03299, lr:2.31e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.538, tt:7103.022\n",
      "Ep:171, loss:0.00000, loss_test:0.03304, lr:2.29e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.541, tt:7145.044\n",
      "Ep:172, loss:0.00000, loss_test:0.03318, lr:2.26e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.550, tt:7188.129\n",
      "Ep:173, loss:0.00000, loss_test:0.03316, lr:2.24e-02, fs:0.62121 (r=0.471,p=0.911),  time:41.555, tt:7230.484\n",
      "Ep:174, loss:0.00000, loss_test:0.03313, lr:2.22e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.563, tt:7273.607\n",
      "Ep:175, loss:0.00000, loss_test:0.03326, lr:2.20e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.566, tt:7315.659\n",
      "Ep:176, loss:0.00000, loss_test:0.03327, lr:2.17e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.576, tt:7358.881\n",
      "Ep:177, loss:0.00000, loss_test:0.03328, lr:2.15e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.577, tt:7400.661\n",
      "Ep:178, loss:0.00000, loss_test:0.03337, lr:2.13e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.579, tt:7442.707\n",
      "Ep:179, loss:0.00000, loss_test:0.03343, lr:2.11e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.585, tt:7485.333\n",
      "Ep:180, loss:0.00000, loss_test:0.03344, lr:2.09e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.589, tt:7527.534\n",
      "Ep:181, loss:0.00000, loss_test:0.03352, lr:2.07e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.586, tt:7568.733\n",
      "Ep:182, loss:0.00000, loss_test:0.03358, lr:2.05e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.587, tt:7610.498\n",
      "Ep:183, loss:0.00000, loss_test:0.03357, lr:2.03e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.578, tt:7650.381\n",
      "Ep:184, loss:0.00000, loss_test:0.03372, lr:2.01e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.583, tt:7692.935\n",
      "Ep:185, loss:0.00000, loss_test:0.03379, lr:1.99e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.576, tt:7733.090\n",
      "Ep:186, loss:0.00000, loss_test:0.03372, lr:1.97e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.578, tt:7775.135\n",
      "Ep:187, loss:0.00000, loss_test:0.03379, lr:1.95e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.576, tt:7816.353\n",
      "Ep:188, loss:0.00000, loss_test:0.03390, lr:1.93e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.576, tt:7857.945\n",
      "Ep:189, loss:0.00000, loss_test:0.03387, lr:1.91e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.572, tt:7898.702\n",
      "Ep:190, loss:0.00000, loss_test:0.03391, lr:1.89e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.576, tt:7941.037\n",
      "Ep:191, loss:0.00000, loss_test:0.03399, lr:1.87e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.578, tt:7983.013\n",
      "Ep:192, loss:0.00000, loss_test:0.03400, lr:1.85e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.603, tt:8029.398\n",
      "Ep:193, loss:0.00000, loss_test:0.03401, lr:1.83e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.606, tt:8071.568\n",
      "Ep:194, loss:0.00000, loss_test:0.03411, lr:1.81e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.613, tt:8114.616\n",
      "Ep:195, loss:0.00000, loss_test:0.03416, lr:1.80e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.621, tt:8157.778\n",
      "Ep:196, loss:0.00000, loss_test:0.03413, lr:1.78e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.623, tt:8199.641\n",
      "Ep:197, loss:0.00000, loss_test:0.03422, lr:1.76e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.634, tt:8243.544\n",
      "Ep:198, loss:0.00000, loss_test:0.03428, lr:1.74e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.631, tt:8284.587\n",
      "Ep:199, loss:0.00000, loss_test:0.03435, lr:1.73e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.634, tt:8326.830\n",
      "Ep:200, loss:0.00000, loss_test:0.03435, lr:1.71e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.627, tt:8366.969\n",
      "Ep:201, loss:0.00000, loss_test:0.03445, lr:1.69e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.623, tt:8407.808\n",
      "Ep:202, loss:0.00000, loss_test:0.03445, lr:1.67e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.617, tt:8448.262\n",
      "Ep:203, loss:0.00000, loss_test:0.03451, lr:1.66e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.617, tt:8489.830\n",
      "Ep:204, loss:0.00000, loss_test:0.03454, lr:1.64e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.623, tt:8532.649\n",
      "Ep:205, loss:0.00000, loss_test:0.03457, lr:1.62e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.626, tt:8574.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.03462, lr:1.61e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.635, tt:8618.435\n",
      "Ep:207, loss:0.00000, loss_test:0.03465, lr:1.59e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.639, tt:8660.845\n",
      "Ep:208, loss:0.00000, loss_test:0.03469, lr:1.58e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.663, tt:8707.596\n",
      "Ep:209, loss:0.00000, loss_test:0.03473, lr:1.56e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.667, tt:8750.051\n",
      "Ep:210, loss:0.00000, loss_test:0.03472, lr:1.54e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.669, tt:8792.082\n",
      "Ep:211, loss:0.00000, loss_test:0.03479, lr:1.53e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.677, tt:8835.447\n",
      "Ep:212, loss:0.00000, loss_test:0.03478, lr:1.51e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.675, tt:8876.743\n",
      "Ep:213, loss:0.00000, loss_test:0.03481, lr:1.50e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.660, tt:8915.145\n",
      "Ep:214, loss:0.00000, loss_test:0.03489, lr:1.48e-02, fs:0.62595 (r=0.471,p=0.932),  time:41.626, tt:8949.560\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13829, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:37.435, tt:37.435\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13562, lr:1.00e-02, fs:0.67451 (r=0.989,p=0.512),  time:37.146, tt:74.292\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13132, lr:1.00e-02, fs:0.67470 (r=0.966,p=0.519),  time:37.984, tt:113.951\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12604, lr:1.00e-02, fs:0.67826 (r=0.897,p=0.545),  time:39.026, tt:156.104\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00023, loss_test:0.12493, lr:1.00e-02, fs:0.67337 (r=0.770,p=0.598),  time:39.311, tt:196.553\n",
      "Ep:5, loss:0.00023, loss_test:0.12826, lr:1.00e-02, fs:0.61538 (r=0.644,p=0.589),  time:39.837, tt:239.023\n",
      "Ep:6, loss:0.00022, loss_test:0.12721, lr:1.00e-02, fs:0.59459 (r=0.632,p=0.561),  time:40.270, tt:281.889\n",
      "Ep:7, loss:0.00021, loss_test:0.12474, lr:1.00e-02, fs:0.65672 (r=0.759,p=0.579),  time:40.401, tt:323.210\n",
      "Ep:8, loss:0.00021, loss_test:0.12134, lr:1.00e-02, fs:0.62827 (r=0.690,p=0.577),  time:40.720, tt:366.477\n",
      "Ep:9, loss:0.00020, loss_test:0.11837, lr:1.00e-02, fs:0.60355 (r=0.586,p=0.622),  time:41.188, tt:411.882\n",
      "Ep:10, loss:0.00020, loss_test:0.11717, lr:1.00e-02, fs:0.60355 (r=0.586,p=0.622),  time:41.326, tt:454.581\n",
      "Ep:11, loss:0.00019, loss_test:0.11511, lr:1.00e-02, fs:0.62921 (r=0.644,p=0.615),  time:41.462, tt:497.539\n",
      "Ep:12, loss:0.00018, loss_test:0.11293, lr:1.00e-02, fs:0.64773 (r=0.655,p=0.640),  time:41.704, tt:542.157\n",
      "Ep:13, loss:0.00018, loss_test:0.11234, lr:1.00e-02, fs:0.63953 (r=0.632,p=0.647),  time:42.186, tt:590.603\n",
      "Ep:14, loss:0.00017, loss_test:0.10972, lr:1.00e-02, fs:0.66286 (r=0.667,p=0.659),  time:42.250, tt:633.750\n",
      "Ep:15, loss:0.00017, loss_test:0.10820, lr:9.90e-03, fs:0.66667 (r=0.667,p=0.667),  time:42.347, tt:677.545\n",
      "Ep:16, loss:0.00016, loss_test:0.10925, lr:9.80e-03, fs:0.65476 (r=0.632,p=0.679),  time:42.348, tt:719.920\n",
      "Ep:17, loss:0.00015, loss_test:0.10627, lr:9.70e-03, fs:0.67052 (r=0.667,p=0.674),  time:42.506, tt:765.106\n",
      "Ep:18, loss:0.00015, loss_test:0.10506, lr:9.61e-03, fs:0.68605 (r=0.678,p=0.694),  time:42.562, tt:808.669\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.10588, lr:9.61e-03, fs:0.68675 (r=0.655,p=0.722),  time:42.635, tt:852.691\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.10396, lr:9.61e-03, fs:0.69412 (r=0.678,p=0.711),  time:42.676, tt:896.190\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.10379, lr:9.61e-03, fs:0.70659 (r=0.678,p=0.738),  time:42.703, tt:939.458\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.10422, lr:9.61e-03, fs:0.69880 (r=0.667,p=0.734),  time:42.810, tt:984.637\n",
      "Ep:23, loss:0.00012, loss_test:0.10362, lr:9.61e-03, fs:0.71084 (r=0.678,p=0.747),  time:42.882, tt:1029.165\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.10500, lr:9.61e-03, fs:0.70303 (r=0.667,p=0.744),  time:42.818, tt:1070.448\n",
      "Ep:25, loss:0.00012, loss_test:0.10190, lr:9.61e-03, fs:0.72189 (r=0.701,p=0.744),  time:42.802, tt:1112.859\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.10366, lr:9.61e-03, fs:0.69565 (r=0.644,p=0.757),  time:42.846, tt:1156.830\n",
      "Ep:27, loss:0.00011, loss_test:0.09981, lr:9.61e-03, fs:0.73988 (r=0.736,p=0.744),  time:42.839, tt:1199.501\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.10199, lr:9.61e-03, fs:0.71605 (r=0.667,p=0.773),  time:42.867, tt:1243.132\n",
      "Ep:29, loss:0.00010, loss_test:0.09874, lr:9.61e-03, fs:0.73810 (r=0.713,p=0.765),  time:42.908, tt:1287.250\n",
      "Ep:30, loss:0.00010, loss_test:0.09844, lr:9.61e-03, fs:0.73054 (r=0.701,p=0.762),  time:42.955, tt:1331.613\n",
      "Ep:31, loss:0.00009, loss_test:0.09754, lr:9.61e-03, fs:0.74556 (r=0.724,p=0.768),  time:42.942, tt:1374.132\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.09681, lr:9.61e-03, fs:0.73054 (r=0.701,p=0.762),  time:42.895, tt:1415.529\n",
      "Ep:33, loss:0.00009, loss_test:0.09809, lr:9.61e-03, fs:0.73620 (r=0.690,p=0.789),  time:43.012, tt:1462.398\n",
      "Ep:34, loss:0.00009, loss_test:0.09401, lr:9.61e-03, fs:0.76023 (r=0.747,p=0.774),  time:43.070, tt:1507.459\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.09683, lr:9.61e-03, fs:0.71605 (r=0.667,p=0.773),  time:43.107, tt:1551.842\n",
      "Ep:36, loss:0.00008, loss_test:0.09517, lr:9.61e-03, fs:0.71951 (r=0.678,p=0.766),  time:43.087, tt:1594.209\n",
      "Ep:37, loss:0.00008, loss_test:0.09734, lr:9.61e-03, fs:0.70440 (r=0.644,p=0.778),  time:43.105, tt:1637.989\n",
      "Ep:38, loss:0.00008, loss_test:0.09033, lr:9.61e-03, fs:0.76571 (r=0.770,p=0.761),  time:43.016, tt:1677.625\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.10029, lr:9.61e-03, fs:0.65753 (r=0.552,p=0.814),  time:42.970, tt:1718.804\n",
      "Ep:40, loss:0.00007, loss_test:0.09460, lr:9.61e-03, fs:0.77301 (r=0.724,p=0.829),  time:42.936, tt:1760.392\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00007, loss_test:0.09567, lr:9.61e-03, fs:0.69799 (r=0.598,p=0.839),  time:42.904, tt:1801.950\n",
      "Ep:42, loss:0.00007, loss_test:0.09391, lr:9.61e-03, fs:0.75776 (r=0.701,p=0.824),  time:42.904, tt:1844.854\n",
      "Ep:43, loss:0.00006, loss_test:0.09141, lr:9.61e-03, fs:0.77381 (r=0.747,p=0.802),  time:42.863, tt:1885.963\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.10280, lr:9.61e-03, fs:0.67114 (r=0.575,p=0.806),  time:42.854, tt:1928.421\n",
      "Ep:45, loss:0.00006, loss_test:0.09208, lr:9.61e-03, fs:0.76923 (r=0.747,p=0.793),  time:42.879, tt:1972.413\n",
      "Ep:46, loss:0.00006, loss_test:0.09876, lr:9.61e-03, fs:0.68966 (r=0.575,p=0.862),  time:42.859, tt:2014.368\n",
      "Ep:47, loss:0.00006, loss_test:0.09281, lr:9.61e-03, fs:0.79268 (r=0.747,p=0.844),  time:42.805, tt:2054.659\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.09929, lr:9.61e-03, fs:0.70748 (r=0.598,p=0.867),  time:42.809, tt:2097.665\n",
      "Ep:49, loss:0.00005, loss_test:0.09220, lr:9.61e-03, fs:0.79755 (r=0.747,p=0.855),  time:42.761, tt:2138.068\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00005, loss_test:0.09724, lr:9.61e-03, fs:0.71233 (r=0.598,p=0.881),  time:42.733, tt:2179.380\n",
      "Ep:51, loss:0.00005, loss_test:0.09011, lr:9.61e-03, fs:0.77844 (r=0.747,p=0.812),  time:42.718, tt:2221.350\n",
      "Ep:52, loss:0.00005, loss_test:0.09640, lr:9.61e-03, fs:0.71233 (r=0.598,p=0.881),  time:42.713, tt:2263.787\n",
      "Ep:53, loss:0.00004, loss_test:0.09206, lr:9.61e-03, fs:0.72000 (r=0.621,p=0.857),  time:42.706, tt:2306.101\n",
      "Ep:54, loss:0.00004, loss_test:0.09639, lr:9.61e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.698, tt:2348.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00004, loss_test:0.09352, lr:9.61e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.675, tt:2389.814\n",
      "Ep:56, loss:0.00004, loss_test:0.09598, lr:9.61e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.622, tt:2429.441\n",
      "Ep:57, loss:0.00004, loss_test:0.09919, lr:9.61e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.597, tt:2470.612\n",
      "Ep:58, loss:0.00004, loss_test:0.09587, lr:9.61e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.553, tt:2510.654\n",
      "Ep:59, loss:0.00004, loss_test:0.09510, lr:9.61e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.535, tt:2552.071\n",
      "Ep:60, loss:0.00003, loss_test:0.09658, lr:9.61e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.516, tt:2593.481\n",
      "Ep:61, loss:0.00003, loss_test:0.09663, lr:9.51e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.555, tt:2638.437\n",
      "Ep:62, loss:0.00003, loss_test:0.09417, lr:9.41e-03, fs:0.72483 (r=0.621,p=0.871),  time:42.569, tt:2681.817\n",
      "Ep:63, loss:0.00003, loss_test:0.09598, lr:9.32e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.580, tt:2725.096\n",
      "Ep:64, loss:0.00003, loss_test:0.10513, lr:9.23e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.602, tt:2769.139\n",
      "Ep:65, loss:0.00003, loss_test:0.09681, lr:9.14e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.627, tt:2813.402\n",
      "Ep:66, loss:0.00003, loss_test:0.09954, lr:9.04e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.636, tt:2856.587\n",
      "Ep:67, loss:0.00003, loss_test:0.09961, lr:8.95e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.649, tt:2900.164\n",
      "Ep:68, loss:0.00003, loss_test:0.10225, lr:8.86e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.661, tt:2943.578\n",
      "Ep:69, loss:0.00003, loss_test:0.10278, lr:8.78e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.665, tt:2986.518\n",
      "Ep:70, loss:0.00003, loss_test:0.09659, lr:8.69e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.652, tt:3028.309\n",
      "Ep:71, loss:0.00003, loss_test:0.10071, lr:8.60e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.666, tt:3071.949\n",
      "Ep:72, loss:0.00003, loss_test:0.10906, lr:8.51e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.717, tt:3118.318\n",
      "Ep:73, loss:0.00002, loss_test:0.09468, lr:8.43e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.732, tt:3162.157\n",
      "Ep:74, loss:0.00002, loss_test:0.11106, lr:8.35e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.717, tt:3203.766\n",
      "Ep:75, loss:0.00002, loss_test:0.09537, lr:8.26e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.702, tt:3245.383\n",
      "Ep:76, loss:0.00002, loss_test:0.11579, lr:8.18e-03, fs:0.72340 (r=0.586,p=0.944),  time:42.701, tt:3288.011\n",
      "Ep:77, loss:0.00002, loss_test:0.09651, lr:8.10e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.682, tt:3329.171\n",
      "Ep:78, loss:0.00002, loss_test:0.12008, lr:8.02e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.694, tt:3372.864\n",
      "Ep:79, loss:0.00002, loss_test:0.10143, lr:7.94e-03, fs:0.71141 (r=0.609,p=0.855),  time:42.668, tt:3413.426\n",
      "Ep:80, loss:0.00002, loss_test:0.11150, lr:7.86e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.666, tt:3455.969\n",
      "Ep:81, loss:0.00002, loss_test:0.11143, lr:7.78e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.655, tt:3497.698\n",
      "Ep:82, loss:0.00002, loss_test:0.10002, lr:7.70e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.623, tt:3537.698\n",
      "Ep:83, loss:0.00002, loss_test:0.11529, lr:7.62e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.617, tt:3579.789\n",
      "Ep:84, loss:0.00002, loss_test:0.10352, lr:7.55e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.624, tt:3623.019\n",
      "Ep:85, loss:0.00002, loss_test:0.11028, lr:7.47e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.660, tt:3668.798\n",
      "Ep:86, loss:0.00002, loss_test:0.11288, lr:7.40e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.675, tt:3712.760\n",
      "Ep:87, loss:0.00002, loss_test:0.10451, lr:7.32e-03, fs:0.71622 (r=0.609,p=0.869),  time:42.664, tt:3754.474\n",
      "Ep:88, loss:0.00002, loss_test:0.11095, lr:7.25e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.636, tt:3794.632\n",
      "Ep:89, loss:0.00002, loss_test:0.10770, lr:7.18e-03, fs:0.70345 (r=0.586,p=0.879),  time:42.610, tt:3834.913\n",
      "Ep:90, loss:0.00002, loss_test:0.10515, lr:7.11e-03, fs:0.72109 (r=0.609,p=0.883),  time:42.610, tt:3877.532\n",
      "Ep:91, loss:0.00002, loss_test:0.11118, lr:7.03e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.592, tt:3918.443\n",
      "Ep:92, loss:0.00001, loss_test:0.10781, lr:6.96e-03, fs:0.70345 (r=0.586,p=0.879),  time:42.561, tt:3958.184\n",
      "Ep:93, loss:0.00001, loss_test:0.10797, lr:6.89e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.556, tt:4000.289\n",
      "Ep:94, loss:0.00001, loss_test:0.10770, lr:6.83e-03, fs:0.70833 (r=0.586,p=0.895),  time:42.538, tt:4041.080\n",
      "Ep:95, loss:0.00001, loss_test:0.11056, lr:6.76e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.493, tt:4079.372\n",
      "Ep:96, loss:0.00001, loss_test:0.10724, lr:6.69e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.470, tt:4119.612\n",
      "Ep:97, loss:0.00001, loss_test:0.11122, lr:6.62e-03, fs:0.70833 (r=0.586,p=0.895),  time:42.437, tt:4158.860\n",
      "Ep:98, loss:0.00001, loss_test:0.11167, lr:6.56e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.422, tt:4199.805\n",
      "Ep:99, loss:0.00001, loss_test:0.10945, lr:6.49e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.410, tt:4240.965\n",
      "Ep:100, loss:0.00001, loss_test:0.11006, lr:6.43e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.396, tt:4281.977\n",
      "Ep:101, loss:0.00001, loss_test:0.10975, lr:6.36e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.400, tt:4324.765\n",
      "Ep:102, loss:0.00001, loss_test:0.10957, lr:6.30e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.372, tt:4364.352\n",
      "Ep:103, loss:0.00001, loss_test:0.11101, lr:6.24e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.358, tt:4405.258\n",
      "Ep:104, loss:0.00001, loss_test:0.11424, lr:6.17e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.362, tt:4447.961\n",
      "Ep:105, loss:0.00001, loss_test:0.10984, lr:6.11e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.340, tt:4487.987\n",
      "Ep:106, loss:0.00001, loss_test:0.11456, lr:6.05e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.343, tt:4530.754\n",
      "Ep:107, loss:0.00001, loss_test:0.10912, lr:5.99e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.340, tt:4572.749\n",
      "Ep:108, loss:0.00001, loss_test:0.11202, lr:5.93e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.334, tt:4614.404\n",
      "Ep:109, loss:0.00001, loss_test:0.11146, lr:5.87e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.354, tt:4658.986\n",
      "Ep:110, loss:0.00001, loss_test:0.11217, lr:5.81e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.361, tt:4702.065\n",
      "Ep:111, loss:0.00001, loss_test:0.10959, lr:5.75e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.358, tt:4744.055\n",
      "Ep:112, loss:0.00001, loss_test:0.11708, lr:5.70e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.358, tt:4786.423\n",
      "Ep:113, loss:0.00001, loss_test:0.11083, lr:5.64e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.345, tt:4827.382\n",
      "Ep:114, loss:0.00001, loss_test:0.11450, lr:5.58e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.353, tt:4870.582\n",
      "Ep:115, loss:0.00001, loss_test:0.11477, lr:5.53e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.339, tt:4911.318\n",
      "Ep:116, loss:0.00001, loss_test:0.11238, lr:5.47e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.327, tt:4952.225\n",
      "Ep:117, loss:0.00001, loss_test:0.11176, lr:5.42e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.318, tt:4993.548\n",
      "Ep:118, loss:0.00001, loss_test:0.11339, lr:5.36e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.303, tt:5034.079\n",
      "Ep:119, loss:0.00001, loss_test:0.11267, lr:5.31e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.299, tt:5075.886\n",
      "Ep:120, loss:0.00001, loss_test:0.11141, lr:5.26e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.267, tt:5114.355\n",
      "Ep:121, loss:0.00001, loss_test:0.11457, lr:5.20e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.278, tt:5157.857\n",
      "Ep:122, loss:0.00001, loss_test:0.11276, lr:5.15e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.256, tt:5197.473\n",
      "Ep:123, loss:0.00001, loss_test:0.11351, lr:5.10e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.223, tt:5235.669\n",
      "Ep:124, loss:0.00001, loss_test:0.11489, lr:5.05e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.216, tt:5276.964\n",
      "Ep:125, loss:0.00001, loss_test:0.11346, lr:5.00e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.192, tt:5316.229\n",
      "Ep:126, loss:0.00001, loss_test:0.11415, lr:4.95e-03, fs:0.71831 (r=0.586,p=0.927),  time:42.188, tt:5357.869\n",
      "Ep:127, loss:0.00001, loss_test:0.11620, lr:4.90e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.168, tt:5397.545\n",
      "Ep:128, loss:0.00001, loss_test:0.11342, lr:4.85e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.173, tt:5440.367\n",
      "Ep:129, loss:0.00001, loss_test:0.11356, lr:4.80e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.172, tt:5482.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.11591, lr:4.75e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.153, tt:5522.013\n",
      "Ep:131, loss:0.00001, loss_test:0.11362, lr:4.71e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.152, tt:5564.083\n",
      "Ep:132, loss:0.00001, loss_test:0.11515, lr:4.66e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.149, tt:5605.782\n",
      "Ep:133, loss:0.00001, loss_test:0.11577, lr:4.61e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.162, tt:5649.772\n",
      "Ep:134, loss:0.00001, loss_test:0.11377, lr:4.57e-03, fs:0.70922 (r=0.575,p=0.926),  time:42.158, tt:5691.275\n",
      "Ep:135, loss:0.00001, loss_test:0.11519, lr:4.52e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.138, tt:5730.765\n",
      "Ep:136, loss:0.00001, loss_test:0.11546, lr:4.48e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.129, tt:5771.617\n",
      "Ep:137, loss:0.00001, loss_test:0.11579, lr:4.43e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.125, tt:5813.259\n",
      "Ep:138, loss:0.00001, loss_test:0.11529, lr:4.39e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.124, tt:5855.278\n",
      "Ep:139, loss:0.00001, loss_test:0.11641, lr:4.34e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.130, tt:5898.184\n",
      "Ep:140, loss:0.00001, loss_test:0.11604, lr:4.30e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.105, tt:5936.828\n",
      "Ep:141, loss:0.00001, loss_test:0.11499, lr:4.26e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.095, tt:5977.522\n",
      "Ep:142, loss:0.00001, loss_test:0.11650, lr:4.21e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.081, tt:6017.653\n",
      "Ep:143, loss:0.00001, loss_test:0.11720, lr:4.17e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.069, tt:6057.999\n",
      "Ep:144, loss:0.00001, loss_test:0.11586, lr:4.13e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.055, tt:6098.034\n",
      "Ep:145, loss:0.00001, loss_test:0.11806, lr:4.09e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.039, tt:6137.684\n",
      "Ep:146, loss:0.00001, loss_test:0.11676, lr:4.05e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.036, tt:6179.263\n",
      "Ep:147, loss:0.00001, loss_test:0.11680, lr:4.01e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.033, tt:6220.943\n",
      "Ep:148, loss:0.00001, loss_test:0.11767, lr:3.97e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.025, tt:6261.677\n",
      "Ep:149, loss:0.00001, loss_test:0.11932, lr:3.93e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.033, tt:6304.883\n",
      "Ep:150, loss:0.00001, loss_test:0.11767, lr:3.89e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.035, tt:6347.223\n",
      "Ep:151, loss:0.00001, loss_test:0.11690, lr:3.85e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.032, tt:6388.842\n",
      "Ep:152, loss:0.00001, loss_test:0.11970, lr:3.81e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.023, tt:6429.529\n",
      "Ep:153, loss:0.00001, loss_test:0.11786, lr:3.77e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.015, tt:6470.385\n",
      "Ep:154, loss:0.00001, loss_test:0.11781, lr:3.73e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.029, tt:6514.517\n",
      "Ep:155, loss:0.00001, loss_test:0.12008, lr:3.70e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.024, tt:6555.708\n",
      "Ep:156, loss:0.00001, loss_test:0.11892, lr:3.66e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.014, tt:6596.140\n",
      "Ep:157, loss:0.00001, loss_test:0.11919, lr:3.62e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.009, tt:6637.423\n",
      "Ep:158, loss:0.00001, loss_test:0.11900, lr:3.59e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.008, tt:6679.307\n",
      "Ep:159, loss:0.00001, loss_test:0.12074, lr:3.55e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.012, tt:6721.975\n",
      "Ep:160, loss:0.00001, loss_test:0.11815, lr:3.52e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.019, tt:6765.030\n",
      "Ep:161, loss:0.00001, loss_test:0.11922, lr:3.48e-03, fs:0.67153 (r=0.529,p=0.920),  time:42.008, tt:6805.292\n",
      "Ep:162, loss:0.00001, loss_test:0.12180, lr:3.45e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.007, tt:6847.143\n",
      "Ep:163, loss:0.00001, loss_test:0.11773, lr:3.41e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.001, tt:6888.131\n",
      "Ep:164, loss:0.00001, loss_test:0.11888, lr:3.38e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.008, tt:6931.317\n",
      "Ep:165, loss:0.00001, loss_test:0.12133, lr:3.34e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.007, tt:6973.192\n",
      "Ep:166, loss:0.00001, loss_test:0.12034, lr:3.31e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.005, tt:7014.872\n",
      "Ep:167, loss:0.00000, loss_test:0.11872, lr:3.28e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.008, tt:7057.378\n",
      "Ep:168, loss:0.00000, loss_test:0.12081, lr:3.24e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.011, tt:7099.777\n",
      "Ep:169, loss:0.00000, loss_test:0.12100, lr:3.21e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.997, tt:7139.499\n",
      "Ep:170, loss:0.00000, loss_test:0.11896, lr:3.18e-03, fs:0.69065 (r=0.552,p=0.923),  time:41.999, tt:7181.768\n",
      "Ep:171, loss:0.00000, loss_test:0.12144, lr:3.15e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.987, tt:7221.755\n",
      "Ep:172, loss:0.00000, loss_test:0.12129, lr:3.12e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.994, tt:7264.910\n",
      "Ep:173, loss:0.00000, loss_test:0.11849, lr:3.09e-03, fs:0.69065 (r=0.552,p=0.923),  time:41.991, tt:7306.509\n",
      "Ep:174, loss:0.00000, loss_test:0.12045, lr:3.05e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.005, tt:7350.936\n",
      "Ep:175, loss:0.00000, loss_test:0.12111, lr:3.02e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.008, tt:7393.443\n",
      "Ep:176, loss:0.00000, loss_test:0.11952, lr:2.99e-03, fs:0.69065 (r=0.552,p=0.923),  time:42.006, tt:7435.050\n",
      "Ep:177, loss:0.00000, loss_test:0.11980, lr:2.96e-03, fs:0.68116 (r=0.540,p=0.922),  time:42.007, tt:7477.245\n",
      "Ep:178, loss:0.00000, loss_test:0.12223, lr:2.93e-03, fs:0.63158 (r=0.483,p=0.913),  time:42.009, tt:7519.654\n",
      "Ep:179, loss:0.00000, loss_test:0.11994, lr:2.90e-03, fs:0.65185 (r=0.506,p=0.917),  time:42.009, tt:7561.565\n",
      "Ep:180, loss:0.00000, loss_test:0.12034, lr:2.88e-03, fs:0.66176 (r=0.517,p=0.918),  time:42.006, tt:7603.141\n",
      "Ep:181, loss:0.00000, loss_test:0.12139, lr:2.85e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.996, tt:7643.332\n",
      "Ep:182, loss:0.00000, loss_test:0.12029, lr:2.82e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.994, tt:7684.939\n",
      "Ep:183, loss:0.00000, loss_test:0.11921, lr:2.79e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.999, tt:7727.779\n",
      "Ep:184, loss:0.00000, loss_test:0.12049, lr:2.76e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.985, tt:7767.202\n",
      "Ep:185, loss:0.00000, loss_test:0.12158, lr:2.73e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.972, tt:7806.820\n",
      "Ep:186, loss:0.00000, loss_test:0.11880, lr:2.71e-03, fs:0.69065 (r=0.552,p=0.923),  time:41.965, tt:7847.462\n",
      "Ep:187, loss:0.00000, loss_test:0.12037, lr:2.68e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.957, tt:7887.909\n",
      "Ep:188, loss:0.00000, loss_test:0.12143, lr:2.65e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.957, tt:7929.916\n",
      "Ep:189, loss:0.00000, loss_test:0.11909, lr:2.63e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.949, tt:7970.350\n",
      "Ep:190, loss:0.00000, loss_test:0.12064, lr:2.60e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.962, tt:8014.717\n",
      "Ep:191, loss:0.00000, loss_test:0.12148, lr:2.57e-03, fs:0.63158 (r=0.483,p=0.913),  time:41.963, tt:8056.959\n",
      "Ep:192, loss:0.00000, loss_test:0.12000, lr:2.55e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.958, tt:8097.963\n",
      "Ep:193, loss:0.00000, loss_test:0.11953, lr:2.52e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.958, tt:8139.862\n",
      "Ep:194, loss:0.00000, loss_test:0.12136, lr:2.50e-03, fs:0.62121 (r=0.471,p=0.911),  time:41.958, tt:8181.837\n",
      "Ep:195, loss:0.00000, loss_test:0.12093, lr:2.47e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.952, tt:8222.606\n",
      "Ep:196, loss:0.00000, loss_test:0.11896, lr:2.45e-03, fs:0.69065 (r=0.552,p=0.923),  time:41.953, tt:8264.822\n",
      "Ep:197, loss:0.00000, loss_test:0.12053, lr:2.42e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.955, tt:8307.048\n",
      "Ep:198, loss:0.00000, loss_test:0.12089, lr:2.40e-03, fs:0.63158 (r=0.483,p=0.913),  time:41.952, tt:8348.379\n",
      "Ep:199, loss:0.00000, loss_test:0.11925, lr:2.38e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.945, tt:8389.082\n",
      "Ep:200, loss:0.00000, loss_test:0.12001, lr:2.35e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.947, tt:8431.268\n",
      "Ep:201, loss:0.00000, loss_test:0.12038, lr:2.33e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.943, tt:8472.529\n",
      "Ep:202, loss:0.00000, loss_test:0.12003, lr:2.31e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.939, tt:8513.600\n",
      "Ep:203, loss:0.00000, loss_test:0.11946, lr:2.28e-03, fs:0.67153 (r=0.529,p=0.920),  time:41.933, tt:8554.367\n",
      "Ep:204, loss:0.00000, loss_test:0.12019, lr:2.26e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.934, tt:8596.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.12072, lr:2.24e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.931, tt:8637.841\n",
      "Ep:206, loss:0.00000, loss_test:0.11902, lr:2.21e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.932, tt:8679.857\n",
      "Ep:207, loss:0.00000, loss_test:0.12044, lr:2.19e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.935, tt:8722.408\n",
      "Ep:208, loss:0.00000, loss_test:0.12108, lr:2.17e-03, fs:0.64179 (r=0.494,p=0.915),  time:41.939, tt:8765.208\n",
      "Ep:209, loss:0.00000, loss_test:0.11906, lr:2.15e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.941, tt:8807.680\n",
      "Ep:210, loss:0.00000, loss_test:0.12033, lr:2.13e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.942, tt:8849.807\n",
      "Ep:211, loss:0.00000, loss_test:0.12076, lr:2.11e-03, fs:0.65185 (r=0.506,p=0.917),  time:41.945, tt:8892.417\n",
      "Ep:212, loss:0.00000, loss_test:0.12025, lr:2.08e-03, fs:0.66176 (r=0.517,p=0.918),  time:41.942, tt:8933.574\n",
      "Ep:213, loss:0.00000, loss_test:0.12007, lr:2.06e-03, fs:0.68116 (r=0.540,p=0.922),  time:41.923, tt:8971.564\n",
      "Ep:214, loss:0.00000, loss_test:0.11954, lr:2.04e-03, fs:0.67153 (r=0.529,p=0.920),  time:41.871, tt:9002.175\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.01961, lr:6.00e-02, fs:0.65152 (r=0.869,p=0.521),  time:26.163, tt:26.163\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02060, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:28.135, tt:56.270\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02097, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:31.175, tt:93.525\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.67347 (r=1.000,p=0.508),  time:33.349, tt:133.398\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01829, lr:6.00e-02, fs:0.70290 (r=0.980,p=0.548),  time:34.491, tt:172.457\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00003, loss_test:0.01778, lr:6.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:35.778, tt:214.666\n",
      "Ep:6, loss:0.00003, loss_test:0.01770, lr:6.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:36.241, tt:253.684\n",
      "Ep:7, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:36.726, tt:293.811\n",
      "Ep:8, loss:0.00003, loss_test:0.01711, lr:6.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:37.015, tt:333.137\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:37.374, tt:373.739\n",
      "Ep:10, loss:0.00003, loss_test:0.01703, lr:6.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:37.753, tt:415.285\n",
      "Ep:11, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:38.004, tt:456.051\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01722, lr:6.00e-02, fs:0.69869 (r=0.808,p=0.615),  time:38.369, tt:498.797\n",
      "Ep:13, loss:0.00003, loss_test:0.01700, lr:6.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:38.439, tt:538.150\n",
      "Ep:14, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:38.532, tt:577.973\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01664, lr:6.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:38.589, tt:617.421\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00002, loss_test:0.01673, lr:6.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:38.662, tt:657.258\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:38.801, tt:698.424\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01659, lr:6.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:38.818, tt:737.546\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01639, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:38.955, tt:779.094\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01627, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:39.077, tt:820.614\n",
      "Ep:21, loss:0.00002, loss_test:0.01624, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:39.073, tt:859.596\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:39.172, tt:900.958\n",
      "Ep:23, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:39.197, tt:940.738\n",
      "Ep:24, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:39.241, tt:981.033\n",
      "Ep:25, loss:0.00002, loss_test:0.01583, lr:6.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:39.291, tt:1021.567\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:39.334, tt:1062.023\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:39.372, tt:1102.409\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01566, lr:6.00e-02, fs:0.76852 (r=0.838,p=0.709),  time:39.548, tt:1146.903\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.77209 (r=0.838,p=0.716),  time:39.600, tt:1188.007\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:39.621, tt:1228.261\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01548, lr:6.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:39.607, tt:1267.409\n",
      "Ep:32, loss:0.00002, loss_test:0.01539, lr:6.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:39.637, tt:1308.023\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.78846 (r=0.828,p=0.752),  time:39.634, tt:1347.545\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01535, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:39.723, tt:1390.307\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:39.706, tt:1429.426\n",
      "Ep:36, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:39.713, tt:1469.392\n",
      "Ep:37, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:39.734, tt:1509.903\n",
      "Ep:38, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:39.786, tt:1551.656\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00001, loss_test:0.01530, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.814, tt:1592.550\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00001, loss_test:0.01532, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.863, tt:1634.379\n",
      "Ep:41, loss:0.00001, loss_test:0.01537, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.896, tt:1675.630\n",
      "Ep:42, loss:0.00001, loss_test:0.01538, lr:6.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:39.895, tt:1715.473\n",
      "Ep:43, loss:0.00001, loss_test:0.01533, lr:6.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:39.877, tt:1754.572\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01540, lr:6.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:39.875, tt:1794.362\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01547, lr:6.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:39.880, tt:1834.468\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01548, lr:6.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.889, tt:1874.765\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01550, lr:6.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.906, tt:1915.498\n",
      "Ep:48, loss:0.00001, loss_test:0.01568, lr:6.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:39.953, tt:1957.696\n",
      "Ep:49, loss:0.00001, loss_test:0.01575, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.006, tt:2000.284\n",
      "Ep:50, loss:0.00001, loss_test:0.01579, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.002, tt:2040.106\n",
      "Ep:51, loss:0.00001, loss_test:0.01594, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.045, tt:2082.366\n",
      "Ep:52, loss:0.00001, loss_test:0.01595, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.094, tt:2124.981\n",
      "Ep:53, loss:0.00001, loss_test:0.01609, lr:6.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.084, tt:2164.560\n",
      "Ep:54, loss:0.00001, loss_test:0.01613, lr:6.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:40.140, tt:2207.691\n",
      "Ep:55, loss:0.00001, loss_test:0.01619, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.169, tt:2249.458\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01640, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.195, tt:2291.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01619, lr:6.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.229, tt:2333.308\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01644, lr:6.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:40.232, tt:2373.690\n",
      "Ep:59, loss:0.00001, loss_test:0.01639, lr:6.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:40.259, tt:2415.549\n",
      "Ep:60, loss:0.00001, loss_test:0.01663, lr:6.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:40.276, tt:2456.853\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01667, lr:6.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.304, tt:2498.845\n",
      "Ep:62, loss:0.00001, loss_test:0.01664, lr:6.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:40.340, tt:2541.405\n",
      "Ep:63, loss:0.00001, loss_test:0.01690, lr:6.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.358, tt:2582.917\n",
      "Ep:64, loss:0.00001, loss_test:0.01697, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.359, tt:2623.323\n",
      "Ep:65, loss:0.00001, loss_test:0.01689, lr:6.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:40.335, tt:2662.082\n",
      "Ep:66, loss:0.00001, loss_test:0.01700, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.372, tt:2704.918\n",
      "Ep:67, loss:0.00001, loss_test:0.01725, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.393, tt:2746.723\n",
      "Ep:68, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.383, tt:2786.431\n",
      "Ep:69, loss:0.00001, loss_test:0.01740, lr:6.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:40.385, tt:2826.982\n",
      "Ep:70, loss:0.00001, loss_test:0.01754, lr:6.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.390, tt:2867.682\n",
      "Ep:71, loss:0.00001, loss_test:0.01764, lr:6.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:40.390, tt:2908.094\n",
      "Ep:72, loss:0.00001, loss_test:0.01752, lr:5.94e-02, fs:0.84324 (r=0.788,p=0.907),  time:40.389, tt:2948.415\n",
      "Ep:73, loss:0.00001, loss_test:0.01794, lr:5.88e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.405, tt:2989.946\n",
      "Ep:74, loss:0.00001, loss_test:0.01793, lr:5.82e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.460, tt:3034.469\n",
      "Ep:75, loss:0.00001, loss_test:0.01783, lr:5.76e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.456, tt:3074.684\n",
      "Ep:76, loss:0.00001, loss_test:0.01811, lr:5.71e-02, fs:0.82873 (r=0.758,p=0.915),  time:40.459, tt:3115.334\n",
      "Ep:77, loss:0.00001, loss_test:0.01812, lr:5.65e-02, fs:0.82873 (r=0.758,p=0.915),  time:40.468, tt:3156.526\n",
      "Ep:78, loss:0.00001, loss_test:0.01830, lr:5.59e-02, fs:0.83516 (r=0.768,p=0.916),  time:40.483, tt:3198.157\n",
      "Ep:79, loss:0.00001, loss_test:0.01838, lr:5.54e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.503, tt:3240.277\n",
      "Ep:80, loss:0.00001, loss_test:0.01841, lr:5.48e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.514, tt:3281.648\n",
      "Ep:81, loss:0.00001, loss_test:0.01857, lr:5.43e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.516, tt:3322.317\n",
      "Ep:82, loss:0.00001, loss_test:0.01847, lr:5.37e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.532, tt:3364.129\n",
      "Ep:83, loss:0.00001, loss_test:0.01870, lr:5.32e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.546, tt:3405.825\n",
      "Ep:84, loss:0.00001, loss_test:0.01874, lr:5.27e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.564, tt:3447.936\n",
      "Ep:85, loss:0.00001, loss_test:0.01881, lr:5.21e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.570, tt:3489.032\n",
      "Ep:86, loss:0.00001, loss_test:0.01884, lr:5.16e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.594, tt:3531.711\n",
      "Ep:87, loss:0.00001, loss_test:0.01905, lr:5.11e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.689, tt:3580.612\n",
      "Ep:88, loss:0.00001, loss_test:0.01911, lr:5.06e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.697, tt:3622.073\n",
      "Ep:89, loss:0.00001, loss_test:0.01913, lr:5.01e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.694, tt:3662.498\n",
      "Ep:90, loss:0.00001, loss_test:0.01943, lr:4.96e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.699, tt:3703.649\n",
      "Ep:91, loss:0.00001, loss_test:0.01942, lr:4.91e-02, fs:0.83333 (r=0.758,p=0.926),  time:40.685, tt:3742.979\n",
      "Ep:92, loss:0.00001, loss_test:0.01940, lr:4.86e-02, fs:0.83978 (r=0.768,p=0.927),  time:40.695, tt:3784.651\n",
      "Ep:93, loss:0.00001, loss_test:0.01975, lr:4.81e-02, fs:0.83146 (r=0.747,p=0.937),  time:40.691, tt:3824.939\n",
      "Ep:94, loss:0.00001, loss_test:0.01974, lr:4.76e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.685, tt:3865.106\n",
      "Ep:95, loss:0.00001, loss_test:0.01979, lr:4.71e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.688, tt:3906.026\n",
      "Ep:96, loss:0.00001, loss_test:0.01982, lr:4.67e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.708, tt:3948.680\n",
      "Ep:97, loss:0.00001, loss_test:0.01987, lr:4.62e-02, fs:0.83799 (r=0.758,p=0.938),  time:40.715, tt:3990.056\n",
      "Ep:98, loss:0.00001, loss_test:0.02000, lr:4.57e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.732, tt:4032.476\n",
      "Ep:99, loss:0.00001, loss_test:0.02015, lr:4.53e-02, fs:0.83908 (r=0.737,p=0.973),  time:40.727, tt:4072.718\n",
      "Ep:100, loss:0.00001, loss_test:0.02002, lr:4.48e-02, fs:0.83429 (r=0.737,p=0.961),  time:40.724, tt:4113.165\n",
      "Ep:101, loss:0.00001, loss_test:0.02022, lr:4.44e-02, fs:0.83429 (r=0.737,p=0.961),  time:40.730, tt:4154.436\n",
      "Ep:102, loss:0.00001, loss_test:0.02036, lr:4.39e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.736, tt:4195.791\n",
      "Ep:103, loss:0.00000, loss_test:0.02031, lr:4.35e-02, fs:0.83237 (r=0.727,p=0.973),  time:40.743, tt:4237.235\n",
      "Ep:104, loss:0.00000, loss_test:0.02040, lr:4.31e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.746, tt:4278.297\n",
      "Ep:105, loss:0.00000, loss_test:0.02049, lr:4.26e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.744, tt:4318.903\n",
      "Ep:106, loss:0.00000, loss_test:0.02058, lr:4.22e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.751, tt:4360.358\n",
      "Ep:107, loss:0.00000, loss_test:0.02067, lr:4.18e-02, fs:0.82558 (r=0.717,p=0.973),  time:40.732, tt:4399.025\n",
      "Ep:108, loss:0.00000, loss_test:0.02063, lr:4.14e-02, fs:0.81871 (r=0.707,p=0.972),  time:40.806, tt:4447.824\n",
      "Ep:109, loss:0.00000, loss_test:0.02077, lr:4.10e-02, fs:0.81871 (r=0.707,p=0.972),  time:40.812, tt:4489.308\n",
      "Ep:110, loss:0.00000, loss_test:0.02093, lr:4.05e-02, fs:0.81176 (r=0.697,p=0.972),  time:40.811, tt:4530.024\n",
      "Ep:111, loss:0.00000, loss_test:0.02092, lr:4.01e-02, fs:0.79762 (r=0.677,p=0.971),  time:40.821, tt:4571.939\n",
      "Ep:112, loss:0.00000, loss_test:0.02105, lr:3.97e-02, fs:0.80473 (r=0.687,p=0.971),  time:40.841, tt:4615.062\n",
      "Ep:113, loss:0.00000, loss_test:0.02100, lr:3.93e-02, fs:0.79762 (r=0.677,p=0.971),  time:40.846, tt:4656.477\n",
      "Ep:114, loss:0.00000, loss_test:0.02121, lr:3.89e-02, fs:0.79042 (r=0.667,p=0.971),  time:40.846, tt:4697.264\n",
      "Ep:115, loss:0.00000, loss_test:0.02129, lr:3.86e-02, fs:0.79762 (r=0.677,p=0.971),  time:40.853, tt:4738.911\n",
      "Ep:116, loss:0.00000, loss_test:0.02126, lr:3.82e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.838, tt:4778.051\n",
      "Ep:117, loss:0.00000, loss_test:0.02149, lr:3.78e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.833, tt:4818.267\n",
      "Ep:118, loss:0.00000, loss_test:0.02150, lr:3.74e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.859, tt:4862.265\n",
      "Ep:119, loss:0.00000, loss_test:0.02152, lr:3.70e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.848, tt:4901.781\n",
      "Ep:120, loss:0.00000, loss_test:0.02171, lr:3.67e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.829, tt:4940.357\n",
      "Ep:121, loss:0.00000, loss_test:0.02173, lr:3.63e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.834, tt:4981.712\n",
      "Ep:122, loss:0.00000, loss_test:0.02169, lr:3.59e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.832, tt:5022.290\n",
      "Ep:123, loss:0.00000, loss_test:0.02189, lr:3.56e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.842, tt:5064.356\n",
      "Ep:124, loss:0.00000, loss_test:0.02196, lr:3.52e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.842, tt:5105.255\n",
      "Ep:125, loss:0.00000, loss_test:0.02192, lr:3.49e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.833, tt:5144.909\n",
      "Ep:126, loss:0.00000, loss_test:0.02201, lr:3.45e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.815, tt:5183.487\n",
      "Ep:127, loss:0.00000, loss_test:0.02205, lr:3.42e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.807, tt:5223.242\n",
      "Ep:128, loss:0.00000, loss_test:0.02219, lr:3.38e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.805, tt:5263.844\n",
      "Ep:129, loss:0.00000, loss_test:0.02212, lr:3.35e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.837, tt:5308.846\n",
      "Ep:130, loss:0.00000, loss_test:0.02229, lr:3.32e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.840, tt:5350.097\n",
      "Ep:131, loss:0.00000, loss_test:0.02237, lr:3.28e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.840, tt:5390.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.02232, lr:3.25e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.841, tt:5431.845\n",
      "Ep:133, loss:0.00000, loss_test:0.02246, lr:3.22e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.840, tt:5472.607\n",
      "Ep:134, loss:0.00000, loss_test:0.02252, lr:3.19e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.823, tt:5511.094\n",
      "Ep:135, loss:0.00000, loss_test:0.02252, lr:3.15e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.824, tt:5552.041\n",
      "Ep:136, loss:0.00000, loss_test:0.02259, lr:3.12e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.809, tt:5590.876\n",
      "Ep:137, loss:0.00000, loss_test:0.02269, lr:3.09e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.812, tt:5632.062\n",
      "Ep:138, loss:0.00000, loss_test:0.02271, lr:3.06e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.813, tt:5673.061\n",
      "Ep:139, loss:0.00000, loss_test:0.02270, lr:3.03e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.820, tt:5714.744\n",
      "Ep:140, loss:0.00000, loss_test:0.02293, lr:3.00e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.814, tt:5754.799\n",
      "Ep:141, loss:0.00000, loss_test:0.02290, lr:2.97e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.815, tt:5795.753\n",
      "Ep:142, loss:0.00000, loss_test:0.02291, lr:2.94e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.814, tt:5836.344\n",
      "Ep:143, loss:0.00000, loss_test:0.02309, lr:2.91e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.796, tt:5874.587\n",
      "Ep:144, loss:0.00000, loss_test:0.02304, lr:2.88e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.809, tt:5917.329\n",
      "Ep:145, loss:0.00000, loss_test:0.02306, lr:2.85e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.840, tt:5962.581\n",
      "Ep:146, loss:0.00000, loss_test:0.02320, lr:2.82e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.834, tt:6002.570\n",
      "Ep:147, loss:0.00000, loss_test:0.02317, lr:2.80e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.826, tt:6042.244\n",
      "Ep:148, loss:0.00000, loss_test:0.02325, lr:2.77e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.822, tt:6082.482\n",
      "Ep:149, loss:0.00000, loss_test:0.02334, lr:2.74e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.812, tt:6121.728\n",
      "Ep:150, loss:0.00000, loss_test:0.02331, lr:2.71e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.817, tt:6163.351\n",
      "Ep:151, loss:0.00000, loss_test:0.02337, lr:2.69e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.808, tt:6202.824\n",
      "Ep:152, loss:0.00000, loss_test:0.02341, lr:2.66e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.813, tt:6244.376\n",
      "Ep:153, loss:0.00000, loss_test:0.02347, lr:2.63e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.812, tt:6285.120\n",
      "Ep:154, loss:0.00000, loss_test:0.02360, lr:2.61e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.810, tt:6325.522\n",
      "Ep:155, loss:0.00000, loss_test:0.02352, lr:2.58e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.805, tt:6365.593\n",
      "Ep:156, loss:0.00000, loss_test:0.02361, lr:2.55e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.802, tt:6405.955\n",
      "Ep:157, loss:0.00000, loss_test:0.02370, lr:2.53e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.800, tt:6446.385\n",
      "Ep:158, loss:0.00000, loss_test:0.02366, lr:2.50e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.809, tt:6488.628\n",
      "Ep:159, loss:0.00000, loss_test:0.02379, lr:2.48e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.803, tt:6528.404\n",
      "Ep:160, loss:0.00000, loss_test:0.02377, lr:2.45e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.795, tt:6568.010\n",
      "Ep:161, loss:0.00000, loss_test:0.02383, lr:2.43e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.795, tt:6608.786\n",
      "Ep:162, loss:0.00000, loss_test:0.02394, lr:2.40e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.804, tt:6650.988\n",
      "Ep:163, loss:0.00000, loss_test:0.02384, lr:2.38e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.799, tt:6691.050\n",
      "Ep:164, loss:0.00000, loss_test:0.02393, lr:2.36e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.796, tt:6731.309\n",
      "Ep:165, loss:0.00000, loss_test:0.02404, lr:2.33e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.788, tt:6770.848\n",
      "Ep:166, loss:0.00000, loss_test:0.02402, lr:2.31e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.779, tt:6810.116\n",
      "Ep:167, loss:0.00000, loss_test:0.02404, lr:2.29e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.761, tt:6847.784\n",
      "Ep:168, loss:0.00000, loss_test:0.02410, lr:2.26e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.752, tt:6887.170\n",
      "Ep:169, loss:0.00000, loss_test:0.02414, lr:2.24e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.748, tt:6927.094\n",
      "Ep:170, loss:0.00000, loss_test:0.02415, lr:2.22e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.733, tt:6965.418\n",
      "Ep:171, loss:0.00000, loss_test:0.02427, lr:2.20e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.728, tt:7005.171\n",
      "Ep:172, loss:0.00000, loss_test:0.02430, lr:2.17e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.732, tt:7046.585\n",
      "Ep:173, loss:0.00000, loss_test:0.02430, lr:2.15e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.735, tt:7087.824\n",
      "Ep:174, loss:0.00000, loss_test:0.02434, lr:2.13e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.734, tt:7128.467\n",
      "Ep:175, loss:0.00000, loss_test:0.02436, lr:2.11e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.728, tt:7168.078\n",
      "Ep:176, loss:0.00000, loss_test:0.02442, lr:2.09e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.716, tt:7206.800\n",
      "Ep:177, loss:0.00000, loss_test:0.02446, lr:2.07e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.717, tt:7247.613\n",
      "Ep:178, loss:0.00000, loss_test:0.02443, lr:2.05e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.720, tt:7288.960\n",
      "Ep:179, loss:0.00000, loss_test:0.02453, lr:2.03e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.752, tt:7335.315\n",
      "Ep:180, loss:0.00000, loss_test:0.02462, lr:2.01e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.750, tt:7375.664\n",
      "Ep:181, loss:0.00000, loss_test:0.02456, lr:1.99e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.750, tt:7416.444\n",
      "Ep:182, loss:0.00000, loss_test:0.02457, lr:1.97e-02, fs:0.78313 (r=0.657,p=0.970),  time:40.750, tt:7457.318\n",
      "Ep:183, loss:0.00000, loss_test:0.02467, lr:1.95e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.732, tt:7494.655\n",
      "Ep:184, loss:0.00000, loss_test:0.02471, lr:1.93e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.725, tt:7534.125\n",
      "Ep:185, loss:0.00000, loss_test:0.02470, lr:1.91e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.716, tt:7573.227\n",
      "Ep:186, loss:0.00000, loss_test:0.02473, lr:1.89e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.714, tt:7613.481\n",
      "Ep:187, loss:0.00000, loss_test:0.02477, lr:1.87e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.709, tt:7653.371\n",
      "Ep:188, loss:0.00000, loss_test:0.02480, lr:1.85e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.705, tt:7693.213\n",
      "Ep:189, loss:0.00000, loss_test:0.02484, lr:1.83e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.699, tt:7732.866\n",
      "Ep:190, loss:0.00000, loss_test:0.02489, lr:1.81e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.688, tt:7771.336\n",
      "Ep:191, loss:0.00000, loss_test:0.02489, lr:1.80e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.679, tt:7810.353\n",
      "Ep:192, loss:0.00000, loss_test:0.02491, lr:1.78e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.676, tt:7850.552\n",
      "Ep:193, loss:0.00000, loss_test:0.02497, lr:1.76e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.683, tt:7892.543\n",
      "Ep:194, loss:0.00000, loss_test:0.02502, lr:1.74e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.684, tt:7933.410\n",
      "Ep:195, loss:0.00000, loss_test:0.02501, lr:1.73e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.683, tt:7973.812\n",
      "Ep:196, loss:0.00000, loss_test:0.02504, lr:1.71e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.675, tt:8012.975\n",
      "Ep:197, loss:0.00000, loss_test:0.02509, lr:1.69e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.675, tt:8053.610\n",
      "Ep:198, loss:0.00000, loss_test:0.02512, lr:1.67e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.681, tt:8095.572\n",
      "Ep:199, loss:0.00000, loss_test:0.02512, lr:1.66e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.687, tt:8137.338\n",
      "Ep:200, loss:0.00000, loss_test:0.02519, lr:1.64e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.687, tt:8178.069\n",
      "Ep:201, loss:0.00000, loss_test:0.02519, lr:1.62e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.691, tt:8219.660\n",
      "Ep:202, loss:0.00000, loss_test:0.02518, lr:1.61e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.683, tt:8258.707\n",
      "Ep:203, loss:0.00000, loss_test:0.02526, lr:1.59e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.679, tt:8298.538\n",
      "Ep:204, loss:0.00000, loss_test:0.02528, lr:1.58e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.686, tt:8340.653\n",
      "Ep:205, loss:0.00000, loss_test:0.02526, lr:1.56e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.689, tt:8381.861\n",
      "Ep:206, loss:0.00000, loss_test:0.02531, lr:1.54e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.691, tt:8423.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02536, lr:1.53e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.695, tt:8464.595\n",
      "Ep:208, loss:0.00000, loss_test:0.02536, lr:1.51e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.729, tt:8512.271\n",
      "Ep:209, loss:0.00000, loss_test:0.02537, lr:1.50e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.717, tt:8550.472\n",
      "Ep:210, loss:0.00000, loss_test:0.02539, lr:1.48e-02, fs:0.78788 (r=0.657,p=0.985),  time:40.690, tt:8585.679\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14012, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:38.401, tt:38.401\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13762, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.154, tt:68.309\n",
      "Ep:2, loss:0.00027, loss_test:0.13307, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:36.759, tt:110.276\n",
      "Ep:3, loss:0.00026, loss_test:0.12607, lr:1.00e-02, fs:0.65233 (r=0.919,p=0.506),  time:37.889, tt:151.555\n",
      "Ep:4, loss:0.00025, loss_test:0.11853, lr:1.00e-02, fs:0.67490 (r=0.828,p=0.569),  time:38.887, tt:194.433\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11394, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:39.352, tt:236.110\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11213, lr:1.00e-02, fs:0.68269 (r=0.717,p=0.651),  time:39.655, tt:277.585\n",
      "Ep:7, loss:0.00022, loss_test:0.11147, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:39.953, tt:319.624\n",
      "Ep:8, loss:0.00021, loss_test:0.10952, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:40.205, tt:361.844\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10651, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:40.340, tt:403.398\n",
      "Ep:10, loss:0.00020, loss_test:0.10541, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:40.706, tt:447.770\n",
      "Ep:11, loss:0.00019, loss_test:0.10393, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:40.882, tt:490.580\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10247, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:41.003, tt:533.040\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09999, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:41.093, tt:575.304\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09769, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:41.072, tt:616.085\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09607, lr:1.00e-02, fs:0.76923 (r=0.808,p=0.734),  time:41.188, tt:659.015\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09498, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:41.149, tt:699.537\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09381, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.224, tt:742.036\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09270, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:41.235, tt:783.462\n",
      "Ep:19, loss:0.00014, loss_test:0.09149, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:41.220, tt:824.393\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.09112, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:41.315, tt:867.617\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08886, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.304, tt:908.681\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08920, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:41.395, tt:952.096\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08717, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:41.347, tt:992.324\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08611, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:41.358, tt:1033.946\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08492, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:41.338, tt:1074.777\n",
      "Ep:26, loss:0.00011, loss_test:0.08366, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:41.311, tt:1115.389\n",
      "Ep:27, loss:0.00010, loss_test:0.08240, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:41.343, tt:1157.615\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07997, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:41.364, tt:1199.558\n",
      "Ep:29, loss:0.00009, loss_test:0.08090, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:41.441, tt:1243.218\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.07802, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.427, tt:1284.229\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07857, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:41.385, tt:1324.304\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07543, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.348, tt:1364.471\n",
      "Ep:33, loss:0.00008, loss_test:0.07722, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:41.361, tt:1406.278\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.07382, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:41.376, tt:1448.173\n",
      "Ep:35, loss:0.00008, loss_test:0.07488, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.406, tt:1490.617\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.07341, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.403, tt:1531.916\n",
      "Ep:37, loss:0.00007, loss_test:0.07233, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.325, tt:1570.363\n",
      "Ep:38, loss:0.00007, loss_test:0.07119, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:41.308, tt:1611.025\n",
      "Ep:39, loss:0.00006, loss_test:0.07150, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.331, tt:1653.232\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.07045, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:41.394, tt:1697.134\n",
      "Ep:41, loss:0.00006, loss_test:0.07177, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.377, tt:1737.815\n",
      "Ep:42, loss:0.00006, loss_test:0.06960, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:41.337, tt:1777.493\n",
      "Ep:43, loss:0.00006, loss_test:0.07382, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.317, tt:1817.968\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00005, loss_test:0.06686, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.343, tt:1860.416\n",
      "Ep:45, loss:0.00005, loss_test:0.07139, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.323, tt:1900.874\n",
      "Ep:46, loss:0.00005, loss_test:0.06722, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:41.297, tt:1940.975\n",
      "Ep:47, loss:0.00005, loss_test:0.06903, lr:1.00e-02, fs:0.87432 (r=0.808,p=0.952),  time:41.266, tt:1980.786\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.06923, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:41.248, tt:2021.171\n",
      "Ep:49, loss:0.00005, loss_test:0.06861, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:41.243, tt:2062.166\n",
      "Ep:50, loss:0.00004, loss_test:0.06593, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:41.270, tt:2104.777\n",
      "Ep:51, loss:0.00004, loss_test:0.07036, lr:1.00e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.281, tt:2146.597\n",
      "Ep:52, loss:0.00004, loss_test:0.06583, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.322, tt:2190.092\n",
      "Ep:53, loss:0.00004, loss_test:0.06711, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.348, tt:2232.804\n",
      "Ep:54, loss:0.00004, loss_test:0.06706, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:41.339, tt:2273.658\n",
      "Ep:55, loss:0.00004, loss_test:0.06547, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.376, tt:2317.058\n",
      "Ep:56, loss:0.00003, loss_test:0.06566, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.375, tt:2358.385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00003, loss_test:0.06603, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:41.370, tt:2399.437\n",
      "Ep:58, loss:0.00003, loss_test:0.06493, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:41.360, tt:2440.249\n",
      "Ep:59, loss:0.00003, loss_test:0.06767, lr:9.90e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.315, tt:2478.872\n",
      "Ep:60, loss:0.00003, loss_test:0.06518, lr:9.80e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.339, tt:2521.695\n",
      "Ep:61, loss:0.00003, loss_test:0.06766, lr:9.70e-03, fs:0.86813 (r=0.798,p=0.952),  time:41.343, tt:2563.261\n",
      "Ep:62, loss:0.00003, loss_test:0.06557, lr:9.61e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.350, tt:2605.063\n",
      "Ep:63, loss:0.00003, loss_test:0.06764, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.375, tt:2648.021\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.06686, lr:9.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.386, tt:2690.106\n",
      "Ep:65, loss:0.00002, loss_test:0.06652, lr:9.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.384, tt:2731.377\n",
      "Ep:66, loss:0.00002, loss_test:0.06921, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.398, tt:2773.653\n",
      "Ep:67, loss:0.00002, loss_test:0.06760, lr:9.51e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.392, tt:2814.667\n",
      "Ep:68, loss:0.00002, loss_test:0.07016, lr:9.51e-03, fs:0.88764 (r=0.798,p=1.000),  time:41.399, tt:2856.530\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.06927, lr:9.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:41.398, tt:2897.880\n",
      "Ep:70, loss:0.00002, loss_test:0.06770, lr:9.51e-03, fs:0.86813 (r=0.798,p=0.952),  time:41.382, tt:2938.140\n",
      "Ep:71, loss:0.00002, loss_test:0.07115, lr:9.51e-03, fs:0.85057 (r=0.747,p=0.987),  time:41.403, tt:2981.003\n",
      "Ep:72, loss:0.00002, loss_test:0.07310, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.408, tt:3022.781\n",
      "Ep:73, loss:0.00002, loss_test:0.06797, lr:9.51e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.414, tt:3064.649\n",
      "Ep:74, loss:0.00002, loss_test:0.07200, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.441, tt:3108.086\n",
      "Ep:75, loss:0.00002, loss_test:0.07022, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.455, tt:3150.549\n",
      "Ep:76, loss:0.00002, loss_test:0.06851, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.473, tt:3193.412\n",
      "Ep:77, loss:0.00002, loss_test:0.07216, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.489, tt:3236.173\n",
      "Ep:78, loss:0.00002, loss_test:0.07125, lr:9.51e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.536, tt:3281.315\n",
      "Ep:79, loss:0.00001, loss_test:0.07093, lr:9.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.555, tt:3324.425\n",
      "Ep:80, loss:0.00001, loss_test:0.06963, lr:9.41e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.564, tt:3366.648\n",
      "Ep:81, loss:0.00001, loss_test:0.07105, lr:9.32e-03, fs:0.87151 (r=0.788,p=0.975),  time:41.590, tt:3410.412\n",
      "Ep:82, loss:0.00001, loss_test:0.07151, lr:9.23e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.608, tt:3453.444\n",
      "Ep:83, loss:0.00001, loss_test:0.06995, lr:9.14e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.616, tt:3495.730\n",
      "Ep:84, loss:0.00001, loss_test:0.07033, lr:9.04e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.637, tt:3539.156\n",
      "Ep:85, loss:0.00001, loss_test:0.07120, lr:8.95e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.667, tt:3583.336\n",
      "Ep:86, loss:0.00001, loss_test:0.07063, lr:8.86e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.677, tt:3625.936\n",
      "Ep:87, loss:0.00001, loss_test:0.07072, lr:8.78e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.684, tt:3668.178\n",
      "Ep:88, loss:0.00001, loss_test:0.07102, lr:8.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.678, tt:3709.305\n",
      "Ep:89, loss:0.00001, loss_test:0.07065, lr:8.60e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.687, tt:3751.856\n",
      "Ep:90, loss:0.00001, loss_test:0.07198, lr:8.51e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.692, tt:3793.965\n",
      "Ep:91, loss:0.00001, loss_test:0.06950, lr:8.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.706, tt:3836.968\n",
      "Ep:92, loss:0.00001, loss_test:0.07389, lr:8.35e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.733, tt:3881.159\n",
      "Ep:93, loss:0.00001, loss_test:0.06942, lr:8.26e-03, fs:0.85876 (r=0.768,p=0.974),  time:41.743, tt:3923.836\n",
      "Ep:94, loss:0.00001, loss_test:0.07387, lr:8.18e-03, fs:0.87778 (r=0.798,p=0.975),  time:41.753, tt:3966.581\n",
      "Ep:95, loss:0.00001, loss_test:0.06908, lr:8.10e-03, fs:0.83908 (r=0.737,p=0.973),  time:41.765, tt:4009.487\n",
      "Ep:96, loss:0.00001, loss_test:0.07545, lr:8.02e-03, fs:0.81657 (r=0.697,p=0.986),  time:41.788, tt:4053.430\n",
      "Ep:97, loss:0.00001, loss_test:0.07162, lr:7.94e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.813, tt:4097.708\n",
      "Ep:98, loss:0.00001, loss_test:0.07323, lr:7.86e-03, fs:0.85227 (r=0.758,p=0.974),  time:41.828, tt:4140.924\n",
      "Ep:99, loss:0.00001, loss_test:0.07279, lr:7.78e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.840, tt:4183.968\n",
      "Ep:100, loss:0.00001, loss_test:0.07437, lr:7.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.859, tt:4227.804\n",
      "Ep:101, loss:0.00001, loss_test:0.07252, lr:7.62e-03, fs:0.84571 (r=0.747,p=0.974),  time:41.845, tt:4268.225\n",
      "Ep:102, loss:0.00001, loss_test:0.07171, lr:7.55e-03, fs:0.81176 (r=0.697,p=0.972),  time:41.851, tt:4310.616\n",
      "Ep:103, loss:0.00001, loss_test:0.07433, lr:7.47e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.853, tt:4352.715\n",
      "Ep:104, loss:0.00001, loss_test:0.07116, lr:7.40e-03, fs:0.80473 (r=0.687,p=0.971),  time:41.854, tt:4394.718\n",
      "Ep:105, loss:0.00001, loss_test:0.07497, lr:7.32e-03, fs:0.80240 (r=0.677,p=0.985),  time:41.866, tt:4437.810\n",
      "Ep:106, loss:0.00001, loss_test:0.07222, lr:7.25e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.852, tt:4478.208\n",
      "Ep:107, loss:0.00001, loss_test:0.07363, lr:7.18e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.868, tt:4521.703\n",
      "Ep:108, loss:0.00001, loss_test:0.07358, lr:7.11e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.862, tt:4562.919\n",
      "Ep:109, loss:0.00000, loss_test:0.07387, lr:7.03e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.884, tt:4607.195\n",
      "Ep:110, loss:0.00000, loss_test:0.07464, lr:6.96e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.878, tt:4648.418\n",
      "Ep:111, loss:0.00000, loss_test:0.07224, lr:6.89e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.890, tt:4691.634\n",
      "Ep:112, loss:0.00000, loss_test:0.07446, lr:6.83e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.893, tt:4733.945\n",
      "Ep:113, loss:0.00000, loss_test:0.07275, lr:6.76e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.900, tt:4776.652\n",
      "Ep:114, loss:0.00000, loss_test:0.07416, lr:6.69e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.918, tt:4820.627\n",
      "Ep:115, loss:0.00000, loss_test:0.07324, lr:6.62e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.926, tt:4863.444\n",
      "Ep:116, loss:0.00000, loss_test:0.07231, lr:6.56e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.956, tt:4908.837\n",
      "Ep:117, loss:0.00000, loss_test:0.07397, lr:6.49e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.968, tt:4952.210\n",
      "Ep:118, loss:0.00000, loss_test:0.07393, lr:6.43e-03, fs:0.79762 (r=0.677,p=0.971),  time:41.975, tt:4995.080\n",
      "Ep:119, loss:0.00000, loss_test:0.07322, lr:6.36e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.005, tt:5040.547\n",
      "Ep:120, loss:0.00000, loss_test:0.07394, lr:6.30e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.019, tt:5084.252\n",
      "Ep:121, loss:0.00000, loss_test:0.07414, lr:6.24e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.033, tt:5128.040\n",
      "Ep:122, loss:0.00000, loss_test:0.07401, lr:6.17e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.033, tt:5170.068\n",
      "Ep:123, loss:0.00000, loss_test:0.07462, lr:6.11e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.040, tt:5213.011\n",
      "Ep:124, loss:0.00000, loss_test:0.07531, lr:6.05e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.045, tt:5255.629\n",
      "Ep:125, loss:0.00000, loss_test:0.07357, lr:5.99e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.053, tt:5298.676\n",
      "Ep:126, loss:0.00000, loss_test:0.07403, lr:5.93e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.059, tt:5341.495\n",
      "Ep:127, loss:0.00000, loss_test:0.07455, lr:5.87e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.063, tt:5384.059\n",
      "Ep:128, loss:0.00000, loss_test:0.07424, lr:5.81e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.062, tt:5426.041\n",
      "Ep:129, loss:0.00000, loss_test:0.07465, lr:5.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.083, tt:5470.780\n",
      "Ep:130, loss:0.00000, loss_test:0.07446, lr:5.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.085, tt:5513.124\n",
      "Ep:131, loss:0.00000, loss_test:0.07446, lr:5.64e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.088, tt:5555.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.07405, lr:5.58e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.089, tt:5597.883\n",
      "Ep:133, loss:0.00000, loss_test:0.07455, lr:5.53e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.081, tt:5638.831\n",
      "Ep:134, loss:0.00000, loss_test:0.07443, lr:5.47e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.078, tt:5680.465\n",
      "Ep:135, loss:0.00000, loss_test:0.07486, lr:5.42e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.081, tt:5722.990\n",
      "Ep:136, loss:0.00000, loss_test:0.07499, lr:5.36e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.074, tt:5764.180\n",
      "Ep:137, loss:0.00000, loss_test:0.07561, lr:5.31e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.073, tt:5806.076\n",
      "Ep:138, loss:0.00000, loss_test:0.07519, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.073, tt:5848.104\n",
      "Ep:139, loss:0.00000, loss_test:0.07508, lr:5.20e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.075, tt:5890.487\n",
      "Ep:140, loss:0.00000, loss_test:0.07588, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.070, tt:5931.826\n",
      "Ep:141, loss:0.00000, loss_test:0.07517, lr:5.10e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.121, tt:5981.134\n",
      "Ep:142, loss:0.00000, loss_test:0.07516, lr:5.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.126, tt:6024.054\n",
      "Ep:143, loss:0.00000, loss_test:0.07610, lr:5.00e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.133, tt:6067.129\n",
      "Ep:144, loss:0.00000, loss_test:0.07552, lr:4.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.132, tt:6109.195\n",
      "Ep:145, loss:0.00000, loss_test:0.07513, lr:4.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.140, tt:6152.377\n",
      "Ep:146, loss:0.00000, loss_test:0.07522, lr:4.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.128, tt:6192.842\n",
      "Ep:147, loss:0.00000, loss_test:0.07580, lr:4.80e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.128, tt:6234.949\n",
      "Ep:148, loss:0.00000, loss_test:0.07569, lr:4.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.141, tt:6278.997\n",
      "Ep:149, loss:0.00000, loss_test:0.07536, lr:4.71e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.153, tt:6322.876\n",
      "Ep:150, loss:0.00000, loss_test:0.07614, lr:4.66e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.147, tt:6364.249\n",
      "Ep:151, loss:0.00000, loss_test:0.07496, lr:4.61e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.149, tt:6406.620\n",
      "Ep:152, loss:0.00000, loss_test:0.07575, lr:4.57e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.159, tt:6450.396\n",
      "Ep:153, loss:0.00000, loss_test:0.07616, lr:4.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.159, tt:6492.423\n",
      "Ep:154, loss:0.00000, loss_test:0.07540, lr:4.48e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.168, tt:6535.985\n",
      "Ep:155, loss:0.00000, loss_test:0.07578, lr:4.43e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.172, tt:6578.788\n",
      "Ep:156, loss:0.00000, loss_test:0.07595, lr:4.39e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.178, tt:6621.994\n",
      "Ep:157, loss:0.00000, loss_test:0.07502, lr:4.34e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.178, tt:6664.162\n",
      "Ep:158, loss:0.00000, loss_test:0.07554, lr:4.30e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.186, tt:6707.549\n",
      "Ep:159, loss:0.00000, loss_test:0.07581, lr:4.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.187, tt:6749.904\n",
      "Ep:160, loss:0.00000, loss_test:0.07514, lr:4.21e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.196, tt:6793.553\n",
      "Ep:161, loss:0.00000, loss_test:0.07600, lr:4.17e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.206, tt:6837.409\n",
      "Ep:162, loss:0.00000, loss_test:0.07610, lr:4.13e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.205, tt:6879.412\n",
      "Ep:163, loss:0.00000, loss_test:0.07502, lr:4.09e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.208, tt:6922.078\n",
      "Ep:164, loss:0.00000, loss_test:0.07582, lr:4.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.231, tt:6968.097\n",
      "Ep:165, loss:0.00000, loss_test:0.07630, lr:4.01e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.225, tt:7009.310\n",
      "Ep:166, loss:0.00000, loss_test:0.07561, lr:3.97e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.236, tt:7053.368\n",
      "Ep:167, loss:0.00000, loss_test:0.07550, lr:3.93e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.241, tt:7096.571\n",
      "Ep:168, loss:0.00000, loss_test:0.07551, lr:3.89e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.243, tt:7139.006\n",
      "Ep:169, loss:0.00000, loss_test:0.07576, lr:3.85e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.241, tt:7180.913\n",
      "Ep:170, loss:0.00000, loss_test:0.07563, lr:3.81e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.243, tt:7223.636\n",
      "Ep:171, loss:0.00000, loss_test:0.07538, lr:3.77e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.239, tt:7265.055\n",
      "Ep:172, loss:0.00000, loss_test:0.07596, lr:3.73e-03, fs:0.76829 (r=0.636,p=0.969),  time:42.241, tt:7307.691\n",
      "Ep:173, loss:0.00000, loss_test:0.07657, lr:3.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.239, tt:7349.617\n",
      "Ep:174, loss:0.00000, loss_test:0.07591, lr:3.66e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.238, tt:7391.645\n",
      "Ep:175, loss:0.00000, loss_test:0.07555, lr:3.62e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.239, tt:7434.084\n",
      "Ep:176, loss:0.00000, loss_test:0.07549, lr:3.59e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.249, tt:7478.058\n",
      "Ep:177, loss:0.00000, loss_test:0.07556, lr:3.55e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.254, tt:7521.124\n",
      "Ep:178, loss:0.00000, loss_test:0.07574, lr:3.52e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.259, tt:7564.312\n",
      "Ep:179, loss:0.00000, loss_test:0.07564, lr:3.48e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.258, tt:7606.431\n",
      "Ep:180, loss:0.00000, loss_test:0.07560, lr:3.45e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.265, tt:7649.913\n",
      "Ep:181, loss:0.00000, loss_test:0.07601, lr:3.41e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.266, tt:7692.404\n",
      "Ep:182, loss:0.00000, loss_test:0.07573, lr:3.38e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.283, tt:7737.793\n",
      "Ep:183, loss:0.00000, loss_test:0.07511, lr:3.34e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.298, tt:7782.833\n",
      "Ep:184, loss:0.00000, loss_test:0.07600, lr:3.31e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.320, tt:7829.127\n",
      "Ep:185, loss:0.00000, loss_test:0.07610, lr:3.28e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.321, tt:7871.670\n",
      "Ep:186, loss:0.00000, loss_test:0.07545, lr:3.24e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.333, tt:7916.322\n",
      "Ep:187, loss:0.00000, loss_test:0.07589, lr:3.21e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.346, tt:7961.121\n",
      "Ep:188, loss:0.00000, loss_test:0.07561, lr:3.18e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.347, tt:8003.496\n",
      "Ep:189, loss:0.00000, loss_test:0.07559, lr:3.15e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.354, tt:8047.203\n",
      "Ep:190, loss:0.00000, loss_test:0.07619, lr:3.12e-03, fs:0.76829 (r=0.636,p=0.969),  time:42.365, tt:8091.730\n",
      "Ep:191, loss:0.00000, loss_test:0.07592, lr:3.09e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.377, tt:8136.364\n",
      "Ep:192, loss:0.00000, loss_test:0.07530, lr:3.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.384, tt:8180.051\n",
      "Ep:193, loss:0.00000, loss_test:0.07562, lr:3.02e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.387, tt:8223.073\n",
      "Ep:194, loss:0.00000, loss_test:0.07602, lr:2.99e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.376, tt:8263.283\n",
      "Ep:195, loss:0.00000, loss_test:0.07605, lr:2.96e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.382, tt:8306.824\n",
      "Ep:196, loss:0.00000, loss_test:0.07607, lr:2.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.414, tt:8355.542\n",
      "Ep:197, loss:0.00000, loss_test:0.07589, lr:2.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.424, tt:8399.872\n",
      "Ep:198, loss:0.00000, loss_test:0.07568, lr:2.88e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.424, tt:8442.461\n",
      "Ep:199, loss:0.00000, loss_test:0.07595, lr:2.85e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.424, tt:8484.801\n",
      "Ep:200, loss:0.00000, loss_test:0.07555, lr:2.82e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.433, tt:8529.122\n",
      "Ep:201, loss:0.00000, loss_test:0.07529, lr:2.79e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.433, tt:8571.508\n",
      "Ep:202, loss:0.00000, loss_test:0.07583, lr:2.76e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.448, tt:8616.862\n",
      "Ep:203, loss:0.00000, loss_test:0.07593, lr:2.73e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.445, tt:8658.716\n",
      "Ep:204, loss:0.00000, loss_test:0.07560, lr:2.71e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.457, tt:8703.775\n",
      "Ep:205, loss:0.00000, loss_test:0.07567, lr:2.68e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.470, tt:8748.887\n",
      "Ep:206, loss:0.00000, loss_test:0.07620, lr:2.65e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.477, tt:8792.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.07593, lr:2.63e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.489, tt:8837.728\n",
      "Ep:208, loss:0.00000, loss_test:0.07558, lr:2.60e-03, fs:0.79042 (r=0.667,p=0.971),  time:42.485, tt:8879.327\n",
      "Ep:209, loss:0.00000, loss_test:0.07564, lr:2.57e-03, fs:0.79762 (r=0.677,p=0.971),  time:42.453, tt:8915.121\n",
      "Ep:210, loss:0.00000, loss_test:0.07572, lr:2.55e-03, fs:0.78313 (r=0.657,p=0.970),  time:42.432, tt:8953.113\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01970, lr:6.00e-02, fs:0.64029 (r=0.899,p=0.497),  time:35.580, tt:35.580\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02290, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.432, tt:76.864\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02388, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.939, tt:119.817\n",
      "Ep:3, loss:0.00005, loss_test:0.02294, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:41.131, tt:164.524\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02135, lr:6.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:41.376, tt:206.880\n",
      "Ep:5, loss:0.00004, loss_test:0.01982, lr:6.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:41.426, tt:248.554\n",
      "Ep:6, loss:0.00004, loss_test:0.01885, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:41.637, tt:291.457\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01831, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:41.996, tt:335.967\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01775, lr:6.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:42.318, tt:380.860\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01723, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:42.459, tt:424.589\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:42.409, tt:466.496\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:42.373, tt:508.472\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:42.852, tt:557.070\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.74380 (r=0.909,p=0.629),  time:42.775, tt:598.853\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01617, lr:6.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:42.657, tt:639.860\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.75439 (r=0.869,p=0.667),  time:42.769, tt:684.306\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01608, lr:6.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:42.735, tt:726.496\n",
      "Ep:17, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:42.780, tt:770.039\n",
      "Ep:18, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:42.774, tt:812.702\n",
      "Ep:19, loss:0.00003, loss_test:0.01631, lr:6.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:42.698, tt:853.955\n",
      "Ep:20, loss:0.00003, loss_test:0.01650, lr:6.00e-02, fs:0.74545 (r=0.828,p=0.678),  time:42.677, tt:896.223\n",
      "Ep:21, loss:0.00002, loss_test:0.01658, lr:6.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:42.664, tt:938.618\n",
      "Ep:22, loss:0.00002, loss_test:0.01654, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:42.621, tt:980.289\n",
      "Ep:23, loss:0.00002, loss_test:0.01651, lr:6.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:42.671, tt:1024.113\n",
      "Ep:24, loss:0.00002, loss_test:0.01650, lr:6.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:42.692, tt:1067.289\n",
      "Ep:25, loss:0.00002, loss_test:0.01644, lr:6.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:42.681, tt:1109.696\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01626, lr:6.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:42.637, tt:1151.206\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:42.630, tt:1193.643\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01622, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:42.621, tt:1236.022\n",
      "Ep:29, loss:0.00002, loss_test:0.01621, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:42.599, tt:1277.961\n",
      "Ep:30, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:42.569, tt:1319.632\n",
      "Ep:31, loss:0.00002, loss_test:0.01613, lr:6.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:42.579, tt:1362.534\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01606, lr:6.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:42.611, tt:1406.150\n",
      "Ep:33, loss:0.00002, loss_test:0.01608, lr:6.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:42.548, tt:1446.622\n",
      "Ep:34, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:42.502, tt:1487.574\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01600, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:42.496, tt:1529.842\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01596, lr:6.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:42.491, tt:1572.166\n",
      "Ep:37, loss:0.00002, loss_test:0.01598, lr:6.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:42.467, tt:1613.728\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:42.514, tt:1658.048\n",
      "Ep:39, loss:0.00002, loss_test:0.01582, lr:6.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:42.476, tt:1699.042\n",
      "Ep:40, loss:0.00002, loss_test:0.01590, lr:6.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:42.418, tt:1739.121\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.361, tt:1779.178\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01589, lr:6.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.357, tt:1821.362\n",
      "Ep:43, loss:0.00001, loss_test:0.01589, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.334, tt:1862.710\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01590, lr:6.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.296, tt:1903.299\n",
      "Ep:45, loss:0.00001, loss_test:0.01591, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.262, tt:1944.054\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01591, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.229, tt:1984.761\n",
      "Ep:47, loss:0.00001, loss_test:0.01594, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.220, tt:2026.582\n",
      "Ep:48, loss:0.00001, loss_test:0.01594, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.213, tt:2068.446\n",
      "Ep:49, loss:0.00001, loss_test:0.01589, lr:6.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:42.160, tt:2107.986\n",
      "Ep:50, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:42.117, tt:2147.980\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01610, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.079, tt:2188.133\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01600, lr:6.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.068, tt:2229.580\n",
      "Ep:53, loss:0.00001, loss_test:0.01608, lr:6.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:42.057, tt:2271.060\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00001, loss_test:0.01617, lr:6.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.024, tt:2311.297\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01610, lr:6.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.028, tt:2353.566\n",
      "Ep:56, loss:0.00001, loss_test:0.01616, lr:6.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.013, tt:2394.733\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01626, lr:6.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.020, tt:2437.163\n",
      "Ep:58, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.033, tt:2479.919\n",
      "Ep:59, loss:0.00001, loss_test:0.01626, lr:6.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.033, tt:2521.972\n",
      "Ep:60, loss:0.00001, loss_test:0.01645, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:42.044, tt:2564.689\n",
      "Ep:61, loss:0.00001, loss_test:0.01638, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:42.029, tt:2605.796\n",
      "Ep:62, loss:0.00001, loss_test:0.01646, lr:6.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:42.020, tt:2647.231\n",
      "Ep:63, loss:0.00001, loss_test:0.01652, lr:6.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:42.046, tt:2690.926\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01667, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.034, tt:2732.180\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01672, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.070, tt:2776.614\n",
      "Ep:66, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.069, tt:2818.597\n",
      "Ep:67, loss:0.00001, loss_test:0.01689, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.073, tt:2860.946\n",
      "Ep:68, loss:0.00001, loss_test:0.01694, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.098, tt:2904.743\n",
      "Ep:69, loss:0.00001, loss_test:0.01700, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.107, tt:2947.485\n",
      "Ep:70, loss:0.00001, loss_test:0.01719, lr:6.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:42.107, tt:2989.615\n",
      "Ep:71, loss:0.00001, loss_test:0.01721, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.117, tt:3032.457\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01729, lr:6.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:42.100, tt:3073.305\n",
      "Ep:73, loss:0.00001, loss_test:0.01740, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.095, tt:3114.994\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01749, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.090, tt:3156.754\n",
      "Ep:75, loss:0.00001, loss_test:0.01766, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.103, tt:3199.793\n",
      "Ep:76, loss:0.00001, loss_test:0.01773, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.103, tt:3241.921\n",
      "Ep:77, loss:0.00001, loss_test:0.01788, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.115, tt:3284.993\n",
      "Ep:78, loss:0.00001, loss_test:0.01791, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.125, tt:3327.892\n",
      "Ep:79, loss:0.00001, loss_test:0.01802, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.131, tt:3370.516\n",
      "Ep:80, loss:0.00001, loss_test:0.01806, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.113, tt:3411.172\n",
      "Ep:81, loss:0.00001, loss_test:0.01808, lr:6.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.130, tt:3454.627\n",
      "Ep:82, loss:0.00001, loss_test:0.01822, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.122, tt:3496.157\n",
      "Ep:83, loss:0.00001, loss_test:0.01830, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.125, tt:3538.515\n",
      "Ep:84, loss:0.00001, loss_test:0.01844, lr:6.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.142, tt:3582.050\n",
      "Ep:85, loss:0.00001, loss_test:0.01846, lr:5.94e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.164, tt:3626.076\n",
      "Ep:86, loss:0.00001, loss_test:0.01850, lr:5.88e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.186, tt:3670.210\n",
      "Ep:87, loss:0.00001, loss_test:0.01866, lr:5.82e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.198, tt:3713.465\n",
      "Ep:88, loss:0.00001, loss_test:0.01871, lr:5.76e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.193, tt:3755.168\n",
      "Ep:89, loss:0.00001, loss_test:0.01886, lr:5.71e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.206, tt:3798.573\n",
      "Ep:90, loss:0.00001, loss_test:0.01898, lr:5.65e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.209, tt:3841.044\n",
      "Ep:91, loss:0.00001, loss_test:0.01916, lr:5.59e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.196, tt:3882.048\n",
      "Ep:92, loss:0.00001, loss_test:0.01913, lr:5.54e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.197, tt:3924.283\n",
      "Ep:93, loss:0.00001, loss_test:0.01934, lr:5.48e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.173, tt:3964.247\n",
      "Ep:94, loss:0.00001, loss_test:0.01943, lr:5.43e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.176, tt:4006.697\n",
      "Ep:95, loss:0.00001, loss_test:0.01945, lr:5.37e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.155, tt:4046.888\n",
      "Ep:96, loss:0.00001, loss_test:0.01971, lr:5.32e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.157, tt:4089.228\n",
      "Ep:97, loss:0.00001, loss_test:0.01970, lr:5.27e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.177, tt:4133.371\n",
      "Ep:98, loss:0.00001, loss_test:0.01985, lr:5.21e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.165, tt:4174.373\n",
      "Ep:99, loss:0.00001, loss_test:0.01999, lr:5.16e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.170, tt:4216.963\n",
      "Ep:100, loss:0.00001, loss_test:0.01994, lr:5.11e-02, fs:0.85870 (r=0.798,p=0.929),  time:42.162, tt:4258.373\n",
      "Ep:101, loss:0.00001, loss_test:0.02008, lr:5.06e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.174, tt:4301.708\n",
      "Ep:102, loss:0.00001, loss_test:0.02014, lr:5.01e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.161, tt:4342.635\n",
      "Ep:103, loss:0.00000, loss_test:0.02031, lr:4.96e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.169, tt:4385.551\n",
      "Ep:104, loss:0.00000, loss_test:0.02041, lr:4.91e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.159, tt:4426.660\n",
      "Ep:105, loss:0.00000, loss_test:0.02047, lr:4.86e-02, fs:0.86339 (r=0.798,p=0.940),  time:42.167, tt:4469.671\n",
      "Ep:106, loss:0.00000, loss_test:0.02063, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.158, tt:4510.905\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00000, loss_test:0.02073, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.166, tt:4553.903\n",
      "Ep:108, loss:0.00000, loss_test:0.02080, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.147, tt:4593.994\n",
      "Ep:109, loss:0.00000, loss_test:0.02086, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.157, tt:4637.273\n",
      "Ep:110, loss:0.00000, loss_test:0.02101, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.150, tt:4678.696\n",
      "Ep:111, loss:0.00000, loss_test:0.02104, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.155, tt:4721.311\n",
      "Ep:112, loss:0.00000, loss_test:0.02122, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.136, tt:4761.350\n",
      "Ep:113, loss:0.00000, loss_test:0.02132, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.130, tt:4802.870\n",
      "Ep:114, loss:0.00000, loss_test:0.02150, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.113, tt:4842.964\n",
      "Ep:115, loss:0.00000, loss_test:0.02154, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.104, tt:4884.023\n",
      "Ep:116, loss:0.00000, loss_test:0.02158, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.067, tt:4921.872\n",
      "Ep:117, loss:0.00000, loss_test:0.02175, lr:4.81e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.036, tt:4960.203\n",
      "Ep:118, loss:0.00000, loss_test:0.02188, lr:4.76e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.027, tt:5001.206\n",
      "Ep:119, loss:0.00000, loss_test:0.02195, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:42.016, tt:5041.940\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00000, loss_test:0.02205, lr:4.71e-02, fs:0.86813 (r=0.798,p=0.952),  time:42.013, tt:5083.540\n",
      "Ep:121, loss:0.00000, loss_test:0.02213, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.988, tt:5122.536\n",
      "Ep:122, loss:0.00000, loss_test:0.02224, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.976, tt:5163.007\n",
      "Ep:123, loss:0.00000, loss_test:0.02235, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.966, tt:5203.774\n",
      "Ep:124, loss:0.00000, loss_test:0.02247, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.953, tt:5244.149\n",
      "Ep:125, loss:0.00000, loss_test:0.02254, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.942, tt:5284.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.02264, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.927, tt:5324.782\n",
      "Ep:127, loss:0.00000, loss_test:0.02278, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.917, tt:5365.371\n",
      "Ep:128, loss:0.00000, loss_test:0.02287, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.910, tt:5406.442\n",
      "Ep:129, loss:0.00000, loss_test:0.02295, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.895, tt:5446.292\n",
      "Ep:130, loss:0.00000, loss_test:0.02296, lr:4.71e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.880, tt:5486.316\n",
      "Ep:131, loss:0.00000, loss_test:0.02312, lr:4.67e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.865, tt:5526.227\n",
      "Ep:132, loss:0.00000, loss_test:0.02324, lr:4.62e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.862, tt:5567.639\n",
      "Ep:133, loss:0.00000, loss_test:0.02334, lr:4.57e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.840, tt:5606.590\n",
      "Ep:134, loss:0.00000, loss_test:0.02342, lr:4.53e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.827, tt:5646.703\n",
      "Ep:135, loss:0.00000, loss_test:0.02354, lr:4.48e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.826, tt:5688.329\n",
      "Ep:136, loss:0.00000, loss_test:0.02359, lr:4.44e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.826, tt:5730.201\n",
      "Ep:137, loss:0.00000, loss_test:0.02372, lr:4.39e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.817, tt:5770.683\n",
      "Ep:138, loss:0.00000, loss_test:0.02382, lr:4.35e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.800, tt:5810.262\n",
      "Ep:139, loss:0.00000, loss_test:0.02395, lr:4.31e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.795, tt:5851.300\n",
      "Ep:140, loss:0.00000, loss_test:0.02403, lr:4.26e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.797, tt:5893.387\n",
      "Ep:141, loss:0.00000, loss_test:0.02414, lr:4.22e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.784, tt:5933.298\n",
      "Ep:142, loss:0.00000, loss_test:0.02418, lr:4.18e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.764, tt:5972.297\n",
      "Ep:143, loss:0.00000, loss_test:0.02427, lr:4.14e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.746, tt:6011.488\n",
      "Ep:144, loss:0.00000, loss_test:0.02430, lr:4.10e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.742, tt:6052.646\n",
      "Ep:145, loss:0.00000, loss_test:0.02438, lr:4.05e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.731, tt:6092.692\n",
      "Ep:146, loss:0.00000, loss_test:0.02444, lr:4.01e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.716, tt:6132.255\n",
      "Ep:147, loss:0.00000, loss_test:0.02455, lr:3.97e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.706, tt:6172.527\n",
      "Ep:148, loss:0.00000, loss_test:0.02469, lr:3.93e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.705, tt:6214.030\n",
      "Ep:149, loss:0.00000, loss_test:0.02473, lr:3.89e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.699, tt:6254.783\n",
      "Ep:150, loss:0.00000, loss_test:0.02479, lr:3.86e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.696, tt:6296.037\n",
      "Ep:151, loss:0.00000, loss_test:0.02489, lr:3.82e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.682, tt:6335.640\n",
      "Ep:152, loss:0.00000, loss_test:0.02498, lr:3.78e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.663, tt:6374.424\n",
      "Ep:153, loss:0.00000, loss_test:0.02503, lr:3.74e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.667, tt:6416.711\n",
      "Ep:154, loss:0.00000, loss_test:0.02514, lr:3.70e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.658, tt:6456.935\n",
      "Ep:155, loss:0.00000, loss_test:0.02524, lr:3.67e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.691, tt:6503.812\n",
      "Ep:156, loss:0.00000, loss_test:0.02531, lr:3.63e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.699, tt:6546.707\n",
      "Ep:157, loss:0.00000, loss_test:0.02532, lr:3.59e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.694, tt:6587.666\n",
      "Ep:158, loss:0.00000, loss_test:0.02543, lr:3.56e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.704, tt:6630.975\n",
      "Ep:159, loss:0.00000, loss_test:0.02552, lr:3.52e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.694, tt:6671.100\n",
      "Ep:160, loss:0.00000, loss_test:0.02558, lr:3.49e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.686, tt:6711.369\n",
      "Ep:161, loss:0.00000, loss_test:0.02566, lr:3.45e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.685, tt:6752.987\n",
      "Ep:162, loss:0.00000, loss_test:0.02573, lr:3.42e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.678, tt:6793.461\n",
      "Ep:163, loss:0.00000, loss_test:0.02578, lr:3.38e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.670, tt:6833.883\n",
      "Ep:164, loss:0.00000, loss_test:0.02582, lr:3.35e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.666, tt:6874.895\n",
      "Ep:165, loss:0.00000, loss_test:0.02593, lr:3.32e-02, fs:0.87293 (r=0.798,p=0.963),  time:41.661, tt:6915.693\n",
      "Ep:166, loss:0.00000, loss_test:0.02601, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.645, tt:6954.668\n",
      "##########Best model found so far##########\n",
      "Ep:167, loss:0.00000, loss_test:0.02603, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.635, tt:6994.630\n",
      "Ep:168, loss:0.00000, loss_test:0.02611, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.632, tt:7035.813\n",
      "Ep:169, loss:0.00000, loss_test:0.02625, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.626, tt:7076.472\n",
      "Ep:170, loss:0.00000, loss_test:0.02630, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.622, tt:7117.303\n",
      "Ep:171, loss:0.00000, loss_test:0.02633, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.610, tt:7156.890\n",
      "Ep:172, loss:0.00000, loss_test:0.02639, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.607, tt:7198.016\n",
      "Ep:173, loss:0.00000, loss_test:0.02645, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.610, tt:7240.090\n",
      "Ep:174, loss:0.00000, loss_test:0.02653, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.601, tt:7280.093\n",
      "Ep:175, loss:0.00000, loss_test:0.02659, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.584, tt:7318.764\n",
      "Ep:176, loss:0.00000, loss_test:0.02664, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.597, tt:7362.586\n",
      "Ep:177, loss:0.00000, loss_test:0.02675, lr:3.28e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.586, tt:7402.266\n",
      "Ep:178, loss:0.00000, loss_test:0.02680, lr:3.25e-02, fs:0.87778 (r=0.798,p=0.975),  time:41.575, tt:7441.897\n",
      "Ep:179, loss:0.00000, loss_test:0.02688, lr:3.22e-02, fs:0.88268 (r=0.798,p=0.988),  time:41.574, tt:7483.244\n",
      "##########Best model found so far##########\n",
      "Ep:180, loss:0.00000, loss_test:0.02695, lr:3.22e-02, fs:0.88268 (r=0.798,p=0.988),  time:41.565, tt:7523.281\n",
      "Ep:181, loss:0.00000, loss_test:0.02700, lr:3.22e-02, fs:0.88268 (r=0.798,p=0.988),  time:41.550, tt:7562.173\n",
      "Ep:182, loss:0.00000, loss_test:0.02708, lr:3.22e-02, fs:0.88268 (r=0.798,p=0.988),  time:41.535, tt:7600.918\n",
      "Ep:183, loss:0.00000, loss_test:0.02714, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.524, tt:7640.446\n",
      "Ep:184, loss:0.00000, loss_test:0.02716, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.505, tt:7678.416\n",
      "Ep:185, loss:0.00000, loss_test:0.02723, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.498, tt:7718.654\n",
      "Ep:186, loss:0.00000, loss_test:0.02731, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.489, tt:7758.365\n",
      "Ep:187, loss:0.00000, loss_test:0.02739, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.485, tt:7799.263\n",
      "Ep:188, loss:0.00000, loss_test:0.02744, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.479, tt:7839.570\n",
      "Ep:189, loss:0.00000, loss_test:0.02751, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.477, tt:7880.708\n",
      "Ep:190, loss:0.00000, loss_test:0.02759, lr:3.22e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.473, tt:7921.276\n",
      "Ep:191, loss:0.00000, loss_test:0.02764, lr:3.19e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.470, tt:7962.182\n",
      "Ep:192, loss:0.00000, loss_test:0.02770, lr:3.15e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.461, tt:8001.914\n",
      "Ep:193, loss:0.00000, loss_test:0.02774, lr:3.12e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.448, tt:8040.822\n",
      "Ep:194, loss:0.00000, loss_test:0.02779, lr:3.09e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.446, tt:8081.929\n",
      "Ep:195, loss:0.00000, loss_test:0.02778, lr:3.06e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.442, tt:8122.716\n",
      "Ep:196, loss:0.00000, loss_test:0.02788, lr:3.03e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.441, tt:8163.924\n",
      "Ep:197, loss:0.00000, loss_test:0.02796, lr:3.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.478, tt:8212.741\n",
      "Ep:198, loss:0.00000, loss_test:0.02800, lr:2.97e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.480, tt:8254.473\n",
      "Ep:199, loss:0.00000, loss_test:0.02812, lr:2.94e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.478, tt:8295.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00000, loss_test:0.02813, lr:2.91e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.474, tt:8336.307\n",
      "Ep:201, loss:0.00000, loss_test:0.02816, lr:2.88e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.461, tt:8375.184\n",
      "Ep:202, loss:0.00000, loss_test:0.02823, lr:2.85e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.457, tt:8415.863\n",
      "Ep:203, loss:0.00000, loss_test:0.02830, lr:2.82e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.451, tt:8456.076\n",
      "Ep:204, loss:0.00000, loss_test:0.02833, lr:2.80e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.444, tt:8496.011\n",
      "Ep:205, loss:0.00000, loss_test:0.02834, lr:2.77e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.439, tt:8536.393\n",
      "Ep:206, loss:0.00000, loss_test:0.02842, lr:2.74e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.435, tt:8577.059\n",
      "Ep:207, loss:0.00000, loss_test:0.02847, lr:2.71e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.430, tt:8617.426\n",
      "Ep:208, loss:0.00000, loss_test:0.02853, lr:2.69e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.424, tt:8657.620\n",
      "Ep:209, loss:0.00000, loss_test:0.02856, lr:2.66e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.411, tt:8696.215\n",
      "Ep:210, loss:0.00000, loss_test:0.02861, lr:2.63e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.381, tt:8731.455\n",
      "Ep:211, loss:0.00000, loss_test:0.02864, lr:2.61e-02, fs:0.87640 (r=0.788,p=0.987),  time:41.361, tt:8768.637\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14123, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.264, tt:31.264\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13933, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.124, tt:64.248\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13569, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.456, tt:106.367\n",
      "Ep:3, loss:0.00026, loss_test:0.12906, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:36.706, tt:146.822\n",
      "Ep:4, loss:0.00025, loss_test:0.11913, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:37.624, tt:188.121\n",
      "Ep:5, loss:0.00024, loss_test:0.11262, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:38.255, tt:229.527\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11198, lr:1.00e-02, fs:0.66990 (r=0.697,p=0.645),  time:38.792, tt:271.547\n",
      "Ep:7, loss:0.00022, loss_test:0.10931, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:39.144, tt:313.150\n",
      "Ep:8, loss:0.00021, loss_test:0.10740, lr:1.00e-02, fs:0.70270 (r=0.788,p=0.634),  time:39.361, tt:354.250\n",
      "Ep:9, loss:0.00020, loss_test:0.10313, lr:1.00e-02, fs:0.69194 (r=0.737,p=0.652),  time:39.612, tt:396.122\n",
      "Ep:10, loss:0.00020, loss_test:0.10133, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:39.856, tt:438.418\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09945, lr:1.00e-02, fs:0.71963 (r=0.778,p=0.670),  time:39.921, tt:479.048\n",
      "Ep:12, loss:0.00018, loss_test:0.09862, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:40.029, tt:520.380\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09725, lr:1.00e-02, fs:0.73892 (r=0.758,p=0.721),  time:40.211, tt:562.954\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09508, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:40.373, tt:605.601\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09417, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:40.441, tt:647.049\n",
      "Ep:16, loss:0.00016, loss_test:0.09357, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:40.589, tt:690.017\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09277, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:40.631, tt:731.354\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09147, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:40.672, tt:772.777\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09062, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:40.681, tt:813.616\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08883, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:40.706, tt:854.826\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08784, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:40.741, tt:896.309\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08634, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:40.758, tt:937.433\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08555, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:40.813, tt:979.512\n",
      "Ep:24, loss:0.00012, loss_test:0.08465, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:40.910, tt:1022.762\n",
      "Ep:25, loss:0.00011, loss_test:0.08417, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:40.870, tt:1062.625\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.08324, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:40.949, tt:1105.631\n",
      "Ep:27, loss:0.00011, loss_test:0.08220, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:40.993, tt:1147.793\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.08244, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:40.991, tt:1188.729\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08100, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:40.989, tt:1229.684\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.08035, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.044, tt:1272.356\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08016, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:41.108, tt:1315.441\n",
      "Ep:32, loss:0.00009, loss_test:0.07958, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.158, tt:1358.200\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07881, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:41.192, tt:1400.517\n",
      "Ep:34, loss:0.00008, loss_test:0.07776, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:41.252, tt:1443.827\n",
      "Ep:35, loss:0.00008, loss_test:0.07882, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.218, tt:1483.866\n",
      "Ep:36, loss:0.00008, loss_test:0.07800, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.233, tt:1525.617\n",
      "Ep:37, loss:0.00007, loss_test:0.07615, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:41.313, tt:1569.880\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.08013, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.325, tt:1611.687\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.07694, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:41.324, tt:1652.952\n",
      "Ep:40, loss:0.00007, loss_test:0.07654, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.362, tt:1695.836\n",
      "Ep:41, loss:0.00006, loss_test:0.07652, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.359, tt:1737.064\n",
      "Ep:42, loss:0.00006, loss_test:0.07670, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.328, tt:1777.101\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.07452, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.362, tt:1819.908\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.07377, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.365, tt:1861.427\n",
      "Ep:45, loss:0.00006, loss_test:0.07925, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.354, tt:1902.280\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00005, loss_test:0.07343, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.310, tt:1941.557\n",
      "Ep:47, loss:0.00005, loss_test:0.07475, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:41.334, tt:1984.051\n",
      "Ep:48, loss:0.00005, loss_test:0.07455, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.273, tt:2022.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00005, loss_test:0.07269, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.280, tt:2063.983\n",
      "Ep:50, loss:0.00005, loss_test:0.07218, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.289, tt:2105.757\n",
      "Ep:51, loss:0.00004, loss_test:0.07260, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:41.276, tt:2146.328\n",
      "Ep:52, loss:0.00004, loss_test:0.07303, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.274, tt:2187.519\n",
      "Ep:53, loss:0.00004, loss_test:0.07192, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.279, tt:2229.051\n",
      "Ep:54, loss:0.00004, loss_test:0.07451, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.301, tt:2271.575\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.07228, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.334, tt:2314.729\n",
      "Ep:56, loss:0.00004, loss_test:0.07345, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.364, tt:2357.746\n",
      "Ep:57, loss:0.00004, loss_test:0.07407, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:41.396, tt:2400.979\n",
      "Ep:58, loss:0.00004, loss_test:0.07053, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:41.460, tt:2446.138\n",
      "Ep:59, loss:0.00003, loss_test:0.07481, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.455, tt:2487.289\n",
      "Ep:60, loss:0.00003, loss_test:0.07255, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:41.452, tt:2528.560\n",
      "Ep:61, loss:0.00003, loss_test:0.07318, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.474, tt:2571.394\n",
      "Ep:62, loss:0.00003, loss_test:0.07346, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.475, tt:2612.942\n",
      "Ep:63, loss:0.00003, loss_test:0.07201, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.488, tt:2655.252\n",
      "Ep:64, loss:0.00003, loss_test:0.07264, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:41.504, tt:2697.779\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.07374, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.513, tt:2739.879\n",
      "Ep:66, loss:0.00003, loss_test:0.07466, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:41.506, tt:2780.908\n",
      "Ep:67, loss:0.00002, loss_test:0.07268, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:41.504, tt:2822.251\n",
      "Ep:68, loss:0.00002, loss_test:0.07422, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:41.520, tt:2864.846\n",
      "Ep:69, loss:0.00002, loss_test:0.07170, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:41.520, tt:2906.386\n",
      "Ep:70, loss:0.00002, loss_test:0.07393, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.504, tt:2946.758\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.07080, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.461, tt:2985.211\n",
      "Ep:72, loss:0.00002, loss_test:0.07373, lr:1.00e-02, fs:0.88525 (r=0.818,p=0.964),  time:41.451, tt:3025.926\n",
      "Ep:73, loss:0.00002, loss_test:0.07177, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.471, tt:3068.853\n",
      "Ep:74, loss:0.00002, loss_test:0.07183, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.449, tt:3108.681\n",
      "Ep:75, loss:0.00002, loss_test:0.07268, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.469, tt:3151.632\n",
      "Ep:76, loss:0.00002, loss_test:0.07153, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:41.467, tt:3192.976\n",
      "Ep:77, loss:0.00002, loss_test:0.07118, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.459, tt:3233.830\n",
      "Ep:78, loss:0.00001, loss_test:0.07233, lr:1.00e-02, fs:0.89617 (r=0.828,p=0.976),  time:41.453, tt:3274.815\n",
      "Ep:79, loss:0.00001, loss_test:0.07056, lr:1.00e-02, fs:0.89840 (r=0.848,p=0.955),  time:41.434, tt:3314.687\n",
      "Ep:80, loss:0.00001, loss_test:0.07352, lr:1.00e-02, fs:0.83908 (r=0.737,p=0.973),  time:41.432, tt:3355.962\n",
      "Ep:81, loss:0.00001, loss_test:0.07090, lr:1.00e-02, fs:0.90323 (r=0.848,p=0.966),  time:41.433, tt:3397.501\n",
      "Ep:82, loss:0.00001, loss_test:0.07604, lr:9.90e-03, fs:0.90217 (r=0.838,p=0.976),  time:41.432, tt:3438.828\n",
      "Ep:83, loss:0.00001, loss_test:0.07048, lr:9.80e-03, fs:0.90323 (r=0.848,p=0.966),  time:41.423, tt:3479.573\n",
      "Ep:84, loss:0.00001, loss_test:0.07703, lr:9.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.431, tt:3521.644\n",
      "Ep:85, loss:0.00001, loss_test:0.07301, lr:9.61e-03, fs:0.90811 (r=0.848,p=0.977),  time:41.420, tt:3562.111\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.07369, lr:9.61e-03, fs:0.84091 (r=0.747,p=0.961),  time:41.424, tt:3603.924\n",
      "Ep:87, loss:0.00001, loss_test:0.07579, lr:9.61e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.414, tt:3644.435\n",
      "Ep:88, loss:0.00001, loss_test:0.07045, lr:9.61e-03, fs:0.90323 (r=0.848,p=0.966),  time:41.408, tt:3685.294\n",
      "Ep:89, loss:0.00001, loss_test:0.07491, lr:9.61e-03, fs:0.84393 (r=0.737,p=0.986),  time:41.414, tt:3727.260\n",
      "Ep:90, loss:0.00001, loss_test:0.07111, lr:9.61e-03, fs:0.90323 (r=0.848,p=0.966),  time:41.401, tt:3767.450\n",
      "Ep:91, loss:0.00001, loss_test:0.07231, lr:9.61e-03, fs:0.81871 (r=0.707,p=0.972),  time:41.406, tt:3809.339\n",
      "Ep:92, loss:0.00001, loss_test:0.07375, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.406, tt:3850.778\n",
      "Ep:93, loss:0.00001, loss_test:0.07182, lr:9.61e-03, fs:0.88525 (r=0.818,p=0.964),  time:41.386, tt:3890.299\n",
      "Ep:94, loss:0.00001, loss_test:0.07175, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.372, tt:3930.354\n",
      "Ep:95, loss:0.00001, loss_test:0.07150, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.360, tt:3970.516\n",
      "Ep:96, loss:0.00001, loss_test:0.07010, lr:9.61e-03, fs:0.91304 (r=0.848,p=0.988),  time:41.363, tt:4012.247\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.07187, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.364, tt:4053.708\n",
      "Ep:98, loss:0.00001, loss_test:0.07198, lr:9.61e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.363, tt:4094.911\n",
      "Ep:99, loss:0.00001, loss_test:0.07006, lr:9.61e-03, fs:0.91304 (r=0.848,p=0.988),  time:41.360, tt:4135.991\n",
      "Ep:100, loss:0.00001, loss_test:0.07312, lr:9.61e-03, fs:0.87006 (r=0.778,p=0.987),  time:41.360, tt:4177.331\n",
      "Ep:101, loss:0.00001, loss_test:0.06989, lr:9.61e-03, fs:0.91304 (r=0.848,p=0.988),  time:41.376, tt:4220.338\n",
      "Ep:102, loss:0.00001, loss_test:0.07394, lr:9.61e-03, fs:0.83041 (r=0.717,p=0.986),  time:41.356, tt:4259.697\n",
      "Ep:103, loss:0.00001, loss_test:0.07189, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.354, tt:4300.809\n",
      "Ep:104, loss:0.00001, loss_test:0.07233, lr:9.61e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.344, tt:4341.173\n",
      "Ep:105, loss:0.00001, loss_test:0.07275, lr:9.61e-03, fs:0.84393 (r=0.737,p=0.986),  time:41.352, tt:4383.291\n",
      "Ep:106, loss:0.00001, loss_test:0.06941, lr:9.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.338, tt:4423.151\n",
      "Ep:107, loss:0.00001, loss_test:0.07231, lr:9.61e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.333, tt:4463.922\n",
      "Ep:108, loss:0.00001, loss_test:0.07136, lr:9.51e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.333, tt:4505.328\n",
      "Ep:109, loss:0.00001, loss_test:0.07201, lr:9.41e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.312, tt:4544.358\n",
      "Ep:110, loss:0.00001, loss_test:0.06986, lr:9.32e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.321, tt:4586.657\n",
      "Ep:111, loss:0.00000, loss_test:0.07150, lr:9.23e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.319, tt:4627.748\n",
      "Ep:112, loss:0.00000, loss_test:0.07101, lr:9.14e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.300, tt:4666.868\n",
      "Ep:113, loss:0.00000, loss_test:0.07131, lr:9.04e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.296, tt:4707.799\n",
      "Ep:114, loss:0.00000, loss_test:0.07078, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.304, tt:4749.947\n",
      "Ep:115, loss:0.00000, loss_test:0.07160, lr:8.86e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.303, tt:4791.158\n",
      "Ep:116, loss:0.00000, loss_test:0.06923, lr:8.78e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.283, tt:4830.097\n",
      "Ep:117, loss:0.00000, loss_test:0.07296, lr:8.69e-03, fs:0.87006 (r=0.778,p=0.987),  time:41.285, tt:4871.684\n",
      "Ep:118, loss:0.00000, loss_test:0.06944, lr:8.60e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.280, tt:4912.379\n",
      "Ep:119, loss:0.00000, loss_test:0.07345, lr:8.51e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.262, tt:4951.442\n",
      "Ep:120, loss:0.00000, loss_test:0.07020, lr:8.43e-03, fs:0.90710 (r=0.838,p=0.988),  time:41.250, tt:4991.241\n",
      "Ep:121, loss:0.00000, loss_test:0.07231, lr:8.35e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.240, tt:5031.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00000, loss_test:0.07108, lr:8.26e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.254, tt:5074.261\n",
      "Ep:123, loss:0.00000, loss_test:0.07094, lr:8.18e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.268, tt:5117.217\n",
      "Ep:124, loss:0.00000, loss_test:0.07048, lr:8.10e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.275, tt:5159.344\n",
      "Ep:125, loss:0.00000, loss_test:0.07205, lr:8.02e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.277, tt:5200.887\n",
      "Ep:126, loss:0.00000, loss_test:0.06995, lr:7.94e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.321, tt:5247.758\n",
      "Ep:127, loss:0.00000, loss_test:0.07163, lr:7.86e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.316, tt:5288.440\n",
      "Ep:128, loss:0.00000, loss_test:0.07076, lr:7.78e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.330, tt:5331.547\n",
      "Ep:129, loss:0.00000, loss_test:0.07083, lr:7.70e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.343, tt:5374.534\n",
      "Ep:130, loss:0.00000, loss_test:0.07076, lr:7.62e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.339, tt:5415.458\n",
      "Ep:131, loss:0.00000, loss_test:0.07017, lr:7.55e-03, fs:0.89503 (r=0.818,p=0.988),  time:41.349, tt:5458.096\n",
      "Ep:132, loss:0.00000, loss_test:0.07021, lr:7.47e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.346, tt:5499.049\n",
      "Ep:133, loss:0.00000, loss_test:0.07132, lr:7.40e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.342, tt:5539.881\n",
      "Ep:134, loss:0.00000, loss_test:0.07112, lr:7.32e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.329, tt:5579.369\n",
      "Ep:135, loss:0.00000, loss_test:0.07044, lr:7.25e-03, fs:0.90110 (r=0.828,p=0.988),  time:41.313, tt:5618.560\n",
      "Ep:136, loss:0.00000, loss_test:0.07147, lr:7.18e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.311, tt:5659.611\n",
      "Ep:137, loss:0.00000, loss_test:0.07137, lr:7.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.306, tt:5700.179\n",
      "Ep:138, loss:0.00000, loss_test:0.07052, lr:7.03e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.312, tt:5742.315\n",
      "Ep:139, loss:0.00000, loss_test:0.07128, lr:6.96e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.312, tt:5783.710\n",
      "Ep:140, loss:0.00000, loss_test:0.07061, lr:6.89e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.312, tt:5825.035\n",
      "Ep:141, loss:0.00000, loss_test:0.07019, lr:6.83e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.313, tt:5866.493\n",
      "Ep:142, loss:0.00000, loss_test:0.07045, lr:6.76e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.312, tt:5907.608\n",
      "Ep:143, loss:0.00000, loss_test:0.07033, lr:6.69e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.304, tt:5947.723\n",
      "Ep:144, loss:0.00000, loss_test:0.07083, lr:6.62e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.288, tt:5986.818\n",
      "Ep:145, loss:0.00000, loss_test:0.07115, lr:6.56e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.265, tt:6024.720\n",
      "Ep:146, loss:0.00000, loss_test:0.07024, lr:6.49e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.298, tt:6070.742\n",
      "Ep:147, loss:0.00000, loss_test:0.07170, lr:6.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.290, tt:6110.869\n",
      "Ep:148, loss:0.00000, loss_test:0.07061, lr:6.36e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.282, tt:6150.961\n",
      "Ep:149, loss:0.00000, loss_test:0.07017, lr:6.30e-03, fs:0.88889 (r=0.808,p=0.988),  time:41.299, tt:6194.903\n",
      "Ep:150, loss:0.00000, loss_test:0.07135, lr:6.24e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.289, tt:6234.650\n",
      "Ep:151, loss:0.00000, loss_test:0.07083, lr:6.17e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.281, tt:6274.637\n",
      "Ep:152, loss:0.00000, loss_test:0.07040, lr:6.11e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.282, tt:6316.207\n",
      "Ep:153, loss:0.00000, loss_test:0.07023, lr:6.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.266, tt:6354.914\n",
      "Ep:154, loss:0.00000, loss_test:0.07016, lr:5.99e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.266, tt:6396.154\n",
      "Ep:155, loss:0.00000, loss_test:0.07044, lr:5.93e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.254, tt:6435.617\n",
      "Ep:156, loss:0.00000, loss_test:0.07021, lr:5.87e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.257, tt:6477.333\n",
      "Ep:157, loss:0.00000, loss_test:0.07040, lr:5.81e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.250, tt:6517.512\n",
      "Ep:158, loss:0.00000, loss_test:0.07071, lr:5.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:41.247, tt:6558.265\n",
      "Ep:159, loss:0.00000, loss_test:0.07100, lr:5.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.244, tt:6599.048\n",
      "Ep:160, loss:0.00000, loss_test:0.07041, lr:5.64e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.234, tt:6638.747\n",
      "Ep:161, loss:0.00000, loss_test:0.06995, lr:5.58e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.234, tt:6679.842\n",
      "Ep:162, loss:0.00000, loss_test:0.07080, lr:5.53e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.226, tt:6719.817\n",
      "Ep:163, loss:0.00000, loss_test:0.07047, lr:5.47e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.231, tt:6761.855\n",
      "Ep:164, loss:0.00000, loss_test:0.07002, lr:5.42e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.232, tt:6803.213\n",
      "Ep:165, loss:0.00000, loss_test:0.07060, lr:5.36e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.236, tt:6845.220\n",
      "Ep:166, loss:0.00000, loss_test:0.07015, lr:5.31e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.238, tt:6886.736\n",
      "Ep:167, loss:0.00000, loss_test:0.07014, lr:5.26e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.233, tt:6927.094\n",
      "Ep:168, loss:0.00000, loss_test:0.07029, lr:5.20e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.228, tt:6967.554\n",
      "Ep:169, loss:0.00000, loss_test:0.06984, lr:5.15e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.226, tt:7008.409\n",
      "Ep:170, loss:0.00000, loss_test:0.07073, lr:5.10e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.220, tt:7048.582\n",
      "Ep:171, loss:0.00000, loss_test:0.07058, lr:5.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.234, tt:7092.275\n",
      "Ep:172, loss:0.00000, loss_test:0.06976, lr:5.00e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.217, tt:7130.591\n",
      "Ep:173, loss:0.00000, loss_test:0.07006, lr:4.95e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.214, tt:7171.269\n",
      "Ep:174, loss:0.00000, loss_test:0.07017, lr:4.90e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.204, tt:7210.745\n",
      "Ep:175, loss:0.00000, loss_test:0.06941, lr:4.85e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.213, tt:7253.403\n",
      "Ep:176, loss:0.00000, loss_test:0.07066, lr:4.80e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.209, tt:7294.007\n",
      "Ep:177, loss:0.00000, loss_test:0.07007, lr:4.75e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.216, tt:7336.494\n",
      "Ep:178, loss:0.00000, loss_test:0.07033, lr:4.71e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.219, tt:7378.115\n",
      "Ep:179, loss:0.00000, loss_test:0.07118, lr:4.66e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.211, tt:7417.925\n",
      "Ep:180, loss:0.00000, loss_test:0.07024, lr:4.61e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.217, tt:7460.328\n",
      "Ep:181, loss:0.00000, loss_test:0.07025, lr:4.57e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.231, tt:7503.971\n",
      "Ep:182, loss:0.00000, loss_test:0.07045, lr:4.52e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.234, tt:7545.766\n",
      "Ep:183, loss:0.00000, loss_test:0.06995, lr:4.48e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.235, tt:7587.324\n",
      "Ep:184, loss:0.00000, loss_test:0.07007, lr:4.43e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.231, tt:7627.665\n",
      "Ep:185, loss:0.00000, loss_test:0.07051, lr:4.39e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.234, tt:7669.542\n",
      "Ep:186, loss:0.00000, loss_test:0.07000, lr:4.34e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.229, tt:7709.825\n",
      "Ep:187, loss:0.00000, loss_test:0.06996, lr:4.30e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.217, tt:7748.807\n",
      "Ep:188, loss:0.00000, loss_test:0.07055, lr:4.26e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.220, tt:7790.541\n",
      "Ep:189, loss:0.00000, loss_test:0.07003, lr:4.21e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.218, tt:7831.436\n",
      "Ep:190, loss:0.00000, loss_test:0.06991, lr:4.17e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.212, tt:7871.527\n",
      "Ep:191, loss:0.00000, loss_test:0.06982, lr:4.13e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.217, tt:7913.738\n",
      "Ep:192, loss:0.00000, loss_test:0.07056, lr:4.09e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.204, tt:7952.425\n",
      "Ep:193, loss:0.00000, loss_test:0.07023, lr:4.05e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.205, tt:7993.808\n",
      "Ep:194, loss:0.00000, loss_test:0.06985, lr:4.01e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.211, tt:8036.051\n",
      "Ep:195, loss:0.00000, loss_test:0.06974, lr:3.97e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.220, tt:8079.061\n",
      "Ep:196, loss:0.00000, loss_test:0.06970, lr:3.93e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.214, tt:8119.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.06958, lr:3.89e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.219, tt:8161.373\n",
      "Ep:198, loss:0.00000, loss_test:0.07006, lr:3.85e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.223, tt:8203.415\n",
      "Ep:199, loss:0.00000, loss_test:0.06996, lr:3.81e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.228, tt:8245.518\n",
      "Ep:200, loss:0.00000, loss_test:0.07010, lr:3.77e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.240, tt:8289.332\n",
      "Ep:201, loss:0.00000, loss_test:0.06993, lr:3.73e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.252, tt:8332.883\n",
      "Ep:202, loss:0.00000, loss_test:0.06989, lr:3.70e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.262, tt:8376.221\n",
      "Ep:203, loss:0.00000, loss_test:0.06975, lr:3.66e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.266, tt:8418.277\n",
      "Ep:204, loss:0.00000, loss_test:0.07019, lr:3.62e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.275, tt:8461.275\n",
      "Ep:205, loss:0.00000, loss_test:0.07074, lr:3.59e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.278, tt:8503.222\n",
      "Ep:206, loss:0.00000, loss_test:0.07025, lr:3.55e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.287, tt:8546.469\n",
      "Ep:207, loss:0.00000, loss_test:0.06971, lr:3.52e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.300, tt:8590.480\n",
      "Ep:208, loss:0.00000, loss_test:0.06982, lr:3.48e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.297, tt:8631.040\n",
      "Ep:209, loss:0.00000, loss_test:0.07010, lr:3.45e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.258, tt:8664.211\n",
      "Ep:210, loss:0.00000, loss_test:0.06988, lr:3.41e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.198, tt:8692.727\n",
      "Ep:211, loss:0.00000, loss_test:0.06963, lr:3.38e-03, fs:0.88268 (r=0.798,p=0.988),  time:41.098, tt:8712.757\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01967, lr:6.00e-02, fs:0.65812 (r=0.885,p=0.524),  time:16.922, tt:16.922\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02199, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.455, tt:40.910\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02279, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.614, tt:73.842\n",
      "Ep:3, loss:0.00004, loss_test:0.02186, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.154, tt:112.617\n",
      "Ep:4, loss:0.00004, loss_test:0.02040, lr:6.00e-02, fs:0.68254 (r=0.989,p=0.521),  time:30.954, tt:154.771\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01932, lr:6.00e-02, fs:0.68908 (r=0.943,p=0.543),  time:32.258, tt:193.547\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01907, lr:6.00e-02, fs:0.67299 (r=0.816,p=0.573),  time:33.708, tt:235.955\n",
      "Ep:7, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.67010 (r=0.747,p=0.607),  time:34.595, tt:276.756\n",
      "Ep:8, loss:0.00003, loss_test:0.01837, lr:6.00e-02, fs:0.68687 (r=0.782,p=0.613),  time:34.998, tt:314.980\n",
      "Ep:9, loss:0.00003, loss_test:0.01805, lr:6.00e-02, fs:0.71770 (r=0.862,p=0.615),  time:35.563, tt:355.635\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01783, lr:6.00e-02, fs:0.71362 (r=0.874,p=0.603),  time:36.232, tt:398.547\n",
      "Ep:11, loss:0.00003, loss_test:0.01756, lr:6.00e-02, fs:0.71770 (r=0.862,p=0.615),  time:36.418, tt:437.014\n",
      "Ep:12, loss:0.00003, loss_test:0.01744, lr:6.00e-02, fs:0.72906 (r=0.851,p=0.638),  time:36.455, tt:473.914\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01734, lr:6.00e-02, fs:0.74490 (r=0.839,p=0.670),  time:36.455, tt:510.377\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01714, lr:6.00e-02, fs:0.75258 (r=0.839,p=0.682),  time:36.701, tt:550.509\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01680, lr:6.00e-02, fs:0.76531 (r=0.862,p=0.688),  time:36.865, tt:589.840\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01655, lr:6.00e-02, fs:0.76768 (r=0.874,p=0.685),  time:37.036, tt:629.617\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.77387 (r=0.885,p=0.688),  time:37.094, tt:667.693\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01646, lr:6.00e-02, fs:0.78173 (r=0.885,p=0.700),  time:37.190, tt:706.614\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01654, lr:6.00e-02, fs:0.78351 (r=0.874,p=0.710),  time:37.283, tt:745.654\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01656, lr:6.00e-02, fs:0.77720 (r=0.862,p=0.708),  time:37.324, tt:783.813\n",
      "Ep:21, loss:0.00002, loss_test:0.01657, lr:6.00e-02, fs:0.76842 (r=0.839,p=0.709),  time:37.413, tt:823.080\n",
      "Ep:22, loss:0.00002, loss_test:0.01667, lr:6.00e-02, fs:0.72131 (r=0.759,p=0.688),  time:37.484, tt:862.135\n",
      "Ep:23, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:37.612, tt:902.697\n",
      "Ep:24, loss:0.00002, loss_test:0.01684, lr:6.00e-02, fs:0.71910 (r=0.736,p=0.703),  time:37.626, tt:940.638\n",
      "Ep:25, loss:0.00002, loss_test:0.01699, lr:6.00e-02, fs:0.71910 (r=0.736,p=0.703),  time:37.670, tt:979.413\n",
      "Ep:26, loss:0.00002, loss_test:0.01720, lr:6.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:37.690, tt:1017.639\n",
      "Ep:27, loss:0.00002, loss_test:0.01738, lr:6.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:37.722, tt:1056.226\n",
      "Ep:28, loss:0.00002, loss_test:0.01753, lr:6.00e-02, fs:0.72414 (r=0.724,p=0.724),  time:37.824, tt:1096.889\n",
      "Ep:29, loss:0.00002, loss_test:0.01773, lr:6.00e-02, fs:0.71345 (r=0.701,p=0.726),  time:37.860, tt:1135.791\n",
      "Ep:30, loss:0.00002, loss_test:0.01789, lr:6.00e-02, fs:0.70588 (r=0.690,p=0.723),  time:37.845, tt:1173.182\n",
      "Ep:31, loss:0.00002, loss_test:0.01807, lr:5.94e-02, fs:0.71345 (r=0.701,p=0.726),  time:37.761, tt:1208.346\n",
      "Ep:32, loss:0.00002, loss_test:0.01830, lr:5.88e-02, fs:0.73256 (r=0.724,p=0.741),  time:37.769, tt:1246.372\n",
      "Ep:33, loss:0.00001, loss_test:0.01841, lr:5.82e-02, fs:0.73256 (r=0.724,p=0.741),  time:37.694, tt:1281.606\n",
      "Ep:34, loss:0.00001, loss_test:0.01872, lr:5.76e-02, fs:0.72515 (r=0.713,p=0.738),  time:37.719, tt:1320.170\n",
      "Ep:35, loss:0.00001, loss_test:0.01900, lr:5.71e-02, fs:0.72515 (r=0.713,p=0.738),  time:37.727, tt:1358.161\n",
      "Ep:36, loss:0.00001, loss_test:0.01914, lr:5.65e-02, fs:0.71765 (r=0.701,p=0.735),  time:37.849, tt:1400.420\n",
      "Ep:37, loss:0.00001, loss_test:0.01945, lr:5.59e-02, fs:0.70238 (r=0.678,p=0.728),  time:37.820, tt:1437.165\n",
      "Ep:38, loss:0.00001, loss_test:0.01968, lr:5.54e-02, fs:0.71006 (r=0.690,p=0.732),  time:37.847, tt:1476.039\n",
      "Ep:39, loss:0.00001, loss_test:0.01994, lr:5.48e-02, fs:0.71006 (r=0.690,p=0.732),  time:37.826, tt:1513.042\n",
      "Ep:40, loss:0.00001, loss_test:0.02017, lr:5.43e-02, fs:0.71429 (r=0.690,p=0.741),  time:37.852, tt:1551.943\n",
      "Ep:41, loss:0.00001, loss_test:0.02039, lr:5.37e-02, fs:0.71856 (r=0.690,p=0.750),  time:37.833, tt:1588.966\n",
      "Ep:42, loss:0.00001, loss_test:0.02047, lr:5.32e-02, fs:0.71429 (r=0.690,p=0.741),  time:37.842, tt:1627.217\n",
      "Ep:43, loss:0.00001, loss_test:0.02065, lr:5.27e-02, fs:0.72727 (r=0.690,p=0.769),  time:37.836, tt:1664.783\n",
      "Ep:44, loss:0.00001, loss_test:0.02089, lr:5.21e-02, fs:0.72727 (r=0.690,p=0.769),  time:37.848, tt:1703.181\n",
      "Ep:45, loss:0.00001, loss_test:0.02114, lr:5.16e-02, fs:0.70370 (r=0.655,p=0.760),  time:37.875, tt:1742.260\n",
      "Ep:46, loss:0.00001, loss_test:0.02143, lr:5.11e-02, fs:0.71951 (r=0.678,p=0.766),  time:37.833, tt:1778.171\n",
      "Ep:47, loss:0.00001, loss_test:0.02165, lr:5.06e-02, fs:0.72727 (r=0.690,p=0.769),  time:37.829, tt:1815.794\n",
      "Ep:48, loss:0.00001, loss_test:0.02189, lr:5.01e-02, fs:0.70370 (r=0.655,p=0.760),  time:37.826, tt:1853.489\n",
      "Ep:49, loss:0.00001, loss_test:0.02219, lr:4.96e-02, fs:0.68354 (r=0.621,p=0.761),  time:37.845, tt:1892.259\n",
      "Ep:50, loss:0.00001, loss_test:0.02246, lr:4.91e-02, fs:0.68354 (r=0.621,p=0.761),  time:37.834, tt:1929.518\n",
      "Ep:51, loss:0.00001, loss_test:0.02262, lr:4.86e-02, fs:0.69231 (r=0.621,p=0.783),  time:37.838, tt:1967.595\n",
      "Ep:52, loss:0.00001, loss_test:0.02292, lr:4.81e-02, fs:0.68387 (r=0.609,p=0.779),  time:37.806, tt:2003.738\n",
      "Ep:53, loss:0.00001, loss_test:0.02326, lr:4.76e-02, fs:0.68831 (r=0.609,p=0.791),  time:37.848, tt:2043.773\n",
      "Ep:54, loss:0.00001, loss_test:0.02338, lr:4.71e-02, fs:0.67974 (r=0.598,p=0.788),  time:37.865, tt:2082.555\n",
      "Ep:55, loss:0.00001, loss_test:0.02354, lr:4.67e-02, fs:0.67114 (r=0.575,p=0.806),  time:37.832, tt:2118.603\n",
      "Ep:56, loss:0.00001, loss_test:0.02387, lr:4.62e-02, fs:0.67550 (r=0.586,p=0.797),  time:37.831, tt:2156.380\n",
      "Ep:57, loss:0.00001, loss_test:0.02407, lr:4.57e-02, fs:0.64828 (r=0.540,p=0.810),  time:37.831, tt:2194.226\n",
      "Ep:58, loss:0.00001, loss_test:0.02434, lr:4.53e-02, fs:0.66207 (r=0.552,p=0.828),  time:37.836, tt:2232.349\n",
      "Ep:59, loss:0.00001, loss_test:0.02469, lr:4.48e-02, fs:0.67568 (r=0.575,p=0.820),  time:37.844, tt:2270.630\n",
      "Ep:60, loss:0.00001, loss_test:0.02484, lr:4.44e-02, fs:0.65278 (r=0.540,p=0.825),  time:37.858, tt:2309.346\n",
      "Ep:61, loss:0.00001, loss_test:0.02511, lr:4.39e-02, fs:0.66207 (r=0.552,p=0.828),  time:37.878, tt:2348.433\n",
      "Ep:62, loss:0.00001, loss_test:0.02538, lr:4.35e-02, fs:0.64336 (r=0.529,p=0.821),  time:37.902, tt:2387.808\n",
      "Ep:63, loss:0.00001, loss_test:0.02559, lr:4.31e-02, fs:0.64336 (r=0.529,p=0.821),  time:37.891, tt:2425.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.02582, lr:4.26e-02, fs:0.64336 (r=0.529,p=0.821),  time:37.903, tt:2463.670\n",
      "Ep:65, loss:0.00001, loss_test:0.02598, lr:4.22e-02, fs:0.63380 (r=0.517,p=0.818),  time:37.912, tt:2502.193\n",
      "Ep:66, loss:0.00001, loss_test:0.02639, lr:4.18e-02, fs:0.63380 (r=0.517,p=0.818),  time:37.909, tt:2539.880\n",
      "Ep:67, loss:0.00001, loss_test:0.02653, lr:4.14e-02, fs:0.63380 (r=0.517,p=0.818),  time:37.881, tt:2575.938\n",
      "Ep:68, loss:0.00001, loss_test:0.02677, lr:4.10e-02, fs:0.63830 (r=0.517,p=0.833),  time:37.907, tt:2615.608\n",
      "Ep:69, loss:0.00001, loss_test:0.02710, lr:4.05e-02, fs:0.61429 (r=0.494,p=0.811),  time:37.902, tt:2653.172\n",
      "Ep:70, loss:0.00001, loss_test:0.02729, lr:4.01e-02, fs:0.60870 (r=0.483,p=0.824),  time:37.967, tt:2695.680\n",
      "Ep:71, loss:0.00001, loss_test:0.02753, lr:3.97e-02, fs:0.60870 (r=0.483,p=0.824),  time:37.999, tt:2735.921\n",
      "Ep:72, loss:0.00001, loss_test:0.02780, lr:3.93e-02, fs:0.59854 (r=0.471,p=0.820),  time:37.993, tt:2773.475\n",
      "Ep:73, loss:0.00001, loss_test:0.02808, lr:3.89e-02, fs:0.59854 (r=0.471,p=0.820),  time:37.990, tt:2811.243\n",
      "Ep:74, loss:0.00001, loss_test:0.02842, lr:3.86e-02, fs:0.59854 (r=0.471,p=0.820),  time:37.989, tt:2849.182\n",
      "Ep:75, loss:0.00001, loss_test:0.02860, lr:3.82e-02, fs:0.59854 (r=0.471,p=0.820),  time:38.018, tt:2889.360\n",
      "Ep:76, loss:0.00000, loss_test:0.02888, lr:3.78e-02, fs:0.59854 (r=0.471,p=0.820),  time:38.002, tt:2926.187\n",
      "Ep:77, loss:0.00000, loss_test:0.02899, lr:3.74e-02, fs:0.59854 (r=0.471,p=0.820),  time:37.977, tt:2962.207\n",
      "Ep:78, loss:0.00000, loss_test:0.02925, lr:3.70e-02, fs:0.58824 (r=0.460,p=0.816),  time:37.990, tt:3001.244\n",
      "Ep:79, loss:0.00000, loss_test:0.02955, lr:3.67e-02, fs:0.58824 (r=0.460,p=0.816),  time:37.960, tt:3036.822\n",
      "Ep:80, loss:0.00000, loss_test:0.02976, lr:3.63e-02, fs:0.58824 (r=0.460,p=0.816),  time:37.983, tt:3076.594\n",
      "Ep:81, loss:0.00000, loss_test:0.03010, lr:3.59e-02, fs:0.58209 (r=0.448,p=0.830),  time:37.998, tt:3115.821\n",
      "Ep:82, loss:0.00000, loss_test:0.03033, lr:3.56e-02, fs:0.58209 (r=0.448,p=0.830),  time:38.001, tt:3154.117\n",
      "Ep:83, loss:0.00000, loss_test:0.03050, lr:3.52e-02, fs:0.58209 (r=0.448,p=0.830),  time:38.013, tt:3193.131\n",
      "Ep:84, loss:0.00000, loss_test:0.03088, lr:3.49e-02, fs:0.57143 (r=0.437,p=0.826),  time:38.023, tt:3231.915\n",
      "Ep:85, loss:0.00000, loss_test:0.03103, lr:3.45e-02, fs:0.57143 (r=0.437,p=0.826),  time:38.007, tt:3268.629\n",
      "Ep:86, loss:0.00000, loss_test:0.03121, lr:3.42e-02, fs:0.57576 (r=0.437,p=0.844),  time:37.978, tt:3304.100\n",
      "Ep:87, loss:0.00000, loss_test:0.03146, lr:3.38e-02, fs:0.58462 (r=0.437,p=0.884),  time:37.950, tt:3339.589\n",
      "Ep:88, loss:0.00000, loss_test:0.03158, lr:3.35e-02, fs:0.58462 (r=0.437,p=0.884),  time:37.933, tt:3376.070\n",
      "Ep:89, loss:0.00000, loss_test:0.03178, lr:3.32e-02, fs:0.58462 (r=0.437,p=0.884),  time:37.929, tt:3413.617\n",
      "Ep:90, loss:0.00000, loss_test:0.03184, lr:3.28e-02, fs:0.58462 (r=0.437,p=0.884),  time:37.937, tt:3452.256\n",
      "Ep:91, loss:0.00000, loss_test:0.03215, lr:3.25e-02, fs:0.58462 (r=0.437,p=0.884),  time:37.942, tt:3490.656\n",
      "Ep:92, loss:0.00000, loss_test:0.03221, lr:3.22e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.016, tt:3535.464\n",
      "Ep:93, loss:0.00000, loss_test:0.03245, lr:3.19e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.021, tt:3573.975\n",
      "Ep:94, loss:0.00000, loss_test:0.03277, lr:3.15e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.022, tt:3612.086\n",
      "Ep:95, loss:0.00000, loss_test:0.03271, lr:3.12e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.024, tt:3650.261\n",
      "Ep:96, loss:0.00000, loss_test:0.03289, lr:3.09e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.026, tt:3688.509\n",
      "Ep:97, loss:0.00000, loss_test:0.03314, lr:3.06e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.027, tt:3726.616\n",
      "Ep:98, loss:0.00000, loss_test:0.03330, lr:3.03e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.045, tt:3766.478\n",
      "Ep:99, loss:0.00000, loss_test:0.03369, lr:3.00e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.054, tt:3805.405\n",
      "Ep:100, loss:0.00000, loss_test:0.03389, lr:2.97e-02, fs:0.58915 (r=0.437,p=0.905),  time:38.051, tt:3843.191\n",
      "Ep:101, loss:0.00000, loss_test:0.03384, lr:2.94e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.045, tt:3880.621\n",
      "Ep:102, loss:0.00000, loss_test:0.03416, lr:2.91e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.029, tt:3916.964\n",
      "Ep:103, loss:0.00000, loss_test:0.03430, lr:2.88e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.051, tt:3957.340\n",
      "Ep:104, loss:0.00000, loss_test:0.03432, lr:2.85e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.050, tt:3995.224\n",
      "Ep:105, loss:0.00000, loss_test:0.03469, lr:2.82e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.045, tt:4032.754\n",
      "Ep:106, loss:0.00000, loss_test:0.03478, lr:2.80e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.065, tt:4072.980\n",
      "Ep:107, loss:0.00000, loss_test:0.03470, lr:2.77e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.055, tt:4109.915\n",
      "Ep:108, loss:0.00000, loss_test:0.03508, lr:2.74e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.043, tt:4146.650\n",
      "Ep:109, loss:0.00000, loss_test:0.03506, lr:2.71e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.071, tt:4187.809\n",
      "Ep:110, loss:0.00000, loss_test:0.03523, lr:2.69e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.077, tt:4226.585\n",
      "Ep:111, loss:0.00000, loss_test:0.03540, lr:2.66e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.074, tt:4264.253\n",
      "Ep:112, loss:0.00000, loss_test:0.03536, lr:2.63e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.058, tt:4300.548\n",
      "Ep:113, loss:0.00000, loss_test:0.03550, lr:2.61e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.052, tt:4337.955\n",
      "Ep:114, loss:0.00000, loss_test:0.03581, lr:2.58e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.076, tt:4378.795\n",
      "Ep:115, loss:0.00000, loss_test:0.03594, lr:2.55e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.075, tt:4416.712\n",
      "Ep:116, loss:0.00000, loss_test:0.03591, lr:2.53e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.087, tt:4456.205\n",
      "Ep:117, loss:0.00000, loss_test:0.03604, lr:2.50e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.103, tt:4496.096\n",
      "Ep:118, loss:0.00000, loss_test:0.03635, lr:2.48e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.092, tt:4532.983\n",
      "Ep:119, loss:0.00000, loss_test:0.03640, lr:2.45e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.112, tt:4573.474\n",
      "Ep:120, loss:0.00000, loss_test:0.03635, lr:2.43e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.119, tt:4612.390\n",
      "Ep:121, loss:0.00000, loss_test:0.03663, lr:2.40e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.139, tt:4652.913\n",
      "Ep:122, loss:0.00000, loss_test:0.03679, lr:2.38e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.145, tt:4691.876\n",
      "Ep:123, loss:0.00000, loss_test:0.03677, lr:2.36e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.155, tt:4731.279\n",
      "Ep:124, loss:0.00000, loss_test:0.03694, lr:2.33e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.165, tt:4770.637\n",
      "Ep:125, loss:0.00000, loss_test:0.03698, lr:2.31e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.172, tt:4809.661\n",
      "Ep:126, loss:0.00000, loss_test:0.03694, lr:2.29e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.179, tt:4848.763\n",
      "Ep:127, loss:0.00000, loss_test:0.03733, lr:2.26e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.192, tt:4888.545\n",
      "Ep:128, loss:0.00000, loss_test:0.03742, lr:2.24e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.199, tt:4927.639\n",
      "Ep:129, loss:0.00000, loss_test:0.03725, lr:2.22e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.203, tt:4966.393\n",
      "Ep:130, loss:0.00000, loss_test:0.03763, lr:2.20e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.218, tt:5006.524\n",
      "Ep:131, loss:0.00000, loss_test:0.03771, lr:2.17e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.220, tt:5044.980\n",
      "Ep:132, loss:0.00000, loss_test:0.03748, lr:2.15e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.222, tt:5083.539\n",
      "Ep:133, loss:0.00000, loss_test:0.03768, lr:2.13e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.218, tt:5121.218\n",
      "Ep:134, loss:0.00000, loss_test:0.03792, lr:2.11e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.214, tt:5158.909\n",
      "Ep:135, loss:0.00000, loss_test:0.03775, lr:2.09e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.210, tt:5196.609\n",
      "Ep:136, loss:0.00000, loss_test:0.03794, lr:2.07e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.214, tt:5235.255\n",
      "Ep:137, loss:0.00000, loss_test:0.03818, lr:2.05e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.228, tt:5275.462\n",
      "Ep:138, loss:0.00000, loss_test:0.03811, lr:2.03e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.235, tt:5314.606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.03811, lr:2.01e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.249, tt:5354.833\n",
      "Ep:140, loss:0.00000, loss_test:0.03829, lr:1.99e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.260, tt:5394.728\n",
      "Ep:141, loss:0.00000, loss_test:0.03840, lr:1.97e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.265, tt:5433.631\n",
      "Ep:142, loss:0.00000, loss_test:0.03845, lr:1.95e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.276, tt:5473.466\n",
      "Ep:143, loss:0.00000, loss_test:0.03851, lr:1.93e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.281, tt:5512.522\n",
      "Ep:144, loss:0.00000, loss_test:0.03864, lr:1.91e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.283, tt:5551.069\n",
      "Ep:145, loss:0.00000, loss_test:0.03870, lr:1.89e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.293, tt:5590.799\n",
      "Ep:146, loss:0.00000, loss_test:0.03868, lr:1.87e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.310, tt:5631.538\n",
      "Ep:147, loss:0.00000, loss_test:0.03892, lr:1.85e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.314, tt:5670.525\n",
      "Ep:148, loss:0.00000, loss_test:0.03895, lr:1.83e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.330, tt:5711.172\n",
      "Ep:149, loss:0.00000, loss_test:0.03899, lr:1.81e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.347, tt:5752.111\n",
      "Ep:150, loss:0.00000, loss_test:0.03907, lr:1.80e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.372, tt:5794.114\n",
      "Ep:151, loss:0.00000, loss_test:0.03922, lr:1.78e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.386, tt:5834.704\n",
      "Ep:152, loss:0.00000, loss_test:0.03918, lr:1.76e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.406, tt:5876.051\n",
      "Ep:153, loss:0.00000, loss_test:0.03917, lr:1.74e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.424, tt:5917.341\n",
      "Ep:154, loss:0.00000, loss_test:0.03936, lr:1.73e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.449, tt:5959.615\n",
      "Ep:155, loss:0.00000, loss_test:0.03943, lr:1.71e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.457, tt:5999.269\n",
      "Ep:156, loss:0.00000, loss_test:0.03941, lr:1.69e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.489, tt:6042.695\n",
      "Ep:157, loss:0.00000, loss_test:0.03946, lr:1.67e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.511, tt:6084.795\n",
      "Ep:158, loss:0.00000, loss_test:0.03965, lr:1.66e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.518, tt:6124.416\n",
      "Ep:159, loss:0.00000, loss_test:0.03964, lr:1.64e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.526, tt:6164.094\n",
      "Ep:160, loss:0.00000, loss_test:0.03963, lr:1.62e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.528, tt:6202.941\n",
      "Ep:161, loss:0.00000, loss_test:0.03969, lr:1.61e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.533, tt:6242.408\n",
      "Ep:162, loss:0.00000, loss_test:0.03979, lr:1.59e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.550, tt:6283.711\n",
      "Ep:163, loss:0.00000, loss_test:0.03980, lr:1.58e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.561, tt:6324.077\n",
      "Ep:164, loss:0.00000, loss_test:0.03988, lr:1.56e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.557, tt:6361.986\n",
      "Ep:165, loss:0.00000, loss_test:0.03997, lr:1.54e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.557, tt:6400.407\n",
      "Ep:166, loss:0.00000, loss_test:0.04005, lr:1.53e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.566, tt:6440.581\n",
      "Ep:167, loss:0.00000, loss_test:0.04004, lr:1.51e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.567, tt:6479.326\n",
      "Ep:168, loss:0.00000, loss_test:0.04005, lr:1.50e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.601, tt:6523.633\n",
      "Ep:169, loss:0.00000, loss_test:0.04018, lr:1.48e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.607, tt:6563.214\n",
      "Ep:170, loss:0.00000, loss_test:0.04016, lr:1.47e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.613, tt:6602.741\n",
      "Ep:171, loss:0.00000, loss_test:0.04022, lr:1.45e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.617, tt:6642.063\n",
      "Ep:172, loss:0.00000, loss_test:0.04034, lr:1.44e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.611, tt:6679.624\n",
      "Ep:173, loss:0.00000, loss_test:0.04035, lr:1.43e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.613, tt:6718.677\n",
      "Ep:174, loss:0.00000, loss_test:0.04039, lr:1.41e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.618, tt:6758.148\n",
      "Ep:175, loss:0.00000, loss_test:0.04056, lr:1.40e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.619, tt:6796.984\n",
      "Ep:176, loss:0.00000, loss_test:0.04064, lr:1.38e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.627, tt:6836.935\n",
      "Ep:177, loss:0.00000, loss_test:0.04051, lr:1.37e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.634, tt:6876.877\n",
      "Ep:178, loss:0.00000, loss_test:0.04052, lr:1.36e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.641, tt:6916.684\n",
      "Ep:179, loss:0.00000, loss_test:0.04070, lr:1.34e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.652, tt:6957.399\n",
      "Ep:180, loss:0.00000, loss_test:0.04072, lr:1.33e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.666, tt:6998.481\n",
      "Ep:181, loss:0.00000, loss_test:0.04064, lr:1.32e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.681, tt:7039.864\n",
      "Ep:182, loss:0.00000, loss_test:0.04078, lr:1.30e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.693, tt:7080.886\n",
      "Ep:183, loss:0.00000, loss_test:0.04085, lr:1.29e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.710, tt:7122.709\n",
      "Ep:184, loss:0.00000, loss_test:0.04077, lr:1.28e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.721, tt:7163.397\n",
      "Ep:185, loss:0.00000, loss_test:0.04084, lr:1.26e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.731, tt:7203.926\n",
      "Ep:186, loss:0.00000, loss_test:0.04100, lr:1.25e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.743, tt:7244.942\n",
      "Ep:187, loss:0.00000, loss_test:0.04096, lr:1.24e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.748, tt:7284.572\n",
      "Ep:188, loss:0.00000, loss_test:0.04093, lr:1.23e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.754, tt:7324.492\n",
      "Ep:189, loss:0.00000, loss_test:0.04100, lr:1.21e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.773, tt:7366.875\n",
      "Ep:190, loss:0.00000, loss_test:0.04107, lr:1.20e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.792, tt:7409.238\n",
      "Ep:191, loss:0.00000, loss_test:0.04104, lr:1.19e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.798, tt:7449.281\n",
      "Ep:192, loss:0.00000, loss_test:0.04106, lr:1.18e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.796, tt:7487.620\n",
      "Ep:193, loss:0.00000, loss_test:0.04112, lr:1.17e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.813, tt:7529.651\n",
      "Ep:194, loss:0.00000, loss_test:0.04125, lr:1.15e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.828, tt:7571.405\n",
      "Ep:195, loss:0.00000, loss_test:0.04123, lr:1.14e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.832, tt:7611.089\n",
      "Ep:196, loss:0.00000, loss_test:0.04121, lr:1.13e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.842, tt:7651.959\n",
      "Ep:197, loss:0.00000, loss_test:0.04132, lr:1.12e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.873, tt:7696.842\n",
      "Ep:198, loss:0.00000, loss_test:0.04135, lr:1.11e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.879, tt:7736.996\n",
      "Ep:199, loss:0.00000, loss_test:0.04128, lr:1.10e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.881, tt:7776.122\n",
      "Ep:200, loss:0.00000, loss_test:0.04135, lr:1.09e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.890, tt:7816.989\n",
      "Ep:201, loss:0.00000, loss_test:0.04148, lr:1.08e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.901, tt:7858.060\n",
      "Ep:202, loss:0.00000, loss_test:0.04148, lr:1.07e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.911, tt:7898.979\n",
      "Ep:203, loss:0.00000, loss_test:0.04148, lr:1.05e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.913, tt:7938.337\n",
      "Ep:204, loss:0.00000, loss_test:0.04153, lr:1.04e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.926, tt:7979.797\n",
      "Ep:205, loss:0.00000, loss_test:0.04162, lr:1.03e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.927, tt:8018.935\n",
      "Ep:206, loss:0.00000, loss_test:0.04154, lr:1.02e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.911, tt:8054.589\n",
      "Ep:207, loss:0.00000, loss_test:0.04152, lr:1.01e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.920, tt:8095.336\n",
      "Ep:208, loss:0.00000, loss_test:0.04166, lr:1.00e-02, fs:0.59375 (r=0.437,p=0.927),  time:38.922, tt:8134.788\n",
      "Ep:209, loss:0.00000, loss_test:0.04170, lr:9.93e-03, fs:0.59375 (r=0.437,p=0.927),  time:38.927, tt:8174.638\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14141, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.647, tt:33.647\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13937, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:34.074, tt:68.147\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13558, lr:1.00e-02, fs:0.66667 (r=0.977,p=0.506),  time:35.986, tt:107.958\n",
      "Ep:3, loss:0.00026, loss_test:0.12955, lr:1.00e-02, fs:0.67500 (r=0.931,p=0.529),  time:37.945, tt:151.780\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12433, lr:1.00e-02, fs:0.64840 (r=0.816,p=0.538),  time:39.194, tt:195.972\n",
      "Ep:5, loss:0.00024, loss_test:0.12169, lr:1.00e-02, fs:0.67692 (r=0.759,p=0.611),  time:39.712, tt:238.272\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11969, lr:1.00e-02, fs:0.68132 (r=0.713,p=0.653),  time:40.243, tt:281.699\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11421, lr:1.00e-02, fs:0.67368 (r=0.736,p=0.621),  time:40.856, tt:326.844\n",
      "Ep:8, loss:0.00022, loss_test:0.11247, lr:1.00e-02, fs:0.68063 (r=0.747,p=0.625),  time:40.937, tt:368.432\n",
      "Ep:9, loss:0.00021, loss_test:0.11175, lr:1.00e-02, fs:0.70213 (r=0.759,p=0.653),  time:41.104, tt:411.037\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11049, lr:1.00e-02, fs:0.69945 (r=0.736,p=0.667),  time:41.348, tt:454.829\n",
      "Ep:11, loss:0.00019, loss_test:0.10930, lr:1.00e-02, fs:0.70391 (r=0.724,p=0.685),  time:41.594, tt:499.124\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10812, lr:1.00e-02, fs:0.71910 (r=0.736,p=0.703),  time:41.804, tt:543.452\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10672, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:41.852, tt:585.924\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10565, lr:1.00e-02, fs:0.70238 (r=0.678,p=0.728),  time:41.876, tt:628.139\n",
      "Ep:15, loss:0.00016, loss_test:0.10400, lr:1.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:41.949, tt:671.184\n",
      "Ep:16, loss:0.00015, loss_test:0.10281, lr:1.00e-02, fs:0.71429 (r=0.690,p=0.741),  time:42.005, tt:714.087\n",
      "Ep:17, loss:0.00015, loss_test:0.10195, lr:1.00e-02, fs:0.71856 (r=0.690,p=0.750),  time:41.980, tt:755.644\n",
      "Ep:18, loss:0.00014, loss_test:0.09902, lr:1.00e-02, fs:0.73256 (r=0.724,p=0.741),  time:41.953, tt:797.107\n",
      "Ep:19, loss:0.00013, loss_test:0.10459, lr:1.00e-02, fs:0.69939 (r=0.655,p=0.750),  time:41.976, tt:839.513\n",
      "Ep:20, loss:0.00013, loss_test:0.10036, lr:1.00e-02, fs:0.70930 (r=0.701,p=0.718),  time:42.072, tt:883.509\n",
      "Ep:21, loss:0.00012, loss_test:0.10305, lr:1.00e-02, fs:0.68323 (r=0.632,p=0.743),  time:42.008, tt:924.181\n",
      "Ep:22, loss:0.00011, loss_test:0.09752, lr:1.00e-02, fs:0.77596 (r=0.816,p=0.740),  time:41.969, tt:965.290\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.10142, lr:1.00e-02, fs:0.70732 (r=0.667,p=0.753),  time:41.978, tt:1007.481\n",
      "Ep:24, loss:0.00011, loss_test:0.09734, lr:1.00e-02, fs:0.75581 (r=0.747,p=0.765),  time:42.083, tt:1052.069\n",
      "Ep:25, loss:0.00010, loss_test:0.09740, lr:1.00e-02, fs:0.77714 (r=0.782,p=0.773),  time:42.178, tt:1096.635\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.09707, lr:1.00e-02, fs:0.73494 (r=0.701,p=0.772),  time:42.130, tt:1137.520\n",
      "Ep:27, loss:0.00009, loss_test:0.09605, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:42.163, tt:1180.567\n",
      "Ep:28, loss:0.00008, loss_test:0.10189, lr:1.00e-02, fs:0.69737 (r=0.609,p=0.815),  time:42.172, tt:1222.985\n",
      "Ep:29, loss:0.00008, loss_test:0.09225, lr:1.00e-02, fs:0.76136 (r=0.770,p=0.753),  time:42.238, tt:1267.142\n",
      "Ep:30, loss:0.00007, loss_test:0.10241, lr:1.00e-02, fs:0.67568 (r=0.575,p=0.820),  time:42.208, tt:1308.458\n",
      "Ep:31, loss:0.00007, loss_test:0.08974, lr:1.00e-02, fs:0.79330 (r=0.816,p=0.772),  time:42.213, tt:1350.812\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00007, loss_test:0.09981, lr:1.00e-02, fs:0.71053 (r=0.621,p=0.831),  time:42.200, tt:1392.614\n",
      "Ep:33, loss:0.00006, loss_test:0.09011, lr:1.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:42.138, tt:1432.700\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.09567, lr:1.00e-02, fs:0.72258 (r=0.644,p=0.824),  time:42.169, tt:1475.915\n",
      "Ep:35, loss:0.00006, loss_test:0.09643, lr:1.00e-02, fs:0.71141 (r=0.609,p=0.855),  time:42.160, tt:1517.770\n",
      "Ep:36, loss:0.00005, loss_test:0.08988, lr:1.00e-02, fs:0.75610 (r=0.713,p=0.805),  time:42.147, tt:1559.456\n",
      "Ep:37, loss:0.00005, loss_test:0.09725, lr:1.00e-02, fs:0.71622 (r=0.609,p=0.869),  time:42.136, tt:1601.178\n",
      "Ep:38, loss:0.00004, loss_test:0.09015, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:42.131, tt:1643.096\n",
      "Ep:39, loss:0.00004, loss_test:0.09578, lr:1.00e-02, fs:0.69444 (r=0.575,p=0.877),  time:42.128, tt:1685.131\n",
      "Ep:40, loss:0.00004, loss_test:0.08629, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:42.118, tt:1726.819\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00004, loss_test:0.09828, lr:1.00e-02, fs:0.66667 (r=0.540,p=0.870),  time:42.108, tt:1768.516\n",
      "Ep:42, loss:0.00005, loss_test:0.07878, lr:1.00e-02, fs:0.83799 (r=0.862,p=0.815),  time:42.101, tt:1810.328\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.09928, lr:1.00e-02, fs:0.74667 (r=0.644,p=0.889),  time:42.121, tt:1853.327\n",
      "Ep:44, loss:0.00004, loss_test:0.09575, lr:1.00e-02, fs:0.72483 (r=0.621,p=0.871),  time:42.127, tt:1895.709\n",
      "Ep:45, loss:0.00003, loss_test:0.08950, lr:1.00e-02, fs:0.78205 (r=0.701,p=0.884),  time:42.157, tt:1939.239\n",
      "Ep:46, loss:0.00003, loss_test:0.09639, lr:1.00e-02, fs:0.75497 (r=0.655,p=0.891),  time:42.192, tt:1983.022\n",
      "Ep:47, loss:0.00003, loss_test:0.08384, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:42.158, tt:2023.600\n",
      "Ep:48, loss:0.00003, loss_test:0.09256, lr:1.00e-02, fs:0.75497 (r=0.655,p=0.891),  time:42.207, tt:2068.154\n",
      "Ep:49, loss:0.00003, loss_test:0.10414, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:42.230, tt:2111.517\n",
      "Ep:50, loss:0.00003, loss_test:0.08685, lr:1.00e-02, fs:0.81250 (r=0.747,p=0.890),  time:42.236, tt:2154.050\n",
      "Ep:51, loss:0.00003, loss_test:0.09436, lr:1.00e-02, fs:0.75325 (r=0.667,p=0.866),  time:42.231, tt:2196.022\n",
      "Ep:52, loss:0.00002, loss_test:0.10050, lr:1.00e-02, fs:0.70833 (r=0.586,p=0.895),  time:42.213, tt:2237.266\n",
      "Ep:53, loss:0.00002, loss_test:0.09081, lr:1.00e-02, fs:0.76000 (r=0.655,p=0.905),  time:42.202, tt:2278.894\n",
      "Ep:54, loss:0.00002, loss_test:0.08522, lr:9.90e-03, fs:0.75000 (r=0.655,p=0.877),  time:42.154, tt:2318.446\n",
      "Ep:55, loss:0.00002, loss_test:0.10495, lr:9.80e-03, fs:0.67143 (r=0.540,p=0.887),  time:42.183, tt:2362.241\n",
      "Ep:56, loss:0.00002, loss_test:0.10197, lr:9.70e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.163, tt:2403.316\n",
      "Ep:57, loss:0.00002, loss_test:0.10198, lr:9.61e-03, fs:0.71724 (r=0.598,p=0.897),  time:42.174, tt:2446.093\n",
      "Ep:58, loss:0.00001, loss_test:0.10097, lr:9.51e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.161, tt:2487.493\n",
      "Ep:59, loss:0.00001, loss_test:0.09906, lr:9.41e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.152, tt:2529.124\n",
      "Ep:60, loss:0.00001, loss_test:0.10122, lr:9.32e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.145, tt:2570.847\n",
      "Ep:61, loss:0.00001, loss_test:0.09809, lr:9.23e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.146, tt:2613.050\n",
      "Ep:62, loss:0.00001, loss_test:0.10521, lr:9.14e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.110, tt:2652.961\n",
      "Ep:63, loss:0.00001, loss_test:0.10879, lr:9.04e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.101, tt:2694.467\n",
      "Ep:64, loss:0.00001, loss_test:0.09762, lr:8.95e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.087, tt:2735.670\n",
      "Ep:65, loss:0.00001, loss_test:0.10509, lr:8.86e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.106, tt:2779.006\n",
      "Ep:66, loss:0.00001, loss_test:0.11645, lr:8.78e-03, fs:0.69014 (r=0.563,p=0.891),  time:42.088, tt:2819.906\n",
      "Ep:67, loss:0.00001, loss_test:0.09867, lr:8.69e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.082, tt:2861.599\n",
      "Ep:68, loss:0.00001, loss_test:0.11544, lr:8.60e-03, fs:0.71329 (r=0.586,p=0.911),  time:42.067, tt:2902.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.10320, lr:8.51e-03, fs:0.71942 (r=0.575,p=0.962),  time:42.038, tt:2942.660\n",
      "Ep:70, loss:0.00001, loss_test:0.10860, lr:8.43e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.031, tt:2984.204\n",
      "Ep:71, loss:0.00001, loss_test:0.11096, lr:8.35e-03, fs:0.75524 (r=0.621,p=0.964),  time:42.037, tt:3026.651\n",
      "Ep:72, loss:0.00001, loss_test:0.10112, lr:8.26e-03, fs:0.72464 (r=0.575,p=0.980),  time:42.033, tt:3068.378\n",
      "Ep:73, loss:0.00001, loss_test:0.11500, lr:8.18e-03, fs:0.73759 (r=0.598,p=0.963),  time:42.003, tt:3108.207\n",
      "Ep:74, loss:0.00001, loss_test:0.09922, lr:8.10e-03, fs:0.69118 (r=0.540,p=0.959),  time:41.980, tt:3148.469\n",
      "Ep:75, loss:0.00001, loss_test:0.11017, lr:8.02e-03, fs:0.70588 (r=0.552,p=0.980),  time:41.946, tt:3187.926\n",
      "Ep:76, loss:0.00001, loss_test:0.09735, lr:7.94e-03, fs:0.73759 (r=0.598,p=0.963),  time:41.911, tt:3227.157\n",
      "Ep:77, loss:0.00001, loss_test:0.11088, lr:7.86e-03, fs:0.70588 (r=0.552,p=0.980),  time:41.885, tt:3267.002\n",
      "Ep:78, loss:0.00001, loss_test:0.11267, lr:7.78e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.861, tt:3306.998\n",
      "Ep:79, loss:0.00001, loss_test:0.10643, lr:7.70e-03, fs:0.68148 (r=0.529,p=0.958),  time:41.797, tt:3343.726\n",
      "Ep:80, loss:0.00000, loss_test:0.11412, lr:7.62e-03, fs:0.72464 (r=0.575,p=0.980),  time:41.782, tt:3384.380\n",
      "Ep:81, loss:0.00000, loss_test:0.11385, lr:7.55e-03, fs:0.61417 (r=0.448,p=0.975),  time:41.777, tt:3425.683\n",
      "Ep:82, loss:0.00000, loss_test:0.11782, lr:7.47e-03, fs:0.65152 (r=0.494,p=0.956),  time:41.793, tt:3468.821\n",
      "Ep:83, loss:0.00000, loss_test:0.10838, lr:7.40e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.779, tt:3509.424\n",
      "Ep:84, loss:0.00000, loss_test:0.11544, lr:7.32e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.729, tt:3546.969\n",
      "Ep:85, loss:0.00000, loss_test:0.10383, lr:7.25e-03, fs:0.71942 (r=0.575,p=0.962),  time:41.704, tt:3586.539\n",
      "Ep:86, loss:0.00000, loss_test:0.11602, lr:7.18e-03, fs:0.64615 (r=0.483,p=0.977),  time:41.689, tt:3626.959\n",
      "Ep:87, loss:0.00000, loss_test:0.10331, lr:7.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.690, tt:3668.690\n",
      "Ep:88, loss:0.00000, loss_test:0.11077, lr:7.03e-03, fs:0.74286 (r=0.598,p=0.981),  time:41.659, tt:3707.614\n",
      "Ep:89, loss:0.00000, loss_test:0.10834, lr:6.96e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.654, tt:3748.884\n",
      "Ep:90, loss:0.00000, loss_test:0.10650, lr:6.89e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.643, tt:3789.555\n",
      "Ep:91, loss:0.00000, loss_test:0.11057, lr:6.83e-03, fs:0.71533 (r=0.563,p=0.980),  time:41.646, tt:3831.450\n",
      "Ep:92, loss:0.00000, loss_test:0.10537, lr:6.76e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.625, tt:3871.137\n",
      "Ep:93, loss:0.00000, loss_test:0.11042, lr:6.69e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.615, tt:3911.833\n",
      "Ep:94, loss:0.00000, loss_test:0.11394, lr:6.62e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.608, tt:3952.805\n",
      "Ep:95, loss:0.00000, loss_test:0.10524, lr:6.56e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.585, tt:3992.183\n",
      "Ep:96, loss:0.00000, loss_test:0.10949, lr:6.49e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.618, tt:4036.906\n",
      "Ep:97, loss:0.00000, loss_test:0.10716, lr:6.43e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.618, tt:4078.589\n",
      "Ep:98, loss:0.00000, loss_test:0.10789, lr:6.36e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.622, tt:4120.545\n",
      "Ep:99, loss:0.00000, loss_test:0.10782, lr:6.30e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.614, tt:4161.443\n",
      "Ep:100, loss:0.00000, loss_test:0.10874, lr:6.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.605, tt:4202.087\n",
      "Ep:101, loss:0.00000, loss_test:0.10926, lr:6.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.589, tt:4242.031\n",
      "Ep:102, loss:0.00000, loss_test:0.10826, lr:6.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.580, tt:4282.690\n",
      "Ep:103, loss:0.00000, loss_test:0.11084, lr:6.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.596, tt:4326.013\n",
      "Ep:104, loss:0.00000, loss_test:0.10626, lr:5.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.582, tt:4366.064\n",
      "Ep:105, loss:0.00000, loss_test:0.11203, lr:5.93e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.582, tt:4407.682\n",
      "Ep:106, loss:0.00000, loss_test:0.10495, lr:5.87e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.574, tt:4448.378\n",
      "Ep:107, loss:0.00000, loss_test:0.10965, lr:5.81e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.557, tt:4488.129\n",
      "Ep:108, loss:0.00000, loss_test:0.11412, lr:5.75e-03, fs:0.68657 (r=0.529,p=0.979),  time:41.550, tt:4528.934\n",
      "Ep:109, loss:0.00000, loss_test:0.10611, lr:5.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.551, tt:4570.637\n",
      "Ep:110, loss:0.00000, loss_test:0.11036, lr:5.64e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.541, tt:4611.096\n",
      "Ep:111, loss:0.00000, loss_test:0.10965, lr:5.58e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.521, tt:4650.383\n",
      "Ep:112, loss:0.00000, loss_test:0.10639, lr:5.53e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.512, tt:4690.855\n",
      "Ep:113, loss:0.00000, loss_test:0.10876, lr:5.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.507, tt:4731.811\n",
      "Ep:114, loss:0.00000, loss_test:0.10820, lr:5.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.513, tt:4773.950\n",
      "Ep:115, loss:0.00000, loss_test:0.10795, lr:5.36e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.505, tt:4814.610\n",
      "Ep:116, loss:0.00000, loss_test:0.10712, lr:5.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.509, tt:4856.587\n",
      "Ep:117, loss:0.00000, loss_test:0.10605, lr:5.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.517, tt:4899.022\n",
      "Ep:118, loss:0.00000, loss_test:0.10653, lr:5.20e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.505, tt:4939.133\n",
      "Ep:119, loss:0.00000, loss_test:0.10795, lr:5.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.491, tt:4978.913\n",
      "Ep:120, loss:0.00000, loss_test:0.10690, lr:5.10e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.504, tt:5022.004\n",
      "Ep:121, loss:0.00000, loss_test:0.10566, lr:5.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.497, tt:5062.684\n",
      "Ep:122, loss:0.00000, loss_test:0.10570, lr:5.00e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.500, tt:5104.483\n",
      "Ep:123, loss:0.00000, loss_test:0.10678, lr:4.95e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.483, tt:5143.831\n",
      "Ep:124, loss:0.00000, loss_test:0.10701, lr:4.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.495, tt:5186.841\n",
      "Ep:125, loss:0.00000, loss_test:0.10615, lr:4.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.496, tt:5228.472\n",
      "Ep:126, loss:0.00000, loss_test:0.10608, lr:4.80e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.470, tt:5266.646\n",
      "Ep:127, loss:0.00000, loss_test:0.10632, lr:4.75e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.470, tt:5308.202\n",
      "Ep:128, loss:0.00000, loss_test:0.10654, lr:4.71e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.463, tt:5348.753\n",
      "Ep:129, loss:0.00000, loss_test:0.10506, lr:4.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.463, tt:5390.225\n",
      "Ep:130, loss:0.00000, loss_test:0.10617, lr:4.61e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.465, tt:5431.939\n",
      "Ep:131, loss:0.00000, loss_test:0.10621, lr:4.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.466, tt:5473.554\n",
      "Ep:132, loss:0.00000, loss_test:0.10479, lr:4.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.458, tt:5513.910\n",
      "Ep:133, loss:0.00000, loss_test:0.10567, lr:4.48e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.500, tt:5561.060\n",
      "Ep:134, loss:0.00000, loss_test:0.10482, lr:4.43e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.523, tt:5605.631\n",
      "Ep:135, loss:0.00000, loss_test:0.10559, lr:4.39e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.526, tt:5647.602\n",
      "Ep:136, loss:0.00000, loss_test:0.10692, lr:4.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.521, tt:5688.366\n",
      "Ep:137, loss:0.00000, loss_test:0.10555, lr:4.30e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.514, tt:5728.974\n",
      "Ep:138, loss:0.00000, loss_test:0.10421, lr:4.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.515, tt:5770.565\n",
      "Ep:139, loss:0.00000, loss_test:0.10637, lr:4.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.522, tt:5813.010\n",
      "Ep:140, loss:0.00000, loss_test:0.10656, lr:4.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.534, tt:5856.333\n",
      "Ep:141, loss:0.00000, loss_test:0.10448, lr:4.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.539, tt:5898.590\n",
      "Ep:142, loss:0.00000, loss_test:0.10487, lr:4.09e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.547, tt:5941.168\n",
      "Ep:143, loss:0.00000, loss_test:0.10506, lr:4.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.545, tt:5982.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.10537, lr:4.01e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.554, tt:6025.291\n",
      "Ep:145, loss:0.00000, loss_test:0.10503, lr:3.97e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.555, tt:6067.001\n",
      "Ep:146, loss:0.00000, loss_test:0.10438, lr:3.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.553, tt:6108.254\n",
      "Ep:147, loss:0.00000, loss_test:0.10580, lr:3.89e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.550, tt:6149.397\n",
      "Ep:148, loss:0.00000, loss_test:0.10561, lr:3.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.558, tt:6192.085\n",
      "Ep:149, loss:0.00000, loss_test:0.10472, lr:3.81e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.565, tt:6234.786\n",
      "Ep:150, loss:0.00000, loss_test:0.10459, lr:3.77e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.570, tt:6277.030\n",
      "Ep:151, loss:0.00000, loss_test:0.10493, lr:3.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.578, tt:6319.832\n",
      "Ep:152, loss:0.00000, loss_test:0.10530, lr:3.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.585, tt:6362.539\n",
      "Ep:153, loss:0.00000, loss_test:0.10464, lr:3.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.616, tt:6408.923\n",
      "Ep:154, loss:0.00000, loss_test:0.10575, lr:3.62e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.620, tt:6451.166\n",
      "Ep:155, loss:0.00000, loss_test:0.10643, lr:3.59e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.628, tt:6494.028\n",
      "Ep:156, loss:0.00000, loss_test:0.10449, lr:3.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.625, tt:6535.147\n",
      "Ep:157, loss:0.00000, loss_test:0.10373, lr:3.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.633, tt:6577.979\n",
      "Ep:158, loss:0.00000, loss_test:0.10483, lr:3.48e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.630, tt:6619.234\n",
      "Ep:159, loss:0.00000, loss_test:0.10501, lr:3.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.644, tt:6662.977\n",
      "Ep:160, loss:0.00000, loss_test:0.10452, lr:3.41e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.651, tt:6705.824\n",
      "Ep:161, loss:0.00000, loss_test:0.10437, lr:3.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.641, tt:6745.780\n",
      "Ep:162, loss:0.00000, loss_test:0.10482, lr:3.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.639, tt:6787.127\n",
      "Ep:163, loss:0.00000, loss_test:0.10480, lr:3.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.652, tt:6830.867\n",
      "Ep:164, loss:0.00000, loss_test:0.10375, lr:3.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.647, tt:6871.825\n",
      "Ep:165, loss:0.00000, loss_test:0.10453, lr:3.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.653, tt:6914.404\n",
      "Ep:166, loss:0.00000, loss_test:0.10487, lr:3.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.650, tt:6955.582\n",
      "Ep:167, loss:0.00000, loss_test:0.10434, lr:3.18e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.650, tt:6997.238\n",
      "Ep:168, loss:0.00000, loss_test:0.10363, lr:3.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.649, tt:7038.682\n",
      "Ep:169, loss:0.00000, loss_test:0.10495, lr:3.12e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.656, tt:7081.442\n",
      "Ep:170, loss:0.00000, loss_test:0.10513, lr:3.09e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.671, tt:7125.748\n",
      "Ep:171, loss:0.00000, loss_test:0.10380, lr:3.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.669, tt:7167.029\n",
      "Ep:172, loss:0.00000, loss_test:0.10409, lr:3.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.673, tt:7209.435\n",
      "Ep:173, loss:0.00000, loss_test:0.10477, lr:2.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.665, tt:7249.715\n",
      "Ep:174, loss:0.00000, loss_test:0.10377, lr:2.96e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.691, tt:7295.856\n",
      "Ep:175, loss:0.00000, loss_test:0.10382, lr:2.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.700, tt:7339.172\n",
      "Ep:176, loss:0.00000, loss_test:0.10442, lr:2.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.704, tt:7381.617\n",
      "Ep:177, loss:0.00000, loss_test:0.10412, lr:2.88e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.711, tt:7424.485\n",
      "Ep:178, loss:0.00000, loss_test:0.10367, lr:2.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.710, tt:7466.059\n",
      "Ep:179, loss:0.00000, loss_test:0.10360, lr:2.82e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.708, tt:7507.441\n",
      "Ep:180, loss:0.00000, loss_test:0.10313, lr:2.79e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.711, tt:7549.608\n",
      "Ep:181, loss:0.00000, loss_test:0.10429, lr:2.76e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.717, tt:7592.578\n",
      "Ep:182, loss:0.00000, loss_test:0.10552, lr:2.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.713, tt:7633.430\n",
      "Ep:183, loss:0.00000, loss_test:0.10354, lr:2.71e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.712, tt:7674.969\n",
      "Ep:184, loss:0.00000, loss_test:0.10323, lr:2.68e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.703, tt:7715.126\n",
      "Ep:185, loss:0.00000, loss_test:0.10407, lr:2.65e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.708, tt:7757.634\n",
      "Ep:186, loss:0.00000, loss_test:0.10433, lr:2.63e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.711, tt:7800.018\n",
      "Ep:187, loss:0.00000, loss_test:0.10366, lr:2.60e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.708, tt:7841.085\n",
      "Ep:188, loss:0.00000, loss_test:0.10314, lr:2.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.698, tt:7880.887\n",
      "Ep:189, loss:0.00000, loss_test:0.10265, lr:2.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.695, tt:7922.071\n",
      "Ep:190, loss:0.00000, loss_test:0.10321, lr:2.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.680, tt:7960.894\n",
      "Ep:191, loss:0.00000, loss_test:0.10350, lr:2.50e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.663, tt:7999.235\n",
      "Ep:192, loss:0.00000, loss_test:0.10334, lr:2.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.669, tt:8042.177\n",
      "Ep:193, loss:0.00000, loss_test:0.10264, lr:2.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.674, tt:8084.800\n",
      "Ep:194, loss:0.00000, loss_test:0.10361, lr:2.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.708, tt:8133.143\n",
      "Ep:195, loss:0.00000, loss_test:0.10491, lr:2.40e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.709, tt:8175.010\n",
      "Ep:196, loss:0.00000, loss_test:0.10465, lr:2.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.710, tt:8216.821\n",
      "Ep:197, loss:0.00000, loss_test:0.10342, lr:2.35e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.715, tt:8259.480\n",
      "Ep:198, loss:0.00000, loss_test:0.10373, lr:2.33e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.728, tt:8303.818\n",
      "Ep:199, loss:0.00000, loss_test:0.10410, lr:2.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.739, tt:8347.802\n",
      "Ep:200, loss:0.00000, loss_test:0.10340, lr:2.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.743, tt:8390.272\n",
      "Ep:201, loss:0.00000, loss_test:0.10266, lr:2.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.742, tt:8431.795\n",
      "Ep:202, loss:0.00000, loss_test:0.10267, lr:2.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.738, tt:8472.878\n",
      "Ep:203, loss:0.00000, loss_test:0.10315, lr:2.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.743, tt:8515.625\n",
      "Ep:204, loss:0.00000, loss_test:0.10306, lr:2.19e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.749, tt:8558.620\n",
      "Ep:205, loss:0.00000, loss_test:0.10289, lr:2.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.725, tt:8595.403\n",
      "Ep:206, loss:0.00000, loss_test:0.10280, lr:2.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.687, tt:8629.241\n",
      "Ep:207, loss:0.00000, loss_test:0.10272, lr:2.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.666, tt:8666.477\n",
      "Ep:208, loss:0.00000, loss_test:0.10306, lr:2.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.644, tt:8703.630\n",
      "Ep:209, loss:0.00000, loss_test:0.10296, lr:2.08e-03, fs:0.67669 (r=0.517,p=0.978),  time:41.630, tt:8742.276\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02066, lr:6.00e-02, fs:0.66390 (r=0.920,p=0.519),  time:25.267, tt:25.267\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.620, tt:47.240\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02327, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.659, tt:64.977\n",
      "Ep:3, loss:0.00004, loss_test:0.02229, lr:6.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:20.724, tt:82.897\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02083, lr:6.00e-02, fs:0.67717 (r=0.989,p=0.515),  time:20.891, tt:104.454\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01977, lr:6.00e-02, fs:0.66957 (r=0.885,p=0.538),  time:21.912, tt:131.474\n",
      "Ep:6, loss:0.00004, loss_test:0.01975, lr:6.00e-02, fs:0.65347 (r=0.759,p=0.574),  time:23.141, tt:161.989\n",
      "Ep:7, loss:0.00004, loss_test:0.01970, lr:6.00e-02, fs:0.65990 (r=0.747,p=0.591),  time:23.940, tt:191.517\n",
      "Ep:8, loss:0.00003, loss_test:0.01909, lr:6.00e-02, fs:0.69268 (r=0.816,p=0.602),  time:24.404, tt:219.635\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01868, lr:6.00e-02, fs:0.70423 (r=0.862,p=0.595),  time:24.771, tt:247.715\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01848, lr:6.00e-02, fs:0.69444 (r=0.862,p=0.581),  time:25.282, tt:278.106\n",
      "Ep:11, loss:0.00003, loss_test:0.01831, lr:6.00e-02, fs:0.70142 (r=0.851,p=0.597),  time:25.672, tt:308.067\n",
      "Ep:12, loss:0.00003, loss_test:0.01818, lr:6.00e-02, fs:0.71845 (r=0.851,p=0.622),  time:26.089, tt:339.154\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01794, lr:6.00e-02, fs:0.73737 (r=0.839,p=0.658),  time:26.469, tt:370.563\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01749, lr:6.00e-02, fs:0.74872 (r=0.839,p=0.676),  time:26.797, tt:401.957\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01713, lr:6.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:27.137, tt:434.193\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01689, lr:6.00e-02, fs:0.76531 (r=0.862,p=0.688),  time:27.318, tt:464.409\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01678, lr:6.00e-02, fs:0.77157 (r=0.874,p=0.691),  time:27.524, tt:495.424\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01690, lr:6.00e-02, fs:0.73684 (r=0.805,p=0.680),  time:27.742, tt:527.093\n",
      "Ep:19, loss:0.00002, loss_test:0.01715, lr:6.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:27.893, tt:557.861\n",
      "Ep:20, loss:0.00002, loss_test:0.01731, lr:6.00e-02, fs:0.71739 (r=0.759,p=0.680),  time:28.105, tt:590.200\n",
      "Ep:21, loss:0.00002, loss_test:0.01755, lr:6.00e-02, fs:0.69613 (r=0.724,p=0.670),  time:28.184, tt:620.046\n",
      "Ep:22, loss:0.00002, loss_test:0.01785, lr:6.00e-02, fs:0.70391 (r=0.724,p=0.685),  time:28.351, tt:652.068\n",
      "Ep:23, loss:0.00002, loss_test:0.01810, lr:6.00e-02, fs:0.70787 (r=0.724,p=0.692),  time:28.437, tt:682.490\n",
      "Ep:24, loss:0.00002, loss_test:0.01823, lr:6.00e-02, fs:0.70056 (r=0.713,p=0.689),  time:28.441, tt:711.018\n",
      "Ep:25, loss:0.00002, loss_test:0.01840, lr:6.00e-02, fs:0.70455 (r=0.713,p=0.697),  time:28.557, tt:742.493\n",
      "Ep:26, loss:0.00002, loss_test:0.01872, lr:6.00e-02, fs:0.70857 (r=0.713,p=0.705),  time:28.688, tt:774.578\n",
      "Ep:27, loss:0.00002, loss_test:0.01905, lr:6.00e-02, fs:0.69364 (r=0.690,p=0.698),  time:28.745, tt:804.874\n",
      "Ep:28, loss:0.00002, loss_test:0.01934, lr:6.00e-02, fs:0.69006 (r=0.678,p=0.702),  time:28.792, tt:834.975\n",
      "Ep:29, loss:0.00002, loss_test:0.01952, lr:5.94e-02, fs:0.69412 (r=0.678,p=0.711),  time:28.807, tt:864.215\n",
      "Ep:30, loss:0.00001, loss_test:0.01988, lr:5.88e-02, fs:0.69412 (r=0.678,p=0.711),  time:28.869, tt:894.938\n",
      "Ep:31, loss:0.00001, loss_test:0.02022, lr:5.82e-02, fs:0.67857 (r=0.655,p=0.704),  time:29.017, tt:928.551\n",
      "Ep:32, loss:0.00001, loss_test:0.02052, lr:5.76e-02, fs:0.67066 (r=0.644,p=0.700),  time:29.040, tt:958.327\n",
      "Ep:33, loss:0.00001, loss_test:0.02090, lr:5.71e-02, fs:0.62963 (r=0.586,p=0.680),  time:29.070, tt:988.368\n",
      "Ep:34, loss:0.00001, loss_test:0.02131, lr:5.65e-02, fs:0.63750 (r=0.586,p=0.699),  time:29.157, tt:1020.495\n",
      "Ep:35, loss:0.00001, loss_test:0.02154, lr:5.59e-02, fs:0.63750 (r=0.586,p=0.699),  time:29.245, tt:1052.810\n",
      "Ep:36, loss:0.00001, loss_test:0.02180, lr:5.54e-02, fs:0.64557 (r=0.586,p=0.718),  time:29.328, tt:1085.126\n",
      "Ep:37, loss:0.00001, loss_test:0.02210, lr:5.48e-02, fs:0.64968 (r=0.586,p=0.729),  time:29.370, tt:1116.073\n",
      "Ep:38, loss:0.00001, loss_test:0.02218, lr:5.43e-02, fs:0.64968 (r=0.586,p=0.729),  time:29.412, tt:1147.080\n",
      "Ep:39, loss:0.00001, loss_test:0.02247, lr:5.37e-02, fs:0.64968 (r=0.586,p=0.729),  time:29.486, tt:1179.455\n",
      "Ep:40, loss:0.00001, loss_test:0.02273, lr:5.32e-02, fs:0.64103 (r=0.575,p=0.725),  time:29.511, tt:1209.961\n",
      "Ep:41, loss:0.00001, loss_test:0.02314, lr:5.27e-02, fs:0.64103 (r=0.575,p=0.725),  time:29.483, tt:1238.297\n",
      "Ep:42, loss:0.00001, loss_test:0.02337, lr:5.21e-02, fs:0.64103 (r=0.575,p=0.725),  time:29.490, tt:1268.073\n",
      "Ep:43, loss:0.00001, loss_test:0.02361, lr:5.16e-02, fs:0.64103 (r=0.575,p=0.725),  time:29.492, tt:1297.632\n",
      "Ep:44, loss:0.00001, loss_test:0.02394, lr:5.11e-02, fs:0.64516 (r=0.575,p=0.735),  time:29.503, tt:1327.655\n",
      "Ep:45, loss:0.00001, loss_test:0.02417, lr:5.06e-02, fs:0.65359 (r=0.575,p=0.758),  time:29.542, tt:1358.928\n",
      "Ep:46, loss:0.00001, loss_test:0.02428, lr:5.01e-02, fs:0.65789 (r=0.575,p=0.769),  time:29.515, tt:1387.215\n",
      "Ep:47, loss:0.00001, loss_test:0.02464, lr:4.96e-02, fs:0.66667 (r=0.575,p=0.794),  time:29.500, tt:1416.000\n",
      "Ep:48, loss:0.00001, loss_test:0.02489, lr:4.91e-02, fs:0.67114 (r=0.575,p=0.806),  time:29.507, tt:1445.857\n",
      "Ep:49, loss:0.00001, loss_test:0.02512, lr:4.86e-02, fs:0.67114 (r=0.575,p=0.806),  time:29.506, tt:1475.284\n",
      "Ep:50, loss:0.00001, loss_test:0.02547, lr:4.81e-02, fs:0.67114 (r=0.575,p=0.806),  time:29.498, tt:1504.419\n",
      "Ep:51, loss:0.00001, loss_test:0.02575, lr:4.76e-02, fs:0.66216 (r=0.563,p=0.803),  time:29.449, tt:1531.355\n",
      "Ep:52, loss:0.00001, loss_test:0.02579, lr:4.71e-02, fs:0.67114 (r=0.575,p=0.806),  time:29.440, tt:1560.306\n",
      "Ep:53, loss:0.00001, loss_test:0.02596, lr:4.67e-02, fs:0.66216 (r=0.563,p=0.803),  time:29.425, tt:1588.962\n",
      "Ep:54, loss:0.00001, loss_test:0.02639, lr:4.62e-02, fs:0.66216 (r=0.563,p=0.803),  time:29.398, tt:1616.887\n",
      "Ep:55, loss:0.00001, loss_test:0.02671, lr:4.57e-02, fs:0.65306 (r=0.552,p=0.800),  time:29.417, tt:1647.326\n",
      "Ep:56, loss:0.00001, loss_test:0.02689, lr:4.53e-02, fs:0.65306 (r=0.552,p=0.800),  time:29.388, tt:1675.097\n",
      "Ep:57, loss:0.00001, loss_test:0.02718, lr:4.48e-02, fs:0.65306 (r=0.552,p=0.800),  time:29.384, tt:1704.244\n",
      "Ep:58, loss:0.00001, loss_test:0.02738, lr:4.44e-02, fs:0.65306 (r=0.552,p=0.800),  time:29.361, tt:1732.300\n",
      "Ep:59, loss:0.00001, loss_test:0.02784, lr:4.39e-02, fs:0.63448 (r=0.529,p=0.793),  time:29.353, tt:1761.168\n",
      "Ep:60, loss:0.00001, loss_test:0.02805, lr:4.35e-02, fs:0.63889 (r=0.529,p=0.807),  time:29.316, tt:1788.288\n",
      "Ep:61, loss:0.00001, loss_test:0.02829, lr:4.31e-02, fs:0.63889 (r=0.529,p=0.807),  time:29.323, tt:1818.051\n",
      "Ep:62, loss:0.00001, loss_test:0.02849, lr:4.26e-02, fs:0.64336 (r=0.529,p=0.821),  time:29.364, tt:1849.943\n",
      "Ep:63, loss:0.00001, loss_test:0.02883, lr:4.22e-02, fs:0.64336 (r=0.529,p=0.821),  time:29.389, tt:1880.918\n",
      "Ep:64, loss:0.00001, loss_test:0.02915, lr:4.18e-02, fs:0.64789 (r=0.529,p=0.836),  time:29.396, tt:1910.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.02922, lr:4.14e-02, fs:0.64789 (r=0.529,p=0.836),  time:29.379, tt:1939.047\n",
      "Ep:66, loss:0.00000, loss_test:0.02959, lr:4.10e-02, fs:0.64286 (r=0.517,p=0.849),  time:29.390, tt:1969.134\n",
      "Ep:67, loss:0.00000, loss_test:0.02979, lr:4.05e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.371, tt:1997.254\n",
      "Ep:68, loss:0.00000, loss_test:0.03000, lr:4.01e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.392, tt:2028.033\n",
      "Ep:69, loss:0.00000, loss_test:0.03012, lr:3.97e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.402, tt:2058.128\n",
      "Ep:70, loss:0.00000, loss_test:0.03026, lr:3.93e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.424, tt:2089.082\n",
      "Ep:71, loss:0.00000, loss_test:0.03050, lr:3.89e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.410, tt:2117.542\n",
      "Ep:72, loss:0.00000, loss_test:0.03077, lr:3.86e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.408, tt:2146.758\n",
      "Ep:73, loss:0.00000, loss_test:0.03083, lr:3.82e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.421, tt:2177.170\n",
      "Ep:74, loss:0.00000, loss_test:0.03106, lr:3.78e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.420, tt:2206.475\n",
      "Ep:75, loss:0.00000, loss_test:0.03113, lr:3.74e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.426, tt:2236.379\n",
      "Ep:76, loss:0.00000, loss_test:0.03148, lr:3.70e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.455, tt:2268.006\n",
      "Ep:77, loss:0.00000, loss_test:0.03163, lr:3.67e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.438, tt:2296.154\n",
      "Ep:78, loss:0.00000, loss_test:0.03166, lr:3.63e-02, fs:0.63309 (r=0.506,p=0.846),  time:29.442, tt:2325.914\n",
      "Ep:79, loss:0.00000, loss_test:0.03191, lr:3.59e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.437, tt:2354.945\n",
      "Ep:80, loss:0.00000, loss_test:0.03197, lr:3.56e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.450, tt:2385.452\n",
      "Ep:81, loss:0.00000, loss_test:0.03228, lr:3.52e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.443, tt:2414.352\n",
      "Ep:82, loss:0.00000, loss_test:0.03241, lr:3.49e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.451, tt:2444.443\n",
      "Ep:83, loss:0.00000, loss_test:0.03246, lr:3.45e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.470, tt:2475.463\n",
      "Ep:84, loss:0.00000, loss_test:0.03275, lr:3.42e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.478, tt:2505.598\n",
      "Ep:85, loss:0.00000, loss_test:0.03298, lr:3.38e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.489, tt:2536.087\n",
      "Ep:86, loss:0.00000, loss_test:0.03286, lr:3.35e-02, fs:0.64234 (r=0.506,p=0.880),  time:29.486, tt:2565.265\n",
      "Ep:87, loss:0.00000, loss_test:0.03314, lr:3.32e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.504, tt:2596.369\n",
      "Ep:88, loss:0.00000, loss_test:0.03335, lr:3.28e-02, fs:0.63768 (r=0.506,p=0.863),  time:29.485, tt:2624.155\n",
      "Ep:89, loss:0.00000, loss_test:0.03332, lr:3.25e-02, fs:0.63235 (r=0.494,p=0.878),  time:29.484, tt:2653.537\n",
      "Ep:90, loss:0.00000, loss_test:0.03344, lr:3.22e-02, fs:0.63704 (r=0.494,p=0.896),  time:29.456, tt:2680.530\n",
      "Ep:91, loss:0.00000, loss_test:0.03376, lr:3.19e-02, fs:0.63235 (r=0.494,p=0.878),  time:29.485, tt:2712.581\n",
      "Ep:92, loss:0.00000, loss_test:0.03375, lr:3.15e-02, fs:0.62687 (r=0.483,p=0.894),  time:29.490, tt:2742.579\n",
      "Ep:93, loss:0.00000, loss_test:0.03396, lr:3.12e-02, fs:0.61194 (r=0.471,p=0.872),  time:29.499, tt:2772.904\n",
      "Ep:94, loss:0.00000, loss_test:0.03404, lr:3.09e-02, fs:0.62121 (r=0.471,p=0.911),  time:29.493, tt:2801.848\n",
      "Ep:95, loss:0.00000, loss_test:0.03402, lr:3.06e-02, fs:0.63158 (r=0.483,p=0.913),  time:29.488, tt:2830.864\n",
      "Ep:96, loss:0.00000, loss_test:0.03428, lr:3.03e-02, fs:0.61069 (r=0.460,p=0.909),  time:29.486, tt:2860.178\n",
      "Ep:97, loss:0.00000, loss_test:0.03429, lr:3.00e-02, fs:0.60000 (r=0.448,p=0.907),  time:29.466, tt:2887.653\n",
      "Ep:98, loss:0.00000, loss_test:0.03450, lr:2.97e-02, fs:0.60000 (r=0.448,p=0.907),  time:29.473, tt:2917.848\n",
      "Ep:99, loss:0.00000, loss_test:0.03457, lr:2.94e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.508, tt:2950.825\n",
      "Ep:100, loss:0.00000, loss_test:0.03464, lr:2.91e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.484, tt:2977.858\n",
      "Ep:101, loss:0.00000, loss_test:0.03479, lr:2.88e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.469, tt:3005.880\n",
      "Ep:102, loss:0.00000, loss_test:0.03499, lr:2.85e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.489, tt:3037.411\n",
      "Ep:103, loss:0.00000, loss_test:0.03510, lr:2.82e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.494, tt:3067.373\n",
      "Ep:104, loss:0.00000, loss_test:0.03511, lr:2.80e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.502, tt:3097.740\n",
      "Ep:105, loss:0.00000, loss_test:0.03528, lr:2.77e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.509, tt:3127.998\n",
      "Ep:106, loss:0.00000, loss_test:0.03539, lr:2.74e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.509, tt:3157.432\n",
      "Ep:107, loss:0.00000, loss_test:0.03555, lr:2.71e-02, fs:0.59375 (r=0.437,p=0.927),  time:29.509, tt:3186.988\n",
      "Ep:108, loss:0.00000, loss_test:0.03563, lr:2.69e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.507, tt:3216.244\n",
      "Ep:109, loss:0.00000, loss_test:0.03561, lr:2.66e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.507, tt:3245.804\n",
      "Ep:110, loss:0.00000, loss_test:0.03564, lr:2.63e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.502, tt:3274.724\n",
      "Ep:111, loss:0.00000, loss_test:0.03580, lr:2.61e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.516, tt:3305.833\n",
      "Ep:112, loss:0.00000, loss_test:0.03601, lr:2.58e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.534, tt:3337.351\n",
      "Ep:113, loss:0.00000, loss_test:0.03604, lr:2.55e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.544, tt:3367.970\n",
      "Ep:114, loss:0.00000, loss_test:0.03616, lr:2.53e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.554, tt:3398.750\n",
      "Ep:115, loss:0.00000, loss_test:0.03623, lr:2.50e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.538, tt:3426.466\n",
      "Ep:116, loss:0.00000, loss_test:0.03632, lr:2.48e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.533, tt:3455.370\n",
      "Ep:117, loss:0.00000, loss_test:0.03632, lr:2.45e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.525, tt:3483.903\n",
      "Ep:118, loss:0.00000, loss_test:0.03649, lr:2.43e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.544, tt:3515.705\n",
      "Ep:119, loss:0.00000, loss_test:0.03646, lr:2.40e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.560, tt:3547.169\n",
      "Ep:120, loss:0.00000, loss_test:0.03661, lr:2.38e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.562, tt:3577.062\n",
      "Ep:121, loss:0.00000, loss_test:0.03676, lr:2.36e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.590, tt:3609.954\n",
      "Ep:122, loss:0.00000, loss_test:0.03676, lr:2.33e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.607, tt:3641.613\n",
      "Ep:123, loss:0.00000, loss_test:0.03677, lr:2.31e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.618, tt:3672.689\n",
      "Ep:124, loss:0.00000, loss_test:0.03683, lr:2.29e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.626, tt:3703.232\n",
      "Ep:125, loss:0.00000, loss_test:0.03701, lr:2.26e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.645, tt:3735.222\n",
      "Ep:126, loss:0.00000, loss_test:0.03718, lr:2.24e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.702, tt:3772.113\n",
      "Ep:127, loss:0.00000, loss_test:0.03701, lr:2.22e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.721, tt:3804.336\n",
      "Ep:128, loss:0.00000, loss_test:0.03712, lr:2.20e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.735, tt:3835.806\n",
      "Ep:129, loss:0.00000, loss_test:0.03732, lr:2.17e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.762, tt:3869.015\n",
      "Ep:130, loss:0.00000, loss_test:0.03730, lr:2.15e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.776, tt:3900.670\n",
      "Ep:131, loss:0.00000, loss_test:0.03743, lr:2.13e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.793, tt:3932.619\n",
      "Ep:132, loss:0.00000, loss_test:0.03756, lr:2.11e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.805, tt:3964.030\n",
      "Ep:133, loss:0.00000, loss_test:0.03739, lr:2.09e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.802, tt:3993.490\n",
      "Ep:134, loss:0.00000, loss_test:0.03756, lr:2.07e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.791, tt:4021.851\n",
      "Ep:135, loss:0.00000, loss_test:0.03771, lr:2.05e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.791, tt:4051.554\n",
      "Ep:136, loss:0.00000, loss_test:0.03762, lr:2.03e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.795, tt:4081.859\n",
      "Ep:137, loss:0.00000, loss_test:0.03773, lr:2.01e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.806, tt:4113.236\n",
      "Ep:138, loss:0.00000, loss_test:0.03781, lr:1.99e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.809, tt:4143.417\n",
      "Ep:139, loss:0.00000, loss_test:0.03785, lr:1.97e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.830, tt:4176.180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00000, loss_test:0.03796, lr:1.95e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.842, tt:4207.691\n",
      "Ep:141, loss:0.00000, loss_test:0.03802, lr:1.93e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.846, tt:4238.138\n",
      "Ep:142, loss:0.00000, loss_test:0.03796, lr:1.91e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.852, tt:4268.776\n",
      "Ep:143, loss:0.00000, loss_test:0.03798, lr:1.89e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.863, tt:4300.231\n",
      "Ep:144, loss:0.00000, loss_test:0.03806, lr:1.87e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.872, tt:4331.483\n",
      "Ep:145, loss:0.00000, loss_test:0.03815, lr:1.85e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.878, tt:4362.175\n",
      "Ep:146, loss:0.00000, loss_test:0.03818, lr:1.83e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.880, tt:4392.403\n",
      "Ep:147, loss:0.00000, loss_test:0.03825, lr:1.81e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.887, tt:4423.286\n",
      "Ep:148, loss:0.00000, loss_test:0.03832, lr:1.80e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.894, tt:4454.251\n",
      "Ep:149, loss:0.00000, loss_test:0.03836, lr:1.78e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.899, tt:4484.866\n",
      "Ep:150, loss:0.00000, loss_test:0.03837, lr:1.76e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.893, tt:4513.781\n",
      "Ep:151, loss:0.00000, loss_test:0.03839, lr:1.74e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.902, tt:4545.078\n",
      "Ep:152, loss:0.00000, loss_test:0.03843, lr:1.73e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.890, tt:4573.155\n",
      "Ep:153, loss:0.00000, loss_test:0.03860, lr:1.71e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.889, tt:4602.862\n",
      "Ep:154, loss:0.00000, loss_test:0.03853, lr:1.69e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.916, tt:4636.981\n",
      "Ep:155, loss:0.00000, loss_test:0.03852, lr:1.67e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.904, tt:4665.019\n",
      "Ep:156, loss:0.00000, loss_test:0.03869, lr:1.66e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.891, tt:4692.871\n",
      "Ep:157, loss:0.00000, loss_test:0.03869, lr:1.64e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.895, tt:4723.472\n",
      "Ep:158, loss:0.00000, loss_test:0.03864, lr:1.62e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.872, tt:4749.680\n",
      "Ep:159, loss:0.00000, loss_test:0.03878, lr:1.61e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.869, tt:4779.059\n",
      "Ep:160, loss:0.00000, loss_test:0.03880, lr:1.59e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.864, tt:4808.127\n",
      "Ep:161, loss:0.00000, loss_test:0.03876, lr:1.58e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.869, tt:4838.806\n",
      "Ep:162, loss:0.00000, loss_test:0.03890, lr:1.56e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.851, tt:4865.700\n",
      "Ep:163, loss:0.00000, loss_test:0.03893, lr:1.54e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.853, tt:4895.813\n",
      "Ep:164, loss:0.00000, loss_test:0.03888, lr:1.53e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.844, tt:4924.332\n",
      "Ep:165, loss:0.00000, loss_test:0.03893, lr:1.51e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.849, tt:4954.981\n",
      "Ep:166, loss:0.00000, loss_test:0.03895, lr:1.50e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.840, tt:4983.247\n",
      "Ep:167, loss:0.00000, loss_test:0.03906, lr:1.48e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.837, tt:5012.629\n",
      "Ep:168, loss:0.00000, loss_test:0.03904, lr:1.47e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.835, tt:5042.087\n",
      "Ep:169, loss:0.00000, loss_test:0.03907, lr:1.45e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.834, tt:5071.698\n",
      "Ep:170, loss:0.00000, loss_test:0.03912, lr:1.44e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.833, tt:5101.466\n",
      "Ep:171, loss:0.00000, loss_test:0.03911, lr:1.43e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.843, tt:5133.071\n",
      "Ep:172, loss:0.00000, loss_test:0.03913, lr:1.41e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.849, tt:5163.912\n",
      "Ep:173, loss:0.00000, loss_test:0.03923, lr:1.40e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.843, tt:5192.739\n",
      "Ep:174, loss:0.00000, loss_test:0.03926, lr:1.38e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.845, tt:5222.942\n",
      "Ep:175, loss:0.00000, loss_test:0.03926, lr:1.37e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.851, tt:5253.725\n",
      "Ep:176, loss:0.00000, loss_test:0.03926, lr:1.36e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.853, tt:5284.016\n",
      "Ep:177, loss:0.00000, loss_test:0.03930, lr:1.34e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.858, tt:5314.662\n",
      "Ep:178, loss:0.00000, loss_test:0.03933, lr:1.33e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.862, tt:5345.224\n",
      "Ep:179, loss:0.00000, loss_test:0.03934, lr:1.32e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.870, tt:5376.654\n",
      "Ep:180, loss:0.00000, loss_test:0.03945, lr:1.30e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.879, tt:5408.138\n",
      "Ep:181, loss:0.00000, loss_test:0.03942, lr:1.29e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.888, tt:5439.610\n",
      "Ep:182, loss:0.00000, loss_test:0.03936, lr:1.28e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.910, tt:5473.563\n",
      "Ep:183, loss:0.00000, loss_test:0.03946, lr:1.26e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.914, tt:5504.105\n",
      "Ep:184, loss:0.00000, loss_test:0.03951, lr:1.25e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.921, tt:5535.433\n",
      "Ep:185, loss:0.00000, loss_test:0.03947, lr:1.24e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.917, tt:5564.642\n",
      "Ep:186, loss:0.00000, loss_test:0.03952, lr:1.23e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.913, tt:5593.777\n",
      "Ep:187, loss:0.00000, loss_test:0.03960, lr:1.21e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.906, tt:5622.390\n",
      "Ep:188, loss:0.00000, loss_test:0.03965, lr:1.20e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.910, tt:5653.000\n",
      "Ep:189, loss:0.00000, loss_test:0.03962, lr:1.19e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.908, tt:5682.503\n",
      "Ep:190, loss:0.00000, loss_test:0.03964, lr:1.18e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.902, tt:5711.344\n",
      "Ep:191, loss:0.00000, loss_test:0.03962, lr:1.17e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.901, tt:5740.977\n",
      "Ep:192, loss:0.00000, loss_test:0.03964, lr:1.15e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.895, tt:5769.727\n",
      "Ep:193, loss:0.00000, loss_test:0.03970, lr:1.14e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.900, tt:5800.636\n",
      "Ep:194, loss:0.00000, loss_test:0.03970, lr:1.13e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.894, tt:5829.307\n",
      "Ep:195, loss:0.00000, loss_test:0.03972, lr:1.12e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.905, tt:5861.320\n",
      "Ep:196, loss:0.00000, loss_test:0.03979, lr:1.11e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.914, tt:5893.135\n",
      "Ep:197, loss:0.00000, loss_test:0.03979, lr:1.10e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.922, tt:5924.475\n",
      "Ep:198, loss:0.00000, loss_test:0.03975, lr:1.09e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.924, tt:5954.786\n",
      "Ep:199, loss:0.00000, loss_test:0.03976, lr:1.08e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.922, tt:5984.433\n",
      "Ep:200, loss:0.00000, loss_test:0.03982, lr:1.07e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.917, tt:6013.332\n",
      "Ep:201, loss:0.00000, loss_test:0.03987, lr:1.05e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.914, tt:6042.574\n",
      "Ep:202, loss:0.00000, loss_test:0.03989, lr:1.04e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.921, tt:6073.997\n",
      "Ep:203, loss:0.00000, loss_test:0.03990, lr:1.03e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.934, tt:6106.528\n",
      "Ep:204, loss:0.00000, loss_test:0.03992, lr:1.02e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.965, tt:6142.776\n",
      "Ep:205, loss:0.00000, loss_test:0.03993, lr:1.01e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.964, tt:6172.599\n",
      "Ep:206, loss:0.00000, loss_test:0.03992, lr:1.00e-02, fs:0.59843 (r=0.437,p=0.950),  time:29.959, tt:6201.608\n",
      "Ep:207, loss:0.00000, loss_test:0.03999, lr:9.93e-03, fs:0.59843 (r=0.437,p=0.950),  time:29.964, tt:6232.579\n",
      "Ep:208, loss:0.00000, loss_test:0.04002, lr:9.83e-03, fs:0.59843 (r=0.437,p=0.950),  time:29.965, tt:6262.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14169, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.598, tt:31.598\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00027, loss_test:0.13940, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.469, tt:62.937\n",
      "Ep:2, loss:0.00027, loss_test:0.13486, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:30.800, tt:92.400\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12699, lr:1.00e-02, fs:0.67511 (r=0.920,p=0.533),  time:29.026, tt:116.104\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.12110, lr:1.00e-02, fs:0.67961 (r=0.805,p=0.588),  time:28.899, tt:144.496\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.12118, lr:1.00e-02, fs:0.65625 (r=0.724,p=0.600),  time:28.113, tt:168.677\n",
      "Ep:6, loss:0.00022, loss_test:0.11855, lr:1.00e-02, fs:0.65608 (r=0.713,p=0.608),  time:28.037, tt:196.256\n",
      "Ep:7, loss:0.00021, loss_test:0.11468, lr:1.00e-02, fs:0.66667 (r=0.747,p=0.602),  time:27.923, tt:223.383\n",
      "Ep:8, loss:0.00021, loss_test:0.11273, lr:1.00e-02, fs:0.68085 (r=0.736,p=0.634),  time:28.366, tt:255.293\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11273, lr:1.00e-02, fs:0.68539 (r=0.701,p=0.670),  time:28.798, tt:287.985\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.11008, lr:1.00e-02, fs:0.70056 (r=0.713,p=0.689),  time:29.149, tt:320.644\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.10700, lr:1.00e-02, fs:0.74194 (r=0.793,p=0.697),  time:29.104, tt:349.253\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.10709, lr:1.00e-02, fs:0.74860 (r=0.770,p=0.728),  time:29.436, tt:382.672\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.10599, lr:1.00e-02, fs:0.75978 (r=0.782,p=0.739),  time:29.570, tt:413.987\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10301, lr:1.00e-02, fs:0.78022 (r=0.816,p=0.747),  time:29.694, tt:445.408\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00015, loss_test:0.10159, lr:1.00e-02, fs:0.77966 (r=0.793,p=0.767),  time:29.878, tt:478.044\n",
      "Ep:16, loss:0.00014, loss_test:0.10068, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:30.113, tt:511.928\n",
      "Ep:17, loss:0.00014, loss_test:0.10018, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:30.268, tt:544.829\n",
      "Ep:18, loss:0.00013, loss_test:0.09785, lr:1.00e-02, fs:0.73988 (r=0.736,p=0.744),  time:30.290, tt:575.503\n",
      "Ep:19, loss:0.00012, loss_test:0.09801, lr:1.00e-02, fs:0.73256 (r=0.724,p=0.741),  time:30.297, tt:605.939\n",
      "Ep:20, loss:0.00012, loss_test:0.09774, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:30.371, tt:637.794\n",
      "Ep:21, loss:0.00011, loss_test:0.09562, lr:1.00e-02, fs:0.72941 (r=0.713,p=0.747),  time:30.416, tt:669.162\n",
      "Ep:22, loss:0.00011, loss_test:0.09731, lr:1.00e-02, fs:0.73810 (r=0.713,p=0.765),  time:30.393, tt:699.028\n",
      "Ep:23, loss:0.00010, loss_test:0.09449, lr:1.00e-02, fs:0.75000 (r=0.724,p=0.778),  time:30.418, tt:730.034\n",
      "Ep:24, loss:0.00010, loss_test:0.09444, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:30.403, tt:760.086\n",
      "Ep:25, loss:0.00009, loss_test:0.09401, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:30.392, tt:790.189\n",
      "Ep:26, loss:0.00009, loss_test:0.09287, lr:9.90e-03, fs:0.73810 (r=0.713,p=0.765),  time:30.351, tt:819.484\n",
      "Ep:27, loss:0.00008, loss_test:0.09466, lr:9.80e-03, fs:0.71605 (r=0.667,p=0.773),  time:30.339, tt:849.491\n",
      "Ep:28, loss:0.00008, loss_test:0.09141, lr:9.70e-03, fs:0.76074 (r=0.713,p=0.816),  time:30.348, tt:880.102\n",
      "Ep:29, loss:0.00007, loss_test:0.09551, lr:9.61e-03, fs:0.70370 (r=0.655,p=0.760),  time:30.364, tt:910.925\n",
      "Ep:30, loss:0.00007, loss_test:0.09237, lr:9.51e-03, fs:0.73750 (r=0.678,p=0.808),  time:30.326, tt:940.091\n",
      "Ep:31, loss:0.00007, loss_test:0.09441, lr:9.41e-03, fs:0.71338 (r=0.644,p=0.800),  time:30.314, tt:970.034\n",
      "Ep:32, loss:0.00006, loss_test:0.09328, lr:9.32e-03, fs:0.70513 (r=0.632,p=0.797),  time:30.269, tt:998.889\n",
      "Ep:33, loss:0.00006, loss_test:0.09524, lr:9.23e-03, fs:0.69737 (r=0.609,p=0.815),  time:30.280, tt:1029.527\n",
      "Ep:34, loss:0.00006, loss_test:0.09377, lr:9.14e-03, fs:0.74534 (r=0.690,p=0.811),  time:30.281, tt:1059.826\n",
      "Ep:35, loss:0.00005, loss_test:0.09348, lr:9.04e-03, fs:0.71053 (r=0.621,p=0.831),  time:30.299, tt:1090.749\n",
      "Ep:36, loss:0.00005, loss_test:0.09269, lr:8.95e-03, fs:0.72727 (r=0.644,p=0.836),  time:30.356, tt:1123.156\n",
      "Ep:37, loss:0.00004, loss_test:0.08919, lr:8.86e-03, fs:0.73885 (r=0.667,p=0.829),  time:30.360, tt:1153.698\n",
      "Ep:38, loss:0.00004, loss_test:0.09005, lr:8.78e-03, fs:0.75949 (r=0.690,p=0.845),  time:30.376, tt:1184.658\n",
      "Ep:39, loss:0.00004, loss_test:0.09039, lr:8.69e-03, fs:0.74359 (r=0.667,p=0.841),  time:30.392, tt:1215.685\n",
      "Ep:40, loss:0.00004, loss_test:0.09127, lr:8.60e-03, fs:0.72727 (r=0.644,p=0.836),  time:30.432, tt:1247.724\n",
      "Ep:41, loss:0.00003, loss_test:0.08695, lr:8.51e-03, fs:0.80488 (r=0.759,p=0.857),  time:30.435, tt:1278.269\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.08927, lr:8.51e-03, fs:0.72368 (r=0.632,p=0.846),  time:30.484, tt:1310.828\n",
      "Ep:43, loss:0.00003, loss_test:0.08592, lr:8.51e-03, fs:0.76730 (r=0.701,p=0.847),  time:30.525, tt:1343.114\n",
      "Ep:44, loss:0.00003, loss_test:0.09891, lr:8.51e-03, fs:0.71233 (r=0.598,p=0.881),  time:30.571, tt:1375.707\n",
      "Ep:45, loss:0.00003, loss_test:0.08391, lr:8.51e-03, fs:0.79268 (r=0.747,p=0.844),  time:30.515, tt:1403.692\n",
      "Ep:46, loss:0.00003, loss_test:0.09453, lr:8.51e-03, fs:0.68085 (r=0.552,p=0.889),  time:30.557, tt:1436.157\n",
      "Ep:47, loss:0.00003, loss_test:0.08880, lr:8.51e-03, fs:0.76730 (r=0.701,p=0.847),  time:30.570, tt:1467.377\n",
      "Ep:48, loss:0.00002, loss_test:0.09167, lr:8.51e-03, fs:0.69863 (r=0.586,p=0.864),  time:30.577, tt:1498.285\n",
      "Ep:49, loss:0.00002, loss_test:0.08781, lr:8.51e-03, fs:0.76129 (r=0.678,p=0.868),  time:30.584, tt:1529.176\n",
      "Ep:50, loss:0.00002, loss_test:0.09346, lr:8.51e-03, fs:0.70748 (r=0.598,p=0.867),  time:30.588, tt:1560.004\n",
      "Ep:51, loss:0.00002, loss_test:0.09002, lr:8.51e-03, fs:0.76316 (r=0.667,p=0.892),  time:30.586, tt:1590.494\n",
      "Ep:52, loss:0.00002, loss_test:0.09040, lr:8.51e-03, fs:0.75000 (r=0.655,p=0.877),  time:30.582, tt:1620.846\n",
      "Ep:53, loss:0.00002, loss_test:0.10130, lr:8.43e-03, fs:0.73103 (r=0.609,p=0.914),  time:30.565, tt:1650.502\n",
      "Ep:54, loss:0.00002, loss_test:0.09020, lr:8.35e-03, fs:0.73333 (r=0.632,p=0.873),  time:30.574, tt:1681.582\n",
      "Ep:55, loss:0.00002, loss_test:0.09514, lr:8.26e-03, fs:0.72848 (r=0.632,p=0.859),  time:30.561, tt:1711.423\n",
      "Ep:56, loss:0.00002, loss_test:0.10395, lr:8.18e-03, fs:0.69014 (r=0.563,p=0.891),  time:30.581, tt:1743.112\n",
      "Ep:57, loss:0.00002, loss_test:0.09028, lr:8.10e-03, fs:0.80000 (r=0.713,p=0.912),  time:30.615, tt:1775.672\n",
      "Ep:58, loss:0.00002, loss_test:0.09527, lr:8.02e-03, fs:0.69565 (r=0.552,p=0.941),  time:30.604, tt:1805.614\n",
      "Ep:59, loss:0.00001, loss_test:0.10030, lr:7.94e-03, fs:0.74324 (r=0.632,p=0.902),  time:30.603, tt:1836.178\n",
      "Ep:60, loss:0.00001, loss_test:0.08960, lr:7.86e-03, fs:0.78146 (r=0.678,p=0.922),  time:30.607, tt:1867.033\n",
      "Ep:61, loss:0.00001, loss_test:0.10291, lr:7.78e-03, fs:0.75000 (r=0.621,p=0.947),  time:30.616, tt:1898.209\n",
      "Ep:62, loss:0.00001, loss_test:0.09323, lr:7.70e-03, fs:0.70423 (r=0.575,p=0.909),  time:30.636, tt:1930.077\n",
      "Ep:63, loss:0.00001, loss_test:0.10028, lr:7.62e-03, fs:0.73759 (r=0.598,p=0.963),  time:30.675, tt:1963.219\n",
      "Ep:64, loss:0.00001, loss_test:0.09748, lr:7.55e-03, fs:0.70000 (r=0.563,p=0.925),  time:30.671, tt:1993.646\n",
      "Ep:65, loss:0.00001, loss_test:0.09652, lr:7.47e-03, fs:0.74830 (r=0.632,p=0.917),  time:30.726, tt:2027.898\n",
      "Ep:66, loss:0.00001, loss_test:0.10094, lr:7.40e-03, fs:0.67164 (r=0.517,p=0.957),  time:30.751, tt:2060.322\n",
      "Ep:67, loss:0.00001, loss_test:0.09689, lr:7.32e-03, fs:0.68613 (r=0.540,p=0.940),  time:30.829, tt:2096.406\n",
      "Ep:68, loss:0.00001, loss_test:0.09829, lr:7.25e-03, fs:0.66667 (r=0.517,p=0.938),  time:30.866, tt:2129.779\n",
      "Ep:69, loss:0.00001, loss_test:0.09958, lr:7.18e-03, fs:0.66667 (r=0.517,p=0.938),  time:30.923, tt:2164.628\n",
      "Ep:70, loss:0.00001, loss_test:0.10146, lr:7.11e-03, fs:0.68148 (r=0.529,p=0.958),  time:30.987, tt:2200.096\n",
      "Ep:71, loss:0.00001, loss_test:0.09866, lr:7.03e-03, fs:0.66667 (r=0.517,p=0.938),  time:31.043, tt:2235.131\n",
      "Ep:72, loss:0.00001, loss_test:0.10255, lr:6.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.094, tt:2269.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:73, loss:0.00001, loss_test:0.10408, lr:6.89e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.156, tt:2305.552\n",
      "Ep:74, loss:0.00001, loss_test:0.09880, lr:6.83e-03, fs:0.66667 (r=0.517,p=0.938),  time:31.184, tt:2338.812\n",
      "Ep:75, loss:0.00001, loss_test:0.10544, lr:6.76e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.252, tt:2375.147\n",
      "Ep:76, loss:0.00001, loss_test:0.10165, lr:6.69e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.333, tt:2412.642\n",
      "Ep:77, loss:0.00001, loss_test:0.10089, lr:6.62e-03, fs:0.66667 (r=0.517,p=0.938),  time:31.401, tt:2449.277\n",
      "Ep:78, loss:0.00001, loss_test:0.10750, lr:6.56e-03, fs:0.67669 (r=0.517,p=0.978),  time:31.467, tt:2485.926\n",
      "Ep:79, loss:0.00001, loss_test:0.10277, lr:6.49e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.487, tt:2518.982\n",
      "Ep:80, loss:0.00000, loss_test:0.10670, lr:6.43e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.528, tt:2553.797\n",
      "Ep:81, loss:0.00000, loss_test:0.10350, lr:6.36e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.572, tt:2588.865\n",
      "Ep:82, loss:0.00000, loss_test:0.10622, lr:6.30e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.604, tt:2623.148\n",
      "Ep:83, loss:0.00000, loss_test:0.10561, lr:6.24e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.676, tt:2660.780\n",
      "Ep:84, loss:0.00000, loss_test:0.10711, lr:6.17e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.746, tt:2698.436\n",
      "Ep:85, loss:0.00000, loss_test:0.10639, lr:6.11e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.785, tt:2733.532\n",
      "Ep:86, loss:0.00000, loss_test:0.10577, lr:6.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.804, tt:2766.963\n",
      "Ep:87, loss:0.00000, loss_test:0.11011, lr:5.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:31.845, tt:2802.329\n",
      "Ep:88, loss:0.00000, loss_test:0.10386, lr:5.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.911, tt:2840.041\n",
      "Ep:89, loss:0.00000, loss_test:0.10951, lr:5.87e-03, fs:0.67669 (r=0.517,p=0.978),  time:31.943, tt:2874.882\n",
      "Ep:90, loss:0.00000, loss_test:0.10783, lr:5.81e-03, fs:0.67164 (r=0.517,p=0.957),  time:31.965, tt:2908.829\n",
      "Ep:91, loss:0.00000, loss_test:0.11066, lr:5.75e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.017, tt:2945.556\n",
      "Ep:92, loss:0.00000, loss_test:0.10478, lr:5.70e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.077, tt:2983.150\n",
      "Ep:93, loss:0.00000, loss_test:0.11156, lr:5.64e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.123, tt:3019.606\n",
      "Ep:94, loss:0.00000, loss_test:0.10705, lr:5.58e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.169, tt:3056.090\n",
      "Ep:95, loss:0.00000, loss_test:0.11077, lr:5.53e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.217, tt:3092.826\n",
      "Ep:96, loss:0.00000, loss_test:0.10740, lr:5.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.252, tt:3128.399\n",
      "Ep:97, loss:0.00000, loss_test:0.11092, lr:5.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.303, tt:3165.675\n",
      "Ep:98, loss:0.00000, loss_test:0.10741, lr:5.36e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.347, tt:3202.349\n",
      "Ep:99, loss:0.00000, loss_test:0.11033, lr:5.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.390, tt:3239.040\n",
      "Ep:100, loss:0.00000, loss_test:0.10866, lr:5.26e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.419, tt:3274.323\n",
      "Ep:101, loss:0.00000, loss_test:0.11067, lr:5.20e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.444, tt:3309.273\n",
      "Ep:102, loss:0.00000, loss_test:0.10732, lr:5.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.463, tt:3343.705\n",
      "Ep:103, loss:0.00000, loss_test:0.11134, lr:5.10e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.504, tt:3380.387\n",
      "Ep:104, loss:0.00000, loss_test:0.10736, lr:5.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.524, tt:3415.066\n",
      "Ep:105, loss:0.00000, loss_test:0.11219, lr:5.00e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.554, tt:3450.769\n",
      "Ep:106, loss:0.00000, loss_test:0.10717, lr:4.95e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.566, tt:3484.571\n",
      "Ep:107, loss:0.00000, loss_test:0.11165, lr:4.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.616, tt:3522.542\n",
      "Ep:108, loss:0.00000, loss_test:0.10879, lr:4.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.635, tt:3557.227\n",
      "Ep:109, loss:0.00000, loss_test:0.11076, lr:4.80e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.662, tt:3592.791\n",
      "Ep:110, loss:0.00000, loss_test:0.10874, lr:4.75e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.704, tt:3630.167\n",
      "Ep:111, loss:0.00000, loss_test:0.11094, lr:4.71e-03, fs:0.68182 (r=0.517,p=1.000),  time:32.731, tt:3665.901\n",
      "Ep:112, loss:0.00000, loss_test:0.10812, lr:4.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.739, tt:3699.505\n",
      "Ep:113, loss:0.00000, loss_test:0.10878, lr:4.61e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.772, tt:3735.973\n",
      "Ep:114, loss:0.00000, loss_test:0.11139, lr:4.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.799, tt:3771.884\n",
      "Ep:115, loss:0.00000, loss_test:0.10774, lr:4.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.838, tt:3809.232\n",
      "Ep:116, loss:0.00000, loss_test:0.11112, lr:4.48e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.875, tt:3846.385\n",
      "Ep:117, loss:0.00000, loss_test:0.10786, lr:4.43e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.923, tt:3884.881\n",
      "Ep:118, loss:0.00000, loss_test:0.11034, lr:4.39e-03, fs:0.67164 (r=0.517,p=0.957),  time:32.953, tt:3921.395\n",
      "Ep:119, loss:0.00000, loss_test:0.11015, lr:4.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:32.976, tt:3957.144\n",
      "Ep:120, loss:0.00000, loss_test:0.10964, lr:4.30e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.020, tt:3995.473\n",
      "Ep:121, loss:0.00000, loss_test:0.11093, lr:4.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.061, tt:4033.435\n",
      "Ep:122, loss:0.00000, loss_test:0.10916, lr:4.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.094, tt:4070.601\n",
      "Ep:123, loss:0.00000, loss_test:0.11201, lr:4.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.127, tt:4107.695\n",
      "Ep:124, loss:0.00000, loss_test:0.10940, lr:4.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.151, tt:4143.826\n",
      "Ep:125, loss:0.00000, loss_test:0.10893, lr:4.09e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.172, tt:4179.673\n",
      "Ep:126, loss:0.00000, loss_test:0.10997, lr:4.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.227, tt:4219.879\n",
      "Ep:127, loss:0.00000, loss_test:0.11039, lr:4.01e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.240, tt:4254.773\n",
      "Ep:128, loss:0.00000, loss_test:0.10974, lr:3.97e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.253, tt:4289.693\n",
      "Ep:129, loss:0.00000, loss_test:0.10859, lr:3.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.248, tt:4322.228\n",
      "Ep:130, loss:0.00000, loss_test:0.11248, lr:3.89e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.251, tt:4355.907\n",
      "Ep:131, loss:0.00000, loss_test:0.10976, lr:3.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.270, tt:4391.578\n",
      "Ep:132, loss:0.00000, loss_test:0.10817, lr:3.81e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.264, tt:4424.106\n",
      "Ep:133, loss:0.00000, loss_test:0.11252, lr:3.77e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.292, tt:4461.069\n",
      "Ep:134, loss:0.00000, loss_test:0.11063, lr:3.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.315, tt:4497.567\n",
      "Ep:135, loss:0.00000, loss_test:0.10968, lr:3.70e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.350, tt:4535.543\n",
      "Ep:136, loss:0.00000, loss_test:0.10954, lr:3.66e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.382, tt:4573.342\n",
      "Ep:137, loss:0.00000, loss_test:0.11008, lr:3.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.391, tt:4607.913\n",
      "Ep:138, loss:0.00000, loss_test:0.11040, lr:3.59e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.400, tt:4642.612\n",
      "Ep:139, loss:0.00000, loss_test:0.10907, lr:3.55e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.422, tt:4679.103\n",
      "Ep:140, loss:0.00000, loss_test:0.11093, lr:3.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.476, tt:4720.069\n",
      "Ep:141, loss:0.00000, loss_test:0.11217, lr:3.48e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.503, tt:4757.458\n",
      "Ep:142, loss:0.00000, loss_test:0.10973, lr:3.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.523, tt:4793.777\n",
      "Ep:143, loss:0.00000, loss_test:0.10985, lr:3.41e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.526, tt:4827.714\n",
      "Ep:144, loss:0.00000, loss_test:0.11024, lr:3.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.542, tt:4863.641\n",
      "Ep:145, loss:0.00000, loss_test:0.11053, lr:3.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.573, tt:4901.612\n",
      "Ep:146, loss:0.00000, loss_test:0.10891, lr:3.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.602, tt:4939.480\n",
      "Ep:147, loss:0.00000, loss_test:0.10870, lr:3.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.633, tt:4977.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00000, loss_test:0.11084, lr:3.24e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.645, tt:5013.050\n",
      "Ep:149, loss:0.00000, loss_test:0.10918, lr:3.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.666, tt:5049.906\n",
      "Ep:150, loss:0.00000, loss_test:0.10999, lr:3.18e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.694, tt:5087.813\n",
      "Ep:151, loss:0.00000, loss_test:0.11031, lr:3.15e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.718, tt:5125.195\n",
      "Ep:152, loss:0.00000, loss_test:0.10971, lr:3.12e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.730, tt:5160.762\n",
      "Ep:153, loss:0.00000, loss_test:0.11065, lr:3.09e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.734, tt:5195.069\n",
      "Ep:154, loss:0.00000, loss_test:0.10951, lr:3.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.761, tt:5233.025\n",
      "Ep:155, loss:0.00000, loss_test:0.10959, lr:3.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.775, tt:5268.845\n",
      "Ep:156, loss:0.00000, loss_test:0.11069, lr:2.99e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.789, tt:5304.934\n",
      "Ep:157, loss:0.00000, loss_test:0.10954, lr:2.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.806, tt:5341.425\n",
      "Ep:158, loss:0.00000, loss_test:0.10890, lr:2.93e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.820, tt:5377.420\n",
      "Ep:159, loss:0.00000, loss_test:0.11019, lr:2.90e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.842, tt:5414.659\n",
      "Ep:160, loss:0.00000, loss_test:0.10970, lr:2.88e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.850, tt:5449.802\n",
      "Ep:161, loss:0.00000, loss_test:0.10933, lr:2.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.871, tt:5487.146\n",
      "Ep:162, loss:0.00000, loss_test:0.10980, lr:2.82e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.881, tt:5522.522\n",
      "Ep:163, loss:0.00000, loss_test:0.10940, lr:2.79e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.906, tt:5560.638\n",
      "Ep:164, loss:0.00000, loss_test:0.11029, lr:2.76e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.915, tt:5596.010\n",
      "Ep:165, loss:0.00000, loss_test:0.10949, lr:2.73e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.931, tt:5632.579\n",
      "Ep:166, loss:0.00000, loss_test:0.10920, lr:2.71e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.943, tt:5668.522\n",
      "Ep:167, loss:0.00000, loss_test:0.11072, lr:2.68e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.961, tt:5705.457\n",
      "Ep:168, loss:0.00000, loss_test:0.10988, lr:2.65e-03, fs:0.67164 (r=0.517,p=0.957),  time:33.981, tt:5742.860\n",
      "Ep:169, loss:0.00000, loss_test:0.10923, lr:2.63e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.001, tt:5780.123\n",
      "Ep:170, loss:0.00000, loss_test:0.10954, lr:2.60e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.002, tt:5814.355\n",
      "Ep:171, loss:0.00000, loss_test:0.10979, lr:2.57e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.015, tt:5850.523\n",
      "Ep:172, loss:0.00000, loss_test:0.10930, lr:2.55e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.031, tt:5887.439\n",
      "Ep:173, loss:0.00000, loss_test:0.10882, lr:2.52e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.043, tt:5923.466\n",
      "Ep:174, loss:0.00000, loss_test:0.10941, lr:2.50e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.062, tt:5960.917\n",
      "Ep:175, loss:0.00000, loss_test:0.10983, lr:2.47e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.064, tt:5995.215\n",
      "Ep:176, loss:0.00000, loss_test:0.10914, lr:2.45e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.080, tt:6032.199\n",
      "Ep:177, loss:0.00000, loss_test:0.10939, lr:2.42e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.127, tt:6074.521\n",
      "Ep:178, loss:0.00000, loss_test:0.10967, lr:2.40e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.143, tt:6111.552\n",
      "Ep:179, loss:0.00000, loss_test:0.10871, lr:2.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.160, tt:6148.799\n",
      "Ep:180, loss:0.00000, loss_test:0.10995, lr:2.35e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.175, tt:6185.674\n",
      "Ep:181, loss:0.00000, loss_test:0.10982, lr:2.33e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.190, tt:6222.644\n",
      "Ep:182, loss:0.00000, loss_test:0.10893, lr:2.31e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.202, tt:6258.891\n",
      "Ep:183, loss:0.00000, loss_test:0.10942, lr:2.28e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.218, tt:6296.146\n",
      "Ep:184, loss:0.00000, loss_test:0.10926, lr:2.26e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.233, tt:6333.093\n",
      "Ep:185, loss:0.00000, loss_test:0.10955, lr:2.24e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.235, tt:6367.638\n",
      "Ep:186, loss:0.00000, loss_test:0.10975, lr:2.21e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.232, tt:6401.372\n",
      "Ep:187, loss:0.00000, loss_test:0.10853, lr:2.19e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.236, tt:6436.411\n",
      "Ep:188, loss:0.00000, loss_test:0.10867, lr:2.17e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.238, tt:6470.958\n",
      "Ep:189, loss:0.00000, loss_test:0.10948, lr:2.15e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.252, tt:6507.953\n",
      "Ep:190, loss:0.00000, loss_test:0.10935, lr:2.13e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.255, tt:6542.696\n",
      "Ep:191, loss:0.00000, loss_test:0.10847, lr:2.11e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.267, tt:6579.351\n",
      "Ep:192, loss:0.00000, loss_test:0.10894, lr:2.08e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.274, tt:6614.836\n",
      "Ep:193, loss:0.00000, loss_test:0.10970, lr:2.06e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.290, tt:6652.319\n",
      "Ep:194, loss:0.00000, loss_test:0.10929, lr:2.04e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.301, tt:6688.682\n",
      "Ep:195, loss:0.00000, loss_test:0.10888, lr:2.02e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.309, tt:6724.615\n",
      "Ep:196, loss:0.00000, loss_test:0.10919, lr:2.00e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.314, tt:6759.808\n",
      "Ep:197, loss:0.00000, loss_test:0.10920, lr:1.98e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.322, tt:6795.758\n",
      "Ep:198, loss:0.00000, loss_test:0.10906, lr:1.96e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.329, tt:6831.457\n",
      "Ep:199, loss:0.00000, loss_test:0.10891, lr:1.94e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.338, tt:6867.645\n",
      "Ep:200, loss:0.00000, loss_test:0.10901, lr:1.92e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.349, tt:6904.180\n",
      "Ep:201, loss:0.00000, loss_test:0.10895, lr:1.90e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.366, tt:6941.895\n",
      "Ep:202, loss:0.00000, loss_test:0.10871, lr:1.89e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.374, tt:6977.845\n",
      "Ep:203, loss:0.00000, loss_test:0.10901, lr:1.87e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.383, tt:7014.088\n",
      "Ep:204, loss:0.00000, loss_test:0.10868, lr:1.85e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.391, tt:7050.244\n",
      "Ep:205, loss:0.00000, loss_test:0.10861, lr:1.83e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.405, tt:7087.362\n",
      "Ep:206, loss:0.00000, loss_test:0.10899, lr:1.81e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.424, tt:7125.689\n",
      "Ep:207, loss:0.00000, loss_test:0.10975, lr:1.79e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.440, tt:7163.449\n",
      "Ep:208, loss:0.00000, loss_test:0.10979, lr:1.78e-03, fs:0.67164 (r=0.517,p=0.957),  time:34.449, tt:7199.815\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02058, lr:6.00e-02, fs:0.62661 (r=0.839,p=0.500),  time:13.365, tt:13.365\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02352, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.620, tt:27.239\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.048, tt:45.143\n",
      "Ep:3, loss:0.00005, loss_test:0.02474, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.493, tt:69.970\n",
      "Ep:4, loss:0.00005, loss_test:0.02370, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.281, tt:96.407\n",
      "Ep:5, loss:0.00004, loss_test:0.02229, lr:6.00e-02, fs:0.64542 (r=0.931,p=0.494),  time:22.024, tt:132.147\n",
      "Ep:6, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.65289 (r=0.908,p=0.510),  time:23.983, tt:167.878\n",
      "Ep:7, loss:0.00004, loss_test:0.02096, lr:6.00e-02, fs:0.65158 (r=0.828,p=0.537),  time:25.395, tt:203.158\n",
      "Ep:8, loss:0.00004, loss_test:0.02119, lr:6.00e-02, fs:0.65072 (r=0.782,p=0.557),  time:26.696, tt:240.264\n",
      "Ep:9, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.64706 (r=0.759,p=0.564),  time:28.029, tt:280.285\n",
      "Ep:10, loss:0.00004, loss_test:0.01953, lr:6.00e-02, fs:0.65049 (r=0.770,p=0.563),  time:28.784, tt:316.628\n",
      "Ep:11, loss:0.00003, loss_test:0.01851, lr:6.00e-02, fs:0.67907 (r=0.839,p=0.570),  time:29.440, tt:353.280\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01785, lr:6.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:29.897, tt:388.657\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.69406 (r=0.874,p=0.576),  time:30.389, tt:425.444\n",
      "Ep:14, loss:0.00003, loss_test:0.01741, lr:6.00e-02, fs:0.72115 (r=0.862,p=0.620),  time:30.875, tt:463.130\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01743, lr:6.00e-02, fs:0.73892 (r=0.862,p=0.647),  time:31.212, tt:499.389\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01736, lr:6.00e-02, fs:0.75377 (r=0.862,p=0.670),  time:31.516, tt:535.779\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01711, lr:6.00e-02, fs:0.74627 (r=0.862,p=0.658),  time:31.642, tt:569.551\n",
      "Ep:18, loss:0.00003, loss_test:0.01694, lr:6.00e-02, fs:0.74877 (r=0.874,p=0.655),  time:31.926, tt:606.598\n",
      "Ep:19, loss:0.00003, loss_test:0.01686, lr:6.00e-02, fs:0.75122 (r=0.885,p=0.653),  time:32.127, tt:642.537\n",
      "Ep:20, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.74257 (r=0.862,p=0.652),  time:32.378, tt:679.928\n",
      "Ep:21, loss:0.00002, loss_test:0.01697, lr:6.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:32.538, tt:715.840\n",
      "Ep:22, loss:0.00002, loss_test:0.01727, lr:6.00e-02, fs:0.69565 (r=0.736,p=0.660),  time:32.696, tt:752.006\n",
      "Ep:23, loss:0.00002, loss_test:0.01748, lr:6.00e-02, fs:0.68132 (r=0.713,p=0.653),  time:32.994, tt:791.856\n",
      "Ep:24, loss:0.00002, loss_test:0.01756, lr:6.00e-02, fs:0.67778 (r=0.701,p=0.656),  time:33.153, tt:828.834\n",
      "Ep:25, loss:0.00002, loss_test:0.01760, lr:6.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:33.321, tt:866.337\n",
      "Ep:26, loss:0.00002, loss_test:0.01766, lr:6.00e-02, fs:0.69231 (r=0.724,p=0.663),  time:33.441, tt:902.915\n",
      "Ep:27, loss:0.00002, loss_test:0.01791, lr:6.00e-02, fs:0.68889 (r=0.713,p=0.667),  time:33.552, tt:939.458\n",
      "Ep:28, loss:0.00002, loss_test:0.01828, lr:5.94e-02, fs:0.69318 (r=0.701,p=0.685),  time:33.631, tt:975.313\n",
      "Ep:29, loss:0.00002, loss_test:0.01865, lr:5.88e-02, fs:0.68208 (r=0.678,p=0.686),  time:33.737, tt:1012.110\n",
      "Ep:30, loss:0.00002, loss_test:0.01887, lr:5.82e-02, fs:0.69364 (r=0.690,p=0.698),  time:33.811, tt:1048.148\n",
      "Ep:31, loss:0.00002, loss_test:0.01913, lr:5.76e-02, fs:0.69412 (r=0.678,p=0.711),  time:33.895, tt:1084.636\n",
      "Ep:32, loss:0.00002, loss_test:0.01934, lr:5.71e-02, fs:0.70175 (r=0.690,p=0.714),  time:33.974, tt:1121.147\n",
      "Ep:33, loss:0.00002, loss_test:0.01968, lr:5.65e-02, fs:0.69412 (r=0.678,p=0.711),  time:34.027, tt:1156.935\n",
      "Ep:34, loss:0.00002, loss_test:0.01989, lr:5.59e-02, fs:0.69461 (r=0.667,p=0.725),  time:34.121, tt:1194.222\n",
      "Ep:35, loss:0.00001, loss_test:0.02012, lr:5.54e-02, fs:0.69880 (r=0.667,p=0.734),  time:34.225, tt:1232.089\n",
      "Ep:36, loss:0.00001, loss_test:0.02043, lr:5.48e-02, fs:0.70303 (r=0.667,p=0.744),  time:34.318, tt:1269.760\n",
      "Ep:37, loss:0.00001, loss_test:0.02075, lr:5.43e-02, fs:0.70732 (r=0.667,p=0.753),  time:34.364, tt:1305.827\n",
      "Ep:38, loss:0.00001, loss_test:0.02112, lr:5.37e-02, fs:0.68323 (r=0.632,p=0.743),  time:34.397, tt:1341.474\n",
      "Ep:39, loss:0.00001, loss_test:0.02136, lr:5.32e-02, fs:0.68323 (r=0.632,p=0.743),  time:34.439, tt:1377.541\n",
      "Ep:40, loss:0.00001, loss_test:0.02155, lr:5.27e-02, fs:0.70000 (r=0.644,p=0.767),  time:34.513, tt:1415.021\n",
      "Ep:41, loss:0.00001, loss_test:0.02167, lr:5.21e-02, fs:0.70000 (r=0.644,p=0.767),  time:34.583, tt:1452.478\n",
      "Ep:42, loss:0.00001, loss_test:0.02190, lr:5.16e-02, fs:0.69182 (r=0.632,p=0.764),  time:34.631, tt:1489.137\n",
      "Ep:43, loss:0.00001, loss_test:0.02219, lr:5.11e-02, fs:0.69620 (r=0.632,p=0.775),  time:34.668, tt:1525.408\n",
      "Ep:44, loss:0.00001, loss_test:0.02247, lr:5.06e-02, fs:0.70064 (r=0.632,p=0.786),  time:34.726, tt:1562.687\n",
      "Ep:45, loss:0.00001, loss_test:0.02269, lr:5.01e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.764, tt:1599.155\n",
      "Ep:46, loss:0.00001, loss_test:0.02291, lr:4.96e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.825, tt:1636.763\n",
      "Ep:47, loss:0.00001, loss_test:0.02310, lr:4.91e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.855, tt:1673.058\n",
      "Ep:48, loss:0.00001, loss_test:0.02327, lr:4.86e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.899, tt:1710.028\n",
      "Ep:49, loss:0.00001, loss_test:0.02348, lr:4.81e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.915, tt:1745.775\n",
      "Ep:50, loss:0.00001, loss_test:0.02373, lr:4.76e-02, fs:0.70513 (r=0.632,p=0.797),  time:34.913, tt:1780.587\n",
      "Ep:51, loss:0.00001, loss_test:0.02399, lr:4.71e-02, fs:0.70130 (r=0.621,p=0.806),  time:34.964, tt:1818.114\n",
      "Ep:52, loss:0.00001, loss_test:0.02414, lr:4.67e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.010, tt:1855.510\n",
      "Ep:53, loss:0.00001, loss_test:0.02437, lr:4.62e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.043, tt:1892.342\n",
      "Ep:54, loss:0.00001, loss_test:0.02458, lr:4.57e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.065, tt:1928.577\n",
      "Ep:55, loss:0.00001, loss_test:0.02475, lr:4.53e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.075, tt:1964.215\n",
      "Ep:56, loss:0.00001, loss_test:0.02495, lr:4.48e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.124, tt:2002.051\n",
      "Ep:57, loss:0.00001, loss_test:0.02511, lr:4.44e-02, fs:0.71429 (r=0.632,p=0.821),  time:35.113, tt:2036.525\n",
      "Ep:58, loss:0.00001, loss_test:0.02528, lr:4.39e-02, fs:0.71429 (r=0.632,p=0.821),  time:35.146, tt:2073.593\n",
      "Ep:59, loss:0.00001, loss_test:0.02545, lr:4.35e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.192, tt:2111.536\n",
      "Ep:60, loss:0.00001, loss_test:0.02572, lr:4.31e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.228, tt:2148.931\n",
      "Ep:61, loss:0.00001, loss_test:0.02598, lr:4.26e-02, fs:0.70588 (r=0.621,p=0.818),  time:35.250, tt:2185.487\n",
      "Ep:62, loss:0.00001, loss_test:0.02605, lr:4.22e-02, fs:0.71053 (r=0.621,p=0.831),  time:35.269, tt:2221.961\n",
      "Ep:63, loss:0.00001, loss_test:0.02620, lr:4.18e-02, fs:0.71523 (r=0.621,p=0.844),  time:35.285, tt:2258.243\n",
      "Ep:64, loss:0.00001, loss_test:0.02645, lr:4.14e-02, fs:0.72368 (r=0.632,p=0.846),  time:35.306, tt:2294.896\n",
      "Ep:65, loss:0.00001, loss_test:0.02664, lr:4.10e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.426, tt:2338.095\n",
      "Ep:66, loss:0.00001, loss_test:0.02680, lr:4.05e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.430, tt:2373.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00001, loss_test:0.02695, lr:4.01e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.459, tt:2411.217\n",
      "Ep:68, loss:0.00001, loss_test:0.02709, lr:3.97e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.461, tt:2446.808\n",
      "Ep:69, loss:0.00001, loss_test:0.02727, lr:3.93e-02, fs:0.72368 (r=0.632,p=0.846),  time:35.494, tt:2484.569\n",
      "Ep:70, loss:0.00001, loss_test:0.02745, lr:3.89e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.530, tt:2522.640\n",
      "Ep:71, loss:0.00001, loss_test:0.02762, lr:3.86e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.553, tt:2559.830\n",
      "Ep:72, loss:0.00001, loss_test:0.02776, lr:3.82e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.565, tt:2596.261\n",
      "Ep:73, loss:0.00000, loss_test:0.02790, lr:3.78e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.586, tt:2633.336\n",
      "Ep:74, loss:0.00000, loss_test:0.02806, lr:3.74e-02, fs:0.70667 (r=0.609,p=0.841),  time:35.590, tt:2669.214\n",
      "Ep:75, loss:0.00000, loss_test:0.02820, lr:3.70e-02, fs:0.71141 (r=0.609,p=0.855),  time:35.606, tt:2706.053\n",
      "Ep:76, loss:0.00000, loss_test:0.02834, lr:3.67e-02, fs:0.70270 (r=0.598,p=0.852),  time:35.600, tt:2741.226\n",
      "Ep:77, loss:0.00000, loss_test:0.02852, lr:3.63e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.594, tt:2776.342\n",
      "Ep:78, loss:0.00000, loss_test:0.02868, lr:3.59e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.593, tt:2811.861\n",
      "Ep:79, loss:0.00000, loss_test:0.02885, lr:3.56e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.610, tt:2848.780\n",
      "Ep:80, loss:0.00000, loss_test:0.02900, lr:3.52e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.594, tt:2883.096\n",
      "Ep:81, loss:0.00000, loss_test:0.02912, lr:3.49e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.615, tt:2920.418\n",
      "Ep:82, loss:0.00000, loss_test:0.02928, lr:3.45e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.629, tt:2957.229\n",
      "Ep:83, loss:0.00000, loss_test:0.02943, lr:3.42e-02, fs:0.69863 (r=0.586,p=0.864),  time:35.649, tt:2994.512\n",
      "Ep:84, loss:0.00000, loss_test:0.02957, lr:3.38e-02, fs:0.69863 (r=0.586,p=0.864),  time:35.650, tt:3030.276\n",
      "Ep:85, loss:0.00000, loss_test:0.02968, lr:3.35e-02, fs:0.70748 (r=0.598,p=0.867),  time:35.644, tt:3065.395\n",
      "Ep:86, loss:0.00000, loss_test:0.02981, lr:3.32e-02, fs:0.69863 (r=0.586,p=0.864),  time:35.624, tt:3099.322\n",
      "Ep:87, loss:0.00000, loss_test:0.02997, lr:3.28e-02, fs:0.69863 (r=0.586,p=0.864),  time:35.626, tt:3135.105\n",
      "Ep:88, loss:0.00000, loss_test:0.03007, lr:3.25e-02, fs:0.69444 (r=0.575,p=0.877),  time:35.638, tt:3171.793\n",
      "Ep:89, loss:0.00000, loss_test:0.03021, lr:3.22e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.634, tt:3207.024\n",
      "Ep:90, loss:0.00000, loss_test:0.03031, lr:3.19e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.650, tt:3244.139\n",
      "Ep:91, loss:0.00000, loss_test:0.03035, lr:3.15e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.630, tt:3277.990\n",
      "Ep:92, loss:0.00000, loss_test:0.03055, lr:3.12e-02, fs:0.69444 (r=0.575,p=0.877),  time:35.636, tt:3314.188\n",
      "Ep:93, loss:0.00000, loss_test:0.03073, lr:3.09e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.638, tt:3349.930\n",
      "Ep:94, loss:0.00000, loss_test:0.03078, lr:3.06e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.649, tt:3386.637\n",
      "Ep:95, loss:0.00000, loss_test:0.03088, lr:3.03e-02, fs:0.69444 (r=0.575,p=0.877),  time:35.665, tt:3423.808\n",
      "Ep:96, loss:0.00000, loss_test:0.03107, lr:3.00e-02, fs:0.70345 (r=0.586,p=0.879),  time:35.649, tt:3457.924\n",
      "Ep:97, loss:0.00000, loss_test:0.03118, lr:2.97e-02, fs:0.69444 (r=0.575,p=0.877),  time:35.656, tt:3494.263\n",
      "Ep:98, loss:0.00000, loss_test:0.03127, lr:2.94e-02, fs:0.69444 (r=0.575,p=0.877),  time:35.654, tt:3529.767\n",
      "Ep:99, loss:0.00000, loss_test:0.03136, lr:2.91e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.666, tt:3566.562\n",
      "Ep:100, loss:0.00000, loss_test:0.03153, lr:2.88e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.663, tt:3601.930\n",
      "Ep:101, loss:0.00000, loss_test:0.03163, lr:2.85e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.654, tt:3636.665\n",
      "Ep:102, loss:0.00000, loss_test:0.03172, lr:2.82e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.653, tt:3672.280\n",
      "Ep:103, loss:0.00000, loss_test:0.03182, lr:2.80e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.653, tt:3707.907\n",
      "Ep:104, loss:0.00000, loss_test:0.03193, lr:2.77e-02, fs:0.67606 (r=0.552,p=0.873),  time:35.662, tt:3744.497\n",
      "Ep:105, loss:0.00000, loss_test:0.03204, lr:2.74e-02, fs:0.67606 (r=0.552,p=0.873),  time:35.649, tt:3778.764\n",
      "Ep:106, loss:0.00000, loss_test:0.03215, lr:2.71e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.653, tt:3814.850\n",
      "Ep:107, loss:0.00000, loss_test:0.03222, lr:2.69e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.630, tt:3848.057\n",
      "Ep:108, loss:0.00000, loss_test:0.03226, lr:2.66e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.619, tt:3882.511\n",
      "Ep:109, loss:0.00000, loss_test:0.03243, lr:2.63e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.580, tt:3913.814\n",
      "Ep:110, loss:0.00000, loss_test:0.03250, lr:2.61e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.539, tt:3944.781\n",
      "Ep:111, loss:0.00000, loss_test:0.03252, lr:2.58e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.510, tt:3977.125\n",
      "Ep:112, loss:0.00000, loss_test:0.03267, lr:2.55e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.456, tt:4006.527\n",
      "Ep:113, loss:0.00000, loss_test:0.03283, lr:2.53e-02, fs:0.66667 (r=0.540,p=0.870),  time:35.426, tt:4038.508\n",
      "Ep:114, loss:0.00000, loss_test:0.03286, lr:2.50e-02, fs:0.65714 (r=0.529,p=0.868),  time:35.371, tt:4067.657\n",
      "Ep:115, loss:0.00000, loss_test:0.03287, lr:2.48e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.339, tt:4099.345\n",
      "Ep:116, loss:0.00000, loss_test:0.03298, lr:2.45e-02, fs:0.65714 (r=0.529,p=0.868),  time:35.310, tt:4131.225\n",
      "Ep:117, loss:0.00000, loss_test:0.03305, lr:2.43e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.309, tt:4166.469\n",
      "Ep:118, loss:0.00000, loss_test:0.03306, lr:2.40e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.340, tt:4205.420\n",
      "Ep:119, loss:0.00000, loss_test:0.03313, lr:2.38e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.340, tt:4240.748\n",
      "Ep:120, loss:0.00000, loss_test:0.03323, lr:2.36e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.339, tt:4275.964\n",
      "Ep:121, loss:0.00000, loss_test:0.03333, lr:2.33e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.351, tt:4312.789\n",
      "Ep:122, loss:0.00000, loss_test:0.03338, lr:2.31e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.339, tt:4346.722\n",
      "Ep:123, loss:0.00000, loss_test:0.03347, lr:2.29e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.352, tt:4383.589\n",
      "Ep:124, loss:0.00000, loss_test:0.03353, lr:2.26e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.366, tt:4420.764\n",
      "Ep:125, loss:0.00000, loss_test:0.03359, lr:2.24e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.378, tt:4457.667\n",
      "Ep:126, loss:0.00000, loss_test:0.03369, lr:2.22e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.390, tt:4494.518\n",
      "Ep:127, loss:0.00000, loss_test:0.03377, lr:2.20e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.399, tt:4531.013\n",
      "Ep:128, loss:0.00000, loss_test:0.03379, lr:2.17e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.393, tt:4565.708\n",
      "Ep:129, loss:0.00000, loss_test:0.03385, lr:2.15e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.399, tt:4601.879\n",
      "Ep:130, loss:0.00000, loss_test:0.03397, lr:2.13e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.417, tt:4639.634\n",
      "Ep:131, loss:0.00000, loss_test:0.03404, lr:2.11e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.429, tt:4676.636\n",
      "Ep:132, loss:0.00000, loss_test:0.03409, lr:2.09e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.423, tt:4711.226\n",
      "Ep:133, loss:0.00000, loss_test:0.03417, lr:2.07e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.428, tt:4747.370\n",
      "Ep:134, loss:0.00000, loss_test:0.03429, lr:2.05e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.442, tt:4784.721\n",
      "Ep:135, loss:0.00000, loss_test:0.03428, lr:2.03e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.447, tt:4820.732\n",
      "Ep:136, loss:0.00000, loss_test:0.03435, lr:2.01e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.459, tt:4857.938\n",
      "Ep:137, loss:0.00000, loss_test:0.03444, lr:1.99e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.470, tt:4894.814\n",
      "Ep:138, loss:0.00000, loss_test:0.03449, lr:1.97e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.472, tt:4930.642\n",
      "Ep:139, loss:0.00000, loss_test:0.03457, lr:1.95e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.471, tt:4965.937\n",
      "Ep:140, loss:0.00000, loss_test:0.03465, lr:1.93e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.464, tt:5000.455\n",
      "Ep:141, loss:0.00000, loss_test:0.03472, lr:1.91e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.479, tt:5037.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00000, loss_test:0.03476, lr:1.89e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.492, tt:5075.355\n",
      "Ep:143, loss:0.00000, loss_test:0.03479, lr:1.87e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.491, tt:5110.634\n",
      "Ep:144, loss:0.00000, loss_test:0.03487, lr:1.85e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.495, tt:5146.729\n",
      "Ep:145, loss:0.00000, loss_test:0.03493, lr:1.83e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.515, tt:5185.140\n",
      "Ep:146, loss:0.00000, loss_test:0.03496, lr:1.81e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.520, tt:5221.398\n",
      "Ep:147, loss:0.00000, loss_test:0.03503, lr:1.80e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.522, tt:5257.201\n",
      "Ep:148, loss:0.00000, loss_test:0.03506, lr:1.78e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.528, tt:5293.657\n",
      "Ep:149, loss:0.00000, loss_test:0.03514, lr:1.76e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.532, tt:5329.856\n",
      "Ep:150, loss:0.00000, loss_test:0.03518, lr:1.74e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.535, tt:5365.743\n",
      "Ep:151, loss:0.00000, loss_test:0.03520, lr:1.73e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.540, tt:5402.015\n",
      "Ep:152, loss:0.00000, loss_test:0.03526, lr:1.71e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.541, tt:5437.769\n",
      "Ep:153, loss:0.00000, loss_test:0.03532, lr:1.69e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.550, tt:5474.717\n",
      "Ep:154, loss:0.00000, loss_test:0.03535, lr:1.67e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.549, tt:5510.040\n",
      "Ep:155, loss:0.00000, loss_test:0.03535, lr:1.66e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.547, tt:5545.372\n",
      "Ep:156, loss:0.00000, loss_test:0.03544, lr:1.64e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.549, tt:5581.156\n",
      "Ep:157, loss:0.00000, loss_test:0.03549, lr:1.62e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.547, tt:5616.435\n",
      "Ep:158, loss:0.00000, loss_test:0.03553, lr:1.61e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.542, tt:5651.229\n",
      "Ep:159, loss:0.00000, loss_test:0.03556, lr:1.59e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.542, tt:5686.757\n",
      "Ep:160, loss:0.00000, loss_test:0.03558, lr:1.58e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.531, tt:5720.411\n",
      "Ep:161, loss:0.00000, loss_test:0.03562, lr:1.56e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.532, tt:5756.182\n",
      "Ep:162, loss:0.00000, loss_test:0.03565, lr:1.54e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.531, tt:5791.574\n",
      "Ep:163, loss:0.00000, loss_test:0.03570, lr:1.53e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.527, tt:5826.453\n",
      "Ep:164, loss:0.00000, loss_test:0.03573, lr:1.51e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.523, tt:5861.245\n",
      "Ep:165, loss:0.00000, loss_test:0.03576, lr:1.50e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.525, tt:5897.177\n",
      "Ep:166, loss:0.00000, loss_test:0.03579, lr:1.48e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.524, tt:5932.468\n",
      "Ep:167, loss:0.00000, loss_test:0.03582, lr:1.47e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.527, tt:5968.550\n",
      "Ep:168, loss:0.00000, loss_test:0.03586, lr:1.45e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.537, tt:6005.777\n",
      "Ep:169, loss:0.00000, loss_test:0.03588, lr:1.44e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.544, tt:6042.536\n",
      "Ep:170, loss:0.00000, loss_test:0.03590, lr:1.43e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.554, tt:6079.788\n",
      "Ep:171, loss:0.00000, loss_test:0.03593, lr:1.41e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.561, tt:6116.424\n",
      "Ep:172, loss:0.00000, loss_test:0.03597, lr:1.40e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.569, tt:6153.440\n",
      "Ep:173, loss:0.00000, loss_test:0.03600, lr:1.38e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.586, tt:6191.932\n",
      "Ep:174, loss:0.00000, loss_test:0.03603, lr:1.37e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.581, tt:6226.602\n",
      "Ep:175, loss:0.00000, loss_test:0.03603, lr:1.36e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.586, tt:6263.149\n",
      "Ep:176, loss:0.00000, loss_test:0.03608, lr:1.34e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.590, tt:6299.431\n",
      "Ep:177, loss:0.00000, loss_test:0.03611, lr:1.33e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.608, tt:6338.247\n",
      "Ep:178, loss:0.00000, loss_test:0.03614, lr:1.32e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.613, tt:6374.689\n",
      "Ep:179, loss:0.00000, loss_test:0.03616, lr:1.30e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.628, tt:6413.063\n",
      "Ep:180, loss:0.00000, loss_test:0.03619, lr:1.29e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.633, tt:6449.580\n",
      "Ep:181, loss:0.00000, loss_test:0.03622, lr:1.28e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.636, tt:6485.734\n",
      "Ep:182, loss:0.00000, loss_test:0.03624, lr:1.26e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.646, tt:6523.270\n",
      "Ep:183, loss:0.00000, loss_test:0.03628, lr:1.25e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.655, tt:6560.561\n",
      "Ep:184, loss:0.00000, loss_test:0.03631, lr:1.24e-02, fs:0.64748 (r=0.517,p=0.865),  time:35.655, tt:6596.251\n",
      "Ep:185, loss:0.00000, loss_test:0.03635, lr:1.23e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.652, tt:6631.188\n",
      "Ep:186, loss:0.00000, loss_test:0.03638, lr:1.21e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.659, tt:6668.214\n",
      "Ep:187, loss:0.00000, loss_test:0.03641, lr:1.20e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.664, tt:6704.743\n",
      "Ep:188, loss:0.00000, loss_test:0.03642, lr:1.19e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.679, tt:6743.321\n",
      "Ep:189, loss:0.00000, loss_test:0.03645, lr:1.18e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.685, tt:6780.072\n",
      "Ep:190, loss:0.00000, loss_test:0.03648, lr:1.17e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.680, tt:6814.848\n",
      "Ep:191, loss:0.00000, loss_test:0.03651, lr:1.15e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.672, tt:6849.036\n",
      "Ep:192, loss:0.00000, loss_test:0.03654, lr:1.14e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.704, tt:6890.860\n",
      "Ep:193, loss:0.00000, loss_test:0.03656, lr:1.13e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.705, tt:6926.746\n",
      "Ep:194, loss:0.00000, loss_test:0.03658, lr:1.12e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.712, tt:6963.782\n",
      "Ep:195, loss:0.00000, loss_test:0.03661, lr:1.11e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.721, tt:7001.329\n",
      "Ep:196, loss:0.00000, loss_test:0.03664, lr:1.10e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.727, tt:7038.224\n",
      "Ep:197, loss:0.00000, loss_test:0.03665, lr:1.09e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.732, tt:7074.855\n",
      "Ep:198, loss:0.00000, loss_test:0.03667, lr:1.08e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.726, tt:7109.433\n",
      "Ep:199, loss:0.00000, loss_test:0.03671, lr:1.07e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.731, tt:7146.152\n",
      "Ep:200, loss:0.00000, loss_test:0.03673, lr:1.05e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.737, tt:7183.074\n",
      "Ep:201, loss:0.00000, loss_test:0.03674, lr:1.04e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.733, tt:7218.066\n",
      "Ep:202, loss:0.00000, loss_test:0.03675, lr:1.03e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.729, tt:7253.077\n",
      "Ep:203, loss:0.00000, loss_test:0.03680, lr:1.02e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.729, tt:7288.720\n",
      "Ep:204, loss:0.00000, loss_test:0.03684, lr:1.01e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.729, tt:7324.533\n",
      "Ep:205, loss:0.00000, loss_test:0.03685, lr:1.00e-02, fs:0.65217 (r=0.517,p=0.882),  time:35.739, tt:7362.164\n",
      "Ep:206, loss:0.00000, loss_test:0.03688, lr:9.93e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.747, tt:7399.667\n",
      "Ep:207, loss:0.00000, loss_test:0.03690, lr:9.83e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.754, tt:7436.842\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14419, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.427, tt:34.427\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14305, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.337, tt:72.674\n",
      "Ep:2, loss:0.00028, loss_test:0.14106, lr:1.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:35.466, tt:106.397\n",
      "Ep:3, loss:0.00027, loss_test:0.13773, lr:1.00e-02, fs:0.64000 (r=0.920,p=0.491),  time:34.730, tt:138.920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00026, loss_test:0.13259, lr:1.00e-02, fs:0.65502 (r=0.862,p=0.528),  time:34.799, tt:173.993\n",
      "Ep:5, loss:0.00024, loss_test:0.12960, lr:1.00e-02, fs:0.63768 (r=0.759,p=0.550),  time:34.866, tt:209.197\n",
      "Ep:6, loss:0.00023, loss_test:0.13115, lr:1.00e-02, fs:0.65476 (r=0.632,p=0.679),  time:35.289, tt:247.021\n",
      "Ep:7, loss:0.00022, loss_test:0.12480, lr:1.00e-02, fs:0.65169 (r=0.667,p=0.637),  time:35.378, tt:283.023\n",
      "Ep:8, loss:0.00021, loss_test:0.11891, lr:1.00e-02, fs:0.68750 (r=0.759,p=0.629),  time:35.596, tt:320.366\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11677, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:35.594, tt:355.942\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.11592, lr:1.00e-02, fs:0.67500 (r=0.621,p=0.740),  time:35.723, tt:392.957\n",
      "Ep:11, loss:0.00018, loss_test:0.11063, lr:1.00e-02, fs:0.73743 (r=0.759,p=0.717),  time:35.774, tt:429.284\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.11025, lr:1.00e-02, fs:0.67073 (r=0.632,p=0.714),  time:35.966, tt:467.559\n",
      "Ep:13, loss:0.00016, loss_test:0.11298, lr:1.00e-02, fs:0.69677 (r=0.621,p=0.794),  time:35.966, tt:503.530\n",
      "Ep:14, loss:0.00016, loss_test:0.10851, lr:1.00e-02, fs:0.70659 (r=0.678,p=0.738),  time:35.981, tt:539.713\n",
      "Ep:15, loss:0.00015, loss_test:0.10708, lr:1.00e-02, fs:0.73054 (r=0.701,p=0.762),  time:36.012, tt:576.192\n",
      "Ep:16, loss:0.00014, loss_test:0.10943, lr:1.00e-02, fs:0.73292 (r=0.678,p=0.797),  time:36.184, tt:615.128\n",
      "Ep:17, loss:0.00014, loss_test:0.10569, lr:1.00e-02, fs:0.73373 (r=0.713,p=0.756),  time:36.135, tt:650.422\n",
      "Ep:18, loss:0.00013, loss_test:0.10710, lr:1.00e-02, fs:0.75152 (r=0.713,p=0.795),  time:36.008, tt:684.150\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.10925, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:35.948, tt:718.952\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.10412, lr:1.00e-02, fs:0.73939 (r=0.701,p=0.782),  time:35.942, tt:754.789\n",
      "Ep:21, loss:0.00011, loss_test:0.10718, lr:1.00e-02, fs:0.74534 (r=0.690,p=0.811),  time:35.905, tt:789.912\n",
      "Ep:22, loss:0.00010, loss_test:0.10556, lr:1.00e-02, fs:0.73750 (r=0.678,p=0.808),  time:35.879, tt:825.223\n",
      "Ep:23, loss:0.00010, loss_test:0.10561, lr:1.00e-02, fs:0.77576 (r=0.736,p=0.821),  time:35.865, tt:860.762\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00009, loss_test:0.10694, lr:1.00e-02, fs:0.72611 (r=0.655,p=0.814),  time:35.798, tt:894.949\n",
      "Ep:25, loss:0.00009, loss_test:0.10577, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:35.756, tt:929.664\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00008, loss_test:0.10512, lr:1.00e-02, fs:0.74359 (r=0.667,p=0.841),  time:35.600, tt:961.200\n",
      "Ep:27, loss:0.00008, loss_test:0.10556, lr:1.00e-02, fs:0.75159 (r=0.678,p=0.843),  time:35.614, tt:997.179\n",
      "Ep:28, loss:0.00007, loss_test:0.10435, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:35.577, tt:1031.742\n",
      "Ep:29, loss:0.00007, loss_test:0.11072, lr:1.00e-02, fs:0.76129 (r=0.678,p=0.868),  time:35.579, tt:1067.357\n",
      "Ep:30, loss:0.00006, loss_test:0.10209, lr:1.00e-02, fs:0.75159 (r=0.678,p=0.843),  time:35.651, tt:1105.192\n",
      "Ep:31, loss:0.00006, loss_test:0.11140, lr:1.00e-02, fs:0.75000 (r=0.655,p=0.877),  time:35.736, tt:1143.555\n",
      "Ep:32, loss:0.00005, loss_test:0.10547, lr:1.00e-02, fs:0.76129 (r=0.678,p=0.868),  time:35.756, tt:1179.942\n",
      "Ep:33, loss:0.00005, loss_test:0.11358, lr:1.00e-02, fs:0.71329 (r=0.586,p=0.911),  time:35.826, tt:1218.091\n",
      "Ep:34, loss:0.00004, loss_test:0.10639, lr:1.00e-02, fs:0.75817 (r=0.667,p=0.879),  time:35.873, tt:1255.573\n",
      "Ep:35, loss:0.00004, loss_test:0.11009, lr:1.00e-02, fs:0.68531 (r=0.563,p=0.875),  time:35.857, tt:1290.855\n",
      "Ep:36, loss:0.00004, loss_test:0.10936, lr:1.00e-02, fs:0.71622 (r=0.609,p=0.869),  time:35.895, tt:1328.099\n",
      "Ep:37, loss:0.00004, loss_test:0.10807, lr:9.90e-03, fs:0.69863 (r=0.586,p=0.864),  time:35.888, tt:1363.754\n",
      "Ep:38, loss:0.00003, loss_test:0.11070, lr:9.80e-03, fs:0.71233 (r=0.598,p=0.881),  time:35.884, tt:1399.466\n",
      "Ep:39, loss:0.00003, loss_test:0.11027, lr:9.70e-03, fs:0.69014 (r=0.563,p=0.891),  time:35.934, tt:1437.356\n",
      "Ep:40, loss:0.00003, loss_test:0.11205, lr:9.61e-03, fs:0.70833 (r=0.586,p=0.895),  time:35.934, tt:1473.283\n",
      "Ep:41, loss:0.00003, loss_test:0.11510, lr:9.51e-03, fs:0.66667 (r=0.529,p=0.902),  time:35.917, tt:1508.526\n",
      "Ep:42, loss:0.00002, loss_test:0.10988, lr:9.41e-03, fs:0.69863 (r=0.586,p=0.864),  time:35.908, tt:1544.045\n",
      "Ep:43, loss:0.00002, loss_test:0.11604, lr:9.32e-03, fs:0.66187 (r=0.529,p=0.885),  time:35.886, tt:1578.991\n",
      "Ep:44, loss:0.00002, loss_test:0.10965, lr:9.23e-03, fs:0.66197 (r=0.540,p=0.855),  time:35.891, tt:1615.075\n",
      "Ep:45, loss:0.00002, loss_test:0.11632, lr:9.14e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.901, tt:1651.430\n",
      "Ep:46, loss:0.00002, loss_test:0.11115, lr:9.04e-03, fs:0.66187 (r=0.529,p=0.885),  time:35.879, tt:1686.332\n",
      "Ep:47, loss:0.00002, loss_test:0.11803, lr:8.95e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.842, tt:1720.427\n",
      "Ep:48, loss:0.00002, loss_test:0.11143, lr:8.86e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.853, tt:1756.812\n",
      "Ep:49, loss:0.00002, loss_test:0.12330, lr:8.78e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.807, tt:1790.359\n",
      "Ep:50, loss:0.00001, loss_test:0.11393, lr:8.69e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.802, tt:1825.890\n",
      "Ep:51, loss:0.00001, loss_test:0.11712, lr:8.60e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.783, tt:1860.702\n",
      "Ep:52, loss:0.00001, loss_test:0.12262, lr:8.51e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.752, tt:1894.869\n",
      "Ep:53, loss:0.00001, loss_test:0.11137, lr:8.43e-03, fs:0.64748 (r=0.517,p=0.865),  time:35.732, tt:1929.504\n",
      "Ep:54, loss:0.00001, loss_test:0.12176, lr:8.35e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.732, tt:1965.283\n",
      "Ep:55, loss:0.00001, loss_test:0.11322, lr:8.26e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.764, tt:2002.795\n",
      "Ep:56, loss:0.00001, loss_test:0.12100, lr:8.18e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.797, tt:2040.415\n",
      "Ep:57, loss:0.00001, loss_test:0.11763, lr:8.10e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.828, tt:2078.042\n",
      "Ep:58, loss:0.00001, loss_test:0.11670, lr:8.02e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.865, tt:2116.030\n",
      "Ep:59, loss:0.00001, loss_test:0.11910, lr:7.94e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.842, tt:2150.493\n",
      "Ep:60, loss:0.00001, loss_test:0.11879, lr:7.86e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.848, tt:2186.704\n",
      "Ep:61, loss:0.00001, loss_test:0.11746, lr:7.78e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.849, tt:2222.612\n",
      "Ep:62, loss:0.00001, loss_test:0.12042, lr:7.70e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.879, tt:2260.370\n",
      "Ep:63, loss:0.00001, loss_test:0.11907, lr:7.62e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.863, tt:2295.222\n",
      "Ep:64, loss:0.00001, loss_test:0.11882, lr:7.55e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.877, tt:2331.989\n",
      "Ep:65, loss:0.00001, loss_test:0.12013, lr:7.47e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.850, tt:2366.102\n",
      "Ep:66, loss:0.00001, loss_test:0.11829, lr:7.40e-03, fs:0.65217 (r=0.517,p=0.882),  time:35.873, tt:2403.515\n",
      "Ep:67, loss:0.00001, loss_test:0.12031, lr:7.32e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.888, tt:2440.405\n",
      "Ep:68, loss:0.00001, loss_test:0.12021, lr:7.25e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.884, tt:2475.980\n",
      "Ep:69, loss:0.00001, loss_test:0.11846, lr:7.18e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.906, tt:2513.451\n",
      "Ep:70, loss:0.00000, loss_test:0.12166, lr:7.11e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.921, tt:2550.386\n",
      "Ep:71, loss:0.00000, loss_test:0.11843, lr:7.03e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.928, tt:2586.849\n",
      "Ep:72, loss:0.00000, loss_test:0.12112, lr:6.96e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.958, tt:2624.965\n",
      "Ep:73, loss:0.00000, loss_test:0.12161, lr:6.89e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.957, tt:2660.849\n",
      "Ep:74, loss:0.00000, loss_test:0.11891, lr:6.83e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.949, tt:2696.197\n",
      "Ep:75, loss:0.00000, loss_test:0.12148, lr:6.76e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.962, tt:2733.111\n",
      "Ep:76, loss:0.00000, loss_test:0.11945, lr:6.69e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.973, tt:2769.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00000, loss_test:0.11914, lr:6.62e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.948, tt:2803.926\n",
      "Ep:78, loss:0.00000, loss_test:0.12150, lr:6.56e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.931, tt:2838.570\n",
      "Ep:79, loss:0.00000, loss_test:0.11940, lr:6.49e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.916, tt:2873.281\n",
      "Ep:80, loss:0.00000, loss_test:0.12016, lr:6.43e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.937, tt:2910.912\n",
      "Ep:81, loss:0.00000, loss_test:0.12007, lr:6.36e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.944, tt:2947.396\n",
      "Ep:82, loss:0.00000, loss_test:0.11876, lr:6.30e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.944, tt:2983.362\n",
      "Ep:83, loss:0.00000, loss_test:0.11978, lr:6.24e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.947, tt:3019.547\n",
      "Ep:84, loss:0.00000, loss_test:0.11880, lr:6.17e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.956, tt:3056.265\n",
      "Ep:85, loss:0.00000, loss_test:0.11939, lr:6.11e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.964, tt:3092.936\n",
      "Ep:86, loss:0.00000, loss_test:0.11961, lr:6.05e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.990, tt:3131.140\n",
      "Ep:87, loss:0.00000, loss_test:0.11827, lr:5.99e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.987, tt:3166.896\n",
      "Ep:88, loss:0.00000, loss_test:0.12020, lr:5.93e-03, fs:0.65693 (r=0.517,p=0.900),  time:36.000, tt:3203.966\n",
      "Ep:89, loss:0.00000, loss_test:0.11953, lr:5.87e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.004, tt:3240.339\n",
      "Ep:90, loss:0.00000, loss_test:0.11876, lr:5.81e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.029, tt:3278.606\n",
      "Ep:91, loss:0.00000, loss_test:0.11899, lr:5.75e-03, fs:0.65217 (r=0.517,p=0.882),  time:36.046, tt:3316.234\n",
      "Ep:92, loss:0.00000, loss_test:0.11896, lr:5.70e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.056, tt:3353.225\n",
      "Ep:93, loss:0.00000, loss_test:0.11913, lr:5.64e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.073, tt:3390.868\n",
      "Ep:94, loss:0.00000, loss_test:0.12063, lr:5.58e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.114, tt:3430.792\n",
      "Ep:95, loss:0.00000, loss_test:0.11919, lr:5.53e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.123, tt:3467.766\n",
      "Ep:96, loss:0.00000, loss_test:0.11919, lr:5.47e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.138, tt:3505.345\n",
      "Ep:97, loss:0.00000, loss_test:0.11997, lr:5.42e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.132, tt:3540.955\n",
      "Ep:98, loss:0.00000, loss_test:0.11907, lr:5.36e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.116, tt:3575.493\n",
      "Ep:99, loss:0.00000, loss_test:0.11952, lr:5.31e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.133, tt:3613.340\n",
      "Ep:100, loss:0.00000, loss_test:0.11998, lr:5.26e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.127, tt:3648.855\n",
      "Ep:101, loss:0.00000, loss_test:0.11882, lr:5.20e-03, fs:0.65693 (r=0.517,p=0.900),  time:36.121, tt:3684.382\n",
      "Ep:102, loss:0.00000, loss_test:0.12020, lr:5.15e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.099, tt:3718.237\n",
      "Ep:103, loss:0.00000, loss_test:0.12029, lr:5.10e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.105, tt:3754.869\n",
      "Ep:104, loss:0.00000, loss_test:0.11928, lr:5.05e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.114, tt:3792.013\n",
      "Ep:105, loss:0.00000, loss_test:0.12005, lr:5.00e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.128, tt:3829.581\n",
      "Ep:106, loss:0.00000, loss_test:0.11949, lr:4.95e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.106, tt:3863.350\n",
      "Ep:107, loss:0.00000, loss_test:0.11910, lr:4.90e-03, fs:0.65217 (r=0.517,p=0.882),  time:36.095, tt:3898.248\n",
      "Ep:108, loss:0.00000, loss_test:0.12092, lr:4.85e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.036, tt:3927.968\n",
      "Ep:109, loss:0.00000, loss_test:0.12069, lr:4.80e-03, fs:0.66176 (r=0.517,p=0.918),  time:36.007, tt:3960.722\n",
      "Ep:110, loss:0.00000, loss_test:0.12006, lr:4.75e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.974, tt:3993.094\n",
      "Ep:111, loss:0.00000, loss_test:0.11997, lr:4.71e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.951, tt:4026.526\n",
      "Ep:112, loss:0.00000, loss_test:0.11939, lr:4.66e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.909, tt:4057.766\n",
      "Ep:113, loss:0.00000, loss_test:0.11942, lr:4.61e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.881, tt:4090.475\n",
      "Ep:114, loss:0.00000, loss_test:0.12004, lr:4.57e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.847, tt:4122.461\n",
      "Ep:115, loss:0.00000, loss_test:0.12029, lr:4.52e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.799, tt:4152.676\n",
      "Ep:116, loss:0.00000, loss_test:0.11948, lr:4.48e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.767, tt:4184.766\n",
      "Ep:117, loss:0.00000, loss_test:0.11986, lr:4.43e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.703, tt:4212.908\n",
      "Ep:118, loss:0.00000, loss_test:0.12024, lr:4.39e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.674, tt:4245.251\n",
      "Ep:119, loss:0.00000, loss_test:0.11953, lr:4.34e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.644, tt:4277.307\n",
      "Ep:120, loss:0.00000, loss_test:0.11946, lr:4.30e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.596, tt:4307.085\n",
      "Ep:121, loss:0.00000, loss_test:0.12008, lr:4.26e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.559, tt:4338.141\n",
      "Ep:122, loss:0.00000, loss_test:0.11999, lr:4.21e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.513, tt:4368.063\n",
      "Ep:123, loss:0.00000, loss_test:0.11953, lr:4.17e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.484, tt:4400.058\n",
      "Ep:124, loss:0.00000, loss_test:0.12004, lr:4.13e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.452, tt:4431.492\n",
      "Ep:125, loss:0.00000, loss_test:0.12023, lr:4.09e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.431, tt:4464.258\n",
      "Ep:126, loss:0.00000, loss_test:0.11976, lr:4.05e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.391, tt:4494.647\n",
      "Ep:127, loss:0.00000, loss_test:0.11984, lr:4.01e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.330, tt:4522.279\n",
      "Ep:128, loss:0.00000, loss_test:0.12072, lr:3.97e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.304, tt:4554.225\n",
      "Ep:129, loss:0.00000, loss_test:0.12036, lr:3.93e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.260, tt:4583.830\n",
      "Ep:130, loss:0.00000, loss_test:0.11987, lr:3.89e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.240, tt:4616.460\n",
      "Ep:131, loss:0.00000, loss_test:0.11998, lr:3.85e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.225, tt:4649.757\n",
      "Ep:132, loss:0.00000, loss_test:0.12020, lr:3.81e-03, fs:0.66176 (r=0.517,p=0.918),  time:35.197, tt:4681.237\n",
      "Ep:133, loss:0.00000, loss_test:0.11991, lr:3.77e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.170, tt:4712.837\n",
      "Ep:134, loss:0.00000, loss_test:0.11979, lr:3.73e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.134, tt:4743.112\n",
      "Ep:135, loss:0.00000, loss_test:0.11981, lr:3.70e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.097, tt:4773.136\n",
      "Ep:136, loss:0.00000, loss_test:0.12020, lr:3.66e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.070, tt:4804.639\n",
      "Ep:137, loss:0.00000, loss_test:0.12013, lr:3.62e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.040, tt:4835.562\n",
      "Ep:138, loss:0.00000, loss_test:0.11982, lr:3.59e-03, fs:0.65693 (r=0.517,p=0.900),  time:35.001, tt:4865.146\n",
      "Ep:139, loss:0.00000, loss_test:0.12025, lr:3.55e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.970, tt:4895.804\n",
      "Ep:140, loss:0.00000, loss_test:0.12027, lr:3.52e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.948, tt:4927.691\n",
      "Ep:141, loss:0.00000, loss_test:0.12004, lr:3.48e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.906, tt:4956.709\n",
      "Ep:142, loss:0.00000, loss_test:0.12010, lr:3.45e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.864, tt:4985.604\n",
      "Ep:143, loss:0.00000, loss_test:0.12017, lr:3.41e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.830, tt:5015.483\n",
      "Ep:144, loss:0.00000, loss_test:0.11993, lr:3.38e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.796, tt:5045.442\n",
      "Ep:145, loss:0.00000, loss_test:0.11985, lr:3.34e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.772, tt:5076.646\n",
      "Ep:146, loss:0.00000, loss_test:0.12020, lr:3.31e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.731, tt:5105.403\n",
      "Ep:147, loss:0.00000, loss_test:0.12028, lr:3.28e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.728, tt:5139.697\n",
      "Ep:148, loss:0.00000, loss_test:0.11982, lr:3.24e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.699, tt:5170.136\n",
      "Ep:149, loss:0.00000, loss_test:0.12017, lr:3.21e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.671, tt:5200.582\n",
      "Ep:150, loss:0.00000, loss_test:0.12028, lr:3.18e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.639, tt:5230.510\n",
      "Ep:151, loss:0.00000, loss_test:0.12032, lr:3.15e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.602, tt:5259.446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.11997, lr:3.12e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.586, tt:5291.717\n",
      "Ep:153, loss:0.00000, loss_test:0.11977, lr:3.09e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.560, tt:5322.265\n",
      "Ep:154, loss:0.00000, loss_test:0.12019, lr:3.05e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.541, tt:5353.915\n",
      "Ep:155, loss:0.00000, loss_test:0.12046, lr:3.02e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.523, tt:5385.562\n",
      "Ep:156, loss:0.00000, loss_test:0.12001, lr:2.99e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.514, tt:5418.710\n",
      "Ep:157, loss:0.00000, loss_test:0.11972, lr:2.96e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.492, tt:5449.786\n",
      "Ep:158, loss:0.00000, loss_test:0.11997, lr:2.93e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.455, tt:5478.356\n",
      "Ep:159, loss:0.00000, loss_test:0.11992, lr:2.90e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.412, tt:5505.935\n",
      "Ep:160, loss:0.00000, loss_test:0.11975, lr:2.88e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.376, tt:5534.526\n",
      "Ep:161, loss:0.00000, loss_test:0.12006, lr:2.85e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.349, tt:5564.471\n",
      "Ep:162, loss:0.00000, loss_test:0.12010, lr:2.82e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.325, tt:5594.930\n",
      "Ep:163, loss:0.00000, loss_test:0.11985, lr:2.79e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.301, tt:5625.340\n",
      "Ep:164, loss:0.00000, loss_test:0.11986, lr:2.76e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.260, tt:5652.904\n",
      "Ep:165, loss:0.00000, loss_test:0.12015, lr:2.73e-03, fs:0.66176 (r=0.517,p=0.918),  time:34.239, tt:5683.679\n",
      "Ep:166, loss:0.00000, loss_test:0.12017, lr:2.71e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.208, tt:5712.674\n",
      "Ep:167, loss:0.00000, loss_test:0.11991, lr:2.68e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.178, tt:5741.862\n",
      "Ep:168, loss:0.00000, loss_test:0.11999, lr:2.65e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.164, tt:5773.780\n",
      "Ep:169, loss:0.00000, loss_test:0.12003, lr:2.63e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.157, tt:5806.753\n",
      "Ep:170, loss:0.00000, loss_test:0.11982, lr:2.60e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.142, tt:5838.314\n",
      "Ep:171, loss:0.00000, loss_test:0.11976, lr:2.57e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.121, tt:5868.738\n",
      "Ep:172, loss:0.00000, loss_test:0.11993, lr:2.55e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.105, tt:5900.250\n",
      "Ep:173, loss:0.00000, loss_test:0.11991, lr:2.52e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.090, tt:5931.701\n",
      "Ep:174, loss:0.00000, loss_test:0.11987, lr:2.50e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.070, tt:5962.272\n",
      "Ep:175, loss:0.00000, loss_test:0.11979, lr:2.47e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.061, tt:5994.684\n",
      "Ep:176, loss:0.00000, loss_test:0.11968, lr:2.45e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.051, tt:6026.978\n",
      "Ep:177, loss:0.00000, loss_test:0.11983, lr:2.42e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.018, tt:6055.203\n",
      "Ep:178, loss:0.00000, loss_test:0.11998, lr:2.40e-03, fs:0.65693 (r=0.517,p=0.900),  time:34.008, tt:6087.386\n",
      "Ep:179, loss:0.00000, loss_test:0.11996, lr:2.38e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.994, tt:6119.004\n",
      "Ep:180, loss:0.00000, loss_test:0.11981, lr:2.35e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.974, tt:6149.240\n",
      "Ep:181, loss:0.00000, loss_test:0.12023, lr:2.33e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.950, tt:6178.861\n",
      "Ep:182, loss:0.00000, loss_test:0.12017, lr:2.31e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.930, tt:6209.280\n",
      "Ep:183, loss:0.00000, loss_test:0.11974, lr:2.28e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.916, tt:6240.461\n",
      "Ep:184, loss:0.00000, loss_test:0.11987, lr:2.26e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.890, tt:6269.716\n",
      "Ep:185, loss:0.00000, loss_test:0.12031, lr:2.24e-03, fs:0.66176 (r=0.517,p=0.918),  time:33.876, tt:6300.965\n",
      "Ep:186, loss:0.00000, loss_test:0.12029, lr:2.21e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.871, tt:6333.928\n",
      "Ep:187, loss:0.00000, loss_test:0.11996, lr:2.19e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.863, tt:6366.279\n",
      "Ep:188, loss:0.00000, loss_test:0.11994, lr:2.17e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.851, tt:6397.762\n",
      "Ep:189, loss:0.00000, loss_test:0.11987, lr:2.15e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.847, tt:6430.869\n",
      "Ep:190, loss:0.00000, loss_test:0.11978, lr:2.13e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.859, tt:6467.084\n",
      "Ep:191, loss:0.00000, loss_test:0.11990, lr:2.11e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.841, tt:6497.402\n",
      "Ep:192, loss:0.00000, loss_test:0.12002, lr:2.08e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.829, tt:6528.954\n",
      "Ep:193, loss:0.00000, loss_test:0.11994, lr:2.06e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.814, tt:6559.969\n",
      "Ep:194, loss:0.00000, loss_test:0.11978, lr:2.04e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.803, tt:6591.529\n",
      "Ep:195, loss:0.00000, loss_test:0.11964, lr:2.02e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.793, tt:6623.333\n",
      "Ep:196, loss:0.00000, loss_test:0.11975, lr:2.00e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.785, tt:6655.629\n",
      "Ep:197, loss:0.00000, loss_test:0.12012, lr:1.98e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.776, tt:6687.668\n",
      "Ep:198, loss:0.00000, loss_test:0.12011, lr:1.96e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.750, tt:6716.255\n",
      "Ep:199, loss:0.00000, loss_test:0.11986, lr:1.94e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.729, tt:6745.730\n",
      "Ep:200, loss:0.00000, loss_test:0.11972, lr:1.92e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.705, tt:6774.717\n",
      "Ep:201, loss:0.00000, loss_test:0.11968, lr:1.90e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.683, tt:6804.003\n",
      "Ep:202, loss:0.00000, loss_test:0.11971, lr:1.89e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.666, tt:6834.214\n",
      "Ep:203, loss:0.00000, loss_test:0.11971, lr:1.87e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.640, tt:6862.570\n",
      "Ep:204, loss:0.00000, loss_test:0.11967, lr:1.85e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.629, tt:6893.845\n",
      "Ep:205, loss:0.00000, loss_test:0.11963, lr:1.83e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.621, tt:6925.887\n",
      "Ep:206, loss:0.00000, loss_test:0.11959, lr:1.81e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.600, tt:6955.254\n",
      "Ep:207, loss:0.00000, loss_test:0.11963, lr:1.79e-03, fs:0.65693 (r=0.517,p=0.900),  time:33.582, tt:6984.986\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "cv_number=\"2-2\"\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 0\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14231, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.749, tt:12.749\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14083, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.514, tt:25.028\n",
      "Ep:2, loss:0.00028, loss_test:0.13813, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.419, tt:37.256\n",
      "Ep:3, loss:0.00027, loss_test:0.13356, lr:1.00e-02, fs:0.67188 (r=0.989,p=0.509),  time:12.427, tt:49.709\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12570, lr:1.00e-02, fs:0.69136 (r=0.966,p=0.538),  time:12.437, tt:62.187\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11724, lr:1.00e-02, fs:0.66364 (r=0.839,p=0.549),  time:12.457, tt:74.742\n",
      "Ep:6, loss:0.00024, loss_test:0.11207, lr:1.00e-02, fs:0.65990 (r=0.747,p=0.591),  time:12.481, tt:87.364\n",
      "Ep:7, loss:0.00023, loss_test:0.10760, lr:1.00e-02, fs:0.70103 (r=0.782,p=0.636),  time:12.497, tt:99.980\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10501, lr:1.00e-02, fs:0.70103 (r=0.782,p=0.636),  time:12.498, tt:112.482\n",
      "Ep:9, loss:0.00021, loss_test:0.10432, lr:1.00e-02, fs:0.69110 (r=0.759,p=0.635),  time:12.473, tt:124.727\n",
      "Ep:10, loss:0.00020, loss_test:0.10161, lr:1.00e-02, fs:0.71658 (r=0.770,p=0.670),  time:12.460, tt:137.060\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09716, lr:1.00e-02, fs:0.75145 (r=0.747,p=0.756),  time:12.497, tt:149.969\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09607, lr:1.00e-02, fs:0.76471 (r=0.747,p=0.783),  time:12.488, tt:162.344\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09633, lr:1.00e-02, fs:0.74713 (r=0.747,p=0.747),  time:12.493, tt:174.901\n",
      "Ep:14, loss:0.00017, loss_test:0.09190, lr:1.00e-02, fs:0.78571 (r=0.759,p=0.815),  time:12.493, tt:187.396\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08884, lr:1.00e-02, fs:0.79518 (r=0.759,p=0.835),  time:12.517, tt:200.266\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.08904, lr:1.00e-02, fs:0.77108 (r=0.736,p=0.810),  time:12.508, tt:212.642\n",
      "Ep:17, loss:0.00014, loss_test:0.08678, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:12.498, tt:224.961\n",
      "Ep:18, loss:0.00014, loss_test:0.08416, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:12.513, tt:237.749\n",
      "Ep:19, loss:0.00013, loss_test:0.08643, lr:1.00e-02, fs:0.78049 (r=0.736,p=0.831),  time:12.519, tt:250.385\n",
      "Ep:20, loss:0.00012, loss_test:0.08313, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:12.527, tt:263.072\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.08141, lr:1.00e-02, fs:0.80247 (r=0.747,p=0.867),  time:12.540, tt:275.870\n",
      "Ep:22, loss:0.00011, loss_test:0.08054, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:12.540, tt:288.414\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00010, loss_test:0.08179, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:12.533, tt:300.781\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08039, lr:1.00e-02, fs:0.82500 (r=0.759,p=0.904),  time:12.527, tt:313.175\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.08156, lr:1.00e-02, fs:0.83019 (r=0.759,p=0.917),  time:12.525, tt:325.649\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.07628, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:12.532, tt:338.365\n",
      "Ep:27, loss:0.00008, loss_test:0.08133, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:12.532, tt:350.884\n",
      "Ep:28, loss:0.00008, loss_test:0.07625, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:12.537, tt:363.586\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00007, loss_test:0.08031, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:12.528, tt:375.832\n",
      "Ep:30, loss:0.00007, loss_test:0.07572, lr:1.00e-02, fs:0.85000 (r=0.782,p=0.932),  time:12.532, tt:388.495\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.07856, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:12.532, tt:401.011\n",
      "Ep:32, loss:0.00006, loss_test:0.07314, lr:1.00e-02, fs:0.83750 (r=0.770,p=0.918),  time:12.530, tt:413.487\n",
      "Ep:33, loss:0.00006, loss_test:0.08343, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:12.521, tt:425.714\n",
      "Ep:34, loss:0.00005, loss_test:0.07498, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:12.606, tt:441.206\n",
      "Ep:35, loss:0.00005, loss_test:0.07683, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:12.600, tt:453.611\n",
      "Ep:36, loss:0.00004, loss_test:0.07747, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:12.584, tt:465.608\n",
      "Ep:37, loss:0.00004, loss_test:0.08088, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:12.579, tt:477.999\n",
      "Ep:38, loss:0.00004, loss_test:0.08529, lr:1.00e-02, fs:0.81046 (r=0.713,p=0.939),  time:12.569, tt:490.181\n",
      "Ep:39, loss:0.00004, loss_test:0.08861, lr:1.00e-02, fs:0.77027 (r=0.655,p=0.934),  time:12.565, tt:502.620\n",
      "Ep:40, loss:0.00004, loss_test:0.07758, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:12.559, tt:514.903\n",
      "Ep:41, loss:0.00003, loss_test:0.07474, lr:1.00e-02, fs:0.84076 (r=0.759,p=0.943),  time:12.555, tt:527.295\n",
      "Ep:42, loss:0.00003, loss_test:0.08287, lr:9.90e-03, fs:0.81579 (r=0.713,p=0.954),  time:12.554, tt:539.825\n",
      "Ep:43, loss:0.00003, loss_test:0.08650, lr:9.80e-03, fs:0.79195 (r=0.678,p=0.952),  time:12.552, tt:552.285\n",
      "Ep:44, loss:0.00003, loss_test:0.08233, lr:9.70e-03, fs:0.78667 (r=0.678,p=0.937),  time:12.548, tt:564.661\n",
      "Ep:45, loss:0.00002, loss_test:0.07423, lr:9.61e-03, fs:0.84615 (r=0.759,p=0.957),  time:12.583, tt:578.807\n",
      "Ep:46, loss:0.00002, loss_test:0.08152, lr:9.51e-03, fs:0.82353 (r=0.724,p=0.955),  time:12.581, tt:591.319\n",
      "Ep:47, loss:0.00002, loss_test:0.08064, lr:9.41e-03, fs:0.82353 (r=0.724,p=0.955),  time:12.571, tt:603.399\n",
      "Ep:48, loss:0.00002, loss_test:0.08077, lr:9.32e-03, fs:0.82353 (r=0.724,p=0.955),  time:12.566, tt:615.711\n",
      "Ep:49, loss:0.00002, loss_test:0.07801, lr:9.23e-03, fs:0.84416 (r=0.747,p=0.970),  time:12.561, tt:628.054\n",
      "Ep:50, loss:0.00002, loss_test:0.08040, lr:9.14e-03, fs:0.80537 (r=0.690,p=0.968),  time:12.555, tt:640.310\n",
      "Ep:51, loss:0.00002, loss_test:0.08634, lr:9.04e-03, fs:0.79730 (r=0.678,p=0.967),  time:12.553, tt:652.760\n",
      "Ep:52, loss:0.00002, loss_test:0.07912, lr:8.95e-03, fs:0.85161 (r=0.759,p=0.971),  time:12.547, tt:665.005\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.08031, lr:8.95e-03, fs:0.83660 (r=0.736,p=0.970),  time:12.548, tt:677.615\n",
      "Ep:54, loss:0.00001, loss_test:0.08825, lr:8.95e-03, fs:0.78912 (r=0.667,p=0.967),  time:12.545, tt:689.949\n",
      "Ep:55, loss:0.00001, loss_test:0.08149, lr:8.95e-03, fs:0.82895 (r=0.724,p=0.969),  time:12.544, tt:702.455\n",
      "Ep:56, loss:0.00001, loss_test:0.08291, lr:8.95e-03, fs:0.84211 (r=0.736,p=0.985),  time:12.542, tt:714.908\n",
      "Ep:57, loss:0.00001, loss_test:0.08294, lr:8.95e-03, fs:0.82895 (r=0.724,p=0.969),  time:12.540, tt:727.339\n",
      "Ep:58, loss:0.00001, loss_test:0.08678, lr:8.95e-03, fs:0.83444 (r=0.724,p=0.984),  time:12.538, tt:739.722\n",
      "Ep:59, loss:0.00001, loss_test:0.08230, lr:8.95e-03, fs:0.82895 (r=0.724,p=0.969),  time:12.538, tt:752.271\n",
      "Ep:60, loss:0.00001, loss_test:0.08522, lr:8.95e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.536, tt:764.681\n",
      "Ep:61, loss:0.00001, loss_test:0.08146, lr:8.95e-03, fs:0.83444 (r=0.724,p=0.984),  time:12.534, tt:777.134\n",
      "Ep:62, loss:0.00001, loss_test:0.08862, lr:8.95e-03, fs:0.80272 (r=0.678,p=0.983),  time:12.535, tt:789.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.08395, lr:8.95e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:802.442\n",
      "Ep:64, loss:0.00001, loss_test:0.08804, lr:8.86e-03, fs:0.83444 (r=0.724,p=0.984),  time:12.540, tt:815.078\n",
      "Ep:65, loss:0.00001, loss_test:0.08647, lr:8.78e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.537, tt:827.475\n",
      "Ep:66, loss:0.00001, loss_test:0.08779, lr:8.69e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.535, tt:839.814\n",
      "Ep:67, loss:0.00001, loss_test:0.08781, lr:8.60e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.531, tt:852.075\n",
      "Ep:68, loss:0.00001, loss_test:0.08600, lr:8.51e-03, fs:0.82432 (r=0.701,p=1.000),  time:12.533, tt:864.780\n",
      "Ep:69, loss:0.00000, loss_test:0.08662, lr:8.43e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.533, tt:877.322\n",
      "Ep:70, loss:0.00000, loss_test:0.08932, lr:8.35e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.536, tt:890.088\n",
      "Ep:71, loss:0.00000, loss_test:0.08639, lr:8.26e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:902.705\n",
      "Ep:72, loss:0.00000, loss_test:0.08744, lr:8.18e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.543, tt:915.625\n",
      "Ep:73, loss:0.00000, loss_test:0.08835, lr:8.10e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:928.361\n",
      "Ep:74, loss:0.00000, loss_test:0.08804, lr:8.02e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:940.910\n",
      "Ep:75, loss:0.00000, loss_test:0.08671, lr:7.94e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.547, tt:953.609\n",
      "Ep:76, loss:0.00000, loss_test:0.08702, lr:7.86e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.549, tt:966.254\n",
      "Ep:77, loss:0.00000, loss_test:0.08680, lr:7.78e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.549, tt:978.829\n",
      "Ep:78, loss:0.00000, loss_test:0.08721, lr:7.70e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.549, tt:991.346\n",
      "Ep:79, loss:0.00000, loss_test:0.08465, lr:7.62e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.552, tt:1004.179\n",
      "Ep:80, loss:0.00000, loss_test:0.08930, lr:7.55e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.554, tt:1016.845\n",
      "Ep:81, loss:0.00000, loss_test:0.08469, lr:7.47e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.553, tt:1029.362\n",
      "Ep:82, loss:0.00000, loss_test:0.08737, lr:7.40e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.556, tt:1042.144\n",
      "Ep:83, loss:0.00000, loss_test:0.08482, lr:7.32e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.556, tt:1054.668\n",
      "Ep:84, loss:0.00000, loss_test:0.08666, lr:7.25e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.557, tt:1067.383\n",
      "Ep:85, loss:0.00000, loss_test:0.08633, lr:7.18e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.602, tt:1083.761\n",
      "Ep:86, loss:0.00000, loss_test:0.08591, lr:7.11e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.603, tt:1096.438\n",
      "Ep:87, loss:0.00000, loss_test:0.08485, lr:7.03e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.602, tt:1108.944\n",
      "Ep:88, loss:0.00000, loss_test:0.08682, lr:6.96e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.603, tt:1121.699\n",
      "Ep:89, loss:0.00000, loss_test:0.08505, lr:6.89e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.603, tt:1134.309\n",
      "Ep:90, loss:0.00000, loss_test:0.08707, lr:6.83e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.599, tt:1146.528\n",
      "Ep:91, loss:0.00000, loss_test:0.08461, lr:6.76e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.597, tt:1158.911\n",
      "Ep:92, loss:0.00000, loss_test:0.08739, lr:6.69e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.595, tt:1171.319\n",
      "Ep:93, loss:0.00000, loss_test:0.08444, lr:6.62e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.594, tt:1183.879\n",
      "Ep:94, loss:0.00000, loss_test:0.08653, lr:6.56e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.593, tt:1196.380\n",
      "Ep:95, loss:0.00000, loss_test:0.08534, lr:6.49e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.589, tt:1208.578\n",
      "Ep:96, loss:0.00000, loss_test:0.08533, lr:6.43e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.587, tt:1220.946\n",
      "Ep:97, loss:0.00000, loss_test:0.08511, lr:6.36e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.587, tt:1233.478\n",
      "Ep:98, loss:0.00000, loss_test:0.08511, lr:6.30e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.583, tt:1245.675\n",
      "Ep:99, loss:0.00000, loss_test:0.08509, lr:6.24e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.580, tt:1257.980\n",
      "Ep:100, loss:0.00000, loss_test:0.08503, lr:6.17e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.576, tt:1270.146\n",
      "Ep:101, loss:0.00000, loss_test:0.08437, lr:6.11e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.572, tt:1282.375\n",
      "Ep:102, loss:0.00000, loss_test:0.08553, lr:6.05e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.572, tt:1294.894\n",
      "Ep:103, loss:0.00000, loss_test:0.08642, lr:5.99e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.570, tt:1307.242\n",
      "Ep:104, loss:0.00000, loss_test:0.08494, lr:5.93e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.570, tt:1319.891\n",
      "Ep:105, loss:0.00000, loss_test:0.08713, lr:5.87e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.568, tt:1332.156\n",
      "Ep:106, loss:0.00000, loss_test:0.08371, lr:5.81e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.565, tt:1344.503\n",
      "Ep:107, loss:0.00000, loss_test:0.08699, lr:5.75e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.566, tt:1357.170\n",
      "Ep:108, loss:0.00000, loss_test:0.08463, lr:5.70e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.568, tt:1369.864\n",
      "Ep:109, loss:0.00000, loss_test:0.08509, lr:5.64e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.568, tt:1382.436\n",
      "Ep:110, loss:0.00000, loss_test:0.08539, lr:5.58e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.569, tt:1395.171\n",
      "Ep:111, loss:0.00000, loss_test:0.08376, lr:5.53e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.569, tt:1407.734\n",
      "Ep:112, loss:0.00000, loss_test:0.08495, lr:5.47e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.570, tt:1420.437\n",
      "Ep:113, loss:0.00000, loss_test:0.08343, lr:5.42e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.571, tt:1433.102\n",
      "Ep:114, loss:0.00000, loss_test:0.08667, lr:5.36e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.570, tt:1445.566\n",
      "Ep:115, loss:0.00000, loss_test:0.08528, lr:5.31e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.569, tt:1457.987\n",
      "Ep:116, loss:0.00000, loss_test:0.08411, lr:5.26e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.568, tt:1470.499\n",
      "Ep:117, loss:0.00000, loss_test:0.08494, lr:5.20e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.566, tt:1482.837\n",
      "Ep:118, loss:0.00000, loss_test:0.08466, lr:5.15e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.564, tt:1495.114\n",
      "Ep:119, loss:0.00000, loss_test:0.08477, lr:5.10e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.563, tt:1507.575\n",
      "Ep:120, loss:0.00000, loss_test:0.08365, lr:5.05e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.563, tt:1520.118\n",
      "Ep:121, loss:0.00000, loss_test:0.08527, lr:5.00e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.562, tt:1532.525\n",
      "Ep:122, loss:0.00000, loss_test:0.08500, lr:4.95e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:1544.969\n",
      "Ep:123, loss:0.00000, loss_test:0.08427, lr:4.90e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:1557.619\n",
      "Ep:124, loss:0.00000, loss_test:0.08474, lr:4.85e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.560, tt:1570.057\n",
      "Ep:125, loss:0.00000, loss_test:0.08336, lr:4.80e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.559, tt:1582.404\n",
      "Ep:126, loss:0.00000, loss_test:0.08465, lr:4.75e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.559, tt:1594.975\n",
      "Ep:127, loss:0.00000, loss_test:0.08379, lr:4.71e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.558, tt:1607.418\n",
      "Ep:128, loss:0.00000, loss_test:0.08430, lr:4.66e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.556, tt:1619.771\n",
      "Ep:129, loss:0.00000, loss_test:0.08511, lr:4.61e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.554, tt:1632.051\n",
      "Ep:130, loss:0.00000, loss_test:0.08408, lr:4.57e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.555, tt:1644.700\n",
      "Ep:131, loss:0.00000, loss_test:0.08438, lr:4.52e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.555, tt:1657.202\n",
      "Ep:132, loss:0.00000, loss_test:0.08374, lr:4.48e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.555, tt:1669.796\n",
      "Ep:133, loss:0.00000, loss_test:0.08424, lr:4.43e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.555, tt:1682.342\n",
      "Ep:134, loss:0.00000, loss_test:0.08476, lr:4.39e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.554, tt:1694.826\n",
      "Ep:135, loss:0.00000, loss_test:0.08401, lr:4.34e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.554, tt:1707.344\n",
      "Ep:136, loss:0.00000, loss_test:0.08336, lr:4.30e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.574, tt:1722.632\n",
      "Ep:137, loss:0.00000, loss_test:0.08401, lr:4.26e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.573, tt:1735.048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00000, loss_test:0.08424, lr:4.21e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.573, tt:1747.645\n",
      "Ep:139, loss:0.00000, loss_test:0.08353, lr:4.17e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.572, tt:1760.106\n",
      "Ep:140, loss:0.00000, loss_test:0.08415, lr:4.13e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.572, tt:1772.599\n",
      "Ep:141, loss:0.00000, loss_test:0.08362, lr:4.09e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.570, tt:1784.992\n",
      "Ep:142, loss:0.00000, loss_test:0.08332, lr:4.05e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.569, tt:1797.363\n",
      "Ep:143, loss:0.00000, loss_test:0.08427, lr:4.01e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.566, tt:1809.502\n",
      "Ep:144, loss:0.00000, loss_test:0.08407, lr:3.97e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.566, tt:1822.044\n",
      "Ep:145, loss:0.00000, loss_test:0.08364, lr:3.93e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.566, tt:1834.705\n",
      "Ep:146, loss:0.00000, loss_test:0.08408, lr:3.89e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.568, tt:1847.514\n",
      "Ep:147, loss:0.00000, loss_test:0.08365, lr:3.85e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.569, tt:1860.233\n",
      "Ep:148, loss:0.00000, loss_test:0.08364, lr:3.81e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.565, tt:1872.111\n",
      "Ep:149, loss:0.00000, loss_test:0.08428, lr:3.77e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.564, tt:1884.627\n",
      "Ep:150, loss:0.00000, loss_test:0.08345, lr:3.73e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.565, tt:1897.356\n",
      "Ep:151, loss:0.00000, loss_test:0.08376, lr:3.70e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.564, tt:1909.794\n",
      "Ep:152, loss:0.00000, loss_test:0.08366, lr:3.66e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.564, tt:1922.340\n",
      "Ep:153, loss:0.00000, loss_test:0.08349, lr:3.62e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.563, tt:1934.643\n",
      "Ep:154, loss:0.00000, loss_test:0.08378, lr:3.59e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.562, tt:1947.050\n",
      "Ep:155, loss:0.00000, loss_test:0.08329, lr:3.55e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.560, tt:1959.432\n",
      "Ep:156, loss:0.00000, loss_test:0.08349, lr:3.52e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.560, tt:1971.844\n",
      "Ep:157, loss:0.00000, loss_test:0.08442, lr:3.48e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.558, tt:1984.224\n",
      "Ep:158, loss:0.00000, loss_test:0.08341, lr:3.45e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.556, tt:1996.461\n",
      "Ep:159, loss:0.00000, loss_test:0.08341, lr:3.41e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.556, tt:2008.915\n",
      "Ep:160, loss:0.00000, loss_test:0.08395, lr:3.38e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.554, tt:2021.127\n",
      "Ep:161, loss:0.00000, loss_test:0.08309, lr:3.34e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.553, tt:2033.663\n",
      "Ep:162, loss:0.00000, loss_test:0.08387, lr:3.31e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.553, tt:2046.180\n",
      "Ep:163, loss:0.00000, loss_test:0.08458, lr:3.28e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.552, tt:2058.564\n",
      "Ep:164, loss:0.00000, loss_test:0.08356, lr:3.24e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.552, tt:2071.132\n",
      "Ep:165, loss:0.00000, loss_test:0.08322, lr:3.21e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.550, tt:2083.370\n",
      "Ep:166, loss:0.00000, loss_test:0.08398, lr:3.18e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.549, tt:2095.623\n",
      "Ep:167, loss:0.00000, loss_test:0.08369, lr:3.15e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.547, tt:2107.941\n",
      "Ep:168, loss:0.00000, loss_test:0.08323, lr:3.12e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2120.096\n",
      "Ep:169, loss:0.00000, loss_test:0.08329, lr:3.09e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2132.657\n",
      "Ep:170, loss:0.00000, loss_test:0.08336, lr:3.05e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2145.130\n",
      "Ep:171, loss:0.00000, loss_test:0.08355, lr:3.02e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2157.671\n",
      "Ep:172, loss:0.00000, loss_test:0.08372, lr:2.99e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2170.236\n",
      "Ep:173, loss:0.00000, loss_test:0.08352, lr:2.96e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.543, tt:2182.560\n",
      "Ep:174, loss:0.00000, loss_test:0.08352, lr:2.93e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.543, tt:2195.007\n",
      "Ep:175, loss:0.00000, loss_test:0.08349, lr:2.90e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.542, tt:2207.359\n",
      "Ep:176, loss:0.00000, loss_test:0.08350, lr:2.88e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.541, tt:2219.706\n",
      "Ep:177, loss:0.00000, loss_test:0.08331, lr:2.85e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2232.007\n",
      "Ep:178, loss:0.00000, loss_test:0.08370, lr:2.82e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:2244.322\n",
      "Ep:179, loss:0.00000, loss_test:0.08381, lr:2.79e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:2256.826\n",
      "Ep:180, loss:0.00000, loss_test:0.08306, lr:2.76e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2269.562\n",
      "Ep:181, loss:0.00000, loss_test:0.08289, lr:2.73e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2282.064\n",
      "Ep:182, loss:0.00000, loss_test:0.08363, lr:2.71e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2294.573\n",
      "Ep:183, loss:0.00000, loss_test:0.08369, lr:2.68e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.537, tt:2306.886\n",
      "Ep:184, loss:0.00000, loss_test:0.08317, lr:2.65e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:2319.586\n",
      "Ep:185, loss:0.00000, loss_test:0.08326, lr:2.63e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.538, tt:2332.103\n",
      "Ep:186, loss:0.00000, loss_test:0.08347, lr:2.60e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2344.826\n",
      "Ep:187, loss:0.00000, loss_test:0.08332, lr:2.57e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.540, tt:2357.603\n",
      "Ep:188, loss:0.00000, loss_test:0.08317, lr:2.55e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2369.940\n",
      "Ep:189, loss:0.00000, loss_test:0.08323, lr:2.52e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.539, tt:2382.454\n",
      "Ep:190, loss:0.00000, loss_test:0.08332, lr:2.50e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.540, tt:2395.101\n",
      "Ep:191, loss:0.00000, loss_test:0.08311, lr:2.47e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.541, tt:2407.799\n",
      "Ep:192, loss:0.00000, loss_test:0.08314, lr:2.45e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.540, tt:2420.285\n",
      "Ep:193, loss:0.00000, loss_test:0.08365, lr:2.42e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.541, tt:2433.000\n",
      "Ep:194, loss:0.00000, loss_test:0.08341, lr:2.40e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.542, tt:2445.648\n",
      "Ep:195, loss:0.00000, loss_test:0.08303, lr:2.38e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.542, tt:2458.326\n",
      "Ep:196, loss:0.00000, loss_test:0.08333, lr:2.35e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.544, tt:2471.093\n",
      "Ep:197, loss:0.00000, loss_test:0.08383, lr:2.33e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2483.816\n",
      "Ep:198, loss:0.00000, loss_test:0.08345, lr:2.31e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.545, tt:2496.528\n",
      "Ep:199, loss:0.00000, loss_test:0.08298, lr:2.28e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.546, tt:2509.203\n",
      "Ep:200, loss:0.00000, loss_test:0.08309, lr:2.26e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.559, tt:2524.263\n",
      "Ep:201, loss:0.00000, loss_test:0.08334, lr:2.24e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.559, tt:2536.933\n",
      "Ep:202, loss:0.00000, loss_test:0.08310, lr:2.21e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.559, tt:2549.545\n",
      "Ep:203, loss:0.00000, loss_test:0.08300, lr:2.19e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.560, tt:2562.260\n",
      "Ep:204, loss:0.00000, loss_test:0.08313, lr:2.17e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:2574.908\n",
      "Ep:205, loss:0.00000, loss_test:0.08323, lr:2.15e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:2587.494\n",
      "Ep:206, loss:0.00000, loss_test:0.08296, lr:2.13e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:2600.134\n",
      "Ep:207, loss:0.00000, loss_test:0.08309, lr:2.11e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.562, tt:2612.831\n",
      "Ep:208, loss:0.00000, loss_test:0.08354, lr:2.08e-03, fs:0.84000 (r=0.724,p=1.000),  time:12.561, tt:2625.320\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "cv_number=\"1-1\"\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "#             batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "#             loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "# cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01960, lr:6.00e-02, fs:0.65468 (r=0.919,p=0.508),  time:18.896, tt:18.896\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02309, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.732, tt:53.464\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02461, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.164, tt:87.492\n",
      "Ep:3, loss:0.00005, loss_test:0.02423, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.386, tt:125.545\n",
      "Ep:4, loss:0.00005, loss_test:0.02282, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:32.772, tt:163.860\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02108, lr:6.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:33.814, tt:202.883\n",
      "Ep:6, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.66904 (r=0.949,p=0.516),  time:34.383, tt:240.678\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01904, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:35.306, tt:282.445\n",
      "Ep:8, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:35.728, tt:321.548\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01876, lr:6.00e-02, fs:0.67769 (r=0.828,p=0.573),  time:35.770, tt:357.703\n",
      "Ep:10, loss:0.00003, loss_test:0.01836, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:35.469, tt:390.163\n",
      "Ep:11, loss:0.00003, loss_test:0.01817, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:35.528, tt:426.334\n",
      "Ep:12, loss:0.00003, loss_test:0.01808, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:35.557, tt:462.248\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01799, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.766, tt:500.721\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01795, lr:6.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:35.672, tt:535.080\n",
      "Ep:15, loss:0.00003, loss_test:0.01793, lr:6.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:35.572, tt:569.155\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01788, lr:6.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:35.471, tt:603.001\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:35.442, tt:637.963\n",
      "Ep:18, loss:0.00003, loss_test:0.01754, lr:6.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:35.355, tt:671.741\n",
      "Ep:19, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:35.327, tt:706.536\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:35.275, tt:740.777\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01708, lr:6.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:35.217, tt:774.763\n",
      "Ep:22, loss:0.00002, loss_test:0.01699, lr:6.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:35.174, tt:809.006\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01689, lr:6.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:35.195, tt:844.681\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01676, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.215, tt:880.370\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01653, lr:6.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:35.171, tt:914.442\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01633, lr:6.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:35.214, tt:950.769\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01614, lr:6.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:35.306, tt:988.581\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01601, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:35.281, tt:1023.156\n",
      "Ep:29, loss:0.00002, loss_test:0.01586, lr:6.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:35.311, tt:1059.331\n",
      "Ep:30, loss:0.00002, loss_test:0.01574, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.303, tt:1094.393\n",
      "Ep:31, loss:0.00002, loss_test:0.01568, lr:6.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:35.305, tt:1129.772\n",
      "Ep:32, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:35.346, tt:1166.426\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.353, tt:1202.012\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01548, lr:6.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:35.376, tt:1238.156\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:35.372, tt:1273.384\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.353, tt:1308.071\n",
      "Ep:37, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:35.372, tt:1344.122\n",
      "Ep:38, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:35.372, tt:1379.497\n",
      "Ep:39, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:35.412, tt:1416.472\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01531, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:35.515, tt:1456.122\n",
      "Ep:41, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.502, tt:1491.094\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01527, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.489, tt:1526.046\n",
      "Ep:43, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:35.463, tt:1560.353\n",
      "Ep:44, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:35.462, tt:1595.778\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01536, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.455, tt:1630.949\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01532, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.504, tt:1668.688\n",
      "Ep:47, loss:0.00001, loss_test:0.01531, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.525, tt:1705.182\n",
      "Ep:48, loss:0.00001, loss_test:0.01535, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.513, tt:1740.141\n",
      "Ep:49, loss:0.00001, loss_test:0.01546, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.505, tt:1775.269\n",
      "Ep:50, loss:0.00001, loss_test:0.01558, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.509, tt:1810.936\n",
      "Ep:51, loss:0.00001, loss_test:0.01565, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.494, tt:1845.710\n",
      "Ep:52, loss:0.00001, loss_test:0.01576, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.524, tt:1882.748\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01586, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.537, tt:1918.982\n",
      "Ep:54, loss:0.00001, loss_test:0.01587, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.558, tt:1955.686\n",
      "Ep:55, loss:0.00001, loss_test:0.01594, lr:6.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:35.529, tt:1989.614\n",
      "Ep:56, loss:0.00001, loss_test:0.01604, lr:6.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.543, tt:2025.944\n",
      "Ep:57, loss:0.00001, loss_test:0.01611, lr:6.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:35.541, tt:2061.354\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01614, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.548, tt:2097.328\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01634, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.565, tt:2133.930\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01647, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.560, tt:2169.164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01652, lr:6.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.538, tt:2203.335\n",
      "Ep:62, loss:0.00001, loss_test:0.01668, lr:6.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:35.523, tt:2237.961\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01681, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.518, tt:2273.145\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01682, lr:6.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.508, tt:2308.031\n",
      "Ep:65, loss:0.00001, loss_test:0.01689, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.515, tt:2344.010\n",
      "Ep:66, loss:0.00001, loss_test:0.01696, lr:6.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.503, tt:2378.670\n",
      "Ep:67, loss:0.00001, loss_test:0.01708, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.496, tt:2413.756\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01721, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.473, tt:2447.613\n",
      "Ep:69, loss:0.00001, loss_test:0.01731, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.510, tt:2485.690\n",
      "Ep:70, loss:0.00001, loss_test:0.01747, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.476, tt:2518.781\n",
      "Ep:71, loss:0.00001, loss_test:0.01762, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.430, tt:2550.943\n",
      "Ep:72, loss:0.00001, loss_test:0.01760, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.393, tt:2583.674\n",
      "Ep:73, loss:0.00001, loss_test:0.01783, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.374, tt:2617.660\n",
      "Ep:74, loss:0.00001, loss_test:0.01796, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.362, tt:2652.146\n",
      "Ep:75, loss:0.00001, loss_test:0.01806, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.346, tt:2686.301\n",
      "Ep:76, loss:0.00001, loss_test:0.01815, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.335, tt:2720.809\n",
      "Ep:77, loss:0.00001, loss_test:0.01835, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.308, tt:2754.033\n",
      "Ep:78, loss:0.00001, loss_test:0.01848, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.302, tt:2788.876\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01865, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.299, tt:2823.911\n",
      "Ep:80, loss:0.00001, loss_test:0.01868, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.293, tt:2858.753\n",
      "Ep:81, loss:0.00001, loss_test:0.01880, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.293, tt:2894.010\n",
      "Ep:82, loss:0.00001, loss_test:0.01891, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.285, tt:2928.625\n",
      "Ep:83, loss:0.00001, loss_test:0.01904, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.285, tt:2963.898\n",
      "Ep:84, loss:0.00001, loss_test:0.01908, lr:6.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:35.277, tt:2998.505\n",
      "Ep:85, loss:0.00001, loss_test:0.01924, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.278, tt:3033.878\n",
      "Ep:86, loss:0.00001, loss_test:0.01935, lr:6.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.276, tt:3069.002\n",
      "Ep:87, loss:0.00001, loss_test:0.01959, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.292, tt:3105.660\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01968, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.338, tt:3145.040\n",
      "Ep:89, loss:0.00001, loss_test:0.01971, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.343, tt:3180.903\n",
      "Ep:90, loss:0.00001, loss_test:0.01992, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.336, tt:3215.594\n",
      "Ep:91, loss:0.00001, loss_test:0.02006, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.337, tt:3251.020\n",
      "Ep:92, loss:0.00001, loss_test:0.02010, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.327, tt:3285.366\n",
      "Ep:93, loss:0.00001, loss_test:0.02034, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.324, tt:3320.494\n",
      "Ep:94, loss:0.00001, loss_test:0.02038, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.339, tt:3357.228\n",
      "Ep:95, loss:0.00001, loss_test:0.02050, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.342, tt:3392.831\n",
      "Ep:96, loss:0.00001, loss_test:0.02073, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.339, tt:3427.876\n",
      "Ep:97, loss:0.00001, loss_test:0.02066, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.345, tt:3463.835\n",
      "Ep:98, loss:0.00001, loss_test:0.02086, lr:6.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.354, tt:3500.050\n",
      "Ep:99, loss:0.00001, loss_test:0.02100, lr:5.94e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.350, tt:3535.017\n",
      "Ep:100, loss:0.00001, loss_test:0.02118, lr:5.88e-02, fs:0.88421 (r=0.848,p=0.923),  time:35.367, tt:3572.045\n",
      "Ep:101, loss:0.00001, loss_test:0.02124, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.366, tt:3607.295\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.02136, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.372, tt:3643.301\n",
      "Ep:103, loss:0.00001, loss_test:0.02148, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.372, tt:3678.685\n",
      "Ep:104, loss:0.00001, loss_test:0.02154, lr:5.82e-02, fs:0.88889 (r=0.848,p=0.933),  time:35.369, tt:3713.732\n",
      "Ep:105, loss:0.00001, loss_test:0.02160, lr:5.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.359, tt:3748.027\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00001, loss_test:0.02175, lr:5.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.362, tt:3783.774\n",
      "Ep:107, loss:0.00000, loss_test:0.02189, lr:5.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.378, tt:3820.835\n",
      "Ep:108, loss:0.00000, loss_test:0.02190, lr:5.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.386, tt:3857.026\n",
      "Ep:109, loss:0.00000, loss_test:0.02201, lr:5.82e-02, fs:0.89362 (r=0.848,p=0.944),  time:35.387, tt:3892.588\n",
      "Ep:110, loss:0.00000, loss_test:0.02205, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.403, tt:3929.755\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.02224, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.396, tt:3964.299\n",
      "Ep:112, loss:0.00000, loss_test:0.02235, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.405, tt:4000.751\n",
      "Ep:113, loss:0.00000, loss_test:0.02247, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.395, tt:4035.013\n",
      "Ep:114, loss:0.00000, loss_test:0.02252, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.401, tt:4071.144\n",
      "Ep:115, loss:0.00000, loss_test:0.02259, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.401, tt:4106.531\n",
      "Ep:116, loss:0.00000, loss_test:0.02263, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.390, tt:4140.618\n",
      "Ep:117, loss:0.00000, loss_test:0.02281, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.441, tt:4182.030\n",
      "Ep:118, loss:0.00000, loss_test:0.02283, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.432, tt:4216.370\n",
      "Ep:119, loss:0.00000, loss_test:0.02298, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.427, tt:4251.225\n",
      "Ep:120, loss:0.00000, loss_test:0.02305, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.433, tt:4287.449\n",
      "Ep:121, loss:0.00000, loss_test:0.02309, lr:5.82e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.433, tt:4322.788\n",
      "Ep:122, loss:0.00000, loss_test:0.02320, lr:5.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.424, tt:4357.193\n",
      "Ep:123, loss:0.00000, loss_test:0.02327, lr:5.71e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.411, tt:4390.943\n",
      "Ep:124, loss:0.00000, loss_test:0.02341, lr:5.65e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.403, tt:4425.325\n",
      "Ep:125, loss:0.00000, loss_test:0.02342, lr:5.59e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.383, tt:4458.312\n",
      "Ep:126, loss:0.00000, loss_test:0.02355, lr:5.54e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.365, tt:4491.351\n",
      "Ep:127, loss:0.00000, loss_test:0.02361, lr:5.48e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.371, tt:4527.441\n",
      "Ep:128, loss:0.00000, loss_test:0.02363, lr:5.43e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.369, tt:4562.616\n",
      "Ep:129, loss:0.00000, loss_test:0.02374, lr:5.37e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.364, tt:4597.295\n",
      "Ep:130, loss:0.00000, loss_test:0.02378, lr:5.32e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.358, tt:4631.845\n",
      "Ep:131, loss:0.00000, loss_test:0.02388, lr:5.27e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.352, tt:4666.397\n",
      "Ep:132, loss:0.00000, loss_test:0.02394, lr:5.21e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.341, tt:4700.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00000, loss_test:0.02395, lr:5.16e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.344, tt:4736.070\n",
      "Ep:134, loss:0.00000, loss_test:0.02412, lr:5.11e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.343, tt:4771.371\n",
      "Ep:135, loss:0.00000, loss_test:0.02402, lr:5.06e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.344, tt:4806.845\n",
      "Ep:136, loss:0.00000, loss_test:0.02418, lr:5.01e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.337, tt:4841.174\n",
      "Ep:137, loss:0.00000, loss_test:0.02427, lr:4.96e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.340, tt:4876.870\n",
      "Ep:138, loss:0.00000, loss_test:0.02426, lr:4.91e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.337, tt:4911.905\n",
      "Ep:139, loss:0.00000, loss_test:0.02433, lr:4.86e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.341, tt:4947.769\n",
      "Ep:140, loss:0.00000, loss_test:0.02434, lr:4.81e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.334, tt:4982.134\n",
      "Ep:141, loss:0.00000, loss_test:0.02448, lr:4.76e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.363, tt:5021.478\n",
      "Ep:142, loss:0.00000, loss_test:0.02453, lr:4.71e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.376, tt:5058.835\n",
      "Ep:143, loss:0.00000, loss_test:0.02460, lr:4.67e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.365, tt:5092.538\n",
      "Ep:144, loss:0.00000, loss_test:0.02470, lr:4.62e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.356, tt:5126.569\n",
      "Ep:145, loss:0.00000, loss_test:0.02471, lr:4.57e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.342, tt:5159.889\n",
      "Ep:146, loss:0.00000, loss_test:0.02480, lr:4.53e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.328, tt:5193.161\n",
      "Ep:147, loss:0.00000, loss_test:0.02485, lr:4.48e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.320, tt:5227.293\n",
      "Ep:148, loss:0.00000, loss_test:0.02491, lr:4.44e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.315, tt:5261.907\n",
      "Ep:149, loss:0.00000, loss_test:0.02496, lr:4.39e-02, fs:0.89840 (r=0.848,p=0.955),  time:35.290, tt:5293.547\n",
      "Ep:150, loss:0.00000, loss_test:0.02496, lr:4.35e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.282, tt:5327.630\n",
      "Ep:151, loss:0.00000, loss_test:0.02501, lr:4.31e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.282, tt:5362.893\n",
      "Ep:152, loss:0.00000, loss_test:0.02508, lr:4.26e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.290, tt:5399.308\n",
      "Ep:153, loss:0.00000, loss_test:0.02515, lr:4.22e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.283, tt:5433.632\n",
      "Ep:154, loss:0.00000, loss_test:0.02513, lr:4.18e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.280, tt:5468.427\n",
      "Ep:155, loss:0.00000, loss_test:0.02520, lr:4.14e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.273, tt:5502.608\n",
      "Ep:156, loss:0.00000, loss_test:0.02525, lr:4.10e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.278, tt:5538.679\n",
      "Ep:157, loss:0.00000, loss_test:0.02532, lr:4.05e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.274, tt:5573.329\n",
      "Ep:158, loss:0.00000, loss_test:0.02536, lr:4.01e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.281, tt:5609.651\n",
      "Ep:159, loss:0.00000, loss_test:0.02539, lr:3.97e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.295, tt:5647.166\n",
      "Ep:160, loss:0.00000, loss_test:0.02545, lr:3.93e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.294, tt:5682.405\n",
      "Ep:161, loss:0.00000, loss_test:0.02549, lr:3.89e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.276, tt:5714.767\n",
      "Ep:162, loss:0.00000, loss_test:0.02557, lr:3.86e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.275, tt:5749.899\n",
      "Ep:163, loss:0.00000, loss_test:0.02554, lr:3.82e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.285, tt:5786.734\n",
      "Ep:164, loss:0.00000, loss_test:0.02562, lr:3.78e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.290, tt:5822.929\n",
      "Ep:165, loss:0.00000, loss_test:0.02566, lr:3.74e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.317, tt:5862.592\n",
      "Ep:166, loss:0.00000, loss_test:0.02565, lr:3.70e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.319, tt:5898.226\n",
      "Ep:167, loss:0.00000, loss_test:0.02575, lr:3.67e-02, fs:0.89247 (r=0.838,p=0.954),  time:35.321, tt:5933.976\n",
      "Ep:168, loss:0.00000, loss_test:0.02577, lr:3.63e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.318, tt:5968.797\n",
      "Ep:169, loss:0.00000, loss_test:0.02583, lr:3.59e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.316, tt:6003.716\n",
      "Ep:170, loss:0.00000, loss_test:0.02587, lr:3.56e-02, fs:0.88649 (r=0.828,p=0.953),  time:35.315, tt:6038.810\n",
      "Ep:171, loss:0.00000, loss_test:0.02587, lr:3.52e-02, fs:0.88043 (r=0.818,p=0.953),  time:35.313, tt:6073.870\n",
      "Ep:172, loss:0.00000, loss_test:0.02595, lr:3.49e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.311, tt:6108.856\n",
      "Ep:173, loss:0.00000, loss_test:0.02598, lr:3.45e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.318, tt:6145.386\n",
      "Ep:174, loss:0.00000, loss_test:0.02605, lr:3.42e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.318, tt:6180.624\n",
      "Ep:175, loss:0.00000, loss_test:0.02609, lr:3.38e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.333, tt:6218.683\n",
      "Ep:176, loss:0.00000, loss_test:0.02605, lr:3.35e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.335, tt:6254.364\n",
      "Ep:177, loss:0.00000, loss_test:0.02607, lr:3.32e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.325, tt:6287.899\n",
      "Ep:178, loss:0.00000, loss_test:0.02616, lr:3.28e-02, fs:0.87432 (r=0.808,p=0.952),  time:35.326, tt:6323.270\n",
      "Ep:179, loss:0.00000, loss_test:0.02622, lr:3.25e-02, fs:0.86813 (r=0.798,p=0.952),  time:35.331, tt:6359.574\n",
      "Ep:180, loss:0.00000, loss_test:0.02622, lr:3.22e-02, fs:0.86188 (r=0.788,p=0.951),  time:35.324, tt:6393.700\n",
      "Ep:181, loss:0.00000, loss_test:0.02621, lr:3.19e-02, fs:0.85556 (r=0.778,p=0.951),  time:35.332, tt:6430.465\n",
      "Ep:182, loss:0.00000, loss_test:0.02629, lr:3.15e-02, fs:0.84916 (r=0.768,p=0.950),  time:35.341, tt:6467.492\n",
      "Ep:183, loss:0.00000, loss_test:0.02631, lr:3.12e-02, fs:0.84916 (r=0.768,p=0.950),  time:35.336, tt:6501.867\n",
      "Ep:184, loss:0.00000, loss_test:0.02633, lr:3.09e-02, fs:0.84916 (r=0.768,p=0.950),  time:35.346, tt:6538.966\n",
      "Ep:185, loss:0.00000, loss_test:0.02638, lr:3.06e-02, fs:0.84916 (r=0.768,p=0.950),  time:35.346, tt:6574.384\n",
      "Ep:186, loss:0.00000, loss_test:0.02639, lr:3.03e-02, fs:0.84916 (r=0.768,p=0.950),  time:35.346, tt:6609.639\n",
      "Ep:187, loss:0.00000, loss_test:0.02642, lr:3.00e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.343, tt:6644.426\n",
      "Ep:188, loss:0.00000, loss_test:0.02645, lr:2.97e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.345, tt:6680.280\n",
      "Ep:189, loss:0.00000, loss_test:0.02649, lr:2.94e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.370, tt:6720.279\n",
      "Ep:190, loss:0.00000, loss_test:0.02651, lr:2.91e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.367, tt:6755.076\n",
      "Ep:191, loss:0.00000, loss_test:0.02653, lr:2.88e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.374, tt:6791.725\n",
      "Ep:192, loss:0.00000, loss_test:0.02656, lr:2.85e-02, fs:0.84270 (r=0.758,p=0.949),  time:35.371, tt:6826.540\n",
      "Ep:193, loss:0.00000, loss_test:0.02659, lr:2.82e-02, fs:0.83616 (r=0.747,p=0.949),  time:35.359, tt:6859.573\n",
      "Ep:194, loss:0.00000, loss_test:0.02661, lr:2.80e-02, fs:0.83616 (r=0.747,p=0.949),  time:35.352, tt:6893.598\n",
      "Ep:195, loss:0.00000, loss_test:0.02665, lr:2.77e-02, fs:0.83616 (r=0.747,p=0.949),  time:35.347, tt:6928.047\n",
      "Ep:196, loss:0.00000, loss_test:0.02670, lr:2.74e-02, fs:0.82955 (r=0.737,p=0.948),  time:35.356, tt:6965.193\n",
      "Ep:197, loss:0.00000, loss_test:0.02672, lr:2.71e-02, fs:0.82955 (r=0.737,p=0.948),  time:35.356, tt:7000.496\n",
      "Ep:198, loss:0.00000, loss_test:0.02672, lr:2.69e-02, fs:0.82955 (r=0.737,p=0.948),  time:35.343, tt:7033.237\n",
      "Ep:199, loss:0.00000, loss_test:0.02675, lr:2.66e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.341, tt:7068.141\n",
      "Ep:200, loss:0.00000, loss_test:0.02679, lr:2.63e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.339, tt:7103.156\n",
      "Ep:201, loss:0.00000, loss_test:0.02679, lr:2.61e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.332, tt:7137.093\n",
      "Ep:202, loss:0.00000, loss_test:0.02682, lr:2.58e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.333, tt:7172.607\n",
      "Ep:203, loss:0.00000, loss_test:0.02684, lr:2.55e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.330, tt:7207.314\n",
      "Ep:204, loss:0.00000, loss_test:0.02686, lr:2.53e-02, fs:0.82759 (r=0.727,p=0.960),  time:35.326, tt:7241.917\n",
      "Ep:205, loss:0.00000, loss_test:0.02690, lr:2.50e-02, fs:0.82286 (r=0.727,p=0.947),  time:35.300, tt:7271.841\n",
      "Ep:206, loss:0.00000, loss_test:0.02694, lr:2.48e-02, fs:0.82759 (r=0.727,p=0.960),  time:35.245, tt:7295.807\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.03015, lr:1.00e-02, fs:0.58824 (r=0.556,p=0.625),  time:23.226, tt:23.226\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02287, lr:1.00e-02, fs:0.64317 (r=0.737,p=0.570),  time:21.403, tt:42.806\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02119, lr:1.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:22.146, tt:66.438\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02160, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:24.023, tt:96.094\n",
      "Ep:4, loss:0.00004, loss_test:0.02233, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:25.894, tt:129.469\n",
      "Ep:5, loss:0.00004, loss_test:0.02290, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:27.367, tt:164.201\n",
      "Ep:6, loss:0.00005, loss_test:0.02319, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:28.423, tt:198.963\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02321, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.167, tt:233.336\n",
      "Ep:8, loss:0.00005, loss_test:0.02301, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:29.608, tt:266.473\n",
      "Ep:9, loss:0.00004, loss_test:0.02266, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:30.084, tt:300.842\n",
      "Ep:10, loss:0.00004, loss_test:0.02222, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:30.470, tt:335.174\n",
      "Ep:11, loss:0.00004, loss_test:0.02173, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:30.920, tt:371.040\n",
      "Ep:12, loss:0.00004, loss_test:0.02123, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:31.332, tt:407.315\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02077, lr:1.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:31.636, tt:442.900\n",
      "Ep:14, loss:0.00004, loss_test:0.02039, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:31.961, tt:479.416\n",
      "Ep:15, loss:0.00004, loss_test:0.02011, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:32.105, tt:513.688\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01990, lr:1.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:32.209, tt:547.548\n",
      "Ep:17, loss:0.00004, loss_test:0.01977, lr:1.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:32.314, tt:581.649\n",
      "Ep:18, loss:0.00004, loss_test:0.01969, lr:1.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:32.314, tt:613.965\n",
      "Ep:19, loss:0.00004, loss_test:0.01961, lr:1.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:32.489, tt:649.780\n",
      "Ep:20, loss:0.00004, loss_test:0.01954, lr:1.00e-02, fs:0.64822 (r=0.828,p=0.532),  time:32.534, tt:683.207\n",
      "Ep:21, loss:0.00004, loss_test:0.01947, lr:1.00e-02, fs:0.64542 (r=0.818,p=0.533),  time:32.626, tt:717.765\n",
      "Ep:22, loss:0.00004, loss_test:0.01940, lr:1.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:32.629, tt:750.467\n",
      "Ep:23, loss:0.00004, loss_test:0.01932, lr:1.00e-02, fs:0.64800 (r=0.818,p=0.536),  time:32.859, tt:788.624\n",
      "Ep:24, loss:0.00004, loss_test:0.01925, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:32.925, tt:823.114\n",
      "Ep:25, loss:0.00004, loss_test:0.01918, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:32.962, tt:857.013\n",
      "Ep:26, loss:0.00004, loss_test:0.01910, lr:1.00e-02, fs:0.64286 (r=0.818,p=0.529),  time:33.012, tt:891.324\n",
      "Ep:27, loss:0.00004, loss_test:0.01901, lr:9.90e-03, fs:0.64286 (r=0.818,p=0.529),  time:32.980, tt:923.439\n",
      "Ep:28, loss:0.00004, loss_test:0.01894, lr:9.80e-03, fs:0.64286 (r=0.818,p=0.529),  time:33.035, tt:958.014\n",
      "Ep:29, loss:0.00003, loss_test:0.01887, lr:9.70e-03, fs:0.64286 (r=0.818,p=0.529),  time:33.092, tt:992.761\n",
      "Ep:30, loss:0.00003, loss_test:0.01880, lr:9.61e-03, fs:0.64286 (r=0.818,p=0.529),  time:33.172, tt:1028.317\n",
      "Ep:31, loss:0.00003, loss_test:0.01874, lr:9.51e-03, fs:0.64777 (r=0.808,p=0.541),  time:33.225, tt:1063.200\n",
      "Ep:32, loss:0.00003, loss_test:0.01867, lr:9.41e-03, fs:0.64777 (r=0.808,p=0.541),  time:33.268, tt:1097.832\n",
      "Ep:33, loss:0.00003, loss_test:0.01861, lr:9.32e-03, fs:0.64777 (r=0.808,p=0.541),  time:33.345, tt:1133.727\n",
      "Ep:34, loss:0.00003, loss_test:0.01855, lr:9.23e-03, fs:0.65041 (r=0.808,p=0.544),  time:33.395, tt:1168.842\n",
      "Ep:35, loss:0.00003, loss_test:0.01850, lr:9.14e-03, fs:0.65574 (r=0.808,p=0.552),  time:33.434, tt:1203.613\n",
      "Ep:36, loss:0.00003, loss_test:0.01844, lr:9.04e-03, fs:0.65844 (r=0.808,p=0.556),  time:33.421, tt:1236.593\n",
      "Ep:37, loss:0.00003, loss_test:0.01839, lr:8.95e-03, fs:0.65844 (r=0.808,p=0.556),  time:33.423, tt:1270.083\n",
      "Ep:38, loss:0.00003, loss_test:0.01833, lr:8.86e-03, fs:0.65844 (r=0.808,p=0.556),  time:33.435, tt:1303.971\n",
      "Ep:39, loss:0.00003, loss_test:0.01828, lr:8.78e-03, fs:0.65844 (r=0.808,p=0.556),  time:33.495, tt:1339.794\n",
      "Ep:40, loss:0.00003, loss_test:0.01823, lr:8.69e-03, fs:0.66116 (r=0.808,p=0.559),  time:33.524, tt:1374.478\n",
      "Ep:41, loss:0.00003, loss_test:0.01818, lr:8.60e-03, fs:0.66390 (r=0.808,p=0.563),  time:33.561, tt:1409.581\n",
      "Ep:42, loss:0.00003, loss_test:0.01813, lr:8.51e-03, fs:0.66667 (r=0.818,p=0.562),  time:33.666, tt:1447.643\n",
      "Ep:43, loss:0.00003, loss_test:0.01809, lr:8.43e-03, fs:0.67220 (r=0.818,p=0.570),  time:33.687, tt:1482.223\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01804, lr:8.43e-03, fs:0.67500 (r=0.818,p=0.574),  time:33.714, tt:1517.109\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01799, lr:8.43e-03, fs:0.67500 (r=0.818,p=0.574),  time:33.738, tt:1551.930\n",
      "Ep:46, loss:0.00003, loss_test:0.01794, lr:8.43e-03, fs:0.67500 (r=0.818,p=0.574),  time:33.755, tt:1586.493\n",
      "Ep:47, loss:0.00003, loss_test:0.01790, lr:8.43e-03, fs:0.68050 (r=0.828,p=0.577),  time:33.786, tt:1621.749\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.01785, lr:8.43e-03, fs:0.68333 (r=0.828,p=0.582),  time:33.832, tt:1657.776\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01781, lr:8.43e-03, fs:0.69167 (r=0.838,p=0.589),  time:33.858, tt:1692.875\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01776, lr:8.43e-03, fs:0.68619 (r=0.828,p=0.586),  time:33.857, tt:1726.727\n",
      "Ep:51, loss:0.00003, loss_test:0.01772, lr:8.43e-03, fs:0.68908 (r=0.828,p=0.590),  time:33.873, tt:1761.413\n",
      "Ep:52, loss:0.00003, loss_test:0.01767, lr:8.43e-03, fs:0.68908 (r=0.828,p=0.590),  time:33.902, tt:1796.806\n",
      "Ep:53, loss:0.00003, loss_test:0.01763, lr:8.43e-03, fs:0.69748 (r=0.838,p=0.597),  time:33.916, tt:1831.469\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01759, lr:8.43e-03, fs:0.70339 (r=0.838,p=0.606),  time:33.959, tt:1867.721\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.01754, lr:8.43e-03, fs:0.70339 (r=0.838,p=0.606),  time:33.977, tt:1902.717\n",
      "Ep:56, loss:0.00003, loss_test:0.01750, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:33.983, tt:1937.016\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01746, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:34.010, tt:1972.557\n",
      "Ep:58, loss:0.00003, loss_test:0.01741, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:34.004, tt:2006.210\n",
      "Ep:59, loss:0.00003, loss_test:0.01737, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:34.044, tt:2042.642\n",
      "Ep:60, loss:0.00003, loss_test:0.01733, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:34.055, tt:2077.371\n",
      "Ep:61, loss:0.00003, loss_test:0.01728, lr:8.43e-03, fs:0.70638 (r=0.838,p=0.610),  time:34.089, tt:2113.529\n",
      "Ep:62, loss:0.00003, loss_test:0.01725, lr:8.43e-03, fs:0.70386 (r=0.828,p=0.612),  time:34.110, tt:2148.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.01721, lr:8.43e-03, fs:0.70690 (r=0.828,p=0.617),  time:34.132, tt:2184.432\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00003, loss_test:0.01716, lr:8.43e-03, fs:0.70690 (r=0.828,p=0.617),  time:34.154, tt:2219.990\n",
      "Ep:65, loss:0.00003, loss_test:0.01712, lr:8.43e-03, fs:0.70996 (r=0.828,p=0.621),  time:34.178, tt:2255.733\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00003, loss_test:0.01708, lr:8.43e-03, fs:0.70996 (r=0.828,p=0.621),  time:34.210, tt:2292.038\n",
      "Ep:67, loss:0.00003, loss_test:0.01705, lr:8.43e-03, fs:0.70996 (r=0.828,p=0.621),  time:34.196, tt:2325.313\n",
      "Ep:68, loss:0.00003, loss_test:0.01701, lr:8.43e-03, fs:0.70435 (r=0.818,p=0.618),  time:34.218, tt:2361.065\n",
      "Ep:69, loss:0.00003, loss_test:0.01698, lr:8.43e-03, fs:0.70435 (r=0.818,p=0.618),  time:34.232, tt:2396.232\n",
      "Ep:70, loss:0.00003, loss_test:0.01694, lr:8.43e-03, fs:0.70435 (r=0.818,p=0.618),  time:34.247, tt:2431.539\n",
      "Ep:71, loss:0.00003, loss_test:0.01691, lr:8.43e-03, fs:0.70435 (r=0.818,p=0.618),  time:34.287, tt:2468.638\n",
      "Ep:72, loss:0.00003, loss_test:0.01688, lr:8.43e-03, fs:0.69869 (r=0.808,p=0.615),  time:34.293, tt:2503.405\n",
      "Ep:73, loss:0.00003, loss_test:0.01684, lr:8.43e-03, fs:0.69869 (r=0.808,p=0.615),  time:34.328, tt:2540.304\n",
      "Ep:74, loss:0.00003, loss_test:0.01680, lr:8.43e-03, fs:0.69869 (r=0.808,p=0.615),  time:34.343, tt:2575.695\n",
      "Ep:75, loss:0.00003, loss_test:0.01677, lr:8.43e-03, fs:0.70175 (r=0.808,p=0.620),  time:34.360, tt:2611.327\n",
      "Ep:76, loss:0.00003, loss_test:0.01673, lr:8.43e-03, fs:0.70742 (r=0.818,p=0.623),  time:34.376, tt:2646.939\n",
      "Ep:77, loss:0.00003, loss_test:0.01669, lr:8.35e-03, fs:0.70742 (r=0.818,p=0.623),  time:34.412, tt:2684.162\n",
      "Ep:78, loss:0.00003, loss_test:0.01665, lr:8.26e-03, fs:0.70742 (r=0.818,p=0.623),  time:34.432, tt:2720.132\n",
      "Ep:79, loss:0.00003, loss_test:0.01662, lr:8.18e-03, fs:0.70742 (r=0.818,p=0.623),  time:34.446, tt:2755.707\n",
      "Ep:80, loss:0.00003, loss_test:0.01659, lr:8.10e-03, fs:0.71053 (r=0.818,p=0.628),  time:34.464, tt:2791.567\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01656, lr:8.10e-03, fs:0.71053 (r=0.818,p=0.628),  time:34.505, tt:2829.449\n",
      "Ep:82, loss:0.00002, loss_test:0.01654, lr:8.10e-03, fs:0.71053 (r=0.818,p=0.628),  time:34.540, tt:2866.840\n",
      "Ep:83, loss:0.00002, loss_test:0.01652, lr:8.10e-03, fs:0.71366 (r=0.818,p=0.633),  time:34.575, tt:2904.296\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.01649, lr:8.10e-03, fs:0.72247 (r=0.828,p=0.641),  time:34.611, tt:2941.947\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.01647, lr:8.10e-03, fs:0.72807 (r=0.838,p=0.643),  time:34.641, tt:2979.110\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01645, lr:8.10e-03, fs:0.72807 (r=0.838,p=0.643),  time:34.672, tt:3016.441\n",
      "Ep:87, loss:0.00002, loss_test:0.01643, lr:8.10e-03, fs:0.73128 (r=0.838,p=0.648),  time:34.696, tt:3053.219\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.01641, lr:8.10e-03, fs:0.72566 (r=0.828,p=0.646),  time:34.708, tt:3088.971\n",
      "Ep:89, loss:0.00002, loss_test:0.01639, lr:8.10e-03, fs:0.72889 (r=0.828,p=0.651),  time:34.735, tt:3126.170\n",
      "Ep:90, loss:0.00002, loss_test:0.01636, lr:8.10e-03, fs:0.72889 (r=0.828,p=0.651),  time:34.760, tt:3163.121\n",
      "Ep:91, loss:0.00002, loss_test:0.01634, lr:8.10e-03, fs:0.72889 (r=0.828,p=0.651),  time:34.768, tt:3198.680\n",
      "Ep:92, loss:0.00002, loss_test:0.01632, lr:8.10e-03, fs:0.72889 (r=0.828,p=0.651),  time:34.779, tt:3234.492\n",
      "Ep:93, loss:0.00002, loss_test:0.01629, lr:8.10e-03, fs:0.72566 (r=0.828,p=0.646),  time:34.802, tt:3271.406\n",
      "Ep:94, loss:0.00002, loss_test:0.01628, lr:8.10e-03, fs:0.72566 (r=0.828,p=0.646),  time:34.822, tt:3308.117\n",
      "Ep:95, loss:0.00002, loss_test:0.01625, lr:8.10e-03, fs:0.73214 (r=0.828,p=0.656),  time:34.841, tt:3344.699\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.01623, lr:8.10e-03, fs:0.73874 (r=0.828,p=0.667),  time:34.843, tt:3379.786\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00002, loss_test:0.01620, lr:8.10e-03, fs:0.73874 (r=0.828,p=0.667),  time:34.848, tt:3415.151\n",
      "Ep:98, loss:0.00002, loss_test:0.01618, lr:8.10e-03, fs:0.73874 (r=0.828,p=0.667),  time:34.843, tt:3449.416\n",
      "Ep:99, loss:0.00002, loss_test:0.01617, lr:8.10e-03, fs:0.73874 (r=0.828,p=0.667),  time:34.841, tt:3484.126\n",
      "Ep:100, loss:0.00002, loss_test:0.01615, lr:8.10e-03, fs:0.74208 (r=0.828,p=0.672),  time:34.826, tt:3517.445\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00002, loss_test:0.01613, lr:8.10e-03, fs:0.74208 (r=0.828,p=0.672),  time:34.836, tt:3553.261\n",
      "Ep:102, loss:0.00002, loss_test:0.01611, lr:8.10e-03, fs:0.74208 (r=0.828,p=0.672),  time:34.856, tt:3590.163\n",
      "Ep:103, loss:0.00002, loss_test:0.01608, lr:8.10e-03, fs:0.74208 (r=0.828,p=0.672),  time:34.861, tt:3625.585\n",
      "Ep:104, loss:0.00002, loss_test:0.01606, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.852, tt:3659.474\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.01605, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.851, tt:3694.181\n",
      "Ep:106, loss:0.00002, loss_test:0.01604, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.834, tt:3727.253\n",
      "Ep:107, loss:0.00002, loss_test:0.01603, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.831, tt:3761.731\n",
      "Ep:108, loss:0.00002, loss_test:0.01601, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.834, tt:3796.885\n",
      "Ep:109, loss:0.00002, loss_test:0.01599, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.847, tt:3833.142\n",
      "Ep:110, loss:0.00002, loss_test:0.01597, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.854, tt:3868.841\n",
      "Ep:111, loss:0.00002, loss_test:0.01595, lr:8.10e-03, fs:0.74545 (r=0.828,p=0.678),  time:34.865, tt:3904.928\n",
      "Ep:112, loss:0.00002, loss_test:0.01593, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.857, tt:3938.863\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00002, loss_test:0.01590, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.841, tt:3971.834\n",
      "Ep:114, loss:0.00002, loss_test:0.01588, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.858, tt:4008.702\n",
      "Ep:115, loss:0.00002, loss_test:0.01586, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.851, tt:4042.674\n",
      "Ep:116, loss:0.00002, loss_test:0.01584, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.855, tt:4077.991\n",
      "Ep:117, loss:0.00002, loss_test:0.01582, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.865, tt:4114.071\n",
      "Ep:118, loss:0.00002, loss_test:0.01581, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.865, tt:4148.881\n",
      "Ep:119, loss:0.00002, loss_test:0.01579, lr:8.10e-03, fs:0.75455 (r=0.838,p=0.686),  time:34.866, tt:4183.941\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.01577, lr:8.10e-03, fs:0.75455 (r=0.838,p=0.686),  time:34.867, tt:4218.964\n",
      "Ep:121, loss:0.00002, loss_test:0.01575, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.875, tt:4254.695\n",
      "Ep:122, loss:0.00002, loss_test:0.01574, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.882, tt:4290.538\n",
      "Ep:123, loss:0.00002, loss_test:0.01573, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.890, tt:4326.401\n",
      "Ep:124, loss:0.00002, loss_test:0.01571, lr:8.10e-03, fs:0.74886 (r=0.828,p=0.683),  time:34.902, tt:4362.711\n",
      "Ep:125, loss:0.00002, loss_test:0.01570, lr:8.10e-03, fs:0.75229 (r=0.828,p=0.689),  time:34.903, tt:4397.787\n",
      "Ep:126, loss:0.00002, loss_test:0.01568, lr:8.10e-03, fs:0.75576 (r=0.828,p=0.695),  time:34.907, tt:4433.248\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.01567, lr:8.10e-03, fs:0.75576 (r=0.828,p=0.695),  time:34.904, tt:4467.742\n",
      "Ep:128, loss:0.00002, loss_test:0.01565, lr:8.10e-03, fs:0.75576 (r=0.828,p=0.695),  time:34.939, tt:4507.074\n",
      "Ep:129, loss:0.00002, loss_test:0.01564, lr:8.10e-03, fs:0.75926 (r=0.828,p=0.701),  time:34.938, tt:4541.918\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00002, loss_test:0.01563, lr:8.10e-03, fs:0.76498 (r=0.838,p=0.703),  time:34.953, tt:4578.863\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00002, loss_test:0.01563, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.954, tt:4613.873\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00002, loss_test:0.01562, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.966, tt:4650.451\n",
      "Ep:133, loss:0.00002, loss_test:0.01561, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.972, tt:4686.269\n",
      "Ep:134, loss:0.00002, loss_test:0.01560, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.981, tt:4722.484\n",
      "Ep:135, loss:0.00002, loss_test:0.01560, lr:8.10e-03, fs:0.77209 (r=0.838,p=0.716),  time:34.972, tt:4756.191\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00002, loss_test:0.01559, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.972, tt:4791.227\n",
      "Ep:137, loss:0.00002, loss_test:0.01559, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.976, tt:4826.726\n",
      "Ep:138, loss:0.00002, loss_test:0.01557, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.978, tt:4861.904\n",
      "Ep:139, loss:0.00002, loss_test:0.01556, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.970, tt:4895.802\n",
      "Ep:140, loss:0.00002, loss_test:0.01555, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.974, tt:4931.370\n",
      "Ep:141, loss:0.00002, loss_test:0.01555, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.976, tt:4966.574\n",
      "Ep:142, loss:0.00002, loss_test:0.01555, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.971, tt:5000.845\n",
      "Ep:143, loss:0.00002, loss_test:0.01555, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.975, tt:5036.358\n",
      "Ep:144, loss:0.00002, loss_test:0.01554, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.982, tt:5072.372\n",
      "Ep:145, loss:0.00002, loss_test:0.01552, lr:8.10e-03, fs:0.77419 (r=0.848,p=0.712),  time:34.984, tt:5107.723\n",
      "##########Best model found so far##########\n",
      "Ep:146, loss:0.00002, loss_test:0.01552, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.993, tt:5144.002\n",
      "Ep:147, loss:0.00002, loss_test:0.01552, lr:8.10e-03, fs:0.76852 (r=0.838,p=0.709),  time:34.994, tt:5179.080\n",
      "Ep:148, loss:0.00002, loss_test:0.01551, lr:8.10e-03, fs:0.77419 (r=0.848,p=0.712),  time:34.996, tt:5214.427\n",
      "Ep:149, loss:0.00002, loss_test:0.01549, lr:8.10e-03, fs:0.77419 (r=0.848,p=0.712),  time:35.004, tt:5250.643\n",
      "Ep:150, loss:0.00002, loss_test:0.01549, lr:8.10e-03, fs:0.77419 (r=0.848,p=0.712),  time:35.009, tt:5286.364\n",
      "Ep:151, loss:0.00002, loss_test:0.01547, lr:8.10e-03, fs:0.77778 (r=0.848,p=0.718),  time:35.013, tt:5322.035\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00002, loss_test:0.01546, lr:8.10e-03, fs:0.77778 (r=0.848,p=0.718),  time:35.015, tt:5357.296\n",
      "Ep:153, loss:0.00002, loss_test:0.01545, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.021, tt:5393.307\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00002, loss_test:0.01543, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.020, tt:5428.159\n",
      "Ep:155, loss:0.00002, loss_test:0.01544, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.017, tt:5462.718\n",
      "Ep:156, loss:0.00002, loss_test:0.01543, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.016, tt:5497.541\n",
      "Ep:157, loss:0.00002, loss_test:0.01542, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.005, tt:5530.711\n",
      "Ep:158, loss:0.00002, loss_test:0.01541, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.004, tt:5565.711\n",
      "Ep:159, loss:0.00002, loss_test:0.01540, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.008, tt:5601.333\n",
      "Ep:160, loss:0.00002, loss_test:0.01540, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.014, tt:5637.200\n",
      "Ep:161, loss:0.00002, loss_test:0.01539, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.020, tt:5673.261\n",
      "Ep:162, loss:0.00002, loss_test:0.01538, lr:8.10e-03, fs:0.78140 (r=0.848,p=0.724),  time:35.029, tt:5709.655\n",
      "Ep:163, loss:0.00002, loss_test:0.01537, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.025, tt:5744.087\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00002, loss_test:0.01537, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.027, tt:5779.386\n",
      "Ep:165, loss:0.00002, loss_test:0.01536, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.036, tt:5816.046\n",
      "Ep:166, loss:0.00002, loss_test:0.01536, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.045, tt:5852.580\n",
      "Ep:167, loss:0.00002, loss_test:0.01534, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.049, tt:5888.220\n",
      "Ep:168, loss:0.00002, loss_test:0.01533, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.055, tt:5924.362\n",
      "Ep:169, loss:0.00002, loss_test:0.01533, lr:8.10e-03, fs:0.78505 (r=0.848,p=0.730),  time:35.055, tt:5959.392\n",
      "Ep:170, loss:0.00002, loss_test:0.01533, lr:8.10e-03, fs:0.79621 (r=0.848,p=0.750),  time:35.061, tt:5995.428\n",
      "##########Best model found so far##########\n",
      "Ep:171, loss:0.00002, loss_test:0.01532, lr:8.10e-03, fs:0.79621 (r=0.848,p=0.750),  time:35.066, tt:6031.289\n",
      "Ep:172, loss:0.00002, loss_test:0.01531, lr:8.10e-03, fs:0.79621 (r=0.848,p=0.750),  time:35.062, tt:6065.809\n",
      "Ep:173, loss:0.00002, loss_test:0.01531, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.060, tt:6100.420\n",
      "##########Best model found so far##########\n",
      "Ep:174, loss:0.00002, loss_test:0.01530, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.058, tt:6135.216\n",
      "Ep:175, loss:0.00002, loss_test:0.01530, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.057, tt:6170.073\n",
      "Ep:176, loss:0.00002, loss_test:0.01528, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.060, tt:6205.705\n",
      "Ep:177, loss:0.00002, loss_test:0.01528, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.058, tt:6240.326\n",
      "Ep:178, loss:0.00002, loss_test:0.01527, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.050, tt:6273.900\n",
      "Ep:179, loss:0.00002, loss_test:0.01527, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.051, tt:6309.188\n",
      "Ep:180, loss:0.00002, loss_test:0.01527, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.059, tt:6345.686\n",
      "Ep:181, loss:0.00002, loss_test:0.01526, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.062, tt:6381.206\n",
      "Ep:182, loss:0.00002, loss_test:0.01525, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.061, tt:6416.077\n",
      "Ep:183, loss:0.00002, loss_test:0.01525, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.059, tt:6450.900\n",
      "Ep:184, loss:0.00002, loss_test:0.01525, lr:8.10e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.051, tt:6484.388\n",
      "Ep:185, loss:0.00002, loss_test:0.01525, lr:8.02e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.051, tt:6519.418\n",
      "Ep:186, loss:0.00002, loss_test:0.01524, lr:7.94e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.047, tt:6553.741\n",
      "Ep:187, loss:0.00002, loss_test:0.01523, lr:7.86e-03, fs:0.80000 (r=0.848,p=0.757),  time:35.042, tt:6587.835\n",
      "Ep:188, loss:0.00002, loss_test:0.01523, lr:7.78e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.040, tt:6622.502\n",
      "Ep:189, loss:0.00001, loss_test:0.01522, lr:7.70e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.040, tt:6657.547\n",
      "Ep:190, loss:0.00001, loss_test:0.01521, lr:7.62e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.046, tt:6693.694\n",
      "Ep:191, loss:0.00001, loss_test:0.01521, lr:7.55e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.049, tt:6729.391\n",
      "Ep:192, loss:0.00001, loss_test:0.01521, lr:7.47e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.054, tt:6765.341\n",
      "Ep:193, loss:0.00001, loss_test:0.01521, lr:7.40e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.055, tt:6800.764\n",
      "Ep:194, loss:0.00001, loss_test:0.01522, lr:7.32e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.049, tt:6834.535\n",
      "Ep:195, loss:0.00001, loss_test:0.01521, lr:7.25e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.047, tt:6869.135\n",
      "Ep:196, loss:0.00001, loss_test:0.01520, lr:7.18e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.043, tt:6903.550\n",
      "Ep:197, loss:0.00001, loss_test:0.01519, lr:7.11e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.040, tt:6937.841\n",
      "Ep:198, loss:0.00001, loss_test:0.01519, lr:7.03e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.031, tt:6971.163\n",
      "Ep:199, loss:0.00001, loss_test:0.01520, lr:6.96e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.017, tt:7003.359\n",
      "Ep:200, loss:0.00001, loss_test:0.01519, lr:6.89e-03, fs:0.79426 (r=0.838,p=0.755),  time:35.014, tt:7037.898\n",
      "Ep:201, loss:0.00001, loss_test:0.01519, lr:6.83e-03, fs:0.79808 (r=0.838,p=0.761),  time:35.018, tt:7073.672\n",
      "Ep:202, loss:0.00001, loss_test:0.01518, lr:6.76e-03, fs:0.79808 (r=0.838,p=0.761),  time:35.005, tt:7106.099\n",
      "Ep:203, loss:0.00001, loss_test:0.01518, lr:6.69e-03, fs:0.79808 (r=0.838,p=0.761),  time:34.998, tt:7139.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00001, loss_test:0.01517, lr:6.62e-03, fs:0.79808 (r=0.838,p=0.761),  time:34.991, tt:7173.218\n",
      "Ep:205, loss:0.00001, loss_test:0.01518, lr:6.56e-03, fs:0.79808 (r=0.838,p=0.761),  time:34.987, tt:7207.333\n",
      "Ep:206, loss:0.00001, loss_test:0.01518, lr:6.49e-03, fs:0.79808 (r=0.838,p=0.761),  time:34.970, tt:7238.873\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02657, lr:1.00e-02, fs:0.58385 (r=0.475,p=0.758),  time:34.598, tt:34.598\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02140, lr:1.00e-02, fs:0.62564 (r=0.616,p=0.635),  time:30.833, tt:61.667\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.01938, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:32.314, tt:96.943\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.01937, lr:1.00e-02, fs:0.65000 (r=0.919,p=0.503),  time:34.531, tt:138.123\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01994, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.692, tt:178.461\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02043, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:35.960, tt:215.762\n",
      "Ep:6, loss:0.00004, loss_test:0.02065, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:36.702, tt:256.917\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02062, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.910, tt:295.277\n",
      "Ep:8, loss:0.00004, loss_test:0.02039, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.186, tt:334.677\n",
      "Ep:9, loss:0.00004, loss_test:0.02003, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:37.401, tt:374.010\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01963, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:37.451, tt:411.957\n",
      "Ep:11, loss:0.00004, loss_test:0.01922, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:37.673, tt:452.079\n",
      "Ep:12, loss:0.00004, loss_test:0.01886, lr:1.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:37.851, tt:492.059\n",
      "Ep:13, loss:0.00004, loss_test:0.01857, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:38.035, tt:532.491\n",
      "Ep:14, loss:0.00004, loss_test:0.01835, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:38.122, tt:571.834\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01821, lr:1.00e-02, fs:0.65399 (r=0.869,p=0.524),  time:38.147, tt:610.358\n",
      "Ep:16, loss:0.00003, loss_test:0.01812, lr:1.00e-02, fs:0.63566 (r=0.828,p=0.516),  time:38.092, tt:647.565\n",
      "Ep:17, loss:0.00003, loss_test:0.01805, lr:1.00e-02, fs:0.64542 (r=0.818,p=0.533),  time:37.947, tt:683.040\n",
      "Ep:18, loss:0.00003, loss_test:0.01799, lr:1.00e-02, fs:0.65323 (r=0.818,p=0.544),  time:38.064, tt:723.220\n",
      "Ep:19, loss:0.00003, loss_test:0.01790, lr:1.00e-02, fs:0.65863 (r=0.828,p=0.547),  time:38.101, tt:762.016\n",
      "Ep:20, loss:0.00003, loss_test:0.01779, lr:1.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:38.159, tt:801.335\n",
      "Ep:21, loss:0.00003, loss_test:0.01767, lr:1.00e-02, fs:0.66400 (r=0.838,p=0.550),  time:38.187, tt:840.110\n",
      "Ep:22, loss:0.00003, loss_test:0.01757, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.234, tt:879.386\n",
      "Ep:23, loss:0.00003, loss_test:0.01748, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.319, tt:919.644\n",
      "Ep:24, loss:0.00003, loss_test:0.01740, lr:1.00e-02, fs:0.66929 (r=0.859,p=0.548),  time:38.372, tt:959.303\n",
      "Ep:25, loss:0.00003, loss_test:0.01733, lr:1.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:38.407, tt:998.587\n",
      "Ep:26, loss:0.00003, loss_test:0.01727, lr:9.90e-03, fs:0.67717 (r=0.869,p=0.555),  time:38.455, tt:1038.298\n",
      "Ep:27, loss:0.00003, loss_test:0.01722, lr:9.80e-03, fs:0.67984 (r=0.869,p=0.558),  time:38.538, tt:1079.054\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01718, lr:9.80e-03, fs:0.67984 (r=0.869,p=0.558),  time:38.646, tt:1120.720\n",
      "Ep:29, loss:0.00003, loss_test:0.01713, lr:9.80e-03, fs:0.68254 (r=0.869,p=0.562),  time:38.762, tt:1162.871\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01709, lr:9.80e-03, fs:0.68800 (r=0.869,p=0.570),  time:38.741, tt:1200.971\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01704, lr:9.80e-03, fs:0.69355 (r=0.869,p=0.577),  time:38.730, tt:1239.355\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01700, lr:9.80e-03, fs:0.69636 (r=0.869,p=0.581),  time:38.732, tt:1278.140\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01695, lr:9.80e-03, fs:0.69106 (r=0.859,p=0.578),  time:38.670, tt:1314.787\n",
      "Ep:34, loss:0.00003, loss_test:0.01691, lr:9.80e-03, fs:0.69388 (r=0.859,p=0.582),  time:38.716, tt:1355.046\n",
      "Ep:35, loss:0.00003, loss_test:0.01686, lr:9.80e-03, fs:0.69672 (r=0.859,p=0.586),  time:38.717, tt:1393.821\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01682, lr:9.80e-03, fs:0.69672 (r=0.859,p=0.586),  time:38.745, tt:1433.576\n",
      "Ep:37, loss:0.00003, loss_test:0.01677, lr:9.80e-03, fs:0.69959 (r=0.859,p=0.590),  time:38.760, tt:1472.895\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01673, lr:9.80e-03, fs:0.69959 (r=0.859,p=0.590),  time:38.765, tt:1511.838\n",
      "Ep:39, loss:0.00003, loss_test:0.01669, lr:9.80e-03, fs:0.69959 (r=0.859,p=0.590),  time:38.733, tt:1549.320\n",
      "Ep:40, loss:0.00003, loss_test:0.01665, lr:9.80e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.732, tt:1588.023\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01661, lr:9.80e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.776, tt:1628.609\n",
      "Ep:42, loss:0.00003, loss_test:0.01658, lr:9.80e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.713, tt:1664.675\n",
      "Ep:43, loss:0.00003, loss_test:0.01654, lr:9.80e-03, fs:0.70248 (r=0.859,p=0.594),  time:38.692, tt:1702.468\n",
      "Ep:44, loss:0.00003, loss_test:0.01650, lr:9.80e-03, fs:0.70000 (r=0.848,p=0.596),  time:38.733, tt:1743.004\n",
      "Ep:45, loss:0.00003, loss_test:0.01645, lr:9.80e-03, fs:0.70000 (r=0.848,p=0.596),  time:38.754, tt:1782.683\n",
      "Ep:46, loss:0.00003, loss_test:0.01641, lr:9.80e-03, fs:0.70293 (r=0.848,p=0.600),  time:38.761, tt:1821.774\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01637, lr:9.80e-03, fs:0.69748 (r=0.838,p=0.597),  time:38.759, tt:1860.427\n",
      "Ep:48, loss:0.00003, loss_test:0.01633, lr:9.80e-03, fs:0.70339 (r=0.838,p=0.606),  time:38.781, tt:1900.263\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01629, lr:9.80e-03, fs:0.70339 (r=0.838,p=0.606),  time:38.739, tt:1936.929\n",
      "Ep:50, loss:0.00003, loss_test:0.01626, lr:9.80e-03, fs:0.70638 (r=0.838,p=0.610),  time:38.753, tt:1976.389\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.01623, lr:9.80e-03, fs:0.70940 (r=0.838,p=0.615),  time:38.741, tt:2014.527\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01619, lr:9.80e-03, fs:0.70940 (r=0.838,p=0.615),  time:38.751, tt:2053.779\n",
      "Ep:53, loss:0.00003, loss_test:0.01616, lr:9.80e-03, fs:0.70940 (r=0.838,p=0.615),  time:38.740, tt:2091.951\n",
      "Ep:54, loss:0.00003, loss_test:0.01612, lr:9.80e-03, fs:0.71795 (r=0.848,p=0.622),  time:38.747, tt:2131.091\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.01608, lr:9.80e-03, fs:0.72103 (r=0.848,p=0.627),  time:38.753, tt:2170.162\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01605, lr:9.80e-03, fs:0.72414 (r=0.848,p=0.632),  time:38.763, tt:2209.500\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01601, lr:9.80e-03, fs:0.72727 (r=0.848,p=0.636),  time:38.784, tt:2249.450\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01598, lr:9.80e-03, fs:0.73043 (r=0.848,p=0.641),  time:38.758, tt:2286.750\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.01594, lr:9.80e-03, fs:0.73362 (r=0.848,p=0.646),  time:38.751, tt:2325.064\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.01591, lr:9.80e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.751, tt:2363.783\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.01588, lr:9.80e-03, fs:0.73684 (r=0.848,p=0.651),  time:38.734, tt:2401.484\n",
      "Ep:62, loss:0.00003, loss_test:0.01584, lr:9.80e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.751, tt:2441.303\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.01581, lr:9.80e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.754, tt:2480.269\n",
      "Ep:64, loss:0.00002, loss_test:0.01578, lr:9.80e-03, fs:0.74336 (r=0.848,p=0.661),  time:38.769, tt:2519.955\n",
      "Ep:65, loss:0.00002, loss_test:0.01575, lr:9.80e-03, fs:0.74667 (r=0.848,p=0.667),  time:38.778, tt:2559.324\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.01572, lr:9.80e-03, fs:0.75000 (r=0.848,p=0.672),  time:38.807, tt:2600.041\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.01569, lr:9.80e-03, fs:0.75336 (r=0.848,p=0.677),  time:38.808, tt:2638.934\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01567, lr:9.80e-03, fs:0.75336 (r=0.848,p=0.677),  time:38.799, tt:2677.157\n",
      "Ep:69, loss:0.00002, loss_test:0.01564, lr:9.80e-03, fs:0.75336 (r=0.848,p=0.677),  time:38.796, tt:2715.732\n",
      "Ep:70, loss:0.00002, loss_test:0.01561, lr:9.80e-03, fs:0.75336 (r=0.848,p=0.677),  time:38.786, tt:2753.772\n",
      "Ep:71, loss:0.00002, loss_test:0.01558, lr:9.80e-03, fs:0.75336 (r=0.848,p=0.677),  time:38.780, tt:2792.176\n",
      "Ep:72, loss:0.00002, loss_test:0.01555, lr:9.80e-03, fs:0.75113 (r=0.838,p=0.680),  time:38.802, tt:2832.523\n",
      "Ep:73, loss:0.00002, loss_test:0.01552, lr:9.80e-03, fs:0.75113 (r=0.838,p=0.680),  time:38.763, tt:2868.429\n",
      "Ep:74, loss:0.00002, loss_test:0.01549, lr:9.80e-03, fs:0.75455 (r=0.838,p=0.686),  time:38.742, tt:2905.684\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.01547, lr:9.80e-03, fs:0.76498 (r=0.838,p=0.703),  time:38.753, tt:2945.261\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.01544, lr:9.80e-03, fs:0.76498 (r=0.838,p=0.703),  time:38.747, tt:2983.503\n",
      "Ep:77, loss:0.00002, loss_test:0.01542, lr:9.80e-03, fs:0.76852 (r=0.838,p=0.709),  time:38.726, tt:3020.639\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.01540, lr:9.80e-03, fs:0.76852 (r=0.838,p=0.709),  time:38.736, tt:3060.146\n",
      "Ep:79, loss:0.00002, loss_test:0.01537, lr:9.80e-03, fs:0.77209 (r=0.838,p=0.716),  time:38.736, tt:3098.915\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.01535, lr:9.80e-03, fs:0.76636 (r=0.828,p=0.713),  time:38.743, tt:3138.143\n",
      "Ep:81, loss:0.00002, loss_test:0.01533, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.769, tt:3179.030\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.01531, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.769, tt:3217.827\n",
      "Ep:83, loss:0.00002, loss_test:0.01529, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.768, tt:3256.483\n",
      "Ep:84, loss:0.00002, loss_test:0.01526, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.779, tt:3296.225\n",
      "Ep:85, loss:0.00002, loss_test:0.01524, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.792, tt:3336.152\n",
      "Ep:86, loss:0.00002, loss_test:0.01522, lr:9.80e-03, fs:0.77358 (r=0.828,p=0.726),  time:38.802, tt:3375.757\n",
      "Ep:87, loss:0.00002, loss_test:0.01520, lr:9.80e-03, fs:0.77725 (r=0.828,p=0.732),  time:38.808, tt:3415.088\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00002, loss_test:0.01518, lr:9.80e-03, fs:0.77725 (r=0.828,p=0.732),  time:38.798, tt:3453.003\n",
      "Ep:89, loss:0.00002, loss_test:0.01516, lr:9.80e-03, fs:0.77725 (r=0.828,p=0.732),  time:38.820, tt:3493.807\n",
      "Ep:90, loss:0.00002, loss_test:0.01514, lr:9.80e-03, fs:0.78095 (r=0.828,p=0.739),  time:38.824, tt:3532.966\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.01512, lr:9.80e-03, fs:0.78095 (r=0.828,p=0.739),  time:38.808, tt:3570.301\n",
      "Ep:92, loss:0.00002, loss_test:0.01511, lr:9.80e-03, fs:0.78469 (r=0.828,p=0.745),  time:38.787, tt:3607.228\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.01509, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.770, tt:3644.417\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00002, loss_test:0.01507, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.754, tt:3681.621\n",
      "Ep:95, loss:0.00002, loss_test:0.01505, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.754, tt:3720.375\n",
      "Ep:96, loss:0.00002, loss_test:0.01503, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.743, tt:3758.095\n",
      "Ep:97, loss:0.00002, loss_test:0.01501, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.743, tt:3796.782\n",
      "Ep:98, loss:0.00002, loss_test:0.01499, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.739, tt:3835.126\n",
      "Ep:99, loss:0.00002, loss_test:0.01498, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.745, tt:3874.456\n",
      "Ep:100, loss:0.00002, loss_test:0.01496, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.746, tt:3913.368\n",
      "Ep:101, loss:0.00002, loss_test:0.01494, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.726, tt:3950.090\n",
      "Ep:102, loss:0.00002, loss_test:0.01492, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.719, tt:3988.032\n",
      "Ep:103, loss:0.00002, loss_test:0.01490, lr:9.80e-03, fs:0.78846 (r=0.828,p=0.752),  time:38.710, tt:4025.871\n",
      "Ep:104, loss:0.00002, loss_test:0.01489, lr:9.80e-03, fs:0.79227 (r=0.828,p=0.759),  time:38.702, tt:4063.673\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.01488, lr:9.80e-03, fs:0.79227 (r=0.828,p=0.759),  time:38.690, tt:4101.121\n",
      "Ep:106, loss:0.00002, loss_test:0.01486, lr:9.80e-03, fs:0.79227 (r=0.828,p=0.759),  time:38.687, tt:4139.457\n",
      "Ep:107, loss:0.00002, loss_test:0.01485, lr:9.80e-03, fs:0.79227 (r=0.828,p=0.759),  time:38.674, tt:4176.831\n",
      "Ep:108, loss:0.00002, loss_test:0.01483, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.687, tt:4216.840\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00002, loss_test:0.01481, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.681, tt:4254.860\n",
      "Ep:110, loss:0.00002, loss_test:0.01480, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.684, tt:4293.879\n",
      "Ep:111, loss:0.00002, loss_test:0.01479, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.688, tt:4333.041\n",
      "Ep:112, loss:0.00002, loss_test:0.01477, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.687, tt:4371.592\n",
      "Ep:113, loss:0.00002, loss_test:0.01476, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.674, tt:4408.882\n",
      "Ep:114, loss:0.00002, loss_test:0.01475, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.663, tt:4446.221\n",
      "Ep:115, loss:0.00002, loss_test:0.01474, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.659, tt:4484.476\n",
      "Ep:116, loss:0.00002, loss_test:0.01473, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.657, tt:4522.883\n",
      "Ep:117, loss:0.00002, loss_test:0.01473, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.655, tt:4561.308\n",
      "Ep:118, loss:0.00002, loss_test:0.01472, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.659, tt:4600.388\n",
      "Ep:119, loss:0.00002, loss_test:0.01472, lr:9.80e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.673, tt:4640.786\n",
      "Ep:120, loss:0.00002, loss_test:0.01471, lr:9.70e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.671, tt:4679.237\n",
      "Ep:121, loss:0.00002, loss_test:0.01470, lr:9.61e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.690, tt:4720.232\n",
      "Ep:122, loss:0.00002, loss_test:0.01470, lr:9.51e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.722, tt:4762.753\n",
      "Ep:123, loss:0.00002, loss_test:0.01469, lr:9.41e-03, fs:0.79612 (r=0.828,p=0.766),  time:38.731, tt:4802.603\n",
      "Ep:124, loss:0.00002, loss_test:0.01468, lr:9.32e-03, fs:0.80193 (r=0.838,p=0.769),  time:38.734, tt:4841.697\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.01468, lr:9.32e-03, fs:0.80583 (r=0.838,p=0.776),  time:38.728, tt:4879.697\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00002, loss_test:0.01467, lr:9.32e-03, fs:0.80976 (r=0.838,p=0.783),  time:38.722, tt:4917.751\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00002, loss_test:0.01467, lr:9.32e-03, fs:0.80976 (r=0.838,p=0.783),  time:38.705, tt:4954.189\n",
      "Ep:128, loss:0.00002, loss_test:0.01467, lr:9.32e-03, fs:0.80976 (r=0.838,p=0.783),  time:38.708, tt:4993.336\n",
      "Ep:129, loss:0.00002, loss_test:0.01467, lr:9.32e-03, fs:0.80976 (r=0.838,p=0.783),  time:38.711, tt:5032.488\n",
      "Ep:130, loss:0.00002, loss_test:0.01466, lr:9.32e-03, fs:0.80976 (r=0.838,p=0.783),  time:38.720, tt:5072.295\n",
      "Ep:131, loss:0.00002, loss_test:0.01466, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.723, tt:5111.454\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00002, loss_test:0.01465, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.722, tt:5150.077\n",
      "Ep:133, loss:0.00002, loss_test:0.01465, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.718, tt:5188.180\n",
      "Ep:134, loss:0.00002, loss_test:0.01464, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.718, tt:5226.965\n",
      "Ep:135, loss:0.00002, loss_test:0.01463, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.707, tt:5264.124\n",
      "Ep:136, loss:0.00002, loss_test:0.01462, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.699, tt:5301.828\n",
      "Ep:137, loss:0.00002, loss_test:0.01462, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.710, tt:5341.969\n",
      "Ep:138, loss:0.00002, loss_test:0.01461, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.705, tt:5380.008\n",
      "Ep:139, loss:0.00002, loss_test:0.01461, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.712, tt:5419.707\n",
      "Ep:140, loss:0.00002, loss_test:0.01461, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.713, tt:5458.468\n",
      "Ep:141, loss:0.00002, loss_test:0.01461, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.717, tt:5497.777\n",
      "Ep:142, loss:0.00002, loss_test:0.01460, lr:9.32e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.718, tt:5536.709\n",
      "Ep:143, loss:0.00002, loss_test:0.01460, lr:9.23e-03, fs:0.81553 (r=0.848,p=0.785),  time:38.708, tt:5573.976\n",
      "Ep:144, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.711, tt:5613.103\n",
      "##########Best model found so far##########\n",
      "Ep:145, loss:0.00002, loss_test:0.01460, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.712, tt:5651.999\n",
      "Ep:146, loss:0.00002, loss_test:0.01460, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.702, tt:5689.251\n",
      "Ep:147, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.702, tt:5727.837\n",
      "Ep:148, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.699, tt:5766.078\n",
      "Ep:149, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.709, tt:5806.334\n",
      "Ep:150, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.81951 (r=0.848,p=0.792),  time:38.723, tt:5847.138\n",
      "Ep:151, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.736, tt:5887.915\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.743, tt:5927.751\n",
      "Ep:153, loss:0.00002, loss_test:0.01458, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.744, tt:5966.517\n",
      "Ep:154, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.745, tt:6005.525\n",
      "Ep:155, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.736, tt:6042.759\n",
      "Ep:156, loss:0.00002, loss_test:0.01458, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.748, tt:6083.395\n",
      "Ep:157, loss:0.00002, loss_test:0.01458, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.746, tt:6121.875\n",
      "Ep:158, loss:0.00002, loss_test:0.01457, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.762, tt:6163.106\n",
      "Ep:159, loss:0.00002, loss_test:0.01458, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.772, tt:6203.529\n",
      "Ep:160, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.780, tt:6243.597\n",
      "Ep:161, loss:0.00002, loss_test:0.01459, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.787, tt:6283.473\n",
      "Ep:162, loss:0.00002, loss_test:0.01458, lr:9.14e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.783, tt:6321.702\n",
      "Ep:163, loss:0.00002, loss_test:0.01458, lr:9.04e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.785, tt:6360.765\n",
      "Ep:164, loss:0.00002, loss_test:0.01458, lr:8.95e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.789, tt:6400.243\n",
      "Ep:165, loss:0.00002, loss_test:0.01459, lr:8.86e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.803, tt:6441.288\n",
      "Ep:166, loss:0.00002, loss_test:0.01459, lr:8.78e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.800, tt:6479.572\n",
      "Ep:167, loss:0.00002, loss_test:0.01459, lr:8.69e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.799, tt:6518.212\n",
      "Ep:168, loss:0.00002, loss_test:0.01459, lr:8.60e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.807, tt:6558.414\n",
      "Ep:169, loss:0.00002, loss_test:0.01459, lr:8.51e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.815, tt:6598.605\n",
      "Ep:170, loss:0.00002, loss_test:0.01460, lr:8.43e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.807, tt:6635.952\n",
      "Ep:171, loss:0.00002, loss_test:0.01460, lr:8.35e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.813, tt:6675.845\n",
      "Ep:172, loss:0.00002, loss_test:0.01460, lr:8.26e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.814, tt:6714.884\n",
      "Ep:173, loss:0.00002, loss_test:0.01461, lr:8.18e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.823, tt:6755.243\n",
      "Ep:174, loss:0.00002, loss_test:0.01462, lr:8.10e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.831, tt:6795.509\n",
      "Ep:175, loss:0.00002, loss_test:0.01463, lr:8.02e-03, fs:0.82353 (r=0.848,p=0.800),  time:38.842, tt:6836.269\n",
      "Ep:176, loss:0.00002, loss_test:0.01463, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.853, tt:6876.947\n",
      "##########Best model found so far##########\n",
      "Ep:177, loss:0.00002, loss_test:0.01463, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.857, tt:6916.533\n",
      "Ep:178, loss:0.00001, loss_test:0.01463, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.874, tt:6958.532\n",
      "Ep:179, loss:0.00001, loss_test:0.01464, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.880, tt:6998.411\n",
      "Ep:180, loss:0.00001, loss_test:0.01464, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.881, tt:7037.415\n",
      "Ep:181, loss:0.00001, loss_test:0.01465, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.883, tt:7076.722\n",
      "Ep:182, loss:0.00001, loss_test:0.01466, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.891, tt:7117.038\n",
      "Ep:183, loss:0.00001, loss_test:0.01467, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.894, tt:7156.577\n",
      "Ep:184, loss:0.00001, loss_test:0.01466, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.898, tt:7196.215\n",
      "Ep:185, loss:0.00001, loss_test:0.01467, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.897, tt:7234.782\n",
      "Ep:186, loss:0.00001, loss_test:0.01467, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.895, tt:7273.285\n",
      "Ep:187, loss:0.00001, loss_test:0.01467, lr:7.94e-03, fs:0.82759 (r=0.848,p=0.808),  time:38.892, tt:7311.684\n",
      "Ep:188, loss:0.00001, loss_test:0.01468, lr:7.86e-03, fs:0.83168 (r=0.848,p=0.816),  time:38.907, tt:7353.515\n",
      "##########Best model found so far##########\n",
      "Ep:189, loss:0.00001, loss_test:0.01467, lr:7.86e-03, fs:0.83168 (r=0.848,p=0.816),  time:38.912, tt:7393.343\n",
      "Ep:190, loss:0.00001, loss_test:0.01467, lr:7.86e-03, fs:0.83582 (r=0.848,p=0.824),  time:38.916, tt:7432.889\n",
      "##########Best model found so far##########\n",
      "Ep:191, loss:0.00001, loss_test:0.01468, lr:7.86e-03, fs:0.83582 (r=0.848,p=0.824),  time:38.925, tt:7473.586\n",
      "Ep:192, loss:0.00001, loss_test:0.01469, lr:7.86e-03, fs:0.83582 (r=0.848,p=0.824),  time:38.918, tt:7511.181\n",
      "Ep:193, loss:0.00001, loss_test:0.01469, lr:7.86e-03, fs:0.84000 (r=0.848,p=0.832),  time:38.916, tt:7549.771\n",
      "##########Best model found so far##########\n",
      "Ep:194, loss:0.00001, loss_test:0.01470, lr:7.86e-03, fs:0.84000 (r=0.848,p=0.832),  time:38.913, tt:7588.070\n",
      "Ep:195, loss:0.00001, loss_test:0.01471, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.925, tt:7629.382\n",
      "##########Best model found so far##########\n",
      "Ep:196, loss:0.00001, loss_test:0.01471, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.939, tt:7671.008\n",
      "Ep:197, loss:0.00001, loss_test:0.01471, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.947, tt:7711.557\n",
      "Ep:198, loss:0.00001, loss_test:0.01472, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.958, tt:7752.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00001, loss_test:0.01473, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.964, tt:7792.723\n",
      "Ep:200, loss:0.00001, loss_test:0.01473, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.963, tt:7831.473\n",
      "Ep:201, loss:0.00001, loss_test:0.01473, lr:7.86e-03, fs:0.84422 (r=0.848,p=0.840),  time:38.964, tt:7870.784\n",
      "Ep:202, loss:0.00001, loss_test:0.01474, lr:7.86e-03, fs:0.84848 (r=0.848,p=0.848),  time:38.964, tt:7909.639\n",
      "##########Best model found so far##########\n",
      "Ep:203, loss:0.00001, loss_test:0.01475, lr:7.86e-03, fs:0.84848 (r=0.848,p=0.848),  time:38.965, tt:7948.866\n",
      "Ep:204, loss:0.00001, loss_test:0.01475, lr:7.86e-03, fs:0.84848 (r=0.848,p=0.848),  time:38.959, tt:7986.630\n",
      "Ep:205, loss:0.00001, loss_test:0.01475, lr:7.86e-03, fs:0.84848 (r=0.848,p=0.848),  time:38.961, tt:8025.948\n",
      "Ep:206, loss:0.00001, loss_test:0.01476, lr:7.86e-03, fs:0.84848 (r=0.848,p=0.848),  time:38.950, tt:8062.727\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13579, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:28.576, tt:28.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13239, lr:1.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:30.733, tt:61.466\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12781, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:31.111, tt:93.332\n",
      "Ep:3, loss:0.00025, loss_test:0.12340, lr:1.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:31.508, tt:126.031\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12041, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:32.702, tt:163.509\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11945, lr:1.00e-02, fs:0.68085 (r=0.808,p=0.588),  time:33.713, tt:202.276\n",
      "Ep:6, loss:0.00024, loss_test:0.11936, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:34.230, tt:239.613\n",
      "Ep:7, loss:0.00023, loss_test:0.11818, lr:1.00e-02, fs:0.64655 (r=0.758,p=0.564),  time:34.729, tt:277.836\n",
      "Ep:8, loss:0.00022, loss_test:0.11689, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:35.105, tt:315.943\n",
      "Ep:9, loss:0.00022, loss_test:0.11490, lr:1.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:35.783, tt:357.830\n",
      "Ep:10, loss:0.00021, loss_test:0.11357, lr:1.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:35.858, tt:394.442\n",
      "Ep:11, loss:0.00020, loss_test:0.11282, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:35.882, tt:430.579\n",
      "Ep:12, loss:0.00020, loss_test:0.11133, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:36.003, tt:468.038\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.10899, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:36.079, tt:505.100\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10756, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:36.048, tt:540.726\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.10625, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:36.071, tt:577.135\n",
      "Ep:16, loss:0.00017, loss_test:0.10494, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:36.085, tt:613.446\n",
      "Ep:17, loss:0.00017, loss_test:0.10348, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:36.144, tt:650.589\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.10210, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:36.228, tt:688.326\n",
      "Ep:19, loss:0.00016, loss_test:0.10070, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:36.230, tt:724.610\n",
      "Ep:20, loss:0.00015, loss_test:0.09939, lr:1.00e-02, fs:0.73171 (r=0.758,p=0.708),  time:36.219, tt:760.606\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.09863, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:36.219, tt:796.819\n",
      "Ep:22, loss:0.00015, loss_test:0.09713, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:36.257, tt:833.910\n",
      "Ep:23, loss:0.00014, loss_test:0.09611, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:36.312, tt:871.497\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09606, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:36.232, tt:905.790\n",
      "Ep:25, loss:0.00013, loss_test:0.09425, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:36.229, tt:941.961\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09333, lr:1.00e-02, fs:0.75377 (r=0.758,p=0.750),  time:36.253, tt:978.822\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09263, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:36.225, tt:1014.294\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.09100, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:36.196, tt:1049.674\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.09001, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:36.198, tt:1085.946\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08951, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:36.234, tt:1123.259\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08898, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:36.269, tt:1160.601\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.08743, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.323, tt:1198.659\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08687, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:36.319, tt:1234.860\n",
      "Ep:34, loss:0.00010, loss_test:0.08628, lr:1.00e-02, fs:0.81633 (r=0.808,p=0.825),  time:36.339, tt:1271.870\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08479, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:36.387, tt:1309.934\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08613, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:36.338, tt:1344.493\n",
      "Ep:37, loss:0.00009, loss_test:0.08413, lr:1.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:36.355, tt:1381.487\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.08511, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:36.333, tt:1416.984\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.08389, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:36.343, tt:1453.708\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.08127, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:36.334, tt:1489.677\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08329, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:36.367, tt:1527.417\n",
      "Ep:42, loss:0.00008, loss_test:0.08276, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:36.369, tt:1563.888\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.08512, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.393, tt:1601.276\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00008, loss_test:0.08091, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:36.399, tt:1637.947\n",
      "Ep:45, loss:0.00008, loss_test:0.08151, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.396, tt:1674.211\n",
      "Ep:46, loss:0.00007, loss_test:0.08247, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:36.419, tt:1711.689\n",
      "Ep:47, loss:0.00007, loss_test:0.07946, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:36.440, tt:1749.096\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08248, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:36.448, tt:1785.960\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.08055, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.436, tt:1821.780\n",
      "Ep:50, loss:0.00006, loss_test:0.07980, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:36.425, tt:1857.663\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00006, loss_test:0.08076, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.411, tt:1893.398\n",
      "Ep:52, loss:0.00006, loss_test:0.07913, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.405, tt:1929.452\n",
      "Ep:53, loss:0.00006, loss_test:0.08090, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:36.361, tt:1963.508\n",
      "Ep:54, loss:0.00006, loss_test:0.08075, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.334, tt:1998.371\n",
      "Ep:55, loss:0.00006, loss_test:0.08004, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.356, tt:2035.955\n",
      "Ep:56, loss:0.00005, loss_test:0.07914, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.349, tt:2071.874\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.08042, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.342, tt:2107.858\n",
      "Ep:58, loss:0.00005, loss_test:0.07964, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.328, tt:2143.369\n",
      "Ep:59, loss:0.00005, loss_test:0.08040, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.301, tt:2178.070\n",
      "Ep:60, loss:0.00005, loss_test:0.07898, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.297, tt:2214.105\n",
      "Ep:61, loss:0.00005, loss_test:0.08282, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.307, tt:2251.043\n",
      "Ep:62, loss:0.00005, loss_test:0.08108, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.307, tt:2287.325\n",
      "Ep:63, loss:0.00005, loss_test:0.08085, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.304, tt:2323.462\n",
      "Ep:64, loss:0.00005, loss_test:0.08598, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:36.304, tt:2359.789\n",
      "Ep:65, loss:0.00005, loss_test:0.08080, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.305, tt:2396.125\n",
      "Ep:66, loss:0.00005, loss_test:0.08174, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.320, tt:2433.443\n",
      "Ep:67, loss:0.00005, loss_test:0.08460, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:36.312, tt:2469.203\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.08169, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.311, tt:2505.433\n",
      "Ep:69, loss:0.00004, loss_test:0.08376, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.316, tt:2542.121\n",
      "Ep:70, loss:0.00004, loss_test:0.08654, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:36.321, tt:2578.760\n",
      "Ep:71, loss:0.00005, loss_test:0.08461, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:36.355, tt:2617.532\n",
      "Ep:72, loss:0.00004, loss_test:0.08489, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.359, tt:2654.189\n",
      "Ep:73, loss:0.00004, loss_test:0.08567, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:36.364, tt:2690.964\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00004, loss_test:0.08310, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:36.383, tt:2728.754\n",
      "Ep:75, loss:0.00004, loss_test:0.08500, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:36.429, tt:2768.613\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.08325, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:36.446, tt:2806.314\n",
      "Ep:77, loss:0.00004, loss_test:0.08516, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:36.471, tt:2844.749\n",
      "Ep:78, loss:0.00004, loss_test:0.08782, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:36.500, tt:2883.521\n",
      "Ep:79, loss:0.00003, loss_test:0.08291, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:36.524, tt:2921.888\n",
      "Ep:80, loss:0.00003, loss_test:0.08611, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:36.556, tt:2961.020\n",
      "Ep:81, loss:0.00003, loss_test:0.08607, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:36.587, tt:3000.159\n",
      "Ep:82, loss:0.00003, loss_test:0.08287, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:36.606, tt:3038.258\n",
      "Ep:83, loss:0.00003, loss_test:0.08940, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:36.634, tt:3077.257\n",
      "Ep:84, loss:0.00003, loss_test:0.08536, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:36.666, tt:3116.604\n",
      "Ep:85, loss:0.00003, loss_test:0.08684, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:36.668, tt:3153.420\n",
      "Ep:86, loss:0.00003, loss_test:0.08603, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:36.694, tt:3192.340\n",
      "Ep:87, loss:0.00003, loss_test:0.08540, lr:9.90e-03, fs:0.87047 (r=0.848,p=0.894),  time:36.703, tt:3229.866\n",
      "Ep:88, loss:0.00003, loss_test:0.08770, lr:9.80e-03, fs:0.87097 (r=0.818,p=0.931),  time:36.694, tt:3265.738\n",
      "Ep:89, loss:0.00003, loss_test:0.08578, lr:9.70e-03, fs:0.85263 (r=0.818,p=0.890),  time:36.713, tt:3304.128\n",
      "Ep:90, loss:0.00003, loss_test:0.08711, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:36.733, tt:3342.666\n",
      "Ep:91, loss:0.00003, loss_test:0.08739, lr:9.51e-03, fs:0.85714 (r=0.818,p=0.900),  time:36.746, tt:3380.605\n",
      "Ep:92, loss:0.00003, loss_test:0.08638, lr:9.41e-03, fs:0.85263 (r=0.818,p=0.890),  time:36.755, tt:3418.241\n",
      "Ep:93, loss:0.00002, loss_test:0.08657, lr:9.32e-03, fs:0.87368 (r=0.838,p=0.912),  time:36.773, tt:3456.623\n",
      "Ep:94, loss:0.00002, loss_test:0.08723, lr:9.23e-03, fs:0.86170 (r=0.818,p=0.910),  time:36.796, tt:3495.574\n",
      "Ep:95, loss:0.00003, loss_test:0.08619, lr:9.14e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.808, tt:3533.582\n",
      "Ep:96, loss:0.00002, loss_test:0.08728, lr:9.04e-03, fs:0.84783 (r=0.788,p=0.918),  time:36.823, tt:3571.798\n",
      "Ep:97, loss:0.00003, loss_test:0.08819, lr:8.95e-03, fs:0.87958 (r=0.848,p=0.913),  time:36.828, tt:3609.167\n",
      "Ep:98, loss:0.00002, loss_test:0.08542, lr:8.86e-03, fs:0.86486 (r=0.808,p=0.930),  time:36.829, tt:3646.054\n",
      "Ep:99, loss:0.00002, loss_test:0.08782, lr:8.78e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.842, tt:3684.197\n",
      "Ep:100, loss:0.00003, loss_test:0.08539, lr:8.69e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.859, tt:3722.772\n",
      "Ep:101, loss:0.00002, loss_test:0.08492, lr:8.60e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.864, tt:3760.113\n",
      "Ep:102, loss:0.00002, loss_test:0.08646, lr:8.51e-03, fs:0.84492 (r=0.798,p=0.898),  time:36.863, tt:3796.900\n",
      "Ep:103, loss:0.00002, loss_test:0.08503, lr:8.43e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.864, tt:3833.880\n",
      "Ep:104, loss:0.00002, loss_test:0.08415, lr:8.35e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.892, tt:3873.639\n",
      "Ep:105, loss:0.00002, loss_test:0.08577, lr:8.26e-03, fs:0.85870 (r=0.798,p=0.929),  time:36.885, tt:3909.800\n",
      "Ep:106, loss:0.00002, loss_test:0.08528, lr:8.18e-03, fs:0.85714 (r=0.818,p=0.900),  time:36.899, tt:3948.231\n",
      "Ep:107, loss:0.00002, loss_test:0.08438, lr:8.10e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.909, tt:3986.219\n",
      "Ep:108, loss:0.00002, loss_test:0.08502, lr:8.02e-03, fs:0.84324 (r=0.788,p=0.907),  time:36.918, tt:4024.086\n",
      "Ep:109, loss:0.00002, loss_test:0.08365, lr:7.94e-03, fs:0.87500 (r=0.848,p=0.903),  time:36.923, tt:4061.569\n",
      "Ep:110, loss:0.00002, loss_test:0.08462, lr:7.86e-03, fs:0.85714 (r=0.818,p=0.900),  time:36.942, tt:4100.525\n",
      "Ep:111, loss:0.00002, loss_test:0.08420, lr:7.78e-03, fs:0.86022 (r=0.808,p=0.920),  time:36.958, tt:4139.289\n",
      "Ep:112, loss:0.00002, loss_test:0.08498, lr:7.70e-03, fs:0.84492 (r=0.798,p=0.898),  time:36.960, tt:4176.507\n",
      "Ep:113, loss:0.00002, loss_test:0.08418, lr:7.62e-03, fs:0.88421 (r=0.848,p=0.923),  time:36.968, tt:4214.338\n",
      "Ep:114, loss:0.00002, loss_test:0.08430, lr:7.55e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.000, tt:4254.986\n",
      "Ep:115, loss:0.00002, loss_test:0.08440, lr:7.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.016, tt:4293.842\n",
      "Ep:116, loss:0.00002, loss_test:0.08488, lr:7.40e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.019, tt:4331.257\n",
      "Ep:117, loss:0.00002, loss_test:0.08453, lr:7.32e-03, fs:0.86339 (r=0.798,p=0.940),  time:37.031, tt:4369.608\n",
      "Ep:118, loss:0.00002, loss_test:0.08423, lr:7.25e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.038, tt:4407.571\n",
      "Ep:119, loss:0.00002, loss_test:0.08340, lr:7.18e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.048, tt:4445.783\n",
      "Ep:120, loss:0.00002, loss_test:0.08571, lr:7.11e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.066, tt:4485.038\n",
      "Ep:121, loss:0.00002, loss_test:0.08445, lr:7.03e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.074, tt:4522.980\n",
      "Ep:122, loss:0.00002, loss_test:0.08262, lr:6.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.079, tt:4560.724\n",
      "Ep:123, loss:0.00002, loss_test:0.08388, lr:6.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.087, tt:4598.844\n",
      "Ep:124, loss:0.00002, loss_test:0.08349, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.104, tt:4638.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00002, loss_test:0.08354, lr:6.76e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.112, tt:4676.102\n",
      "Ep:126, loss:0.00001, loss_test:0.08360, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.114, tt:4713.482\n",
      "Ep:127, loss:0.00001, loss_test:0.08331, lr:6.62e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.111, tt:4750.189\n",
      "Ep:128, loss:0.00001, loss_test:0.08409, lr:6.56e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.109, tt:4787.012\n",
      "Ep:129, loss:0.00001, loss_test:0.08322, lr:6.49e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.114, tt:4824.764\n",
      "Ep:130, loss:0.00001, loss_test:0.08305, lr:6.43e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.115, tt:4862.066\n",
      "Ep:131, loss:0.00001, loss_test:0.08417, lr:6.36e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.110, tt:4898.557\n",
      "Ep:132, loss:0.00001, loss_test:0.08392, lr:6.30e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.091, tt:4933.145\n",
      "Ep:133, loss:0.00001, loss_test:0.08322, lr:6.24e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.092, tt:4970.354\n",
      "Ep:134, loss:0.00001, loss_test:0.08413, lr:6.17e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.091, tt:5007.245\n",
      "Ep:135, loss:0.00001, loss_test:0.08370, lr:6.11e-03, fs:0.83243 (r=0.778,p=0.895),  time:37.092, tt:5044.508\n",
      "Ep:136, loss:0.00001, loss_test:0.08323, lr:6.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.073, tt:5079.058\n",
      "Ep:137, loss:0.00001, loss_test:0.08325, lr:5.99e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.068, tt:5115.450\n",
      "Ep:138, loss:0.00001, loss_test:0.08423, lr:5.93e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.057, tt:5150.992\n",
      "Ep:139, loss:0.00001, loss_test:0.08376, lr:5.87e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.033, tt:5184.577\n",
      "Ep:140, loss:0.00001, loss_test:0.08300, lr:5.81e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.027, tt:5220.857\n",
      "Ep:141, loss:0.00001, loss_test:0.08383, lr:5.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.030, tt:5258.315\n",
      "Ep:142, loss:0.00001, loss_test:0.08349, lr:5.70e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.024, tt:5294.407\n",
      "Ep:143, loss:0.00001, loss_test:0.08367, lr:5.64e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.007, tt:5329.062\n",
      "Ep:144, loss:0.00001, loss_test:0.08355, lr:5.58e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.997, tt:5364.621\n",
      "Ep:145, loss:0.00001, loss_test:0.08364, lr:5.53e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.990, tt:5400.572\n",
      "Ep:146, loss:0.00001, loss_test:0.08401, lr:5.47e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.983, tt:5436.544\n",
      "Ep:147, loss:0.00001, loss_test:0.08325, lr:5.42e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.972, tt:5471.785\n",
      "Ep:148, loss:0.00001, loss_test:0.08370, lr:5.36e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.955, tt:5506.250\n",
      "Ep:149, loss:0.00001, loss_test:0.08401, lr:5.31e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.945, tt:5541.701\n",
      "Ep:150, loss:0.00001, loss_test:0.08333, lr:5.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.925, tt:5575.676\n",
      "Ep:151, loss:0.00001, loss_test:0.08348, lr:5.20e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.916, tt:5611.276\n",
      "Ep:152, loss:0.00001, loss_test:0.08355, lr:5.15e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.920, tt:5648.692\n",
      "Ep:153, loss:0.00001, loss_test:0.08380, lr:5.10e-03, fs:0.84153 (r=0.778,p=0.917),  time:36.912, tt:5684.481\n",
      "Ep:154, loss:0.00001, loss_test:0.08338, lr:5.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.894, tt:5718.524\n",
      "Ep:155, loss:0.00001, loss_test:0.08374, lr:5.00e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.902, tt:5756.651\n",
      "Ep:156, loss:0.00001, loss_test:0.08360, lr:4.95e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.916, tt:5795.794\n",
      "Ep:157, loss:0.00001, loss_test:0.08326, lr:4.90e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.916, tt:5832.719\n",
      "Ep:158, loss:0.00001, loss_test:0.08356, lr:4.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.916, tt:5869.664\n",
      "Ep:159, loss:0.00001, loss_test:0.08296, lr:4.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.927, tt:5908.399\n",
      "Ep:160, loss:0.00001, loss_test:0.08362, lr:4.75e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.940, tt:5947.323\n",
      "Ep:161, loss:0.00001, loss_test:0.08370, lr:4.71e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.937, tt:5983.741\n",
      "Ep:162, loss:0.00001, loss_test:0.08313, lr:4.66e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.931, tt:6019.693\n",
      "Ep:163, loss:0.00001, loss_test:0.08306, lr:4.61e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.933, tt:6057.064\n",
      "Ep:164, loss:0.00001, loss_test:0.08342, lr:4.57e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.931, tt:6093.628\n",
      "Ep:165, loss:0.00001, loss_test:0.08326, lr:4.52e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.926, tt:6129.740\n",
      "Ep:166, loss:0.00001, loss_test:0.08325, lr:4.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.926, tt:6166.671\n",
      "Ep:167, loss:0.00001, loss_test:0.08335, lr:4.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.920, tt:6202.565\n",
      "Ep:168, loss:0.00001, loss_test:0.08347, lr:4.39e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.920, tt:6239.445\n",
      "Ep:169, loss:0.00001, loss_test:0.08356, lr:4.34e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.921, tt:6276.581\n",
      "Ep:170, loss:0.00001, loss_test:0.08312, lr:4.30e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.925, tt:6314.108\n",
      "Ep:171, loss:0.00001, loss_test:0.08334, lr:4.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.926, tt:6351.267\n",
      "Ep:172, loss:0.00001, loss_test:0.08416, lr:4.21e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.930, tt:6388.902\n",
      "Ep:173, loss:0.00001, loss_test:0.08352, lr:4.17e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.928, tt:6425.390\n",
      "Ep:174, loss:0.00001, loss_test:0.08401, lr:4.13e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.930, tt:6462.797\n",
      "Ep:175, loss:0.00001, loss_test:0.08370, lr:4.09e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.935, tt:6500.528\n",
      "Ep:176, loss:0.00001, loss_test:0.08338, lr:4.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.939, tt:6538.247\n",
      "Ep:177, loss:0.00001, loss_test:0.08399, lr:4.01e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.941, tt:6575.455\n",
      "Ep:178, loss:0.00001, loss_test:0.08349, lr:3.97e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.946, tt:6613.380\n",
      "Ep:179, loss:0.00001, loss_test:0.08422, lr:3.93e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.968, tt:6654.313\n",
      "Ep:180, loss:0.00001, loss_test:0.08392, lr:3.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.971, tt:6691.828\n",
      "Ep:181, loss:0.00001, loss_test:0.08305, lr:3.85e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.961, tt:6726.864\n",
      "Ep:182, loss:0.00001, loss_test:0.08394, lr:3.81e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.971, tt:6765.659\n",
      "Ep:183, loss:0.00001, loss_test:0.08381, lr:3.77e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.975, tt:6803.453\n",
      "Ep:184, loss:0.00001, loss_test:0.08397, lr:3.73e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.985, tt:6842.253\n",
      "Ep:185, loss:0.00001, loss_test:0.08420, lr:3.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.994, tt:6880.840\n",
      "Ep:186, loss:0.00001, loss_test:0.08334, lr:3.66e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.995, tt:6918.022\n",
      "Ep:187, loss:0.00001, loss_test:0.08356, lr:3.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.995, tt:6955.145\n",
      "Ep:188, loss:0.00001, loss_test:0.08387, lr:3.59e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.992, tt:6991.480\n",
      "Ep:189, loss:0.00001, loss_test:0.08374, lr:3.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.993, tt:7028.664\n",
      "Ep:190, loss:0.00001, loss_test:0.08399, lr:3.52e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.993, tt:7065.600\n",
      "Ep:191, loss:0.00001, loss_test:0.08366, lr:3.48e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.998, tt:7103.603\n",
      "Ep:192, loss:0.00001, loss_test:0.08403, lr:3.45e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.000, tt:7141.054\n",
      "Ep:193, loss:0.00001, loss_test:0.08418, lr:3.41e-03, fs:0.85083 (r=0.778,p=0.939),  time:36.998, tt:7177.581\n",
      "Ep:194, loss:0.00001, loss_test:0.08358, lr:3.38e-03, fs:0.84615 (r=0.778,p=0.928),  time:36.998, tt:7214.628\n",
      "Ep:195, loss:0.00001, loss_test:0.08416, lr:3.34e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.005, tt:7253.049\n",
      "Ep:196, loss:0.00001, loss_test:0.08382, lr:3.31e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.009, tt:7290.792\n",
      "Ep:197, loss:0.00001, loss_test:0.08353, lr:3.28e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.022, tt:7330.382\n",
      "Ep:198, loss:0.00001, loss_test:0.08374, lr:3.24e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.032, tt:7369.290\n",
      "Ep:199, loss:0.00001, loss_test:0.08401, lr:3.21e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.035, tt:7407.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00001, loss_test:0.08394, lr:3.18e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.039, tt:7444.785\n",
      "Ep:201, loss:0.00001, loss_test:0.08363, lr:3.15e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.050, tt:7484.016\n",
      "Ep:202, loss:0.00001, loss_test:0.08346, lr:3.12e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.063, tt:7523.694\n",
      "Ep:203, loss:0.00001, loss_test:0.08399, lr:3.09e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.073, tt:7562.829\n",
      "Ep:204, loss:0.00001, loss_test:0.08406, lr:3.05e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.082, tt:7601.801\n",
      "Ep:205, loss:0.00001, loss_test:0.08379, lr:3.02e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.081, tt:7638.592\n",
      "Ep:206, loss:0.00001, loss_test:0.08372, lr:2.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.089, tt:7677.432\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14191, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.047, tt:37.047\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14071, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.668, tt:73.336\n",
      "Ep:2, loss:0.00028, loss_test:0.13860, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.625, tt:106.875\n",
      "Ep:3, loss:0.00027, loss_test:0.13519, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:36.142, tt:144.569\n",
      "Ep:4, loss:0.00027, loss_test:0.12966, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:37.002, tt:185.008\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12171, lr:1.00e-02, fs:0.66160 (r=0.879,p=0.530),  time:36.963, tt:221.781\n",
      "Ep:6, loss:0.00024, loss_test:0.11465, lr:1.00e-02, fs:0.68966 (r=0.808,p=0.602),  time:37.067, tt:259.469\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11348, lr:1.00e-02, fs:0.66667 (r=0.687,p=0.648),  time:37.058, tt:296.468\n",
      "Ep:8, loss:0.00022, loss_test:0.11004, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:37.233, tt:335.093\n",
      "Ep:9, loss:0.00021, loss_test:0.11092, lr:1.00e-02, fs:0.66379 (r=0.778,p=0.579),  time:37.210, tt:372.104\n",
      "Ep:10, loss:0.00021, loss_test:0.10664, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:37.295, tt:410.247\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10575, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:37.332, tt:447.986\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10432, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:37.310, tt:485.030\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10328, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:37.388, tt:523.434\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.10120, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:37.444, tt:561.667\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09874, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:37.474, tt:599.586\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09760, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:37.322, tt:634.482\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09690, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:37.410, tt:673.383\n",
      "Ep:18, loss:0.00015, loss_test:0.09569, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:37.380, tt:710.222\n",
      "Ep:19, loss:0.00014, loss_test:0.09434, lr:1.00e-02, fs:0.75248 (r=0.768,p=0.738),  time:37.415, tt:748.296\n",
      "Ep:20, loss:0.00014, loss_test:0.09396, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:37.461, tt:786.681\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09199, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:37.545, tt:825.981\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09078, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:37.627, tt:865.424\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09099, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:37.647, tt:903.536\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.08941, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:37.631, tt:940.770\n",
      "Ep:25, loss:0.00012, loss_test:0.08886, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:37.692, tt:979.982\n",
      "Ep:26, loss:0.00011, loss_test:0.08914, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:37.712, tt:1018.224\n",
      "Ep:27, loss:0.00011, loss_test:0.08707, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:37.762, tt:1057.329\n",
      "Ep:28, loss:0.00011, loss_test:0.08662, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:37.769, tt:1095.311\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08622, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:37.777, tt:1133.324\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.08499, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:37.861, tt:1173.698\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.08626, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:37.899, tt:1212.761\n",
      "Ep:32, loss:0.00009, loss_test:0.08370, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:37.941, tt:1252.053\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.08485, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:37.982, tt:1291.401\n",
      "Ep:34, loss:0.00009, loss_test:0.08296, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:38.022, tt:1330.768\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.08327, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:38.024, tt:1368.873\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.08450, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:38.019, tt:1406.710\n",
      "Ep:37, loss:0.00008, loss_test:0.08181, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:38.025, tt:1444.940\n",
      "Ep:38, loss:0.00007, loss_test:0.08336, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:38.005, tt:1482.179\n",
      "Ep:39, loss:0.00007, loss_test:0.08152, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:37.984, tt:1519.371\n",
      "Ep:40, loss:0.00007, loss_test:0.08425, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:38.039, tt:1559.582\n",
      "Ep:41, loss:0.00007, loss_test:0.08094, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:38.011, tt:1596.465\n",
      "Ep:42, loss:0.00007, loss_test:0.08183, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:38.021, tt:1634.904\n",
      "Ep:43, loss:0.00006, loss_test:0.08028, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:38.091, tt:1676.014\n",
      "Ep:44, loss:0.00006, loss_test:0.08108, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:38.050, tt:1712.229\n",
      "Ep:45, loss:0.00006, loss_test:0.08298, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.001, tt:1748.055\n",
      "Ep:46, loss:0.00006, loss_test:0.07881, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:37.994, tt:1785.711\n",
      "Ep:47, loss:0.00006, loss_test:0.08894, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:38.003, tt:1824.162\n",
      "Ep:48, loss:0.00006, loss_test:0.07516, lr:9.80e-03, fs:0.83422 (r=0.788,p=0.886),  time:38.088, tt:1866.317\n",
      "Ep:49, loss:0.00006, loss_test:0.08643, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:38.056, tt:1902.781\n",
      "Ep:50, loss:0.00005, loss_test:0.08172, lr:9.61e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.998, tt:1937.887\n",
      "Ep:51, loss:0.00005, loss_test:0.07697, lr:9.51e-03, fs:0.82353 (r=0.778,p=0.875),  time:38.004, tt:1976.211\n",
      "Ep:52, loss:0.00005, loss_test:0.08465, lr:9.41e-03, fs:0.83978 (r=0.768,p=0.927),  time:38.002, tt:2014.082\n",
      "Ep:53, loss:0.00005, loss_test:0.07856, lr:9.32e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.967, tt:2050.233\n",
      "Ep:54, loss:0.00005, loss_test:0.07788, lr:9.23e-03, fs:0.83696 (r=0.778,p=0.906),  time:37.973, tt:2088.503\n",
      "Ep:55, loss:0.00005, loss_test:0.08420, lr:9.14e-03, fs:0.83516 (r=0.768,p=0.916),  time:37.979, tt:2126.798\n",
      "Ep:56, loss:0.00004, loss_test:0.07923, lr:9.04e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.981, tt:2164.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00004, loss_test:0.08035, lr:8.95e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.977, tt:2202.688\n",
      "Ep:58, loss:0.00004, loss_test:0.08062, lr:8.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.944, tt:2238.675\n",
      "Ep:59, loss:0.00004, loss_test:0.08074, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.936, tt:2276.142\n",
      "Ep:60, loss:0.00004, loss_test:0.08213, lr:8.69e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.919, tt:2313.037\n",
      "Ep:61, loss:0.00004, loss_test:0.08031, lr:8.60e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.934, tt:2351.929\n",
      "Ep:62, loss:0.00004, loss_test:0.08190, lr:8.51e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.922, tt:2389.060\n",
      "Ep:63, loss:0.00004, loss_test:0.08077, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.902, tt:2425.711\n",
      "Ep:64, loss:0.00004, loss_test:0.08407, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.889, tt:2462.760\n",
      "Ep:65, loss:0.00004, loss_test:0.08276, lr:8.26e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.869, tt:2499.333\n",
      "Ep:66, loss:0.00003, loss_test:0.08067, lr:8.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.851, tt:2535.992\n",
      "Ep:67, loss:0.00003, loss_test:0.08440, lr:8.10e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.855, tt:2574.154\n",
      "Ep:68, loss:0.00003, loss_test:0.08041, lr:8.02e-03, fs:0.84153 (r=0.778,p=0.917),  time:37.813, tt:2609.065\n",
      "Ep:69, loss:0.00003, loss_test:0.08323, lr:7.94e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.804, tt:2646.292\n",
      "Ep:70, loss:0.00003, loss_test:0.08274, lr:7.86e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.760, tt:2680.927\n",
      "Ep:71, loss:0.00003, loss_test:0.08088, lr:7.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.749, tt:2717.952\n",
      "Ep:72, loss:0.00003, loss_test:0.08247, lr:7.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.754, tt:2756.064\n",
      "Ep:73, loss:0.00003, loss_test:0.08449, lr:7.62e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.755, tt:2793.860\n",
      "Ep:74, loss:0.00003, loss_test:0.07950, lr:7.55e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.768, tt:2832.622\n",
      "Ep:75, loss:0.00003, loss_test:0.08452, lr:7.47e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.754, tt:2869.312\n",
      "Ep:76, loss:0.00003, loss_test:0.08353, lr:7.40e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.720, tt:2904.464\n",
      "Ep:77, loss:0.00003, loss_test:0.08057, lr:7.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.731, tt:2943.024\n",
      "Ep:78, loss:0.00002, loss_test:0.08465, lr:7.25e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.744, tt:2981.775\n",
      "Ep:79, loss:0.00002, loss_test:0.07986, lr:7.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.753, tt:3020.250\n",
      "Ep:80, loss:0.00002, loss_test:0.08500, lr:7.11e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.765, tt:3058.941\n",
      "Ep:81, loss:0.00002, loss_test:0.08513, lr:7.03e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.749, tt:3095.415\n",
      "Ep:82, loss:0.00002, loss_test:0.08109, lr:6.96e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.731, tt:3131.650\n",
      "Ep:83, loss:0.00002, loss_test:0.08365, lr:6.89e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.739, tt:3170.044\n",
      "Ep:84, loss:0.00002, loss_test:0.08263, lr:6.83e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.714, tt:3205.721\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.08299, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.689, tt:3241.276\n",
      "Ep:86, loss:0.00002, loss_test:0.08162, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.668, tt:3277.087\n",
      "Ep:87, loss:0.00002, loss_test:0.08526, lr:6.83e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.672, tt:3315.117\n",
      "Ep:88, loss:0.00002, loss_test:0.08221, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.676, tt:3353.138\n",
      "Ep:89, loss:0.00002, loss_test:0.08151, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.675, tt:3390.775\n",
      "Ep:90, loss:0.00002, loss_test:0.08412, lr:6.83e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.676, tt:3428.488\n",
      "Ep:91, loss:0.00002, loss_test:0.08127, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.671, tt:3465.776\n",
      "Ep:92, loss:0.00002, loss_test:0.08487, lr:6.83e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.649, tt:3501.394\n",
      "Ep:93, loss:0.00002, loss_test:0.08372, lr:6.83e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.639, tt:3538.053\n",
      "Ep:94, loss:0.00002, loss_test:0.08220, lr:6.83e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.656, tt:3577.282\n",
      "Ep:95, loss:0.00002, loss_test:0.08521, lr:6.83e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.639, tt:3613.346\n",
      "Ep:96, loss:0.00002, loss_test:0.08264, lr:6.76e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.648, tt:3651.902\n",
      "Ep:97, loss:0.00002, loss_test:0.08323, lr:6.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.644, tt:3689.070\n",
      "Ep:98, loss:0.00002, loss_test:0.08432, lr:6.62e-03, fs:0.84916 (r=0.768,p=0.950),  time:37.612, tt:3723.563\n",
      "Ep:99, loss:0.00002, loss_test:0.08304, lr:6.56e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.618, tt:3761.773\n",
      "Ep:100, loss:0.00002, loss_test:0.08298, lr:6.49e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.610, tt:3798.592\n",
      "Ep:101, loss:0.00001, loss_test:0.08370, lr:6.43e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.610, tt:3836.176\n",
      "Ep:102, loss:0.00001, loss_test:0.08255, lr:6.36e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.594, tt:3872.181\n",
      "Ep:103, loss:0.00001, loss_test:0.08372, lr:6.30e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.597, tt:3910.039\n",
      "Ep:104, loss:0.00001, loss_test:0.08302, lr:6.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.587, tt:3946.594\n",
      "Ep:105, loss:0.00001, loss_test:0.08213, lr:6.17e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.573, tt:3982.754\n",
      "Ep:106, loss:0.00001, loss_test:0.08404, lr:6.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.571, tt:4020.077\n",
      "Ep:107, loss:0.00001, loss_test:0.08356, lr:6.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.567, tt:4057.215\n",
      "Ep:108, loss:0.00001, loss_test:0.08191, lr:5.99e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.574, tt:4095.538\n",
      "Ep:109, loss:0.00001, loss_test:0.08430, lr:5.93e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.576, tt:4133.355\n",
      "Ep:110, loss:0.00001, loss_test:0.08218, lr:5.87e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.561, tt:4169.285\n",
      "Ep:111, loss:0.00001, loss_test:0.08426, lr:5.81e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.562, tt:4206.951\n",
      "Ep:112, loss:0.00001, loss_test:0.08436, lr:5.75e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.557, tt:4243.956\n",
      "Ep:113, loss:0.00001, loss_test:0.08159, lr:5.70e-03, fs:0.85083 (r=0.778,p=0.939),  time:37.553, tt:4281.031\n",
      "Ep:114, loss:0.00001, loss_test:0.08428, lr:5.64e-03, fs:0.85876 (r=0.768,p=0.974),  time:37.546, tt:4317.767\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.08513, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.535, tt:4354.052\n",
      "Ep:116, loss:0.00001, loss_test:0.08223, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.532, tt:4391.193\n",
      "Ep:117, loss:0.00001, loss_test:0.08395, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.504, tt:4425.438\n",
      "Ep:118, loss:0.00001, loss_test:0.08364, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.529, tt:4465.905\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00001, loss_test:0.08241, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.516, tt:4501.940\n",
      "Ep:120, loss:0.00001, loss_test:0.08567, lr:5.64e-03, fs:0.85876 (r=0.768,p=0.974),  time:37.524, tt:4540.351\n",
      "Ep:121, loss:0.00001, loss_test:0.08413, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.505, tt:4575.550\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00001, loss_test:0.08233, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.495, tt:4611.857\n",
      "Ep:123, loss:0.00001, loss_test:0.08505, lr:5.64e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.478, tt:4647.267\n",
      "Ep:124, loss:0.00001, loss_test:0.08365, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.485, tt:4685.571\n",
      "Ep:125, loss:0.00001, loss_test:0.08345, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.480, tt:4722.504\n",
      "Ep:126, loss:0.00001, loss_test:0.08376, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.488, tt:4761.012\n",
      "Ep:127, loss:0.00001, loss_test:0.08295, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.495, tt:4799.314\n",
      "Ep:128, loss:0.00001, loss_test:0.08382, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.497, tt:4837.070\n",
      "Ep:129, loss:0.00001, loss_test:0.08269, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.499, tt:4874.834\n",
      "Ep:130, loss:0.00001, loss_test:0.08476, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.500, tt:4912.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.08301, lr:5.64e-03, fs:0.84571 (r=0.747,p=0.974),  time:37.498, tt:4949.676\n",
      "Ep:132, loss:0.00001, loss_test:0.08399, lr:5.64e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.489, tt:4985.979\n",
      "Ep:133, loss:0.00001, loss_test:0.08530, lr:5.58e-03, fs:0.80473 (r=0.687,p=0.971),  time:37.487, tt:5023.314\n",
      "Ep:134, loss:0.00001, loss_test:0.08220, lr:5.53e-03, fs:0.86034 (r=0.778,p=0.963),  time:37.497, tt:5062.141\n",
      "Ep:135, loss:0.00001, loss_test:0.08442, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:37.500, tt:5100.031\n",
      "Ep:136, loss:0.00001, loss_test:0.08377, lr:5.42e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.490, tt:5136.095\n",
      "Ep:137, loss:0.00001, loss_test:0.08330, lr:5.36e-03, fs:0.85227 (r=0.758,p=0.974),  time:37.501, tt:5175.166\n",
      "Ep:138, loss:0.00001, loss_test:0.08356, lr:5.31e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.497, tt:5212.101\n",
      "Ep:139, loss:0.00001, loss_test:0.08373, lr:5.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.495, tt:5249.259\n",
      "Ep:140, loss:0.00001, loss_test:0.08369, lr:5.20e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.468, tt:5283.047\n",
      "Ep:141, loss:0.00001, loss_test:0.08345, lr:5.15e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.462, tt:5319.618\n",
      "Ep:142, loss:0.00001, loss_test:0.08334, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.463, tt:5357.277\n",
      "Ep:143, loss:0.00001, loss_test:0.08422, lr:5.05e-03, fs:0.83908 (r=0.737,p=0.973),  time:37.453, tt:5393.202\n",
      "Ep:144, loss:0.00001, loss_test:0.08351, lr:5.00e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.436, tt:5428.237\n",
      "Ep:145, loss:0.00001, loss_test:0.08416, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.445, tt:5466.952\n",
      "Ep:146, loss:0.00001, loss_test:0.08400, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:37.431, tt:5502.331\n",
      "Ep:147, loss:0.00001, loss_test:0.08299, lr:4.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.440, tt:5541.099\n",
      "Ep:148, loss:0.00001, loss_test:0.08354, lr:4.80e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.439, tt:5578.446\n",
      "Ep:149, loss:0.00001, loss_test:0.08422, lr:4.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.431, tt:5614.613\n",
      "Ep:150, loss:0.00001, loss_test:0.08431, lr:4.71e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.429, tt:5651.767\n",
      "Ep:151, loss:0.00001, loss_test:0.08431, lr:4.66e-03, fs:0.81871 (r=0.707,p=0.972),  time:37.423, tt:5688.268\n",
      "Ep:152, loss:0.00001, loss_test:0.08431, lr:4.61e-03, fs:0.83908 (r=0.737,p=0.973),  time:37.406, tt:5723.163\n",
      "Ep:153, loss:0.00001, loss_test:0.08446, lr:4.57e-03, fs:0.79042 (r=0.667,p=0.971),  time:37.419, tt:5762.578\n",
      "Ep:154, loss:0.00001, loss_test:0.08322, lr:4.52e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.409, tt:5798.338\n",
      "Ep:155, loss:0.00001, loss_test:0.08299, lr:4.48e-03, fs:0.83908 (r=0.737,p=0.973),  time:37.410, tt:5835.946\n",
      "Ep:156, loss:0.00001, loss_test:0.08348, lr:4.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.403, tt:5872.294\n",
      "Ep:157, loss:0.00001, loss_test:0.08334, lr:4.39e-03, fs:0.83237 (r=0.727,p=0.973),  time:37.407, tt:5910.338\n",
      "Ep:158, loss:0.00001, loss_test:0.08357, lr:4.34e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.404, tt:5947.280\n",
      "Ep:159, loss:0.00001, loss_test:0.08308, lr:4.30e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.401, tt:5984.131\n",
      "Ep:160, loss:0.00001, loss_test:0.08334, lr:4.26e-03, fs:0.82558 (r=0.717,p=0.973),  time:37.395, tt:6020.556\n",
      "Ep:161, loss:0.00001, loss_test:0.08291, lr:4.21e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.388, tt:6056.807\n",
      "Ep:162, loss:0.00001, loss_test:0.08312, lr:4.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:37.387, tt:6094.080\n",
      "Ep:163, loss:0.00001, loss_test:0.08353, lr:4.13e-03, fs:0.85876 (r=0.768,p=0.974),  time:37.381, tt:6130.443\n",
      "Ep:164, loss:0.00001, loss_test:0.08234, lr:4.09e-03, fs:0.84571 (r=0.747,p=0.974),  time:37.375, tt:6166.926\n",
      "Ep:165, loss:0.00001, loss_test:0.08381, lr:4.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:37.382, tt:6205.448\n",
      "Ep:166, loss:0.00001, loss_test:0.08356, lr:4.01e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.384, tt:6243.090\n",
      "Ep:167, loss:0.00001, loss_test:0.08289, lr:3.97e-03, fs:0.85227 (r=0.758,p=0.974),  time:37.385, tt:6280.622\n",
      "Ep:168, loss:0.00001, loss_test:0.08415, lr:3.93e-03, fs:0.85876 (r=0.768,p=0.974),  time:37.385, tt:6318.047\n",
      "Ep:169, loss:0.00001, loss_test:0.08309, lr:3.89e-03, fs:0.79762 (r=0.677,p=0.971),  time:37.399, tt:6357.868\n",
      "Ep:170, loss:0.00001, loss_test:0.08327, lr:3.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:37.397, tt:6394.901\n",
      "Ep:171, loss:0.00001, loss_test:0.08361, lr:3.81e-03, fs:0.79042 (r=0.667,p=0.971),  time:37.395, tt:6431.987\n",
      "Ep:172, loss:0.00001, loss_test:0.08252, lr:3.77e-03, fs:0.82558 (r=0.717,p=0.973),  time:37.386, tt:6467.783\n",
      "Ep:173, loss:0.00001, loss_test:0.08376, lr:3.73e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.386, tt:6505.211\n",
      "Ep:174, loss:0.00001, loss_test:0.08402, lr:3.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.377, tt:6541.009\n",
      "Ep:175, loss:0.00001, loss_test:0.08327, lr:3.66e-03, fs:0.83908 (r=0.737,p=0.973),  time:37.373, tt:6577.616\n",
      "Ep:176, loss:0.00001, loss_test:0.08363, lr:3.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.371, tt:6614.747\n",
      "Ep:177, loss:0.00001, loss_test:0.08307, lr:3.59e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.373, tt:6652.307\n",
      "Ep:178, loss:0.00001, loss_test:0.08306, lr:3.55e-03, fs:0.84571 (r=0.747,p=0.974),  time:37.367, tt:6688.675\n",
      "Ep:179, loss:0.00000, loss_test:0.08339, lr:3.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.376, tt:6727.641\n",
      "Ep:180, loss:0.00000, loss_test:0.08301, lr:3.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.365, tt:6763.068\n",
      "Ep:181, loss:0.00000, loss_test:0.08324, lr:3.45e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.373, tt:6801.819\n",
      "Ep:182, loss:0.00000, loss_test:0.08347, lr:3.41e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.370, tt:6838.797\n",
      "Ep:183, loss:0.00000, loss_test:0.08359, lr:3.38e-03, fs:0.79762 (r=0.677,p=0.971),  time:37.373, tt:6876.724\n",
      "Ep:184, loss:0.00000, loss_test:0.08355, lr:3.34e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.372, tt:6913.791\n",
      "Ep:185, loss:0.00000, loss_test:0.08270, lr:3.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.377, tt:6952.062\n",
      "Ep:186, loss:0.00000, loss_test:0.08308, lr:3.28e-03, fs:0.81176 (r=0.697,p=0.972),  time:37.372, tt:6988.561\n",
      "Ep:187, loss:0.00000, loss_test:0.08317, lr:3.24e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.395, tt:7030.307\n",
      "Ep:188, loss:0.00000, loss_test:0.08314, lr:3.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.392, tt:7067.053\n",
      "Ep:189, loss:0.00000, loss_test:0.08345, lr:3.18e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.389, tt:7103.961\n",
      "Ep:190, loss:0.00000, loss_test:0.08334, lr:3.15e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.374, tt:7138.464\n",
      "Ep:191, loss:0.00000, loss_test:0.08297, lr:3.12e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.378, tt:7176.482\n",
      "Ep:192, loss:0.00000, loss_test:0.08418, lr:3.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.374, tt:7213.168\n",
      "Ep:193, loss:0.00000, loss_test:0.08414, lr:3.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.369, tt:7249.559\n",
      "Ep:194, loss:0.00000, loss_test:0.08278, lr:3.02e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.373, tt:7287.770\n",
      "Ep:195, loss:0.00000, loss_test:0.08319, lr:2.99e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.370, tt:7324.520\n",
      "Ep:196, loss:0.00000, loss_test:0.08378, lr:2.96e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.363, tt:7360.562\n",
      "Ep:197, loss:0.00000, loss_test:0.08324, lr:2.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.369, tt:7398.985\n",
      "Ep:198, loss:0.00000, loss_test:0.08298, lr:2.90e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.376, tt:7437.888\n",
      "Ep:199, loss:0.00000, loss_test:0.08342, lr:2.88e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.374, tt:7474.806\n",
      "Ep:200, loss:0.00000, loss_test:0.08323, lr:2.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.368, tt:7511.053\n",
      "Ep:201, loss:0.00000, loss_test:0.08305, lr:2.82e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.358, tt:7546.368\n",
      "Ep:202, loss:0.00000, loss_test:0.08301, lr:2.79e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.367, tt:7585.419\n",
      "Ep:203, loss:0.00000, loss_test:0.08335, lr:2.76e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.367, tt:7622.820\n",
      "Ep:204, loss:0.00000, loss_test:0.08303, lr:2.73e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.377, tt:7662.266\n",
      "Ep:205, loss:0.00000, loss_test:0.08347, lr:2.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.375, tt:7699.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.08330, lr:2.68e-03, fs:0.78313 (r=0.657,p=0.970),  time:37.368, tt:7735.234\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00081, loss_test:0.02003, lr:1.00e-02, fs:0.66667 (r=0.897,p=0.531),  time:591.626, tt:591.626\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01773, lr:1.00e-02, fs:0.69767 (r=0.862,p=0.586),  time:629.100, tt:1258.201\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00053, loss_test:0.01624, lr:1.00e-02, fs:0.76847 (r=0.897,p=0.672),  time:638.478, tt:1915.433\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00047, loss_test:0.01533, lr:1.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:645.832, tt:2583.327\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00042, loss_test:0.01469, lr:1.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:648.164, tt:3240.819\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.01457, lr:1.00e-02, fs:0.81053 (r=0.885,p=0.748),  time:648.915, tt:3893.488\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00033, loss_test:0.01442, lr:1.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:648.815, tt:4541.708\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00030, loss_test:0.01436, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:649.571, tt:5196.565\n",
      "Ep:8, loss:0.00027, loss_test:0.01442, lr:1.00e-02, fs:0.83616 (r=0.851,p=0.822),  time:649.618, tt:5846.562\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.01482, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:650.923, tt:6509.229\n",
      "Ep:10, loss:0.00023, loss_test:0.01550, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:651.543, tt:7166.968\n",
      "Ep:11, loss:0.00021, loss_test:0.01572, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:651.949, tt:7823.384\n",
      "Ep:12, loss:0.00019, loss_test:0.01638, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:651.927, tt:8475.047\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.01688, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:651.551, tt:9121.711\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.01748, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:651.357, tt:9770.359\n",
      "Ep:15, loss:0.00015, loss_test:0.01800, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:651.452, tt:10423.233\n",
      "Ep:16, loss:0.00014, loss_test:0.01881, lr:1.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:651.437, tt:11074.433\n",
      "Ep:17, loss:0.00013, loss_test:0.01926, lr:1.00e-02, fs:0.86061 (r=0.816,p=0.910),  time:651.297, tt:11723.354\n",
      "Ep:18, loss:0.00012, loss_test:0.01987, lr:1.00e-02, fs:0.85185 (r=0.793,p=0.920),  time:651.313, tt:12374.942\n",
      "Ep:19, loss:0.00011, loss_test:0.02056, lr:1.00e-02, fs:0.82278 (r=0.747,p=0.915),  time:651.298, tt:13025.963\n",
      "Ep:20, loss:0.00010, loss_test:0.02144, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:651.118, tt:13673.478\n",
      "Ep:21, loss:0.00010, loss_test:0.02195, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:651.719, tt:14337.809\n",
      "Ep:22, loss:0.00009, loss_test:0.02277, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:651.986, tt:14995.668\n",
      "Ep:23, loss:0.00009, loss_test:0.02344, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:652.248, tt:15653.943\n",
      "Ep:24, loss:0.00008, loss_test:0.02382, lr:1.00e-02, fs:0.78947 (r=0.690,p=0.923),  time:652.242, tt:16306.055\n",
      "Ep:25, loss:0.00008, loss_test:0.02470, lr:9.90e-03, fs:0.79470 (r=0.690,p=0.938),  time:652.467, tt:16964.145\n",
      "Ep:26, loss:0.00007, loss_test:0.02508, lr:9.80e-03, fs:0.79470 (r=0.690,p=0.938),  time:652.665, tt:17621.944\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00088, loss_test:0.02191, lr:1.00e-02, fs:0.64777 (r=0.920,p=0.500),  time:607.971, tt:607.971\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00065, loss_test:0.01956, lr:1.00e-02, fs:0.67249 (r=0.885,p=0.542),  time:602.257, tt:1204.514\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01748, lr:1.00e-02, fs:0.71171 (r=0.908,p=0.585),  time:606.644, tt:1819.931\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00049, loss_test:0.01599, lr:1.00e-02, fs:0.76098 (r=0.897,p=0.661),  time:606.924, tt:2427.697\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.01519, lr:1.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:605.033, tt:3025.166\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00039, loss_test:0.01459, lr:1.00e-02, fs:0.80423 (r=0.874,p=0.745),  time:605.791, tt:3634.746\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00035, loss_test:0.01447, lr:1.00e-02, fs:0.79144 (r=0.851,p=0.740),  time:605.669, tt:4239.686\n",
      "Ep:7, loss:0.00031, loss_test:0.01440, lr:1.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:606.370, tt:4850.956\n",
      "Ep:8, loss:0.00028, loss_test:0.01452, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:607.131, tt:5464.181\n",
      "Ep:9, loss:0.00026, loss_test:0.01474, lr:1.00e-02, fs:0.80226 (r=0.816,p=0.789),  time:606.352, tt:6063.523\n",
      "Ep:10, loss:0.00024, loss_test:0.01493, lr:1.00e-02, fs:0.79545 (r=0.805,p=0.787),  time:605.861, tt:6664.468\n",
      "Ep:11, loss:0.00022, loss_test:0.01517, lr:1.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:606.342, tt:7276.103\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.01506, lr:1.00e-02, fs:0.80460 (r=0.805,p=0.805),  time:607.060, tt:7891.775\n",
      "Ep:13, loss:0.00019, loss_test:0.01551, lr:1.00e-02, fs:0.80473 (r=0.782,p=0.829),  time:607.293, tt:8502.101\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.01574, lr:1.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:607.325, tt:9109.870\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.01615, lr:1.00e-02, fs:0.80952 (r=0.782,p=0.840),  time:607.513, tt:9720.209\n",
      "Ep:16, loss:0.00015, loss_test:0.01654, lr:1.00e-02, fs:0.77778 (r=0.724,p=0.840),  time:607.461, tt:10326.833\n",
      "Ep:17, loss:0.00014, loss_test:0.01703, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:607.584, tt:10936.508\n",
      "Ep:18, loss:0.00013, loss_test:0.01753, lr:1.00e-02, fs:0.75159 (r=0.678,p=0.843),  time:607.749, tt:11547.236\n",
      "Ep:19, loss:0.00012, loss_test:0.01788, lr:1.00e-02, fs:0.76129 (r=0.678,p=0.868),  time:608.256, tt:12165.127\n",
      "Ep:20, loss:0.00011, loss_test:0.01807, lr:1.00e-02, fs:0.74510 (r=0.655,p=0.864),  time:608.537, tt:12779.282\n",
      "Ep:21, loss:0.00011, loss_test:0.01859, lr:1.00e-02, fs:0.74172 (r=0.644,p=0.875),  time:607.896, tt:13373.718\n",
      "Ep:22, loss:0.00010, loss_test:0.01896, lr:1.00e-02, fs:0.74324 (r=0.632,p=0.902),  time:608.555, tt:13996.765\n",
      "Ep:23, loss:0.00009, loss_test:0.01948, lr:1.00e-02, fs:0.73103 (r=0.609,p=0.914),  time:609.160, tt:14619.847\n",
      "Ep:24, loss:0.00009, loss_test:0.01988, lr:1.00e-02, fs:0.72222 (r=0.598,p=0.912),  time:610.247, tt:15256.164\n",
      "Ep:25, loss:0.00008, loss_test:0.02048, lr:1.00e-02, fs:0.71329 (r=0.586,p=0.911),  time:611.173, tt:15890.495\n",
      "Ep:26, loss:0.00008, loss_test:0.02079, lr:9.90e-03, fs:0.69504 (r=0.563,p=0.907),  time:611.747, tt:16517.182\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00078, loss_test:0.01996, lr:1.00e-02, fs:0.66667 (r=0.954,p=0.512),  time:688.560, tt:688.560\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01867, lr:1.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:688.965, tt:1377.930\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00055, loss_test:0.01771, lr:1.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:692.452, tt:2077.355\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00051, loss_test:0.01687, lr:1.00e-02, fs:0.73786 (r=0.874,p=0.639),  time:691.776, tt:2767.104\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01621, lr:1.00e-02, fs:0.76923 (r=0.862,p=0.694),  time:691.140, tt:3455.700\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.01561, lr:1.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:691.335, tt:4148.012\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.01516, lr:1.00e-02, fs:0.81283 (r=0.874,p=0.760),  time:692.826, tt:4849.782\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.01478, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:691.486, tt:5531.887\n",
      "Ep:8, loss:0.00037, loss_test:0.01454, lr:1.00e-02, fs:0.80435 (r=0.851,p=0.763),  time:692.334, tt:6231.003\n",
      "Ep:9, loss:0.00035, loss_test:0.01435, lr:1.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:692.657, tt:6926.571\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01415, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:692.431, tt:7616.745\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.01404, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:692.504, tt:8310.045\n",
      "Ep:12, loss:0.00030, loss_test:0.01388, lr:1.00e-02, fs:0.80899 (r=0.828,p=0.791),  time:692.784, tt:9006.194\n",
      "Ep:13, loss:0.00028, loss_test:0.01395, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:692.212, tt:9690.966\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.01401, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:692.268, tt:10384.012\n",
      "Ep:15, loss:0.00025, loss_test:0.01394, lr:1.00e-02, fs:0.81818 (r=0.828,p=0.809),  time:691.693, tt:11067.088\n",
      "Ep:16, loss:0.00024, loss_test:0.01402, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:691.735, tt:11759.503\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.01410, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:691.799, tt:12452.374\n",
      "Ep:18, loss:0.00022, loss_test:0.01422, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:691.242, tt:13133.590\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.01432, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:690.883, tt:13817.652\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.01434, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:689.009, tt:14469.194\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.01441, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:687.307, tt:15120.758\n",
      "Ep:22, loss:0.00018, loss_test:0.01455, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:685.493, tt:15766.348\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.01469, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:684.144, tt:16419.468\n",
      "Ep:24, loss:0.00016, loss_test:0.01489, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:682.762, tt:17069.058\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.01507, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:681.604, tt:17721.693\n",
      "Ep:26, loss:0.00015, loss_test:0.01519, lr:1.00e-02, fs:0.85030 (r=0.816,p=0.887),  time:680.375, tt:18370.117\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.02018, lr:1.00e-02, fs:0.66406 (r=0.977,p=0.503),  time:649.817, tt:649.817\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01864, lr:1.00e-02, fs:0.69828 (r=0.931,p=0.559),  time:646.654, tt:1293.309\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00059, loss_test:0.01785, lr:1.00e-02, fs:0.70222 (r=0.908,p=0.572),  time:648.183, tt:1944.550\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00055, loss_test:0.01725, lr:1.00e-02, fs:0.72477 (r=0.908,p=0.603),  time:649.584, tt:2598.334\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00053, loss_test:0.01676, lr:1.00e-02, fs:0.73832 (r=0.908,p=0.622),  time:651.703, tt:3258.514\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00051, loss_test:0.01632, lr:1.00e-02, fs:0.75598 (r=0.908,p=0.648),  time:651.767, tt:3910.603\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00049, loss_test:0.01599, lr:1.00e-02, fs:0.76847 (r=0.897,p=0.672),  time:651.606, tt:4561.243\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00047, loss_test:0.01570, lr:1.00e-02, fs:0.78607 (r=0.908,p=0.693),  time:651.297, tt:5210.372\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00045, loss_test:0.01542, lr:1.00e-02, fs:0.78173 (r=0.885,p=0.700),  time:651.797, tt:5866.169\n",
      "Ep:9, loss:0.00043, loss_test:0.01520, lr:1.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:651.170, tt:6511.699\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00042, loss_test:0.01502, lr:1.00e-02, fs:0.80208 (r=0.885,p=0.733),  time:651.422, tt:7165.647\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00040, loss_test:0.01482, lr:1.00e-02, fs:0.81053 (r=0.885,p=0.748),  time:651.622, tt:7819.470\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00039, loss_test:0.01464, lr:1.00e-02, fs:0.81481 (r=0.885,p=0.755),  time:652.222, tt:8478.892\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00037, loss_test:0.01448, lr:1.00e-02, fs:0.81720 (r=0.874,p=0.768),  time:652.506, tt:9135.077\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00036, loss_test:0.01437, lr:1.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:652.263, tt:9783.947\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00035, loss_test:0.01425, lr:1.00e-02, fs:0.82162 (r=0.874,p=0.776),  time:652.471, tt:10439.543\n",
      "Ep:16, loss:0.00034, loss_test:0.01422, lr:1.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:652.342, tt:11089.821\n",
      "Ep:17, loss:0.00033, loss_test:0.01412, lr:1.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:652.727, tt:11749.087\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00032, loss_test:0.01408, lr:1.00e-02, fs:0.82418 (r=0.862,p=0.789),  time:652.519, tt:12397.858\n",
      "Ep:19, loss:0.00031, loss_test:0.01402, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:652.217, tt:13044.335\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00030, loss_test:0.01394, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:652.557, tt:13703.702\n",
      "Ep:21, loss:0.00029, loss_test:0.01391, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:652.120, tt:14346.637\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00028, loss_test:0.01386, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:651.823, tt:14991.926\n",
      "Ep:23, loss:0.00027, loss_test:0.01389, lr:1.00e-02, fs:0.83333 (r=0.862,p=0.806),  time:651.493, tt:15635.836\n",
      "Ep:24, loss:0.00026, loss_test:0.01383, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:651.467, tt:16286.674\n",
      "Ep:25, loss:0.00025, loss_test:0.01386, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:651.655, tt:16943.039\n",
      "Ep:26, loss:0.00024, loss_test:0.01388, lr:1.00e-02, fs:0.82682 (r=0.851,p=0.804),  time:651.591, tt:17592.970\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.02007, lr:1.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:532.416, tt:532.416\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00060, loss_test:0.01862, lr:1.00e-02, fs:0.68996 (r=0.908,p=0.556),  time:530.921, tt:1061.842\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00054, loss_test:0.01749, lr:1.00e-02, fs:0.72477 (r=0.908,p=0.603),  time:528.503, tt:1585.509\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00050, loss_test:0.01656, lr:1.00e-02, fs:0.77833 (r=0.908,p=0.681),  time:541.092, tt:2164.366\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00047, loss_test:0.01582, lr:1.00e-02, fs:0.79592 (r=0.897,p=0.716),  time:539.419, tt:2697.097\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00044, loss_test:0.01524, lr:1.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:538.780, tt:3232.678\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.01486, lr:1.00e-02, fs:0.82540 (r=0.897,p=0.765),  time:537.861, tt:3765.027\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.01445, lr:1.00e-02, fs:0.83422 (r=0.897,p=0.780),  time:536.815, tt:4294.521\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.01417, lr:1.00e-02, fs:0.81967 (r=0.862,p=0.781),  time:536.003, tt:4824.030\n",
      "Ep:9, loss:0.00034, loss_test:0.01399, lr:1.00e-02, fs:0.81768 (r=0.851,p=0.787),  time:534.902, tt:5349.021\n",
      "Ep:10, loss:0.00032, loss_test:0.01375, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:535.087, tt:5885.956\n",
      "Ep:11, loss:0.00030, loss_test:0.01359, lr:1.00e-02, fs:0.82873 (r=0.862,p=0.798),  time:534.189, tt:6410.263\n",
      "Ep:12, loss:0.00029, loss_test:0.01351, lr:1.00e-02, fs:0.82222 (r=0.851,p=0.796),  time:533.767, tt:6938.966\n",
      "Ep:13, loss:0.00027, loss_test:0.01348, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:533.582, tt:7470.144\n",
      "Ep:14, loss:0.00026, loss_test:0.01346, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:533.833, tt:8007.491\n",
      "Ep:15, loss:0.00024, loss_test:0.01335, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:533.295, tt:8532.712\n",
      "Ep:16, loss:0.00023, loss_test:0.01348, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:533.161, tt:9063.738\n",
      "Ep:17, loss:0.00022, loss_test:0.01350, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:533.077, tt:9595.378\n",
      "Ep:18, loss:0.00021, loss_test:0.01347, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:533.165, tt:10130.132\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.01358, lr:1.00e-02, fs:0.83429 (r=0.839,p=0.830),  time:532.768, tt:10655.358\n",
      "Ep:20, loss:0.00019, loss_test:0.01368, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:532.795, tt:11188.698\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.01362, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:532.866, tt:11723.044\n",
      "Ep:22, loss:0.00017, loss_test:0.01391, lr:1.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:532.630, tt:12250.497\n",
      "Ep:23, loss:0.00017, loss_test:0.01394, lr:1.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:532.597, tt:12782.325\n",
      "Ep:24, loss:0.00016, loss_test:0.01405, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:532.663, tt:13316.588\n",
      "Ep:25, loss:0.00015, loss_test:0.01416, lr:1.00e-02, fs:0.82927 (r=0.782,p=0.883),  time:532.290, tt:13839.530\n",
      "Ep:26, loss:0.00015, loss_test:0.01438, lr:1.00e-02, fs:0.80745 (r=0.747,p=0.878),  time:532.270, tt:14371.296\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00101, loss_test:0.02289, lr:1.00e-02, fs:0.66949 (r=0.908,p=0.530),  time:594.148, tt:594.148\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00073, loss_test:0.02117, lr:1.00e-02, fs:0.65812 (r=0.885,p=0.524),  time:594.897, tt:1189.794\n",
      "Ep:2, loss:0.00062, loss_test:0.01912, lr:1.00e-02, fs:0.69643 (r=0.897,p=0.569),  time:596.784, tt:1790.351\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00053, loss_test:0.01736, lr:1.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:597.437, tt:2389.747\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.01635, lr:1.00e-02, fs:0.75758 (r=0.862,p=0.676),  time:599.926, tt:2999.628\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00038, loss_test:0.01574, lr:1.00e-02, fs:0.76440 (r=0.839,p=0.702),  time:604.378, tt:3626.268\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.01564, lr:1.00e-02, fs:0.77005 (r=0.828,p=0.720),  time:605.550, tt:4238.853\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.01582, lr:1.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:606.485, tt:4851.880\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.01605, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:606.740, tt:5460.664\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00018, loss_test:0.01675, lr:1.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:607.236, tt:6072.361\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00015, loss_test:0.01760, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:607.614, tt:6683.757\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00013, loss_test:0.01869, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:607.769, tt:7293.226\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00011, loss_test:0.01911, lr:1.00e-02, fs:0.84277 (r=0.770,p=0.931),  time:608.661, tt:7912.593\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00010, loss_test:0.01993, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:608.940, tt:8525.154\n",
      "Ep:14, loss:0.00009, loss_test:0.02092, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:609.722, tt:9145.823\n",
      "Ep:15, loss:0.00008, loss_test:0.02210, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:610.119, tt:9761.902\n",
      "Ep:16, loss:0.00007, loss_test:0.02305, lr:1.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:610.926, tt:10385.750\n",
      "Ep:17, loss:0.00006, loss_test:0.02400, lr:1.00e-02, fs:0.81579 (r=0.713,p=0.954),  time:610.730, tt:10993.146\n",
      "Ep:18, loss:0.00006, loss_test:0.02497, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:611.013, tt:11609.249\n",
      "Ep:19, loss:0.00005, loss_test:0.02559, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:611.194, tt:12223.875\n",
      "Ep:20, loss:0.00005, loss_test:0.02637, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:611.472, tt:12840.919\n",
      "Ep:21, loss:0.00004, loss_test:0.02762, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:611.931, tt:13462.472\n",
      "Ep:22, loss:0.00004, loss_test:0.02856, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:612.154, tt:14079.535\n",
      "Ep:23, loss:0.00004, loss_test:0.02897, lr:1.00e-02, fs:0.80000 (r=0.690,p=0.952),  time:612.281, tt:14694.740\n",
      "Ep:24, loss:0.00003, loss_test:0.02964, lr:9.90e-03, fs:0.80000 (r=0.690,p=0.952),  time:612.473, tt:15311.828\n",
      "Ep:25, loss:0.00003, loss_test:0.03079, lr:9.80e-03, fs:0.80000 (r=0.690,p=0.952),  time:612.247, tt:15918.429\n",
      "Ep:26, loss:0.00003, loss_test:0.03157, lr:9.70e-03, fs:0.80000 (r=0.690,p=0.952),  time:612.085, tt:16526.287\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 1\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.01937, lr:1.00e-02, fs:0.66964 (r=0.862,p=0.547),  time:206.271, tt:206.271\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.01748, lr:1.00e-02, fs:0.71296 (r=0.885,p=0.597),  time:205.895, tt:411.789\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01626, lr:1.00e-02, fs:0.74757 (r=0.885,p=0.647),  time:205.566, tt:616.699\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.01561, lr:1.00e-02, fs:0.78974 (r=0.885,p=0.713),  time:206.299, tt:825.197\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00041, loss_test:0.01505, lr:1.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:206.168, tt:1030.838\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00037, loss_test:0.01475, lr:1.00e-02, fs:0.80645 (r=0.862,p=0.758),  time:206.005, tt:1236.030\n",
      "Ep:6, loss:0.00034, loss_test:0.01455, lr:1.00e-02, fs:0.78689 (r=0.828,p=0.750),  time:205.844, tt:1440.909\n",
      "Ep:7, loss:0.00031, loss_test:0.01449, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:205.979, tt:1647.828\n",
      "Ep:8, loss:0.00029, loss_test:0.01449, lr:1.00e-02, fs:0.80447 (r=0.828,p=0.783),  time:205.663, tt:1850.969\n",
      "Ep:9, loss:0.00027, loss_test:0.01446, lr:1.00e-02, fs:0.81564 (r=0.839,p=0.793),  time:205.387, tt:2053.867\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.01455, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:205.211, tt:2257.326\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.01467, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:205.320, tt:2463.839\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.01480, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:205.164, tt:2667.135\n",
      "Ep:13, loss:0.00020, loss_test:0.01499, lr:1.00e-02, fs:0.82759 (r=0.828,p=0.828),  time:205.065, tt:2870.912\n",
      "Ep:14, loss:0.00018, loss_test:0.01512, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:204.973, tt:3074.596\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.01535, lr:1.00e-02, fs:0.84211 (r=0.828,p=0.857),  time:204.923, tt:3278.766\n",
      "Ep:16, loss:0.00016, loss_test:0.01536, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:204.896, tt:3483.224\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.01585, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:204.806, tt:3686.503\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.01582, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:204.743, tt:3890.123\n",
      "Ep:19, loss:0.00013, loss_test:0.01604, lr:1.00e-02, fs:0.86747 (r=0.828,p=0.911),  time:204.837, tt:4096.746\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.01623, lr:1.00e-02, fs:0.85890 (r=0.805,p=0.921),  time:204.847, tt:4301.785\n",
      "Ep:21, loss:0.00012, loss_test:0.01650, lr:1.00e-02, fs:0.84472 (r=0.782,p=0.919),  time:204.789, tt:4505.361\n",
      "Ep:22, loss:0.00011, loss_test:0.01674, lr:1.00e-02, fs:0.81290 (r=0.724,p=0.926),  time:204.732, tt:4708.840\n",
      "Ep:23, loss:0.00010, loss_test:0.01703, lr:1.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:204.688, tt:4912.520\n",
      "Ep:24, loss:0.00010, loss_test:0.01725, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:204.866, tt:5121.655\n",
      "Ep:25, loss:0.00009, loss_test:0.01751, lr:1.00e-02, fs:0.78146 (r=0.678,p=0.922),  time:204.837, tt:5325.758\n",
      "Ep:26, loss:0.00009, loss_test:0.01767, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:218.406, tt:5896.961\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number = \"2-2\"\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14158, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.567, tt:46.567\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14000, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.443, tt:92.887\n",
      "Ep:2, loss:0.00001, loss_test:0.13696, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:47.594, tt:142.782\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00001, loss_test:0.13154, lr:1.00e-02, fs:0.66667 (r=0.931,p=0.519),  time:46.991, tt:187.962\n",
      "Ep:4, loss:0.00001, loss_test:0.12619, lr:1.00e-02, fs:0.65385 (r=0.782,p=0.562),  time:47.207, tt:236.034\n",
      "Ep:5, loss:0.00001, loss_test:0.12803, lr:1.00e-02, fs:0.59649 (r=0.586,p=0.607),  time:47.479, tt:284.877\n",
      "Ep:6, loss:0.00001, loss_test:0.13021, lr:1.00e-02, fs:0.53247 (r=0.471,p=0.612),  time:47.432, tt:332.023\n",
      "Ep:7, loss:0.00001, loss_test:0.12192, lr:1.00e-02, fs:0.58182 (r=0.552,p=0.615),  time:47.526, tt:380.209\n",
      "Ep:8, loss:0.00001, loss_test:0.11716, lr:1.00e-02, fs:0.60000 (r=0.586,p=0.614),  time:47.439, tt:426.952\n",
      "Ep:9, loss:0.00001, loss_test:0.11733, lr:1.00e-02, fs:0.58065 (r=0.517,p=0.662),  time:47.443, tt:474.427\n",
      "Ep:10, loss:0.00001, loss_test:0.11366, lr:1.00e-02, fs:0.56774 (r=0.506,p=0.647),  time:47.404, tt:521.442\n",
      "Ep:11, loss:0.00001, loss_test:0.10758, lr:1.00e-02, fs:0.63855 (r=0.609,p=0.671),  time:47.245, tt:566.943\n",
      "Ep:12, loss:0.00001, loss_test:0.10658, lr:1.00e-02, fs:0.68354 (r=0.621,p=0.761),  time:47.098, tt:612.274\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.10440, lr:1.00e-02, fs:0.68874 (r=0.598,p=0.812),  time:47.078, tt:659.089\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00001, loss_test:0.09918, lr:1.00e-02, fs:0.71698 (r=0.655,p=0.792),  time:47.047, tt:705.704\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00001, loss_test:0.09876, lr:1.00e-02, fs:0.69677 (r=0.621,p=0.794),  time:46.946, tt:751.129\n",
      "Ep:16, loss:0.00001, loss_test:0.09594, lr:1.00e-02, fs:0.72500 (r=0.667,p=0.795),  time:46.954, tt:798.216\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09332, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:46.905, tt:844.284\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.09273, lr:1.00e-02, fs:0.75000 (r=0.690,p=0.822),  time:46.834, tt:889.839\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.09047, lr:1.00e-02, fs:0.75610 (r=0.713,p=0.805),  time:47.037, tt:940.738\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.09095, lr:1.00e-02, fs:0.75000 (r=0.690,p=0.822),  time:47.040, tt:987.845\n",
      "Ep:21, loss:0.00001, loss_test:0.08935, lr:1.00e-02, fs:0.74847 (r=0.701,p=0.803),  time:47.075, tt:1035.649\n",
      "Ep:22, loss:0.00001, loss_test:0.09004, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:47.015, tt:1081.348\n",
      "Ep:23, loss:0.00001, loss_test:0.08851, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:46.954, tt:1126.887\n",
      "Ep:24, loss:0.00001, loss_test:0.08859, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:46.935, tt:1173.365\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.08711, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:46.870, tt:1218.614\n",
      "Ep:26, loss:0.00001, loss_test:0.08730, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:46.854, tt:1265.060\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00001, loss_test:0.08634, lr:1.00e-02, fs:0.76543 (r=0.713,p=0.827),  time:46.710, tt:1307.894\n",
      "Ep:28, loss:0.00001, loss_test:0.08698, lr:1.00e-02, fs:0.77500 (r=0.713,p=0.849),  time:46.719, tt:1354.861\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.08626, lr:1.00e-02, fs:0.77987 (r=0.713,p=0.861),  time:46.642, tt:1399.251\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00000, loss_test:0.08683, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:46.610, tt:1444.907\n",
      "Ep:31, loss:0.00000, loss_test:0.08685, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:46.610, tt:1491.506\n",
      "Ep:32, loss:0.00000, loss_test:0.08641, lr:1.00e-02, fs:0.77987 (r=0.713,p=0.861),  time:46.597, tt:1537.711\n",
      "Ep:33, loss:0.00000, loss_test:0.08745, lr:1.00e-02, fs:0.75325 (r=0.667,p=0.866),  time:46.591, tt:1584.098\n",
      "Ep:34, loss:0.00000, loss_test:0.08584, lr:1.00e-02, fs:0.77707 (r=0.701,p=0.871),  time:46.587, tt:1630.549\n",
      "Ep:35, loss:0.00000, loss_test:0.08573, lr:1.00e-02, fs:0.74839 (r=0.667,p=0.853),  time:46.563, tt:1676.251\n",
      "Ep:36, loss:0.00000, loss_test:0.08621, lr:1.00e-02, fs:0.75000 (r=0.655,p=0.877),  time:46.562, tt:1722.801\n",
      "Ep:37, loss:0.00000, loss_test:0.08638, lr:1.00e-02, fs:0.72848 (r=0.632,p=0.859),  time:46.691, tt:1774.252\n",
      "Ep:38, loss:0.00000, loss_test:0.08569, lr:1.00e-02, fs:0.74510 (r=0.655,p=0.864),  time:46.719, tt:1822.023\n",
      "Ep:39, loss:0.00000, loss_test:0.08818, lr:1.00e-02, fs:0.73826 (r=0.632,p=0.887),  time:46.734, tt:1869.342\n",
      "Ep:40, loss:0.00000, loss_test:0.08772, lr:1.00e-02, fs:0.73826 (r=0.632,p=0.887),  time:46.738, tt:1916.242\n",
      "Ep:41, loss:0.00000, loss_test:0.08613, lr:9.90e-03, fs:0.73333 (r=0.632,p=0.873),  time:46.726, tt:1962.480\n",
      "Ep:42, loss:0.00000, loss_test:0.09044, lr:9.80e-03, fs:0.73973 (r=0.621,p=0.915),  time:46.787, tt:2011.845\n",
      "Ep:43, loss:0.00000, loss_test:0.08646, lr:9.70e-03, fs:0.74324 (r=0.632,p=0.902),  time:46.790, tt:2058.768\n",
      "Ep:44, loss:0.00000, loss_test:0.08825, lr:9.61e-03, fs:0.74324 (r=0.632,p=0.902),  time:46.793, tt:2105.687\n",
      "Ep:45, loss:0.00000, loss_test:0.08900, lr:9.51e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.739, tt:2150.011\n",
      "Ep:46, loss:0.00000, loss_test:0.08901, lr:9.41e-03, fs:0.74324 (r=0.632,p=0.902),  time:46.701, tt:2194.966\n",
      "Ep:47, loss:0.00000, loss_test:0.08867, lr:9.32e-03, fs:0.74830 (r=0.632,p=0.917),  time:46.677, tt:2240.486\n",
      "Ep:48, loss:0.00000, loss_test:0.08907, lr:9.23e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.678, tt:2287.226\n",
      "Ep:49, loss:0.00000, loss_test:0.09035, lr:9.14e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.675, tt:2333.762\n",
      "Ep:50, loss:0.00000, loss_test:0.08936, lr:9.04e-03, fs:0.73469 (r=0.621,p=0.900),  time:46.533, tt:2373.197\n",
      "Ep:51, loss:0.00000, loss_test:0.09191, lr:8.95e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.411, tt:2413.378\n",
      "Ep:52, loss:0.00000, loss_test:0.09008, lr:8.86e-03, fs:0.73103 (r=0.609,p=0.914),  time:46.349, tt:2456.489\n",
      "Ep:53, loss:0.00000, loss_test:0.09123, lr:8.78e-03, fs:0.73611 (r=0.609,p=0.930),  time:46.279, tt:2499.044\n",
      "Ep:54, loss:0.00000, loss_test:0.09174, lr:8.69e-03, fs:0.73611 (r=0.609,p=0.930),  time:46.188, tt:2540.345\n",
      "Ep:55, loss:0.00000, loss_test:0.08998, lr:8.60e-03, fs:0.72603 (r=0.609,p=0.898),  time:46.100, tt:2581.628\n",
      "Ep:56, loss:0.00000, loss_test:0.09427, lr:8.51e-03, fs:0.73239 (r=0.598,p=0.945),  time:46.032, tt:2623.819\n",
      "Ep:57, loss:0.00000, loss_test:0.09016, lr:8.43e-03, fs:0.73103 (r=0.609,p=0.914),  time:45.965, tt:2665.978\n",
      "Ep:58, loss:0.00000, loss_test:0.09467, lr:8.35e-03, fs:0.72727 (r=0.598,p=0.929),  time:45.869, tt:2706.265\n",
      "Ep:59, loss:0.00000, loss_test:0.09161, lr:8.26e-03, fs:0.73611 (r=0.609,p=0.930),  time:45.794, tt:2747.666\n",
      "Ep:60, loss:0.00000, loss_test:0.09387, lr:8.18e-03, fs:0.73611 (r=0.609,p=0.930),  time:45.720, tt:2788.933\n",
      "Ep:61, loss:0.00000, loss_test:0.09410, lr:8.10e-03, fs:0.73239 (r=0.598,p=0.945),  time:45.631, tt:2829.129\n",
      "Ep:62, loss:0.00000, loss_test:0.09288, lr:8.02e-03, fs:0.73611 (r=0.609,p=0.930),  time:45.533, tt:2868.609\n",
      "Ep:63, loss:0.00000, loss_test:0.09605, lr:7.94e-03, fs:0.73239 (r=0.598,p=0.945),  time:45.446, tt:2908.520\n",
      "Ep:64, loss:0.00000, loss_test:0.09252, lr:7.86e-03, fs:0.74126 (r=0.609,p=0.946),  time:45.281, tt:2943.288\n",
      "Ep:65, loss:0.00000, loss_test:0.09541, lr:7.78e-03, fs:0.73239 (r=0.598,p=0.945),  time:45.068, tt:2974.518\n",
      "Ep:66, loss:0.00000, loss_test:0.09319, lr:7.70e-03, fs:0.74126 (r=0.609,p=0.946),  time:44.830, tt:3003.632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:67, loss:0.00000, loss_test:0.09568, lr:7.62e-03, fs:0.74286 (r=0.598,p=0.981),  time:44.533, tt:3028.247\n",
      "Ep:68, loss:0.00000, loss_test:0.09359, lr:7.55e-03, fs:0.74126 (r=0.609,p=0.946),  time:44.108, tt:3043.451\n",
      "Ep:69, loss:0.00000, loss_test:0.09603, lr:7.47e-03, fs:0.74286 (r=0.598,p=0.981),  time:43.653, tt:3055.713\n",
      "Ep:70, loss:0.00000, loss_test:0.09490, lr:7.40e-03, fs:0.74286 (r=0.598,p=0.981),  time:43.212, tt:3068.058\n",
      "Ep:71, loss:0.00000, loss_test:0.09628, lr:7.32e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.783, tt:3080.400\n",
      "Ep:72, loss:0.00000, loss_test:0.09619, lr:7.25e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.367, tt:3092.803\n",
      "Ep:73, loss:0.00000, loss_test:0.09607, lr:7.18e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.974, tt:3106.093\n",
      "Ep:74, loss:0.00000, loss_test:0.09751, lr:7.11e-03, fs:0.71533 (r=0.563,p=0.980),  time:41.580, tt:3118.523\n",
      "Ep:75, loss:0.00000, loss_test:0.09638, lr:7.03e-03, fs:0.73381 (r=0.586,p=0.981),  time:41.196, tt:3130.871\n",
      "Ep:76, loss:0.00000, loss_test:0.09779, lr:6.96e-03, fs:0.71533 (r=0.563,p=0.980),  time:40.821, tt:3143.194\n",
      "Ep:77, loss:0.00000, loss_test:0.09677, lr:6.89e-03, fs:0.75177 (r=0.609,p=0.981),  time:40.456, tt:3155.597\n",
      "Ep:78, loss:0.00000, loss_test:0.09901, lr:6.83e-03, fs:0.69630 (r=0.540,p=0.979),  time:40.101, tt:3168.010\n",
      "Ep:79, loss:0.00000, loss_test:0.09782, lr:6.76e-03, fs:0.73381 (r=0.586,p=0.981),  time:39.755, tt:3180.396\n",
      "Ep:80, loss:0.00000, loss_test:0.09949, lr:6.69e-03, fs:0.68657 (r=0.529,p=0.979),  time:39.417, tt:3192.759\n",
      "Ep:81, loss:0.00000, loss_test:0.09822, lr:6.62e-03, fs:0.71533 (r=0.563,p=0.980),  time:39.086, tt:3205.034\n",
      "Ep:82, loss:0.00000, loss_test:0.10018, lr:6.56e-03, fs:0.69173 (r=0.529,p=1.000),  time:38.763, tt:3217.323\n",
      "Ep:83, loss:0.00000, loss_test:0.09913, lr:6.49e-03, fs:0.71533 (r=0.563,p=0.980),  time:38.457, tt:3230.363\n",
      "Ep:84, loss:0.00000, loss_test:0.10073, lr:6.43e-03, fs:0.68182 (r=0.517,p=1.000),  time:38.149, tt:3242.707\n",
      "Ep:85, loss:0.00000, loss_test:0.10081, lr:6.36e-03, fs:0.71111 (r=0.552,p=1.000),  time:37.849, tt:3254.995\n",
      "Ep:86, loss:0.00000, loss_test:0.10125, lr:6.30e-03, fs:0.66154 (r=0.494,p=1.000),  time:37.551, tt:3266.941\n",
      "Ep:87, loss:0.00000, loss_test:0.10220, lr:6.24e-03, fs:0.69173 (r=0.529,p=1.000),  time:37.264, tt:3279.214\n",
      "Ep:88, loss:0.00000, loss_test:0.10148, lr:6.17e-03, fs:0.70149 (r=0.540,p=1.000),  time:36.983, tt:3291.465\n",
      "Ep:89, loss:0.00000, loss_test:0.10314, lr:6.11e-03, fs:0.67176 (r=0.506,p=1.000),  time:36.708, tt:3303.730\n",
      "Ep:90, loss:0.00000, loss_test:0.10269, lr:6.05e-03, fs:0.69173 (r=0.529,p=1.000),  time:36.441, tt:3316.111\n",
      "Ep:91, loss:0.00000, loss_test:0.10361, lr:5.99e-03, fs:0.65116 (r=0.483,p=1.000),  time:36.179, tt:3328.498\n",
      "Ep:92, loss:0.00000, loss_test:0.10352, lr:5.93e-03, fs:0.69173 (r=0.529,p=1.000),  time:35.923, tt:3340.821\n",
      "Ep:93, loss:0.00000, loss_test:0.10388, lr:5.87e-03, fs:0.65116 (r=0.483,p=1.000),  time:35.672, tt:3353.186\n",
      "Ep:94, loss:0.00000, loss_test:0.10411, lr:5.81e-03, fs:0.65116 (r=0.483,p=1.000),  time:35.427, tt:3365.579\n",
      "Ep:95, loss:0.00000, loss_test:0.10439, lr:5.75e-03, fs:0.65116 (r=0.483,p=1.000),  time:35.186, tt:3377.899\n",
      "Ep:96, loss:0.00000, loss_test:0.10448, lr:5.70e-03, fs:0.62992 (r=0.460,p=1.000),  time:34.949, tt:3390.040\n",
      "Ep:97, loss:0.00000, loss_test:0.10482, lr:5.64e-03, fs:0.64062 (r=0.471,p=1.000),  time:34.718, tt:3402.406\n",
      "Ep:98, loss:0.00000, loss_test:0.10525, lr:5.58e-03, fs:0.62992 (r=0.460,p=1.000),  time:34.493, tt:3414.781\n",
      "Ep:99, loss:0.00000, loss_test:0.10571, lr:5.53e-03, fs:0.62992 (r=0.460,p=1.000),  time:34.271, tt:3427.068\n",
      "Ep:100, loss:0.00000, loss_test:0.10571, lr:5.47e-03, fs:0.62992 (r=0.460,p=1.000),  time:34.054, tt:3439.462\n",
      "Ep:101, loss:0.00000, loss_test:0.10619, lr:5.42e-03, fs:0.61905 (r=0.448,p=1.000),  time:33.843, tt:3451.954\n",
      "Ep:102, loss:0.00000, loss_test:0.10606, lr:5.36e-03, fs:0.61905 (r=0.448,p=1.000),  time:33.636, tt:3464.500\n",
      "Ep:103, loss:0.00000, loss_test:0.10645, lr:5.31e-03, fs:0.61905 (r=0.448,p=1.000),  time:33.445, tt:3478.273\n",
      "Ep:104, loss:0.00000, loss_test:0.10676, lr:5.26e-03, fs:0.61905 (r=0.448,p=1.000),  time:33.263, tt:3492.627\n",
      "Ep:105, loss:0.00000, loss_test:0.10668, lr:5.20e-03, fs:0.61905 (r=0.448,p=1.000),  time:33.085, tt:3507.047\n",
      "Ep:106, loss:0.00000, loss_test:0.10688, lr:5.15e-03, fs:0.61905 (r=0.448,p=1.000),  time:32.913, tt:3521.716\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14246, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.872, tt:48.872\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14111, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.380, tt:98.761\n",
      "Ep:2, loss:0.00001, loss_test:0.13861, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.600, tt:148.801\n",
      "Ep:3, loss:0.00001, loss_test:0.13437, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.401, tt:197.604\n",
      "Ep:4, loss:0.00001, loss_test:0.12746, lr:1.00e-02, fs:0.68908 (r=0.943,p=0.543),  time:49.277, tt:246.387\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.12015, lr:1.00e-02, fs:0.67980 (r=0.793,p=0.595),  time:49.340, tt:296.039\n",
      "Ep:6, loss:0.00001, loss_test:0.12233, lr:1.00e-02, fs:0.59394 (r=0.563,p=0.628),  time:49.269, tt:344.881\n",
      "Ep:7, loss:0.00001, loss_test:0.12008, lr:1.00e-02, fs:0.58824 (r=0.517,p=0.682),  time:48.966, tt:391.725\n",
      "Ep:8, loss:0.00001, loss_test:0.11273, lr:1.00e-02, fs:0.66286 (r=0.667,p=0.659),  time:48.742, tt:438.680\n",
      "Ep:9, loss:0.00001, loss_test:0.10952, lr:1.00e-02, fs:0.69006 (r=0.678,p=0.702),  time:48.382, tt:483.821\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.11009, lr:1.00e-02, fs:0.64901 (r=0.563,p=0.766),  time:48.288, tt:531.168\n",
      "Ep:11, loss:0.00001, loss_test:0.10469, lr:1.00e-02, fs:0.67081 (r=0.621,p=0.730),  time:48.190, tt:578.280\n",
      "Ep:12, loss:0.00001, loss_test:0.10030, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:48.032, tt:624.419\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00001, loss_test:0.09978, lr:1.00e-02, fs:0.70064 (r=0.632,p=0.786),  time:47.989, tt:671.851\n",
      "Ep:14, loss:0.00001, loss_test:0.09716, lr:1.00e-02, fs:0.70130 (r=0.621,p=0.806),  time:48.205, tt:723.074\n",
      "Ep:15, loss:0.00001, loss_test:0.09312, lr:1.00e-02, fs:0.74214 (r=0.678,p=0.819),  time:48.081, tt:769.295\n",
      "Ep:16, loss:0.00001, loss_test:0.09415, lr:1.00e-02, fs:0.69737 (r=0.609,p=0.815),  time:47.924, tt:814.702\n",
      "Ep:17, loss:0.00001, loss_test:0.09138, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:47.860, tt:861.481\n",
      "Ep:18, loss:0.00001, loss_test:0.08947, lr:1.00e-02, fs:0.71429 (r=0.632,p=0.821),  time:47.860, tt:909.348\n",
      "Ep:19, loss:0.00001, loss_test:0.08990, lr:1.00e-02, fs:0.71523 (r=0.621,p=0.844),  time:47.761, tt:955.211\n",
      "Ep:20, loss:0.00001, loss_test:0.08688, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:47.650, tt:1000.650\n",
      "Ep:21, loss:0.00001, loss_test:0.08765, lr:1.00e-02, fs:0.72000 (r=0.621,p=0.857),  time:47.593, tt:1047.044\n",
      "Ep:22, loss:0.00001, loss_test:0.08520, lr:1.00e-02, fs:0.72727 (r=0.644,p=0.836),  time:47.480, tt:1092.044\n",
      "Ep:23, loss:0.00001, loss_test:0.08509, lr:1.00e-02, fs:0.73203 (r=0.644,p=0.848),  time:47.332, tt:1135.972\n",
      "Ep:24, loss:0.00001, loss_test:0.08404, lr:9.90e-03, fs:0.74026 (r=0.655,p=0.851),  time:47.275, tt:1181.887\n",
      "Ep:25, loss:0.00001, loss_test:0.08262, lr:9.80e-03, fs:0.75641 (r=0.678,p=0.855),  time:47.262, tt:1228.806\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.08238, lr:9.80e-03, fs:0.74839 (r=0.667,p=0.853),  time:47.283, tt:1276.636\n",
      "Ep:27, loss:0.00001, loss_test:0.08110, lr:9.80e-03, fs:0.76923 (r=0.690,p=0.870),  time:47.272, tt:1323.607\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.08214, lr:9.80e-03, fs:0.75325 (r=0.667,p=0.866),  time:47.261, tt:1370.571\n",
      "Ep:29, loss:0.00001, loss_test:0.08145, lr:9.80e-03, fs:0.74510 (r=0.655,p=0.864),  time:47.404, tt:1422.127\n",
      "Ep:30, loss:0.00001, loss_test:0.08182, lr:9.80e-03, fs:0.73684 (r=0.644,p=0.862),  time:47.492, tt:1472.249\n",
      "Ep:31, loss:0.00000, loss_test:0.08092, lr:9.80e-03, fs:0.76129 (r=0.678,p=0.868),  time:47.452, tt:1518.452\n",
      "Ep:32, loss:0.00000, loss_test:0.08223, lr:9.80e-03, fs:0.75497 (r=0.655,p=0.891),  time:47.508, tt:1567.776\n",
      "Ep:33, loss:0.00000, loss_test:0.08083, lr:9.80e-03, fs:0.76316 (r=0.667,p=0.892),  time:47.558, tt:1616.967\n",
      "Ep:34, loss:0.00000, loss_test:0.08155, lr:9.80e-03, fs:0.74667 (r=0.644,p=0.889),  time:47.552, tt:1664.310\n",
      "Ep:35, loss:0.00000, loss_test:0.08100, lr:9.80e-03, fs:0.73826 (r=0.632,p=0.887),  time:47.531, tt:1711.121\n",
      "Ep:36, loss:0.00000, loss_test:0.08195, lr:9.80e-03, fs:0.73469 (r=0.621,p=0.900),  time:47.499, tt:1757.479\n",
      "Ep:37, loss:0.00000, loss_test:0.08324, lr:9.80e-03, fs:0.73469 (r=0.621,p=0.900),  time:47.421, tt:1801.987\n",
      "Ep:38, loss:0.00000, loss_test:0.08511, lr:9.80e-03, fs:0.72603 (r=0.609,p=0.898),  time:47.412, tt:1849.082\n",
      "Ep:39, loss:0.00000, loss_test:0.08486, lr:9.70e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.331, tt:1893.254\n",
      "Ep:40, loss:0.00000, loss_test:0.08667, lr:9.61e-03, fs:0.73103 (r=0.609,p=0.914),  time:47.280, tt:1938.470\n",
      "Ep:41, loss:0.00000, loss_test:0.08516, lr:9.51e-03, fs:0.72222 (r=0.598,p=0.912),  time:47.257, tt:1984.776\n",
      "Ep:42, loss:0.00000, loss_test:0.08672, lr:9.41e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.282, tt:2033.111\n",
      "Ep:43, loss:0.00000, loss_test:0.08643, lr:9.32e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.265, tt:2079.673\n",
      "Ep:44, loss:0.00000, loss_test:0.08643, lr:9.23e-03, fs:0.72340 (r=0.586,p=0.944),  time:47.247, tt:2126.121\n",
      "Ep:45, loss:0.00000, loss_test:0.08636, lr:9.14e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.167, tt:2169.695\n",
      "Ep:46, loss:0.00000, loss_test:0.08628, lr:9.04e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.158, tt:2216.422\n",
      "Ep:47, loss:0.00000, loss_test:0.08642, lr:8.95e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.154, tt:2263.369\n",
      "Ep:48, loss:0.00000, loss_test:0.08567, lr:8.86e-03, fs:0.72340 (r=0.586,p=0.944),  time:47.125, tt:2309.144\n",
      "Ep:49, loss:0.00000, loss_test:0.08630, lr:8.78e-03, fs:0.73239 (r=0.598,p=0.945),  time:47.136, tt:2356.783\n",
      "Ep:50, loss:0.00000, loss_test:0.08737, lr:8.69e-03, fs:0.71429 (r=0.575,p=0.943),  time:47.011, tt:2397.550\n",
      "Ep:51, loss:0.00000, loss_test:0.08828, lr:8.60e-03, fs:0.73381 (r=0.586,p=0.981),  time:46.922, tt:2439.968\n",
      "Ep:52, loss:0.00000, loss_test:0.08813, lr:8.51e-03, fs:0.72340 (r=0.586,p=0.944),  time:46.855, tt:2483.325\n",
      "Ep:53, loss:0.00000, loss_test:0.08961, lr:8.43e-03, fs:0.71014 (r=0.563,p=0.961),  time:46.759, tt:2524.966\n",
      "Ep:54, loss:0.00000, loss_test:0.08811, lr:8.35e-03, fs:0.73381 (r=0.586,p=0.981),  time:46.652, tt:2565.839\n",
      "Ep:55, loss:0.00000, loss_test:0.09010, lr:8.26e-03, fs:0.73381 (r=0.586,p=0.981),  time:46.535, tt:2605.939\n",
      "Ep:56, loss:0.00000, loss_test:0.09014, lr:8.18e-03, fs:0.70073 (r=0.552,p=0.960),  time:46.411, tt:2645.427\n",
      "Ep:57, loss:0.00000, loss_test:0.09016, lr:8.10e-03, fs:0.72464 (r=0.575,p=0.980),  time:46.320, tt:2686.586\n",
      "Ep:58, loss:0.00000, loss_test:0.09066, lr:8.02e-03, fs:0.72464 (r=0.575,p=0.980),  time:46.323, tt:2733.074\n",
      "Ep:59, loss:0.00000, loss_test:0.09084, lr:7.94e-03, fs:0.71533 (r=0.563,p=0.980),  time:46.251, tt:2775.073\n",
      "Ep:60, loss:0.00000, loss_test:0.09173, lr:7.86e-03, fs:0.70588 (r=0.552,p=0.980),  time:46.161, tt:2815.828\n",
      "Ep:61, loss:0.00000, loss_test:0.09087, lr:7.78e-03, fs:0.72464 (r=0.575,p=0.980),  time:45.983, tt:2850.976\n",
      "Ep:62, loss:0.00000, loss_test:0.09204, lr:7.70e-03, fs:0.69630 (r=0.540,p=0.979),  time:45.916, tt:2892.718\n",
      "Ep:63, loss:0.00000, loss_test:0.09209, lr:7.62e-03, fs:0.69630 (r=0.540,p=0.979),  time:45.903, tt:2937.813\n",
      "Ep:64, loss:0.00000, loss_test:0.09330, lr:7.55e-03, fs:0.69630 (r=0.540,p=0.979),  time:45.903, tt:2983.700\n",
      "Ep:65, loss:0.00000, loss_test:0.09247, lr:7.47e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.920, tt:3030.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00000, loss_test:0.09272, lr:7.40e-03, fs:0.69630 (r=0.540,p=0.979),  time:45.936, tt:3077.735\n",
      "Ep:67, loss:0.00000, loss_test:0.09328, lr:7.32e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.940, tt:3123.912\n",
      "Ep:68, loss:0.00000, loss_test:0.09400, lr:7.25e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.962, tt:3171.395\n",
      "Ep:69, loss:0.00000, loss_test:0.09317, lr:7.18e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.959, tt:3217.106\n",
      "Ep:70, loss:0.00000, loss_test:0.09418, lr:7.11e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.980, tt:3264.577\n",
      "Ep:71, loss:0.00000, loss_test:0.09447, lr:7.03e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.980, tt:3310.553\n",
      "Ep:72, loss:0.00000, loss_test:0.09371, lr:6.96e-03, fs:0.68657 (r=0.529,p=0.979),  time:45.976, tt:3356.268\n",
      "Ep:73, loss:0.00000, loss_test:0.09474, lr:6.89e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.000, tt:3404.027\n",
      "Ep:74, loss:0.00000, loss_test:0.09395, lr:6.83e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.019, tt:3451.438\n",
      "Ep:75, loss:0.00000, loss_test:0.09492, lr:6.76e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.059, tt:3500.481\n",
      "Ep:76, loss:0.00000, loss_test:0.09496, lr:6.69e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.090, tt:3548.896\n",
      "Ep:77, loss:0.00000, loss_test:0.09475, lr:6.62e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.184, tt:3602.347\n",
      "Ep:78, loss:0.00000, loss_test:0.09493, lr:6.56e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.206, tt:3650.305\n",
      "Ep:79, loss:0.00000, loss_test:0.09493, lr:6.49e-03, fs:0.68657 (r=0.529,p=0.979),  time:46.197, tt:3695.781\n",
      "Ep:80, loss:0.00000, loss_test:0.09538, lr:6.43e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.189, tt:3741.348\n",
      "Ep:81, loss:0.00000, loss_test:0.09559, lr:6.36e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.201, tt:3788.519\n",
      "Ep:82, loss:0.00000, loss_test:0.09588, lr:6.30e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.185, tt:3833.386\n",
      "Ep:83, loss:0.00000, loss_test:0.09595, lr:6.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.211, tt:3881.732\n",
      "Ep:84, loss:0.00000, loss_test:0.09601, lr:6.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.232, tt:3929.750\n",
      "Ep:85, loss:0.00000, loss_test:0.09649, lr:6.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.235, tt:3976.223\n",
      "Ep:86, loss:0.00000, loss_test:0.09612, lr:6.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.259, tt:4024.558\n",
      "Ep:87, loss:0.00000, loss_test:0.09695, lr:5.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.271, tt:4071.817\n",
      "Ep:88, loss:0.00000, loss_test:0.09640, lr:5.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.252, tt:4116.465\n",
      "Ep:89, loss:0.00000, loss_test:0.09704, lr:5.87e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.257, tt:4163.096\n",
      "Ep:90, loss:0.00000, loss_test:0.09642, lr:5.81e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.267, tt:4210.276\n",
      "Ep:91, loss:0.00000, loss_test:0.09740, lr:5.75e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.259, tt:4255.799\n",
      "Ep:92, loss:0.00000, loss_test:0.09709, lr:5.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:46.272, tt:4303.321\n",
      "Ep:93, loss:0.00000, loss_test:0.09711, lr:5.64e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.273, tt:4349.636\n",
      "Ep:94, loss:0.00000, loss_test:0.09733, lr:5.58e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.258, tt:4394.535\n",
      "Ep:95, loss:0.00000, loss_test:0.09736, lr:5.53e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.252, tt:4440.153\n",
      "Ep:96, loss:0.00000, loss_test:0.09765, lr:5.47e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.293, tt:4490.400\n",
      "Ep:97, loss:0.00000, loss_test:0.09777, lr:5.42e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.300, tt:4537.387\n",
      "Ep:98, loss:0.00000, loss_test:0.09764, lr:5.36e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.310, tt:4584.658\n",
      "Ep:99, loss:0.00000, loss_test:0.09838, lr:5.31e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.314, tt:4631.373\n",
      "Ep:100, loss:0.00000, loss_test:0.09758, lr:5.26e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.313, tt:4677.660\n",
      "Ep:101, loss:0.00000, loss_test:0.09851, lr:5.20e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.307, tt:4723.323\n",
      "Ep:102, loss:0.00000, loss_test:0.09759, lr:5.15e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.287, tt:4767.570\n",
      "Ep:103, loss:0.00000, loss_test:0.09859, lr:5.10e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.288, tt:4813.925\n",
      "Ep:104, loss:0.00000, loss_test:0.09793, lr:5.05e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.295, tt:4861.020\n",
      "Ep:105, loss:0.00000, loss_test:0.09846, lr:5.00e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.290, tt:4906.706\n",
      "Ep:106, loss:0.00000, loss_test:0.09850, lr:4.95e-03, fs:0.66667 (r=0.506,p=0.978),  time:46.292, tt:4953.278\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14182, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.338, tt:27.338\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14027, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.628, tt:69.255\n",
      "Ep:2, loss:0.00001, loss_test:0.13753, lr:1.00e-02, fs:0.66148 (r=0.977,p=0.500),  time:38.552, tt:115.655\n",
      "Ep:3, loss:0.00001, loss_test:0.13302, lr:1.00e-02, fs:0.67220 (r=0.931,p=0.526),  time:40.284, tt:161.136\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.12712, lr:1.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:41.740, tt:208.700\n",
      "Ep:5, loss:0.00001, loss_test:0.12938, lr:1.00e-02, fs:0.54217 (r=0.517,p=0.570),  time:42.946, tt:257.676\n",
      "Ep:6, loss:0.00001, loss_test:0.13201, lr:1.00e-02, fs:0.50649 (r=0.448,p=0.582),  time:43.905, tt:307.336\n",
      "Ep:7, loss:0.00001, loss_test:0.12368, lr:1.00e-02, fs:0.57831 (r=0.552,p=0.608),  time:44.356, tt:354.852\n",
      "Ep:8, loss:0.00001, loss_test:0.11855, lr:1.00e-02, fs:0.68449 (r=0.736,p=0.640),  time:45.138, tt:406.238\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.11770, lr:1.00e-02, fs:0.62353 (r=0.609,p=0.639),  time:45.359, tt:453.587\n",
      "Ep:10, loss:0.00001, loss_test:0.11619, lr:1.00e-02, fs:0.58750 (r=0.540,p=0.644),  time:45.515, tt:500.663\n",
      "Ep:11, loss:0.00001, loss_test:0.10962, lr:1.00e-02, fs:0.62963 (r=0.586,p=0.680),  time:45.670, tt:548.046\n",
      "Ep:12, loss:0.00001, loss_test:0.10659, lr:1.00e-02, fs:0.62500 (r=0.575,p=0.685),  time:45.951, tt:597.365\n",
      "Ep:13, loss:0.00001, loss_test:0.10652, lr:1.00e-02, fs:0.58824 (r=0.517,p=0.682),  time:45.860, tt:642.042\n",
      "Ep:14, loss:0.00001, loss_test:0.10192, lr:1.00e-02, fs:0.67081 (r=0.621,p=0.730),  time:45.888, tt:688.316\n",
      "Ep:15, loss:0.00001, loss_test:0.09999, lr:1.00e-02, fs:0.69565 (r=0.644,p=0.757),  time:45.948, tt:735.162\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09912, lr:1.00e-02, fs:0.69620 (r=0.632,p=0.775),  time:45.972, tt:781.518\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09496, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:46.036, tt:828.641\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.09448, lr:1.00e-02, fs:0.73292 (r=0.678,p=0.797),  time:46.116, tt:876.195\n",
      "Ep:19, loss:0.00001, loss_test:0.09333, lr:1.00e-02, fs:0.72956 (r=0.667,p=0.806),  time:46.215, tt:924.306\n",
      "Ep:20, loss:0.00001, loss_test:0.09114, lr:1.00e-02, fs:0.74534 (r=0.690,p=0.811),  time:46.280, tt:971.872\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.09106, lr:1.00e-02, fs:0.73750 (r=0.678,p=0.808),  time:46.311, tt:1018.834\n",
      "Ep:22, loss:0.00001, loss_test:0.08885, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:46.391, tt:1067.001\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.08919, lr:1.00e-02, fs:0.73750 (r=0.678,p=0.808),  time:46.438, tt:1114.513\n",
      "Ep:24, loss:0.00001, loss_test:0.08867, lr:1.00e-02, fs:0.74534 (r=0.690,p=0.811),  time:46.469, tt:1161.729\n",
      "Ep:25, loss:0.00001, loss_test:0.08822, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:46.507, tt:1209.193\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.08835, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:46.674, tt:1260.200\n",
      "Ep:27, loss:0.00001, loss_test:0.08791, lr:1.00e-02, fs:0.74534 (r=0.690,p=0.811),  time:46.763, tt:1309.369\n",
      "Ep:28, loss:0.00001, loss_test:0.08756, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:46.833, tt:1358.161\n",
      "Ep:29, loss:0.00000, loss_test:0.08839, lr:1.00e-02, fs:0.73418 (r=0.667,p=0.817),  time:46.882, tt:1406.448\n",
      "Ep:30, loss:0.00000, loss_test:0.08854, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:46.876, tt:1453.147\n",
      "Ep:31, loss:0.00000, loss_test:0.08806, lr:1.00e-02, fs:0.71795 (r=0.644,p=0.812),  time:46.832, tt:1498.634\n",
      "Ep:32, loss:0.00000, loss_test:0.08968, lr:1.00e-02, fs:0.66216 (r=0.563,p=0.803),  time:46.857, tt:1546.266\n",
      "Ep:33, loss:0.00000, loss_test:0.08875, lr:1.00e-02, fs:0.68456 (r=0.586,p=0.823),  time:46.921, tt:1595.317\n",
      "Ep:34, loss:0.00000, loss_test:0.09022, lr:1.00e-02, fs:0.65753 (r=0.552,p=0.814),  time:46.980, tt:1644.309\n",
      "Ep:35, loss:0.00000, loss_test:0.08969, lr:1.00e-02, fs:0.67586 (r=0.563,p=0.845),  time:47.007, tt:1692.253\n",
      "Ep:36, loss:0.00000, loss_test:0.09209, lr:1.00e-02, fs:0.65734 (r=0.540,p=0.839),  time:47.044, tt:1740.616\n",
      "Ep:37, loss:0.00000, loss_test:0.09212, lr:9.90e-03, fs:0.64828 (r=0.540,p=0.810),  time:47.115, tt:1790.378\n",
      "Ep:38, loss:0.00000, loss_test:0.09351, lr:9.80e-03, fs:0.65734 (r=0.540,p=0.839),  time:47.158, tt:1839.155\n",
      "Ep:39, loss:0.00000, loss_test:0.09243, lr:9.70e-03, fs:0.65278 (r=0.540,p=0.825),  time:47.224, tt:1888.954\n",
      "Ep:40, loss:0.00000, loss_test:0.09471, lr:9.61e-03, fs:0.64789 (r=0.529,p=0.836),  time:47.261, tt:1937.693\n",
      "Ep:41, loss:0.00000, loss_test:0.09312, lr:9.51e-03, fs:0.64789 (r=0.529,p=0.836),  time:47.292, tt:1986.244\n",
      "Ep:42, loss:0.00000, loss_test:0.09416, lr:9.41e-03, fs:0.65248 (r=0.529,p=0.852),  time:47.316, tt:2034.605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b8746a910509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m107\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00354, loss_test:0.12006, lr:4.00e-03, fs:0.68376 (r=0.808,p=0.593),  time:514.978, tt:514.978\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00276, loss_test:0.10430, lr:4.00e-03, fs:0.73585 (r=0.788,p=0.690),  time:546.760, tt:1093.521\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00204, loss_test:0.09424, lr:4.00e-03, fs:0.77157 (r=0.768,p=0.776),  time:559.803, tt:1679.409\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00147, loss_test:0.09135, lr:4.00e-03, fs:0.80214 (r=0.758,p=0.852),  time:566.671, tt:2266.683\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00105, loss_test:0.09244, lr:4.00e-03, fs:0.74118 (r=0.636,p=0.887),  time:571.267, tt:2856.335\n",
      "Ep:5, loss:0.00071, loss_test:0.09635, lr:4.00e-03, fs:0.73171 (r=0.606,p=0.923),  time:573.320, tt:3439.922\n",
      "Ep:6, loss:0.00047, loss_test:0.09333, lr:4.00e-03, fs:0.75904 (r=0.636,p=0.940),  time:574.606, tt:4022.244\n",
      "Ep:7, loss:0.00031, loss_test:0.09792, lr:4.00e-03, fs:0.74390 (r=0.616,p=0.938),  time:576.173, tt:4609.383\n",
      "Ep:8, loss:0.00021, loss_test:0.10066, lr:4.00e-03, fs:0.70440 (r=0.566,p=0.933),  time:577.162, tt:5194.460\n",
      "Ep:9, loss:0.00014, loss_test:0.10599, lr:4.00e-03, fs:0.67532 (r=0.525,p=0.945),  time:578.323, tt:5783.226\n",
      "Ep:10, loss:0.00010, loss_test:0.10840, lr:4.00e-03, fs:0.61224 (r=0.455,p=0.938),  time:576.892, tt:6345.812\n",
      "Ep:11, loss:0.00008, loss_test:0.10967, lr:4.00e-03, fs:0.64430 (r=0.485,p=0.960),  time:573.075, tt:6876.900\n",
      "Ep:12, loss:0.00006, loss_test:0.11001, lr:4.00e-03, fs:0.64865 (r=0.485,p=0.980),  time:569.030, tt:7397.396\n",
      "Ep:13, loss:0.00004, loss_test:0.10987, lr:4.00e-03, fs:0.66225 (r=0.505,p=0.962),  time:565.839, tt:7921.743\n",
      "Ep:14, loss:0.00004, loss_test:0.11014, lr:4.00e-03, fs:0.64430 (r=0.485,p=0.960),  time:563.887, tt:8458.302\n",
      "Ep:15, loss:0.00003, loss_test:0.11074, lr:3.96e-03, fs:0.63946 (r=0.475,p=0.979),  time:561.614, tt:8985.817\n",
      "Ep:16, loss:0.00003, loss_test:0.11171, lr:3.92e-03, fs:0.64430 (r=0.485,p=0.960),  time:559.664, tt:9514.292\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14237, lr:4.00e-03, fs:0.66667 (r=1.000,p=0.500),  time:30.782, tt:30.782\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.13906, lr:4.00e-03, fs:0.67119 (r=1.000,p=0.505),  time:37.417, tt:74.835\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.13206, lr:4.00e-03, fs:0.65185 (r=0.889,p=0.515),  time:48.140, tt:144.419\n",
      "Ep:3, loss:0.00049, loss_test:0.12390, lr:4.00e-03, fs:0.60274 (r=0.667,p=0.550),  time:56.911, tt:227.645\n",
      "Ep:4, loss:0.00046, loss_test:0.12133, lr:4.00e-03, fs:0.63682 (r=0.646,p=0.627),  time:62.536, tt:312.680\n",
      "Ep:5, loss:0.00044, loss_test:0.11779, lr:4.00e-03, fs:0.66351 (r=0.707,p=0.625),  time:65.882, tt:395.291\n",
      "Ep:6, loss:0.00042, loss_test:0.11394, lr:4.00e-03, fs:0.68966 (r=0.707,p=0.673),  time:68.273, tt:477.910\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00040, loss_test:0.11136, lr:4.00e-03, fs:0.65641 (r=0.646,p=0.667),  time:70.164, tt:561.311\n",
      "Ep:8, loss:0.00038, loss_test:0.10766, lr:4.00e-03, fs:0.68718 (r=0.677,p=0.698),  time:72.134, tt:649.206\n",
      "Ep:9, loss:0.00036, loss_test:0.10612, lr:4.00e-03, fs:0.70833 (r=0.687,p=0.731),  time:72.757, tt:727.569\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00034, loss_test:0.10330, lr:4.00e-03, fs:0.71579 (r=0.687,p=0.747),  time:73.679, tt:810.472\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.10299, lr:4.00e-03, fs:0.70718 (r=0.646,p=0.780),  time:74.592, tt:895.107\n",
      "Ep:12, loss:0.00031, loss_test:0.09927, lr:4.00e-03, fs:0.72432 (r=0.677,p=0.779),  time:75.407, tt:980.290\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00029, loss_test:0.09900, lr:4.00e-03, fs:0.70787 (r=0.636,p=0.797),  time:75.934, tt:1063.083\n",
      "Ep:14, loss:0.00028, loss_test:0.09603, lr:4.00e-03, fs:0.71508 (r=0.646,p=0.800),  time:76.356, tt:1145.346\n",
      "Ep:15, loss:0.00026, loss_test:0.09561, lr:4.00e-03, fs:0.72000 (r=0.636,p=0.829),  time:76.726, tt:1227.623\n",
      "Ep:16, loss:0.00025, loss_test:0.09415, lr:4.00e-03, fs:0.72000 (r=0.636,p=0.829),  time:77.102, tt:1310.726\n",
      "Ep:17, loss:0.00024, loss_test:0.09194, lr:4.00e-03, fs:0.74860 (r=0.677,p=0.838),  time:77.622, tt:1397.191\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.09193, lr:4.00e-03, fs:0.73563 (r=0.646,p=0.853),  time:77.907, tt:1480.230\n",
      "Ep:19, loss:0.00021, loss_test:0.09070, lr:4.00e-03, fs:0.75706 (r=0.677,p=0.859),  time:77.945, tt:1558.904\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09107, lr:4.00e-03, fs:0.72832 (r=0.636,p=0.851),  time:77.755, tt:1632.860\n",
      "Ep:21, loss:0.00019, loss_test:0.09237, lr:4.00e-03, fs:0.75000 (r=0.636,p=0.913),  time:77.915, tt:1714.132\n",
      "Ep:22, loss:0.00018, loss_test:0.08630, lr:4.00e-03, fs:0.77095 (r=0.697,p=0.863),  time:78.387, tt:1802.891\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00017, loss_test:0.08733, lr:4.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:78.590, tt:1886.160\n",
      "Ep:24, loss:0.00016, loss_test:0.09407, lr:4.00e-03, fs:0.68790 (r=0.545,p=0.931),  time:78.799, tt:1969.972\n",
      "Ep:25, loss:0.00015, loss_test:0.08807, lr:4.00e-03, fs:0.75740 (r=0.646,p=0.914),  time:78.992, tt:2053.782\n",
      "Ep:26, loss:0.00014, loss_test:0.08473, lr:4.00e-03, fs:0.76301 (r=0.667,p=0.892),  time:79.119, tt:2136.214\n",
      "Ep:27, loss:0.00013, loss_test:0.08982, lr:4.00e-03, fs:0.74251 (r=0.626,p=0.912),  time:79.310, tt:2220.686\n",
      "Ep:28, loss:0.00012, loss_test:0.09197, lr:4.00e-03, fs:0.70886 (r=0.566,p=0.949),  time:79.315, tt:2300.122\n",
      "Ep:29, loss:0.00011, loss_test:0.09135, lr:4.00e-03, fs:0.70440 (r=0.566,p=0.933),  time:79.190, tt:2375.701\n",
      "Ep:30, loss:0.00011, loss_test:0.09074, lr:4.00e-03, fs:0.71605 (r=0.586,p=0.921),  time:79.379, tt:2460.736\n",
      "Ep:31, loss:0.00010, loss_test:0.08926, lr:4.00e-03, fs:0.69565 (r=0.566,p=0.903),  time:79.428, tt:2541.696\n",
      "Ep:32, loss:0.00009, loss_test:0.08801, lr:4.00e-03, fs:0.71166 (r=0.586,p=0.906),  time:79.686, tt:2629.644\n",
      "Ep:33, loss:0.00008, loss_test:0.09103, lr:4.00e-03, fs:0.68354 (r=0.545,p=0.915),  time:79.808, tt:2713.474\n",
      "Ep:34, loss:0.00008, loss_test:0.09304, lr:3.96e-03, fs:0.65789 (r=0.505,p=0.943),  time:79.860, tt:2795.085\n",
      "Ep:35, loss:0.00007, loss_test:0.09134, lr:3.92e-03, fs:0.66234 (r=0.515,p=0.927),  time:79.934, tt:2877.609\n",
      "Ep:36, loss:0.00007, loss_test:0.09168, lr:3.88e-03, fs:0.66234 (r=0.515,p=0.927),  time:79.974, tt:2959.029\n",
      "Ep:37, loss:0.00006, loss_test:0.09681, lr:3.84e-03, fs:0.64901 (r=0.495,p=0.942),  time:80.058, tt:3042.211\n",
      "Ep:38, loss:0.00006, loss_test:0.09465, lr:3.80e-03, fs:0.65789 (r=0.505,p=0.943),  time:80.068, tt:3122.646\n",
      "Ep:39, loss:0.00005, loss_test:0.09404, lr:3.77e-03, fs:0.64901 (r=0.495,p=0.942),  time:80.130, tt:3205.183\n",
      "Ep:40, loss:0.00005, loss_test:0.09399, lr:3.73e-03, fs:0.65359 (r=0.505,p=0.926),  time:80.147, tt:3286.040\n",
      "Ep:41, loss:0.00005, loss_test:0.09078, lr:3.69e-03, fs:0.68790 (r=0.545,p=0.931),  time:80.302, tt:3372.671\n",
      "Ep:42, loss:0.00005, loss_test:0.09407, lr:3.65e-03, fs:0.65789 (r=0.505,p=0.943),  time:80.373, tt:3456.035\n",
      "Ep:43, loss:0.00004, loss_test:0.09441, lr:3.62e-03, fs:0.65359 (r=0.505,p=0.926),  time:80.425, tt:3538.686\n",
      "Ep:44, loss:0.00004, loss_test:0.09503, lr:3.58e-03, fs:0.65789 (r=0.505,p=0.943),  time:80.469, tt:3621.097\n",
      "Ep:45, loss:0.00004, loss_test:0.09897, lr:3.55e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.524, tt:3704.107\n",
      "Ep:46, loss:0.00004, loss_test:0.09938, lr:3.51e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.583, tt:3787.412\n",
      "Ep:47, loss:0.00003, loss_test:0.09149, lr:3.47e-03, fs:0.65789 (r=0.505,p=0.943),  time:80.698, tt:3873.487\n",
      "Ep:48, loss:0.00003, loss_test:0.09538, lr:3.44e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.676, tt:3953.147\n",
      "Ep:49, loss:0.00003, loss_test:0.10004, lr:3.41e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.730, tt:4036.490\n",
      "Ep:50, loss:0.00003, loss_test:0.09629, lr:3.37e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.778, tt:4119.682\n",
      "Ep:51, loss:0.00003, loss_test:0.09216, lr:3.34e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.777, tt:4200.409\n",
      "Ep:52, loss:0.00002, loss_test:0.09704, lr:3.30e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.807, tt:4282.781\n",
      "Ep:53, loss:0.00002, loss_test:0.09567, lr:3.27e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.905, tt:4368.876\n",
      "Ep:54, loss:0.00002, loss_test:0.09755, lr:3.24e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.888, tt:4448.867\n",
      "Ep:55, loss:0.00002, loss_test:0.09399, lr:3.21e-03, fs:0.66225 (r=0.505,p=0.962),  time:80.919, tt:4531.468\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"3-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00424, loss_test:0.10472, lr:4.00e-03, fs:0.73636 (r=0.818,p=0.669),  time:706.942, tt:706.942\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00291, loss_test:0.09620, lr:4.00e-03, fs:0.72043 (r=0.677,p=0.770),  time:730.311, tt:1460.623\n",
      "Ep:2, loss:0.00209, loss_test:0.09251, lr:4.00e-03, fs:0.77083 (r=0.747,p=0.796),  time:739.795, tt:2219.384\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00150, loss_test:0.09427, lr:4.00e-03, fs:0.81522 (r=0.758,p=0.882),  time:743.264, tt:2973.054\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00107, loss_test:0.09070, lr:4.00e-03, fs:0.80435 (r=0.747,p=0.871),  time:746.009, tt:3730.044\n",
      "Ep:5, loss:0.00076, loss_test:0.10451, lr:4.00e-03, fs:0.76829 (r=0.636,p=0.969),  time:746.251, tt:4477.508\n",
      "Ep:6, loss:0.00055, loss_test:0.10092, lr:4.00e-03, fs:0.76647 (r=0.646,p=0.941),  time:744.971, tt:5214.794\n",
      "Ep:7, loss:0.00040, loss_test:0.11050, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:745.341, tt:5962.730\n",
      "Ep:8, loss:0.00028, loss_test:0.11842, lr:4.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:745.126, tt:6706.134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8330ca8f10b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"3-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00373, loss_test:0.09679, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:673.239, tt:673.239\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00193, loss_test:0.08834, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:715.051, tt:1430.102\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00097, loss_test:0.09621, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:722.427, tt:2167.280\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00046, loss_test:0.09808, lr:1.00e-02, fs:0.73418 (r=0.586,p=0.983),  time:729.137, tt:2916.547\n",
      "Ep:4, loss:0.00023, loss_test:0.10870, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:733.615, tt:3668.077\n",
      "Ep:5, loss:0.00012, loss_test:0.12259, lr:1.00e-02, fs:0.72611 (r=0.576,p=0.983),  time:736.432, tt:4418.589\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cf0e4e39f849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"3-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00354, loss_test:0.09764, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:724.793, tt:724.793\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00185, loss_test:0.10399, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:733.607, tt:1467.214\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00083, loss_test:0.10931, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:739.652, tt:2218.955\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00040, loss_test:0.10430, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:743.483, tt:2973.933\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00020, loss_test:0.11578, lr:1.00e-02, fs:0.72050 (r=0.586,p=0.935),  time:747.946, tt:3739.729\n",
      "Ep:5, loss:0.00010, loss_test:0.11535, lr:1.00e-02, fs:0.77576 (r=0.646,p=0.970),  time:749.096, tt:4494.576\n",
      "Ep:6, loss:0.00005, loss_test:0.12280, lr:1.00e-02, fs:0.73750 (r=0.596,p=0.967),  time:747.574, tt:5233.020\n",
      "Ep:7, loss:0.00003, loss_test:0.12053, lr:1.00e-02, fs:0.73750 (r=0.596,p=0.967),  time:746.359, tt:5970.869\n",
      "Ep:8, loss:0.00002, loss_test:0.12391, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:745.204, tt:6706.840\n",
      "Ep:9, loss:0.00002, loss_test:0.12409, lr:1.00e-02, fs:0.74214 (r=0.596,p=0.983),  time:744.691, tt:7446.908\n",
      "Ep:10, loss:0.00002, loss_test:0.12405, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:743.612, tt:8179.727\n",
      "Ep:11, loss:0.00001, loss_test:0.12208, lr:1.00e-02, fs:0.74214 (r=0.596,p=0.983),  time:745.114, tt:8941.366\n",
      "Ep:12, loss:0.00001, loss_test:0.12435, lr:1.00e-02, fs:0.73292 (r=0.596,p=0.952),  time:746.363, tt:9702.724\n",
      "Ep:13, loss:0.00001, loss_test:0.12210, lr:1.00e-02, fs:0.74684 (r=0.596,p=1.000),  time:746.679, tt:10453.504\n",
      "Ep:14, loss:0.00001, loss_test:0.11993, lr:1.00e-02, fs:0.73292 (r=0.596,p=0.952),  time:747.567, tt:11213.503\n",
      "Ep:15, loss:0.00001, loss_test:0.12009, lr:9.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:747.766, tt:11964.251\n",
      "Ep:16, loss:0.00001, loss_test:0.11919, lr:9.80e-03, fs:0.72840 (r=0.596,p=0.937),  time:748.480, tt:12724.159\n",
      "Ep:17, loss:0.00001, loss_test:0.11952, lr:9.70e-03, fs:0.73292 (r=0.596,p=0.952),  time:748.814, tt:13478.660\n",
      "Ep:18, loss:0.00001, loss_test:0.11876, lr:9.61e-03, fs:0.72840 (r=0.596,p=0.937),  time:749.645, tt:14243.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m                                           apply_func=apply_node_func)\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     def prop_nodes(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[1;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             out_map)\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n\u001b[1;32m    390\u001b[0m             \u001b[0mreducer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             graph, target, in_data_nd, out_data_nd, in_map[0], out_map[0])\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# normalize if mean reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# NOTE(zihao): this is a temporary hack and we should have better solution in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/kernel.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, G, target, X, out, X_rows, out_rows)\u001b[0m\n\u001b[1;32m    370\u001b[0m     _CAPI_DGLKernelCopyReduce(\n\u001b[1;32m    371\u001b[0m         \u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         X, out, X_rows, out_rows)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14355, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:11.439, tt:11.439\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14319, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:12.934, tt:25.867\n",
      "Ep:2, loss:0.00004, loss_test:0.14266, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:14.738, tt:44.214\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.14189, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:15.750, tt:63.001\n",
      "Ep:4, loss:0.00004, loss_test:0.14084, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:16.357, tt:81.785\n",
      "Ep:5, loss:0.00004, loss_test:0.13951, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:16.919, tt:101.513\n",
      "Ep:6, loss:0.00004, loss_test:0.13794, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:17.280, tt:120.957\n",
      "Ep:7, loss:0.00004, loss_test:0.13594, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:17.587, tt:140.696\n",
      "Ep:8, loss:0.00004, loss_test:0.13332, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:17.766, tt:159.891\n",
      "Ep:9, loss:0.00004, loss_test:0.13021, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:17.880, tt:178.803\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.12667, lr:1.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:17.977, tt:197.743\n",
      "Ep:11, loss:0.00003, loss_test:0.12424, lr:1.00e-02, fs:0.63755 (r=0.737,p=0.562),  time:18.093, tt:217.110\n",
      "Ep:12, loss:0.00003, loss_test:0.12300, lr:1.00e-02, fs:0.62673 (r=0.687,p=0.576),  time:18.198, tt:236.569\n",
      "Ep:13, loss:0.00003, loss_test:0.12145, lr:1.00e-02, fs:0.63256 (r=0.687,p=0.586),  time:18.233, tt:255.269\n",
      "Ep:14, loss:0.00003, loss_test:0.11984, lr:1.00e-02, fs:0.65158 (r=0.727,p=0.590),  time:18.318, tt:274.777\n",
      "Ep:15, loss:0.00003, loss_test:0.11899, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:18.332, tt:293.316\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.11947, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:18.327, tt:311.567\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.11917, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:18.422, tt:331.589\n",
      "Ep:18, loss:0.00003, loss_test:0.11789, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:18.429, tt:350.156\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11734, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:18.465, tt:369.301\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.11757, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:18.457, tt:387.603\n",
      "Ep:21, loss:0.00003, loss_test:0.11658, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:18.478, tt:406.523\n",
      "Ep:22, loss:0.00003, loss_test:0.11507, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:18.458, tt:424.527\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.11478, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:18.444, tt:442.652\n",
      "Ep:24, loss:0.00003, loss_test:0.11421, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:18.516, tt:462.892\n",
      "Ep:25, loss:0.00003, loss_test:0.11299, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:18.567, tt:482.735\n",
      "Ep:26, loss:0.00003, loss_test:0.11205, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:18.588, tt:501.886\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.11197, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:18.587, tt:520.424\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.11149, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:18.584, tt:538.940\n",
      "Ep:29, loss:0.00002, loss_test:0.11095, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:18.627, tt:558.822\n",
      "Ep:30, loss:0.00002, loss_test:0.11062, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:18.672, tt:578.821\n",
      "Ep:31, loss:0.00002, loss_test:0.10928, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:18.725, tt:599.194\n",
      "Ep:32, loss:0.00002, loss_test:0.10821, lr:1.00e-02, fs:0.72195 (r=0.747,p=0.698),  time:18.778, tt:619.674\n",
      "Ep:33, loss:0.00002, loss_test:0.10730, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:18.807, tt:639.432\n",
      "Ep:34, loss:0.00002, loss_test:0.10684, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:18.813, tt:658.471\n",
      "Ep:35, loss:0.00002, loss_test:0.10613, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:18.845, tt:678.426\n",
      "Ep:36, loss:0.00002, loss_test:0.10513, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:18.828, tt:696.627\n",
      "Ep:37, loss:0.00002, loss_test:0.10453, lr:1.00e-02, fs:0.72816 (r=0.758,p=0.701),  time:18.828, tt:715.466\n",
      "Ep:38, loss:0.00002, loss_test:0.10413, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:18.848, tt:735.064\n",
      "Ep:39, loss:0.00002, loss_test:0.10346, lr:9.90e-03, fs:0.73430 (r=0.768,p=0.704),  time:18.847, tt:753.896\n",
      "Ep:40, loss:0.00002, loss_test:0.10292, lr:9.80e-03, fs:0.73786 (r=0.768,p=0.710),  time:18.869, tt:773.612\n",
      "Ep:41, loss:0.00002, loss_test:0.10232, lr:9.70e-03, fs:0.74396 (r=0.778,p=0.713),  time:18.884, tt:793.112\n",
      "Ep:42, loss:0.00002, loss_test:0.10159, lr:9.61e-03, fs:0.75000 (r=0.788,p=0.716),  time:18.917, tt:813.411\n",
      "Ep:43, loss:0.00002, loss_test:0.10085, lr:9.51e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.929, tt:832.892\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.10033, lr:9.51e-03, fs:0.75000 (r=0.788,p=0.716),  time:18.948, tt:852.658\n",
      "Ep:45, loss:0.00002, loss_test:0.09985, lr:9.51e-03, fs:0.75000 (r=0.788,p=0.716),  time:18.932, tt:870.891\n",
      "Ep:46, loss:0.00002, loss_test:0.09937, lr:9.51e-03, fs:0.75829 (r=0.808,p=0.714),  time:18.958, tt:891.027\n",
      "Ep:47, loss:0.00002, loss_test:0.09883, lr:9.51e-03, fs:0.76329 (r=0.798,p=0.731),  time:18.950, tt:909.606\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09816, lr:9.51e-03, fs:0.75238 (r=0.798,p=0.712),  time:18.957, tt:928.908\n",
      "Ep:49, loss:0.00002, loss_test:0.09779, lr:9.51e-03, fs:0.76555 (r=0.808,p=0.727),  time:18.935, tt:946.732\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.09765, lr:9.51e-03, fs:0.76555 (r=0.808,p=0.727),  time:18.951, tt:966.511\n",
      "Ep:51, loss:0.00001, loss_test:0.09725, lr:9.51e-03, fs:0.76190 (r=0.808,p=0.721),  time:19.023, tt:989.210\n",
      "Ep:52, loss:0.00001, loss_test:0.09672, lr:9.51e-03, fs:0.77143 (r=0.818,p=0.730),  time:19.021, tt:1008.109\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.09622, lr:9.51e-03, fs:0.77725 (r=0.828,p=0.732),  time:19.016, tt:1026.884\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.09620, lr:9.51e-03, fs:0.78095 (r=0.828,p=0.739),  time:19.009, tt:1045.469\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.09610, lr:9.51e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.001, tt:1064.061\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.09495, lr:9.51e-03, fs:0.78469 (r=0.828,p=0.745),  time:19.008, tt:1083.436\n",
      "Ep:57, loss:0.00001, loss_test:0.09452, lr:9.51e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.048, tt:1104.759\n",
      "Ep:58, loss:0.00001, loss_test:0.09455, lr:9.51e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.048, tt:1123.829\n",
      "Ep:59, loss:0.00001, loss_test:0.09447, lr:9.51e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.069, tt:1144.164\n",
      "Ep:60, loss:0.00001, loss_test:0.09388, lr:9.51e-03, fs:0.81188 (r=0.828,p=0.796),  time:19.068, tt:1163.160\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.09260, lr:9.51e-03, fs:0.79621 (r=0.848,p=0.750),  time:19.067, tt:1182.167\n",
      "Ep:62, loss:0.00001, loss_test:0.09262, lr:9.51e-03, fs:0.79227 (r=0.828,p=0.759),  time:19.056, tt:1200.549\n",
      "Ep:63, loss:0.00001, loss_test:0.09224, lr:9.51e-03, fs:0.80000 (r=0.828,p=0.774),  time:19.060, tt:1219.824\n",
      "Ep:64, loss:0.00001, loss_test:0.09152, lr:9.51e-03, fs:0.79621 (r=0.848,p=0.750),  time:19.058, tt:1238.780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.09157, lr:9.51e-03, fs:0.82828 (r=0.828,p=0.828),  time:19.072, tt:1258.746\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.09065, lr:9.51e-03, fs:0.80976 (r=0.838,p=0.783),  time:19.061, tt:1277.100\n",
      "Ep:67, loss:0.00001, loss_test:0.09092, lr:9.51e-03, fs:0.78873 (r=0.848,p=0.737),  time:19.039, tt:1294.675\n",
      "Ep:68, loss:0.00001, loss_test:0.09190, lr:9.51e-03, fs:0.83333 (r=0.808,p=0.860),  time:19.045, tt:1314.073\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09088, lr:9.51e-03, fs:0.83249 (r=0.828,p=0.837),  time:19.047, tt:1333.310\n",
      "Ep:70, loss:0.00001, loss_test:0.09057, lr:9.51e-03, fs:0.78140 (r=0.848,p=0.724),  time:19.032, tt:1351.280\n",
      "Ep:71, loss:0.00001, loss_test:0.08896, lr:9.51e-03, fs:0.81592 (r=0.828,p=0.804),  time:19.027, tt:1369.947\n",
      "Ep:72, loss:0.00001, loss_test:0.08826, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:19.037, tt:1389.707\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.08698, lr:9.51e-03, fs:0.81159 (r=0.848,p=0.778),  time:19.040, tt:1408.961\n",
      "Ep:74, loss:0.00001, loss_test:0.08807, lr:9.51e-03, fs:0.78873 (r=0.848,p=0.737),  time:19.050, tt:1428.723\n",
      "Ep:75, loss:0.00001, loss_test:0.08922, lr:9.51e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.051, tt:1447.846\n",
      "Ep:76, loss:0.00001, loss_test:0.08907, lr:9.51e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.051, tt:1466.904\n",
      "Ep:77, loss:0.00001, loss_test:0.08693, lr:9.51e-03, fs:0.79621 (r=0.848,p=0.750),  time:19.050, tt:1485.879\n",
      "Ep:78, loss:0.00001, loss_test:0.08665, lr:9.51e-03, fs:0.79621 (r=0.848,p=0.750),  time:19.049, tt:1504.882\n",
      "Ep:79, loss:0.00001, loss_test:0.08786, lr:9.51e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.055, tt:1524.406\n",
      "Ep:80, loss:0.00001, loss_test:0.08800, lr:9.51e-03, fs:0.83505 (r=0.818,p=0.853),  time:19.053, tt:1543.301\n",
      "Ep:81, loss:0.00001, loss_test:0.08573, lr:9.51e-03, fs:0.80000 (r=0.848,p=0.757),  time:19.056, tt:1562.609\n",
      "Ep:82, loss:0.00001, loss_test:0.08388, lr:9.51e-03, fs:0.80769 (r=0.848,p=0.771),  time:19.055, tt:1581.603\n",
      "Ep:83, loss:0.00001, loss_test:0.08582, lr:9.51e-03, fs:0.83938 (r=0.818,p=0.862),  time:19.060, tt:1601.046\n",
      "Ep:84, loss:0.00001, loss_test:0.08820, lr:9.41e-03, fs:0.84375 (r=0.818,p=0.871),  time:19.055, tt:1619.680\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.08655, lr:9.41e-03, fs:0.82353 (r=0.848,p=0.800),  time:19.044, tt:1637.772\n",
      "Ep:86, loss:0.00001, loss_test:0.08409, lr:9.41e-03, fs:0.79621 (r=0.848,p=0.750),  time:19.040, tt:1656.446\n",
      "Ep:87, loss:0.00001, loss_test:0.08182, lr:9.41e-03, fs:0.84694 (r=0.838,p=0.856),  time:19.029, tt:1674.573\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.08408, lr:9.41e-03, fs:0.84974 (r=0.828,p=0.872),  time:19.037, tt:1694.250\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.08414, lr:9.41e-03, fs:0.84422 (r=0.848,p=0.840),  time:19.037, tt:1713.294\n",
      "Ep:90, loss:0.00001, loss_test:0.08384, lr:9.41e-03, fs:0.80569 (r=0.859,p=0.759),  time:19.072, tt:1735.577\n",
      "Ep:91, loss:0.00001, loss_test:0.08012, lr:9.41e-03, fs:0.83582 (r=0.848,p=0.824),  time:19.082, tt:1755.513\n",
      "Ep:92, loss:0.00001, loss_test:0.08028, lr:9.41e-03, fs:0.85567 (r=0.838,p=0.874),  time:19.089, tt:1775.271\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.08149, lr:9.41e-03, fs:0.84694 (r=0.838,p=0.856),  time:19.101, tt:1795.535\n",
      "Ep:94, loss:0.00001, loss_test:0.08272, lr:9.41e-03, fs:0.84000 (r=0.848,p=0.832),  time:19.113, tt:1815.742\n",
      "Ep:95, loss:0.00001, loss_test:0.08077, lr:9.41e-03, fs:0.84000 (r=0.848,p=0.832),  time:19.104, tt:1833.965\n",
      "Ep:96, loss:0.00001, loss_test:0.07857, lr:9.41e-03, fs:0.84848 (r=0.848,p=0.848),  time:19.118, tt:1854.401\n",
      "Ep:97, loss:0.00001, loss_test:0.07902, lr:9.41e-03, fs:0.85567 (r=0.838,p=0.874),  time:19.121, tt:1873.811\n",
      "Ep:98, loss:0.00001, loss_test:0.08021, lr:9.41e-03, fs:0.85279 (r=0.848,p=0.857),  time:19.118, tt:1892.654\n",
      "Ep:99, loss:0.00001, loss_test:0.08015, lr:9.41e-03, fs:0.84422 (r=0.848,p=0.840),  time:19.125, tt:1912.550\n",
      "Ep:100, loss:0.00001, loss_test:0.07725, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:19.135, tt:1932.645\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.07641, lr:9.41e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.134, tt:1951.622\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.07725, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:19.142, tt:1971.661\n",
      "Ep:103, loss:0.00001, loss_test:0.07908, lr:9.41e-03, fs:0.85859 (r=0.859,p=0.859),  time:19.148, tt:1991.362\n",
      "Ep:104, loss:0.00001, loss_test:0.07750, lr:9.41e-03, fs:0.85714 (r=0.848,p=0.866),  time:19.157, tt:2011.445\n",
      "Ep:105, loss:0.00001, loss_test:0.07580, lr:9.41e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.162, tt:2031.175\n",
      "Ep:106, loss:0.00001, loss_test:0.07557, lr:9.41e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.184, tt:2052.659\n",
      "Ep:107, loss:0.00001, loss_test:0.07731, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.190, tt:2072.470\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.07747, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.205, tt:2093.364\n",
      "Ep:109, loss:0.00001, loss_test:0.07565, lr:9.41e-03, fs:0.86154 (r=0.848,p=0.875),  time:19.210, tt:2113.074\n",
      "Ep:110, loss:0.00000, loss_test:0.07476, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.222, tt:2133.628\n",
      "Ep:111, loss:0.00000, loss_test:0.07580, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.236, tt:2154.387\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.07718, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.227, tt:2172.699\n",
      "Ep:113, loss:0.00000, loss_test:0.07626, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.228, tt:2192.026\n",
      "Ep:114, loss:0.00000, loss_test:0.07487, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.235, tt:2212.013\n",
      "Ep:115, loss:0.00000, loss_test:0.07493, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.241, tt:2231.912\n",
      "Ep:116, loss:0.00000, loss_test:0.07611, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.305, tt:2258.722\n",
      "Ep:117, loss:0.00000, loss_test:0.07652, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.306, tt:2278.127\n",
      "Ep:118, loss:0.00000, loss_test:0.07498, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.312, tt:2298.167\n",
      "Ep:119, loss:0.00000, loss_test:0.07478, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.321, tt:2318.505\n",
      "Ep:120, loss:0.00000, loss_test:0.07551, lr:9.41e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.326, tt:2338.428\n",
      "Ep:121, loss:0.00000, loss_test:0.07603, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.329, tt:2358.159\n",
      "Ep:122, loss:0.00000, loss_test:0.07494, lr:9.41e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.332, tt:2377.855\n",
      "Ep:123, loss:0.00000, loss_test:0.07454, lr:9.32e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.341, tt:2398.273\n",
      "Ep:124, loss:0.00000, loss_test:0.07501, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.355, tt:2419.340\n",
      "Ep:125, loss:0.00000, loss_test:0.07519, lr:9.14e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.351, tt:2438.207\n",
      "Ep:126, loss:0.00000, loss_test:0.07507, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.347, tt:2457.086\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00000, loss_test:0.07422, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.345, tt:2476.096\n",
      "Ep:128, loss:0.00000, loss_test:0.07418, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.343, tt:2495.243\n",
      "Ep:129, loss:0.00000, loss_test:0.07442, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.333, tt:2513.242\n",
      "Ep:130, loss:0.00000, loss_test:0.07435, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.320, tt:2530.938\n",
      "Ep:131, loss:0.00000, loss_test:0.07409, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.324, tt:2550.725\n",
      "Ep:132, loss:0.00000, loss_test:0.07420, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.334, tt:2571.449\n",
      "Ep:133, loss:0.00000, loss_test:0.07428, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.334, tt:2590.712\n",
      "Ep:134, loss:0.00000, loss_test:0.07417, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.338, tt:2610.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.07382, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.336, tt:2629.734\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.07386, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.348, tt:2650.688\n",
      "Ep:137, loss:0.00000, loss_test:0.07400, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.348, tt:2670.019\n",
      "Ep:138, loss:0.00000, loss_test:0.07369, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.353, tt:2690.098\n",
      "Ep:139, loss:0.00000, loss_test:0.07361, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.355, tt:2709.671\n",
      "Ep:140, loss:0.00000, loss_test:0.07369, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.356, tt:2729.235\n",
      "Ep:141, loss:0.00000, loss_test:0.07390, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.354, tt:2748.202\n",
      "Ep:142, loss:0.00000, loss_test:0.07372, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.364, tt:2769.089\n",
      "Ep:143, loss:0.00000, loss_test:0.07339, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.369, tt:2789.119\n",
      "Ep:144, loss:0.00000, loss_test:0.07337, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.364, tt:2807.756\n",
      "Ep:145, loss:0.00000, loss_test:0.07365, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.361, tt:2826.682\n",
      "Ep:146, loss:0.00000, loss_test:0.07350, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.361, tt:2846.110\n",
      "Ep:147, loss:0.00000, loss_test:0.07298, lr:8.95e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.365, tt:2866.020\n",
      "Ep:148, loss:0.00000, loss_test:0.07307, lr:8.86e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.358, tt:2884.378\n",
      "Ep:149, loss:0.00000, loss_test:0.07324, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.412, tt:2911.760\n",
      "Ep:150, loss:0.00000, loss_test:0.07451, lr:8.69e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.408, tt:2930.599\n",
      "Ep:151, loss:0.00000, loss_test:0.07454, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.417, tt:2951.458\n",
      "##########Best model found so far##########\n",
      "Ep:152, loss:0.00000, loss_test:0.07281, lr:8.60e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.422, tt:2971.592\n",
      "Ep:153, loss:0.00000, loss_test:0.07272, lr:8.60e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.426, tt:2991.602\n",
      "Ep:154, loss:0.00000, loss_test:0.07542, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.430, tt:3011.689\n",
      "Ep:155, loss:0.00000, loss_test:0.07658, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.435, tt:3031.936\n",
      "Ep:156, loss:0.00000, loss_test:0.07375, lr:8.60e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.443, tt:3052.492\n",
      "Ep:157, loss:0.00000, loss_test:0.07284, lr:8.60e-03, fs:0.86735 (r=0.859,p=0.876),  time:19.444, tt:3072.099\n",
      "Ep:158, loss:0.00000, loss_test:0.07565, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.450, tt:3092.574\n",
      "Ep:159, loss:0.00000, loss_test:0.07879, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.451, tt:3112.088\n",
      "Ep:160, loss:0.00000, loss_test:0.07659, lr:8.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.452, tt:3131.746\n",
      "Ep:161, loss:0.00000, loss_test:0.07309, lr:8.60e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.447, tt:3150.336\n",
      "Ep:162, loss:0.00000, loss_test:0.07241, lr:8.60e-03, fs:0.87179 (r=0.859,p=0.885),  time:19.450, tt:3170.310\n",
      "Ep:163, loss:0.00000, loss_test:0.07470, lr:8.51e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.458, tt:3191.160\n",
      "Ep:164, loss:0.00000, loss_test:0.07809, lr:8.43e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.465, tt:3211.647\n",
      "Ep:165, loss:0.00000, loss_test:0.07663, lr:8.35e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.480, tt:3233.705\n",
      "Ep:166, loss:0.00000, loss_test:0.07339, lr:8.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.491, tt:3255.064\n",
      "Ep:167, loss:0.00000, loss_test:0.07239, lr:8.18e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.500, tt:3276.012\n",
      "Ep:168, loss:0.00000, loss_test:0.07386, lr:8.10e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.497, tt:3295.064\n",
      "Ep:169, loss:0.00000, loss_test:0.07641, lr:8.02e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.496, tt:3314.237\n",
      "Ep:170, loss:0.00000, loss_test:0.07633, lr:7.94e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.499, tt:3334.260\n",
      "Ep:171, loss:0.00000, loss_test:0.07445, lr:7.86e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.506, tt:3354.952\n",
      "Ep:172, loss:0.00000, loss_test:0.07346, lr:7.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.518, tt:3376.677\n",
      "Ep:173, loss:0.00000, loss_test:0.07383, lr:7.70e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.528, tt:3397.876\n",
      "Ep:174, loss:0.00000, loss_test:0.07486, lr:7.62e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.536, tt:3418.815\n",
      "Ep:175, loss:0.00000, loss_test:0.07522, lr:7.55e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.546, tt:3440.022\n",
      "Ep:176, loss:0.00000, loss_test:0.07501, lr:7.47e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.548, tt:3459.917\n",
      "Ep:177, loss:0.00000, loss_test:0.07476, lr:7.40e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.552, tt:3480.280\n",
      "Ep:178, loss:0.00000, loss_test:0.07388, lr:7.32e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.554, tt:3500.190\n",
      "Ep:179, loss:0.00000, loss_test:0.07391, lr:7.25e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.560, tt:3520.722\n",
      "Ep:180, loss:0.00000, loss_test:0.07477, lr:7.18e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.561, tt:3540.514\n",
      "Ep:181, loss:0.00000, loss_test:0.07577, lr:7.11e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.564, tt:3560.601\n",
      "Ep:182, loss:0.00000, loss_test:0.07516, lr:7.03e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.571, tt:3581.563\n",
      "Ep:183, loss:0.00000, loss_test:0.07386, lr:6.96e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.576, tt:3602.004\n",
      "Ep:184, loss:0.00000, loss_test:0.07308, lr:6.89e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.582, tt:3622.604\n",
      "Ep:185, loss:0.00000, loss_test:0.07445, lr:6.83e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.589, tt:3643.586\n",
      "Ep:186, loss:0.00000, loss_test:0.07584, lr:6.76e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.593, tt:3663.966\n",
      "Ep:187, loss:0.00000, loss_test:0.07591, lr:6.69e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.599, tt:3684.706\n",
      "Ep:188, loss:0.00000, loss_test:0.07457, lr:6.62e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.611, tt:3706.444\n",
      "Ep:189, loss:0.00000, loss_test:0.07398, lr:6.56e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.613, tt:3726.543\n",
      "Ep:190, loss:0.00000, loss_test:0.07435, lr:6.49e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.627, tt:3748.850\n",
      "Ep:191, loss:0.00000, loss_test:0.07464, lr:6.43e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.638, tt:3770.524\n",
      "Ep:192, loss:0.00000, loss_test:0.07479, lr:6.36e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.639, tt:3790.295\n",
      "Ep:193, loss:0.00000, loss_test:0.07571, lr:6.30e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.641, tt:3810.450\n",
      "Ep:194, loss:0.00000, loss_test:0.07583, lr:6.24e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.649, tt:3831.569\n",
      "Ep:195, loss:0.00000, loss_test:0.07500, lr:6.17e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.655, tt:3852.454\n",
      "Ep:196, loss:0.00000, loss_test:0.07425, lr:6.11e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.660, tt:3873.078\n",
      "Ep:197, loss:0.00000, loss_test:0.07442, lr:6.05e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.667, tt:3894.142\n",
      "Ep:198, loss:0.00000, loss_test:0.07503, lr:5.99e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.671, tt:3914.454\n",
      "Ep:199, loss:0.00000, loss_test:0.07530, lr:5.93e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.675, tt:3935.056\n",
      "Ep:200, loss:0.00000, loss_test:0.07513, lr:5.87e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.680, tt:3955.663\n",
      "Ep:201, loss:0.00000, loss_test:0.07481, lr:5.81e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.686, tt:3976.577\n",
      "Ep:202, loss:0.00000, loss_test:0.07471, lr:5.75e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.697, tt:3998.459\n",
      "Ep:203, loss:0.00000, loss_test:0.07468, lr:5.70e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.698, tt:4018.343\n",
      "Ep:204, loss:0.00000, loss_test:0.07450, lr:5.64e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.703, tt:4039.119\n",
      "Ep:205, loss:0.00000, loss_test:0.07495, lr:5.58e-03, fs:0.87629 (r=0.859,p=0.895),  time:19.709, tt:4060.078\n",
      "Ep:206, loss:0.00000, loss_test:0.07592, lr:5.53e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.722, tt:4082.550\n",
      "Ep:207, loss:0.00000, loss_test:0.07581, lr:5.47e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.726, tt:4102.904\n",
      "Ep:208, loss:0.00000, loss_test:0.07502, lr:5.42e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.727, tt:4122.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:209, loss:0.00000, loss_test:0.07417, lr:5.36e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.733, tt:4143.907\n",
      "Ep:210, loss:0.00000, loss_test:0.07444, lr:5.31e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.735, tt:4164.154\n",
      "Ep:211, loss:0.00000, loss_test:0.07548, lr:5.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.736, tt:4184.097\n",
      "Ep:212, loss:0.00000, loss_test:0.07614, lr:5.20e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.738, tt:4204.155\n",
      "Ep:213, loss:0.00000, loss_test:0.07581, lr:5.15e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.738, tt:4224.029\n",
      "Ep:214, loss:0.00000, loss_test:0.07490, lr:5.10e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.760, tt:4248.488\n",
      "Ep:215, loss:0.00000, loss_test:0.07470, lr:5.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.760, tt:4268.090\n",
      "Ep:216, loss:0.00000, loss_test:0.07537, lr:5.00e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.763, tt:4288.528\n",
      "Ep:217, loss:0.00000, loss_test:0.07601, lr:4.95e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.765, tt:4308.815\n",
      "Ep:218, loss:0.00000, loss_test:0.07595, lr:4.90e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.770, tt:4329.639\n",
      "Ep:219, loss:0.00000, loss_test:0.07538, lr:4.85e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.777, tt:4350.882\n",
      "Ep:220, loss:0.00000, loss_test:0.07521, lr:4.80e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.782, tt:4371.900\n",
      "Ep:221, loss:0.00000, loss_test:0.07548, lr:4.75e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.782, tt:4391.523\n",
      "Ep:222, loss:0.00000, loss_test:0.07577, lr:4.71e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.782, tt:4411.464\n",
      "Ep:223, loss:0.00000, loss_test:0.07585, lr:4.66e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.785, tt:4431.730\n",
      "Ep:224, loss:0.00000, loss_test:0.07580, lr:4.61e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.788, tt:4452.205\n",
      "Ep:225, loss:0.00000, loss_test:0.07559, lr:4.57e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.785, tt:4471.449\n",
      "Ep:226, loss:0.00000, loss_test:0.07573, lr:4.52e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.787, tt:4491.758\n",
      "Ep:227, loss:0.00000, loss_test:0.07582, lr:4.48e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.777, tt:4509.079\n",
      "Ep:228, loss:0.00000, loss_test:0.07569, lr:4.43e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.775, tt:4528.579\n",
      "Ep:229, loss:0.00000, loss_test:0.07579, lr:4.39e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.777, tt:4548.740\n",
      "Ep:230, loss:0.00000, loss_test:0.07592, lr:4.34e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.776, tt:4568.242\n",
      "Ep:231, loss:0.00000, loss_test:0.07601, lr:4.30e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.775, tt:4587.842\n",
      "Ep:232, loss:0.00000, loss_test:0.07588, lr:4.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.773, tt:4607.214\n",
      "Ep:233, loss:0.00000, loss_test:0.07563, lr:4.21e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.774, tt:4627.128\n",
      "Ep:234, loss:0.00000, loss_test:0.07561, lr:4.17e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.769, tt:4645.619\n",
      "Ep:235, loss:0.00000, loss_test:0.07572, lr:4.13e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.766, tt:4664.705\n",
      "Ep:236, loss:0.00000, loss_test:0.07605, lr:4.09e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.767, tt:4684.824\n",
      "Ep:237, loss:0.00000, loss_test:0.07625, lr:4.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.769, tt:4705.035\n",
      "Ep:238, loss:0.00000, loss_test:0.07617, lr:4.01e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.766, tt:4724.042\n",
      "Ep:239, loss:0.00000, loss_test:0.07608, lr:3.97e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.765, tt:4743.618\n",
      "Ep:240, loss:0.00000, loss_test:0.07599, lr:3.93e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.764, tt:4763.181\n",
      "Ep:241, loss:0.00000, loss_test:0.07620, lr:3.89e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.768, tt:4783.848\n",
      "Ep:242, loss:0.00000, loss_test:0.07612, lr:3.85e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.771, tt:4804.391\n",
      "Ep:243, loss:0.00000, loss_test:0.07589, lr:3.81e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.768, tt:4823.311\n",
      "Ep:244, loss:0.00000, loss_test:0.07622, lr:3.77e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.771, tt:4843.963\n",
      "Ep:245, loss:0.00000, loss_test:0.07645, lr:3.73e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.770, tt:4863.464\n",
      "Ep:246, loss:0.00000, loss_test:0.07631, lr:3.70e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.771, tt:4883.380\n",
      "Ep:247, loss:0.00000, loss_test:0.07591, lr:3.66e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.772, tt:4903.564\n",
      "Ep:248, loss:0.00000, loss_test:0.07645, lr:3.62e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.780, tt:4925.323\n",
      "Ep:249, loss:0.00000, loss_test:0.07679, lr:3.59e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.774, tt:4943.626\n",
      "Ep:250, loss:0.00000, loss_test:0.07680, lr:3.55e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.772, tt:4962.780\n",
      "Ep:251, loss:0.00000, loss_test:0.07655, lr:3.52e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.768, tt:4981.544\n",
      "Ep:252, loss:0.00000, loss_test:0.07629, lr:3.48e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.766, tt:5000.886\n",
      "Ep:253, loss:0.00000, loss_test:0.07627, lr:3.45e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.773, tt:5022.384\n",
      "Ep:254, loss:0.00000, loss_test:0.07624, lr:3.41e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.791, tt:5046.825\n",
      "Ep:255, loss:0.00000, loss_test:0.07616, lr:3.38e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.791, tt:5066.555\n",
      "Ep:256, loss:0.00000, loss_test:0.07621, lr:3.34e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.783, tt:5084.345\n",
      "Ep:257, loss:0.00000, loss_test:0.07681, lr:3.31e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.785, tt:5104.576\n",
      "Ep:258, loss:0.00000, loss_test:0.07700, lr:3.28e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.783, tt:5123.670\n",
      "Ep:259, loss:0.00000, loss_test:0.07679, lr:3.24e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.779, tt:5142.601\n",
      "Ep:260, loss:0.00000, loss_test:0.07637, lr:3.21e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.780, tt:5162.571\n",
      "Ep:261, loss:0.00000, loss_test:0.07619, lr:3.18e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.781, tt:5182.608\n",
      "Ep:262, loss:0.00000, loss_test:0.07681, lr:3.15e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.777, tt:5201.362\n",
      "Ep:263, loss:0.00000, loss_test:0.07715, lr:3.12e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.774, tt:5220.325\n",
      "Ep:264, loss:0.00000, loss_test:0.07717, lr:3.09e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.772, tt:5239.545\n",
      "Ep:265, loss:0.00000, loss_test:0.07689, lr:3.05e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.771, tt:5259.174\n",
      "Ep:266, loss:0.00000, loss_test:0.07648, lr:3.02e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.765, tt:5277.349\n",
      "Ep:267, loss:0.00000, loss_test:0.07646, lr:2.99e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.766, tt:5297.227\n",
      "Ep:268, loss:0.00000, loss_test:0.07657, lr:2.96e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.765, tt:5316.756\n",
      "Ep:269, loss:0.00000, loss_test:0.07663, lr:2.93e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.766, tt:5336.779\n",
      "Ep:270, loss:0.00000, loss_test:0.07669, lr:2.90e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.769, tt:5357.291\n",
      "Ep:271, loss:0.00000, loss_test:0.07680, lr:2.88e-03, fs:0.88083 (r=0.859,p=0.904),  time:19.770, tt:5377.426\n",
      "Ep:272, loss:0.00000, loss_test:0.07700, lr:2.85e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.773, tt:5398.162\n",
      "Ep:273, loss:0.00000, loss_test:0.07703, lr:2.82e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.776, tt:5418.513\n",
      "Ep:274, loss:0.00000, loss_test:0.07687, lr:2.79e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.769, tt:5436.516\n",
      "Ep:275, loss:0.00000, loss_test:0.07680, lr:2.76e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.772, tt:5456.965\n",
      "Ep:276, loss:0.00000, loss_test:0.07685, lr:2.73e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.772, tt:5476.884\n",
      "Ep:277, loss:0.00000, loss_test:0.07695, lr:2.71e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.774, tt:5497.253\n",
      "Ep:278, loss:0.00000, loss_test:0.07711, lr:2.68e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.778, tt:5518.063\n",
      "Ep:279, loss:0.00000, loss_test:0.07712, lr:2.65e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.775, tt:5536.967\n",
      "Ep:280, loss:0.00000, loss_test:0.07704, lr:2.63e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.775, tt:5556.903\n",
      "Ep:281, loss:0.00000, loss_test:0.07697, lr:2.60e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.779, tt:5577.617\n",
      "Ep:282, loss:0.00000, loss_test:0.07704, lr:2.57e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.782, tt:5598.280\n",
      "Ep:283, loss:0.00000, loss_test:0.07717, lr:2.55e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.785, tt:5619.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:284, loss:0.00000, loss_test:0.07713, lr:2.52e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.784, tt:5638.471\n",
      "Ep:285, loss:0.00000, loss_test:0.07692, lr:2.50e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.789, tt:5659.689\n",
      "Ep:286, loss:0.00000, loss_test:0.07683, lr:2.47e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.792, tt:5680.317\n",
      "Ep:287, loss:0.00000, loss_test:0.07699, lr:2.45e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.791, tt:5699.796\n",
      "Ep:288, loss:0.00000, loss_test:0.07713, lr:2.42e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.793, tt:5720.060\n",
      "Ep:289, loss:0.00000, loss_test:0.07712, lr:2.40e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.798, tt:5741.474\n",
      "Ep:290, loss:0.00000, loss_test:0.07704, lr:2.38e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.800, tt:5761.871\n",
      "Ep:291, loss:0.00000, loss_test:0.07719, lr:2.35e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.800, tt:5781.466\n",
      "Ep:292, loss:0.00000, loss_test:0.07724, lr:2.33e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.802, tt:5802.116\n",
      "Ep:293, loss:0.00000, loss_test:0.07719, lr:2.31e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.810, tt:5824.183\n",
      "Ep:294, loss:0.00000, loss_test:0.07710, lr:2.28e-03, fs:0.88542 (r=0.859,p=0.914),  time:19.812, tt:5844.675\n",
      "Ep:295, loss:0.00000, loss_test:0.07728, lr:2.26e-03, fs:0.87958 (r=0.848,p=0.913),  time:19.804, tt:5862.001\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13917, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:12.397, tt:12.397\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13856, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:14.291, tt:28.583\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.13764, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:15.077, tt:45.230\n",
      "Ep:3, loss:0.00004, loss_test:0.13634, lr:1.00e-02, fs:0.67128 (r=0.980,p=0.511),  time:15.415, tt:61.661\n",
      "Ep:4, loss:0.00004, loss_test:0.13460, lr:1.00e-02, fs:0.67845 (r=0.970,p=0.522),  time:15.682, tt:78.408\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13266, lr:1.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:15.686, tt:94.116\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13043, lr:1.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:15.956, tt:111.690\n",
      "Ep:7, loss:0.00004, loss_test:0.12913, lr:1.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:16.118, tt:128.941\n",
      "Ep:8, loss:0.00004, loss_test:0.12860, lr:1.00e-02, fs:0.66667 (r=0.848,p=0.549),  time:16.237, tt:146.133\n",
      "Ep:9, loss:0.00004, loss_test:0.12831, lr:1.00e-02, fs:0.65041 (r=0.808,p=0.544),  time:16.294, tt:162.941\n",
      "Ep:10, loss:0.00003, loss_test:0.12734, lr:1.00e-02, fs:0.64706 (r=0.778,p=0.554),  time:16.429, tt:180.717\n",
      "Ep:11, loss:0.00003, loss_test:0.12523, lr:1.00e-02, fs:0.64378 (r=0.758,p=0.560),  time:16.524, tt:198.294\n",
      "Ep:12, loss:0.00003, loss_test:0.12305, lr:1.00e-02, fs:0.65517 (r=0.768,p=0.571),  time:16.555, tt:215.220\n",
      "Ep:13, loss:0.00003, loss_test:0.12127, lr:1.00e-02, fs:0.65812 (r=0.778,p=0.570),  time:16.578, tt:232.088\n",
      "Ep:14, loss:0.00003, loss_test:0.12018, lr:1.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:16.608, tt:249.125\n",
      "Ep:15, loss:0.00003, loss_test:0.11932, lr:1.00e-02, fs:0.66946 (r=0.808,p=0.571),  time:16.575, tt:265.199\n",
      "Ep:16, loss:0.00003, loss_test:0.11822, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:16.595, tt:282.115\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.11670, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:16.590, tt:298.613\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.11554, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:16.630, tt:315.965\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11447, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:16.639, tt:332.781\n",
      "Ep:20, loss:0.00003, loss_test:0.11334, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:16.696, tt:350.608\n",
      "Ep:21, loss:0.00003, loss_test:0.11230, lr:1.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:16.736, tt:368.187\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.11150, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:16.813, tt:386.695\n",
      "Ep:23, loss:0.00003, loss_test:0.11071, lr:1.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:16.803, tt:403.281\n",
      "Ep:24, loss:0.00003, loss_test:0.10994, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:16.810, tt:420.240\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.10909, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:17.019, tt:442.504\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10797, lr:1.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:17.023, tt:459.633\n",
      "Ep:27, loss:0.00003, loss_test:0.10692, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:17.033, tt:476.927\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.10607, lr:1.00e-02, fs:0.71552 (r=0.838,p=0.624),  time:17.072, tt:495.096\n",
      "Ep:29, loss:0.00003, loss_test:0.10546, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:17.091, tt:512.743\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.10492, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:17.148, tt:531.598\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.10424, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:17.188, tt:550.005\n",
      "Ep:32, loss:0.00002, loss_test:0.10352, lr:1.00e-02, fs:0.72489 (r=0.838,p=0.638),  time:17.162, tt:566.352\n",
      "Ep:33, loss:0.00002, loss_test:0.10290, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:17.142, tt:582.831\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.10246, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:17.140, tt:599.884\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.10215, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:17.165, tt:617.957\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10203, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:17.204, tt:636.556\n",
      "Ep:37, loss:0.00002, loss_test:0.10213, lr:1.00e-02, fs:0.74336 (r=0.848,p=0.661),  time:17.210, tt:653.971\n",
      "Ep:38, loss:0.00002, loss_test:0.10223, lr:1.00e-02, fs:0.71818 (r=0.798,p=0.653),  time:17.214, tt:671.365\n",
      "Ep:39, loss:0.00002, loss_test:0.10205, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:17.259, tt:690.370\n",
      "Ep:40, loss:0.00002, loss_test:0.10159, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:17.297, tt:709.197\n",
      "Ep:41, loss:0.00002, loss_test:0.10103, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:17.328, tt:727.783\n",
      "Ep:42, loss:0.00002, loss_test:0.10073, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:17.334, tt:745.364\n",
      "Ep:43, loss:0.00002, loss_test:0.10056, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:17.354, tt:763.571\n",
      "Ep:44, loss:0.00002, loss_test:0.10020, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:17.374, tt:781.822\n",
      "Ep:45, loss:0.00002, loss_test:0.09971, lr:1.00e-02, fs:0.71889 (r=0.788,p=0.661),  time:17.381, tt:799.525\n",
      "Ep:46, loss:0.00002, loss_test:0.09929, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:17.404, tt:817.993\n",
      "Ep:47, loss:0.00002, loss_test:0.09875, lr:9.90e-03, fs:0.72146 (r=0.798,p=0.658),  time:17.427, tt:836.512\n",
      "Ep:48, loss:0.00002, loss_test:0.09813, lr:9.80e-03, fs:0.72477 (r=0.798,p=0.664),  time:17.466, tt:855.855\n",
      "Ep:49, loss:0.00002, loss_test:0.09743, lr:9.70e-03, fs:0.73059 (r=0.808,p=0.667),  time:17.500, tt:874.986\n",
      "Ep:50, loss:0.00002, loss_test:0.09685, lr:9.61e-03, fs:0.73059 (r=0.808,p=0.667),  time:17.536, tt:894.313\n",
      "Ep:51, loss:0.00002, loss_test:0.09662, lr:9.51e-03, fs:0.73636 (r=0.818,p=0.669),  time:17.579, tt:914.126\n",
      "Ep:52, loss:0.00002, loss_test:0.09641, lr:9.41e-03, fs:0.73394 (r=0.808,p=0.672),  time:17.591, tt:932.317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00002, loss_test:0.09619, lr:9.32e-03, fs:0.73394 (r=0.808,p=0.672),  time:17.615, tt:951.233\n",
      "Ep:54, loss:0.00002, loss_test:0.09582, lr:9.23e-03, fs:0.74654 (r=0.818,p=0.686),  time:17.619, tt:969.036\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.09519, lr:9.23e-03, fs:0.75000 (r=0.818,p=0.692),  time:17.640, tt:987.831\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.09474, lr:9.23e-03, fs:0.75117 (r=0.808,p=0.702),  time:17.662, tt:1006.747\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.09439, lr:9.23e-03, fs:0.75117 (r=0.808,p=0.702),  time:17.687, tt:1025.841\n",
      "Ep:58, loss:0.00002, loss_test:0.09390, lr:9.23e-03, fs:0.75701 (r=0.818,p=0.704),  time:17.710, tt:1044.883\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.09324, lr:9.23e-03, fs:0.75701 (r=0.818,p=0.704),  time:17.708, tt:1062.467\n",
      "Ep:60, loss:0.00002, loss_test:0.09271, lr:9.23e-03, fs:0.76056 (r=0.818,p=0.711),  time:17.713, tt:1080.475\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.09259, lr:9.23e-03, fs:0.75701 (r=0.818,p=0.704),  time:17.741, tt:1099.918\n",
      "Ep:62, loss:0.00001, loss_test:0.09238, lr:9.23e-03, fs:0.75926 (r=0.828,p=0.701),  time:17.746, tt:1118.029\n",
      "Ep:63, loss:0.00001, loss_test:0.09189, lr:9.23e-03, fs:0.76995 (r=0.828,p=0.719),  time:17.762, tt:1136.776\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09168, lr:9.23e-03, fs:0.76995 (r=0.828,p=0.719),  time:17.772, tt:1155.154\n",
      "Ep:65, loss:0.00001, loss_test:0.09161, lr:9.23e-03, fs:0.76995 (r=0.828,p=0.719),  time:17.762, tt:1172.308\n",
      "Ep:66, loss:0.00001, loss_test:0.09153, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:17.770, tt:1190.575\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.09107, lr:9.23e-03, fs:0.77358 (r=0.828,p=0.726),  time:17.771, tt:1208.395\n",
      "Ep:68, loss:0.00001, loss_test:0.09050, lr:9.23e-03, fs:0.78302 (r=0.838,p=0.735),  time:17.779, tt:1226.776\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09052, lr:9.23e-03, fs:0.77570 (r=0.838,p=0.722),  time:17.782, tt:1244.720\n",
      "Ep:70, loss:0.00001, loss_test:0.09003, lr:9.23e-03, fs:0.77934 (r=0.838,p=0.728),  time:17.784, tt:1262.691\n",
      "Ep:71, loss:0.00001, loss_test:0.08938, lr:9.23e-03, fs:0.77934 (r=0.838,p=0.728),  time:17.802, tt:1281.746\n",
      "Ep:72, loss:0.00001, loss_test:0.08922, lr:9.23e-03, fs:0.77934 (r=0.838,p=0.728),  time:17.809, tt:1300.059\n",
      "Ep:73, loss:0.00001, loss_test:0.08854, lr:9.23e-03, fs:0.77934 (r=0.838,p=0.728),  time:17.817, tt:1318.474\n",
      "Ep:74, loss:0.00001, loss_test:0.08777, lr:9.23e-03, fs:0.79048 (r=0.838,p=0.748),  time:17.814, tt:1336.084\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.08765, lr:9.23e-03, fs:0.79048 (r=0.838,p=0.748),  time:17.820, tt:1354.302\n",
      "Ep:76, loss:0.00001, loss_test:0.08743, lr:9.23e-03, fs:0.78873 (r=0.848,p=0.737),  time:17.819, tt:1372.072\n",
      "Ep:77, loss:0.00001, loss_test:0.08648, lr:9.23e-03, fs:0.79426 (r=0.838,p=0.755),  time:17.814, tt:1389.502\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.08609, lr:9.23e-03, fs:0.79426 (r=0.838,p=0.755),  time:17.817, tt:1407.559\n",
      "Ep:79, loss:0.00001, loss_test:0.08606, lr:9.23e-03, fs:0.80000 (r=0.848,p=0.757),  time:17.803, tt:1424.277\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.08531, lr:9.23e-03, fs:0.79808 (r=0.838,p=0.761),  time:17.807, tt:1442.334\n",
      "Ep:81, loss:0.00001, loss_test:0.08512, lr:9.23e-03, fs:0.79808 (r=0.838,p=0.761),  time:17.798, tt:1459.409\n",
      "Ep:82, loss:0.00001, loss_test:0.08497, lr:9.23e-03, fs:0.80769 (r=0.848,p=0.771),  time:17.792, tt:1476.737\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.08464, lr:9.23e-03, fs:0.80193 (r=0.838,p=0.769),  time:17.783, tt:1493.800\n",
      "Ep:84, loss:0.00001, loss_test:0.08424, lr:9.23e-03, fs:0.80769 (r=0.848,p=0.771),  time:17.792, tt:1512.331\n",
      "Ep:85, loss:0.00001, loss_test:0.08343, lr:9.23e-03, fs:0.81159 (r=0.848,p=0.778),  time:17.785, tt:1529.477\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.08437, lr:9.23e-03, fs:0.80769 (r=0.848,p=0.771),  time:17.789, tt:1547.649\n",
      "Ep:87, loss:0.00001, loss_test:0.08252, lr:9.23e-03, fs:0.81159 (r=0.848,p=0.778),  time:17.785, tt:1565.085\n",
      "Ep:88, loss:0.00001, loss_test:0.08261, lr:9.23e-03, fs:0.80000 (r=0.848,p=0.757),  time:17.779, tt:1582.356\n",
      "Ep:89, loss:0.00001, loss_test:0.08240, lr:9.23e-03, fs:0.80976 (r=0.838,p=0.783),  time:17.762, tt:1598.588\n",
      "Ep:90, loss:0.00001, loss_test:0.08181, lr:9.23e-03, fs:0.81553 (r=0.848,p=0.785),  time:17.763, tt:1616.420\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.08141, lr:9.23e-03, fs:0.80569 (r=0.859,p=0.759),  time:17.767, tt:1634.580\n",
      "Ep:92, loss:0.00001, loss_test:0.08065, lr:9.23e-03, fs:0.82353 (r=0.848,p=0.800),  time:17.766, tt:1652.201\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.08104, lr:9.23e-03, fs:0.81951 (r=0.848,p=0.792),  time:17.757, tt:1669.146\n",
      "Ep:94, loss:0.00001, loss_test:0.08029, lr:9.23e-03, fs:0.80569 (r=0.859,p=0.759),  time:17.752, tt:1686.430\n",
      "Ep:95, loss:0.00001, loss_test:0.08004, lr:9.23e-03, fs:0.82353 (r=0.848,p=0.800),  time:17.737, tt:1702.795\n",
      "Ep:96, loss:0.00001, loss_test:0.07943, lr:9.23e-03, fs:0.83582 (r=0.848,p=0.824),  time:17.727, tt:1719.529\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.07896, lr:9.23e-03, fs:0.82126 (r=0.859,p=0.787),  time:17.713, tt:1735.893\n",
      "Ep:98, loss:0.00001, loss_test:0.07873, lr:9.23e-03, fs:0.82524 (r=0.859,p=0.794),  time:17.713, tt:1753.627\n",
      "Ep:99, loss:0.00001, loss_test:0.07948, lr:9.23e-03, fs:0.83168 (r=0.848,p=0.816),  time:17.698, tt:1769.782\n",
      "Ep:100, loss:0.00001, loss_test:0.07823, lr:9.23e-03, fs:0.83744 (r=0.859,p=0.817),  time:17.683, tt:1785.945\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.07777, lr:9.23e-03, fs:0.82927 (r=0.859,p=0.802),  time:17.680, tt:1803.399\n",
      "Ep:102, loss:0.00001, loss_test:0.07982, lr:9.23e-03, fs:0.83333 (r=0.859,p=0.810),  time:17.671, tt:1820.133\n",
      "Ep:103, loss:0.00001, loss_test:0.07658, lr:9.23e-03, fs:0.83582 (r=0.848,p=0.824),  time:17.670, tt:1837.698\n",
      "Ep:104, loss:0.00001, loss_test:0.07673, lr:9.23e-03, fs:0.83333 (r=0.859,p=0.810),  time:17.676, tt:1855.993\n",
      "Ep:105, loss:0.00001, loss_test:0.07751, lr:9.23e-03, fs:0.83744 (r=0.859,p=0.817),  time:17.679, tt:1873.925\n",
      "Ep:106, loss:0.00001, loss_test:0.07554, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.682, tt:1891.981\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.07874, lr:9.23e-03, fs:0.83333 (r=0.859,p=0.810),  time:17.670, tt:1908.351\n",
      "Ep:108, loss:0.00001, loss_test:0.07419, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.663, tt:1925.278\n",
      "Ep:109, loss:0.00001, loss_test:0.07704, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.656, tt:1942.193\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00001, loss_test:0.07639, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.656, tt:1959.784\n",
      "Ep:111, loss:0.00001, loss_test:0.07372, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.649, tt:1976.697\n",
      "Ep:112, loss:0.00001, loss_test:0.07940, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.641, tt:1993.424\n",
      "Ep:113, loss:0.00001, loss_test:0.07342, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.636, tt:2010.559\n",
      "Ep:114, loss:0.00001, loss_test:0.07605, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.637, tt:2028.240\n",
      "Ep:115, loss:0.00001, loss_test:0.07552, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.639, tt:2046.138\n",
      "Ep:116, loss:0.00001, loss_test:0.07301, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.644, tt:2064.390\n",
      "Ep:117, loss:0.00001, loss_test:0.07678, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.636, tt:2081.052\n",
      "Ep:118, loss:0.00001, loss_test:0.07393, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.634, tt:2098.387\n",
      "Ep:119, loss:0.00001, loss_test:0.07242, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.633, tt:2115.984\n",
      "Ep:120, loss:0.00001, loss_test:0.07666, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.630, tt:2133.189\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.07323, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.615, tt:2149.030\n",
      "Ep:122, loss:0.00001, loss_test:0.07199, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.608, tt:2165.792\n",
      "Ep:123, loss:0.00001, loss_test:0.07774, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.606, tt:2183.156\n",
      "Ep:124, loss:0.00001, loss_test:0.07260, lr:9.23e-03, fs:0.85859 (r=0.859,p=0.859),  time:17.605, tt:2200.615\n",
      "Ep:125, loss:0.00001, loss_test:0.07422, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.589, tt:2216.238\n",
      "Ep:126, loss:0.00001, loss_test:0.07478, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.592, tt:2234.134\n",
      "Ep:127, loss:0.00001, loss_test:0.07219, lr:9.23e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.597, tt:2252.426\n",
      "Ep:128, loss:0.00001, loss_test:0.07535, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.595, tt:2269.690\n",
      "Ep:129, loss:0.00001, loss_test:0.07492, lr:9.23e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.595, tt:2287.331\n",
      "Ep:130, loss:0.00001, loss_test:0.07087, lr:9.23e-03, fs:0.83333 (r=0.859,p=0.810),  time:17.583, tt:2303.414\n",
      "Ep:131, loss:0.00001, loss_test:0.07392, lr:9.23e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.588, tt:2321.586\n",
      "##########Best model found so far##########\n",
      "Ep:132, loss:0.00001, loss_test:0.07653, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.594, tt:2340.043\n",
      "Ep:133, loss:0.00001, loss_test:0.07057, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.598, tt:2358.170\n",
      "Ep:134, loss:0.00001, loss_test:0.07224, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.616, tt:2378.136\n",
      "Ep:135, loss:0.00000, loss_test:0.07711, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.612, tt:2395.180\n",
      "Ep:136, loss:0.00000, loss_test:0.07266, lr:9.23e-03, fs:0.86598 (r=0.848,p=0.884),  time:17.612, tt:2412.881\n",
      "Ep:137, loss:0.00000, loss_test:0.07211, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.617, tt:2431.152\n",
      "Ep:138, loss:0.00000, loss_test:0.07269, lr:9.23e-03, fs:0.85427 (r=0.859,p=0.850),  time:17.626, tt:2449.975\n",
      "Ep:139, loss:0.00000, loss_test:0.07231, lr:9.23e-03, fs:0.87629 (r=0.859,p=0.895),  time:17.632, tt:2468.498\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00000, loss_test:0.07240, lr:9.23e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.642, tt:2487.523\n",
      "Ep:141, loss:0.00000, loss_test:0.07165, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:17.656, tt:2507.117\n",
      "Ep:142, loss:0.00000, loss_test:0.07014, lr:9.23e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.663, tt:2525.829\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00000, loss_test:0.07435, lr:9.23e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.666, tt:2543.919\n",
      "Ep:144, loss:0.00000, loss_test:0.07464, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.677, tt:2563.214\n",
      "Ep:145, loss:0.00000, loss_test:0.06910, lr:9.23e-03, fs:0.85859 (r=0.859,p=0.859),  time:17.684, tt:2581.818\n",
      "Ep:146, loss:0.00000, loss_test:0.07305, lr:9.23e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.691, tt:2600.567\n",
      "Ep:147, loss:0.00000, loss_test:0.07878, lr:9.23e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.696, tt:2619.019\n",
      "Ep:148, loss:0.00000, loss_test:0.06933, lr:9.23e-03, fs:0.87629 (r=0.859,p=0.895),  time:17.712, tt:2639.135\n",
      "Ep:149, loss:0.00000, loss_test:0.06965, lr:9.23e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.724, tt:2658.673\n",
      "Ep:150, loss:0.00000, loss_test:0.07851, lr:9.23e-03, fs:0.83744 (r=0.859,p=0.817),  time:17.740, tt:2678.741\n",
      "Ep:151, loss:0.00000, loss_test:0.07300, lr:9.23e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.755, tt:2698.729\n",
      "Ep:152, loss:0.00000, loss_test:0.07082, lr:9.23e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.767, tt:2718.372\n",
      "Ep:153, loss:0.00000, loss_test:0.07568, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:17.781, tt:2738.256\n",
      "Ep:154, loss:0.00000, loss_test:0.07350, lr:9.14e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.798, tt:2758.643\n",
      "Ep:155, loss:0.00000, loss_test:0.07141, lr:9.04e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.805, tt:2777.507\n",
      "Ep:156, loss:0.00000, loss_test:0.07224, lr:8.95e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.833, tt:2799.852\n",
      "Ep:157, loss:0.00000, loss_test:0.07586, lr:8.86e-03, fs:0.85000 (r=0.859,p=0.842),  time:17.840, tt:2818.648\n",
      "Ep:158, loss:0.00000, loss_test:0.07129, lr:8.78e-03, fs:0.86294 (r=0.859,p=0.867),  time:17.851, tt:2838.332\n",
      "Ep:159, loss:0.00000, loss_test:0.07203, lr:8.69e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.860, tt:2857.623\n",
      "Ep:160, loss:0.00000, loss_test:0.07417, lr:8.60e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.873, tt:2877.486\n",
      "Ep:161, loss:0.00000, loss_test:0.07396, lr:8.51e-03, fs:0.85859 (r=0.859,p=0.859),  time:17.878, tt:2896.313\n",
      "Ep:162, loss:0.00000, loss_test:0.06845, lr:8.43e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.890, tt:2916.152\n",
      "Ep:163, loss:0.00000, loss_test:0.07046, lr:8.35e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.899, tt:2935.395\n",
      "Ep:164, loss:0.00000, loss_test:0.07524, lr:8.26e-03, fs:0.87629 (r=0.859,p=0.895),  time:17.913, tt:2955.634\n",
      "Ep:165, loss:0.00000, loss_test:0.07298, lr:8.18e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.911, tt:2973.178\n",
      "Ep:166, loss:0.00000, loss_test:0.06913, lr:8.10e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.913, tt:2991.457\n",
      "Ep:167, loss:0.00000, loss_test:0.07016, lr:8.02e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.919, tt:3010.456\n",
      "Ep:168, loss:0.00000, loss_test:0.07372, lr:7.94e-03, fs:0.87629 (r=0.859,p=0.895),  time:17.927, tt:3029.604\n",
      "Ep:169, loss:0.00000, loss_test:0.07207, lr:7.86e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.940, tt:3049.815\n",
      "Ep:170, loss:0.00000, loss_test:0.06943, lr:7.78e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.953, tt:3069.982\n",
      "Ep:171, loss:0.00000, loss_test:0.06995, lr:7.70e-03, fs:0.87179 (r=0.859,p=0.885),  time:17.961, tt:3089.270\n",
      "Ep:172, loss:0.00000, loss_test:0.07299, lr:7.62e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.970, tt:3108.814\n",
      "Ep:173, loss:0.00000, loss_test:0.07129, lr:7.55e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.981, tt:3128.619\n",
      "Ep:174, loss:0.00000, loss_test:0.06980, lr:7.47e-03, fs:0.88083 (r=0.859,p=0.904),  time:17.990, tt:3148.240\n",
      "Ep:175, loss:0.00000, loss_test:0.07076, lr:7.40e-03, fs:0.86735 (r=0.859,p=0.876),  time:17.994, tt:3166.924\n",
      "Ep:176, loss:0.00000, loss_test:0.07162, lr:7.32e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.003, tt:3186.473\n",
      "Ep:177, loss:0.00000, loss_test:0.07089, lr:7.25e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.010, tt:3205.721\n",
      "Ep:178, loss:0.00000, loss_test:0.07024, lr:7.18e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.017, tt:3225.000\n",
      "Ep:179, loss:0.00000, loss_test:0.07040, lr:7.11e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.023, tt:3244.191\n",
      "Ep:180, loss:0.00000, loss_test:0.07095, lr:7.03e-03, fs:0.85859 (r=0.859,p=0.859),  time:18.030, tt:3263.394\n",
      "Ep:181, loss:0.00000, loss_test:0.07001, lr:6.96e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.037, tt:3282.749\n",
      "Ep:182, loss:0.00000, loss_test:0.07036, lr:6.89e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.045, tt:3302.188\n",
      "Ep:183, loss:0.00000, loss_test:0.07074, lr:6.83e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.051, tt:3321.440\n",
      "Ep:184, loss:0.00000, loss_test:0.07074, lr:6.76e-03, fs:0.86735 (r=0.859,p=0.876),  time:18.060, tt:3341.186\n",
      "Ep:185, loss:0.00000, loss_test:0.07021, lr:6.69e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.066, tt:3360.334\n",
      "Ep:186, loss:0.00000, loss_test:0.07053, lr:6.62e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.072, tt:3379.533\n",
      "Ep:187, loss:0.00000, loss_test:0.07031, lr:6.56e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.080, tt:3399.131\n",
      "Ep:188, loss:0.00000, loss_test:0.07023, lr:6.49e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.085, tt:3418.130\n",
      "Ep:189, loss:0.00000, loss_test:0.07026, lr:6.43e-03, fs:0.86735 (r=0.859,p=0.876),  time:18.092, tt:3437.483\n",
      "Ep:190, loss:0.00000, loss_test:0.07038, lr:6.36e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.100, tt:3457.086\n",
      "Ep:191, loss:0.00000, loss_test:0.07040, lr:6.30e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.104, tt:3476.009\n",
      "Ep:192, loss:0.00000, loss_test:0.07012, lr:6.24e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.110, tt:3495.221\n",
      "Ep:193, loss:0.00000, loss_test:0.06983, lr:6.17e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.121, tt:3515.432\n",
      "Ep:194, loss:0.00000, loss_test:0.07060, lr:6.11e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.120, tt:3533.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:195, loss:0.00000, loss_test:0.07045, lr:6.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.126, tt:3552.708\n",
      "Ep:196, loss:0.00000, loss_test:0.07014, lr:5.99e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.132, tt:3571.999\n",
      "Ep:197, loss:0.00000, loss_test:0.07007, lr:5.93e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.138, tt:3591.358\n",
      "Ep:198, loss:0.00000, loss_test:0.07044, lr:5.87e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.140, tt:3609.762\n",
      "Ep:199, loss:0.00000, loss_test:0.06997, lr:5.81e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.145, tt:3629.061\n",
      "Ep:200, loss:0.00000, loss_test:0.06996, lr:5.75e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.149, tt:3648.047\n",
      "Ep:201, loss:0.00000, loss_test:0.07030, lr:5.70e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.155, tt:3667.286\n",
      "Ep:202, loss:0.00000, loss_test:0.07010, lr:5.64e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.157, tt:3685.813\n",
      "Ep:203, loss:0.00000, loss_test:0.06966, lr:5.58e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.162, tt:3705.076\n",
      "Ep:204, loss:0.00000, loss_test:0.07080, lr:5.53e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.164, tt:3723.688\n",
      "Ep:205, loss:0.00000, loss_test:0.07055, lr:5.47e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.168, tt:3742.647\n",
      "Ep:206, loss:0.00000, loss_test:0.06919, lr:5.42e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.175, tt:3762.176\n",
      "Ep:207, loss:0.00000, loss_test:0.06927, lr:5.36e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.179, tt:3781.259\n",
      "Ep:208, loss:0.00000, loss_test:0.07061, lr:5.31e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.179, tt:3799.447\n",
      "Ep:209, loss:0.00000, loss_test:0.07003, lr:5.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.183, tt:3818.440\n",
      "Ep:210, loss:0.00000, loss_test:0.06964, lr:5.20e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.188, tt:3837.599\n",
      "Ep:211, loss:0.00000, loss_test:0.06954, lr:5.15e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.197, tt:3857.746\n",
      "Ep:212, loss:0.00000, loss_test:0.07009, lr:5.10e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.198, tt:3876.133\n",
      "Ep:213, loss:0.00000, loss_test:0.07000, lr:5.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.204, tt:3895.597\n",
      "Ep:214, loss:0.00000, loss_test:0.06933, lr:5.00e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.209, tt:3914.864\n",
      "Ep:215, loss:0.00000, loss_test:0.07025, lr:4.95e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.215, tt:3934.495\n",
      "Ep:216, loss:0.00000, loss_test:0.07055, lr:4.90e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.218, tt:3953.201\n",
      "Ep:217, loss:0.00000, loss_test:0.06946, lr:4.85e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.219, tt:3971.772\n",
      "Ep:218, loss:0.00000, loss_test:0.06939, lr:4.80e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.218, tt:3989.750\n",
      "Ep:219, loss:0.00000, loss_test:0.06978, lr:4.75e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.222, tt:4008.818\n",
      "Ep:220, loss:0.00000, loss_test:0.07012, lr:4.71e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.225, tt:4027.692\n",
      "Ep:221, loss:0.00000, loss_test:0.06952, lr:4.66e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.230, tt:4047.124\n",
      "Ep:222, loss:0.00000, loss_test:0.06968, lr:4.61e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.230, tt:4065.375\n",
      "Ep:223, loss:0.00000, loss_test:0.06997, lr:4.57e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.235, tt:4084.578\n",
      "Ep:224, loss:0.00000, loss_test:0.06978, lr:4.52e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.234, tt:4102.676\n",
      "Ep:225, loss:0.00000, loss_test:0.06963, lr:4.48e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.239, tt:4121.957\n",
      "Ep:226, loss:0.00000, loss_test:0.06997, lr:4.43e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.238, tt:4140.023\n",
      "Ep:227, loss:0.00000, loss_test:0.07000, lr:4.39e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.246, tt:4160.163\n",
      "Ep:228, loss:0.00000, loss_test:0.06974, lr:4.34e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.248, tt:4178.766\n",
      "Ep:229, loss:0.00000, loss_test:0.06940, lr:4.30e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.252, tt:4197.913\n",
      "Ep:230, loss:0.00000, loss_test:0.07013, lr:4.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.253, tt:4216.518\n",
      "Ep:231, loss:0.00000, loss_test:0.07001, lr:4.21e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.253, tt:4234.657\n",
      "Ep:232, loss:0.00000, loss_test:0.06923, lr:4.17e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.257, tt:4253.846\n",
      "Ep:233, loss:0.00000, loss_test:0.06937, lr:4.13e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.260, tt:4272.808\n",
      "Ep:234, loss:0.00000, loss_test:0.07005, lr:4.09e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.263, tt:4291.691\n",
      "Ep:235, loss:0.00000, loss_test:0.07031, lr:4.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.261, tt:4309.482\n",
      "Ep:236, loss:0.00000, loss_test:0.06961, lr:4.01e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.262, tt:4328.158\n",
      "Ep:237, loss:0.00000, loss_test:0.06901, lr:3.97e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.266, tt:4347.401\n",
      "Ep:238, loss:0.00000, loss_test:0.07062, lr:3.93e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.271, tt:4366.844\n",
      "Ep:239, loss:0.00000, loss_test:0.07102, lr:3.89e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.277, tt:4386.463\n",
      "Ep:240, loss:0.00000, loss_test:0.06945, lr:3.85e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.280, tt:4405.369\n",
      "Ep:241, loss:0.00000, loss_test:0.06875, lr:3.81e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.285, tt:4425.064\n",
      "Ep:242, loss:0.00000, loss_test:0.06993, lr:3.77e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.289, tt:4444.292\n",
      "Ep:243, loss:0.00000, loss_test:0.07082, lr:3.73e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.290, tt:4462.828\n",
      "Ep:244, loss:0.00000, loss_test:0.06980, lr:3.70e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.295, tt:4482.298\n",
      "Ep:245, loss:0.00000, loss_test:0.06897, lr:3.66e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.294, tt:4500.272\n",
      "Ep:246, loss:0.00000, loss_test:0.06921, lr:3.62e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.293, tt:4518.439\n",
      "Ep:247, loss:0.00000, loss_test:0.06990, lr:3.59e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.297, tt:4537.714\n",
      "Ep:248, loss:0.00000, loss_test:0.07025, lr:3.55e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.302, tt:4557.266\n",
      "Ep:249, loss:0.00000, loss_test:0.06991, lr:3.52e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.304, tt:4575.961\n",
      "Ep:250, loss:0.00000, loss_test:0.06946, lr:3.48e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.306, tt:4594.847\n",
      "Ep:251, loss:0.00000, loss_test:0.06962, lr:3.45e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.306, tt:4613.174\n",
      "Ep:252, loss:0.00000, loss_test:0.06991, lr:3.41e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.307, tt:4631.779\n",
      "Ep:253, loss:0.00000, loss_test:0.06959, lr:3.38e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.305, tt:4649.562\n",
      "Ep:254, loss:0.00000, loss_test:0.06938, lr:3.34e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.305, tt:4667.821\n",
      "Ep:255, loss:0.00000, loss_test:0.06948, lr:3.31e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.308, tt:4686.919\n",
      "Ep:256, loss:0.00000, loss_test:0.06987, lr:3.28e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.308, tt:4705.158\n",
      "Ep:257, loss:0.00000, loss_test:0.06964, lr:3.24e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.309, tt:4723.713\n",
      "Ep:258, loss:0.00000, loss_test:0.06938, lr:3.21e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.308, tt:4741.812\n",
      "Ep:259, loss:0.00000, loss_test:0.06938, lr:3.18e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.308, tt:4760.079\n",
      "Ep:260, loss:0.00000, loss_test:0.06963, lr:3.15e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.308, tt:4778.489\n",
      "Ep:261, loss:0.00000, loss_test:0.06966, lr:3.12e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.311, tt:4797.599\n",
      "Ep:262, loss:0.00000, loss_test:0.06960, lr:3.09e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.315, tt:4816.744\n",
      "Ep:263, loss:0.00000, loss_test:0.06956, lr:3.05e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.316, tt:4835.482\n",
      "Ep:264, loss:0.00000, loss_test:0.06964, lr:3.02e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.315, tt:4853.541\n",
      "Ep:265, loss:0.00000, loss_test:0.06964, lr:2.99e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.315, tt:4871.902\n",
      "Ep:266, loss:0.00000, loss_test:0.06955, lr:2.96e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.321, tt:4891.660\n",
      "Ep:267, loss:0.00000, loss_test:0.06993, lr:2.93e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.321, tt:4910.064\n",
      "Ep:268, loss:0.00000, loss_test:0.06991, lr:2.90e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.320, tt:4928.056\n",
      "Ep:269, loss:0.00000, loss_test:0.06958, lr:2.88e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.323, tt:4947.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:270, loss:0.00000, loss_test:0.06942, lr:2.85e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.322, tt:4965.234\n",
      "Ep:271, loss:0.00000, loss_test:0.06983, lr:2.82e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.326, tt:4984.674\n",
      "Ep:272, loss:0.00000, loss_test:0.07017, lr:2.79e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.331, tt:5004.368\n",
      "Ep:273, loss:0.00000, loss_test:0.07000, lr:2.76e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.332, tt:5023.034\n",
      "Ep:274, loss:0.00000, loss_test:0.06946, lr:2.73e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.338, tt:5042.946\n",
      "Ep:275, loss:0.00000, loss_test:0.06941, lr:2.71e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.339, tt:5061.442\n",
      "Ep:276, loss:0.00000, loss_test:0.07010, lr:2.68e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.334, tt:5078.409\n",
      "Ep:277, loss:0.00000, loss_test:0.07038, lr:2.65e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.325, tt:5094.323\n",
      "Ep:278, loss:0.00000, loss_test:0.06995, lr:2.63e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.324, tt:5112.305\n",
      "Ep:279, loss:0.00000, loss_test:0.06926, lr:2.60e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.325, tt:5130.947\n",
      "Ep:280, loss:0.00000, loss_test:0.06949, lr:2.57e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.326, tt:5149.645\n",
      "Ep:281, loss:0.00000, loss_test:0.06997, lr:2.55e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.324, tt:5167.461\n",
      "Ep:282, loss:0.00000, loss_test:0.07005, lr:2.52e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.329, tt:5187.132\n",
      "Ep:283, loss:0.00000, loss_test:0.06959, lr:2.50e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.331, tt:5206.140\n",
      "Ep:284, loss:0.00000, loss_test:0.06916, lr:2.47e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.334, tt:5225.287\n",
      "Ep:285, loss:0.00000, loss_test:0.06949, lr:2.45e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.336, tt:5244.141\n",
      "Ep:286, loss:0.00000, loss_test:0.06980, lr:2.42e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.337, tt:5262.752\n",
      "Ep:287, loss:0.00000, loss_test:0.06997, lr:2.40e-03, fs:0.87629 (r=0.859,p=0.895),  time:18.337, tt:5280.954\n",
      "Ep:288, loss:0.00000, loss_test:0.06950, lr:2.38e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.339, tt:5299.859\n",
      "Ep:289, loss:0.00000, loss_test:0.06937, lr:2.35e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.336, tt:5317.481\n",
      "Ep:290, loss:0.00000, loss_test:0.06928, lr:2.33e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.334, tt:5335.059\n",
      "Ep:291, loss:0.00000, loss_test:0.06965, lr:2.31e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.335, tt:5353.959\n",
      "Ep:292, loss:0.00000, loss_test:0.06993, lr:2.28e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.334, tt:5371.937\n",
      "Ep:293, loss:0.00000, loss_test:0.06984, lr:2.26e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.335, tt:5390.444\n",
      "Ep:294, loss:0.00000, loss_test:0.06949, lr:2.24e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.326, tt:5406.159\n",
      "Ep:295, loss:0.00000, loss_test:0.06935, lr:2.21e-03, fs:0.88083 (r=0.859,p=0.904),  time:18.316, tt:5421.659\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13138, lr:1.00e-02, fs:0.65116 (r=0.848,p=0.528),  time:6.058, tt:6.058\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13120, lr:1.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:8.012, tt:16.023\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.13113, lr:1.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:10.640, tt:31.919\n",
      "Ep:3, loss:0.00004, loss_test:0.13161, lr:1.00e-02, fs:0.65600 (r=0.828,p=0.543),  time:12.714, tt:50.857\n",
      "Ep:4, loss:0.00004, loss_test:0.13256, lr:1.00e-02, fs:0.65339 (r=0.828,p=0.539),  time:13.996, tt:69.978\n",
      "Ep:5, loss:0.00004, loss_test:0.13335, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:14.595, tt:87.571\n",
      "Ep:6, loss:0.00004, loss_test:0.13416, lr:1.00e-02, fs:0.62097 (r=0.778,p=0.517),  time:15.204, tt:106.427\n",
      "Ep:7, loss:0.00004, loss_test:0.13491, lr:1.00e-02, fs:0.59836 (r=0.737,p=0.503),  time:15.598, tt:124.785\n",
      "Ep:8, loss:0.00004, loss_test:0.13552, lr:1.00e-02, fs:0.60331 (r=0.737,p=0.510),  time:15.800, tt:142.200\n",
      "Ep:9, loss:0.00004, loss_test:0.13593, lr:1.00e-02, fs:0.60833 (r=0.737,p=0.518),  time:16.107, tt:161.073\n",
      "Ep:10, loss:0.00004, loss_test:0.13604, lr:1.00e-02, fs:0.61345 (r=0.737,p=0.525),  time:16.279, tt:179.066\n",
      "Ep:11, loss:0.00004, loss_test:0.13575, lr:1.00e-02, fs:0.61864 (r=0.737,p=0.533),  time:16.407, tt:196.886\n",
      "Ep:12, loss:0.00004, loss_test:0.13514, lr:1.00e-02, fs:0.62128 (r=0.737,p=0.537),  time:16.578, tt:215.519\n",
      "Ep:13, loss:0.00004, loss_test:0.13430, lr:9.90e-03, fs:0.62661 (r=0.737,p=0.545),  time:16.712, tt:233.967\n",
      "Ep:14, loss:0.00004, loss_test:0.13349, lr:9.80e-03, fs:0.62128 (r=0.737,p=0.537),  time:16.858, tt:252.868\n",
      "Ep:15, loss:0.00003, loss_test:0.13278, lr:9.70e-03, fs:0.61864 (r=0.737,p=0.533),  time:16.976, tt:271.610\n",
      "Ep:16, loss:0.00003, loss_test:0.13217, lr:9.61e-03, fs:0.62393 (r=0.737,p=0.541),  time:17.032, tt:289.536\n",
      "Ep:17, loss:0.00003, loss_test:0.13173, lr:9.51e-03, fs:0.62128 (r=0.737,p=0.537),  time:17.066, tt:307.192\n",
      "Ep:18, loss:0.00003, loss_test:0.13142, lr:9.41e-03, fs:0.62069 (r=0.727,p=0.541),  time:17.164, tt:326.122\n",
      "Ep:19, loss:0.00003, loss_test:0.13098, lr:9.32e-03, fs:0.62338 (r=0.727,p=0.545),  time:17.213, tt:344.265\n",
      "Ep:20, loss:0.00003, loss_test:0.13038, lr:9.23e-03, fs:0.62338 (r=0.727,p=0.545),  time:17.296, tt:363.224\n",
      "Ep:21, loss:0.00003, loss_test:0.12949, lr:9.14e-03, fs:0.62661 (r=0.737,p=0.545),  time:17.389, tt:382.552\n",
      "Ep:22, loss:0.00003, loss_test:0.12871, lr:9.04e-03, fs:0.62338 (r=0.727,p=0.545),  time:17.460, tt:401.579\n",
      "Ep:23, loss:0.00003, loss_test:0.12804, lr:8.95e-03, fs:0.62609 (r=0.727,p=0.550),  time:17.516, tt:420.383\n",
      "Ep:24, loss:0.00003, loss_test:0.12747, lr:8.86e-03, fs:0.62609 (r=0.727,p=0.550),  time:17.573, tt:439.313\n",
      "Ep:25, loss:0.00003, loss_test:0.12688, lr:8.78e-03, fs:0.62882 (r=0.727,p=0.554),  time:17.603, tt:457.682\n",
      "Ep:26, loss:0.00003, loss_test:0.12618, lr:8.69e-03, fs:0.63755 (r=0.737,p=0.562),  time:17.686, tt:477.525\n",
      "Ep:27, loss:0.00003, loss_test:0.12514, lr:8.60e-03, fs:0.64069 (r=0.747,p=0.561),  time:17.735, tt:496.569\n",
      "Ep:28, loss:0.00003, loss_test:0.12383, lr:8.51e-03, fs:0.64629 (r=0.747,p=0.569),  time:17.749, tt:514.725\n",
      "Ep:29, loss:0.00003, loss_test:0.12245, lr:8.43e-03, fs:0.64912 (r=0.747,p=0.574),  time:17.787, tt:533.597\n",
      "Ep:30, loss:0.00003, loss_test:0.12107, lr:8.35e-03, fs:0.64912 (r=0.747,p=0.574),  time:17.779, tt:551.148\n",
      "Ep:31, loss:0.00003, loss_test:0.11986, lr:8.26e-03, fs:0.64602 (r=0.737,p=0.575),  time:17.787, tt:569.198\n",
      "Ep:32, loss:0.00003, loss_test:0.11881, lr:8.18e-03, fs:0.64889 (r=0.737,p=0.579),  time:17.788, tt:586.994\n",
      "Ep:33, loss:0.00003, loss_test:0.11780, lr:8.10e-03, fs:0.65179 (r=0.737,p=0.584),  time:17.822, tt:605.959\n",
      "Ep:34, loss:0.00003, loss_test:0.11664, lr:8.02e-03, fs:0.65471 (r=0.737,p=0.589),  time:17.824, tt:623.847\n",
      "Ep:35, loss:0.00003, loss_test:0.11537, lr:7.94e-03, fs:0.65766 (r=0.737,p=0.593),  time:17.813, tt:641.261\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.11406, lr:7.94e-03, fs:0.65455 (r=0.727,p=0.595),  time:17.817, tt:659.246\n",
      "Ep:37, loss:0.00003, loss_test:0.11282, lr:7.94e-03, fs:0.66667 (r=0.717,p=0.623),  time:17.838, tt:677.840\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.11159, lr:7.94e-03, fs:0.67943 (r=0.717,p=0.645),  time:17.811, tt:694.639\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.11037, lr:7.94e-03, fs:0.69524 (r=0.737,p=0.658),  time:17.833, tt:713.313\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.10913, lr:7.94e-03, fs:0.70142 (r=0.747,p=0.661),  time:17.866, tt:732.489\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.10816, lr:7.94e-03, fs:0.69811 (r=0.747,p=0.655),  time:17.878, tt:750.867\n",
      "Ep:42, loss:0.00003, loss_test:0.10722, lr:7.94e-03, fs:0.70142 (r=0.747,p=0.661),  time:17.927, tt:770.876\n",
      "Ep:43, loss:0.00003, loss_test:0.10633, lr:7.94e-03, fs:0.69811 (r=0.747,p=0.655),  time:17.955, tt:790.018\n",
      "Ep:44, loss:0.00003, loss_test:0.10560, lr:7.94e-03, fs:0.69194 (r=0.737,p=0.652),  time:17.995, tt:809.796\n",
      "Ep:45, loss:0.00003, loss_test:0.10528, lr:7.94e-03, fs:0.69231 (r=0.727,p=0.661),  time:18.030, tt:829.361\n",
      "Ep:46, loss:0.00003, loss_test:0.10504, lr:7.94e-03, fs:0.69565 (r=0.727,p=0.667),  time:18.067, tt:849.160\n",
      "Ep:47, loss:0.00003, loss_test:0.10451, lr:7.94e-03, fs:0.68932 (r=0.717,p=0.664),  time:18.089, tt:868.260\n",
      "Ep:48, loss:0.00003, loss_test:0.10383, lr:7.94e-03, fs:0.70755 (r=0.758,p=0.664),  time:18.106, tt:887.172\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.10316, lr:7.94e-03, fs:0.71698 (r=0.768,p=0.673),  time:18.131, tt:906.559\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.10268, lr:7.94e-03, fs:0.72897 (r=0.788,p=0.678),  time:18.157, tt:926.021\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.10223, lr:7.94e-03, fs:0.73832 (r=0.798,p=0.687),  time:18.178, tt:945.260\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.10152, lr:7.94e-03, fs:0.73488 (r=0.798,p=0.681),  time:18.210, tt:965.151\n",
      "Ep:53, loss:0.00002, loss_test:0.10097, lr:7.94e-03, fs:0.73832 (r=0.798,p=0.687),  time:18.219, tt:983.838\n",
      "Ep:54, loss:0.00002, loss_test:0.10056, lr:7.94e-03, fs:0.74178 (r=0.798,p=0.693),  time:18.221, tt:1002.134\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.09997, lr:7.94e-03, fs:0.74178 (r=0.798,p=0.693),  time:18.264, tt:1022.779\n",
      "Ep:56, loss:0.00002, loss_test:0.09913, lr:7.94e-03, fs:0.74766 (r=0.808,p=0.696),  time:18.269, tt:1041.335\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.09846, lr:7.94e-03, fs:0.74766 (r=0.808,p=0.696),  time:18.294, tt:1061.041\n",
      "Ep:58, loss:0.00002, loss_test:0.09794, lr:7.94e-03, fs:0.75349 (r=0.818,p=0.698),  time:18.314, tt:1080.504\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.09738, lr:7.94e-03, fs:0.75349 (r=0.818,p=0.698),  time:18.334, tt:1100.020\n",
      "Ep:60, loss:0.00002, loss_test:0.09664, lr:7.94e-03, fs:0.75926 (r=0.828,p=0.701),  time:18.354, tt:1119.593\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.09602, lr:7.94e-03, fs:0.76852 (r=0.838,p=0.709),  time:18.364, tt:1138.537\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.09544, lr:7.94e-03, fs:0.77778 (r=0.848,p=0.718),  time:18.377, tt:1157.726\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.09512, lr:7.94e-03, fs:0.77778 (r=0.848,p=0.718),  time:18.384, tt:1176.574\n",
      "Ep:64, loss:0.00002, loss_test:0.09512, lr:7.94e-03, fs:0.77778 (r=0.848,p=0.718),  time:18.377, tt:1194.501\n",
      "Ep:65, loss:0.00002, loss_test:0.09495, lr:7.94e-03, fs:0.77209 (r=0.838,p=0.716),  time:18.361, tt:1211.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00002, loss_test:0.09426, lr:7.94e-03, fs:0.77626 (r=0.859,p=0.708),  time:18.350, tt:1229.437\n",
      "Ep:67, loss:0.00002, loss_test:0.09364, lr:7.94e-03, fs:0.78341 (r=0.859,p=0.720),  time:18.350, tt:1247.777\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.09335, lr:7.94e-03, fs:0.78704 (r=0.859,p=0.726),  time:18.345, tt:1265.832\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.09296, lr:7.94e-03, fs:0.78140 (r=0.848,p=0.724),  time:18.333, tt:1283.290\n",
      "Ep:70, loss:0.00002, loss_test:0.09238, lr:7.94e-03, fs:0.78899 (r=0.869,p=0.723),  time:18.347, tt:1302.625\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.09206, lr:7.94e-03, fs:0.78899 (r=0.869,p=0.723),  time:18.348, tt:1321.083\n",
      "Ep:72, loss:0.00002, loss_test:0.09181, lr:7.94e-03, fs:0.78704 (r=0.859,p=0.726),  time:18.358, tt:1340.158\n",
      "Ep:73, loss:0.00002, loss_test:0.09149, lr:7.94e-03, fs:0.78704 (r=0.859,p=0.726),  time:18.361, tt:1358.688\n",
      "Ep:74, loss:0.00002, loss_test:0.09105, lr:7.94e-03, fs:0.79439 (r=0.859,p=0.739),  time:18.360, tt:1376.985\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.09065, lr:7.94e-03, fs:0.80000 (r=0.869,p=0.741),  time:18.360, tt:1395.395\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.09069, lr:7.94e-03, fs:0.80751 (r=0.869,p=0.754),  time:18.365, tt:1414.106\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.09095, lr:7.94e-03, fs:0.80000 (r=0.848,p=0.757),  time:18.355, tt:1431.665\n",
      "Ep:78, loss:0.00002, loss_test:0.09081, lr:7.94e-03, fs:0.79808 (r=0.838,p=0.761),  time:18.374, tt:1451.568\n",
      "Ep:79, loss:0.00002, loss_test:0.09060, lr:7.94e-03, fs:0.80383 (r=0.848,p=0.764),  time:18.391, tt:1471.244\n",
      "Ep:80, loss:0.00002, loss_test:0.09077, lr:7.94e-03, fs:0.79808 (r=0.838,p=0.761),  time:18.405, tt:1490.767\n",
      "Ep:81, loss:0.00002, loss_test:0.09034, lr:7.94e-03, fs:0.79808 (r=0.838,p=0.761),  time:18.418, tt:1510.307\n",
      "Ep:82, loss:0.00002, loss_test:0.08977, lr:7.94e-03, fs:0.80569 (r=0.859,p=0.759),  time:18.421, tt:1528.960\n",
      "Ep:83, loss:0.00002, loss_test:0.09003, lr:7.94e-03, fs:0.79426 (r=0.838,p=0.755),  time:18.421, tt:1547.340\n",
      "Ep:84, loss:0.00001, loss_test:0.09045, lr:7.94e-03, fs:0.79426 (r=0.838,p=0.755),  time:18.419, tt:1565.638\n",
      "Ep:85, loss:0.00001, loss_test:0.09065, lr:7.94e-03, fs:0.79808 (r=0.838,p=0.761),  time:18.445, tt:1586.239\n",
      "Ep:86, loss:0.00001, loss_test:0.09126, lr:7.94e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.449, tt:1605.083\n",
      "Ep:87, loss:0.00001, loss_test:0.09098, lr:7.94e-03, fs:0.83019 (r=0.889,p=0.779),  time:18.443, tt:1622.996\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.09087, lr:7.94e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.442, tt:1641.369\n",
      "Ep:89, loss:0.00001, loss_test:0.09078, lr:7.94e-03, fs:0.82464 (r=0.879,p=0.777),  time:18.440, tt:1659.644\n",
      "Ep:90, loss:0.00001, loss_test:0.09079, lr:7.94e-03, fs:0.78818 (r=0.808,p=0.769),  time:18.445, tt:1678.467\n",
      "Ep:91, loss:0.00001, loss_test:0.09041, lr:7.94e-03, fs:0.79412 (r=0.818,p=0.771),  time:18.445, tt:1696.946\n",
      "Ep:92, loss:0.00001, loss_test:0.09192, lr:7.94e-03, fs:0.79602 (r=0.808,p=0.784),  time:18.437, tt:1714.683\n",
      "Ep:93, loss:0.00001, loss_test:0.09159, lr:7.94e-03, fs:0.74074 (r=0.707,p=0.778),  time:18.435, tt:1732.935\n",
      "Ep:94, loss:0.00001, loss_test:0.09203, lr:7.94e-03, fs:0.81517 (r=0.869,p=0.768),  time:18.428, tt:1750.691\n",
      "Ep:95, loss:0.00001, loss_test:0.09428, lr:7.94e-03, fs:0.73797 (r=0.697,p=0.784),  time:18.424, tt:1768.667\n",
      "Ep:96, loss:0.00001, loss_test:0.09151, lr:7.94e-03, fs:0.81340 (r=0.859,p=0.773),  time:18.422, tt:1786.935\n",
      "Ep:97, loss:0.00001, loss_test:0.09215, lr:7.94e-03, fs:0.73958 (r=0.717,p=0.763),  time:18.421, tt:1805.226\n",
      "Ep:98, loss:0.00001, loss_test:0.09303, lr:7.94e-03, fs:0.73298 (r=0.707,p=0.761),  time:18.414, tt:1822.950\n",
      "Ep:99, loss:0.00001, loss_test:0.09046, lr:7.86e-03, fs:0.82524 (r=0.859,p=0.794),  time:18.418, tt:1841.761\n",
      "Ep:100, loss:0.00001, loss_test:0.09549, lr:7.78e-03, fs:0.72432 (r=0.677,p=0.779),  time:18.409, tt:1859.268\n",
      "Ep:101, loss:0.00001, loss_test:0.09125, lr:7.70e-03, fs:0.80000 (r=0.808,p=0.792),  time:18.416, tt:1878.479\n",
      "Ep:102, loss:0.00001, loss_test:0.09278, lr:7.62e-03, fs:0.74872 (r=0.737,p=0.760),  time:18.425, tt:1897.740\n",
      "Ep:103, loss:0.00001, loss_test:0.09259, lr:7.55e-03, fs:0.75648 (r=0.737,p=0.777),  time:18.427, tt:1916.390\n",
      "Ep:104, loss:0.00001, loss_test:0.09291, lr:7.47e-03, fs:0.75393 (r=0.727,p=0.783),  time:18.423, tt:1934.427\n",
      "Ep:105, loss:0.00001, loss_test:0.09197, lr:7.40e-03, fs:0.76142 (r=0.758,p=0.765),  time:18.418, tt:1952.337\n",
      "Ep:106, loss:0.00001, loss_test:0.09891, lr:7.32e-03, fs:0.70652 (r=0.657,p=0.765),  time:18.409, tt:1969.761\n",
      "Ep:107, loss:0.00001, loss_test:0.08828, lr:7.25e-03, fs:0.77228 (r=0.788,p=0.757),  time:18.408, tt:1988.084\n",
      "Ep:108, loss:0.00001, loss_test:0.09746, lr:7.18e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.408, tt:2006.444\n",
      "Ep:109, loss:0.00001, loss_test:0.09468, lr:7.11e-03, fs:0.75000 (r=0.727,p=0.774),  time:18.414, tt:2025.510\n",
      "Ep:110, loss:0.00001, loss_test:0.08948, lr:7.03e-03, fs:0.75258 (r=0.737,p=0.768),  time:18.421, tt:2044.713\n",
      "Ep:111, loss:0.00001, loss_test:0.09956, lr:6.96e-03, fs:0.66279 (r=0.576,p=0.781),  time:18.438, tt:2065.046\n",
      "Ep:112, loss:0.00001, loss_test:0.09034, lr:6.89e-03, fs:0.75127 (r=0.747,p=0.755),  time:18.440, tt:2083.713\n",
      "Ep:113, loss:0.00001, loss_test:0.09472, lr:6.83e-03, fs:0.74074 (r=0.707,p=0.778),  time:18.444, tt:2102.595\n",
      "Ep:114, loss:0.00001, loss_test:0.10080, lr:6.76e-03, fs:0.65089 (r=0.556,p=0.786),  time:18.448, tt:2121.551\n",
      "Ep:115, loss:0.00001, loss_test:0.08942, lr:6.69e-03, fs:0.77000 (r=0.778,p=0.762),  time:18.449, tt:2140.049\n",
      "Ep:116, loss:0.00001, loss_test:0.09835, lr:6.62e-03, fs:0.68132 (r=0.626,p=0.747),  time:18.464, tt:2160.238\n",
      "Ep:117, loss:0.00001, loss_test:0.09545, lr:6.56e-03, fs:0.71591 (r=0.636,p=0.818),  time:18.466, tt:2178.980\n",
      "Ep:118, loss:0.00001, loss_test:0.09142, lr:6.49e-03, fs:0.74317 (r=0.687,p=0.810),  time:18.470, tt:2197.905\n",
      "Ep:119, loss:0.00001, loss_test:0.09992, lr:6.43e-03, fs:0.67059 (r=0.576,p=0.803),  time:18.476, tt:2217.140\n",
      "Ep:120, loss:0.00001, loss_test:0.09101, lr:6.36e-03, fs:0.80583 (r=0.838,p=0.776),  time:18.483, tt:2236.418\n",
      "Ep:121, loss:0.00001, loss_test:0.09804, lr:6.30e-03, fs:0.71508 (r=0.646,p=0.800),  time:18.491, tt:2255.959\n",
      "Ep:122, loss:0.00001, loss_test:0.10169, lr:6.24e-03, fs:0.67033 (r=0.616,p=0.735),  time:18.497, tt:2275.187\n",
      "Ep:123, loss:0.00001, loss_test:0.09091, lr:6.17e-03, fs:0.79188 (r=0.788,p=0.796),  time:18.498, tt:2293.802\n",
      "Ep:124, loss:0.00001, loss_test:0.09890, lr:6.11e-03, fs:0.67039 (r=0.606,p=0.750),  time:18.502, tt:2312.705\n",
      "Ep:125, loss:0.00001, loss_test:0.09845, lr:6.05e-03, fs:0.66667 (r=0.576,p=0.792),  time:18.506, tt:2331.807\n",
      "Ep:126, loss:0.00001, loss_test:0.09259, lr:5.99e-03, fs:0.74595 (r=0.697,p=0.802),  time:18.512, tt:2350.994\n",
      "Ep:127, loss:0.00001, loss_test:0.09993, lr:5.93e-03, fs:0.69792 (r=0.677,p=0.720),  time:18.521, tt:2370.675\n",
      "Ep:128, loss:0.00001, loss_test:0.09571, lr:5.87e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.533, tt:2390.814\n",
      "Ep:129, loss:0.00001, loss_test:0.08505, lr:5.81e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.540, tt:2410.178\n",
      "Ep:130, loss:0.00001, loss_test:0.10419, lr:5.75e-03, fs:0.60571 (r=0.535,p=0.697),  time:18.543, tt:2429.155\n",
      "Ep:131, loss:0.00001, loss_test:0.10080, lr:5.70e-03, fs:0.63529 (r=0.545,p=0.761),  time:18.548, tt:2448.327\n",
      "Ep:132, loss:0.00001, loss_test:0.08464, lr:5.64e-03, fs:0.79397 (r=0.798,p=0.790),  time:18.552, tt:2467.477\n",
      "Ep:133, loss:0.00001, loss_test:0.09032, lr:5.58e-03, fs:0.76087 (r=0.707,p=0.824),  time:18.560, tt:2487.047\n",
      "Ep:134, loss:0.00001, loss_test:0.10813, lr:5.53e-03, fs:0.56209 (r=0.434,p=0.796),  time:18.565, tt:2506.215\n",
      "Ep:135, loss:0.00001, loss_test:0.09958, lr:5.47e-03, fs:0.65143 (r=0.576,p=0.750),  time:18.570, tt:2525.510\n",
      "Ep:136, loss:0.00001, loss_test:0.08707, lr:5.42e-03, fs:0.76042 (r=0.737,p=0.785),  time:18.574, tt:2544.579\n",
      "Ep:137, loss:0.00001, loss_test:0.09080, lr:5.36e-03, fs:0.78947 (r=0.758,p=0.824),  time:18.576, tt:2563.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.10481, lr:5.31e-03, fs:0.59119 (r=0.475,p=0.783),  time:18.580, tt:2582.664\n",
      "Ep:139, loss:0.00001, loss_test:0.09961, lr:5.26e-03, fs:0.62722 (r=0.535,p=0.757),  time:18.589, tt:2602.464\n",
      "Ep:140, loss:0.00001, loss_test:0.09025, lr:5.20e-03, fs:0.78261 (r=0.727,p=0.847),  time:18.594, tt:2621.813\n",
      "Ep:141, loss:0.00001, loss_test:0.08674, lr:5.15e-03, fs:0.80208 (r=0.778,p=0.828),  time:18.602, tt:2641.480\n",
      "Ep:142, loss:0.00001, loss_test:0.10098, lr:5.10e-03, fs:0.63354 (r=0.515,p=0.823),  time:18.607, tt:2660.844\n",
      "Ep:143, loss:0.00001, loss_test:0.10414, lr:5.05e-03, fs:0.57692 (r=0.455,p=0.789),  time:18.611, tt:2680.027\n",
      "Ep:144, loss:0.00001, loss_test:0.09600, lr:5.00e-03, fs:0.69767 (r=0.606,p=0.822),  time:18.616, tt:2699.322\n",
      "Ep:145, loss:0.00001, loss_test:0.08936, lr:4.95e-03, fs:0.76757 (r=0.717,p=0.826),  time:18.618, tt:2718.159\n",
      "Ep:146, loss:0.00001, loss_test:0.09606, lr:4.90e-03, fs:0.67456 (r=0.576,p=0.814),  time:18.619, tt:2737.065\n",
      "Ep:147, loss:0.00001, loss_test:0.10349, lr:4.85e-03, fs:0.55484 (r=0.434,p=0.768),  time:18.626, tt:2756.693\n",
      "Ep:148, loss:0.00001, loss_test:0.10115, lr:4.80e-03, fs:0.61635 (r=0.495,p=0.817),  time:18.623, tt:2774.838\n",
      "Ep:149, loss:0.00000, loss_test:0.09101, lr:4.75e-03, fs:0.75824 (r=0.697,p=0.831),  time:18.624, tt:2793.641\n",
      "Ep:150, loss:0.00001, loss_test:0.09526, lr:4.71e-03, fs:0.73446 (r=0.657,p=0.833),  time:18.631, tt:2813.291\n",
      "Ep:151, loss:0.00000, loss_test:0.10067, lr:4.66e-03, fs:0.58599 (r=0.465,p=0.793),  time:18.630, tt:2831.741\n",
      "Ep:152, loss:0.00000, loss_test:0.10022, lr:4.61e-03, fs:0.59873 (r=0.475,p=0.810),  time:18.628, tt:2850.104\n",
      "Ep:153, loss:0.00000, loss_test:0.09244, lr:4.57e-03, fs:0.72093 (r=0.626,p=0.849),  time:18.629, tt:2868.934\n",
      "Ep:154, loss:0.00000, loss_test:0.09490, lr:4.52e-03, fs:0.68235 (r=0.586,p=0.817),  time:18.636, tt:2888.640\n",
      "Ep:155, loss:0.00000, loss_test:0.09970, lr:4.48e-03, fs:0.59119 (r=0.475,p=0.783),  time:18.636, tt:2907.260\n",
      "Ep:156, loss:0.00000, loss_test:0.09762, lr:4.43e-03, fs:0.63354 (r=0.515,p=0.823),  time:18.630, tt:2924.972\n",
      "Ep:157, loss:0.00000, loss_test:0.09326, lr:4.39e-03, fs:0.68263 (r=0.576,p=0.838),  time:18.628, tt:2943.281\n",
      "Ep:158, loss:0.00000, loss_test:0.09847, lr:4.34e-03, fs:0.58974 (r=0.465,p=0.807),  time:18.629, tt:2962.033\n",
      "Ep:159, loss:0.00000, loss_test:0.09931, lr:4.30e-03, fs:0.58599 (r=0.465,p=0.793),  time:18.630, tt:2980.852\n",
      "Ep:160, loss:0.00000, loss_test:0.09641, lr:4.26e-03, fs:0.65868 (r=0.556,p=0.809),  time:18.642, tt:3001.443\n",
      "Ep:161, loss:0.00000, loss_test:0.09620, lr:4.21e-03, fs:0.65854 (r=0.545,p=0.831),  time:18.642, tt:3019.997\n",
      "Ep:162, loss:0.00000, loss_test:0.10042, lr:4.17e-03, fs:0.60759 (r=0.485,p=0.814),  time:18.643, tt:3038.831\n",
      "Ep:163, loss:0.00000, loss_test:0.10174, lr:4.13e-03, fs:0.53333 (r=0.404,p=0.784),  time:18.639, tt:3056.762\n",
      "Ep:164, loss:0.00000, loss_test:0.09748, lr:4.09e-03, fs:0.62112 (r=0.505,p=0.806),  time:18.644, tt:3076.281\n",
      "Ep:165, loss:0.00000, loss_test:0.09628, lr:4.05e-03, fs:0.64634 (r=0.535,p=0.815),  time:18.647, tt:3095.345\n",
      "Ep:166, loss:0.00000, loss_test:0.10096, lr:4.01e-03, fs:0.53691 (r=0.404,p=0.800),  time:18.647, tt:3114.083\n",
      "Ep:167, loss:0.00000, loss_test:0.10122, lr:3.97e-03, fs:0.54305 (r=0.414,p=0.788),  time:18.647, tt:3132.692\n",
      "Ep:168, loss:0.00000, loss_test:0.09719, lr:3.93e-03, fs:0.64198 (r=0.525,p=0.825),  time:18.652, tt:3152.156\n",
      "Ep:169, loss:0.00000, loss_test:0.09696, lr:3.89e-03, fs:0.62112 (r=0.505,p=0.806),  time:18.658, tt:3171.807\n",
      "Ep:170, loss:0.00000, loss_test:0.10059, lr:3.85e-03, fs:0.55263 (r=0.424,p=0.792),  time:18.662, tt:3191.132\n",
      "Ep:171, loss:0.00000, loss_test:0.10114, lr:3.81e-03, fs:0.58065 (r=0.455,p=0.804),  time:18.669, tt:3211.061\n",
      "Ep:172, loss:0.00000, loss_test:0.09974, lr:3.77e-03, fs:0.59355 (r=0.465,p=0.821),  time:18.671, tt:3230.142\n",
      "Ep:173, loss:0.00000, loss_test:0.10028, lr:3.73e-03, fs:0.58065 (r=0.455,p=0.804),  time:18.661, tt:3247.067\n",
      "Ep:174, loss:0.00000, loss_test:0.10060, lr:3.70e-03, fs:0.59873 (r=0.475,p=0.810),  time:18.664, tt:3266.281\n",
      "Ep:175, loss:0.00000, loss_test:0.10099, lr:3.66e-03, fs:0.56209 (r=0.434,p=0.796),  time:18.663, tt:3284.661\n",
      "Ep:176, loss:0.00000, loss_test:0.10137, lr:3.62e-03, fs:0.56954 (r=0.434,p=0.827),  time:18.662, tt:3303.172\n",
      "Ep:177, loss:0.00000, loss_test:0.10307, lr:3.59e-03, fs:0.53333 (r=0.404,p=0.784),  time:18.662, tt:3321.843\n",
      "Ep:178, loss:0.00000, loss_test:0.10242, lr:3.55e-03, fs:0.56579 (r=0.434,p=0.811),  time:18.666, tt:3341.204\n",
      "Ep:179, loss:0.00000, loss_test:0.10097, lr:3.52e-03, fs:0.56579 (r=0.434,p=0.811),  time:18.670, tt:3360.647\n",
      "Ep:180, loss:0.00000, loss_test:0.10339, lr:3.48e-03, fs:0.54667 (r=0.414,p=0.804),  time:18.672, tt:3379.640\n",
      "Ep:181, loss:0.00000, loss_test:0.10377, lr:3.45e-03, fs:0.53691 (r=0.404,p=0.800),  time:18.680, tt:3399.713\n",
      "Ep:182, loss:0.00000, loss_test:0.10237, lr:3.41e-03, fs:0.54667 (r=0.414,p=0.804),  time:18.682, tt:3418.760\n",
      "Ep:183, loss:0.00000, loss_test:0.10343, lr:3.38e-03, fs:0.54667 (r=0.414,p=0.804),  time:18.685, tt:3438.111\n",
      "Ep:184, loss:0.00000, loss_test:0.10483, lr:3.34e-03, fs:0.54054 (r=0.404,p=0.816),  time:18.688, tt:3457.349\n",
      "Ep:185, loss:0.00000, loss_test:0.10414, lr:3.31e-03, fs:0.55405 (r=0.414,p=0.837),  time:18.689, tt:3476.198\n",
      "Ep:186, loss:0.00000, loss_test:0.10466, lr:3.28e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.686, tt:3494.346\n",
      "Ep:187, loss:0.00000, loss_test:0.10431, lr:3.24e-03, fs:0.55034 (r=0.414,p=0.820),  time:18.690, tt:3513.706\n",
      "Ep:188, loss:0.00000, loss_test:0.10425, lr:3.21e-03, fs:0.55405 (r=0.414,p=0.837),  time:18.692, tt:3532.738\n",
      "Ep:189, loss:0.00000, loss_test:0.10542, lr:3.18e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.695, tt:3552.011\n",
      "Ep:190, loss:0.00000, loss_test:0.10533, lr:3.15e-03, fs:0.55405 (r=0.414,p=0.837),  time:18.697, tt:3571.211\n",
      "Ep:191, loss:0.00000, loss_test:0.10399, lr:3.12e-03, fs:0.55405 (r=0.414,p=0.837),  time:18.698, tt:3589.987\n",
      "Ep:192, loss:0.00000, loss_test:0.10511, lr:3.09e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.694, tt:3607.914\n",
      "Ep:193, loss:0.00000, loss_test:0.10606, lr:3.05e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.693, tt:3626.513\n",
      "Ep:194, loss:0.00000, loss_test:0.10595, lr:3.02e-03, fs:0.55782 (r=0.414,p=0.854),  time:18.696, tt:3645.764\n",
      "Ep:195, loss:0.00000, loss_test:0.10585, lr:2.99e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.699, tt:3664.915\n",
      "Ep:196, loss:0.00000, loss_test:0.10510, lr:2.96e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.700, tt:3683.908\n",
      "Ep:197, loss:0.00000, loss_test:0.10609, lr:2.93e-03, fs:0.55782 (r=0.414,p=0.854),  time:18.723, tt:3707.104\n",
      "Ep:198, loss:0.00000, loss_test:0.10634, lr:2.90e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.731, tt:3727.408\n",
      "Ep:199, loss:0.00000, loss_test:0.10633, lr:2.88e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.737, tt:3747.449\n",
      "Ep:200, loss:0.00000, loss_test:0.10588, lr:2.85e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.739, tt:3766.609\n",
      "Ep:201, loss:0.00000, loss_test:0.10569, lr:2.82e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.745, tt:3786.473\n",
      "Ep:202, loss:0.00000, loss_test:0.10644, lr:2.79e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.747, tt:3805.719\n",
      "Ep:203, loss:0.00000, loss_test:0.10603, lr:2.76e-03, fs:0.56164 (r=0.414,p=0.872),  time:18.750, tt:3824.941\n",
      "Ep:204, loss:0.00000, loss_test:0.10599, lr:2.73e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.746, tt:3843.000\n",
      "Ep:205, loss:0.00000, loss_test:0.10649, lr:2.71e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.754, tt:3863.256\n",
      "Ep:206, loss:0.00000, loss_test:0.10615, lr:2.68e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.758, tt:3882.964\n",
      "Ep:207, loss:0.00000, loss_test:0.10681, lr:2.65e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.763, tt:3902.646\n",
      "Ep:208, loss:0.00000, loss_test:0.10626, lr:2.63e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.768, tt:3922.528\n",
      "Ep:209, loss:0.00000, loss_test:0.10628, lr:2.60e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.772, tt:3942.101\n",
      "Ep:210, loss:0.00000, loss_test:0.10736, lr:2.57e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.775, tt:3961.564\n",
      "Ep:211, loss:0.00000, loss_test:0.10674, lr:2.55e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.778, tt:3980.864\n",
      "Ep:212, loss:0.00000, loss_test:0.10635, lr:2.52e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.784, tt:4000.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:213, loss:0.00000, loss_test:0.10734, lr:2.50e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.788, tt:4020.558\n",
      "Ep:214, loss:0.00000, loss_test:0.10697, lr:2.47e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.794, tt:4040.744\n",
      "Ep:215, loss:0.00000, loss_test:0.10687, lr:2.45e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.796, tt:4059.832\n",
      "Ep:216, loss:0.00000, loss_test:0.10727, lr:2.42e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.799, tt:4079.323\n",
      "Ep:217, loss:0.00000, loss_test:0.10689, lr:2.40e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.803, tt:4098.970\n",
      "Ep:218, loss:0.00000, loss_test:0.10760, lr:2.38e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.804, tt:4118.075\n",
      "Ep:219, loss:0.00000, loss_test:0.10786, lr:2.35e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.808, tt:4137.723\n",
      "Ep:220, loss:0.00000, loss_test:0.10722, lr:2.33e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.810, tt:4157.007\n",
      "Ep:221, loss:0.00000, loss_test:0.10801, lr:2.31e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.811, tt:4176.136\n",
      "Ep:222, loss:0.00000, loss_test:0.10814, lr:2.28e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.815, tt:4195.770\n",
      "Ep:223, loss:0.00000, loss_test:0.10783, lr:2.26e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.821, tt:4215.839\n",
      "Ep:224, loss:0.00000, loss_test:0.10772, lr:2.24e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.828, tt:4236.244\n",
      "Ep:225, loss:0.00000, loss_test:0.10791, lr:2.21e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.831, tt:4255.712\n",
      "Ep:226, loss:0.00000, loss_test:0.10830, lr:2.19e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.831, tt:4274.743\n",
      "Ep:227, loss:0.00000, loss_test:0.10827, lr:2.17e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.839, tt:4295.217\n",
      "Ep:228, loss:0.00000, loss_test:0.10786, lr:2.15e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.842, tt:4314.750\n",
      "Ep:229, loss:0.00000, loss_test:0.10839, lr:2.13e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.849, tt:4335.327\n",
      "Ep:230, loss:0.00000, loss_test:0.10817, lr:2.11e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.857, tt:4356.047\n",
      "Ep:231, loss:0.00000, loss_test:0.10832, lr:2.08e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.861, tt:4375.851\n",
      "Ep:232, loss:0.00000, loss_test:0.10837, lr:2.06e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.869, tt:4396.551\n",
      "Ep:233, loss:0.00000, loss_test:0.10789, lr:2.04e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.873, tt:4416.334\n",
      "Ep:234, loss:0.00000, loss_test:0.10843, lr:2.02e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.875, tt:4435.569\n",
      "Ep:235, loss:0.00000, loss_test:0.10876, lr:2.00e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.878, tt:4455.203\n",
      "Ep:236, loss:0.00000, loss_test:0.10821, lr:1.98e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.880, tt:4474.597\n",
      "Ep:237, loss:0.00000, loss_test:0.10811, lr:1.96e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.885, tt:4494.717\n",
      "Ep:238, loss:0.00000, loss_test:0.10896, lr:1.94e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.890, tt:4514.621\n",
      "Ep:239, loss:0.00000, loss_test:0.10878, lr:1.92e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.889, tt:4533.244\n",
      "Ep:240, loss:0.00000, loss_test:0.10847, lr:1.90e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.894, tt:4553.400\n",
      "Ep:241, loss:0.00000, loss_test:0.10869, lr:1.89e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.901, tt:4574.072\n",
      "Ep:242, loss:0.00000, loss_test:0.10885, lr:1.87e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.902, tt:4593.148\n",
      "Ep:243, loss:0.00000, loss_test:0.10876, lr:1.85e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.905, tt:4612.826\n",
      "Ep:244, loss:0.00000, loss_test:0.10898, lr:1.83e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.909, tt:4632.818\n",
      "Ep:245, loss:0.00000, loss_test:0.10903, lr:1.81e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.917, tt:4653.673\n",
      "Ep:246, loss:0.00000, loss_test:0.10873, lr:1.79e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.919, tt:4673.004\n",
      "Ep:247, loss:0.00000, loss_test:0.10930, lr:1.78e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.924, tt:4693.044\n",
      "Ep:248, loss:0.00000, loss_test:0.10940, lr:1.76e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.924, tt:4711.984\n",
      "Ep:249, loss:0.00000, loss_test:0.10908, lr:1.74e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.924, tt:4731.120\n",
      "Ep:250, loss:0.00000, loss_test:0.10888, lr:1.72e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.923, tt:4749.696\n",
      "Ep:251, loss:0.00000, loss_test:0.10932, lr:1.71e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.920, tt:4767.804\n",
      "Ep:252, loss:0.00000, loss_test:0.10946, lr:1.69e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.922, tt:4787.359\n",
      "Ep:253, loss:0.00000, loss_test:0.10928, lr:1.67e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.920, tt:4805.802\n",
      "Ep:254, loss:0.00000, loss_test:0.10908, lr:1.65e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.919, tt:4824.454\n",
      "Ep:255, loss:0.00000, loss_test:0.10927, lr:1.64e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.917, tt:4842.777\n",
      "Ep:256, loss:0.00000, loss_test:0.10933, lr:1.62e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.906, tt:4858.738\n",
      "Ep:257, loss:0.00000, loss_test:0.10949, lr:1.61e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.900, tt:4876.291\n",
      "Ep:258, loss:0.00000, loss_test:0.10950, lr:1.59e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.892, tt:4893.086\n",
      "Ep:259, loss:0.00000, loss_test:0.10926, lr:1.57e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.887, tt:4910.554\n",
      "Ep:260, loss:0.00000, loss_test:0.10955, lr:1.56e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.878, tt:4927.212\n",
      "Ep:261, loss:0.00000, loss_test:0.10995, lr:1.54e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.870, tt:4943.870\n",
      "Ep:262, loss:0.00000, loss_test:0.10983, lr:1.53e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.862, tt:4960.654\n",
      "Ep:263, loss:0.00000, loss_test:0.10943, lr:1.51e-03, fs:0.56552 (r=0.414,p=0.891),  time:18.856, tt:4977.913\n",
      "Ep:264, loss:0.00000, loss_test:0.11015, lr:1.50e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.845, tt:4993.801\n",
      "Ep:265, loss:0.00000, loss_test:0.11029, lr:1.48e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.835, tt:5010.149\n",
      "Ep:266, loss:0.00000, loss_test:0.11009, lr:1.47e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.827, tt:5026.924\n",
      "Ep:267, loss:0.00000, loss_test:0.11003, lr:1.45e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.818, tt:5043.260\n",
      "Ep:268, loss:0.00000, loss_test:0.11013, lr:1.44e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.805, tt:5058.561\n",
      "Ep:269, loss:0.00000, loss_test:0.11017, lr:1.42e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.798, tt:5075.591\n",
      "Ep:270, loss:0.00000, loss_test:0.11018, lr:1.41e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.794, tt:5093.098\n",
      "Ep:271, loss:0.00000, loss_test:0.11022, lr:1.39e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.789, tt:5110.714\n",
      "Ep:272, loss:0.00000, loss_test:0.11012, lr:1.38e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.780, tt:5127.063\n",
      "Ep:273, loss:0.00000, loss_test:0.11003, lr:1.37e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.770, tt:5143.099\n",
      "Ep:274, loss:0.00000, loss_test:0.11042, lr:1.35e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.764, tt:5159.986\n",
      "Ep:275, loss:0.00000, loss_test:0.11054, lr:1.34e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.757, tt:5177.033\n",
      "Ep:276, loss:0.00000, loss_test:0.11013, lr:1.33e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.752, tt:5194.414\n",
      "Ep:277, loss:0.00000, loss_test:0.11025, lr:1.31e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.749, tt:5212.127\n",
      "Ep:278, loss:0.00000, loss_test:0.11061, lr:1.30e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.743, tt:5229.330\n",
      "Ep:279, loss:0.00000, loss_test:0.11057, lr:1.29e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.739, tt:5246.926\n",
      "Ep:280, loss:0.00000, loss_test:0.11037, lr:1.27e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.733, tt:5263.977\n",
      "Ep:281, loss:0.00000, loss_test:0.11057, lr:1.26e-03, fs:0.55556 (r=0.404,p=0.889),  time:18.737, tt:5283.697\n",
      "Ep:282, loss:0.00000, loss_test:0.11060, lr:1.25e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.733, tt:5301.426\n",
      "Ep:283, loss:0.00000, loss_test:0.11036, lr:1.24e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.727, tt:5318.411\n",
      "Ep:284, loss:0.00000, loss_test:0.11056, lr:1.22e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.724, tt:5336.348\n",
      "Ep:285, loss:0.00000, loss_test:0.11099, lr:1.21e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.717, tt:5353.088\n",
      "Ep:286, loss:0.00000, loss_test:0.11083, lr:1.20e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.718, tt:5372.047\n",
      "Ep:287, loss:0.00000, loss_test:0.11042, lr:1.19e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.717, tt:5390.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:288, loss:0.00000, loss_test:0.11067, lr:1.18e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.712, tt:5407.743\n",
      "Ep:289, loss:0.00000, loss_test:0.11095, lr:1.16e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.707, tt:5425.060\n",
      "Ep:290, loss:0.00000, loss_test:0.11096, lr:1.15e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.703, tt:5442.463\n",
      "Ep:291, loss:0.00000, loss_test:0.11074, lr:1.14e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.696, tt:5459.160\n",
      "Ep:292, loss:0.00000, loss_test:0.11078, lr:1.13e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.692, tt:5476.875\n",
      "Ep:293, loss:0.00000, loss_test:0.11097, lr:1.12e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.690, tt:5494.731\n",
      "Ep:294, loss:0.00000, loss_test:0.11087, lr:1.11e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.686, tt:5512.460\n",
      "Ep:295, loss:0.00000, loss_test:0.11093, lr:1.10e-03, fs:0.55944 (r=0.404,p=0.909),  time:18.677, tt:5528.479\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14529, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:8.953, tt:8.953\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14514, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.067, tt:18.134\n",
      "Ep:2, loss:0.00004, loss_test:0.14491, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.618, tt:31.854\n",
      "Ep:3, loss:0.00004, loss_test:0.14459, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:11.625, tt:46.500\n",
      "Ep:4, loss:0.00004, loss_test:0.14420, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.169, tt:60.847\n",
      "Ep:5, loss:0.00004, loss_test:0.14371, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.771, tt:76.627\n",
      "Ep:6, loss:0.00004, loss_test:0.14312, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:13.102, tt:91.715\n",
      "Ep:7, loss:0.00004, loss_test:0.14241, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:13.323, tt:106.585\n",
      "Ep:8, loss:0.00004, loss_test:0.14154, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:13.569, tt:122.122\n",
      "Ep:9, loss:0.00004, loss_test:0.14051, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:13.753, tt:137.525\n",
      "Ep:10, loss:0.00004, loss_test:0.13921, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:13.928, tt:153.208\n",
      "Ep:11, loss:0.00004, loss_test:0.13760, lr:1.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:14.105, tt:169.259\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.13560, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:14.150, tt:183.946\n",
      "Ep:13, loss:0.00004, loss_test:0.13347, lr:1.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:14.194, tt:198.723\n",
      "Ep:14, loss:0.00004, loss_test:0.13125, lr:1.00e-02, fs:0.64639 (r=0.859,p=0.518),  time:14.284, tt:214.258\n",
      "Ep:15, loss:0.00003, loss_test:0.12981, lr:1.00e-02, fs:0.62762 (r=0.758,p=0.536),  time:14.324, tt:229.179\n",
      "Ep:16, loss:0.00003, loss_test:0.12917, lr:1.00e-02, fs:0.61187 (r=0.677,p=0.558),  time:14.400, tt:244.794\n",
      "Ep:17, loss:0.00003, loss_test:0.12909, lr:1.00e-02, fs:0.61765 (r=0.636,p=0.600),  time:14.447, tt:260.045\n",
      "Ep:18, loss:0.00003, loss_test:0.12968, lr:1.00e-02, fs:0.56180 (r=0.505,p=0.633),  time:14.541, tt:276.281\n",
      "Ep:19, loss:0.00003, loss_test:0.12995, lr:1.00e-02, fs:0.55491 (r=0.485,p=0.649),  time:14.641, tt:292.827\n",
      "Ep:20, loss:0.00003, loss_test:0.12880, lr:1.00e-02, fs:0.54118 (r=0.465,p=0.648),  time:14.713, tt:308.983\n",
      "Ep:21, loss:0.00003, loss_test:0.12616, lr:1.00e-02, fs:0.59669 (r=0.545,p=0.659),  time:14.724, tt:323.921\n",
      "Ep:22, loss:0.00003, loss_test:0.12382, lr:1.00e-02, fs:0.63590 (r=0.626,p=0.646),  time:14.705, tt:338.211\n",
      "Ep:23, loss:0.00003, loss_test:0.12246, lr:9.90e-03, fs:0.64322 (r=0.646,p=0.640),  time:14.686, tt:352.462\n",
      "Ep:24, loss:0.00003, loss_test:0.12148, lr:9.80e-03, fs:0.65347 (r=0.667,p=0.641),  time:14.683, tt:367.074\n",
      "Ep:25, loss:0.00003, loss_test:0.12070, lr:9.70e-03, fs:0.65327 (r=0.657,p=0.650),  time:14.675, tt:381.544\n",
      "Ep:26, loss:0.00003, loss_test:0.12014, lr:9.61e-03, fs:0.65641 (r=0.646,p=0.667),  time:14.697, tt:396.828\n",
      "Ep:27, loss:0.00003, loss_test:0.11989, lr:9.51e-03, fs:0.63784 (r=0.596,p=0.686),  time:14.719, tt:412.135\n",
      "Ep:28, loss:0.00003, loss_test:0.11959, lr:9.41e-03, fs:0.61798 (r=0.556,p=0.696),  time:14.750, tt:427.761\n",
      "Ep:29, loss:0.00003, loss_test:0.11870, lr:9.32e-03, fs:0.62570 (r=0.566,p=0.700),  time:14.748, tt:442.429\n",
      "Ep:30, loss:0.00003, loss_test:0.11721, lr:9.23e-03, fs:0.62983 (r=0.576,p=0.695),  time:14.755, tt:457.393\n",
      "Ep:31, loss:0.00003, loss_test:0.11578, lr:9.14e-03, fs:0.65591 (r=0.616,p=0.701),  time:14.768, tt:472.567\n",
      "Ep:32, loss:0.00003, loss_test:0.11465, lr:9.04e-03, fs:0.67016 (r=0.646,p=0.696),  time:14.766, tt:487.278\n",
      "Ep:33, loss:0.00003, loss_test:0.11370, lr:8.95e-03, fs:0.65969 (r=0.636,p=0.685),  time:14.782, tt:502.597\n",
      "Ep:34, loss:0.00003, loss_test:0.11280, lr:8.86e-03, fs:0.68085 (r=0.646,p=0.719),  time:14.789, tt:517.628\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.11207, lr:8.86e-03, fs:0.65934 (r=0.606,p=0.723),  time:14.802, tt:532.855\n",
      "Ep:36, loss:0.00003, loss_test:0.11155, lr:8.86e-03, fs:0.63636 (r=0.566,p=0.727),  time:14.795, tt:547.423\n",
      "Ep:37, loss:0.00002, loss_test:0.11078, lr:8.86e-03, fs:0.63953 (r=0.556,p=0.753),  time:14.789, tt:561.978\n",
      "Ep:38, loss:0.00002, loss_test:0.10979, lr:8.86e-03, fs:0.64368 (r=0.566,p=0.747),  time:14.821, tt:578.036\n",
      "Ep:39, loss:0.00002, loss_test:0.10892, lr:8.86e-03, fs:0.68132 (r=0.626,p=0.747),  time:14.804, tt:592.156\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10823, lr:8.86e-03, fs:0.69189 (r=0.646,p=0.744),  time:14.788, tt:606.322\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.10773, lr:8.86e-03, fs:0.69892 (r=0.657,p=0.747),  time:14.813, tt:622.141\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10727, lr:8.86e-03, fs:0.69231 (r=0.636,p=0.759),  time:14.823, tt:637.396\n",
      "Ep:43, loss:0.00002, loss_test:0.10680, lr:8.86e-03, fs:0.69613 (r=0.636,p=0.768),  time:14.847, tt:653.283\n",
      "Ep:44, loss:0.00002, loss_test:0.10623, lr:8.86e-03, fs:0.69663 (r=0.626,p=0.785),  time:14.948, tt:672.670\n",
      "Ep:45, loss:0.00002, loss_test:0.10552, lr:8.86e-03, fs:0.70391 (r=0.636,p=0.787),  time:14.969, tt:688.564\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.10464, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.000, tt:704.987\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.10388, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:14.997, tt:719.851\n",
      "Ep:48, loss:0.00002, loss_test:0.10331, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.026, tt:736.283\n",
      "Ep:49, loss:0.00002, loss_test:0.10291, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.025, tt:751.226\n",
      "Ep:50, loss:0.00002, loss_test:0.10271, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.034, tt:766.708\n",
      "Ep:51, loss:0.00002, loss_test:0.10244, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.020, tt:781.055\n",
      "Ep:52, loss:0.00002, loss_test:0.10198, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.036, tt:796.915\n",
      "Ep:53, loss:0.00002, loss_test:0.10149, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.053, tt:812.874\n",
      "Ep:54, loss:0.00002, loss_test:0.10113, lr:8.86e-03, fs:0.71823 (r=0.657,p=0.793),  time:15.076, tt:829.189\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.10091, lr:8.86e-03, fs:0.71508 (r=0.646,p=0.800),  time:15.090, tt:845.060\n",
      "Ep:56, loss:0.00002, loss_test:0.10080, lr:8.86e-03, fs:0.70056 (r=0.626,p=0.795),  time:15.109, tt:861.187\n",
      "Ep:57, loss:0.00002, loss_test:0.10072, lr:8.86e-03, fs:0.70056 (r=0.626,p=0.795),  time:15.097, tt:875.641\n",
      "Ep:58, loss:0.00002, loss_test:0.10046, lr:8.86e-03, fs:0.69318 (r=0.616,p=0.792),  time:15.120, tt:892.081\n",
      "Ep:59, loss:0.00002, loss_test:0.09997, lr:8.86e-03, fs:0.71508 (r=0.646,p=0.800),  time:15.135, tt:908.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00002, loss_test:0.09950, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.127, tt:922.744\n",
      "Ep:61, loss:0.00002, loss_test:0.09921, lr:8.86e-03, fs:0.71111 (r=0.646,p=0.790),  time:15.135, tt:938.396\n",
      "Ep:62, loss:0.00002, loss_test:0.09917, lr:8.86e-03, fs:0.69714 (r=0.616,p=0.803),  time:15.144, tt:954.099\n",
      "Ep:63, loss:0.00002, loss_test:0.09909, lr:8.86e-03, fs:0.69714 (r=0.616,p=0.803),  time:15.143, tt:969.163\n",
      "Ep:64, loss:0.00002, loss_test:0.09884, lr:8.86e-03, fs:0.70455 (r=0.626,p=0.805),  time:15.170, tt:986.018\n",
      "Ep:65, loss:0.00002, loss_test:0.09857, lr:8.86e-03, fs:0.70056 (r=0.626,p=0.795),  time:15.180, tt:1001.897\n",
      "Ep:66, loss:0.00002, loss_test:0.09842, lr:8.78e-03, fs:0.70056 (r=0.626,p=0.795),  time:15.185, tt:1017.425\n",
      "Ep:67, loss:0.00002, loss_test:0.09855, lr:8.69e-03, fs:0.68571 (r=0.606,p=0.789),  time:15.201, tt:1033.677\n",
      "Ep:68, loss:0.00002, loss_test:0.09878, lr:8.60e-03, fs:0.67836 (r=0.586,p=0.806),  time:15.219, tt:1050.116\n",
      "Ep:69, loss:0.00002, loss_test:0.09886, lr:8.51e-03, fs:0.66272 (r=0.566,p=0.800),  time:15.237, tt:1066.576\n",
      "Ep:70, loss:0.00002, loss_test:0.09873, lr:8.43e-03, fs:0.66272 (r=0.566,p=0.800),  time:15.241, tt:1082.112\n",
      "Ep:71, loss:0.00002, loss_test:0.09861, lr:8.35e-03, fs:0.66272 (r=0.566,p=0.800),  time:15.254, tt:1098.314\n",
      "Ep:72, loss:0.00002, loss_test:0.09854, lr:8.26e-03, fs:0.66272 (r=0.566,p=0.800),  time:15.252, tt:1113.361\n",
      "Ep:73, loss:0.00002, loss_test:0.09854, lr:8.18e-03, fs:0.67059 (r=0.576,p=0.803),  time:15.266, tt:1129.700\n",
      "Ep:74, loss:0.00002, loss_test:0.09854, lr:8.10e-03, fs:0.67059 (r=0.576,p=0.803),  time:15.268, tt:1145.068\n",
      "Ep:75, loss:0.00002, loss_test:0.09862, lr:8.02e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.265, tt:1160.165\n",
      "Ep:76, loss:0.00002, loss_test:0.09868, lr:7.94e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.289, tt:1177.235\n",
      "Ep:77, loss:0.00002, loss_test:0.09862, lr:7.86e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.300, tt:1193.381\n",
      "Ep:78, loss:0.00002, loss_test:0.09843, lr:7.78e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.294, tt:1208.247\n",
      "Ep:79, loss:0.00002, loss_test:0.09824, lr:7.70e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.300, tt:1223.960\n",
      "Ep:80, loss:0.00002, loss_test:0.09816, lr:7.62e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.307, tt:1239.887\n",
      "Ep:81, loss:0.00002, loss_test:0.09815, lr:7.55e-03, fs:0.66667 (r=0.566,p=0.812),  time:15.315, tt:1255.861\n",
      "Ep:82, loss:0.00002, loss_test:0.09814, lr:7.47e-03, fs:0.65868 (r=0.556,p=0.809),  time:15.327, tt:1272.112\n",
      "Ep:83, loss:0.00002, loss_test:0.09799, lr:7.40e-03, fs:0.65060 (r=0.545,p=0.806),  time:15.331, tt:1287.838\n",
      "Ep:84, loss:0.00001, loss_test:0.09773, lr:7.32e-03, fs:0.65868 (r=0.556,p=0.809),  time:15.336, tt:1303.549\n",
      "Ep:85, loss:0.00001, loss_test:0.09749, lr:7.25e-03, fs:0.65868 (r=0.556,p=0.809),  time:15.347, tt:1319.799\n",
      "Ep:86, loss:0.00001, loss_test:0.09739, lr:7.18e-03, fs:0.65868 (r=0.556,p=0.809),  time:15.357, tt:1336.041\n",
      "Ep:87, loss:0.00001, loss_test:0.09740, lr:7.11e-03, fs:0.65868 (r=0.556,p=0.809),  time:15.382, tt:1353.625\n",
      "Ep:88, loss:0.00001, loss_test:0.09750, lr:7.03e-03, fs:0.65060 (r=0.545,p=0.806),  time:15.380, tt:1368.817\n",
      "Ep:89, loss:0.00001, loss_test:0.09763, lr:6.96e-03, fs:0.65060 (r=0.545,p=0.806),  time:15.399, tt:1385.914\n",
      "Ep:90, loss:0.00001, loss_test:0.09774, lr:6.89e-03, fs:0.65060 (r=0.545,p=0.806),  time:15.407, tt:1402.041\n",
      "Ep:91, loss:0.00001, loss_test:0.09773, lr:6.83e-03, fs:0.64242 (r=0.535,p=0.803),  time:15.414, tt:1418.043\n",
      "Ep:92, loss:0.00001, loss_test:0.09768, lr:6.76e-03, fs:0.64242 (r=0.535,p=0.803),  time:15.432, tt:1435.158\n",
      "Ep:93, loss:0.00001, loss_test:0.09770, lr:6.69e-03, fs:0.64242 (r=0.535,p=0.803),  time:15.442, tt:1451.561\n",
      "Ep:94, loss:0.00001, loss_test:0.09772, lr:6.62e-03, fs:0.63415 (r=0.525,p=0.800),  time:15.451, tt:1467.884\n",
      "Ep:95, loss:0.00001, loss_test:0.09780, lr:6.56e-03, fs:0.63804 (r=0.525,p=0.812),  time:15.450, tt:1483.155\n",
      "Ep:96, loss:0.00001, loss_test:0.09784, lr:6.49e-03, fs:0.63804 (r=0.525,p=0.812),  time:15.458, tt:1499.430\n",
      "Ep:97, loss:0.00001, loss_test:0.09781, lr:6.43e-03, fs:0.63804 (r=0.525,p=0.812),  time:15.476, tt:1516.681\n",
      "Ep:98, loss:0.00001, loss_test:0.09783, lr:6.36e-03, fs:0.63804 (r=0.525,p=0.812),  time:15.493, tt:1533.796\n",
      "Ep:99, loss:0.00001, loss_test:0.09789, lr:6.30e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.512, tt:1551.240\n",
      "Ep:100, loss:0.00001, loss_test:0.09793, lr:6.24e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.529, tt:1568.392\n",
      "Ep:101, loss:0.00001, loss_test:0.09785, lr:6.17e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.539, tt:1584.935\n",
      "Ep:102, loss:0.00001, loss_test:0.09777, lr:6.11e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.548, tt:1601.442\n",
      "Ep:103, loss:0.00001, loss_test:0.09783, lr:6.05e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.555, tt:1617.743\n",
      "Ep:104, loss:0.00001, loss_test:0.09792, lr:5.99e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.577, tt:1635.598\n",
      "Ep:105, loss:0.00001, loss_test:0.09805, lr:5.93e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.595, tt:1653.105\n",
      "Ep:106, loss:0.00001, loss_test:0.09814, lr:5.87e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.607, tt:1670.000\n",
      "Ep:107, loss:0.00001, loss_test:0.09825, lr:5.81e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.614, tt:1686.356\n",
      "Ep:108, loss:0.00001, loss_test:0.09829, lr:5.75e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.624, tt:1702.995\n",
      "Ep:109, loss:0.00001, loss_test:0.09832, lr:5.70e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.628, tt:1719.046\n",
      "Ep:110, loss:0.00001, loss_test:0.09835, lr:5.64e-03, fs:0.62963 (r=0.515,p=0.810),  time:15.628, tt:1734.717\n",
      "Ep:111, loss:0.00001, loss_test:0.09839, lr:5.58e-03, fs:0.62500 (r=0.505,p=0.820),  time:15.632, tt:1750.832\n",
      "Ep:112, loss:0.00001, loss_test:0.09837, lr:5.53e-03, fs:0.62500 (r=0.505,p=0.820),  time:15.644, tt:1767.780\n",
      "Ep:113, loss:0.00001, loss_test:0.09833, lr:5.47e-03, fs:0.62500 (r=0.505,p=0.820),  time:15.646, tt:1783.682\n",
      "Ep:114, loss:0.00001, loss_test:0.09832, lr:5.42e-03, fs:0.62500 (r=0.505,p=0.820),  time:15.651, tt:1799.861\n",
      "Ep:115, loss:0.00001, loss_test:0.09834, lr:5.36e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.649, tt:1815.285\n",
      "Ep:116, loss:0.00001, loss_test:0.09839, lr:5.31e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.661, tt:1832.294\n",
      "Ep:117, loss:0.00001, loss_test:0.09838, lr:5.26e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.667, tt:1848.753\n",
      "Ep:118, loss:0.00001, loss_test:0.09832, lr:5.20e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.677, tt:1865.536\n",
      "Ep:119, loss:0.00001, loss_test:0.09824, lr:5.15e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.687, tt:1882.439\n",
      "Ep:120, loss:0.00001, loss_test:0.09817, lr:5.10e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.692, tt:1898.735\n",
      "Ep:121, loss:0.00001, loss_test:0.09815, lr:5.05e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.706, tt:1916.106\n",
      "Ep:122, loss:0.00001, loss_test:0.09814, lr:5.00e-03, fs:0.61250 (r=0.495,p=0.803),  time:15.713, tt:1932.659\n",
      "Ep:123, loss:0.00001, loss_test:0.09818, lr:4.95e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.701, tt:1946.935\n",
      "Ep:124, loss:0.00001, loss_test:0.09821, lr:4.90e-03, fs:0.60377 (r=0.485,p=0.800),  time:15.703, tt:1962.885\n",
      "Ep:125, loss:0.00001, loss_test:0.09821, lr:4.85e-03, fs:0.60377 (r=0.485,p=0.800),  time:15.705, tt:1978.886\n",
      "Ep:126, loss:0.00001, loss_test:0.09826, lr:4.80e-03, fs:0.60377 (r=0.485,p=0.800),  time:15.706, tt:1994.695\n",
      "Ep:127, loss:0.00001, loss_test:0.09836, lr:4.75e-03, fs:0.60759 (r=0.485,p=0.814),  time:15.708, tt:2010.570\n",
      "Ep:128, loss:0.00001, loss_test:0.09842, lr:4.71e-03, fs:0.60759 (r=0.485,p=0.814),  time:15.704, tt:2025.858\n",
      "Ep:129, loss:0.00001, loss_test:0.09838, lr:4.66e-03, fs:0.60759 (r=0.485,p=0.814),  time:15.703, tt:2041.337\n",
      "Ep:130, loss:0.00001, loss_test:0.09833, lr:4.61e-03, fs:0.61250 (r=0.495,p=0.803),  time:15.693, tt:2055.813\n",
      "Ep:131, loss:0.00001, loss_test:0.09841, lr:4.57e-03, fs:0.61250 (r=0.495,p=0.803),  time:15.691, tt:2071.244\n",
      "Ep:132, loss:0.00001, loss_test:0.09854, lr:4.52e-03, fs:0.61250 (r=0.495,p=0.803),  time:15.691, tt:2086.940\n",
      "Ep:133, loss:0.00001, loss_test:0.09862, lr:4.48e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.685, tt:2101.740\n",
      "Ep:134, loss:0.00001, loss_test:0.09866, lr:4.43e-03, fs:0.61635 (r=0.495,p=0.817),  time:15.679, tt:2116.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.09864, lr:4.39e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.678, tt:2132.170\n",
      "Ep:136, loss:0.00001, loss_test:0.09861, lr:4.34e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.678, tt:2147.818\n",
      "Ep:137, loss:0.00001, loss_test:0.09860, lr:4.30e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.677, tt:2163.494\n",
      "Ep:138, loss:0.00001, loss_test:0.09865, lr:4.26e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.670, tt:2178.081\n",
      "Ep:139, loss:0.00001, loss_test:0.09865, lr:4.21e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.664, tt:2193.004\n",
      "Ep:140, loss:0.00001, loss_test:0.09864, lr:4.17e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.662, tt:2208.304\n",
      "Ep:141, loss:0.00001, loss_test:0.09869, lr:4.13e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.662, tt:2224.007\n",
      "Ep:142, loss:0.00001, loss_test:0.09877, lr:4.09e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.666, tt:2240.226\n",
      "Ep:143, loss:0.00001, loss_test:0.09875, lr:4.05e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.670, tt:2256.445\n",
      "Ep:144, loss:0.00001, loss_test:0.09871, lr:4.01e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.673, tt:2272.604\n",
      "Ep:145, loss:0.00001, loss_test:0.09877, lr:3.97e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.677, tt:2288.823\n",
      "Ep:146, loss:0.00001, loss_test:0.09881, lr:3.93e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.677, tt:2304.498\n",
      "Ep:147, loss:0.00001, loss_test:0.09878, lr:3.89e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.676, tt:2320.011\n",
      "Ep:148, loss:0.00001, loss_test:0.09873, lr:3.85e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.674, tt:2335.430\n",
      "Ep:149, loss:0.00001, loss_test:0.09869, lr:3.81e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.669, tt:2350.421\n",
      "Ep:150, loss:0.00001, loss_test:0.09870, lr:3.77e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.669, tt:2365.980\n",
      "Ep:151, loss:0.00001, loss_test:0.09873, lr:3.73e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.669, tt:2381.691\n",
      "Ep:152, loss:0.00001, loss_test:0.09871, lr:3.70e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.668, tt:2397.242\n",
      "Ep:153, loss:0.00001, loss_test:0.09865, lr:3.66e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.662, tt:2411.943\n",
      "Ep:154, loss:0.00001, loss_test:0.09860, lr:3.62e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.662, tt:2427.643\n",
      "Ep:155, loss:0.00001, loss_test:0.09859, lr:3.59e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.655, tt:2442.125\n",
      "Ep:156, loss:0.00001, loss_test:0.09862, lr:3.55e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.656, tt:2457.971\n",
      "Ep:157, loss:0.00001, loss_test:0.09863, lr:3.52e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.660, tt:2474.279\n",
      "Ep:158, loss:0.00001, loss_test:0.09863, lr:3.48e-03, fs:0.62025 (r=0.495,p=0.831),  time:15.660, tt:2489.914\n",
      "Ep:159, loss:0.00001, loss_test:0.09866, lr:3.45e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.656, tt:2505.013\n",
      "Ep:160, loss:0.00001, loss_test:0.09869, lr:3.41e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.660, tt:2521.264\n",
      "Ep:161, loss:0.00001, loss_test:0.09871, lr:3.38e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.662, tt:2537.323\n",
      "Ep:162, loss:0.00001, loss_test:0.09870, lr:3.34e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.663, tt:2553.119\n",
      "Ep:163, loss:0.00001, loss_test:0.09868, lr:3.31e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.663, tt:2568.809\n",
      "Ep:164, loss:0.00001, loss_test:0.09874, lr:3.28e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.661, tt:2584.121\n",
      "Ep:165, loss:0.00001, loss_test:0.09877, lr:3.24e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.661, tt:2599.677\n",
      "Ep:166, loss:0.00001, loss_test:0.09876, lr:3.21e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.659, tt:2614.997\n",
      "Ep:167, loss:0.00001, loss_test:0.09871, lr:3.18e-03, fs:0.61538 (r=0.485,p=0.842),  time:15.657, tt:2630.356\n",
      "Ep:168, loss:0.00001, loss_test:0.09878, lr:3.15e-03, fs:0.60645 (r=0.475,p=0.839),  time:15.661, tt:2646.695\n",
      "Ep:169, loss:0.00001, loss_test:0.09893, lr:3.12e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.661, tt:2662.365\n",
      "Ep:170, loss:0.00001, loss_test:0.09897, lr:3.09e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.658, tt:2677.529\n",
      "Ep:171, loss:0.00001, loss_test:0.09895, lr:3.05e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.660, tt:2693.502\n",
      "Ep:172, loss:0.00001, loss_test:0.09895, lr:3.02e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.663, tt:2709.648\n",
      "Ep:173, loss:0.00001, loss_test:0.09899, lr:2.99e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.667, tt:2726.048\n",
      "Ep:174, loss:0.00001, loss_test:0.09907, lr:2.96e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.664, tt:2741.271\n",
      "Ep:175, loss:0.00001, loss_test:0.09912, lr:2.93e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.667, tt:2757.308\n",
      "Ep:176, loss:0.00001, loss_test:0.09915, lr:2.90e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.671, tt:2773.796\n",
      "Ep:177, loss:0.00001, loss_test:0.09915, lr:2.88e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.670, tt:2789.339\n",
      "Ep:178, loss:0.00001, loss_test:0.09919, lr:2.85e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.668, tt:2804.527\n",
      "Ep:179, loss:0.00001, loss_test:0.09925, lr:2.82e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.669, tt:2820.334\n",
      "Ep:180, loss:0.00001, loss_test:0.09924, lr:2.79e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.671, tt:2836.529\n",
      "Ep:181, loss:0.00001, loss_test:0.09918, lr:2.76e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.671, tt:2852.163\n",
      "Ep:182, loss:0.00001, loss_test:0.09917, lr:2.73e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.673, tt:2868.101\n",
      "Ep:183, loss:0.00001, loss_test:0.09920, lr:2.71e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.666, tt:2882.585\n",
      "Ep:184, loss:0.00001, loss_test:0.09924, lr:2.68e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.667, tt:2898.469\n",
      "Ep:185, loss:0.00001, loss_test:0.09927, lr:2.65e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.663, tt:2913.228\n",
      "Ep:186, loss:0.00001, loss_test:0.09928, lr:2.63e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.658, tt:2928.056\n",
      "Ep:187, loss:0.00001, loss_test:0.09930, lr:2.60e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.659, tt:2943.875\n",
      "Ep:188, loss:0.00001, loss_test:0.09933, lr:2.57e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.655, tt:2958.758\n",
      "Ep:189, loss:0.00001, loss_test:0.09936, lr:2.55e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.652, tt:2973.866\n",
      "Ep:190, loss:0.00001, loss_test:0.09938, lr:2.52e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.649, tt:2989.054\n",
      "Ep:191, loss:0.00001, loss_test:0.09939, lr:2.50e-03, fs:0.58824 (r=0.455,p=0.833),  time:15.650, tt:3004.881\n",
      "Ep:192, loss:0.00001, loss_test:0.09940, lr:2.47e-03, fs:0.59211 (r=0.455,p=0.849),  time:15.651, tt:3020.660\n",
      "Ep:193, loss:0.00001, loss_test:0.09943, lr:2.45e-03, fs:0.59211 (r=0.455,p=0.849),  time:15.649, tt:3035.822\n",
      "Ep:194, loss:0.00001, loss_test:0.09946, lr:2.42e-03, fs:0.59603 (r=0.455,p=0.865),  time:15.651, tt:3051.986\n",
      "Ep:195, loss:0.00001, loss_test:0.09949, lr:2.40e-03, fs:0.59603 (r=0.455,p=0.865),  time:15.648, tt:3067.074\n",
      "Ep:196, loss:0.00001, loss_test:0.09953, lr:2.38e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.644, tt:3081.888\n",
      "Ep:197, loss:0.00001, loss_test:0.09950, lr:2.35e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.647, tt:3098.195\n",
      "Ep:198, loss:0.00001, loss_test:0.09949, lr:2.33e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.646, tt:3113.571\n",
      "Ep:199, loss:0.00001, loss_test:0.09953, lr:2.31e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.640, tt:3127.973\n",
      "Ep:200, loss:0.00001, loss_test:0.09957, lr:2.28e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.639, tt:3143.483\n",
      "Ep:201, loss:0.00001, loss_test:0.09960, lr:2.26e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.633, tt:3157.806\n",
      "Ep:202, loss:0.00001, loss_test:0.09958, lr:2.24e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.629, tt:3172.766\n",
      "Ep:203, loss:0.00001, loss_test:0.09957, lr:2.21e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.629, tt:3188.402\n",
      "Ep:204, loss:0.00001, loss_test:0.09957, lr:2.19e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.632, tt:3204.466\n",
      "Ep:205, loss:0.00001, loss_test:0.09961, lr:2.17e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.629, tt:3219.527\n",
      "Ep:206, loss:0.00001, loss_test:0.09964, lr:2.15e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.626, tt:3234.666\n",
      "Ep:207, loss:0.00001, loss_test:0.09965, lr:2.13e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.627, tt:3250.473\n",
      "Ep:208, loss:0.00001, loss_test:0.09965, lr:2.11e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.625, tt:3265.552\n",
      "Ep:209, loss:0.00001, loss_test:0.09962, lr:2.08e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.629, tt:3282.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00001, loss_test:0.09960, lr:2.06e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.630, tt:3297.877\n",
      "Ep:211, loss:0.00001, loss_test:0.09960, lr:2.04e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.627, tt:3312.956\n",
      "Ep:212, loss:0.00001, loss_test:0.09957, lr:2.02e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.624, tt:3327.834\n",
      "Ep:213, loss:0.00001, loss_test:0.09957, lr:2.00e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.621, tt:3342.920\n",
      "Ep:214, loss:0.00001, loss_test:0.09959, lr:1.98e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.622, tt:3358.647\n",
      "Ep:215, loss:0.00001, loss_test:0.09957, lr:1.96e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.624, tt:3374.707\n",
      "Ep:216, loss:0.00001, loss_test:0.09957, lr:1.94e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.626, tt:3390.751\n",
      "Ep:217, loss:0.00001, loss_test:0.09955, lr:1.92e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.628, tt:3406.870\n",
      "Ep:218, loss:0.00001, loss_test:0.09958, lr:1.90e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.627, tt:3422.398\n",
      "Ep:219, loss:0.00001, loss_test:0.09961, lr:1.89e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.628, tt:3438.193\n",
      "Ep:220, loss:0.00001, loss_test:0.09961, lr:1.87e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.626, tt:3453.347\n",
      "Ep:221, loss:0.00001, loss_test:0.09960, lr:1.85e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.634, tt:3470.766\n",
      "Ep:222, loss:0.00001, loss_test:0.09963, lr:1.83e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.633, tt:3486.237\n",
      "Ep:223, loss:0.00001, loss_test:0.09962, lr:1.81e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.637, tt:3502.772\n",
      "Ep:224, loss:0.00001, loss_test:0.09958, lr:1.79e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.637, tt:3518.329\n",
      "Ep:225, loss:0.00001, loss_test:0.09960, lr:1.78e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.638, tt:3534.235\n",
      "Ep:226, loss:0.00001, loss_test:0.09967, lr:1.76e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.641, tt:3550.560\n",
      "Ep:227, loss:0.00001, loss_test:0.09972, lr:1.74e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.643, tt:3566.556\n",
      "Ep:228, loss:0.00001, loss_test:0.09972, lr:1.72e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.643, tt:3582.267\n",
      "Ep:229, loss:0.00001, loss_test:0.09971, lr:1.71e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.642, tt:3597.718\n",
      "Ep:230, loss:0.00001, loss_test:0.09971, lr:1.69e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.636, tt:3611.921\n",
      "Ep:231, loss:0.00001, loss_test:0.09975, lr:1.67e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.635, tt:3627.332\n",
      "Ep:232, loss:0.00001, loss_test:0.09977, lr:1.65e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.632, tt:3642.192\n",
      "Ep:233, loss:0.00001, loss_test:0.09979, lr:1.64e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.631, tt:3657.574\n",
      "Ep:234, loss:0.00001, loss_test:0.09980, lr:1.62e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.629, tt:3672.925\n",
      "Ep:235, loss:0.00001, loss_test:0.09984, lr:1.61e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.631, tt:3688.824\n",
      "Ep:236, loss:0.00001, loss_test:0.09988, lr:1.59e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.627, tt:3703.565\n",
      "Ep:237, loss:0.00001, loss_test:0.09989, lr:1.57e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.625, tt:3718.721\n",
      "Ep:238, loss:0.00001, loss_test:0.09986, lr:1.56e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.625, tt:3734.434\n",
      "Ep:239, loss:0.00001, loss_test:0.09985, lr:1.54e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.622, tt:3749.174\n",
      "Ep:240, loss:0.00001, loss_test:0.09986, lr:1.53e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.619, tt:3764.078\n",
      "Ep:241, loss:0.00001, loss_test:0.09985, lr:1.51e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.617, tt:3779.217\n",
      "Ep:242, loss:0.00001, loss_test:0.09986, lr:1.50e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.613, tt:3794.039\n",
      "Ep:243, loss:0.00001, loss_test:0.09987, lr:1.48e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.607, tt:3808.158\n",
      "Ep:244, loss:0.00001, loss_test:0.09987, lr:1.47e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.603, tt:3822.660\n",
      "Ep:245, loss:0.00001, loss_test:0.09987, lr:1.45e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.597, tt:3836.952\n",
      "Ep:246, loss:0.00001, loss_test:0.09987, lr:1.44e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.594, tt:3851.796\n",
      "Ep:247, loss:0.00001, loss_test:0.09986, lr:1.42e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.598, tt:3868.361\n",
      "Ep:248, loss:0.00001, loss_test:0.09986, lr:1.41e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.596, tt:3883.460\n",
      "Ep:249, loss:0.00001, loss_test:0.09983, lr:1.39e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.600, tt:3900.006\n",
      "Ep:250, loss:0.00001, loss_test:0.09980, lr:1.38e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.600, tt:3915.662\n",
      "Ep:251, loss:0.00001, loss_test:0.09978, lr:1.37e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.604, tt:3932.205\n",
      "Ep:252, loss:0.00001, loss_test:0.09978, lr:1.35e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.605, tt:3948.039\n",
      "Ep:253, loss:0.00001, loss_test:0.09978, lr:1.34e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.607, tt:3964.093\n",
      "Ep:254, loss:0.00001, loss_test:0.09978, lr:1.33e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.605, tt:3979.178\n",
      "Ep:255, loss:0.00001, loss_test:0.09978, lr:1.31e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.604, tt:3994.652\n",
      "Ep:256, loss:0.00001, loss_test:0.09978, lr:1.30e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.603, tt:4010.001\n",
      "Ep:257, loss:0.00001, loss_test:0.09978, lr:1.29e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.606, tt:4026.232\n",
      "Ep:258, loss:0.00001, loss_test:0.09976, lr:1.27e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.606, tt:4041.951\n",
      "Ep:259, loss:0.00001, loss_test:0.09975, lr:1.26e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.602, tt:4056.590\n",
      "Ep:260, loss:0.00001, loss_test:0.09974, lr:1.25e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.606, tt:4073.069\n",
      "Ep:261, loss:0.00001, loss_test:0.09974, lr:1.24e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.608, tt:4089.348\n",
      "Ep:262, loss:0.00001, loss_test:0.09974, lr:1.22e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.609, tt:4105.131\n",
      "Ep:263, loss:0.00001, loss_test:0.09972, lr:1.21e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.605, tt:4119.621\n",
      "Ep:264, loss:0.00001, loss_test:0.09972, lr:1.20e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.603, tt:4134.808\n",
      "Ep:265, loss:0.00001, loss_test:0.09972, lr:1.19e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.604, tt:4150.658\n",
      "Ep:266, loss:0.00001, loss_test:0.09972, lr:1.18e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.606, tt:4166.917\n",
      "Ep:267, loss:0.00001, loss_test:0.09973, lr:1.16e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.611, tt:4183.768\n",
      "Ep:268, loss:0.00001, loss_test:0.09973, lr:1.15e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.612, tt:4199.608\n",
      "Ep:269, loss:0.00001, loss_test:0.09974, lr:1.14e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.613, tt:4215.626\n",
      "Ep:270, loss:0.00001, loss_test:0.09974, lr:1.13e-03, fs:0.59603 (r=0.455,p=0.865),  time:15.611, tt:4230.704\n",
      "Ep:271, loss:0.00001, loss_test:0.09976, lr:1.12e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.608, tt:4245.335\n",
      "Ep:272, loss:0.00001, loss_test:0.09976, lr:1.11e-03, fs:0.58667 (r=0.444,p=0.863),  time:15.610, tt:4261.663\n",
      "Ep:273, loss:0.00001, loss_test:0.09975, lr:1.10e-03, fs:0.59603 (r=0.455,p=0.865),  time:15.611, tt:4277.430\n",
      "Ep:274, loss:0.00001, loss_test:0.09975, lr:1.08e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.610, tt:4292.819\n",
      "Ep:275, loss:0.00001, loss_test:0.09975, lr:1.07e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.610, tt:4308.263\n",
      "Ep:276, loss:0.00001, loss_test:0.09976, lr:1.06e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.615, tt:4325.300\n",
      "Ep:277, loss:0.00001, loss_test:0.09976, lr:1.05e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.620, tt:4342.330\n",
      "Ep:278, loss:0.00001, loss_test:0.09976, lr:1.04e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.623, tt:4358.948\n",
      "Ep:279, loss:0.00001, loss_test:0.09974, lr:1.03e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.623, tt:4374.538\n",
      "Ep:280, loss:0.00001, loss_test:0.09975, lr:1.02e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.623, tt:4390.177\n",
      "Ep:281, loss:0.00001, loss_test:0.09976, lr:1.01e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.626, tt:4406.467\n",
      "Ep:282, loss:0.00001, loss_test:0.09977, lr:1.00e-03, fs:0.60000 (r=0.455,p=0.882),  time:15.630, tt:4423.317\n",
      "Ep:283, loss:0.00001, loss_test:0.09978, lr:9.91e-04, fs:0.60000 (r=0.455,p=0.882),  time:15.630, tt:4438.912\n",
      "Ep:284, loss:0.00001, loss_test:0.09978, lr:9.81e-04, fs:0.60000 (r=0.455,p=0.882),  time:15.632, tt:4455.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:285, loss:0.00001, loss_test:0.09978, lr:9.71e-04, fs:0.60000 (r=0.455,p=0.882),  time:15.635, tt:4471.518\n",
      "Ep:286, loss:0.00001, loss_test:0.09980, lr:9.62e-04, fs:0.59060 (r=0.444,p=0.880),  time:15.637, tt:4487.920\n",
      "Ep:287, loss:0.00001, loss_test:0.09981, lr:9.52e-04, fs:0.59060 (r=0.444,p=0.880),  time:15.644, tt:4505.492\n",
      "Ep:288, loss:0.00001, loss_test:0.09982, lr:9.42e-04, fs:0.59060 (r=0.444,p=0.880),  time:15.645, tt:4521.473\n",
      "Ep:289, loss:0.00001, loss_test:0.09983, lr:9.33e-04, fs:0.59060 (r=0.444,p=0.880),  time:15.646, tt:4537.484\n",
      "Ep:290, loss:0.00001, loss_test:0.09984, lr:9.24e-04, fs:0.59060 (r=0.444,p=0.880),  time:15.650, tt:4554.202\n",
      "Ep:291, loss:0.00001, loss_test:0.09985, lr:9.14e-04, fs:0.59459 (r=0.444,p=0.898),  time:15.653, tt:4570.817\n",
      "Ep:292, loss:0.00001, loss_test:0.09985, lr:9.05e-04, fs:0.59459 (r=0.444,p=0.898),  time:15.658, tt:4587.920\n",
      "Ep:293, loss:0.00001, loss_test:0.09987, lr:8.96e-04, fs:0.59459 (r=0.444,p=0.898),  time:15.656, tt:4602.848\n",
      "Ep:294, loss:0.00001, loss_test:0.09989, lr:8.87e-04, fs:0.59459 (r=0.444,p=0.898),  time:15.653, tt:4617.632\n",
      "Ep:295, loss:0.00001, loss_test:0.09990, lr:8.78e-04, fs:0.59459 (r=0.444,p=0.898),  time:15.652, tt:4632.976\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14316, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:9.664, tt:9.664\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14279, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.355, tt:26.709\n",
      "Ep:2, loss:0.00004, loss_test:0.14221, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:15.803, tt:47.409\n",
      "Ep:3, loss:0.00004, loss_test:0.14139, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:16.882, tt:67.527\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.14028, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:17.561, tt:87.805\n",
      "Ep:5, loss:0.00004, loss_test:0.13880, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:17.793, tt:106.760\n",
      "Ep:6, loss:0.00004, loss_test:0.13693, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:18.194, tt:127.355\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.13459, lr:1.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:18.401, tt:147.204\n",
      "Ep:8, loss:0.00004, loss_test:0.13169, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:18.672, tt:168.048\n",
      "Ep:9, loss:0.00004, loss_test:0.12892, lr:1.00e-02, fs:0.64865 (r=0.848,p=0.525),  time:18.717, tt:187.175\n",
      "Ep:10, loss:0.00003, loss_test:0.12648, lr:1.00e-02, fs:0.66383 (r=0.788,p=0.574),  time:18.669, tt:205.355\n",
      "Ep:11, loss:0.00003, loss_test:0.12499, lr:1.00e-02, fs:0.64115 (r=0.677,p=0.609),  time:18.736, tt:224.826\n",
      "Ep:12, loss:0.00003, loss_test:0.12559, lr:1.00e-02, fs:0.56684 (r=0.535,p=0.602),  time:18.832, tt:244.814\n",
      "Ep:13, loss:0.00003, loss_test:0.12661, lr:1.00e-02, fs:0.55866 (r=0.505,p=0.625),  time:18.879, tt:264.304\n",
      "Ep:14, loss:0.00003, loss_test:0.12510, lr:1.00e-02, fs:0.56044 (r=0.515,p=0.614),  time:18.863, tt:282.945\n",
      "Ep:15, loss:0.00003, loss_test:0.12195, lr:1.00e-02, fs:0.58947 (r=0.566,p=0.615),  time:18.854, tt:301.658\n",
      "Ep:16, loss:0.00003, loss_test:0.11972, lr:1.00e-02, fs:0.66981 (r=0.717,p=0.628),  time:18.817, tt:319.888\n",
      "Ep:17, loss:0.00003, loss_test:0.11874, lr:1.00e-02, fs:0.67580 (r=0.747,p=0.617),  time:18.837, tt:339.075\n",
      "Ep:18, loss:0.00003, loss_test:0.11775, lr:9.90e-03, fs:0.68519 (r=0.747,p=0.632),  time:18.863, tt:358.388\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.11723, lr:9.90e-03, fs:0.67961 (r=0.707,p=0.654),  time:18.871, tt:377.426\n",
      "Ep:20, loss:0.00003, loss_test:0.11784, lr:9.90e-03, fs:0.61458 (r=0.596,p=0.634),  time:18.955, tt:398.054\n",
      "Ep:21, loss:0.00003, loss_test:0.11821, lr:9.90e-03, fs:0.59893 (r=0.566,p=0.636),  time:18.966, tt:417.256\n",
      "Ep:22, loss:0.00003, loss_test:0.11703, lr:9.90e-03, fs:0.59893 (r=0.566,p=0.636),  time:18.993, tt:436.848\n",
      "Ep:23, loss:0.00003, loss_test:0.11448, lr:9.90e-03, fs:0.63542 (r=0.616,p=0.656),  time:18.979, tt:455.490\n",
      "Ep:24, loss:0.00003, loss_test:0.11218, lr:9.90e-03, fs:0.66667 (r=0.677,p=0.657),  time:19.018, tt:475.449\n",
      "Ep:25, loss:0.00003, loss_test:0.11041, lr:9.90e-03, fs:0.71090 (r=0.758,p=0.670),  time:19.091, tt:496.365\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.10891, lr:9.90e-03, fs:0.71090 (r=0.758,p=0.670),  time:19.099, tt:515.682\n",
      "Ep:27, loss:0.00002, loss_test:0.10777, lr:9.90e-03, fs:0.70936 (r=0.727,p=0.692),  time:19.143, tt:536.009\n",
      "Ep:28, loss:0.00002, loss_test:0.10683, lr:9.90e-03, fs:0.68718 (r=0.677,p=0.698),  time:19.188, tt:556.460\n",
      "Ep:29, loss:0.00002, loss_test:0.10589, lr:9.90e-03, fs:0.67358 (r=0.657,p=0.691),  time:19.210, tt:576.311\n",
      "Ep:30, loss:0.00002, loss_test:0.10462, lr:9.90e-03, fs:0.68041 (r=0.667,p=0.695),  time:19.163, tt:594.047\n",
      "Ep:31, loss:0.00002, loss_test:0.10323, lr:9.90e-03, fs:0.70647 (r=0.717,p=0.696),  time:19.169, tt:613.410\n",
      "Ep:32, loss:0.00002, loss_test:0.10222, lr:9.90e-03, fs:0.72195 (r=0.747,p=0.698),  time:19.202, tt:633.665\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10159, lr:9.90e-03, fs:0.71287 (r=0.727,p=0.699),  time:19.247, tt:654.392\n",
      "Ep:34, loss:0.00002, loss_test:0.10142, lr:9.90e-03, fs:0.69388 (r=0.687,p=0.701),  time:19.289, tt:675.131\n",
      "Ep:35, loss:0.00002, loss_test:0.10134, lr:9.90e-03, fs:0.68394 (r=0.667,p=0.702),  time:19.340, tt:696.233\n",
      "Ep:36, loss:0.00002, loss_test:0.10079, lr:9.90e-03, fs:0.67708 (r=0.657,p=0.699),  time:19.375, tt:716.865\n",
      "Ep:37, loss:0.00002, loss_test:0.09966, lr:9.90e-03, fs:0.69036 (r=0.687,p=0.694),  time:19.412, tt:737.652\n",
      "Ep:38, loss:0.00002, loss_test:0.09862, lr:9.90e-03, fs:0.71000 (r=0.717,p=0.703),  time:19.455, tt:758.755\n",
      "Ep:39, loss:0.00002, loss_test:0.09806, lr:9.90e-03, fs:0.71642 (r=0.727,p=0.706),  time:19.493, tt:779.723\n",
      "Ep:40, loss:0.00002, loss_test:0.09793, lr:9.90e-03, fs:0.69744 (r=0.687,p=0.708),  time:19.528, tt:800.641\n",
      "Ep:41, loss:0.00002, loss_test:0.09781, lr:9.90e-03, fs:0.70157 (r=0.677,p=0.728),  time:19.569, tt:821.916\n",
      "Ep:42, loss:0.00002, loss_test:0.09723, lr:9.90e-03, fs:0.70833 (r=0.687,p=0.731),  time:19.581, tt:841.987\n",
      "Ep:43, loss:0.00002, loss_test:0.09629, lr:9.90e-03, fs:0.72165 (r=0.707,p=0.737),  time:19.559, tt:860.611\n",
      "Ep:44, loss:0.00002, loss_test:0.09567, lr:9.80e-03, fs:0.72821 (r=0.717,p=0.740),  time:19.582, tt:881.210\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.09538, lr:9.80e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.580, tt:900.699\n",
      "Ep:46, loss:0.00002, loss_test:0.09513, lr:9.80e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.579, tt:920.230\n",
      "Ep:47, loss:0.00002, loss_test:0.09453, lr:9.80e-03, fs:0.73575 (r=0.717,p=0.755),  time:19.599, tt:940.749\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.09356, lr:9.80e-03, fs:0.74490 (r=0.737,p=0.753),  time:19.613, tt:961.022\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.09301, lr:9.80e-03, fs:0.74112 (r=0.737,p=0.745),  time:19.638, tt:981.906\n",
      "Ep:50, loss:0.00002, loss_test:0.09294, lr:9.80e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.648, tt:1002.058\n",
      "Ep:51, loss:0.00002, loss_test:0.09296, lr:9.80e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.675, tt:1023.105\n",
      "Ep:52, loss:0.00002, loss_test:0.09275, lr:9.80e-03, fs:0.73196 (r=0.717,p=0.747),  time:19.664, tt:1042.182\n",
      "Ep:53, loss:0.00002, loss_test:0.09242, lr:9.80e-03, fs:0.73846 (r=0.727,p=0.750),  time:19.684, tt:1062.937\n",
      "Ep:54, loss:0.00002, loss_test:0.09219, lr:9.80e-03, fs:0.74227 (r=0.727,p=0.758),  time:19.709, tt:1084.008\n",
      "Ep:55, loss:0.00002, loss_test:0.09215, lr:9.80e-03, fs:0.74611 (r=0.727,p=0.766),  time:19.722, tt:1104.443\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.09205, lr:9.80e-03, fs:0.75258 (r=0.737,p=0.768),  time:19.726, tt:1124.369\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.09196, lr:9.80e-03, fs:0.74872 (r=0.737,p=0.760),  time:19.715, tt:1143.466\n",
      "Ep:58, loss:0.00001, loss_test:0.09188, lr:9.80e-03, fs:0.75897 (r=0.747,p=0.771),  time:19.714, tt:1163.127\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.09205, lr:9.80e-03, fs:0.74737 (r=0.717,p=0.780),  time:19.719, tt:1183.119\n",
      "Ep:60, loss:0.00001, loss_test:0.09189, lr:9.80e-03, fs:0.75132 (r=0.717,p=0.789),  time:19.709, tt:1202.227\n",
      "Ep:61, loss:0.00001, loss_test:0.09140, lr:9.80e-03, fs:0.77551 (r=0.768,p=0.784),  time:19.682, tt:1220.286\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.09123, lr:9.80e-03, fs:0.77551 (r=0.768,p=0.784),  time:19.677, tt:1239.676\n",
      "Ep:63, loss:0.00001, loss_test:0.09111, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.664, tt:1258.472\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09068, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:19.656, tt:1277.643\n",
      "Ep:65, loss:0.00001, loss_test:0.09015, lr:9.80e-03, fs:0.78351 (r=0.768,p=0.800),  time:19.667, tt:1298.030\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.08994, lr:9.80e-03, fs:0.79581 (r=0.768,p=0.826),  time:19.666, tt:1317.641\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.08991, lr:9.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:19.662, tt:1337.003\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.08960, lr:9.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:19.642, tt:1355.281\n",
      "Ep:69, loss:0.00001, loss_test:0.08916, lr:9.80e-03, fs:0.81250 (r=0.788,p=0.839),  time:19.610, tt:1372.721\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.08922, lr:9.80e-03, fs:0.81053 (r=0.778,p=0.846),  time:19.599, tt:1391.547\n",
      "Ep:71, loss:0.00001, loss_test:0.08941, lr:9.80e-03, fs:0.80423 (r=0.768,p=0.844),  time:19.586, tt:1410.182\n",
      "Ep:72, loss:0.00001, loss_test:0.08895, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:19.580, tt:1429.365\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.08899, lr:9.80e-03, fs:0.81053 (r=0.778,p=0.846),  time:19.582, tt:1449.047\n",
      "Ep:74, loss:0.00001, loss_test:0.08909, lr:9.80e-03, fs:0.81481 (r=0.778,p=0.856),  time:19.564, tt:1467.295\n",
      "Ep:75, loss:0.00001, loss_test:0.08881, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.569, tt:1487.263\n",
      "Ep:76, loss:0.00001, loss_test:0.08863, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.534, tt:1504.136\n",
      "Ep:77, loss:0.00001, loss_test:0.08882, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.524, tt:1522.886\n",
      "Ep:78, loss:0.00001, loss_test:0.08842, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.509, tt:1541.220\n",
      "Ep:79, loss:0.00001, loss_test:0.08852, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.506, tt:1560.446\n",
      "Ep:80, loss:0.00001, loss_test:0.08840, lr:9.80e-03, fs:0.80214 (r=0.758,p=0.852),  time:19.506, tt:1580.008\n",
      "Ep:81, loss:0.00001, loss_test:0.08825, lr:9.80e-03, fs:0.80851 (r=0.768,p=0.854),  time:19.520, tt:1600.602\n",
      "Ep:82, loss:0.00001, loss_test:0.08848, lr:9.80e-03, fs:0.80435 (r=0.747,p=0.871),  time:19.518, tt:1620.006\n",
      "Ep:83, loss:0.00001, loss_test:0.08824, lr:9.80e-03, fs:0.80874 (r=0.747,p=0.881),  time:19.514, tt:1639.189\n",
      "Ep:84, loss:0.00001, loss_test:0.08820, lr:9.70e-03, fs:0.79558 (r=0.727,p=0.878),  time:19.523, tt:1659.481\n",
      "Ep:85, loss:0.00001, loss_test:0.08862, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:19.526, tt:1679.272\n",
      "Ep:86, loss:0.00001, loss_test:0.08803, lr:9.51e-03, fs:0.80663 (r=0.737,p=0.890),  time:19.520, tt:1698.229\n",
      "Ep:87, loss:0.00001, loss_test:0.08898, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.533, tt:1718.941\n",
      "Ep:88, loss:0.00001, loss_test:0.08859, lr:9.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.542, tt:1739.220\n",
      "Ep:89, loss:0.00001, loss_test:0.08789, lr:9.23e-03, fs:0.81111 (r=0.737,p=0.901),  time:19.522, tt:1756.983\n",
      "Ep:90, loss:0.00001, loss_test:0.08870, lr:9.14e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.528, tt:1777.058\n",
      "Ep:91, loss:0.00001, loss_test:0.08835, lr:9.04e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.526, tt:1796.349\n",
      "Ep:92, loss:0.00001, loss_test:0.08798, lr:8.95e-03, fs:0.81564 (r=0.737,p=0.912),  time:19.535, tt:1816.768\n",
      "Ep:93, loss:0.00001, loss_test:0.08880, lr:8.86e-03, fs:0.80000 (r=0.707,p=0.921),  time:19.542, tt:1836.908\n",
      "Ep:94, loss:0.00001, loss_test:0.08835, lr:8.78e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.539, tt:1856.159\n",
      "Ep:95, loss:0.00001, loss_test:0.08749, lr:8.69e-03, fs:0.82022 (r=0.737,p=0.924),  time:19.531, tt:1875.000\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.08885, lr:8.69e-03, fs:0.78613 (r=0.687,p=0.919),  time:19.525, tt:1893.896\n",
      "Ep:97, loss:0.00001, loss_test:0.08797, lr:8.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.511, tt:1912.089\n",
      "Ep:98, loss:0.00001, loss_test:0.08755, lr:8.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.504, tt:1930.886\n",
      "Ep:99, loss:0.00001, loss_test:0.08911, lr:8.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.488, tt:1948.829\n",
      "Ep:100, loss:0.00001, loss_test:0.08817, lr:8.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.490, tt:1968.484\n",
      "Ep:101, loss:0.00001, loss_test:0.08750, lr:8.69e-03, fs:0.79310 (r=0.697,p=0.920),  time:19.487, tt:1987.657\n",
      "Ep:102, loss:0.00001, loss_test:0.08936, lr:8.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.473, tt:2005.740\n",
      "Ep:103, loss:0.00001, loss_test:0.08851, lr:8.69e-03, fs:0.77193 (r=0.667,p=0.917),  time:19.472, tt:2025.126\n",
      "Ep:104, loss:0.00001, loss_test:0.08719, lr:8.69e-03, fs:0.82022 (r=0.737,p=0.924),  time:19.477, tt:2045.050\n",
      "Ep:105, loss:0.00001, loss_test:0.08988, lr:8.69e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.463, tt:2063.051\n",
      "Ep:106, loss:0.00001, loss_test:0.08961, lr:8.69e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.464, tt:2082.606\n",
      "Ep:107, loss:0.00001, loss_test:0.08743, lr:8.60e-03, fs:0.80682 (r=0.717,p=0.922),  time:19.499, tt:2105.913\n",
      "Ep:108, loss:0.00001, loss_test:0.08938, lr:8.51e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.514, tt:2126.997\n",
      "Ep:109, loss:0.00001, loss_test:0.08960, lr:8.43e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.509, tt:2145.940\n",
      "Ep:110, loss:0.00001, loss_test:0.08777, lr:8.35e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.503, tt:2164.867\n",
      "Ep:111, loss:0.00001, loss_test:0.08846, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.507, tt:2184.786\n",
      "Ep:112, loss:0.00001, loss_test:0.08967, lr:8.18e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.508, tt:2204.376\n",
      "Ep:113, loss:0.00001, loss_test:0.08903, lr:8.10e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.515, tt:2224.758\n",
      "Ep:114, loss:0.00001, loss_test:0.08847, lr:8.02e-03, fs:0.76471 (r=0.657,p=0.915),  time:19.522, tt:2244.984\n",
      "Ep:115, loss:0.00001, loss_test:0.08952, lr:7.94e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.527, tt:2265.184\n",
      "Ep:116, loss:0.00001, loss_test:0.08989, lr:7.86e-03, fs:0.74251 (r=0.626,p=0.912),  time:19.522, tt:2284.035\n",
      "Ep:117, loss:0.00001, loss_test:0.08920, lr:7.78e-03, fs:0.75740 (r=0.646,p=0.914),  time:19.516, tt:2302.912\n",
      "Ep:118, loss:0.00001, loss_test:0.08933, lr:7.70e-03, fs:0.75000 (r=0.636,p=0.913),  time:19.521, tt:2323.030\n",
      "Ep:119, loss:0.00001, loss_test:0.09037, lr:7.62e-03, fs:0.73494 (r=0.616,p=0.910),  time:19.530, tt:2343.590\n",
      "Ep:120, loss:0.00001, loss_test:0.09024, lr:7.55e-03, fs:0.72727 (r=0.606,p=0.909),  time:19.532, tt:2363.389\n",
      "Ep:121, loss:0.00000, loss_test:0.08996, lr:7.47e-03, fs:0.72727 (r=0.606,p=0.909),  time:19.538, tt:2383.628\n",
      "Ep:122, loss:0.00000, loss_test:0.09078, lr:7.40e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.550, tt:2404.608\n",
      "Ep:123, loss:0.00000, loss_test:0.09099, lr:7.32e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.569, tt:2426.593\n",
      "Ep:124, loss:0.00000, loss_test:0.09061, lr:7.25e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.579, tt:2447.360\n",
      "Ep:125, loss:0.00000, loss_test:0.09096, lr:7.18e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.583, tt:2467.426\n",
      "Ep:126, loss:0.00000, loss_test:0.09165, lr:7.11e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.592, tt:2488.201\n",
      "Ep:127, loss:0.00000, loss_test:0.09155, lr:7.03e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.599, tt:2508.669\n",
      "Ep:128, loss:0.00000, loss_test:0.09172, lr:6.96e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.611, tt:2529.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.09205, lr:6.89e-03, fs:0.71951 (r=0.596,p=0.908),  time:19.613, tt:2549.702\n",
      "Ep:130, loss:0.00000, loss_test:0.09219, lr:6.83e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.614, tt:2569.377\n",
      "Ep:131, loss:0.00000, loss_test:0.09211, lr:6.76e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.614, tt:2589.028\n",
      "Ep:132, loss:0.00000, loss_test:0.09293, lr:6.69e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.620, tt:2609.455\n",
      "Ep:133, loss:0.00000, loss_test:0.09292, lr:6.62e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.634, tt:2630.949\n",
      "Ep:134, loss:0.00000, loss_test:0.09248, lr:6.56e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.643, tt:2651.819\n",
      "Ep:135, loss:0.00000, loss_test:0.09321, lr:6.49e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.647, tt:2672.011\n",
      "Ep:136, loss:0.00000, loss_test:0.09321, lr:6.43e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.659, tt:2693.258\n",
      "Ep:137, loss:0.00000, loss_test:0.09261, lr:6.36e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.667, tt:2714.025\n",
      "Ep:138, loss:0.00000, loss_test:0.09312, lr:6.30e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.669, tt:2734.004\n",
      "Ep:139, loss:0.00000, loss_test:0.09341, lr:6.24e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.675, tt:2754.528\n",
      "Ep:140, loss:0.00000, loss_test:0.09315, lr:6.17e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.679, tt:2774.731\n",
      "Ep:141, loss:0.00000, loss_test:0.09349, lr:6.11e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.681, tt:2794.765\n",
      "Ep:142, loss:0.00000, loss_test:0.09364, lr:6.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.693, tt:2816.101\n",
      "Ep:143, loss:0.00000, loss_test:0.09352, lr:5.99e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.692, tt:2835.624\n",
      "Ep:144, loss:0.00000, loss_test:0.09379, lr:5.93e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.687, tt:2854.588\n",
      "Ep:145, loss:0.00000, loss_test:0.09387, lr:5.87e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.686, tt:2874.083\n",
      "Ep:146, loss:0.00000, loss_test:0.09382, lr:5.81e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.691, tt:2894.631\n",
      "Ep:147, loss:0.00000, loss_test:0.09412, lr:5.75e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.697, tt:2915.087\n",
      "Ep:148, loss:0.00000, loss_test:0.09425, lr:5.70e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.705, tt:2935.986\n",
      "Ep:149, loss:0.00000, loss_test:0.09431, lr:5.64e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.701, tt:2955.084\n",
      "Ep:150, loss:0.00000, loss_test:0.09471, lr:5.58e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.703, tt:2975.109\n",
      "Ep:151, loss:0.00000, loss_test:0.09484, lr:5.53e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.711, tt:2996.096\n",
      "Ep:152, loss:0.00000, loss_test:0.09485, lr:5.47e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.718, tt:3016.847\n",
      "Ep:153, loss:0.00000, loss_test:0.09505, lr:5.42e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.722, tt:3037.225\n",
      "Ep:154, loss:0.00000, loss_test:0.09516, lr:5.36e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.724, tt:3057.238\n",
      "Ep:155, loss:0.00000, loss_test:0.09524, lr:5.31e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.731, tt:3078.002\n",
      "Ep:156, loss:0.00000, loss_test:0.09528, lr:5.26e-03, fs:0.70370 (r=0.576,p=0.905),  time:19.734, tt:3098.313\n",
      "Ep:157, loss:0.00000, loss_test:0.09564, lr:5.20e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.739, tt:3118.784\n",
      "Ep:158, loss:0.00000, loss_test:0.09534, lr:5.15e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.747, tt:3139.722\n",
      "Ep:159, loss:0.00000, loss_test:0.09522, lr:5.10e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.750, tt:3160.017\n",
      "Ep:160, loss:0.00000, loss_test:0.09585, lr:5.05e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.756, tt:3180.788\n",
      "Ep:161, loss:0.00000, loss_test:0.09561, lr:5.00e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.767, tt:3202.283\n",
      "Ep:162, loss:0.00000, loss_test:0.09496, lr:4.95e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.769, tt:3222.367\n",
      "Ep:163, loss:0.00000, loss_test:0.09561, lr:4.90e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.773, tt:3242.698\n",
      "Ep:164, loss:0.00000, loss_test:0.09601, lr:4.85e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.781, tt:3263.873\n",
      "Ep:165, loss:0.00000, loss_test:0.09522, lr:4.80e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.789, tt:3284.946\n",
      "Ep:166, loss:0.00000, loss_test:0.09544, lr:4.75e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.785, tt:3304.071\n",
      "Ep:167, loss:0.00000, loss_test:0.09600, lr:4.71e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.797, tt:3325.839\n",
      "Ep:168, loss:0.00000, loss_test:0.09562, lr:4.66e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.790, tt:3344.518\n",
      "Ep:169, loss:0.00000, loss_test:0.09532, lr:4.61e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.791, tt:3364.421\n",
      "Ep:170, loss:0.00000, loss_test:0.09589, lr:4.57e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.801, tt:3385.894\n",
      "Ep:171, loss:0.00000, loss_test:0.09603, lr:4.52e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.799, tt:3405.360\n",
      "Ep:172, loss:0.00000, loss_test:0.09553, lr:4.48e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.806, tt:3426.498\n",
      "Ep:173, loss:0.00000, loss_test:0.09580, lr:4.43e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.808, tt:3446.518\n",
      "Ep:174, loss:0.00000, loss_test:0.09639, lr:4.39e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.817, tt:3467.925\n",
      "Ep:175, loss:0.00000, loss_test:0.09609, lr:4.34e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.823, tt:3488.907\n",
      "Ep:176, loss:0.00000, loss_test:0.09554, lr:4.30e-03, fs:0.69565 (r=0.566,p=0.903),  time:19.826, tt:3509.263\n",
      "Ep:177, loss:0.00000, loss_test:0.09614, lr:4.26e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.826, tt:3528.952\n",
      "Ep:178, loss:0.00000, loss_test:0.09648, lr:4.21e-03, fs:0.67089 (r=0.535,p=0.898),  time:19.822, tt:3548.064\n",
      "Ep:179, loss:0.00000, loss_test:0.09615, lr:4.17e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.824, tt:3568.338\n",
      "Ep:180, loss:0.00000, loss_test:0.09578, lr:4.13e-03, fs:0.68750 (r=0.556,p=0.902),  time:19.828, tt:3588.857\n",
      "Ep:181, loss:0.00000, loss_test:0.09643, lr:4.09e-03, fs:0.67089 (r=0.535,p=0.898),  time:19.833, tt:3609.564\n",
      "Ep:182, loss:0.00000, loss_test:0.09671, lr:4.05e-03, fs:0.66242 (r=0.525,p=0.897),  time:19.835, tt:3629.734\n",
      "Ep:183, loss:0.00000, loss_test:0.09628, lr:4.01e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.844, tt:3651.305\n",
      "Ep:184, loss:0.00000, loss_test:0.09625, lr:3.97e-03, fs:0.67925 (r=0.545,p=0.900),  time:19.846, tt:3671.432\n",
      "Ep:185, loss:0.00000, loss_test:0.09690, lr:3.93e-03, fs:0.66242 (r=0.525,p=0.897),  time:19.852, tt:3692.515\n",
      "Ep:186, loss:0.00000, loss_test:0.09696, lr:3.89e-03, fs:0.64516 (r=0.505,p=0.893),  time:19.850, tt:3711.858\n",
      "Ep:187, loss:0.00000, loss_test:0.09654, lr:3.85e-03, fs:0.65385 (r=0.515,p=0.895),  time:19.848, tt:3731.401\n",
      "Ep:188, loss:0.00000, loss_test:0.09669, lr:3.81e-03, fs:0.65385 (r=0.515,p=0.895),  time:19.849, tt:3751.519\n",
      "Ep:189, loss:0.00000, loss_test:0.09692, lr:3.77e-03, fs:0.64516 (r=0.505,p=0.893),  time:19.842, tt:3769.958\n",
      "Ep:190, loss:0.00000, loss_test:0.09694, lr:3.73e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.838, tt:3789.152\n",
      "Ep:191, loss:0.00000, loss_test:0.09670, lr:3.70e-03, fs:0.65385 (r=0.515,p=0.895),  time:19.839, tt:3809.028\n",
      "Ep:192, loss:0.00000, loss_test:0.09704, lr:3.66e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.836, tt:3828.435\n",
      "Ep:193, loss:0.00000, loss_test:0.09724, lr:3.62e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.834, tt:3847.873\n",
      "Ep:194, loss:0.00000, loss_test:0.09695, lr:3.59e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.839, tt:3868.581\n",
      "Ep:195, loss:0.00000, loss_test:0.09721, lr:3.55e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.841, tt:3888.928\n",
      "Ep:196, loss:0.00000, loss_test:0.09721, lr:3.52e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.842, tt:3908.896\n",
      "Ep:197, loss:0.00000, loss_test:0.09707, lr:3.48e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.848, tt:3929.987\n",
      "Ep:198, loss:0.00000, loss_test:0.09727, lr:3.45e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.845, tt:3949.162\n",
      "Ep:199, loss:0.00000, loss_test:0.09706, lr:3.41e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.850, tt:3969.936\n",
      "Ep:200, loss:0.00000, loss_test:0.09736, lr:3.38e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.853, tt:3990.427\n",
      "Ep:201, loss:0.00000, loss_test:0.09746, lr:3.34e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.849, tt:4009.477\n",
      "Ep:202, loss:0.00000, loss_test:0.09727, lr:3.31e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.850, tt:4029.582\n",
      "Ep:203, loss:0.00000, loss_test:0.09740, lr:3.28e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.846, tt:4048.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.09744, lr:3.24e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.852, tt:4069.721\n",
      "Ep:205, loss:0.00000, loss_test:0.09731, lr:3.21e-03, fs:0.66667 (r=0.525,p=0.912),  time:19.856, tt:4090.245\n",
      "Ep:206, loss:0.00000, loss_test:0.09774, lr:3.18e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.858, tt:4110.611\n",
      "Ep:207, loss:0.00000, loss_test:0.09760, lr:3.15e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.860, tt:4130.871\n",
      "Ep:208, loss:0.00000, loss_test:0.09712, lr:3.12e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.865, tt:4151.765\n",
      "Ep:209, loss:0.00000, loss_test:0.09768, lr:3.09e-03, fs:0.65806 (r=0.515,p=0.911),  time:19.868, tt:4172.356\n",
      "Ep:210, loss:0.00000, loss_test:0.09786, lr:3.05e-03, fs:0.63158 (r=0.485,p=0.906),  time:19.874, tt:4193.335\n",
      "Ep:211, loss:0.00000, loss_test:0.09760, lr:3.02e-03, fs:0.64935 (r=0.505,p=0.909),  time:19.873, tt:4213.010\n",
      "Ep:212, loss:0.00000, loss_test:0.09755, lr:2.99e-03, fs:0.64052 (r=0.495,p=0.907),  time:19.874, tt:4233.096\n",
      "Ep:213, loss:0.00000, loss_test:0.09783, lr:2.96e-03, fs:0.62252 (r=0.475,p=0.904),  time:19.877, tt:4253.735\n",
      "Ep:214, loss:0.00000, loss_test:0.09771, lr:2.93e-03, fs:0.63158 (r=0.485,p=0.906),  time:19.888, tt:4275.850\n",
      "Ep:215, loss:0.00000, loss_test:0.09745, lr:2.90e-03, fs:0.63158 (r=0.485,p=0.906),  time:19.894, tt:4297.014\n",
      "Ep:216, loss:0.00000, loss_test:0.09765, lr:2.88e-03, fs:0.62252 (r=0.475,p=0.904),  time:19.895, tt:4317.284\n",
      "Ep:217, loss:0.00000, loss_test:0.09780, lr:2.85e-03, fs:0.60403 (r=0.455,p=0.900),  time:19.909, tt:4340.125\n",
      "Ep:218, loss:0.00000, loss_test:0.09764, lr:2.82e-03, fs:0.62252 (r=0.475,p=0.904),  time:19.910, tt:4360.316\n",
      "Ep:219, loss:0.00000, loss_test:0.09758, lr:2.79e-03, fs:0.61333 (r=0.465,p=0.902),  time:19.910, tt:4380.195\n",
      "Ep:220, loss:0.00000, loss_test:0.09798, lr:2.76e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.909, tt:4399.880\n",
      "Ep:221, loss:0.00000, loss_test:0.09797, lr:2.73e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.912, tt:4420.466\n",
      "Ep:222, loss:0.00000, loss_test:0.09757, lr:2.71e-03, fs:0.62252 (r=0.475,p=0.904),  time:19.913, tt:4440.629\n",
      "Ep:223, loss:0.00000, loss_test:0.09766, lr:2.68e-03, fs:0.60403 (r=0.455,p=0.900),  time:19.911, tt:4460.089\n",
      "Ep:224, loss:0.00000, loss_test:0.09806, lr:2.65e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.914, tt:4480.739\n",
      "Ep:225, loss:0.00000, loss_test:0.09791, lr:2.63e-03, fs:0.60403 (r=0.455,p=0.900),  time:19.911, tt:4499.820\n",
      "Ep:226, loss:0.00000, loss_test:0.09761, lr:2.60e-03, fs:0.61333 (r=0.465,p=0.902),  time:19.906, tt:4518.583\n",
      "Ep:227, loss:0.00000, loss_test:0.09788, lr:2.57e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.898, tt:4536.747\n",
      "Ep:228, loss:0.00000, loss_test:0.09802, lr:2.55e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.894, tt:4555.754\n",
      "Ep:229, loss:0.00000, loss_test:0.09778, lr:2.52e-03, fs:0.60403 (r=0.455,p=0.900),  time:19.901, tt:4577.195\n",
      "Ep:230, loss:0.00000, loss_test:0.09782, lr:2.50e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.899, tt:4596.605\n",
      "Ep:231, loss:0.00000, loss_test:0.09793, lr:2.47e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.899, tt:4616.669\n",
      "Ep:232, loss:0.00000, loss_test:0.09788, lr:2.45e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.891, tt:4634.645\n",
      "Ep:233, loss:0.00000, loss_test:0.09791, lr:2.42e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.894, tt:4655.284\n",
      "Ep:234, loss:0.00000, loss_test:0.09767, lr:2.40e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.893, tt:4674.955\n",
      "Ep:235, loss:0.00000, loss_test:0.09811, lr:2.38e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.891, tt:4694.237\n",
      "Ep:236, loss:0.00000, loss_test:0.09798, lr:2.35e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.889, tt:4713.576\n",
      "Ep:237, loss:0.00000, loss_test:0.09768, lr:2.33e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.891, tt:4734.120\n",
      "Ep:238, loss:0.00000, loss_test:0.09796, lr:2.31e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.892, tt:4754.102\n",
      "Ep:239, loss:0.00000, loss_test:0.09809, lr:2.28e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.895, tt:4774.774\n",
      "Ep:240, loss:0.00000, loss_test:0.09779, lr:2.26e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.899, tt:4795.722\n",
      "Ep:241, loss:0.00000, loss_test:0.09791, lr:2.24e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.904, tt:4816.812\n",
      "Ep:242, loss:0.00000, loss_test:0.09800, lr:2.21e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.903, tt:4836.363\n",
      "Ep:243, loss:0.00000, loss_test:0.09800, lr:2.19e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.904, tt:4856.575\n",
      "Ep:244, loss:0.00000, loss_test:0.09786, lr:2.17e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.906, tt:4877.002\n",
      "Ep:245, loss:0.00000, loss_test:0.09819, lr:2.15e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.905, tt:4896.616\n",
      "Ep:246, loss:0.00000, loss_test:0.09810, lr:2.13e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.906, tt:4916.675\n",
      "Ep:247, loss:0.00000, loss_test:0.09781, lr:2.11e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.911, tt:4937.872\n",
      "Ep:248, loss:0.00000, loss_test:0.09783, lr:2.08e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.913, tt:4958.396\n",
      "Ep:249, loss:0.00000, loss_test:0.09828, lr:2.06e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.926, tt:4981.434\n",
      "Ep:250, loss:0.00000, loss_test:0.09833, lr:2.04e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.922, tt:5000.512\n",
      "Ep:251, loss:0.00000, loss_test:0.09795, lr:2.02e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.927, tt:5021.547\n",
      "Ep:252, loss:0.00000, loss_test:0.09769, lr:2.00e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.928, tt:5041.876\n",
      "Ep:253, loss:0.00000, loss_test:0.09818, lr:1.98e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.933, tt:5063.072\n",
      "Ep:254, loss:0.00000, loss_test:0.09839, lr:1.96e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.929, tt:5081.967\n",
      "Ep:255, loss:0.00000, loss_test:0.09820, lr:1.94e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.932, tt:5102.477\n",
      "Ep:256, loss:0.00000, loss_test:0.09782, lr:1.92e-03, fs:0.59459 (r=0.444,p=0.898),  time:19.935, tt:5123.183\n",
      "Ep:257, loss:0.00000, loss_test:0.09801, lr:1.90e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.932, tt:5142.565\n",
      "Ep:258, loss:0.00000, loss_test:0.09838, lr:1.89e-03, fs:0.56552 (r=0.414,p=0.891),  time:19.936, tt:5163.439\n",
      "Ep:259, loss:0.00000, loss_test:0.09839, lr:1.87e-03, fs:0.56552 (r=0.414,p=0.891),  time:19.938, tt:5183.818\n",
      "Ep:260, loss:0.00000, loss_test:0.09811, lr:1.85e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.940, tt:5204.462\n",
      "Ep:261, loss:0.00000, loss_test:0.09792, lr:1.83e-03, fs:0.58503 (r=0.434,p=0.896),  time:19.943, tt:5225.145\n",
      "Ep:262, loss:0.00000, loss_test:0.09822, lr:1.81e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.944, tt:5245.345\n",
      "Ep:263, loss:0.00000, loss_test:0.09845, lr:1.79e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.943, tt:5264.950\n",
      "Ep:264, loss:0.00000, loss_test:0.09841, lr:1.78e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.949, tt:5286.513\n",
      "Ep:265, loss:0.00000, loss_test:0.09821, lr:1.76e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.951, tt:5307.012\n",
      "Ep:266, loss:0.00000, loss_test:0.09824, lr:1.74e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.952, tt:5327.311\n",
      "Ep:267, loss:0.00000, loss_test:0.09841, lr:1.72e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.953, tt:5347.367\n",
      "Ep:268, loss:0.00000, loss_test:0.09836, lr:1.71e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.954, tt:5367.505\n",
      "Ep:269, loss:0.00000, loss_test:0.09823, lr:1.69e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.951, tt:5386.819\n",
      "Ep:270, loss:0.00000, loss_test:0.09832, lr:1.67e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.949, tt:5406.205\n",
      "Ep:271, loss:0.00000, loss_test:0.09843, lr:1.65e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.959, tt:5428.880\n",
      "Ep:272, loss:0.00000, loss_test:0.09834, lr:1.64e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.961, tt:5449.384\n",
      "Ep:273, loss:0.00000, loss_test:0.09835, lr:1.62e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.966, tt:5470.801\n",
      "Ep:274, loss:0.00000, loss_test:0.09841, lr:1.61e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.968, tt:5491.228\n",
      "Ep:275, loss:0.00000, loss_test:0.09826, lr:1.59e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.969, tt:5511.331\n",
      "Ep:276, loss:0.00000, loss_test:0.09845, lr:1.57e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.963, tt:5529.817\n",
      "Ep:277, loss:0.00000, loss_test:0.09842, lr:1.56e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.969, tt:5551.393\n",
      "Ep:278, loss:0.00000, loss_test:0.09826, lr:1.54e-03, fs:0.57534 (r=0.424,p=0.894),  time:19.980, tt:5574.471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:279, loss:0.00000, loss_test:0.09848, lr:1.53e-03, fs:0.56552 (r=0.414,p=0.891),  time:19.984, tt:5595.491\n",
      "Ep:280, loss:0.00000, loss_test:0.09852, lr:1.51e-03, fs:0.56552 (r=0.414,p=0.891),  time:19.986, tt:5616.167\n",
      "Ep:281, loss:0.00000, loss_test:0.09836, lr:1.50e-03, fs:0.57534 (r=0.424,p=0.894),  time:20.006, tt:5641.745\n",
      "Ep:282, loss:0.00000, loss_test:0.09844, lr:1.48e-03, fs:0.57534 (r=0.424,p=0.894),  time:20.009, tt:5662.529\n",
      "Ep:283, loss:0.00000, loss_test:0.09854, lr:1.47e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.008, tt:5682.228\n",
      "Ep:284, loss:0.00000, loss_test:0.09847, lr:1.45e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.012, tt:5703.430\n",
      "Ep:285, loss:0.00000, loss_test:0.09849, lr:1.44e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.017, tt:5724.770\n",
      "Ep:286, loss:0.00000, loss_test:0.09854, lr:1.42e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.016, tt:5744.674\n",
      "Ep:287, loss:0.00000, loss_test:0.09846, lr:1.41e-03, fs:0.57534 (r=0.424,p=0.894),  time:20.019, tt:5765.397\n",
      "Ep:288, loss:0.00000, loss_test:0.09864, lr:1.39e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.022, tt:5786.319\n",
      "Ep:289, loss:0.00000, loss_test:0.09859, lr:1.38e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.024, tt:5806.874\n",
      "Ep:290, loss:0.00000, loss_test:0.09848, lr:1.37e-03, fs:0.57534 (r=0.424,p=0.894),  time:20.028, tt:5828.031\n",
      "Ep:291, loss:0.00000, loss_test:0.09874, lr:1.35e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.030, tt:5848.786\n",
      "Ep:292, loss:0.00000, loss_test:0.09876, lr:1.34e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.030, tt:5868.926\n",
      "Ep:293, loss:0.00000, loss_test:0.09857, lr:1.33e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.032, tt:5889.357\n",
      "Ep:294, loss:0.00000, loss_test:0.09851, lr:1.31e-03, fs:0.57534 (r=0.424,p=0.894),  time:20.034, tt:5910.063\n",
      "Ep:295, loss:0.00000, loss_test:0.09876, lr:1.30e-03, fs:0.56552 (r=0.414,p=0.891),  time:20.023, tt:5926.738\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13889, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:12.515, tt:12.515\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13794, lr:1.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:14.658, tt:29.316\n",
      "Ep:2, loss:0.00004, loss_test:0.13679, lr:1.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:15.443, tt:46.328\n",
      "Ep:3, loss:0.00004, loss_test:0.13621, lr:1.00e-02, fs:0.64844 (r=0.838,p=0.529),  time:16.204, tt:64.816\n",
      "Ep:4, loss:0.00004, loss_test:0.13603, lr:1.00e-02, fs:0.64777 (r=0.808,p=0.541),  time:16.608, tt:83.038\n",
      "Ep:5, loss:0.00004, loss_test:0.13673, lr:1.00e-02, fs:0.59227 (r=0.697,p=0.515),  time:17.011, tt:102.063\n",
      "Ep:6, loss:0.00004, loss_test:0.13736, lr:1.00e-02, fs:0.59556 (r=0.677,p=0.532),  time:17.169, tt:120.183\n",
      "Ep:7, loss:0.00003, loss_test:0.13722, lr:1.00e-02, fs:0.59193 (r=0.667,p=0.532),  time:17.376, tt:139.007\n",
      "Ep:8, loss:0.00003, loss_test:0.13645, lr:1.00e-02, fs:0.57534 (r=0.636,p=0.525),  time:17.453, tt:157.073\n",
      "Ep:9, loss:0.00003, loss_test:0.13496, lr:1.00e-02, fs:0.58716 (r=0.646,p=0.538),  time:17.444, tt:174.444\n",
      "Ep:10, loss:0.00003, loss_test:0.13338, lr:1.00e-02, fs:0.58216 (r=0.626,p=0.544),  time:17.588, tt:193.468\n",
      "Ep:11, loss:0.00003, loss_test:0.13198, lr:1.00e-02, fs:0.57547 (r=0.616,p=0.540),  time:17.637, tt:211.645\n",
      "Ep:12, loss:0.00003, loss_test:0.13089, lr:9.90e-03, fs:0.59155 (r=0.636,p=0.553),  time:17.709, tt:230.221\n",
      "Ep:13, loss:0.00003, loss_test:0.13004, lr:9.80e-03, fs:0.60287 (r=0.636,p=0.573),  time:17.776, tt:248.864\n",
      "Ep:14, loss:0.00003, loss_test:0.12913, lr:9.70e-03, fs:0.60194 (r=0.626,p=0.579),  time:17.857, tt:267.860\n",
      "Ep:15, loss:0.00003, loss_test:0.12810, lr:9.61e-03, fs:0.59406 (r=0.606,p=0.583),  time:17.959, tt:287.338\n",
      "Ep:16, loss:0.00003, loss_test:0.12718, lr:9.51e-03, fs:0.57576 (r=0.576,p=0.576),  time:17.984, tt:305.734\n",
      "Ep:17, loss:0.00003, loss_test:0.12602, lr:9.41e-03, fs:0.55670 (r=0.545,p=0.568),  time:18.088, tt:325.583\n",
      "Ep:18, loss:0.00003, loss_test:0.12454, lr:9.32e-03, fs:0.56995 (r=0.556,p=0.585),  time:18.182, tt:345.449\n",
      "Ep:19, loss:0.00003, loss_test:0.12291, lr:9.23e-03, fs:0.58031 (r=0.566,p=0.596),  time:18.183, tt:363.653\n",
      "Ep:20, loss:0.00003, loss_test:0.12146, lr:9.14e-03, fs:0.60204 (r=0.596,p=0.608),  time:18.179, tt:381.762\n",
      "Ep:21, loss:0.00003, loss_test:0.12012, lr:9.04e-03, fs:0.61616 (r=0.616,p=0.616),  time:18.246, tt:401.409\n",
      "Ep:22, loss:0.00003, loss_test:0.11900, lr:8.95e-03, fs:0.61929 (r=0.616,p=0.622),  time:18.238, tt:419.470\n",
      "Ep:23, loss:0.00003, loss_test:0.11807, lr:8.86e-03, fs:0.61929 (r=0.616,p=0.622),  time:18.257, tt:438.156\n",
      "Ep:24, loss:0.00003, loss_test:0.11733, lr:8.78e-03, fs:0.63317 (r=0.636,p=0.630),  time:18.293, tt:457.335\n",
      "Ep:25, loss:0.00003, loss_test:0.11667, lr:8.69e-03, fs:0.64322 (r=0.646,p=0.640),  time:18.334, tt:476.690\n",
      "Ep:26, loss:0.00003, loss_test:0.11600, lr:8.60e-03, fs:0.65327 (r=0.657,p=0.650),  time:18.335, tt:495.049\n",
      "Ep:27, loss:0.00003, loss_test:0.11520, lr:8.51e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.342, tt:513.576\n",
      "Ep:28, loss:0.00003, loss_test:0.11428, lr:8.43e-03, fs:0.66332 (r=0.667,p=0.660),  time:18.374, tt:532.836\n",
      "Ep:29, loss:0.00003, loss_test:0.11337, lr:8.35e-03, fs:0.67000 (r=0.677,p=0.663),  time:18.370, tt:551.088\n",
      "Ep:30, loss:0.00003, loss_test:0.11247, lr:8.26e-03, fs:0.68317 (r=0.697,p=0.670),  time:18.376, tt:569.666\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.11163, lr:8.26e-03, fs:0.67662 (r=0.687,p=0.667),  time:18.392, tt:588.553\n",
      "Ep:32, loss:0.00002, loss_test:0.11096, lr:8.26e-03, fs:0.67000 (r=0.677,p=0.663),  time:18.372, tt:606.292\n",
      "Ep:33, loss:0.00002, loss_test:0.11026, lr:8.26e-03, fs:0.65990 (r=0.657,p=0.663),  time:18.366, tt:624.443\n",
      "Ep:34, loss:0.00002, loss_test:0.10948, lr:8.26e-03, fs:0.66667 (r=0.657,p=0.677),  time:18.394, tt:643.786\n",
      "Ep:35, loss:0.00002, loss_test:0.10865, lr:8.26e-03, fs:0.66327 (r=0.657,p=0.670),  time:18.414, tt:662.906\n",
      "Ep:36, loss:0.00002, loss_test:0.10768, lr:8.26e-03, fs:0.67005 (r=0.667,p=0.673),  time:18.428, tt:681.854\n",
      "Ep:37, loss:0.00002, loss_test:0.10669, lr:8.26e-03, fs:0.68000 (r=0.687,p=0.673),  time:18.418, tt:699.902\n",
      "Ep:38, loss:0.00002, loss_test:0.10591, lr:8.26e-03, fs:0.69036 (r=0.687,p=0.694),  time:18.423, tt:718.495\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10546, lr:8.26e-03, fs:0.70051 (r=0.697,p=0.704),  time:18.437, tt:737.491\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.10505, lr:8.26e-03, fs:0.69072 (r=0.677,p=0.705),  time:18.423, tt:755.339\n",
      "Ep:41, loss:0.00002, loss_test:0.10435, lr:8.26e-03, fs:0.70466 (r=0.687,p=0.723),  time:18.395, tt:772.601\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.10353, lr:8.26e-03, fs:0.71134 (r=0.697,p=0.726),  time:18.390, tt:790.788\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.10269, lr:8.26e-03, fs:0.71795 (r=0.707,p=0.729),  time:18.407, tt:809.902\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.10201, lr:8.26e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.415, tt:828.667\n",
      "Ep:45, loss:0.00002, loss_test:0.10142, lr:8.26e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.422, tt:847.430\n",
      "Ep:46, loss:0.00002, loss_test:0.10095, lr:8.26e-03, fs:0.70707 (r=0.707,p=0.707),  time:18.409, tt:865.234\n",
      "Ep:47, loss:0.00002, loss_test:0.10067, lr:8.26e-03, fs:0.71066 (r=0.707,p=0.714),  time:18.386, tt:882.510\n",
      "Ep:48, loss:0.00002, loss_test:0.10044, lr:8.26e-03, fs:0.69744 (r=0.687,p=0.708),  time:18.374, tt:900.349\n",
      "Ep:49, loss:0.00002, loss_test:0.10008, lr:8.26e-03, fs:0.71134 (r=0.697,p=0.726),  time:18.364, tt:918.220\n",
      "Ep:50, loss:0.00002, loss_test:0.09950, lr:8.26e-03, fs:0.71134 (r=0.697,p=0.726),  time:18.340, tt:935.356\n",
      "Ep:51, loss:0.00002, loss_test:0.09875, lr:8.26e-03, fs:0.71503 (r=0.697,p=0.734),  time:18.325, tt:952.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00002, loss_test:0.09822, lr:8.26e-03, fs:0.72165 (r=0.707,p=0.737),  time:18.315, tt:970.694\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.09802, lr:8.26e-03, fs:0.71875 (r=0.697,p=0.742),  time:18.300, tt:988.204\n",
      "Ep:54, loss:0.00002, loss_test:0.09792, lr:8.26e-03, fs:0.71204 (r=0.687,p=0.739),  time:18.296, tt:1006.287\n",
      "Ep:55, loss:0.00002, loss_test:0.09756, lr:8.26e-03, fs:0.72251 (r=0.697,p=0.750),  time:18.305, tt:1025.089\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.09699, lr:8.26e-03, fs:0.72632 (r=0.697,p=0.758),  time:18.298, tt:1043.009\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.09656, lr:8.26e-03, fs:0.71958 (r=0.687,p=0.756),  time:18.310, tt:1061.999\n",
      "Ep:58, loss:0.00002, loss_test:0.09632, lr:8.26e-03, fs:0.71277 (r=0.677,p=0.753),  time:18.301, tt:1079.745\n",
      "Ep:59, loss:0.00002, loss_test:0.09610, lr:8.26e-03, fs:0.71277 (r=0.677,p=0.753),  time:18.325, tt:1099.476\n",
      "Ep:60, loss:0.00002, loss_test:0.09573, lr:8.26e-03, fs:0.71277 (r=0.677,p=0.753),  time:18.321, tt:1117.575\n",
      "Ep:61, loss:0.00002, loss_test:0.09549, lr:8.26e-03, fs:0.71277 (r=0.677,p=0.753),  time:18.337, tt:1136.869\n",
      "Ep:62, loss:0.00002, loss_test:0.09560, lr:8.26e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.328, tt:1154.672\n",
      "Ep:63, loss:0.00002, loss_test:0.09575, lr:8.26e-03, fs:0.71658 (r=0.677,p=0.761),  time:18.328, tt:1173.012\n",
      "Ep:64, loss:0.00002, loss_test:0.09557, lr:8.26e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.344, tt:1192.379\n",
      "Ep:65, loss:0.00002, loss_test:0.09542, lr:8.26e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.344, tt:1210.719\n",
      "Ep:66, loss:0.00002, loss_test:0.09542, lr:8.26e-03, fs:0.70588 (r=0.667,p=0.750),  time:18.346, tt:1229.175\n",
      "Ep:67, loss:0.00002, loss_test:0.09523, lr:8.26e-03, fs:0.69892 (r=0.657,p=0.747),  time:18.344, tt:1247.382\n",
      "Ep:68, loss:0.00002, loss_test:0.09493, lr:8.18e-03, fs:0.69892 (r=0.657,p=0.747),  time:18.351, tt:1266.222\n",
      "Ep:69, loss:0.00002, loss_test:0.09498, lr:8.10e-03, fs:0.70270 (r=0.657,p=0.756),  time:18.349, tt:1284.442\n",
      "Ep:70, loss:0.00002, loss_test:0.09506, lr:8.02e-03, fs:0.70270 (r=0.657,p=0.756),  time:18.380, tt:1304.980\n",
      "Ep:71, loss:0.00002, loss_test:0.09491, lr:7.94e-03, fs:0.70270 (r=0.657,p=0.756),  time:18.363, tt:1322.163\n",
      "Ep:72, loss:0.00001, loss_test:0.09469, lr:7.86e-03, fs:0.70270 (r=0.657,p=0.756),  time:18.362, tt:1340.402\n",
      "Ep:73, loss:0.00001, loss_test:0.09474, lr:7.78e-03, fs:0.69565 (r=0.646,p=0.753),  time:18.335, tt:1356.788\n",
      "Ep:74, loss:0.00001, loss_test:0.09461, lr:7.70e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.332, tt:1374.892\n",
      "Ep:75, loss:0.00001, loss_test:0.09456, lr:7.62e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.320, tt:1392.291\n",
      "Ep:76, loss:0.00001, loss_test:0.09441, lr:7.55e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.343, tt:1412.382\n",
      "Ep:77, loss:0.00001, loss_test:0.09415, lr:7.47e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.345, tt:1430.939\n",
      "Ep:78, loss:0.00001, loss_test:0.09406, lr:7.40e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.338, tt:1448.731\n",
      "Ep:79, loss:0.00001, loss_test:0.09399, lr:7.32e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.336, tt:1466.874\n",
      "Ep:80, loss:0.00001, loss_test:0.09361, lr:7.25e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.342, tt:1485.736\n",
      "Ep:81, loss:0.00001, loss_test:0.09329, lr:7.18e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.336, tt:1503.550\n",
      "Ep:82, loss:0.00001, loss_test:0.09311, lr:7.11e-03, fs:0.69945 (r=0.646,p=0.762),  time:18.324, tt:1520.860\n",
      "Ep:83, loss:0.00001, loss_test:0.09319, lr:7.03e-03, fs:0.70718 (r=0.646,p=0.780),  time:18.328, tt:1539.521\n",
      "Ep:84, loss:0.00001, loss_test:0.09335, lr:6.96e-03, fs:0.71508 (r=0.646,p=0.800),  time:18.325, tt:1557.612\n",
      "Ep:85, loss:0.00001, loss_test:0.09332, lr:6.89e-03, fs:0.71111 (r=0.646,p=0.790),  time:18.323, tt:1575.758\n",
      "Ep:86, loss:0.00001, loss_test:0.09316, lr:6.83e-03, fs:0.71111 (r=0.646,p=0.790),  time:18.314, tt:1593.278\n",
      "Ep:87, loss:0.00001, loss_test:0.09329, lr:6.76e-03, fs:0.71111 (r=0.646,p=0.790),  time:18.305, tt:1610.865\n",
      "Ep:88, loss:0.00001, loss_test:0.09340, lr:6.69e-03, fs:0.71508 (r=0.646,p=0.800),  time:18.308, tt:1629.441\n",
      "Ep:89, loss:0.00001, loss_test:0.09316, lr:6.62e-03, fs:0.71111 (r=0.646,p=0.790),  time:18.302, tt:1647.191\n",
      "Ep:90, loss:0.00001, loss_test:0.09315, lr:6.56e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.299, tt:1665.214\n",
      "Ep:91, loss:0.00001, loss_test:0.09328, lr:6.49e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.299, tt:1683.489\n",
      "Ep:92, loss:0.00001, loss_test:0.09298, lr:6.43e-03, fs:0.71910 (r=0.646,p=0.810),  time:18.290, tt:1701.011\n",
      "Ep:93, loss:0.00001, loss_test:0.09292, lr:6.36e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.288, tt:1719.086\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.09288, lr:6.36e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.297, tt:1738.186\n",
      "Ep:95, loss:0.00001, loss_test:0.09284, lr:6.36e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.295, tt:1756.304\n",
      "Ep:96, loss:0.00001, loss_test:0.09284, lr:6.36e-03, fs:0.73034 (r=0.657,p=0.823),  time:18.300, tt:1775.143\n",
      "Ep:97, loss:0.00001, loss_test:0.09282, lr:6.36e-03, fs:0.72316 (r=0.646,p=0.821),  time:18.316, tt:1795.009\n",
      "Ep:98, loss:0.00001, loss_test:0.09281, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.339, tt:1815.606\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.09254, lr:6.36e-03, fs:0.72727 (r=0.646,p=0.831),  time:18.329, tt:1832.937\n",
      "Ep:100, loss:0.00001, loss_test:0.09224, lr:6.36e-03, fs:0.72727 (r=0.646,p=0.831),  time:18.326, tt:1850.880\n",
      "Ep:101, loss:0.00001, loss_test:0.09261, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.332, tt:1869.854\n",
      "Ep:102, loss:0.00001, loss_test:0.09261, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.340, tt:1889.065\n",
      "Ep:103, loss:0.00001, loss_test:0.09247, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.344, tt:1907.792\n",
      "Ep:104, loss:0.00001, loss_test:0.09258, lr:6.36e-03, fs:0.73143 (r=0.646,p=0.842),  time:18.346, tt:1926.360\n",
      "Ep:105, loss:0.00001, loss_test:0.09260, lr:6.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.352, tt:1945.299\n",
      "Ep:106, loss:0.00001, loss_test:0.09246, lr:6.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.356, tt:1964.062\n",
      "Ep:107, loss:0.00001, loss_test:0.09263, lr:6.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.354, tt:1982.196\n",
      "Ep:108, loss:0.00001, loss_test:0.09279, lr:6.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.349, tt:2000.058\n",
      "Ep:109, loss:0.00001, loss_test:0.09296, lr:6.36e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.347, tt:2018.218\n",
      "Ep:110, loss:0.00001, loss_test:0.09297, lr:6.30e-03, fs:0.72414 (r=0.636,p=0.840),  time:18.353, tt:2037.134\n",
      "Ep:111, loss:0.00001, loss_test:0.09296, lr:6.24e-03, fs:0.71676 (r=0.626,p=0.838),  time:18.349, tt:2055.059\n",
      "Ep:112, loss:0.00001, loss_test:0.09341, lr:6.17e-03, fs:0.70930 (r=0.616,p=0.836),  time:18.348, tt:2073.338\n",
      "Ep:113, loss:0.00001, loss_test:0.09346, lr:6.11e-03, fs:0.70175 (r=0.606,p=0.833),  time:18.346, tt:2091.475\n",
      "Ep:114, loss:0.00001, loss_test:0.09364, lr:6.05e-03, fs:0.69412 (r=0.596,p=0.831),  time:18.344, tt:2109.518\n",
      "Ep:115, loss:0.00001, loss_test:0.09397, lr:5.99e-03, fs:0.70588 (r=0.606,p=0.845),  time:18.343, tt:2127.842\n",
      "Ep:116, loss:0.00001, loss_test:0.09389, lr:5.93e-03, fs:0.69822 (r=0.596,p=0.843),  time:18.338, tt:2145.570\n",
      "Ep:117, loss:0.00001, loss_test:0.09380, lr:5.87e-03, fs:0.69822 (r=0.596,p=0.843),  time:18.344, tt:2164.566\n",
      "Ep:118, loss:0.00001, loss_test:0.09387, lr:5.81e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.347, tt:2183.249\n",
      "Ep:119, loss:0.00001, loss_test:0.09438, lr:5.75e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.352, tt:2202.280\n",
      "Ep:120, loss:0.00001, loss_test:0.09424, lr:5.70e-03, fs:0.69822 (r=0.596,p=0.843),  time:18.362, tt:2221.743\n",
      "Ep:121, loss:0.00001, loss_test:0.09418, lr:5.64e-03, fs:0.69822 (r=0.596,p=0.843),  time:18.359, tt:2239.754\n",
      "Ep:122, loss:0.00001, loss_test:0.09448, lr:5.58e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.360, tt:2258.230\n",
      "Ep:123, loss:0.00001, loss_test:0.09461, lr:5.53e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.360, tt:2276.681\n",
      "Ep:124, loss:0.00001, loss_test:0.09439, lr:5.47e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.362, tt:2295.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:125, loss:0.00001, loss_test:0.09428, lr:5.42e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.364, tt:2313.840\n",
      "Ep:126, loss:0.00001, loss_test:0.09449, lr:5.36e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.371, tt:2333.104\n",
      "Ep:127, loss:0.00001, loss_test:0.09424, lr:5.31e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.373, tt:2351.684\n",
      "Ep:128, loss:0.00001, loss_test:0.09431, lr:5.26e-03, fs:0.69048 (r=0.586,p=0.841),  time:18.359, tt:2368.350\n",
      "Ep:129, loss:0.00001, loss_test:0.09440, lr:5.20e-03, fs:0.69461 (r=0.586,p=0.853),  time:18.357, tt:2386.352\n",
      "Ep:130, loss:0.00001, loss_test:0.09436, lr:5.15e-03, fs:0.69461 (r=0.586,p=0.853),  time:18.364, tt:2405.703\n",
      "Ep:131, loss:0.00001, loss_test:0.09446, lr:5.10e-03, fs:0.69461 (r=0.586,p=0.853),  time:18.367, tt:2424.429\n",
      "Ep:132, loss:0.00001, loss_test:0.09462, lr:5.05e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.360, tt:2441.921\n",
      "Ep:133, loss:0.00001, loss_test:0.09482, lr:5.00e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.363, tt:2460.700\n",
      "Ep:134, loss:0.00001, loss_test:0.09451, lr:4.95e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.363, tt:2478.971\n",
      "Ep:135, loss:0.00001, loss_test:0.09448, lr:4.90e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.368, tt:2498.049\n",
      "Ep:136, loss:0.00001, loss_test:0.09462, lr:4.85e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.376, tt:2517.492\n",
      "Ep:137, loss:0.00001, loss_test:0.09475, lr:4.80e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.376, tt:2535.831\n",
      "Ep:138, loss:0.00001, loss_test:0.09488, lr:4.75e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.383, tt:2555.173\n",
      "Ep:139, loss:0.00001, loss_test:0.09462, lr:4.71e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.380, tt:2573.139\n",
      "Ep:140, loss:0.00001, loss_test:0.09492, lr:4.66e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.376, tt:2590.968\n",
      "Ep:141, loss:0.00001, loss_test:0.09504, lr:4.61e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.376, tt:2609.442\n",
      "Ep:142, loss:0.00001, loss_test:0.09531, lr:4.57e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.379, tt:2628.222\n",
      "Ep:143, loss:0.00001, loss_test:0.09529, lr:4.52e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.374, tt:2645.844\n",
      "Ep:144, loss:0.00001, loss_test:0.09511, lr:4.48e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.374, tt:2664.283\n",
      "Ep:145, loss:0.00001, loss_test:0.09549, lr:4.43e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.363, tt:2681.037\n",
      "Ep:146, loss:0.00001, loss_test:0.09565, lr:4.39e-03, fs:0.69880 (r=0.586,p=0.866),  time:18.363, tt:2699.412\n",
      "Ep:147, loss:0.00001, loss_test:0.09570, lr:4.34e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.371, tt:2718.943\n",
      "Ep:148, loss:0.00001, loss_test:0.09570, lr:4.30e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.383, tt:2739.042\n",
      "Ep:149, loss:0.00001, loss_test:0.09593, lr:4.26e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.387, tt:2758.017\n",
      "Ep:150, loss:0.00001, loss_test:0.09578, lr:4.21e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.384, tt:2776.045\n",
      "Ep:151, loss:0.00001, loss_test:0.09583, lr:4.17e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.387, tt:2794.788\n",
      "Ep:152, loss:0.00001, loss_test:0.09602, lr:4.13e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.391, tt:2813.787\n",
      "Ep:153, loss:0.00001, loss_test:0.09584, lr:4.09e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.387, tt:2831.674\n",
      "Ep:154, loss:0.00001, loss_test:0.09603, lr:4.05e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.390, tt:2850.429\n",
      "Ep:155, loss:0.00001, loss_test:0.09581, lr:4.01e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.390, tt:2868.772\n",
      "Ep:156, loss:0.00001, loss_test:0.09585, lr:3.97e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.393, tt:2887.724\n",
      "Ep:157, loss:0.00001, loss_test:0.09597, lr:3.93e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.404, tt:2907.890\n",
      "Ep:158, loss:0.00001, loss_test:0.09589, lr:3.89e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.410, tt:2927.112\n",
      "Ep:159, loss:0.00001, loss_test:0.09611, lr:3.85e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.416, tt:2946.622\n",
      "Ep:160, loss:0.00001, loss_test:0.09623, lr:3.81e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.419, tt:2965.517\n",
      "Ep:161, loss:0.00001, loss_test:0.09628, lr:3.77e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.425, tt:2984.845\n",
      "Ep:162, loss:0.00001, loss_test:0.09621, lr:3.73e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.422, tt:3002.775\n",
      "Ep:163, loss:0.00001, loss_test:0.09636, lr:3.70e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.423, tt:3021.359\n",
      "Ep:164, loss:0.00001, loss_test:0.09629, lr:3.66e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.426, tt:3040.366\n",
      "Ep:165, loss:0.00001, loss_test:0.09640, lr:3.62e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.431, tt:3059.576\n",
      "Ep:166, loss:0.00001, loss_test:0.09634, lr:3.59e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.432, tt:3078.176\n",
      "Ep:167, loss:0.00001, loss_test:0.09638, lr:3.55e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.442, tt:3098.223\n",
      "Ep:168, loss:0.00001, loss_test:0.09647, lr:3.52e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.448, tt:3117.786\n",
      "Ep:169, loss:0.00001, loss_test:0.09648, lr:3.48e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.450, tt:3136.510\n",
      "Ep:170, loss:0.00001, loss_test:0.09656, lr:3.45e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.454, tt:3155.641\n",
      "Ep:171, loss:0.00001, loss_test:0.09654, lr:3.41e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.457, tt:3174.624\n",
      "Ep:172, loss:0.00001, loss_test:0.09647, lr:3.38e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.459, tt:3193.424\n",
      "Ep:173, loss:0.00001, loss_test:0.09663, lr:3.34e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.462, tt:3212.447\n",
      "Ep:174, loss:0.00001, loss_test:0.09655, lr:3.31e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.466, tt:3231.473\n",
      "Ep:175, loss:0.00001, loss_test:0.09657, lr:3.28e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.466, tt:3250.076\n",
      "Ep:176, loss:0.00001, loss_test:0.09669, lr:3.24e-03, fs:0.69512 (r=0.576,p=0.877),  time:18.459, tt:3267.299\n",
      "Ep:177, loss:0.00001, loss_test:0.09669, lr:3.21e-03, fs:0.69939 (r=0.576,p=0.891),  time:18.458, tt:3285.442\n",
      "Ep:178, loss:0.00001, loss_test:0.09696, lr:3.18e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.461, tt:3304.462\n",
      "Ep:179, loss:0.00001, loss_test:0.09664, lr:3.15e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.461, tt:3322.929\n",
      "Ep:180, loss:0.00001, loss_test:0.09674, lr:3.12e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.461, tt:3341.476\n",
      "Ep:181, loss:0.00001, loss_test:0.09697, lr:3.09e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.466, tt:3360.827\n",
      "Ep:182, loss:0.00001, loss_test:0.09680, lr:3.05e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.471, tt:3380.222\n",
      "Ep:183, loss:0.00001, loss_test:0.09710, lr:3.02e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.470, tt:3398.445\n",
      "Ep:184, loss:0.00001, loss_test:0.09687, lr:2.99e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.480, tt:3418.770\n",
      "Ep:185, loss:0.00001, loss_test:0.09696, lr:2.96e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.483, tt:3437.884\n",
      "Ep:186, loss:0.00001, loss_test:0.09720, lr:2.93e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.486, tt:3456.872\n",
      "Ep:187, loss:0.00001, loss_test:0.09706, lr:2.90e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.483, tt:3474.803\n",
      "Ep:188, loss:0.00001, loss_test:0.09686, lr:2.88e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.477, tt:3492.243\n",
      "Ep:189, loss:0.00001, loss_test:0.09719, lr:2.85e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.478, tt:3510.739\n",
      "Ep:190, loss:0.00001, loss_test:0.09724, lr:2.82e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.479, tt:3529.574\n",
      "Ep:191, loss:0.00001, loss_test:0.09692, lr:2.79e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.476, tt:3547.362\n",
      "Ep:192, loss:0.00001, loss_test:0.09711, lr:2.76e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.480, tt:3566.601\n",
      "Ep:193, loss:0.00001, loss_test:0.09717, lr:2.73e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.488, tt:3586.692\n",
      "Ep:194, loss:0.00001, loss_test:0.09710, lr:2.71e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.491, tt:3605.735\n",
      "Ep:195, loss:0.00001, loss_test:0.09729, lr:2.68e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.491, tt:3624.270\n",
      "Ep:196, loss:0.00001, loss_test:0.09725, lr:2.65e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.492, tt:3642.957\n",
      "Ep:197, loss:0.00001, loss_test:0.09704, lr:2.63e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.496, tt:3662.200\n",
      "Ep:198, loss:0.00001, loss_test:0.09728, lr:2.60e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.494, tt:3680.264\n",
      "Ep:199, loss:0.00001, loss_test:0.09742, lr:2.57e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.490, tt:3698.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:200, loss:0.00001, loss_test:0.09706, lr:2.55e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.496, tt:3717.635\n",
      "Ep:201, loss:0.00001, loss_test:0.09726, lr:2.52e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.496, tt:3736.133\n",
      "Ep:202, loss:0.00001, loss_test:0.09736, lr:2.50e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.496, tt:3754.624\n",
      "Ep:203, loss:0.00001, loss_test:0.09723, lr:2.47e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.496, tt:3773.251\n",
      "Ep:204, loss:0.00001, loss_test:0.09731, lr:2.45e-03, fs:0.70370 (r=0.576,p=0.905),  time:18.502, tt:3792.853\n",
      "Ep:205, loss:0.00001, loss_test:0.09729, lr:2.42e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.498, tt:3810.665\n",
      "Ep:206, loss:0.00001, loss_test:0.09718, lr:2.40e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.495, tt:3828.459\n",
      "Ep:207, loss:0.00001, loss_test:0.09731, lr:2.38e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.493, tt:3846.560\n",
      "Ep:208, loss:0.00001, loss_test:0.09739, lr:2.35e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.491, tt:3864.715\n",
      "Ep:209, loss:0.00001, loss_test:0.09719, lr:2.33e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.490, tt:3882.822\n",
      "Ep:210, loss:0.00001, loss_test:0.09739, lr:2.31e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.493, tt:3902.109\n",
      "Ep:211, loss:0.00001, loss_test:0.09736, lr:2.28e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.494, tt:3920.741\n",
      "Ep:212, loss:0.00001, loss_test:0.09719, lr:2.26e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.493, tt:3938.992\n",
      "Ep:213, loss:0.00000, loss_test:0.09747, lr:2.24e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.495, tt:3957.856\n",
      "Ep:214, loss:0.00000, loss_test:0.09740, lr:2.21e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.491, tt:3975.499\n",
      "Ep:215, loss:0.00000, loss_test:0.09724, lr:2.19e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.487, tt:3993.221\n",
      "Ep:216, loss:0.00000, loss_test:0.09743, lr:2.17e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.487, tt:4011.672\n",
      "Ep:217, loss:0.00000, loss_test:0.09737, lr:2.15e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.489, tt:4030.666\n",
      "Ep:218, loss:0.00000, loss_test:0.09725, lr:2.13e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.493, tt:4050.053\n",
      "Ep:219, loss:0.00000, loss_test:0.09754, lr:2.11e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.493, tt:4068.563\n",
      "Ep:220, loss:0.00000, loss_test:0.09764, lr:2.08e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.497, tt:4087.848\n",
      "Ep:221, loss:0.00000, loss_test:0.09745, lr:2.06e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.499, tt:4106.874\n",
      "Ep:222, loss:0.00000, loss_test:0.09744, lr:2.04e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.501, tt:4125.808\n",
      "Ep:223, loss:0.00000, loss_test:0.09761, lr:2.02e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.504, tt:4144.859\n",
      "Ep:224, loss:0.00000, loss_test:0.09764, lr:2.00e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.505, tt:4163.629\n",
      "Ep:225, loss:0.00000, loss_test:0.09754, lr:1.98e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.502, tt:4181.557\n",
      "Ep:226, loss:0.00000, loss_test:0.09773, lr:1.96e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.504, tt:4200.480\n",
      "Ep:227, loss:0.00000, loss_test:0.09775, lr:1.94e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.509, tt:4220.011\n",
      "Ep:228, loss:0.00000, loss_test:0.09775, lr:1.92e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.514, tt:4239.733\n",
      "Ep:229, loss:0.00000, loss_test:0.09779, lr:1.90e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.517, tt:4258.844\n",
      "Ep:230, loss:0.00000, loss_test:0.09783, lr:1.89e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.524, tt:4279.040\n",
      "Ep:231, loss:0.00000, loss_test:0.09783, lr:1.87e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.530, tt:4299.044\n",
      "Ep:232, loss:0.00000, loss_test:0.09780, lr:1.85e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.533, tt:4318.146\n",
      "Ep:233, loss:0.00000, loss_test:0.09779, lr:1.83e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.541, tt:4338.531\n",
      "Ep:234, loss:0.00000, loss_test:0.09793, lr:1.81e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.548, tt:4358.668\n",
      "Ep:235, loss:0.00000, loss_test:0.09798, lr:1.79e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.552, tt:4378.208\n",
      "Ep:236, loss:0.00000, loss_test:0.09785, lr:1.78e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.558, tt:4398.234\n",
      "Ep:237, loss:0.00000, loss_test:0.09793, lr:1.76e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.566, tt:4418.609\n",
      "Ep:238, loss:0.00000, loss_test:0.09800, lr:1.74e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.569, tt:4437.960\n",
      "Ep:239, loss:0.00000, loss_test:0.09788, lr:1.72e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.571, tt:4457.040\n",
      "Ep:240, loss:0.00000, loss_test:0.09799, lr:1.71e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.577, tt:4477.172\n",
      "Ep:241, loss:0.00000, loss_test:0.09811, lr:1.69e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.578, tt:4495.928\n",
      "Ep:242, loss:0.00000, loss_test:0.09796, lr:1.67e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.590, tt:4517.388\n",
      "Ep:243, loss:0.00000, loss_test:0.09795, lr:1.65e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.591, tt:4536.315\n",
      "Ep:244, loss:0.00000, loss_test:0.09805, lr:1.64e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.593, tt:4555.323\n",
      "Ep:245, loss:0.00000, loss_test:0.09806, lr:1.62e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.597, tt:4574.879\n",
      "Ep:246, loss:0.00000, loss_test:0.09797, lr:1.61e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.595, tt:4593.070\n",
      "Ep:247, loss:0.00000, loss_test:0.09799, lr:1.59e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.598, tt:4612.297\n",
      "Ep:248, loss:0.00000, loss_test:0.09809, lr:1.57e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.600, tt:4631.520\n",
      "Ep:249, loss:0.00000, loss_test:0.09809, lr:1.56e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.607, tt:4651.697\n",
      "Ep:250, loss:0.00000, loss_test:0.09805, lr:1.54e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.613, tt:4671.836\n",
      "Ep:251, loss:0.00000, loss_test:0.09815, lr:1.53e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.613, tt:4690.533\n",
      "Ep:252, loss:0.00000, loss_test:0.09821, lr:1.51e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.612, tt:4708.927\n",
      "Ep:253, loss:0.00000, loss_test:0.09813, lr:1.50e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.611, tt:4727.144\n",
      "Ep:254, loss:0.00000, loss_test:0.09820, lr:1.48e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.613, tt:4746.332\n",
      "Ep:255, loss:0.00000, loss_test:0.09815, lr:1.47e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.614, tt:4765.063\n",
      "Ep:256, loss:0.00000, loss_test:0.09821, lr:1.45e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.615, tt:4783.998\n",
      "Ep:257, loss:0.00000, loss_test:0.09818, lr:1.44e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.618, tt:4803.474\n",
      "Ep:258, loss:0.00000, loss_test:0.09822, lr:1.42e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.620, tt:4822.622\n",
      "Ep:259, loss:0.00000, loss_test:0.09832, lr:1.41e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.626, tt:4842.735\n",
      "Ep:260, loss:0.00000, loss_test:0.09836, lr:1.39e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.632, tt:4863.050\n",
      "Ep:261, loss:0.00000, loss_test:0.09824, lr:1.38e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.634, tt:4882.024\n",
      "Ep:262, loss:0.00000, loss_test:0.09833, lr:1.37e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.633, tt:4900.571\n",
      "Ep:263, loss:0.00000, loss_test:0.09845, lr:1.35e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.638, tt:4920.483\n",
      "Ep:264, loss:0.00000, loss_test:0.09840, lr:1.34e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.639, tt:4939.327\n",
      "Ep:265, loss:0.00000, loss_test:0.09836, lr:1.33e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.644, tt:4959.214\n",
      "Ep:266, loss:0.00000, loss_test:0.09841, lr:1.31e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.645, tt:4978.329\n",
      "Ep:267, loss:0.00000, loss_test:0.09845, lr:1.30e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.647, tt:4997.444\n",
      "Ep:268, loss:0.00000, loss_test:0.09848, lr:1.29e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.650, tt:5016.804\n",
      "Ep:269, loss:0.00000, loss_test:0.09850, lr:1.27e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.657, tt:5037.403\n",
      "Ep:270, loss:0.00000, loss_test:0.09844, lr:1.26e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.659, tt:5056.563\n",
      "Ep:271, loss:0.00000, loss_test:0.09849, lr:1.25e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.662, tt:5076.134\n",
      "Ep:272, loss:0.00000, loss_test:0.09850, lr:1.24e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.666, tt:5095.809\n",
      "Ep:273, loss:0.00000, loss_test:0.09849, lr:1.22e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.668, tt:5114.936\n",
      "Ep:274, loss:0.00000, loss_test:0.09858, lr:1.21e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.667, tt:5133.463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:275, loss:0.00000, loss_test:0.09860, lr:1.20e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.668, tt:5152.242\n",
      "Ep:276, loss:0.00000, loss_test:0.09858, lr:1.19e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.668, tt:5171.114\n",
      "Ep:277, loss:0.00000, loss_test:0.09871, lr:1.18e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.671, tt:5190.657\n",
      "Ep:278, loss:0.00000, loss_test:0.09868, lr:1.16e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.673, tt:5209.652\n",
      "Ep:279, loss:0.00000, loss_test:0.09869, lr:1.15e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.673, tt:5228.578\n",
      "Ep:280, loss:0.00000, loss_test:0.09872, lr:1.14e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.676, tt:5247.858\n",
      "Ep:281, loss:0.00000, loss_test:0.09871, lr:1.13e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.673, tt:5265.817\n",
      "Ep:282, loss:0.00000, loss_test:0.09882, lr:1.12e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.673, tt:5284.492\n",
      "Ep:283, loss:0.00000, loss_test:0.09872, lr:1.11e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.670, tt:5302.393\n",
      "Ep:284, loss:0.00000, loss_test:0.09881, lr:1.10e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.672, tt:5321.453\n",
      "Ep:285, loss:0.00000, loss_test:0.09885, lr:1.08e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.671, tt:5339.955\n",
      "Ep:286, loss:0.00000, loss_test:0.09887, lr:1.07e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.671, tt:5358.514\n",
      "Ep:287, loss:0.00000, loss_test:0.09884, lr:1.06e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.668, tt:5376.343\n",
      "Ep:288, loss:0.00000, loss_test:0.09896, lr:1.05e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.666, tt:5394.594\n",
      "Ep:289, loss:0.00000, loss_test:0.09892, lr:1.04e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.661, tt:5411.693\n",
      "Ep:290, loss:0.00000, loss_test:0.09897, lr:1.03e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.659, tt:5429.796\n",
      "Ep:291, loss:0.00000, loss_test:0.09899, lr:1.02e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.659, tt:5448.535\n",
      "Ep:292, loss:0.00000, loss_test:0.09895, lr:1.01e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.661, tt:5467.552\n",
      "Ep:293, loss:0.00000, loss_test:0.09905, lr:1.00e-03, fs:0.70807 (r=0.576,p=0.919),  time:18.662, tt:5486.546\n",
      "Ep:294, loss:0.00000, loss_test:0.09902, lr:9.91e-04, fs:0.70807 (r=0.576,p=0.919),  time:18.662, tt:5505.241\n",
      "Ep:295, loss:0.00000, loss_test:0.09902, lr:9.81e-04, fs:0.70807 (r=0.576,p=0.919),  time:18.663, tt:5524.205\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.13758, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:24.396, tt:24.396\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13128, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:28.620, tt:57.240\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.11866, lr:1.00e-02, fs:0.64135 (r=0.768,p=0.551),  time:34.747, tt:104.242\n",
      "Ep:3, loss:0.00047, loss_test:0.11291, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:40.734, tt:162.937\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00045, loss_test:0.11035, lr:1.00e-02, fs:0.67281 (r=0.737,p=0.619),  time:45.384, tt:226.922\n",
      "Ep:5, loss:0.00043, loss_test:0.10519, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:48.613, tt:291.676\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.10246, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:51.260, tt:358.818\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09983, lr:1.00e-02, fs:0.70157 (r=0.677,p=0.728),  time:53.202, tt:425.620\n",
      "Ep:8, loss:0.00036, loss_test:0.09772, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:54.702, tt:492.315\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.09552, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:56.367, tt:563.668\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.09420, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:57.287, tt:630.157\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.09107, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:58.017, tt:696.208\n",
      "Ep:12, loss:0.00030, loss_test:0.09099, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:58.584, tt:761.591\n",
      "Ep:13, loss:0.00028, loss_test:0.09029, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:59.170, tt:828.382\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00027, loss_test:0.09034, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:59.544, tt:893.159\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00026, loss_test:0.08890, lr:1.00e-02, fs:0.75556 (r=0.687,p=0.840),  time:59.958, tt:959.336\n",
      "Ep:16, loss:0.00025, loss_test:0.08871, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:60.232, tt:1023.942\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.08910, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:60.477, tt:1088.588\n",
      "Ep:18, loss:0.00022, loss_test:0.08863, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:60.892, tt:1156.956\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.08843, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:61.183, tt:1223.652\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.08575, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:61.404, tt:1289.484\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00019, loss_test:0.08834, lr:1.00e-02, fs:0.78453 (r=0.717,p=0.866),  time:61.670, tt:1356.740\n",
      "Ep:22, loss:0.00019, loss_test:0.08670, lr:1.00e-02, fs:0.79330 (r=0.717,p=0.887),  time:61.832, tt:1422.146\n",
      "Ep:23, loss:0.00018, loss_test:0.08686, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:62.031, tt:1488.734\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.08932, lr:1.00e-02, fs:0.78613 (r=0.687,p=0.919),  time:62.221, tt:1555.523\n",
      "Ep:25, loss:0.00016, loss_test:0.08838, lr:1.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:62.388, tt:1622.090\n",
      "Ep:26, loss:0.00015, loss_test:0.08866, lr:1.00e-02, fs:0.77907 (r=0.677,p=0.918),  time:62.516, tt:1687.940\n",
      "Ep:27, loss:0.00014, loss_test:0.08652, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:62.750, tt:1756.993\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.08591, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:62.847, tt:1822.566\n",
      "Ep:29, loss:0.00013, loss_test:0.08400, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:62.988, tt:1889.630\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08647, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:63.167, tt:1958.163\n",
      "Ep:31, loss:0.00012, loss_test:0.08531, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:63.315, tt:2026.077\n",
      "Ep:32, loss:0.00011, loss_test:0.08651, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:63.407, tt:2092.428\n",
      "Ep:33, loss:0.00011, loss_test:0.08672, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:63.423, tt:2156.395\n",
      "Ep:34, loss:0.00010, loss_test:0.08880, lr:1.00e-02, fs:0.80682 (r=0.717,p=0.922),  time:63.522, tt:2223.258\n",
      "Ep:35, loss:0.00010, loss_test:0.08384, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:63.592, tt:2289.300\n",
      "Ep:36, loss:0.00009, loss_test:0.08509, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:63.720, tt:2357.643\n",
      "Ep:37, loss:0.00009, loss_test:0.08746, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:63.755, tt:2422.686\n",
      "Ep:38, loss:0.00009, loss_test:0.08802, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:63.844, tt:2489.925\n",
      "Ep:39, loss:0.00008, loss_test:0.08299, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:63.883, tt:2555.319\n",
      "Ep:40, loss:0.00008, loss_test:0.08606, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:63.901, tt:2619.943\n",
      "Ep:41, loss:0.00008, loss_test:0.08541, lr:9.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:63.925, tt:2684.834\n",
      "Ep:42, loss:0.00007, loss_test:0.08270, lr:9.80e-03, fs:0.83978 (r=0.768,p=0.927),  time:63.954, tt:2750.033\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.08410, lr:9.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:64.024, tt:2817.069\n",
      "Ep:44, loss:0.00007, loss_test:0.09054, lr:9.80e-03, fs:0.79070 (r=0.687,p=0.932),  time:64.070, tt:2883.141\n",
      "Ep:45, loss:0.00007, loss_test:0.08420, lr:9.80e-03, fs:0.82955 (r=0.737,p=0.948),  time:64.124, tt:2949.701\n",
      "Ep:46, loss:0.00006, loss_test:0.08571, lr:9.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.178, tt:3016.352\n",
      "Ep:47, loss:0.00006, loss_test:0.09150, lr:9.80e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.163, tt:3079.844\n",
      "Ep:48, loss:0.00006, loss_test:0.08798, lr:9.80e-03, fs:0.79290 (r=0.677,p=0.957),  time:64.242, tt:3147.852\n",
      "Ep:49, loss:0.00006, loss_test:0.08420, lr:9.80e-03, fs:0.80000 (r=0.687,p=0.958),  time:64.274, tt:3213.703\n",
      "Ep:50, loss:0.00006, loss_test:0.08733, lr:9.80e-03, fs:0.83146 (r=0.747,p=0.937),  time:64.287, tt:3278.617\n",
      "Ep:51, loss:0.00005, loss_test:0.09032, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.304, tt:3343.804\n",
      "Ep:52, loss:0.00005, loss_test:0.08394, lr:9.80e-03, fs:0.84444 (r=0.768,p=0.938),  time:64.324, tt:3409.198\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.09089, lr:9.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:64.374, tt:3476.198\n",
      "Ep:54, loss:0.00005, loss_test:0.08657, lr:9.80e-03, fs:0.83616 (r=0.747,p=0.949),  time:64.427, tt:3543.510\n",
      "Ep:55, loss:0.00005, loss_test:0.08974, lr:9.80e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.465, tt:3610.023\n",
      "Ep:56, loss:0.00005, loss_test:0.08896, lr:9.80e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.486, tt:3675.680\n",
      "Ep:57, loss:0.00004, loss_test:0.08856, lr:9.80e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.563, tt:3744.658\n",
      "Ep:58, loss:0.00004, loss_test:0.08901, lr:9.80e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.567, tt:3809.442\n",
      "Ep:59, loss:0.00004, loss_test:0.08895, lr:9.80e-03, fs:0.84270 (r=0.758,p=0.949),  time:64.617, tt:3877.021\n",
      "Ep:60, loss:0.00004, loss_test:0.08814, lr:9.80e-03, fs:0.84916 (r=0.768,p=0.950),  time:64.613, tt:3941.388\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00004, loss_test:0.08710, lr:9.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:64.659, tt:4008.849\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.08997, lr:9.80e-03, fs:0.83429 (r=0.737,p=0.961),  time:64.687, tt:4075.252\n",
      "Ep:63, loss:0.00004, loss_test:0.08993, lr:9.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.711, tt:4141.478\n",
      "Ep:64, loss:0.00003, loss_test:0.09140, lr:9.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.717, tt:4206.580\n",
      "Ep:65, loss:0.00003, loss_test:0.08664, lr:9.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:64.737, tt:4272.619\n",
      "Ep:66, loss:0.00003, loss_test:0.08990, lr:9.80e-03, fs:0.84746 (r=0.758,p=0.962),  time:64.755, tt:4338.591\n",
      "Ep:67, loss:0.00003, loss_test:0.09055, lr:9.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.771, tt:4404.423\n",
      "Ep:68, loss:0.00003, loss_test:0.09035, lr:9.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.771, tt:4469.206\n",
      "Ep:69, loss:0.00003, loss_test:0.08794, lr:9.80e-03, fs:0.80000 (r=0.687,p=0.958),  time:64.808, tt:4536.557\n",
      "Ep:70, loss:0.00003, loss_test:0.09016, lr:9.80e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.798, tt:4600.684\n",
      "Ep:71, loss:0.00003, loss_test:0.09520, lr:9.80e-03, fs:0.75610 (r=0.626,p=0.954),  time:64.799, tt:4665.562\n",
      "Ep:72, loss:0.00003, loss_test:0.08708, lr:9.80e-03, fs:0.84746 (r=0.758,p=0.962),  time:64.803, tt:4730.606\n",
      "Ep:73, loss:0.00003, loss_test:0.09121, lr:9.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.824, tt:4796.992\n",
      "Ep:74, loss:0.00003, loss_test:0.09389, lr:9.61e-03, fs:0.75610 (r=0.626,p=0.954),  time:64.855, tt:4864.103\n",
      "Ep:75, loss:0.00002, loss_test:0.08793, lr:9.51e-03, fs:0.82081 (r=0.717,p=0.959),  time:64.862, tt:4929.518\n",
      "Ep:76, loss:0.00002, loss_test:0.09026, lr:9.41e-03, fs:0.84091 (r=0.747,p=0.961),  time:64.872, tt:4995.112\n",
      "Ep:77, loss:0.00002, loss_test:0.09081, lr:9.32e-03, fs:0.80702 (r=0.697,p=0.958),  time:64.883, tt:5060.860\n",
      "Ep:78, loss:0.00002, loss_test:0.08882, lr:9.23e-03, fs:0.82759 (r=0.727,p=0.960),  time:64.897, tt:5126.895\n",
      "Ep:79, loss:0.00002, loss_test:0.09111, lr:9.14e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.897, tt:5191.795\n",
      "Ep:80, loss:0.00002, loss_test:0.08967, lr:9.04e-03, fs:0.77844 (r=0.657,p=0.956),  time:64.921, tt:5258.575\n",
      "Ep:81, loss:0.00002, loss_test:0.09063, lr:8.95e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.935, tt:5324.660\n",
      "Ep:82, loss:0.00002, loss_test:0.09237, lr:8.86e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.951, tt:5390.915\n",
      "Ep:83, loss:0.00002, loss_test:0.09154, lr:8.78e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.973, tt:5457.701\n",
      "Ep:84, loss:0.00002, loss_test:0.08987, lr:8.69e-03, fs:0.77108 (r=0.646,p=0.955),  time:64.977, tt:5523.075\n",
      "Ep:85, loss:0.00002, loss_test:0.09283, lr:8.60e-03, fs:0.76364 (r=0.636,p=0.955),  time:64.987, tt:5588.905\n",
      "Ep:86, loss:0.00002, loss_test:0.09091, lr:8.51e-03, fs:0.75610 (r=0.626,p=0.954),  time:65.015, tt:5656.265\n",
      "Ep:87, loss:0.00002, loss_test:0.09173, lr:8.43e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.008, tt:5720.676\n",
      "Ep:88, loss:0.00002, loss_test:0.09169, lr:8.35e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.016, tt:5786.422\n",
      "Ep:89, loss:0.00002, loss_test:0.09137, lr:8.26e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.014, tt:5851.292\n",
      "Ep:90, loss:0.00002, loss_test:0.09167, lr:8.18e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.002, tt:5915.155\n",
      "Ep:91, loss:0.00002, loss_test:0.09271, lr:8.10e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.009, tt:5980.843\n",
      "Ep:92, loss:0.00002, loss_test:0.09211, lr:8.02e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.057, tt:6050.322\n",
      "Ep:93, loss:0.00002, loss_test:0.09151, lr:7.94e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.063, tt:6115.953\n",
      "Ep:94, loss:0.00002, loss_test:0.09479, lr:7.86e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.061, tt:6180.769\n",
      "Ep:95, loss:0.00001, loss_test:0.09075, lr:7.78e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.070, tt:6246.757\n",
      "Ep:96, loss:0.00001, loss_test:0.09258, lr:7.70e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.092, tt:6313.905\n",
      "Ep:97, loss:0.00001, loss_test:0.09347, lr:7.62e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.127, tt:6382.423\n",
      "Ep:98, loss:0.00001, loss_test:0.09160, lr:7.55e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.146, tt:6449.473\n",
      "Ep:99, loss:0.00001, loss_test:0.09306, lr:7.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.164, tt:6516.423\n",
      "Ep:100, loss:0.00001, loss_test:0.09200, lr:7.40e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.186, tt:6583.811\n",
      "Ep:101, loss:0.00001, loss_test:0.09363, lr:7.32e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.195, tt:6649.866\n",
      "Ep:102, loss:0.00001, loss_test:0.09254, lr:7.25e-03, fs:0.77108 (r=0.646,p=0.955),  time:65.194, tt:6715.021\n",
      "Ep:103, loss:0.00001, loss_test:0.09314, lr:7.18e-03, fs:0.76364 (r=0.636,p=0.955),  time:65.221, tt:6783.028\n",
      "Ep:104, loss:0.00001, loss_test:0.09333, lr:7.11e-03, fs:0.76829 (r=0.636,p=0.969),  time:65.241, tt:6850.303\n",
      "Ep:105, loss:0.00001, loss_test:0.09295, lr:7.03e-03, fs:0.77576 (r=0.646,p=0.970),  time:65.189, tt:6910.013\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00057, loss_test:0.14108, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:72.143, tt:72.143\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00056, loss_test:0.13622, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:74.990, tt:149.979\n",
      "Ep:2, loss:0.00053, loss_test:0.12401, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:73.306, tt:219.917\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00048, loss_test:0.10752, lr:1.00e-02, fs:0.69792 (r=0.677,p=0.720),  time:75.361, tt:301.444\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00044, loss_test:0.10570, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:76.731, tt:383.657\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00041, loss_test:0.09995, lr:1.00e-02, fs:0.71429 (r=0.657,p=0.783),  time:78.158, tt:468.950\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00038, loss_test:0.09559, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:79.217, tt:554.522\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00035, loss_test:0.09200, lr:1.00e-02, fs:0.75648 (r=0.737,p=0.777),  time:79.813, tt:638.507\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00032, loss_test:0.09058, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:80.075, tt:720.679\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00030, loss_test:0.08423, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:80.347, tt:803.467\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00028, loss_test:0.08531, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:80.576, tt:886.337\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.08127, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:80.770, tt:969.236\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.07962, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:80.845, tt:1050.991\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.07756, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:81.172, tt:1136.403\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.07868, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:81.171, tt:1217.562\n",
      "Ep:15, loss:0.00018, loss_test:0.07061, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:81.411, tt:1302.573\n",
      "Ep:16, loss:0.00017, loss_test:0.07566, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:81.453, tt:1384.696\n",
      "Ep:17, loss:0.00015, loss_test:0.06831, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:81.531, tt:1467.555\n",
      "Ep:18, loss:0.00014, loss_test:0.07468, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:81.549, tt:1549.434\n",
      "Ep:19, loss:0.00013, loss_test:0.07271, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:81.656, tt:1633.115\n",
      "Ep:20, loss:0.00012, loss_test:0.06969, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:81.696, tt:1715.622\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00010, loss_test:0.07062, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:81.794, tt:1799.471\n",
      "Ep:22, loss:0.00009, loss_test:0.07547, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:81.754, tt:1880.339\n",
      "Ep:23, loss:0.00009, loss_test:0.06995, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:81.915, tt:1965.952\n",
      "Ep:24, loss:0.00008, loss_test:0.07176, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:82.030, tt:2050.739\n",
      "Ep:25, loss:0.00007, loss_test:0.07468, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:82.067, tt:2133.734\n",
      "Ep:26, loss:0.00007, loss_test:0.06818, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:82.163, tt:2218.407\n",
      "Ep:27, loss:0.00006, loss_test:0.06749, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:82.281, tt:2303.878\n",
      "Ep:28, loss:0.00006, loss_test:0.07257, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:82.220, tt:2384.372\n",
      "Ep:29, loss:0.00005, loss_test:0.06866, lr:1.00e-02, fs:0.82759 (r=0.727,p=0.960),  time:82.245, tt:2467.352\n",
      "Ep:30, loss:0.00005, loss_test:0.07703, lr:1.00e-02, fs:0.74074 (r=0.606,p=0.952),  time:82.346, tt:2552.716\n",
      "Ep:31, loss:0.00004, loss_test:0.06900, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:82.348, tt:2635.148\n",
      "Ep:32, loss:0.00004, loss_test:0.07431, lr:9.90e-03, fs:0.82081 (r=0.717,p=0.959),  time:82.396, tt:2719.068\n",
      "Ep:33, loss:0.00004, loss_test:0.07268, lr:9.80e-03, fs:0.82759 (r=0.727,p=0.960),  time:82.499, tt:2804.951\n",
      "Ep:34, loss:0.00003, loss_test:0.07430, lr:9.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:82.604, tt:2891.143\n",
      "Ep:35, loss:0.00003, loss_test:0.07982, lr:9.61e-03, fs:0.78571 (r=0.667,p=0.957),  time:82.709, tt:2977.531\n",
      "Ep:36, loss:0.00003, loss_test:0.08213, lr:9.51e-03, fs:0.77576 (r=0.646,p=0.970),  time:82.698, tt:3059.827\n",
      "Ep:37, loss:0.00002, loss_test:0.07884, lr:9.41e-03, fs:0.79290 (r=0.677,p=0.957),  time:82.715, tt:3143.155\n",
      "Ep:38, loss:0.00002, loss_test:0.08082, lr:9.32e-03, fs:0.80473 (r=0.687,p=0.971),  time:82.720, tt:3226.090\n",
      "Ep:39, loss:0.00002, loss_test:0.08588, lr:9.23e-03, fs:0.76829 (r=0.636,p=0.969),  time:82.681, tt:3307.233\n",
      "Ep:40, loss:0.00002, loss_test:0.08378, lr:9.14e-03, fs:0.76074 (r=0.626,p=0.969),  time:82.708, tt:3391.039\n",
      "Ep:41, loss:0.00002, loss_test:0.08349, lr:9.04e-03, fs:0.77576 (r=0.646,p=0.970),  time:82.725, tt:3474.438\n",
      "Ep:42, loss:0.00001, loss_test:0.08572, lr:8.95e-03, fs:0.78313 (r=0.657,p=0.970),  time:82.759, tt:3558.643\n",
      "Ep:43, loss:0.00001, loss_test:0.08454, lr:8.86e-03, fs:0.77576 (r=0.646,p=0.970),  time:82.770, tt:3641.899\n",
      "Ep:44, loss:0.00001, loss_test:0.08623, lr:8.78e-03, fs:0.75309 (r=0.616,p=0.968),  time:82.725, tt:3722.639\n",
      "Ep:45, loss:0.00001, loss_test:0.08486, lr:8.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:82.752, tt:3806.574\n",
      "Ep:46, loss:0.00001, loss_test:0.08714, lr:8.60e-03, fs:0.68831 (r=0.535,p=0.964),  time:82.735, tt:3888.557\n",
      "Ep:47, loss:0.00001, loss_test:0.08824, lr:8.51e-03, fs:0.73750 (r=0.596,p=0.967),  time:82.746, tt:3971.808\n",
      "Ep:48, loss:0.00001, loss_test:0.09032, lr:8.43e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.717, tt:4053.140\n",
      "Ep:49, loss:0.00001, loss_test:0.08739, lr:8.35e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.644, tt:4132.180\n",
      "Ep:50, loss:0.00001, loss_test:0.08934, lr:8.26e-03, fs:0.68831 (r=0.535,p=0.964),  time:82.681, tt:4216.750\n",
      "Ep:51, loss:0.00001, loss_test:0.09060, lr:8.18e-03, fs:0.72956 (r=0.586,p=0.967),  time:82.669, tt:4298.786\n",
      "Ep:52, loss:0.00001, loss_test:0.08966, lr:8.10e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.696, tt:4382.873\n",
      "Ep:53, loss:0.00001, loss_test:0.08916, lr:8.02e-03, fs:0.69677 (r=0.545,p=0.964),  time:82.709, tt:4466.301\n",
      "Ep:54, loss:0.00001, loss_test:0.09465, lr:7.94e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.682, tt:4547.516\n",
      "Ep:55, loss:0.00001, loss_test:0.09121, lr:7.86e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.698, tt:4631.090\n",
      "Ep:56, loss:0.00001, loss_test:0.09077, lr:7.78e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.684, tt:4712.961\n",
      "Ep:57, loss:0.00001, loss_test:0.09354, lr:7.70e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.677, tt:4795.268\n",
      "Ep:58, loss:0.00001, loss_test:0.09250, lr:7.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.706, tt:4879.652\n",
      "Ep:59, loss:0.00000, loss_test:0.09294, lr:7.55e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.758, tt:4965.480\n",
      "Ep:60, loss:0.00000, loss_test:0.09395, lr:7.47e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.797, tt:5050.603\n",
      "Ep:61, loss:0.00000, loss_test:0.09211, lr:7.40e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.790, tt:5133.003\n",
      "Ep:62, loss:0.00000, loss_test:0.09256, lr:7.32e-03, fs:0.69677 (r=0.545,p=0.964),  time:82.794, tt:5216.026\n",
      "Ep:63, loss:0.00000, loss_test:0.09259, lr:7.25e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.808, tt:5299.688\n",
      "Ep:64, loss:0.00000, loss_test:0.09328, lr:7.18e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.823, tt:5383.472\n",
      "Ep:65, loss:0.00000, loss_test:0.09290, lr:7.11e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.770, tt:5462.839\n",
      "Ep:66, loss:0.00000, loss_test:0.09375, lr:7.03e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.772, tt:5545.754\n",
      "Ep:67, loss:0.00000, loss_test:0.09274, lr:6.96e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.800, tt:5630.409\n",
      "Ep:68, loss:0.00000, loss_test:0.09364, lr:6.89e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.809, tt:5713.796\n",
      "Ep:69, loss:0.00000, loss_test:0.09343, lr:6.83e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.801, tt:5796.104\n",
      "Ep:70, loss:0.00000, loss_test:0.09352, lr:6.76e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.839, tt:5881.601\n",
      "Ep:71, loss:0.00000, loss_test:0.09438, lr:6.69e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.834, tt:5964.064\n",
      "Ep:72, loss:0.00000, loss_test:0.09281, lr:6.62e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.792, tt:6043.812\n",
      "Ep:73, loss:0.00000, loss_test:0.09392, lr:6.56e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.796, tt:6126.883\n",
      "Ep:74, loss:0.00000, loss_test:0.09348, lr:6.49e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.812, tt:6210.886\n",
      "Ep:75, loss:0.00000, loss_test:0.09373, lr:6.43e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.804, tt:6293.093\n",
      "Ep:76, loss:0.00000, loss_test:0.09423, lr:6.36e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.772, tt:6373.446\n",
      "Ep:77, loss:0.00000, loss_test:0.09371, lr:6.30e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.735, tt:6453.349\n",
      "Ep:78, loss:0.00000, loss_test:0.09336, lr:6.24e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.773, tt:6539.048\n",
      "Ep:79, loss:0.00000, loss_test:0.09373, lr:6.17e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.852, tt:6628.133\n",
      "Ep:80, loss:0.00000, loss_test:0.09412, lr:6.11e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.863, tt:6711.935\n",
      "Ep:81, loss:0.00000, loss_test:0.09372, lr:6.05e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.875, tt:6795.759\n",
      "Ep:82, loss:0.00000, loss_test:0.09425, lr:5.99e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.859, tt:6877.338\n",
      "Ep:83, loss:0.00000, loss_test:0.09354, lr:5.93e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.857, tt:6959.952\n",
      "Ep:84, loss:0.00000, loss_test:0.09497, lr:5.87e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.861, tt:7043.193\n",
      "Ep:85, loss:0.00000, loss_test:0.09406, lr:5.81e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.881, tt:7127.730\n",
      "Ep:86, loss:0.00000, loss_test:0.09376, lr:5.75e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.899, tt:7212.173\n",
      "Ep:87, loss:0.00000, loss_test:0.09502, lr:5.70e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.906, tt:7295.736\n",
      "Ep:88, loss:0.00000, loss_test:0.09433, lr:5.64e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.919, tt:7379.754\n",
      "Ep:89, loss:0.00000, loss_test:0.09466, lr:5.58e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.963, tt:7466.673\n",
      "Ep:90, loss:0.00000, loss_test:0.09431, lr:5.53e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.924, tt:7546.128\n",
      "Ep:91, loss:0.00000, loss_test:0.09545, lr:5.47e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.926, tt:7629.236\n",
      "Ep:92, loss:0.00000, loss_test:0.09512, lr:5.42e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.898, tt:7709.556\n",
      "Ep:93, loss:0.00000, loss_test:0.09461, lr:5.36e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.884, tt:7791.051\n",
      "Ep:94, loss:0.00000, loss_test:0.09620, lr:5.31e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.874, tt:7873.039\n",
      "Ep:95, loss:0.00000, loss_test:0.09477, lr:5.26e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.850, tt:7953.634\n",
      "Ep:96, loss:0.00000, loss_test:0.09476, lr:5.20e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.851, tt:8036.526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00000, loss_test:0.09533, lr:5.15e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.853, tt:8119.610\n",
      "Ep:98, loss:0.00000, loss_test:0.09619, lr:5.10e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.838, tt:8200.988\n",
      "Ep:99, loss:0.00000, loss_test:0.09598, lr:5.05e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.835, tt:8283.495\n",
      "Ep:100, loss:0.00000, loss_test:0.09668, lr:5.00e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.829, tt:8365.779\n",
      "Ep:101, loss:0.00000, loss_test:0.09684, lr:4.95e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.834, tt:8449.078\n",
      "Ep:102, loss:0.00000, loss_test:0.09633, lr:4.90e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.800, tt:8528.442\n",
      "Ep:103, loss:0.00000, loss_test:0.09735, lr:4.85e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.793, tt:8610.436\n",
      "Ep:104, loss:0.00000, loss_test:0.09624, lr:4.80e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.770, tt:8690.833\n",
      "Ep:105, loss:0.00000, loss_test:0.09730, lr:4.75e-03, fs:0.67974 (r=0.525,p=0.963),  time:82.730, tt:8769.365\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13214, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:66.920, tt:66.920\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.12395, lr:1.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:68.303, tt:136.606\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00051, loss_test:0.12053, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:65.571, tt:196.714\n",
      "Ep:3, loss:0.00048, loss_test:0.11801, lr:1.00e-02, fs:0.64069 (r=0.747,p=0.561),  time:67.380, tt:269.519\n",
      "Ep:4, loss:0.00046, loss_test:0.11298, lr:1.00e-02, fs:0.65236 (r=0.768,p=0.567),  time:68.624, tt:343.119\n",
      "Ep:5, loss:0.00043, loss_test:0.10773, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:69.331, tt:415.985\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00041, loss_test:0.10145, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:70.151, tt:491.058\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00038, loss_test:0.09768, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:70.648, tt:565.187\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00036, loss_test:0.09291, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:71.084, tt:639.753\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00034, loss_test:0.09061, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:71.320, tt:713.202\n",
      "Ep:10, loss:0.00033, loss_test:0.08914, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:71.606, tt:787.662\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00031, loss_test:0.08912, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:71.867, tt:862.407\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00030, loss_test:0.08696, lr:1.00e-02, fs:0.76842 (r=0.737,p=0.802),  time:72.161, tt:938.092\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00028, loss_test:0.08591, lr:1.00e-02, fs:0.74872 (r=0.737,p=0.760),  time:72.334, tt:1012.670\n",
      "Ep:14, loss:0.00027, loss_test:0.08501, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:72.434, tt:1086.516\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00025, loss_test:0.08357, lr:1.00e-02, fs:0.77660 (r=0.737,p=0.820),  time:72.624, tt:1161.977\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00024, loss_test:0.08446, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:72.751, tt:1236.769\n",
      "Ep:17, loss:0.00023, loss_test:0.08331, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:72.778, tt:1309.998\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.07880, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:72.938, tt:1385.815\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00020, loss_test:0.07629, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:73.052, tt:1461.040\n",
      "Ep:20, loss:0.00019, loss_test:0.07518, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:73.078, tt:1534.647\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.07541, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:73.087, tt:1607.923\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00016, loss_test:0.07335, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:73.009, tt:1679.206\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.07237, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:72.991, tt:1751.782\n",
      "Ep:24, loss:0.00015, loss_test:0.07374, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:73.106, tt:1827.645\n",
      "Ep:25, loss:0.00014, loss_test:0.07218, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:73.111, tt:1900.884\n",
      "Ep:26, loss:0.00013, loss_test:0.06961, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:73.177, tt:1975.788\n",
      "Ep:27, loss:0.00012, loss_test:0.06965, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:73.143, tt:2048.008\n",
      "Ep:28, loss:0.00012, loss_test:0.07137, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:73.179, tt:2122.188\n",
      "Ep:29, loss:0.00011, loss_test:0.06787, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:73.194, tt:2195.819\n",
      "Ep:30, loss:0.00010, loss_test:0.06764, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:73.288, tt:2271.919\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.06730, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:73.314, tt:2346.050\n",
      "Ep:32, loss:0.00009, loss_test:0.06806, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:73.360, tt:2420.869\n",
      "Ep:33, loss:0.00008, loss_test:0.06681, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:73.360, tt:2494.236\n",
      "Ep:34, loss:0.00008, loss_test:0.06690, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:73.427, tt:2569.927\n",
      "Ep:35, loss:0.00007, loss_test:0.06663, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:73.404, tt:2642.560\n",
      "Ep:36, loss:0.00007, loss_test:0.07066, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:73.521, tt:2720.294\n",
      "Ep:37, loss:0.00007, loss_test:0.06980, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:73.556, tt:2795.138\n",
      "Ep:38, loss:0.00007, loss_test:0.06652, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:73.564, tt:2868.989\n",
      "Ep:39, loss:0.00006, loss_test:0.06823, lr:1.00e-02, fs:0.79070 (r=0.687,p=0.932),  time:73.540, tt:2941.596\n",
      "Ep:40, loss:0.00006, loss_test:0.06939, lr:1.00e-02, fs:0.79769 (r=0.697,p=0.932),  time:73.577, tt:3016.654\n",
      "Ep:41, loss:0.00006, loss_test:0.06866, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:73.607, tt:3091.489\n",
      "Ep:42, loss:0.00005, loss_test:0.06486, lr:9.90e-03, fs:0.78857 (r=0.697,p=0.908),  time:73.653, tt:3167.060\n",
      "Ep:43, loss:0.00005, loss_test:0.06374, lr:9.80e-03, fs:0.79769 (r=0.697,p=0.932),  time:73.640, tt:3240.140\n",
      "Ep:44, loss:0.00005, loss_test:0.06765, lr:9.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:73.693, tt:3316.199\n",
      "Ep:45, loss:0.00005, loss_test:0.07158, lr:9.61e-03, fs:0.78857 (r=0.697,p=0.908),  time:73.688, tt:3389.642\n",
      "Ep:46, loss:0.00004, loss_test:0.06965, lr:9.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:73.716, tt:3464.641\n",
      "Ep:47, loss:0.00004, loss_test:0.06814, lr:9.41e-03, fs:0.79310 (r=0.697,p=0.920),  time:73.792, tt:3542.040\n",
      "Ep:48, loss:0.00004, loss_test:0.06969, lr:9.32e-03, fs:0.79310 (r=0.697,p=0.920),  time:73.841, tt:3618.195\n",
      "Ep:49, loss:0.00004, loss_test:0.06976, lr:9.23e-03, fs:0.78857 (r=0.697,p=0.908),  time:73.941, tt:3697.047\n",
      "Ep:50, loss:0.00004, loss_test:0.06548, lr:9.14e-03, fs:0.79769 (r=0.697,p=0.932),  time:73.969, tt:3772.417\n",
      "Ep:51, loss:0.00004, loss_test:0.06497, lr:9.04e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.003, tt:3848.138\n",
      "Ep:52, loss:0.00004, loss_test:0.06653, lr:8.95e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.059, tt:3925.117\n",
      "Ep:53, loss:0.00003, loss_test:0.06771, lr:8.86e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.064, tt:3999.455\n",
      "Ep:54, loss:0.00003, loss_test:0.06468, lr:8.78e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.114, tt:4076.262\n",
      "Ep:55, loss:0.00003, loss_test:0.06403, lr:8.69e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.166, tt:4153.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00003, loss_test:0.06887, lr:8.60e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.150, tt:4226.556\n",
      "Ep:57, loss:0.00003, loss_test:0.06913, lr:8.51e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.191, tt:4303.098\n",
      "Ep:58, loss:0.00003, loss_test:0.06434, lr:8.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.175, tt:4376.349\n",
      "Ep:59, loss:0.00003, loss_test:0.06562, lr:8.35e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.161, tt:4449.632\n",
      "Ep:60, loss:0.00003, loss_test:0.06983, lr:8.26e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.150, tt:4523.124\n",
      "Ep:61, loss:0.00003, loss_test:0.07017, lr:8.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.116, tt:4595.190\n",
      "Ep:62, loss:0.00003, loss_test:0.06855, lr:8.10e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.109, tt:4668.869\n",
      "Ep:63, loss:0.00003, loss_test:0.06944, lr:8.02e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.117, tt:4743.476\n",
      "Ep:64, loss:0.00003, loss_test:0.07290, lr:7.94e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.133, tt:4818.642\n",
      "Ep:65, loss:0.00003, loss_test:0.07247, lr:7.86e-03, fs:0.79310 (r=0.697,p=0.920),  time:74.129, tt:4892.505\n",
      "Ep:66, loss:0.00002, loss_test:0.07314, lr:7.78e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.151, tt:4968.124\n",
      "Ep:67, loss:0.00002, loss_test:0.07386, lr:7.70e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.155, tt:5042.564\n",
      "Ep:68, loss:0.00002, loss_test:0.07215, lr:7.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.215, tt:5120.851\n",
      "Ep:69, loss:0.00002, loss_test:0.06978, lr:7.55e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.205, tt:5194.363\n",
      "Ep:70, loss:0.00002, loss_test:0.06989, lr:7.47e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.242, tt:5271.157\n",
      "Ep:71, loss:0.00002, loss_test:0.07101, lr:7.40e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.238, tt:5345.126\n",
      "Ep:72, loss:0.00002, loss_test:0.07080, lr:7.32e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.259, tt:5420.873\n",
      "Ep:73, loss:0.00002, loss_test:0.07126, lr:7.25e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.267, tt:5495.776\n",
      "Ep:74, loss:0.00002, loss_test:0.07339, lr:7.18e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.280, tt:5570.987\n",
      "Ep:75, loss:0.00002, loss_test:0.07218, lr:7.11e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.322, tt:5648.435\n",
      "Ep:76, loss:0.00002, loss_test:0.07221, lr:7.03e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.371, tt:5726.582\n",
      "Ep:77, loss:0.00002, loss_test:0.07386, lr:6.96e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.394, tt:5802.746\n",
      "Ep:78, loss:0.00002, loss_test:0.07449, lr:6.89e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.406, tt:5878.085\n",
      "Ep:79, loss:0.00002, loss_test:0.07320, lr:6.83e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.444, tt:5955.543\n",
      "Ep:80, loss:0.00002, loss_test:0.07506, lr:6.76e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.454, tt:6030.750\n",
      "Ep:81, loss:0.00002, loss_test:0.07718, lr:6.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.460, tt:6105.749\n",
      "Ep:82, loss:0.00002, loss_test:0.07517, lr:6.62e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.466, tt:6180.691\n",
      "Ep:83, loss:0.00002, loss_test:0.07574, lr:6.56e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.474, tt:6255.798\n",
      "Ep:84, loss:0.00002, loss_test:0.07756, lr:6.49e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.481, tt:6330.894\n",
      "Ep:85, loss:0.00002, loss_test:0.07575, lr:6.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:74.505, tt:6407.441\n",
      "Ep:86, loss:0.00002, loss_test:0.07446, lr:6.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.499, tt:6481.417\n",
      "Ep:87, loss:0.00002, loss_test:0.07427, lr:6.30e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.488, tt:6554.985\n",
      "Ep:88, loss:0.00002, loss_test:0.07379, lr:6.24e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.501, tt:6630.576\n",
      "Ep:89, loss:0.00002, loss_test:0.07453, lr:6.17e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.542, tt:6708.736\n",
      "Ep:90, loss:0.00002, loss_test:0.07463, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.554, tt:6784.399\n",
      "Ep:91, loss:0.00002, loss_test:0.07522, lr:6.05e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.575, tt:6860.927\n",
      "Ep:92, loss:0.00001, loss_test:0.07398, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.589, tt:6936.810\n",
      "Ep:93, loss:0.00001, loss_test:0.07518, lr:5.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.612, tt:7013.546\n",
      "Ep:94, loss:0.00001, loss_test:0.07498, lr:5.87e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.571, tt:7084.266\n",
      "Ep:95, loss:0.00001, loss_test:0.07438, lr:5.81e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.599, tt:7161.497\n",
      "Ep:96, loss:0.00001, loss_test:0.07444, lr:5.75e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.604, tt:7236.597\n",
      "Ep:97, loss:0.00001, loss_test:0.07555, lr:5.70e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.606, tt:7311.347\n",
      "Ep:98, loss:0.00001, loss_test:0.07605, lr:5.64e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.611, tt:7386.521\n",
      "Ep:99, loss:0.00001, loss_test:0.07573, lr:5.58e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.641, tt:7464.052\n",
      "Ep:100, loss:0.00001, loss_test:0.07545, lr:5.53e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.665, tt:7541.127\n",
      "Ep:101, loss:0.00001, loss_test:0.07642, lr:5.47e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.662, tt:7615.559\n",
      "Ep:102, loss:0.00001, loss_test:0.07712, lr:5.42e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.660, tt:7689.937\n",
      "Ep:103, loss:0.00001, loss_test:0.07620, lr:5.36e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.665, tt:7765.160\n",
      "Ep:104, loss:0.00001, loss_test:0.07534, lr:5.31e-03, fs:0.80233 (r=0.697,p=0.945),  time:74.608, tt:7833.816\n",
      "Ep:105, loss:0.00001, loss_test:0.07514, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:74.410, tt:7887.415\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"3-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02362, lr:6.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:12.449, tt:12.449\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02270, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:14.666, tt:29.332\n",
      "Ep:2, loss:0.00005, loss_test:0.02605, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:17.777, tt:53.332\n",
      "Ep:3, loss:0.00005, loss_test:0.02688, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.192, tt:80.769\n",
      "Ep:4, loss:0.00005, loss_test:0.02608, lr:6.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:22.601, tt:113.005\n",
      "Ep:5, loss:0.00005, loss_test:0.02490, lr:6.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:24.596, tt:147.578\n",
      "Ep:6, loss:0.00005, loss_test:0.02402, lr:6.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:25.934, tt:181.536\n",
      "Ep:7, loss:0.00005, loss_test:0.02338, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:26.744, tt:213.952\n",
      "Ep:8, loss:0.00005, loss_test:0.02281, lr:6.00e-02, fs:0.66920 (r=0.889,p=0.537),  time:27.620, tt:248.581\n",
      "Ep:9, loss:0.00005, loss_test:0.02218, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:28.213, tt:282.130\n",
      "Ep:10, loss:0.00005, loss_test:0.02171, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:28.579, tt:314.374\n",
      "Ep:11, loss:0.00005, loss_test:0.02141, lr:6.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:29.095, tt:349.134\n",
      "Ep:12, loss:0.00005, loss_test:0.02087, lr:5.94e-02, fs:0.67647 (r=0.929,p=0.532),  time:29.490, tt:383.371\n",
      "Ep:13, loss:0.00005, loss_test:0.02002, lr:5.88e-02, fs:0.66667 (r=0.889,p=0.533),  time:29.931, tt:419.027\n",
      "Ep:14, loss:0.00004, loss_test:0.01925, lr:5.82e-02, fs:0.67954 (r=0.889,p=0.550),  time:30.236, tt:453.536\n",
      "Ep:15, loss:0.00004, loss_test:0.01875, lr:5.76e-02, fs:0.69261 (r=0.899,p=0.563),  time:30.482, tt:487.714\n",
      "Ep:16, loss:0.00004, loss_test:0.01842, lr:5.71e-02, fs:0.69962 (r=0.929,p=0.561),  time:30.705, tt:521.990\n",
      "Ep:17, loss:0.00004, loss_test:0.01819, lr:5.65e-02, fs:0.69434 (r=0.929,p=0.554),  time:30.998, tt:557.970\n",
      "Ep:18, loss:0.00004, loss_test:0.01782, lr:5.59e-02, fs:0.70229 (r=0.929,p=0.564),  time:31.193, tt:592.662\n",
      "Ep:19, loss:0.00004, loss_test:0.01748, lr:5.54e-02, fs:0.71042 (r=0.929,p=0.575),  time:31.355, tt:627.108\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01714, lr:5.54e-02, fs:0.72441 (r=0.929,p=0.594),  time:31.531, tt:662.161\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01689, lr:5.54e-02, fs:0.72656 (r=0.939,p=0.592),  time:31.675, tt:696.845\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00004, loss_test:0.01656, lr:5.54e-02, fs:0.72157 (r=0.929,p=0.590),  time:31.802, tt:731.438\n",
      "Ep:23, loss:0.00004, loss_test:0.01618, lr:5.54e-02, fs:0.72441 (r=0.929,p=0.594),  time:31.897, tt:765.532\n",
      "Ep:24, loss:0.00004, loss_test:0.01586, lr:5.54e-02, fs:0.72374 (r=0.939,p=0.589),  time:32.038, tt:800.957\n",
      "Ep:25, loss:0.00004, loss_test:0.01556, lr:5.54e-02, fs:0.72093 (r=0.939,p=0.585),  time:32.127, tt:835.301\n",
      "Ep:26, loss:0.00003, loss_test:0.01525, lr:5.54e-02, fs:0.73725 (r=0.949,p=0.603),  time:32.244, tt:870.579\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01503, lr:5.54e-02, fs:0.76113 (r=0.949,p=0.635),  time:32.360, tt:906.078\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01492, lr:5.54e-02, fs:0.76000 (r=0.960,p=0.629),  time:32.489, tt:942.169\n",
      "Ep:29, loss:0.00003, loss_test:0.01487, lr:5.54e-02, fs:0.75000 (r=0.939,p=0.624),  time:32.547, tt:976.412\n",
      "Ep:30, loss:0.00003, loss_test:0.01481, lr:5.54e-02, fs:0.74897 (r=0.919,p=0.632),  time:32.639, tt:1011.793\n",
      "Ep:31, loss:0.00003, loss_test:0.01487, lr:5.54e-02, fs:0.72881 (r=0.869,p=0.628),  time:32.678, tt:1045.686\n",
      "Ep:32, loss:0.00003, loss_test:0.01496, lr:5.54e-02, fs:0.74138 (r=0.869,p=0.647),  time:32.777, tt:1081.629\n",
      "Ep:33, loss:0.00003, loss_test:0.01492, lr:5.54e-02, fs:0.75000 (r=0.879,p=0.654),  time:32.808, tt:1115.481\n",
      "Ep:34, loss:0.00003, loss_test:0.01493, lr:5.54e-02, fs:0.75771 (r=0.869,p=0.672),  time:32.876, tt:1150.646\n",
      "Ep:35, loss:0.00003, loss_test:0.01500, lr:5.54e-02, fs:0.76106 (r=0.869,p=0.677),  time:32.939, tt:1185.812\n",
      "Ep:36, loss:0.00003, loss_test:0.01508, lr:5.54e-02, fs:0.75439 (r=0.869,p=0.667),  time:32.985, tt:1220.460\n",
      "Ep:37, loss:0.00003, loss_test:0.01510, lr:5.54e-02, fs:0.76444 (r=0.869,p=0.683),  time:33.056, tt:1256.126\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01522, lr:5.54e-02, fs:0.76106 (r=0.869,p=0.677),  time:33.125, tt:1291.864\n",
      "Ep:39, loss:0.00002, loss_test:0.01521, lr:5.54e-02, fs:0.75771 (r=0.869,p=0.672),  time:33.201, tt:1328.045\n",
      "Ep:40, loss:0.00002, loss_test:0.01513, lr:5.54e-02, fs:0.76444 (r=0.869,p=0.683),  time:33.270, tt:1364.054\n",
      "Ep:41, loss:0.00002, loss_test:0.01511, lr:5.54e-02, fs:0.76652 (r=0.879,p=0.680),  time:33.345, tt:1400.504\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01498, lr:5.54e-02, fs:0.77729 (r=0.899,p=0.685),  time:33.373, tt:1435.040\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01502, lr:5.54e-02, fs:0.79295 (r=0.909,p=0.703),  time:33.427, tt:1470.776\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01503, lr:5.54e-02, fs:0.80357 (r=0.909,p=0.720),  time:33.445, tt:1505.044\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01500, lr:5.54e-02, fs:0.80717 (r=0.909,p=0.726),  time:33.483, tt:1540.211\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01525, lr:5.54e-02, fs:0.81250 (r=0.919,p=0.728),  time:33.521, tt:1575.489\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01546, lr:5.54e-02, fs:0.81614 (r=0.919,p=0.734),  time:33.547, tt:1610.275\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01538, lr:5.54e-02, fs:0.82727 (r=0.919,p=0.752),  time:33.568, tt:1644.849\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01555, lr:5.54e-02, fs:0.81818 (r=0.909,p=0.744),  time:33.590, tt:1679.519\n",
      "Ep:50, loss:0.00002, loss_test:0.01555, lr:5.54e-02, fs:0.82028 (r=0.899,p=0.754),  time:33.597, tt:1713.439\n",
      "Ep:51, loss:0.00002, loss_test:0.01561, lr:5.54e-02, fs:0.82192 (r=0.909,p=0.750),  time:33.608, tt:1747.631\n",
      "Ep:52, loss:0.00002, loss_test:0.01573, lr:5.54e-02, fs:0.81860 (r=0.889,p=0.759),  time:33.648, tt:1783.346\n",
      "Ep:53, loss:0.00002, loss_test:0.01586, lr:5.54e-02, fs:0.82243 (r=0.889,p=0.765),  time:33.653, tt:1817.237\n",
      "Ep:54, loss:0.00002, loss_test:0.01571, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.684, tt:1852.602\n",
      "Ep:55, loss:0.00001, loss_test:0.01662, lr:5.54e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.731, tt:1888.954\n",
      "Ep:56, loss:0.00001, loss_test:0.01601, lr:5.54e-02, fs:0.80769 (r=0.848,p=0.771),  time:33.752, tt:1923.850\n",
      "Ep:57, loss:0.00001, loss_test:0.01680, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.755, tt:1957.793\n",
      "Ep:58, loss:0.00001, loss_test:0.01636, lr:5.54e-02, fs:0.81905 (r=0.869,p=0.775),  time:33.782, tt:1993.150\n",
      "Ep:59, loss:0.00001, loss_test:0.01679, lr:5.54e-02, fs:0.80769 (r=0.848,p=0.771),  time:33.799, tt:2027.912\n",
      "Ep:60, loss:0.00001, loss_test:0.01709, lr:5.48e-02, fs:0.79808 (r=0.838,p=0.761),  time:33.817, tt:2062.814\n",
      "Ep:61, loss:0.00001, loss_test:0.01694, lr:5.43e-02, fs:0.80788 (r=0.828,p=0.788),  time:33.814, tt:2096.474\n",
      "Ep:62, loss:0.00001, loss_test:0.01693, lr:5.37e-02, fs:0.82178 (r=0.838,p=0.806),  time:33.836, tt:2131.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00001, loss_test:0.01745, lr:5.32e-02, fs:0.80597 (r=0.818,p=0.794),  time:33.859, tt:2166.979\n",
      "Ep:64, loss:0.00001, loss_test:0.01744, lr:5.27e-02, fs:0.80829 (r=0.788,p=0.830),  time:33.880, tt:2202.228\n",
      "Ep:65, loss:0.00001, loss_test:0.01723, lr:5.21e-02, fs:0.82653 (r=0.818,p=0.835),  time:33.895, tt:2237.068\n",
      "Ep:66, loss:0.00001, loss_test:0.01768, lr:5.16e-02, fs:0.81000 (r=0.818,p=0.802),  time:33.922, tt:2272.802\n",
      "Ep:67, loss:0.00001, loss_test:0.01734, lr:5.11e-02, fs:0.83077 (r=0.818,p=0.844),  time:33.957, tt:2309.055\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01768, lr:5.11e-02, fs:0.83505 (r=0.818,p=0.853),  time:33.987, tt:2345.121\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01791, lr:5.11e-02, fs:0.81407 (r=0.818,p=0.810),  time:34.004, tt:2380.280\n",
      "Ep:70, loss:0.00001, loss_test:0.01798, lr:5.11e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.027, tt:2415.944\n",
      "Ep:71, loss:0.00001, loss_test:0.01788, lr:5.11e-02, fs:0.83938 (r=0.818,p=0.862),  time:34.068, tt:2452.864\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01844, lr:5.11e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.102, tt:2489.451\n",
      "Ep:73, loss:0.00001, loss_test:0.01778, lr:5.11e-02, fs:0.83938 (r=0.818,p=0.862),  time:34.142, tt:2526.510\n",
      "Ep:74, loss:0.00001, loss_test:0.01834, lr:5.11e-02, fs:0.83077 (r=0.818,p=0.844),  time:34.147, tt:2561.018\n",
      "Ep:75, loss:0.00001, loss_test:0.01836, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.161, tt:2596.235\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01778, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.168, tt:2630.909\n",
      "Ep:77, loss:0.00001, loss_test:0.01893, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.171, tt:2665.363\n",
      "Ep:78, loss:0.00001, loss_test:0.01835, lr:5.11e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.194, tt:2701.331\n",
      "Ep:79, loss:0.00001, loss_test:0.01806, lr:5.11e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.202, tt:2736.155\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01852, lr:5.11e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.216, tt:2771.460\n",
      "Ep:81, loss:0.00001, loss_test:0.01794, lr:5.11e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.221, tt:2806.136\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01839, lr:5.11e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.250, tt:2842.715\n",
      "Ep:83, loss:0.00001, loss_test:0.01785, lr:5.11e-02, fs:0.84375 (r=0.818,p=0.871),  time:34.274, tt:2878.994\n",
      "Ep:84, loss:0.00001, loss_test:0.01797, lr:5.11e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.275, tt:2913.395\n",
      "Ep:85, loss:0.00001, loss_test:0.01924, lr:5.11e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.305, tt:2950.218\n",
      "Ep:86, loss:0.00001, loss_test:0.01792, lr:5.11e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.307, tt:2984.722\n",
      "Ep:87, loss:0.00001, loss_test:0.01794, lr:5.11e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.301, tt:3018.451\n",
      "Ep:88, loss:0.00001, loss_test:0.01899, lr:5.11e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.311, tt:3053.651\n",
      "Ep:89, loss:0.00001, loss_test:0.01874, lr:5.11e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.322, tt:3088.967\n",
      "Ep:90, loss:0.00001, loss_test:0.01845, lr:5.11e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.328, tt:3123.868\n",
      "Ep:91, loss:0.00000, loss_test:0.01899, lr:5.11e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.333, tt:3158.619\n",
      "Ep:92, loss:0.00000, loss_test:0.01912, lr:5.11e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.331, tt:3192.777\n",
      "Ep:93, loss:0.00000, loss_test:0.01900, lr:5.06e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.370, tt:3230.773\n",
      "Ep:94, loss:0.00000, loss_test:0.01948, lr:5.01e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.382, tt:3266.315\n",
      "Ep:95, loss:0.00000, loss_test:0.01947, lr:4.96e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.397, tt:3302.092\n",
      "Ep:96, loss:0.00000, loss_test:0.01920, lr:4.91e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.407, tt:3337.448\n",
      "Ep:97, loss:0.00000, loss_test:0.01959, lr:4.86e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.412, tt:3372.371\n",
      "Ep:98, loss:0.00000, loss_test:0.01945, lr:4.81e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.411, tt:3406.721\n",
      "Ep:99, loss:0.00000, loss_test:0.01935, lr:4.76e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.422, tt:3442.224\n",
      "Ep:100, loss:0.00000, loss_test:0.01967, lr:4.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.436, tt:3478.079\n",
      "Ep:101, loss:0.00000, loss_test:0.01968, lr:4.67e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.447, tt:3513.629\n",
      "Ep:102, loss:0.00000, loss_test:0.02026, lr:4.62e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.457, tt:3549.102\n",
      "Ep:103, loss:0.00000, loss_test:0.02038, lr:4.57e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.459, tt:3583.758\n",
      "Ep:104, loss:0.00000, loss_test:0.01964, lr:4.53e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.466, tt:3618.932\n",
      "Ep:105, loss:0.00000, loss_test:0.02043, lr:4.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.479, tt:3654.740\n",
      "Ep:106, loss:0.00000, loss_test:0.02074, lr:4.44e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.488, tt:3690.262\n",
      "Ep:107, loss:0.00000, loss_test:0.02044, lr:4.39e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.495, tt:3725.482\n",
      "Ep:108, loss:0.00000, loss_test:0.02019, lr:4.35e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.506, tt:3761.123\n",
      "Ep:109, loss:0.00000, loss_test:0.02109, lr:4.31e-02, fs:0.82873 (r=0.758,p=0.915),  time:34.502, tt:3795.176\n",
      "Ep:110, loss:0.00000, loss_test:0.02008, lr:4.26e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.508, tt:3830.419\n",
      "Ep:111, loss:0.00000, loss_test:0.02092, lr:4.22e-02, fs:0.81768 (r=0.747,p=0.902),  time:34.506, tt:3864.724\n",
      "Ep:112, loss:0.00000, loss_test:0.02095, lr:4.18e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.532, tt:3902.065\n",
      "Ep:113, loss:0.00000, loss_test:0.02049, lr:4.14e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.537, tt:3937.259\n",
      "Ep:114, loss:0.00000, loss_test:0.02144, lr:4.10e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.545, tt:3972.638\n",
      "Ep:115, loss:0.00000, loss_test:0.02115, lr:4.05e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.537, tt:4006.248\n",
      "Ep:116, loss:0.00000, loss_test:0.02103, lr:4.01e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.538, tt:4040.913\n",
      "Ep:117, loss:0.00000, loss_test:0.02165, lr:3.97e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.539, tt:4075.647\n",
      "Ep:118, loss:0.00000, loss_test:0.02121, lr:3.93e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.544, tt:4110.756\n",
      "Ep:119, loss:0.00000, loss_test:0.02174, lr:3.89e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.558, tt:4147.005\n",
      "Ep:120, loss:0.00000, loss_test:0.02205, lr:3.86e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.554, tt:4181.058\n",
      "Ep:121, loss:0.00000, loss_test:0.02120, lr:3.82e-02, fs:0.81564 (r=0.737,p=0.912),  time:34.551, tt:4215.230\n",
      "Ep:122, loss:0.00000, loss_test:0.02235, lr:3.78e-02, fs:0.80899 (r=0.727,p=0.911),  time:34.556, tt:4250.362\n",
      "Ep:123, loss:0.00000, loss_test:0.02121, lr:3.74e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.554, tt:4284.659\n",
      "Ep:124, loss:0.00000, loss_test:0.02173, lr:3.70e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.558, tt:4319.779\n",
      "Ep:125, loss:0.00000, loss_test:0.02206, lr:3.67e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.559, tt:4354.458\n",
      "Ep:126, loss:0.00000, loss_test:0.02189, lr:3.63e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.568, tt:4390.183\n",
      "Ep:127, loss:0.00000, loss_test:0.02236, lr:3.59e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.568, tt:4424.651\n",
      "Ep:128, loss:0.00000, loss_test:0.02237, lr:3.56e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.580, tt:4460.804\n",
      "Ep:129, loss:0.00000, loss_test:0.02250, lr:3.52e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.584, tt:4495.861\n",
      "Ep:130, loss:0.00000, loss_test:0.02259, lr:3.49e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.597, tt:4532.271\n",
      "Ep:131, loss:0.00000, loss_test:0.02249, lr:3.45e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.594, tt:4566.431\n",
      "Ep:132, loss:0.00000, loss_test:0.02294, lr:3.42e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.625, tt:4605.140\n",
      "Ep:133, loss:0.00000, loss_test:0.02265, lr:3.38e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.625, tt:4639.813\n",
      "Ep:134, loss:0.00000, loss_test:0.02269, lr:3.35e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.628, tt:4674.764\n",
      "Ep:135, loss:0.00000, loss_test:0.02336, lr:3.32e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.634, tt:4710.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02291, lr:3.28e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.631, tt:4744.505\n",
      "Ep:137, loss:0.00000, loss_test:0.02311, lr:3.25e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.636, tt:4779.741\n",
      "Ep:138, loss:0.00000, loss_test:0.02296, lr:3.22e-02, fs:0.82682 (r=0.747,p=0.925),  time:34.644, tt:4815.453\n",
      "Ep:139, loss:0.00000, loss_test:0.02312, lr:3.19e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.648, tt:4850.686\n",
      "Ep:140, loss:0.00000, loss_test:0.02326, lr:3.15e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.649, tt:4885.445\n",
      "Ep:141, loss:0.00000, loss_test:0.02331, lr:3.12e-02, fs:0.82022 (r=0.737,p=0.924),  time:34.646, tt:4919.772\n",
      "Ep:142, loss:0.00000, loss_test:0.02352, lr:3.09e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.644, tt:4954.064\n",
      "Ep:143, loss:0.00000, loss_test:0.02341, lr:3.06e-02, fs:0.82486 (r=0.737,p=0.936),  time:34.635, tt:4987.411\n",
      "Ep:144, loss:0.00000, loss_test:0.02381, lr:3.03e-02, fs:0.80000 (r=0.707,p=0.921),  time:34.649, tt:5024.136\n",
      "Ep:145, loss:0.00000, loss_test:0.02367, lr:3.00e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.653, tt:5059.380\n",
      "Ep:146, loss:0.00000, loss_test:0.02359, lr:2.97e-02, fs:0.81356 (r=0.727,p=0.923),  time:34.650, tt:5093.534\n",
      "Ep:147, loss:0.00000, loss_test:0.02402, lr:2.94e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.664, tt:5130.240\n",
      "Ep:148, loss:0.00000, loss_test:0.02394, lr:2.91e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.664, tt:5164.948\n",
      "Ep:149, loss:0.00000, loss_test:0.02426, lr:2.88e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.673, tt:5200.912\n",
      "Ep:150, loss:0.00000, loss_test:0.02396, lr:2.85e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.673, tt:5235.639\n",
      "Ep:151, loss:0.00000, loss_test:0.02448, lr:2.82e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.667, tt:5269.399\n",
      "Ep:152, loss:0.00000, loss_test:0.02436, lr:2.80e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.667, tt:5304.050\n",
      "Ep:153, loss:0.00000, loss_test:0.02430, lr:2.77e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.668, tt:5338.811\n",
      "Ep:154, loss:0.00000, loss_test:0.02452, lr:2.74e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.657, tt:5371.864\n",
      "Ep:155, loss:0.00000, loss_test:0.02450, lr:2.71e-02, fs:0.80460 (r=0.707,p=0.933),  time:34.656, tt:5406.356\n",
      "Ep:156, loss:0.00000, loss_test:0.02492, lr:2.69e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.657, tt:5441.078\n",
      "Ep:157, loss:0.00000, loss_test:0.02475, lr:2.66e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.652, tt:5475.025\n",
      "Ep:158, loss:0.00000, loss_test:0.02499, lr:2.63e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.647, tt:5508.839\n",
      "Ep:159, loss:0.00000, loss_test:0.02474, lr:2.61e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.636, tt:5541.755\n",
      "Ep:160, loss:0.00000, loss_test:0.02490, lr:2.58e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.632, tt:5575.674\n",
      "Ep:161, loss:0.00000, loss_test:0.02514, lr:2.55e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.641, tt:5611.838\n",
      "Ep:162, loss:0.00000, loss_test:0.02537, lr:2.53e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.636, tt:5645.631\n",
      "Ep:163, loss:0.00000, loss_test:0.02505, lr:2.50e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.634, tt:5679.996\n",
      "Ep:164, loss:0.00000, loss_test:0.02544, lr:2.48e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.632, tt:5714.229\n",
      "Ep:165, loss:0.00000, loss_test:0.02518, lr:2.45e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.635, tt:5749.433\n",
      "Ep:166, loss:0.00000, loss_test:0.02573, lr:2.43e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.634, tt:5783.924\n",
      "Ep:167, loss:0.00000, loss_test:0.02535, lr:2.40e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.637, tt:5819.068\n",
      "Ep:168, loss:0.00000, loss_test:0.02550, lr:2.38e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.632, tt:5852.750\n",
      "Ep:169, loss:0.00000, loss_test:0.02569, lr:2.36e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.626, tt:5886.386\n",
      "Ep:170, loss:0.00000, loss_test:0.02555, lr:2.33e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.629, tt:5921.499\n",
      "Ep:171, loss:0.00000, loss_test:0.02573, lr:2.31e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.629, tt:5956.134\n",
      "Ep:172, loss:0.00000, loss_test:0.02564, lr:2.29e-02, fs:0.79769 (r=0.697,p=0.932),  time:34.631, tt:5991.218\n",
      "Ep:173, loss:0.00000, loss_test:0.02582, lr:2.26e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.636, tt:6026.621\n",
      "Ep:174, loss:0.00000, loss_test:0.02574, lr:2.24e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.642, tt:6062.409\n",
      "Ep:175, loss:0.00000, loss_test:0.02586, lr:2.22e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.650, tt:6098.334\n",
      "Ep:176, loss:0.00000, loss_test:0.02597, lr:2.20e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.671, tt:6136.802\n",
      "Ep:177, loss:0.00000, loss_test:0.02605, lr:2.17e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.675, tt:6172.234\n",
      "Ep:178, loss:0.00000, loss_test:0.02594, lr:2.15e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.678, tt:6207.397\n",
      "Ep:179, loss:0.00000, loss_test:0.02623, lr:2.13e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.686, tt:6243.487\n",
      "Ep:180, loss:0.00000, loss_test:0.02612, lr:2.11e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.683, tt:6277.555\n",
      "Ep:181, loss:0.00000, loss_test:0.02628, lr:2.09e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.686, tt:6312.923\n",
      "Ep:182, loss:0.00000, loss_test:0.02618, lr:2.07e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.694, tt:6348.974\n",
      "Ep:183, loss:0.00000, loss_test:0.02641, lr:2.05e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.695, tt:6383.905\n",
      "Ep:184, loss:0.00000, loss_test:0.02630, lr:2.03e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.700, tt:6419.428\n",
      "Ep:185, loss:0.00000, loss_test:0.02658, lr:2.01e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.706, tt:6455.300\n",
      "Ep:186, loss:0.00000, loss_test:0.02623, lr:1.99e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.708, tt:6490.386\n",
      "Ep:187, loss:0.00000, loss_test:0.02671, lr:1.97e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.709, tt:6525.280\n",
      "Ep:188, loss:0.00000, loss_test:0.02637, lr:1.95e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.721, tt:6562.265\n",
      "Ep:189, loss:0.00000, loss_test:0.02674, lr:1.93e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.728, tt:6598.395\n",
      "Ep:190, loss:0.00000, loss_test:0.02640, lr:1.91e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.731, tt:6633.716\n",
      "Ep:191, loss:0.00000, loss_test:0.02683, lr:1.89e-02, fs:0.79532 (r=0.687,p=0.944),  time:34.735, tt:6669.035\n",
      "Ep:192, loss:0.00000, loss_test:0.02658, lr:1.87e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.740, tt:6704.817\n",
      "Ep:193, loss:0.00000, loss_test:0.02672, lr:1.85e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.738, tt:6739.093\n",
      "Ep:194, loss:0.00000, loss_test:0.02666, lr:1.83e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.729, tt:6772.186\n",
      "Ep:195, loss:0.00000, loss_test:0.02675, lr:1.81e-02, fs:0.80233 (r=0.697,p=0.945),  time:34.711, tt:6803.358\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02039, lr:6.00e-02, fs:0.62979 (r=0.747,p=0.544),  time:28.476, tt:28.476\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02119, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:27.718, tt:55.436\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02308, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.513, tt:85.539\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02314, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.353, tt:113.413\n",
      "Ep:4, loss:0.00005, loss_test:0.02212, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.794, tt:143.971\n",
      "Ep:5, loss:0.00004, loss_test:0.02085, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:29.210, tt:175.262\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01923, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:29.583, tt:207.084\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01778, lr:6.00e-02, fs:0.68613 (r=0.949,p=0.537),  time:29.974, tt:239.793\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01693, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:30.207, tt:271.862\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00004, loss_test:0.01668, lr:6.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:30.394, tt:303.943\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01651, lr:6.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:30.325, tt:333.572\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:30.485, tt:365.826\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:30.557, tt:397.236\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01589, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:30.579, tt:428.104\n",
      "Ep:14, loss:0.00003, loss_test:0.01586, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:30.602, tt:459.036\n",
      "Ep:15, loss:0.00003, loss_test:0.01578, lr:6.00e-02, fs:0.73016 (r=0.929,p=0.601),  time:30.671, tt:490.741\n",
      "Ep:16, loss:0.00003, loss_test:0.01570, lr:6.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:30.663, tt:521.268\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01568, lr:6.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:30.616, tt:551.081\n",
      "Ep:18, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:30.687, tt:583.053\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:30.797, tt:615.932\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01565, lr:6.00e-02, fs:0.75455 (r=0.838,p=0.686),  time:30.802, tt:646.837\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:30.883, tt:679.415\n",
      "Ep:22, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.932, tt:711.437\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01545, lr:6.00e-02, fs:0.75676 (r=0.848,p=0.683),  time:30.981, tt:743.553\n",
      "Ep:24, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:30.955, tt:773.868\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01536, lr:6.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:30.966, tt:805.107\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.76923 (r=0.859,p=0.697),  time:30.993, tt:836.821\n",
      "Ep:27, loss:0.00002, loss_test:0.01533, lr:6.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:30.983, tt:867.511\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01534, lr:6.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:30.966, tt:898.013\n",
      "Ep:29, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:30.926, tt:927.792\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01540, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:30.967, tt:959.969\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01544, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:30.994, tt:991.794\n",
      "Ep:32, loss:0.00002, loss_test:0.01547, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:31.004, tt:1023.129\n",
      "Ep:33, loss:0.00002, loss_test:0.01549, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:31.020, tt:1054.695\n",
      "Ep:34, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:31.022, tt:1085.778\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01553, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:31.016, tt:1116.583\n",
      "Ep:36, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:31.010, tt:1147.376\n",
      "Ep:37, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:31.084, tt:1181.194\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:31.084, tt:1212.270\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:31.072, tt:1242.871\n",
      "Ep:40, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:31.091, tt:1274.725\n",
      "Ep:41, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:31.114, tt:1306.769\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01558, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:31.100, tt:1337.320\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:31.097, tt:1368.283\n",
      "Ep:44, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:31.071, tt:1398.178\n",
      "Ep:45, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:31.051, tt:1428.340\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01556, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.998, tt:1456.919\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01557, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.990, tt:1487.542\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01560, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.969, tt:1517.467\n",
      "Ep:49, loss:0.00002, loss_test:0.01564, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.967, tt:1548.361\n",
      "Ep:50, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.974, tt:1579.673\n",
      "Ep:51, loss:0.00002, loss_test:0.01567, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.995, tt:1611.715\n",
      "Ep:52, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:30.972, tt:1641.507\n",
      "Ep:53, loss:0.00002, loss_test:0.01571, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:30.949, tt:1671.268\n",
      "Ep:54, loss:0.00002, loss_test:0.01572, lr:6.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:30.937, tt:1701.508\n",
      "Ep:55, loss:0.00002, loss_test:0.01576, lr:6.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:30.912, tt:1731.095\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01575, lr:6.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:30.901, tt:1761.363\n",
      "Ep:57, loss:0.00002, loss_test:0.01578, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.889, tt:1791.584\n",
      "Ep:58, loss:0.00001, loss_test:0.01584, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.884, tt:1822.147\n",
      "Ep:59, loss:0.00001, loss_test:0.01590, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.924, tt:1855.445\n",
      "Ep:60, loss:0.00001, loss_test:0.01594, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:30.907, tt:1885.356\n",
      "Ep:61, loss:0.00001, loss_test:0.01599, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.917, tt:1916.854\n",
      "Ep:62, loss:0.00001, loss_test:0.01602, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.903, tt:1946.910\n",
      "Ep:63, loss:0.00001, loss_test:0.01605, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.884, tt:1976.606\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01606, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.866, tt:2006.305\n",
      "Ep:65, loss:0.00001, loss_test:0.01610, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.862, tt:2036.904\n",
      "Ep:66, loss:0.00001, loss_test:0.01615, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.879, tt:2068.879\n",
      "Ep:67, loss:0.00001, loss_test:0.01617, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.872, tt:2099.297\n",
      "Ep:68, loss:0.00001, loss_test:0.01620, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.846, tt:2128.362\n",
      "Ep:69, loss:0.00001, loss_test:0.01627, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.834, tt:2158.350\n",
      "Ep:70, loss:0.00001, loss_test:0.01630, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.826, tt:2188.668\n",
      "Ep:71, loss:0.00001, loss_test:0.01632, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.823, tt:2219.222\n",
      "Ep:72, loss:0.00001, loss_test:0.01633, lr:6.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.824, tt:2250.181\n",
      "Ep:73, loss:0.00001, loss_test:0.01639, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.819, tt:2280.569\n",
      "Ep:74, loss:0.00001, loss_test:0.01647, lr:6.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:30.805, tt:2310.399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00001, loss_test:0.01650, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.809, tt:2341.508\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01652, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.802, tt:2371.784\n",
      "Ep:77, loss:0.00001, loss_test:0.01660, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.813, tt:2403.391\n",
      "Ep:78, loss:0.00001, loss_test:0.01664, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.796, tt:2432.867\n",
      "Ep:79, loss:0.00001, loss_test:0.01669, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.779, tt:2462.289\n",
      "Ep:80, loss:0.00001, loss_test:0.01674, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.772, tt:2492.537\n",
      "Ep:81, loss:0.00001, loss_test:0.01674, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.777, tt:2523.748\n",
      "Ep:82, loss:0.00001, loss_test:0.01678, lr:5.94e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.781, tt:2554.850\n",
      "Ep:83, loss:0.00001, loss_test:0.01683, lr:5.94e-02, fs:0.85854 (r=0.889,p=0.830),  time:30.783, tt:2585.769\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01687, lr:5.94e-02, fs:0.86275 (r=0.889,p=0.838),  time:30.777, tt:2616.010\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01691, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.780, tt:2647.054\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01699, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.782, tt:2678.006\n",
      "Ep:87, loss:0.00001, loss_test:0.01705, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.774, tt:2708.069\n",
      "Ep:88, loss:0.00001, loss_test:0.01710, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.767, tt:2738.258\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01715, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.755, tt:2767.946\n",
      "Ep:90, loss:0.00001, loss_test:0.01722, lr:5.94e-02, fs:0.86700 (r=0.889,p=0.846),  time:30.747, tt:2797.946\n",
      "Ep:91, loss:0.00001, loss_test:0.01728, lr:5.94e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.733, tt:2827.437\n",
      "Ep:92, loss:0.00001, loss_test:0.01731, lr:5.94e-02, fs:0.87129 (r=0.889,p=0.854),  time:30.709, tt:2855.931\n",
      "Ep:93, loss:0.00001, loss_test:0.01738, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.699, tt:2885.694\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01741, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.692, tt:2915.754\n",
      "Ep:95, loss:0.00001, loss_test:0.01741, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.670, tt:2944.288\n",
      "Ep:96, loss:0.00001, loss_test:0.01749, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.651, tt:2973.142\n",
      "Ep:97, loss:0.00001, loss_test:0.01753, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.646, tt:3003.261\n",
      "Ep:98, loss:0.00001, loss_test:0.01761, lr:5.94e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.642, tt:3033.529\n",
      "Ep:99, loss:0.00001, loss_test:0.01765, lr:5.94e-02, fs:0.88119 (r=0.899,p=0.864),  time:30.628, tt:3062.776\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01772, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.630, tt:3093.642\n",
      "Ep:101, loss:0.00001, loss_test:0.01775, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.627, tt:3123.960\n",
      "Ep:102, loss:0.00001, loss_test:0.01780, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.639, tt:3155.798\n",
      "Ep:103, loss:0.00001, loss_test:0.01787, lr:5.94e-02, fs:0.87000 (r=0.879,p=0.861),  time:30.620, tt:3184.469\n",
      "Ep:104, loss:0.00001, loss_test:0.01794, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:30.640, tt:3217.212\n",
      "Ep:105, loss:0.00001, loss_test:0.01805, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:30.640, tt:3247.826\n",
      "Ep:106, loss:0.00001, loss_test:0.01811, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:30.635, tt:3277.905\n",
      "Ep:107, loss:0.00001, loss_test:0.01817, lr:5.94e-02, fs:0.87310 (r=0.869,p=0.878),  time:30.615, tt:3306.392\n",
      "Ep:108, loss:0.00001, loss_test:0.01825, lr:5.94e-02, fs:0.86154 (r=0.848,p=0.875),  time:30.607, tt:3336.144\n",
      "Ep:109, loss:0.00001, loss_test:0.01827, lr:5.94e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.601, tt:3366.113\n",
      "Ep:110, loss:0.00001, loss_test:0.01833, lr:5.94e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.589, tt:3395.377\n",
      "Ep:111, loss:0.00001, loss_test:0.01837, lr:5.88e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.590, tt:3426.088\n",
      "Ep:112, loss:0.00001, loss_test:0.01841, lr:5.82e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.584, tt:3456.043\n",
      "Ep:113, loss:0.00001, loss_test:0.01848, lr:5.76e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.590, tt:3487.210\n",
      "Ep:114, loss:0.00001, loss_test:0.01853, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.586, tt:3517.432\n",
      "Ep:115, loss:0.00001, loss_test:0.01858, lr:5.65e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.587, tt:3548.049\n",
      "Ep:116, loss:0.00001, loss_test:0.01862, lr:5.59e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.577, tt:3577.463\n",
      "Ep:117, loss:0.00001, loss_test:0.01872, lr:5.54e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.570, tt:3607.249\n",
      "Ep:118, loss:0.00001, loss_test:0.01881, lr:5.48e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.561, tt:3636.748\n",
      "Ep:119, loss:0.00001, loss_test:0.01887, lr:5.43e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.554, tt:3666.496\n",
      "Ep:120, loss:0.00001, loss_test:0.01892, lr:5.37e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.534, tt:3694.648\n",
      "Ep:121, loss:0.00001, loss_test:0.01898, lr:5.32e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.530, tt:3724.622\n",
      "Ep:122, loss:0.00001, loss_test:0.01904, lr:5.27e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.532, tt:3755.470\n",
      "Ep:123, loss:0.00001, loss_test:0.01911, lr:5.21e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.527, tt:3785.293\n",
      "Ep:124, loss:0.00001, loss_test:0.01920, lr:5.16e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.532, tt:3816.440\n",
      "Ep:125, loss:0.00001, loss_test:0.01924, lr:5.11e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.530, tt:3846.826\n",
      "Ep:126, loss:0.00001, loss_test:0.01928, lr:5.06e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.527, tt:3876.900\n",
      "Ep:127, loss:0.00001, loss_test:0.01933, lr:5.01e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.522, tt:3906.869\n",
      "Ep:128, loss:0.00001, loss_test:0.01939, lr:4.96e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.513, tt:3936.217\n",
      "Ep:129, loss:0.00001, loss_test:0.01947, lr:4.91e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.525, tt:3968.237\n",
      "Ep:130, loss:0.00001, loss_test:0.01951, lr:4.86e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.525, tt:3998.756\n",
      "Ep:131, loss:0.00001, loss_test:0.01954, lr:4.81e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.526, tt:4029.416\n",
      "Ep:132, loss:0.00001, loss_test:0.01961, lr:4.76e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.518, tt:4058.932\n",
      "Ep:133, loss:0.00001, loss_test:0.01968, lr:4.71e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.514, tt:4088.919\n",
      "Ep:134, loss:0.00001, loss_test:0.01972, lr:4.67e-02, fs:0.85106 (r=0.808,p=0.899),  time:30.514, tt:4119.425\n",
      "Ep:135, loss:0.00001, loss_test:0.01976, lr:4.62e-02, fs:0.84492 (r=0.798,p=0.898),  time:30.511, tt:4149.451\n",
      "Ep:136, loss:0.00001, loss_test:0.01981, lr:4.57e-02, fs:0.84946 (r=0.798,p=0.908),  time:30.505, tt:4179.165\n",
      "Ep:137, loss:0.00001, loss_test:0.01989, lr:4.53e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.502, tt:4209.314\n",
      "Ep:138, loss:0.00001, loss_test:0.01997, lr:4.48e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.496, tt:4238.981\n",
      "Ep:139, loss:0.00001, loss_test:0.01999, lr:4.44e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.494, tt:4269.113\n",
      "Ep:140, loss:0.00001, loss_test:0.02006, lr:4.39e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.496, tt:4299.893\n",
      "Ep:141, loss:0.00001, loss_test:0.02011, lr:4.35e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.492, tt:4329.929\n",
      "Ep:142, loss:0.00001, loss_test:0.02018, lr:4.31e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.492, tt:4360.409\n",
      "Ep:143, loss:0.00001, loss_test:0.02023, lr:4.26e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.494, tt:4391.124\n",
      "Ep:144, loss:0.00001, loss_test:0.02028, lr:4.22e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.493, tt:4421.462\n",
      "Ep:145, loss:0.00001, loss_test:0.02034, lr:4.18e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.489, tt:4451.381\n",
      "Ep:146, loss:0.00001, loss_test:0.02037, lr:4.14e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.496, tt:4482.879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.02040, lr:4.10e-02, fs:0.84324 (r=0.788,p=0.907),  time:30.490, tt:4512.571\n",
      "Ep:148, loss:0.00001, loss_test:0.02046, lr:4.05e-02, fs:0.83696 (r=0.778,p=0.906),  time:30.478, tt:4541.213\n",
      "Ep:149, loss:0.00001, loss_test:0.02053, lr:4.01e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.468, tt:4570.128\n",
      "Ep:150, loss:0.00001, loss_test:0.02056, lr:3.97e-02, fs:0.83060 (r=0.768,p=0.905),  time:30.469, tt:4600.787\n",
      "Ep:151, loss:0.00001, loss_test:0.02060, lr:3.93e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.463, tt:4630.375\n",
      "Ep:152, loss:0.00001, loss_test:0.02062, lr:3.89e-02, fs:0.82418 (r=0.758,p=0.904),  time:30.463, tt:4660.915\n",
      "Ep:153, loss:0.00001, loss_test:0.02069, lr:3.86e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.462, tt:4691.149\n",
      "Ep:154, loss:0.00001, loss_test:0.02076, lr:3.82e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.454, tt:4720.319\n",
      "Ep:155, loss:0.00001, loss_test:0.02080, lr:3.78e-02, fs:0.81768 (r=0.747,p=0.902),  time:30.455, tt:4751.037\n",
      "Ep:156, loss:0.00000, loss_test:0.02084, lr:3.74e-02, fs:0.80447 (r=0.727,p=0.900),  time:30.449, tt:4780.424\n",
      "Ep:157, loss:0.00000, loss_test:0.02089, lr:3.70e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.441, tt:4809.637\n",
      "Ep:158, loss:0.00000, loss_test:0.02094, lr:3.67e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.434, tt:4839.031\n",
      "Ep:159, loss:0.00000, loss_test:0.02097, lr:3.63e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.439, tt:4870.221\n",
      "Ep:160, loss:0.00000, loss_test:0.02100, lr:3.59e-02, fs:0.79775 (r=0.717,p=0.899),  time:30.444, tt:4901.520\n",
      "Ep:161, loss:0.00000, loss_test:0.02107, lr:3.56e-02, fs:0.79096 (r=0.707,p=0.897),  time:30.442, tt:4931.603\n",
      "Ep:162, loss:0.00000, loss_test:0.02111, lr:3.52e-02, fs:0.78409 (r=0.697,p=0.896),  time:30.443, tt:4962.131\n",
      "Ep:163, loss:0.00000, loss_test:0.02116, lr:3.49e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.441, tt:4992.381\n",
      "Ep:164, loss:0.00000, loss_test:0.02119, lr:3.45e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.448, tt:5024.000\n",
      "Ep:165, loss:0.00000, loss_test:0.02123, lr:3.42e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.436, tt:5052.395\n",
      "Ep:166, loss:0.00000, loss_test:0.02128, lr:3.38e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.446, tt:5084.561\n",
      "Ep:167, loss:0.00000, loss_test:0.02135, lr:3.35e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.437, tt:5113.375\n",
      "Ep:168, loss:0.00000, loss_test:0.02139, lr:3.32e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.435, tt:5143.594\n",
      "Ep:169, loss:0.00000, loss_test:0.02142, lr:3.28e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.436, tt:5174.112\n",
      "Ep:170, loss:0.00000, loss_test:0.02144, lr:3.25e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.427, tt:5203.007\n",
      "Ep:171, loss:0.00000, loss_test:0.02148, lr:3.22e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.414, tt:5231.245\n",
      "Ep:172, loss:0.00000, loss_test:0.02154, lr:3.19e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.417, tt:5262.145\n",
      "Ep:173, loss:0.00000, loss_test:0.02157, lr:3.15e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.414, tt:5291.991\n",
      "Ep:174, loss:0.00000, loss_test:0.02160, lr:3.12e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.417, tt:5323.012\n",
      "Ep:175, loss:0.00000, loss_test:0.02163, lr:3.09e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.420, tt:5353.899\n",
      "Ep:176, loss:0.00000, loss_test:0.02169, lr:3.06e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.415, tt:5383.517\n",
      "Ep:177, loss:0.00000, loss_test:0.02173, lr:3.03e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.406, tt:5412.333\n",
      "Ep:178, loss:0.00000, loss_test:0.02177, lr:3.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.405, tt:5442.548\n",
      "Ep:179, loss:0.00000, loss_test:0.02180, lr:2.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.403, tt:5472.499\n",
      "Ep:180, loss:0.00000, loss_test:0.02182, lr:2.94e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.409, tt:5504.021\n",
      "Ep:181, loss:0.00000, loss_test:0.02183, lr:2.91e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.410, tt:5534.605\n",
      "Ep:182, loss:0.00000, loss_test:0.02186, lr:2.88e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.407, tt:5564.449\n",
      "Ep:183, loss:0.00000, loss_test:0.02190, lr:2.85e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.408, tt:5595.011\n",
      "Ep:184, loss:0.00000, loss_test:0.02194, lr:2.82e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.413, tt:5626.348\n",
      "Ep:185, loss:0.00000, loss_test:0.02198, lr:2.80e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.415, tt:5657.159\n",
      "Ep:186, loss:0.00000, loss_test:0.02200, lr:2.77e-02, fs:0.77714 (r=0.687,p=0.895),  time:30.412, tt:5687.002\n",
      "Ep:187, loss:0.00000, loss_test:0.02204, lr:2.74e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.419, tt:5718.724\n",
      "Ep:188, loss:0.00000, loss_test:0.02208, lr:2.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.419, tt:5749.282\n",
      "Ep:189, loss:0.00000, loss_test:0.02214, lr:2.69e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.419, tt:5779.581\n",
      "Ep:190, loss:0.00000, loss_test:0.02216, lr:2.66e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.418, tt:5809.904\n",
      "Ep:191, loss:0.00000, loss_test:0.02219, lr:2.63e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.419, tt:5840.351\n",
      "Ep:192, loss:0.00000, loss_test:0.02221, lr:2.61e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.417, tt:5870.463\n",
      "Ep:193, loss:0.00000, loss_test:0.02225, lr:2.58e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.425, tt:5902.359\n",
      "Ep:194, loss:0.00000, loss_test:0.02229, lr:2.55e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.415, tt:5930.985\n",
      "Ep:195, loss:0.00000, loss_test:0.02233, lr:2.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:30.419, tt:5962.044\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01999, lr:6.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:30.515, tt:30.515\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02290, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.984, tt:67.968\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02372, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.773, tt:104.319\n",
      "Ep:3, loss:0.00005, loss_test:0.02308, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.271, tt:141.082\n",
      "Ep:4, loss:0.00005, loss_test:0.02137, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:36.003, tt:180.017\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01925, lr:6.00e-02, fs:0.68531 (r=0.990,p=0.524),  time:36.035, tt:216.210\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01753, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:36.339, tt:254.373\n",
      "Ep:7, loss:0.00004, loss_test:0.01682, lr:6.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:36.593, tt:292.745\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01657, lr:6.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:36.813, tt:331.316\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01619, lr:6.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:36.873, tt:368.728\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01607, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:37.014, tt:407.158\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.71875 (r=0.929,p=0.586),  time:37.374, tt:448.490\n",
      "Ep:12, loss:0.00003, loss_test:0.01600, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:37.577, tt:488.501\n",
      "Ep:13, loss:0.00003, loss_test:0.01576, lr:6.00e-02, fs:0.73307 (r=0.929,p=0.605),  time:37.757, tt:528.592\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01561, lr:6.00e-02, fs:0.75102 (r=0.929,p=0.630),  time:37.777, tt:566.650\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01553, lr:6.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:37.803, tt:604.850\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:37.794, tt:642.490\n",
      "Ep:17, loss:0.00003, loss_test:0.01530, lr:6.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:37.789, tt:680.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00003, loss_test:0.01526, lr:6.00e-02, fs:0.74561 (r=0.859,p=0.659),  time:37.890, tt:719.917\n",
      "Ep:19, loss:0.00003, loss_test:0.01523, lr:6.00e-02, fs:0.74236 (r=0.859,p=0.654),  time:37.873, tt:757.469\n",
      "Ep:20, loss:0.00003, loss_test:0.01524, lr:6.00e-02, fs:0.76233 (r=0.859,p=0.685),  time:37.955, tt:797.045\n",
      "Ep:21, loss:0.00003, loss_test:0.01530, lr:6.00e-02, fs:0.76364 (r=0.848,p=0.694),  time:38.082, tt:837.796\n",
      "Ep:22, loss:0.00002, loss_test:0.01532, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:38.119, tt:876.732\n",
      "Ep:23, loss:0.00002, loss_test:0.01529, lr:6.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:38.149, tt:915.565\n",
      "Ep:24, loss:0.00002, loss_test:0.01522, lr:6.00e-02, fs:0.77064 (r=0.848,p=0.706),  time:38.197, tt:954.922\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01516, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:38.239, tt:994.224\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01513, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:38.396, tt:1036.679\n",
      "Ep:27, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.77626 (r=0.859,p=0.708),  time:38.400, tt:1075.208\n",
      "Ep:28, loss:0.00002, loss_test:0.01510, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:38.458, tt:1115.278\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:38.442, tt:1153.245\n",
      "Ep:30, loss:0.00002, loss_test:0.01509, lr:6.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:38.482, tt:1192.950\n",
      "Ep:31, loss:0.00002, loss_test:0.01506, lr:6.00e-02, fs:0.79263 (r=0.869,p=0.729),  time:38.476, tt:1231.222\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:38.534, tt:1271.637\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01499, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:38.555, tt:1310.880\n",
      "Ep:34, loss:0.00002, loss_test:0.01489, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:38.515, tt:1348.035\n",
      "Ep:35, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:38.563, tt:1388.264\n",
      "Ep:36, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:38.539, tt:1425.947\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:38.572, tt:1465.724\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:38.593, tt:1505.113\n",
      "Ep:39, loss:0.00002, loss_test:0.01482, lr:6.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:38.582, tt:1543.265\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:38.551, tt:1580.572\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01478, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:38.545, tt:1618.883\n",
      "Ep:42, loss:0.00002, loss_test:0.01477, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:38.567, tt:1658.386\n",
      "Ep:43, loss:0.00001, loss_test:0.01477, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:38.571, tt:1697.124\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00001, loss_test:0.01473, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:38.599, tt:1736.953\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01474, lr:6.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:38.622, tt:1776.619\n",
      "Ep:46, loss:0.00001, loss_test:0.01477, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.625, tt:1815.357\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01477, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.667, tt:1856.016\n",
      "Ep:48, loss:0.00001, loss_test:0.01479, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.684, tt:1895.523\n",
      "Ep:49, loss:0.00001, loss_test:0.01483, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:38.693, tt:1934.669\n",
      "Ep:50, loss:0.00001, loss_test:0.01487, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:38.712, tt:1974.292\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01480, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:38.711, tt:2012.982\n",
      "Ep:52, loss:0.00001, loss_test:0.01479, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.699, tt:2051.041\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01484, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.695, tt:2089.524\n",
      "Ep:54, loss:0.00001, loss_test:0.01488, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.703, tt:2128.683\n",
      "Ep:55, loss:0.00001, loss_test:0.01482, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.720, tt:2168.306\n",
      "Ep:56, loss:0.00001, loss_test:0.01490, lr:6.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:38.767, tt:2209.724\n",
      "Ep:57, loss:0.00001, loss_test:0.01496, lr:6.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:38.770, tt:2248.631\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01490, lr:6.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:38.804, tt:2289.432\n",
      "Ep:59, loss:0.00001, loss_test:0.01495, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:38.791, tt:2327.466\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01493, lr:6.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:38.793, tt:2366.350\n",
      "Ep:61, loss:0.00001, loss_test:0.01502, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.776, tt:2404.138\n",
      "Ep:62, loss:0.00001, loss_test:0.01500, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.781, tt:2443.213\n",
      "Ep:63, loss:0.00001, loss_test:0.01497, lr:6.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:38.778, tt:2481.805\n",
      "Ep:64, loss:0.00001, loss_test:0.01510, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.753, tt:2518.972\n",
      "Ep:65, loss:0.00001, loss_test:0.01507, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.754, tt:2557.756\n",
      "Ep:66, loss:0.00001, loss_test:0.01514, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.739, tt:2595.498\n",
      "Ep:67, loss:0.00001, loss_test:0.01511, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.743, tt:2634.550\n",
      "Ep:68, loss:0.00001, loss_test:0.01513, lr:6.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:38.723, tt:2671.870\n",
      "Ep:69, loss:0.00001, loss_test:0.01518, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:38.704, tt:2709.277\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01517, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:38.668, tt:2745.452\n",
      "Ep:71, loss:0.00001, loss_test:0.01526, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:38.648, tt:2782.691\n",
      "Ep:72, loss:0.00001, loss_test:0.01516, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:38.635, tt:2820.333\n",
      "Ep:73, loss:0.00001, loss_test:0.01523, lr:6.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:38.709, tt:2864.461\n",
      "Ep:74, loss:0.00001, loss_test:0.01531, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:38.715, tt:2903.647\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01526, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:38.719, tt:2942.681\n",
      "Ep:76, loss:0.00001, loss_test:0.01539, lr:6.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:38.697, tt:2979.655\n",
      "Ep:77, loss:0.00001, loss_test:0.01538, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.682, tt:3017.223\n",
      "Ep:78, loss:0.00001, loss_test:0.01544, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:38.668, tt:3054.809\n",
      "Ep:79, loss:0.00001, loss_test:0.01554, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.689, tt:3095.096\n",
      "Ep:80, loss:0.00001, loss_test:0.01549, lr:6.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:38.699, tt:3134.619\n",
      "Ep:81, loss:0.00001, loss_test:0.01557, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.690, tt:3172.554\n",
      "Ep:82, loss:0.00001, loss_test:0.01566, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.705, tt:3212.483\n",
      "Ep:83, loss:0.00001, loss_test:0.01554, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:38.694, tt:3250.260\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01569, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.693, tt:3288.912\n",
      "Ep:85, loss:0.00001, loss_test:0.01567, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.694, tt:3327.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00001, loss_test:0.01570, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.713, tt:3368.002\n",
      "Ep:87, loss:0.00001, loss_test:0.01578, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.711, tt:3406.584\n",
      "Ep:88, loss:0.00001, loss_test:0.01583, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.715, tt:3445.655\n",
      "Ep:89, loss:0.00001, loss_test:0.01577, lr:6.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:38.729, tt:3485.617\n",
      "Ep:90, loss:0.00001, loss_test:0.01589, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.718, tt:3523.307\n",
      "Ep:91, loss:0.00001, loss_test:0.01606, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:38.717, tt:3561.919\n",
      "Ep:92, loss:0.00001, loss_test:0.01597, lr:6.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:38.717, tt:3600.706\n",
      "Ep:93, loss:0.00001, loss_test:0.01610, lr:6.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:38.704, tt:3638.169\n",
      "Ep:94, loss:0.00001, loss_test:0.01613, lr:6.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:38.699, tt:3676.414\n",
      "Ep:95, loss:0.00001, loss_test:0.01614, lr:5.94e-02, fs:0.87179 (r=0.859,p=0.885),  time:38.712, tt:3716.342\n",
      "Ep:96, loss:0.00001, loss_test:0.01619, lr:5.88e-02, fs:0.86735 (r=0.859,p=0.876),  time:38.719, tt:3755.764\n",
      "Ep:97, loss:0.00001, loss_test:0.01629, lr:5.82e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.700, tt:3792.599\n",
      "Ep:98, loss:0.00000, loss_test:0.01632, lr:5.76e-02, fs:0.86154 (r=0.848,p=0.875),  time:38.688, tt:3830.105\n",
      "Ep:99, loss:0.00000, loss_test:0.01640, lr:5.71e-02, fs:0.84375 (r=0.818,p=0.871),  time:38.689, tt:3868.947\n",
      "Ep:100, loss:0.00000, loss_test:0.01643, lr:5.65e-02, fs:0.84817 (r=0.818,p=0.880),  time:38.712, tt:3909.873\n",
      "Ep:101, loss:0.00000, loss_test:0.01652, lr:5.59e-02, fs:0.84375 (r=0.818,p=0.871),  time:38.703, tt:3947.688\n",
      "Ep:102, loss:0.00000, loss_test:0.01655, lr:5.54e-02, fs:0.84375 (r=0.818,p=0.871),  time:38.700, tt:3986.118\n",
      "Ep:103, loss:0.00000, loss_test:0.01654, lr:5.48e-02, fs:0.84817 (r=0.818,p=0.880),  time:38.698, tt:4024.609\n",
      "Ep:104, loss:0.00000, loss_test:0.01661, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:38.683, tt:4061.759\n",
      "Ep:105, loss:0.00000, loss_test:0.01679, lr:5.37e-02, fs:0.82979 (r=0.788,p=0.876),  time:38.691, tt:4101.220\n",
      "Ep:106, loss:0.00000, loss_test:0.01671, lr:5.32e-02, fs:0.84043 (r=0.798,p=0.888),  time:38.692, tt:4140.042\n",
      "Ep:107, loss:0.00000, loss_test:0.01672, lr:5.27e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.687, tt:4178.222\n",
      "Ep:108, loss:0.00000, loss_test:0.01686, lr:5.21e-02, fs:0.82796 (r=0.778,p=0.885),  time:38.709, tt:4219.241\n",
      "Ep:109, loss:0.00000, loss_test:0.01687, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.697, tt:4256.623\n",
      "Ep:110, loss:0.00000, loss_test:0.01686, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.697, tt:4295.323\n",
      "Ep:111, loss:0.00000, loss_test:0.01707, lr:5.06e-02, fs:0.83060 (r=0.768,p=0.905),  time:38.681, tt:4332.257\n",
      "Ep:112, loss:0.00000, loss_test:0.01708, lr:5.01e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.665, tt:4369.173\n",
      "Ep:113, loss:0.00000, loss_test:0.01706, lr:4.96e-02, fs:0.82418 (r=0.758,p=0.904),  time:38.648, tt:4405.883\n",
      "Ep:114, loss:0.00000, loss_test:0.01716, lr:4.91e-02, fs:0.82609 (r=0.768,p=0.894),  time:38.654, tt:4445.193\n",
      "Ep:115, loss:0.00000, loss_test:0.01715, lr:4.86e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.661, tt:4484.683\n",
      "Ep:116, loss:0.00000, loss_test:0.01721, lr:4.81e-02, fs:0.82418 (r=0.758,p=0.904),  time:38.641, tt:4521.026\n",
      "Ep:117, loss:0.00000, loss_test:0.01728, lr:4.76e-02, fs:0.82418 (r=0.758,p=0.904),  time:38.648, tt:4560.416\n",
      "Ep:118, loss:0.00000, loss_test:0.01723, lr:4.71e-02, fs:0.82418 (r=0.758,p=0.904),  time:38.650, tt:4599.317\n",
      "Ep:119, loss:0.00000, loss_test:0.01732, lr:4.67e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.637, tt:4636.381\n",
      "Ep:120, loss:0.00000, loss_test:0.01738, lr:4.62e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.638, tt:4675.197\n",
      "Ep:121, loss:0.00000, loss_test:0.01742, lr:4.57e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.640, tt:4714.125\n",
      "Ep:122, loss:0.00000, loss_test:0.01748, lr:4.53e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.648, tt:4753.667\n",
      "Ep:123, loss:0.00000, loss_test:0.01754, lr:4.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.643, tt:4791.726\n",
      "Ep:124, loss:0.00000, loss_test:0.01754, lr:4.44e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.644, tt:4830.463\n",
      "Ep:125, loss:0.00000, loss_test:0.01762, lr:4.39e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.660, tt:4871.178\n",
      "Ep:126, loss:0.00000, loss_test:0.01770, lr:4.35e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.673, tt:4911.464\n",
      "Ep:127, loss:0.00000, loss_test:0.01767, lr:4.31e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.679, tt:4950.866\n",
      "Ep:128, loss:0.00000, loss_test:0.01770, lr:4.26e-02, fs:0.82873 (r=0.758,p=0.915),  time:38.680, tt:4989.757\n",
      "Ep:129, loss:0.00000, loss_test:0.01781, lr:4.22e-02, fs:0.82222 (r=0.747,p=0.914),  time:38.674, tt:5027.629\n",
      "Ep:130, loss:0.00000, loss_test:0.01778, lr:4.18e-02, fs:0.82222 (r=0.747,p=0.914),  time:38.669, tt:5065.703\n",
      "Ep:131, loss:0.00000, loss_test:0.01781, lr:4.14e-02, fs:0.82222 (r=0.747,p=0.914),  time:38.668, tt:5104.210\n",
      "Ep:132, loss:0.00000, loss_test:0.01794, lr:4.10e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.662, tt:5142.093\n",
      "Ep:133, loss:0.00000, loss_test:0.01789, lr:4.05e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.662, tt:5180.688\n",
      "Ep:134, loss:0.00000, loss_test:0.01794, lr:4.01e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.672, tt:5220.722\n",
      "Ep:135, loss:0.00000, loss_test:0.01806, lr:3.97e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.653, tt:5256.798\n",
      "Ep:136, loss:0.00000, loss_test:0.01800, lr:3.93e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.653, tt:5295.484\n",
      "Ep:137, loss:0.00000, loss_test:0.01802, lr:3.89e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.660, tt:5335.147\n",
      "Ep:138, loss:0.00000, loss_test:0.01811, lr:3.86e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.664, tt:5374.251\n",
      "Ep:139, loss:0.00000, loss_test:0.01816, lr:3.82e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.662, tt:5412.721\n",
      "Ep:140, loss:0.00000, loss_test:0.01813, lr:3.78e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.644, tt:5448.848\n",
      "Ep:141, loss:0.00000, loss_test:0.01825, lr:3.74e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.643, tt:5487.290\n",
      "Ep:142, loss:0.00000, loss_test:0.01835, lr:3.70e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.644, tt:5526.086\n",
      "Ep:143, loss:0.00000, loss_test:0.01825, lr:3.67e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.638, tt:5563.848\n",
      "Ep:144, loss:0.00000, loss_test:0.01833, lr:3.63e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.636, tt:5602.275\n",
      "Ep:145, loss:0.00000, loss_test:0.01842, lr:3.59e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.635, tt:5640.647\n",
      "Ep:146, loss:0.00000, loss_test:0.01839, lr:3.56e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.630, tt:5678.629\n",
      "Ep:147, loss:0.00000, loss_test:0.01844, lr:3.52e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.655, tt:5720.969\n",
      "Ep:148, loss:0.00000, loss_test:0.01856, lr:3.49e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.650, tt:5758.878\n",
      "Ep:149, loss:0.00000, loss_test:0.01853, lr:3.45e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.647, tt:5797.061\n",
      "Ep:150, loss:0.00000, loss_test:0.01850, lr:3.42e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.637, tt:5834.128\n",
      "Ep:151, loss:0.00000, loss_test:0.01863, lr:3.38e-02, fs:0.82682 (r=0.747,p=0.925),  time:38.639, tt:5873.155\n",
      "Ep:152, loss:0.00000, loss_test:0.01871, lr:3.35e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.635, tt:5911.141\n",
      "Ep:153, loss:0.00000, loss_test:0.01867, lr:3.32e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.640, tt:5950.611\n",
      "Ep:154, loss:0.00000, loss_test:0.01871, lr:3.28e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.633, tt:5988.121\n",
      "Ep:155, loss:0.00000, loss_test:0.01881, lr:3.25e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.626, tt:6025.709\n",
      "Ep:156, loss:0.00000, loss_test:0.01881, lr:3.22e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.634, tt:6065.511\n",
      "Ep:157, loss:0.00000, loss_test:0.01881, lr:3.19e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.617, tt:6101.435\n",
      "Ep:158, loss:0.00000, loss_test:0.01891, lr:3.15e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.622, tt:6140.967\n",
      "Ep:159, loss:0.00000, loss_test:0.01891, lr:3.12e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.631, tt:6180.930\n",
      "Ep:160, loss:0.00000, loss_test:0.01891, lr:3.09e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.623, tt:6218.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:161, loss:0.00000, loss_test:0.01897, lr:3.06e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.627, tt:6257.502\n",
      "Ep:162, loss:0.00000, loss_test:0.01903, lr:3.03e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.611, tt:6293.545\n",
      "Ep:163, loss:0.00000, loss_test:0.01904, lr:3.00e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.606, tt:6331.412\n",
      "Ep:164, loss:0.00000, loss_test:0.01909, lr:2.97e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.615, tt:6371.506\n",
      "Ep:165, loss:0.00000, loss_test:0.01911, lr:2.94e-02, fs:0.83616 (r=0.747,p=0.949),  time:38.609, tt:6409.174\n",
      "Ep:166, loss:0.00000, loss_test:0.01914, lr:2.91e-02, fs:0.83146 (r=0.747,p=0.937),  time:38.611, tt:6448.038\n",
      "Ep:167, loss:0.00000, loss_test:0.01917, lr:2.88e-02, fs:0.83616 (r=0.747,p=0.949),  time:38.612, tt:6486.888\n",
      "Ep:168, loss:0.00000, loss_test:0.01920, lr:2.85e-02, fs:0.83616 (r=0.747,p=0.949),  time:38.612, tt:6525.360\n",
      "Ep:169, loss:0.00000, loss_test:0.01926, lr:2.82e-02, fs:0.83616 (r=0.747,p=0.949),  time:38.612, tt:6564.035\n",
      "Ep:170, loss:0.00000, loss_test:0.01926, lr:2.80e-02, fs:0.83616 (r=0.747,p=0.949),  time:38.597, tt:6600.090\n",
      "Ep:171, loss:0.00000, loss_test:0.01929, lr:2.77e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.594, tt:6638.101\n",
      "Ep:172, loss:0.00000, loss_test:0.01940, lr:2.74e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.590, tt:6676.128\n",
      "Ep:173, loss:0.00000, loss_test:0.01937, lr:2.71e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.589, tt:6714.462\n",
      "Ep:174, loss:0.00000, loss_test:0.01936, lr:2.69e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.582, tt:6751.888\n",
      "Ep:175, loss:0.00000, loss_test:0.01945, lr:2.66e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.596, tt:6792.839\n",
      "Ep:176, loss:0.00000, loss_test:0.01947, lr:2.63e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.594, tt:6831.168\n",
      "Ep:177, loss:0.00000, loss_test:0.01949, lr:2.61e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.595, tt:6869.938\n",
      "Ep:178, loss:0.00000, loss_test:0.01949, lr:2.58e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.588, tt:6907.333\n",
      "Ep:179, loss:0.00000, loss_test:0.01957, lr:2.55e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.594, tt:6946.955\n",
      "Ep:180, loss:0.00000, loss_test:0.01961, lr:2.53e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.595, tt:6985.610\n",
      "Ep:181, loss:0.00000, loss_test:0.01956, lr:2.50e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.589, tt:7023.229\n",
      "Ep:182, loss:0.00000, loss_test:0.01963, lr:2.48e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.591, tt:7062.114\n",
      "Ep:183, loss:0.00000, loss_test:0.01967, lr:2.45e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.600, tt:7102.456\n",
      "Ep:184, loss:0.00000, loss_test:0.01969, lr:2.43e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.599, tt:7140.774\n",
      "Ep:185, loss:0.00000, loss_test:0.01972, lr:2.40e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.596, tt:7178.905\n",
      "Ep:186, loss:0.00000, loss_test:0.01974, lr:2.38e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.598, tt:7217.824\n",
      "Ep:187, loss:0.00000, loss_test:0.01977, lr:2.36e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.601, tt:7256.921\n",
      "Ep:188, loss:0.00000, loss_test:0.01980, lr:2.33e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.601, tt:7295.660\n",
      "Ep:189, loss:0.00000, loss_test:0.01984, lr:2.31e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.608, tt:7335.558\n",
      "Ep:190, loss:0.00000, loss_test:0.01988, lr:2.29e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.608, tt:7374.164\n",
      "Ep:191, loss:0.00000, loss_test:0.01989, lr:2.26e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.611, tt:7413.272\n",
      "Ep:192, loss:0.00000, loss_test:0.01991, lr:2.24e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.607, tt:7451.122\n",
      "Ep:193, loss:0.00000, loss_test:0.01997, lr:2.22e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.611, tt:7490.550\n",
      "Ep:194, loss:0.00000, loss_test:0.01994, lr:2.20e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.605, tt:7527.993\n",
      "Ep:195, loss:0.00000, loss_test:0.01999, lr:2.17e-02, fs:0.84091 (r=0.747,p=0.961),  time:38.594, tt:7564.491\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 2\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02065, lr:6.00e-02, fs:0.65672 (r=0.889,p=0.521),  time:26.916, tt:26.916\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02541, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.393, tt:60.787\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02772, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.524, tt:91.572\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00006, loss_test:0.02820, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.743, tt:126.973\n",
      "Ep:4, loss:0.00006, loss_test:0.02757, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.156, tt:160.780\n",
      "Ep:5, loss:0.00005, loss_test:0.02600, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:32.655, tt:195.933\n",
      "Ep:6, loss:0.00005, loss_test:0.02399, lr:6.00e-02, fs:0.67606 (r=0.970,p=0.519),  time:33.102, tt:231.715\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00005, loss_test:0.02194, lr:6.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:33.431, tt:267.448\n",
      "Ep:8, loss:0.00005, loss_test:0.02050, lr:6.00e-02, fs:0.67416 (r=0.909,p=0.536),  time:33.587, tt:302.286\n",
      "Ep:9, loss:0.00005, loss_test:0.01952, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:33.767, tt:337.674\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01841, lr:6.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:33.979, tt:373.771\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01788, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:34.051, tt:408.607\n",
      "Ep:12, loss:0.00004, loss_test:0.01769, lr:6.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:34.177, tt:444.296\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01726, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:34.292, tt:480.088\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01681, lr:6.00e-02, fs:0.71264 (r=0.939,p=0.574),  time:34.373, tt:515.601\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01644, lr:6.00e-02, fs:0.72441 (r=0.929,p=0.594),  time:34.447, tt:551.153\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01613, lr:6.00e-02, fs:0.71713 (r=0.909,p=0.592),  time:34.518, tt:586.808\n",
      "Ep:17, loss:0.00004, loss_test:0.01597, lr:6.00e-02, fs:0.71200 (r=0.899,p=0.589),  time:34.458, tt:620.236\n",
      "Ep:18, loss:0.00004, loss_test:0.01584, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:34.494, tt:655.380\n",
      "Ep:19, loss:0.00004, loss_test:0.01571, lr:6.00e-02, fs:0.71937 (r=0.919,p=0.591),  time:34.512, tt:690.243\n",
      "Ep:20, loss:0.00004, loss_test:0.01552, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:34.524, tt:725.007\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:34.534, tt:759.739\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:34.549, tt:794.628\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01501, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:34.569, tt:829.665\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:34.602, tt:865.040\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01484, lr:6.00e-02, fs:0.76033 (r=0.929,p=0.643),  time:34.614, tt:899.953\n",
      "Ep:26, loss:0.00003, loss_test:0.01476, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.588, tt:933.880\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01466, lr:6.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:34.567, tt:967.871\n",
      "Ep:28, loss:0.00003, loss_test:0.01450, lr:6.00e-02, fs:0.76471 (r=0.919,p=0.655),  time:34.565, tt:1002.377\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01438, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:34.611, tt:1038.331\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00003, loss_test:0.01426, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:34.627, tt:1073.434\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01414, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:34.600, tt:1107.211\n",
      "Ep:32, loss:0.00003, loss_test:0.01404, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.681, tt:1144.475\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01395, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.673, tt:1178.895\n",
      "Ep:34, loss:0.00003, loss_test:0.01391, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:34.689, tt:1214.115\n",
      "Ep:35, loss:0.00002, loss_test:0.01388, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:34.671, tt:1248.151\n",
      "Ep:36, loss:0.00002, loss_test:0.01386, lr:6.00e-02, fs:0.74678 (r=0.879,p=0.649),  time:34.658, tt:1282.365\n",
      "Ep:37, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:34.641, tt:1316.343\n",
      "Ep:38, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.655, tt:1351.554\n",
      "Ep:39, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.77922 (r=0.909,p=0.682),  time:34.647, tt:1385.861\n",
      "Ep:40, loss:0.00002, loss_test:0.01377, lr:6.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:34.611, tt:1419.047\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01378, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.615, tt:1453.821\n",
      "Ep:42, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:34.591, tt:1487.424\n",
      "Ep:43, loss:0.00002, loss_test:0.01369, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:34.567, tt:1520.935\n",
      "Ep:44, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:34.558, tt:1555.111\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:34.537, tt:1588.712\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01353, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:34.488, tt:1620.944\n",
      "Ep:47, loss:0.00002, loss_test:0.01342, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:34.586, tt:1660.115\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01337, lr:6.00e-02, fs:0.80000 (r=0.889,p=0.727),  time:34.609, tt:1695.834\n",
      "Ep:49, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.630, tt:1731.488\n",
      "Ep:50, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.625, tt:1765.863\n",
      "Ep:51, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:34.624, tt:1800.463\n",
      "Ep:52, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:34.632, tt:1835.502\n",
      "Ep:53, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:34.641, tt:1870.594\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.668, tt:1906.762\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:34.680, tt:1942.078\n",
      "Ep:56, loss:0.00001, loss_test:0.01283, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.692, tt:1977.421\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01275, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:34.696, tt:2012.380\n",
      "Ep:58, loss:0.00001, loss_test:0.01274, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.713, tt:2048.059\n",
      "Ep:59, loss:0.00001, loss_test:0.01267, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.699, tt:2081.962\n",
      "Ep:60, loss:0.00001, loss_test:0.01269, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.700, tt:2116.719\n",
      "Ep:61, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:34.732, tt:2153.401\n",
      "Ep:62, loss:0.00001, loss_test:0.01249, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.745, tt:2188.904\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.754, tt:2224.226\n",
      "Ep:64, loss:0.00001, loss_test:0.01250, lr:6.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.764, tt:2259.646\n",
      "Ep:65, loss:0.00001, loss_test:0.01272, lr:6.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.779, tt:2295.414\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01256, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:34.812, tt:2332.374\n",
      "Ep:67, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.833, tt:2368.676\n",
      "Ep:68, loss:0.00001, loss_test:0.01254, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:34.839, tt:2403.890\n",
      "Ep:69, loss:0.00001, loss_test:0.01268, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.843, tt:2438.976\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.864, tt:2475.343\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.869, tt:2510.555\n",
      "Ep:72, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:34.867, tt:2545.286\n",
      "Ep:73, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.876, tt:2580.790\n",
      "Ep:74, loss:0.00001, loss_test:0.01271, lr:6.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.872, tt:2615.373\n",
      "Ep:75, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.867, tt:2649.867\n",
      "Ep:76, loss:0.00001, loss_test:0.01275, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.891, tt:2686.585\n",
      "Ep:77, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.887, tt:2721.216\n",
      "Ep:78, loss:0.00001, loss_test:0.01282, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.897, tt:2756.862\n",
      "Ep:79, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.910, tt:2792.768\n",
      "Ep:80, loss:0.00001, loss_test:0.01296, lr:6.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.917, tt:2828.270\n",
      "Ep:81, loss:0.00001, loss_test:0.01317, lr:6.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.933, tt:2864.485\n",
      "Ep:82, loss:0.00001, loss_test:0.01294, lr:5.94e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.926, tt:2898.824\n",
      "Ep:83, loss:0.00001, loss_test:0.01330, lr:5.88e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.920, tt:2933.314\n",
      "Ep:84, loss:0.00001, loss_test:0.01323, lr:5.82e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.930, tt:2969.063\n",
      "Ep:85, loss:0.00001, loss_test:0.01344, lr:5.76e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.944, tt:3005.153\n",
      "Ep:86, loss:0.00001, loss_test:0.01313, lr:5.71e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.954, tt:3040.967\n",
      "Ep:87, loss:0.00001, loss_test:0.01348, lr:5.65e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.959, tt:3076.428\n",
      "Ep:88, loss:0.00001, loss_test:0.01329, lr:5.59e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.966, tt:3112.006\n",
      "Ep:89, loss:0.00001, loss_test:0.01369, lr:5.54e-02, fs:0.84375 (r=0.818,p=0.871),  time:34.981, tt:3148.249\n",
      "Ep:90, loss:0.00001, loss_test:0.01342, lr:5.48e-02, fs:0.83158 (r=0.798,p=0.868),  time:34.984, tt:3183.556\n",
      "Ep:91, loss:0.00001, loss_test:0.01381, lr:5.43e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.965, tt:3216.745\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01358, lr:5.43e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.947, tt:3250.094\n",
      "Ep:93, loss:0.00001, loss_test:0.01391, lr:5.43e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.958, tt:3286.018\n",
      "Ep:94, loss:0.00001, loss_test:0.01379, lr:5.43e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.968, tt:3321.920\n",
      "Ep:95, loss:0.00001, loss_test:0.01392, lr:5.43e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.966, tt:3356.750\n",
      "Ep:96, loss:0.00001, loss_test:0.01395, lr:5.43e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.946, tt:3389.738\n",
      "Ep:97, loss:0.00001, loss_test:0.01392, lr:5.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.947, tt:3424.785\n",
      "Ep:98, loss:0.00001, loss_test:0.01428, lr:5.43e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.953, tt:3460.344\n",
      "Ep:99, loss:0.00001, loss_test:0.01390, lr:5.43e-02, fs:0.81720 (r=0.768,p=0.874),  time:34.951, tt:3495.106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:100, loss:0.00001, loss_test:0.01445, lr:5.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.955, tt:3530.500\n",
      "Ep:101, loss:0.00001, loss_test:0.01411, lr:5.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.938, tt:3563.695\n",
      "Ep:102, loss:0.00001, loss_test:0.01445, lr:5.43e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.933, tt:3598.117\n",
      "Ep:103, loss:0.00001, loss_test:0.01430, lr:5.37e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.938, tt:3633.564\n",
      "Ep:104, loss:0.00000, loss_test:0.01455, lr:5.32e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.946, tt:3669.297\n",
      "Ep:105, loss:0.00000, loss_test:0.01464, lr:5.27e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.931, tt:3702.652\n",
      "Ep:106, loss:0.00000, loss_test:0.01458, lr:5.21e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.925, tt:3736.955\n",
      "Ep:107, loss:0.00000, loss_test:0.01475, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.922, tt:3771.630\n",
      "Ep:108, loss:0.00000, loss_test:0.01473, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.903, tt:3804.459\n",
      "Ep:109, loss:0.00000, loss_test:0.01492, lr:5.06e-02, fs:0.82162 (r=0.768,p=0.884),  time:34.901, tt:3839.091\n",
      "Ep:110, loss:0.00000, loss_test:0.01499, lr:5.01e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.914, tt:3875.461\n",
      "Ep:111, loss:0.00000, loss_test:0.01497, lr:4.96e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.899, tt:3908.687\n",
      "Ep:112, loss:0.00000, loss_test:0.01531, lr:4.91e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.895, tt:3943.089\n",
      "Ep:113, loss:0.00000, loss_test:0.01508, lr:4.86e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.888, tt:3977.216\n",
      "Ep:114, loss:0.00000, loss_test:0.01542, lr:4.81e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.884, tt:4011.717\n",
      "Ep:115, loss:0.00000, loss_test:0.01523, lr:4.76e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.873, tt:4045.215\n",
      "Ep:116, loss:0.00000, loss_test:0.01558, lr:4.71e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.885, tt:4081.526\n",
      "Ep:117, loss:0.00000, loss_test:0.01554, lr:4.67e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.879, tt:4115.777\n",
      "Ep:118, loss:0.00000, loss_test:0.01568, lr:4.62e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.888, tt:4151.695\n",
      "Ep:119, loss:0.00000, loss_test:0.01578, lr:4.57e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.894, tt:4187.317\n",
      "Ep:120, loss:0.00000, loss_test:0.01572, lr:4.53e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.902, tt:4223.124\n",
      "Ep:121, loss:0.00000, loss_test:0.01603, lr:4.48e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.908, tt:4258.735\n",
      "Ep:122, loss:0.00000, loss_test:0.01582, lr:4.44e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.902, tt:4293.001\n",
      "Ep:123, loss:0.00000, loss_test:0.01611, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.909, tt:4328.701\n",
      "Ep:124, loss:0.00000, loss_test:0.01598, lr:4.35e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.904, tt:4363.000\n",
      "Ep:125, loss:0.00000, loss_test:0.01631, lr:4.31e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.911, tt:4398.799\n",
      "Ep:126, loss:0.00000, loss_test:0.01625, lr:4.26e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.910, tt:4433.614\n",
      "Ep:127, loss:0.00000, loss_test:0.01635, lr:4.22e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.911, tt:4468.653\n",
      "Ep:128, loss:0.00000, loss_test:0.01650, lr:4.18e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.903, tt:4502.466\n",
      "Ep:129, loss:0.00000, loss_test:0.01641, lr:4.14e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.898, tt:4536.701\n",
      "Ep:130, loss:0.00000, loss_test:0.01661, lr:4.10e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.893, tt:4570.995\n",
      "Ep:131, loss:0.00000, loss_test:0.01657, lr:4.05e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.891, tt:4605.591\n",
      "Ep:132, loss:0.00000, loss_test:0.01681, lr:4.01e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.888, tt:4640.050\n",
      "Ep:133, loss:0.00000, loss_test:0.01671, lr:3.97e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.882, tt:4674.175\n",
      "Ep:134, loss:0.00000, loss_test:0.01686, lr:3.93e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.890, tt:4710.114\n",
      "Ep:135, loss:0.00000, loss_test:0.01692, lr:3.89e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.891, tt:4745.201\n",
      "Ep:136, loss:0.00000, loss_test:0.01691, lr:3.86e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.888, tt:4779.665\n",
      "Ep:137, loss:0.00000, loss_test:0.01710, lr:3.82e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.879, tt:4813.251\n",
      "Ep:138, loss:0.00000, loss_test:0.01711, lr:3.78e-02, fs:0.83516 (r=0.768,p=0.916),  time:34.873, tt:4847.286\n",
      "Ep:139, loss:0.00000, loss_test:0.01722, lr:3.74e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.859, tt:4880.237\n",
      "Ep:140, loss:0.00000, loss_test:0.01717, lr:3.70e-02, fs:0.83978 (r=0.768,p=0.927),  time:34.853, tt:4914.334\n",
      "Ep:141, loss:0.00000, loss_test:0.01736, lr:3.67e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.848, tt:4948.425\n",
      "Ep:142, loss:0.00000, loss_test:0.01731, lr:3.63e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.849, tt:4983.399\n",
      "Ep:143, loss:0.00000, loss_test:0.01746, lr:3.59e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.840, tt:5016.974\n",
      "Ep:144, loss:0.00000, loss_test:0.01752, lr:3.56e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.826, tt:5049.752\n",
      "Ep:145, loss:0.00000, loss_test:0.01749, lr:3.52e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.813, tt:5082.747\n",
      "Ep:146, loss:0.00000, loss_test:0.01762, lr:3.49e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.809, tt:5116.913\n",
      "Ep:147, loss:0.00000, loss_test:0.01765, lr:3.45e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.806, tt:5151.225\n",
      "Ep:148, loss:0.00000, loss_test:0.01771, lr:3.42e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.793, tt:5184.195\n",
      "Ep:149, loss:0.00000, loss_test:0.01783, lr:3.38e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.803, tt:5220.514\n",
      "Ep:150, loss:0.00000, loss_test:0.01781, lr:3.35e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.785, tt:5252.469\n",
      "Ep:151, loss:0.00000, loss_test:0.01800, lr:3.32e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.758, tt:5283.269\n",
      "Ep:152, loss:0.00000, loss_test:0.01782, lr:3.28e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.754, tt:5317.357\n",
      "Ep:153, loss:0.00000, loss_test:0.01797, lr:3.25e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.752, tt:5351.748\n",
      "Ep:154, loss:0.00000, loss_test:0.01803, lr:3.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.733, tt:5383.660\n",
      "Ep:155, loss:0.00000, loss_test:0.01808, lr:3.19e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.732, tt:5418.187\n",
      "Ep:156, loss:0.00000, loss_test:0.01813, lr:3.15e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.730, tt:5452.554\n",
      "Ep:157, loss:0.00000, loss_test:0.01817, lr:3.12e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.737, tt:5488.493\n",
      "Ep:158, loss:0.00000, loss_test:0.01821, lr:3.09e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.743, tt:5524.134\n",
      "Ep:159, loss:0.00000, loss_test:0.01837, lr:3.06e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.755, tt:5560.765\n",
      "Ep:160, loss:0.00000, loss_test:0.01825, lr:3.03e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.757, tt:5595.859\n",
      "Ep:161, loss:0.00000, loss_test:0.01842, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.765, tt:5631.949\n",
      "##########Best model found so far##########\n",
      "Ep:162, loss:0.00000, loss_test:0.01838, lr:3.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:34.766, tt:5666.842\n",
      "Ep:163, loss:0.00000, loss_test:0.01844, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.774, tt:5702.930\n",
      "Ep:164, loss:0.00000, loss_test:0.01854, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.769, tt:5736.929\n",
      "Ep:165, loss:0.00000, loss_test:0.01853, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.776, tt:5772.879\n",
      "Ep:166, loss:0.00000, loss_test:0.01868, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.768, tt:5806.333\n",
      "Ep:167, loss:0.00000, loss_test:0.01864, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.774, tt:5841.976\n",
      "Ep:168, loss:0.00000, loss_test:0.01873, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.782, tt:5878.098\n",
      "Ep:169, loss:0.00000, loss_test:0.01879, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.789, tt:5914.145\n",
      "Ep:170, loss:0.00000, loss_test:0.01874, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.791, tt:5949.260\n",
      "Ep:171, loss:0.00000, loss_test:0.01894, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.798, tt:5985.300\n",
      "##########Best model found so far##########\n",
      "Ep:172, loss:0.00000, loss_test:0.01884, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.802, tt:6020.706\n",
      "Ep:173, loss:0.00000, loss_test:0.01893, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.802, tt:6055.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:174, loss:0.00000, loss_test:0.01901, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.813, tt:6092.324\n",
      "Ep:175, loss:0.00000, loss_test:0.01898, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.821, tt:6128.440\n",
      "Ep:176, loss:0.00000, loss_test:0.01916, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.829, tt:6164.664\n",
      "Ep:177, loss:0.00000, loss_test:0.01908, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.839, tt:6201.306\n",
      "Ep:178, loss:0.00000, loss_test:0.01919, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.836, tt:6235.697\n",
      "Ep:179, loss:0.00000, loss_test:0.01927, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.840, tt:6271.150\n",
      "Ep:180, loss:0.00000, loss_test:0.01918, lr:3.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:34.852, tt:6308.196\n",
      "Ep:181, loss:0.00000, loss_test:0.01936, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.859, tt:6344.251\n",
      "Ep:182, loss:0.00000, loss_test:0.01935, lr:3.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.854, tt:6378.351\n",
      "Ep:183, loss:0.00000, loss_test:0.01940, lr:2.97e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.856, tt:6413.449\n",
      "Ep:184, loss:0.00000, loss_test:0.01944, lr:2.94e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.863, tt:6449.715\n",
      "Ep:185, loss:0.00000, loss_test:0.01951, lr:2.91e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.866, tt:6485.098\n",
      "Ep:186, loss:0.00000, loss_test:0.01956, lr:2.88e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.866, tt:6519.872\n",
      "Ep:187, loss:0.00000, loss_test:0.01960, lr:2.85e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.864, tt:6554.407\n",
      "Ep:188, loss:0.00000, loss_test:0.01963, lr:2.82e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.863, tt:6589.098\n",
      "Ep:189, loss:0.00000, loss_test:0.01968, lr:2.80e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.867, tt:6624.754\n",
      "Ep:190, loss:0.00000, loss_test:0.01972, lr:2.77e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.865, tt:6659.296\n",
      "Ep:191, loss:0.00000, loss_test:0.01979, lr:2.74e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.866, tt:6694.341\n",
      "Ep:192, loss:0.00000, loss_test:0.01974, lr:2.71e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.867, tt:6729.354\n",
      "Ep:193, loss:0.00000, loss_test:0.01982, lr:2.69e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.873, tt:6765.337\n",
      "Ep:194, loss:0.00000, loss_test:0.01988, lr:2.66e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.873, tt:6800.252\n",
      "Ep:195, loss:0.00000, loss_test:0.01991, lr:2.63e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.870, tt:6834.504\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"3-3\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14428, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.406, tt:38.406\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14335, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.058, tt:86.117\n",
      "Ep:2, loss:0.00028, loss_test:0.14170, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.605, tt:136.815\n",
      "Ep:3, loss:0.00028, loss_test:0.13901, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:46.949, tt:187.797\n",
      "Ep:4, loss:0.00027, loss_test:0.13458, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.656, tt:238.280\n",
      "Ep:5, loss:0.00026, loss_test:0.12685, lr:1.00e-02, fs:0.67820 (r=0.990,p=0.516),  time:48.078, tt:288.470\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11560, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:48.468, tt:339.275\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10875, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:48.794, tt:390.348\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10676, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:49.227, tt:443.042\n",
      "Ep:9, loss:0.00021, loss_test:0.10516, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:49.672, tt:496.722\n",
      "Ep:10, loss:0.00021, loss_test:0.10290, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:49.668, tt:546.346\n",
      "Ep:11, loss:0.00020, loss_test:0.10018, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:50.043, tt:600.513\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09895, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:50.272, tt:653.537\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09730, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:50.397, tt:705.556\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09503, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:50.426, tt:756.395\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09351, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:50.410, tt:806.566\n",
      "Ep:16, loss:0.00017, loss_test:0.09243, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:50.343, tt:855.829\n",
      "Ep:17, loss:0.00017, loss_test:0.09145, lr:1.00e-02, fs:0.75000 (r=0.758,p=0.743),  time:50.406, tt:907.306\n",
      "Ep:18, loss:0.00016, loss_test:0.09072, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:50.529, tt:960.049\n",
      "Ep:19, loss:0.00016, loss_test:0.08924, lr:1.00e-02, fs:0.75758 (r=0.758,p=0.758),  time:50.574, tt:1011.477\n",
      "Ep:20, loss:0.00015, loss_test:0.08763, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:50.586, tt:1062.314\n",
      "Ep:21, loss:0.00015, loss_test:0.08521, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:50.634, tt:1113.942\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08484, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:50.670, tt:1165.404\n",
      "Ep:23, loss:0.00014, loss_test:0.08230, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:50.585, tt:1214.045\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08145, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:50.601, tt:1265.026\n",
      "Ep:25, loss:0.00013, loss_test:0.07964, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:50.613, tt:1315.943\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07840, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:50.624, tt:1366.835\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07869, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:50.566, tt:1415.860\n",
      "Ep:28, loss:0.00013, loss_test:0.07607, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:50.597, tt:1467.316\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07854, lr:1.00e-02, fs:0.78261 (r=0.727,p=0.847),  time:50.660, tt:1519.792\n",
      "Ep:30, loss:0.00012, loss_test:0.07374, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:50.773, tt:1573.955\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07713, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:50.823, tt:1626.324\n",
      "Ep:32, loss:0.00012, loss_test:0.07153, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:50.951, tt:1681.393\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07351, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:50.969, tt:1732.944\n",
      "Ep:34, loss:0.00011, loss_test:0.06937, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:50.980, tt:1784.285\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07125, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:51.001, tt:1836.038\n",
      "Ep:36, loss:0.00010, loss_test:0.06704, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:51.031, tt:1888.162\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.06795, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:51.022, tt:1938.852\n",
      "Ep:38, loss:0.00010, loss_test:0.06936, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.079, tt:1992.070\n",
      "Ep:39, loss:0.00010, loss_test:0.06519, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:51.080, tt:2043.197\n",
      "Ep:40, loss:0.00009, loss_test:0.07161, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:51.077, tt:2094.160\n",
      "Ep:41, loss:0.00009, loss_test:0.06389, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:51.075, tt:2145.146\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.06660, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.130, tt:2198.600\n",
      "Ep:43, loss:0.00009, loss_test:0.06669, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:51.155, tt:2250.814\n",
      "Ep:44, loss:0.00008, loss_test:0.06310, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:51.171, tt:2302.677\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06959, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:51.159, tt:2353.336\n",
      "Ep:46, loss:0.00008, loss_test:0.06327, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:51.189, tt:2405.874\n",
      "Ep:47, loss:0.00008, loss_test:0.06874, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:51.189, tt:2457.081\n",
      "Ep:48, loss:0.00008, loss_test:0.06026, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:51.179, tt:2507.778\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.06478, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:51.175, tt:2558.746\n",
      "Ep:50, loss:0.00007, loss_test:0.05811, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:51.206, tt:2611.507\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06281, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:51.224, tt:2663.671\n",
      "Ep:52, loss:0.00007, loss_test:0.05725, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:51.286, tt:2718.136\n",
      "Ep:53, loss:0.00007, loss_test:0.05790, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:51.289, tt:2769.596\n",
      "Ep:54, loss:0.00006, loss_test:0.05846, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:51.301, tt:2821.545\n",
      "Ep:55, loss:0.00006, loss_test:0.05588, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:51.339, tt:2874.970\n",
      "Ep:56, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:51.319, tt:2925.182\n",
      "Ep:57, loss:0.00006, loss_test:0.05562, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:51.316, tt:2976.345\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.06240, lr:1.00e-02, fs:0.85876 (r=0.768,p=0.974),  time:51.321, tt:3027.954\n",
      "Ep:59, loss:0.00005, loss_test:0.05471, lr:1.00e-02, fs:0.91837 (r=0.909,p=0.928),  time:51.354, tt:3081.263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.05734, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:51.339, tt:3131.697\n",
      "Ep:61, loss:0.00005, loss_test:0.05660, lr:1.00e-02, fs:0.89362 (r=0.848,p=0.944),  time:51.327, tt:3182.252\n",
      "Ep:62, loss:0.00005, loss_test:0.05683, lr:1.00e-02, fs:0.85556 (r=0.778,p=0.951),  time:51.324, tt:3233.408\n",
      "Ep:63, loss:0.00004, loss_test:0.05315, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:51.319, tt:3284.408\n",
      "Ep:64, loss:0.00004, loss_test:0.05807, lr:1.00e-02, fs:0.85393 (r=0.768,p=0.962),  time:51.378, tt:3339.585\n",
      "Ep:65, loss:0.00004, loss_test:0.05751, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:51.356, tt:3389.501\n",
      "Ep:66, loss:0.00004, loss_test:0.05603, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:51.357, tt:3440.887\n",
      "Ep:67, loss:0.00004, loss_test:0.05599, lr:1.00e-02, fs:0.84916 (r=0.768,p=0.950),  time:51.388, tt:3494.392\n",
      "Ep:68, loss:0.00004, loss_test:0.05643, lr:1.00e-02, fs:0.86034 (r=0.778,p=0.963),  time:51.411, tt:3547.332\n",
      "Ep:69, loss:0.00004, loss_test:0.05721, lr:9.90e-03, fs:0.84746 (r=0.758,p=0.962),  time:51.423, tt:3599.628\n",
      "Ep:70, loss:0.00003, loss_test:0.05460, lr:9.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:51.434, tt:3651.799\n",
      "Ep:71, loss:0.00003, loss_test:0.05989, lr:9.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.409, tt:3701.414\n",
      "Ep:72, loss:0.00003, loss_test:0.06423, lr:9.61e-03, fs:0.84571 (r=0.747,p=0.974),  time:51.406, tt:3752.620\n",
      "Ep:73, loss:0.00003, loss_test:0.05523, lr:9.51e-03, fs:0.88770 (r=0.838,p=0.943),  time:51.406, tt:3804.068\n",
      "Ep:74, loss:0.00003, loss_test:0.05835, lr:9.41e-03, fs:0.84746 (r=0.758,p=0.962),  time:51.401, tt:3855.102\n",
      "Ep:75, loss:0.00003, loss_test:0.06359, lr:9.32e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.385, tt:3905.222\n",
      "Ep:76, loss:0.00003, loss_test:0.05370, lr:9.23e-03, fs:0.86813 (r=0.798,p=0.952),  time:51.397, tt:3957.544\n",
      "Ep:77, loss:0.00003, loss_test:0.06126, lr:9.14e-03, fs:0.85227 (r=0.758,p=0.974),  time:51.416, tt:4010.472\n",
      "Ep:78, loss:0.00003, loss_test:0.05760, lr:9.04e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.413, tt:4061.607\n",
      "Ep:79, loss:0.00003, loss_test:0.05584, lr:8.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:51.421, tt:4113.666\n",
      "Ep:80, loss:0.00003, loss_test:0.05824, lr:8.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.414, tt:4164.533\n",
      "Ep:81, loss:0.00002, loss_test:0.06290, lr:8.78e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.454, tt:4219.267\n",
      "Ep:82, loss:0.00002, loss_test:0.05401, lr:8.69e-03, fs:0.85556 (r=0.778,p=0.951),  time:51.465, tt:4271.572\n",
      "Ep:83, loss:0.00002, loss_test:0.06593, lr:8.60e-03, fs:0.84571 (r=0.747,p=0.974),  time:51.470, tt:4323.440\n",
      "Ep:84, loss:0.00002, loss_test:0.05916, lr:8.51e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.478, tt:4375.654\n",
      "Ep:85, loss:0.00002, loss_test:0.06478, lr:8.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.498, tt:4428.834\n",
      "Ep:86, loss:0.00002, loss_test:0.05939, lr:8.35e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.492, tt:4479.803\n",
      "Ep:87, loss:0.00002, loss_test:0.06344, lr:8.26e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.505, tt:4532.439\n",
      "Ep:88, loss:0.00002, loss_test:0.06049, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.490, tt:4582.640\n",
      "Ep:89, loss:0.00002, loss_test:0.06252, lr:8.10e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.475, tt:4632.756\n",
      "Ep:90, loss:0.00002, loss_test:0.06153, lr:8.02e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.451, tt:4682.028\n",
      "Ep:91, loss:0.00002, loss_test:0.06462, lr:7.94e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.438, tt:4732.305\n",
      "Ep:92, loss:0.00002, loss_test:0.06348, lr:7.86e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.441, tt:4784.008\n",
      "Ep:93, loss:0.00002, loss_test:0.06332, lr:7.78e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.456, tt:4836.910\n",
      "Ep:94, loss:0.00002, loss_test:0.06492, lr:7.70e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.456, tt:4888.293\n",
      "Ep:95, loss:0.00001, loss_test:0.06153, lr:7.62e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.450, tt:4939.185\n",
      "Ep:96, loss:0.00001, loss_test:0.06801, lr:7.55e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.450, tt:4990.686\n",
      "Ep:97, loss:0.00001, loss_test:0.06003, lr:7.47e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.461, tt:5043.192\n",
      "Ep:98, loss:0.00001, loss_test:0.07211, lr:7.40e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.455, tt:5094.057\n",
      "Ep:99, loss:0.00001, loss_test:0.06048, lr:7.32e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.442, tt:5144.155\n",
      "Ep:100, loss:0.00001, loss_test:0.07227, lr:7.25e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.447, tt:5196.171\n",
      "Ep:101, loss:0.00001, loss_test:0.06116, lr:7.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.465, tt:5249.406\n",
      "Ep:102, loss:0.00001, loss_test:0.07389, lr:7.11e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.456, tt:5299.969\n",
      "Ep:103, loss:0.00001, loss_test:0.06182, lr:7.03e-03, fs:0.85393 (r=0.768,p=0.962),  time:51.449, tt:5350.682\n",
      "Ep:104, loss:0.00001, loss_test:0.07368, lr:6.96e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.437, tt:5400.913\n",
      "Ep:105, loss:0.00001, loss_test:0.06281, lr:6.89e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.458, tt:5454.516\n",
      "Ep:106, loss:0.00001, loss_test:0.07343, lr:6.83e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.439, tt:5503.982\n",
      "Ep:107, loss:0.00001, loss_test:0.06446, lr:6.76e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.439, tt:5555.397\n",
      "Ep:108, loss:0.00001, loss_test:0.07408, lr:6.69e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.446, tt:5607.580\n",
      "Ep:109, loss:0.00001, loss_test:0.06857, lr:6.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.452, tt:5659.676\n",
      "Ep:110, loss:0.00001, loss_test:0.06742, lr:6.56e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.448, tt:5710.752\n",
      "Ep:111, loss:0.00001, loss_test:0.07135, lr:6.49e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.421, tt:5759.207\n",
      "Ep:112, loss:0.00001, loss_test:0.06449, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.449, tt:5813.710\n",
      "Ep:113, loss:0.00001, loss_test:0.07368, lr:6.36e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.439, tt:5864.023\n",
      "Ep:114, loss:0.00001, loss_test:0.06412, lr:6.30e-03, fs:0.85876 (r=0.768,p=0.974),  time:51.432, tt:5914.689\n",
      "Ep:115, loss:0.00001, loss_test:0.07061, lr:6.24e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.429, tt:5965.750\n",
      "Ep:116, loss:0.00001, loss_test:0.06820, lr:6.17e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.416, tt:6015.631\n",
      "Ep:117, loss:0.00001, loss_test:0.06636, lr:6.11e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.417, tt:6067.162\n",
      "Ep:118, loss:0.00001, loss_test:0.07171, lr:6.05e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.435, tt:6120.757\n",
      "Ep:119, loss:0.00001, loss_test:0.06657, lr:5.99e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.437, tt:6172.408\n",
      "Ep:120, loss:0.00001, loss_test:0.07099, lr:5.93e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.443, tt:6224.608\n",
      "Ep:121, loss:0.00001, loss_test:0.06726, lr:5.87e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.440, tt:6275.639\n",
      "Ep:122, loss:0.00001, loss_test:0.07143, lr:5.81e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.434, tt:6326.350\n",
      "Ep:123, loss:0.00001, loss_test:0.06783, lr:5.75e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.450, tt:6379.806\n",
      "Ep:124, loss:0.00001, loss_test:0.06966, lr:5.70e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.441, tt:6430.120\n",
      "Ep:125, loss:0.00001, loss_test:0.06853, lr:5.64e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.423, tt:6479.351\n",
      "Ep:126, loss:0.00001, loss_test:0.06823, lr:5.58e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.423, tt:6530.692\n",
      "Ep:127, loss:0.00001, loss_test:0.06949, lr:5.53e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.407, tt:6580.040\n",
      "Ep:128, loss:0.00001, loss_test:0.06921, lr:5.47e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.407, tt:6631.446\n",
      "Ep:129, loss:0.00001, loss_test:0.06824, lr:5.42e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.428, tt:6685.702\n",
      "Ep:130, loss:0.00001, loss_test:0.06940, lr:5.36e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.439, tt:6738.556\n",
      "Ep:131, loss:0.00001, loss_test:0.06799, lr:5.31e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.447, tt:6791.038\n",
      "Ep:132, loss:0.00001, loss_test:0.07024, lr:5.26e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.472, tt:6845.821\n",
      "Ep:133, loss:0.00001, loss_test:0.06973, lr:5.20e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.483, tt:6898.756\n",
      "Ep:134, loss:0.00001, loss_test:0.06949, lr:5.15e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.488, tt:6950.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00001, loss_test:0.07050, lr:5.10e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.501, tt:7004.108\n",
      "Ep:136, loss:0.00001, loss_test:0.06945, lr:5.05e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.516, tt:7057.740\n",
      "Ep:137, loss:0.00001, loss_test:0.07010, lr:5.00e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.530, tt:7111.200\n",
      "Ep:138, loss:0.00001, loss_test:0.07058, lr:4.95e-03, fs:0.83041 (r=0.717,p=0.986),  time:51.558, tt:7166.517\n",
      "Ep:139, loss:0.00001, loss_test:0.06944, lr:4.90e-03, fs:0.86364 (r=0.768,p=0.987),  time:51.567, tt:7219.340\n",
      "Ep:140, loss:0.00001, loss_test:0.07226, lr:4.85e-03, fs:0.80952 (r=0.687,p=0.986),  time:51.592, tt:7274.521\n",
      "Ep:141, loss:0.00001, loss_test:0.07170, lr:4.80e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.596, tt:7326.689\n",
      "Ep:142, loss:0.00001, loss_test:0.06908, lr:4.75e-03, fs:0.85714 (r=0.758,p=0.987),  time:51.601, tt:7378.953\n",
      "Ep:143, loss:0.00001, loss_test:0.07155, lr:4.71e-03, fs:0.83041 (r=0.717,p=0.986),  time:51.634, tt:7435.308\n",
      "Ep:144, loss:0.00001, loss_test:0.07113, lr:4.66e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.641, tt:7487.899\n",
      "Ep:145, loss:0.00001, loss_test:0.07016, lr:4.61e-03, fs:0.85057 (r=0.747,p=0.987),  time:51.639, tt:7539.291\n",
      "Ep:146, loss:0.00001, loss_test:0.07186, lr:4.57e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.641, tt:7591.199\n",
      "Ep:147, loss:0.00000, loss_test:0.06974, lr:4.52e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.642, tt:7642.976\n",
      "Ep:148, loss:0.00000, loss_test:0.07101, lr:4.48e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.651, tt:7696.066\n",
      "Ep:149, loss:0.00000, loss_test:0.07267, lr:4.43e-03, fs:0.79518 (r=0.667,p=0.985),  time:51.656, tt:7748.364\n",
      "Ep:150, loss:0.00000, loss_test:0.06974, lr:4.39e-03, fs:0.84393 (r=0.737,p=0.986),  time:51.665, tt:7801.391\n",
      "Ep:151, loss:0.00000, loss_test:0.07245, lr:4.34e-03, fs:0.80240 (r=0.677,p=0.985),  time:51.665, tt:7853.128\n",
      "Ep:152, loss:0.00000, loss_test:0.07078, lr:4.30e-03, fs:0.83721 (r=0.727,p=0.986),  time:51.687, tt:7908.059\n",
      "Ep:153, loss:0.00000, loss_test:0.07222, lr:4.26e-03, fs:0.80952 (r=0.687,p=0.986),  time:51.693, tt:7960.796\n",
      "Ep:154, loss:0.00000, loss_test:0.07202, lr:4.21e-03, fs:0.81657 (r=0.697,p=0.986),  time:51.696, tt:8012.947\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14439, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.796, tt:50.796\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14339, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:47.159, tt:94.318\n",
      "Ep:2, loss:0.00028, loss_test:0.14161, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:48.954, tt:146.862\n",
      "Ep:3, loss:0.00027, loss_test:0.13854, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:49.975, tt:199.898\n",
      "Ep:4, loss:0.00027, loss_test:0.13313, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:50.504, tt:252.519\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12451, lr:1.00e-02, fs:0.69818 (r=0.970,p=0.545),  time:51.136, tt:306.813\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11562, lr:1.00e-02, fs:0.68908 (r=0.828,p=0.590),  time:51.411, tt:359.877\n",
      "Ep:7, loss:0.00022, loss_test:0.11367, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:51.626, tt:413.004\n",
      "Ep:8, loss:0.00021, loss_test:0.11506, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:52.130, tt:469.169\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.11134, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:52.270, tt:522.701\n",
      "Ep:10, loss:0.00020, loss_test:0.10878, lr:1.00e-02, fs:0.71111 (r=0.808,p=0.635),  time:52.299, tt:575.289\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10696, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:52.306, tt:627.675\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.10800, lr:1.00e-02, fs:0.71429 (r=0.758,p=0.676),  time:52.251, tt:679.269\n",
      "Ep:13, loss:0.00018, loss_test:0.10598, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:52.204, tt:730.853\n",
      "Ep:14, loss:0.00017, loss_test:0.10422, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:52.301, tt:784.513\n",
      "Ep:15, loss:0.00017, loss_test:0.10349, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:52.335, tt:837.354\n",
      "Ep:16, loss:0.00017, loss_test:0.10202, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:52.462, tt:891.861\n",
      "Ep:17, loss:0.00016, loss_test:0.10019, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:52.515, tt:945.269\n",
      "Ep:18, loss:0.00016, loss_test:0.09891, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:52.553, tt:998.516\n",
      "Ep:19, loss:0.00015, loss_test:0.09786, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:52.546, tt:1050.922\n",
      "Ep:20, loss:0.00015, loss_test:0.09576, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:52.536, tt:1103.246\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.09544, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:52.434, tt:1153.543\n",
      "Ep:22, loss:0.00014, loss_test:0.09360, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:52.407, tt:1205.352\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.09310, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:52.233, tt:1253.599\n",
      "Ep:24, loss:0.00013, loss_test:0.09182, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:52.277, tt:1306.918\n",
      "Ep:25, loss:0.00013, loss_test:0.09035, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:52.304, tt:1359.898\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09220, lr:1.00e-02, fs:0.74396 (r=0.778,p=0.713),  time:52.375, tt:1414.121\n",
      "Ep:27, loss:0.00012, loss_test:0.08964, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:52.427, tt:1467.956\n",
      "Ep:28, loss:0.00012, loss_test:0.08865, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:52.417, tt:1520.093\n",
      "Ep:29, loss:0.00012, loss_test:0.08937, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:52.486, tt:1574.575\n",
      "Ep:30, loss:0.00012, loss_test:0.08622, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:52.498, tt:1627.441\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.08661, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:52.466, tt:1678.910\n",
      "Ep:32, loss:0.00011, loss_test:0.08553, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:52.440, tt:1730.535\n",
      "Ep:33, loss:0.00011, loss_test:0.08487, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.569, tt:1787.341\n",
      "Ep:34, loss:0.00010, loss_test:0.08509, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:52.648, tt:1842.685\n",
      "Ep:35, loss:0.00010, loss_test:0.08386, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:52.623, tt:1894.426\n",
      "Ep:36, loss:0.00010, loss_test:0.08414, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:52.645, tt:1947.858\n",
      "Ep:37, loss:0.00010, loss_test:0.08327, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.634, tt:2000.098\n",
      "Ep:38, loss:0.00009, loss_test:0.08357, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:52.659, tt:2053.684\n",
      "Ep:39, loss:0.00009, loss_test:0.08261, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.706, tt:2108.235\n",
      "Ep:40, loss:0.00009, loss_test:0.08219, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:52.717, tt:2161.403\n",
      "Ep:41, loss:0.00009, loss_test:0.08228, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:52.781, tt:2216.803\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.08201, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:52.883, tt:2273.950\n",
      "Ep:43, loss:0.00008, loss_test:0.08131, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:52.965, tt:2330.477\n",
      "Ep:44, loss:0.00008, loss_test:0.08145, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:53.005, tt:2385.245\n",
      "Ep:45, loss:0.00008, loss_test:0.08126, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:52.992, tt:2437.620\n",
      "Ep:46, loss:0.00007, loss_test:0.08086, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:53.035, tt:2492.644\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00007, loss_test:0.08355, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:53.082, tt:2547.956\n",
      "Ep:48, loss:0.00008, loss_test:0.07996, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.091, tt:2601.450\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.09696, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:53.122, tt:2656.089\n",
      "Ep:50, loss:0.00009, loss_test:0.08251, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:53.132, tt:2709.730\n",
      "Ep:51, loss:0.00008, loss_test:0.08348, lr:1.00e-02, fs:0.79310 (r=0.697,p=0.920),  time:53.155, tt:2764.076\n",
      "Ep:52, loss:0.00008, loss_test:0.08443, lr:1.00e-02, fs:0.77778 (r=0.778,p=0.778),  time:53.202, tt:2819.691\n",
      "Ep:53, loss:0.00007, loss_test:0.08298, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:53.215, tt:2873.586\n",
      "Ep:54, loss:0.00007, loss_test:0.08213, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:53.246, tt:2928.544\n",
      "Ep:55, loss:0.00007, loss_test:0.07988, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:53.272, tt:2983.209\n",
      "Ep:56, loss:0.00006, loss_test:0.07848, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:53.253, tt:3035.414\n",
      "Ep:57, loss:0.00006, loss_test:0.07682, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:53.272, tt:3089.802\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.07870, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.226, tt:3140.343\n",
      "Ep:59, loss:0.00005, loss_test:0.07918, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:53.240, tt:3194.399\n",
      "Ep:60, loss:0.00005, loss_test:0.08123, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:53.285, tt:3250.387\n",
      "Ep:61, loss:0.00005, loss_test:0.07775, lr:1.00e-02, fs:0.79545 (r=0.707,p=0.909),  time:53.314, tt:3305.455\n",
      "Ep:62, loss:0.00005, loss_test:0.08362, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:53.315, tt:3358.820\n",
      "Ep:63, loss:0.00005, loss_test:0.07876, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:53.305, tt:3411.540\n",
      "Ep:64, loss:0.00005, loss_test:0.08345, lr:1.00e-02, fs:0.80000 (r=0.707,p=0.921),  time:53.314, tt:3465.383\n",
      "Ep:65, loss:0.00005, loss_test:0.08252, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:53.319, tt:3519.083\n",
      "Ep:66, loss:0.00004, loss_test:0.07805, lr:1.00e-02, fs:0.80226 (r=0.717,p=0.910),  time:53.322, tt:3572.549\n",
      "Ep:67, loss:0.00004, loss_test:0.08054, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:53.298, tt:3624.288\n",
      "Ep:68, loss:0.00004, loss_test:0.07473, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:53.323, tt:3679.311\n",
      "Ep:69, loss:0.00004, loss_test:0.08011, lr:9.90e-03, fs:0.82022 (r=0.737,p=0.924),  time:53.312, tt:3731.838\n",
      "Ep:70, loss:0.00003, loss_test:0.07906, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:53.277, tt:3782.674\n",
      "Ep:71, loss:0.00003, loss_test:0.08109, lr:9.70e-03, fs:0.82955 (r=0.737,p=0.948),  time:53.251, tt:3834.086\n",
      "Ep:72, loss:0.00003, loss_test:0.07846, lr:9.61e-03, fs:0.79775 (r=0.717,p=0.899),  time:53.247, tt:3887.026\n",
      "Ep:73, loss:0.00003, loss_test:0.07869, lr:9.51e-03, fs:0.82022 (r=0.737,p=0.924),  time:53.241, tt:3939.858\n",
      "Ep:74, loss:0.00003, loss_test:0.08216, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:53.227, tt:3992.038\n",
      "Ep:75, loss:0.00003, loss_test:0.08006, lr:9.32e-03, fs:0.81564 (r=0.737,p=0.912),  time:53.245, tt:4046.637\n",
      "Ep:76, loss:0.00003, loss_test:0.08285, lr:9.23e-03, fs:0.80226 (r=0.717,p=0.910),  time:53.240, tt:4099.482\n",
      "Ep:77, loss:0.00003, loss_test:0.08129, lr:9.14e-03, fs:0.82081 (r=0.717,p=0.959),  time:53.254, tt:4153.847\n",
      "Ep:78, loss:0.00003, loss_test:0.08219, lr:9.04e-03, fs:0.80899 (r=0.727,p=0.911),  time:53.247, tt:4206.534\n",
      "Ep:79, loss:0.00002, loss_test:0.08254, lr:8.95e-03, fs:0.82081 (r=0.717,p=0.959),  time:53.256, tt:4260.509\n",
      "Ep:80, loss:0.00002, loss_test:0.08104, lr:8.86e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.267, tt:4314.610\n",
      "Ep:81, loss:0.00002, loss_test:0.08519, lr:8.78e-03, fs:0.81143 (r=0.717,p=0.934),  time:53.225, tt:4364.444\n",
      "Ep:82, loss:0.00002, loss_test:0.08530, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.157, tt:4412.016\n",
      "Ep:83, loss:0.00002, loss_test:0.08752, lr:8.60e-03, fs:0.82558 (r=0.717,p=0.973),  time:53.084, tt:4459.075\n",
      "Ep:84, loss:0.00002, loss_test:0.08192, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:53.019, tt:4506.646\n",
      "Ep:85, loss:0.00002, loss_test:0.08883, lr:8.43e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.959, tt:4554.487\n",
      "Ep:86, loss:0.00002, loss_test:0.08199, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.975, tt:4608.855\n",
      "Ep:87, loss:0.00002, loss_test:0.08360, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.984, tt:4662.594\n",
      "Ep:88, loss:0.00002, loss_test:0.08707, lr:8.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.985, tt:4715.698\n",
      "Ep:89, loss:0.00002, loss_test:0.08296, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.994, tt:4769.457\n",
      "Ep:90, loss:0.00002, loss_test:0.09035, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.968, tt:4820.053\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.08249, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.990, tt:4875.060\n",
      "Ep:92, loss:0.00002, loss_test:0.08928, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.965, tt:4925.770\n",
      "Ep:93, loss:0.00002, loss_test:0.09073, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.946, tt:4976.958\n",
      "Ep:94, loss:0.00002, loss_test:0.08670, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.931, tt:5028.431\n",
      "Ep:95, loss:0.00002, loss_test:0.09110, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.912, tt:5079.562\n",
      "Ep:96, loss:0.00002, loss_test:0.08870, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.899, tt:5131.169\n",
      "Ep:97, loss:0.00001, loss_test:0.08921, lr:8.02e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.897, tt:5183.948\n",
      "Ep:98, loss:0.00001, loss_test:0.08861, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.888, tt:5235.900\n",
      "Ep:99, loss:0.00002, loss_test:0.08649, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.887, tt:5288.724\n",
      "Ep:100, loss:0.00001, loss_test:0.09110, lr:8.02e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.886, tt:5341.515\n",
      "Ep:101, loss:0.00001, loss_test:0.08884, lr:8.02e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.882, tt:5394.007\n",
      "Ep:102, loss:0.00001, loss_test:0.09003, lr:7.94e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.869, tt:5445.540\n",
      "Ep:103, loss:0.00001, loss_test:0.09132, lr:7.86e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.872, tt:5498.648\n",
      "Ep:104, loss:0.00001, loss_test:0.09199, lr:7.78e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.878, tt:5552.182\n",
      "Ep:105, loss:0.00001, loss_test:0.09361, lr:7.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.889, tt:5606.226\n",
      "Ep:106, loss:0.00001, loss_test:0.09020, lr:7.62e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.869, tt:5656.966\n",
      "Ep:107, loss:0.00001, loss_test:0.09665, lr:7.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.862, tt:5709.150\n",
      "Ep:108, loss:0.00001, loss_test:0.09013, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.851, tt:5760.754\n",
      "Ep:109, loss:0.00001, loss_test:0.09803, lr:7.40e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.850, tt:5813.501\n",
      "Ep:110, loss:0.00001, loss_test:0.09522, lr:7.32e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.858, tt:5867.292\n",
      "Ep:111, loss:0.00001, loss_test:0.08969, lr:7.25e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.860, tt:5920.355\n",
      "Ep:112, loss:0.00001, loss_test:0.09740, lr:7.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.858, tt:5972.902\n",
      "Ep:113, loss:0.00001, loss_test:0.09366, lr:7.11e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.836, tt:6023.326\n",
      "Ep:114, loss:0.00001, loss_test:0.09381, lr:7.03e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.821, tt:6074.469\n",
      "Ep:115, loss:0.00001, loss_test:0.09465, lr:6.96e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.816, tt:6126.680\n",
      "Ep:116, loss:0.00001, loss_test:0.09489, lr:6.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.807, tt:6178.379\n",
      "Ep:117, loss:0.00001, loss_test:0.09237, lr:6.83e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.800, tt:6230.371\n",
      "Ep:118, loss:0.00001, loss_test:0.09477, lr:6.76e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.784, tt:6281.245\n",
      "Ep:119, loss:0.00001, loss_test:0.09678, lr:6.69e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.779, tt:6333.426\n",
      "Ep:120, loss:0.00001, loss_test:0.09462, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.787, tt:6387.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.09552, lr:6.56e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.784, tt:6439.690\n",
      "Ep:122, loss:0.00001, loss_test:0.09505, lr:6.49e-03, fs:0.82558 (r=0.717,p=0.973),  time:52.808, tt:6495.371\n",
      "Ep:123, loss:0.00001, loss_test:0.09826, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.802, tt:6547.452\n",
      "Ep:124, loss:0.00001, loss_test:0.09374, lr:6.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.787, tt:6598.359\n",
      "Ep:125, loss:0.00001, loss_test:0.09880, lr:6.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.775, tt:6649.604\n",
      "Ep:126, loss:0.00001, loss_test:0.09409, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:52.766, tt:6701.319\n",
      "Ep:127, loss:0.00001, loss_test:0.09902, lr:6.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.772, tt:6754.766\n",
      "Ep:128, loss:0.00001, loss_test:0.09581, lr:6.11e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.762, tt:6806.248\n",
      "Ep:129, loss:0.00001, loss_test:0.09641, lr:6.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.750, tt:6857.564\n",
      "Ep:130, loss:0.00001, loss_test:0.09689, lr:5.99e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.765, tt:6912.279\n",
      "Ep:131, loss:0.00001, loss_test:0.09888, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.752, tt:6963.326\n",
      "Ep:132, loss:0.00001, loss_test:0.09793, lr:5.87e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.744, tt:7014.976\n",
      "Ep:133, loss:0.00001, loss_test:0.09888, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.750, tt:7068.545\n",
      "Ep:134, loss:0.00001, loss_test:0.09727, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.755, tt:7121.953\n",
      "Ep:135, loss:0.00000, loss_test:0.09616, lr:5.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.764, tt:7175.957\n",
      "Ep:136, loss:0.00001, loss_test:0.09848, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.744, tt:7225.982\n",
      "Ep:137, loss:0.00001, loss_test:0.09719, lr:5.58e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.741, tt:7278.204\n",
      "Ep:138, loss:0.00000, loss_test:0.09647, lr:5.53e-03, fs:0.79042 (r=0.667,p=0.971),  time:52.743, tt:7331.276\n",
      "Ep:139, loss:0.00000, loss_test:0.09827, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.724, tt:7381.426\n",
      "Ep:140, loss:0.00000, loss_test:0.09756, lr:5.42e-03, fs:0.79042 (r=0.667,p=0.971),  time:52.757, tt:7438.793\n",
      "Ep:141, loss:0.00000, loss_test:0.09767, lr:5.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.759, tt:7491.781\n",
      "Ep:142, loss:0.00000, loss_test:0.09825, lr:5.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.753, tt:7543.729\n",
      "Ep:143, loss:0.00000, loss_test:0.09681, lr:5.26e-03, fs:0.81871 (r=0.707,p=0.972),  time:52.749, tt:7595.800\n",
      "Ep:144, loss:0.00000, loss_test:0.09965, lr:5.20e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.733, tt:7646.260\n",
      "Ep:145, loss:0.00000, loss_test:0.09533, lr:5.15e-03, fs:0.81176 (r=0.697,p=0.972),  time:52.726, tt:7698.040\n",
      "Ep:146, loss:0.00000, loss_test:0.09945, lr:5.10e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.725, tt:7750.579\n",
      "Ep:147, loss:0.00000, loss_test:0.10006, lr:5.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.740, tt:7805.525\n",
      "Ep:148, loss:0.00000, loss_test:0.09760, lr:5.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.739, tt:7858.077\n",
      "Ep:149, loss:0.00000, loss_test:0.09973, lr:4.95e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.742, tt:7911.363\n",
      "Ep:150, loss:0.00000, loss_test:0.09644, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:52.747, tt:7964.762\n",
      "Ep:151, loss:0.00000, loss_test:0.09898, lr:4.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.754, tt:8018.678\n",
      "Ep:152, loss:0.00000, loss_test:0.09741, lr:4.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.753, tt:8071.239\n",
      "Ep:153, loss:0.00000, loss_test:0.09750, lr:4.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.754, tt:8124.044\n",
      "Ep:154, loss:0.00000, loss_test:0.09818, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:52.755, tt:8177.022\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14241, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.576, tt:20.576\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14108, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.502, tt:37.005\n",
      "Ep:2, loss:0.00028, loss_test:0.13869, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:17.587, tt:52.761\n",
      "Ep:3, loss:0.00027, loss_test:0.13454, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:17.635, tt:70.539\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12748, lr:1.00e-02, fs:0.67391 (r=0.939,p=0.525),  time:18.216, tt:91.081\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11782, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:18.865, tt:113.189\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11277, lr:1.00e-02, fs:0.67662 (r=0.687,p=0.667),  time:19.900, tt:139.302\n",
      "Ep:7, loss:0.00023, loss_test:0.10970, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:20.361, tt:162.888\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10927, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:20.506, tt:184.554\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10520, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:20.734, tt:207.336\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10312, lr:1.00e-02, fs:0.68783 (r=0.657,p=0.722),  time:20.634, tt:226.979\n",
      "Ep:11, loss:0.00019, loss_test:0.09996, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:20.646, tt:247.751\n",
      "Ep:12, loss:0.00019, loss_test:0.09684, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:20.549, tt:267.136\n",
      "Ep:13, loss:0.00018, loss_test:0.09462, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:20.502, tt:287.031\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09037, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:20.438, tt:306.574\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08910, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:20.388, tt:326.210\n",
      "Ep:16, loss:0.00016, loss_test:0.08738, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:20.377, tt:346.410\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08575, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:20.451, tt:368.114\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08336, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:20.393, tt:387.473\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08156, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:20.493, tt:409.861\n",
      "Ep:20, loss:0.00014, loss_test:0.08182, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:20.530, tt:431.120\n",
      "Ep:21, loss:0.00013, loss_test:0.07882, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:20.598, tt:453.163\n",
      "Ep:22, loss:0.00012, loss_test:0.08061, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:20.614, tt:474.127\n",
      "Ep:23, loss:0.00012, loss_test:0.07580, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:20.701, tt:496.824\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07776, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:20.709, tt:517.725\n",
      "Ep:25, loss:0.00011, loss_test:0.07429, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:20.713, tt:538.533\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07544, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:20.717, tt:559.355\n",
      "Ep:27, loss:0.00010, loss_test:0.07433, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:20.697, tt:579.503\n",
      "Ep:28, loss:0.00010, loss_test:0.07108, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:20.697, tt:600.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:29, loss:0.00009, loss_test:0.07324, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:20.710, tt:621.310\n",
      "Ep:30, loss:0.00009, loss_test:0.06736, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:20.708, tt:641.941\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06960, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:20.703, tt:662.504\n",
      "Ep:32, loss:0.00008, loss_test:0.07035, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:20.706, tt:683.292\n",
      "Ep:33, loss:0.00008, loss_test:0.06534, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:20.699, tt:703.755\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06913, lr:1.00e-02, fs:0.81967 (r=0.758,p=0.893),  time:20.686, tt:724.018\n",
      "Ep:35, loss:0.00007, loss_test:0.06527, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:20.730, tt:746.286\n",
      "Ep:36, loss:0.00006, loss_test:0.06644, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:20.710, tt:766.282\n",
      "Ep:37, loss:0.00006, loss_test:0.07107, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:20.707, tt:786.853\n",
      "Ep:38, loss:0.00006, loss_test:0.06291, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:20.661, tt:805.795\n",
      "Ep:39, loss:0.00006, loss_test:0.06949, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.676, tt:827.023\n",
      "Ep:40, loss:0.00005, loss_test:0.06282, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:20.709, tt:849.052\n",
      "Ep:41, loss:0.00005, loss_test:0.06475, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.682, tt:868.647\n",
      "Ep:42, loss:0.00005, loss_test:0.06234, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:20.693, tt:889.819\n",
      "Ep:43, loss:0.00005, loss_test:0.06238, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:20.701, tt:910.864\n",
      "Ep:44, loss:0.00004, loss_test:0.06014, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:20.737, tt:933.166\n",
      "Ep:45, loss:0.00004, loss_test:0.06191, lr:9.90e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.762, tt:955.058\n",
      "Ep:46, loss:0.00004, loss_test:0.06464, lr:9.80e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.780, tt:976.660\n",
      "Ep:47, loss:0.00004, loss_test:0.06089, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.820, tt:999.339\n",
      "Ep:48, loss:0.00003, loss_test:0.06037, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:20.869, tt:1022.564\n",
      "Ep:49, loss:0.00003, loss_test:0.06553, lr:9.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:20.956, tt:1047.795\n",
      "Ep:50, loss:0.00003, loss_test:0.06026, lr:9.41e-03, fs:0.80899 (r=0.727,p=0.911),  time:20.980, tt:1069.971\n",
      "Ep:51, loss:0.00003, loss_test:0.06217, lr:9.32e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.000, tt:1092.023\n",
      "Ep:52, loss:0.00003, loss_test:0.05739, lr:9.23e-03, fs:0.81564 (r=0.737,p=0.912),  time:21.058, tt:1116.082\n",
      "Ep:53, loss:0.00003, loss_test:0.06798, lr:9.14e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.085, tt:1138.601\n",
      "Ep:54, loss:0.00003, loss_test:0.06293, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.127, tt:1162.001\n",
      "Ep:55, loss:0.00003, loss_test:0.06368, lr:8.95e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.132, tt:1183.372\n",
      "Ep:56, loss:0.00003, loss_test:0.06300, lr:8.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.151, tt:1205.603\n",
      "Ep:57, loss:0.00002, loss_test:0.06055, lr:8.78e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.179, tt:1228.387\n",
      "Ep:58, loss:0.00002, loss_test:0.06731, lr:8.69e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.185, tt:1249.893\n",
      "Ep:59, loss:0.00002, loss_test:0.06212, lr:8.60e-03, fs:0.80899 (r=0.727,p=0.911),  time:21.215, tt:1272.876\n",
      "Ep:60, loss:0.00002, loss_test:0.06713, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.214, tt:1294.060\n",
      "Ep:61, loss:0.00002, loss_test:0.06640, lr:8.43e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.192, tt:1313.875\n",
      "Ep:62, loss:0.00002, loss_test:0.06099, lr:8.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.183, tt:1334.506\n",
      "Ep:63, loss:0.00002, loss_test:0.06641, lr:8.26e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.205, tt:1357.149\n",
      "Ep:64, loss:0.00002, loss_test:0.06207, lr:8.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.296, tt:1384.218\n",
      "Ep:65, loss:0.00002, loss_test:0.06471, lr:8.10e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.301, tt:1405.898\n",
      "Ep:66, loss:0.00002, loss_test:0.06333, lr:8.02e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.312, tt:1427.934\n",
      "Ep:67, loss:0.00002, loss_test:0.06317, lr:7.94e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.328, tt:1450.330\n",
      "Ep:68, loss:0.00002, loss_test:0.06401, lr:7.86e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.340, tt:1472.428\n",
      "Ep:69, loss:0.00002, loss_test:0.06840, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.355, tt:1494.854\n",
      "Ep:70, loss:0.00002, loss_test:0.06472, lr:7.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.360, tt:1516.550\n",
      "Ep:71, loss:0.00001, loss_test:0.06639, lr:7.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.348, tt:1537.065\n",
      "Ep:72, loss:0.00001, loss_test:0.06808, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.355, tt:1558.881\n",
      "Ep:73, loss:0.00001, loss_test:0.06593, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.340, tt:1579.185\n",
      "Ep:74, loss:0.00001, loss_test:0.07019, lr:7.40e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.336, tt:1600.192\n",
      "Ep:75, loss:0.00001, loss_test:0.06482, lr:7.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.336, tt:1621.526\n",
      "Ep:76, loss:0.00001, loss_test:0.07183, lr:7.25e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.339, tt:1643.114\n",
      "Ep:77, loss:0.00001, loss_test:0.06921, lr:7.18e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.320, tt:1662.945\n",
      "Ep:78, loss:0.00001, loss_test:0.06719, lr:7.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.312, tt:1683.651\n",
      "Ep:79, loss:0.00001, loss_test:0.07167, lr:7.03e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.307, tt:1704.567\n",
      "Ep:80, loss:0.00001, loss_test:0.06694, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.283, tt:1723.951\n",
      "Ep:81, loss:0.00001, loss_test:0.07221, lr:6.89e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.270, tt:1744.135\n",
      "Ep:82, loss:0.00001, loss_test:0.06912, lr:6.83e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.242, tt:1763.126\n",
      "Ep:83, loss:0.00001, loss_test:0.06920, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.244, tt:1784.529\n",
      "Ep:84, loss:0.00001, loss_test:0.07126, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.238, tt:1805.261\n",
      "Ep:85, loss:0.00001, loss_test:0.06879, lr:6.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.228, tt:1825.593\n",
      "Ep:86, loss:0.00001, loss_test:0.06930, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.214, tt:1845.613\n",
      "Ep:87, loss:0.00001, loss_test:0.07066, lr:6.49e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.211, tt:1866.561\n",
      "Ep:88, loss:0.00001, loss_test:0.06736, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.190, tt:1885.877\n",
      "Ep:89, loss:0.00001, loss_test:0.07090, lr:6.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:1904.841\n",
      "Ep:90, loss:0.00001, loss_test:0.06948, lr:6.30e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.139, tt:1923.617\n",
      "Ep:91, loss:0.00001, loss_test:0.07220, lr:6.24e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.129, tt:1943.912\n",
      "Ep:92, loss:0.00001, loss_test:0.07309, lr:6.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.106, tt:1962.892\n",
      "Ep:93, loss:0.00001, loss_test:0.07002, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.094, tt:1982.829\n",
      "Ep:94, loss:0.00001, loss_test:0.07130, lr:6.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.087, tt:2003.242\n",
      "Ep:95, loss:0.00001, loss_test:0.07096, lr:5.99e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.077, tt:2023.365\n",
      "Ep:96, loss:0.00001, loss_test:0.07005, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.059, tt:2042.713\n",
      "Ep:97, loss:0.00001, loss_test:0.07074, lr:5.87e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.043, tt:2062.203\n",
      "Ep:98, loss:0.00001, loss_test:0.07284, lr:5.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.072, tt:2086.114\n",
      "Ep:99, loss:0.00001, loss_test:0.06972, lr:5.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.066, tt:2106.568\n",
      "Ep:100, loss:0.00001, loss_test:0.07337, lr:5.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2127.391\n",
      "Ep:101, loss:0.00001, loss_test:0.07260, lr:5.64e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2147.447\n",
      "Ep:102, loss:0.00001, loss_test:0.07122, lr:5.58e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.067, tt:2169.918\n",
      "Ep:103, loss:0.00001, loss_test:0.07314, lr:5.53e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2189.465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:104, loss:0.00001, loss_test:0.07219, lr:5.47e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.052, tt:2210.489\n",
      "Ep:105, loss:0.00001, loss_test:0.07173, lr:5.42e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.045, tt:2230.792\n",
      "Ep:106, loss:0.00001, loss_test:0.07212, lr:5.36e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.053, tt:2252.715\n",
      "Ep:107, loss:0.00001, loss_test:0.07134, lr:5.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2274.758\n",
      "Ep:108, loss:0.00001, loss_test:0.07300, lr:5.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.063, tt:2295.896\n",
      "Ep:109, loss:0.00001, loss_test:0.07230, lr:5.20e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.075, tt:2318.238\n",
      "Ep:110, loss:0.00001, loss_test:0.07371, lr:5.15e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.079, tt:2339.761\n",
      "Ep:111, loss:0.00001, loss_test:0.07205, lr:5.10e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.061, tt:2358.870\n",
      "Ep:112, loss:0.00001, loss_test:0.07033, lr:5.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.048, tt:2378.438\n",
      "Ep:113, loss:0.00001, loss_test:0.07544, lr:5.00e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.059, tt:2400.688\n",
      "Ep:114, loss:0.00001, loss_test:0.07415, lr:4.95e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.069, tt:2422.971\n",
      "Ep:115, loss:0.00001, loss_test:0.07199, lr:4.90e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.093, tt:2446.760\n",
      "Ep:116, loss:0.00001, loss_test:0.07442, lr:4.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.086, tt:2467.050\n",
      "Ep:117, loss:0.00000, loss_test:0.07356, lr:4.80e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.084, tt:2487.861\n",
      "Ep:118, loss:0.00000, loss_test:0.07302, lr:4.75e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.079, tt:2508.440\n",
      "Ep:119, loss:0.00000, loss_test:0.07372, lr:4.71e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.090, tt:2530.855\n",
      "Ep:120, loss:0.00000, loss_test:0.07370, lr:4.66e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.111, tt:2554.396\n",
      "Ep:121, loss:0.00000, loss_test:0.07273, lr:4.61e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.106, tt:2574.964\n",
      "Ep:122, loss:0.00000, loss_test:0.07361, lr:4.57e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.107, tt:2596.102\n",
      "Ep:123, loss:0.00000, loss_test:0.07304, lr:4.52e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.112, tt:2617.827\n",
      "Ep:124, loss:0.00000, loss_test:0.07454, lr:4.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.113, tt:2639.071\n",
      "Ep:125, loss:0.00000, loss_test:0.07278, lr:4.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.129, tt:2662.311\n",
      "Ep:126, loss:0.00000, loss_test:0.07465, lr:4.39e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.133, tt:2683.922\n",
      "Ep:127, loss:0.00000, loss_test:0.07499, lr:4.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.145, tt:2706.507\n",
      "Ep:128, loss:0.00000, loss_test:0.07409, lr:4.30e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.140, tt:2727.034\n",
      "Ep:129, loss:0.00000, loss_test:0.07378, lr:4.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.151, tt:2749.687\n",
      "Ep:130, loss:0.00000, loss_test:0.07352, lr:4.21e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.154, tt:2771.190\n",
      "Ep:131, loss:0.00000, loss_test:0.07463, lr:4.17e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.156, tt:2792.591\n",
      "Ep:132, loss:0.00000, loss_test:0.07346, lr:4.13e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.150, tt:2812.899\n",
      "Ep:133, loss:0.00000, loss_test:0.07547, lr:4.09e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.169, tt:2836.603\n",
      "Ep:134, loss:0.00000, loss_test:0.07512, lr:4.05e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.168, tt:2857.620\n",
      "Ep:135, loss:0.00000, loss_test:0.07444, lr:4.01e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.170, tt:2879.179\n",
      "Ep:136, loss:0.00000, loss_test:0.07367, lr:3.97e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.151, tt:2897.739\n",
      "Ep:137, loss:0.00000, loss_test:0.07496, lr:3.93e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.153, tt:2919.100\n",
      "Ep:138, loss:0.00000, loss_test:0.07648, lr:3.89e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.149, tt:2939.676\n",
      "Ep:139, loss:0.00000, loss_test:0.07393, lr:3.85e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.175, tt:2964.456\n",
      "Ep:140, loss:0.00000, loss_test:0.07366, lr:3.81e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:2984.231\n",
      "Ep:141, loss:0.00000, loss_test:0.07561, lr:3.77e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.150, tt:3003.320\n",
      "Ep:142, loss:0.00000, loss_test:0.07520, lr:3.73e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.156, tt:3025.344\n",
      "Ep:143, loss:0.00000, loss_test:0.07495, lr:3.70e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.154, tt:3046.158\n",
      "Ep:144, loss:0.00000, loss_test:0.07479, lr:3.66e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.165, tt:3068.922\n",
      "Ep:145, loss:0.00000, loss_test:0.07552, lr:3.62e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.186, tt:3093.209\n",
      "Ep:146, loss:0.00000, loss_test:0.07464, lr:3.59e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.179, tt:3113.260\n",
      "Ep:147, loss:0.00000, loss_test:0.07437, lr:3.55e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.183, tt:3135.148\n",
      "Ep:148, loss:0.00000, loss_test:0.07514, lr:3.52e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.181, tt:3155.956\n",
      "Ep:149, loss:0.00000, loss_test:0.07499, lr:3.48e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.179, tt:3176.920\n",
      "Ep:150, loss:0.00000, loss_test:0.07449, lr:3.45e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.174, tt:3197.219\n",
      "Ep:151, loss:0.00000, loss_test:0.07474, lr:3.41e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.191, tt:3221.086\n",
      "Ep:152, loss:0.00000, loss_test:0.07558, lr:3.38e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.206, tt:3244.481\n",
      "Ep:153, loss:0.00000, loss_test:0.07512, lr:3.34e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.216, tt:3267.297\n",
      "Ep:154, loss:0.00000, loss_test:0.07422, lr:3.31e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.214, tt:3288.229\n",
      "Ep:155, loss:0.00000, loss_test:0.07477, lr:3.28e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.220, tt:3310.306\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14328, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.628, tt:21.628\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14186, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.239, tt:42.478\n",
      "Ep:2, loss:0.00027, loss_test:0.13924, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.906, tt:59.717\n",
      "Ep:3, loss:0.00027, loss_test:0.13449, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.123, tt:80.492\n",
      "Ep:4, loss:0.00026, loss_test:0.12591, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:20.501, tt:102.503\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11320, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:20.804, tt:124.823\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10836, lr:1.00e-02, fs:0.69903 (r=0.727,p=0.673),  time:20.924, tt:146.469\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10618, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:20.798, tt:166.380\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10567, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:20.984, tt:188.853\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09928, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:21.006, tt:210.062\n",
      "Ep:10, loss:0.00020, loss_test:0.09782, lr:1.00e-02, fs:0.71875 (r=0.697,p=0.742),  time:21.016, tt:231.173\n",
      "Ep:11, loss:0.00019, loss_test:0.09512, lr:1.00e-02, fs:0.76712 (r=0.848,p=0.700),  time:20.936, tt:251.232\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09233, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:21.002, tt:273.021\n",
      "Ep:13, loss:0.00018, loss_test:0.09104, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:20.985, tt:293.783\n",
      "Ep:14, loss:0.00017, loss_test:0.08782, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:21.086, tt:316.296\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08823, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:21.118, tt:337.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:16, loss:0.00015, loss_test:0.08587, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:21.076, tt:358.293\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08443, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:21.102, tt:379.829\n",
      "Ep:18, loss:0.00014, loss_test:0.08337, lr:1.00e-02, fs:0.80392 (r=0.828,p=0.781),  time:21.063, tt:400.191\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08170, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:21.226, tt:424.527\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08090, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:21.153, tt:444.211\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.07904, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:21.153, tt:465.357\n",
      "Ep:22, loss:0.00012, loss_test:0.07859, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:21.163, tt:486.757\n",
      "Ep:23, loss:0.00012, loss_test:0.07640, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:21.150, tt:507.604\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07716, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:21.178, tt:529.457\n",
      "Ep:25, loss:0.00011, loss_test:0.07418, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:21.232, tt:552.042\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.07392, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:21.154, tt:571.154\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07160, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:21.138, tt:591.861\n",
      "Ep:28, loss:0.00009, loss_test:0.07099, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:21.205, tt:614.937\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.06908, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:21.216, tt:636.465\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.06895, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:21.230, tt:658.142\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.06713, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:21.206, tt:678.606\n",
      "Ep:32, loss:0.00008, loss_test:0.06851, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:21.208, tt:699.877\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00008, loss_test:0.06463, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:21.256, tt:722.719\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00007, loss_test:0.06598, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:21.233, tt:743.143\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00007, loss_test:0.06257, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:21.220, tt:763.921\n",
      "Ep:36, loss:0.00007, loss_test:0.06424, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:21.196, tt:784.270\n",
      "Ep:37, loss:0.00007, loss_test:0.06139, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:21.240, tt:807.102\n",
      "Ep:38, loss:0.00006, loss_test:0.06367, lr:1.00e-02, fs:0.93401 (r=0.929,p=0.939),  time:21.244, tt:828.506\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00006, loss_test:0.06038, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:21.214, tt:848.579\n",
      "Ep:40, loss:0.00006, loss_test:0.06483, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.189, tt:868.762\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.05907, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:21.220, tt:891.222\n",
      "Ep:42, loss:0.00006, loss_test:0.06338, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.234, tt:913.078\n",
      "Ep:43, loss:0.00005, loss_test:0.05756, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:21.223, tt:933.799\n",
      "Ep:44, loss:0.00005, loss_test:0.06208, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:21.213, tt:954.594\n",
      "Ep:45, loss:0.00005, loss_test:0.05635, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:21.243, tt:977.157\n",
      "Ep:46, loss:0.00005, loss_test:0.05832, lr:1.00e-02, fs:0.94359 (r=0.929,p=0.958),  time:21.265, tt:999.432\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.05484, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.261, tt:1020.513\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.05650, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.254, tt:1041.468\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.05445, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.261, tt:1063.072\n",
      "Ep:50, loss:0.00004, loss_test:0.05562, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.256, tt:1084.071\n",
      "Ep:51, loss:0.00004, loss_test:0.05382, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.260, tt:1105.506\n",
      "Ep:52, loss:0.00004, loss_test:0.05428, lr:1.00e-02, fs:0.95431 (r=0.949,p=0.959),  time:21.244, tt:1125.911\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00004, loss_test:0.05285, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:21.241, tt:1147.006\n",
      "Ep:54, loss:0.00003, loss_test:0.05405, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.223, tt:1167.289\n",
      "Ep:55, loss:0.00003, loss_test:0.05263, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:21.220, tt:1188.296\n",
      "Ep:56, loss:0.00003, loss_test:0.05411, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.199, tt:1208.316\n",
      "Ep:57, loss:0.00003, loss_test:0.05308, lr:1.00e-02, fs:0.95431 (r=0.949,p=0.959),  time:21.199, tt:1229.567\n",
      "Ep:58, loss:0.00003, loss_test:0.05477, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.202, tt:1250.914\n",
      "Ep:59, loss:0.00003, loss_test:0.05115, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:21.236, tt:1274.181\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.05559, lr:1.00e-02, fs:0.94845 (r=0.929,p=0.968),  time:21.240, tt:1295.620\n",
      "Ep:61, loss:0.00003, loss_test:0.05119, lr:1.00e-02, fs:0.97537 (r=1.000,p=0.952),  time:21.236, tt:1316.615\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.05397, lr:1.00e-02, fs:0.95385 (r=0.939,p=0.969),  time:21.229, tt:1337.420\n",
      "Ep:63, loss:0.00002, loss_test:0.05222, lr:1.00e-02, fs:0.97487 (r=0.980,p=0.970),  time:21.241, tt:1359.453\n",
      "Ep:64, loss:0.00002, loss_test:0.05416, lr:1.00e-02, fs:0.96482 (r=0.970,p=0.960),  time:21.236, tt:1380.348\n",
      "Ep:65, loss:0.00002, loss_test:0.05426, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.240, tt:1401.849\n",
      "Ep:66, loss:0.00002, loss_test:0.05346, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.255, tt:1424.097\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00002, loss_test:0.05400, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.242, tt:1444.459\n",
      "Ep:68, loss:0.00002, loss_test:0.05397, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:21.259, tt:1466.866\n",
      "Ep:69, loss:0.00002, loss_test:0.05550, lr:1.00e-02, fs:0.94898 (r=0.939,p=0.959),  time:21.285, tt:1489.965\n",
      "Ep:70, loss:0.00002, loss_test:0.05563, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.265, tt:1509.791\n",
      "Ep:71, loss:0.00002, loss_test:0.05531, lr:1.00e-02, fs:0.94792 (r=0.919,p=0.978),  time:21.255, tt:1530.362\n",
      "Ep:72, loss:0.00002, loss_test:0.05484, lr:1.00e-02, fs:0.95337 (r=0.929,p=0.979),  time:21.250, tt:1551.222\n",
      "Ep:73, loss:0.00002, loss_test:0.05555, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.260, tt:1573.221\n",
      "Ep:74, loss:0.00002, loss_test:0.05423, lr:1.00e-02, fs:0.98000 (r=0.990,p=0.970),  time:21.268, tt:1595.130\n",
      "Ep:75, loss:0.00002, loss_test:0.05693, lr:1.00e-02, fs:0.95337 (r=0.929,p=0.979),  time:21.271, tt:1616.573\n",
      "Ep:76, loss:0.00002, loss_test:0.05422, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.267, tt:1637.535\n",
      "Ep:77, loss:0.00001, loss_test:0.05996, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:21.247, tt:1657.227\n",
      "Ep:78, loss:0.00001, loss_test:0.05385, lr:9.90e-03, fs:0.96410 (r=0.949,p=0.979),  time:21.260, tt:1679.579\n",
      "Ep:79, loss:0.00001, loss_test:0.05798, lr:9.80e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.243, tt:1699.452\n",
      "Ep:80, loss:0.00001, loss_test:0.05626, lr:9.70e-03, fs:0.94792 (r=0.919,p=0.978),  time:21.258, tt:1721.868\n",
      "Ep:81, loss:0.00001, loss_test:0.05717, lr:9.61e-03, fs:0.94241 (r=0.909,p=0.978),  time:21.244, tt:1742.049\n",
      "Ep:82, loss:0.00001, loss_test:0.05885, lr:9.51e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.248, tt:1763.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00001, loss_test:0.05467, lr:9.41e-03, fs:0.96410 (r=0.949,p=0.979),  time:21.241, tt:1784.217\n",
      "Ep:84, loss:0.00001, loss_test:0.05995, lr:9.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.247, tt:1805.964\n",
      "Ep:85, loss:0.00001, loss_test:0.05756, lr:9.23e-03, fs:0.95337 (r=0.929,p=0.979),  time:21.253, tt:1827.775\n",
      "Ep:86, loss:0.00001, loss_test:0.05676, lr:9.14e-03, fs:0.92553 (r=0.879,p=0.978),  time:21.250, tt:1848.779\n",
      "Ep:87, loss:0.00001, loss_test:0.05924, lr:9.04e-03, fs:0.92553 (r=0.879,p=0.978),  time:21.249, tt:1869.871\n",
      "Ep:88, loss:0.00001, loss_test:0.05752, lr:8.95e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.251, tt:1891.309\n",
      "Ep:89, loss:0.00001, loss_test:0.05876, lr:8.86e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.254, tt:1912.892\n",
      "Ep:90, loss:0.00001, loss_test:0.06079, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.254, tt:1934.112\n",
      "Ep:91, loss:0.00001, loss_test:0.05767, lr:8.69e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.264, tt:1956.266\n",
      "Ep:92, loss:0.00001, loss_test:0.06052, lr:8.60e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.246, tt:1975.845\n",
      "Ep:93, loss:0.00001, loss_test:0.05760, lr:8.51e-03, fs:0.91979 (r=0.869,p=0.977),  time:21.265, tt:1998.928\n",
      "Ep:94, loss:0.00001, loss_test:0.06015, lr:8.43e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.272, tt:2020.835\n",
      "Ep:95, loss:0.00001, loss_test:0.06233, lr:8.35e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.265, tt:2041.482\n",
      "Ep:96, loss:0.00001, loss_test:0.05782, lr:8.26e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.258, tt:2062.023\n",
      "Ep:97, loss:0.00001, loss_test:0.06307, lr:8.18e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.251, tt:2082.582\n",
      "Ep:98, loss:0.00001, loss_test:0.06011, lr:8.10e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.246, tt:2103.318\n",
      "Ep:99, loss:0.00001, loss_test:0.05984, lr:8.02e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.244, tt:2124.433\n",
      "Ep:100, loss:0.00001, loss_test:0.06220, lr:7.94e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.251, tt:2146.401\n",
      "Ep:101, loss:0.00001, loss_test:0.05987, lr:7.86e-03, fs:0.89617 (r=0.828,p=0.976),  time:21.259, tt:2168.413\n",
      "Ep:102, loss:0.00001, loss_test:0.06172, lr:7.78e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.251, tt:2188.852\n",
      "Ep:103, loss:0.00001, loss_test:0.06223, lr:7.70e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.251, tt:2210.151\n",
      "Ep:104, loss:0.00001, loss_test:0.06184, lr:7.62e-03, fs:0.87151 (r=0.788,p=0.975),  time:21.253, tt:2231.577\n",
      "Ep:105, loss:0.00001, loss_test:0.06268, lr:7.55e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.278, tt:2255.443\n",
      "Ep:106, loss:0.00001, loss_test:0.06080, lr:7.47e-03, fs:0.89011 (r=0.818,p=0.976),  time:21.288, tt:2277.768\n",
      "Ep:107, loss:0.00001, loss_test:0.06393, lr:7.40e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.270, tt:2297.183\n",
      "Ep:108, loss:0.00001, loss_test:0.06299, lr:7.32e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.247, tt:2315.972\n",
      "Ep:109, loss:0.00001, loss_test:0.06079, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.218, tt:2333.975\n",
      "Ep:110, loss:0.00001, loss_test:0.06509, lr:7.18e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.224, tt:2355.914\n",
      "Ep:111, loss:0.00001, loss_test:0.06123, lr:7.11e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.231, tt:2377.824\n",
      "Ep:112, loss:0.00001, loss_test:0.06364, lr:7.03e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.232, tt:2399.227\n",
      "Ep:113, loss:0.00001, loss_test:0.06566, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.210, tt:2417.950\n",
      "Ep:114, loss:0.00001, loss_test:0.06164, lr:6.89e-03, fs:0.87778 (r=0.798,p=0.975),  time:21.189, tt:2436.725\n",
      "Ep:115, loss:0.00001, loss_test:0.06506, lr:6.83e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.186, tt:2457.538\n",
      "Ep:116, loss:0.00000, loss_test:0.06479, lr:6.76e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.204, tt:2480.818\n",
      "Ep:117, loss:0.00000, loss_test:0.06301, lr:6.69e-03, fs:0.83908 (r=0.737,p=0.973),  time:21.204, tt:2502.073\n",
      "Ep:118, loss:0.00000, loss_test:0.06658, lr:6.62e-03, fs:0.76829 (r=0.636,p=0.969),  time:21.215, tt:2524.565\n",
      "Ep:119, loss:0.00000, loss_test:0.06360, lr:6.56e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.220, tt:2546.452\n",
      "Ep:120, loss:0.00000, loss_test:0.06507, lr:6.49e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.228, tt:2568.632\n",
      "Ep:121, loss:0.00000, loss_test:0.06594, lr:6.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.218, tt:2588.544\n",
      "Ep:122, loss:0.00000, loss_test:0.06348, lr:6.36e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.235, tt:2611.871\n",
      "Ep:123, loss:0.00000, loss_test:0.06572, lr:6.30e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.225, tt:2631.919\n",
      "Ep:124, loss:0.00000, loss_test:0.06638, lr:6.24e-03, fs:0.76074 (r=0.626,p=0.969),  time:21.217, tt:2652.186\n",
      "Ep:125, loss:0.00000, loss_test:0.06324, lr:6.17e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.215, tt:2673.042\n",
      "Ep:126, loss:0.00000, loss_test:0.06577, lr:6.11e-03, fs:0.77576 (r=0.646,p=0.970),  time:21.220, tt:2694.890\n",
      "Ep:127, loss:0.00000, loss_test:0.06668, lr:6.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:21.217, tt:2715.834\n",
      "Ep:128, loss:0.00000, loss_test:0.06420, lr:5.99e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.230, tt:2738.645\n",
      "Ep:129, loss:0.00000, loss_test:0.06644, lr:5.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.226, tt:2759.364\n",
      "Ep:130, loss:0.00000, loss_test:0.06474, lr:5.87e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.221, tt:2779.999\n",
      "Ep:131, loss:0.00000, loss_test:0.06580, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.242, tt:2803.998\n",
      "Ep:132, loss:0.00000, loss_test:0.06650, lr:5.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.244, tt:2825.474\n",
      "Ep:133, loss:0.00000, loss_test:0.06597, lr:5.70e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.236, tt:2845.610\n",
      "Ep:134, loss:0.00000, loss_test:0.06520, lr:5.64e-03, fs:0.81176 (r=0.697,p=0.972),  time:21.240, tt:2867.380\n",
      "Ep:135, loss:0.00000, loss_test:0.06722, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.241, tt:2888.715\n",
      "Ep:136, loss:0.00000, loss_test:0.06641, lr:5.53e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.258, tt:2912.310\n",
      "Ep:137, loss:0.00000, loss_test:0.06497, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.255, tt:2933.171\n",
      "Ep:138, loss:0.00000, loss_test:0.06601, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.246, tt:2953.170\n",
      "Ep:139, loss:0.00000, loss_test:0.06511, lr:5.36e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.236, tt:2973.084\n",
      "Ep:140, loss:0.00000, loss_test:0.06628, lr:5.31e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.230, tt:2993.501\n",
      "Ep:141, loss:0.00000, loss_test:0.06521, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.235, tt:3015.383\n",
      "Ep:142, loss:0.00000, loss_test:0.06562, lr:5.20e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.239, tt:3037.158\n",
      "Ep:143, loss:0.00000, loss_test:0.06465, lr:5.15e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.240, tt:3058.570\n",
      "Ep:144, loss:0.00000, loss_test:0.06628, lr:5.10e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.237, tt:3079.303\n",
      "Ep:145, loss:0.00000, loss_test:0.06529, lr:5.05e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.235, tt:3100.352\n",
      "Ep:146, loss:0.00000, loss_test:0.06574, lr:5.00e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.236, tt:3121.765\n",
      "Ep:147, loss:0.00000, loss_test:0.06661, lr:4.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.242, tt:3143.764\n",
      "Ep:148, loss:0.00000, loss_test:0.06554, lr:4.90e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.238, tt:3164.507\n",
      "Ep:149, loss:0.00000, loss_test:0.06606, lr:4.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.248, tt:3187.255\n",
      "Ep:150, loss:0.00000, loss_test:0.06567, lr:4.80e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.253, tt:3209.175\n",
      "Ep:151, loss:0.00000, loss_test:0.06595, lr:4.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.249, tt:3229.809\n",
      "Ep:152, loss:0.00000, loss_test:0.06578, lr:4.71e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.262, tt:3253.072\n",
      "Ep:153, loss:0.00000, loss_test:0.06520, lr:4.66e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.261, tt:3274.179\n",
      "Ep:154, loss:0.00000, loss_test:0.06781, lr:4.61e-03, fs:0.70513 (r=0.556,p=0.965),  time:21.267, tt:3296.310\n",
      "Ep:155, loss:0.00000, loss_test:0.06627, lr:4.57e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.258, tt:3316.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14343, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.480, tt:24.480\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14233, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.108, tt:44.216\n",
      "Ep:2, loss:0.00028, loss_test:0.14038, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.398, tt:64.195\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13682, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:22.445, tt:89.780\n",
      "Ep:4, loss:0.00026, loss_test:0.13164, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:23.088, tt:115.441\n",
      "Ep:5, loss:0.00025, loss_test:0.12687, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:23.369, tt:140.216\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12309, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:23.669, tt:165.685\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11889, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:23.786, tt:190.287\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11623, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:24.017, tt:216.151\n",
      "Ep:9, loss:0.00022, loss_test:0.11217, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:23.985, tt:239.847\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10826, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:23.971, tt:263.682\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.10590, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:24.283, tt:291.396\n",
      "Ep:12, loss:0.00019, loss_test:0.10260, lr:1.00e-02, fs:0.76190 (r=0.889,p=0.667),  time:24.269, tt:315.501\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09790, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:24.254, tt:339.554\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09519, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:24.229, tt:363.442\n",
      "Ep:15, loss:0.00017, loss_test:0.09484, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:24.222, tt:387.555\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09322, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:24.498, tt:416.471\n",
      "Ep:17, loss:0.00016, loss_test:0.08985, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:24.631, tt:443.361\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08785, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:24.678, tt:468.879\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08624, lr:1.00e-02, fs:0.80952 (r=0.859,p=0.766),  time:24.626, tt:492.515\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08501, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:24.626, tt:517.138\n",
      "Ep:21, loss:0.00013, loss_test:0.08385, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:24.620, tt:541.636\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08304, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:24.616, tt:566.179\n",
      "Ep:23, loss:0.00012, loss_test:0.08219, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:24.608, tt:590.585\n",
      "Ep:24, loss:0.00012, loss_test:0.08049, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:24.635, tt:615.866\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07985, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:24.625, tt:640.249\n",
      "Ep:26, loss:0.00011, loss_test:0.07815, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:24.627, tt:664.919\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07690, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:24.678, tt:690.983\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07603, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:24.694, tt:716.114\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.07585, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:24.749, tt:742.465\n",
      "Ep:30, loss:0.00009, loss_test:0.07392, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.762, tt:767.637\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07322, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:24.735, tt:791.524\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.07236, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:24.746, tt:816.633\n",
      "Ep:33, loss:0.00008, loss_test:0.07045, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:24.796, tt:843.061\n",
      "Ep:34, loss:0.00008, loss_test:0.07028, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.809, tt:868.332\n",
      "Ep:35, loss:0.00007, loss_test:0.06923, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:24.839, tt:894.211\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.06937, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:24.887, tt:920.818\n",
      "Ep:37, loss:0.00007, loss_test:0.06827, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.834, tt:943.704\n",
      "Ep:38, loss:0.00007, loss_test:0.06814, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:24.849, tt:969.092\n",
      "Ep:39, loss:0.00006, loss_test:0.06741, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.871, tt:994.855\n",
      "Ep:40, loss:0.00006, loss_test:0.06689, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:24.904, tt:1021.063\n",
      "Ep:41, loss:0.00006, loss_test:0.06575, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:24.937, tt:1047.371\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.06592, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:24.913, tt:1071.242\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.06360, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:24.916, tt:1096.317\n",
      "Ep:44, loss:0.00005, loss_test:0.06557, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.922, tt:1121.497\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.06418, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:24.939, tt:1147.173\n",
      "Ep:46, loss:0.00005, loss_test:0.06587, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:24.920, tt:1171.232\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00004, loss_test:0.06317, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.910, tt:1195.679\n",
      "Ep:48, loss:0.00004, loss_test:0.06540, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:24.942, tt:1222.167\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.06357, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:24.949, tt:1247.433\n",
      "Ep:50, loss:0.00004, loss_test:0.06719, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:24.949, tt:1272.407\n",
      "Ep:51, loss:0.00004, loss_test:0.06323, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:24.949, tt:1297.335\n",
      "Ep:52, loss:0.00004, loss_test:0.06686, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:24.966, tt:1323.192\n",
      "Ep:53, loss:0.00004, loss_test:0.06347, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:24.974, tt:1348.601\n",
      "Ep:54, loss:0.00003, loss_test:0.06496, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:24.980, tt:1373.909\n",
      "Ep:55, loss:0.00003, loss_test:0.06357, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:24.992, tt:1399.556\n",
      "Ep:56, loss:0.00003, loss_test:0.06393, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:25.018, tt:1426.028\n",
      "Ep:57, loss:0.00003, loss_test:0.06570, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:25.010, tt:1450.551\n",
      "Ep:58, loss:0.00003, loss_test:0.06425, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:25.037, tt:1477.202\n",
      "Ep:59, loss:0.00003, loss_test:0.06593, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:25.079, tt:1504.732\n",
      "Ep:60, loss:0.00003, loss_test:0.06480, lr:9.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:25.080, tt:1529.907\n",
      "Ep:61, loss:0.00003, loss_test:0.06362, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:25.064, tt:1553.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00003, loss_test:0.06690, lr:9.70e-03, fs:0.82222 (r=0.747,p=0.914),  time:25.076, tt:1579.815\n",
      "Ep:63, loss:0.00002, loss_test:0.06386, lr:9.61e-03, fs:0.88421 (r=0.848,p=0.923),  time:25.083, tt:1605.344\n",
      "Ep:64, loss:0.00002, loss_test:0.06535, lr:9.51e-03, fs:0.84444 (r=0.768,p=0.938),  time:25.081, tt:1630.294\n",
      "Ep:65, loss:0.00002, loss_test:0.06311, lr:9.41e-03, fs:0.88542 (r=0.859,p=0.914),  time:25.091, tt:1656.010\n",
      "Ep:66, loss:0.00002, loss_test:0.06693, lr:9.32e-03, fs:0.83429 (r=0.737,p=0.961),  time:25.092, tt:1681.197\n",
      "Ep:67, loss:0.00002, loss_test:0.06308, lr:9.23e-03, fs:0.88542 (r=0.859,p=0.914),  time:25.116, tt:1707.897\n",
      "Ep:68, loss:0.00002, loss_test:0.06434, lr:9.14e-03, fs:0.86813 (r=0.798,p=0.952),  time:25.104, tt:1732.188\n",
      "Ep:69, loss:0.00002, loss_test:0.06474, lr:9.04e-03, fs:0.84615 (r=0.778,p=0.928),  time:25.138, tt:1759.632\n",
      "Ep:70, loss:0.00002, loss_test:0.06364, lr:8.95e-03, fs:0.91489 (r=0.869,p=0.966),  time:25.129, tt:1784.178\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.06491, lr:8.95e-03, fs:0.83429 (r=0.737,p=0.961),  time:25.106, tt:1807.642\n",
      "Ep:72, loss:0.00002, loss_test:0.06360, lr:8.95e-03, fs:0.90811 (r=0.848,p=0.977),  time:25.093, tt:1831.808\n",
      "Ep:73, loss:0.00002, loss_test:0.06276, lr:8.95e-03, fs:0.90323 (r=0.848,p=0.966),  time:25.080, tt:1855.910\n",
      "Ep:74, loss:0.00002, loss_test:0.06444, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:25.103, tt:1882.741\n",
      "Ep:75, loss:0.00002, loss_test:0.06385, lr:8.95e-03, fs:0.88525 (r=0.818,p=0.964),  time:25.115, tt:1908.744\n",
      "Ep:76, loss:0.00002, loss_test:0.06448, lr:8.95e-03, fs:0.91304 (r=0.848,p=0.988),  time:25.103, tt:1932.908\n",
      "Ep:77, loss:0.00001, loss_test:0.06289, lr:8.95e-03, fs:0.90909 (r=0.859,p=0.966),  time:25.077, tt:1956.007\n",
      "Ep:78, loss:0.00001, loss_test:0.06309, lr:8.95e-03, fs:0.87293 (r=0.798,p=0.963),  time:25.091, tt:1982.224\n",
      "Ep:79, loss:0.00001, loss_test:0.06491, lr:8.95e-03, fs:0.89503 (r=0.818,p=0.988),  time:25.096, tt:2007.706\n",
      "Ep:80, loss:0.00001, loss_test:0.06465, lr:8.95e-03, fs:0.85714 (r=0.758,p=0.987),  time:25.090, tt:2032.317\n",
      "Ep:81, loss:0.00001, loss_test:0.06229, lr:8.95e-03, fs:0.91489 (r=0.869,p=0.966),  time:25.087, tt:2057.128\n",
      "Ep:82, loss:0.00001, loss_test:0.06546, lr:8.86e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.067, tt:2080.549\n",
      "Ep:83, loss:0.00001, loss_test:0.06408, lr:8.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:25.075, tt:2106.298\n",
      "Ep:84, loss:0.00001, loss_test:0.06404, lr:8.69e-03, fs:0.86667 (r=0.788,p=0.963),  time:25.062, tt:2130.233\n",
      "Ep:85, loss:0.00001, loss_test:0.06681, lr:8.60e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.065, tt:2155.592\n",
      "Ep:86, loss:0.00001, loss_test:0.06397, lr:8.51e-03, fs:0.87640 (r=0.788,p=0.987),  time:25.041, tt:2178.603\n",
      "Ep:87, loss:0.00001, loss_test:0.06668, lr:8.43e-03, fs:0.84884 (r=0.737,p=1.000),  time:25.003, tt:2200.261\n",
      "Ep:88, loss:0.00001, loss_test:0.06454, lr:8.35e-03, fs:0.85714 (r=0.758,p=0.987),  time:24.967, tt:2222.025\n",
      "Ep:89, loss:0.00001, loss_test:0.06472, lr:8.26e-03, fs:0.88889 (r=0.808,p=0.988),  time:24.921, tt:2242.870\n",
      "Ep:90, loss:0.00001, loss_test:0.06541, lr:8.18e-03, fs:0.84393 (r=0.737,p=0.986),  time:24.876, tt:2263.672\n",
      "Ep:91, loss:0.00001, loss_test:0.06477, lr:8.10e-03, fs:0.88764 (r=0.798,p=1.000),  time:24.815, tt:2283.000\n",
      "Ep:92, loss:0.00001, loss_test:0.06594, lr:8.02e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.807, tt:2307.028\n",
      "Ep:93, loss:0.00001, loss_test:0.06574, lr:7.94e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.766, tt:2328.012\n",
      "Ep:94, loss:0.00001, loss_test:0.06507, lr:7.86e-03, fs:0.84393 (r=0.737,p=0.986),  time:24.729, tt:2349.224\n",
      "Ep:95, loss:0.00001, loss_test:0.06532, lr:7.78e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.699, tt:2371.089\n",
      "Ep:96, loss:0.00001, loss_test:0.06574, lr:7.70e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.725, tt:2398.357\n",
      "Ep:97, loss:0.00001, loss_test:0.06567, lr:7.62e-03, fs:0.85057 (r=0.747,p=0.987),  time:24.717, tt:2422.296\n",
      "Ep:98, loss:0.00001, loss_test:0.06710, lr:7.55e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2446.356\n",
      "Ep:99, loss:0.00001, loss_test:0.06619, lr:7.47e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.698, tt:2469.815\n",
      "Ep:100, loss:0.00001, loss_test:0.06615, lr:7.40e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.698, tt:2494.514\n",
      "Ep:101, loss:0.00001, loss_test:0.06626, lr:7.32e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2520.477\n",
      "Ep:102, loss:0.00001, loss_test:0.06715, lr:7.25e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.711, tt:2545.226\n",
      "Ep:103, loss:0.00001, loss_test:0.06550, lr:7.18e-03, fs:0.86207 (r=0.758,p=1.000),  time:24.731, tt:2571.985\n",
      "Ep:104, loss:0.00001, loss_test:0.06697, lr:7.11e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.750, tt:2598.719\n",
      "Ep:105, loss:0.00001, loss_test:0.06653, lr:7.03e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.755, tt:2624.066\n",
      "Ep:106, loss:0.00001, loss_test:0.06773, lr:6.96e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.753, tt:2648.610\n",
      "Ep:107, loss:0.00001, loss_test:0.06645, lr:6.89e-03, fs:0.84884 (r=0.737,p=1.000),  time:24.739, tt:2671.838\n",
      "Ep:108, loss:0.00001, loss_test:0.06752, lr:6.83e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.755, tt:2698.309\n",
      "Ep:109, loss:0.00001, loss_test:0.06736, lr:6.76e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.750, tt:2722.504\n",
      "Ep:110, loss:0.00001, loss_test:0.06803, lr:6.69e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.741, tt:2746.216\n",
      "Ep:111, loss:0.00001, loss_test:0.06885, lr:6.62e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.735, tt:2770.305\n",
      "Ep:112, loss:0.00001, loss_test:0.06684, lr:6.56e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.729, tt:2794.412\n",
      "Ep:113, loss:0.00001, loss_test:0.06783, lr:6.49e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.724, tt:2818.540\n",
      "Ep:114, loss:0.00001, loss_test:0.06705, lr:6.43e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.717, tt:2842.497\n",
      "Ep:115, loss:0.00001, loss_test:0.06842, lr:6.36e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.699, tt:2865.089\n",
      "Ep:116, loss:0.00001, loss_test:0.06709, lr:6.30e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.700, tt:2889.919\n",
      "Ep:117, loss:0.00001, loss_test:0.06879, lr:6.24e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.711, tt:2915.929\n",
      "Ep:118, loss:0.00001, loss_test:0.06759, lr:6.17e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.709, tt:2940.325\n",
      "Ep:119, loss:0.00001, loss_test:0.06850, lr:6.11e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.708, tt:2965.010\n",
      "Ep:120, loss:0.00001, loss_test:0.06831, lr:6.05e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.704, tt:2989.242\n",
      "Ep:121, loss:0.00001, loss_test:0.06916, lr:5.99e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.697, tt:3013.019\n",
      "Ep:122, loss:0.00001, loss_test:0.06932, lr:5.93e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.688, tt:3036.602\n",
      "Ep:123, loss:0.00000, loss_test:0.07034, lr:5.87e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.682, tt:3060.590\n",
      "Ep:124, loss:0.00000, loss_test:0.06865, lr:5.81e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.679, tt:3084.913\n",
      "Ep:125, loss:0.00000, loss_test:0.06968, lr:5.75e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.663, tt:3107.494\n",
      "Ep:126, loss:0.00000, loss_test:0.06896, lr:5.70e-03, fs:0.84211 (r=0.727,p=1.000),  time:24.659, tt:3131.753\n",
      "Ep:127, loss:0.00000, loss_test:0.06960, lr:5.64e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.658, tt:3156.195\n",
      "Ep:128, loss:0.00000, loss_test:0.06995, lr:5.58e-03, fs:0.82143 (r=0.697,p=1.000),  time:24.651, tt:3179.922\n",
      "Ep:129, loss:0.00000, loss_test:0.06911, lr:5.53e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.655, tt:3205.099\n",
      "Ep:130, loss:0.00000, loss_test:0.06971, lr:5.47e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.652, tt:3229.410\n",
      "Ep:131, loss:0.00000, loss_test:0.06954, lr:5.42e-03, fs:0.83529 (r=0.717,p=1.000),  time:24.638, tt:3252.198\n",
      "Ep:132, loss:0.00000, loss_test:0.06966, lr:5.36e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.633, tt:3276.192\n",
      "Ep:133, loss:0.00000, loss_test:0.06943, lr:5.31e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.638, tt:3301.535\n",
      "Ep:134, loss:0.00000, loss_test:0.06937, lr:5.26e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.622, tt:3323.935\n",
      "Ep:135, loss:0.00000, loss_test:0.06958, lr:5.20e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.618, tt:3348.042\n",
      "Ep:136, loss:0.00000, loss_test:0.07037, lr:5.15e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.620, tt:3372.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.06923, lr:5.10e-03, fs:0.82840 (r=0.707,p=1.000),  time:24.626, tt:3398.398\n",
      "Ep:138, loss:0.00000, loss_test:0.06987, lr:5.05e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.629, tt:3423.384\n",
      "Ep:139, loss:0.00000, loss_test:0.07121, lr:5.00e-03, fs:0.78528 (r=0.646,p=1.000),  time:24.629, tt:3448.009\n",
      "Ep:140, loss:0.00000, loss_test:0.06937, lr:4.95e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.627, tt:3472.357\n",
      "Ep:141, loss:0.00000, loss_test:0.06986, lr:4.90e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.637, tt:3498.405\n",
      "Ep:142, loss:0.00000, loss_test:0.07151, lr:4.85e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.646, tt:3524.318\n",
      "Ep:143, loss:0.00000, loss_test:0.07036, lr:4.80e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.631, tt:3546.817\n",
      "Ep:144, loss:0.00000, loss_test:0.07003, lr:4.75e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.629, tt:3571.246\n",
      "Ep:145, loss:0.00000, loss_test:0.06993, lr:4.71e-03, fs:0.81437 (r=0.687,p=1.000),  time:24.631, tt:3596.077\n",
      "Ep:146, loss:0.00000, loss_test:0.07053, lr:4.66e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.624, tt:3619.774\n",
      "Ep:147, loss:0.00000, loss_test:0.07061, lr:4.61e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.617, tt:3643.327\n",
      "Ep:148, loss:0.00000, loss_test:0.07040, lr:4.57e-03, fs:0.80000 (r=0.667,p=1.000),  time:24.619, tt:3668.266\n",
      "Ep:149, loss:0.00000, loss_test:0.07131, lr:4.52e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.612, tt:3691.743\n",
      "Ep:150, loss:0.00000, loss_test:0.07014, lr:4.48e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.607, tt:3715.646\n",
      "Ep:151, loss:0.00000, loss_test:0.06996, lr:4.43e-03, fs:0.80723 (r=0.677,p=1.000),  time:24.614, tt:3741.257\n",
      "Ep:152, loss:0.00000, loss_test:0.07116, lr:4.39e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.612, tt:3765.574\n",
      "Ep:153, loss:0.00000, loss_test:0.07087, lr:4.34e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.619, tt:3791.274\n",
      "Ep:154, loss:0.00000, loss_test:0.07018, lr:4.30e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.623, tt:3816.623\n",
      "Ep:155, loss:0.00000, loss_test:0.07028, lr:4.26e-03, fs:0.79268 (r=0.657,p=1.000),  time:24.616, tt:3840.136\n",
      "Ep:156, loss:0.00000, loss_test:0.07130, lr:4.21e-03, fs:0.77019 (r=0.626,p=1.000),  time:24.601, tt:3862.378\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14527, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.842, tt:23.842\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14418, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.390, tt:46.779\n",
      "Ep:2, loss:0.00028, loss_test:0.14234, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.744, tt:65.233\n",
      "Ep:3, loss:0.00027, loss_test:0.13888, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:22.622, tt:90.487\n",
      "Ep:4, loss:0.00026, loss_test:0.13348, lr:1.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:23.124, tt:115.622\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.13029, lr:1.00e-02, fs:0.63200 (r=0.798,p=0.523),  time:23.313, tt:139.880\n",
      "Ep:6, loss:0.00024, loss_test:0.12819, lr:1.00e-02, fs:0.65823 (r=0.788,p=0.565),  time:23.293, tt:163.052\n",
      "Ep:7, loss:0.00024, loss_test:0.12378, lr:1.00e-02, fs:0.66390 (r=0.808,p=0.563),  time:23.349, tt:186.793\n",
      "Ep:8, loss:0.00023, loss_test:0.12044, lr:1.00e-02, fs:0.66667 (r=0.828,p=0.558),  time:23.489, tt:211.400\n",
      "Ep:9, loss:0.00022, loss_test:0.11580, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:23.635, tt:236.347\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11259, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:23.833, tt:262.168\n",
      "Ep:11, loss:0.00019, loss_test:0.11030, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:24.079, tt:288.944\n",
      "Ep:12, loss:0.00018, loss_test:0.10802, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:24.180, tt:314.342\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10652, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:24.091, tt:337.276\n",
      "Ep:14, loss:0.00017, loss_test:0.10406, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:24.177, tt:362.650\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.10173, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:24.224, tt:387.588\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09997, lr:1.00e-02, fs:0.72549 (r=0.747,p=0.705),  time:24.450, tt:415.656\n",
      "Ep:17, loss:0.00014, loss_test:0.09865, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:24.448, tt:440.063\n",
      "Ep:18, loss:0.00014, loss_test:0.09658, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:24.481, tt:465.139\n",
      "Ep:19, loss:0.00013, loss_test:0.09461, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:24.507, tt:490.135\n",
      "Ep:20, loss:0.00013, loss_test:0.09293, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:24.511, tt:514.731\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00012, loss_test:0.09154, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:24.651, tt:542.333\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00011, loss_test:0.08990, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:24.655, tt:567.061\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00011, loss_test:0.08995, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:24.722, tt:593.329\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00010, loss_test:0.08772, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:24.653, tt:616.329\n",
      "Ep:25, loss:0.00010, loss_test:0.08636, lr:1.00e-02, fs:0.77949 (r=0.768,p=0.792),  time:24.693, tt:642.008\n",
      "Ep:26, loss:0.00010, loss_test:0.08529, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:24.663, tt:665.892\n",
      "Ep:27, loss:0.00009, loss_test:0.08316, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:24.641, tt:689.961\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.08316, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:24.635, tt:714.417\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00008, loss_test:0.08160, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:24.581, tt:737.435\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.08141, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.558, tt:761.288\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00008, loss_test:0.07936, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:24.526, tt:784.845\n",
      "Ep:32, loss:0.00007, loss_test:0.07954, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:24.538, tt:809.765\n",
      "Ep:33, loss:0.00007, loss_test:0.07830, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.530, tt:834.006\n",
      "Ep:34, loss:0.00007, loss_test:0.07809, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:24.526, tt:858.393\n",
      "Ep:35, loss:0.00006, loss_test:0.07700, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:24.458, tt:880.499\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00006, loss_test:0.07663, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:24.523, tt:907.346\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.07514, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:24.484, tt:930.383\n",
      "Ep:38, loss:0.00006, loss_test:0.07364, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:24.465, tt:954.122\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.07630, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:24.459, tt:978.374\n",
      "Ep:40, loss:0.00005, loss_test:0.07205, lr:1.00e-02, fs:0.87129 (r=0.889,p=0.854),  time:24.515, tt:1005.123\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00005, loss_test:0.07698, lr:1.00e-02, fs:0.77838 (r=0.727,p=0.837),  time:24.496, tt:1028.835\n",
      "Ep:42, loss:0.00005, loss_test:0.07463, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:24.467, tt:1052.078\n",
      "Ep:43, loss:0.00004, loss_test:0.07199, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:24.492, tt:1077.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:44, loss:0.00004, loss_test:0.07659, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:24.473, tt:1101.279\n",
      "Ep:45, loss:0.00004, loss_test:0.07017, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:24.476, tt:1125.886\n",
      "Ep:46, loss:0.00004, loss_test:0.07582, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:24.442, tt:1148.797\n",
      "Ep:47, loss:0.00004, loss_test:0.06987, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:24.470, tt:1174.545\n",
      "Ep:48, loss:0.00004, loss_test:0.07285, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:24.465, tt:1198.782\n",
      "Ep:49, loss:0.00004, loss_test:0.06894, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:24.491, tt:1224.569\n",
      "Ep:50, loss:0.00003, loss_test:0.07257, lr:1.00e-02, fs:0.82286 (r=0.727,p=0.947),  time:24.455, tt:1247.195\n",
      "Ep:51, loss:0.00003, loss_test:0.06830, lr:1.00e-02, fs:0.83516 (r=0.768,p=0.916),  time:24.418, tt:1269.718\n",
      "Ep:52, loss:0.00003, loss_test:0.07207, lr:9.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.397, tt:1293.049\n",
      "Ep:53, loss:0.00003, loss_test:0.06925, lr:9.80e-03, fs:0.82873 (r=0.758,p=0.915),  time:24.395, tt:1317.338\n",
      "Ep:54, loss:0.00003, loss_test:0.07014, lr:9.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.428, tt:1343.565\n",
      "Ep:55, loss:0.00003, loss_test:0.06771, lr:9.61e-03, fs:0.82222 (r=0.747,p=0.914),  time:24.384, tt:1365.500\n",
      "Ep:56, loss:0.00003, loss_test:0.07019, lr:9.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:24.415, tt:1391.675\n",
      "Ep:57, loss:0.00003, loss_test:0.06618, lr:9.41e-03, fs:0.82222 (r=0.747,p=0.914),  time:24.461, tt:1418.728\n",
      "Ep:58, loss:0.00003, loss_test:0.07309, lr:9.32e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.466, tt:1443.508\n",
      "Ep:59, loss:0.00002, loss_test:0.06877, lr:9.23e-03, fs:0.81356 (r=0.727,p=0.923),  time:24.454, tt:1467.256\n",
      "Ep:60, loss:0.00002, loss_test:0.07079, lr:9.14e-03, fs:0.83146 (r=0.747,p=0.937),  time:24.495, tt:1494.171\n",
      "Ep:61, loss:0.00002, loss_test:0.07180, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.524, tt:1520.482\n",
      "Ep:62, loss:0.00002, loss_test:0.06728, lr:8.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:24.511, tt:1544.167\n",
      "Ep:63, loss:0.00002, loss_test:0.07046, lr:8.86e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.482, tt:1566.863\n",
      "Ep:64, loss:0.00002, loss_test:0.06874, lr:8.78e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.469, tt:1590.484\n",
      "Ep:65, loss:0.00002, loss_test:0.07178, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.483, tt:1615.885\n",
      "Ep:66, loss:0.00002, loss_test:0.07122, lr:8.60e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.486, tt:1640.592\n",
      "Ep:67, loss:0.00002, loss_test:0.06846, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.501, tt:1666.049\n",
      "Ep:68, loss:0.00002, loss_test:0.07237, lr:8.43e-03, fs:0.81818 (r=0.727,p=0.935),  time:24.503, tt:1690.673\n",
      "Ep:69, loss:0.00002, loss_test:0.06993, lr:8.35e-03, fs:0.82286 (r=0.727,p=0.947),  time:24.513, tt:1715.930\n",
      "Ep:70, loss:0.00002, loss_test:0.07218, lr:8.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:24.509, tt:1740.174\n",
      "Ep:71, loss:0.00002, loss_test:0.07388, lr:8.18e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.506, tt:1764.402\n",
      "Ep:72, loss:0.00002, loss_test:0.07109, lr:8.10e-03, fs:0.81609 (r=0.717,p=0.947),  time:24.502, tt:1788.642\n",
      "Ep:73, loss:0.00002, loss_test:0.07359, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.504, tt:1813.299\n",
      "Ep:74, loss:0.00002, loss_test:0.07405, lr:7.94e-03, fs:0.78571 (r=0.667,p=0.957),  time:24.498, tt:1837.331\n",
      "Ep:75, loss:0.00002, loss_test:0.07076, lr:7.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:24.495, tt:1861.634\n",
      "Ep:76, loss:0.00002, loss_test:0.07523, lr:7.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:24.517, tt:1887.847\n",
      "Ep:77, loss:0.00002, loss_test:0.07475, lr:7.70e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.540, tt:1914.119\n",
      "Ep:78, loss:0.00002, loss_test:0.07297, lr:7.62e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.581, tt:1941.896\n",
      "Ep:79, loss:0.00001, loss_test:0.07641, lr:7.55e-03, fs:0.75610 (r=0.626,p=0.954),  time:24.570, tt:1965.610\n",
      "Ep:80, loss:0.00001, loss_test:0.07358, lr:7.47e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.595, tt:1992.214\n",
      "Ep:81, loss:0.00001, loss_test:0.07626, lr:7.40e-03, fs:0.75904 (r=0.636,p=0.940),  time:24.588, tt:2016.179\n",
      "Ep:82, loss:0.00001, loss_test:0.07443, lr:7.32e-03, fs:0.75152 (r=0.626,p=0.939),  time:24.625, tt:2043.843\n",
      "Ep:83, loss:0.00001, loss_test:0.07739, lr:7.25e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.634, tt:2069.243\n",
      "Ep:84, loss:0.00001, loss_test:0.07729, lr:7.18e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.624, tt:2093.007\n",
      "Ep:85, loss:0.00001, loss_test:0.07682, lr:7.11e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.622, tt:2117.514\n",
      "Ep:86, loss:0.00001, loss_test:0.07643, lr:7.03e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.611, tt:2141.120\n",
      "Ep:87, loss:0.00001, loss_test:0.07819, lr:6.96e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.604, tt:2165.123\n",
      "Ep:88, loss:0.00001, loss_test:0.07744, lr:6.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.591, tt:2188.582\n",
      "Ep:89, loss:0.00001, loss_test:0.07876, lr:6.83e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.600, tt:2213.963\n",
      "Ep:90, loss:0.00001, loss_test:0.07833, lr:6.76e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.613, tt:2239.805\n",
      "Ep:91, loss:0.00001, loss_test:0.07721, lr:6.69e-03, fs:0.74390 (r=0.616,p=0.938),  time:24.644, tt:2267.272\n",
      "Ep:92, loss:0.00001, loss_test:0.08183, lr:6.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.650, tt:2292.483\n",
      "Ep:93, loss:0.00001, loss_test:0.08003, lr:6.56e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.671, tt:2319.050\n",
      "Ep:94, loss:0.00001, loss_test:0.07857, lr:6.49e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.650, tt:2341.742\n",
      "Ep:95, loss:0.00001, loss_test:0.08103, lr:6.43e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.649, tt:2366.285\n",
      "Ep:96, loss:0.00001, loss_test:0.07937, lr:6.36e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.626, tt:2388.723\n",
      "Ep:97, loss:0.00001, loss_test:0.08066, lr:6.30e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.615, tt:2412.282\n",
      "Ep:98, loss:0.00001, loss_test:0.08107, lr:6.24e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.608, tt:2436.145\n",
      "Ep:99, loss:0.00001, loss_test:0.07912, lr:6.17e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.602, tt:2460.226\n",
      "Ep:100, loss:0.00001, loss_test:0.08089, lr:6.11e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.595, tt:2484.123\n",
      "Ep:101, loss:0.00001, loss_test:0.08347, lr:6.05e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.582, tt:2507.413\n",
      "Ep:102, loss:0.00001, loss_test:0.07968, lr:5.99e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.580, tt:2531.717\n",
      "Ep:103, loss:0.00001, loss_test:0.08070, lr:5.93e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.600, tt:2558.392\n",
      "Ep:104, loss:0.00001, loss_test:0.08029, lr:5.87e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.596, tt:2582.545\n",
      "Ep:105, loss:0.00001, loss_test:0.08151, lr:5.81e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.583, tt:2605.760\n",
      "Ep:106, loss:0.00001, loss_test:0.07991, lr:5.75e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.567, tt:2628.703\n",
      "Ep:107, loss:0.00001, loss_test:0.08110, lr:5.70e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.548, tt:2651.170\n",
      "Ep:108, loss:0.00001, loss_test:0.08106, lr:5.64e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.550, tt:2675.904\n",
      "Ep:109, loss:0.00001, loss_test:0.08336, lr:5.58e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.544, tt:2699.857\n",
      "Ep:110, loss:0.00001, loss_test:0.08015, lr:5.53e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.547, tt:2724.697\n",
      "Ep:111, loss:0.00001, loss_test:0.08150, lr:5.47e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.563, tt:2751.017\n",
      "Ep:112, loss:0.00001, loss_test:0.08142, lr:5.42e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.565, tt:2775.872\n",
      "Ep:113, loss:0.00001, loss_test:0.08062, lr:5.36e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.569, tt:2800.910\n",
      "Ep:114, loss:0.00001, loss_test:0.08334, lr:5.31e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.565, tt:2824.934\n",
      "Ep:115, loss:0.00001, loss_test:0.08110, lr:5.26e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.567, tt:2849.735\n",
      "Ep:116, loss:0.00001, loss_test:0.08233, lr:5.20e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.559, tt:2873.374\n",
      "Ep:117, loss:0.00001, loss_test:0.08303, lr:5.15e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.566, tt:2898.768\n",
      "Ep:118, loss:0.00001, loss_test:0.08183, lr:5.10e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.554, tt:2921.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:119, loss:0.00001, loss_test:0.08163, lr:5.05e-03, fs:0.74847 (r=0.616,p=0.953),  time:24.540, tt:2944.760\n",
      "Ep:120, loss:0.00001, loss_test:0.08112, lr:5.00e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.536, tt:2968.899\n",
      "Ep:121, loss:0.00001, loss_test:0.08563, lr:4.95e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.520, tt:2991.463\n",
      "Ep:122, loss:0.00001, loss_test:0.08245, lr:4.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.531, tt:3017.294\n",
      "Ep:123, loss:0.00001, loss_test:0.08344, lr:4.85e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.523, tt:3040.904\n",
      "Ep:124, loss:0.00001, loss_test:0.08314, lr:4.80e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.519, tt:3064.846\n",
      "Ep:125, loss:0.00001, loss_test:0.08212, lr:4.75e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.522, tt:3089.722\n",
      "Ep:126, loss:0.00001, loss_test:0.08358, lr:4.71e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.524, tt:3114.507\n",
      "Ep:127, loss:0.00001, loss_test:0.08342, lr:4.66e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.526, tt:3139.378\n",
      "Ep:128, loss:0.00001, loss_test:0.08439, lr:4.61e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.522, tt:3163.398\n",
      "Ep:129, loss:0.00001, loss_test:0.08503, lr:4.57e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.525, tt:3188.295\n",
      "Ep:130, loss:0.00001, loss_test:0.08279, lr:4.52e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.533, tt:3213.863\n",
      "Ep:131, loss:0.00001, loss_test:0.08461, lr:4.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.531, tt:3238.076\n",
      "Ep:132, loss:0.00001, loss_test:0.08428, lr:4.43e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.523, tt:3261.503\n",
      "Ep:133, loss:0.00001, loss_test:0.08414, lr:4.39e-03, fs:0.75309 (r=0.616,p=0.968),  time:24.534, tt:3287.583\n",
      "Ep:134, loss:0.00001, loss_test:0.08484, lr:4.34e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.539, tt:3312.750\n",
      "Ep:135, loss:0.00001, loss_test:0.08393, lr:4.30e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3339.623\n",
      "Ep:136, loss:0.00001, loss_test:0.08530, lr:4.26e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.552, tt:3363.570\n",
      "Ep:137, loss:0.00001, loss_test:0.08512, lr:4.21e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3388.635\n",
      "Ep:138, loss:0.00001, loss_test:0.08337, lr:4.17e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.543, tt:3411.485\n",
      "Ep:139, loss:0.00001, loss_test:0.08562, lr:4.13e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.548, tt:3436.701\n",
      "Ep:140, loss:0.00001, loss_test:0.08505, lr:4.09e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3462.341\n",
      "Ep:141, loss:0.00001, loss_test:0.08529, lr:4.05e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.552, tt:3486.373\n",
      "Ep:142, loss:0.00001, loss_test:0.08652, lr:4.01e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3511.100\n",
      "Ep:143, loss:0.00001, loss_test:0.08506, lr:3.97e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3535.906\n",
      "Ep:144, loss:0.00001, loss_test:0.08656, lr:3.93e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.557, tt:3560.765\n",
      "Ep:145, loss:0.00001, loss_test:0.08739, lr:3.89e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.548, tt:3584.077\n",
      "Ep:146, loss:0.00001, loss_test:0.08492, lr:3.85e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.556, tt:3609.750\n",
      "Ep:147, loss:0.00000, loss_test:0.08620, lr:3.81e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.555, tt:3634.134\n",
      "Ep:148, loss:0.00000, loss_test:0.08748, lr:3.77e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3658.445\n",
      "Ep:149, loss:0.00000, loss_test:0.08556, lr:3.73e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3682.889\n",
      "Ep:150, loss:0.00000, loss_test:0.08510, lr:3.70e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.553, tt:3707.499\n",
      "Ep:151, loss:0.00000, loss_test:0.08591, lr:3.66e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.554, tt:3732.194\n",
      "Ep:152, loss:0.00000, loss_test:0.08669, lr:3.62e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.549, tt:3756.057\n",
      "Ep:153, loss:0.00000, loss_test:0.08628, lr:3.59e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.549, tt:3780.494\n",
      "Ep:154, loss:0.00000, loss_test:0.08546, lr:3.55e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.542, tt:3803.986\n",
      "Ep:155, loss:0.00000, loss_test:0.08593, lr:3.52e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.536, tt:3827.673\n",
      "Ep:156, loss:0.00000, loss_test:0.08604, lr:3.48e-03, fs:0.75776 (r=0.616,p=0.984),  time:24.537, tt:3852.289\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14128, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:31.903, tt:31.903\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13860, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:33.207, tt:66.413\n",
      "Ep:2, loss:0.00027, loss_test:0.13378, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:36.577, tt:109.731\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12721, lr:1.00e-02, fs:0.66667 (r=0.939,p=0.517),  time:37.758, tt:151.033\n",
      "Ep:4, loss:0.00025, loss_test:0.11725, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:38.159, tt:190.796\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10973, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:38.924, tt:233.545\n",
      "Ep:6, loss:0.00022, loss_test:0.10825, lr:1.00e-02, fs:0.68599 (r=0.717,p=0.657),  time:39.515, tt:276.608\n",
      "Ep:7, loss:0.00022, loss_test:0.10743, lr:1.00e-02, fs:0.70588 (r=0.788,p=0.639),  time:40.102, tt:320.817\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10486, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:40.474, tt:364.270\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10319, lr:1.00e-02, fs:0.74107 (r=0.838,p=0.664),  time:40.730, tt:407.301\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10363, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:40.823, tt:449.056\n",
      "Ep:11, loss:0.00019, loss_test:0.10261, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:40.895, tt:490.736\n",
      "Ep:12, loss:0.00019, loss_test:0.10062, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:41.026, tt:533.343\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09973, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:41.216, tt:577.030\n",
      "Ep:14, loss:0.00018, loss_test:0.09787, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.359, tt:620.381\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09684, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:41.205, tt:659.286\n",
      "Ep:16, loss:0.00017, loss_test:0.09574, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:41.418, tt:704.109\n",
      "Ep:17, loss:0.00017, loss_test:0.09380, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:41.451, tt:746.113\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.09248, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:41.625, tt:790.876\n",
      "Ep:19, loss:0.00016, loss_test:0.09171, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:41.576, tt:831.528\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08990, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:41.622, tt:874.068\n",
      "Ep:21, loss:0.00015, loss_test:0.08828, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.753, tt:918.572\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08716, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:41.849, tt:962.527\n",
      "Ep:23, loss:0.00015, loss_test:0.08616, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:41.863, tt:1004.713\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08573, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:41.897, tt:1047.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:25, loss:0.00014, loss_test:0.08511, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:42.014, tt:1092.364\n",
      "Ep:26, loss:0.00013, loss_test:0.08394, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:42.141, tt:1137.799\n",
      "Ep:27, loss:0.00013, loss_test:0.08420, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:42.104, tt:1178.918\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08263, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:42.126, tt:1221.659\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.08301, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:42.134, tt:1264.010\n",
      "Ep:30, loss:0.00012, loss_test:0.08244, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:42.145, tt:1306.496\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.08097, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:42.146, tt:1348.685\n",
      "Ep:32, loss:0.00012, loss_test:0.08093, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:42.119, tt:1389.928\n",
      "Ep:33, loss:0.00012, loss_test:0.08055, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:42.127, tt:1432.308\n",
      "Ep:34, loss:0.00011, loss_test:0.07826, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:42.113, tt:1473.964\n",
      "Ep:35, loss:0.00011, loss_test:0.08079, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:42.102, tt:1515.659\n",
      "Ep:36, loss:0.00011, loss_test:0.07757, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.132, tt:1558.878\n",
      "Ep:37, loss:0.00011, loss_test:0.07858, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:42.087, tt:1599.311\n",
      "Ep:38, loss:0.00010, loss_test:0.07813, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:42.125, tt:1642.866\n",
      "Ep:39, loss:0.00010, loss_test:0.07602, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:42.161, tt:1686.447\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.07998, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:42.246, tt:1732.083\n",
      "Ep:41, loss:0.00010, loss_test:0.07573, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.273, tt:1775.471\n",
      "Ep:42, loss:0.00009, loss_test:0.07800, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:42.257, tt:1817.058\n",
      "Ep:43, loss:0.00009, loss_test:0.07584, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.238, tt:1858.486\n",
      "Ep:44, loss:0.00009, loss_test:0.07667, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.273, tt:1902.306\n",
      "Ep:45, loss:0.00009, loss_test:0.07558, lr:1.00e-02, fs:0.81218 (r=0.808,p=0.816),  time:42.256, tt:1943.755\n",
      "Ep:46, loss:0.00008, loss_test:0.07512, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:42.250, tt:1985.750\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07534, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.251, tt:2028.025\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.07436, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:42.251, tt:2070.304\n",
      "Ep:49, loss:0.00008, loss_test:0.07658, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:42.298, tt:2114.915\n",
      "Ep:50, loss:0.00008, loss_test:0.07598, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:42.273, tt:2155.910\n",
      "Ep:51, loss:0.00008, loss_test:0.07392, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:42.303, tt:2199.738\n",
      "Ep:52, loss:0.00008, loss_test:0.07174, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:42.335, tt:2243.742\n",
      "Ep:53, loss:0.00008, loss_test:0.07055, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:42.333, tt:2286.000\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.07344, lr:1.00e-02, fs:0.81443 (r=0.798,p=0.832),  time:42.319, tt:2327.559\n",
      "Ep:55, loss:0.00007, loss_test:0.06989, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:42.307, tt:2369.191\n",
      "Ep:56, loss:0.00007, loss_test:0.07324, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.330, tt:2412.788\n",
      "Ep:57, loss:0.00007, loss_test:0.06854, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.310, tt:2453.963\n",
      "Ep:58, loss:0.00007, loss_test:0.07228, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:42.341, tt:2498.143\n",
      "Ep:59, loss:0.00006, loss_test:0.07097, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.346, tt:2540.741\n",
      "Ep:60, loss:0.00006, loss_test:0.07077, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:42.376, tt:2584.938\n",
      "Ep:61, loss:0.00006, loss_test:0.07137, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:42.404, tt:2629.053\n",
      "Ep:62, loss:0.00006, loss_test:0.07117, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.405, tt:2671.534\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.06995, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.407, tt:2714.018\n",
      "Ep:64, loss:0.00006, loss_test:0.07085, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:42.380, tt:2754.677\n",
      "Ep:65, loss:0.00006, loss_test:0.07023, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:42.400, tt:2798.408\n",
      "Ep:66, loss:0.00005, loss_test:0.07342, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:42.407, tt:2841.264\n",
      "Ep:67, loss:0.00005, loss_test:0.07117, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:42.433, tt:2885.426\n",
      "Ep:68, loss:0.00006, loss_test:0.06858, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:42.437, tt:2928.137\n",
      "Ep:69, loss:0.00005, loss_test:0.07749, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:42.448, tt:2971.349\n",
      "Ep:70, loss:0.00005, loss_test:0.06991, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:42.467, tt:3015.165\n",
      "Ep:71, loss:0.00005, loss_test:0.07539, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:42.484, tt:3058.884\n",
      "Ep:72, loss:0.00005, loss_test:0.06928, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:42.493, tt:3102.002\n",
      "Ep:73, loss:0.00005, loss_test:0.07235, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:42.531, tt:3147.294\n",
      "Ep:74, loss:0.00005, loss_test:0.07006, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:42.524, tt:3189.306\n",
      "Ep:75, loss:0.00004, loss_test:0.07027, lr:9.80e-03, fs:0.81675 (r=0.788,p=0.848),  time:42.522, tt:3231.636\n",
      "Ep:76, loss:0.00004, loss_test:0.07047, lr:9.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:42.579, tt:3278.606\n",
      "Ep:77, loss:0.00004, loss_test:0.06852, lr:9.61e-03, fs:0.82540 (r=0.788,p=0.867),  time:42.618, tt:3324.230\n",
      "Ep:78, loss:0.00004, loss_test:0.06978, lr:9.51e-03, fs:0.84211 (r=0.808,p=0.879),  time:42.654, tt:3369.673\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00004, loss_test:0.06946, lr:9.51e-03, fs:0.82540 (r=0.788,p=0.867),  time:42.674, tt:3413.899\n",
      "Ep:80, loss:0.00004, loss_test:0.06914, lr:9.51e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.684, tt:3457.414\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00004, loss_test:0.06915, lr:9.51e-03, fs:0.81250 (r=0.788,p=0.839),  time:42.709, tt:3502.143\n",
      "Ep:82, loss:0.00004, loss_test:0.06791, lr:9.51e-03, fs:0.81675 (r=0.788,p=0.848),  time:42.725, tt:3546.140\n",
      "Ep:83, loss:0.00004, loss_test:0.07016, lr:9.51e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.732, tt:3589.484\n",
      "Ep:84, loss:0.00004, loss_test:0.06745, lr:9.51e-03, fs:0.84103 (r=0.828,p=0.854),  time:42.734, tt:3632.379\n",
      "Ep:85, loss:0.00003, loss_test:0.07010, lr:9.51e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.737, tt:3675.390\n",
      "Ep:86, loss:0.00003, loss_test:0.06691, lr:9.51e-03, fs:0.84375 (r=0.818,p=0.871),  time:42.746, tt:3718.881\n",
      "Ep:87, loss:0.00003, loss_test:0.06811, lr:9.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.773, tt:3764.013\n",
      "Ep:88, loss:0.00003, loss_test:0.06672, lr:9.51e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.776, tt:3807.033\n",
      "Ep:89, loss:0.00003, loss_test:0.06771, lr:9.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.790, tt:3851.116\n",
      "Ep:90, loss:0.00003, loss_test:0.06732, lr:9.51e-03, fs:0.84211 (r=0.808,p=0.879),  time:42.802, tt:3894.964\n",
      "Ep:91, loss:0.00003, loss_test:0.06646, lr:9.51e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.844, tt:3941.654\n",
      "Ep:92, loss:0.00003, loss_test:0.06723, lr:9.41e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.874, tt:3987.249\n",
      "Ep:93, loss:0.00003, loss_test:0.06529, lr:9.32e-03, fs:0.84817 (r=0.818,p=0.880),  time:42.889, tt:4031.579\n",
      "Ep:94, loss:0.00003, loss_test:0.06990, lr:9.23e-03, fs:0.83516 (r=0.768,p=0.916),  time:42.874, tt:4073.074\n",
      "Ep:95, loss:0.00003, loss_test:0.06619, lr:9.14e-03, fs:0.84656 (r=0.808,p=0.889),  time:42.871, tt:4115.597\n",
      "Ep:96, loss:0.00003, loss_test:0.06904, lr:9.04e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.876, tt:4158.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:97, loss:0.00003, loss_test:0.06563, lr:8.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.894, tt:4203.633\n",
      "Ep:98, loss:0.00003, loss_test:0.06776, lr:8.86e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.930, tt:4250.048\n",
      "Ep:99, loss:0.00003, loss_test:0.06520, lr:8.78e-03, fs:0.85714 (r=0.818,p=0.900),  time:42.928, tt:4292.784\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00003, loss_test:0.06663, lr:8.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.935, tt:4336.400\n",
      "Ep:101, loss:0.00003, loss_test:0.06651, lr:8.78e-03, fs:0.84324 (r=0.788,p=0.907),  time:42.922, tt:4378.034\n",
      "Ep:102, loss:0.00002, loss_test:0.06676, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.919, tt:4420.618\n",
      "Ep:103, loss:0.00002, loss_test:0.06601, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.924, tt:4464.119\n",
      "Ep:104, loss:0.00002, loss_test:0.06706, lr:8.78e-03, fs:0.84043 (r=0.798,p=0.888),  time:42.915, tt:4506.111\n",
      "Ep:105, loss:0.00002, loss_test:0.06589, lr:8.78e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.907, tt:4548.142\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.06725, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.898, tt:4590.073\n",
      "Ep:107, loss:0.00002, loss_test:0.06498, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.911, tt:4634.411\n",
      "Ep:108, loss:0.00002, loss_test:0.06709, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.914, tt:4677.600\n",
      "Ep:109, loss:0.00002, loss_test:0.07066, lr:8.78e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.920, tt:4721.219\n",
      "Ep:110, loss:0.00002, loss_test:0.06550, lr:8.78e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.937, tt:4766.059\n",
      "Ep:111, loss:0.00002, loss_test:0.06928, lr:8.78e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.946, tt:4809.910\n",
      "Ep:112, loss:0.00002, loss_test:0.06587, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:42.947, tt:4853.034\n",
      "Ep:113, loss:0.00002, loss_test:0.06981, lr:8.78e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.946, tt:4895.863\n",
      "Ep:114, loss:0.00002, loss_test:0.06538, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:42.930, tt:4936.926\n",
      "Ep:115, loss:0.00002, loss_test:0.06936, lr:8.78e-03, fs:0.83696 (r=0.778,p=0.906),  time:42.931, tt:4980.016\n",
      "Ep:116, loss:0.00002, loss_test:0.06931, lr:8.78e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.929, tt:5022.718\n",
      "Ep:117, loss:0.00002, loss_test:0.06635, lr:8.69e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.946, tt:5067.621\n",
      "Ep:118, loss:0.00002, loss_test:0.07167, lr:8.60e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.935, tt:5109.323\n",
      "Ep:119, loss:0.00002, loss_test:0.06627, lr:8.51e-03, fs:0.86170 (r=0.818,p=0.910),  time:42.959, tt:5155.022\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00002, loss_test:0.07180, lr:8.51e-03, fs:0.82682 (r=0.747,p=0.925),  time:42.948, tt:5196.693\n",
      "Ep:121, loss:0.00002, loss_test:0.06527, lr:8.51e-03, fs:0.86772 (r=0.828,p=0.911),  time:42.943, tt:5239.089\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.07201, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.935, tt:5281.065\n",
      "Ep:123, loss:0.00002, loss_test:0.06620, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.958, tt:5326.813\n",
      "Ep:124, loss:0.00002, loss_test:0.07133, lr:8.51e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.972, tt:5371.514\n",
      "Ep:125, loss:0.00002, loss_test:0.06680, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.963, tt:5413.296\n",
      "Ep:126, loss:0.00002, loss_test:0.07031, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.969, tt:5457.059\n",
      "Ep:127, loss:0.00002, loss_test:0.06642, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.966, tt:5499.690\n",
      "Ep:128, loss:0.00002, loss_test:0.07078, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.966, tt:5542.659\n",
      "Ep:129, loss:0.00002, loss_test:0.06746, lr:8.51e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.950, tt:5583.541\n",
      "Ep:130, loss:0.00002, loss_test:0.07057, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.946, tt:5625.969\n",
      "Ep:131, loss:0.00002, loss_test:0.06934, lr:8.51e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.960, tt:5670.742\n",
      "Ep:132, loss:0.00002, loss_test:0.06864, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:42.967, tt:5714.607\n",
      "Ep:133, loss:0.00002, loss_test:0.06959, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.951, tt:5755.492\n",
      "Ep:134, loss:0.00002, loss_test:0.06862, lr:8.35e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.953, tt:5798.712\n",
      "Ep:135, loss:0.00002, loss_test:0.06899, lr:8.26e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.923, tt:5837.511\n",
      "Ep:136, loss:0.00002, loss_test:0.07007, lr:8.18e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.919, tt:5879.862\n",
      "Ep:137, loss:0.00002, loss_test:0.06799, lr:8.10e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.905, tt:5920.940\n",
      "Ep:138, loss:0.00002, loss_test:0.06941, lr:8.02e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.901, tt:5963.203\n",
      "Ep:139, loss:0.00002, loss_test:0.06904, lr:7.94e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.937, tt:6011.159\n",
      "Ep:140, loss:0.00002, loss_test:0.06973, lr:7.86e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.942, tt:6054.854\n",
      "Ep:141, loss:0.00001, loss_test:0.06869, lr:7.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.944, tt:6098.085\n",
      "Ep:142, loss:0.00001, loss_test:0.07079, lr:7.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.940, tt:6140.436\n",
      "Ep:143, loss:0.00001, loss_test:0.06669, lr:7.62e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.925, tt:6181.175\n",
      "Ep:144, loss:0.00002, loss_test:0.07294, lr:7.55e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.943, tt:6226.736\n",
      "Ep:145, loss:0.00002, loss_test:0.07012, lr:7.47e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.929, tt:6267.659\n",
      "Ep:146, loss:0.00001, loss_test:0.07120, lr:7.40e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.935, tt:6311.414\n",
      "Ep:147, loss:0.00001, loss_test:0.07380, lr:7.32e-03, fs:0.81818 (r=0.727,p=0.935),  time:42.931, tt:6353.821\n",
      "Ep:148, loss:0.00001, loss_test:0.07123, lr:7.25e-03, fs:0.85246 (r=0.788,p=0.929),  time:42.939, tt:6397.917\n",
      "Ep:149, loss:0.00001, loss_test:0.07151, lr:7.18e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.939, tt:6440.843\n",
      "Ep:150, loss:0.00001, loss_test:0.07120, lr:7.11e-03, fs:0.82022 (r=0.737,p=0.924),  time:42.942, tt:6484.251\n",
      "Ep:151, loss:0.00001, loss_test:0.06941, lr:7.03e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.944, tt:6527.552\n",
      "Ep:152, loss:0.00001, loss_test:0.07197, lr:6.96e-03, fs:0.81356 (r=0.727,p=0.923),  time:42.932, tt:6568.581\n",
      "Ep:153, loss:0.00001, loss_test:0.07045, lr:6.89e-03, fs:0.84615 (r=0.778,p=0.928),  time:42.934, tt:6611.896\n",
      "Ep:154, loss:0.00001, loss_test:0.07071, lr:6.83e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.902, tt:6649.852\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14230, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.822, tt:34.822\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13958, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:37.463, tt:74.927\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13443, lr:1.00e-02, fs:0.68041 (r=1.000,p=0.516),  time:39.357, tt:118.071\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12719, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:40.473, tt:161.893\n",
      "Ep:4, loss:0.00024, loss_test:0.11844, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:40.724, tt:203.621\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11059, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:41.147, tt:246.880\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10852, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:41.307, tt:289.146\n",
      "Ep:7, loss:0.00021, loss_test:0.11057, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:41.494, tt:331.951\n",
      "Ep:8, loss:0.00020, loss_test:0.10782, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:41.551, tt:373.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:9, loss:0.00020, loss_test:0.10493, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:41.568, tt:415.679\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.10265, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:41.725, tt:458.970\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10201, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:41.801, tt:501.607\n",
      "Ep:12, loss:0.00018, loss_test:0.09966, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.798, tt:543.377\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09886, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:41.894, tt:586.516\n",
      "Ep:14, loss:0.00017, loss_test:0.09878, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:41.900, tt:628.495\n",
      "Ep:15, loss:0.00017, loss_test:0.09667, lr:1.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:41.848, tt:669.563\n",
      "Ep:16, loss:0.00017, loss_test:0.09411, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:41.825, tt:711.024\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09295, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:41.870, tt:753.655\n",
      "Ep:18, loss:0.00016, loss_test:0.09205, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:41.903, tt:796.162\n",
      "Ep:19, loss:0.00015, loss_test:0.09066, lr:1.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:41.981, tt:839.625\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.09038, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:42.022, tt:882.460\n",
      "Ep:21, loss:0.00015, loss_test:0.08869, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:41.961, tt:923.144\n",
      "Ep:22, loss:0.00014, loss_test:0.08747, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:41.980, tt:965.539\n",
      "Ep:23, loss:0.00014, loss_test:0.08525, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:41.988, tt:1007.712\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08576, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:42.129, tt:1053.216\n",
      "Ep:25, loss:0.00013, loss_test:0.08352, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:42.186, tt:1096.834\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08392, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:42.227, tt:1140.117\n",
      "Ep:27, loss:0.00013, loss_test:0.08340, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:42.212, tt:1181.930\n",
      "Ep:28, loss:0.00012, loss_test:0.08095, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:42.245, tt:1225.097\n",
      "Ep:29, loss:0.00012, loss_test:0.08137, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:42.266, tt:1267.988\n",
      "Ep:30, loss:0.00012, loss_test:0.07869, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.276, tt:1310.556\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07969, lr:1.00e-02, fs:0.80769 (r=0.848,p=0.771),  time:42.265, tt:1352.482\n",
      "Ep:32, loss:0.00011, loss_test:0.07691, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.307, tt:1396.146\n",
      "Ep:33, loss:0.00011, loss_test:0.07733, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.319, tt:1438.833\n",
      "Ep:34, loss:0.00011, loss_test:0.07593, lr:1.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.406, tt:1484.224\n",
      "Ep:35, loss:0.00010, loss_test:0.07628, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.346, tt:1524.447\n",
      "Ep:36, loss:0.00010, loss_test:0.07430, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:42.400, tt:1568.817\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00010, loss_test:0.07468, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:42.395, tt:1611.011\n",
      "Ep:38, loss:0.00010, loss_test:0.07397, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:42.414, tt:1654.130\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07391, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:42.401, tt:1696.041\n",
      "Ep:40, loss:0.00009, loss_test:0.07276, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:42.362, tt:1736.840\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.07407, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:42.318, tt:1777.338\n",
      "Ep:42, loss:0.00009, loss_test:0.07158, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:42.318, tt:1819.664\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00009, loss_test:0.07394, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:42.337, tt:1862.841\n",
      "Ep:44, loss:0.00009, loss_test:0.07119, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:42.332, tt:1904.957\n",
      "Ep:45, loss:0.00008, loss_test:0.07096, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:42.297, tt:1945.648\n",
      "Ep:46, loss:0.00008, loss_test:0.07341, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:42.339, tt:1989.932\n",
      "Ep:47, loss:0.00008, loss_test:0.07041, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:42.345, tt:2032.567\n",
      "Ep:48, loss:0.00008, loss_test:0.07467, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:42.350, tt:2075.162\n",
      "Ep:49, loss:0.00008, loss_test:0.06862, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:42.326, tt:2116.310\n",
      "Ep:50, loss:0.00008, loss_test:0.06843, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:42.358, tt:2160.251\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00008, loss_test:0.06945, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:42.379, tt:2203.691\n",
      "Ep:52, loss:0.00007, loss_test:0.06867, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:42.403, tt:2247.369\n",
      "Ep:53, loss:0.00007, loss_test:0.08065, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:42.411, tt:2290.188\n",
      "Ep:54, loss:0.00008, loss_test:0.07134, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:42.403, tt:2332.152\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00008, loss_test:0.07525, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:42.431, tt:2376.156\n",
      "Ep:56, loss:0.00008, loss_test:0.06878, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:42.408, tt:2417.262\n",
      "Ep:57, loss:0.00007, loss_test:0.06827, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:42.391, tt:2458.679\n",
      "Ep:58, loss:0.00007, loss_test:0.07825, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:42.388, tt:2500.879\n",
      "Ep:59, loss:0.00008, loss_test:0.06997, lr:1.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:42.404, tt:2544.215\n",
      "Ep:60, loss:0.00007, loss_test:0.07271, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:42.405, tt:2586.716\n",
      "Ep:61, loss:0.00007, loss_test:0.06712, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:42.405, tt:2629.118\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.07293, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:42.400, tt:2671.230\n",
      "Ep:63, loss:0.00007, loss_test:0.06710, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:42.388, tt:2712.825\n",
      "Ep:64, loss:0.00006, loss_test:0.07060, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:42.382, tt:2754.821\n",
      "Ep:65, loss:0.00006, loss_test:0.06782, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:42.398, tt:2798.260\n",
      "Ep:66, loss:0.00006, loss_test:0.06830, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:42.380, tt:2839.476\n",
      "Ep:67, loss:0.00006, loss_test:0.06659, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:42.331, tt:2878.489\n",
      "Ep:68, loss:0.00005, loss_test:0.06970, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:42.246, tt:2914.991\n",
      "Ep:69, loss:0.00005, loss_test:0.06755, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:42.140, tt:2949.799\n",
      "Ep:70, loss:0.00005, loss_test:0.06863, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:42.110, tt:2989.783\n",
      "Ep:71, loss:0.00005, loss_test:0.06718, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:42.126, tt:3033.097\n",
      "Ep:72, loss:0.00005, loss_test:0.07255, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:42.115, tt:3074.360\n",
      "Ep:73, loss:0.00005, loss_test:0.06617, lr:9.90e-03, fs:0.87685 (r=0.899,p=0.856),  time:42.129, tt:3117.570\n",
      "Ep:74, loss:0.00005, loss_test:0.06940, lr:9.80e-03, fs:0.87179 (r=0.859,p=0.885),  time:42.134, tt:3160.034\n",
      "Ep:75, loss:0.00005, loss_test:0.06888, lr:9.70e-03, fs:0.77778 (r=0.707,p=0.864),  time:42.153, tt:3203.628\n",
      "Ep:76, loss:0.00005, loss_test:0.07319, lr:9.61e-03, fs:0.86275 (r=0.889,p=0.838),  time:42.168, tt:3246.943\n",
      "Ep:77, loss:0.00005, loss_test:0.06610, lr:9.51e-03, fs:0.81319 (r=0.747,p=0.892),  time:42.168, tt:3289.114\n",
      "Ep:78, loss:0.00005, loss_test:0.06799, lr:9.41e-03, fs:0.77348 (r=0.707,p=0.854),  time:42.148, tt:3329.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00005, loss_test:0.06846, lr:9.32e-03, fs:0.87562 (r=0.889,p=0.863),  time:42.148, tt:3371.822\n",
      "Ep:80, loss:0.00005, loss_test:0.07292, lr:9.23e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.185, tt:3416.969\n",
      "Ep:81, loss:0.00005, loss_test:0.06574, lr:9.14e-03, fs:0.86010 (r=0.838,p=0.883),  time:42.189, tt:3459.508\n",
      "Ep:82, loss:0.00004, loss_test:0.06859, lr:9.04e-03, fs:0.80874 (r=0.747,p=0.881),  time:42.183, tt:3501.208\n",
      "Ep:83, loss:0.00004, loss_test:0.06807, lr:8.95e-03, fs:0.77778 (r=0.707,p=0.864),  time:42.165, tt:3541.852\n",
      "Ep:84, loss:0.00004, loss_test:0.06823, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:42.160, tt:3583.595\n",
      "Ep:85, loss:0.00004, loss_test:0.06816, lr:8.78e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.188, tt:3628.211\n",
      "Ep:86, loss:0.00004, loss_test:0.06857, lr:8.69e-03, fs:0.78212 (r=0.707,p=0.875),  time:42.187, tt:3670.246\n",
      "Ep:87, loss:0.00004, loss_test:0.06706, lr:8.60e-03, fs:0.79558 (r=0.727,p=0.878),  time:42.176, tt:3711.485\n",
      "Ep:88, loss:0.00004, loss_test:0.06780, lr:8.51e-03, fs:0.78889 (r=0.717,p=0.877),  time:42.184, tt:3754.401\n",
      "Ep:89, loss:0.00004, loss_test:0.06864, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.170, tt:3795.289\n",
      "Ep:90, loss:0.00004, loss_test:0.06785, lr:8.35e-03, fs:0.84974 (r=0.828,p=0.872),  time:42.171, tt:3837.520\n",
      "Ep:91, loss:0.00004, loss_test:0.06815, lr:8.26e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.181, tt:3880.687\n",
      "Ep:92, loss:0.00004, loss_test:0.06795, lr:8.18e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.175, tt:3922.275\n",
      "Ep:93, loss:0.00003, loss_test:0.06998, lr:8.10e-03, fs:0.80663 (r=0.737,p=0.890),  time:42.157, tt:3962.760\n",
      "Ep:94, loss:0.00003, loss_test:0.06673, lr:8.02e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.166, tt:4005.792\n",
      "Ep:95, loss:0.00003, loss_test:0.06912, lr:7.94e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.165, tt:4047.836\n",
      "Ep:96, loss:0.00003, loss_test:0.06869, lr:7.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.167, tt:4090.162\n",
      "Ep:97, loss:0.00003, loss_test:0.06803, lr:7.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.153, tt:4131.042\n",
      "Ep:98, loss:0.00003, loss_test:0.06688, lr:7.70e-03, fs:0.80220 (r=0.737,p=0.880),  time:42.142, tt:4172.036\n",
      "Ep:99, loss:0.00003, loss_test:0.06885, lr:7.62e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.139, tt:4213.923\n",
      "Ep:100, loss:0.00003, loss_test:0.06788, lr:7.55e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.161, tt:4258.224\n",
      "Ep:101, loss:0.00003, loss_test:0.06850, lr:7.47e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.167, tt:4301.084\n",
      "Ep:102, loss:0.00003, loss_test:0.06747, lr:7.40e-03, fs:0.78652 (r=0.707,p=0.886),  time:42.180, tt:4344.520\n",
      "Ep:103, loss:0.00003, loss_test:0.06879, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:42.198, tt:4388.612\n",
      "Ep:104, loss:0.00003, loss_test:0.06871, lr:7.25e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.217, tt:4432.751\n",
      "Ep:105, loss:0.00003, loss_test:0.06826, lr:7.18e-03, fs:0.76836 (r=0.687,p=0.872),  time:42.243, tt:4477.786\n",
      "Ep:106, loss:0.00003, loss_test:0.06890, lr:7.11e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.243, tt:4520.054\n",
      "Ep:107, loss:0.00003, loss_test:0.06787, lr:7.03e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.242, tt:4562.185\n",
      "Ep:108, loss:0.00003, loss_test:0.06859, lr:6.96e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.244, tt:4604.613\n",
      "Ep:109, loss:0.00003, loss_test:0.06860, lr:6.89e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.229, tt:4645.184\n",
      "Ep:110, loss:0.00003, loss_test:0.06866, lr:6.83e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.267, tt:4691.684\n",
      "Ep:111, loss:0.00003, loss_test:0.06771, lr:6.76e-03, fs:0.77273 (r=0.687,p=0.883),  time:42.299, tt:4737.516\n",
      "Ep:112, loss:0.00003, loss_test:0.06844, lr:6.69e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.329, tt:4783.223\n",
      "Ep:113, loss:0.00003, loss_test:0.06783, lr:6.62e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.335, tt:4826.180\n",
      "Ep:114, loss:0.00003, loss_test:0.06872, lr:6.56e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.333, tt:4868.335\n",
      "Ep:115, loss:0.00003, loss_test:0.06872, lr:6.49e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.337, tt:4911.050\n",
      "Ep:116, loss:0.00003, loss_test:0.06904, lr:6.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.333, tt:4952.971\n",
      "Ep:117, loss:0.00003, loss_test:0.06907, lr:6.36e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.325, tt:4994.334\n",
      "Ep:118, loss:0.00003, loss_test:0.06832, lr:6.30e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.303, tt:5034.098\n",
      "Ep:119, loss:0.00002, loss_test:0.06987, lr:6.24e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.307, tt:5076.803\n",
      "Ep:120, loss:0.00002, loss_test:0.06774, lr:6.17e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.307, tt:5119.178\n",
      "Ep:121, loss:0.00002, loss_test:0.06863, lr:6.11e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5162.063\n",
      "Ep:122, loss:0.00002, loss_test:0.06953, lr:6.05e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5204.426\n",
      "Ep:123, loss:0.00002, loss_test:0.06823, lr:5.99e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.298, tt:5244.968\n",
      "Ep:124, loss:0.00002, loss_test:0.06860, lr:5.93e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.300, tt:5287.499\n",
      "Ep:125, loss:0.00002, loss_test:0.06821, lr:5.87e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.294, tt:5329.078\n",
      "Ep:126, loss:0.00002, loss_test:0.06893, lr:5.81e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.311, tt:5373.474\n",
      "Ep:127, loss:0.00002, loss_test:0.06944, lr:5.75e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.307, tt:5415.319\n",
      "Ep:128, loss:0.00002, loss_test:0.06904, lr:5.70e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.312, tt:5458.271\n",
      "Ep:129, loss:0.00002, loss_test:0.06954, lr:5.64e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.329, tt:5502.799\n",
      "Ep:130, loss:0.00002, loss_test:0.06853, lr:5.58e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.347, tt:5547.442\n",
      "Ep:131, loss:0.00002, loss_test:0.06923, lr:5.53e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.357, tt:5591.066\n",
      "Ep:132, loss:0.00002, loss_test:0.06949, lr:5.47e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.345, tt:5631.929\n",
      "Ep:133, loss:0.00002, loss_test:0.07012, lr:5.42e-03, fs:0.80226 (r=0.717,p=0.910),  time:42.337, tt:5673.212\n",
      "Ep:134, loss:0.00002, loss_test:0.06716, lr:5.36e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.336, tt:5715.395\n",
      "Ep:135, loss:0.00002, loss_test:0.07020, lr:5.31e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.345, tt:5758.863\n",
      "Ep:136, loss:0.00002, loss_test:0.06922, lr:5.26e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.365, tt:5804.046\n",
      "Ep:137, loss:0.00002, loss_test:0.06860, lr:5.20e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:5844.345\n",
      "Ep:138, loss:0.00002, loss_test:0.06843, lr:5.15e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.364, tt:5888.609\n",
      "Ep:139, loss:0.00002, loss_test:0.06939, lr:5.10e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.358, tt:5930.180\n",
      "Ep:140, loss:0.00002, loss_test:0.06842, lr:5.05e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.362, tt:5972.995\n",
      "Ep:141, loss:0.00002, loss_test:0.06905, lr:5.00e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.368, tt:6016.287\n",
      "Ep:142, loss:0.00002, loss_test:0.06881, lr:4.95e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.357, tt:6057.019\n",
      "Ep:143, loss:0.00002, loss_test:0.06938, lr:4.90e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:6098.347\n",
      "Ep:144, loss:0.00002, loss_test:0.06908, lr:4.85e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.350, tt:6140.681\n",
      "Ep:145, loss:0.00002, loss_test:0.06905, lr:4.80e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.358, tt:6184.231\n",
      "Ep:146, loss:0.00002, loss_test:0.06888, lr:4.75e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.356, tt:6226.366\n",
      "Ep:147, loss:0.00002, loss_test:0.06893, lr:4.71e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.370, tt:6270.833\n",
      "Ep:148, loss:0.00002, loss_test:0.06972, lr:4.66e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.376, tt:6314.067\n",
      "Ep:149, loss:0.00002, loss_test:0.06852, lr:4.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.377, tt:6356.546\n",
      "Ep:150, loss:0.00002, loss_test:0.06995, lr:4.57e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.369, tt:6397.734\n",
      "Ep:151, loss:0.00002, loss_test:0.06927, lr:4.52e-03, fs:0.79096 (r=0.707,p=0.897),  time:42.363, tt:6439.245\n",
      "Ep:152, loss:0.00002, loss_test:0.06896, lr:4.48e-03, fs:0.79545 (r=0.707,p=0.909),  time:42.363, tt:6481.489\n",
      "Ep:153, loss:0.00002, loss_test:0.06939, lr:4.43e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.360, tt:6523.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00002, loss_test:0.06923, lr:4.39e-03, fs:0.79775 (r=0.717,p=0.899),  time:42.336, tt:6562.115\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14054, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:14.363, tt:14.363\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13810, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:14.784, tt:29.569\n",
      "Ep:2, loss:0.00027, loss_test:0.13535, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:14.426, tt:43.277\n",
      "Ep:3, loss:0.00026, loss_test:0.13333, lr:1.00e-02, fs:0.66421 (r=0.909,p=0.523),  time:15.848, tt:63.393\n",
      "Ep:4, loss:0.00025, loss_test:0.12981, lr:1.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:16.611, tt:83.055\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12527, lr:1.00e-02, fs:0.66935 (r=0.838,p=0.557),  time:16.640, tt:99.840\n",
      "Ep:6, loss:0.00024, loss_test:0.12155, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:17.190, tt:120.333\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11921, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:17.250, tt:137.999\n",
      "Ep:8, loss:0.00023, loss_test:0.11686, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:17.538, tt:157.843\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11327, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:17.637, tt:176.367\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.11000, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:17.622, tt:193.840\n",
      "Ep:11, loss:0.00021, loss_test:0.10747, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:17.567, tt:210.806\n",
      "Ep:12, loss:0.00021, loss_test:0.10515, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:17.624, tt:229.117\n",
      "Ep:13, loss:0.00020, loss_test:0.10209, lr:1.00e-02, fs:0.71493 (r=0.798,p=0.648),  time:17.707, tt:247.897\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09946, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:17.735, tt:266.021\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09570, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:17.631, tt:282.101\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09333, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:17.580, tt:298.865\n",
      "Ep:17, loss:0.00017, loss_test:0.09108, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:17.481, tt:314.664\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08797, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:17.567, tt:333.773\n",
      "Ep:19, loss:0.00016, loss_test:0.08645, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:17.574, tt:351.487\n",
      "Ep:20, loss:0.00016, loss_test:0.08485, lr:1.00e-02, fs:0.75238 (r=0.798,p=0.712),  time:17.546, tt:368.456\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08358, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:17.514, tt:385.304\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08360, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:17.504, tt:402.592\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.08260, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.608, tt:422.590\n",
      "Ep:24, loss:0.00014, loss_test:0.08110, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.666, tt:441.654\n",
      "Ep:25, loss:0.00013, loss_test:0.08076, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:17.610, tt:457.854\n",
      "Ep:26, loss:0.00013, loss_test:0.07986, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:17.628, tt:475.953\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07952, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:17.627, tt:493.545\n",
      "Ep:28, loss:0.00012, loss_test:0.07728, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.706, tt:513.466\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07900, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:17.797, tt:533.917\n",
      "Ep:30, loss:0.00011, loss_test:0.07613, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:17.727, tt:549.541\n",
      "Ep:31, loss:0.00011, loss_test:0.07582, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:17.769, tt:568.598\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.07322, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:17.785, tt:586.915\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07381, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:17.742, tt:603.222\n",
      "Ep:34, loss:0.00010, loss_test:0.07086, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:17.797, tt:622.902\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.07200, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:17.786, tt:640.290\n",
      "Ep:36, loss:0.00009, loss_test:0.06752, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:17.807, tt:658.875\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07320, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:17.861, tt:678.728\n",
      "Ep:38, loss:0.00009, loss_test:0.06603, lr:1.00e-02, fs:0.85854 (r=0.889,p=0.830),  time:17.883, tt:697.454\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06950, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:17.885, tt:715.412\n",
      "Ep:40, loss:0.00008, loss_test:0.06753, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:17.854, tt:732.032\n",
      "Ep:41, loss:0.00008, loss_test:0.06750, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:17.854, tt:749.866\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.06537, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:17.837, tt:766.973\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06792, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:17.840, tt:784.944\n",
      "Ep:44, loss:0.00007, loss_test:0.06259, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:17.862, tt:803.796\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06411, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:17.822, tt:819.825\n",
      "Ep:46, loss:0.00007, loss_test:0.06370, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:17.847, tt:838.816\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.06188, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:17.851, tt:856.849\n",
      "Ep:48, loss:0.00006, loss_test:0.06800, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:17.829, tt:873.620\n",
      "Ep:49, loss:0.00006, loss_test:0.06073, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:17.805, tt:890.248\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.07013, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:17.780, tt:906.759\n",
      "Ep:51, loss:0.00006, loss_test:0.06431, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:17.802, tt:925.703\n",
      "Ep:52, loss:0.00006, loss_test:0.06330, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:17.811, tt:943.990\n",
      "Ep:53, loss:0.00006, loss_test:0.06800, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:17.783, tt:960.257\n",
      "Ep:54, loss:0.00005, loss_test:0.06144, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:17.799, tt:978.945\n",
      "Ep:55, loss:0.00005, loss_test:0.06562, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:17.821, tt:997.994\n",
      "Ep:56, loss:0.00005, loss_test:0.05880, lr:1.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:17.908, tt:1020.779\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.06976, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:17.972, tt:1042.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:58, loss:0.00005, loss_test:0.05783, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:18.012, tt:1062.717\n",
      "Ep:59, loss:0.00005, loss_test:0.06349, lr:1.00e-02, fs:0.85714 (r=0.818,p=0.900),  time:18.041, tt:1082.447\n",
      "Ep:60, loss:0.00004, loss_test:0.05982, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:18.007, tt:1098.410\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00004, loss_test:0.06409, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:18.027, tt:1117.687\n",
      "Ep:62, loss:0.00004, loss_test:0.05789, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:18.017, tt:1135.095\n",
      "Ep:63, loss:0.00004, loss_test:0.06263, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:18.016, tt:1153.010\n",
      "Ep:64, loss:0.00004, loss_test:0.06954, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:18.048, tt:1173.145\n",
      "Ep:65, loss:0.00004, loss_test:0.05589, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:18.020, tt:1189.333\n",
      "Ep:66, loss:0.00004, loss_test:0.07176, lr:1.00e-02, fs:0.80000 (r=0.727,p=0.889),  time:18.019, tt:1207.260\n",
      "Ep:67, loss:0.00004, loss_test:0.05542, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.997, tt:1223.809\n",
      "Ep:68, loss:0.00004, loss_test:0.06460, lr:1.00e-02, fs:0.82222 (r=0.747,p=0.914),  time:17.980, tt:1240.612\n",
      "Ep:69, loss:0.00004, loss_test:0.06312, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:17.970, tt:1257.887\n",
      "Ep:70, loss:0.00003, loss_test:0.06157, lr:1.00e-02, fs:0.87500 (r=0.848,p=0.903),  time:17.945, tt:1274.092\n",
      "Ep:71, loss:0.00003, loss_test:0.06121, lr:1.00e-02, fs:0.86631 (r=0.818,p=0.920),  time:17.942, tt:1291.812\n",
      "Ep:72, loss:0.00003, loss_test:0.06230, lr:9.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:17.937, tt:1309.411\n",
      "Ep:73, loss:0.00003, loss_test:0.05952, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.931, tt:1326.870\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00003, loss_test:0.06079, lr:9.80e-03, fs:0.85561 (r=0.808,p=0.909),  time:17.922, tt:1344.178\n",
      "Ep:75, loss:0.00003, loss_test:0.06211, lr:9.80e-03, fs:0.86957 (r=0.808,p=0.941),  time:17.913, tt:1361.393\n",
      "Ep:76, loss:0.00003, loss_test:0.06000, lr:9.80e-03, fs:0.87500 (r=0.848,p=0.903),  time:17.947, tt:1381.901\n",
      "Ep:77, loss:0.00003, loss_test:0.06169, lr:9.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:17.947, tt:1399.882\n",
      "Ep:78, loss:0.00003, loss_test:0.05998, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.924, tt:1415.978\n",
      "Ep:79, loss:0.00003, loss_test:0.05865, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.944, tt:1435.491\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.06010, lr:9.80e-03, fs:0.88421 (r=0.848,p=0.923),  time:17.927, tt:1452.081\n",
      "Ep:81, loss:0.00002, loss_test:0.06092, lr:9.80e-03, fs:0.86339 (r=0.798,p=0.940),  time:17.924, tt:1469.739\n",
      "Ep:82, loss:0.00002, loss_test:0.06011, lr:9.80e-03, fs:0.86486 (r=0.808,p=0.930),  time:17.935, tt:1488.589\n",
      "Ep:83, loss:0.00002, loss_test:0.06725, lr:9.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:17.913, tt:1504.713\n",
      "Ep:84, loss:0.00002, loss_test:0.05549, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.899, tt:1521.435\n",
      "Ep:85, loss:0.00002, loss_test:0.06310, lr:9.80e-03, fs:0.84615 (r=0.778,p=0.928),  time:17.875, tt:1537.244\n",
      "Ep:86, loss:0.00002, loss_test:0.05584, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.884, tt:1555.881\n",
      "Ep:87, loss:0.00002, loss_test:0.06584, lr:9.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:17.881, tt:1573.566\n",
      "Ep:88, loss:0.00002, loss_test:0.05590, lr:9.80e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.861, tt:1589.617\n",
      "Ep:89, loss:0.00002, loss_test:0.06226, lr:9.80e-03, fs:0.82486 (r=0.737,p=0.936),  time:17.851, tt:1606.617\n",
      "Ep:90, loss:0.00002, loss_test:0.05606, lr:9.80e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.845, tt:1623.905\n",
      "Ep:91, loss:0.00002, loss_test:0.06296, lr:9.70e-03, fs:0.82682 (r=0.747,p=0.925),  time:17.827, tt:1640.096\n",
      "Ep:92, loss:0.00002, loss_test:0.05625, lr:9.61e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.827, tt:1657.875\n",
      "Ep:93, loss:0.00002, loss_test:0.06189, lr:9.51e-03, fs:0.83978 (r=0.768,p=0.927),  time:17.812, tt:1674.288\n",
      "Ep:94, loss:0.00002, loss_test:0.05984, lr:9.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:17.826, tt:1693.488\n",
      "Ep:95, loss:0.00002, loss_test:0.06849, lr:9.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.852, tt:1713.818\n",
      "Ep:96, loss:0.00002, loss_test:0.05332, lr:9.23e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.830, tt:1729.497\n",
      "Ep:97, loss:0.00002, loss_test:0.06689, lr:9.14e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.825, tt:1746.828\n",
      "Ep:98, loss:0.00002, loss_test:0.06140, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.807, tt:1762.935\n",
      "Ep:99, loss:0.00002, loss_test:0.05723, lr:8.95e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.812, tt:1781.182\n",
      "Ep:100, loss:0.00002, loss_test:0.06518, lr:8.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.801, tt:1797.885\n",
      "Ep:101, loss:0.00002, loss_test:0.05623, lr:8.78e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.791, tt:1814.732\n",
      "Ep:102, loss:0.00002, loss_test:0.06997, lr:8.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.788, tt:1832.144\n",
      "Ep:103, loss:0.00002, loss_test:0.05555, lr:8.60e-03, fs:0.88889 (r=0.848,p=0.933),  time:17.796, tt:1850.735\n",
      "Ep:104, loss:0.00002, loss_test:0.06793, lr:8.51e-03, fs:0.81818 (r=0.727,p=0.935),  time:17.792, tt:1868.193\n",
      "Ep:105, loss:0.00002, loss_test:0.05582, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.790, tt:1885.744\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.06201, lr:8.43e-03, fs:0.83516 (r=0.768,p=0.916),  time:17.775, tt:1901.882\n",
      "Ep:107, loss:0.00002, loss_test:0.06069, lr:8.43e-03, fs:0.83908 (r=0.737,p=0.973),  time:17.770, tt:1919.161\n",
      "Ep:108, loss:0.00002, loss_test:0.05769, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:17.772, tt:1937.138\n",
      "Ep:109, loss:0.00002, loss_test:0.06163, lr:8.43e-03, fs:0.83237 (r=0.727,p=0.973),  time:17.806, tt:1958.648\n",
      "Ep:110, loss:0.00002, loss_test:0.06048, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.880, tt:1984.656\n",
      "Ep:111, loss:0.00002, loss_test:0.05775, lr:8.43e-03, fs:0.89947 (r=0.859,p=0.944),  time:17.885, tt:2003.146\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00002, loss_test:0.06665, lr:8.43e-03, fs:0.83721 (r=0.727,p=0.986),  time:17.904, tt:2023.133\n",
      "Ep:113, loss:0.00002, loss_test:0.05557, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.903, tt:2040.969\n",
      "Ep:114, loss:0.00002, loss_test:0.06196, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.925, tt:2061.337\n",
      "Ep:115, loss:0.00002, loss_test:0.05745, lr:8.43e-03, fs:0.86034 (r=0.778,p=0.963),  time:17.941, tt:2081.113\n",
      "Ep:116, loss:0.00001, loss_test:0.06193, lr:8.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:17.956, tt:2100.888\n",
      "Ep:117, loss:0.00002, loss_test:0.05488, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.950, tt:2118.107\n",
      "Ep:118, loss:0.00001, loss_test:0.06390, lr:8.43e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.952, tt:2136.317\n",
      "Ep:119, loss:0.00001, loss_test:0.05534, lr:8.43e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.949, tt:2153.933\n",
      "Ep:120, loss:0.00001, loss_test:0.06368, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.950, tt:2171.997\n",
      "Ep:121, loss:0.00001, loss_test:0.05843, lr:8.43e-03, fs:0.83429 (r=0.737,p=0.961),  time:17.938, tt:2188.384\n",
      "Ep:122, loss:0.00001, loss_test:0.05722, lr:8.43e-03, fs:0.89362 (r=0.848,p=0.944),  time:17.936, tt:2206.169\n",
      "Ep:123, loss:0.00001, loss_test:0.06003, lr:8.35e-03, fs:0.83429 (r=0.737,p=0.961),  time:17.928, tt:2223.091\n",
      "Ep:124, loss:0.00001, loss_test:0.05976, lr:8.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.924, tt:2240.483\n",
      "Ep:125, loss:0.00001, loss_test:0.05884, lr:8.18e-03, fs:0.87432 (r=0.808,p=0.952),  time:17.926, tt:2258.652\n",
      "Ep:126, loss:0.00001, loss_test:0.06049, lr:8.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.921, tt:2275.916\n",
      "Ep:127, loss:0.00001, loss_test:0.05776, lr:8.02e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.923, tt:2294.195\n",
      "Ep:128, loss:0.00001, loss_test:0.05982, lr:7.94e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.901, tt:2309.196\n",
      "Ep:129, loss:0.00001, loss_test:0.05789, lr:7.86e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.898, tt:2326.696\n",
      "Ep:130, loss:0.00001, loss_test:0.05909, lr:7.78e-03, fs:0.83616 (r=0.747,p=0.949),  time:17.898, tt:2344.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.05871, lr:7.70e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.889, tt:2361.314\n",
      "Ep:132, loss:0.00001, loss_test:0.05681, lr:7.62e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.896, tt:2380.103\n",
      "Ep:133, loss:0.00001, loss_test:0.05680, lr:7.55e-03, fs:0.90323 (r=0.848,p=0.966),  time:17.879, tt:2395.756\n",
      "##########Best model found so far##########\n",
      "Ep:134, loss:0.00001, loss_test:0.05967, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.863, tt:2411.513\n",
      "Ep:135, loss:0.00001, loss_test:0.05863, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.857, tt:2428.596\n",
      "Ep:136, loss:0.00001, loss_test:0.05812, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.853, tt:2445.836\n",
      "Ep:137, loss:0.00001, loss_test:0.05916, lr:7.55e-03, fs:0.82759 (r=0.727,p=0.960),  time:17.861, tt:2464.801\n",
      "Ep:138, loss:0.00001, loss_test:0.05829, lr:7.55e-03, fs:0.84916 (r=0.768,p=0.950),  time:17.849, tt:2481.068\n",
      "Ep:139, loss:0.00001, loss_test:0.05799, lr:7.55e-03, fs:0.85556 (r=0.778,p=0.951),  time:17.835, tt:2496.917\n",
      "Ep:140, loss:0.00001, loss_test:0.05889, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.836, tt:2514.868\n",
      "Ep:141, loss:0.00001, loss_test:0.05765, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:17.829, tt:2531.707\n",
      "Ep:142, loss:0.00001, loss_test:0.05894, lr:7.55e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.830, tt:2549.620\n",
      "Ep:143, loss:0.00001, loss_test:0.05917, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.838, tt:2568.669\n",
      "Ep:144, loss:0.00001, loss_test:0.05766, lr:7.55e-03, fs:0.86188 (r=0.788,p=0.951),  time:17.836, tt:2586.205\n",
      "Ep:145, loss:0.00001, loss_test:0.06065, lr:7.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.840, tt:2604.571\n",
      "Ep:146, loss:0.00001, loss_test:0.05693, lr:7.40e-03, fs:0.89840 (r=0.848,p=0.955),  time:17.828, tt:2620.758\n",
      "Ep:147, loss:0.00001, loss_test:0.06095, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.830, tt:2638.910\n",
      "Ep:148, loss:0.00001, loss_test:0.05807, lr:7.25e-03, fs:0.86813 (r=0.798,p=0.952),  time:17.827, tt:2656.231\n",
      "Ep:149, loss:0.00001, loss_test:0.05926, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.819, tt:2672.912\n",
      "Ep:150, loss:0.00001, loss_test:0.05847, lr:7.11e-03, fs:0.82955 (r=0.737,p=0.948),  time:17.812, tt:2689.611\n",
      "Ep:151, loss:0.00001, loss_test:0.06321, lr:7.03e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.809, tt:2706.970\n",
      "Ep:152, loss:0.00001, loss_test:0.05629, lr:6.96e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.822, tt:2726.819\n",
      "Ep:153, loss:0.00001, loss_test:0.06300, lr:6.89e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.831, tt:2745.958\n",
      "Ep:154, loss:0.00001, loss_test:0.05783, lr:6.83e-03, fs:0.88043 (r=0.818,p=0.953),  time:17.835, tt:2764.493\n",
      "Ep:155, loss:0.00001, loss_test:0.06251, lr:6.76e-03, fs:0.82286 (r=0.727,p=0.947),  time:17.812, tt:2778.726\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14059, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:16.639, tt:16.639\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13789, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:16.767, tt:33.533\n",
      "Ep:2, loss:0.00027, loss_test:0.13362, lr:1.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:15.348, tt:46.045\n",
      "Ep:3, loss:0.00026, loss_test:0.12978, lr:1.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:15.798, tt:63.192\n",
      "Ep:4, loss:0.00025, loss_test:0.12653, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:16.100, tt:80.502\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.12341, lr:1.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:16.562, tt:99.371\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11998, lr:1.00e-02, fs:0.67213 (r=0.828,p=0.566),  time:16.990, tt:118.928\n",
      "Ep:7, loss:0.00024, loss_test:0.11711, lr:1.00e-02, fs:0.68571 (r=0.848,p=0.575),  time:17.123, tt:136.983\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11402, lr:1.00e-02, fs:0.69388 (r=0.859,p=0.582),  time:17.230, tt:155.070\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.11057, lr:1.00e-02, fs:0.69136 (r=0.848,p=0.583),  time:17.187, tt:171.872\n",
      "Ep:10, loss:0.00022, loss_test:0.10646, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:17.289, tt:190.180\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10252, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:17.621, tt:211.457\n",
      "Ep:12, loss:0.00020, loss_test:0.09898, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:17.536, tt:227.965\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09590, lr:1.00e-02, fs:0.75556 (r=0.859,p=0.675),  time:17.610, tt:246.536\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09255, lr:1.00e-02, fs:0.77193 (r=0.889,p=0.682),  time:17.501, tt:262.517\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08983, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:17.437, tt:278.999\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08779, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:17.307, tt:294.224\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08538, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:17.087, tt:307.569\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08364, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:17.027, tt:323.504\n",
      "Ep:19, loss:0.00016, loss_test:0.08230, lr:1.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:16.917, tt:338.340\n",
      "Ep:20, loss:0.00016, loss_test:0.08121, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:16.972, tt:356.415\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08013, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:17.060, tt:375.324\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.07943, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:17.110, tt:393.524\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07897, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:17.190, tt:412.566\n",
      "Ep:24, loss:0.00014, loss_test:0.07831, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:17.202, tt:430.060\n",
      "Ep:25, loss:0.00013, loss_test:0.07750, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:17.243, tt:448.313\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07715, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:17.291, tt:466.846\n",
      "Ep:27, loss:0.00012, loss_test:0.07520, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:17.284, tt:483.965\n",
      "Ep:28, loss:0.00012, loss_test:0.07480, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:17.384, tt:504.125\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07336, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:17.555, tt:526.650\n",
      "Ep:30, loss:0.00011, loss_test:0.07170, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:17.636, tt:546.726\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07076, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:17.739, tt:567.651\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.06947, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:17.753, tt:585.846\n",
      "Ep:33, loss:0.00010, loss_test:0.06844, lr:1.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:17.755, tt:603.658\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06734, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:17.782, tt:622.371\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06611, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:17.809, tt:641.133\n",
      "Ep:36, loss:0.00009, loss_test:0.06447, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:17.811, tt:659.021\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:37, loss:0.00009, loss_test:0.06450, lr:1.00e-02, fs:0.87500 (r=0.919,p=0.835),  time:17.835, tt:677.715\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.06342, lr:1.00e-02, fs:0.86364 (r=0.960,p=0.785),  time:17.865, tt:696.736\n",
      "Ep:39, loss:0.00008, loss_test:0.06329, lr:1.00e-02, fs:0.86878 (r=0.970,p=0.787),  time:17.847, tt:713.888\n",
      "Ep:40, loss:0.00008, loss_test:0.06069, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:17.921, tt:734.744\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06256, lr:1.00e-02, fs:0.87963 (r=0.960,p=0.812),  time:17.925, tt:752.862\n",
      "Ep:42, loss:0.00008, loss_test:0.05934, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:17.996, tt:773.825\n",
      "Ep:43, loss:0.00007, loss_test:0.06147, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:18.073, tt:795.209\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.06034, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:18.054, tt:812.415\n",
      "Ep:45, loss:0.00007, loss_test:0.05979, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:18.043, tt:829.983\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.05975, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:18.059, tt:848.779\n",
      "Ep:47, loss:0.00007, loss_test:0.06508, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:18.050, tt:866.415\n",
      "Ep:48, loss:0.00007, loss_test:0.05669, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.071, tt:885.503\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.05869, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:18.065, tt:903.230\n",
      "Ep:50, loss:0.00006, loss_test:0.05884, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:18.085, tt:922.357\n",
      "Ep:51, loss:0.00006, loss_test:0.05478, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.087, tt:940.514\n",
      "Ep:52, loss:0.00006, loss_test:0.05431, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:18.120, tt:960.354\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.05551, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:18.148, tt:979.994\n",
      "Ep:54, loss:0.00005, loss_test:0.05320, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.183, tt:1000.038\n",
      "Ep:55, loss:0.00005, loss_test:0.05420, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:18.205, tt:1019.469\n",
      "Ep:56, loss:0.00005, loss_test:0.05491, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:18.219, tt:1038.477\n",
      "Ep:57, loss:0.00005, loss_test:0.05359, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:18.247, tt:1058.354\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.05253, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.263, tt:1077.501\n",
      "Ep:59, loss:0.00005, loss_test:0.05989, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:18.274, tt:1096.434\n",
      "Ep:60, loss:0.00005, loss_test:0.05094, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.253, tt:1113.415\n",
      "Ep:61, loss:0.00005, loss_test:0.05479, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:18.290, tt:1133.954\n",
      "Ep:62, loss:0.00005, loss_test:0.05351, lr:1.00e-02, fs:0.91943 (r=0.980,p=0.866),  time:18.301, tt:1152.962\n",
      "Ep:63, loss:0.00004, loss_test:0.05220, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:18.326, tt:1172.873\n",
      "Ep:64, loss:0.00004, loss_test:0.04966, lr:1.00e-02, fs:0.93720 (r=0.980,p=0.898),  time:18.331, tt:1191.524\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.05337, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:18.302, tt:1207.917\n",
      "Ep:66, loss:0.00004, loss_test:0.04967, lr:1.00e-02, fs:0.92381 (r=0.980,p=0.874),  time:18.295, tt:1225.743\n",
      "Ep:67, loss:0.00004, loss_test:0.04957, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:18.296, tt:1244.145\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.05436, lr:1.00e-02, fs:0.91509 (r=0.980,p=0.858),  time:18.280, tt:1261.344\n",
      "Ep:69, loss:0.00004, loss_test:0.05032, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:18.275, tt:1279.239\n",
      "Ep:70, loss:0.00004, loss_test:0.04966, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:18.281, tt:1297.963\n",
      "Ep:71, loss:0.00004, loss_test:0.05332, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:18.257, tt:1314.527\n",
      "Ep:72, loss:0.00004, loss_test:0.04893, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:18.246, tt:1331.979\n",
      "Ep:73, loss:0.00004, loss_test:0.05107, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:18.225, tt:1348.663\n",
      "Ep:74, loss:0.00004, loss_test:0.04855, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:18.255, tt:1369.139\n",
      "Ep:75, loss:0.00004, loss_test:0.05614, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:18.238, tt:1386.126\n",
      "Ep:76, loss:0.00003, loss_test:0.04710, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:18.224, tt:1403.229\n",
      "Ep:77, loss:0.00003, loss_test:0.05439, lr:1.00e-02, fs:0.88235 (r=0.909,p=0.857),  time:18.234, tt:1422.265\n",
      "Ep:78, loss:0.00003, loss_test:0.04681, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:18.229, tt:1440.128\n",
      "Ep:79, loss:0.00003, loss_test:0.05141, lr:9.90e-03, fs:0.90816 (r=0.899,p=0.918),  time:18.221, tt:1457.712\n",
      "Ep:80, loss:0.00003, loss_test:0.04760, lr:9.80e-03, fs:0.94472 (r=0.949,p=0.940),  time:18.231, tt:1476.695\n",
      "Ep:81, loss:0.00003, loss_test:0.04956, lr:9.70e-03, fs:0.91282 (r=0.899,p=0.927),  time:18.233, tt:1495.081\n",
      "Ep:82, loss:0.00003, loss_test:0.04538, lr:9.61e-03, fs:0.96552 (r=0.990,p=0.942),  time:18.229, tt:1513.009\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00003, loss_test:0.04714, lr:9.61e-03, fs:0.94000 (r=0.949,p=0.931),  time:18.212, tt:1529.840\n",
      "Ep:84, loss:0.00003, loss_test:0.04751, lr:9.61e-03, fs:0.91837 (r=0.909,p=0.928),  time:18.199, tt:1546.889\n",
      "Ep:85, loss:0.00003, loss_test:0.04516, lr:9.61e-03, fs:0.93939 (r=0.939,p=0.939),  time:18.226, tt:1567.465\n",
      "Ep:86, loss:0.00003, loss_test:0.04918, lr:9.61e-03, fs:0.90909 (r=0.909,p=0.909),  time:18.238, tt:1586.747\n",
      "Ep:87, loss:0.00003, loss_test:0.04524, lr:9.61e-03, fs:0.92929 (r=0.929,p=0.929),  time:18.232, tt:1604.403\n",
      "Ep:88, loss:0.00003, loss_test:0.04539, lr:9.61e-03, fs:0.91371 (r=0.909,p=0.918),  time:18.234, tt:1622.814\n",
      "Ep:89, loss:0.00003, loss_test:0.04771, lr:9.61e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.233, tt:1640.973\n",
      "Ep:90, loss:0.00002, loss_test:0.04480, lr:9.61e-03, fs:0.92784 (r=0.909,p=0.947),  time:18.231, tt:1658.997\n",
      "Ep:91, loss:0.00002, loss_test:0.04876, lr:9.61e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.238, tt:1677.892\n",
      "Ep:92, loss:0.00002, loss_test:0.04740, lr:9.61e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.253, tt:1697.488\n",
      "Ep:93, loss:0.00002, loss_test:0.04480, lr:9.61e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.265, tt:1716.945\n",
      "Ep:94, loss:0.00002, loss_test:0.04482, lr:9.51e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.270, tt:1735.643\n",
      "Ep:95, loss:0.00002, loss_test:0.05071, lr:9.41e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.293, tt:1756.118\n",
      "Ep:96, loss:0.00002, loss_test:0.04327, lr:9.32e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.330, tt:1778.050\n",
      "Ep:97, loss:0.00002, loss_test:0.04871, lr:9.23e-03, fs:0.90526 (r=0.869,p=0.945),  time:18.331, tt:1796.465\n",
      "Ep:98, loss:0.00002, loss_test:0.04330, lr:9.14e-03, fs:0.92308 (r=0.909,p=0.938),  time:18.336, tt:1815.263\n",
      "Ep:99, loss:0.00002, loss_test:0.04399, lr:9.04e-03, fs:0.93264 (r=0.909,p=0.957),  time:18.341, tt:1834.063\n",
      "Ep:100, loss:0.00002, loss_test:0.04774, lr:8.95e-03, fs:0.92228 (r=0.899,p=0.947),  time:18.343, tt:1852.604\n",
      "Ep:101, loss:0.00002, loss_test:0.04268, lr:8.86e-03, fs:0.93401 (r=0.929,p=0.939),  time:18.343, tt:1870.951\n",
      "Ep:102, loss:0.00002, loss_test:0.04756, lr:8.78e-03, fs:0.91005 (r=0.869,p=0.956),  time:18.378, tt:1892.974\n",
      "Ep:103, loss:0.00002, loss_test:0.04329, lr:8.69e-03, fs:0.91667 (r=0.889,p=0.946),  time:18.405, tt:1914.157\n",
      "Ep:104, loss:0.00002, loss_test:0.04845, lr:8.60e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.428, tt:1934.945\n",
      "Ep:105, loss:0.00002, loss_test:0.04296, lr:8.51e-03, fs:0.91192 (r=0.889,p=0.936),  time:18.432, tt:1953.756\n",
      "Ep:106, loss:0.00002, loss_test:0.04683, lr:8.43e-03, fs:0.90323 (r=0.848,p=0.966),  time:18.436, tt:1972.652\n",
      "Ep:107, loss:0.00002, loss_test:0.04387, lr:8.35e-03, fs:0.90426 (r=0.859,p=0.955),  time:18.438, tt:1991.265\n",
      "Ep:108, loss:0.00002, loss_test:0.04390, lr:8.26e-03, fs:0.90052 (r=0.869,p=0.935),  time:18.467, tt:2012.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:109, loss:0.00002, loss_test:0.04635, lr:8.18e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.464, tt:2031.080\n",
      "Ep:110, loss:0.00002, loss_test:0.04354, lr:8.10e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.471, tt:2050.311\n",
      "Ep:111, loss:0.00002, loss_test:0.04480, lr:8.02e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.470, tt:2068.627\n",
      "Ep:112, loss:0.00002, loss_test:0.04494, lr:7.94e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.468, tt:2086.915\n",
      "Ep:113, loss:0.00002, loss_test:0.04469, lr:7.86e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.468, tt:2105.327\n",
      "Ep:114, loss:0.00002, loss_test:0.04339, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.487, tt:2125.978\n",
      "Ep:115, loss:0.00002, loss_test:0.04784, lr:7.70e-03, fs:0.91489 (r=0.869,p=0.966),  time:18.496, tt:2145.545\n",
      "Ep:116, loss:0.00002, loss_test:0.04272, lr:7.62e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.494, tt:2163.822\n",
      "Ep:117, loss:0.00002, loss_test:0.04717, lr:7.55e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.497, tt:2182.613\n",
      "Ep:118, loss:0.00002, loss_test:0.04278, lr:7.47e-03, fs:0.91099 (r=0.879,p=0.946),  time:18.499, tt:2201.377\n",
      "Ep:119, loss:0.00002, loss_test:0.04718, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.489, tt:2218.648\n",
      "Ep:120, loss:0.00002, loss_test:0.04342, lr:7.32e-03, fs:0.89947 (r=0.859,p=0.944),  time:18.482, tt:2236.347\n",
      "Ep:121, loss:0.00002, loss_test:0.04626, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.502, tt:2257.239\n",
      "Ep:122, loss:0.00002, loss_test:0.04327, lr:7.18e-03, fs:0.90526 (r=0.869,p=0.945),  time:18.505, tt:2276.100\n",
      "Ep:123, loss:0.00002, loss_test:0.04633, lr:7.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.490, tt:2292.759\n",
      "Ep:124, loss:0.00002, loss_test:0.04284, lr:7.03e-03, fs:0.88889 (r=0.848,p=0.933),  time:18.473, tt:2309.139\n",
      "Ep:125, loss:0.00002, loss_test:0.04866, lr:6.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.472, tt:2327.461\n",
      "Ep:126, loss:0.00002, loss_test:0.04264, lr:6.89e-03, fs:0.93333 (r=0.919,p=0.948),  time:18.476, tt:2346.412\n",
      "Ep:127, loss:0.00002, loss_test:0.04927, lr:6.83e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.503, tt:2368.404\n",
      "Ep:128, loss:0.00002, loss_test:0.04204, lr:6.76e-03, fs:0.92784 (r=0.909,p=0.947),  time:18.493, tt:2385.537\n",
      "Ep:129, loss:0.00001, loss_test:0.04720, lr:6.69e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.492, tt:2403.968\n",
      "Ep:130, loss:0.00001, loss_test:0.04286, lr:6.62e-03, fs:0.93684 (r=0.899,p=0.978),  time:18.520, tt:2426.099\n",
      "Ep:131, loss:0.00001, loss_test:0.04572, lr:6.56e-03, fs:0.88770 (r=0.838,p=0.943),  time:18.513, tt:2443.743\n",
      "Ep:132, loss:0.00001, loss_test:0.04346, lr:6.49e-03, fs:0.92553 (r=0.879,p=0.978),  time:18.532, tt:2464.734\n",
      "Ep:133, loss:0.00001, loss_test:0.04530, lr:6.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.532, tt:2483.241\n",
      "Ep:134, loss:0.00001, loss_test:0.04413, lr:6.36e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.533, tt:2501.893\n",
      "Ep:135, loss:0.00001, loss_test:0.04345, lr:6.30e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.529, tt:2519.930\n",
      "Ep:136, loss:0.00001, loss_test:0.04485, lr:6.24e-03, fs:0.89730 (r=0.838,p=0.965),  time:18.527, tt:2538.132\n",
      "Ep:137, loss:0.00001, loss_test:0.04278, lr:6.17e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.537, tt:2558.139\n",
      "Ep:138, loss:0.00001, loss_test:0.04480, lr:6.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.547, tt:2577.977\n",
      "Ep:139, loss:0.00001, loss_test:0.04267, lr:6.05e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.536, tt:2595.049\n",
      "Ep:140, loss:0.00001, loss_test:0.04456, lr:5.99e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.533, tt:2613.136\n",
      "Ep:141, loss:0.00001, loss_test:0.04280, lr:5.93e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.523, tt:2630.231\n",
      "Ep:142, loss:0.00001, loss_test:0.04493, lr:5.87e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.527, tt:2649.422\n",
      "Ep:143, loss:0.00001, loss_test:0.04243, lr:5.81e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.515, tt:2666.106\n",
      "Ep:144, loss:0.00001, loss_test:0.04521, lr:5.75e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.523, tt:2685.877\n",
      "Ep:145, loss:0.00001, loss_test:0.04312, lr:5.70e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.517, tt:2703.451\n",
      "Ep:146, loss:0.00001, loss_test:0.04484, lr:5.64e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.509, tt:2720.855\n",
      "Ep:147, loss:0.00001, loss_test:0.04232, lr:5.58e-03, fs:0.93684 (r=0.899,p=0.978),  time:18.517, tt:2740.455\n",
      "Ep:148, loss:0.00001, loss_test:0.04453, lr:5.53e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.508, tt:2757.697\n",
      "Ep:149, loss:0.00001, loss_test:0.04348, lr:5.47e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.497, tt:2774.568\n",
      "Ep:150, loss:0.00001, loss_test:0.04479, lr:5.42e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.492, tt:2792.224\n",
      "Ep:151, loss:0.00001, loss_test:0.04352, lr:5.36e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.474, tt:2808.076\n",
      "Ep:152, loss:0.00001, loss_test:0.04548, lr:5.31e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.484, tt:2828.102\n",
      "Ep:153, loss:0.00001, loss_test:0.04464, lr:5.26e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.481, tt:2846.136\n",
      "Ep:154, loss:0.00001, loss_test:0.04349, lr:5.20e-03, fs:0.90710 (r=0.838,p=0.988),  time:18.490, tt:2865.883\n",
      "Ep:155, loss:0.00001, loss_test:0.04580, lr:5.15e-03, fs:0.90217 (r=0.838,p=0.976),  time:18.498, tt:2885.678\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 3\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14423, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:22.188, tt:22.188\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14287, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.635, tt:43.271\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.14062, lr:1.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:20.262, tt:60.785\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13781, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:19.107, tt:76.429\n",
      "Ep:4, loss:0.00026, loss_test:0.13494, lr:1.00e-02, fs:0.65649 (r=0.869,p=0.528),  time:19.100, tt:95.501\n",
      "Ep:5, loss:0.00025, loss_test:0.13189, lr:1.00e-02, fs:0.63710 (r=0.798,p=0.530),  time:19.632, tt:117.792\n",
      "Ep:6, loss:0.00025, loss_test:0.12995, lr:1.00e-02, fs:0.64257 (r=0.808,p=0.533),  time:19.785, tt:138.493\n",
      "Ep:7, loss:0.00024, loss_test:0.12783, lr:1.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:20.058, tt:160.463\n",
      "Ep:8, loss:0.00024, loss_test:0.12560, lr:1.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:20.320, tt:182.883\n",
      "Ep:9, loss:0.00023, loss_test:0.12247, lr:1.00e-02, fs:0.65574 (r=0.808,p=0.552),  time:20.377, tt:203.775\n",
      "Ep:10, loss:0.00023, loss_test:0.12012, lr:1.00e-02, fs:0.66102 (r=0.788,p=0.569),  time:20.421, tt:224.632\n",
      "Ep:11, loss:0.00022, loss_test:0.11701, lr:1.00e-02, fs:0.66953 (r=0.788,p=0.582),  time:20.496, tt:245.954\n",
      "Ep:12, loss:0.00021, loss_test:0.11397, lr:1.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:20.540, tt:267.015\n",
      "Ep:13, loss:0.00021, loss_test:0.11000, lr:1.00e-02, fs:0.69604 (r=0.798,p=0.617),  time:20.530, tt:287.419\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10668, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:20.436, tt:306.541\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.10499, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:20.367, tt:325.865\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.10148, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:20.204, tt:343.467\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09846, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:20.151, tt:362.723\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:18, loss:0.00017, loss_test:0.09828, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:20.156, tt:382.972\n",
      "Ep:19, loss:0.00017, loss_test:0.09600, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:20.279, tt:405.588\n",
      "Ep:20, loss:0.00016, loss_test:0.09303, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:20.311, tt:426.523\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09257, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:20.433, tt:449.532\n",
      "Ep:22, loss:0.00015, loss_test:0.09190, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:20.512, tt:471.768\n",
      "Ep:23, loss:0.00015, loss_test:0.08926, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:20.523, tt:492.555\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09032, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:20.549, tt:513.737\n",
      "Ep:25, loss:0.00014, loss_test:0.08944, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:20.597, tt:535.530\n",
      "Ep:26, loss:0.00013, loss_test:0.08769, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:20.590, tt:555.937\n",
      "Ep:27, loss:0.00013, loss_test:0.08752, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:20.566, tt:575.843\n",
      "Ep:28, loss:0.00012, loss_test:0.08587, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:20.631, tt:598.302\n",
      "Ep:29, loss:0.00012, loss_test:0.08445, lr:1.00e-02, fs:0.78049 (r=0.808,p=0.755),  time:20.576, tt:617.286\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08426, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:20.581, tt:638.024\n",
      "Ep:31, loss:0.00011, loss_test:0.08268, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:20.570, tt:658.240\n",
      "Ep:32, loss:0.00011, loss_test:0.08207, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:20.535, tt:677.643\n",
      "Ep:33, loss:0.00011, loss_test:0.08103, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:20.643, tt:701.867\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07944, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:20.686, tt:724.027\n",
      "Ep:35, loss:0.00010, loss_test:0.08001, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:20.741, tt:746.690\n",
      "Ep:36, loss:0.00009, loss_test:0.07782, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:20.695, tt:765.698\n",
      "Ep:37, loss:0.00009, loss_test:0.07963, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:20.733, tt:787.840\n",
      "Ep:38, loss:0.00009, loss_test:0.07586, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:20.738, tt:808.790\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.07570, lr:1.00e-02, fs:0.77487 (r=0.747,p=0.804),  time:20.765, tt:830.619\n",
      "Ep:40, loss:0.00008, loss_test:0.07510, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:20.787, tt:852.271\n",
      "Ep:41, loss:0.00008, loss_test:0.07402, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:20.894, tt:877.541\n",
      "Ep:42, loss:0.00008, loss_test:0.07380, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:20.947, tt:900.717\n",
      "Ep:43, loss:0.00008, loss_test:0.07318, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:21.008, tt:924.341\n",
      "Ep:44, loss:0.00007, loss_test:0.07456, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:21.045, tt:947.006\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07292, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.047, tt:968.181\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.07165, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.030, tt:988.411\n",
      "Ep:47, loss:0.00007, loss_test:0.07131, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:21.025, tt:1009.188\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07149, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:20.998, tt:1028.892\n",
      "Ep:49, loss:0.00006, loss_test:0.07066, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:20.995, tt:1049.747\n",
      "Ep:50, loss:0.00006, loss_test:0.06925, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:21.026, tt:1072.350\n",
      "Ep:51, loss:0.00006, loss_test:0.06941, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:20.983, tt:1091.098\n",
      "Ep:52, loss:0.00005, loss_test:0.06757, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:21.005, tt:1113.275\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06686, lr:1.00e-02, fs:0.81081 (r=0.758,p=0.872),  time:21.023, tt:1135.259\n",
      "Ep:54, loss:0.00005, loss_test:0.06748, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:21.048, tt:1157.623\n",
      "Ep:55, loss:0.00005, loss_test:0.06761, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:21.023, tt:1177.261\n",
      "Ep:56, loss:0.00005, loss_test:0.06762, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:21.020, tt:1198.120\n",
      "Ep:57, loss:0.00005, loss_test:0.06740, lr:1.00e-02, fs:0.81319 (r=0.747,p=0.892),  time:21.006, tt:1218.369\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.06622, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:21.008, tt:1239.445\n",
      "Ep:59, loss:0.00004, loss_test:0.06928, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:20.983, tt:1258.969\n",
      "Ep:60, loss:0.00004, loss_test:0.06436, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:20.981, tt:1279.833\n",
      "Ep:61, loss:0.00004, loss_test:0.06769, lr:1.00e-02, fs:0.80435 (r=0.747,p=0.871),  time:20.975, tt:1300.448\n",
      "Ep:62, loss:0.00004, loss_test:0.06637, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:20.957, tt:1320.319\n",
      "Ep:63, loss:0.00004, loss_test:0.06460, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:20.980, tt:1342.734\n",
      "Ep:64, loss:0.00004, loss_test:0.06760, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:21.003, tt:1365.198\n",
      "Ep:65, loss:0.00004, loss_test:0.06082, lr:1.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:20.983, tt:1384.861\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.06780, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:20.979, tt:1405.594\n",
      "Ep:67, loss:0.00004, loss_test:0.06009, lr:1.00e-02, fs:0.83978 (r=0.768,p=0.927),  time:20.967, tt:1425.724\n",
      "Ep:68, loss:0.00004, loss_test:0.06617, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.963, tt:1446.444\n",
      "Ep:69, loss:0.00003, loss_test:0.06138, lr:1.00e-02, fs:0.81564 (r=0.737,p=0.912),  time:20.968, tt:1467.795\n",
      "Ep:70, loss:0.00003, loss_test:0.06467, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.993, tt:1490.518\n",
      "Ep:71, loss:0.00003, loss_test:0.06170, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:20.965, tt:1509.479\n",
      "Ep:72, loss:0.00003, loss_test:0.06266, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.985, tt:1531.884\n",
      "Ep:73, loss:0.00003, loss_test:0.06215, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.986, tt:1552.999\n",
      "Ep:74, loss:0.00003, loss_test:0.06057, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:20.986, tt:1573.939\n",
      "Ep:75, loss:0.00003, loss_test:0.06380, lr:1.00e-02, fs:0.81818 (r=0.727,p=0.935),  time:20.972, tt:1593.842\n",
      "Ep:76, loss:0.00003, loss_test:0.05836, lr:1.00e-02, fs:0.82486 (r=0.737,p=0.936),  time:20.979, tt:1615.379\n",
      "Ep:77, loss:0.00003, loss_test:0.06394, lr:9.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:20.998, tt:1637.878\n",
      "Ep:78, loss:0.00003, loss_test:0.05956, lr:9.80e-03, fs:0.82682 (r=0.747,p=0.925),  time:21.022, tt:1660.746\n",
      "Ep:79, loss:0.00003, loss_test:0.06542, lr:9.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.037, tt:1682.997\n",
      "Ep:80, loss:0.00003, loss_test:0.06164, lr:9.61e-03, fs:0.82418 (r=0.758,p=0.904),  time:21.045, tt:1704.621\n",
      "Ep:81, loss:0.00003, loss_test:0.06445, lr:9.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.055, tt:1726.471\n",
      "Ep:82, loss:0.00002, loss_test:0.06220, lr:9.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.044, tt:1746.657\n",
      "Ep:83, loss:0.00002, loss_test:0.06313, lr:9.32e-03, fs:0.82022 (r=0.737,p=0.924),  time:21.031, tt:1766.564\n",
      "Ep:84, loss:0.00002, loss_test:0.06179, lr:9.23e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.007, tt:1785.556\n",
      "Ep:85, loss:0.00002, loss_test:0.06220, lr:9.14e-03, fs:0.83333 (r=0.758,p=0.926),  time:21.025, tt:1808.156\n",
      "Ep:86, loss:0.00002, loss_test:0.06247, lr:9.04e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.031, tt:1829.675\n",
      "Ep:87, loss:0.00002, loss_test:0.06160, lr:8.95e-03, fs:0.81356 (r=0.727,p=0.923),  time:21.024, tt:1850.153\n",
      "Ep:88, loss:0.00002, loss_test:0.06121, lr:8.86e-03, fs:0.83616 (r=0.747,p=0.949),  time:21.030, tt:1871.689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:89, loss:0.00002, loss_test:0.06150, lr:8.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.045, tt:1894.008\n",
      "Ep:90, loss:0.00002, loss_test:0.06154, lr:8.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.054, tt:1915.946\n",
      "Ep:91, loss:0.00002, loss_test:0.05988, lr:8.60e-03, fs:0.83146 (r=0.747,p=0.937),  time:21.051, tt:1936.736\n",
      "Ep:92, loss:0.00002, loss_test:0.06008, lr:8.51e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.047, tt:1957.328\n",
      "Ep:93, loss:0.00002, loss_test:0.06105, lr:8.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.033, tt:1977.088\n",
      "Ep:94, loss:0.00002, loss_test:0.05923, lr:8.35e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.065, tt:2001.142\n",
      "Ep:95, loss:0.00002, loss_test:0.06176, lr:8.26e-03, fs:0.83237 (r=0.727,p=0.973),  time:21.056, tt:2021.331\n",
      "Ep:96, loss:0.00002, loss_test:0.06069, lr:8.18e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.063, tt:2043.115\n",
      "Ep:97, loss:0.00002, loss_test:0.06023, lr:8.10e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.072, tt:2065.007\n",
      "Ep:98, loss:0.00002, loss_test:0.06281, lr:8.02e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.102, tt:2089.120\n",
      "Ep:99, loss:0.00002, loss_test:0.05906, lr:7.94e-03, fs:0.82022 (r=0.737,p=0.924),  time:21.121, tt:2112.055\n",
      "Ep:100, loss:0.00002, loss_test:0.06109, lr:7.86e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.124, tt:2133.541\n",
      "Ep:101, loss:0.00002, loss_test:0.05969, lr:7.78e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.121, tt:2154.367\n",
      "Ep:102, loss:0.00002, loss_test:0.06172, lr:7.70e-03, fs:0.82022 (r=0.737,p=0.924),  time:21.117, tt:2175.094\n",
      "Ep:103, loss:0.00002, loss_test:0.06034, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.124, tt:2196.870\n",
      "Ep:104, loss:0.00002, loss_test:0.06111, lr:7.55e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.133, tt:2218.940\n",
      "Ep:105, loss:0.00001, loss_test:0.06013, lr:7.47e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.139, tt:2240.697\n",
      "Ep:106, loss:0.00001, loss_test:0.06062, lr:7.40e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.142, tt:2262.240\n",
      "Ep:107, loss:0.00001, loss_test:0.05982, lr:7.32e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.140, tt:2283.099\n",
      "Ep:108, loss:0.00001, loss_test:0.06072, lr:7.25e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.125, tt:2302.618\n",
      "Ep:109, loss:0.00001, loss_test:0.05999, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.145, tt:2325.953\n",
      "Ep:110, loss:0.00001, loss_test:0.05991, lr:7.11e-03, fs:0.82955 (r=0.737,p=0.948),  time:21.140, tt:2346.539\n",
      "Ep:111, loss:0.00001, loss_test:0.05968, lr:7.03e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.114, tt:2364.714\n",
      "Ep:112, loss:0.00001, loss_test:0.05972, lr:6.96e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.102, tt:2384.546\n",
      "Ep:113, loss:0.00001, loss_test:0.06016, lr:6.89e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.089, tt:2404.096\n",
      "Ep:114, loss:0.00001, loss_test:0.06126, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.084, tt:2424.691\n",
      "Ep:115, loss:0.00001, loss_test:0.06107, lr:6.76e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.077, tt:2444.919\n",
      "Ep:116, loss:0.00001, loss_test:0.05972, lr:6.69e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.090, tt:2467.536\n",
      "Ep:117, loss:0.00001, loss_test:0.06158, lr:6.62e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.083, tt:2487.759\n",
      "Ep:118, loss:0.00001, loss_test:0.05961, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.074, tt:2507.783\n",
      "Ep:119, loss:0.00001, loss_test:0.06151, lr:6.49e-03, fs:0.82486 (r=0.737,p=0.936),  time:21.056, tt:2526.743\n",
      "Ep:120, loss:0.00001, loss_test:0.05954, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.063, tt:2548.582\n",
      "Ep:121, loss:0.00001, loss_test:0.06104, lr:6.36e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.053, tt:2568.463\n",
      "Ep:122, loss:0.00001, loss_test:0.06070, lr:6.30e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.054, tt:2589.678\n",
      "Ep:123, loss:0.00001, loss_test:0.06030, lr:6.24e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.053, tt:2610.597\n",
      "Ep:124, loss:0.00001, loss_test:0.06245, lr:6.17e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.055, tt:2631.853\n",
      "Ep:125, loss:0.00001, loss_test:0.05926, lr:6.11e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.067, tt:2654.413\n",
      "Ep:126, loss:0.00001, loss_test:0.06118, lr:6.05e-03, fs:0.82022 (r=0.737,p=0.924),  time:21.071, tt:2676.056\n",
      "Ep:127, loss:0.00001, loss_test:0.05987, lr:5.99e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.068, tt:2696.723\n",
      "Ep:128, loss:0.00001, loss_test:0.06131, lr:5.93e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.081, tt:2719.455\n",
      "Ep:129, loss:0.00001, loss_test:0.05993, lr:5.87e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.079, tt:2740.332\n",
      "Ep:130, loss:0.00001, loss_test:0.06103, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.085, tt:2762.196\n",
      "Ep:131, loss:0.00001, loss_test:0.06086, lr:5.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.085, tt:2783.155\n",
      "Ep:132, loss:0.00001, loss_test:0.06063, lr:5.70e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.093, tt:2805.358\n",
      "Ep:133, loss:0.00001, loss_test:0.06229, lr:5.64e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.098, tt:2827.132\n",
      "Ep:134, loss:0.00001, loss_test:0.05958, lr:5.58e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.111, tt:2850.052\n",
      "Ep:135, loss:0.00001, loss_test:0.06134, lr:5.53e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.108, tt:2870.619\n",
      "Ep:136, loss:0.00001, loss_test:0.06127, lr:5.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.100, tt:2890.656\n",
      "Ep:137, loss:0.00001, loss_test:0.05978, lr:5.42e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.090, tt:2910.423\n",
      "Ep:138, loss:0.00001, loss_test:0.06103, lr:5.36e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.104, tt:2933.451\n",
      "Ep:139, loss:0.00001, loss_test:0.06112, lr:5.31e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.092, tt:2952.854\n",
      "Ep:140, loss:0.00001, loss_test:0.05910, lr:5.26e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.082, tt:2972.618\n",
      "Ep:141, loss:0.00001, loss_test:0.06171, lr:5.20e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.072, tt:2992.189\n",
      "Ep:142, loss:0.00001, loss_test:0.06121, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.063, tt:3012.040\n",
      "Ep:143, loss:0.00001, loss_test:0.06012, lr:5.10e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.065, tt:3033.377\n",
      "Ep:144, loss:0.00001, loss_test:0.06041, lr:5.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.057, tt:3053.255\n",
      "Ep:145, loss:0.00001, loss_test:0.06102, lr:5.00e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.058, tt:3074.490\n",
      "Ep:146, loss:0.00001, loss_test:0.06022, lr:4.95e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.062, tt:3096.169\n",
      "Ep:147, loss:0.00001, loss_test:0.06168, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.064, tt:3117.496\n",
      "Ep:148, loss:0.00001, loss_test:0.06107, lr:4.85e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.062, tt:3138.243\n",
      "Ep:149, loss:0.00001, loss_test:0.05993, lr:4.80e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.072, tt:3160.781\n",
      "Ep:150, loss:0.00001, loss_test:0.06169, lr:4.75e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.085, tt:3183.784\n",
      "Ep:151, loss:0.00001, loss_test:0.06067, lr:4.71e-03, fs:0.82759 (r=0.727,p=0.960),  time:21.072, tt:3202.942\n",
      "Ep:152, loss:0.00001, loss_test:0.06139, lr:4.66e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.057, tt:3221.693\n",
      "Ep:153, loss:0.00001, loss_test:0.06114, lr:4.61e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.057, tt:3242.728\n",
      "Ep:154, loss:0.00001, loss_test:0.06054, lr:4.57e-03, fs:0.82286 (r=0.727,p=0.947),  time:21.065, tt:3265.054\n",
      "Ep:155, loss:0.00001, loss_test:0.06168, lr:4.52e-03, fs:0.81818 (r=0.727,p=0.935),  time:21.068, tt:3286.644\n",
      "Ep:156, loss:0.00001, loss_test:0.06009, lr:4.48e-03, fs:0.82955 (r=0.737,p=0.948),  time:21.051, tt:3304.938\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 4\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14491, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.867, tt:20.867\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14370, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:21.818, tt:43.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:2, loss:0.00028, loss_test:0.14189, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:22.189, tt:66.568\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13916, lr:1.00e-02, fs:0.65217 (r=0.909,p=0.508),  time:20.974, tt:83.897\n",
      "Ep:4, loss:0.00026, loss_test:0.13723, lr:1.00e-02, fs:0.63602 (r=0.838,p=0.512),  time:20.473, tt:102.366\n",
      "Ep:5, loss:0.00025, loss_test:0.13640, lr:1.00e-02, fs:0.62400 (r=0.788,p=0.517),  time:20.444, tt:122.664\n",
      "Ep:6, loss:0.00025, loss_test:0.13447, lr:1.00e-02, fs:0.64000 (r=0.808,p=0.530),  time:20.349, tt:142.446\n",
      "Ep:7, loss:0.00025, loss_test:0.13151, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:20.448, tt:163.586\n",
      "Ep:8, loss:0.00024, loss_test:0.12892, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:20.466, tt:184.197\n",
      "Ep:9, loss:0.00023, loss_test:0.12668, lr:1.00e-02, fs:0.65289 (r=0.798,p=0.552),  time:20.508, tt:205.084\n",
      "Ep:10, loss:0.00023, loss_test:0.12441, lr:1.00e-02, fs:0.63830 (r=0.758,p=0.551),  time:20.215, tt:222.369\n",
      "Ep:11, loss:0.00022, loss_test:0.12215, lr:1.00e-02, fs:0.64407 (r=0.768,p=0.555),  time:20.300, tt:243.604\n",
      "Ep:12, loss:0.00021, loss_test:0.11981, lr:1.00e-02, fs:0.64957 (r=0.768,p=0.563),  time:20.237, tt:263.082\n",
      "Ep:13, loss:0.00021, loss_test:0.11705, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:20.207, tt:282.898\n",
      "Ep:14, loss:0.00020, loss_test:0.11511, lr:9.90e-03, fs:0.66964 (r=0.758,p=0.600),  time:20.268, tt:304.026\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.11368, lr:9.90e-03, fs:0.70175 (r=0.808,p=0.620),  time:20.196, tt:323.131\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00019, loss_test:0.11107, lr:9.90e-03, fs:0.73043 (r=0.848,p=0.641),  time:20.047, tt:340.804\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.10856, lr:9.90e-03, fs:0.72247 (r=0.828,p=0.641),  time:19.892, tt:358.062\n",
      "Ep:18, loss:0.00018, loss_test:0.10705, lr:9.90e-03, fs:0.72727 (r=0.808,p=0.661),  time:19.590, tt:372.206\n",
      "Ep:19, loss:0.00017, loss_test:0.10556, lr:9.90e-03, fs:0.73059 (r=0.808,p=0.667),  time:19.389, tt:387.782\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.10363, lr:9.90e-03, fs:0.71889 (r=0.788,p=0.661),  time:19.176, tt:402.690\n",
      "Ep:21, loss:0.00016, loss_test:0.10186, lr:9.90e-03, fs:0.74312 (r=0.818,p=0.681),  time:18.972, tt:417.381\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09985, lr:9.90e-03, fs:0.73488 (r=0.798,p=0.681),  time:18.774, tt:431.808\n",
      "Ep:23, loss:0.00015, loss_test:0.09853, lr:9.90e-03, fs:0.73832 (r=0.798,p=0.687),  time:18.595, tt:446.287\n",
      "Ep:24, loss:0.00014, loss_test:0.09710, lr:9.90e-03, fs:0.75000 (r=0.818,p=0.692),  time:18.469, tt:461.722\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09476, lr:9.90e-03, fs:0.74286 (r=0.788,p=0.703),  time:18.321, tt:476.342\n",
      "Ep:26, loss:0.00013, loss_test:0.09283, lr:9.90e-03, fs:0.76056 (r=0.818,p=0.711),  time:18.179, tt:490.833\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09156, lr:9.90e-03, fs:0.76636 (r=0.828,p=0.713),  time:18.057, tt:505.597\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.08982, lr:9.90e-03, fs:0.78505 (r=0.848,p=0.730),  time:17.918, tt:519.622\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08826, lr:9.90e-03, fs:0.79263 (r=0.869,p=0.729),  time:17.808, tt:534.229\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.08668, lr:9.90e-03, fs:0.78673 (r=0.838,p=0.741),  time:17.716, tt:549.190\n",
      "Ep:31, loss:0.00011, loss_test:0.08552, lr:9.90e-03, fs:0.78673 (r=0.838,p=0.741),  time:17.632, tt:564.227\n",
      "Ep:32, loss:0.00011, loss_test:0.08441, lr:9.90e-03, fs:0.79245 (r=0.848,p=0.743),  time:17.555, tt:579.320\n",
      "Ep:33, loss:0.00010, loss_test:0.08252, lr:9.90e-03, fs:0.81860 (r=0.889,p=0.759),  time:17.508, tt:595.278\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08220, lr:9.90e-03, fs:0.80569 (r=0.859,p=0.759),  time:17.432, tt:610.112\n",
      "Ep:35, loss:0.00010, loss_test:0.08099, lr:9.90e-03, fs:0.79612 (r=0.828,p=0.766),  time:17.369, tt:625.290\n",
      "Ep:36, loss:0.00009, loss_test:0.07870, lr:9.90e-03, fs:0.82791 (r=0.899,p=0.767),  time:17.299, tt:640.082\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.07973, lr:9.90e-03, fs:0.81000 (r=0.818,p=0.802),  time:17.240, tt:655.105\n",
      "Ep:38, loss:0.00009, loss_test:0.07633, lr:9.90e-03, fs:0.83019 (r=0.889,p=0.779),  time:17.178, tt:669.948\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.07809, lr:9.90e-03, fs:0.83168 (r=0.848,p=0.816),  time:17.123, tt:684.917\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.07543, lr:9.90e-03, fs:0.81553 (r=0.848,p=0.785),  time:17.063, tt:699.600\n",
      "Ep:41, loss:0.00008, loss_test:0.07697, lr:9.90e-03, fs:0.83902 (r=0.869,p=0.811),  time:17.014, tt:714.589\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07451, lr:9.90e-03, fs:0.83495 (r=0.869,p=0.804),  time:16.953, tt:728.964\n",
      "Ep:43, loss:0.00008, loss_test:0.07528, lr:9.90e-03, fs:0.82412 (r=0.828,p=0.820),  time:16.909, tt:743.983\n",
      "Ep:44, loss:0.00007, loss_test:0.07367, lr:9.90e-03, fs:0.84729 (r=0.869,p=0.827),  time:16.859, tt:758.655\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07281, lr:9.90e-03, fs:0.83744 (r=0.859,p=0.817),  time:16.819, tt:773.689\n",
      "Ep:46, loss:0.00007, loss_test:0.07299, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:16.786, tt:788.961\n",
      "Ep:47, loss:0.00006, loss_test:0.07354, lr:9.90e-03, fs:0.82412 (r=0.828,p=0.820),  time:16.799, tt:806.374\n",
      "Ep:48, loss:0.00006, loss_test:0.07326, lr:9.90e-03, fs:0.82902 (r=0.808,p=0.851),  time:16.755, tt:820.990\n",
      "Ep:49, loss:0.00006, loss_test:0.07188, lr:9.90e-03, fs:0.83417 (r=0.838,p=0.830),  time:16.720, tt:835.997\n",
      "Ep:50, loss:0.00006, loss_test:0.07209, lr:9.90e-03, fs:0.84694 (r=0.838,p=0.856),  time:16.680, tt:850.674\n",
      "Ep:51, loss:0.00006, loss_test:0.06921, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:16.640, tt:865.285\n",
      "Ep:52, loss:0.00006, loss_test:0.07028, lr:9.90e-03, fs:0.84848 (r=0.848,p=0.848),  time:16.610, tt:880.332\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.06883, lr:9.90e-03, fs:0.84577 (r=0.859,p=0.833),  time:16.580, tt:895.300\n",
      "Ep:54, loss:0.00005, loss_test:0.07092, lr:9.90e-03, fs:0.83770 (r=0.808,p=0.870),  time:16.547, tt:910.067\n",
      "Ep:55, loss:0.00005, loss_test:0.06806, lr:9.90e-03, fs:0.85149 (r=0.869,p=0.835),  time:16.531, tt:925.709\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.06852, lr:9.90e-03, fs:0.81443 (r=0.798,p=0.832),  time:16.507, tt:940.926\n",
      "Ep:57, loss:0.00005, loss_test:0.06895, lr:9.90e-03, fs:0.85567 (r=0.838,p=0.874),  time:16.487, tt:956.228\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00005, loss_test:0.06833, lr:9.90e-03, fs:0.82723 (r=0.798,p=0.859),  time:16.467, tt:971.536\n",
      "Ep:59, loss:0.00004, loss_test:0.06763, lr:9.90e-03, fs:0.86294 (r=0.859,p=0.867),  time:16.437, tt:986.202\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00004, loss_test:0.06879, lr:9.90e-03, fs:0.84492 (r=0.798,p=0.898),  time:16.403, tt:1000.575\n",
      "Ep:61, loss:0.00004, loss_test:0.06820, lr:9.90e-03, fs:0.82979 (r=0.788,p=0.876),  time:16.374, tt:1015.159\n",
      "Ep:62, loss:0.00004, loss_test:0.06723, lr:9.90e-03, fs:0.84043 (r=0.798,p=0.888),  time:16.341, tt:1029.474\n",
      "Ep:63, loss:0.00004, loss_test:0.06724, lr:9.90e-03, fs:0.84656 (r=0.808,p=0.889),  time:16.322, tt:1044.603\n",
      "Ep:64, loss:0.00004, loss_test:0.06583, lr:9.90e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.297, tt:1059.308\n",
      "Ep:65, loss:0.00004, loss_test:0.06654, lr:9.90e-03, fs:0.83243 (r=0.778,p=0.895),  time:16.276, tt:1074.209\n",
      "Ep:66, loss:0.00004, loss_test:0.06672, lr:9.90e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.251, tt:1088.844\n",
      "Ep:67, loss:0.00004, loss_test:0.06471, lr:9.90e-03, fs:0.86598 (r=0.848,p=0.884),  time:16.229, tt:1103.588\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.06826, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:16.211, tt:1118.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00004, loss_test:0.06571, lr:9.90e-03, fs:0.82723 (r=0.798,p=0.859),  time:16.190, tt:1133.273\n",
      "Ep:70, loss:0.00004, loss_test:0.06749, lr:9.90e-03, fs:0.83243 (r=0.778,p=0.895),  time:16.170, tt:1148.097\n",
      "Ep:71, loss:0.00004, loss_test:0.06797, lr:9.90e-03, fs:0.82418 (r=0.758,p=0.904),  time:16.155, tt:1163.148\n",
      "Ep:72, loss:0.00003, loss_test:0.06447, lr:9.90e-03, fs:0.87755 (r=0.869,p=0.887),  time:16.138, tt:1178.093\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.06879, lr:9.90e-03, fs:0.83696 (r=0.778,p=0.906),  time:16.131, tt:1193.662\n",
      "Ep:74, loss:0.00003, loss_test:0.06489, lr:9.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:16.113, tt:1208.493\n",
      "Ep:75, loss:0.00003, loss_test:0.06492, lr:9.90e-03, fs:0.82162 (r=0.768,p=0.884),  time:16.097, tt:1223.387\n",
      "Ep:76, loss:0.00003, loss_test:0.06574, lr:9.90e-03, fs:0.83243 (r=0.778,p=0.895),  time:16.090, tt:1238.921\n",
      "Ep:77, loss:0.00003, loss_test:0.06475, lr:9.90e-03, fs:0.82609 (r=0.768,p=0.894),  time:16.080, tt:1254.251\n",
      "Ep:78, loss:0.00003, loss_test:0.06553, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:16.077, tt:1270.074\n",
      "Ep:79, loss:0.00003, loss_test:0.06641, lr:9.90e-03, fs:0.82609 (r=0.768,p=0.894),  time:16.066, tt:1285.302\n",
      "Ep:80, loss:0.00003, loss_test:0.06509, lr:9.90e-03, fs:0.84324 (r=0.788,p=0.907),  time:16.060, tt:1300.874\n",
      "Ep:81, loss:0.00003, loss_test:0.06975, lr:9.90e-03, fs:0.82609 (r=0.768,p=0.894),  time:16.046, tt:1315.736\n",
      "Ep:82, loss:0.00003, loss_test:0.06444, lr:9.90e-03, fs:0.87500 (r=0.848,p=0.903),  time:16.035, tt:1330.912\n",
      "Ep:83, loss:0.00003, loss_test:0.06685, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:16.021, tt:1345.797\n",
      "Ep:84, loss:0.00003, loss_test:0.06641, lr:9.80e-03, fs:0.82609 (r=0.768,p=0.894),  time:16.000, tt:1359.989\n",
      "Ep:85, loss:0.00003, loss_test:0.06524, lr:9.70e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.987, tt:1374.897\n",
      "Ep:86, loss:0.00003, loss_test:0.06435, lr:9.61e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.979, tt:1390.152\n",
      "Ep:87, loss:0.00002, loss_test:0.06593, lr:9.51e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.970, tt:1405.342\n",
      "Ep:88, loss:0.00002, loss_test:0.06486, lr:9.41e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.954, tt:1419.878\n",
      "Ep:89, loss:0.00002, loss_test:0.06451, lr:9.32e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.955, tt:1435.917\n",
      "Ep:90, loss:0.00002, loss_test:0.06500, lr:9.23e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.946, tt:1451.108\n",
      "Ep:91, loss:0.00002, loss_test:0.06545, lr:9.14e-03, fs:0.83060 (r=0.768,p=0.905),  time:15.933, tt:1465.852\n",
      "Ep:92, loss:0.00002, loss_test:0.06532, lr:9.04e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.926, tt:1481.156\n",
      "Ep:93, loss:0.00002, loss_test:0.06538, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.918, tt:1496.253\n",
      "Ep:94, loss:0.00002, loss_test:0.06420, lr:8.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.906, tt:1511.108\n",
      "Ep:95, loss:0.00002, loss_test:0.06651, lr:8.78e-03, fs:0.81768 (r=0.747,p=0.902),  time:15.894, tt:1525.792\n",
      "Ep:96, loss:0.00002, loss_test:0.06511, lr:8.69e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.880, tt:1540.341\n",
      "Ep:97, loss:0.00002, loss_test:0.06643, lr:8.60e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.871, tt:1555.313\n",
      "Ep:98, loss:0.00002, loss_test:0.06449, lr:8.51e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.858, tt:1569.967\n",
      "Ep:99, loss:0.00002, loss_test:0.06635, lr:8.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.847, tt:1584.683\n",
      "Ep:100, loss:0.00002, loss_test:0.06552, lr:8.35e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.834, tt:1599.262\n",
      "Ep:101, loss:0.00002, loss_test:0.06475, lr:8.26e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.835, tt:1615.156\n",
      "Ep:102, loss:0.00002, loss_test:0.06632, lr:8.18e-03, fs:0.82222 (r=0.747,p=0.914),  time:15.836, tt:1631.157\n",
      "Ep:103, loss:0.00002, loss_test:0.06409, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.828, tt:1646.098\n",
      "Ep:104, loss:0.00002, loss_test:0.06704, lr:8.02e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.837, tt:1662.891\n",
      "Ep:105, loss:0.00002, loss_test:0.06630, lr:7.94e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.828, tt:1677.767\n",
      "Ep:106, loss:0.00002, loss_test:0.06481, lr:7.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.824, tt:1693.148\n",
      "Ep:107, loss:0.00002, loss_test:0.06798, lr:7.78e-03, fs:0.81768 (r=0.747,p=0.902),  time:15.831, tt:1709.731\n",
      "Ep:108, loss:0.00002, loss_test:0.06498, lr:7.70e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.827, tt:1725.135\n",
      "Ep:109, loss:0.00002, loss_test:0.06611, lr:7.62e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.815, tt:1739.655\n",
      "Ep:110, loss:0.00002, loss_test:0.06778, lr:7.55e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.802, tt:1754.045\n",
      "Ep:111, loss:0.00002, loss_test:0.06567, lr:7.47e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.797, tt:1769.217\n",
      "Ep:112, loss:0.00002, loss_test:0.06856, lr:7.40e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.792, tt:1784.491\n",
      "Ep:113, loss:0.00002, loss_test:0.06739, lr:7.32e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.779, tt:1798.861\n",
      "Ep:114, loss:0.00002, loss_test:0.06611, lr:7.25e-03, fs:0.83978 (r=0.768,p=0.927),  time:15.768, tt:1813.325\n",
      "Ep:115, loss:0.00002, loss_test:0.06816, lr:7.18e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.757, tt:1827.825\n",
      "Ep:116, loss:0.00002, loss_test:0.06798, lr:7.11e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.748, tt:1842.466\n",
      "Ep:117, loss:0.00002, loss_test:0.06663, lr:7.03e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.742, tt:1857.519\n",
      "Ep:118, loss:0.00002, loss_test:0.06946, lr:6.96e-03, fs:0.82222 (r=0.747,p=0.914),  time:15.729, tt:1871.703\n",
      "Ep:119, loss:0.00002, loss_test:0.06807, lr:6.89e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.721, tt:1886.553\n",
      "Ep:120, loss:0.00002, loss_test:0.06668, lr:6.83e-03, fs:0.84444 (r=0.768,p=0.938),  time:15.716, tt:1901.642\n",
      "Ep:121, loss:0.00002, loss_test:0.06823, lr:6.76e-03, fs:0.82222 (r=0.747,p=0.914),  time:15.709, tt:1916.454\n",
      "Ep:122, loss:0.00002, loss_test:0.06823, lr:6.69e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.704, tt:1931.635\n",
      "Ep:123, loss:0.00002, loss_test:0.06774, lr:6.62e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.703, tt:1947.164\n",
      "Ep:124, loss:0.00002, loss_test:0.06889, lr:6.56e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.695, tt:1961.858\n",
      "Ep:125, loss:0.00002, loss_test:0.06986, lr:6.49e-03, fs:0.82222 (r=0.747,p=0.914),  time:15.687, tt:1976.606\n",
      "Ep:126, loss:0.00002, loss_test:0.06794, lr:6.43e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.678, tt:1991.158\n",
      "Ep:127, loss:0.00002, loss_test:0.07018, lr:6.36e-03, fs:0.82222 (r=0.747,p=0.914),  time:15.675, tt:2006.369\n",
      "Ep:128, loss:0.00002, loss_test:0.06870, lr:6.30e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.670, tt:2021.433\n",
      "Ep:129, loss:0.00002, loss_test:0.06829, lr:6.24e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.664, tt:2036.304\n",
      "Ep:130, loss:0.00001, loss_test:0.06963, lr:6.17e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.653, tt:2050.480\n",
      "Ep:131, loss:0.00001, loss_test:0.06930, lr:6.11e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.646, tt:2065.324\n",
      "Ep:132, loss:0.00001, loss_test:0.06857, lr:6.05e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.644, tt:2080.708\n",
      "Ep:133, loss:0.00001, loss_test:0.06967, lr:5.99e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.640, tt:2095.695\n",
      "Ep:134, loss:0.00001, loss_test:0.06994, lr:5.93e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.632, tt:2110.272\n",
      "Ep:135, loss:0.00001, loss_test:0.06953, lr:5.87e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.622, tt:2124.608\n",
      "Ep:136, loss:0.00001, loss_test:0.06957, lr:5.81e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.613, tt:2138.931\n",
      "Ep:137, loss:0.00001, loss_test:0.07038, lr:5.75e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.607, tt:2153.822\n",
      "Ep:138, loss:0.00001, loss_test:0.06934, lr:5.70e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.598, tt:2168.190\n",
      "Ep:139, loss:0.00001, loss_test:0.07023, lr:5.64e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.590, tt:2182.558\n",
      "Ep:140, loss:0.00001, loss_test:0.07115, lr:5.58e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.583, tt:2197.245\n",
      "Ep:141, loss:0.00001, loss_test:0.06989, lr:5.53e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.577, tt:2211.939\n",
      "Ep:142, loss:0.00001, loss_test:0.07045, lr:5.47e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.583, tt:2228.335\n",
      "Ep:143, loss:0.00001, loss_test:0.07151, lr:5.42e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.576, tt:2242.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00001, loss_test:0.07021, lr:5.36e-03, fs:0.83146 (r=0.747,p=0.937),  time:15.572, tt:2257.930\n",
      "Ep:145, loss:0.00001, loss_test:0.07084, lr:5.31e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.567, tt:2272.849\n",
      "Ep:146, loss:0.00001, loss_test:0.07085, lr:5.26e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.559, tt:2287.245\n",
      "Ep:147, loss:0.00001, loss_test:0.07079, lr:5.20e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.555, tt:2302.201\n",
      "Ep:148, loss:0.00001, loss_test:0.07146, lr:5.15e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.548, tt:2316.649\n",
      "Ep:149, loss:0.00001, loss_test:0.07196, lr:5.10e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.545, tt:2331.727\n",
      "Ep:150, loss:0.00001, loss_test:0.07115, lr:5.05e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.540, tt:2346.520\n",
      "Ep:151, loss:0.00001, loss_test:0.07159, lr:5.00e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.536, tt:2361.546\n",
      "Ep:152, loss:0.00001, loss_test:0.07154, lr:4.95e-03, fs:0.82682 (r=0.747,p=0.925),  time:15.532, tt:2376.321\n",
      "Ep:153, loss:0.00001, loss_test:0.07106, lr:4.90e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.529, tt:2391.411\n",
      "Ep:154, loss:0.00001, loss_test:0.07216, lr:4.85e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.520, tt:2405.587\n",
      "Ep:155, loss:0.00001, loss_test:0.07246, lr:4.80e-03, fs:0.81356 (r=0.727,p=0.923),  time:15.515, tt:2420.403\n",
      "Ep:156, loss:0.00001, loss_test:0.07111, lr:4.75e-03, fs:0.81818 (r=0.727,p=0.935),  time:15.509, tt:2434.887\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"4-5\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
