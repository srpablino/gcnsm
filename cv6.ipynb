{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variables set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SETUP IS READY\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the dataset name (the dataset should be inside the folder /dataset in csv format)\n",
    "The default dataset is: openml_203ds_datasets_matching\n",
    "\"\"\"\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "\n",
    "\"\"\"\n",
    "choose integer number of ratio negative/positive to sample (0 will use all negative pairs)\n",
    "\"\"\"\n",
    "neg_sample = 2\n",
    "\"\"\"\n",
    "Choose one split trategy [\"isolation\",\"random\"] : \n",
    "- random will randomly spread positive node pairs in 80-20 fashion\n",
    "- isolation will isolate 1 node from some topics in test (none pair in train will see these nodes).\n",
    "The positive pairs will be splitted almost in 80-20%, like in the random case.\n",
    "\"\"\"\n",
    "strategy = \"random\"\n",
    "\"\"\"\n",
    "Choose to use the selected strategy to create a new split \n",
    "or reuse a previously created one (useful to repeat exact same experiment)\n",
    "\"\"\"\n",
    "create_new_split = False\n",
    "\n",
    "\"\"\"\n",
    "You can choose to use one of [\"FASTTEXT\",\"BERT\"] as initial word_embedding encoding for the nodes in the datasets\n",
    "\"\"\"\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\n",
    "\"\"\"\n",
    "These are the default values\n",
    "\n",
    "dataset_name = \"openml_203ds_datasets_matching\"\n",
    "neg_sample = 2\n",
    "strategy = \"random\"\n",
    "create_new_split = False #assumes splitted files exists already\n",
    "word_embedding_encoding = \"FASTTEXT\"\n",
    "\"\"\"\n",
    "print(\"Env variables set\")\n",
    "\n",
    "#import libraries\n",
    "from step3 import step3_gcnsm\n",
    "from step3.step3_gcnsm import confusion_matrix as confusion_matrix\n",
    "from step3.step3_gcnsm import train as train\n",
    "from step3.step3_gcnsm import cross_validation as cross_validation\n",
    "from step3.step3_gcnsm import test_mask, train_mask\n",
    "from step3.step3_gcnsm import g\n",
    "from step3 import step3_gcn_nn_concatenate as gcn_nn\n",
    "from step3 import step3_gcn_loss as gcn_loss\n",
    "from step3 import step3_gcn_training as gcn_training\n",
    "from step3 import step3_plot_results as plot\n",
    "# step3_gcnsm.load_env(ds_name=dataset_name,ns=neg_sample,st=strategy,sp=create_new_split,we=word_embedding_encoding)\n",
    "print(\"\\n SETUP IS READY\")\n",
    "cv_number=\"6-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_nn.get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose NN architecture and loss function, then run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and run training\n",
    "### NN architectures: \n",
    "\n",
    "{<br>\n",
    "    \"0\": \"Bert_300\", <br>\n",
    "    \"1\": \"Bert_300_300_200\", <br>\n",
    "    \"2\": \"Bert_768\", <br>\n",
    "    \"3\": 'Fasttext2_150', <br>\n",
    "    \"4\": \"Fasttext3GCN_300\" <br>\n",
    "    \"5\": \"Fasttext_150\", <br>\n",
    "    \"6\": \"Fasttext_150_150_100\", <br>\n",
    "    \"7\": \"Fasttext_300\" <br>\n",
    "}\n",
    "### Loss functions: \n",
    "{<br>\n",
    "    \"0\": \"ContrastiveLoss\", <br>\n",
    "    \"1\": \"CosineEmbeddingLoss\", <br>\n",
    "}\n",
    "\n",
    "### Optimizer\n",
    "{<br>\n",
    "    \"adam\" (default)<br>\n",
    "    \"sgd\"<br> \n",
    "}\n",
    "\n",
    "\n",
    "### Loss functions parameters examples: format -> [margin]+[aggregation_function] \n",
    "{<br>\n",
    "    0.9+mean, <br>\n",
    "    0.7+mean, <br>\n",
    "    0.5+mean, <br>\n",
    "    0.3+mean, <br>\n",
    "    0.9+sum, <br>\n",
    "    0.7+sum, <br>\n",
    "    0.5+sum, <br>\n",
    "    0.3+sum, <br>\n",
    "}\n",
    "\n",
    "### batch_splits examples: \n",
    "{<br>\n",
    "    64, <br>\n",
    "    128, <br>\n",
    "}\n",
    "### learning rate examples (lr): \n",
    "{<br>\n",
    "    1e-3, <br>\n",
    "    1e-4, <br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model from path\n",
    "# training = gcn_training.Training()\n",
    "# training.load_state(path=\"./models/[file_name].pt\")\n",
    "# train(training,iterations=N)\n",
    "\n",
    "# #train new model and specify parameters\n",
    "# training = gcn_training.Training()\n",
    "# training.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "# train(training,iterations=N)\n",
    "\n",
    "## Print confusion matrix and results using the training object\n",
    "#confusion_matrix(training.net, step3_gcnsm.g, step3_gcnsm.g.ndata['vector'], step3_gcnsm.test_mask,training.loss_name,threshold = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 3\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 2664 Test samples: 198\n",
      "Train positive samples: 1332 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.13827, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:21.903, tt:21.903\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.13654, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:26.258, tt:52.516\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00014, loss_test:0.13365, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:28.064, tt:84.193\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00013, loss_test:0.12935, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:29.043, tt:116.171\n",
      "Ep:4, loss:0.00013, loss_test:0.12334, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:29.520, tt:147.602\n",
      "Ep:5, loss:0.00012, loss_test:0.11436, lr:1.00e-02, fs:0.69710 (r=0.848,p=0.592),  time:29.569, tt:177.417\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00012, loss_test:0.10852, lr:1.00e-02, fs:0.68224 (r=0.737,p=0.635),  time:29.909, tt:209.362\n",
      "Ep:7, loss:0.00011, loss_test:0.10673, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:30.226, tt:241.806\n",
      "Ep:8, loss:0.00011, loss_test:0.10653, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:30.317, tt:272.857\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.10478, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:30.350, tt:303.505\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00011, loss_test:0.10154, lr:1.00e-02, fs:0.75362 (r=0.788,p=0.722),  time:30.452, tt:334.971\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00010, loss_test:0.09875, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:30.553, tt:366.636\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00010, loss_test:0.09780, lr:1.00e-02, fs:0.75598 (r=0.798,p=0.718),  time:30.531, tt:396.898\n",
      "Ep:13, loss:0.00010, loss_test:0.09641, lr:1.00e-02, fs:0.76190 (r=0.808,p=0.721),  time:30.602, tt:428.425\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00010, loss_test:0.09353, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:30.643, tt:459.651\n",
      "Ep:15, loss:0.00009, loss_test:0.09256, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:30.661, tt:490.570\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.09169, lr:1.00e-02, fs:0.78431 (r=0.808,p=0.762),  time:30.701, tt:521.915\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00009, loss_test:0.08974, lr:1.00e-02, fs:0.78974 (r=0.778,p=0.802),  time:30.885, tt:555.932\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.08875, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.876, tt:586.641\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00008, loss_test:0.08723, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:30.801, tt:616.023\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.08591, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:30.810, tt:647.009\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00008, loss_test:0.08520, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:30.859, tt:678.905\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.08393, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:30.888, tt:710.422\n",
      "Ep:23, loss:0.00008, loss_test:0.08307, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:30.968, tt:743.233\n",
      "Ep:24, loss:0.00007, loss_test:0.08224, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:31.005, tt:775.128\n",
      "Ep:25, loss:0.00007, loss_test:0.08175, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.043, tt:807.127\n",
      "Ep:26, loss:0.00007, loss_test:0.08107, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.085, tt:839.303\n",
      "Ep:27, loss:0.00007, loss_test:0.07990, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.095, tt:870.652\n",
      "Ep:28, loss:0.00007, loss_test:0.07893, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.104, tt:902.011\n",
      "Ep:29, loss:0.00006, loss_test:0.07861, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.112, tt:933.353\n",
      "Ep:30, loss:0.00006, loss_test:0.07769, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:31.136, tt:965.222\n",
      "Ep:31, loss:0.00006, loss_test:0.07709, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:31.170, tt:997.453\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.07678, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:31.146, tt:1027.819\n",
      "Ep:33, loss:0.00006, loss_test:0.07642, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.167, tt:1059.678\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00006, loss_test:0.07721, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:31.120, tt:1089.207\n",
      "Ep:35, loss:0.00006, loss_test:0.07549, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.128, tt:1120.610\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00005, loss_test:0.07645, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:31.131, tt:1151.844\n",
      "Ep:37, loss:0.00005, loss_test:0.07504, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:31.156, tt:1183.947\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00005, loss_test:0.07568, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.172, tt:1215.719\n",
      "Ep:39, loss:0.00005, loss_test:0.07391, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:31.227, tt:1249.066\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00005, loss_test:0.07468, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:31.274, tt:1282.245\n",
      "Ep:41, loss:0.00005, loss_test:0.07313, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:31.300, tt:1314.616\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00005, loss_test:0.07413, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:31.349, tt:1347.995\n",
      "Ep:43, loss:0.00005, loss_test:0.07298, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:31.362, tt:1379.930\n",
      "Ep:44, loss:0.00004, loss_test:0.07246, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.408, tt:1413.345\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00004, loss_test:0.07236, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:31.415, tt:1445.100\n",
      "Ep:46, loss:0.00004, loss_test:0.07210, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:31.442, tt:1477.772\n",
      "Ep:47, loss:0.00004, loss_test:0.07239, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:31.480, tt:1511.040\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00004, loss_test:0.07104, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:31.522, tt:1544.571\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.07149, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:31.544, tt:1577.220\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00004, loss_test:0.07151, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:31.561, tt:1609.588\n",
      "Ep:51, loss:0.00004, loss_test:0.06957, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:31.603, tt:1643.362\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.07258, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.627, tt:1676.243\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.06838, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.650, tt:1709.089\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.07136, lr:1.00e-02, fs:0.85561 (r=0.808,p=0.909),  time:31.657, tt:1741.133\n",
      "Ep:55, loss:0.00003, loss_test:0.06745, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.685, tt:1774.357\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.07053, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:31.720, tt:1808.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00003, loss_test:0.06718, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:31.737, tt:1840.740\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.06860, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:31.800, tt:1876.208\n",
      "Ep:59, loss:0.00003, loss_test:0.06809, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:31.813, tt:1908.759\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.06675, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:31.822, tt:1941.162\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00003, loss_test:0.06778, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.845, tt:1974.386\n",
      "Ep:62, loss:0.00003, loss_test:0.06551, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.844, tt:2006.194\n",
      "Ep:63, loss:0.00003, loss_test:0.06749, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:31.880, tt:2040.345\n",
      "Ep:64, loss:0.00003, loss_test:0.06499, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.895, tt:2073.189\n",
      "Ep:65, loss:0.00003, loss_test:0.06638, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.907, tt:2105.892\n",
      "Ep:66, loss:0.00002, loss_test:0.06500, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.922, tt:2138.807\n",
      "Ep:67, loss:0.00002, loss_test:0.06518, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.953, tt:2172.814\n",
      "Ep:68, loss:0.00002, loss_test:0.06615, lr:1.00e-02, fs:0.90426 (r=0.859,p=0.955),  time:31.957, tt:2205.053\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00002, loss_test:0.06405, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:32.001, tt:2240.097\n",
      "Ep:70, loss:0.00002, loss_test:0.06554, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:32.000, tt:2271.995\n",
      "Ep:71, loss:0.00002, loss_test:0.06379, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:32.016, tt:2305.181\n",
      "Ep:72, loss:0.00002, loss_test:0.06487, lr:1.00e-02, fs:0.90052 (r=0.869,p=0.935),  time:32.047, tt:2339.454\n",
      "Ep:73, loss:0.00002, loss_test:0.06352, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:32.074, tt:2373.501\n",
      "Ep:74, loss:0.00002, loss_test:0.06449, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:32.130, tt:2409.782\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00002, loss_test:0.06259, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:32.149, tt:2443.344\n",
      "Ep:76, loss:0.00002, loss_test:0.06369, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:32.166, tt:2476.798\n",
      "Ep:77, loss:0.00002, loss_test:0.06452, lr:1.00e-02, fs:0.91579 (r=0.879,p=0.956),  time:32.210, tt:2512.401\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.06168, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:32.221, tt:2545.475\n",
      "Ep:79, loss:0.00002, loss_test:0.06363, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:32.231, tt:2578.471\n",
      "Ep:80, loss:0.00002, loss_test:0.06199, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:32.249, tt:2612.197\n",
      "Ep:81, loss:0.00002, loss_test:0.06373, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:32.261, tt:2645.376\n",
      "Ep:82, loss:0.00002, loss_test:0.06145, lr:1.00e-02, fs:0.90155 (r=0.879,p=0.926),  time:32.271, tt:2678.456\n",
      "Ep:83, loss:0.00002, loss_test:0.06363, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:32.282, tt:2711.647\n",
      "Ep:84, loss:0.00002, loss_test:0.06133, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:32.291, tt:2744.730\n",
      "Ep:85, loss:0.00002, loss_test:0.06312, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:32.280, tt:2776.089\n",
      "Ep:86, loss:0.00002, loss_test:0.06139, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:32.285, tt:2808.809\n",
      "Ep:87, loss:0.00002, loss_test:0.06202, lr:1.00e-02, fs:0.90625 (r=0.879,p=0.935),  time:32.298, tt:2842.233\n",
      "Ep:88, loss:0.00001, loss_test:0.06142, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:32.295, tt:2874.240\n",
      "Ep:89, loss:0.00001, loss_test:0.06189, lr:9.90e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.289, tt:2905.993\n",
      "Ep:90, loss:0.00001, loss_test:0.06256, lr:9.80e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.304, tt:2939.633\n",
      "Ep:91, loss:0.00001, loss_test:0.06075, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.304, tt:2971.988\n",
      "Ep:92, loss:0.00001, loss_test:0.06302, lr:9.61e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.316, tt:3005.387\n",
      "Ep:93, loss:0.00001, loss_test:0.06058, lr:9.51e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.303, tt:3036.511\n",
      "Ep:94, loss:0.00001, loss_test:0.06355, lr:9.41e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.323, tt:3070.678\n",
      "Ep:95, loss:0.00001, loss_test:0.05927, lr:9.32e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.328, tt:3103.525\n",
      "Ep:96, loss:0.00001, loss_test:0.06402, lr:9.23e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.316, tt:3134.668\n",
      "Ep:97, loss:0.00001, loss_test:0.05983, lr:9.14e-03, fs:0.89691 (r=0.879,p=0.916),  time:32.296, tt:3164.983\n",
      "Ep:98, loss:0.00001, loss_test:0.06298, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.296, tt:3197.266\n",
      "Ep:99, loss:0.00001, loss_test:0.05980, lr:8.95e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.292, tt:3229.218\n",
      "Ep:100, loss:0.00001, loss_test:0.06177, lr:8.86e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.282, tt:3260.527\n",
      "Ep:101, loss:0.00001, loss_test:0.06061, lr:8.78e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.257, tt:3290.197\n",
      "Ep:102, loss:0.00001, loss_test:0.06078, lr:8.69e-03, fs:0.90155 (r=0.879,p=0.926),  time:32.247, tt:3321.471\n",
      "Ep:103, loss:0.00001, loss_test:0.06197, lr:8.60e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.214, tt:3350.298\n",
      "Ep:104, loss:0.00001, loss_test:0.06115, lr:8.51e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.196, tt:3380.626\n",
      "Ep:105, loss:0.00001, loss_test:0.06187, lr:8.43e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.190, tt:3412.113\n",
      "Ep:106, loss:0.00001, loss_test:0.05970, lr:8.35e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.180, tt:3443.224\n",
      "Ep:107, loss:0.00001, loss_test:0.06253, lr:8.26e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.173, tt:3474.738\n",
      "Ep:108, loss:0.00001, loss_test:0.06098, lr:8.18e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.145, tt:3503.777\n",
      "Ep:109, loss:0.00001, loss_test:0.06035, lr:8.10e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.138, tt:3535.136\n",
      "Ep:110, loss:0.00001, loss_test:0.06150, lr:8.02e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.123, tt:3565.676\n",
      "Ep:111, loss:0.00001, loss_test:0.06005, lr:7.94e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.123, tt:3597.748\n",
      "Ep:112, loss:0.00001, loss_test:0.06151, lr:7.86e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.123, tt:3629.927\n",
      "Ep:113, loss:0.00001, loss_test:0.06011, lr:7.78e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.103, tt:3659.702\n",
      "Ep:114, loss:0.00001, loss_test:0.06121, lr:7.70e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.098, tt:3691.218\n",
      "Ep:115, loss:0.00001, loss_test:0.06082, lr:7.62e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.126, tt:3726.601\n",
      "Ep:116, loss:0.00001, loss_test:0.06059, lr:7.55e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.138, tt:3760.105\n",
      "Ep:117, loss:0.00001, loss_test:0.06089, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.155, tt:3794.243\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.06057, lr:7.47e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.138, tt:3824.376\n",
      "Ep:119, loss:0.00001, loss_test:0.06101, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.142, tt:3857.023\n",
      "Ep:120, loss:0.00001, loss_test:0.05993, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.146, tt:3889.651\n",
      "Ep:121, loss:0.00001, loss_test:0.06068, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.135, tt:3920.439\n",
      "Ep:122, loss:0.00001, loss_test:0.06082, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.147, tt:3954.097\n",
      "Ep:123, loss:0.00001, loss_test:0.06033, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.162, tt:3988.034\n",
      "Ep:124, loss:0.00001, loss_test:0.06083, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.169, tt:4021.065\n",
      "Ep:125, loss:0.00001, loss_test:0.05979, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.175, tt:4054.096\n",
      "Ep:126, loss:0.00001, loss_test:0.06086, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.185, tt:4087.515\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.05943, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.177, tt:4118.627\n",
      "Ep:128, loss:0.00001, loss_test:0.06059, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.182, tt:4151.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.06059, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.184, tt:4183.867\n",
      "Ep:130, loss:0.00001, loss_test:0.06020, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.197, tt:4217.779\n",
      "Ep:131, loss:0.00001, loss_test:0.05962, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.196, tt:4249.893\n",
      "Ep:132, loss:0.00001, loss_test:0.06027, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.201, tt:4282.728\n",
      "Ep:133, loss:0.00001, loss_test:0.05980, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.193, tt:4313.912\n",
      "Ep:134, loss:0.00001, loss_test:0.06084, lr:7.47e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.191, tt:4345.795\n",
      "Ep:135, loss:0.00001, loss_test:0.06016, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.186, tt:4377.333\n",
      "Ep:136, loss:0.00001, loss_test:0.06045, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.181, tt:4408.853\n",
      "Ep:137, loss:0.00001, loss_test:0.05997, lr:7.47e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.175, tt:4440.092\n",
      "Ep:138, loss:0.00001, loss_test:0.05990, lr:7.40e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.175, tt:4472.300\n",
      "Ep:139, loss:0.00001, loss_test:0.06103, lr:7.32e-03, fs:0.93048 (r=0.879,p=0.989),  time:32.163, tt:4502.883\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00001, loss_test:0.05991, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.161, tt:4534.764\n",
      "Ep:141, loss:0.00001, loss_test:0.06029, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.152, tt:4565.531\n",
      "Ep:142, loss:0.00001, loss_test:0.05980, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.148, tt:4597.169\n",
      "Ep:143, loss:0.00001, loss_test:0.06067, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.153, tt:4630.017\n",
      "Ep:144, loss:0.00001, loss_test:0.05962, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.143, tt:4660.725\n",
      "Ep:145, loss:0.00001, loss_test:0.06116, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.142, tt:4692.781\n",
      "Ep:146, loss:0.00001, loss_test:0.05951, lr:7.32e-03, fs:0.92553 (r=0.879,p=0.978),  time:32.141, tt:4724.738\n",
      "Ep:147, loss:0.00001, loss_test:0.06187, lr:7.32e-03, fs:0.90110 (r=0.828,p=0.988),  time:32.135, tt:4756.045\n",
      "Ep:148, loss:0.00001, loss_test:0.06009, lr:7.32e-03, fs:0.90811 (r=0.848,p=0.977),  time:32.145, tt:4789.636\n",
      "Ep:149, loss:0.00001, loss_test:0.06091, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.153, tt:4822.932\n",
      "Ep:150, loss:0.00001, loss_test:0.06031, lr:7.32e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.155, tt:4855.377\n",
      "Ep:151, loss:0.00001, loss_test:0.06070, lr:7.25e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.171, tt:4890.057\n",
      "Ep:152, loss:0.00001, loss_test:0.06153, lr:7.18e-03, fs:0.90217 (r=0.838,p=0.976),  time:32.170, tt:4922.072\n",
      "Ep:153, loss:0.00001, loss_test:0.05976, lr:7.11e-03, fs:0.89617 (r=0.828,p=0.976),  time:32.157, tt:4952.175\n",
      "Ep:154, loss:0.00000, loss_test:0.06077, lr:7.03e-03, fs:0.90710 (r=0.838,p=0.988),  time:32.166, tt:4985.805\n",
      "Ep:155, loss:0.00000, loss_test:0.06073, lr:6.96e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.169, tt:5018.310\n",
      "Ep:156, loss:0.00000, loss_test:0.06064, lr:6.89e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.172, tt:5051.018\n",
      "Ep:157, loss:0.00000, loss_test:0.06102, lr:6.83e-03, fs:0.89011 (r=0.818,p=0.976),  time:32.160, tt:5081.266\n",
      "Ep:158, loss:0.00000, loss_test:0.06049, lr:6.76e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.157, tt:5112.913\n",
      "Ep:159, loss:0.00000, loss_test:0.06098, lr:6.69e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.154, tt:5144.709\n",
      "Ep:160, loss:0.00000, loss_test:0.06051, lr:6.62e-03, fs:0.87778 (r=0.798,p=0.975),  time:32.156, tt:5177.150\n",
      "Ep:161, loss:0.00000, loss_test:0.06054, lr:6.56e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.150, tt:5208.313\n",
      "Ep:162, loss:0.00000, loss_test:0.06119, lr:6.49e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.141, tt:5238.988\n",
      "Ep:163, loss:0.00000, loss_test:0.06055, lr:6.43e-03, fs:0.87151 (r=0.788,p=0.975),  time:32.138, tt:5270.551\n",
      "Ep:164, loss:0.00000, loss_test:0.06122, lr:6.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.138, tt:5302.722\n",
      "Ep:165, loss:0.00000, loss_test:0.06070, lr:6.30e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.139, tt:5335.122\n",
      "Ep:166, loss:0.00000, loss_test:0.06102, lr:6.24e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.134, tt:5366.370\n",
      "Ep:167, loss:0.00000, loss_test:0.06098, lr:6.17e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.134, tt:5398.538\n",
      "Ep:168, loss:0.00000, loss_test:0.06126, lr:6.11e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.131, tt:5430.151\n",
      "Ep:169, loss:0.00000, loss_test:0.06179, lr:6.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.146, tt:5464.815\n",
      "Ep:170, loss:0.00000, loss_test:0.06147, lr:5.99e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.151, tt:5497.813\n",
      "Ep:171, loss:0.00000, loss_test:0.06148, lr:5.93e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.153, tt:5530.299\n",
      "Ep:172, loss:0.00000, loss_test:0.06173, lr:5.87e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.178, tt:5566.762\n",
      "Ep:173, loss:0.00000, loss_test:0.06112, lr:5.81e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.179, tt:5599.113\n",
      "Ep:174, loss:0.00000, loss_test:0.06202, lr:5.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.175, tt:5630.604\n",
      "Ep:175, loss:0.00000, loss_test:0.06197, lr:5.70e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.183, tt:5664.260\n",
      "Ep:176, loss:0.00000, loss_test:0.06135, lr:5.64e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.189, tt:5697.367\n",
      "Ep:177, loss:0.00000, loss_test:0.06164, lr:5.58e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.193, tt:5730.322\n",
      "Ep:178, loss:0.00000, loss_test:0.06208, lr:5.53e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.197, tt:5763.309\n",
      "Ep:179, loss:0.00000, loss_test:0.06142, lr:5.47e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.194, tt:5794.984\n",
      "Ep:180, loss:0.00000, loss_test:0.06207, lr:5.42e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.198, tt:5827.867\n",
      "Ep:181, loss:0.00000, loss_test:0.06167, lr:5.36e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.197, tt:5859.849\n",
      "Ep:182, loss:0.00000, loss_test:0.06171, lr:5.31e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.194, tt:5891.559\n",
      "Ep:183, loss:0.00000, loss_test:0.06295, lr:5.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.198, tt:5924.459\n",
      "Ep:184, loss:0.00000, loss_test:0.06115, lr:5.20e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.206, tt:5958.174\n",
      "Ep:185, loss:0.00000, loss_test:0.06247, lr:5.15e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.208, tt:5990.758\n",
      "Ep:186, loss:0.00000, loss_test:0.06228, lr:5.10e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.212, tt:6023.617\n",
      "Ep:187, loss:0.00000, loss_test:0.06208, lr:5.05e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.221, tt:6057.551\n",
      "Ep:188, loss:0.00000, loss_test:0.06279, lr:5.00e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.223, tt:6090.198\n",
      "Ep:189, loss:0.00000, loss_test:0.06222, lr:4.95e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.222, tt:6122.248\n",
      "Ep:190, loss:0.00000, loss_test:0.06242, lr:4.90e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.228, tt:6155.528\n",
      "Ep:191, loss:0.00000, loss_test:0.06275, lr:4.85e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.228, tt:6187.859\n",
      "Ep:192, loss:0.00000, loss_test:0.06272, lr:4.80e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.232, tt:6220.841\n",
      "Ep:193, loss:0.00000, loss_test:0.06291, lr:4.75e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.258, tt:6258.080\n",
      "Ep:194, loss:0.00000, loss_test:0.06209, lr:4.71e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.269, tt:6292.494\n",
      "Ep:195, loss:0.00000, loss_test:0.06329, lr:4.66e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.268, tt:6324.466\n",
      "Ep:196, loss:0.00000, loss_test:0.06285, lr:4.61e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.267, tt:6356.637\n",
      "Ep:197, loss:0.00000, loss_test:0.06319, lr:4.57e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.273, tt:6389.980\n",
      "Ep:198, loss:0.00000, loss_test:0.06290, lr:4.52e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.276, tt:6422.916\n",
      "Ep:199, loss:0.00000, loss_test:0.06217, lr:4.48e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.283, tt:6456.586\n",
      "Ep:200, loss:0.00000, loss_test:0.06353, lr:4.43e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.281, tt:6488.541\n",
      "Ep:201, loss:0.00000, loss_test:0.06332, lr:4.39e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.266, tt:6517.803\n",
      "Ep:202, loss:0.00000, loss_test:0.06289, lr:4.34e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.248, tt:6546.278\n",
      "Ep:203, loss:0.00000, loss_test:0.06313, lr:4.30e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.236, tt:6576.185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.06307, lr:4.26e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.221, tt:6605.212\n",
      "Ep:205, loss:0.00000, loss_test:0.06333, lr:4.21e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.174, tt:6627.822\n",
      "Ep:206, loss:0.00000, loss_test:0.06316, lr:4.17e-03, fs:0.86517 (r=0.778,p=0.975),  time:32.090, tt:6642.722\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=3,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 2048: \n",
      "Ep:0, loss:0.00014, loss_test:0.14582, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:23.650, tt:23.650\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14527, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.490, tt:54.980\n",
      "Ep:2, loss:0.00014, loss_test:0.14432, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.860, tt:86.580\n",
      "Ep:3, loss:0.00014, loss_test:0.14278, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.858, tt:119.432\n",
      "Ep:4, loss:0.00014, loss_test:0.14052, lr:1.00e-02, fs:0.64846 (r=0.960,p=0.490),  time:30.475, tt:152.375\n",
      "Ep:5, loss:0.00013, loss_test:0.13715, lr:1.00e-02, fs:0.63604 (r=0.909,p=0.489),  time:30.944, tt:185.663\n",
      "Ep:6, loss:0.00013, loss_test:0.13248, lr:1.00e-02, fs:0.62357 (r=0.828,p=0.500),  time:31.408, tt:219.856\n",
      "Ep:7, loss:0.00012, loss_test:0.12725, lr:1.00e-02, fs:0.66116 (r=0.808,p=0.559),  time:31.690, tt:253.523\n",
      "Ep:8, loss:0.00012, loss_test:0.12314, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:31.749, tt:285.743\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00011, loss_test:0.12092, lr:1.00e-02, fs:0.70531 (r=0.737,p=0.676),  time:31.637, tt:316.375\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00011, loss_test:0.11752, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:31.688, tt:348.572\n",
      "Ep:11, loss:0.00011, loss_test:0.11497, lr:1.00e-02, fs:0.70698 (r=0.768,p=0.655),  time:31.865, tt:382.384\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00010, loss_test:0.11249, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:31.879, tt:414.430\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00010, loss_test:0.11032, lr:1.00e-02, fs:0.69951 (r=0.717,p=0.683),  time:31.957, tt:447.396\n",
      "Ep:14, loss:0.00010, loss_test:0.10673, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:32.177, tt:482.659\n",
      "Ep:15, loss:0.00009, loss_test:0.10371, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:32.146, tt:514.343\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00009, loss_test:0.10109, lr:1.00e-02, fs:0.71845 (r=0.747,p=0.692),  time:32.246, tt:548.184\n",
      "Ep:17, loss:0.00009, loss_test:0.09977, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:32.259, tt:580.660\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00009, loss_test:0.09847, lr:1.00e-02, fs:0.71134 (r=0.697,p=0.726),  time:32.246, tt:612.665\n",
      "Ep:19, loss:0.00008, loss_test:0.09720, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:32.261, tt:645.213\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00008, loss_test:0.09599, lr:1.00e-02, fs:0.72251 (r=0.697,p=0.750),  time:32.282, tt:677.925\n",
      "Ep:21, loss:0.00008, loss_test:0.09484, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:32.310, tt:710.816\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00008, loss_test:0.09406, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:32.382, tt:744.782\n",
      "Ep:23, loss:0.00007, loss_test:0.09344, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:32.345, tt:776.292\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00007, loss_test:0.09249, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:32.325, tt:808.117\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00007, loss_test:0.09141, lr:1.00e-02, fs:0.76289 (r=0.747,p=0.779),  time:32.369, tt:841.602\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00007, loss_test:0.09083, lr:1.00e-02, fs:0.76190 (r=0.727,p=0.800),  time:32.415, tt:875.209\n",
      "Ep:27, loss:0.00007, loss_test:0.09051, lr:1.00e-02, fs:0.75532 (r=0.717,p=0.798),  time:32.390, tt:906.923\n",
      "Ep:28, loss:0.00007, loss_test:0.08983, lr:1.00e-02, fs:0.75936 (r=0.717,p=0.807),  time:32.373, tt:938.818\n",
      "Ep:29, loss:0.00006, loss_test:0.08870, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.408, tt:972.242\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00006, loss_test:0.08823, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:32.451, tt:1005.979\n",
      "Ep:31, loss:0.00006, loss_test:0.08757, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:32.474, tt:1039.182\n",
      "Ep:32, loss:0.00006, loss_test:0.08714, lr:1.00e-02, fs:0.76344 (r=0.717,p=0.816),  time:32.497, tt:1072.401\n",
      "Ep:33, loss:0.00006, loss_test:0.08633, lr:1.00e-02, fs:0.77005 (r=0.727,p=0.818),  time:32.499, tt:1104.957\n",
      "Ep:34, loss:0.00006, loss_test:0.08580, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:32.497, tt:1137.396\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00005, loss_test:0.08513, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.523, tt:1170.825\n",
      "Ep:36, loss:0.00005, loss_test:0.08436, lr:1.00e-02, fs:0.78075 (r=0.737,p=0.830),  time:32.523, tt:1203.337\n",
      "Ep:37, loss:0.00005, loss_test:0.08428, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:32.518, tt:1235.699\n",
      "Ep:38, loss:0.00005, loss_test:0.08381, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:32.496, tt:1267.334\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00005, loss_test:0.08318, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:32.489, tt:1299.559\n",
      "Ep:40, loss:0.00005, loss_test:0.08273, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:32.466, tt:1331.090\n",
      "Ep:41, loss:0.00005, loss_test:0.08256, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:32.483, tt:1364.294\n",
      "Ep:42, loss:0.00005, loss_test:0.08258, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:32.477, tt:1396.524\n",
      "Ep:43, loss:0.00004, loss_test:0.08214, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:32.499, tt:1429.945\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00004, loss_test:0.08240, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:32.489, tt:1462.014\n",
      "Ep:45, loss:0.00004, loss_test:0.08208, lr:1.00e-02, fs:0.79365 (r=0.758,p=0.833),  time:32.502, tt:1495.085\n",
      "Ep:46, loss:0.00004, loss_test:0.08264, lr:1.00e-02, fs:0.79144 (r=0.747,p=0.841),  time:32.523, tt:1528.568\n",
      "Ep:47, loss:0.00004, loss_test:0.08155, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:32.518, tt:1560.841\n",
      "Ep:48, loss:0.00004, loss_test:0.08305, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:32.556, tt:1595.264\n",
      "Ep:49, loss:0.00004, loss_test:0.08191, lr:1.00e-02, fs:0.79570 (r=0.747,p=0.851),  time:32.580, tt:1628.980\n",
      "Ep:50, loss:0.00004, loss_test:0.08149, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:32.592, tt:1662.183\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.08288, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:32.587, tt:1694.531\n",
      "Ep:52, loss:0.00004, loss_test:0.08141, lr:1.00e-02, fs:0.81481 (r=0.778,p=0.856),  time:32.571, tt:1726.254\n",
      "Ep:53, loss:0.00003, loss_test:0.08186, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:32.565, tt:1758.521\n",
      "Ep:54, loss:0.00003, loss_test:0.08235, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:32.564, tt:1791.039\n",
      "Ep:55, loss:0.00003, loss_test:0.08181, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:32.560, tt:1823.358\n",
      "Ep:56, loss:0.00003, loss_test:0.08260, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:32.543, tt:1854.929\n",
      "Ep:57, loss:0.00003, loss_test:0.08153, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:32.509, tt:1885.519\n",
      "Ep:58, loss:0.00003, loss_test:0.08295, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:32.485, tt:1916.642\n",
      "Ep:59, loss:0.00003, loss_test:0.08255, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:32.471, tt:1948.285\n",
      "Ep:60, loss:0.00003, loss_test:0.08192, lr:1.00e-02, fs:0.80000 (r=0.747,p=0.860),  time:32.464, tt:1980.293\n",
      "Ep:61, loss:0.00003, loss_test:0.08326, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:32.448, tt:2011.804\n",
      "Ep:62, loss:0.00003, loss_test:0.08199, lr:9.90e-03, fs:0.80000 (r=0.747,p=0.860),  time:32.433, tt:2043.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00003, loss_test:0.08393, lr:9.80e-03, fs:0.78022 (r=0.717,p=0.855),  time:32.418, tt:2074.742\n",
      "Ep:64, loss:0.00003, loss_test:0.08298, lr:9.70e-03, fs:0.77348 (r=0.707,p=0.854),  time:32.395, tt:2105.695\n",
      "Ep:65, loss:0.00003, loss_test:0.08326, lr:9.61e-03, fs:0.80000 (r=0.747,p=0.860),  time:32.385, tt:2137.401\n",
      "Ep:66, loss:0.00003, loss_test:0.08357, lr:9.51e-03, fs:0.76667 (r=0.697,p=0.852),  time:32.374, tt:2169.086\n",
      "Ep:67, loss:0.00003, loss_test:0.08414, lr:9.41e-03, fs:0.77348 (r=0.707,p=0.854),  time:32.367, tt:2200.990\n",
      "Ep:68, loss:0.00003, loss_test:0.08337, lr:9.32e-03, fs:0.77348 (r=0.707,p=0.854),  time:32.338, tt:2231.293\n",
      "Ep:69, loss:0.00002, loss_test:0.08421, lr:9.23e-03, fs:0.77528 (r=0.697,p=0.873),  time:32.360, tt:2265.176\n",
      "Ep:70, loss:0.00002, loss_test:0.08444, lr:9.14e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.323, tt:2294.929\n",
      "Ep:71, loss:0.00002, loss_test:0.08425, lr:9.04e-03, fs:0.77966 (r=0.697,p=0.885),  time:32.272, tt:2323.592\n",
      "Ep:72, loss:0.00002, loss_test:0.08484, lr:8.95e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.270, tt:2355.687\n",
      "Ep:73, loss:0.00002, loss_test:0.08427, lr:8.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:32.263, tt:2387.427\n",
      "Ep:74, loss:0.00002, loss_test:0.08541, lr:8.78e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.227, tt:2417.006\n",
      "Ep:75, loss:0.00002, loss_test:0.08430, lr:8.69e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.245, tt:2450.586\n",
      "Ep:76, loss:0.00002, loss_test:0.08724, lr:8.60e-03, fs:0.79096 (r=0.707,p=0.897),  time:32.244, tt:2482.762\n",
      "Ep:77, loss:0.00002, loss_test:0.08493, lr:8.51e-03, fs:0.79121 (r=0.727,p=0.867),  time:32.241, tt:2514.796\n",
      "Ep:78, loss:0.00002, loss_test:0.08521, lr:8.43e-03, fs:0.78652 (r=0.707,p=0.886),  time:32.246, tt:2547.407\n",
      "Ep:79, loss:0.00002, loss_test:0.08840, lr:8.35e-03, fs:0.78212 (r=0.707,p=0.875),  time:32.269, tt:2581.483\n",
      "Ep:80, loss:0.00002, loss_test:0.08416, lr:8.26e-03, fs:0.79558 (r=0.727,p=0.878),  time:32.285, tt:2615.110\n",
      "Ep:81, loss:0.00002, loss_test:0.08899, lr:8.18e-03, fs:0.78652 (r=0.707,p=0.886),  time:32.264, tt:2645.649\n",
      "Ep:82, loss:0.00002, loss_test:0.08646, lr:8.10e-03, fs:0.79775 (r=0.717,p=0.899),  time:32.271, tt:2678.520\n",
      "Ep:83, loss:0.00002, loss_test:0.08670, lr:8.02e-03, fs:0.79558 (r=0.727,p=0.878),  time:32.254, tt:2709.300\n",
      "Ep:84, loss:0.00002, loss_test:0.08715, lr:7.94e-03, fs:0.79330 (r=0.717,p=0.887),  time:32.250, tt:2741.255\n",
      "Ep:85, loss:0.00002, loss_test:0.08823, lr:7.86e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.251, tt:2773.628\n",
      "Ep:86, loss:0.00002, loss_test:0.08603, lr:7.78e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.265, tt:2807.020\n",
      "Ep:87, loss:0.00002, loss_test:0.08770, lr:7.70e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.262, tt:2839.076\n",
      "Ep:88, loss:0.00002, loss_test:0.08691, lr:7.62e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.273, tt:2872.297\n",
      "Ep:89, loss:0.00002, loss_test:0.08843, lr:7.55e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.285, tt:2905.685\n",
      "Ep:90, loss:0.00002, loss_test:0.08726, lr:7.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.283, tt:2937.760\n",
      "Ep:91, loss:0.00002, loss_test:0.08778, lr:7.40e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.266, tt:2968.456\n",
      "Ep:92, loss:0.00002, loss_test:0.08851, lr:7.32e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.259, tt:3000.083\n",
      "Ep:93, loss:0.00002, loss_test:0.08698, lr:7.25e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.266, tt:3032.987\n",
      "Ep:94, loss:0.00002, loss_test:0.08938, lr:7.18e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.263, tt:3064.986\n",
      "Ep:95, loss:0.00002, loss_test:0.08734, lr:7.11e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.252, tt:3096.172\n",
      "Ep:96, loss:0.00002, loss_test:0.08868, lr:7.03e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.255, tt:3128.727\n",
      "Ep:97, loss:0.00002, loss_test:0.08824, lr:6.96e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.259, tt:3161.354\n",
      "Ep:98, loss:0.00002, loss_test:0.08784, lr:6.89e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.267, tt:3194.385\n",
      "Ep:99, loss:0.00001, loss_test:0.08998, lr:6.83e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.258, tt:3225.779\n",
      "Ep:100, loss:0.00001, loss_test:0.08829, lr:6.76e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.257, tt:3257.926\n",
      "Ep:101, loss:0.00001, loss_test:0.08939, lr:6.69e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.253, tt:3289.842\n",
      "Ep:102, loss:0.00001, loss_test:0.09001, lr:6.62e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.245, tt:3321.222\n",
      "Ep:103, loss:0.00001, loss_test:0.08975, lr:6.56e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.226, tt:3351.536\n",
      "Ep:104, loss:0.00001, loss_test:0.09008, lr:6.49e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.223, tt:3383.372\n",
      "Ep:105, loss:0.00001, loss_test:0.08941, lr:6.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.276, tt:3421.275\n",
      "Ep:106, loss:0.00001, loss_test:0.09011, lr:6.36e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.271, tt:3452.959\n",
      "Ep:107, loss:0.00001, loss_test:0.08983, lr:6.30e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.262, tt:3484.314\n",
      "Ep:108, loss:0.00001, loss_test:0.09047, lr:6.24e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.265, tt:3516.885\n",
      "Ep:109, loss:0.00001, loss_test:0.08958, lr:6.17e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.259, tt:3548.453\n",
      "Ep:110, loss:0.00001, loss_test:0.09072, lr:6.11e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.228, tt:3577.333\n",
      "Ep:111, loss:0.00001, loss_test:0.08987, lr:6.05e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.215, tt:3608.095\n",
      "Ep:112, loss:0.00001, loss_test:0.09049, lr:5.99e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.204, tt:3639.098\n",
      "Ep:113, loss:0.00001, loss_test:0.09059, lr:5.93e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.209, tt:3671.869\n",
      "Ep:114, loss:0.00001, loss_test:0.09123, lr:5.87e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.214, tt:3704.627\n",
      "Ep:115, loss:0.00001, loss_test:0.09026, lr:5.81e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.212, tt:3736.554\n",
      "Ep:116, loss:0.00001, loss_test:0.09172, lr:5.75e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.199, tt:3767.311\n",
      "Ep:117, loss:0.00001, loss_test:0.09136, lr:5.70e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.178, tt:3796.995\n",
      "Ep:118, loss:0.00001, loss_test:0.09096, lr:5.64e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.168, tt:3828.029\n",
      "Ep:119, loss:0.00001, loss_test:0.09083, lr:5.58e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.149, tt:3857.864\n",
      "Ep:120, loss:0.00001, loss_test:0.09167, lr:5.53e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.136, tt:3888.493\n",
      "Ep:121, loss:0.00001, loss_test:0.09242, lr:5.47e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.133, tt:3920.244\n",
      "Ep:122, loss:0.00001, loss_test:0.08993, lr:5.42e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.120, tt:3950.735\n",
      "Ep:123, loss:0.00001, loss_test:0.09216, lr:5.36e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.113, tt:3982.029\n",
      "Ep:124, loss:0.00001, loss_test:0.09160, lr:5.31e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.103, tt:4012.892\n",
      "Ep:125, loss:0.00001, loss_test:0.09128, lr:5.26e-03, fs:0.80000 (r=0.727,p=0.889),  time:32.101, tt:4044.743\n",
      "Ep:126, loss:0.00001, loss_test:0.09261, lr:5.20e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.094, tt:4075.938\n",
      "Ep:127, loss:0.00001, loss_test:0.09059, lr:5.15e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.098, tt:4108.556\n",
      "Ep:128, loss:0.00001, loss_test:0.09184, lr:5.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:32.101, tt:4141.063\n",
      "Ep:129, loss:0.00001, loss_test:0.09158, lr:5.05e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.097, tt:4172.665\n",
      "Ep:130, loss:0.00001, loss_test:0.09137, lr:5.00e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.101, tt:4205.205\n",
      "Ep:131, loss:0.00001, loss_test:0.09213, lr:4.95e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.129, tt:4240.965\n",
      "Ep:132, loss:0.00001, loss_test:0.09115, lr:4.90e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.124, tt:4272.546\n",
      "Ep:133, loss:0.00001, loss_test:0.09138, lr:4.85e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.128, tt:4305.165\n",
      "Ep:134, loss:0.00001, loss_test:0.09211, lr:4.80e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.134, tt:4338.028\n",
      "Ep:135, loss:0.00001, loss_test:0.09155, lr:4.75e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.134, tt:4370.188\n",
      "Ep:136, loss:0.00001, loss_test:0.09181, lr:4.71e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.131, tt:4401.976\n",
      "Ep:137, loss:0.00001, loss_test:0.09170, lr:4.66e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.132, tt:4434.275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.09192, lr:4.61e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.134, tt:4466.617\n",
      "Ep:139, loss:0.00001, loss_test:0.09207, lr:4.57e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.135, tt:4498.940\n",
      "Ep:140, loss:0.00001, loss_test:0.09088, lr:4.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.137, tt:4531.351\n",
      "Ep:141, loss:0.00001, loss_test:0.09205, lr:4.48e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.137, tt:4563.399\n",
      "Ep:142, loss:0.00001, loss_test:0.09214, lr:4.43e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.137, tt:4595.567\n",
      "Ep:143, loss:0.00001, loss_test:0.09147, lr:4.39e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.145, tt:4628.938\n",
      "Ep:144, loss:0.00001, loss_test:0.09284, lr:4.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.146, tt:4661.196\n",
      "Ep:145, loss:0.00001, loss_test:0.09155, lr:4.30e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.147, tt:4693.482\n",
      "Ep:146, loss:0.00001, loss_test:0.09192, lr:4.26e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.141, tt:4724.688\n",
      "Ep:147, loss:0.00001, loss_test:0.09230, lr:4.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.151, tt:4758.391\n",
      "Ep:148, loss:0.00001, loss_test:0.09143, lr:4.17e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.153, tt:4790.787\n",
      "Ep:149, loss:0.00001, loss_test:0.09271, lr:4.13e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.152, tt:4822.834\n",
      "Ep:150, loss:0.00001, loss_test:0.09262, lr:4.09e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.153, tt:4855.163\n",
      "Ep:151, loss:0.00001, loss_test:0.09129, lr:4.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.157, tt:4887.795\n",
      "Ep:152, loss:0.00001, loss_test:0.09268, lr:4.01e-03, fs:0.80899 (r=0.727,p=0.911),  time:32.152, tt:4919.209\n",
      "Ep:153, loss:0.00001, loss_test:0.09231, lr:3.97e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.150, tt:4951.113\n",
      "Ep:154, loss:0.00001, loss_test:0.09158, lr:3.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.148, tt:4982.937\n",
      "Ep:155, loss:0.00001, loss_test:0.09318, lr:3.89e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.151, tt:5015.564\n",
      "Ep:156, loss:0.00001, loss_test:0.09203, lr:3.85e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.150, tt:5047.554\n",
      "Ep:157, loss:0.00001, loss_test:0.09179, lr:3.81e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.141, tt:5078.306\n",
      "Ep:158, loss:0.00001, loss_test:0.09267, lr:3.77e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.140, tt:5110.276\n",
      "Ep:159, loss:0.00001, loss_test:0.09238, lr:3.73e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.136, tt:5141.723\n",
      "Ep:160, loss:0.00001, loss_test:0.09220, lr:3.70e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.139, tt:5174.333\n",
      "Ep:161, loss:0.00001, loss_test:0.09241, lr:3.66e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.145, tt:5207.481\n",
      "Ep:162, loss:0.00001, loss_test:0.09200, lr:3.62e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.148, tt:5240.189\n",
      "Ep:163, loss:0.00001, loss_test:0.09243, lr:3.59e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.158, tt:5273.872\n",
      "Ep:164, loss:0.00001, loss_test:0.09261, lr:3.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.156, tt:5305.727\n",
      "Ep:165, loss:0.00001, loss_test:0.09202, lr:3.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.153, tt:5337.421\n",
      "Ep:166, loss:0.00001, loss_test:0.09309, lr:3.48e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.147, tt:5368.516\n",
      "Ep:167, loss:0.00001, loss_test:0.09343, lr:3.45e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.143, tt:5400.000\n",
      "Ep:168, loss:0.00001, loss_test:0.09176, lr:3.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.140, tt:5431.615\n",
      "Ep:169, loss:0.00001, loss_test:0.09260, lr:3.38e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.143, tt:5464.284\n",
      "Ep:170, loss:0.00001, loss_test:0.09359, lr:3.34e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.145, tt:5496.726\n",
      "Ep:171, loss:0.00001, loss_test:0.09217, lr:3.31e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.145, tt:5528.889\n",
      "Ep:172, loss:0.00001, loss_test:0.09263, lr:3.28e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.162, tt:5563.972\n",
      "Ep:173, loss:0.00001, loss_test:0.09355, lr:3.24e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.156, tt:5595.223\n",
      "Ep:174, loss:0.00001, loss_test:0.09203, lr:3.21e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.152, tt:5626.546\n",
      "Ep:175, loss:0.00001, loss_test:0.09279, lr:3.18e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.157, tt:5659.691\n",
      "Ep:176, loss:0.00001, loss_test:0.09344, lr:3.15e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.151, tt:5690.658\n",
      "Ep:177, loss:0.00001, loss_test:0.09243, lr:3.12e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.150, tt:5722.721\n",
      "Ep:178, loss:0.00001, loss_test:0.09240, lr:3.09e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.152, tt:5755.252\n",
      "Ep:179, loss:0.00001, loss_test:0.09300, lr:3.05e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.161, tt:5788.923\n",
      "Ep:180, loss:0.00001, loss_test:0.09254, lr:3.02e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.163, tt:5821.563\n",
      "Ep:181, loss:0.00001, loss_test:0.09232, lr:2.99e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.160, tt:5853.042\n",
      "Ep:182, loss:0.00001, loss_test:0.09305, lr:2.96e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.165, tt:5886.129\n",
      "Ep:183, loss:0.00001, loss_test:0.09265, lr:2.93e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.172, tt:5919.665\n",
      "Ep:184, loss:0.00001, loss_test:0.09291, lr:2.90e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.184, tt:5953.954\n",
      "Ep:185, loss:0.00001, loss_test:0.09279, lr:2.88e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.189, tt:5987.169\n",
      "Ep:186, loss:0.00001, loss_test:0.09231, lr:2.85e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.202, tt:6021.727\n",
      "Ep:187, loss:0.00001, loss_test:0.09285, lr:2.82e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.205, tt:6054.607\n",
      "Ep:188, loss:0.00001, loss_test:0.09255, lr:2.79e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.208, tt:6087.393\n",
      "Ep:189, loss:0.00001, loss_test:0.09257, lr:2.76e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.215, tt:6120.764\n",
      "Ep:190, loss:0.00001, loss_test:0.09310, lr:2.73e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.226, tt:6155.143\n",
      "Ep:191, loss:0.00001, loss_test:0.09292, lr:2.71e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.232, tt:6188.488\n",
      "Ep:192, loss:0.00001, loss_test:0.09277, lr:2.68e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.241, tt:6222.490\n",
      "Ep:193, loss:0.00001, loss_test:0.09302, lr:2.65e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.279, tt:6262.170\n",
      "Ep:194, loss:0.00001, loss_test:0.09278, lr:2.63e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.277, tt:6294.031\n",
      "Ep:195, loss:0.00001, loss_test:0.09263, lr:2.60e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.284, tt:6327.577\n",
      "Ep:196, loss:0.00001, loss_test:0.09303, lr:2.57e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.284, tt:6359.984\n",
      "Ep:197, loss:0.00001, loss_test:0.09270, lr:2.55e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.290, tt:6393.403\n",
      "Ep:198, loss:0.00001, loss_test:0.09260, lr:2.52e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.291, tt:6425.914\n",
      "Ep:199, loss:0.00001, loss_test:0.09286, lr:2.50e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.302, tt:6460.358\n",
      "Ep:200, loss:0.00001, loss_test:0.09307, lr:2.47e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.309, tt:6494.017\n",
      "Ep:201, loss:0.00001, loss_test:0.09303, lr:2.45e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.313, tt:6527.167\n",
      "Ep:202, loss:0.00001, loss_test:0.09267, lr:2.42e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.304, tt:6557.687\n",
      "Ep:203, loss:0.00001, loss_test:0.09298, lr:2.40e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.308, tt:6590.742\n",
      "Ep:204, loss:0.00001, loss_test:0.09275, lr:2.38e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.302, tt:6621.928\n",
      "Ep:205, loss:0.00001, loss_test:0.09293, lr:2.35e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.306, tt:6655.067\n",
      "Ep:206, loss:0.00001, loss_test:0.09287, lr:2.33e-03, fs:0.81356 (r=0.727,p=0.923),  time:32.287, tt:6683.311\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=2048 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.14164, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:58.541, tt:58.541\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13552, lr:1.00e-02, fs:0.64311 (r=0.919,p=0.495),  time:62.418, tt:124.835\n",
      "Ep:2, loss:0.00049, loss_test:0.12437, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:63.505, tt:190.514\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.12170, lr:1.00e-02, fs:0.65990 (r=0.657,p=0.663),  time:64.522, tt:258.087\n",
      "Ep:4, loss:0.00043, loss_test:0.11326, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:65.110, tt:325.550\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00040, loss_test:0.11152, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:65.047, tt:390.281\n",
      "Ep:6, loss:0.00038, loss_test:0.10505, lr:1.00e-02, fs:0.69347 (r=0.697,p=0.690),  time:65.353, tt:457.472\n",
      "Ep:7, loss:0.00035, loss_test:0.10294, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:65.605, tt:524.839\n",
      "Ep:8, loss:0.00034, loss_test:0.10003, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:65.581, tt:590.230\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00032, loss_test:0.09820, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:65.802, tt:658.018\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00030, loss_test:0.09620, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:65.785, tt:723.636\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00029, loss_test:0.09537, lr:1.00e-02, fs:0.72043 (r=0.677,p=0.770),  time:65.854, tt:790.246\n",
      "Ep:12, loss:0.00027, loss_test:0.09489, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:66.049, tt:858.634\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00026, loss_test:0.09207, lr:1.00e-02, fs:0.73118 (r=0.687,p=0.782),  time:66.150, tt:926.107\n",
      "Ep:14, loss:0.00025, loss_test:0.09200, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:66.281, tt:994.214\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.09102, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:66.439, tt:1063.026\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.08877, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:66.501, tt:1130.524\n",
      "Ep:17, loss:0.00021, loss_test:0.08820, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:66.498, tt:1196.971\n",
      "Ep:18, loss:0.00020, loss_test:0.08849, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:66.468, tt:1262.898\n",
      "Ep:19, loss:0.00019, loss_test:0.08935, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:66.551, tt:1331.013\n",
      "Ep:20, loss:0.00018, loss_test:0.08720, lr:1.00e-02, fs:0.75000 (r=0.697,p=0.812),  time:66.668, tt:1400.029\n",
      "Ep:21, loss:0.00018, loss_test:0.08647, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:66.601, tt:1465.220\n",
      "Ep:22, loss:0.00017, loss_test:0.08626, lr:1.00e-02, fs:0.77249 (r=0.737,p=0.811),  time:66.598, tt:1531.755\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08551, lr:1.00e-02, fs:0.76757 (r=0.717,p=0.826),  time:66.659, tt:1599.827\n",
      "Ep:24, loss:0.00016, loss_test:0.08488, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:66.665, tt:1666.621\n",
      "Ep:25, loss:0.00015, loss_test:0.08360, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:66.649, tt:1732.869\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.08385, lr:1.00e-02, fs:0.78307 (r=0.747,p=0.822),  time:66.616, tt:1798.626\n",
      "Ep:27, loss:0.00014, loss_test:0.08390, lr:1.00e-02, fs:0.79121 (r=0.727,p=0.867),  time:66.629, tt:1865.625\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08692, lr:1.00e-02, fs:0.76571 (r=0.677,p=0.882),  time:66.613, tt:1931.789\n",
      "Ep:29, loss:0.00013, loss_test:0.08424, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:66.618, tt:1998.537\n",
      "Ep:30, loss:0.00012, loss_test:0.08575, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:66.658, tt:2066.412\n",
      "Ep:31, loss:0.00012, loss_test:0.08739, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:66.632, tt:2132.231\n",
      "Ep:32, loss:0.00011, loss_test:0.08719, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.673, tt:2200.217\n",
      "Ep:33, loss:0.00011, loss_test:0.08308, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:66.664, tt:2266.588\n",
      "Ep:34, loss:0.00011, loss_test:0.08452, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:66.649, tt:2332.703\n",
      "Ep:35, loss:0.00010, loss_test:0.08838, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.677, tt:2400.365\n",
      "Ep:36, loss:0.00010, loss_test:0.08979, lr:1.00e-02, fs:0.77011 (r=0.677,p=0.893),  time:66.644, tt:2465.842\n",
      "Ep:37, loss:0.00010, loss_test:0.08410, lr:1.00e-02, fs:0.76836 (r=0.687,p=0.872),  time:66.635, tt:2532.137\n",
      "Ep:38, loss:0.00009, loss_test:0.08119, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:66.654, tt:2599.504\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.08171, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:66.673, tt:2666.911\n",
      "Ep:40, loss:0.00009, loss_test:0.08774, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.658, tt:2732.983\n",
      "Ep:41, loss:0.00008, loss_test:0.08749, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.630, tt:2798.451\n",
      "Ep:42, loss:0.00008, loss_test:0.08375, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:66.692, tt:2867.754\n",
      "Ep:43, loss:0.00008, loss_test:0.08608, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:66.701, tt:2934.840\n",
      "Ep:44, loss:0.00007, loss_test:0.08822, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.731, tt:3002.908\n",
      "Ep:45, loss:0.00007, loss_test:0.08974, lr:1.00e-02, fs:0.78161 (r=0.687,p=0.907),  time:66.743, tt:3070.196\n",
      "Ep:46, loss:0.00007, loss_test:0.08834, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.731, tt:3136.369\n",
      "Ep:47, loss:0.00007, loss_test:0.08555, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:66.750, tt:3203.995\n",
      "Ep:48, loss:0.00007, loss_test:0.08577, lr:1.00e-02, fs:0.77273 (r=0.687,p=0.883),  time:66.718, tt:3269.182\n",
      "Ep:49, loss:0.00006, loss_test:0.08607, lr:1.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:66.689, tt:3334.440\n",
      "Ep:50, loss:0.00006, loss_test:0.08832, lr:9.90e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.702, tt:3401.779\n",
      "Ep:51, loss:0.00006, loss_test:0.08976, lr:9.80e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.673, tt:3466.982\n",
      "Ep:52, loss:0.00006, loss_test:0.09145, lr:9.70e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.643, tt:3532.059\n",
      "Ep:53, loss:0.00006, loss_test:0.08981, lr:9.61e-03, fs:0.78161 (r=0.687,p=0.907),  time:66.623, tt:3597.631\n",
      "Ep:54, loss:0.00006, loss_test:0.08846, lr:9.51e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.562, tt:3660.895\n",
      "Ep:55, loss:0.00005, loss_test:0.09259, lr:9.41e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.569, tt:3727.875\n",
      "Ep:56, loss:0.00005, loss_test:0.09363, lr:9.32e-03, fs:0.76023 (r=0.657,p=0.903),  time:66.567, tt:3794.311\n",
      "Ep:57, loss:0.00005, loss_test:0.08726, lr:9.23e-03, fs:0.78857 (r=0.697,p=0.908),  time:66.584, tt:3861.854\n",
      "Ep:58, loss:0.00005, loss_test:0.08979, lr:9.14e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.582, tt:3928.333\n",
      "Ep:59, loss:0.00005, loss_test:0.09082, lr:9.04e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.646, tt:3998.741\n",
      "Ep:60, loss:0.00004, loss_test:0.09509, lr:8.95e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.664, tt:4066.492\n",
      "Ep:61, loss:0.00004, loss_test:0.09415, lr:8.86e-03, fs:0.78613 (r=0.687,p=0.919),  time:66.647, tt:4132.112\n",
      "Ep:62, loss:0.00004, loss_test:0.09521, lr:8.78e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.584, tt:4194.823\n",
      "Ep:63, loss:0.00004, loss_test:0.08942, lr:8.69e-03, fs:0.78161 (r=0.687,p=0.907),  time:66.578, tt:4260.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00004, loss_test:0.09144, lr:8.60e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.581, tt:4327.748\n",
      "Ep:65, loss:0.00004, loss_test:0.09652, lr:8.51e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.561, tt:4393.028\n",
      "Ep:66, loss:0.00003, loss_test:0.09311, lr:8.43e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.528, tt:4457.367\n",
      "Ep:67, loss:0.00003, loss_test:0.09042, lr:8.35e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.526, tt:4523.774\n",
      "Ep:68, loss:0.00003, loss_test:0.09530, lr:8.26e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.515, tt:4589.565\n",
      "Ep:69, loss:0.00003, loss_test:0.09255, lr:8.18e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.528, tt:4656.981\n",
      "Ep:70, loss:0.00003, loss_test:0.09023, lr:8.10e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.548, tt:4724.911\n",
      "Ep:71, loss:0.00003, loss_test:0.09468, lr:8.02e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.554, tt:4791.874\n",
      "Ep:72, loss:0.00003, loss_test:0.09255, lr:7.94e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.599, tt:4861.745\n",
      "Ep:73, loss:0.00003, loss_test:0.09354, lr:7.86e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.568, tt:4926.007\n",
      "Ep:74, loss:0.00003, loss_test:0.09446, lr:7.78e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.597, tt:4994.766\n",
      "Ep:75, loss:0.00003, loss_test:0.09176, lr:7.70e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.608, tt:5062.197\n",
      "Ep:76, loss:0.00003, loss_test:0.09320, lr:7.62e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.594, tt:5127.713\n",
      "Ep:77, loss:0.00003, loss_test:0.09265, lr:7.55e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.581, tt:5193.353\n",
      "Ep:78, loss:0.00002, loss_test:0.09572, lr:7.47e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.596, tt:5261.061\n",
      "Ep:79, loss:0.00002, loss_test:0.09392, lr:7.40e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.591, tt:5327.295\n",
      "Ep:80, loss:0.00002, loss_test:0.09333, lr:7.32e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.589, tt:5393.721\n",
      "Ep:81, loss:0.00002, loss_test:0.09565, lr:7.25e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.575, tt:5459.178\n",
      "Ep:82, loss:0.00002, loss_test:0.09142, lr:7.18e-03, fs:0.79070 (r=0.687,p=0.932),  time:66.596, tt:5527.450\n",
      "Ep:83, loss:0.00002, loss_test:0.09619, lr:7.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.606, tt:5594.922\n",
      "Ep:84, loss:0.00002, loss_test:0.09590, lr:7.03e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.602, tt:5661.169\n",
      "Ep:85, loss:0.00002, loss_test:0.09416, lr:6.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.586, tt:5726.392\n",
      "Ep:86, loss:0.00002, loss_test:0.09484, lr:6.89e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.562, tt:5790.890\n",
      "Ep:87, loss:0.00002, loss_test:0.09749, lr:6.83e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.538, tt:5855.385\n",
      "Ep:88, loss:0.00002, loss_test:0.09460, lr:6.76e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.522, tt:5920.495\n",
      "Ep:89, loss:0.00002, loss_test:0.09649, lr:6.69e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.497, tt:5984.746\n",
      "Ep:90, loss:0.00002, loss_test:0.09658, lr:6.62e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.473, tt:6049.007\n",
      "Ep:91, loss:0.00002, loss_test:0.09663, lr:6.56e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.485, tt:6116.595\n",
      "Ep:92, loss:0.00002, loss_test:0.09715, lr:6.49e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.492, tt:6183.710\n",
      "Ep:93, loss:0.00002, loss_test:0.09580, lr:6.43e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.494, tt:6250.482\n",
      "Ep:94, loss:0.00002, loss_test:0.09774, lr:6.36e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.495, tt:6317.057\n",
      "Ep:95, loss:0.00002, loss_test:0.09833, lr:6.30e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.483, tt:6382.409\n",
      "Ep:96, loss:0.00002, loss_test:0.09730, lr:6.24e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.476, tt:6448.203\n",
      "Ep:97, loss:0.00002, loss_test:0.09753, lr:6.17e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.454, tt:6512.502\n",
      "Ep:98, loss:0.00002, loss_test:0.09754, lr:6.11e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.468, tt:6580.284\n",
      "Ep:99, loss:0.00001, loss_test:0.09866, lr:6.05e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.457, tt:6645.711\n",
      "Ep:100, loss:0.00001, loss_test:0.09828, lr:5.99e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.441, tt:6710.570\n",
      "Ep:101, loss:0.00001, loss_test:0.09747, lr:5.93e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.414, tt:6774.193\n",
      "Ep:102, loss:0.00001, loss_test:0.10036, lr:5.87e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.403, tt:6839.548\n",
      "Ep:103, loss:0.00001, loss_test:0.09865, lr:5.81e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.399, tt:6905.505\n",
      "Ep:104, loss:0.00001, loss_test:0.09941, lr:5.75e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.394, tt:6971.392\n",
      "Ep:105, loss:0.00001, loss_test:0.09863, lr:5.70e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.381, tt:7036.363\n",
      "Ep:106, loss:0.00001, loss_test:0.10053, lr:5.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:66.328, tt:7097.106\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00014, loss_test:0.14225, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:10.619, tt:10.619\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00014, loss_test:0.14187, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:11.934, tt:23.867\n",
      "Ep:2, loss:0.00014, loss_test:0.14130, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:12.672, tt:38.015\n",
      "Ep:3, loss:0.00014, loss_test:0.14053, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:13.179, tt:52.716\n",
      "Ep:4, loss:0.00014, loss_test:0.13950, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:13.659, tt:68.296\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00013, loss_test:0.13815, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:13.831, tt:82.984\n",
      "Ep:6, loss:0.00013, loss_test:0.13638, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:14.040, tt:98.283\n",
      "Ep:7, loss:0.00013, loss_test:0.13410, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:14.243, tt:113.942\n",
      "Ep:8, loss:0.00013, loss_test:0.13123, lr:1.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:14.131, tt:127.177\n",
      "Ep:9, loss:0.00013, loss_test:0.12797, lr:1.00e-02, fs:0.68401 (r=0.929,p=0.541),  time:14.252, tt:142.520\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00012, loss_test:0.12440, lr:1.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:14.235, tt:156.581\n",
      "Ep:11, loss:0.00012, loss_test:0.12112, lr:1.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:14.312, tt:171.744\n",
      "Ep:12, loss:0.00012, loss_test:0.11950, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:14.428, tt:187.570\n",
      "Ep:13, loss:0.00012, loss_test:0.11861, lr:1.00e-02, fs:0.67857 (r=0.768,p=0.608),  time:14.536, tt:203.498\n",
      "Ep:14, loss:0.00012, loss_test:0.11766, lr:1.00e-02, fs:0.66972 (r=0.737,p=0.613),  time:14.480, tt:217.201\n",
      "Ep:15, loss:0.00011, loss_test:0.11660, lr:1.00e-02, fs:0.69406 (r=0.768,p=0.633),  time:14.546, tt:232.740\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00011, loss_test:0.11567, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:14.621, tt:248.565\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00011, loss_test:0.11516, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:14.664, tt:263.959\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00011, loss_test:0.11524, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:14.736, tt:279.980\n",
      "Ep:19, loss:0.00011, loss_test:0.11472, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:14.735, tt:294.702\n",
      "Ep:20, loss:0.00011, loss_test:0.11301, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:14.771, tt:310.188\n",
      "Ep:21, loss:0.00010, loss_test:0.11060, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:14.740, tt:324.288\n",
      "Ep:22, loss:0.00010, loss_test:0.10885, lr:1.00e-02, fs:0.69643 (r=0.788,p=0.624),  time:14.787, tt:340.099\n",
      "Ep:23, loss:0.00010, loss_test:0.10774, lr:1.00e-02, fs:0.69091 (r=0.768,p=0.628),  time:14.751, tt:354.034\n",
      "Ep:24, loss:0.00010, loss_test:0.10677, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:14.737, tt:368.421\n",
      "Ep:25, loss:0.00010, loss_test:0.10583, lr:1.00e-02, fs:0.70000 (r=0.778,p=0.636),  time:14.776, tt:384.168\n",
      "Ep:26, loss:0.00010, loss_test:0.10521, lr:1.00e-02, fs:0.70536 (r=0.798,p=0.632),  time:14.821, tt:400.164\n",
      "Ep:27, loss:0.00010, loss_test:0.10477, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:14.863, tt:416.150\n",
      "Ep:28, loss:0.00009, loss_test:0.10410, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:14.892, tt:431.878\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.10296, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:14.938, tt:448.127\n",
      "Ep:30, loss:0.00009, loss_test:0.10154, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:14.960, tt:463.750\n",
      "Ep:31, loss:0.00009, loss_test:0.10023, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:14.986, tt:479.558\n",
      "Ep:32, loss:0.00009, loss_test:0.09927, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:15.037, tt:496.228\n",
      "Ep:33, loss:0.00009, loss_test:0.09850, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:15.086, tt:512.911\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.09812, lr:1.00e-02, fs:0.72973 (r=0.818,p=0.659),  time:15.130, tt:529.562\n",
      "Ep:35, loss:0.00008, loss_test:0.09778, lr:1.00e-02, fs:0.73451 (r=0.838,p=0.654),  time:15.163, tt:545.869\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.09694, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:15.219, tt:563.114\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.09595, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:15.238, tt:579.051\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.09524, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:15.250, tt:594.732\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.09462, lr:1.00e-02, fs:0.75701 (r=0.818,p=0.704),  time:15.275, tt:610.989\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00008, loss_test:0.09420, lr:1.00e-02, fs:0.75576 (r=0.828,p=0.695),  time:15.284, tt:626.642\n",
      "Ep:41, loss:0.00008, loss_test:0.09374, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:15.309, tt:642.981\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.09304, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:15.343, tt:659.766\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.09231, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:15.360, tt:675.844\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.09177, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:15.362, tt:691.301\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.09133, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:15.374, tt:707.194\n",
      "Ep:46, loss:0.00007, loss_test:0.09089, lr:1.00e-02, fs:0.77358 (r=0.828,p=0.726),  time:15.402, tt:723.896\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.09036, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:15.390, tt:738.705\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00007, loss_test:0.08984, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.383, tt:753.743\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.08934, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.377, tt:768.827\n",
      "Ep:50, loss:0.00007, loss_test:0.08890, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.354, tt:783.070\n",
      "Ep:51, loss:0.00007, loss_test:0.08848, lr:1.00e-02, fs:0.78505 (r=0.848,p=0.730),  time:15.360, tt:798.745\n",
      "Ep:52, loss:0.00007, loss_test:0.08802, lr:1.00e-02, fs:0.78673 (r=0.838,p=0.741),  time:15.350, tt:813.524\n",
      "Ep:53, loss:0.00007, loss_test:0.08772, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.334, tt:828.063\n",
      "Ep:54, loss:0.00007, loss_test:0.08743, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.321, tt:842.663\n",
      "Ep:55, loss:0.00006, loss_test:0.08702, lr:1.00e-02, fs:0.78873 (r=0.848,p=0.737),  time:15.302, tt:856.939\n",
      "Ep:56, loss:0.00006, loss_test:0.08660, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:15.301, tt:872.154\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.08623, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:15.311, tt:888.043\n",
      "Ep:58, loss:0.00006, loss_test:0.08589, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:15.299, tt:902.616\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00006, loss_test:0.08576, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:15.288, tt:917.310\n",
      "Ep:60, loss:0.00006, loss_test:0.08548, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:15.294, tt:932.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00006, loss_test:0.08508, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:15.281, tt:947.399\n",
      "Ep:62, loss:0.00006, loss_test:0.08478, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:15.267, tt:961.792\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00006, loss_test:0.08460, lr:1.00e-02, fs:0.81132 (r=0.869,p=0.761),  time:15.264, tt:976.912\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.08429, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:15.260, tt:991.875\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.08418, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:15.237, tt:1005.675\n",
      "Ep:66, loss:0.00006, loss_test:0.08401, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:15.206, tt:1018.782\n",
      "Ep:67, loss:0.00006, loss_test:0.08378, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:15.197, tt:1033.401\n",
      "Ep:68, loss:0.00006, loss_test:0.08355, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:15.182, tt:1047.565\n",
      "Ep:69, loss:0.00005, loss_test:0.08337, lr:1.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:15.192, tt:1063.409\n",
      "Ep:70, loss:0.00005, loss_test:0.08282, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:15.189, tt:1078.405\n",
      "Ep:71, loss:0.00005, loss_test:0.08274, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:15.172, tt:1092.400\n",
      "Ep:72, loss:0.00005, loss_test:0.08250, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:15.166, tt:1107.099\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00005, loss_test:0.08204, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:15.154, tt:1121.429\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.08188, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:15.152, tt:1136.420\n",
      "Ep:75, loss:0.00005, loss_test:0.08201, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:15.142, tt:1150.802\n",
      "Ep:76, loss:0.00005, loss_test:0.08147, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:15.142, tt:1165.945\n",
      "Ep:77, loss:0.00005, loss_test:0.08138, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:15.137, tt:1180.724\n",
      "Ep:78, loss:0.00005, loss_test:0.08163, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:15.122, tt:1194.652\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.08130, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:15.121, tt:1209.704\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00005, loss_test:0.08091, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:15.107, tt:1223.696\n",
      "Ep:81, loss:0.00005, loss_test:0.08090, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:15.098, tt:1238.040\n",
      "Ep:82, loss:0.00005, loss_test:0.08078, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:15.081, tt:1251.714\n",
      "Ep:83, loss:0.00005, loss_test:0.08056, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:15.083, tt:1266.957\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00005, loss_test:0.08037, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:15.069, tt:1280.829\n",
      "Ep:85, loss:0.00005, loss_test:0.08027, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:15.076, tt:1296.526\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00005, loss_test:0.08003, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:15.092, tt:1313.045\n",
      "Ep:87, loss:0.00004, loss_test:0.07976, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:15.086, tt:1327.570\n",
      "Ep:88, loss:0.00004, loss_test:0.07989, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.088, tt:1342.825\n",
      "Ep:89, loss:0.00004, loss_test:0.07962, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.083, tt:1357.492\n",
      "Ep:90, loss:0.00004, loss_test:0.07935, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.072, tt:1371.595\n",
      "Ep:91, loss:0.00004, loss_test:0.07950, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.070, tt:1386.403\n",
      "Ep:92, loss:0.00004, loss_test:0.07921, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.054, tt:1399.983\n",
      "Ep:93, loss:0.00004, loss_test:0.07903, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.038, tt:1413.610\n",
      "Ep:94, loss:0.00004, loss_test:0.07894, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.055, tt:1430.209\n",
      "Ep:95, loss:0.00004, loss_test:0.07849, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.046, tt:1444.377\n",
      "Ep:96, loss:0.00004, loss_test:0.07852, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:15.044, tt:1459.232\n",
      "Ep:97, loss:0.00004, loss_test:0.07821, lr:9.90e-03, fs:0.82949 (r=0.909,p=0.763),  time:15.041, tt:1473.996\n",
      "Ep:98, loss:0.00004, loss_test:0.07818, lr:9.80e-03, fs:0.83333 (r=0.909,p=0.769),  time:15.041, tt:1489.073\n",
      "Ep:99, loss:0.00004, loss_test:0.07816, lr:9.70e-03, fs:0.83871 (r=0.919,p=0.771),  time:15.033, tt:1503.321\n",
      "Ep:100, loss:0.00004, loss_test:0.07782, lr:9.61e-03, fs:0.83178 (r=0.899,p=0.774),  time:15.034, tt:1518.399\n",
      "Ep:101, loss:0.00004, loss_test:0.07792, lr:9.51e-03, fs:0.83178 (r=0.899,p=0.774),  time:15.026, tt:1532.660\n",
      "Ep:102, loss:0.00004, loss_test:0.07802, lr:9.41e-03, fs:0.83871 (r=0.919,p=0.771),  time:15.023, tt:1547.418\n",
      "Ep:103, loss:0.00004, loss_test:0.07730, lr:9.32e-03, fs:0.83962 (r=0.899,p=0.788),  time:15.024, tt:1562.453\n",
      "Ep:104, loss:0.00004, loss_test:0.07714, lr:9.23e-03, fs:0.84360 (r=0.899,p=0.795),  time:15.026, tt:1577.705\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00004, loss_test:0.07736, lr:9.23e-03, fs:0.83962 (r=0.899,p=0.788),  time:15.019, tt:1592.017\n",
      "Ep:106, loss:0.00004, loss_test:0.07766, lr:9.23e-03, fs:0.83178 (r=0.899,p=0.774),  time:15.014, tt:1606.452\n",
      "Ep:107, loss:0.00004, loss_test:0.07671, lr:9.23e-03, fs:0.83654 (r=0.879,p=0.798),  time:15.013, tt:1621.355\n",
      "Ep:108, loss:0.00004, loss_test:0.07648, lr:9.23e-03, fs:0.84314 (r=0.869,p=0.819),  time:15.017, tt:1636.838\n",
      "Ep:109, loss:0.00004, loss_test:0.07655, lr:9.23e-03, fs:0.82857 (r=0.879,p=0.784),  time:15.009, tt:1650.993\n",
      "Ep:110, loss:0.00004, loss_test:0.07728, lr:9.23e-03, fs:0.84112 (r=0.909,p=0.783),  time:15.011, tt:1666.228\n",
      "Ep:111, loss:0.00004, loss_test:0.07641, lr:9.23e-03, fs:0.82857 (r=0.879,p=0.784),  time:15.010, tt:1681.075\n",
      "Ep:112, loss:0.00004, loss_test:0.07599, lr:9.23e-03, fs:0.84729 (r=0.869,p=0.827),  time:15.009, tt:1696.002\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00003, loss_test:0.07599, lr:9.23e-03, fs:0.85149 (r=0.869,p=0.835),  time:15.013, tt:1711.490\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00003, loss_test:0.07635, lr:9.23e-03, fs:0.83254 (r=0.879,p=0.791),  time:15.016, tt:1726.881\n",
      "Ep:115, loss:0.00003, loss_test:0.07650, lr:9.23e-03, fs:0.83412 (r=0.889,p=0.786),  time:15.011, tt:1741.220\n",
      "Ep:116, loss:0.00003, loss_test:0.07594, lr:9.23e-03, fs:0.84466 (r=0.879,p=0.813),  time:15.003, tt:1755.345\n",
      "Ep:117, loss:0.00003, loss_test:0.07573, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:15.002, tt:1770.225\n",
      "Ep:118, loss:0.00003, loss_test:0.07590, lr:9.23e-03, fs:0.84158 (r=0.859,p=0.825),  time:14.997, tt:1784.604\n",
      "Ep:119, loss:0.00003, loss_test:0.07616, lr:9.23e-03, fs:0.83092 (r=0.869,p=0.796),  time:14.991, tt:1798.968\n",
      "Ep:120, loss:0.00003, loss_test:0.07580, lr:9.23e-03, fs:0.83582 (r=0.848,p=0.824),  time:14.991, tt:1813.895\n",
      "Ep:121, loss:0.00003, loss_test:0.07550, lr:9.23e-03, fs:0.84422 (r=0.848,p=0.840),  time:14.987, tt:1828.458\n",
      "Ep:122, loss:0.00003, loss_test:0.07544, lr:9.23e-03, fs:0.84000 (r=0.848,p=0.832),  time:14.987, tt:1843.402\n",
      "Ep:123, loss:0.00003, loss_test:0.07561, lr:9.23e-03, fs:0.84314 (r=0.869,p=0.819),  time:14.989, tt:1858.601\n",
      "Ep:124, loss:0.00003, loss_test:0.07536, lr:9.23e-03, fs:0.84577 (r=0.859,p=0.833),  time:14.989, tt:1873.670\n",
      "Ep:125, loss:0.00003, loss_test:0.07513, lr:9.14e-03, fs:0.85000 (r=0.859,p=0.842),  time:14.990, tt:1888.790\n",
      "Ep:126, loss:0.00003, loss_test:0.07500, lr:9.04e-03, fs:0.85572 (r=0.869,p=0.843),  time:14.991, tt:1903.861\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00003, loss_test:0.07497, lr:9.04e-03, fs:0.85714 (r=0.879,p=0.837),  time:14.989, tt:1918.640\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00003, loss_test:0.07486, lr:9.04e-03, fs:0.84848 (r=0.848,p=0.848),  time:14.986, tt:1933.154\n",
      "Ep:129, loss:0.00003, loss_test:0.07480, lr:9.04e-03, fs:0.86432 (r=0.869,p=0.860),  time:14.988, tt:1948.376\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00003, loss_test:0.07470, lr:9.04e-03, fs:0.85714 (r=0.879,p=0.837),  time:14.984, tt:1962.855\n",
      "Ep:131, loss:0.00003, loss_test:0.07455, lr:9.04e-03, fs:0.85279 (r=0.848,p=0.857),  time:14.984, tt:1977.894\n",
      "Ep:132, loss:0.00003, loss_test:0.07454, lr:9.04e-03, fs:0.84848 (r=0.848,p=0.848),  time:14.980, tt:1992.337\n",
      "Ep:133, loss:0.00003, loss_test:0.07456, lr:9.04e-03, fs:0.86139 (r=0.879,p=0.845),  time:14.968, tt:2005.654\n",
      "Ep:134, loss:0.00003, loss_test:0.07445, lr:9.04e-03, fs:0.85714 (r=0.848,p=0.866),  time:14.968, tt:2020.654\n",
      "Ep:135, loss:0.00003, loss_test:0.07441, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.972, tt:2036.157\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00003, loss_test:0.07425, lr:9.04e-03, fs:0.85859 (r=0.859,p=0.859),  time:14.969, tt:2050.801\n",
      "Ep:137, loss:0.00003, loss_test:0.07420, lr:9.04e-03, fs:0.85859 (r=0.859,p=0.859),  time:14.971, tt:2066.016\n",
      "Ep:138, loss:0.00003, loss_test:0.07425, lr:9.04e-03, fs:0.85714 (r=0.848,p=0.866),  time:14.973, tt:2081.285\n",
      "Ep:139, loss:0.00003, loss_test:0.07438, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.984, tt:2097.692\n",
      "Ep:140, loss:0.00003, loss_test:0.07425, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:14.984, tt:2112.772\n",
      "Ep:141, loss:0.00003, loss_test:0.07401, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:14.984, tt:2127.773\n",
      "Ep:142, loss:0.00003, loss_test:0.07395, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:14.994, tt:2144.105\n",
      "Ep:143, loss:0.00003, loss_test:0.07409, lr:9.04e-03, fs:0.86294 (r=0.859,p=0.867),  time:14.991, tt:2158.726\n",
      "Ep:144, loss:0.00003, loss_test:0.07404, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.993, tt:2174.012\n",
      "##########Best model found so far##########\n",
      "Ep:145, loss:0.00003, loss_test:0.07398, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.993, tt:2189.013\n",
      "Ep:146, loss:0.00003, loss_test:0.07377, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.995, tt:2204.305\n",
      "Ep:147, loss:0.00002, loss_test:0.07365, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.996, tt:2219.369\n",
      "Ep:148, loss:0.00002, loss_test:0.07369, lr:9.04e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.990, tt:2233.543\n",
      "Ep:149, loss:0.00002, loss_test:0.07363, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.985, tt:2247.776\n",
      "Ep:150, loss:0.00002, loss_test:0.07349, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.981, tt:2262.166\n",
      "Ep:151, loss:0.00002, loss_test:0.07345, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.976, tt:2276.350\n",
      "Ep:152, loss:0.00002, loss_test:0.07349, lr:9.04e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.968, tt:2290.069\n",
      "Ep:153, loss:0.00002, loss_test:0.07325, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.961, tt:2303.944\n",
      "Ep:154, loss:0.00002, loss_test:0.07329, lr:9.04e-03, fs:0.85859 (r=0.859,p=0.859),  time:14.950, tt:2317.186\n",
      "Ep:155, loss:0.00002, loss_test:0.07322, lr:9.04e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.944, tt:2331.282\n",
      "Ep:156, loss:0.00002, loss_test:0.07334, lr:8.95e-03, fs:0.84817 (r=0.818,p=0.880),  time:14.940, tt:2345.609\n",
      "Ep:157, loss:0.00002, loss_test:0.07306, lr:8.86e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.936, tt:2359.884\n",
      "Ep:158, loss:0.00002, loss_test:0.07294, lr:8.78e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.930, tt:2373.798\n",
      "Ep:159, loss:0.00002, loss_test:0.07287, lr:8.69e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.925, tt:2388.006\n",
      "Ep:160, loss:0.00002, loss_test:0.07272, lr:8.60e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.922, tt:2402.506\n",
      "Ep:161, loss:0.00002, loss_test:0.07257, lr:8.51e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.915, tt:2416.220\n",
      "Ep:162, loss:0.00002, loss_test:0.07300, lr:8.43e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.906, tt:2429.663\n",
      "Ep:163, loss:0.00002, loss_test:0.07312, lr:8.35e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.899, tt:2443.447\n",
      "Ep:164, loss:0.00002, loss_test:0.07271, lr:8.26e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.891, tt:2457.081\n",
      "Ep:165, loss:0.00002, loss_test:0.07226, lr:8.18e-03, fs:0.87179 (r=0.859,p=0.885),  time:14.884, tt:2470.751\n",
      "Ep:166, loss:0.00002, loss_test:0.07232, lr:8.10e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.880, tt:2484.957\n",
      "Ep:167, loss:0.00002, loss_test:0.07289, lr:8.02e-03, fs:0.85417 (r=0.828,p=0.882),  time:14.876, tt:2499.185\n",
      "Ep:168, loss:0.00002, loss_test:0.07284, lr:7.94e-03, fs:0.85567 (r=0.838,p=0.874),  time:14.868, tt:2512.728\n",
      "Ep:169, loss:0.00002, loss_test:0.07268, lr:7.86e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.869, tt:2527.800\n",
      "Ep:170, loss:0.00002, loss_test:0.07228, lr:7.78e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.863, tt:2541.564\n",
      "Ep:171, loss:0.00002, loss_test:0.07223, lr:7.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:14.852, tt:2554.578\n",
      "Ep:172, loss:0.00002, loss_test:0.07199, lr:7.62e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.840, tt:2567.352\n",
      "Ep:173, loss:0.00002, loss_test:0.07214, lr:7.55e-03, fs:0.86735 (r=0.859,p=0.876),  time:14.839, tt:2581.979\n",
      "Ep:174, loss:0.00002, loss_test:0.07220, lr:7.47e-03, fs:0.85567 (r=0.838,p=0.874),  time:14.830, tt:2595.278\n",
      "Ep:175, loss:0.00002, loss_test:0.07240, lr:7.40e-03, fs:0.84656 (r=0.808,p=0.889),  time:14.826, tt:2609.406\n",
      "Ep:176, loss:0.00002, loss_test:0.07206, lr:7.32e-03, fs:0.85864 (r=0.828,p=0.891),  time:14.816, tt:2622.439\n",
      "Ep:177, loss:0.00002, loss_test:0.07182, lr:7.25e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.799, tt:2634.240\n",
      "Ep:178, loss:0.00002, loss_test:0.07209, lr:7.18e-03, fs:0.85567 (r=0.838,p=0.874),  time:14.784, tt:2646.279\n",
      "Ep:179, loss:0.00002, loss_test:0.07229, lr:7.11e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.775, tt:2659.565\n",
      "Ep:180, loss:0.00002, loss_test:0.07215, lr:7.03e-03, fs:0.84656 (r=0.808,p=0.889),  time:14.772, tt:2673.648\n",
      "Ep:181, loss:0.00002, loss_test:0.07179, lr:6.96e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.765, tt:2687.226\n",
      "Ep:182, loss:0.00002, loss_test:0.07205, lr:6.89e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.758, tt:2700.797\n",
      "Ep:183, loss:0.00002, loss_test:0.07242, lr:6.83e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.755, tt:2714.841\n",
      "Ep:184, loss:0.00002, loss_test:0.07218, lr:6.76e-03, fs:0.85864 (r=0.828,p=0.891),  time:14.741, tt:2727.009\n",
      "Ep:185, loss:0.00002, loss_test:0.07158, lr:6.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.723, tt:2738.444\n",
      "Ep:186, loss:0.00002, loss_test:0.07149, lr:6.62e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.713, tt:2751.322\n",
      "Ep:187, loss:0.00002, loss_test:0.07199, lr:6.56e-03, fs:0.84817 (r=0.818,p=0.880),  time:14.706, tt:2764.639\n",
      "Ep:188, loss:0.00002, loss_test:0.07230, lr:6.49e-03, fs:0.85263 (r=0.818,p=0.890),  time:14.696, tt:2777.539\n",
      "Ep:189, loss:0.00002, loss_test:0.07199, lr:6.43e-03, fs:0.86010 (r=0.838,p=0.883),  time:14.687, tt:2790.543\n",
      "Ep:190, loss:0.00002, loss_test:0.07156, lr:6.36e-03, fs:0.85263 (r=0.818,p=0.890),  time:14.697, tt:2807.082\n",
      "Ep:191, loss:0.00002, loss_test:0.07158, lr:6.30e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.693, tt:2821.046\n",
      "Ep:192, loss:0.00002, loss_test:0.07175, lr:6.24e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.689, tt:2835.048\n",
      "Ep:193, loss:0.00002, loss_test:0.07188, lr:6.17e-03, fs:0.86458 (r=0.838,p=0.892),  time:14.685, tt:2848.967\n",
      "Ep:194, loss:0.00002, loss_test:0.07179, lr:6.11e-03, fs:0.85263 (r=0.818,p=0.890),  time:14.678, tt:2862.243\n",
      "Ep:195, loss:0.00002, loss_test:0.07164, lr:6.05e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.674, tt:2876.198\n",
      "Ep:196, loss:0.00002, loss_test:0.07144, lr:5.99e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.667, tt:2889.406\n",
      "Ep:197, loss:0.00002, loss_test:0.07140, lr:5.93e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.652, tt:2901.109\n",
      "Ep:198, loss:0.00002, loss_test:0.07140, lr:5.87e-03, fs:0.86316 (r=0.828,p=0.901),  time:14.646, tt:2914.579\n",
      "Ep:199, loss:0.00002, loss_test:0.07140, lr:5.81e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.641, tt:2928.208\n",
      "Ep:200, loss:0.00002, loss_test:0.07140, lr:5.75e-03, fs:0.85106 (r=0.808,p=0.899),  time:14.634, tt:2941.338\n",
      "Ep:201, loss:0.00002, loss_test:0.07165, lr:5.70e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.628, tt:2954.834\n",
      "Ep:202, loss:0.00002, loss_test:0.07158, lr:5.64e-03, fs:0.85263 (r=0.818,p=0.890),  time:14.623, tt:2968.468\n",
      "Ep:203, loss:0.00002, loss_test:0.07130, lr:5.58e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.609, tt:2980.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00002, loss_test:0.07104, lr:5.53e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.591, tt:2991.162\n",
      "Ep:205, loss:0.00002, loss_test:0.07106, lr:5.47e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.564, tt:3000.230\n",
      "Ep:206, loss:0.00002, loss_test:0.07124, lr:5.42e-03, fs:0.85714 (r=0.818,p=0.900),  time:14.539, tt:3009.469\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=1,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00029, loss_test:0.14507, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.187, tt:24.187\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14465, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.059, tt:54.117\n",
      "Ep:2, loss:0.00028, loss_test:0.14399, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:28.964, tt:86.893\n",
      "Ep:3, loss:0.00028, loss_test:0.14302, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.755, tt:119.020\n",
      "Ep:4, loss:0.00028, loss_test:0.14165, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.406, tt:152.031\n",
      "Ep:5, loss:0.00028, loss_test:0.13976, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.645, tt:183.871\n",
      "Ep:6, loss:0.00027, loss_test:0.13713, lr:1.00e-02, fs:0.66250 (r=0.981,p=0.500),  time:31.079, tt:217.554\n",
      "Ep:7, loss:0.00027, loss_test:0.13346, lr:1.00e-02, fs:0.65385 (r=0.944,p=0.500),  time:31.309, tt:250.475\n",
      "Ep:8, loss:0.00026, loss_test:0.12829, lr:1.00e-02, fs:0.63576 (r=0.889,p=0.495),  time:31.430, tt:282.870\n",
      "Ep:9, loss:0.00025, loss_test:0.12156, lr:1.00e-02, fs:0.65185 (r=0.815,p=0.543),  time:31.639, tt:316.393\n",
      "Ep:10, loss:0.00024, loss_test:0.11568, lr:1.00e-02, fs:0.68333 (r=0.759,p=0.621),  time:31.841, tt:350.248\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.11459, lr:1.00e-02, fs:0.70270 (r=0.722,p=0.684),  time:31.986, tt:383.830\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.11119, lr:1.00e-02, fs:0.72897 (r=0.722,p=0.736),  time:32.004, tt:416.052\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10752, lr:1.00e-02, fs:0.72566 (r=0.759,p=0.695),  time:32.067, tt:448.940\n",
      "Ep:14, loss:0.00021, loss_test:0.10429, lr:1.00e-02, fs:0.73874 (r=0.759,p=0.719),  time:32.119, tt:481.789\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00020, loss_test:0.10057, lr:1.00e-02, fs:0.72897 (r=0.722,p=0.736),  time:32.107, tt:513.718\n",
      "Ep:16, loss:0.00020, loss_test:0.09820, lr:1.00e-02, fs:0.72897 (r=0.722,p=0.736),  time:32.133, tt:546.262\n",
      "Ep:17, loss:0.00019, loss_test:0.09488, lr:1.00e-02, fs:0.73394 (r=0.741,p=0.727),  time:32.157, tt:578.817\n",
      "Ep:18, loss:0.00019, loss_test:0.09221, lr:1.00e-02, fs:0.74545 (r=0.759,p=0.732),  time:32.193, tt:611.664\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00018, loss_test:0.09078, lr:1.00e-02, fs:0.76636 (r=0.759,p=0.774),  time:32.230, tt:644.606\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.08815, lr:1.00e-02, fs:0.75229 (r=0.759,p=0.745),  time:32.280, tt:677.870\n",
      "Ep:21, loss:0.00017, loss_test:0.08644, lr:1.00e-02, fs:0.75229 (r=0.759,p=0.745),  time:32.298, tt:710.549\n",
      "Ep:22, loss:0.00017, loss_test:0.08527, lr:1.00e-02, fs:0.77064 (r=0.778,p=0.764),  time:32.282, tt:742.491\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.08432, lr:1.00e-02, fs:0.78571 (r=0.815,p=0.759),  time:32.331, tt:775.941\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.08290, lr:1.00e-02, fs:0.79630 (r=0.796,p=0.796),  time:32.292, tt:807.294\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.08121, lr:1.00e-02, fs:0.80734 (r=0.815,p=0.800),  time:32.282, tt:839.343\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.07902, lr:1.00e-02, fs:0.80734 (r=0.815,p=0.800),  time:32.266, tt:871.173\n",
      "Ep:27, loss:0.00015, loss_test:0.07808, lr:1.00e-02, fs:0.79630 (r=0.796,p=0.796),  time:32.252, tt:903.064\n",
      "Ep:28, loss:0.00014, loss_test:0.07673, lr:1.00e-02, fs:0.80734 (r=0.815,p=0.800),  time:32.275, tt:935.987\n",
      "Ep:29, loss:0.00014, loss_test:0.07505, lr:1.00e-02, fs:0.83636 (r=0.852,p=0.821),  time:32.308, tt:969.234\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.07380, lr:1.00e-02, fs:0.82883 (r=0.852,p=0.807),  time:32.256, tt:999.931\n",
      "Ep:31, loss:0.00013, loss_test:0.07268, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:32.268, tt:1032.571\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.07076, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:32.268, tt:1064.838\n",
      "Ep:33, loss:0.00013, loss_test:0.06930, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:32.266, tt:1097.054\n",
      "Ep:34, loss:0.00012, loss_test:0.06835, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:32.219, tt:1127.660\n",
      "Ep:35, loss:0.00012, loss_test:0.06685, lr:1.00e-02, fs:0.84404 (r=0.852,p=0.836),  time:32.239, tt:1160.594\n",
      "Ep:36, loss:0.00012, loss_test:0.06602, lr:1.00e-02, fs:0.85455 (r=0.870,p=0.839),  time:32.274, tt:1194.134\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00012, loss_test:0.06465, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:32.295, tt:1227.207\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.06340, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:32.253, tt:1257.868\n",
      "Ep:39, loss:0.00011, loss_test:0.06209, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.304, tt:1292.147\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.06135, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.327, tt:1325.396\n",
      "Ep:41, loss:0.00010, loss_test:0.06010, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.325, tt:1357.660\n",
      "Ep:42, loss:0.00010, loss_test:0.05886, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.288, tt:1388.371\n",
      "Ep:43, loss:0.00010, loss_test:0.05844, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:32.227, tt:1417.988\n",
      "Ep:44, loss:0.00010, loss_test:0.05680, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:32.206, tt:1449.279\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.05662, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:32.215, tt:1481.891\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00009, loss_test:0.05580, lr:1.00e-02, fs:0.88696 (r=0.944,p=0.836),  time:32.191, tt:1512.968\n",
      "Ep:47, loss:0.00009, loss_test:0.05396, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.192, tt:1545.200\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.05546, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:32.175, tt:1576.564\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.05238, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.177, tt:1608.850\n",
      "Ep:50, loss:0.00009, loss_test:0.05244, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:32.177, tt:1641.030\n",
      "Ep:51, loss:0.00009, loss_test:0.05138, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:32.185, tt:1673.618\n",
      "Ep:52, loss:0.00008, loss_test:0.04964, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.178, tt:1705.448\n",
      "Ep:53, loss:0.00008, loss_test:0.05050, lr:1.00e-02, fs:0.90265 (r=0.944,p=0.864),  time:32.156, tt:1736.407\n",
      "Ep:54, loss:0.00008, loss_test:0.04823, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.166, tt:1769.111\n",
      "Ep:55, loss:0.00008, loss_test:0.04792, lr:1.00e-02, fs:0.89474 (r=0.944,p=0.850),  time:32.170, tt:1801.506\n",
      "Ep:56, loss:0.00008, loss_test:0.04825, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.188, tt:1834.729\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00008, loss_test:0.04578, lr:1.00e-02, fs:0.90435 (r=0.963,p=0.852),  time:32.209, tt:1868.104\n",
      "Ep:58, loss:0.00007, loss_test:0.04587, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:32.195, tt:1899.508\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00007, loss_test:0.04494, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:32.194, tt:1931.656\n",
      "Ep:60, loss:0.00007, loss_test:0.04385, lr:1.00e-02, fs:0.91071 (r=0.944,p=0.879),  time:32.206, tt:1964.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00007, loss_test:0.04328, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.190, tt:1995.811\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00007, loss_test:0.04242, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.199, tt:2028.537\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00007, loss_test:0.04139, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:32.206, tt:2061.209\n",
      "Ep:64, loss:0.00007, loss_test:0.04135, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.209, tt:2093.608\n",
      "Ep:65, loss:0.00006, loss_test:0.03975, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.210, tt:2125.843\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.03975, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.215, tt:2158.405\n",
      "Ep:67, loss:0.00006, loss_test:0.03866, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.214, tt:2190.564\n",
      "Ep:68, loss:0.00006, loss_test:0.03815, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.209, tt:2222.402\n",
      "Ep:69, loss:0.00006, loss_test:0.03750, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.217, tt:2255.220\n",
      "Ep:70, loss:0.00006, loss_test:0.03673, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.203, tt:2286.379\n",
      "Ep:71, loss:0.00006, loss_test:0.03575, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.184, tt:2317.254\n",
      "Ep:72, loss:0.00006, loss_test:0.03559, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.166, tt:2348.117\n",
      "Ep:73, loss:0.00005, loss_test:0.03487, lr:1.00e-02, fs:0.92857 (r=0.963,p=0.897),  time:32.176, tt:2380.999\n",
      "Ep:74, loss:0.00005, loss_test:0.03390, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.153, tt:2411.499\n",
      "Ep:75, loss:0.00005, loss_test:0.03411, lr:1.00e-02, fs:0.93694 (r=0.963,p=0.912),  time:32.209, tt:2447.919\n",
      "Ep:76, loss:0.00005, loss_test:0.03285, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:32.230, tt:2481.723\n",
      "Ep:77, loss:0.00005, loss_test:0.03280, lr:9.90e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.243, tt:2514.985\n",
      "Ep:78, loss:0.00005, loss_test:0.03192, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.244, tt:2547.271\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00005, loss_test:0.03192, lr:9.80e-03, fs:0.92857 (r=0.963,p=0.897),  time:32.211, tt:2576.848\n",
      "Ep:80, loss:0.00005, loss_test:0.03096, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.228, tt:2610.438\n",
      "Ep:81, loss:0.00005, loss_test:0.03115, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.202, tt:2640.568\n",
      "Ep:82, loss:0.00005, loss_test:0.02999, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.205, tt:2673.051\n",
      "Ep:83, loss:0.00004, loss_test:0.02957, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.207, tt:2705.370\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00004, loss_test:0.02931, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.179, tt:2735.238\n",
      "Ep:85, loss:0.00004, loss_test:0.02892, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.180, tt:2767.455\n",
      "Ep:86, loss:0.00004, loss_test:0.02846, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.192, tt:2800.736\n",
      "Ep:87, loss:0.00004, loss_test:0.02819, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.228, tt:2836.034\n",
      "Ep:88, loss:0.00004, loss_test:0.02817, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.228, tt:2868.292\n",
      "Ep:89, loss:0.00004, loss_test:0.02737, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.253, tt:2902.784\n",
      "Ep:90, loss:0.00004, loss_test:0.02793, lr:9.80e-03, fs:0.94545 (r=0.963,p=0.929),  time:32.238, tt:2933.685\n",
      "Ep:91, loss:0.00004, loss_test:0.02694, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.240, tt:2966.095\n",
      "Ep:92, loss:0.00004, loss_test:0.02661, lr:9.80e-03, fs:0.94643 (r=0.981,p=0.914),  time:32.259, tt:3000.062\n",
      "Ep:93, loss:0.00004, loss_test:0.02576, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.273, tt:3033.666\n",
      "Ep:94, loss:0.00004, loss_test:0.02582, lr:9.80e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.270, tt:3065.635\n",
      "Ep:95, loss:0.00004, loss_test:0.02516, lr:9.70e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.263, tt:3097.287\n",
      "Ep:96, loss:0.00003, loss_test:0.02501, lr:9.61e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.270, tt:3130.221\n",
      "Ep:97, loss:0.00003, loss_test:0.02435, lr:9.51e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.281, tt:3163.528\n",
      "Ep:98, loss:0.00003, loss_test:0.02418, lr:9.41e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.270, tt:3194.732\n",
      "Ep:99, loss:0.00003, loss_test:0.02366, lr:9.32e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.287, tt:3228.662\n",
      "Ep:100, loss:0.00003, loss_test:0.02375, lr:9.23e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.298, tt:3262.106\n",
      "Ep:101, loss:0.00003, loss_test:0.02326, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.311, tt:3295.688\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00003, loss_test:0.02324, lr:9.14e-03, fs:0.95495 (r=0.981,p=0.930),  time:32.320, tt:3328.936\n",
      "Ep:103, loss:0.00003, loss_test:0.02250, lr:9.14e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.320, tt:3361.282\n",
      "Ep:104, loss:0.00003, loss_test:0.02259, lr:9.14e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.315, tt:3393.070\n",
      "Ep:105, loss:0.00003, loss_test:0.02214, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.321, tt:3426.061\n",
      "Ep:106, loss:0.00003, loss_test:0.02209, lr:9.14e-03, fs:0.96364 (r=0.981,p=0.946),  time:32.323, tt:3458.589\n",
      "Ep:107, loss:0.00003, loss_test:0.02151, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.318, tt:3490.397\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00003, loss_test:0.02151, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.319, tt:3522.793\n",
      "Ep:109, loss:0.00003, loss_test:0.02101, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.294, tt:3552.365\n",
      "Ep:110, loss:0.00003, loss_test:0.02075, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.289, tt:3584.072\n",
      "Ep:111, loss:0.00003, loss_test:0.02066, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.276, tt:3614.912\n",
      "Ep:112, loss:0.00003, loss_test:0.02036, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.281, tt:3647.724\n",
      "Ep:113, loss:0.00003, loss_test:0.02040, lr:9.14e-03, fs:0.97248 (r=0.981,p=0.964),  time:32.277, tt:3679.582\n",
      "Ep:114, loss:0.00003, loss_test:0.01965, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.279, tt:3712.143\n",
      "Ep:115, loss:0.00003, loss_test:0.01932, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.268, tt:3743.097\n",
      "Ep:116, loss:0.00002, loss_test:0.01945, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.247, tt:3772.948\n",
      "Ep:117, loss:0.00002, loss_test:0.01875, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.238, tt:3804.103\n",
      "Ep:118, loss:0.00002, loss_test:0.01859, lr:9.14e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.227, tt:3835.064\n",
      "Ep:119, loss:0.00002, loss_test:0.01839, lr:9.04e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.228, tt:3867.303\n",
      "Ep:120, loss:0.00002, loss_test:0.01830, lr:8.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.215, tt:3898.046\n",
      "Ep:121, loss:0.00002, loss_test:0.01806, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.252, tt:3934.725\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00002, loss_test:0.01749, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.251, tt:3966.909\n",
      "Ep:123, loss:0.00002, loss_test:0.01821, lr:8.86e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.258, tt:3999.955\n",
      "Ep:124, loss:0.00002, loss_test:0.01711, lr:8.86e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.253, tt:4031.574\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.01724, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.260, tt:4064.699\n",
      "Ep:126, loss:0.00002, loss_test:0.01709, lr:8.86e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.273, tt:4098.653\n",
      "Ep:127, loss:0.00002, loss_test:0.01638, lr:8.86e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.276, tt:4131.309\n",
      "Ep:128, loss:0.00002, loss_test:0.01646, lr:8.86e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.268, tt:4162.590\n",
      "Ep:129, loss:0.00002, loss_test:0.01630, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.282, tt:4196.717\n",
      "Ep:130, loss:0.00002, loss_test:0.01610, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.277, tt:4228.300\n",
      "Ep:131, loss:0.00002, loss_test:0.01609, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.276, tt:4260.407\n",
      "Ep:132, loss:0.00002, loss_test:0.01583, lr:8.86e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.265, tt:4291.226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00002, loss_test:0.01591, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.254, tt:4322.031\n",
      "Ep:134, loss:0.00002, loss_test:0.01566, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.240, tt:4352.449\n",
      "Ep:135, loss:0.00002, loss_test:0.01555, lr:8.86e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.245, tt:4385.385\n",
      "Ep:136, loss:0.00002, loss_test:0.01491, lr:8.78e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.235, tt:4416.263\n",
      "Ep:137, loss:0.00002, loss_test:0.01472, lr:8.69e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.228, tt:4447.406\n",
      "Ep:138, loss:0.00002, loss_test:0.01560, lr:8.60e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.225, tt:4479.210\n",
      "Ep:139, loss:0.00002, loss_test:0.01442, lr:8.51e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.224, tt:4511.404\n",
      "Ep:140, loss:0.00002, loss_test:0.01477, lr:8.43e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.221, tt:4543.204\n",
      "Ep:141, loss:0.00002, loss_test:0.01490, lr:8.35e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.218, tt:4574.967\n",
      "Ep:142, loss:0.00002, loss_test:0.01426, lr:8.26e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.229, tt:4608.686\n",
      "Ep:143, loss:0.00002, loss_test:0.01485, lr:8.18e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.225, tt:4640.425\n",
      "Ep:144, loss:0.00002, loss_test:0.01375, lr:8.10e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.220, tt:4671.865\n",
      "Ep:145, loss:0.00002, loss_test:0.01415, lr:8.02e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.223, tt:4704.509\n",
      "Ep:146, loss:0.00002, loss_test:0.01415, lr:7.94e-03, fs:0.99083 (r=1.000,p=0.982),  time:32.219, tt:4736.144\n",
      "Ep:147, loss:0.00002, loss_test:0.01342, lr:7.86e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.219, tt:4768.403\n",
      "Ep:148, loss:0.00001, loss_test:0.01397, lr:7.78e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.211, tt:4799.447\n",
      "Ep:149, loss:0.00001, loss_test:0.01323, lr:7.70e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.201, tt:4830.162\n",
      "Ep:150, loss:0.00001, loss_test:0.01338, lr:7.62e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.197, tt:4861.798\n",
      "Ep:151, loss:0.00001, loss_test:0.01362, lr:7.55e-03, fs:1.00000 (r=1.000,p=1.000),  time:32.202, tt:4894.673\n",
      "Ep:152, loss:0.00001, loss_test:0.01312, lr:7.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.202, tt:4926.868\n",
      "Ep:153, loss:0.00001, loss_test:0.01359, lr:7.40e-03, fs:0.98148 (r=0.981,p=0.981),  time:32.199, tt:4958.718\n",
      "Ep:154, loss:0.00001, loss_test:0.01319, lr:7.32e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.185, tt:4988.645\n",
      "Ep:155, loss:0.00001, loss_test:0.01309, lr:7.25e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.188, tt:5021.384\n",
      "Ep:156, loss:0.00001, loss_test:0.01289, lr:7.18e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.177, tt:5051.839\n",
      "Ep:157, loss:0.00001, loss_test:0.01280, lr:7.11e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.171, tt:5082.962\n",
      "Ep:158, loss:0.00001, loss_test:0.01273, lr:7.03e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.158, tt:5113.201\n",
      "Ep:159, loss:0.00001, loss_test:0.01252, lr:6.96e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.155, tt:5144.856\n",
      "Ep:160, loss:0.00001, loss_test:0.01287, lr:6.89e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.152, tt:5176.457\n",
      "Ep:161, loss:0.00001, loss_test:0.01241, lr:6.83e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.158, tt:5209.640\n",
      "Ep:162, loss:0.00001, loss_test:0.01274, lr:6.76e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.157, tt:5241.527\n",
      "Ep:163, loss:0.00001, loss_test:0.01224, lr:6.69e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.158, tt:5273.836\n",
      "Ep:164, loss:0.00001, loss_test:0.01244, lr:6.62e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.157, tt:5305.862\n",
      "Ep:165, loss:0.00001, loss_test:0.01210, lr:6.56e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.153, tt:5337.410\n",
      "Ep:166, loss:0.00001, loss_test:0.01206, lr:6.49e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.159, tt:5370.598\n",
      "Ep:167, loss:0.00001, loss_test:0.01221, lr:6.43e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.157, tt:5402.293\n",
      "Ep:168, loss:0.00001, loss_test:0.01174, lr:6.36e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.159, tt:5434.944\n",
      "Ep:169, loss:0.00001, loss_test:0.01187, lr:6.30e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.160, tt:5467.249\n",
      "Ep:170, loss:0.00001, loss_test:0.01184, lr:6.24e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.162, tt:5499.765\n",
      "Ep:171, loss:0.00001, loss_test:0.01183, lr:6.17e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.166, tt:5532.472\n",
      "Ep:172, loss:0.00001, loss_test:0.01176, lr:6.11e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.162, tt:5563.995\n",
      "Ep:173, loss:0.00001, loss_test:0.01182, lr:6.05e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.168, tt:5597.201\n",
      "Ep:174, loss:0.00001, loss_test:0.01153, lr:5.99e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.167, tt:5629.265\n",
      "Ep:175, loss:0.00001, loss_test:0.01166, lr:5.93e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.174, tt:5662.636\n",
      "Ep:176, loss:0.00001, loss_test:0.01148, lr:5.87e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.175, tt:5695.055\n",
      "Ep:177, loss:0.00001, loss_test:0.01151, lr:5.81e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.174, tt:5727.046\n",
      "Ep:178, loss:0.00001, loss_test:0.01127, lr:5.75e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.172, tt:5758.737\n",
      "Ep:179, loss:0.00001, loss_test:0.01133, lr:5.70e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.175, tt:5791.461\n",
      "Ep:180, loss:0.00001, loss_test:0.01129, lr:5.64e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.184, tt:5825.255\n",
      "Ep:181, loss:0.00001, loss_test:0.01134, lr:5.58e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.190, tt:5858.623\n",
      "Ep:182, loss:0.00001, loss_test:0.01111, lr:5.53e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.202, tt:5892.885\n",
      "Ep:183, loss:0.00001, loss_test:0.01122, lr:5.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.194, tt:5923.672\n",
      "Ep:184, loss:0.00001, loss_test:0.01087, lr:5.42e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.213, tt:5959.464\n",
      "Ep:185, loss:0.00001, loss_test:0.01117, lr:5.36e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.213, tt:5991.644\n",
      "Ep:186, loss:0.00001, loss_test:0.01106, lr:5.31e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.219, tt:6024.906\n",
      "Ep:187, loss:0.00001, loss_test:0.01105, lr:5.26e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.219, tt:6057.265\n",
      "Ep:188, loss:0.00001, loss_test:0.01087, lr:5.20e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.217, tt:6089.031\n",
      "Ep:189, loss:0.00001, loss_test:0.01081, lr:5.15e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.225, tt:6122.838\n",
      "Ep:190, loss:0.00001, loss_test:0.01072, lr:5.10e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.231, tt:6156.069\n",
      "Ep:191, loss:0.00001, loss_test:0.01081, lr:5.05e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.237, tt:6189.483\n",
      "Ep:192, loss:0.00001, loss_test:0.01067, lr:5.00e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.241, tt:6222.470\n",
      "Ep:193, loss:0.00001, loss_test:0.01062, lr:4.95e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.247, tt:6255.938\n",
      "Ep:194, loss:0.00001, loss_test:0.01062, lr:4.90e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.251, tt:6289.037\n",
      "Ep:195, loss:0.00001, loss_test:0.01056, lr:4.85e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.256, tt:6322.187\n",
      "Ep:196, loss:0.00001, loss_test:0.01054, lr:4.80e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.257, tt:6354.714\n",
      "Ep:197, loss:0.00001, loss_test:0.01046, lr:4.75e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.259, tt:6387.361\n",
      "Ep:198, loss:0.00001, loss_test:0.01059, lr:4.71e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.266, tt:6420.875\n",
      "Ep:199, loss:0.00001, loss_test:0.01073, lr:4.66e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.266, tt:6453.212\n",
      "Ep:200, loss:0.00001, loss_test:0.01045, lr:4.61e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.269, tt:6485.993\n",
      "Ep:201, loss:0.00001, loss_test:0.01031, lr:4.57e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.272, tt:6518.924\n",
      "Ep:202, loss:0.00001, loss_test:0.01037, lr:4.52e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.274, tt:6551.522\n",
      "Ep:203, loss:0.00001, loss_test:0.01033, lr:4.48e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.282, tt:6585.549\n",
      "Ep:204, loss:0.00001, loss_test:0.01021, lr:4.43e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.288, tt:6619.068\n",
      "Ep:205, loss:0.00001, loss_test:0.01019, lr:4.39e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.286, tt:6650.999\n",
      "Ep:206, loss:0.00001, loss_test:0.01036, lr:4.34e-03, fs:0.99065 (r=0.981,p=1.000),  time:32.259, tt:6677.534\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14302, lr:1.00e-02, fs:0.64103 (r=0.926,p=0.490),  time:29.404, tt:29.404\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14053, lr:1.00e-02, fs:0.64935 (r=0.926,p=0.500),  time:32.821, tt:65.642\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.13699, lr:1.00e-02, fs:0.63087 (r=0.870,p=0.495),  time:34.145, tt:102.435\n",
      "Ep:3, loss:0.00026, loss_test:0.13393, lr:1.00e-02, fs:0.66197 (r=0.870,p=0.534),  time:34.806, tt:139.222\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12955, lr:1.00e-02, fs:0.68750 (r=0.815,p=0.595),  time:34.838, tt:174.188\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.12587, lr:1.00e-02, fs:0.70492 (r=0.796,p=0.632),  time:35.323, tt:211.936\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.12199, lr:1.00e-02, fs:0.73770 (r=0.833,p=0.662),  time:35.394, tt:247.756\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11726, lr:1.00e-02, fs:0.72581 (r=0.833,p=0.643),  time:35.585, tt:284.677\n",
      "Ep:8, loss:0.00022, loss_test:0.11287, lr:1.00e-02, fs:0.72881 (r=0.796,p=0.672),  time:35.914, tt:323.224\n",
      "Ep:9, loss:0.00022, loss_test:0.10938, lr:1.00e-02, fs:0.70690 (r=0.759,p=0.661),  time:36.018, tt:360.179\n",
      "Ep:10, loss:0.00021, loss_test:0.10574, lr:1.00e-02, fs:0.73043 (r=0.778,p=0.689),  time:36.155, tt:397.706\n",
      "Ep:11, loss:0.00020, loss_test:0.10298, lr:1.00e-02, fs:0.73043 (r=0.778,p=0.689),  time:36.204, tt:434.450\n",
      "Ep:12, loss:0.00020, loss_test:0.10023, lr:1.00e-02, fs:0.74545 (r=0.759,p=0.732),  time:36.222, tt:470.887\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09789, lr:1.00e-02, fs:0.73874 (r=0.759,p=0.719),  time:36.276, tt:507.863\n",
      "Ep:14, loss:0.00019, loss_test:0.09537, lr:1.00e-02, fs:0.74545 (r=0.759,p=0.732),  time:36.414, tt:546.205\n",
      "Ep:15, loss:0.00018, loss_test:0.09250, lr:1.00e-02, fs:0.75000 (r=0.778,p=0.724),  time:36.586, tt:585.383\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08927, lr:1.00e-02, fs:0.77064 (r=0.778,p=0.764),  time:36.619, tt:622.516\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08637, lr:1.00e-02, fs:0.77064 (r=0.778,p=0.764),  time:36.564, tt:658.143\n",
      "Ep:18, loss:0.00016, loss_test:0.08503, lr:1.00e-02, fs:0.78182 (r=0.796,p=0.768),  time:36.654, tt:696.423\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08274, lr:1.00e-02, fs:0.79279 (r=0.815,p=0.772),  time:36.727, tt:734.543\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.07992, lr:1.00e-02, fs:0.80734 (r=0.815,p=0.800),  time:36.755, tt:771.855\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08009, lr:1.00e-02, fs:0.80734 (r=0.815,p=0.800),  time:36.879, tt:811.348\n",
      "Ep:22, loss:0.00014, loss_test:0.07643, lr:1.00e-02, fs:0.82883 (r=0.852,p=0.807),  time:36.870, tt:848.004\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07652, lr:1.00e-02, fs:0.80374 (r=0.796,p=0.811),  time:36.815, tt:883.549\n",
      "Ep:24, loss:0.00014, loss_test:0.07350, lr:1.00e-02, fs:0.83636 (r=0.852,p=0.821),  time:36.797, tt:919.920\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07221, lr:1.00e-02, fs:0.83636 (r=0.852,p=0.821),  time:36.789, tt:956.511\n",
      "Ep:26, loss:0.00013, loss_test:0.06990, lr:1.00e-02, fs:0.85185 (r=0.852,p=0.852),  time:36.913, tt:996.647\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.06937, lr:1.00e-02, fs:0.84685 (r=0.870,p=0.825),  time:36.883, tt:1032.722\n",
      "Ep:28, loss:0.00012, loss_test:0.06718, lr:1.00e-02, fs:0.86486 (r=0.889,p=0.842),  time:36.909, tt:1070.353\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.06628, lr:1.00e-02, fs:0.85455 (r=0.870,p=0.839),  time:36.920, tt:1107.587\n",
      "Ep:30, loss:0.00011, loss_test:0.06348, lr:1.00e-02, fs:0.86726 (r=0.907,p=0.831),  time:36.911, tt:1144.246\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.06448, lr:1.00e-02, fs:0.87273 (r=0.889,p=0.857),  time:36.891, tt:1180.522\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00011, loss_test:0.06056, lr:1.00e-02, fs:0.87719 (r=0.926,p=0.833),  time:36.894, tt:1217.493\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.06134, lr:1.00e-02, fs:0.88288 (r=0.907,p=0.860),  time:36.908, tt:1254.864\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.05751, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:36.894, tt:1291.303\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.05908, lr:1.00e-02, fs:0.86239 (r=0.870,p=0.855),  time:36.859, tt:1326.935\n",
      "Ep:36, loss:0.00009, loss_test:0.05493, lr:1.00e-02, fs:0.89655 (r=0.963,p=0.839),  time:36.879, tt:1364.510\n",
      "Ep:37, loss:0.00009, loss_test:0.05548, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.867, tt:1400.932\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.05295, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.826, tt:1436.230\n",
      "Ep:39, loss:0.00008, loss_test:0.05111, lr:1.00e-02, fs:0.91228 (r=0.963,p=0.867),  time:36.820, tt:1472.819\n",
      "Ep:40, loss:0.00008, loss_test:0.05014, lr:1.00e-02, fs:0.92174 (r=0.981,p=0.869),  time:36.801, tt:1508.821\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.04866, lr:1.00e-02, fs:0.92174 (r=0.981,p=0.869),  time:36.800, tt:1545.611\n",
      "Ep:42, loss:0.00007, loss_test:0.04697, lr:1.00e-02, fs:0.92174 (r=0.981,p=0.869),  time:36.804, tt:1582.574\n",
      "Ep:43, loss:0.00007, loss_test:0.04549, lr:1.00e-02, fs:0.92174 (r=0.981,p=0.869),  time:36.770, tt:1617.870\n",
      "Ep:44, loss:0.00007, loss_test:0.04589, lr:1.00e-02, fs:0.91379 (r=0.981,p=0.855),  time:36.715, tt:1652.157\n",
      "Ep:45, loss:0.00007, loss_test:0.04417, lr:1.00e-02, fs:0.92174 (r=0.981,p=0.869),  time:36.701, tt:1688.262\n",
      "Ep:46, loss:0.00007, loss_test:0.04240, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.688, tt:1724.327\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.04281, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:36.707, tt:1761.933\n",
      "Ep:48, loss:0.00006, loss_test:0.04013, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.682, tt:1797.400\n",
      "Ep:49, loss:0.00006, loss_test:0.04078, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:36.684, tt:1834.187\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.03930, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:36.694, tt:1871.379\n",
      "Ep:51, loss:0.00006, loss_test:0.03732, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:36.685, tt:1907.614\n",
      "Ep:52, loss:0.00006, loss_test:0.03629, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:36.671, tt:1943.561\n",
      "Ep:53, loss:0.00005, loss_test:0.03668, lr:1.00e-02, fs:0.94643 (r=0.981,p=0.914),  time:36.681, tt:1980.770\n",
      "Ep:54, loss:0.00005, loss_test:0.03422, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:36.684, tt:2017.610\n",
      "Ep:55, loss:0.00005, loss_test:0.03378, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:36.657, tt:2052.766\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.03454, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:36.650, tt:2089.025\n",
      "Ep:57, loss:0.00005, loss_test:0.03309, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:36.664, tt:2126.524\n",
      "Ep:59, loss:0.00005, loss_test:0.03142, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:36.658, tt:2199.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00005, loss_test:0.03600, lr:1.00e-02, fs:0.92982 (r=0.981,p=0.883),  time:36.646, tt:2235.431\n",
      "Ep:61, loss:0.00005, loss_test:0.03402, lr:1.00e-02, fs:0.95495 (r=0.981,p=0.930),  time:36.649, tt:2272.268\n",
      "Ep:62, loss:0.00005, loss_test:0.03502, lr:1.00e-02, fs:0.93805 (r=0.981,p=0.898),  time:36.669, tt:2310.172\n",
      "Ep:63, loss:0.00005, loss_test:0.03042, lr:1.00e-02, fs:0.95413 (r=0.963,p=0.945),  time:36.662, tt:2346.363\n",
      "Ep:64, loss:0.00005, loss_test:0.03210, lr:1.00e-02, fs:0.96364 (r=0.981,p=0.946),  time:36.660, tt:2382.922\n",
      "Ep:65, loss:0.00005, loss_test:0.02820, lr:1.00e-02, fs:0.94545 (r=0.963,p=0.929),  time:36.689, tt:2421.488\n",
      "Ep:66, loss:0.00004, loss_test:0.02796, lr:1.00e-02, fs:0.95413 (r=0.963,p=0.945),  time:36.680, tt:2457.580\n",
      "Ep:67, loss:0.00004, loss_test:0.02981, lr:9.90e-03, fs:0.94643 (r=0.981,p=0.914),  time:36.647, tt:2491.983\n",
      "Ep:68, loss:0.00004, loss_test:0.02647, lr:9.80e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.656, tt:2529.290\n",
      "Ep:69, loss:0.00004, loss_test:0.02837, lr:9.70e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.646, tt:2565.226\n",
      "Ep:70, loss:0.00004, loss_test:0.02533, lr:9.61e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.649, tt:2602.091\n",
      "Ep:71, loss:0.00004, loss_test:0.02882, lr:9.51e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.653, tt:2638.982\n",
      "Ep:72, loss:0.00004, loss_test:0.02582, lr:9.41e-03, fs:0.94545 (r=0.963,p=0.929),  time:36.641, tt:2674.817\n",
      "Ep:73, loss:0.00004, loss_test:0.02745, lr:9.32e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.647, tt:2711.861\n",
      "Ep:74, loss:0.00003, loss_test:0.02367, lr:9.23e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.627, tt:2747.039\n",
      "Ep:75, loss:0.00003, loss_test:0.02653, lr:9.14e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.634, tt:2784.163\n",
      "Ep:76, loss:0.00003, loss_test:0.02394, lr:9.04e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.605, tt:2818.579\n",
      "Ep:77, loss:0.00003, loss_test:0.02450, lr:8.95e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.609, tt:2855.519\n",
      "Ep:78, loss:0.00003, loss_test:0.02219, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.607, tt:2891.978\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.02264, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.603, tt:2928.221\n",
      "Ep:80, loss:0.00003, loss_test:0.02151, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.601, tt:2964.684\n",
      "Ep:81, loss:0.00003, loss_test:0.02192, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.608, tt:3001.819\n",
      "Ep:82, loss:0.00003, loss_test:0.02121, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.613, tt:3038.883\n",
      "Ep:83, loss:0.00003, loss_test:0.02089, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.631, tt:3077.011\n",
      "Ep:84, loss:0.00003, loss_test:0.01997, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.625, tt:3113.106\n",
      "Ep:85, loss:0.00002, loss_test:0.02137, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.608, tt:3148.326\n",
      "Ep:86, loss:0.00002, loss_test:0.02016, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.588, tt:3183.144\n",
      "Ep:87, loss:0.00002, loss_test:0.02040, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.553, tt:3216.652\n",
      "Ep:88, loss:0.00002, loss_test:0.01951, lr:8.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.538, tt:3251.847\n",
      "Ep:89, loss:0.00002, loss_test:0.02034, lr:8.86e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.534, tt:3288.086\n",
      "Ep:90, loss:0.00002, loss_test:0.01941, lr:8.78e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.485, tt:3320.106\n",
      "Ep:91, loss:0.00002, loss_test:0.01932, lr:8.69e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.487, tt:3356.801\n",
      "Ep:92, loss:0.00002, loss_test:0.01936, lr:8.60e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.473, tt:3392.032\n",
      "Ep:93, loss:0.00002, loss_test:0.01922, lr:8.51e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.482, tt:3429.313\n",
      "Ep:94, loss:0.00002, loss_test:0.01851, lr:8.43e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.485, tt:3466.081\n",
      "Ep:95, loss:0.00002, loss_test:0.01837, lr:8.35e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.479, tt:3502.001\n",
      "Ep:96, loss:0.00002, loss_test:0.01929, lr:8.26e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.456, tt:3536.228\n",
      "Ep:97, loss:0.00002, loss_test:0.01818, lr:8.18e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.442, tt:3571.276\n",
      "Ep:98, loss:0.00002, loss_test:0.01859, lr:8.10e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.434, tt:3606.971\n",
      "Ep:99, loss:0.00002, loss_test:0.01736, lr:8.02e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.432, tt:3643.178\n",
      "Ep:100, loss:0.00002, loss_test:0.01835, lr:7.94e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.423, tt:3678.686\n",
      "Ep:101, loss:0.00002, loss_test:0.01737, lr:7.86e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.418, tt:3714.638\n",
      "Ep:102, loss:0.00002, loss_test:0.01846, lr:7.78e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.404, tt:3749.656\n",
      "Ep:103, loss:0.00002, loss_test:0.01728, lr:7.70e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.391, tt:3784.663\n",
      "Ep:104, loss:0.00002, loss_test:0.01730, lr:7.62e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.387, tt:3820.662\n",
      "Ep:105, loss:0.00002, loss_test:0.01802, lr:7.55e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.368, tt:3854.958\n",
      "Ep:106, loss:0.00002, loss_test:0.01657, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.362, tt:3890.753\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00002, loss_test:0.01831, lr:7.47e-03, fs:0.95413 (r=0.963,p=0.945),  time:36.373, tt:3928.287\n",
      "Ep:108, loss:0.00002, loss_test:0.01612, lr:7.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.359, tt:3963.102\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00002, loss_test:0.01782, lr:7.47e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.319, tt:3995.064\n",
      "Ep:110, loss:0.00002, loss_test:0.01596, lr:7.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.322, tt:4031.745\n",
      "Ep:111, loss:0.00002, loss_test:0.01760, lr:7.47e-03, fs:0.96296 (r=0.963,p=0.963),  time:36.330, tt:4069.015\n",
      "Ep:112, loss:0.00002, loss_test:0.01616, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.335, tt:4105.826\n",
      "Ep:113, loss:0.00002, loss_test:0.01625, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.344, tt:4143.171\n",
      "Ep:114, loss:0.00001, loss_test:0.01701, lr:7.47e-03, fs:0.97196 (r=0.963,p=0.981),  time:36.362, tt:4181.658\n",
      "Ep:115, loss:0.00001, loss_test:0.01607, lr:7.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.365, tt:4218.342\n",
      "Ep:116, loss:0.00001, loss_test:0.01608, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.357, tt:4253.766\n",
      "Ep:117, loss:0.00001, loss_test:0.01611, lr:7.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.367, tt:4291.269\n",
      "Ep:118, loss:0.00001, loss_test:0.01547, lr:7.47e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.423, tt:4334.285\n",
      "Ep:119, loss:0.00001, loss_test:0.01653, lr:7.47e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.427, tt:4371.208\n",
      "Ep:120, loss:0.00001, loss_test:0.01481, lr:7.40e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.432, tt:4408.280\n",
      "Ep:121, loss:0.00001, loss_test:0.01588, lr:7.32e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.437, tt:4445.319\n",
      "Ep:122, loss:0.00001, loss_test:0.01519, lr:7.25e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.428, tt:4480.647\n",
      "Ep:123, loss:0.00001, loss_test:0.01510, lr:7.18e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.427, tt:4516.962\n",
      "Ep:124, loss:0.00001, loss_test:0.01613, lr:7.11e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.432, tt:4553.981\n",
      "Ep:125, loss:0.00001, loss_test:0.01474, lr:7.03e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.436, tt:4590.928\n",
      "Ep:126, loss:0.00001, loss_test:0.01555, lr:6.96e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.434, tt:4627.110\n",
      "Ep:127, loss:0.00001, loss_test:0.01425, lr:6.89e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.441, tt:4664.430\n",
      "Ep:128, loss:0.00001, loss_test:0.01591, lr:6.83e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.445, tt:4701.349\n",
      "Ep:129, loss:0.00001, loss_test:0.01456, lr:6.76e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.456, tt:4739.305\n",
      "Ep:130, loss:0.00001, loss_test:0.01585, lr:6.69e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.456, tt:4775.799\n",
      "Ep:131, loss:0.00001, loss_test:0.01436, lr:6.62e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.466, tt:4813.490\n",
      "Ep:132, loss:0.00001, loss_test:0.01654, lr:6.56e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.468, tt:4850.300\n",
      "Ep:133, loss:0.00001, loss_test:0.01345, lr:6.49e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.480, tt:4888.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.01598, lr:6.43e-03, fs:0.96364 (r=0.981,p=0.946),  time:36.490, tt:4926.097\n",
      "Ep:135, loss:0.00001, loss_test:0.01349, lr:6.36e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.501, tt:4964.163\n",
      "Ep:136, loss:0.00001, loss_test:0.01457, lr:6.30e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.510, tt:5001.823\n",
      "Ep:137, loss:0.00001, loss_test:0.01417, lr:6.24e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.521, tt:5039.858\n",
      "Ep:138, loss:0.00001, loss_test:0.01422, lr:6.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.521, tt:5076.438\n",
      "Ep:139, loss:0.00001, loss_test:0.01393, lr:6.11e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.522, tt:5113.145\n",
      "Ep:140, loss:0.00001, loss_test:0.01404, lr:6.05e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.532, tt:5150.985\n",
      "Ep:141, loss:0.00001, loss_test:0.01365, lr:5.99e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.549, tt:5189.907\n",
      "Ep:142, loss:0.00001, loss_test:0.01397, lr:5.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.542, tt:5225.577\n",
      "Ep:143, loss:0.00001, loss_test:0.01336, lr:5.87e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.541, tt:5261.927\n",
      "Ep:144, loss:0.00001, loss_test:0.01395, lr:5.81e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.542, tt:5298.642\n",
      "Ep:145, loss:0.00001, loss_test:0.01383, lr:5.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.546, tt:5335.733\n",
      "Ep:146, loss:0.00001, loss_test:0.01387, lr:5.70e-03, fs:0.99065 (r=0.981,p=1.000),  time:36.521, tt:5368.536\n",
      "Ep:147, loss:0.00001, loss_test:0.01353, lr:5.64e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.519, tt:5404.776\n",
      "Ep:148, loss:0.00001, loss_test:0.01342, lr:5.58e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.528, tt:5442.714\n",
      "Ep:149, loss:0.00001, loss_test:0.01373, lr:5.53e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.527, tt:5479.036\n",
      "Ep:150, loss:0.00001, loss_test:0.01331, lr:5.47e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.529, tt:5515.896\n",
      "Ep:151, loss:0.00001, loss_test:0.01370, lr:5.42e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.540, tt:5554.030\n",
      "Ep:152, loss:0.00001, loss_test:0.01284, lr:5.36e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.545, tt:5591.429\n",
      "Ep:153, loss:0.00001, loss_test:0.01333, lr:5.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.551, tt:5628.910\n",
      "Ep:154, loss:0.00001, loss_test:0.01316, lr:5.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.555, tt:5665.979\n",
      "Ep:155, loss:0.00001, loss_test:0.01318, lr:5.20e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.582, tt:5706.766\n",
      "Ep:156, loss:0.00001, loss_test:0.01324, lr:5.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.581, tt:5743.282\n",
      "Ep:157, loss:0.00001, loss_test:0.01286, lr:5.10e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.584, tt:5780.341\n",
      "Ep:158, loss:0.00001, loss_test:0.01293, lr:5.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.583, tt:5816.719\n",
      "Ep:159, loss:0.00001, loss_test:0.01302, lr:5.00e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.589, tt:5854.201\n",
      "Ep:160, loss:0.00001, loss_test:0.01283, lr:4.95e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.584, tt:5890.094\n",
      "Ep:161, loss:0.00001, loss_test:0.01313, lr:4.90e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.584, tt:5926.621\n",
      "Ep:162, loss:0.00001, loss_test:0.01265, lr:4.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.582, tt:5962.792\n",
      "Ep:163, loss:0.00001, loss_test:0.01302, lr:4.80e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.575, tt:5998.219\n",
      "Ep:164, loss:0.00001, loss_test:0.01281, lr:4.75e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.579, tt:6035.567\n",
      "Ep:165, loss:0.00001, loss_test:0.01281, lr:4.71e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.573, tt:6071.071\n",
      "Ep:166, loss:0.00001, loss_test:0.01317, lr:4.66e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.564, tt:6106.203\n",
      "Ep:167, loss:0.00001, loss_test:0.01237, lr:4.61e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.575, tt:6144.542\n",
      "Ep:168, loss:0.00001, loss_test:0.01310, lr:4.57e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.577, tt:6181.588\n",
      "Ep:169, loss:0.00001, loss_test:0.01255, lr:4.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.579, tt:6218.373\n",
      "Ep:170, loss:0.00001, loss_test:0.01254, lr:4.48e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.579, tt:6254.980\n",
      "Ep:171, loss:0.00001, loss_test:0.01280, lr:4.43e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.580, tt:6291.775\n",
      "Ep:172, loss:0.00001, loss_test:0.01257, lr:4.39e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.582, tt:6328.772\n",
      "Ep:173, loss:0.00001, loss_test:0.01225, lr:4.34e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.578, tt:6364.637\n",
      "Ep:174, loss:0.00001, loss_test:0.01305, lr:4.30e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.585, tt:6402.295\n",
      "Ep:175, loss:0.00001, loss_test:0.01219, lr:4.26e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.587, tt:6439.331\n",
      "Ep:176, loss:0.00001, loss_test:0.01231, lr:4.21e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.587, tt:6475.958\n",
      "Ep:177, loss:0.00001, loss_test:0.01272, lr:4.17e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.591, tt:6513.265\n",
      "Ep:178, loss:0.00001, loss_test:0.01213, lr:4.13e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.603, tt:6551.916\n",
      "Ep:179, loss:0.00001, loss_test:0.01249, lr:4.09e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.610, tt:6589.868\n",
      "Ep:180, loss:0.00001, loss_test:0.01253, lr:4.05e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.611, tt:6626.668\n",
      "Ep:181, loss:0.00001, loss_test:0.01240, lr:4.01e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.626, tt:6666.022\n",
      "Ep:182, loss:0.00001, loss_test:0.01233, lr:3.97e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.637, tt:6704.512\n",
      "Ep:183, loss:0.00001, loss_test:0.01240, lr:3.93e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.659, tt:6745.231\n",
      "Ep:184, loss:0.00001, loss_test:0.01193, lr:3.89e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.670, tt:6783.934\n",
      "Ep:185, loss:0.00001, loss_test:0.01217, lr:3.85e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.676, tt:6821.721\n",
      "Ep:186, loss:0.00001, loss_test:0.01248, lr:3.81e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.677, tt:6858.515\n",
      "Ep:187, loss:0.00001, loss_test:0.01172, lr:3.77e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.678, tt:6895.419\n",
      "Ep:188, loss:0.00001, loss_test:0.01223, lr:3.73e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.679, tt:6932.354\n",
      "Ep:189, loss:0.00001, loss_test:0.01231, lr:3.70e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.683, tt:6969.853\n",
      "Ep:190, loss:0.00001, loss_test:0.01203, lr:3.66e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.685, tt:7006.752\n",
      "Ep:191, loss:0.00001, loss_test:0.01229, lr:3.62e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.685, tt:7043.451\n",
      "Ep:192, loss:0.00001, loss_test:0.01218, lr:3.59e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.691, tt:7081.453\n",
      "Ep:193, loss:0.00001, loss_test:0.01216, lr:3.55e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.685, tt:7116.856\n",
      "Ep:194, loss:0.00001, loss_test:0.01167, lr:3.52e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.687, tt:7154.019\n",
      "Ep:195, loss:0.00001, loss_test:0.01205, lr:3.48e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.692, tt:7191.591\n",
      "Ep:196, loss:0.00001, loss_test:0.01220, lr:3.45e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.692, tt:7228.362\n",
      "Ep:197, loss:0.00001, loss_test:0.01191, lr:3.41e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.694, tt:7265.504\n",
      "Ep:198, loss:0.00001, loss_test:0.01216, lr:3.38e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.699, tt:7303.035\n",
      "Ep:199, loss:0.00001, loss_test:0.01186, lr:3.34e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.697, tt:7339.386\n",
      "Ep:200, loss:0.00001, loss_test:0.01195, lr:3.31e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.700, tt:7376.729\n",
      "Ep:201, loss:0.00001, loss_test:0.01203, lr:3.28e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.708, tt:7414.924\n",
      "Ep:202, loss:0.00001, loss_test:0.01175, lr:3.24e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.711, tt:7452.259\n",
      "Ep:203, loss:0.00001, loss_test:0.01196, lr:3.21e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.715, tt:7489.882\n",
      "Ep:204, loss:0.00001, loss_test:0.01200, lr:3.18e-03, fs:0.97248 (r=0.981,p=0.964),  time:36.660, tt:7515.346\n",
      "Ep:205, loss:0.00001, loss_test:0.01186, lr:3.15e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.567, tt:7532.763\n",
      "Ep:206, loss:0.00001, loss_test:0.01189, lr:3.12e-03, fs:0.98148 (r=0.981,p=0.981),  time:36.463, tt:7547.802\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1736 Test samples: 218\n",
      "Train positive samples: 868 Test positive samples: 109\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= random\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1954 Test samples: 108\n",
      "Train positive samples: 977 Test positive samples: 54\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.02947, lr:6.00e-02, fs:0.60163 (r=0.685,p=0.536),  time:34.971, tt:34.971\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02536, lr:6.00e-02, fs:0.63087 (r=0.870,p=0.495),  time:35.044, tt:70.088\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02616, lr:6.00e-02, fs:0.63694 (r=0.926,p=0.485),  time:35.350, tt:106.051\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02651, lr:6.00e-02, fs:0.64935 (r=0.926,p=0.500),  time:35.209, tt:140.837\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00005, loss_test:0.02646, lr:6.00e-02, fs:0.65359 (r=0.926,p=0.505),  time:34.974, tt:174.870\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02639, lr:6.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:35.143, tt:210.858\n",
      "Ep:6, loss:0.00005, loss_test:0.02630, lr:6.00e-02, fs:0.63014 (r=0.852,p=0.500),  time:35.077, tt:245.537\n",
      "Ep:7, loss:0.00005, loss_test:0.02596, lr:6.00e-02, fs:0.64336 (r=0.852,p=0.517),  time:35.112, tt:280.894\n",
      "Ep:8, loss:0.00005, loss_test:0.02527, lr:6.00e-02, fs:0.64336 (r=0.852,p=0.517),  time:35.062, tt:315.558\n",
      "Ep:9, loss:0.00005, loss_test:0.02451, lr:6.00e-02, fs:0.64336 (r=0.852,p=0.517),  time:35.198, tt:351.978\n",
      "Ep:10, loss:0.00004, loss_test:0.02345, lr:6.00e-02, fs:0.66207 (r=0.889,p=0.527),  time:35.173, tt:386.905\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02220, lr:6.00e-02, fs:0.68085 (r=0.889,p=0.552),  time:35.238, tt:422.858\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02110, lr:6.00e-02, fs:0.69630 (r=0.870,p=0.580),  time:35.233, tt:458.026\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02020, lr:6.00e-02, fs:0.69173 (r=0.852,p=0.582),  time:35.226, tt:493.170\n",
      "Ep:14, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.70229 (r=0.852,p=0.597),  time:35.266, tt:528.983\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01851, lr:6.00e-02, fs:0.70229 (r=0.852,p=0.597),  time:35.270, tt:564.319\n",
      "Ep:16, loss:0.00004, loss_test:0.01804, lr:6.00e-02, fs:0.70677 (r=0.870,p=0.595),  time:35.331, tt:600.627\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01769, lr:6.00e-02, fs:0.71212 (r=0.870,p=0.603),  time:35.270, tt:634.853\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01745, lr:6.00e-02, fs:0.72308 (r=0.870,p=0.618),  time:35.190, tt:668.614\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01733, lr:6.00e-02, fs:0.72308 (r=0.870,p=0.618),  time:35.150, tt:702.996\n",
      "Ep:20, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.72308 (r=0.870,p=0.618),  time:35.105, tt:737.206\n",
      "Ep:21, loss:0.00003, loss_test:0.01662, lr:6.00e-02, fs:0.71875 (r=0.852,p=0.622),  time:35.101, tt:772.211\n",
      "Ep:22, loss:0.00003, loss_test:0.01628, lr:6.00e-02, fs:0.74016 (r=0.870,p=0.644),  time:35.060, tt:806.391\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01595, lr:6.00e-02, fs:0.75969 (r=0.907,p=0.653),  time:35.058, tt:841.393\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.76562 (r=0.907,p=0.662),  time:34.982, tt:874.562\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.76562 (r=0.907,p=0.662),  time:35.027, tt:910.710\n",
      "Ep:26, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.76800 (r=0.889,p=0.676),  time:34.953, tt:943.726\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01502, lr:6.00e-02, fs:0.78400 (r=0.907,p=0.690),  time:34.961, tt:978.920\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01460, lr:6.00e-02, fs:0.79032 (r=0.907,p=0.700),  time:34.974, tt:1014.243\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.80000 (r=0.926,p=0.704),  time:34.992, tt:1049.771\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01379, lr:6.00e-02, fs:0.80645 (r=0.926,p=0.714),  time:34.994, tt:1084.801\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.80645 (r=0.926,p=0.714),  time:34.998, tt:1119.921\n",
      "Ep:32, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.81301 (r=0.926,p=0.725),  time:34.979, tt:1154.302\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.81967 (r=0.926,p=0.735),  time:34.992, tt:1189.726\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01242, lr:6.00e-02, fs:0.81967 (r=0.926,p=0.735),  time:34.968, tt:1223.897\n",
      "Ep:35, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.81967 (r=0.926,p=0.735),  time:34.961, tt:1258.605\n",
      "Ep:36, loss:0.00002, loss_test:0.01169, lr:6.00e-02, fs:0.84298 (r=0.944,p=0.761),  time:34.975, tt:1294.065\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.86179 (r=0.981,p=0.768),  time:34.991, tt:1329.658\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01080, lr:6.00e-02, fs:0.86179 (r=0.981,p=0.768),  time:35.055, tt:1367.132\n",
      "Ep:39, loss:0.00002, loss_test:0.01042, lr:6.00e-02, fs:0.85246 (r=0.963,p=0.765),  time:35.033, tt:1401.336\n",
      "Ep:40, loss:0.00002, loss_test:0.01013, lr:6.00e-02, fs:0.85484 (r=0.981,p=0.757),  time:35.026, tt:1436.078\n",
      "Ep:41, loss:0.00002, loss_test:0.00958, lr:6.00e-02, fs:0.85484 (r=0.981,p=0.757),  time:35.036, tt:1471.530\n",
      "Ep:42, loss:0.00002, loss_test:0.00943, lr:6.00e-02, fs:0.84800 (r=0.981,p=0.746),  time:35.034, tt:1506.478\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6913c0e69143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.3+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m207\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"random\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02230, lr:6.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:22.748, tt:22.748\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02469, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:24.492, tt:48.984\n",
      "Ep:2, loss:0.00005, loss_test:0.02712, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:26.542, tt:79.625\n",
      "Ep:3, loss:0.00005, loss_test:0.02773, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:27.705, tt:110.818\n",
      "Ep:4, loss:0.00005, loss_test:0.02746, lr:6.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:28.368, tt:141.842\n",
      "Ep:5, loss:0.00005, loss_test:0.02674, lr:6.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:28.968, tt:173.807\n",
      "Ep:6, loss:0.00005, loss_test:0.02565, lr:6.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:29.307, tt:205.150\n",
      "Ep:7, loss:0.00005, loss_test:0.02452, lr:6.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:29.630, tt:237.041\n",
      "Ep:8, loss:0.00005, loss_test:0.02364, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:29.751, tt:267.760\n",
      "Ep:9, loss:0.00005, loss_test:0.02269, lr:6.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:29.855, tt:298.550\n",
      "Ep:10, loss:0.00005, loss_test:0.02204, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:29.998, tt:329.978\n",
      "Ep:11, loss:0.00005, loss_test:0.02165, lr:6.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:30.054, tt:360.647\n",
      "Ep:12, loss:0.00004, loss_test:0.02091, lr:5.94e-02, fs:0.67159 (r=0.919,p=0.529),  time:30.138, tt:391.799\n",
      "Ep:13, loss:0.00004, loss_test:0.02004, lr:5.88e-02, fs:0.68462 (r=0.899,p=0.553),  time:30.237, tt:423.315\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01939, lr:5.88e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.370, tt:455.546\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01892, lr:5.88e-02, fs:0.69880 (r=0.879,p=0.580),  time:30.553, tt:488.843\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01860, lr:5.88e-02, fs:0.69323 (r=0.879,p=0.572),  time:30.533, tt:519.060\n",
      "Ep:17, loss:0.00004, loss_test:0.01838, lr:5.88e-02, fs:0.70588 (r=0.909,p=0.577),  time:30.632, tt:551.372\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01819, lr:5.88e-02, fs:0.71318 (r=0.929,p=0.579),  time:30.637, tt:582.102\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01791, lr:5.88e-02, fs:0.71595 (r=0.929,p=0.582),  time:30.677, tt:613.543\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01747, lr:5.88e-02, fs:0.72157 (r=0.929,p=0.590),  time:30.687, tt:644.436\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01708, lr:5.88e-02, fs:0.71713 (r=0.909,p=0.592),  time:30.737, tt:676.209\n",
      "Ep:22, loss:0.00003, loss_test:0.01673, lr:5.88e-02, fs:0.71486 (r=0.899,p=0.593),  time:30.763, tt:707.556\n",
      "Ep:23, loss:0.00003, loss_test:0.01631, lr:5.88e-02, fs:0.71486 (r=0.899,p=0.593),  time:30.748, tt:737.945\n",
      "Ep:24, loss:0.00003, loss_test:0.01590, lr:5.88e-02, fs:0.72065 (r=0.899,p=0.601),  time:30.783, tt:769.574\n",
      "Ep:25, loss:0.00003, loss_test:0.01564, lr:5.88e-02, fs:0.75200 (r=0.949,p=0.623),  time:30.780, tt:800.272\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01529, lr:5.88e-02, fs:0.76113 (r=0.949,p=0.635),  time:30.795, tt:831.476\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01494, lr:5.88e-02, fs:0.75918 (r=0.939,p=0.637),  time:30.812, tt:862.740\n",
      "Ep:28, loss:0.00003, loss_test:0.01461, lr:5.88e-02, fs:0.76667 (r=0.929,p=0.652),  time:30.816, tt:893.673\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01432, lr:5.88e-02, fs:0.76349 (r=0.929,p=0.648),  time:30.780, tt:923.402\n",
      "Ep:30, loss:0.00003, loss_test:0.01412, lr:5.88e-02, fs:0.76033 (r=0.929,p=0.643),  time:30.825, tt:955.586\n",
      "Ep:31, loss:0.00003, loss_test:0.01381, lr:5.88e-02, fs:0.77686 (r=0.949,p=0.657),  time:30.858, tt:987.463\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01349, lr:5.88e-02, fs:0.78838 (r=0.960,p=0.669),  time:30.883, tt:1019.129\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01328, lr:5.88e-02, fs:0.78151 (r=0.939,p=0.669),  time:30.925, tt:1051.456\n",
      "Ep:34, loss:0.00003, loss_test:0.01307, lr:5.88e-02, fs:0.80519 (r=0.939,p=0.705),  time:30.967, tt:1083.845\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01287, lr:5.88e-02, fs:0.80851 (r=0.960,p=0.699),  time:30.990, tt:1115.645\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01263, lr:5.88e-02, fs:0.81197 (r=0.960,p=0.704),  time:31.021, tt:1147.761\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01235, lr:5.88e-02, fs:0.80519 (r=0.939,p=0.705),  time:31.029, tt:1179.094\n",
      "Ep:38, loss:0.00002, loss_test:0.01212, lr:5.88e-02, fs:0.78947 (r=0.909,p=0.698),  time:31.043, tt:1210.665\n",
      "Ep:39, loss:0.00002, loss_test:0.01196, lr:5.88e-02, fs:0.79476 (r=0.919,p=0.700),  time:31.061, tt:1242.447\n",
      "Ep:40, loss:0.00002, loss_test:0.01179, lr:5.88e-02, fs:0.80349 (r=0.929,p=0.708),  time:31.064, tt:1273.607\n",
      "Ep:41, loss:0.00002, loss_test:0.01155, lr:5.88e-02, fs:0.80176 (r=0.919,p=0.711),  time:31.088, tt:1305.715\n",
      "Ep:42, loss:0.00002, loss_test:0.01140, lr:5.88e-02, fs:0.81057 (r=0.929,p=0.719),  time:31.110, tt:1337.713\n",
      "Ep:43, loss:0.00002, loss_test:0.01131, lr:5.88e-02, fs:0.80531 (r=0.919,p=0.717),  time:31.142, tt:1370.263\n",
      "Ep:44, loss:0.00002, loss_test:0.01118, lr:5.88e-02, fs:0.80702 (r=0.929,p=0.713),  time:31.144, tt:1401.467\n",
      "Ep:45, loss:0.00002, loss_test:0.01108, lr:5.88e-02, fs:0.81778 (r=0.929,p=0.730),  time:31.186, tt:1434.574\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01119, lr:5.88e-02, fs:0.81938 (r=0.939,p=0.727),  time:31.182, tt:1465.566\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01112, lr:5.88e-02, fs:0.81579 (r=0.939,p=0.721),  time:31.193, tt:1497.259\n",
      "Ep:48, loss:0.00002, loss_test:0.01110, lr:5.88e-02, fs:0.82301 (r=0.939,p=0.732),  time:31.190, tt:1528.303\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01085, lr:5.88e-02, fs:0.82301 (r=0.939,p=0.732),  time:31.191, tt:1559.575\n",
      "Ep:50, loss:0.00002, loss_test:0.01063, lr:5.88e-02, fs:0.83556 (r=0.949,p=0.746),  time:31.214, tt:1591.928\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01068, lr:5.88e-02, fs:0.82301 (r=0.939,p=0.732),  time:31.224, tt:1623.639\n",
      "Ep:52, loss:0.00001, loss_test:0.01049, lr:5.88e-02, fs:0.82301 (r=0.939,p=0.732),  time:31.223, tt:1654.833\n",
      "Ep:53, loss:0.00001, loss_test:0.01056, lr:5.88e-02, fs:0.84305 (r=0.949,p=0.758),  time:31.227, tt:1686.271\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01069, lr:5.88e-02, fs:0.82456 (r=0.949,p=0.729),  time:31.233, tt:1717.809\n",
      "Ep:55, loss:0.00001, loss_test:0.01058, lr:5.88e-02, fs:0.84685 (r=0.949,p=0.764),  time:31.239, tt:1749.412\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01053, lr:5.88e-02, fs:0.83929 (r=0.949,p=0.752),  time:31.249, tt:1781.208\n",
      "Ep:57, loss:0.00001, loss_test:0.01029, lr:5.88e-02, fs:0.80734 (r=0.889,p=0.739),  time:31.254, tt:1812.752\n",
      "Ep:58, loss:0.00001, loss_test:0.01031, lr:5.88e-02, fs:0.83929 (r=0.949,p=0.752),  time:31.264, tt:1844.597\n",
      "Ep:59, loss:0.00001, loss_test:0.01037, lr:5.88e-02, fs:0.83486 (r=0.919,p=0.765),  time:31.274, tt:1876.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01031, lr:5.88e-02, fs:0.83962 (r=0.899,p=0.788),  time:31.299, tt:1909.264\n",
      "Ep:61, loss:0.00001, loss_test:0.01037, lr:5.88e-02, fs:0.84360 (r=0.899,p=0.795),  time:31.302, tt:1940.744\n",
      "Ep:62, loss:0.00001, loss_test:0.01044, lr:5.88e-02, fs:0.85437 (r=0.889,p=0.822),  time:31.322, tt:1973.289\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01032, lr:5.88e-02, fs:0.82857 (r=0.879,p=0.784),  time:31.335, tt:2005.421\n",
      "Ep:64, loss:0.00001, loss_test:0.01038, lr:5.88e-02, fs:0.86792 (r=0.929,p=0.814),  time:31.355, tt:2038.082\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01019, lr:5.88e-02, fs:0.84466 (r=0.879,p=0.813),  time:31.346, tt:2068.812\n",
      "Ep:66, loss:0.00001, loss_test:0.01007, lr:5.88e-02, fs:0.84466 (r=0.879,p=0.813),  time:31.331, tt:2099.159\n",
      "Ep:67, loss:0.00001, loss_test:0.01015, lr:5.88e-02, fs:0.84878 (r=0.879,p=0.821),  time:31.299, tt:2128.324\n",
      "Ep:68, loss:0.00001, loss_test:0.01016, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:31.309, tt:2160.302\n",
      "Ep:69, loss:0.00001, loss_test:0.01027, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:31.327, tt:2192.887\n",
      "Ep:70, loss:0.00001, loss_test:0.01033, lr:5.88e-02, fs:0.86408 (r=0.899,p=0.832),  time:31.328, tt:2224.319\n",
      "Ep:71, loss:0.00001, loss_test:0.01042, lr:5.88e-02, fs:0.85714 (r=0.879,p=0.837),  time:31.332, tt:2255.918\n",
      "Ep:72, loss:0.00001, loss_test:0.01084, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:31.303, tt:2285.127\n",
      "Ep:73, loss:0.00001, loss_test:0.01040, lr:5.88e-02, fs:0.84058 (r=0.879,p=0.806),  time:31.298, tt:2316.029\n",
      "Ep:74, loss:0.00001, loss_test:0.01081, lr:5.88e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.304, tt:2347.774\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01054, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:31.281, tt:2377.369\n",
      "Ep:76, loss:0.00001, loss_test:0.01084, lr:5.88e-02, fs:0.87310 (r=0.869,p=0.878),  time:31.284, tt:2408.883\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01087, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:31.303, tt:2441.662\n",
      "Ep:78, loss:0.00001, loss_test:0.01103, lr:5.88e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.308, tt:2473.294\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01149, lr:5.88e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.316, tt:2505.312\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01116, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:31.316, tt:2536.615\n",
      "Ep:81, loss:0.00001, loss_test:0.01133, lr:5.88e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.305, tt:2566.993\n",
      "Ep:82, loss:0.00001, loss_test:0.01123, lr:5.88e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.301, tt:2598.010\n",
      "Ep:83, loss:0.00001, loss_test:0.01133, lr:5.88e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.278, tt:2627.386\n",
      "Ep:84, loss:0.00001, loss_test:0.01115, lr:5.88e-02, fs:0.86139 (r=0.879,p=0.845),  time:31.271, tt:2658.022\n",
      "Ep:85, loss:0.00001, loss_test:0.01186, lr:5.88e-02, fs:0.87000 (r=0.879,p=0.861),  time:31.291, tt:2691.019\n",
      "Ep:86, loss:0.00001, loss_test:0.01148, lr:5.88e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.292, tt:2722.374\n",
      "Ep:87, loss:0.00000, loss_test:0.01155, lr:5.88e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.292, tt:2753.691\n",
      "Ep:88, loss:0.00000, loss_test:0.01179, lr:5.88e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.283, tt:2784.169\n",
      "Ep:89, loss:0.00000, loss_test:0.01190, lr:5.88e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.278, tt:2815.038\n",
      "Ep:90, loss:0.00000, loss_test:0.01200, lr:5.88e-02, fs:0.86869 (r=0.869,p=0.869),  time:31.279, tt:2846.430\n",
      "Ep:91, loss:0.00000, loss_test:0.01206, lr:5.82e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.274, tt:2877.185\n",
      "Ep:92, loss:0.00000, loss_test:0.01238, lr:5.76e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.269, tt:2907.973\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00000, loss_test:0.01203, lr:5.76e-02, fs:0.86567 (r=0.879,p=0.853),  time:31.255, tt:2938.015\n",
      "Ep:94, loss:0.00000, loss_test:0.01229, lr:5.76e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.254, tt:2969.140\n",
      "Ep:95, loss:0.00000, loss_test:0.01226, lr:5.76e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.225, tt:2997.596\n",
      "Ep:96, loss:0.00000, loss_test:0.01291, lr:5.76e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.234, tt:3029.737\n",
      "Ep:97, loss:0.00000, loss_test:0.01211, lr:5.76e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.217, tt:3059.244\n",
      "Ep:98, loss:0.00000, loss_test:0.01301, lr:5.76e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.213, tt:3090.070\n",
      "Ep:99, loss:0.00000, loss_test:0.01304, lr:5.76e-02, fs:0.88660 (r=0.869,p=0.905),  time:31.219, tt:3121.876\n",
      "Ep:100, loss:0.00000, loss_test:0.01377, lr:5.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:31.220, tt:3153.215\n",
      "Ep:101, loss:0.00000, loss_test:0.01318, lr:5.76e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.223, tt:3184.792\n",
      "Ep:102, loss:0.00000, loss_test:0.01323, lr:5.76e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.222, tt:3215.864\n",
      "Ep:103, loss:0.00000, loss_test:0.01266, lr:5.76e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.233, tt:3248.205\n",
      "Ep:104, loss:0.00000, loss_test:0.01318, lr:5.71e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.243, tt:3280.544\n",
      "Ep:105, loss:0.00000, loss_test:0.01347, lr:5.65e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.243, tt:3311.770\n",
      "Ep:106, loss:0.00000, loss_test:0.01360, lr:5.59e-02, fs:0.88205 (r=0.869,p=0.896),  time:31.251, tt:3343.862\n",
      "Ep:107, loss:0.00000, loss_test:0.01286, lr:5.54e-02, fs:0.87879 (r=0.879,p=0.879),  time:31.267, tt:3376.823\n",
      "Ep:108, loss:0.00000, loss_test:0.01321, lr:5.48e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.240, tt:3405.183\n",
      "Ep:109, loss:0.00000, loss_test:0.01407, lr:5.43e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.237, tt:3436.098\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01345, lr:5.43e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.240, tt:3467.653\n",
      "Ep:111, loss:0.00000, loss_test:0.01328, lr:5.43e-02, fs:0.86432 (r=0.869,p=0.860),  time:31.236, tt:3498.423\n",
      "Ep:112, loss:0.00000, loss_test:0.01389, lr:5.43e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.238, tt:3529.877\n",
      "Ep:113, loss:0.00000, loss_test:0.01367, lr:5.43e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.239, tt:3561.201\n",
      "Ep:114, loss:0.00000, loss_test:0.01337, lr:5.43e-02, fs:0.87437 (r=0.879,p=0.870),  time:31.236, tt:3592.088\n",
      "Ep:115, loss:0.00000, loss_test:0.01386, lr:5.43e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.227, tt:3622.328\n",
      "Ep:116, loss:0.00000, loss_test:0.01386, lr:5.43e-02, fs:0.88776 (r=0.879,p=0.897),  time:31.215, tt:3652.133\n",
      "Ep:117, loss:0.00000, loss_test:0.01400, lr:5.43e-02, fs:0.89231 (r=0.879,p=0.906),  time:31.205, tt:3682.246\n",
      "Ep:118, loss:0.00000, loss_test:0.01367, lr:5.43e-02, fs:0.87755 (r=0.869,p=0.887),  time:31.194, tt:3712.065\n",
      "Ep:119, loss:0.00000, loss_test:0.01458, lr:5.43e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.188, tt:3742.605\n",
      "Ep:120, loss:0.00000, loss_test:0.01452, lr:5.43e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.190, tt:3774.018\n",
      "Ep:121, loss:0.00000, loss_test:0.01444, lr:5.37e-02, fs:0.89691 (r=0.879,p=0.916),  time:31.183, tt:3804.307\n",
      "##########Best model found so far##########\n",
      "Ep:122, loss:0.00000, loss_test:0.01411, lr:5.37e-02, fs:0.87179 (r=0.859,p=0.885),  time:31.182, tt:3835.406\n",
      "Ep:123, loss:0.00000, loss_test:0.01447, lr:5.37e-02, fs:0.89231 (r=0.879,p=0.906),  time:31.183, tt:3866.706\n",
      "Ep:124, loss:0.00000, loss_test:0.01456, lr:5.37e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.183, tt:3897.838\n",
      "Ep:125, loss:0.00000, loss_test:0.01496, lr:5.37e-02, fs:0.88542 (r=0.859,p=0.914),  time:31.184, tt:3929.124\n",
      "Ep:126, loss:0.00000, loss_test:0.01429, lr:5.37e-02, fs:0.90155 (r=0.879,p=0.926),  time:31.178, tt:3959.639\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00000, loss_test:0.01476, lr:5.37e-02, fs:0.87368 (r=0.838,p=0.912),  time:31.177, tt:3990.628\n",
      "Ep:128, loss:0.00000, loss_test:0.01462, lr:5.37e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.179, tt:4022.136\n",
      "Ep:129, loss:0.00000, loss_test:0.01527, lr:5.37e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.195, tt:4055.326\n",
      "Ep:130, loss:0.00000, loss_test:0.01497, lr:5.37e-02, fs:0.90155 (r=0.879,p=0.926),  time:31.196, tt:4086.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01511, lr:5.37e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.204, tt:4118.903\n",
      "Ep:132, loss:0.00000, loss_test:0.01502, lr:5.37e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.197, tt:4149.168\n",
      "Ep:133, loss:0.00000, loss_test:0.01533, lr:5.37e-02, fs:0.89474 (r=0.859,p=0.934),  time:31.194, tt:4180.029\n",
      "Ep:134, loss:0.00000, loss_test:0.01513, lr:5.37e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.192, tt:4210.915\n",
      "Ep:135, loss:0.00000, loss_test:0.01506, lr:5.37e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.195, tt:4242.493\n",
      "Ep:136, loss:0.00000, loss_test:0.01467, lr:5.37e-02, fs:0.87179 (r=0.859,p=0.885),  time:31.188, tt:4272.787\n",
      "Ep:137, loss:0.00000, loss_test:0.01503, lr:5.37e-02, fs:0.89119 (r=0.869,p=0.915),  time:31.188, tt:4304.001\n",
      "Ep:138, loss:0.00000, loss_test:0.01528, lr:5.32e-02, fs:0.89947 (r=0.859,p=0.944),  time:31.191, tt:4335.482\n",
      "Ep:139, loss:0.00000, loss_test:0.01483, lr:5.27e-02, fs:0.89231 (r=0.879,p=0.906),  time:31.189, tt:4366.429\n",
      "Ep:140, loss:0.00000, loss_test:0.01482, lr:5.21e-02, fs:0.89583 (r=0.869,p=0.925),  time:31.182, tt:4396.649\n",
      "Ep:141, loss:0.00000, loss_test:0.01563, lr:5.16e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.179, tt:4427.398\n",
      "Ep:142, loss:0.00000, loss_test:0.01474, lr:5.11e-02, fs:0.87234 (r=0.828,p=0.921),  time:31.174, tt:4457.841\n",
      "Ep:143, loss:0.00000, loss_test:0.01517, lr:5.06e-02, fs:0.89474 (r=0.859,p=0.934),  time:31.164, tt:4487.598\n",
      "Ep:144, loss:0.00000, loss_test:0.01512, lr:5.01e-02, fs:0.81111 (r=0.737,p=0.901),  time:31.168, tt:4519.367\n",
      "Ep:145, loss:0.00000, loss_test:0.01513, lr:4.96e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.164, tt:4549.911\n",
      "Ep:146, loss:0.00000, loss_test:0.01512, lr:4.91e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.166, tt:4581.362\n",
      "Ep:147, loss:0.00000, loss_test:0.01528, lr:4.86e-02, fs:0.90052 (r=0.869,p=0.935),  time:31.180, tt:4614.698\n",
      "Ep:148, loss:0.00000, loss_test:0.01483, lr:4.81e-02, fs:0.84153 (r=0.778,p=0.917),  time:31.183, tt:4646.239\n",
      "Ep:149, loss:0.00000, loss_test:0.01540, lr:4.76e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.192, tt:4678.866\n",
      "Ep:150, loss:0.00000, loss_test:0.01545, lr:4.71e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.199, tt:4711.017\n",
      "Ep:151, loss:0.00000, loss_test:0.01544, lr:4.67e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.205, tt:4743.165\n",
      "Ep:152, loss:0.00000, loss_test:0.01537, lr:4.62e-02, fs:0.87097 (r=0.818,p=0.931),  time:31.203, tt:4774.060\n",
      "Ep:153, loss:0.00000, loss_test:0.01566, lr:4.57e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.205, tt:4805.527\n",
      "Ep:154, loss:0.00000, loss_test:0.01543, lr:4.53e-02, fs:0.88889 (r=0.848,p=0.933),  time:31.201, tt:4836.193\n",
      "Ep:155, loss:0.00000, loss_test:0.01544, lr:4.48e-02, fs:0.80682 (r=0.717,p=0.922),  time:31.206, tt:4868.146\n",
      "Ep:156, loss:0.00000, loss_test:0.01564, lr:4.44e-02, fs:0.89474 (r=0.859,p=0.934),  time:31.210, tt:4900.012\n",
      "Ep:157, loss:0.00000, loss_test:0.01528, lr:4.39e-02, fs:0.83516 (r=0.768,p=0.916),  time:31.216, tt:4932.126\n",
      "Ep:158, loss:0.00000, loss_test:0.01572, lr:4.35e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.225, tt:4964.708\n",
      "Ep:159, loss:0.00000, loss_test:0.01558, lr:4.31e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.224, tt:4995.806\n",
      "Ep:160, loss:0.00000, loss_test:0.01569, lr:4.26e-02, fs:0.85246 (r=0.788,p=0.929),  time:31.228, tt:5027.694\n",
      "Ep:161, loss:0.00000, loss_test:0.01573, lr:4.22e-02, fs:0.81356 (r=0.727,p=0.923),  time:31.230, tt:5059.213\n",
      "Ep:162, loss:0.00000, loss_test:0.01568, lr:4.18e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.233, tt:5091.052\n",
      "Ep:163, loss:0.00000, loss_test:0.01572, lr:4.14e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.239, tt:5123.189\n",
      "Ep:164, loss:0.00000, loss_test:0.01592, lr:4.10e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.247, tt:5155.726\n",
      "Ep:165, loss:0.00000, loss_test:0.01555, lr:4.05e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.247, tt:5186.988\n",
      "Ep:166, loss:0.00000, loss_test:0.01587, lr:4.01e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.260, tt:5220.389\n",
      "Ep:167, loss:0.00000, loss_test:0.01564, lr:3.97e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.270, tt:5253.378\n",
      "Ep:168, loss:0.00000, loss_test:0.01573, lr:3.93e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.276, tt:5285.603\n",
      "Ep:169, loss:0.00000, loss_test:0.01593, lr:3.89e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.278, tt:5317.314\n",
      "Ep:170, loss:0.00000, loss_test:0.01576, lr:3.86e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.287, tt:5350.023\n",
      "Ep:171, loss:0.00000, loss_test:0.01607, lr:3.82e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.286, tt:5381.145\n",
      "Ep:172, loss:0.00000, loss_test:0.01576, lr:3.78e-02, fs:0.83978 (r=0.768,p=0.927),  time:31.300, tt:5414.901\n",
      "Ep:173, loss:0.00000, loss_test:0.01606, lr:3.74e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.299, tt:5446.074\n",
      "Ep:174, loss:0.00000, loss_test:0.01577, lr:3.70e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.296, tt:5476.867\n",
      "Ep:175, loss:0.00000, loss_test:0.01599, lr:3.67e-02, fs:0.85714 (r=0.788,p=0.940),  time:31.298, tt:5508.496\n",
      "Ep:176, loss:0.00000, loss_test:0.01587, lr:3.63e-02, fs:0.82486 (r=0.737,p=0.936),  time:31.304, tt:5540.796\n",
      "Ep:177, loss:0.00000, loss_test:0.01602, lr:3.59e-02, fs:0.85083 (r=0.778,p=0.939),  time:31.309, tt:5573.052\n",
      "Ep:178, loss:0.00000, loss_test:0.01579, lr:3.56e-02, fs:0.82022 (r=0.737,p=0.924),  time:31.312, tt:5604.850\n",
      "Ep:179, loss:0.00000, loss_test:0.01609, lr:3.52e-02, fs:0.85083 (r=0.778,p=0.939),  time:31.315, tt:5636.744\n",
      "Ep:180, loss:0.00000, loss_test:0.01591, lr:3.49e-02, fs:0.82486 (r=0.737,p=0.936),  time:31.317, tt:5668.293\n",
      "Ep:181, loss:0.00000, loss_test:0.01602, lr:3.45e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.310, tt:5698.486\n",
      "Ep:182, loss:0.00000, loss_test:0.01593, lr:3.42e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.310, tt:5729.754\n",
      "Ep:183, loss:0.00000, loss_test:0.01607, lr:3.38e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.310, tt:5761.057\n",
      "Ep:184, loss:0.00000, loss_test:0.01588, lr:3.35e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.310, tt:5792.358\n",
      "Ep:185, loss:0.00000, loss_test:0.01618, lr:3.32e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.316, tt:5824.850\n",
      "Ep:186, loss:0.00000, loss_test:0.01588, lr:3.28e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.314, tt:5855.786\n",
      "Ep:187, loss:0.00000, loss_test:0.01621, lr:3.25e-02, fs:0.83146 (r=0.747,p=0.937),  time:31.311, tt:5886.442\n",
      "Ep:188, loss:0.00000, loss_test:0.01599, lr:3.22e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.315, tt:5918.618\n",
      "Ep:189, loss:0.00000, loss_test:0.01611, lr:3.19e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.317, tt:5950.306\n",
      "Ep:190, loss:0.00000, loss_test:0.01600, lr:3.15e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.315, tt:5981.218\n",
      "Ep:191, loss:0.00000, loss_test:0.01614, lr:3.12e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.320, tt:6013.454\n",
      "Ep:192, loss:0.00000, loss_test:0.01611, lr:3.09e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.321, tt:6045.027\n",
      "Ep:193, loss:0.00000, loss_test:0.01608, lr:3.06e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.326, tt:6077.182\n",
      "Ep:194, loss:0.00000, loss_test:0.01623, lr:3.03e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.339, tt:6111.162\n",
      "Ep:195, loss:0.00000, loss_test:0.01603, lr:3.00e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.334, tt:6141.546\n",
      "Ep:196, loss:0.00000, loss_test:0.01622, lr:2.97e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.330, tt:6171.991\n",
      "Ep:197, loss:0.00000, loss_test:0.01612, lr:2.94e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.335, tt:6204.244\n",
      "Ep:198, loss:0.00000, loss_test:0.01616, lr:2.91e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.337, tt:6236.049\n",
      "Ep:199, loss:0.00000, loss_test:0.01632, lr:2.88e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.345, tt:6268.899\n",
      "Ep:200, loss:0.00000, loss_test:0.01614, lr:2.85e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.354, tt:6302.107\n",
      "Ep:201, loss:0.00000, loss_test:0.01622, lr:2.82e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.350, tt:6332.601\n",
      "Ep:202, loss:0.00000, loss_test:0.01623, lr:2.80e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.349, tt:6363.785\n",
      "Ep:203, loss:0.00000, loss_test:0.01628, lr:2.77e-02, fs:0.84444 (r=0.768,p=0.938),  time:31.329, tt:6391.140\n",
      "Ep:204, loss:0.00000, loss_test:0.01624, lr:2.74e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.289, tt:6414.203\n",
      "Ep:205, loss:0.00000, loss_test:0.01629, lr:2.71e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.275, tt:6442.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.01628, lr:2.69e-02, fs:0.83799 (r=0.758,p=0.938),  time:31.268, tt:6472.437\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12461, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:31.299, tt:31.299\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12374, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:29.887, tt:59.773\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12288, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:30.012, tt:90.036\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12172, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:30.472, tt:121.887\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11961, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:30.939, tt:154.696\n",
      "Ep:5, loss:0.00026, loss_test:0.11725, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:31.076, tt:186.459\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11552, lr:1.00e-02, fs:0.68775 (r=0.879,p=0.565),  time:31.127, tt:217.892\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11426, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:31.263, tt:250.102\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.11346, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:31.423, tt:282.806\n",
      "Ep:9, loss:0.00025, loss_test:0.11237, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:31.541, tt:315.405\n",
      "Ep:10, loss:0.00024, loss_test:0.11098, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:31.516, tt:346.680\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.10957, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:31.612, tt:379.341\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.10839, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:31.690, tt:411.966\n",
      "Ep:13, loss:0.00023, loss_test:0.10701, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:31.816, tt:445.426\n",
      "Ep:14, loss:0.00023, loss_test:0.10507, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:31.714, tt:475.717\n",
      "Ep:15, loss:0.00022, loss_test:0.10310, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:31.764, tt:508.223\n",
      "Ep:16, loss:0.00022, loss_test:0.10131, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:31.734, tt:539.475\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00021, loss_test:0.10000, lr:1.00e-02, fs:0.72574 (r=0.869,p=0.623),  time:31.867, tt:573.599\n",
      "Ep:18, loss:0.00021, loss_test:0.09895, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:31.860, tt:605.343\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.09829, lr:1.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:31.893, tt:637.851\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.09760, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:31.932, tt:670.564\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.09685, lr:1.00e-02, fs:0.73043 (r=0.848,p=0.641),  time:31.956, tt:703.023\n",
      "Ep:22, loss:0.00020, loss_test:0.09619, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:31.985, tt:735.659\n",
      "Ep:23, loss:0.00019, loss_test:0.09521, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:32.017, tt:768.416\n",
      "Ep:24, loss:0.00019, loss_test:0.09422, lr:1.00e-02, fs:0.73128 (r=0.838,p=0.648),  time:31.916, tt:797.897\n",
      "Ep:25, loss:0.00018, loss_test:0.09352, lr:1.00e-02, fs:0.73276 (r=0.859,p=0.639),  time:31.923, tt:830.004\n",
      "Ep:26, loss:0.00018, loss_test:0.09201, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:31.895, tt:861.171\n",
      "Ep:27, loss:0.00018, loss_test:0.09077, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:31.891, tt:892.943\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08939, lr:1.00e-02, fs:0.74667 (r=0.848,p=0.667),  time:31.897, tt:925.025\n",
      "Ep:29, loss:0.00017, loss_test:0.08797, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:31.878, tt:956.333\n",
      "Ep:30, loss:0.00016, loss_test:0.08589, lr:1.00e-02, fs:0.75771 (r=0.869,p=0.672),  time:31.877, tt:988.198\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00016, loss_test:0.08397, lr:1.00e-02, fs:0.77477 (r=0.869,p=0.699),  time:31.878, tt:1020.095\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.08417, lr:1.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:31.894, tt:1052.507\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00015, loss_test:0.08107, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:31.901, tt:1084.637\n",
      "Ep:34, loss:0.00015, loss_test:0.08114, lr:1.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:31.907, tt:1116.749\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00014, loss_test:0.07803, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:31.908, tt:1148.677\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.07781, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:31.936, tt:1181.644\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00013, loss_test:0.07169, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:31.940, tt:1213.712\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00013, loss_test:0.07043, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:31.968, tt:1246.739\n",
      "Ep:39, loss:0.00012, loss_test:0.06853, lr:1.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:31.960, tt:1278.405\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.06684, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:32.021, tt:1312.859\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.06504, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:32.013, tt:1344.541\n",
      "Ep:42, loss:0.00011, loss_test:0.07198, lr:1.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:32.031, tt:1377.339\n",
      "Ep:43, loss:0.00011, loss_test:0.06372, lr:1.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:32.034, tt:1409.518\n",
      "Ep:44, loss:0.00010, loss_test:0.06218, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:32.047, tt:1442.113\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.06034, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:32.084, tt:1475.883\n",
      "Ep:46, loss:0.00009, loss_test:0.06796, lr:1.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:32.120, tt:1509.621\n",
      "Ep:47, loss:0.00010, loss_test:0.05802, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:32.112, tt:1541.376\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.05858, lr:1.00e-02, fs:0.87273 (r=0.970,p=0.793),  time:32.110, tt:1573.400\n",
      "Ep:49, loss:0.00008, loss_test:0.05835, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:32.112, tt:1605.593\n",
      "Ep:50, loss:0.00008, loss_test:0.06131, lr:1.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:32.147, tt:1639.483\n",
      "Ep:51, loss:0.00008, loss_test:0.05307, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:32.125, tt:1670.493\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00008, loss_test:0.05244, lr:1.00e-02, fs:0.89720 (r=0.970,p=0.835),  time:32.131, tt:1702.931\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.05582, lr:1.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:32.130, tt:1734.994\n",
      "Ep:54, loss:0.00007, loss_test:0.05319, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:32.111, tt:1766.122\n",
      "Ep:55, loss:0.00006, loss_test:0.05376, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:32.103, tt:1797.790\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.05244, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:32.086, tt:1828.927\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.05423, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:32.063, tt:1859.660\n",
      "Ep:58, loss:0.00006, loss_test:0.05537, lr:1.00e-02, fs:0.89401 (r=0.980,p=0.822),  time:32.033, tt:1889.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00006, loss_test:0.05999, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:32.031, tt:1921.882\n",
      "Ep:60, loss:0.00006, loss_test:0.05259, lr:1.00e-02, fs:0.92000 (r=0.929,p=0.911),  time:32.008, tt:1952.519\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00006, loss_test:0.05315, lr:1.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:31.975, tt:1982.453\n",
      "Ep:62, loss:0.00005, loss_test:0.05152, lr:1.00e-02, fs:0.89899 (r=0.899,p=0.899),  time:31.958, tt:2013.328\n",
      "Ep:63, loss:0.00005, loss_test:0.05582, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:31.938, tt:2044.033\n",
      "Ep:64, loss:0.00005, loss_test:0.05685, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:31.926, tt:2075.204\n",
      "Ep:65, loss:0.00005, loss_test:0.05255, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:31.918, tt:2106.563\n",
      "Ep:66, loss:0.00005, loss_test:0.04772, lr:1.00e-02, fs:0.93333 (r=0.990,p=0.883),  time:31.909, tt:2137.883\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00005, loss_test:0.05441, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:31.913, tt:2170.058\n",
      "Ep:68, loss:0.00004, loss_test:0.05270, lr:1.00e-02, fs:0.89524 (r=0.949,p=0.847),  time:31.907, tt:2201.593\n",
      "Ep:69, loss:0.00004, loss_test:0.05241, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:31.895, tt:2232.639\n",
      "Ep:70, loss:0.00004, loss_test:0.06197, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:31.899, tt:2264.858\n",
      "Ep:71, loss:0.00004, loss_test:0.05272, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.882, tt:2295.530\n",
      "Ep:72, loss:0.00004, loss_test:0.06018, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:31.861, tt:2325.823\n",
      "Ep:73, loss:0.00004, loss_test:0.04962, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:31.846, tt:2356.626\n",
      "Ep:74, loss:0.00004, loss_test:0.05465, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:31.822, tt:2386.652\n",
      "Ep:75, loss:0.00003, loss_test:0.05780, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:31.784, tt:2415.612\n",
      "Ep:76, loss:0.00003, loss_test:0.05634, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:31.778, tt:2446.907\n",
      "Ep:77, loss:0.00004, loss_test:0.05558, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:31.767, tt:2477.831\n",
      "Ep:78, loss:0.00004, loss_test:0.05001, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:31.762, tt:2509.207\n",
      "Ep:79, loss:0.00003, loss_test:0.05976, lr:9.80e-03, fs:0.86829 (r=0.899,p=0.840),  time:31.775, tt:2541.995\n",
      "Ep:80, loss:0.00004, loss_test:0.06403, lr:9.70e-03, fs:0.85308 (r=0.909,p=0.804),  time:31.784, tt:2574.472\n",
      "Ep:81, loss:0.00005, loss_test:0.04816, lr:9.61e-03, fs:0.89593 (r=1.000,p=0.811),  time:31.787, tt:2606.525\n",
      "Ep:82, loss:0.00005, loss_test:0.05850, lr:9.51e-03, fs:0.90566 (r=0.970,p=0.850),  time:31.797, tt:2639.181\n",
      "Ep:83, loss:0.00004, loss_test:0.05100, lr:9.41e-03, fs:0.91005 (r=0.869,p=0.956),  time:31.809, tt:2671.920\n",
      "Ep:84, loss:0.00003, loss_test:0.05494, lr:9.32e-03, fs:0.89423 (r=0.939,p=0.853),  time:31.811, tt:2703.921\n",
      "Ep:85, loss:0.00003, loss_test:0.04813, lr:9.23e-03, fs:0.91707 (r=0.949,p=0.887),  time:31.818, tt:2736.348\n",
      "Ep:86, loss:0.00003, loss_test:0.05712, lr:9.14e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.841, tt:2770.131\n",
      "Ep:87, loss:0.00003, loss_test:0.05417, lr:9.04e-03, fs:0.89119 (r=0.869,p=0.915),  time:31.866, tt:2804.232\n",
      "Ep:88, loss:0.00003, loss_test:0.04545, lr:8.95e-03, fs:0.91429 (r=0.970,p=0.865),  time:31.884, tt:2837.633\n",
      "Ep:89, loss:0.00003, loss_test:0.04986, lr:8.86e-03, fs:0.90000 (r=0.909,p=0.891),  time:31.917, tt:2872.555\n",
      "Ep:90, loss:0.00003, loss_test:0.04719, lr:8.78e-03, fs:0.94000 (r=0.949,p=0.931),  time:31.945, tt:2906.967\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.05250, lr:8.78e-03, fs:0.86869 (r=0.869,p=0.869),  time:31.978, tt:2941.936\n",
      "Ep:92, loss:0.00002, loss_test:0.04908, lr:8.78e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.014, tt:2977.297\n",
      "Ep:93, loss:0.00002, loss_test:0.05060, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.084, tt:3015.862\n",
      "Ep:94, loss:0.00002, loss_test:0.05310, lr:8.78e-03, fs:0.85561 (r=0.808,p=0.909),  time:32.132, tt:3052.578\n",
      "Ep:95, loss:0.00002, loss_test:0.05080, lr:8.78e-03, fs:0.88542 (r=0.859,p=0.914),  time:32.172, tt:3088.543\n",
      "Ep:96, loss:0.00002, loss_test:0.05093, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:32.206, tt:3123.958\n",
      "Ep:97, loss:0.00002, loss_test:0.05223, lr:8.78e-03, fs:0.87234 (r=0.828,p=0.921),  time:32.244, tt:3159.941\n",
      "Ep:98, loss:0.00002, loss_test:0.04924, lr:8.78e-03, fs:0.90722 (r=0.889,p=0.926),  time:32.284, tt:3196.092\n",
      "Ep:99, loss:0.00002, loss_test:0.05244, lr:8.78e-03, fs:0.88083 (r=0.859,p=0.904),  time:32.294, tt:3229.352\n",
      "Ep:100, loss:0.00002, loss_test:0.04753, lr:8.78e-03, fs:0.91667 (r=0.889,p=0.946),  time:32.325, tt:3264.799\n",
      "Ep:101, loss:0.00002, loss_test:0.05143, lr:8.78e-03, fs:0.88421 (r=0.848,p=0.923),  time:32.369, tt:3301.668\n",
      "Ep:102, loss:0.00002, loss_test:0.05202, lr:8.69e-03, fs:0.87097 (r=0.818,p=0.931),  time:32.407, tt:3337.876\n",
      "Ep:103, loss:0.00002, loss_test:0.05420, lr:8.60e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.431, tt:3372.841\n",
      "Ep:104, loss:0.00002, loss_test:0.04753, lr:8.51e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.454, tt:3407.673\n",
      "Ep:105, loss:0.00002, loss_test:0.04959, lr:8.43e-03, fs:0.89583 (r=0.869,p=0.925),  time:32.475, tt:3442.320\n",
      "Ep:106, loss:0.00002, loss_test:0.05516, lr:8.35e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.492, tt:3476.614\n",
      "Ep:107, loss:0.00001, loss_test:0.05686, lr:8.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:32.516, tt:3511.762\n",
      "Ep:108, loss:0.00001, loss_test:0.04968, lr:8.18e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.538, tt:3546.621\n",
      "Ep:109, loss:0.00001, loss_test:0.05421, lr:8.10e-03, fs:0.85246 (r=0.788,p=0.929),  time:32.562, tt:3581.809\n",
      "Ep:110, loss:0.00001, loss_test:0.05138, lr:8.02e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.593, tt:3617.779\n",
      "Ep:111, loss:0.00001, loss_test:0.05243, lr:7.94e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.614, tt:3652.811\n",
      "Ep:112, loss:0.00001, loss_test:0.05290, lr:7.86e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.649, tt:3689.340\n",
      "Ep:113, loss:0.00001, loss_test:0.05441, lr:7.78e-03, fs:0.86486 (r=0.808,p=0.930),  time:32.677, tt:3725.234\n",
      "Ep:114, loss:0.00001, loss_test:0.04990, lr:7.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:32.697, tt:3760.195\n",
      "Ep:115, loss:0.00001, loss_test:0.05426, lr:7.62e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.716, tt:3795.018\n",
      "Ep:116, loss:0.00001, loss_test:0.05591, lr:7.55e-03, fs:0.84270 (r=0.758,p=0.949),  time:32.732, tt:3829.636\n",
      "Ep:117, loss:0.00001, loss_test:0.05007, lr:7.47e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.748, tt:3864.298\n",
      "Ep:118, loss:0.00001, loss_test:0.05259, lr:7.40e-03, fs:0.86957 (r=0.808,p=0.941),  time:32.783, tt:3901.203\n",
      "Ep:119, loss:0.00001, loss_test:0.05400, lr:7.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:32.808, tt:3936.908\n",
      "Ep:120, loss:0.00001, loss_test:0.05377, lr:7.25e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.835, tt:3972.987\n",
      "Ep:121, loss:0.00001, loss_test:0.05432, lr:7.18e-03, fs:0.86188 (r=0.788,p=0.951),  time:32.855, tt:4008.299\n",
      "Ep:122, loss:0.00001, loss_test:0.05312, lr:7.11e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.881, tt:4044.335\n",
      "Ep:123, loss:0.00001, loss_test:0.05260, lr:7.03e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.909, tt:4080.679\n",
      "Ep:124, loss:0.00001, loss_test:0.05605, lr:6.96e-03, fs:0.85870 (r=0.798,p=0.929),  time:32.938, tt:4117.270\n",
      "Ep:125, loss:0.00001, loss_test:0.05684, lr:6.89e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.955, tt:4152.272\n",
      "Ep:126, loss:0.00001, loss_test:0.05518, lr:6.83e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.974, tt:4187.725\n",
      "Ep:127, loss:0.00001, loss_test:0.05281, lr:6.76e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.979, tt:4221.317\n",
      "Ep:128, loss:0.00001, loss_test:0.05387, lr:6.69e-03, fs:0.86339 (r=0.798,p=0.940),  time:32.987, tt:4255.342\n",
      "Ep:129, loss:0.00001, loss_test:0.05344, lr:6.62e-03, fs:0.88172 (r=0.828,p=0.943),  time:33.001, tt:4290.174\n",
      "Ep:130, loss:0.00001, loss_test:0.05415, lr:6.56e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.025, tt:4326.258\n",
      "Ep:131, loss:0.00001, loss_test:0.05536, lr:6.49e-03, fs:0.87432 (r=0.808,p=0.952),  time:33.038, tt:4361.079\n",
      "Ep:132, loss:0.00001, loss_test:0.05524, lr:6.43e-03, fs:0.87097 (r=0.818,p=0.931),  time:33.056, tt:4396.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:133, loss:0.00001, loss_test:0.05353, lr:6.36e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.064, tt:4430.578\n",
      "Ep:134, loss:0.00001, loss_test:0.05410, lr:6.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.067, tt:4464.110\n",
      "Ep:135, loss:0.00001, loss_test:0.05598, lr:6.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.071, tt:4497.650\n",
      "Ep:136, loss:0.00001, loss_test:0.05453, lr:6.17e-03, fs:0.87432 (r=0.808,p=0.952),  time:33.073, tt:4530.935\n",
      "Ep:137, loss:0.00001, loss_test:0.05490, lr:6.11e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.082, tt:4565.325\n",
      "Ep:138, loss:0.00001, loss_test:0.05649, lr:6.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.100, tt:4600.883\n",
      "Ep:139, loss:0.00001, loss_test:0.05658, lr:5.99e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.110, tt:4635.352\n",
      "Ep:140, loss:0.00001, loss_test:0.05591, lr:5.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.122, tt:4670.251\n",
      "Ep:141, loss:0.00001, loss_test:0.05512, lr:5.87e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.132, tt:4704.744\n",
      "Ep:142, loss:0.00001, loss_test:0.05697, lr:5.81e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.147, tt:4739.949\n",
      "Ep:143, loss:0.00001, loss_test:0.05739, lr:5.75e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.159, tt:4774.885\n",
      "Ep:144, loss:0.00001, loss_test:0.05553, lr:5.70e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.179, tt:4810.888\n",
      "Ep:145, loss:0.00001, loss_test:0.05647, lr:5.64e-03, fs:0.86339 (r=0.798,p=0.940),  time:33.196, tt:4846.545\n",
      "Ep:146, loss:0.00001, loss_test:0.05715, lr:5.58e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.210, tt:4881.926\n",
      "Ep:147, loss:0.00001, loss_test:0.05585, lr:5.53e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.221, tt:4916.638\n",
      "Ep:148, loss:0.00001, loss_test:0.05773, lr:5.47e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.234, tt:4951.832\n",
      "Ep:149, loss:0.00001, loss_test:0.05816, lr:5.42e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.248, tt:4987.143\n",
      "Ep:150, loss:0.00001, loss_test:0.05622, lr:5.36e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.264, tt:5022.861\n",
      "Ep:151, loss:0.00001, loss_test:0.05626, lr:5.31e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.271, tt:5057.150\n",
      "Ep:152, loss:0.00000, loss_test:0.05788, lr:5.26e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.284, tt:5092.382\n",
      "Ep:153, loss:0.00000, loss_test:0.05637, lr:5.20e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.287, tt:5126.186\n",
      "Ep:154, loss:0.00000, loss_test:0.05611, lr:5.15e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.293, tt:5160.366\n",
      "Ep:155, loss:0.00000, loss_test:0.05661, lr:5.10e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.298, tt:5194.456\n",
      "Ep:156, loss:0.00000, loss_test:0.05680, lr:5.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.304, tt:5228.709\n",
      "Ep:157, loss:0.00000, loss_test:0.05613, lr:5.00e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.309, tt:5262.857\n",
      "Ep:158, loss:0.00000, loss_test:0.05795, lr:4.95e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.316, tt:5297.229\n",
      "Ep:159, loss:0.00001, loss_test:0.05693, lr:4.90e-03, fs:0.87432 (r=0.808,p=0.952),  time:33.317, tt:5330.742\n",
      "Ep:160, loss:0.00001, loss_test:0.05730, lr:4.85e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.323, tt:5365.022\n",
      "Ep:161, loss:0.00000, loss_test:0.05706, lr:4.80e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.324, tt:5398.466\n",
      "Ep:162, loss:0.00000, loss_test:0.05602, lr:4.75e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.332, tt:5433.051\n",
      "Ep:163, loss:0.00000, loss_test:0.05746, lr:4.71e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.327, tt:5465.687\n",
      "Ep:164, loss:0.00000, loss_test:0.05777, lr:4.66e-03, fs:0.86188 (r=0.788,p=0.951),  time:33.337, tt:5500.534\n",
      "Ep:165, loss:0.00000, loss_test:0.05678, lr:4.61e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.344, tt:5535.146\n",
      "Ep:166, loss:0.00000, loss_test:0.05716, lr:4.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.346, tt:5568.846\n",
      "Ep:167, loss:0.00000, loss_test:0.05747, lr:4.52e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.353, tt:5603.234\n",
      "Ep:168, loss:0.00000, loss_test:0.05685, lr:4.48e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.359, tt:5637.721\n",
      "Ep:169, loss:0.00000, loss_test:0.05702, lr:4.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.358, tt:5670.887\n",
      "Ep:170, loss:0.00000, loss_test:0.05681, lr:4.39e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.360, tt:5704.475\n",
      "Ep:171, loss:0.00000, loss_test:0.05684, lr:4.34e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.365, tt:5738.865\n",
      "Ep:172, loss:0.00000, loss_test:0.05825, lr:4.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.376, tt:5773.961\n",
      "Ep:173, loss:0.00000, loss_test:0.05708, lr:4.26e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.376, tt:5807.361\n",
      "Ep:174, loss:0.00000, loss_test:0.05747, lr:4.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.382, tt:5841.782\n",
      "Ep:175, loss:0.00000, loss_test:0.05841, lr:4.17e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.406, tt:5879.413\n",
      "Ep:176, loss:0.00000, loss_test:0.05831, lr:4.13e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.417, tt:5914.852\n",
      "Ep:177, loss:0.00000, loss_test:0.05566, lr:4.09e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.426, tt:5949.838\n",
      "Ep:178, loss:0.00000, loss_test:0.05823, lr:4.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.428, tt:5983.610\n",
      "Ep:179, loss:0.00000, loss_test:0.05923, lr:4.01e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.432, tt:6017.809\n",
      "Ep:180, loss:0.00000, loss_test:0.05807, lr:3.97e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.434, tt:6051.572\n",
      "Ep:181, loss:0.00000, loss_test:0.05642, lr:3.93e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.439, tt:6085.871\n",
      "Ep:182, loss:0.00000, loss_test:0.05756, lr:3.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.446, tt:6120.538\n",
      "Ep:183, loss:0.00000, loss_test:0.05882, lr:3.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.449, tt:6154.686\n",
      "Ep:184, loss:0.00000, loss_test:0.05780, lr:3.81e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.462, tt:6190.402\n",
      "Ep:185, loss:0.00000, loss_test:0.05769, lr:3.77e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.463, tt:6224.189\n",
      "Ep:186, loss:0.00000, loss_test:0.05807, lr:3.73e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.476, tt:6260.064\n",
      "Ep:187, loss:0.00000, loss_test:0.05781, lr:3.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.484, tt:6294.952\n",
      "Ep:188, loss:0.00000, loss_test:0.05674, lr:3.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.481, tt:6327.956\n",
      "Ep:189, loss:0.00000, loss_test:0.05666, lr:3.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.490, tt:6363.152\n",
      "Ep:190, loss:0.00000, loss_test:0.05750, lr:3.59e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.493, tt:6397.209\n",
      "Ep:191, loss:0.00000, loss_test:0.05758, lr:3.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.499, tt:6431.798\n",
      "Ep:192, loss:0.00000, loss_test:0.05664, lr:3.52e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.494, tt:6464.339\n",
      "Ep:193, loss:0.00000, loss_test:0.05687, lr:3.48e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.500, tt:6499.065\n",
      "Ep:194, loss:0.00000, loss_test:0.05741, lr:3.45e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.528, tt:6537.951\n",
      "Ep:195, loss:0.00000, loss_test:0.05814, lr:3.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.541, tt:6574.071\n",
      "Ep:196, loss:0.00000, loss_test:0.05735, lr:3.38e-03, fs:0.85714 (r=0.788,p=0.940),  time:33.542, tt:6607.845\n",
      "Ep:197, loss:0.00000, loss_test:0.05732, lr:3.34e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.543, tt:6641.556\n",
      "Ep:198, loss:0.00000, loss_test:0.05753, lr:3.31e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.545, tt:6675.432\n",
      "Ep:199, loss:0.00000, loss_test:0.05797, lr:3.28e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.548, tt:6709.596\n",
      "Ep:200, loss:0.00000, loss_test:0.05774, lr:3.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.562, tt:6745.949\n",
      "Ep:201, loss:0.00000, loss_test:0.05689, lr:3.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.562, tt:6779.592\n",
      "Ep:202, loss:0.00000, loss_test:0.05775, lr:3.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.556, tt:6811.929\n",
      "Ep:203, loss:0.00000, loss_test:0.05791, lr:3.15e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.557, tt:6845.596\n",
      "Ep:204, loss:0.00000, loss_test:0.05767, lr:3.12e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.532, tt:6873.991\n",
      "Ep:205, loss:0.00000, loss_test:0.05693, lr:3.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.491, tt:6899.215\n",
      "Ep:206, loss:0.00000, loss_test:0.05681, lr:3.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:33.469, tt:6928.025\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02315, lr:6.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:28.326, tt:28.326\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02605, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:29.747, tt:59.494\n",
      "Ep:2, loss:0.00005, loss_test:0.02834, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.255, tt:93.765\n",
      "Ep:3, loss:0.00005, loss_test:0.02835, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:32.031, tt:128.125\n",
      "Ep:4, loss:0.00005, loss_test:0.02753, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:32.157, tt:160.783\n",
      "Ep:5, loss:0.00005, loss_test:0.02646, lr:6.00e-02, fs:0.64286 (r=0.909,p=0.497),  time:32.372, tt:194.234\n",
      "Ep:6, loss:0.00005, loss_test:0.02587, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:32.345, tt:226.418\n",
      "Ep:7, loss:0.00005, loss_test:0.02535, lr:6.00e-02, fs:0.65918 (r=0.889,p=0.524),  time:32.458, tt:259.662\n",
      "Ep:8, loss:0.00005, loss_test:0.02487, lr:6.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:32.547, tt:292.922\n",
      "Ep:9, loss:0.00005, loss_test:0.02467, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:32.732, tt:327.323\n",
      "Ep:10, loss:0.00005, loss_test:0.02456, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:32.665, tt:359.320\n",
      "Ep:11, loss:0.00005, loss_test:0.02411, lr:6.00e-02, fs:0.64964 (r=0.899,p=0.509),  time:32.564, tt:390.766\n",
      "Ep:12, loss:0.00005, loss_test:0.02346, lr:5.94e-02, fs:0.64964 (r=0.899,p=0.509),  time:32.584, tt:423.598\n",
      "Ep:13, loss:0.00005, loss_test:0.02275, lr:5.88e-02, fs:0.66171 (r=0.899,p=0.524),  time:32.622, tt:456.709\n",
      "Ep:14, loss:0.00005, loss_test:0.02217, lr:5.82e-02, fs:0.67170 (r=0.899,p=0.536),  time:32.609, tt:489.136\n",
      "Ep:15, loss:0.00004, loss_test:0.02173, lr:5.76e-02, fs:0.67416 (r=0.909,p=0.536),  time:32.681, tt:522.900\n",
      "Ep:16, loss:0.00004, loss_test:0.02138, lr:5.71e-02, fs:0.66667 (r=0.909,p=0.526),  time:32.719, tt:556.227\n",
      "Ep:17, loss:0.00004, loss_test:0.02102, lr:5.65e-02, fs:0.68165 (r=0.919,p=0.542),  time:32.797, tt:590.343\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.02074, lr:5.65e-02, fs:0.66923 (r=0.879,p=0.540),  time:32.736, tt:621.986\n",
      "Ep:19, loss:0.00004, loss_test:0.02063, lr:5.65e-02, fs:0.67704 (r=0.879,p=0.551),  time:32.757, tt:655.142\n",
      "Ep:20, loss:0.00004, loss_test:0.02049, lr:5.65e-02, fs:0.68199 (r=0.899,p=0.549),  time:32.813, tt:689.074\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.02039, lr:5.65e-02, fs:0.67170 (r=0.899,p=0.536),  time:32.871, tt:723.160\n",
      "Ep:22, loss:0.00004, loss_test:0.02018, lr:5.65e-02, fs:0.67170 (r=0.899,p=0.536),  time:32.921, tt:757.182\n",
      "Ep:23, loss:0.00004, loss_test:0.01989, lr:5.65e-02, fs:0.66667 (r=0.889,p=0.533),  time:32.962, tt:791.080\n",
      "Ep:24, loss:0.00004, loss_test:0.01960, lr:5.65e-02, fs:0.67692 (r=0.889,p=0.547),  time:32.962, tt:824.050\n",
      "Ep:25, loss:0.00004, loss_test:0.01930, lr:5.65e-02, fs:0.67692 (r=0.889,p=0.547),  time:33.009, tt:858.241\n",
      "Ep:26, loss:0.00004, loss_test:0.01898, lr:5.65e-02, fs:0.67442 (r=0.879,p=0.547),  time:33.076, tt:893.041\n",
      "Ep:27, loss:0.00004, loss_test:0.01869, lr:5.65e-02, fs:0.69261 (r=0.899,p=0.563),  time:33.134, tt:927.744\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00004, loss_test:0.01846, lr:5.65e-02, fs:0.69020 (r=0.889,p=0.564),  time:33.190, tt:962.522\n",
      "Ep:29, loss:0.00004, loss_test:0.01822, lr:5.65e-02, fs:0.69020 (r=0.889,p=0.564),  time:33.175, tt:995.248\n",
      "Ep:30, loss:0.00003, loss_test:0.01793, lr:5.65e-02, fs:0.69804 (r=0.899,p=0.571),  time:33.209, tt:1029.478\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01765, lr:5.65e-02, fs:0.70588 (r=0.909,p=0.577),  time:33.228, tt:1063.288\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01738, lr:5.65e-02, fs:0.71373 (r=0.919,p=0.583),  time:33.276, tt:1098.104\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01707, lr:5.65e-02, fs:0.71429 (r=0.909,p=0.588),  time:33.308, tt:1132.485\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01687, lr:5.65e-02, fs:0.71713 (r=0.909,p=0.592),  time:33.352, tt:1167.326\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01665, lr:5.65e-02, fs:0.71713 (r=0.909,p=0.592),  time:33.387, tt:1201.930\n",
      "Ep:36, loss:0.00003, loss_test:0.01646, lr:5.65e-02, fs:0.71937 (r=0.919,p=0.591),  time:33.441, tt:1237.309\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01626, lr:5.65e-02, fs:0.73684 (r=0.919,p=0.615),  time:33.454, tt:1271.269\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01612, lr:5.65e-02, fs:0.72874 (r=0.909,p=0.608),  time:33.497, tt:1306.400\n",
      "Ep:39, loss:0.00003, loss_test:0.01596, lr:5.65e-02, fs:0.73469 (r=0.909,p=0.616),  time:33.553, tt:1342.122\n",
      "Ep:40, loss:0.00003, loss_test:0.01571, lr:5.65e-02, fs:0.74286 (r=0.919,p=0.623),  time:33.575, tt:1376.592\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01550, lr:5.65e-02, fs:0.74897 (r=0.919,p=0.632),  time:33.620, tt:1412.043\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01534, lr:5.65e-02, fs:0.74380 (r=0.909,p=0.629),  time:33.634, tt:1446.264\n",
      "Ep:43, loss:0.00003, loss_test:0.01523, lr:5.65e-02, fs:0.75000 (r=0.909,p=0.638),  time:33.616, tt:1479.095\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01508, lr:5.65e-02, fs:0.75949 (r=0.909,p=0.652),  time:33.620, tt:1512.889\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01487, lr:5.65e-02, fs:0.76987 (r=0.929,p=0.657),  time:33.634, tt:1547.148\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01475, lr:5.65e-02, fs:0.76596 (r=0.909,p=0.662),  time:33.627, tt:1580.480\n",
      "Ep:47, loss:0.00002, loss_test:0.01456, lr:5.65e-02, fs:0.76987 (r=0.929,p=0.657),  time:33.660, tt:1615.668\n",
      "Ep:48, loss:0.00002, loss_test:0.01445, lr:5.65e-02, fs:0.76596 (r=0.909,p=0.662),  time:33.685, tt:1650.553\n",
      "Ep:49, loss:0.00002, loss_test:0.01442, lr:5.65e-02, fs:0.77586 (r=0.909,p=0.677),  time:33.715, tt:1685.746\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01423, lr:5.65e-02, fs:0.77637 (r=0.929,p=0.667),  time:33.692, tt:1718.301\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01417, lr:5.65e-02, fs:0.79310 (r=0.929,p=0.692),  time:33.709, tt:1752.862\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01411, lr:5.65e-02, fs:0.78298 (r=0.929,p=0.676),  time:33.715, tt:1786.900\n",
      "Ep:53, loss:0.00002, loss_test:0.01415, lr:5.65e-02, fs:0.79310 (r=0.929,p=0.692),  time:33.725, tt:1821.162\n",
      "Ep:54, loss:0.00002, loss_test:0.01406, lr:5.65e-02, fs:0.78632 (r=0.929,p=0.681),  time:33.759, tt:1856.746\n",
      "Ep:55, loss:0.00002, loss_test:0.01411, lr:5.65e-02, fs:0.79295 (r=0.909,p=0.703),  time:33.827, tt:1894.308\n",
      "Ep:56, loss:0.00002, loss_test:0.01387, lr:5.65e-02, fs:0.78632 (r=0.929,p=0.681),  time:33.831, tt:1928.348\n",
      "Ep:57, loss:0.00002, loss_test:0.01399, lr:5.65e-02, fs:0.79111 (r=0.899,p=0.706),  time:33.863, tt:1964.052\n",
      "Ep:58, loss:0.00002, loss_test:0.01397, lr:5.65e-02, fs:0.77119 (r=0.919,p=0.664),  time:33.887, tt:1999.355\n",
      "Ep:59, loss:0.00002, loss_test:0.01368, lr:5.65e-02, fs:0.79464 (r=0.899,p=0.712),  time:33.911, tt:2034.636\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.01368, lr:5.65e-02, fs:0.78603 (r=0.909,p=0.692),  time:33.906, tt:2068.265\n",
      "Ep:61, loss:0.00002, loss_test:0.01377, lr:5.65e-02, fs:0.79638 (r=0.889,p=0.721),  time:33.920, tt:2103.047\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00002, loss_test:0.01361, lr:5.65e-02, fs:0.78924 (r=0.889,p=0.710),  time:33.937, tt:2138.000\n",
      "Ep:63, loss:0.00002, loss_test:0.01377, lr:5.65e-02, fs:0.77729 (r=0.899,p=0.685),  time:33.921, tt:2170.972\n",
      "Ep:64, loss:0.00002, loss_test:0.01340, lr:5.65e-02, fs:0.79821 (r=0.899,p=0.718),  time:33.938, tt:2205.980\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01342, lr:5.65e-02, fs:0.80909 (r=0.899,p=0.736),  time:33.955, tt:2241.049\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01387, lr:5.65e-02, fs:0.78414 (r=0.899,p=0.695),  time:33.948, tt:2274.498\n",
      "Ep:67, loss:0.00002, loss_test:0.01368, lr:5.65e-02, fs:0.81279 (r=0.899,p=0.742),  time:33.962, tt:2309.383\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.01385, lr:5.65e-02, fs:0.80543 (r=0.899,p=0.730),  time:33.969, tt:2343.853\n",
      "Ep:69, loss:0.00001, loss_test:0.01369, lr:5.65e-02, fs:0.78448 (r=0.919,p=0.684),  time:33.996, tt:2379.749\n",
      "Ep:70, loss:0.00001, loss_test:0.01370, lr:5.65e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.024, tt:2415.697\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01357, lr:5.65e-02, fs:0.79279 (r=0.889,p=0.715),  time:34.049, tt:2451.524\n",
      "Ep:72, loss:0.00001, loss_test:0.01310, lr:5.65e-02, fs:0.80180 (r=0.899,p=0.724),  time:34.052, tt:2485.806\n",
      "Ep:73, loss:0.00001, loss_test:0.01339, lr:5.65e-02, fs:0.80734 (r=0.889,p=0.739),  time:34.052, tt:2519.865\n",
      "Ep:74, loss:0.00001, loss_test:0.01367, lr:5.65e-02, fs:0.79817 (r=0.879,p=0.731),  time:34.055, tt:2554.089\n",
      "Ep:75, loss:0.00001, loss_test:0.01368, lr:5.65e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.080, tt:2590.072\n",
      "Ep:76, loss:0.00001, loss_test:0.01346, lr:5.65e-02, fs:0.80184 (r=0.879,p=0.737),  time:34.090, tt:2624.910\n",
      "Ep:77, loss:0.00001, loss_test:0.01381, lr:5.65e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.106, tt:2660.257\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01376, lr:5.65e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.102, tt:2694.059\n",
      "Ep:79, loss:0.00001, loss_test:0.01378, lr:5.65e-02, fs:0.82243 (r=0.889,p=0.765),  time:34.105, tt:2728.400\n",
      "Ep:80, loss:0.00001, loss_test:0.01412, lr:5.65e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.096, tt:2761.811\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01420, lr:5.65e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.094, tt:2795.739\n",
      "Ep:82, loss:0.00001, loss_test:0.01391, lr:5.65e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.095, tt:2829.922\n",
      "Ep:83, loss:0.00001, loss_test:0.01459, lr:5.65e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.065, tt:2861.432\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01423, lr:5.65e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.082, tt:2896.956\n",
      "Ep:85, loss:0.00001, loss_test:0.01433, lr:5.65e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.131, tt:2935.282\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01441, lr:5.65e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.127, tt:2969.047\n",
      "Ep:87, loss:0.00001, loss_test:0.01441, lr:5.65e-02, fs:0.81340 (r=0.859,p=0.773),  time:34.133, tt:3003.709\n",
      "Ep:88, loss:0.00001, loss_test:0.01379, lr:5.65e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.118, tt:3036.502\n",
      "Ep:89, loss:0.00001, loss_test:0.01398, lr:5.65e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.131, tt:3071.814\n",
      "Ep:90, loss:0.00001, loss_test:0.01422, lr:5.65e-02, fs:0.81731 (r=0.859,p=0.780),  time:34.130, tt:3105.802\n",
      "Ep:91, loss:0.00001, loss_test:0.01386, lr:5.65e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.120, tt:3139.081\n",
      "Ep:92, loss:0.00001, loss_test:0.01395, lr:5.65e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.104, tt:3171.631\n",
      "Ep:93, loss:0.00001, loss_test:0.01357, lr:5.65e-02, fs:0.83178 (r=0.899,p=0.774),  time:34.097, tt:3205.124\n",
      "Ep:94, loss:0.00001, loss_test:0.01420, lr:5.65e-02, fs:0.82791 (r=0.899,p=0.767),  time:34.091, tt:3238.672\n",
      "Ep:95, loss:0.00001, loss_test:0.01396, lr:5.65e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.096, tt:3273.200\n",
      "Ep:96, loss:0.00001, loss_test:0.01591, lr:5.65e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.084, tt:3306.102\n",
      "Ep:97, loss:0.00001, loss_test:0.01551, lr:5.59e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.078, tt:3339.604\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01554, lr:5.59e-02, fs:0.82524 (r=0.859,p=0.794),  time:34.078, tt:3373.672\n",
      "Ep:99, loss:0.00001, loss_test:0.01552, lr:5.59e-02, fs:0.85024 (r=0.889,p=0.815),  time:34.078, tt:3407.777\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01587, lr:5.59e-02, fs:0.84878 (r=0.879,p=0.821),  time:34.108, tt:3444.948\n",
      "Ep:101, loss:0.00001, loss_test:0.01541, lr:5.59e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.117, tt:3479.907\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.01558, lr:5.59e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.105, tt:3512.818\n",
      "Ep:103, loss:0.00001, loss_test:0.01653, lr:5.59e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.104, tt:3546.830\n",
      "Ep:104, loss:0.00001, loss_test:0.01593, lr:5.59e-02, fs:0.86408 (r=0.899,p=0.832),  time:34.104, tt:3580.961\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01658, lr:5.59e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.103, tt:3614.917\n",
      "Ep:106, loss:0.00001, loss_test:0.01652, lr:5.59e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.117, tt:3650.513\n",
      "Ep:107, loss:0.00001, loss_test:0.01721, lr:5.59e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.118, tt:3684.789\n",
      "Ep:108, loss:0.00001, loss_test:0.01653, lr:5.59e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.112, tt:3718.181\n",
      "Ep:109, loss:0.00000, loss_test:0.01672, lr:5.59e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.117, tt:3752.894\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00000, loss_test:0.01732, lr:5.59e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.113, tt:3786.535\n",
      "Ep:111, loss:0.00000, loss_test:0.01731, lr:5.59e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.115, tt:3820.867\n",
      "Ep:112, loss:0.00001, loss_test:0.01665, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.118, tt:3855.300\n",
      "Ep:113, loss:0.00001, loss_test:0.01685, lr:5.59e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.109, tt:3888.416\n",
      "Ep:114, loss:0.00000, loss_test:0.01650, lr:5.59e-02, fs:0.85024 (r=0.889,p=0.815),  time:34.106, tt:3922.244\n",
      "Ep:115, loss:0.00000, loss_test:0.01712, lr:5.59e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.104, tt:3956.121\n",
      "Ep:116, loss:0.00000, loss_test:0.01739, lr:5.59e-02, fs:0.86408 (r=0.899,p=0.832),  time:34.097, tt:3989.302\n",
      "Ep:117, loss:0.00000, loss_test:0.01777, lr:5.59e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.095, tt:4023.163\n",
      "Ep:118, loss:0.00000, loss_test:0.01752, lr:5.59e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.087, tt:4056.352\n",
      "Ep:119, loss:0.00000, loss_test:0.01766, lr:5.59e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.084, tt:4090.141\n",
      "Ep:120, loss:0.00000, loss_test:0.01800, lr:5.59e-02, fs:0.83744 (r=0.859,p=0.817),  time:34.083, tt:4124.049\n",
      "Ep:121, loss:0.00000, loss_test:0.01830, lr:5.54e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.074, tt:4157.047\n",
      "Ep:122, loss:0.00000, loss_test:0.01736, lr:5.48e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.071, tt:4190.671\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01766, lr:5.48e-02, fs:0.81443 (r=0.798,p=0.832),  time:34.066, tt:4224.176\n",
      "Ep:124, loss:0.00000, loss_test:0.01790, lr:5.48e-02, fs:0.85294 (r=0.879,p=0.829),  time:34.071, tt:4258.888\n",
      "Ep:125, loss:0.00000, loss_test:0.01726, lr:5.48e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.075, tt:4293.455\n",
      "Ep:126, loss:0.00000, loss_test:0.01779, lr:5.48e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.074, tt:4327.447\n",
      "Ep:127, loss:0.00000, loss_test:0.01817, lr:5.48e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.071, tt:4361.112\n",
      "Ep:128, loss:0.00000, loss_test:0.01831, lr:5.48e-02, fs:0.81188 (r=0.828,p=0.796),  time:34.062, tt:4393.960\n",
      "Ep:129, loss:0.00000, loss_test:0.01788, lr:5.48e-02, fs:0.82051 (r=0.808,p=0.833),  time:34.051, tt:4426.680\n",
      "Ep:130, loss:0.00000, loss_test:0.01743, lr:5.48e-02, fs:0.84577 (r=0.859,p=0.833),  time:34.047, tt:4460.120\n",
      "Ep:131, loss:0.00000, loss_test:0.01894, lr:5.48e-02, fs:0.84878 (r=0.879,p=0.821),  time:34.044, tt:4493.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01772, lr:5.48e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.044, tt:4527.790\n",
      "Ep:133, loss:0.00000, loss_test:0.01761, lr:5.48e-02, fs:0.79793 (r=0.778,p=0.819),  time:34.046, tt:4562.118\n",
      "Ep:134, loss:0.00000, loss_test:0.01721, lr:5.43e-02, fs:0.84158 (r=0.859,p=0.825),  time:34.050, tt:4596.688\n",
      "Ep:135, loss:0.00000, loss_test:0.01855, lr:5.37e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.040, tt:4629.383\n",
      "Ep:136, loss:0.00000, loss_test:0.01817, lr:5.32e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.033, tt:4662.483\n",
      "Ep:137, loss:0.00000, loss_test:0.01913, lr:5.27e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.023, tt:4695.221\n",
      "Ep:138, loss:0.00000, loss_test:0.01886, lr:5.21e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.014, tt:4728.006\n",
      "Ep:139, loss:0.00000, loss_test:0.01866, lr:5.16e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.010, tt:4761.336\n",
      "Ep:140, loss:0.00000, loss_test:0.01916, lr:5.11e-02, fs:0.81283 (r=0.768,p=0.864),  time:34.009, tt:4795.208\n",
      "Ep:141, loss:0.00000, loss_test:0.01979, lr:5.06e-02, fs:0.78689 (r=0.727,p=0.857),  time:34.005, tt:4828.728\n",
      "Ep:142, loss:0.00000, loss_test:0.01967, lr:5.01e-02, fs:0.80000 (r=0.747,p=0.860),  time:33.993, tt:4860.984\n",
      "Ep:143, loss:0.00000, loss_test:0.02000, lr:4.96e-02, fs:0.78022 (r=0.717,p=0.855),  time:33.986, tt:4893.924\n",
      "Ep:144, loss:0.00000, loss_test:0.01999, lr:4.91e-02, fs:0.79781 (r=0.737,p=0.869),  time:33.981, tt:4927.216\n",
      "Ep:145, loss:0.00000, loss_test:0.02037, lr:4.86e-02, fs:0.77778 (r=0.707,p=0.864),  time:33.975, tt:4960.293\n",
      "Ep:146, loss:0.00000, loss_test:0.02022, lr:4.81e-02, fs:0.76667 (r=0.697,p=0.852),  time:33.974, tt:4994.217\n",
      "Ep:147, loss:0.00000, loss_test:0.02063, lr:4.76e-02, fs:0.75429 (r=0.667,p=0.868),  time:33.969, tt:5027.363\n",
      "Ep:148, loss:0.00000, loss_test:0.02049, lr:4.71e-02, fs:0.77095 (r=0.697,p=0.863),  time:33.969, tt:5061.404\n",
      "Ep:149, loss:0.00000, loss_test:0.02053, lr:4.67e-02, fs:0.75429 (r=0.667,p=0.868),  time:33.969, tt:5095.322\n",
      "Ep:150, loss:0.00000, loss_test:0.02093, lr:4.62e-02, fs:0.77095 (r=0.697,p=0.863),  time:33.966, tt:5128.937\n",
      "Ep:151, loss:0.00000, loss_test:0.02139, lr:4.57e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.949, tt:5160.193\n",
      "Ep:152, loss:0.00000, loss_test:0.02090, lr:4.53e-02, fs:0.75429 (r=0.667,p=0.868),  time:33.941, tt:5193.007\n",
      "Ep:153, loss:0.00000, loss_test:0.02171, lr:4.48e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.935, tt:5225.919\n",
      "Ep:154, loss:0.00000, loss_test:0.02154, lr:4.44e-02, fs:0.76404 (r=0.687,p=0.861),  time:33.935, tt:5259.994\n",
      "Ep:155, loss:0.00000, loss_test:0.02151, lr:4.39e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.920, tt:5291.584\n",
      "Ep:156, loss:0.00000, loss_test:0.02137, lr:4.35e-02, fs:0.73684 (r=0.636,p=0.875),  time:33.912, tt:5324.182\n",
      "Ep:157, loss:0.00000, loss_test:0.02150, lr:4.31e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.908, tt:5357.449\n",
      "Ep:158, loss:0.00000, loss_test:0.02181, lr:4.26e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.900, tt:5390.095\n",
      "Ep:159, loss:0.00000, loss_test:0.02150, lr:4.22e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.889, tt:5422.248\n",
      "Ep:160, loss:0.00000, loss_test:0.02198, lr:4.18e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.883, tt:5455.185\n",
      "Ep:161, loss:0.00000, loss_test:0.02246, lr:4.14e-02, fs:0.76301 (r=0.667,p=0.892),  time:33.882, tt:5488.942\n",
      "Ep:162, loss:0.00000, loss_test:0.02167, lr:4.10e-02, fs:0.72093 (r=0.626,p=0.849),  time:33.880, tt:5522.494\n",
      "Ep:163, loss:0.00000, loss_test:0.02201, lr:4.05e-02, fs:0.76301 (r=0.667,p=0.892),  time:33.886, tt:5557.356\n",
      "Ep:164, loss:0.00000, loss_test:0.02196, lr:4.01e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.888, tt:5591.449\n",
      "Ep:165, loss:0.00000, loss_test:0.02165, lr:3.97e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.891, tt:5625.976\n",
      "Ep:166, loss:0.00000, loss_test:0.02211, lr:3.93e-02, fs:0.76301 (r=0.667,p=0.892),  time:33.886, tt:5659.029\n",
      "Ep:167, loss:0.00000, loss_test:0.02242, lr:3.89e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.886, tt:5692.796\n",
      "Ep:168, loss:0.00000, loss_test:0.02218, lr:3.86e-02, fs:0.73988 (r=0.646,p=0.865),  time:33.887, tt:5726.903\n",
      "Ep:169, loss:0.00000, loss_test:0.02262, lr:3.82e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.890, tt:5761.338\n",
      "Ep:170, loss:0.00000, loss_test:0.02282, lr:3.78e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.893, tt:5795.757\n",
      "Ep:171, loss:0.00000, loss_test:0.02273, lr:3.74e-02, fs:0.75862 (r=0.667,p=0.880),  time:33.902, tt:5831.109\n",
      "Ep:172, loss:0.00000, loss_test:0.02277, lr:3.70e-02, fs:0.75145 (r=0.657,p=0.878),  time:33.901, tt:5864.883\n",
      "Ep:173, loss:0.00000, loss_test:0.02317, lr:3.67e-02, fs:0.76301 (r=0.667,p=0.892),  time:33.914, tt:5900.976\n",
      "Ep:174, loss:0.00000, loss_test:0.02284, lr:3.63e-02, fs:0.74419 (r=0.646,p=0.877),  time:33.910, tt:5934.222\n",
      "Ep:175, loss:0.00000, loss_test:0.02298, lr:3.59e-02, fs:0.75145 (r=0.657,p=0.878),  time:33.908, tt:5967.770\n",
      "Ep:176, loss:0.00000, loss_test:0.02331, lr:3.56e-02, fs:0.76744 (r=0.667,p=0.904),  time:33.907, tt:6001.483\n",
      "Ep:177, loss:0.00000, loss_test:0.02318, lr:3.52e-02, fs:0.75581 (r=0.657,p=0.890),  time:33.914, tt:6036.673\n",
      "Ep:178, loss:0.00000, loss_test:0.02309, lr:3.49e-02, fs:0.74419 (r=0.646,p=0.877),  time:33.905, tt:6068.945\n",
      "Ep:179, loss:0.00000, loss_test:0.02349, lr:3.45e-02, fs:0.76301 (r=0.667,p=0.892),  time:33.913, tt:6104.281\n",
      "Ep:180, loss:0.00000, loss_test:0.02344, lr:3.42e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.913, tt:6138.331\n",
      "Ep:181, loss:0.00000, loss_test:0.02339, lr:3.38e-02, fs:0.74419 (r=0.646,p=0.877),  time:33.915, tt:6172.553\n",
      "Ep:182, loss:0.00000, loss_test:0.02372, lr:3.35e-02, fs:0.75581 (r=0.657,p=0.890),  time:33.904, tt:6204.380\n",
      "Ep:183, loss:0.00000, loss_test:0.02348, lr:3.32e-02, fs:0.74419 (r=0.646,p=0.877),  time:33.903, tt:6238.072\n",
      "Ep:184, loss:0.00000, loss_test:0.02373, lr:3.28e-02, fs:0.75581 (r=0.657,p=0.890),  time:33.898, tt:6271.120\n",
      "Ep:185, loss:0.00000, loss_test:0.02381, lr:3.25e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.895, tt:6304.503\n",
      "Ep:186, loss:0.00000, loss_test:0.02393, lr:3.22e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.891, tt:6337.575\n",
      "Ep:187, loss:0.00000, loss_test:0.02393, lr:3.19e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.884, tt:6370.271\n",
      "Ep:188, loss:0.00000, loss_test:0.02392, lr:3.15e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.879, tt:6403.156\n",
      "Ep:189, loss:0.00000, loss_test:0.02407, lr:3.12e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.887, tt:6438.487\n",
      "Ep:190, loss:0.00000, loss_test:0.02413, lr:3.09e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.892, tt:6473.295\n",
      "Ep:191, loss:0.00000, loss_test:0.02420, lr:3.06e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.893, tt:6507.395\n",
      "Ep:192, loss:0.00000, loss_test:0.02393, lr:3.03e-02, fs:0.73988 (r=0.646,p=0.865),  time:33.886, tt:6540.059\n",
      "Ep:193, loss:0.00000, loss_test:0.02459, lr:3.00e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.899, tt:6576.465\n",
      "Ep:194, loss:0.00000, loss_test:0.02434, lr:2.97e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.897, tt:6609.876\n",
      "Ep:195, loss:0.00000, loss_test:0.02410, lr:2.94e-02, fs:0.73684 (r=0.636,p=0.875),  time:33.903, tt:6644.992\n",
      "Ep:196, loss:0.00000, loss_test:0.02445, lr:2.91e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.896, tt:6677.421\n",
      "Ep:197, loss:0.00000, loss_test:0.02432, lr:2.88e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.893, tt:6710.813\n",
      "Ep:198, loss:0.00000, loss_test:0.02477, lr:2.85e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.897, tt:6745.567\n",
      "Ep:199, loss:0.00000, loss_test:0.02449, lr:2.82e-02, fs:0.74854 (r=0.646,p=0.889),  time:33.904, tt:6780.821\n",
      "Ep:200, loss:0.00000, loss_test:0.02460, lr:2.80e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.898, tt:6813.572\n",
      "Ep:201, loss:0.00000, loss_test:0.02485, lr:2.77e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.900, tt:6847.716\n",
      "Ep:202, loss:0.00000, loss_test:0.02464, lr:2.74e-02, fs:0.74118 (r=0.636,p=0.887),  time:33.899, tt:6881.582\n",
      "Ep:203, loss:0.00000, loss_test:0.02524, lr:2.71e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.893, tt:6914.195\n",
      "Ep:204, loss:0.00000, loss_test:0.02458, lr:2.69e-02, fs:0.73684 (r=0.636,p=0.875),  time:33.903, tt:6950.104\n",
      "Ep:205, loss:0.00000, loss_test:0.02521, lr:2.66e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.910, tt:6985.363\n",
      "Ep:206, loss:0.00000, loss_test:0.02439, lr:2.63e-02, fs:0.71765 (r=0.616,p=0.859),  time:33.916, tt:7020.601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.02520, lr:2.61e-02, fs:0.75740 (r=0.646,p=0.914),  time:33.928, tt:7057.037\n",
      "Ep:208, loss:0.00000, loss_test:0.02480, lr:2.58e-02, fs:0.73810 (r=0.626,p=0.899),  time:33.936, tt:7092.668\n",
      "Ep:209, loss:0.00000, loss_test:0.02510, lr:2.55e-02, fs:0.75294 (r=0.646,p=0.901),  time:33.920, tt:7123.105\n",
      "Ep:210, loss:0.00000, loss_test:0.02501, lr:2.53e-02, fs:0.73810 (r=0.626,p=0.899),  time:33.889, tt:7150.573\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12706, lr:1.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:31.815, tt:31.815\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12563, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:32.316, tt:64.632\n",
      "Ep:2, loss:0.00026, loss_test:0.12387, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:33.355, tt:100.064\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12249, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:34.327, tt:137.309\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12150, lr:1.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:34.538, tt:172.690\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12051, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.581, tt:207.487\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.11927, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:34.869, tt:244.084\n",
      "Ep:7, loss:0.00025, loss_test:0.11831, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:35.349, tt:282.794\n",
      "Ep:8, loss:0.00025, loss_test:0.11736, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.368, tt:318.310\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00025, loss_test:0.11595, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:35.384, tt:353.837\n",
      "Ep:10, loss:0.00025, loss_test:0.11462, lr:1.00e-02, fs:0.68800 (r=0.869,p=0.570),  time:35.519, tt:390.710\n",
      "Ep:11, loss:0.00024, loss_test:0.11341, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:35.621, tt:427.448\n",
      "Ep:12, loss:0.00024, loss_test:0.11257, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:35.589, tt:462.652\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.11173, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:35.653, tt:499.148\n",
      "Ep:14, loss:0.00024, loss_test:0.11025, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:35.593, tt:533.895\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.10870, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:35.576, tt:569.210\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00023, loss_test:0.10740, lr:1.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:35.526, tt:603.939\n",
      "Ep:17, loss:0.00023, loss_test:0.10612, lr:1.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:35.565, tt:640.163\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10536, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:35.656, tt:677.464\n",
      "Ep:19, loss:0.00022, loss_test:0.10387, lr:1.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:35.697, tt:713.932\n",
      "Ep:20, loss:0.00022, loss_test:0.10280, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:35.692, tt:749.528\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10094, lr:1.00e-02, fs:0.72358 (r=0.899,p=0.605),  time:35.743, tt:786.340\n",
      "Ep:22, loss:0.00021, loss_test:0.09890, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:35.763, tt:822.539\n",
      "Ep:23, loss:0.00020, loss_test:0.09655, lr:1.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:35.787, tt:858.900\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00020, loss_test:0.09333, lr:1.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:35.786, tt:894.652\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00019, loss_test:0.09093, lr:1.00e-02, fs:0.75833 (r=0.919,p=0.645),  time:35.793, tt:930.623\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.08830, lr:1.00e-02, fs:0.76793 (r=0.919,p=0.659),  time:35.835, tt:967.546\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.08521, lr:1.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:35.824, tt:1003.062\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08389, lr:1.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:35.837, tt:1039.283\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.08138, lr:1.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:35.877, tt:1076.300\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08135, lr:1.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:35.908, tt:1113.162\n",
      "Ep:31, loss:0.00015, loss_test:0.07767, lr:1.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:35.922, tt:1149.488\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.07701, lr:1.00e-02, fs:0.79310 (r=0.929,p=0.692),  time:35.910, tt:1185.034\n",
      "Ep:33, loss:0.00014, loss_test:0.07505, lr:1.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:35.933, tt:1221.712\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.07352, lr:1.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:35.946, tt:1258.114\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00013, loss_test:0.07256, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.915, tt:1292.934\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00013, loss_test:0.07026, lr:1.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:35.934, tt:1329.571\n",
      "Ep:37, loss:0.00013, loss_test:0.06946, lr:1.00e-02, fs:0.82883 (r=0.929,p=0.748),  time:35.950, tt:1366.119\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.06884, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:35.965, tt:1402.621\n",
      "Ep:39, loss:0.00012, loss_test:0.06657, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:35.988, tt:1439.510\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00011, loss_test:0.06601, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:36.003, tt:1476.119\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00011, loss_test:0.06431, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:35.997, tt:1511.854\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00010, loss_test:0.06658, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:36.006, tt:1548.237\n",
      "Ep:43, loss:0.00010, loss_test:0.06501, lr:1.00e-02, fs:0.85714 (r=0.970,p=0.768),  time:36.025, tt:1585.107\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.06782, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:36.012, tt:1620.541\n",
      "Ep:45, loss:0.00011, loss_test:0.06241, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:36.018, tt:1656.844\n",
      "Ep:46, loss:0.00009, loss_test:0.07319, lr:1.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:35.997, tt:1691.879\n",
      "Ep:47, loss:0.00010, loss_test:0.06212, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:35.986, tt:1727.331\n",
      "Ep:48, loss:0.00009, loss_test:0.05894, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:35.966, tt:1762.323\n",
      "Ep:49, loss:0.00008, loss_test:0.05742, lr:1.00e-02, fs:0.84507 (r=0.909,p=0.789),  time:35.952, tt:1797.611\n",
      "Ep:50, loss:0.00008, loss_test:0.05868, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:35.963, tt:1834.110\n",
      "Ep:51, loss:0.00007, loss_test:0.05838, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.979, tt:1870.933\n",
      "Ep:52, loss:0.00007, loss_test:0.05406, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:36.001, tt:1908.042\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00007, loss_test:0.05681, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:36.008, tt:1944.430\n",
      "Ep:54, loss:0.00006, loss_test:0.06736, lr:1.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.986, tt:1979.251\n",
      "Ep:55, loss:0.00009, loss_test:0.07293, lr:1.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.999, tt:2015.923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00008, loss_test:0.06690, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.970, tt:2050.277\n",
      "Ep:57, loss:0.00009, loss_test:0.07340, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:35.960, tt:2085.664\n",
      "Ep:58, loss:0.00008, loss_test:0.06730, lr:1.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:35.974, tt:2122.475\n",
      "Ep:59, loss:0.00008, loss_test:0.06664, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:35.950, tt:2157.027\n",
      "Ep:60, loss:0.00007, loss_test:0.06121, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:35.968, tt:2194.019\n",
      "Ep:61, loss:0.00007, loss_test:0.06551, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.975, tt:2230.441\n",
      "Ep:62, loss:0.00006, loss_test:0.05902, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:35.992, tt:2267.522\n",
      "Ep:63, loss:0.00006, loss_test:0.05737, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:35.994, tt:2303.612\n",
      "Ep:64, loss:0.00005, loss_test:0.05419, lr:9.90e-03, fs:0.85308 (r=0.909,p=0.804),  time:35.998, tt:2339.856\n",
      "Ep:65, loss:0.00005, loss_test:0.06000, lr:9.80e-03, fs:0.86000 (r=0.869,p=0.851),  time:35.985, tt:2374.986\n",
      "Ep:66, loss:0.00005, loss_test:0.05507, lr:9.70e-03, fs:0.85167 (r=0.899,p=0.809),  time:35.984, tt:2410.947\n",
      "Ep:67, loss:0.00005, loss_test:0.05605, lr:9.61e-03, fs:0.87923 (r=0.919,p=0.843),  time:35.979, tt:2446.586\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.05159, lr:9.61e-03, fs:0.85167 (r=0.899,p=0.809),  time:35.968, tt:2481.808\n",
      "Ep:69, loss:0.00004, loss_test:0.05239, lr:9.61e-03, fs:0.90196 (r=0.929,p=0.876),  time:35.965, tt:2517.544\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00004, loss_test:0.04945, lr:9.61e-03, fs:0.88995 (r=0.939,p=0.845),  time:35.968, tt:2553.753\n",
      "Ep:71, loss:0.00004, loss_test:0.05922, lr:9.61e-03, fs:0.86538 (r=0.909,p=0.826),  time:36.007, tt:2592.492\n",
      "Ep:72, loss:0.00005, loss_test:0.05824, lr:9.61e-03, fs:0.83333 (r=0.909,p=0.769),  time:36.003, tt:2628.205\n",
      "Ep:73, loss:0.00005, loss_test:0.05545, lr:9.61e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.017, tt:2665.289\n",
      "Ep:74, loss:0.00005, loss_test:0.05738, lr:9.61e-03, fs:0.87324 (r=0.939,p=0.816),  time:36.021, tt:2701.594\n",
      "Ep:75, loss:0.00005, loss_test:0.05394, lr:9.61e-03, fs:0.86432 (r=0.869,p=0.860),  time:36.021, tt:2737.574\n",
      "Ep:76, loss:0.00004, loss_test:0.05507, lr:9.61e-03, fs:0.85577 (r=0.899,p=0.817),  time:36.012, tt:2772.957\n",
      "Ep:77, loss:0.00004, loss_test:0.06171, lr:9.61e-03, fs:0.85417 (r=0.828,p=0.882),  time:36.002, tt:2808.190\n",
      "Ep:78, loss:0.00004, loss_test:0.05155, lr:9.61e-03, fs:0.83962 (r=0.899,p=0.788),  time:35.999, tt:2843.890\n",
      "Ep:79, loss:0.00004, loss_test:0.05248, lr:9.61e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.006, tt:2880.494\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00004, loss_test:0.05107, lr:9.61e-03, fs:0.87685 (r=0.899,p=0.856),  time:36.038, tt:2919.041\n",
      "Ep:81, loss:0.00004, loss_test:0.04426, lr:9.61e-03, fs:0.91787 (r=0.960,p=0.880),  time:36.036, tt:2954.929\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.04488, lr:9.61e-03, fs:0.90355 (r=0.899,p=0.908),  time:36.051, tt:2992.266\n",
      "Ep:83, loss:0.00003, loss_test:0.04848, lr:9.61e-03, fs:0.90291 (r=0.939,p=0.869),  time:36.041, tt:3027.471\n",
      "Ep:84, loss:0.00003, loss_test:0.04550, lr:9.61e-03, fs:0.91089 (r=0.929,p=0.893),  time:36.027, tt:3062.331\n",
      "Ep:85, loss:0.00003, loss_test:0.04797, lr:9.61e-03, fs:0.93069 (r=0.949,p=0.913),  time:36.031, tt:3098.664\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00003, loss_test:0.04402, lr:9.61e-03, fs:0.92537 (r=0.939,p=0.912),  time:36.036, tt:3135.109\n",
      "Ep:87, loss:0.00003, loss_test:0.04057, lr:9.61e-03, fs:0.89109 (r=0.909,p=0.874),  time:36.026, tt:3170.244\n",
      "Ep:88, loss:0.00003, loss_test:0.04870, lr:9.61e-03, fs:0.91707 (r=0.949,p=0.887),  time:36.014, tt:3205.273\n",
      "Ep:89, loss:0.00003, loss_test:0.04004, lr:9.61e-03, fs:0.91282 (r=0.899,p=0.927),  time:35.999, tt:3239.935\n",
      "Ep:90, loss:0.00003, loss_test:0.04248, lr:9.61e-03, fs:0.95192 (r=1.000,p=0.908),  time:35.997, tt:3275.685\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00003, loss_test:0.04520, lr:9.61e-03, fs:0.89000 (r=0.899,p=0.881),  time:35.995, tt:3311.534\n",
      "Ep:92, loss:0.00002, loss_test:0.04324, lr:9.61e-03, fs:0.94000 (r=0.949,p=0.931),  time:36.005, tt:3348.432\n",
      "Ep:93, loss:0.00003, loss_test:0.03957, lr:9.61e-03, fs:0.90355 (r=0.899,p=0.908),  time:36.014, tt:3385.301\n",
      "Ep:94, loss:0.00002, loss_test:0.04428, lr:9.61e-03, fs:0.94000 (r=0.949,p=0.931),  time:36.026, tt:3422.499\n",
      "Ep:95, loss:0.00002, loss_test:0.03972, lr:9.61e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.048, tt:3460.648\n",
      "Ep:96, loss:0.00002, loss_test:0.04702, lr:9.61e-03, fs:0.92157 (r=0.949,p=0.895),  time:36.056, tt:3497.431\n",
      "Ep:97, loss:0.00002, loss_test:0.04157, lr:9.61e-03, fs:0.89000 (r=0.899,p=0.881),  time:36.063, tt:3534.154\n",
      "Ep:98, loss:0.00002, loss_test:0.04260, lr:9.61e-03, fs:0.92462 (r=0.929,p=0.920),  time:36.051, tt:3569.000\n",
      "Ep:99, loss:0.00002, loss_test:0.04465, lr:9.61e-03, fs:0.92157 (r=0.949,p=0.895),  time:36.068, tt:3606.761\n",
      "Ep:100, loss:0.00002, loss_test:0.03832, lr:9.61e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.069, tt:3642.954\n",
      "Ep:101, loss:0.00002, loss_test:0.04160, lr:9.61e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.061, tt:3678.208\n",
      "Ep:102, loss:0.00002, loss_test:0.04311, lr:9.51e-03, fs:0.92611 (r=0.949,p=0.904),  time:36.069, tt:3715.089\n",
      "Ep:103, loss:0.00002, loss_test:0.04038, lr:9.41e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.080, tt:3752.289\n",
      "Ep:104, loss:0.00002, loss_test:0.04116, lr:9.32e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.084, tt:3788.870\n",
      "Ep:105, loss:0.00002, loss_test:0.04066, lr:9.23e-03, fs:0.94949 (r=0.949,p=0.949),  time:36.088, tt:3825.374\n",
      "Ep:106, loss:0.00002, loss_test:0.04119, lr:9.14e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.093, tt:3861.903\n",
      "Ep:107, loss:0.00002, loss_test:0.04156, lr:9.04e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.113, tt:3900.202\n",
      "Ep:108, loss:0.00002, loss_test:0.04347, lr:8.95e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.100, tt:3934.950\n",
      "Ep:109, loss:0.00002, loss_test:0.04364, lr:8.86e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.095, tt:3970.478\n",
      "Ep:110, loss:0.00002, loss_test:0.03903, lr:8.78e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.093, tt:4006.338\n",
      "Ep:111, loss:0.00002, loss_test:0.04342, lr:8.69e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.088, tt:4041.808\n",
      "Ep:112, loss:0.00002, loss_test:0.04544, lr:8.60e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.076, tt:4076.625\n",
      "Ep:113, loss:0.00002, loss_test:0.04951, lr:8.51e-03, fs:0.89899 (r=0.899,p=0.899),  time:36.077, tt:4112.814\n",
      "Ep:114, loss:0.00002, loss_test:0.04326, lr:8.43e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.070, tt:4148.006\n",
      "Ep:115, loss:0.00002, loss_test:0.04526, lr:8.35e-03, fs:0.89447 (r=0.899,p=0.890),  time:36.063, tt:4183.321\n",
      "Ep:116, loss:0.00002, loss_test:0.04163, lr:8.26e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.066, tt:4219.733\n",
      "Ep:117, loss:0.00002, loss_test:0.04364, lr:8.18e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.071, tt:4256.396\n",
      "Ep:118, loss:0.00001, loss_test:0.04193, lr:8.10e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.065, tt:4291.714\n",
      "Ep:119, loss:0.00001, loss_test:0.04055, lr:8.02e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.067, tt:4328.014\n",
      "Ep:120, loss:0.00001, loss_test:0.04129, lr:7.94e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.073, tt:4364.807\n",
      "Ep:121, loss:0.00001, loss_test:0.04345, lr:7.86e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.067, tt:4400.142\n",
      "Ep:122, loss:0.00001, loss_test:0.03934, lr:7.78e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.064, tt:4435.824\n",
      "Ep:123, loss:0.00001, loss_test:0.04377, lr:7.70e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.062, tt:4471.708\n",
      "Ep:124, loss:0.00001, loss_test:0.04140, lr:7.62e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.062, tt:4507.788\n",
      "Ep:125, loss:0.00001, loss_test:0.04105, lr:7.55e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.061, tt:4543.734\n",
      "Ep:126, loss:0.00001, loss_test:0.04106, lr:7.47e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.061, tt:4579.795\n",
      "Ep:127, loss:0.00001, loss_test:0.04182, lr:7.40e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.069, tt:4616.894\n",
      "Ep:128, loss:0.00001, loss_test:0.04358, lr:7.32e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.072, tt:4653.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.04036, lr:7.25e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.073, tt:4689.524\n",
      "Ep:130, loss:0.00001, loss_test:0.04122, lr:7.18e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.064, tt:4724.440\n",
      "Ep:131, loss:0.00001, loss_test:0.04336, lr:7.11e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.071, tt:4761.410\n",
      "Ep:132, loss:0.00001, loss_test:0.04181, lr:7.03e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.070, tt:4797.258\n",
      "Ep:133, loss:0.00001, loss_test:0.04063, lr:6.96e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.064, tt:4832.574\n",
      "Ep:134, loss:0.00001, loss_test:0.04204, lr:6.89e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.064, tt:4868.654\n",
      "Ep:135, loss:0.00001, loss_test:0.04216, lr:6.83e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.070, tt:4905.461\n",
      "Ep:136, loss:0.00001, loss_test:0.04127, lr:6.76e-03, fs:0.92228 (r=0.899,p=0.947),  time:36.083, tt:4943.397\n",
      "Ep:137, loss:0.00001, loss_test:0.04208, lr:6.69e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.087, tt:4980.046\n",
      "Ep:138, loss:0.00001, loss_test:0.04237, lr:6.62e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.096, tt:5017.314\n",
      "Ep:139, loss:0.00001, loss_test:0.04109, lr:6.56e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.107, tt:5055.002\n",
      "Ep:140, loss:0.00001, loss_test:0.04233, lr:6.49e-03, fs:0.92708 (r=0.899,p=0.957),  time:36.107, tt:5091.046\n",
      "Ep:141, loss:0.00001, loss_test:0.04259, lr:6.43e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.113, tt:5128.008\n",
      "Ep:142, loss:0.00001, loss_test:0.04065, lr:6.36e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.128, tt:5166.257\n",
      "Ep:143, loss:0.00001, loss_test:0.04247, lr:6.30e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.139, tt:5203.985\n",
      "Ep:144, loss:0.00001, loss_test:0.04272, lr:6.24e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.143, tt:5240.723\n",
      "Ep:145, loss:0.00001, loss_test:0.04202, lr:6.17e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.149, tt:5277.821\n",
      "Ep:146, loss:0.00001, loss_test:0.04199, lr:6.11e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.147, tt:5313.589\n",
      "Ep:147, loss:0.00001, loss_test:0.04176, lr:6.05e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.154, tt:5350.769\n",
      "Ep:148, loss:0.00001, loss_test:0.04227, lr:5.99e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.152, tt:5386.599\n",
      "Ep:149, loss:0.00001, loss_test:0.04228, lr:5.93e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.153, tt:5422.890\n",
      "Ep:150, loss:0.00001, loss_test:0.04316, lr:5.87e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.167, tt:5461.242\n",
      "Ep:151, loss:0.00001, loss_test:0.04206, lr:5.81e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.171, tt:5498.038\n",
      "Ep:152, loss:0.00001, loss_test:0.04328, lr:5.75e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.177, tt:5535.131\n",
      "Ep:153, loss:0.00001, loss_test:0.04352, lr:5.70e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.185, tt:5572.484\n",
      "Ep:154, loss:0.00001, loss_test:0.04313, lr:5.64e-03, fs:0.94681 (r=0.899,p=1.000),  time:36.193, tt:5609.912\n",
      "Ep:155, loss:0.00001, loss_test:0.04335, lr:5.58e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.201, tt:5647.428\n",
      "Ep:156, loss:0.00001, loss_test:0.04334, lr:5.53e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.197, tt:5682.856\n",
      "Ep:157, loss:0.00001, loss_test:0.04263, lr:5.47e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.190, tt:5718.096\n",
      "Ep:158, loss:0.00001, loss_test:0.04241, lr:5.42e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.189, tt:5754.050\n",
      "Ep:159, loss:0.00001, loss_test:0.04487, lr:5.36e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.178, tt:5788.438\n",
      "Ep:160, loss:0.00001, loss_test:0.04202, lr:5.31e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.165, tt:5822.603\n",
      "Ep:161, loss:0.00001, loss_test:0.04327, lr:5.26e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.153, tt:5856.841\n",
      "Ep:162, loss:0.00001, loss_test:0.04348, lr:5.20e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.148, tt:5892.108\n",
      "Ep:163, loss:0.00001, loss_test:0.04280, lr:5.15e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.138, tt:5926.673\n",
      "Ep:164, loss:0.00001, loss_test:0.04341, lr:5.10e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.121, tt:5959.946\n",
      "Ep:165, loss:0.00001, loss_test:0.04281, lr:5.05e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.105, tt:5993.505\n",
      "Ep:166, loss:0.00001, loss_test:0.04255, lr:5.00e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.095, tt:6027.872\n",
      "Ep:167, loss:0.00001, loss_test:0.04248, lr:4.95e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.087, tt:6062.544\n",
      "Ep:168, loss:0.00001, loss_test:0.04225, lr:4.90e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.070, tt:6095.808\n",
      "Ep:169, loss:0.00001, loss_test:0.04312, lr:4.85e-03, fs:0.93684 (r=0.899,p=0.978),  time:36.051, tt:6128.713\n",
      "Ep:170, loss:0.00001, loss_test:0.04165, lr:4.80e-03, fs:0.94681 (r=0.899,p=1.000),  time:36.047, tt:6164.069\n",
      "Ep:171, loss:0.00001, loss_test:0.04339, lr:4.75e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.036, tt:6198.152\n",
      "Ep:172, loss:0.00001, loss_test:0.04332, lr:4.71e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.023, tt:6232.038\n",
      "Ep:173, loss:0.00001, loss_test:0.04232, lr:4.66e-03, fs:0.94681 (r=0.899,p=1.000),  time:36.011, tt:6265.902\n",
      "Ep:174, loss:0.00001, loss_test:0.04240, lr:4.61e-03, fs:0.94180 (r=0.899,p=0.989),  time:36.004, tt:6300.710\n",
      "Ep:175, loss:0.00001, loss_test:0.04356, lr:4.57e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.989, tt:6334.011\n",
      "Ep:176, loss:0.00001, loss_test:0.04162, lr:4.52e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.981, tt:6368.711\n",
      "Ep:177, loss:0.00001, loss_test:0.04325, lr:4.48e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.966, tt:6401.957\n",
      "Ep:178, loss:0.00001, loss_test:0.04258, lr:4.43e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.958, tt:6436.478\n",
      "Ep:179, loss:0.00001, loss_test:0.04418, lr:4.39e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.952, tt:6471.378\n",
      "Ep:180, loss:0.00001, loss_test:0.04177, lr:4.34e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.946, tt:6506.175\n",
      "Ep:181, loss:0.00001, loss_test:0.04466, lr:4.30e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.934, tt:6539.953\n",
      "Ep:182, loss:0.00001, loss_test:0.04257, lr:4.26e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.921, tt:6573.502\n",
      "Ep:183, loss:0.00001, loss_test:0.04393, lr:4.21e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.909, tt:6607.222\n",
      "Ep:184, loss:0.00001, loss_test:0.04314, lr:4.17e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.896, tt:6640.799\n",
      "Ep:185, loss:0.00001, loss_test:0.04422, lr:4.13e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.889, tt:6675.428\n",
      "Ep:186, loss:0.00001, loss_test:0.04290, lr:4.09e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.895, tt:6712.340\n",
      "Ep:187, loss:0.00000, loss_test:0.04340, lr:4.05e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.897, tt:6748.544\n",
      "Ep:188, loss:0.00000, loss_test:0.04338, lr:4.01e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.889, tt:6783.093\n",
      "Ep:189, loss:0.00000, loss_test:0.04382, lr:3.97e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.876, tt:6816.364\n",
      "Ep:190, loss:0.00000, loss_test:0.04401, lr:3.93e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.862, tt:6849.648\n",
      "Ep:191, loss:0.00000, loss_test:0.04227, lr:3.89e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.858, tt:6884.678\n",
      "Ep:192, loss:0.00000, loss_test:0.04423, lr:3.85e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.846, tt:6918.283\n",
      "Ep:193, loss:0.00000, loss_test:0.04270, lr:3.81e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.836, tt:6952.245\n",
      "Ep:194, loss:0.00000, loss_test:0.04430, lr:3.77e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.826, tt:6986.047\n",
      "Ep:195, loss:0.00000, loss_test:0.04426, lr:3.73e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.809, tt:7018.609\n",
      "Ep:196, loss:0.00000, loss_test:0.04355, lr:3.70e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.800, tt:7052.693\n",
      "Ep:197, loss:0.00000, loss_test:0.04542, lr:3.66e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.794, tt:7087.197\n",
      "Ep:198, loss:0.00000, loss_test:0.04329, lr:3.62e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.788, tt:7121.752\n",
      "Ep:199, loss:0.00000, loss_test:0.04590, lr:3.59e-03, fs:0.93684 (r=0.899,p=0.978),  time:35.780, tt:7156.049\n",
      "Ep:200, loss:0.00000, loss_test:0.04432, lr:3.55e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.778, tt:7191.308\n",
      "Ep:201, loss:0.00000, loss_test:0.04435, lr:3.52e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.774, tt:7226.410\n",
      "Ep:202, loss:0.00000, loss_test:0.04451, lr:3.48e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.771, tt:7261.534\n",
      "Ep:203, loss:0.00000, loss_test:0.04374, lr:3.45e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.760, tt:7295.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.04572, lr:3.41e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.751, tt:7328.860\n",
      "Ep:205, loss:0.00000, loss_test:0.04431, lr:3.38e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.748, tt:7364.031\n",
      "Ep:206, loss:0.00000, loss_test:0.04439, lr:3.34e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.746, tt:7399.497\n",
      "Ep:207, loss:0.00000, loss_test:0.04432, lr:3.31e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.742, tt:7434.412\n",
      "Ep:208, loss:0.00000, loss_test:0.04489, lr:3.28e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.739, tt:7469.472\n",
      "Ep:209, loss:0.00000, loss_test:0.04582, lr:3.24e-03, fs:0.94180 (r=0.899,p=0.989),  time:35.724, tt:7502.013\n",
      "Ep:210, loss:0.00000, loss_test:0.04412, lr:3.21e-03, fs:0.94681 (r=0.899,p=1.000),  time:35.665, tt:7525.278\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02408, lr:6.00e-02, fs:0.67234 (r=0.798,p=0.581),  time:29.380, tt:29.380\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02401, lr:6.00e-02, fs:0.66667 (r=0.949,p=0.514),  time:29.170, tt:58.340\n",
      "Ep:2, loss:0.00005, loss_test:0.02612, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:29.505, tt:88.515\n",
      "Ep:3, loss:0.00005, loss_test:0.02625, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:30.214, tt:120.856\n",
      "Ep:4, loss:0.00005, loss_test:0.02573, lr:6.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:30.998, tt:154.989\n",
      "Ep:5, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:31.354, tt:188.127\n",
      "Ep:6, loss:0.00005, loss_test:0.02460, lr:6.00e-02, fs:0.65428 (r=0.889,p=0.518),  time:31.659, tt:221.610\n",
      "Ep:7, loss:0.00005, loss_test:0.02413, lr:6.00e-02, fs:0.66415 (r=0.889,p=0.530),  time:32.089, tt:256.714\n",
      "Ep:8, loss:0.00005, loss_test:0.02361, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:32.319, tt:290.871\n",
      "Ep:9, loss:0.00005, loss_test:0.02326, lr:6.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:32.519, tt:325.191\n",
      "Ep:10, loss:0.00005, loss_test:0.02287, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:32.600, tt:358.600\n",
      "Ep:11, loss:0.00005, loss_test:0.02226, lr:6.00e-02, fs:0.66176 (r=0.909,p=0.520),  time:32.614, tt:391.368\n",
      "Ep:12, loss:0.00005, loss_test:0.02160, lr:5.94e-02, fs:0.66667 (r=0.909,p=0.526),  time:32.706, tt:425.183\n",
      "Ep:13, loss:0.00004, loss_test:0.02106, lr:5.88e-02, fs:0.67176 (r=0.889,p=0.540),  time:32.779, tt:458.905\n",
      "Ep:14, loss:0.00004, loss_test:0.02065, lr:5.82e-02, fs:0.67969 (r=0.879,p=0.554),  time:32.800, tt:492.007\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02043, lr:5.82e-02, fs:0.67939 (r=0.899,p=0.546),  time:32.847, tt:525.551\n",
      "Ep:16, loss:0.00004, loss_test:0.02022, lr:5.82e-02, fs:0.67925 (r=0.909,p=0.542),  time:32.915, tt:559.550\n",
      "Ep:17, loss:0.00004, loss_test:0.01996, lr:5.82e-02, fs:0.68441 (r=0.909,p=0.549),  time:32.894, tt:592.084\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01977, lr:5.82e-02, fs:0.68966 (r=0.909,p=0.556),  time:32.900, tt:625.092\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01957, lr:5.82e-02, fs:0.69231 (r=0.909,p=0.559),  time:32.914, tt:658.274\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01937, lr:5.82e-02, fs:0.68702 (r=0.909,p=0.552),  time:33.036, tt:693.747\n",
      "Ep:21, loss:0.00004, loss_test:0.01916, lr:5.82e-02, fs:0.68441 (r=0.909,p=0.549),  time:33.065, tt:727.420\n",
      "Ep:22, loss:0.00004, loss_test:0.01885, lr:5.82e-02, fs:0.68702 (r=0.909,p=0.552),  time:33.133, tt:762.057\n",
      "Ep:23, loss:0.00004, loss_test:0.01855, lr:5.82e-02, fs:0.70270 (r=0.919,p=0.569),  time:33.273, tt:798.558\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00004, loss_test:0.01828, lr:5.82e-02, fs:0.70270 (r=0.919,p=0.569),  time:33.286, tt:832.157\n",
      "Ep:25, loss:0.00004, loss_test:0.01801, lr:5.82e-02, fs:0.71094 (r=0.919,p=0.580),  time:33.226, tt:863.870\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01769, lr:5.82e-02, fs:0.69600 (r=0.879,p=0.576),  time:33.252, tt:897.811\n",
      "Ep:27, loss:0.00003, loss_test:0.01737, lr:5.82e-02, fs:0.70635 (r=0.899,p=0.582),  time:33.273, tt:931.654\n",
      "Ep:28, loss:0.00003, loss_test:0.01700, lr:5.82e-02, fs:0.70356 (r=0.899,p=0.578),  time:33.290, tt:965.400\n",
      "Ep:29, loss:0.00003, loss_test:0.01667, lr:5.82e-02, fs:0.71486 (r=0.899,p=0.593),  time:33.306, tt:999.180\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01639, lr:5.82e-02, fs:0.72581 (r=0.909,p=0.604),  time:33.317, tt:1032.835\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01602, lr:5.82e-02, fs:0.72289 (r=0.909,p=0.600),  time:33.365, tt:1067.681\n",
      "Ep:32, loss:0.00003, loss_test:0.01583, lr:5.82e-02, fs:0.72800 (r=0.919,p=0.603),  time:33.418, tt:1102.788\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01569, lr:5.82e-02, fs:0.74900 (r=0.949,p=0.618),  time:33.435, tt:1136.791\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01549, lr:5.82e-02, fs:0.74286 (r=0.919,p=0.623),  time:33.447, tt:1170.636\n",
      "Ep:35, loss:0.00003, loss_test:0.01530, lr:5.82e-02, fs:0.73251 (r=0.899,p=0.618),  time:33.476, tt:1205.136\n",
      "Ep:36, loss:0.00003, loss_test:0.01521, lr:5.82e-02, fs:0.73859 (r=0.899,p=0.627),  time:33.450, tt:1237.636\n",
      "Ep:37, loss:0.00003, loss_test:0.01507, lr:5.82e-02, fs:0.73333 (r=0.889,p=0.624),  time:33.465, tt:1271.669\n",
      "Ep:38, loss:0.00003, loss_test:0.01495, lr:5.82e-02, fs:0.73950 (r=0.889,p=0.633),  time:33.485, tt:1305.896\n",
      "Ep:39, loss:0.00002, loss_test:0.01490, lr:5.82e-02, fs:0.73729 (r=0.879,p=0.635),  time:33.476, tt:1339.044\n",
      "Ep:40, loss:0.00002, loss_test:0.01484, lr:5.82e-02, fs:0.73276 (r=0.859,p=0.639),  time:33.504, tt:1373.682\n",
      "Ep:41, loss:0.00002, loss_test:0.01475, lr:5.82e-02, fs:0.73913 (r=0.859,p=0.649),  time:33.490, tt:1406.568\n",
      "Ep:42, loss:0.00002, loss_test:0.01465, lr:5.82e-02, fs:0.74561 (r=0.859,p=0.659),  time:33.536, tt:1442.064\n",
      "Ep:43, loss:0.00002, loss_test:0.01462, lr:5.82e-02, fs:0.74138 (r=0.869,p=0.647),  time:33.563, tt:1476.760\n",
      "Ep:44, loss:0.00002, loss_test:0.01456, lr:5.82e-02, fs:0.75771 (r=0.869,p=0.672),  time:33.567, tt:1510.510\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01456, lr:5.82e-02, fs:0.75893 (r=0.859,p=0.680),  time:33.558, tt:1543.667\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01457, lr:5.82e-02, fs:0.76233 (r=0.859,p=0.685),  time:33.559, tt:1577.256\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01461, lr:5.82e-02, fs:0.76652 (r=0.879,p=0.680),  time:33.555, tt:1610.647\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01458, lr:5.82e-02, fs:0.76712 (r=0.848,p=0.700),  time:33.563, tt:1644.596\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01463, lr:5.82e-02, fs:0.75926 (r=0.828,p=0.701),  time:33.548, tt:1677.388\n",
      "Ep:50, loss:0.00002, loss_test:0.01464, lr:5.82e-02, fs:0.77626 (r=0.859,p=0.708),  time:33.562, tt:1711.638\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01478, lr:5.82e-02, fs:0.77419 (r=0.848,p=0.712),  time:33.556, tt:1744.934\n",
      "Ep:52, loss:0.00002, loss_test:0.01485, lr:5.82e-02, fs:0.76852 (r=0.838,p=0.709),  time:33.552, tt:1778.271\n",
      "Ep:53, loss:0.00002, loss_test:0.01470, lr:5.82e-02, fs:0.77419 (r=0.848,p=0.712),  time:33.561, tt:1812.315\n",
      "Ep:54, loss:0.00001, loss_test:0.01488, lr:5.82e-02, fs:0.79070 (r=0.859,p=0.733),  time:33.576, tt:1846.704\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00001, loss_test:0.01509, lr:5.82e-02, fs:0.78140 (r=0.848,p=0.724),  time:33.578, tt:1880.345\n",
      "Ep:56, loss:0.00001, loss_test:0.01562, lr:5.82e-02, fs:0.76852 (r=0.838,p=0.709),  time:33.587, tt:1914.468\n",
      "Ep:57, loss:0.00002, loss_test:0.01455, lr:5.82e-02, fs:0.78341 (r=0.859,p=0.720),  time:33.609, tt:1949.342\n",
      "Ep:58, loss:0.00001, loss_test:0.01488, lr:5.82e-02, fs:0.79070 (r=0.859,p=0.733),  time:33.615, tt:1983.274\n",
      "Ep:59, loss:0.00001, loss_test:0.01513, lr:5.82e-02, fs:0.77934 (r=0.838,p=0.728),  time:33.638, tt:2018.294\n",
      "Ep:60, loss:0.00001, loss_test:0.01543, lr:5.82e-02, fs:0.77064 (r=0.848,p=0.706),  time:33.673, tt:2054.025\n",
      "Ep:61, loss:0.00002, loss_test:0.01450, lr:5.82e-02, fs:0.77626 (r=0.859,p=0.708),  time:33.683, tt:2088.355\n",
      "Ep:62, loss:0.00002, loss_test:0.01373, lr:5.82e-02, fs:0.78182 (r=0.869,p=0.711),  time:33.679, tt:2121.803\n",
      "Ep:63, loss:0.00001, loss_test:0.01407, lr:5.82e-02, fs:0.77828 (r=0.869,p=0.705),  time:33.708, tt:2157.327\n",
      "Ep:64, loss:0.00001, loss_test:0.01422, lr:5.82e-02, fs:0.77828 (r=0.869,p=0.705),  time:33.748, tt:2193.636\n",
      "Ep:65, loss:0.00001, loss_test:0.01443, lr:5.82e-02, fs:0.77778 (r=0.848,p=0.718),  time:33.748, tt:2227.375\n",
      "Ep:66, loss:0.00001, loss_test:0.01505, lr:5.76e-02, fs:0.78704 (r=0.859,p=0.726),  time:33.759, tt:2261.822\n",
      "Ep:67, loss:0.00001, loss_test:0.01510, lr:5.71e-02, fs:0.77209 (r=0.838,p=0.716),  time:33.790, tt:2297.712\n",
      "Ep:68, loss:0.00001, loss_test:0.01505, lr:5.65e-02, fs:0.78140 (r=0.848,p=0.724),  time:33.819, tt:2333.536\n",
      "Ep:69, loss:0.00001, loss_test:0.01545, lr:5.59e-02, fs:0.78673 (r=0.838,p=0.741),  time:33.818, tt:2367.254\n",
      "Ep:70, loss:0.00001, loss_test:0.01631, lr:5.54e-02, fs:0.79426 (r=0.838,p=0.755),  time:33.820, tt:2401.191\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01545, lr:5.54e-02, fs:0.80189 (r=0.859,p=0.752),  time:33.835, tt:2436.095\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01627, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.839, tt:2470.245\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01635, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.848, tt:2504.734\n",
      "Ep:74, loss:0.00001, loss_test:0.01673, lr:5.54e-02, fs:0.80952 (r=0.859,p=0.766),  time:33.839, tt:2537.926\n",
      "Ep:75, loss:0.00001, loss_test:0.01678, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:33.839, tt:2571.775\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01630, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:33.841, tt:2605.782\n",
      "Ep:77, loss:0.00001, loss_test:0.01695, lr:5.54e-02, fs:0.81731 (r=0.859,p=0.780),  time:33.848, tt:2640.132\n",
      "Ep:78, loss:0.00001, loss_test:0.01695, lr:5.54e-02, fs:0.82126 (r=0.859,p=0.787),  time:33.857, tt:2674.704\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01740, lr:5.54e-02, fs:0.82927 (r=0.859,p=0.802),  time:33.869, tt:2709.521\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01701, lr:5.54e-02, fs:0.82759 (r=0.848,p=0.808),  time:33.882, tt:2744.455\n",
      "Ep:81, loss:0.00001, loss_test:0.01649, lr:5.54e-02, fs:0.82524 (r=0.859,p=0.794),  time:33.884, tt:2778.499\n",
      "Ep:82, loss:0.00001, loss_test:0.01762, lr:5.54e-02, fs:0.82927 (r=0.859,p=0.802),  time:33.917, tt:2815.117\n",
      "Ep:83, loss:0.00001, loss_test:0.01730, lr:5.54e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.942, tt:2851.143\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01635, lr:5.54e-02, fs:0.81773 (r=0.838,p=0.798),  time:33.980, tt:2888.326\n",
      "Ep:85, loss:0.00001, loss_test:0.01767, lr:5.54e-02, fs:0.82353 (r=0.848,p=0.800),  time:33.965, tt:2920.953\n",
      "Ep:86, loss:0.00001, loss_test:0.01732, lr:5.54e-02, fs:0.81407 (r=0.818,p=0.810),  time:33.977, tt:2956.024\n",
      "Ep:87, loss:0.00001, loss_test:0.01800, lr:5.54e-02, fs:0.83582 (r=0.848,p=0.824),  time:33.994, tt:2991.480\n",
      "Ep:88, loss:0.00001, loss_test:0.01835, lr:5.54e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.010, tt:3026.913\n",
      "Ep:89, loss:0.00001, loss_test:0.01744, lr:5.54e-02, fs:0.83582 (r=0.848,p=0.824),  time:34.018, tt:3061.604\n",
      "Ep:90, loss:0.00000, loss_test:0.01847, lr:5.54e-02, fs:0.81633 (r=0.808,p=0.825),  time:34.012, tt:3095.092\n",
      "Ep:91, loss:0.00000, loss_test:0.01827, lr:5.54e-02, fs:0.81026 (r=0.798,p=0.823),  time:34.036, tt:3131.274\n",
      "Ep:92, loss:0.00000, loss_test:0.01893, lr:5.54e-02, fs:0.83838 (r=0.838,p=0.838),  time:34.062, tt:3167.784\n",
      "Ep:93, loss:0.00000, loss_test:0.01959, lr:5.54e-02, fs:0.81865 (r=0.798,p=0.840),  time:34.074, tt:3202.936\n",
      "Ep:94, loss:0.00000, loss_test:0.01912, lr:5.54e-02, fs:0.83673 (r=0.828,p=0.845),  time:34.104, tt:3239.852\n",
      "Ep:95, loss:0.00000, loss_test:0.01971, lr:5.48e-02, fs:0.82902 (r=0.808,p=0.851),  time:34.112, tt:3274.716\n",
      "Ep:96, loss:0.00000, loss_test:0.01854, lr:5.43e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.120, tt:3309.668\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00000, loss_test:0.01893, lr:5.43e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.137, tt:3345.427\n",
      "Ep:98, loss:0.00000, loss_test:0.01911, lr:5.43e-02, fs:0.82292 (r=0.798,p=0.849),  time:34.151, tt:3380.911\n",
      "Ep:99, loss:0.00000, loss_test:0.01921, lr:5.43e-02, fs:0.84694 (r=0.838,p=0.856),  time:34.163, tt:3416.347\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.01919, lr:5.43e-02, fs:0.81250 (r=0.788,p=0.839),  time:34.176, tt:3451.820\n",
      "Ep:101, loss:0.00000, loss_test:0.01880, lr:5.43e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.187, tt:3487.111\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00000, loss_test:0.01936, lr:5.43e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.201, tt:3522.689\n",
      "Ep:103, loss:0.00000, loss_test:0.01809, lr:5.43e-02, fs:0.80628 (r=0.778,p=0.837),  time:34.215, tt:3558.323\n",
      "Ep:104, loss:0.00000, loss_test:0.01864, lr:5.43e-02, fs:0.85128 (r=0.838,p=0.865),  time:34.237, tt:3594.845\n",
      "Ep:105, loss:0.00000, loss_test:0.01917, lr:5.43e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.257, tt:3631.190\n",
      "Ep:106, loss:0.00000, loss_test:0.01852, lr:5.43e-02, fs:0.84264 (r=0.838,p=0.847),  time:34.282, tt:3668.135\n",
      "Ep:107, loss:0.00000, loss_test:0.01942, lr:5.43e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.303, tt:3704.761\n",
      "Ep:108, loss:0.00000, loss_test:0.01947, lr:5.43e-02, fs:0.82540 (r=0.788,p=0.867),  time:34.322, tt:3741.081\n",
      "Ep:109, loss:0.00000, loss_test:0.01919, lr:5.43e-02, fs:0.84974 (r=0.828,p=0.872),  time:34.338, tt:3777.191\n",
      "Ep:110, loss:0.00000, loss_test:0.01861, lr:5.43e-02, fs:0.83333 (r=0.808,p=0.860),  time:34.349, tt:3812.718\n",
      "Ep:111, loss:0.00000, loss_test:0.01904, lr:5.43e-02, fs:0.84694 (r=0.838,p=0.856),  time:34.350, tt:3847.184\n",
      "Ep:112, loss:0.00000, loss_test:0.01859, lr:5.43e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.361, tt:3882.792\n",
      "Ep:113, loss:0.00000, loss_test:0.01937, lr:5.37e-02, fs:0.87368 (r=0.838,p=0.912),  time:34.377, tt:3918.952\n",
      "##########Best model found so far##########\n",
      "Ep:114, loss:0.00000, loss_test:0.01976, lr:5.37e-02, fs:0.82105 (r=0.788,p=0.857),  time:34.398, tt:3955.797\n",
      "Ep:115, loss:0.00000, loss_test:0.01903, lr:5.37e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.415, tt:3992.093\n",
      "Ep:116, loss:0.00000, loss_test:0.02042, lr:5.37e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.445, tt:4030.073\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00000, loss_test:0.01979, lr:5.37e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.465, tt:4066.843\n",
      "Ep:118, loss:0.00000, loss_test:0.02081, lr:5.37e-02, fs:0.87368 (r=0.838,p=0.912),  time:34.479, tt:4103.031\n",
      "Ep:119, loss:0.00000, loss_test:0.02052, lr:5.37e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.493, tt:4139.205\n",
      "Ep:120, loss:0.00000, loss_test:0.02005, lr:5.37e-02, fs:0.83422 (r=0.788,p=0.886),  time:34.513, tt:4176.128\n",
      "Ep:121, loss:0.00000, loss_test:0.02093, lr:5.37e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.542, tt:4214.068\n",
      "Ep:122, loss:0.00000, loss_test:0.02069, lr:5.37e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.559, tt:4250.810\n",
      "Ep:123, loss:0.00000, loss_test:0.02142, lr:5.37e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.576, tt:4287.372\n",
      "Ep:124, loss:0.00000, loss_test:0.02118, lr:5.37e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.589, tt:4323.671\n",
      "Ep:125, loss:0.00000, loss_test:0.02140, lr:5.37e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.614, tt:4361.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.02171, lr:5.37e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.633, tt:4398.355\n",
      "Ep:127, loss:0.00000, loss_test:0.02155, lr:5.37e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.647, tt:4434.831\n",
      "Ep:128, loss:0.00000, loss_test:0.02163, lr:5.32e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.655, tt:4470.473\n",
      "Ep:129, loss:0.00000, loss_test:0.02158, lr:5.27e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.670, tt:4507.155\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00000, loss_test:0.02080, lr:5.27e-02, fs:0.85870 (r=0.798,p=0.929),  time:34.675, tt:4542.412\n",
      "Ep:131, loss:0.00000, loss_test:0.02135, lr:5.27e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.674, tt:4576.940\n",
      "Ep:132, loss:0.00000, loss_test:0.02093, lr:5.27e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.684, tt:4612.933\n",
      "Ep:133, loss:0.00000, loss_test:0.02162, lr:5.27e-02, fs:0.85714 (r=0.788,p=0.940),  time:34.693, tt:4648.889\n",
      "Ep:134, loss:0.00000, loss_test:0.02151, lr:5.27e-02, fs:0.86772 (r=0.828,p=0.911),  time:34.712, tt:4686.120\n",
      "Ep:135, loss:0.00000, loss_test:0.02116, lr:5.27e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.727, tt:4722.849\n",
      "Ep:136, loss:0.00000, loss_test:0.02092, lr:5.27e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.740, tt:4759.380\n",
      "Ep:137, loss:0.00000, loss_test:0.02156, lr:5.27e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.757, tt:4796.504\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00000, loss_test:0.02131, lr:5.27e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.764, tt:4832.196\n",
      "Ep:139, loss:0.00000, loss_test:0.02244, lr:5.27e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.774, tt:4868.306\n",
      "Ep:140, loss:0.00000, loss_test:0.02190, lr:5.27e-02, fs:0.84783 (r=0.788,p=0.918),  time:34.780, tt:4903.965\n",
      "Ep:141, loss:0.00000, loss_test:0.02229, lr:5.27e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.797, tt:4941.127\n",
      "Ep:142, loss:0.00000, loss_test:0.02225, lr:5.27e-02, fs:0.85246 (r=0.788,p=0.929),  time:34.801, tt:4976.514\n",
      "Ep:143, loss:0.00000, loss_test:0.02246, lr:5.27e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.817, tt:5013.717\n",
      "Ep:144, loss:0.00000, loss_test:0.02230, lr:5.27e-02, fs:0.88649 (r=0.828,p=0.953),  time:34.821, tt:5049.015\n",
      "Ep:145, loss:0.00000, loss_test:0.02225, lr:5.27e-02, fs:0.84153 (r=0.778,p=0.917),  time:34.820, tt:5083.791\n",
      "Ep:146, loss:0.00000, loss_test:0.02181, lr:5.27e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.825, tt:5119.281\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00000, loss_test:0.02254, lr:5.27e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.831, tt:5154.953\n",
      "Ep:148, loss:0.00000, loss_test:0.02208, lr:5.27e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.832, tt:5189.899\n",
      "Ep:149, loss:0.00000, loss_test:0.02227, lr:5.27e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.817, tt:5222.477\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00000, loss_test:0.02232, lr:5.27e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.809, tt:5256.160\n",
      "Ep:151, loss:0.00000, loss_test:0.02205, lr:5.27e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.806, tt:5290.449\n",
      "Ep:152, loss:0.00000, loss_test:0.02239, lr:5.27e-02, fs:0.88172 (r=0.828,p=0.943),  time:34.815, tt:5326.647\n",
      "Ep:153, loss:0.00000, loss_test:0.02126, lr:5.27e-02, fs:0.83799 (r=0.758,p=0.938),  time:34.816, tt:5361.736\n",
      "Ep:154, loss:0.00000, loss_test:0.02180, lr:5.27e-02, fs:0.89247 (r=0.838,p=0.954),  time:34.810, tt:5395.616\n",
      "Ep:155, loss:0.00000, loss_test:0.02108, lr:5.27e-02, fs:0.86170 (r=0.818,p=0.910),  time:34.816, tt:5431.272\n",
      "Ep:156, loss:0.00000, loss_test:0.02108, lr:5.27e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.808, tt:5464.928\n",
      "Ep:157, loss:0.00000, loss_test:0.02213, lr:5.27e-02, fs:0.88043 (r=0.818,p=0.953),  time:34.819, tt:5501.391\n",
      "Ep:158, loss:0.00000, loss_test:0.02183, lr:5.27e-02, fs:0.88298 (r=0.838,p=0.933),  time:34.819, tt:5536.256\n",
      "Ep:159, loss:0.00000, loss_test:0.02216, lr:5.27e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.807, tt:5569.053\n",
      "Ep:160, loss:0.00000, loss_test:0.02203, lr:5.27e-02, fs:0.86813 (r=0.798,p=0.952),  time:34.804, tt:5603.412\n",
      "Ep:161, loss:0.00000, loss_test:0.02222, lr:5.21e-02, fs:0.88770 (r=0.838,p=0.943),  time:34.798, tt:5637.208\n",
      "Ep:162, loss:0.00000, loss_test:0.02210, lr:5.16e-02, fs:0.86022 (r=0.808,p=0.920),  time:34.796, tt:5671.677\n",
      "Ep:163, loss:0.00000, loss_test:0.02317, lr:5.11e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.791, tt:5705.772\n",
      "Ep:164, loss:0.00000, loss_test:0.02183, lr:5.06e-02, fs:0.86339 (r=0.798,p=0.940),  time:34.781, tt:5738.893\n",
      "Ep:165, loss:0.00000, loss_test:0.02307, lr:5.01e-02, fs:0.89362 (r=0.848,p=0.944),  time:34.772, tt:5772.224\n",
      "Ep:166, loss:0.00000, loss_test:0.02284, lr:4.96e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.751, tt:5803.422\n",
      "Ep:167, loss:0.00000, loss_test:0.02301, lr:4.91e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.750, tt:5837.980\n",
      "Ep:168, loss:0.00000, loss_test:0.02326, lr:4.86e-02, fs:0.86486 (r=0.808,p=0.930),  time:34.734, tt:5870.108\n",
      "Ep:169, loss:0.00000, loss_test:0.02270, lr:4.81e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.717, tt:5901.899\n",
      "Ep:170, loss:0.00000, loss_test:0.02371, lr:4.76e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.716, tt:5936.511\n",
      "Ep:171, loss:0.00000, loss_test:0.02311, lr:4.71e-02, fs:0.87097 (r=0.818,p=0.931),  time:34.709, tt:5969.917\n",
      "Ep:172, loss:0.00000, loss_test:0.02339, lr:4.67e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.705, tt:6003.887\n",
      "Ep:173, loss:0.00000, loss_test:0.02369, lr:4.62e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.700, tt:6037.868\n",
      "Ep:174, loss:0.00000, loss_test:0.02376, lr:4.57e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.703, tt:6073.110\n",
      "Ep:175, loss:0.00000, loss_test:0.02361, lr:4.53e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.705, tt:6108.003\n",
      "Ep:176, loss:0.00000, loss_test:0.02367, lr:4.48e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.692, tt:6140.502\n",
      "Ep:177, loss:0.00000, loss_test:0.02388, lr:4.44e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.681, tt:6173.255\n",
      "Ep:178, loss:0.00000, loss_test:0.02386, lr:4.39e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.682, tt:6208.162\n",
      "Ep:179, loss:0.00000, loss_test:0.02403, lr:4.35e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.673, tt:6241.091\n",
      "Ep:180, loss:0.00000, loss_test:0.02404, lr:4.31e-02, fs:0.85393 (r=0.768,p=0.962),  time:34.662, tt:6273.837\n",
      "Ep:181, loss:0.00000, loss_test:0.02419, lr:4.26e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.656, tt:6307.419\n",
      "Ep:182, loss:0.00000, loss_test:0.02407, lr:4.22e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.657, tt:6342.221\n",
      "Ep:183, loss:0.00000, loss_test:0.02431, lr:4.18e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.652, tt:6375.960\n",
      "Ep:184, loss:0.00000, loss_test:0.02423, lr:4.14e-02, fs:0.86667 (r=0.788,p=0.963),  time:34.651, tt:6410.368\n",
      "Ep:185, loss:0.00000, loss_test:0.02443, lr:4.10e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.645, tt:6443.981\n",
      "Ep:186, loss:0.00000, loss_test:0.02418, lr:4.05e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.638, tt:6477.252\n",
      "Ep:187, loss:0.00000, loss_test:0.02440, lr:4.01e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.635, tt:6511.385\n",
      "Ep:188, loss:0.00000, loss_test:0.02441, lr:3.97e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.630, tt:6545.142\n",
      "Ep:189, loss:0.00000, loss_test:0.02435, lr:3.93e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.644, tt:6582.417\n",
      "Ep:190, loss:0.00000, loss_test:0.02446, lr:3.89e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.638, tt:6615.793\n",
      "Ep:191, loss:0.00000, loss_test:0.02455, lr:3.86e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.627, tt:6648.326\n",
      "Ep:192, loss:0.00000, loss_test:0.02446, lr:3.82e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.622, tt:6682.009\n",
      "Ep:193, loss:0.00000, loss_test:0.02449, lr:3.78e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.612, tt:6714.760\n",
      "Ep:194, loss:0.00000, loss_test:0.02453, lr:3.74e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.607, tt:6748.272\n",
      "Ep:195, loss:0.00000, loss_test:0.02462, lr:3.70e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.593, tt:6780.150\n",
      "Ep:196, loss:0.00000, loss_test:0.02465, lr:3.67e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.588, tt:6813.930\n",
      "Ep:197, loss:0.00000, loss_test:0.02462, lr:3.63e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.581, tt:6847.099\n",
      "Ep:198, loss:0.00000, loss_test:0.02467, lr:3.59e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.574, tt:6880.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:199, loss:0.00000, loss_test:0.02474, lr:3.56e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.570, tt:6913.935\n",
      "Ep:200, loss:0.00000, loss_test:0.02489, lr:3.52e-02, fs:0.88525 (r=0.818,p=0.964),  time:34.567, tt:6947.983\n",
      "Ep:201, loss:0.00000, loss_test:0.02471, lr:3.49e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.560, tt:6981.069\n",
      "Ep:202, loss:0.00000, loss_test:0.02474, lr:3.45e-02, fs:0.87293 (r=0.798,p=0.963),  time:34.550, tt:7013.601\n",
      "Ep:203, loss:0.00000, loss_test:0.02498, lr:3.42e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.541, tt:7046.386\n",
      "Ep:204, loss:0.00000, loss_test:0.02478, lr:3.38e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.530, tt:7078.740\n",
      "Ep:205, loss:0.00000, loss_test:0.02486, lr:3.35e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.520, tt:7111.196\n",
      "Ep:206, loss:0.00000, loss_test:0.02492, lr:3.32e-02, fs:0.86034 (r=0.778,p=0.963),  time:34.506, tt:7142.674\n",
      "Ep:207, loss:0.00000, loss_test:0.02490, lr:3.28e-02, fs:0.89130 (r=0.828,p=0.965),  time:34.508, tt:7177.653\n",
      "Ep:208, loss:0.00000, loss_test:0.02485, lr:3.25e-02, fs:0.83429 (r=0.737,p=0.961),  time:34.486, tt:7207.589\n",
      "Ep:209, loss:0.00000, loss_test:0.02507, lr:3.22e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.457, tt:7235.924\n",
      "Ep:210, loss:0.00000, loss_test:0.02483, lr:3.19e-02, fs:0.83429 (r=0.737,p=0.961),  time:34.435, tt:7265.738\n",
      "Ep:211, loss:0.00000, loss_test:0.02508, lr:3.15e-02, fs:0.89730 (r=0.838,p=0.965),  time:34.417, tt:7296.353\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12619, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:31.643, tt:31.643\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12515, lr:1.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:31.606, tt:63.211\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12397, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:32.289, tt:96.868\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12261, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:32.995, tt:131.981\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12133, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:33.229, tt:166.145\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.12005, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:33.525, tt:201.153\n",
      "Ep:6, loss:0.00025, loss_test:0.11864, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.162, tt:239.131\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11739, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.261, tt:274.090\n",
      "Ep:8, loss:0.00025, loss_test:0.11654, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:34.278, tt:308.499\n",
      "Ep:9, loss:0.00025, loss_test:0.11577, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:34.226, tt:342.265\n",
      "Ep:10, loss:0.00024, loss_test:0.11480, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:34.418, tt:378.596\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11366, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:34.441, tt:413.290\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00024, loss_test:0.11255, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:34.500, tt:448.495\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00023, loss_test:0.11159, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:34.474, tt:482.630\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00023, loss_test:0.11103, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:34.526, tt:517.885\n",
      "Ep:15, loss:0.00023, loss_test:0.10964, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:34.462, tt:551.389\n",
      "Ep:16, loss:0.00022, loss_test:0.10823, lr:1.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:34.479, tt:586.150\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.10713, lr:1.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:34.458, tt:620.247\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10642, lr:1.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:34.431, tt:654.180\n",
      "Ep:19, loss:0.00021, loss_test:0.10475, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:34.468, tt:689.369\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.10348, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:34.414, tt:722.705\n",
      "Ep:21, loss:0.00020, loss_test:0.10203, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:34.368, tt:756.101\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00020, loss_test:0.10041, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:34.375, tt:790.622\n",
      "Ep:23, loss:0.00019, loss_test:0.09871, lr:1.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:34.402, tt:825.648\n",
      "Ep:24, loss:0.00019, loss_test:0.09576, lr:1.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:34.355, tt:858.863\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00018, loss_test:0.09414, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:34.371, tt:893.637\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.09206, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:34.292, tt:925.875\n",
      "Ep:27, loss:0.00017, loss_test:0.09002, lr:1.00e-02, fs:0.74167 (r=0.899,p=0.631),  time:34.284, tt:959.964\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00017, loss_test:0.08734, lr:1.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:34.261, tt:993.563\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.08495, lr:1.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:34.312, tt:1029.371\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00016, loss_test:0.08344, lr:1.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:34.242, tt:1061.489\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00015, loss_test:0.08041, lr:1.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:34.192, tt:1094.158\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00015, loss_test:0.08049, lr:1.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:34.168, tt:1127.559\n",
      "Ep:33, loss:0.00014, loss_test:0.07711, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:34.186, tt:1162.311\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00014, loss_test:0.07611, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:34.215, tt:1197.536\n",
      "Ep:35, loss:0.00014, loss_test:0.07428, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:34.234, tt:1232.410\n",
      "Ep:36, loss:0.00013, loss_test:0.07268, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:34.200, tt:1265.402\n",
      "Ep:37, loss:0.00012, loss_test:0.07330, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:34.230, tt:1300.744\n",
      "Ep:38, loss:0.00012, loss_test:0.06992, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:34.236, tt:1335.189\n",
      "Ep:39, loss:0.00012, loss_test:0.07131, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:34.234, tt:1369.353\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00013, loss_test:0.07553, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:34.238, tt:1403.740\n",
      "Ep:41, loss:0.00012, loss_test:0.07359, lr:1.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.272, tt:1439.420\n",
      "Ep:42, loss:0.00011, loss_test:0.06956, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:34.270, tt:1473.618\n",
      "Ep:43, loss:0.00010, loss_test:0.07224, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.288, tt:1508.657\n",
      "Ep:44, loss:0.00010, loss_test:0.06598, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:34.272, tt:1542.226\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.06587, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:34.268, tt:1576.339\n",
      "Ep:46, loss:0.00009, loss_test:0.07415, lr:1.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.274, tt:1610.867\n",
      "Ep:47, loss:0.00010, loss_test:0.06178, lr:1.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:34.242, tt:1643.638\n",
      "Ep:48, loss:0.00009, loss_test:0.06054, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:34.260, tt:1678.734\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:49, loss:0.00008, loss_test:0.06870, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:34.253, tt:1712.646\n",
      "Ep:50, loss:0.00008, loss_test:0.06067, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:34.254, tt:1746.958\n",
      "Ep:51, loss:0.00007, loss_test:0.05777, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:34.247, tt:1780.868\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.06290, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:34.288, tt:1817.282\n",
      "Ep:53, loss:0.00007, loss_test:0.05886, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:34.278, tt:1851.024\n",
      "Ep:54, loss:0.00006, loss_test:0.05430, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:34.285, tt:1885.697\n",
      "Ep:55, loss:0.00007, loss_test:0.05508, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:34.286, tt:1920.017\n",
      "Ep:56, loss:0.00006, loss_test:0.06705, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:34.289, tt:1954.472\n",
      "Ep:57, loss:0.00006, loss_test:0.05465, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:34.280, tt:1988.259\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00006, loss_test:0.05457, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:34.261, tt:2021.374\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00005, loss_test:0.06042, lr:1.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:34.307, tt:2058.450\n",
      "Ep:60, loss:0.00006, loss_test:0.05801, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.299, tt:2092.241\n",
      "Ep:61, loss:0.00005, loss_test:0.05345, lr:1.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:34.303, tt:2126.794\n",
      "Ep:62, loss:0.00005, loss_test:0.04874, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:34.313, tt:2161.726\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00005, loss_test:0.05445, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:34.318, tt:2196.368\n",
      "Ep:64, loss:0.00005, loss_test:0.05202, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.322, tt:2230.898\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00004, loss_test:0.04534, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:34.319, tt:2265.066\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.04950, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:34.331, tt:2300.146\n",
      "Ep:67, loss:0.00004, loss_test:0.05620, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:34.333, tt:2334.658\n",
      "Ep:68, loss:0.00004, loss_test:0.04840, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:34.331, tt:2368.828\n",
      "Ep:69, loss:0.00004, loss_test:0.04361, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.338, tt:2403.631\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00004, loss_test:0.04566, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.337, tt:2437.927\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00006, loss_test:0.04904, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.326, tt:2471.448\n",
      "Ep:72, loss:0.00005, loss_test:0.06066, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.309, tt:2504.572\n",
      "Ep:73, loss:0.00004, loss_test:0.04652, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:34.303, tt:2538.408\n",
      "Ep:74, loss:0.00004, loss_test:0.04980, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.292, tt:2571.877\n",
      "Ep:75, loss:0.00003, loss_test:0.04793, lr:1.00e-02, fs:0.92611 (r=0.949,p=0.904),  time:34.283, tt:2605.494\n",
      "Ep:76, loss:0.00003, loss_test:0.04733, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.283, tt:2639.758\n",
      "Ep:77, loss:0.00003, loss_test:0.05217, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.289, tt:2674.554\n",
      "Ep:78, loss:0.00003, loss_test:0.05103, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:34.292, tt:2709.073\n",
      "Ep:79, loss:0.00003, loss_test:0.04938, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:34.293, tt:2743.441\n",
      "Ep:80, loss:0.00003, loss_test:0.05116, lr:1.00e-02, fs:0.89655 (r=0.919,p=0.875),  time:34.295, tt:2777.880\n",
      "Ep:81, loss:0.00003, loss_test:0.04800, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:34.311, tt:2813.530\n",
      "Ep:82, loss:0.00003, loss_test:0.06427, lr:9.90e-03, fs:0.82927 (r=0.859,p=0.802),  time:34.327, tt:2849.162\n",
      "Ep:83, loss:0.00003, loss_test:0.05033, lr:9.80e-03, fs:0.89756 (r=0.929,p=0.868),  time:34.356, tt:2885.941\n",
      "Ep:84, loss:0.00003, loss_test:0.04637, lr:9.70e-03, fs:0.90816 (r=0.899,p=0.918),  time:34.379, tt:2922.201\n",
      "Ep:85, loss:0.00003, loss_test:0.05616, lr:9.61e-03, fs:0.88235 (r=0.909,p=0.857),  time:34.409, tt:2959.136\n",
      "Ep:86, loss:0.00004, loss_test:0.04411, lr:9.51e-03, fs:0.91089 (r=0.929,p=0.893),  time:34.455, tt:2997.570\n",
      "Ep:87, loss:0.00003, loss_test:0.04441, lr:9.41e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.460, tt:3032.465\n",
      "Ep:88, loss:0.00003, loss_test:0.04884, lr:9.32e-03, fs:0.92079 (r=0.939,p=0.903),  time:34.486, tt:3069.243\n",
      "Ep:89, loss:0.00003, loss_test:0.04634, lr:9.23e-03, fs:0.90640 (r=0.929,p=0.885),  time:34.505, tt:3105.435\n",
      "Ep:90, loss:0.00003, loss_test:0.05111, lr:9.14e-03, fs:0.90732 (r=0.939,p=0.877),  time:34.518, tt:3141.147\n",
      "Ep:91, loss:0.00002, loss_test:0.04319, lr:9.04e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.539, tt:3177.558\n",
      "Ep:92, loss:0.00002, loss_test:0.04672, lr:8.95e-03, fs:0.91707 (r=0.949,p=0.887),  time:34.564, tt:3214.415\n",
      "Ep:93, loss:0.00002, loss_test:0.04411, lr:8.86e-03, fs:0.90385 (r=0.949,p=0.862),  time:34.580, tt:3250.480\n",
      "Ep:94, loss:0.00002, loss_test:0.04725, lr:8.78e-03, fs:0.91707 (r=0.949,p=0.887),  time:34.601, tt:3287.108\n",
      "Ep:95, loss:0.00002, loss_test:0.04531, lr:8.69e-03, fs:0.93532 (r=0.949,p=0.922),  time:34.615, tt:3322.995\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.05335, lr:8.69e-03, fs:0.91176 (r=0.939,p=0.886),  time:34.625, tt:3358.642\n",
      "Ep:97, loss:0.00002, loss_test:0.04272, lr:8.69e-03, fs:0.92000 (r=0.929,p=0.911),  time:34.648, tt:3395.486\n",
      "Ep:98, loss:0.00002, loss_test:0.04678, lr:8.69e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.669, tt:3432.188\n",
      "Ep:99, loss:0.00002, loss_test:0.04538, lr:8.69e-03, fs:0.91542 (r=0.929,p=0.902),  time:34.692, tt:3469.236\n",
      "Ep:100, loss:0.00002, loss_test:0.04759, lr:8.69e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.699, tt:3504.608\n",
      "Ep:101, loss:0.00002, loss_test:0.04557, lr:8.69e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.730, tt:3542.498\n",
      "Ep:102, loss:0.00002, loss_test:0.04264, lr:8.69e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.743, tt:3578.549\n",
      "Ep:103, loss:0.00002, loss_test:0.06247, lr:8.69e-03, fs:0.84211 (r=0.808,p=0.879),  time:34.773, tt:3616.421\n",
      "Ep:104, loss:0.00002, loss_test:0.04345, lr:8.69e-03, fs:0.90355 (r=0.899,p=0.908),  time:34.790, tt:3652.989\n",
      "Ep:105, loss:0.00002, loss_test:0.05525, lr:8.69e-03, fs:0.91626 (r=0.939,p=0.894),  time:34.790, tt:3687.757\n",
      "Ep:106, loss:0.00002, loss_test:0.04440, lr:8.69e-03, fs:0.91282 (r=0.899,p=0.927),  time:34.796, tt:3723.130\n",
      "Ep:107, loss:0.00002, loss_test:0.04927, lr:8.60e-03, fs:0.92611 (r=0.949,p=0.904),  time:34.810, tt:3759.444\n",
      "Ep:108, loss:0.00002, loss_test:0.04980, lr:8.51e-03, fs:0.93069 (r=0.949,p=0.913),  time:34.818, tt:3795.150\n",
      "Ep:109, loss:0.00002, loss_test:0.04397, lr:8.43e-03, fs:0.91753 (r=0.899,p=0.937),  time:34.834, tt:3831.727\n",
      "Ep:110, loss:0.00001, loss_test:0.04888, lr:8.35e-03, fs:0.93069 (r=0.949,p=0.913),  time:34.845, tt:3867.837\n",
      "Ep:111, loss:0.00001, loss_test:0.04903, lr:8.26e-03, fs:0.93532 (r=0.949,p=0.922),  time:34.853, tt:3903.580\n",
      "Ep:112, loss:0.00001, loss_test:0.04579, lr:8.18e-03, fs:0.90816 (r=0.899,p=0.918),  time:34.890, tt:3942.560\n",
      "Ep:113, loss:0.00001, loss_test:0.04837, lr:8.10e-03, fs:0.93532 (r=0.949,p=0.922),  time:34.903, tt:3978.946\n",
      "Ep:114, loss:0.00001, loss_test:0.04656, lr:8.02e-03, fs:0.90816 (r=0.899,p=0.918),  time:34.923, tt:4016.145\n",
      "Ep:115, loss:0.00001, loss_test:0.05179, lr:7.94e-03, fs:0.90816 (r=0.899,p=0.918),  time:34.933, tt:4052.259\n",
      "Ep:116, loss:0.00001, loss_test:0.04689, lr:7.86e-03, fs:0.93532 (r=0.949,p=0.922),  time:34.928, tt:4086.591\n",
      "Ep:117, loss:0.00001, loss_test:0.04614, lr:7.78e-03, fs:0.91282 (r=0.899,p=0.927),  time:34.941, tt:4123.097\n",
      "Ep:118, loss:0.00001, loss_test:0.04865, lr:7.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:34.949, tt:4158.979\n",
      "Ep:119, loss:0.00001, loss_test:0.04732, lr:7.62e-03, fs:0.91282 (r=0.899,p=0.927),  time:34.961, tt:4195.362\n",
      "Ep:120, loss:0.00001, loss_test:0.04991, lr:7.55e-03, fs:0.91753 (r=0.899,p=0.937),  time:34.973, tt:4231.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:121, loss:0.00001, loss_test:0.04744, lr:7.47e-03, fs:0.91753 (r=0.899,p=0.937),  time:34.974, tt:4266.776\n",
      "Ep:122, loss:0.00001, loss_test:0.04685, lr:7.40e-03, fs:0.92228 (r=0.899,p=0.947),  time:34.985, tt:4303.147\n",
      "Ep:123, loss:0.00001, loss_test:0.04984, lr:7.32e-03, fs:0.91282 (r=0.899,p=0.927),  time:35.001, tt:4340.184\n",
      "Ep:124, loss:0.00001, loss_test:0.04715, lr:7.25e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.006, tt:4375.701\n",
      "Ep:125, loss:0.00001, loss_test:0.04677, lr:7.18e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.008, tt:4411.035\n",
      "Ep:126, loss:0.00001, loss_test:0.04953, lr:7.11e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.021, tt:4447.708\n",
      "Ep:127, loss:0.00001, loss_test:0.04884, lr:7.03e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.023, tt:4482.903\n",
      "Ep:128, loss:0.00001, loss_test:0.04835, lr:6.96e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.043, tt:4520.588\n",
      "Ep:129, loss:0.00001, loss_test:0.04746, lr:6.89e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.038, tt:4554.935\n",
      "Ep:130, loss:0.00001, loss_test:0.04868, lr:6.83e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.067, tt:4593.724\n",
      "Ep:131, loss:0.00000, loss_test:0.04734, lr:6.76e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.085, tt:4631.276\n",
      "Ep:132, loss:0.00000, loss_test:0.04841, lr:6.69e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.100, tt:4668.336\n",
      "Ep:133, loss:0.00000, loss_test:0.04749, lr:6.62e-03, fs:0.92228 (r=0.899,p=0.947),  time:35.106, tt:4704.168\n",
      "Ep:134, loss:0.00000, loss_test:0.04658, lr:6.56e-03, fs:0.91753 (r=0.899,p=0.937),  time:35.125, tt:4741.877\n",
      "Ep:135, loss:0.00000, loss_test:0.04776, lr:6.49e-03, fs:0.92228 (r=0.899,p=0.947),  time:35.133, tt:4778.106\n",
      "Ep:136, loss:0.00000, loss_test:0.04673, lr:6.43e-03, fs:0.92228 (r=0.899,p=0.947),  time:35.145, tt:4814.843\n",
      "Ep:137, loss:0.00000, loss_test:0.04852, lr:6.36e-03, fs:0.92228 (r=0.899,p=0.947),  time:35.153, tt:4851.124\n",
      "Ep:138, loss:0.00000, loss_test:0.04758, lr:6.30e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.156, tt:4886.720\n",
      "Ep:139, loss:0.00000, loss_test:0.04747, lr:6.24e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.166, tt:4923.305\n",
      "Ep:140, loss:0.00000, loss_test:0.04789, lr:6.17e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.186, tt:4961.252\n",
      "Ep:141, loss:0.00000, loss_test:0.04640, lr:6.11e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.183, tt:4995.924\n",
      "Ep:142, loss:0.00000, loss_test:0.04727, lr:6.05e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.188, tt:5031.882\n",
      "Ep:143, loss:0.00000, loss_test:0.04633, lr:5.99e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.195, tt:5068.122\n",
      "Ep:144, loss:0.00000, loss_test:0.04876, lr:5.93e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.195, tt:5103.334\n",
      "Ep:145, loss:0.00000, loss_test:0.04707, lr:5.87e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.201, tt:5139.300\n",
      "Ep:146, loss:0.00000, loss_test:0.04827, lr:5.81e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.203, tt:5174.860\n",
      "Ep:147, loss:0.00000, loss_test:0.04752, lr:5.75e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.208, tt:5210.780\n",
      "Ep:148, loss:0.00000, loss_test:0.04768, lr:5.70e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.219, tt:5247.561\n",
      "Ep:149, loss:0.00000, loss_test:0.04749, lr:5.64e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.225, tt:5283.787\n",
      "Ep:150, loss:0.00000, loss_test:0.04751, lr:5.58e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.226, tt:5319.138\n",
      "Ep:151, loss:0.00000, loss_test:0.04728, lr:5.53e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.247, tt:5357.514\n",
      "Ep:152, loss:0.00000, loss_test:0.04802, lr:5.47e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.258, tt:5394.501\n",
      "Ep:153, loss:0.00000, loss_test:0.04727, lr:5.42e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.273, tt:5432.091\n",
      "Ep:154, loss:0.00000, loss_test:0.04799, lr:5.36e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.280, tt:5468.340\n",
      "Ep:155, loss:0.00000, loss_test:0.04708, lr:5.31e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.284, tt:5504.257\n",
      "Ep:156, loss:0.00000, loss_test:0.04970, lr:5.26e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.288, tt:5540.197\n",
      "Ep:157, loss:0.00000, loss_test:0.04729, lr:5.20e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.302, tt:5577.650\n",
      "Ep:158, loss:0.00000, loss_test:0.04941, lr:5.15e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.311, tt:5614.527\n",
      "Ep:159, loss:0.00000, loss_test:0.04746, lr:5.10e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.317, tt:5650.670\n",
      "Ep:160, loss:0.00000, loss_test:0.04965, lr:5.05e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.327, tt:5687.677\n",
      "Ep:161, loss:0.00000, loss_test:0.04811, lr:5.00e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.341, tt:5725.257\n",
      "Ep:162, loss:0.00000, loss_test:0.04897, lr:4.95e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.345, tt:5761.269\n",
      "Ep:163, loss:0.00000, loss_test:0.04778, lr:4.90e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.356, tt:5798.310\n",
      "Ep:164, loss:0.00000, loss_test:0.04964, lr:4.85e-03, fs:0.93194 (r=0.899,p=0.967),  time:35.361, tt:5834.567\n",
      "Ep:165, loss:0.00000, loss_test:0.04822, lr:4.80e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.367, tt:5870.985\n",
      "Ep:166, loss:0.00000, loss_test:0.04964, lr:4.75e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.359, tt:5904.984\n",
      "Ep:167, loss:0.00000, loss_test:0.04786, lr:4.71e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.361, tt:5940.619\n",
      "Ep:168, loss:0.00000, loss_test:0.04894, lr:4.66e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.372, tt:5977.905\n",
      "Ep:169, loss:0.00000, loss_test:0.04817, lr:4.61e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.374, tt:6013.660\n",
      "Ep:170, loss:0.00000, loss_test:0.04909, lr:4.57e-03, fs:0.92228 (r=0.899,p=0.947),  time:35.386, tt:6051.015\n",
      "Ep:171, loss:0.00000, loss_test:0.04849, lr:4.52e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.404, tt:6089.443\n",
      "Ep:172, loss:0.00000, loss_test:0.04830, lr:4.48e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.408, tt:6125.578\n",
      "Ep:173, loss:0.00000, loss_test:0.04806, lr:4.43e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.416, tt:6162.435\n",
      "Ep:174, loss:0.00000, loss_test:0.04843, lr:4.39e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.426, tt:6199.579\n",
      "Ep:175, loss:0.00000, loss_test:0.04775, lr:4.34e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.427, tt:6235.202\n",
      "Ep:176, loss:0.00000, loss_test:0.04950, lr:4.30e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.434, tt:6271.793\n",
      "Ep:177, loss:0.00000, loss_test:0.04806, lr:4.26e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.446, tt:6309.417\n",
      "Ep:178, loss:0.00000, loss_test:0.04865, lr:4.21e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.449, tt:6345.353\n",
      "Ep:179, loss:0.00000, loss_test:0.04828, lr:4.17e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.457, tt:6382.345\n",
      "Ep:180, loss:0.00000, loss_test:0.04833, lr:4.13e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.459, tt:6418.155\n",
      "Ep:181, loss:0.00000, loss_test:0.04939, lr:4.09e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.465, tt:6454.586\n",
      "Ep:182, loss:0.00000, loss_test:0.04862, lr:4.05e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.477, tt:6492.241\n",
      "Ep:183, loss:0.00000, loss_test:0.04886, lr:4.01e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.484, tt:6529.117\n",
      "Ep:184, loss:0.00000, loss_test:0.04801, lr:3.97e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.493, tt:6566.274\n",
      "Ep:185, loss:0.00000, loss_test:0.04931, lr:3.93e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.494, tt:6601.903\n",
      "Ep:186, loss:0.00000, loss_test:0.04832, lr:3.89e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.499, tt:6638.399\n",
      "Ep:187, loss:0.00000, loss_test:0.04904, lr:3.85e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.505, tt:6674.960\n",
      "Ep:188, loss:0.00000, loss_test:0.04884, lr:3.81e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.508, tt:6710.999\n",
      "Ep:189, loss:0.00000, loss_test:0.04854, lr:3.77e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.516, tt:6748.117\n",
      "Ep:190, loss:0.00000, loss_test:0.04864, lr:3.73e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.519, tt:6784.187\n",
      "Ep:191, loss:0.00000, loss_test:0.04862, lr:3.70e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.523, tt:6820.437\n",
      "Ep:192, loss:0.00000, loss_test:0.04897, lr:3.66e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.528, tt:6856.838\n",
      "Ep:193, loss:0.00000, loss_test:0.04752, lr:3.62e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.531, tt:6892.991\n",
      "Ep:194, loss:0.00000, loss_test:0.04836, lr:3.59e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.533, tt:6928.892\n",
      "Ep:195, loss:0.00000, loss_test:0.04855, lr:3.55e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.532, tt:6964.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:196, loss:0.00000, loss_test:0.04878, lr:3.52e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.534, tt:7000.191\n",
      "Ep:197, loss:0.00000, loss_test:0.04839, lr:3.48e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.540, tt:7036.904\n",
      "Ep:198, loss:0.00000, loss_test:0.04832, lr:3.45e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.545, tt:7073.431\n",
      "Ep:199, loss:0.00000, loss_test:0.04898, lr:3.41e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.538, tt:7107.592\n",
      "Ep:200, loss:0.00000, loss_test:0.04800, lr:3.38e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.543, tt:7144.204\n",
      "Ep:201, loss:0.00000, loss_test:0.04874, lr:3.34e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.544, tt:7179.926\n",
      "Ep:202, loss:0.00000, loss_test:0.04827, lr:3.31e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.549, tt:7216.474\n",
      "Ep:203, loss:0.00000, loss_test:0.04848, lr:3.28e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.552, tt:7252.611\n",
      "Ep:204, loss:0.00000, loss_test:0.04848, lr:3.24e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.554, tt:7288.522\n",
      "Ep:205, loss:0.00000, loss_test:0.04823, lr:3.21e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.560, tt:7325.315\n",
      "Ep:206, loss:0.00000, loss_test:0.04840, lr:3.18e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.562, tt:7361.260\n",
      "Ep:207, loss:0.00000, loss_test:0.04797, lr:3.15e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.566, tt:7397.727\n",
      "Ep:208, loss:0.00000, loss_test:0.04839, lr:3.12e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.554, tt:7430.687\n",
      "Ep:209, loss:0.00000, loss_test:0.04838, lr:3.09e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.521, tt:7459.355\n",
      "Ep:210, loss:0.00000, loss_test:0.04829, lr:3.05e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.479, tt:7486.048\n",
      "Ep:211, loss:0.00000, loss_test:0.04800, lr:3.02e-03, fs:0.92708 (r=0.899,p=0.957),  time:35.455, tt:7516.463\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02888, lr:6.00e-02, fs:0.65766 (r=0.737,p=0.593),  time:32.294, tt:32.294\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00006, loss_test:0.02278, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:32.012, tt:64.025\n",
      "Ep:2, loss:0.00005, loss_test:0.02442, lr:6.00e-02, fs:0.66667 (r=0.960,p=0.511),  time:33.440, tt:100.321\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02427, lr:6.00e-02, fs:0.66431 (r=0.949,p=0.511),  time:33.614, tt:134.457\n",
      "Ep:4, loss:0.00005, loss_test:0.02372, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:34.215, tt:171.075\n",
      "Ep:5, loss:0.00005, loss_test:0.02344, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:34.401, tt:206.405\n",
      "Ep:6, loss:0.00005, loss_test:0.02333, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:34.641, tt:242.488\n",
      "Ep:7, loss:0.00005, loss_test:0.02314, lr:6.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:34.743, tt:277.945\n",
      "Ep:8, loss:0.00005, loss_test:0.02293, lr:6.00e-02, fs:0.65441 (r=0.899,p=0.514),  time:34.631, tt:311.677\n",
      "Ep:9, loss:0.00005, loss_test:0.02267, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:34.679, tt:346.790\n",
      "Ep:10, loss:0.00005, loss_test:0.02224, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:34.731, tt:382.041\n",
      "Ep:11, loss:0.00005, loss_test:0.02163, lr:6.00e-02, fs:0.66912 (r=0.919,p=0.526),  time:34.787, tt:417.442\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00005, loss_test:0.02099, lr:6.00e-02, fs:0.66914 (r=0.909,p=0.529),  time:34.786, tt:452.215\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02044, lr:6.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:34.785, tt:486.995\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.02007, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:34.772, tt:521.584\n",
      "Ep:15, loss:0.00004, loss_test:0.01980, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:34.778, tt:556.452\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01954, lr:6.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:34.844, tt:592.356\n",
      "Ep:17, loss:0.00004, loss_test:0.01926, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:34.858, tt:627.446\n",
      "Ep:18, loss:0.00004, loss_test:0.01895, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:34.831, tt:661.780\n",
      "Ep:19, loss:0.00004, loss_test:0.01862, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:34.824, tt:696.472\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01826, lr:6.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:34.807, tt:730.952\n",
      "Ep:21, loss:0.00004, loss_test:0.01795, lr:6.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:34.847, tt:766.644\n",
      "Ep:22, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:34.855, tt:801.676\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01733, lr:6.00e-02, fs:0.71042 (r=0.929,p=0.575),  time:34.835, tt:836.032\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01695, lr:6.00e-02, fs:0.72656 (r=0.939,p=0.592),  time:34.771, tt:869.283\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01657, lr:6.00e-02, fs:0.73810 (r=0.939,p=0.608),  time:34.796, tt:904.703\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:34.782, tt:939.125\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:34.739, tt:972.699\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.76190 (r=0.970,p=0.627),  time:34.725, tt:1007.024\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01534, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:34.681, tt:1040.424\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01507, lr:6.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:34.734, tt:1076.756\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:34.717, tt:1110.942\n",
      "Ep:32, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.78661 (r=0.949,p=0.671),  time:34.748, tt:1146.690\n",
      "Ep:33, loss:0.00002, loss_test:0.01432, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:34.764, tt:1181.982\n",
      "Ep:34, loss:0.00002, loss_test:0.01417, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.760, tt:1216.602\n",
      "Ep:35, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:34.758, tt:1251.288\n",
      "Ep:36, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.77391 (r=0.899,p=0.679),  time:34.751, tt:1285.795\n",
      "Ep:37, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:34.749, tt:1320.449\n",
      "Ep:38, loss:0.00002, loss_test:0.01385, lr:6.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:34.769, tt:1355.997\n",
      "Ep:39, loss:0.00002, loss_test:0.01393, lr:6.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:34.757, tt:1390.270\n",
      "Ep:40, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.76147 (r=0.838,p=0.697),  time:34.736, tt:1424.184\n",
      "Ep:41, loss:0.00001, loss_test:0.01407, lr:6.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:34.727, tt:1458.520\n",
      "Ep:42, loss:0.00001, loss_test:0.01409, lr:5.94e-02, fs:0.75576 (r=0.828,p=0.695),  time:34.687, tt:1491.537\n",
      "Ep:43, loss:0.00001, loss_test:0.01427, lr:5.88e-02, fs:0.76636 (r=0.828,p=0.713),  time:34.712, tt:1527.337\n",
      "Ep:44, loss:0.00001, loss_test:0.01442, lr:5.82e-02, fs:0.77725 (r=0.828,p=0.732),  time:34.699, tt:1561.445\n",
      "Ep:45, loss:0.00001, loss_test:0.01448, lr:5.76e-02, fs:0.77725 (r=0.828,p=0.732),  time:34.687, tt:1595.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00001, loss_test:0.01441, lr:5.71e-02, fs:0.78846 (r=0.828,p=0.752),  time:34.682, tt:1630.071\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01446, lr:5.71e-02, fs:0.78846 (r=0.828,p=0.752),  time:34.675, tt:1664.399\n",
      "Ep:48, loss:0.00001, loss_test:0.01458, lr:5.71e-02, fs:0.79227 (r=0.828,p=0.759),  time:34.674, tt:1699.027\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01472, lr:5.71e-02, fs:0.79612 (r=0.828,p=0.766),  time:34.657, tt:1732.831\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01461, lr:5.71e-02, fs:0.80193 (r=0.838,p=0.769),  time:34.664, tt:1767.866\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01463, lr:5.71e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.683, tt:1803.510\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01494, lr:5.71e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.697, tt:1838.934\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01470, lr:5.71e-02, fs:0.82759 (r=0.848,p=0.808),  time:34.690, tt:1873.282\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01490, lr:5.71e-02, fs:0.82524 (r=0.859,p=0.794),  time:34.696, tt:1908.269\n",
      "Ep:55, loss:0.00001, loss_test:0.01482, lr:5.71e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.695, tt:1942.909\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.01502, lr:5.71e-02, fs:0.84314 (r=0.869,p=0.819),  time:34.668, tt:1976.066\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01515, lr:5.71e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.662, tt:2010.421\n",
      "Ep:58, loss:0.00001, loss_test:0.01519, lr:5.71e-02, fs:0.84314 (r=0.869,p=0.819),  time:34.642, tt:2043.904\n",
      "Ep:59, loss:0.00001, loss_test:0.01536, lr:5.71e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.642, tt:2078.514\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01541, lr:5.71e-02, fs:0.84729 (r=0.869,p=0.827),  time:34.632, tt:2112.544\n",
      "Ep:61, loss:0.00001, loss_test:0.01554, lr:5.71e-02, fs:0.85149 (r=0.869,p=0.835),  time:34.602, tt:2145.305\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01571, lr:5.71e-02, fs:0.85149 (r=0.869,p=0.835),  time:34.575, tt:2178.198\n",
      "Ep:63, loss:0.00001, loss_test:0.01593, lr:5.71e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.547, tt:2211.009\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01596, lr:5.71e-02, fs:0.85149 (r=0.869,p=0.835),  time:34.542, tt:2245.240\n",
      "Ep:65, loss:0.00001, loss_test:0.01634, lr:5.71e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.526, tt:2278.706\n",
      "Ep:66, loss:0.00001, loss_test:0.01635, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.513, tt:2312.375\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01648, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.514, tt:2346.973\n",
      "Ep:68, loss:0.00000, loss_test:0.01684, lr:5.71e-02, fs:0.85000 (r=0.859,p=0.842),  time:34.514, tt:2381.437\n",
      "Ep:69, loss:0.00000, loss_test:0.01662, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.507, tt:2415.457\n",
      "Ep:70, loss:0.00000, loss_test:0.01731, lr:5.71e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.482, tt:2448.187\n",
      "Ep:71, loss:0.00000, loss_test:0.01713, lr:5.71e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.488, tt:2483.160\n",
      "Ep:72, loss:0.00000, loss_test:0.01743, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.476, tt:2516.723\n",
      "Ep:73, loss:0.00000, loss_test:0.01741, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.484, tt:2551.779\n",
      "Ep:74, loss:0.00000, loss_test:0.01792, lr:5.71e-02, fs:0.84422 (r=0.848,p=0.840),  time:34.481, tt:2586.055\n",
      "Ep:75, loss:0.00000, loss_test:0.01758, lr:5.71e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.484, tt:2620.750\n",
      "Ep:76, loss:0.00000, loss_test:0.01826, lr:5.71e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.489, tt:2655.630\n",
      "Ep:77, loss:0.00000, loss_test:0.01801, lr:5.71e-02, fs:0.85572 (r=0.869,p=0.843),  time:34.489, tt:2690.174\n",
      "Ep:78, loss:0.00000, loss_test:0.01866, lr:5.65e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.522, tt:2727.256\n",
      "Ep:79, loss:0.00000, loss_test:0.01819, lr:5.59e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.530, tt:2762.404\n",
      "Ep:80, loss:0.00000, loss_test:0.01894, lr:5.54e-02, fs:0.83249 (r=0.828,p=0.837),  time:34.542, tt:2797.936\n",
      "Ep:81, loss:0.00000, loss_test:0.01871, lr:5.48e-02, fs:0.86139 (r=0.879,p=0.845),  time:34.542, tt:2832.421\n",
      "Ep:82, loss:0.00000, loss_test:0.01913, lr:5.43e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.529, tt:2865.933\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00000, loss_test:0.01933, lr:5.43e-02, fs:0.84694 (r=0.838,p=0.856),  time:34.535, tt:2900.926\n",
      "Ep:84, loss:0.00000, loss_test:0.01928, lr:5.43e-02, fs:0.86000 (r=0.869,p=0.851),  time:34.522, tt:2934.385\n",
      "Ep:85, loss:0.00000, loss_test:0.01949, lr:5.43e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.558, tt:2972.028\n",
      "Ep:86, loss:0.00000, loss_test:0.01997, lr:5.43e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.569, tt:3007.506\n",
      "Ep:87, loss:0.00000, loss_test:0.01979, lr:5.43e-02, fs:0.85279 (r=0.848,p=0.857),  time:34.607, tt:3045.453\n",
      "Ep:88, loss:0.00000, loss_test:0.02024, lr:5.43e-02, fs:0.83505 (r=0.818,p=0.853),  time:34.664, tt:3085.124\n",
      "Ep:89, loss:0.00000, loss_test:0.02028, lr:5.43e-02, fs:0.84103 (r=0.828,p=0.854),  time:34.685, tt:3121.668\n",
      "Ep:90, loss:0.00000, loss_test:0.02036, lr:5.43e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.691, tt:3156.913\n",
      "Ep:91, loss:0.00000, loss_test:0.02063, lr:5.43e-02, fs:0.84536 (r=0.828,p=0.863),  time:34.702, tt:3192.573\n",
      "Ep:92, loss:0.00000, loss_test:0.02055, lr:5.43e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.715, tt:3228.526\n",
      "Ep:93, loss:0.00000, loss_test:0.02113, lr:5.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.731, tt:3264.739\n",
      "Ep:94, loss:0.00000, loss_test:0.02084, lr:5.37e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.744, tt:3300.646\n",
      "Ep:95, loss:0.00000, loss_test:0.02130, lr:5.32e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.744, tt:3335.417\n",
      "Ep:96, loss:0.00000, loss_test:0.02111, lr:5.27e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.751, tt:3370.857\n",
      "Ep:97, loss:0.00000, loss_test:0.02152, lr:5.21e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.771, tt:3407.550\n",
      "Ep:98, loss:0.00000, loss_test:0.02155, lr:5.16e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.804, tt:3445.616\n",
      "Ep:99, loss:0.00000, loss_test:0.02180, lr:5.11e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.819, tt:3481.863\n",
      "Ep:100, loss:0.00000, loss_test:0.02164, lr:5.06e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.815, tt:3516.292\n",
      "Ep:101, loss:0.00000, loss_test:0.02204, lr:5.01e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.833, tt:3552.950\n",
      "Ep:102, loss:0.00000, loss_test:0.02217, lr:4.96e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.840, tt:3588.510\n",
      "Ep:103, loss:0.00000, loss_test:0.02213, lr:4.91e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.842, tt:3623.618\n",
      "Ep:104, loss:0.00000, loss_test:0.02237, lr:4.86e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.855, tt:3659.814\n",
      "Ep:105, loss:0.00000, loss_test:0.02228, lr:4.81e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.865, tt:3695.720\n",
      "Ep:106, loss:0.00000, loss_test:0.02255, lr:4.76e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.878, tt:3731.915\n",
      "Ep:107, loss:0.00000, loss_test:0.02269, lr:4.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.887, tt:3767.803\n",
      "Ep:108, loss:0.00000, loss_test:0.02248, lr:4.67e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.902, tt:3804.286\n",
      "Ep:109, loss:0.00000, loss_test:0.02300, lr:4.62e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.916, tt:3840.754\n",
      "Ep:110, loss:0.00000, loss_test:0.02279, lr:4.57e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.913, tt:3875.288\n",
      "Ep:111, loss:0.00000, loss_test:0.02310, lr:4.53e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.917, tt:3910.702\n",
      "Ep:112, loss:0.00000, loss_test:0.02315, lr:4.48e-02, fs:0.85106 (r=0.808,p=0.899),  time:34.934, tt:3947.595\n",
      "Ep:113, loss:0.00000, loss_test:0.02332, lr:4.44e-02, fs:0.80663 (r=0.737,p=0.890),  time:34.942, tt:3983.375\n",
      "Ep:114, loss:0.00000, loss_test:0.02324, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.951, tt:4019.320\n",
      "Ep:115, loss:0.00000, loss_test:0.02351, lr:4.35e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.961, tt:4055.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00000, loss_test:0.02360, lr:4.31e-02, fs:0.79330 (r=0.717,p=0.887),  time:34.974, tt:4091.938\n",
      "Ep:117, loss:0.00000, loss_test:0.02355, lr:4.26e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.985, tt:4128.215\n",
      "Ep:118, loss:0.00000, loss_test:0.02373, lr:4.22e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.989, tt:4163.713\n",
      "Ep:119, loss:0.00000, loss_test:0.02385, lr:4.18e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.998, tt:4199.741\n",
      "Ep:120, loss:0.00000, loss_test:0.02383, lr:4.14e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.999, tt:4234.862\n",
      "Ep:121, loss:0.00000, loss_test:0.02384, lr:4.10e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.013, tt:4271.606\n",
      "Ep:122, loss:0.00000, loss_test:0.02418, lr:4.05e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.016, tt:4306.968\n",
      "Ep:123, loss:0.00000, loss_test:0.02400, lr:4.01e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.024, tt:4342.970\n",
      "Ep:124, loss:0.00000, loss_test:0.02410, lr:3.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.038, tt:4379.760\n",
      "Ep:125, loss:0.00000, loss_test:0.02423, lr:3.93e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.043, tt:4415.364\n",
      "Ep:126, loss:0.00000, loss_test:0.02420, lr:3.89e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.032, tt:4449.026\n",
      "Ep:127, loss:0.00000, loss_test:0.02439, lr:3.86e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.057, tt:4487.310\n",
      "Ep:128, loss:0.00000, loss_test:0.02436, lr:3.82e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.056, tt:4522.282\n",
      "Ep:129, loss:0.00000, loss_test:0.02437, lr:3.78e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.037, tt:4554.839\n",
      "Ep:130, loss:0.00000, loss_test:0.02442, lr:3.74e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.053, tt:4591.907\n",
      "Ep:131, loss:0.00000, loss_test:0.02459, lr:3.70e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.051, tt:4626.752\n",
      "Ep:132, loss:0.00000, loss_test:0.02461, lr:3.67e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.062, tt:4663.203\n",
      "Ep:133, loss:0.00000, loss_test:0.02456, lr:3.63e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.054, tt:4697.303\n",
      "Ep:134, loss:0.00000, loss_test:0.02464, lr:3.59e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.064, tt:4733.659\n",
      "Ep:135, loss:0.00000, loss_test:0.02475, lr:3.56e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.077, tt:4770.406\n",
      "Ep:136, loss:0.00000, loss_test:0.02484, lr:3.52e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.077, tt:4805.566\n",
      "Ep:137, loss:0.00000, loss_test:0.02477, lr:3.49e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.074, tt:4840.226\n",
      "Ep:138, loss:0.00000, loss_test:0.02480, lr:3.45e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.056, tt:4872.722\n",
      "Ep:139, loss:0.00000, loss_test:0.02504, lr:3.42e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.045, tt:4906.338\n",
      "Ep:140, loss:0.00000, loss_test:0.02496, lr:3.38e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.051, tt:4942.227\n",
      "Ep:141, loss:0.00000, loss_test:0.02507, lr:3.35e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.049, tt:4976.952\n",
      "Ep:142, loss:0.00000, loss_test:0.02513, lr:3.32e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.040, tt:5010.688\n",
      "Ep:143, loss:0.00000, loss_test:0.02515, lr:3.28e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.049, tt:5047.082\n",
      "Ep:144, loss:0.00000, loss_test:0.02515, lr:3.25e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.053, tt:5082.730\n",
      "Ep:145, loss:0.00000, loss_test:0.02521, lr:3.22e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.058, tt:5118.481\n",
      "Ep:146, loss:0.00000, loss_test:0.02523, lr:3.19e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.061, tt:5153.938\n",
      "Ep:147, loss:0.00000, loss_test:0.02522, lr:3.15e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.058, tt:5188.630\n",
      "Ep:148, loss:0.00000, loss_test:0.02531, lr:3.12e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.056, tt:5223.411\n",
      "Ep:149, loss:0.00000, loss_test:0.02533, lr:3.09e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.059, tt:5258.863\n",
      "Ep:150, loss:0.00000, loss_test:0.02541, lr:3.06e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.057, tt:5293.577\n",
      "Ep:151, loss:0.00000, loss_test:0.02545, lr:3.03e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.063, tt:5329.635\n",
      "Ep:152, loss:0.00000, loss_test:0.02541, lr:3.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.067, tt:5365.321\n",
      "Ep:153, loss:0.00000, loss_test:0.02560, lr:2.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.066, tt:5400.227\n",
      "Ep:154, loss:0.00000, loss_test:0.02542, lr:2.94e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.070, tt:5435.824\n",
      "Ep:155, loss:0.00000, loss_test:0.02560, lr:2.91e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.064, tt:5470.042\n",
      "Ep:156, loss:0.00000, loss_test:0.02559, lr:2.88e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.060, tt:5504.357\n",
      "Ep:157, loss:0.00000, loss_test:0.02556, lr:2.85e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.055, tt:5538.758\n",
      "Ep:158, loss:0.00000, loss_test:0.02573, lr:2.82e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.055, tt:5573.766\n",
      "Ep:159, loss:0.00000, loss_test:0.02560, lr:2.80e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.056, tt:5608.952\n",
      "Ep:160, loss:0.00000, loss_test:0.02577, lr:2.77e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.060, tt:5644.699\n",
      "Ep:161, loss:0.00000, loss_test:0.02575, lr:2.74e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.058, tt:5679.437\n",
      "Ep:162, loss:0.00000, loss_test:0.02565, lr:2.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.055, tt:5714.006\n",
      "Ep:163, loss:0.00000, loss_test:0.02588, lr:2.69e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.056, tt:5749.262\n",
      "Ep:164, loss:0.00000, loss_test:0.02579, lr:2.66e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.052, tt:5783.566\n",
      "Ep:165, loss:0.00000, loss_test:0.02593, lr:2.63e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.050, tt:5818.319\n",
      "Ep:166, loss:0.00000, loss_test:0.02586, lr:2.61e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.048, tt:5853.050\n",
      "Ep:167, loss:0.00000, loss_test:0.02583, lr:2.58e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.047, tt:5887.960\n",
      "Ep:168, loss:0.00000, loss_test:0.02595, lr:2.55e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.053, tt:5924.004\n",
      "Ep:169, loss:0.00000, loss_test:0.02593, lr:2.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.052, tt:5958.801\n",
      "Ep:170, loss:0.00000, loss_test:0.02602, lr:2.50e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.046, tt:5992.919\n",
      "Ep:171, loss:0.00000, loss_test:0.02600, lr:2.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.043, tt:6027.317\n",
      "Ep:172, loss:0.00000, loss_test:0.02605, lr:2.45e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.040, tt:6061.886\n",
      "Ep:173, loss:0.00000, loss_test:0.02604, lr:2.43e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.034, tt:6095.958\n",
      "Ep:174, loss:0.00000, loss_test:0.02611, lr:2.40e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.038, tt:6131.658\n",
      "Ep:175, loss:0.00000, loss_test:0.02607, lr:2.38e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.037, tt:6166.594\n",
      "Ep:176, loss:0.00000, loss_test:0.02614, lr:2.36e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.041, tt:6202.316\n",
      "Ep:177, loss:0.00000, loss_test:0.02615, lr:2.33e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.034, tt:6236.052\n",
      "Ep:178, loss:0.00000, loss_test:0.02615, lr:2.31e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.037, tt:6271.582\n",
      "Ep:179, loss:0.00000, loss_test:0.02620, lr:2.29e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.034, tt:6306.079\n",
      "Ep:180, loss:0.00000, loss_test:0.02618, lr:2.26e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.036, tt:6341.460\n",
      "Ep:181, loss:0.00000, loss_test:0.02624, lr:2.24e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.047, tt:6378.543\n",
      "Ep:182, loss:0.00000, loss_test:0.02627, lr:2.22e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.043, tt:6412.851\n",
      "Ep:183, loss:0.00000, loss_test:0.02627, lr:2.20e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.039, tt:6447.244\n",
      "Ep:184, loss:0.00000, loss_test:0.02629, lr:2.17e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.045, tt:6483.288\n",
      "Ep:185, loss:0.00000, loss_test:0.02632, lr:2.15e-02, fs:0.76301 (r=0.667,p=0.892),  time:35.058, tt:6520.756\n",
      "Ep:186, loss:0.00000, loss_test:0.02628, lr:2.13e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.072, tt:6558.484\n",
      "Ep:187, loss:0.00000, loss_test:0.02634, lr:2.11e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.086, tt:6596.132\n",
      "Ep:188, loss:0.00000, loss_test:0.02637, lr:2.09e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.101, tt:6634.109\n",
      "Ep:189, loss:0.00000, loss_test:0.02634, lr:2.07e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.113, tt:6671.559\n",
      "Ep:190, loss:0.00000, loss_test:0.02640, lr:2.05e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.116, tt:6707.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00000, loss_test:0.02642, lr:2.03e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.120, tt:6742.960\n",
      "Ep:192, loss:0.00000, loss_test:0.02643, lr:2.01e-02, fs:0.75581 (r=0.657,p=0.890),  time:35.122, tt:6778.639\n",
      "Ep:193, loss:0.00000, loss_test:0.02640, lr:1.99e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.123, tt:6813.929\n",
      "Ep:194, loss:0.00000, loss_test:0.02649, lr:1.97e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.131, tt:6850.614\n",
      "Ep:195, loss:0.00000, loss_test:0.02656, lr:1.95e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.129, tt:6885.286\n",
      "Ep:196, loss:0.00000, loss_test:0.02647, lr:1.93e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.125, tt:6919.635\n",
      "Ep:197, loss:0.00000, loss_test:0.02653, lr:1.91e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.118, tt:6953.325\n",
      "Ep:198, loss:0.00000, loss_test:0.02653, lr:1.89e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.082, tt:6981.310\n",
      "Ep:199, loss:0.00000, loss_test:0.02653, lr:1.87e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.065, tt:7012.980\n",
      "Ep:200, loss:0.00000, loss_test:0.02659, lr:1.85e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.061, tt:7047.244\n",
      "Ep:201, loss:0.00000, loss_test:0.02655, lr:1.83e-02, fs:0.74854 (r=0.646,p=0.889),  time:35.023, tt:7074.642\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13136, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:35.385, tt:35.385\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13031, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:36.064, tt:72.127\n",
      "Ep:2, loss:0.00027, loss_test:0.12980, lr:1.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:36.014, tt:108.042\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.12921, lr:1.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:36.018, tt:144.071\n",
      "Ep:4, loss:0.00027, loss_test:0.12832, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:35.807, tt:179.036\n",
      "Ep:5, loss:0.00027, loss_test:0.12723, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:35.827, tt:214.964\n",
      "Ep:6, loss:0.00027, loss_test:0.12606, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:35.818, tt:250.727\n",
      "Ep:7, loss:0.00026, loss_test:0.12495, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:35.985, tt:287.884\n",
      "Ep:8, loss:0.00026, loss_test:0.12366, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:35.952, tt:323.569\n",
      "Ep:9, loss:0.00026, loss_test:0.12269, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:35.935, tt:359.349\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00026, loss_test:0.12172, lr:1.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:35.939, tt:395.329\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00026, loss_test:0.12068, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:35.879, tt:430.544\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00026, loss_test:0.11982, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.177, tt:470.305\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00025, loss_test:0.11920, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.179, tt:506.504\n",
      "Ep:14, loss:0.00025, loss_test:0.11900, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.294, tt:544.405\n",
      "Ep:15, loss:0.00025, loss_test:0.11887, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.428, tt:582.847\n",
      "Ep:16, loss:0.00025, loss_test:0.11806, lr:1.00e-02, fs:0.68482 (r=0.889,p=0.557),  time:36.448, tt:619.618\n",
      "Ep:17, loss:0.00024, loss_test:0.11692, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:36.383, tt:654.896\n",
      "Ep:18, loss:0.00024, loss_test:0.11566, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:36.416, tt:691.906\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00024, loss_test:0.11444, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:36.398, tt:727.953\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00023, loss_test:0.11326, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:36.440, tt:765.237\n",
      "Ep:21, loss:0.00023, loss_test:0.11256, lr:1.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:36.386, tt:800.489\n",
      "Ep:22, loss:0.00023, loss_test:0.11108, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:36.342, tt:835.872\n",
      "Ep:23, loss:0.00022, loss_test:0.10831, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:36.376, tt:873.012\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00022, loss_test:0.10659, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:36.362, tt:909.049\n",
      "Ep:25, loss:0.00021, loss_test:0.10687, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:36.424, tt:947.021\n",
      "Ep:26, loss:0.00021, loss_test:0.10672, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:36.424, tt:983.449\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00020, loss_test:0.10445, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:36.417, tt:1019.667\n",
      "Ep:28, loss:0.00020, loss_test:0.10496, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:36.407, tt:1055.791\n",
      "Ep:29, loss:0.00019, loss_test:0.10730, lr:1.00e-02, fs:0.70204 (r=0.869,p=0.589),  time:36.399, tt:1091.980\n",
      "Ep:30, loss:0.00019, loss_test:0.10384, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:36.417, tt:1128.914\n",
      "Ep:31, loss:0.00018, loss_test:0.10288, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:36.393, tt:1164.588\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00018, loss_test:0.10582, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:36.339, tt:1199.198\n",
      "Ep:33, loss:0.00017, loss_test:0.10187, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:36.329, tt:1235.194\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00016, loss_test:0.10375, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:36.314, tt:1270.981\n",
      "Ep:35, loss:0.00016, loss_test:0.10483, lr:1.00e-02, fs:0.70492 (r=0.869,p=0.593),  time:36.314, tt:1307.315\n",
      "Ep:36, loss:0.00015, loss_test:0.09752, lr:1.00e-02, fs:0.73504 (r=0.869,p=0.637),  time:36.302, tt:1343.175\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00015, loss_test:0.10314, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:36.239, tt:1377.100\n",
      "Ep:38, loss:0.00014, loss_test:0.10062, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:36.242, tt:1413.431\n",
      "Ep:39, loss:0.00014, loss_test:0.10609, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:36.258, tt:1450.319\n",
      "Ep:40, loss:0.00013, loss_test:0.09980, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:36.263, tt:1486.777\n",
      "Ep:41, loss:0.00013, loss_test:0.09284, lr:1.00e-02, fs:0.78704 (r=0.859,p=0.726),  time:36.235, tt:1521.884\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00014, loss_test:0.10929, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:36.253, tt:1558.865\n",
      "Ep:43, loss:0.00013, loss_test:0.08780, lr:1.00e-02, fs:0.77419 (r=0.848,p=0.712),  time:36.293, tt:1596.910\n",
      "Ep:44, loss:0.00012, loss_test:0.09610, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:36.285, tt:1632.825\n",
      "Ep:45, loss:0.00011, loss_test:0.09138, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:36.284, tt:1669.053\n",
      "Ep:46, loss:0.00011, loss_test:0.09097, lr:1.00e-02, fs:0.73585 (r=0.788,p=0.690),  time:36.291, tt:1705.679\n",
      "Ep:47, loss:0.00010, loss_test:0.09348, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:36.299, tt:1742.344\n",
      "Ep:48, loss:0.00009, loss_test:0.09084, lr:1.00e-02, fs:0.73684 (r=0.778,p=0.700),  time:36.285, tt:1777.977\n",
      "Ep:49, loss:0.00009, loss_test:0.08728, lr:1.00e-02, fs:0.76471 (r=0.788,p=0.743),  time:36.283, tt:1814.141\n",
      "Ep:50, loss:0.00008, loss_test:0.09319, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:36.284, tt:1850.484\n",
      "Ep:51, loss:0.00008, loss_test:0.08919, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:36.273, tt:1886.217\n",
      "Ep:52, loss:0.00007, loss_test:0.08901, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:36.279, tt:1922.797\n",
      "Ep:53, loss:0.00007, loss_test:0.08395, lr:9.90e-03, fs:0.79188 (r=0.788,p=0.796),  time:36.286, tt:1959.445\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00007, loss_test:0.09633, lr:9.90e-03, fs:0.71642 (r=0.727,p=0.706),  time:36.276, tt:1995.200\n",
      "Ep:55, loss:0.00006, loss_test:0.07935, lr:9.90e-03, fs:0.81250 (r=0.788,p=0.839),  time:36.275, tt:2031.394\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.08559, lr:9.90e-03, fs:0.76503 (r=0.707,p=0.833),  time:36.269, tt:2067.354\n",
      "Ep:57, loss:0.00006, loss_test:0.08866, lr:9.90e-03, fs:0.79798 (r=0.798,p=0.798),  time:36.262, tt:2103.170\n",
      "Ep:58, loss:0.00005, loss_test:0.07413, lr:9.90e-03, fs:0.80829 (r=0.788,p=0.830),  time:36.258, tt:2139.198\n",
      "Ep:59, loss:0.00006, loss_test:0.09611, lr:9.90e-03, fs:0.74000 (r=0.747,p=0.733),  time:36.259, tt:2175.535\n",
      "Ep:60, loss:0.00005, loss_test:0.07391, lr:9.90e-03, fs:0.81675 (r=0.788,p=0.848),  time:36.248, tt:2211.142\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.09483, lr:9.90e-03, fs:0.71910 (r=0.646,p=0.810),  time:36.247, tt:2247.338\n",
      "Ep:62, loss:0.00005, loss_test:0.08032, lr:9.90e-03, fs:0.75978 (r=0.687,p=0.850),  time:36.243, tt:2283.298\n",
      "Ep:63, loss:0.00004, loss_test:0.07689, lr:9.90e-03, fs:0.82723 (r=0.798,p=0.859),  time:36.212, tt:2317.587\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.09354, lr:9.90e-03, fs:0.71264 (r=0.626,p=0.827),  time:36.172, tt:2351.150\n",
      "Ep:65, loss:0.00004, loss_test:0.07951, lr:9.90e-03, fs:0.74157 (r=0.667,p=0.835),  time:36.150, tt:2385.910\n",
      "Ep:66, loss:0.00003, loss_test:0.08033, lr:9.90e-03, fs:0.74033 (r=0.677,p=0.817),  time:36.157, tt:2422.514\n",
      "Ep:67, loss:0.00003, loss_test:0.07800, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:36.131, tt:2456.914\n",
      "Ep:68, loss:0.00003, loss_test:0.07858, lr:9.90e-03, fs:0.76404 (r=0.687,p=0.861),  time:36.152, tt:2494.481\n",
      "Ep:69, loss:0.00003, loss_test:0.08048, lr:9.90e-03, fs:0.72000 (r=0.636,p=0.829),  time:36.192, tt:2533.456\n",
      "Ep:70, loss:0.00003, loss_test:0.07506, lr:9.90e-03, fs:0.85417 (r=0.828,p=0.882),  time:36.176, tt:2568.519\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.08208, lr:9.90e-03, fs:0.76136 (r=0.677,p=0.870),  time:36.173, tt:2604.445\n",
      "Ep:72, loss:0.00002, loss_test:0.07696, lr:9.90e-03, fs:0.77528 (r=0.697,p=0.873),  time:36.153, tt:2639.193\n",
      "Ep:73, loss:0.00002, loss_test:0.08890, lr:9.90e-03, fs:0.78022 (r=0.717,p=0.855),  time:36.136, tt:2674.098\n",
      "Ep:74, loss:0.00003, loss_test:0.08224, lr:9.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.124, tt:2709.317\n",
      "Ep:75, loss:0.00002, loss_test:0.07823, lr:9.90e-03, fs:0.82292 (r=0.798,p=0.849),  time:36.127, tt:2745.645\n",
      "Ep:76, loss:0.00002, loss_test:0.08709, lr:9.90e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.113, tt:2780.684\n",
      "Ep:77, loss:0.00003, loss_test:0.07388, lr:9.90e-03, fs:0.82902 (r=0.808,p=0.851),  time:36.093, tt:2815.272\n",
      "Ep:78, loss:0.00002, loss_test:0.09477, lr:9.90e-03, fs:0.73256 (r=0.636,p=0.863),  time:36.080, tt:2850.297\n",
      "Ep:79, loss:0.00002, loss_test:0.06854, lr:9.90e-03, fs:0.86316 (r=0.828,p=0.901),  time:36.055, tt:2884.425\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.09070, lr:9.90e-03, fs:0.73684 (r=0.636,p=0.875),  time:36.029, tt:2918.380\n",
      "Ep:81, loss:0.00002, loss_test:0.07211, lr:9.90e-03, fs:0.86869 (r=0.869,p=0.869),  time:36.021, tt:2953.736\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.09002, lr:9.90e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.003, tt:2988.246\n",
      "Ep:83, loss:0.00002, loss_test:0.07462, lr:9.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:35.991, tt:3023.208\n",
      "Ep:84, loss:0.00002, loss_test:0.09043, lr:9.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:35.979, tt:3058.255\n",
      "Ep:85, loss:0.00002, loss_test:0.08566, lr:9.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:35.958, tt:3092.384\n",
      "Ep:86, loss:0.00002, loss_test:0.08076, lr:9.90e-03, fs:0.76404 (r=0.687,p=0.861),  time:35.938, tt:3126.596\n",
      "Ep:87, loss:0.00002, loss_test:0.08488, lr:9.90e-03, fs:0.75862 (r=0.667,p=0.880),  time:35.939, tt:3162.610\n",
      "Ep:88, loss:0.00002, loss_test:0.08091, lr:9.90e-03, fs:0.78889 (r=0.717,p=0.877),  time:35.942, tt:3198.855\n",
      "Ep:89, loss:0.00001, loss_test:0.08545, lr:9.90e-03, fs:0.76136 (r=0.677,p=0.870),  time:35.960, tt:3236.375\n",
      "Ep:90, loss:0.00001, loss_test:0.08202, lr:9.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:35.980, tt:3274.222\n",
      "Ep:91, loss:0.00001, loss_test:0.08281, lr:9.90e-03, fs:0.75000 (r=0.667,p=0.857),  time:35.998, tt:3311.814\n",
      "Ep:92, loss:0.00001, loss_test:0.09024, lr:9.90e-03, fs:0.75706 (r=0.677,p=0.859),  time:36.017, tt:3349.613\n",
      "Ep:93, loss:0.00001, loss_test:0.08001, lr:9.80e-03, fs:0.75706 (r=0.677,p=0.859),  time:36.018, tt:3385.661\n",
      "Ep:94, loss:0.00001, loss_test:0.08748, lr:9.70e-03, fs:0.75706 (r=0.677,p=0.859),  time:36.016, tt:3421.512\n",
      "Ep:95, loss:0.00001, loss_test:0.08405, lr:9.61e-03, fs:0.78453 (r=0.717,p=0.866),  time:36.001, tt:3456.058\n",
      "Ep:96, loss:0.00001, loss_test:0.08401, lr:9.51e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.024, tt:3494.298\n",
      "Ep:97, loss:0.00001, loss_test:0.08678, lr:9.41e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.053, tt:3533.231\n",
      "Ep:98, loss:0.00001, loss_test:0.08975, lr:9.32e-03, fs:0.77095 (r=0.697,p=0.863),  time:36.063, tt:3570.250\n",
      "Ep:99, loss:0.00001, loss_test:0.08570, lr:9.23e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.078, tt:3607.798\n",
      "Ep:100, loss:0.00001, loss_test:0.08658, lr:9.14e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.093, tt:3645.350\n",
      "Ep:101, loss:0.00001, loss_test:0.08774, lr:9.04e-03, fs:0.75706 (r=0.677,p=0.859),  time:36.112, tt:3683.375\n",
      "Ep:102, loss:0.00001, loss_test:0.08749, lr:8.95e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.117, tt:3720.002\n",
      "Ep:103, loss:0.00001, loss_test:0.08768, lr:8.86e-03, fs:0.75000 (r=0.667,p=0.857),  time:36.149, tt:3759.519\n",
      "Ep:104, loss:0.00001, loss_test:0.09027, lr:8.78e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.160, tt:3796.791\n",
      "Ep:105, loss:0.00001, loss_test:0.08963, lr:8.69e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.152, tt:3832.149\n",
      "Ep:106, loss:0.00001, loss_test:0.08926, lr:8.60e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.157, tt:3868.832\n",
      "Ep:107, loss:0.00001, loss_test:0.09017, lr:8.51e-03, fs:0.69822 (r=0.596,p=0.843),  time:36.158, tt:3905.051\n",
      "Ep:108, loss:0.00001, loss_test:0.08942, lr:8.43e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.147, tt:3940.038\n",
      "Ep:109, loss:0.00001, loss_test:0.09345, lr:8.35e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.128, tt:3974.127\n",
      "Ep:110, loss:0.00001, loss_test:0.08948, lr:8.26e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.124, tt:4009.727\n",
      "Ep:111, loss:0.00001, loss_test:0.08811, lr:8.18e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.112, tt:4044.508\n",
      "Ep:112, loss:0.00001, loss_test:0.09126, lr:8.10e-03, fs:0.75429 (r=0.667,p=0.868),  time:36.109, tt:4080.285\n",
      "Ep:113, loss:0.00001, loss_test:0.09080, lr:8.02e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.106, tt:4116.037\n",
      "Ep:114, loss:0.00001, loss_test:0.09283, lr:7.94e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.097, tt:4151.176\n",
      "Ep:115, loss:0.00001, loss_test:0.09379, lr:7.86e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.090, tt:4186.481\n",
      "Ep:116, loss:0.00001, loss_test:0.08999, lr:7.78e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.098, tt:4223.439\n",
      "Ep:117, loss:0.00001, loss_test:0.09495, lr:7.70e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.084, tt:4257.900\n",
      "Ep:118, loss:0.00001, loss_test:0.09070, lr:7.62e-03, fs:0.74713 (r=0.657,p=0.867),  time:36.082, tt:4293.708\n",
      "Ep:119, loss:0.00000, loss_test:0.09294, lr:7.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:36.078, tt:4329.323\n",
      "Ep:120, loss:0.00000, loss_test:0.09195, lr:7.47e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.075, tt:4365.075\n",
      "Ep:121, loss:0.00000, loss_test:0.09290, lr:7.40e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.078, tt:4401.510\n",
      "Ep:122, loss:0.00000, loss_test:0.09380, lr:7.32e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.082, tt:4438.057\n",
      "Ep:123, loss:0.00000, loss_test:0.09603, lr:7.25e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.085, tt:4474.537\n",
      "Ep:124, loss:0.00000, loss_test:0.09217, lr:7.18e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.093, tt:4511.567\n",
      "Ep:125, loss:0.00000, loss_test:0.09290, lr:7.11e-03, fs:0.75581 (r=0.657,p=0.890),  time:36.099, tt:4548.421\n",
      "Ep:126, loss:0.00000, loss_test:0.09667, lr:7.03e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.100, tt:4584.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:127, loss:0.00000, loss_test:0.09076, lr:6.96e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.103, tt:4621.224\n",
      "Ep:128, loss:0.00000, loss_test:0.09502, lr:6.89e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.098, tt:4656.668\n",
      "Ep:129, loss:0.00000, loss_test:0.09273, lr:6.83e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.091, tt:4691.846\n",
      "Ep:130, loss:0.00000, loss_test:0.09365, lr:6.76e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.124, tt:4732.229\n",
      "Ep:131, loss:0.00000, loss_test:0.09557, lr:6.69e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.132, tt:4769.370\n",
      "Ep:132, loss:0.00000, loss_test:0.09133, lr:6.62e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.131, tt:4805.387\n",
      "Ep:133, loss:0.00000, loss_test:0.09289, lr:6.56e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.130, tt:4841.386\n",
      "Ep:134, loss:0.00000, loss_test:0.09431, lr:6.49e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.126, tt:4877.016\n",
      "Ep:135, loss:0.00000, loss_test:0.09386, lr:6.43e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.130, tt:4913.713\n",
      "Ep:136, loss:0.00000, loss_test:0.09601, lr:6.36e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.137, tt:4950.805\n",
      "Ep:137, loss:0.00000, loss_test:0.09548, lr:6.30e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.141, tt:4987.502\n",
      "Ep:138, loss:0.00000, loss_test:0.09336, lr:6.24e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.139, tt:5023.377\n",
      "Ep:139, loss:0.00000, loss_test:0.09337, lr:6.17e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.146, tt:5060.440\n",
      "Ep:140, loss:0.00000, loss_test:0.09267, lr:6.11e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.157, tt:5098.178\n",
      "Ep:141, loss:0.00000, loss_test:0.09447, lr:6.05e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.153, tt:5133.681\n",
      "Ep:142, loss:0.00000, loss_test:0.09456, lr:5.99e-03, fs:0.73684 (r=0.636,p=0.875),  time:36.144, tt:5168.525\n",
      "Ep:143, loss:0.00000, loss_test:0.09503, lr:5.93e-03, fs:0.73684 (r=0.636,p=0.875),  time:36.144, tt:5204.794\n",
      "Ep:144, loss:0.00000, loss_test:0.09197, lr:5.87e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.147, tt:5241.320\n",
      "Ep:145, loss:0.00000, loss_test:0.09397, lr:5.81e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.140, tt:5276.473\n",
      "Ep:146, loss:0.00000, loss_test:0.09369, lr:5.75e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.130, tt:5311.040\n",
      "Ep:147, loss:0.00000, loss_test:0.09409, lr:5.70e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.127, tt:5346.743\n",
      "Ep:150, loss:0.00000, loss_test:0.09380, lr:5.53e-03, fs:0.73373 (r=0.626,p=0.886),  time:36.135, tt:5456.427\n",
      "Ep:151, loss:0.00000, loss_test:0.09526, lr:5.47e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.140, tt:5493.343\n",
      "Ep:152, loss:0.00000, loss_test:0.09395, lr:5.42e-03, fs:0.76301 (r=0.667,p=0.892),  time:36.136, tt:5528.863\n",
      "Ep:153, loss:0.00000, loss_test:0.09487, lr:5.36e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.139, tt:5565.352\n",
      "Ep:154, loss:0.00000, loss_test:0.09447, lr:5.31e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.159, tt:5604.720\n",
      "Ep:155, loss:0.00000, loss_test:0.09416, lr:5.26e-03, fs:0.74854 (r=0.646,p=0.889),  time:36.153, tt:5639.821\n",
      "Ep:156, loss:0.00000, loss_test:0.09685, lr:5.20e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.150, tt:5675.623\n",
      "Ep:157, loss:0.00000, loss_test:0.09506, lr:5.15e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.147, tt:5711.259\n",
      "Ep:158, loss:0.00000, loss_test:0.09675, lr:5.10e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.145, tt:5747.107\n",
      "Ep:159, loss:0.00000, loss_test:0.09548, lr:5.05e-03, fs:0.75145 (r=0.657,p=0.878),  time:36.141, tt:5782.609\n",
      "Ep:160, loss:0.00000, loss_test:0.09487, lr:5.00e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.139, tt:5818.345\n",
      "Ep:161, loss:0.00000, loss_test:0.09522, lr:4.95e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.141, tt:5854.893\n",
      "Ep:162, loss:0.00000, loss_test:0.09759, lr:4.90e-03, fs:0.71856 (r=0.606,p=0.882),  time:36.145, tt:5891.637\n",
      "Ep:163, loss:0.00000, loss_test:0.09428, lr:4.85e-03, fs:0.73988 (r=0.646,p=0.865),  time:36.141, tt:5927.163\n",
      "Ep:164, loss:0.00000, loss_test:0.09643, lr:4.80e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.141, tt:5963.208\n",
      "Ep:165, loss:0.00000, loss_test:0.09859, lr:4.75e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.136, tt:5998.500\n",
      "Ep:166, loss:0.00000, loss_test:0.09557, lr:4.71e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.135, tt:6034.610\n",
      "Ep:167, loss:0.00000, loss_test:0.09558, lr:4.66e-03, fs:0.71084 (r=0.596,p=0.881),  time:36.138, tt:6071.141\n",
      "Ep:168, loss:0.00000, loss_test:0.09621, lr:4.61e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.135, tt:6106.812\n",
      "Ep:169, loss:0.00000, loss_test:0.09576, lr:4.57e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.131, tt:6142.273\n",
      "Ep:170, loss:0.00000, loss_test:0.09730, lr:4.52e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.129, tt:6178.004\n",
      "Ep:171, loss:0.00000, loss_test:0.09665, lr:4.48e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.124, tt:6213.339\n",
      "Ep:172, loss:0.00000, loss_test:0.09564, lr:4.43e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.131, tt:6250.603\n",
      "Ep:173, loss:0.00000, loss_test:0.09610, lr:4.39e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.128, tt:6286.338\n",
      "Ep:174, loss:0.00000, loss_test:0.09646, lr:4.34e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.124, tt:6321.650\n",
      "Ep:175, loss:0.00000, loss_test:0.09584, lr:4.30e-03, fs:0.72941 (r=0.626,p=0.873),  time:36.121, tt:6357.216\n",
      "Ep:176, loss:0.00000, loss_test:0.09518, lr:4.26e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.119, tt:6393.008\n",
      "Ep:177, loss:0.00000, loss_test:0.09574, lr:4.21e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.119, tt:6429.257\n",
      "Ep:178, loss:0.00000, loss_test:0.09542, lr:4.17e-03, fs:0.72515 (r=0.626,p=0.861),  time:36.151, tt:6471.065\n",
      "Ep:179, loss:0.00000, loss_test:0.09664, lr:4.13e-03, fs:0.71765 (r=0.616,p=0.859),  time:36.155, tt:6507.949\n",
      "Ep:180, loss:0.00000, loss_test:0.09622, lr:4.09e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.158, tt:6544.684\n",
      "Ep:181, loss:0.00000, loss_test:0.09616, lr:4.05e-03, fs:0.73256 (r=0.636,p=0.863),  time:36.154, tt:6580.053\n",
      "Ep:182, loss:0.00000, loss_test:0.09695, lr:4.01e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.148, tt:6615.058\n",
      "Ep:183, loss:0.00000, loss_test:0.09775, lr:3.97e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.145, tt:6650.764\n",
      "Ep:184, loss:0.00000, loss_test:0.09610, lr:3.93e-03, fs:0.72189 (r=0.616,p=0.871),  time:36.145, tt:6686.840\n",
      "Ep:185, loss:0.00000, loss_test:0.09735, lr:3.89e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.144, tt:6722.733\n",
      "Ep:186, loss:0.00000, loss_test:0.09753, lr:3.85e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.143, tt:6758.679\n",
      "Ep:187, loss:0.00000, loss_test:0.09524, lr:3.81e-03, fs:0.73256 (r=0.636,p=0.863),  time:36.136, tt:6793.542\n",
      "Ep:188, loss:0.00000, loss_test:0.09688, lr:3.77e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.132, tt:6828.867\n",
      "Ep:189, loss:0.00000, loss_test:0.09768, lr:3.73e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.126, tt:6864.000\n",
      "Ep:190, loss:0.00000, loss_test:0.09656, lr:3.70e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.128, tt:6900.464\n",
      "Ep:191, loss:0.00000, loss_test:0.09788, lr:3.66e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.123, tt:6935.596\n",
      "Ep:192, loss:0.00000, loss_test:0.09864, lr:3.62e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.119, tt:6970.927\n",
      "Ep:193, loss:0.00000, loss_test:0.09687, lr:3.59e-03, fs:0.71429 (r=0.606,p=0.870),  time:36.114, tt:7006.035\n",
      "Ep:194, loss:0.00000, loss_test:0.09660, lr:3.55e-03, fs:0.72941 (r=0.626,p=0.873),  time:36.107, tt:7040.822\n",
      "Ep:195, loss:0.00000, loss_test:0.09725, lr:3.52e-03, fs:0.74419 (r=0.646,p=0.877),  time:36.104, tt:7076.474\n",
      "Ep:196, loss:0.00000, loss_test:0.09709, lr:3.48e-03, fs:0.70659 (r=0.596,p=0.868),  time:36.083, tt:7108.442\n",
      "Ep:197, loss:0.00000, loss_test:0.09640, lr:3.45e-03, fs:0.70238 (r=0.596,p=0.855),  time:36.044, tt:7136.713\n",
      "Ep:198, loss:0.00000, loss_test:0.09665, lr:3.41e-03, fs:0.75862 (r=0.667,p=0.880),  time:36.001, tt:7164.125\n",
      "Ep:199, loss:0.00000, loss_test:0.09715, lr:3.38e-03, fs:0.75145 (r=0.657,p=0.878),  time:35.972, tt:7194.306\n",
      "Ep:200, loss:0.00000, loss_test:0.09701, lr:3.34e-03, fs:0.70659 (r=0.596,p=0.868),  time:35.933, tt:7222.454\n",
      "Ep:201, loss:0.00000, loss_test:0.09721, lr:3.31e-03, fs:0.70659 (r=0.596,p=0.868),  time:35.887, tt:7249.104\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02437, lr:6.00e-02, fs:0.70085 (r=0.828,p=0.607),  time:29.335, tt:29.335\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02346, lr:6.00e-02, fs:0.67376 (r=0.960,p=0.519),  time:30.016, tt:60.033\n",
      "Ep:2, loss:0.00005, loss_test:0.02534, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:29.852, tt:89.556\n",
      "Ep:3, loss:0.00005, loss_test:0.02444, lr:6.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:29.877, tt:119.508\n",
      "Ep:4, loss:0.00005, loss_test:0.02356, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:29.875, tt:149.377\n",
      "Ep:5, loss:0.00005, loss_test:0.02352, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:29.929, tt:179.577\n",
      "Ep:6, loss:0.00005, loss_test:0.02333, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:30.061, tt:210.427\n",
      "Ep:7, loss:0.00005, loss_test:0.02299, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:30.069, tt:240.553\n",
      "Ep:8, loss:0.00005, loss_test:0.02258, lr:6.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:30.074, tt:270.665\n",
      "Ep:9, loss:0.00005, loss_test:0.02198, lr:6.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:30.034, tt:300.344\n",
      "Ep:10, loss:0.00004, loss_test:0.02123, lr:6.00e-02, fs:0.67159 (r=0.919,p=0.529),  time:29.997, tt:329.969\n",
      "Ep:11, loss:0.00004, loss_test:0.02065, lr:6.00e-02, fs:0.67188 (r=0.869,p=0.548),  time:30.075, tt:360.899\n",
      "Ep:12, loss:0.00004, loss_test:0.02042, lr:5.94e-02, fs:0.67742 (r=0.848,p=0.564),  time:30.105, tt:391.364\n",
      "Ep:13, loss:0.00004, loss_test:0.02038, lr:5.88e-02, fs:0.67742 (r=0.848,p=0.564),  time:30.089, tt:421.240\n",
      "Ep:14, loss:0.00004, loss_test:0.02036, lr:5.82e-02, fs:0.69076 (r=0.869,p=0.573),  time:30.045, tt:450.675\n",
      "Ep:15, loss:0.00004, loss_test:0.02033, lr:5.76e-02, fs:0.68800 (r=0.869,p=0.570),  time:30.104, tt:481.668\n",
      "Ep:16, loss:0.00004, loss_test:0.02025, lr:5.71e-02, fs:0.68800 (r=0.869,p=0.570),  time:30.117, tt:511.982\n",
      "Ep:17, loss:0.00004, loss_test:0.02015, lr:5.65e-02, fs:0.68800 (r=0.869,p=0.570),  time:30.127, tt:542.280\n",
      "Ep:18, loss:0.00004, loss_test:0.02003, lr:5.59e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.109, tt:572.070\n",
      "Ep:19, loss:0.00004, loss_test:0.01992, lr:5.54e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.148, tt:602.965\n",
      "Ep:20, loss:0.00004, loss_test:0.01983, lr:5.48e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.160, tt:633.353\n",
      "Ep:21, loss:0.00004, loss_test:0.01972, lr:5.43e-02, fs:0.68800 (r=0.869,p=0.570),  time:30.144, tt:663.176\n",
      "Ep:22, loss:0.00004, loss_test:0.01958, lr:5.37e-02, fs:0.69076 (r=0.869,p=0.573),  time:30.132, tt:693.028\n",
      "Ep:23, loss:0.00004, loss_test:0.01942, lr:5.32e-02, fs:0.69636 (r=0.869,p=0.581),  time:30.107, tt:722.573\n",
      "Ep:24, loss:0.00004, loss_test:0.01926, lr:5.27e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.081, tt:752.037\n",
      "Ep:25, loss:0.00004, loss_test:0.01913, lr:5.21e-02, fs:0.68293 (r=0.848,p=0.571),  time:30.064, tt:781.664\n",
      "Ep:26, loss:0.00004, loss_test:0.01897, lr:5.16e-02, fs:0.67470 (r=0.848,p=0.560),  time:30.101, tt:812.716\n",
      "Ep:27, loss:0.00004, loss_test:0.01877, lr:5.11e-02, fs:0.68016 (r=0.848,p=0.568),  time:30.066, tt:841.858\n",
      "Ep:28, loss:0.00004, loss_test:0.01856, lr:5.06e-02, fs:0.68548 (r=0.859,p=0.570),  time:30.164, tt:874.748\n",
      "Ep:29, loss:0.00003, loss_test:0.01836, lr:5.01e-02, fs:0.68826 (r=0.859,p=0.574),  time:30.163, tt:904.896\n",
      "Ep:30, loss:0.00003, loss_test:0.01820, lr:4.96e-02, fs:0.69355 (r=0.869,p=0.577),  time:30.131, tt:934.076\n",
      "Ep:31, loss:0.00003, loss_test:0.01800, lr:4.91e-02, fs:0.70683 (r=0.889,p=0.587),  time:30.113, tt:963.617\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.01776, lr:4.91e-02, fs:0.71486 (r=0.899,p=0.593),  time:30.116, tt:993.819\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01753, lr:4.91e-02, fs:0.71200 (r=0.899,p=0.589),  time:30.104, tt:1023.545\n",
      "Ep:34, loss:0.00003, loss_test:0.01728, lr:4.91e-02, fs:0.71486 (r=0.899,p=0.593),  time:30.071, tt:1052.501\n",
      "Ep:35, loss:0.00003, loss_test:0.01703, lr:4.91e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.039, tt:1081.403\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01680, lr:4.91e-02, fs:0.74308 (r=0.949,p=0.610),  time:30.021, tt:1110.777\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01655, lr:4.91e-02, fs:0.73810 (r=0.939,p=0.608),  time:30.041, tt:1141.560\n",
      "Ep:38, loss:0.00003, loss_test:0.01629, lr:4.91e-02, fs:0.74104 (r=0.939,p=0.612),  time:30.004, tt:1170.138\n",
      "Ep:39, loss:0.00003, loss_test:0.01610, lr:4.91e-02, fs:0.74699 (r=0.939,p=0.620),  time:29.970, tt:1198.786\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01597, lr:4.91e-02, fs:0.75304 (r=0.939,p=0.628),  time:29.925, tt:1226.935\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01575, lr:4.91e-02, fs:0.75410 (r=0.929,p=0.634),  time:29.915, tt:1256.420\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01553, lr:4.91e-02, fs:0.76230 (r=0.939,p=0.641),  time:29.936, tt:1287.233\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01538, lr:4.91e-02, fs:0.76735 (r=0.949,p=0.644),  time:29.913, tt:1316.163\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01510, lr:4.91e-02, fs:0.77366 (r=0.949,p=0.653),  time:29.899, tt:1345.473\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01493, lr:4.91e-02, fs:0.77500 (r=0.939,p=0.660),  time:29.930, tt:1376.763\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01463, lr:4.91e-02, fs:0.77311 (r=0.929,p=0.662),  time:29.917, tt:1406.119\n",
      "Ep:47, loss:0.00002, loss_test:0.01442, lr:4.91e-02, fs:0.77447 (r=0.919,p=0.669),  time:29.904, tt:1435.390\n",
      "Ep:48, loss:0.00002, loss_test:0.01412, lr:4.91e-02, fs:0.78970 (r=0.929,p=0.687),  time:29.883, tt:1464.288\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01398, lr:4.91e-02, fs:0.79654 (r=0.929,p=0.697),  time:29.879, tt:1493.938\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01371, lr:4.91e-02, fs:0.79654 (r=0.929,p=0.697),  time:29.886, tt:1524.179\n",
      "Ep:51, loss:0.00002, loss_test:0.01363, lr:4.91e-02, fs:0.80870 (r=0.939,p=0.710),  time:29.901, tt:1554.836\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01355, lr:4.91e-02, fs:0.80889 (r=0.919,p=0.722),  time:29.892, tt:1584.292\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01321, lr:4.91e-02, fs:0.81223 (r=0.939,p=0.715),  time:29.906, tt:1614.910\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01330, lr:4.91e-02, fs:0.81416 (r=0.929,p=0.724),  time:29.905, tt:1644.787\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01302, lr:4.91e-02, fs:0.82143 (r=0.929,p=0.736),  time:29.895, tt:1674.139\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01298, lr:4.91e-02, fs:0.83408 (r=0.939,p=0.750),  time:29.890, tt:1703.719\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01304, lr:4.91e-02, fs:0.82511 (r=0.929,p=0.742),  time:29.883, tt:1733.203\n",
      "Ep:58, loss:0.00001, loss_test:0.01294, lr:4.91e-02, fs:0.82727 (r=0.919,p=0.752),  time:29.873, tt:1762.495\n",
      "Ep:59, loss:0.00001, loss_test:0.01301, lr:4.91e-02, fs:0.81481 (r=0.889,p=0.752),  time:29.900, tt:1793.974\n",
      "Ep:60, loss:0.00001, loss_test:0.01290, lr:4.91e-02, fs:0.82949 (r=0.909,p=0.763),  time:29.893, tt:1823.469\n",
      "Ep:61, loss:0.00001, loss_test:0.01291, lr:4.91e-02, fs:0.82243 (r=0.889,p=0.765),  time:29.897, tt:1853.597\n",
      "Ep:62, loss:0.00001, loss_test:0.01274, lr:4.91e-02, fs:0.82407 (r=0.899,p=0.761),  time:29.893, tt:1883.254\n",
      "Ep:63, loss:0.00001, loss_test:0.01275, lr:4.91e-02, fs:0.81690 (r=0.879,p=0.763),  time:29.927, tt:1915.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00001, loss_test:0.01253, lr:4.91e-02, fs:0.81690 (r=0.879,p=0.763),  time:29.936, tt:1945.829\n",
      "Ep:65, loss:0.00001, loss_test:0.01292, lr:4.91e-02, fs:0.82297 (r=0.869,p=0.782),  time:29.946, tt:1976.459\n",
      "Ep:66, loss:0.00001, loss_test:0.01270, lr:4.91e-02, fs:0.81340 (r=0.859,p=0.773),  time:29.946, tt:2006.391\n",
      "Ep:67, loss:0.00001, loss_test:0.01259, lr:4.91e-02, fs:0.79227 (r=0.828,p=0.759),  time:29.960, tt:2037.311\n",
      "Ep:68, loss:0.00001, loss_test:0.01285, lr:4.86e-02, fs:0.82000 (r=0.828,p=0.812),  time:29.964, tt:2067.527\n",
      "Ep:69, loss:0.00001, loss_test:0.01258, lr:4.81e-02, fs:0.79208 (r=0.808,p=0.777),  time:29.981, tt:2098.683\n",
      "Ep:70, loss:0.00001, loss_test:0.01275, lr:4.76e-02, fs:0.80402 (r=0.808,p=0.800),  time:29.994, tt:2129.592\n",
      "Ep:71, loss:0.00001, loss_test:0.01306, lr:4.71e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.997, tt:2159.820\n",
      "Ep:72, loss:0.00001, loss_test:0.01272, lr:4.67e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.015, tt:2191.064\n",
      "Ep:73, loss:0.00001, loss_test:0.01287, lr:4.62e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.013, tt:2220.970\n",
      "Ep:74, loss:0.00001, loss_test:0.01286, lr:4.57e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.997, tt:2249.755\n",
      "Ep:75, loss:0.00001, loss_test:0.01315, lr:4.53e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.981, tt:2278.574\n",
      "Ep:76, loss:0.00001, loss_test:0.01319, lr:4.48e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.971, tt:2307.774\n",
      "Ep:77, loss:0.00001, loss_test:0.01313, lr:4.44e-02, fs:0.80808 (r=0.808,p=0.808),  time:29.969, tt:2337.564\n",
      "Ep:78, loss:0.00001, loss_test:0.01332, lr:4.39e-02, fs:0.80402 (r=0.808,p=0.800),  time:29.973, tt:2367.832\n",
      "Ep:79, loss:0.00001, loss_test:0.01388, lr:4.35e-02, fs:0.80000 (r=0.788,p=0.812),  time:29.996, tt:2399.651\n",
      "Ep:80, loss:0.00001, loss_test:0.01339, lr:4.31e-02, fs:0.80808 (r=0.808,p=0.808),  time:30.004, tt:2430.297\n",
      "Ep:81, loss:0.00001, loss_test:0.01299, lr:4.26e-02, fs:0.79602 (r=0.808,p=0.784),  time:30.015, tt:2461.190\n",
      "Ep:82, loss:0.00001, loss_test:0.01379, lr:4.22e-02, fs:0.81633 (r=0.808,p=0.825),  time:30.015, tt:2491.215\n",
      "Ep:83, loss:0.00001, loss_test:0.01387, lr:4.18e-02, fs:0.81443 (r=0.798,p=0.832),  time:30.023, tt:2521.972\n",
      "Ep:84, loss:0.00001, loss_test:0.01378, lr:4.14e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.034, tt:2552.860\n",
      "Ep:85, loss:0.00001, loss_test:0.01350, lr:4.10e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.039, tt:2583.345\n",
      "Ep:86, loss:0.00001, loss_test:0.01397, lr:4.05e-02, fs:0.81633 (r=0.808,p=0.825),  time:30.043, tt:2613.763\n",
      "Ep:87, loss:0.00001, loss_test:0.01403, lr:4.01e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.048, tt:2644.256\n",
      "Ep:88, loss:0.00001, loss_test:0.01461, lr:3.97e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.056, tt:2674.954\n",
      "Ep:89, loss:0.00001, loss_test:0.01447, lr:3.93e-02, fs:0.81865 (r=0.798,p=0.840),  time:30.065, tt:2705.885\n",
      "Ep:90, loss:0.00001, loss_test:0.01390, lr:3.89e-02, fs:0.82051 (r=0.808,p=0.833),  time:30.076, tt:2736.934\n",
      "Ep:91, loss:0.00001, loss_test:0.01430, lr:3.86e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.090, tt:2768.271\n",
      "Ep:92, loss:0.00001, loss_test:0.01423, lr:3.82e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.096, tt:2798.903\n",
      "Ep:93, loss:0.00001, loss_test:0.01464, lr:3.78e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.103, tt:2829.717\n",
      "Ep:94, loss:0.00001, loss_test:0.01424, lr:3.74e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.116, tt:2861.001\n",
      "Ep:95, loss:0.00001, loss_test:0.01496, lr:3.70e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.127, tt:2892.233\n",
      "Ep:96, loss:0.00001, loss_test:0.01490, lr:3.67e-02, fs:0.82292 (r=0.798,p=0.849),  time:30.136, tt:2923.165\n",
      "Ep:97, loss:0.00001, loss_test:0.01551, lr:3.63e-02, fs:0.81675 (r=0.788,p=0.848),  time:30.150, tt:2954.654\n",
      "Ep:98, loss:0.00001, loss_test:0.01487, lr:3.59e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.161, tt:2985.966\n",
      "Ep:99, loss:0.00001, loss_test:0.01444, lr:3.56e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.174, tt:3017.350\n",
      "Ep:100, loss:0.00001, loss_test:0.01572, lr:3.52e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.186, tt:3048.814\n",
      "Ep:101, loss:0.00001, loss_test:0.01442, lr:3.49e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.191, tt:3079.441\n",
      "Ep:102, loss:0.00000, loss_test:0.01520, lr:3.45e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.187, tt:3109.253\n",
      "Ep:103, loss:0.00000, loss_test:0.01487, lr:3.42e-02, fs:0.82902 (r=0.808,p=0.851),  time:30.189, tt:3139.696\n",
      "Ep:104, loss:0.00000, loss_test:0.01537, lr:3.38e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.187, tt:3169.640\n",
      "Ep:105, loss:0.00000, loss_test:0.01504, lr:3.35e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.178, tt:3198.903\n",
      "Ep:106, loss:0.00000, loss_test:0.01511, lr:3.32e-02, fs:0.82474 (r=0.808,p=0.842),  time:30.180, tt:3229.254\n",
      "Ep:107, loss:0.00000, loss_test:0.01587, lr:3.28e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.193, tt:3260.878\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00000, loss_test:0.01539, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.192, tt:3290.959\n",
      "Ep:109, loss:0.00000, loss_test:0.01594, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.200, tt:3322.030\n",
      "Ep:110, loss:0.00000, loss_test:0.01562, lr:3.28e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.204, tt:3352.590\n",
      "Ep:111, loss:0.00000, loss_test:0.01590, lr:3.28e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.198, tt:3382.206\n",
      "Ep:112, loss:0.00000, loss_test:0.01606, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.203, tt:3412.941\n",
      "Ep:113, loss:0.00000, loss_test:0.01630, lr:3.28e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.211, tt:3444.043\n",
      "Ep:114, loss:0.00000, loss_test:0.01624, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.221, tt:3475.421\n",
      "Ep:115, loss:0.00000, loss_test:0.01589, lr:3.28e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.217, tt:3505.137\n",
      "Ep:116, loss:0.00000, loss_test:0.01622, lr:3.28e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.206, tt:3534.049\n",
      "Ep:117, loss:0.00000, loss_test:0.01590, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.202, tt:3563.863\n",
      "Ep:118, loss:0.00000, loss_test:0.01684, lr:3.28e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.209, tt:3594.918\n",
      "Ep:119, loss:0.00000, loss_test:0.01623, lr:3.25e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.212, tt:3625.382\n",
      "Ep:120, loss:0.00000, loss_test:0.01615, lr:3.22e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.232, tt:3658.104\n",
      "Ep:121, loss:0.00000, loss_test:0.01648, lr:3.19e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.236, tt:3688.803\n",
      "Ep:122, loss:0.00000, loss_test:0.01632, lr:3.15e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.243, tt:3719.872\n",
      "Ep:123, loss:0.00000, loss_test:0.01613, lr:3.12e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.237, tt:3749.343\n",
      "Ep:124, loss:0.00000, loss_test:0.01675, lr:3.09e-02, fs:0.83333 (r=0.808,p=0.860),  time:30.247, tt:3780.894\n",
      "Ep:125, loss:0.00000, loss_test:0.01629, lr:3.06e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.251, tt:3811.673\n",
      "Ep:126, loss:0.00000, loss_test:0.01625, lr:3.03e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.252, tt:3842.007\n",
      "Ep:127, loss:0.00000, loss_test:0.01672, lr:3.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:30.258, tt:3873.009\n",
      "Ep:128, loss:0.00000, loss_test:0.01579, lr:2.97e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.258, tt:3903.341\n",
      "Ep:129, loss:0.00000, loss_test:0.01596, lr:2.94e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.266, tt:3934.524\n",
      "Ep:130, loss:0.00000, loss_test:0.01630, lr:2.91e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.274, tt:3965.926\n",
      "Ep:131, loss:0.00000, loss_test:0.01616, lr:2.88e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.282, tt:3997.220\n",
      "Ep:132, loss:0.00000, loss_test:0.01657, lr:2.85e-02, fs:0.82723 (r=0.798,p=0.859),  time:30.283, tt:4027.651\n",
      "Ep:133, loss:0.00000, loss_test:0.01602, lr:2.82e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.294, tt:4059.353\n",
      "Ep:134, loss:0.00000, loss_test:0.01612, lr:2.80e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.296, tt:4089.926\n",
      "Ep:135, loss:0.00000, loss_test:0.01659, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.301, tt:4120.875\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.01611, lr:2.77e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.303, tt:4151.499\n",
      "Ep:137, loss:0.00000, loss_test:0.01712, lr:2.77e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.312, tt:4183.064\n",
      "Ep:138, loss:0.00000, loss_test:0.01630, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.317, tt:4214.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00000, loss_test:0.01710, lr:2.77e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.316, tt:4244.250\n",
      "Ep:140, loss:0.00000, loss_test:0.01675, lr:2.77e-02, fs:0.83770 (r=0.808,p=0.870),  time:30.316, tt:4274.500\n",
      "Ep:141, loss:0.00000, loss_test:0.01721, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.323, tt:4305.864\n",
      "Ep:142, loss:0.00000, loss_test:0.01682, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.321, tt:4335.928\n",
      "Ep:143, loss:0.00000, loss_test:0.01735, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.322, tt:4366.354\n",
      "Ep:144, loss:0.00000, loss_test:0.01709, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.321, tt:4396.574\n",
      "Ep:145, loss:0.00000, loss_test:0.01757, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.322, tt:4427.038\n",
      "Ep:146, loss:0.00000, loss_test:0.01728, lr:2.77e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.326, tt:4457.910\n",
      "Ep:147, loss:0.00000, loss_test:0.01764, lr:2.74e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.328, tt:4488.578\n",
      "Ep:148, loss:0.00000, loss_test:0.01742, lr:2.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.324, tt:4518.222\n",
      "Ep:149, loss:0.00000, loss_test:0.01764, lr:2.69e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.321, tt:4548.212\n",
      "Ep:150, loss:0.00000, loss_test:0.01769, lr:2.66e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.316, tt:4577.708\n",
      "Ep:151, loss:0.00000, loss_test:0.01763, lr:2.63e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.312, tt:4607.498\n",
      "Ep:152, loss:0.00000, loss_test:0.01776, lr:2.61e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.314, tt:4637.980\n",
      "Ep:153, loss:0.00000, loss_test:0.01762, lr:2.58e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.317, tt:4668.818\n",
      "Ep:154, loss:0.00000, loss_test:0.01803, lr:2.55e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.316, tt:4699.021\n",
      "Ep:155, loss:0.00000, loss_test:0.01753, lr:2.53e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.312, tt:4728.726\n",
      "Ep:156, loss:0.00000, loss_test:0.01815, lr:2.50e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.307, tt:4758.269\n",
      "Ep:157, loss:0.00000, loss_test:0.01772, lr:2.48e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.310, tt:4788.970\n",
      "Ep:158, loss:0.00000, loss_test:0.01813, lr:2.45e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.308, tt:4818.897\n",
      "Ep:159, loss:0.00000, loss_test:0.01783, lr:2.43e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.302, tt:4848.372\n",
      "Ep:160, loss:0.00000, loss_test:0.01816, lr:2.40e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.293, tt:4877.222\n",
      "Ep:161, loss:0.00000, loss_test:0.01811, lr:2.38e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.282, tt:4905.724\n",
      "Ep:162, loss:0.00000, loss_test:0.01809, lr:2.36e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.278, tt:4935.240\n",
      "Ep:163, loss:0.00000, loss_test:0.01821, lr:2.33e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.277, tt:4965.350\n",
      "Ep:164, loss:0.00000, loss_test:0.01829, lr:2.31e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.277, tt:4995.726\n",
      "Ep:165, loss:0.00000, loss_test:0.01827, lr:2.29e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.274, tt:5025.534\n",
      "Ep:166, loss:0.00000, loss_test:0.01837, lr:2.26e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.263, tt:5053.951\n",
      "Ep:167, loss:0.00000, loss_test:0.01837, lr:2.24e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.258, tt:5083.269\n",
      "Ep:168, loss:0.00000, loss_test:0.01846, lr:2.22e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.248, tt:5111.966\n",
      "Ep:169, loss:0.00000, loss_test:0.01840, lr:2.20e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.242, tt:5141.153\n",
      "Ep:170, loss:0.00000, loss_test:0.01850, lr:2.17e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.245, tt:5171.921\n",
      "Ep:171, loss:0.00000, loss_test:0.01850, lr:2.15e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.262, tt:5205.145\n",
      "Ep:172, loss:0.00000, loss_test:0.01855, lr:2.13e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.256, tt:5234.265\n",
      "Ep:173, loss:0.00000, loss_test:0.01866, lr:2.11e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.254, tt:5264.163\n",
      "Ep:174, loss:0.00000, loss_test:0.01863, lr:2.09e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.249, tt:5293.508\n",
      "Ep:175, loss:0.00000, loss_test:0.01874, lr:2.07e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.241, tt:5322.431\n",
      "Ep:176, loss:0.00000, loss_test:0.01878, lr:2.05e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.235, tt:5351.628\n",
      "Ep:177, loss:0.00000, loss_test:0.01871, lr:2.03e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.237, tt:5382.248\n",
      "Ep:178, loss:0.00000, loss_test:0.01889, lr:2.01e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.238, tt:5412.656\n",
      "Ep:179, loss:0.00000, loss_test:0.01883, lr:1.99e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.237, tt:5442.603\n",
      "Ep:180, loss:0.00000, loss_test:0.01895, lr:1.97e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.235, tt:5472.622\n",
      "Ep:181, loss:0.00000, loss_test:0.01882, lr:1.95e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.231, tt:5502.022\n",
      "Ep:182, loss:0.00000, loss_test:0.01905, lr:1.93e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.229, tt:5531.837\n",
      "Ep:183, loss:0.00000, loss_test:0.01895, lr:1.91e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.219, tt:5560.235\n",
      "Ep:184, loss:0.00000, loss_test:0.01907, lr:1.89e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.208, tt:5588.495\n",
      "Ep:185, loss:0.00000, loss_test:0.01897, lr:1.87e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.205, tt:5618.219\n",
      "Ep:186, loss:0.00000, loss_test:0.01913, lr:1.85e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.206, tt:5648.490\n",
      "Ep:187, loss:0.00000, loss_test:0.01910, lr:1.83e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.201, tt:5677.867\n",
      "Ep:188, loss:0.00000, loss_test:0.01918, lr:1.81e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.199, tt:5707.633\n",
      "Ep:189, loss:0.00000, loss_test:0.01918, lr:1.80e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.188, tt:5735.775\n",
      "Ep:190, loss:0.00000, loss_test:0.01926, lr:1.78e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.185, tt:5765.338\n",
      "Ep:191, loss:0.00000, loss_test:0.01922, lr:1.76e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.185, tt:5795.450\n",
      "Ep:192, loss:0.00000, loss_test:0.01930, lr:1.74e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.179, tt:5824.548\n",
      "Ep:193, loss:0.00000, loss_test:0.01925, lr:1.73e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.173, tt:5853.590\n",
      "Ep:194, loss:0.00000, loss_test:0.01926, lr:1.71e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.159, tt:5881.023\n",
      "Ep:195, loss:0.00000, loss_test:0.01934, lr:1.69e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.146, tt:5908.697\n",
      "Ep:196, loss:0.00000, loss_test:0.01932, lr:1.67e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.132, tt:5936.044\n",
      "Ep:197, loss:0.00000, loss_test:0.01939, lr:1.66e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.119, tt:5963.650\n",
      "Ep:198, loss:0.00000, loss_test:0.01938, lr:1.64e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.101, tt:5990.052\n",
      "Ep:199, loss:0.00000, loss_test:0.01950, lr:1.62e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.080, tt:6016.000\n",
      "Ep:200, loss:0.00000, loss_test:0.01936, lr:1.61e-02, fs:0.84211 (r=0.808,p=0.879),  time:30.051, tt:6040.267\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_250_200_150 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12783, lr:1.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:29.371, tt:29.371\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12638, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:29.978, tt:59.957\n",
      "Ep:2, loss:0.00027, loss_test:0.12452, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:29.711, tt:89.133\n",
      "Ep:3, loss:0.00027, loss_test:0.12257, lr:1.00e-02, fs:0.67681 (r=0.899,p=0.543),  time:30.020, tt:120.078\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12080, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:30.563, tt:152.815\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00026, loss_test:0.11963, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:30.580, tt:183.479\n",
      "Ep:6, loss:0.00026, loss_test:0.11869, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:30.835, tt:215.848\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:7, loss:0.00026, loss_test:0.11797, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:30.811, tt:246.491\n",
      "Ep:8, loss:0.00025, loss_test:0.11696, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:30.770, tt:276.931\n",
      "Ep:9, loss:0.00025, loss_test:0.11526, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:30.878, tt:308.779\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.11375, lr:1.00e-02, fs:0.70356 (r=0.899,p=0.578),  time:30.761, tt:338.372\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00024, loss_test:0.11227, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:30.774, tt:369.287\n",
      "Ep:12, loss:0.00024, loss_test:0.11062, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:30.762, tt:399.907\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00024, loss_test:0.10949, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:30.730, tt:430.222\n",
      "Ep:14, loss:0.00023, loss_test:0.10884, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:30.736, tt:461.046\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00023, loss_test:0.10740, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:30.618, tt:489.887\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00022, loss_test:0.10596, lr:1.00e-02, fs:0.71967 (r=0.869,p=0.614),  time:30.610, tt:520.368\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00022, loss_test:0.10617, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:30.572, tt:550.303\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00022, loss_test:0.10588, lr:1.00e-02, fs:0.72727 (r=0.889,p=0.615),  time:30.543, tt:580.310\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00021, loss_test:0.10451, lr:1.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:30.492, tt:609.832\n",
      "Ep:20, loss:0.00021, loss_test:0.10409, lr:1.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:30.456, tt:639.567\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00021, loss_test:0.10402, lr:1.00e-02, fs:0.72653 (r=0.899,p=0.610),  time:30.422, tt:669.292\n",
      "Ep:22, loss:0.00020, loss_test:0.10287, lr:1.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:30.462, tt:700.627\n",
      "Ep:23, loss:0.00020, loss_test:0.10183, lr:1.00e-02, fs:0.72428 (r=0.889,p=0.611),  time:30.450, tt:730.798\n",
      "Ep:24, loss:0.00019, loss_test:0.10149, lr:1.00e-02, fs:0.71901 (r=0.879,p=0.608),  time:30.476, tt:761.909\n",
      "Ep:25, loss:0.00019, loss_test:0.10058, lr:1.00e-02, fs:0.73251 (r=0.899,p=0.618),  time:30.452, tt:791.761\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00018, loss_test:0.09938, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:30.432, tt:821.661\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.09839, lr:1.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:30.433, tt:852.129\n",
      "Ep:28, loss:0.00018, loss_test:0.09741, lr:1.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:30.412, tt:881.947\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00017, loss_test:0.09826, lr:1.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:30.416, tt:912.489\n",
      "Ep:30, loss:0.00017, loss_test:0.09573, lr:1.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:30.425, tt:943.171\n",
      "Ep:31, loss:0.00016, loss_test:0.09696, lr:1.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:30.413, tt:973.207\n",
      "Ep:32, loss:0.00016, loss_test:0.09519, lr:1.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:30.425, tt:1004.019\n",
      "Ep:33, loss:0.00015, loss_test:0.09236, lr:1.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:30.422, tt:1034.335\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00015, loss_test:0.09641, lr:1.00e-02, fs:0.75697 (r=0.960,p=0.625),  time:30.418, tt:1064.644\n",
      "Ep:35, loss:0.00014, loss_test:0.08886, lr:1.00e-02, fs:0.78112 (r=0.919,p=0.679),  time:30.443, tt:1095.949\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00014, loss_test:0.09409, lr:1.00e-02, fs:0.76305 (r=0.960,p=0.633),  time:30.421, tt:1125.590\n",
      "Ep:37, loss:0.00013, loss_test:0.08797, lr:1.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:30.441, tt:1156.775\n",
      "Ep:38, loss:0.00013, loss_test:0.08686, lr:1.00e-02, fs:0.78632 (r=0.929,p=0.681),  time:30.453, tt:1187.679\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00013, loss_test:0.08327, lr:1.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.475, tt:1218.993\n",
      "Ep:40, loss:0.00013, loss_test:0.08621, lr:1.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:30.446, tt:1248.274\n",
      "Ep:41, loss:0.00011, loss_test:0.09612, lr:1.00e-02, fs:0.74790 (r=0.899,p=0.640),  time:30.424, tt:1277.802\n",
      "Ep:42, loss:0.00011, loss_test:0.08720, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:30.376, tt:1306.182\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00011, loss_test:0.09277, lr:1.00e-02, fs:0.75117 (r=0.808,p=0.702),  time:30.362, tt:1335.937\n",
      "Ep:44, loss:0.00014, loss_test:0.10615, lr:1.00e-02, fs:0.70498 (r=0.929,p=0.568),  time:30.370, tt:1366.665\n",
      "Ep:45, loss:0.00014, loss_test:0.07974, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:30.370, tt:1397.008\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00013, loss_test:0.07648, lr:1.00e-02, fs:0.84112 (r=0.909,p=0.783),  time:30.390, tt:1428.351\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00011, loss_test:0.09709, lr:1.00e-02, fs:0.71130 (r=0.859,p=0.607),  time:30.381, tt:1458.305\n",
      "Ep:48, loss:0.00011, loss_test:0.07386, lr:1.00e-02, fs:0.83810 (r=0.889,p=0.793),  time:30.378, tt:1488.542\n",
      "Ep:49, loss:0.00010, loss_test:0.08135, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:30.447, tt:1522.354\n",
      "Ep:50, loss:0.00009, loss_test:0.08841, lr:1.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:30.470, tt:1553.986\n",
      "Ep:51, loss:0.00010, loss_test:0.07203, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:30.495, tt:1585.734\n",
      "Ep:52, loss:0.00009, loss_test:0.09226, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:30.517, tt:1617.403\n",
      "Ep:53, loss:0.00008, loss_test:0.06963, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:30.543, tt:1649.307\n",
      "Ep:54, loss:0.00007, loss_test:0.09312, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:30.534, tt:1679.386\n",
      "Ep:55, loss:0.00007, loss_test:0.06929, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:30.519, tt:1709.062\n",
      "Ep:56, loss:0.00007, loss_test:0.09061, lr:1.00e-02, fs:0.70874 (r=0.737,p=0.682),  time:30.534, tt:1740.433\n",
      "Ep:57, loss:0.00006, loss_test:0.07501, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:30.560, tt:1772.508\n",
      "Ep:58, loss:0.00007, loss_test:0.08097, lr:9.90e-03, fs:0.77387 (r=0.778,p=0.770),  time:30.577, tt:1804.039\n",
      "Ep:59, loss:0.00006, loss_test:0.07530, lr:9.80e-03, fs:0.83092 (r=0.869,p=0.796),  time:30.589, tt:1835.324\n",
      "Ep:60, loss:0.00006, loss_test:0.07892, lr:9.70e-03, fs:0.82412 (r=0.828,p=0.820),  time:30.602, tt:1866.720\n",
      "Ep:61, loss:0.00006, loss_test:0.07959, lr:9.61e-03, fs:0.73196 (r=0.717,p=0.747),  time:30.603, tt:1897.382\n",
      "Ep:62, loss:0.00005, loss_test:0.07232, lr:9.51e-03, fs:0.83417 (r=0.838,p=0.830),  time:30.615, tt:1928.726\n",
      "Ep:63, loss:0.00005, loss_test:0.08082, lr:9.41e-03, fs:0.74074 (r=0.707,p=0.778),  time:30.610, tt:1959.020\n",
      "Ep:64, loss:0.00005, loss_test:0.07644, lr:9.32e-03, fs:0.80829 (r=0.788,p=0.830),  time:30.634, tt:1991.233\n",
      "Ep:65, loss:0.00004, loss_test:0.08743, lr:9.23e-03, fs:0.74346 (r=0.717,p=0.772),  time:30.653, tt:2023.077\n",
      "Ep:66, loss:0.00004, loss_test:0.07560, lr:9.14e-03, fs:0.80435 (r=0.747,p=0.871),  time:30.666, tt:2054.627\n",
      "Ep:67, loss:0.00004, loss_test:0.08693, lr:9.04e-03, fs:0.75510 (r=0.747,p=0.763),  time:30.655, tt:2084.570\n",
      "Ep:68, loss:0.00004, loss_test:0.07185, lr:8.95e-03, fs:0.85263 (r=0.818,p=0.890),  time:30.650, tt:2114.827\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.08586, lr:8.95e-03, fs:0.75269 (r=0.707,p=0.805),  time:30.647, tt:2145.301\n",
      "Ep:70, loss:0.00004, loss_test:0.08288, lr:8.95e-03, fs:0.72000 (r=0.636,p=0.829),  time:30.661, tt:2176.900\n",
      "Ep:71, loss:0.00004, loss_test:0.08407, lr:8.95e-03, fs:0.76087 (r=0.707,p=0.824),  time:30.697, tt:2210.192\n",
      "Ep:72, loss:0.00003, loss_test:0.08065, lr:8.95e-03, fs:0.76243 (r=0.697,p=0.841),  time:30.701, tt:2241.182\n",
      "Ep:73, loss:0.00003, loss_test:0.08937, lr:8.95e-03, fs:0.73743 (r=0.667,p=0.825),  time:30.692, tt:2271.241\n",
      "Ep:74, loss:0.00003, loss_test:0.08516, lr:8.95e-03, fs:0.75676 (r=0.707,p=0.814),  time:30.692, tt:2301.901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00003, loss_test:0.08731, lr:8.95e-03, fs:0.73563 (r=0.646,p=0.853),  time:30.696, tt:2332.898\n",
      "Ep:76, loss:0.00004, loss_test:0.09467, lr:8.95e-03, fs:0.72316 (r=0.646,p=0.821),  time:30.699, tt:2363.861\n",
      "Ep:77, loss:0.00003, loss_test:0.07859, lr:8.95e-03, fs:0.73446 (r=0.657,p=0.833),  time:30.698, tt:2394.448\n",
      "Ep:78, loss:0.00003, loss_test:0.09803, lr:8.95e-03, fs:0.72626 (r=0.657,p=0.812),  time:30.707, tt:2425.871\n",
      "Ep:79, loss:0.00003, loss_test:0.08174, lr:8.95e-03, fs:0.72414 (r=0.636,p=0.840),  time:30.703, tt:2456.259\n",
      "Ep:80, loss:0.00003, loss_test:0.09269, lr:8.86e-03, fs:0.75138 (r=0.687,p=0.829),  time:30.697, tt:2486.495\n",
      "Ep:81, loss:0.00003, loss_test:0.08319, lr:8.78e-03, fs:0.76923 (r=0.707,p=0.843),  time:30.697, tt:2517.120\n",
      "Ep:82, loss:0.00003, loss_test:0.09362, lr:8.69e-03, fs:0.73446 (r=0.657,p=0.833),  time:30.708, tt:2548.763\n",
      "Ep:83, loss:0.00003, loss_test:0.07701, lr:8.60e-03, fs:0.82723 (r=0.798,p=0.859),  time:30.709, tt:2579.565\n",
      "Ep:84, loss:0.00003, loss_test:0.11023, lr:8.51e-03, fs:0.70857 (r=0.626,p=0.816),  time:30.732, tt:2612.225\n",
      "Ep:85, loss:0.00003, loss_test:0.08499, lr:8.43e-03, fs:0.73333 (r=0.667,p=0.815),  time:30.738, tt:2643.445\n",
      "Ep:86, loss:0.00003, loss_test:0.09036, lr:8.35e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.756, tt:2675.734\n",
      "Ep:87, loss:0.00003, loss_test:0.10289, lr:8.26e-03, fs:0.74725 (r=0.687,p=0.819),  time:30.765, tt:2707.328\n",
      "Ep:88, loss:0.00003, loss_test:0.07173, lr:8.18e-03, fs:0.84656 (r=0.808,p=0.889),  time:30.759, tt:2737.536\n",
      "Ep:89, loss:0.00003, loss_test:0.10534, lr:8.10e-03, fs:0.74112 (r=0.737,p=0.745),  time:30.770, tt:2769.318\n",
      "Ep:90, loss:0.00003, loss_test:0.07242, lr:8.02e-03, fs:0.77778 (r=0.707,p=0.864),  time:30.760, tt:2799.158\n",
      "Ep:91, loss:0.00003, loss_test:0.10535, lr:7.94e-03, fs:0.70455 (r=0.626,p=0.805),  time:30.769, tt:2830.760\n",
      "Ep:92, loss:0.00003, loss_test:0.08337, lr:7.86e-03, fs:0.76923 (r=0.707,p=0.843),  time:30.772, tt:2861.778\n",
      "Ep:93, loss:0.00003, loss_test:0.07906, lr:7.78e-03, fs:0.75862 (r=0.667,p=0.880),  time:30.782, tt:2893.473\n",
      "Ep:94, loss:0.00003, loss_test:0.09701, lr:7.70e-03, fs:0.71658 (r=0.677,p=0.761),  time:30.787, tt:2924.719\n",
      "Ep:95, loss:0.00003, loss_test:0.07646, lr:7.62e-03, fs:0.80663 (r=0.737,p=0.890),  time:30.792, tt:2956.037\n",
      "Ep:96, loss:0.00003, loss_test:0.09720, lr:7.55e-03, fs:0.71910 (r=0.646,p=0.810),  time:30.803, tt:2987.917\n",
      "Ep:97, loss:0.00003, loss_test:0.10519, lr:7.47e-03, fs:0.71186 (r=0.636,p=0.808),  time:30.811, tt:3019.520\n",
      "Ep:98, loss:0.00002, loss_test:0.08010, lr:7.40e-03, fs:0.74713 (r=0.657,p=0.867),  time:30.815, tt:3050.653\n",
      "Ep:99, loss:0.00002, loss_test:0.09090, lr:7.32e-03, fs:0.72316 (r=0.646,p=0.821),  time:30.842, tt:3084.181\n",
      "Ep:100, loss:0.00002, loss_test:0.10650, lr:7.25e-03, fs:0.70175 (r=0.606,p=0.833),  time:30.846, tt:3115.490\n",
      "Ep:101, loss:0.00002, loss_test:0.09043, lr:7.18e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.837, tt:3145.336\n",
      "Ep:102, loss:0.00002, loss_test:0.09161, lr:7.11e-03, fs:0.71676 (r=0.626,p=0.838),  time:30.835, tt:3175.965\n",
      "Ep:103, loss:0.00002, loss_test:0.10340, lr:7.03e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.850, tt:3208.350\n",
      "Ep:104, loss:0.00002, loss_test:0.09152, lr:6.96e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.849, tt:3239.160\n",
      "Ep:105, loss:0.00002, loss_test:0.08378, lr:6.89e-03, fs:0.72832 (r=0.636,p=0.851),  time:30.850, tt:3270.058\n",
      "Ep:106, loss:0.00002, loss_test:0.10638, lr:6.83e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.859, tt:3301.965\n",
      "Ep:107, loss:0.00002, loss_test:0.10460, lr:6.76e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.861, tt:3332.953\n",
      "Ep:108, loss:0.00002, loss_test:0.09365, lr:6.69e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.867, tt:3364.463\n",
      "Ep:109, loss:0.00002, loss_test:0.09405, lr:6.62e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.865, tt:3395.157\n",
      "Ep:110, loss:0.00002, loss_test:0.09708, lr:6.56e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.870, tt:3426.527\n",
      "Ep:111, loss:0.00001, loss_test:0.09636, lr:6.49e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.865, tt:3456.859\n",
      "Ep:112, loss:0.00001, loss_test:0.09312, lr:6.43e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.867, tt:3487.962\n",
      "Ep:113, loss:0.00001, loss_test:0.09807, lr:6.36e-03, fs:0.72515 (r=0.626,p=0.861),  time:30.866, tt:3518.715\n",
      "Ep:114, loss:0.00001, loss_test:0.09860, lr:6.30e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.853, tt:3548.062\n",
      "Ep:115, loss:0.00001, loss_test:0.09632, lr:6.24e-03, fs:0.72093 (r=0.626,p=0.849),  time:30.856, tt:3579.292\n",
      "Ep:116, loss:0.00001, loss_test:0.09985, lr:6.17e-03, fs:0.71765 (r=0.616,p=0.859),  time:30.854, tt:3609.905\n",
      "Ep:117, loss:0.00001, loss_test:0.09968, lr:6.11e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.860, tt:3641.517\n",
      "Ep:118, loss:0.00001, loss_test:0.10334, lr:6.05e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.870, tt:3673.517\n",
      "Ep:119, loss:0.00001, loss_test:0.10054, lr:5.99e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.869, tt:3704.231\n",
      "Ep:120, loss:0.00001, loss_test:0.10686, lr:5.93e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.857, tt:3733.742\n",
      "Ep:121, loss:0.00001, loss_test:0.10312, lr:5.87e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.855, tt:3764.310\n",
      "Ep:122, loss:0.00001, loss_test:0.10144, lr:5.81e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.856, tt:3795.309\n",
      "Ep:123, loss:0.00001, loss_test:0.10457, lr:5.75e-03, fs:0.70588 (r=0.606,p=0.845),  time:30.868, tt:3827.657\n",
      "Ep:124, loss:0.00001, loss_test:0.10364, lr:5.70e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.866, tt:3858.284\n",
      "Ep:125, loss:0.00001, loss_test:0.10655, lr:5.64e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.863, tt:3888.718\n",
      "Ep:126, loss:0.00001, loss_test:0.10667, lr:5.58e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.860, tt:3919.231\n",
      "Ep:127, loss:0.00001, loss_test:0.10648, lr:5.53e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.855, tt:3949.499\n",
      "Ep:128, loss:0.00001, loss_test:0.10661, lr:5.47e-03, fs:0.71006 (r=0.606,p=0.857),  time:30.862, tt:3981.175\n",
      "Ep:129, loss:0.00001, loss_test:0.10764, lr:5.42e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.856, tt:4011.311\n",
      "Ep:130, loss:0.00001, loss_test:0.11131, lr:5.36e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.859, tt:4042.498\n",
      "Ep:131, loss:0.00001, loss_test:0.11005, lr:5.31e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.864, tt:4074.057\n",
      "Ep:132, loss:0.00001, loss_test:0.10883, lr:5.26e-03, fs:0.70238 (r=0.596,p=0.855),  time:30.872, tt:4106.006\n",
      "Ep:133, loss:0.00001, loss_test:0.10596, lr:5.20e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.888, tt:4138.952\n",
      "Ep:134, loss:0.00001, loss_test:0.11044, lr:5.15e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.898, tt:4171.166\n",
      "Ep:135, loss:0.00001, loss_test:0.10920, lr:5.10e-03, fs:0.69412 (r=0.596,p=0.831),  time:30.914, tt:4204.362\n",
      "Ep:136, loss:0.00001, loss_test:0.11169, lr:5.05e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.920, tt:4236.097\n",
      "Ep:137, loss:0.00001, loss_test:0.10658, lr:5.00e-03, fs:0.69412 (r=0.596,p=0.831),  time:30.917, tt:4266.521\n",
      "Ep:138, loss:0.00001, loss_test:0.10843, lr:4.95e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.921, tt:4297.986\n",
      "Ep:139, loss:0.00001, loss_test:0.11174, lr:4.90e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.931, tt:4330.319\n",
      "Ep:140, loss:0.00001, loss_test:0.11028, lr:4.85e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.944, tt:4363.047\n",
      "Ep:141, loss:0.00001, loss_test:0.10742, lr:4.80e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.941, tt:4393.670\n",
      "Ep:142, loss:0.00001, loss_test:0.11133, lr:4.75e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.945, tt:4425.155\n",
      "Ep:143, loss:0.00001, loss_test:0.11175, lr:4.71e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.953, tt:4457.195\n",
      "Ep:144, loss:0.00001, loss_test:0.10670, lr:4.66e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.959, tt:4489.082\n",
      "Ep:145, loss:0.00001, loss_test:0.11110, lr:4.61e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.956, tt:4519.534\n",
      "Ep:146, loss:0.00001, loss_test:0.10956, lr:4.57e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.966, tt:4551.992\n",
      "Ep:147, loss:0.00001, loss_test:0.10987, lr:4.52e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.954, tt:4581.124\n",
      "Ep:148, loss:0.00001, loss_test:0.10917, lr:4.48e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.941, tt:4610.262\n",
      "Ep:149, loss:0.00001, loss_test:0.11175, lr:4.43e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.928, tt:4639.130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00001, loss_test:0.10675, lr:4.39e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.928, tt:4670.061\n",
      "Ep:151, loss:0.00001, loss_test:0.10877, lr:4.34e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.932, tt:4701.596\n",
      "Ep:152, loss:0.00001, loss_test:0.11012, lr:4.30e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.933, tt:4732.822\n",
      "Ep:153, loss:0.00001, loss_test:0.11085, lr:4.26e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.932, tt:4763.471\n",
      "Ep:154, loss:0.00001, loss_test:0.11035, lr:4.21e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.936, tt:4795.136\n",
      "Ep:155, loss:0.00001, loss_test:0.10807, lr:4.17e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.941, tt:4826.848\n",
      "Ep:156, loss:0.00001, loss_test:0.10933, lr:4.13e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.937, tt:4857.083\n",
      "Ep:157, loss:0.00001, loss_test:0.10846, lr:4.09e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.946, tt:4889.403\n",
      "Ep:158, loss:0.00001, loss_test:0.11058, lr:4.05e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.942, tt:4919.724\n",
      "Ep:159, loss:0.00001, loss_test:0.11210, lr:4.01e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.952, tt:4952.315\n",
      "Ep:160, loss:0.00001, loss_test:0.10821, lr:3.97e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.961, tt:4984.738\n",
      "Ep:161, loss:0.00001, loss_test:0.10944, lr:3.93e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.957, tt:5015.010\n",
      "Ep:162, loss:0.00001, loss_test:0.10776, lr:3.89e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.961, tt:5046.606\n",
      "Ep:163, loss:0.00001, loss_test:0.11002, lr:3.85e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.965, tt:5078.242\n",
      "Ep:164, loss:0.00001, loss_test:0.10945, lr:3.81e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.959, tt:5108.170\n",
      "Ep:165, loss:0.00001, loss_test:0.11102, lr:3.77e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.969, tt:5140.898\n",
      "Ep:166, loss:0.00001, loss_test:0.10756, lr:3.73e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.978, tt:5173.275\n",
      "Ep:167, loss:0.00001, loss_test:0.10982, lr:3.70e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.978, tt:5204.370\n",
      "Ep:168, loss:0.00001, loss_test:0.10962, lr:3.66e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.981, tt:5235.752\n",
      "Ep:169, loss:0.00001, loss_test:0.10952, lr:3.62e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.980, tt:5266.574\n",
      "Ep:170, loss:0.00001, loss_test:0.11278, lr:3.59e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.984, tt:5298.228\n",
      "Ep:171, loss:0.00001, loss_test:0.10849, lr:3.55e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.990, tt:5330.199\n",
      "Ep:172, loss:0.00001, loss_test:0.11077, lr:3.52e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.001, tt:5363.122\n",
      "Ep:173, loss:0.00001, loss_test:0.10885, lr:3.48e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.007, tt:5395.272\n",
      "Ep:174, loss:0.00001, loss_test:0.10723, lr:3.45e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.012, tt:5427.048\n",
      "Ep:175, loss:0.00001, loss_test:0.11056, lr:3.41e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.024, tt:5460.184\n",
      "Ep:176, loss:0.00001, loss_test:0.10731, lr:3.38e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.022, tt:5490.826\n",
      "Ep:177, loss:0.00001, loss_test:0.11127, lr:3.34e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.023, tt:5522.086\n",
      "Ep:178, loss:0.00001, loss_test:0.11224, lr:3.31e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.030, tt:5554.403\n",
      "Ep:179, loss:0.00001, loss_test:0.10918, lr:3.28e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.029, tt:5585.185\n",
      "Ep:180, loss:0.00001, loss_test:0.11068, lr:3.24e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.036, tt:5617.560\n",
      "Ep:181, loss:0.00001, loss_test:0.10905, lr:3.21e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.038, tt:5648.825\n",
      "Ep:182, loss:0.00001, loss_test:0.10869, lr:3.18e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.045, tt:5681.270\n",
      "Ep:183, loss:0.00000, loss_test:0.11027, lr:3.15e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.049, tt:5712.950\n",
      "Ep:184, loss:0.00001, loss_test:0.10928, lr:3.12e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.051, tt:5744.347\n",
      "Ep:185, loss:0.00000, loss_test:0.10881, lr:3.09e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.041, tt:5773.639\n",
      "Ep:186, loss:0.00000, loss_test:0.10845, lr:3.05e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.042, tt:5804.768\n",
      "Ep:187, loss:0.00000, loss_test:0.11011, lr:3.02e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.044, tt:5836.320\n",
      "Ep:188, loss:0.00000, loss_test:0.10939, lr:2.99e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.042, tt:5866.869\n",
      "Ep:189, loss:0.00000, loss_test:0.10727, lr:2.96e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.037, tt:5896.936\n",
      "Ep:190, loss:0.00000, loss_test:0.11108, lr:2.93e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.041, tt:5928.881\n",
      "Ep:191, loss:0.00000, loss_test:0.11031, lr:2.90e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.043, tt:5960.217\n",
      "Ep:192, loss:0.00000, loss_test:0.10888, lr:2.88e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.046, tt:5991.824\n",
      "Ep:193, loss:0.00000, loss_test:0.11000, lr:2.85e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.041, tt:6021.933\n",
      "Ep:194, loss:0.00000, loss_test:0.10780, lr:2.82e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.037, tt:6052.117\n",
      "Ep:195, loss:0.00000, loss_test:0.10895, lr:2.79e-03, fs:0.69822 (r=0.596,p=0.843),  time:31.018, tt:6079.550\n",
      "Ep:196, loss:0.00000, loss_test:0.11010, lr:2.76e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.993, tt:6105.537\n",
      "Ep:197, loss:0.00000, loss_test:0.10846, lr:2.73e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.968, tt:6131.705\n",
      "Ep:198, loss:0.00000, loss_test:0.10933, lr:2.71e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.937, tt:6156.437\n",
      "Ep:199, loss:0.00000, loss_test:0.11015, lr:2.68e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.886, tt:6177.150\n",
      "Ep:200, loss:0.00000, loss_test:0.10790, lr:2.65e-03, fs:0.69822 (r=0.596,p=0.843),  time:30.851, tt:6201.063\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02025, lr:6.00e-02, fs:0.65079 (r=0.828,p=0.536),  time:28.673, tt:28.673\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02130, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:29.681, tt:59.363\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02294, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.778, tt:89.333\n",
      "Ep:3, loss:0.00004, loss_test:0.02314, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.931, tt:119.724\n",
      "Ep:4, loss:0.00004, loss_test:0.02236, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.937, tt:149.684\n",
      "Ep:5, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.298, tt:181.788\n",
      "Ep:6, loss:0.00004, loss_test:0.01995, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:30.374, tt:212.615\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01884, lr:6.00e-02, fs:0.65714 (r=0.929,p=0.508),  time:30.382, tt:243.057\n",
      "Ep:8, loss:0.00004, loss_test:0.01811, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:30.456, tt:274.105\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01763, lr:6.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:30.520, tt:305.195\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01716, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:30.546, tt:336.004\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01684, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:30.507, tt:366.087\n",
      "Ep:12, loss:0.00003, loss_test:0.01668, lr:6.00e-02, fs:0.69498 (r=0.909,p=0.562),  time:30.591, tt:397.682\n",
      "Ep:13, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.70722 (r=0.939,p=0.567),  time:30.689, tt:429.645\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00003, loss_test:0.01628, lr:6.00e-02, fs:0.70455 (r=0.939,p=0.564),  time:30.843, tt:462.638\n",
      "Ep:15, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:30.832, tt:493.316\n",
      "Ep:16, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:30.809, tt:523.752\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01538, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:30.817, tt:554.701\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.73469 (r=0.909,p=0.616),  time:30.829, tt:585.756\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:30.791, tt:615.813\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01474, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:30.829, tt:647.419\n",
      "Ep:21, loss:0.00003, loss_test:0.01459, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:30.876, tt:679.267\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01446, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:30.891, tt:710.504\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01430, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:30.836, tt:740.073\n",
      "Ep:24, loss:0.00003, loss_test:0.01411, lr:6.00e-02, fs:0.76230 (r=0.939,p=0.641),  time:30.874, tt:771.844\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01393, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:30.867, tt:802.533\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01377, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:30.857, tt:833.131\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.78992 (r=0.949,p=0.676),  time:30.826, tt:863.129\n",
      "Ep:28, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:30.814, tt:893.609\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:30.815, tt:924.436\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01320, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:30.899, tt:957.875\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81513 (r=0.980,p=0.698),  time:30.899, tt:988.759\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:30.945, tt:1021.171\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:30.927, tt:1051.512\n",
      "Ep:34, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:30.892, tt:1081.227\n",
      "Ep:35, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.82353 (r=0.990,p=0.705),  time:30.865, tt:1111.147\n",
      "Ep:36, loss:0.00002, loss_test:0.01252, lr:6.00e-02, fs:0.82008 (r=0.990,p=0.700),  time:30.891, tt:1142.955\n",
      "Ep:37, loss:0.00002, loss_test:0.01242, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:30.868, tt:1172.998\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.83051 (r=0.990,p=0.715),  time:30.872, tt:1203.992\n",
      "Ep:39, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:30.905, tt:1236.182\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01215, lr:6.00e-02, fs:0.83404 (r=0.990,p=0.721),  time:30.925, tt:1267.938\n",
      "Ep:41, loss:0.00002, loss_test:0.01206, lr:6.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:30.962, tt:1300.385\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01197, lr:6.00e-02, fs:0.83761 (r=0.990,p=0.726),  time:30.956, tt:1331.094\n",
      "Ep:43, loss:0.00002, loss_test:0.01189, lr:6.00e-02, fs:0.84120 (r=0.990,p=0.731),  time:30.957, tt:1362.119\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01181, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:30.984, tt:1394.294\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.84483 (r=0.990,p=0.737),  time:30.995, tt:1425.770\n",
      "Ep:46, loss:0.00002, loss_test:0.01165, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:30.995, tt:1456.781\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01158, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:30.993, tt:1487.653\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01150, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.953, tt:1516.699\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.949, tt:1547.456\n",
      "Ep:50, loss:0.00002, loss_test:0.01141, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.969, tt:1579.442\n",
      "Ep:51, loss:0.00002, loss_test:0.01137, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:30.962, tt:1610.013\n",
      "Ep:52, loss:0.00002, loss_test:0.01131, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:31.039, tt:1645.084\n",
      "Ep:53, loss:0.00002, loss_test:0.01127, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:31.060, tt:1677.229\n",
      "Ep:54, loss:0.00002, loss_test:0.01123, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:31.052, tt:1707.861\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.01119, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:31.053, tt:1738.985\n",
      "Ep:56, loss:0.00002, loss_test:0.01114, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:31.041, tt:1769.331\n",
      "Ep:57, loss:0.00001, loss_test:0.01111, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:31.055, tt:1801.198\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00001, loss_test:0.01108, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:31.058, tt:1832.421\n",
      "Ep:59, loss:0.00001, loss_test:0.01104, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:31.064, tt:1863.844\n",
      "Ep:60, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:31.061, tt:1894.743\n",
      "Ep:61, loss:0.00001, loss_test:0.01098, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:31.045, tt:1924.812\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01094, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:31.012, tt:1953.760\n",
      "Ep:63, loss:0.00001, loss_test:0.01090, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:31.024, tt:1985.515\n",
      "Ep:64, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:31.027, tt:2016.774\n",
      "Ep:65, loss:0.00001, loss_test:0.01082, lr:6.00e-02, fs:0.87111 (r=0.990,p=0.778),  time:31.050, tt:2049.297\n",
      "Ep:66, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:31.040, tt:2079.687\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01078, lr:6.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:31.040, tt:2110.692\n",
      "Ep:68, loss:0.00001, loss_test:0.01076, lr:6.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:31.047, tt:2142.211\n",
      "Ep:69, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:31.033, tt:2172.294\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01074, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:31.047, tt:2204.363\n",
      "Ep:71, loss:0.00001, loss_test:0.01073, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:31.023, tt:2233.672\n",
      "Ep:72, loss:0.00001, loss_test:0.01071, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:30.993, tt:2262.510\n",
      "Ep:73, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.965, tt:2291.390\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01067, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.944, tt:2320.808\n",
      "Ep:75, loss:0.00001, loss_test:0.01067, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.929, tt:2350.628\n",
      "Ep:76, loss:0.00001, loss_test:0.01066, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.936, tt:2382.078\n",
      "Ep:77, loss:0.00001, loss_test:0.01063, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:30.926, tt:2412.249\n",
      "Ep:78, loss:0.00001, loss_test:0.01062, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.894, tt:2440.632\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00001, loss_test:0.01062, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.896, tt:2471.659\n",
      "Ep:80, loss:0.00001, loss_test:0.01062, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.892, tt:2502.274\n",
      "Ep:81, loss:0.00001, loss_test:0.01062, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.898, tt:2533.652\n",
      "Ep:82, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.908, tt:2565.384\n",
      "Ep:83, loss:0.00001, loss_test:0.01059, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.915, tt:2596.835\n",
      "Ep:84, loss:0.00001, loss_test:0.01059, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.895, tt:2626.051\n",
      "Ep:85, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.874, tt:2655.173\n",
      "Ep:86, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.850, tt:2683.941\n",
      "Ep:87, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.855, tt:2715.220\n",
      "Ep:88, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:30.838, tt:2744.623\n",
      "Ep:89, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:30.854, tt:2776.898\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.882, tt:2810.271\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01054, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.885, tt:2841.465\n",
      "Ep:92, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:30.886, tt:2872.404\n",
      "Ep:93, loss:0.00001, loss_test:0.01054, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:30.900, tt:2904.630\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:30.894, tt:2934.916\n",
      "Ep:95, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:30.895, tt:2965.960\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.90654 (r=0.980,p=0.843),  time:30.905, tt:2997.796\n",
      "Ep:97, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.913, tt:3029.456\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01054, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.925, tt:3061.615\n",
      "Ep:99, loss:0.00001, loss_test:0.01054, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.949, tt:3094.911\n",
      "Ep:100, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.949, tt:3125.830\n",
      "Ep:101, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.958, tt:3157.753\n",
      "Ep:102, loss:0.00001, loss_test:0.01056, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.963, tt:3189.183\n",
      "Ep:103, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.962, tt:3220.015\n",
      "Ep:104, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.970, tt:3251.847\n",
      "Ep:105, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.974, tt:3283.206\n",
      "Ep:106, loss:0.00001, loss_test:0.01057, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:30.996, tt:3316.553\n",
      "Ep:107, loss:0.00001, loss_test:0.01058, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:31.010, tt:3349.072\n",
      "Ep:108, loss:0.00001, loss_test:0.01060, lr:6.00e-02, fs:0.91080 (r=0.980,p=0.851),  time:31.012, tt:3380.335\n",
      "Ep:109, loss:0.00001, loss_test:0.01060, lr:5.94e-02, fs:0.91080 (r=0.980,p=0.851),  time:31.027, tt:3412.930\n",
      "Ep:110, loss:0.00001, loss_test:0.01060, lr:5.88e-02, fs:0.91080 (r=0.980,p=0.851),  time:31.034, tt:3444.822\n",
      "Ep:111, loss:0.00001, loss_test:0.01060, lr:5.82e-02, fs:0.91080 (r=0.980,p=0.851),  time:31.075, tt:3480.382\n",
      "Ep:112, loss:0.00001, loss_test:0.01061, lr:5.76e-02, fs:0.90566 (r=0.970,p=0.850),  time:31.079, tt:3511.933\n",
      "Ep:113, loss:0.00001, loss_test:0.01063, lr:5.71e-02, fs:0.90566 (r=0.970,p=0.850),  time:31.085, tt:3543.648\n",
      "Ep:114, loss:0.00001, loss_test:0.01066, lr:5.65e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.085, tt:3574.774\n",
      "Ep:115, loss:0.00001, loss_test:0.01066, lr:5.59e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.095, tt:3607.010\n",
      "Ep:116, loss:0.00001, loss_test:0.01064, lr:5.54e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.102, tt:3638.981\n",
      "Ep:117, loss:0.00001, loss_test:0.01066, lr:5.48e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.095, tt:3669.171\n",
      "Ep:118, loss:0.00001, loss_test:0.01068, lr:5.43e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.098, tt:3700.682\n",
      "Ep:119, loss:0.00001, loss_test:0.01068, lr:5.37e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.098, tt:3731.785\n",
      "Ep:120, loss:0.00001, loss_test:0.01067, lr:5.32e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.089, tt:3761.788\n",
      "Ep:121, loss:0.00001, loss_test:0.01068, lr:5.27e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.091, tt:3793.074\n",
      "Ep:122, loss:0.00001, loss_test:0.01070, lr:5.21e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.090, tt:3824.048\n",
      "Ep:123, loss:0.00001, loss_test:0.01070, lr:5.16e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.098, tt:3856.154\n",
      "Ep:124, loss:0.00001, loss_test:0.01072, lr:5.11e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.096, tt:3887.030\n",
      "Ep:125, loss:0.00001, loss_test:0.01072, lr:5.06e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.096, tt:3918.113\n",
      "Ep:126, loss:0.00001, loss_test:0.01071, lr:5.01e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.091, tt:3948.523\n",
      "Ep:127, loss:0.00001, loss_test:0.01071, lr:4.96e-02, fs:0.90995 (r=0.970,p=0.857),  time:31.094, tt:3980.074\n",
      "Ep:128, loss:0.00001, loss_test:0.01074, lr:4.91e-02, fs:0.91429 (r=0.970,p=0.865),  time:31.098, tt:4011.596\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00001, loss_test:0.01077, lr:4.91e-02, fs:0.91429 (r=0.970,p=0.865),  time:31.099, tt:4042.831\n",
      "Ep:130, loss:0.00001, loss_test:0.01076, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.103, tt:4074.475\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.01077, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.089, tt:4103.683\n",
      "Ep:132, loss:0.00001, loss_test:0.01080, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.080, tt:4133.650\n",
      "Ep:133, loss:0.00001, loss_test:0.01081, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.105, tt:4168.113\n",
      "Ep:134, loss:0.00001, loss_test:0.01081, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.096, tt:4198.017\n",
      "Ep:135, loss:0.00001, loss_test:0.01080, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.102, tt:4229.864\n",
      "Ep:136, loss:0.00001, loss_test:0.01084, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.098, tt:4260.403\n",
      "Ep:137, loss:0.00001, loss_test:0.01088, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.107, tt:4292.721\n",
      "Ep:138, loss:0.00001, loss_test:0.01086, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.109, tt:4324.208\n",
      "Ep:139, loss:0.00001, loss_test:0.01085, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.104, tt:4354.547\n",
      "Ep:140, loss:0.00001, loss_test:0.01087, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.098, tt:4384.773\n",
      "Ep:141, loss:0.00001, loss_test:0.01089, lr:4.91e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.107, tt:4417.132\n",
      "Ep:142, loss:0.00001, loss_test:0.01091, lr:4.86e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.109, tt:4448.615\n",
      "Ep:143, loss:0.00001, loss_test:0.01093, lr:4.81e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.110, tt:4479.842\n",
      "Ep:144, loss:0.00001, loss_test:0.01092, lr:4.76e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.105, tt:4510.166\n",
      "Ep:145, loss:0.00001, loss_test:0.01092, lr:4.71e-02, fs:0.91866 (r=0.970,p=0.873),  time:31.107, tt:4541.650\n",
      "Ep:146, loss:0.00001, loss_test:0.01095, lr:4.67e-02, fs:0.91787 (r=0.960,p=0.880),  time:31.103, tt:4572.186\n",
      "Ep:147, loss:0.00001, loss_test:0.01097, lr:4.62e-02, fs:0.91787 (r=0.960,p=0.880),  time:31.102, tt:4603.117\n",
      "Ep:148, loss:0.00001, loss_test:0.01098, lr:4.57e-02, fs:0.91787 (r=0.960,p=0.880),  time:31.094, tt:4632.965\n",
      "Ep:149, loss:0.00001, loss_test:0.01099, lr:4.53e-02, fs:0.91787 (r=0.960,p=0.880),  time:31.091, tt:4663.649\n",
      "Ep:150, loss:0.00001, loss_test:0.01100, lr:4.48e-02, fs:0.91787 (r=0.960,p=0.880),  time:31.097, tt:4695.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00001, loss_test:0.01101, lr:4.44e-02, fs:0.91262 (r=0.949,p=0.879),  time:31.096, tt:4726.634\n",
      "Ep:152, loss:0.00001, loss_test:0.01104, lr:4.39e-02, fs:0.91262 (r=0.949,p=0.879),  time:31.097, tt:4757.777\n",
      "Ep:153, loss:0.00001, loss_test:0.01105, lr:4.35e-02, fs:0.91262 (r=0.949,p=0.879),  time:31.092, tt:4788.106\n",
      "Ep:154, loss:0.00001, loss_test:0.01105, lr:4.31e-02, fs:0.91262 (r=0.949,p=0.879),  time:31.095, tt:4819.728\n",
      "Ep:155, loss:0.00001, loss_test:0.01107, lr:4.26e-02, fs:0.91707 (r=0.949,p=0.887),  time:31.098, tt:4851.344\n",
      "Ep:156, loss:0.00001, loss_test:0.01108, lr:4.22e-02, fs:0.91707 (r=0.949,p=0.887),  time:31.097, tt:4882.296\n",
      "Ep:157, loss:0.00001, loss_test:0.01109, lr:4.18e-02, fs:0.91626 (r=0.939,p=0.894),  time:31.104, tt:4914.364\n",
      "Ep:158, loss:0.00001, loss_test:0.01110, lr:4.14e-02, fs:0.91626 (r=0.939,p=0.894),  time:31.097, tt:4944.463\n",
      "Ep:159, loss:0.00001, loss_test:0.01113, lr:4.10e-02, fs:0.91626 (r=0.939,p=0.894),  time:31.093, tt:4974.918\n",
      "Ep:160, loss:0.00000, loss_test:0.01114, lr:4.05e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.092, tt:5005.765\n",
      "Ep:161, loss:0.00000, loss_test:0.01115, lr:4.01e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.089, tt:5036.484\n",
      "Ep:162, loss:0.00000, loss_test:0.01116, lr:3.97e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.085, tt:5066.869\n",
      "Ep:163, loss:0.00000, loss_test:0.01116, lr:3.93e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.086, tt:5098.028\n",
      "Ep:164, loss:0.00000, loss_test:0.01116, lr:3.89e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.081, tt:5128.447\n",
      "Ep:165, loss:0.00000, loss_test:0.01119, lr:3.86e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.083, tt:5159.830\n",
      "Ep:166, loss:0.00000, loss_test:0.01120, lr:3.82e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.081, tt:5190.497\n",
      "Ep:167, loss:0.00000, loss_test:0.01120, lr:3.78e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.085, tt:5222.260\n",
      "Ep:168, loss:0.00000, loss_test:0.01121, lr:3.74e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.081, tt:5252.650\n",
      "Ep:169, loss:0.00000, loss_test:0.01124, lr:3.70e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.080, tt:5283.597\n",
      "Ep:170, loss:0.00000, loss_test:0.01126, lr:3.67e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.088, tt:5316.012\n",
      "Ep:171, loss:0.00000, loss_test:0.01127, lr:3.63e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.110, tt:5350.901\n",
      "Ep:172, loss:0.00000, loss_test:0.01127, lr:3.59e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.109, tt:5381.805\n",
      "Ep:173, loss:0.00000, loss_test:0.01128, lr:3.56e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.103, tt:5411.931\n",
      "Ep:174, loss:0.00000, loss_test:0.01130, lr:3.52e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.106, tt:5443.626\n",
      "Ep:175, loss:0.00000, loss_test:0.01132, lr:3.49e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.102, tt:5474.010\n",
      "Ep:176, loss:0.00000, loss_test:0.01132, lr:3.45e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.102, tt:5505.141\n",
      "Ep:177, loss:0.00000, loss_test:0.01134, lr:3.42e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.106, tt:5536.804\n",
      "Ep:178, loss:0.00000, loss_test:0.01135, lr:3.38e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.107, tt:5568.144\n",
      "Ep:179, loss:0.00000, loss_test:0.01135, lr:3.35e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.109, tt:5599.675\n",
      "Ep:180, loss:0.00000, loss_test:0.01135, lr:3.32e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.110, tt:5630.858\n",
      "Ep:181, loss:0.00000, loss_test:0.01138, lr:3.28e-02, fs:0.91089 (r=0.929,p=0.893),  time:31.115, tt:5662.909\n",
      "Ep:182, loss:0.00000, loss_test:0.01139, lr:3.25e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.116, tt:5694.235\n",
      "Ep:183, loss:0.00000, loss_test:0.01142, lr:3.22e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.113, tt:5724.774\n",
      "Ep:184, loss:0.00000, loss_test:0.01141, lr:3.19e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.109, tt:5755.077\n",
      "Ep:185, loss:0.00000, loss_test:0.01141, lr:3.15e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.110, tt:5786.533\n",
      "Ep:186, loss:0.00000, loss_test:0.01142, lr:3.12e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.113, tt:5818.159\n",
      "Ep:187, loss:0.00000, loss_test:0.01144, lr:3.09e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.114, tt:5849.378\n",
      "Ep:188, loss:0.00000, loss_test:0.01146, lr:3.06e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.114, tt:5880.488\n",
      "Ep:189, loss:0.00000, loss_test:0.01146, lr:3.03e-02, fs:0.90547 (r=0.919,p=0.892),  time:31.108, tt:5910.475\n",
      "Ep:190, loss:0.00000, loss_test:0.01146, lr:3.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.110, tt:5942.071\n",
      "Ep:191, loss:0.00000, loss_test:0.01148, lr:2.97e-02, fs:0.90000 (r=0.909,p=0.891),  time:31.120, tt:5975.130\n",
      "Ep:192, loss:0.00000, loss_test:0.01149, lr:2.94e-02, fs:0.89447 (r=0.899,p=0.890),  time:31.126, tt:6007.373\n",
      "Ep:193, loss:0.00000, loss_test:0.01149, lr:2.91e-02, fs:0.89447 (r=0.899,p=0.890),  time:31.128, tt:6038.868\n",
      "Ep:194, loss:0.00000, loss_test:0.01149, lr:2.88e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.128, tt:6069.874\n",
      "Ep:195, loss:0.00000, loss_test:0.01151, lr:2.85e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.124, tt:6100.266\n",
      "Ep:196, loss:0.00000, loss_test:0.01152, lr:2.82e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.125, tt:6131.548\n",
      "Ep:197, loss:0.00000, loss_test:0.01154, lr:2.80e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.119, tt:6161.567\n",
      "Ep:198, loss:0.00000, loss_test:0.01155, lr:2.77e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.112, tt:6191.246\n",
      "Ep:199, loss:0.00000, loss_test:0.01155, lr:2.74e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.114, tt:6222.846\n",
      "Ep:200, loss:0.00000, loss_test:0.01156, lr:2.71e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.102, tt:6251.507\n",
      "Ep:201, loss:0.00000, loss_test:0.01157, lr:2.69e-02, fs:0.88889 (r=0.889,p=0.889),  time:31.084, tt:6278.998\n",
      "Ep:202, loss:0.00000, loss_test:0.01159, lr:2.66e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.072, tt:6307.636\n",
      "Ep:203, loss:0.00000, loss_test:0.01158, lr:2.63e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.092, tt:6342.772\n",
      "Ep:204, loss:0.00000, loss_test:0.01160, lr:2.61e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.059, tt:6367.167\n",
      "Ep:205, loss:0.00000, loss_test:0.01161, lr:2.58e-02, fs:0.88325 (r=0.879,p=0.888),  time:31.024, tt:6391.033\n",
      "Ep:206, loss:0.00000, loss_test:0.01161, lr:2.55e-02, fs:0.88325 (r=0.879,p=0.888),  time:30.995, tt:6415.918\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13928, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.751, tt:31.751\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13768, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:31.972, tt:63.944\n",
      "Ep:2, loss:0.00027, loss_test:0.13495, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:31.781, tt:95.343\n",
      "Ep:3, loss:0.00027, loss_test:0.13068, lr:1.00e-02, fs:0.65278 (r=0.949,p=0.497),  time:31.475, tt:125.898\n",
      "Ep:4, loss:0.00026, loss_test:0.12438, lr:1.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:31.554, tt:157.770\n",
      "Ep:5, loss:0.00025, loss_test:0.11638, lr:1.00e-02, fs:0.70539 (r=0.859,p=0.599),  time:31.770, tt:190.617\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11054, lr:1.00e-02, fs:0.66355 (r=0.717,p=0.617),  time:31.946, tt:223.624\n",
      "Ep:7, loss:0.00023, loss_test:0.10800, lr:1.00e-02, fs:0.66667 (r=0.707,p=0.631),  time:32.053, tt:256.427\n",
      "Ep:8, loss:0.00023, loss_test:0.10685, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:32.187, tt:289.682\n",
      "Ep:9, loss:0.00022, loss_test:0.10660, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:32.208, tt:322.077\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10205, lr:1.00e-02, fs:0.71681 (r=0.818,p=0.638),  time:32.208, tt:354.283\n",
      "Ep:11, loss:0.00021, loss_test:0.09937, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:32.223, tt:386.671\n",
      "Ep:12, loss:0.00020, loss_test:0.09849, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:32.219, tt:418.844\n",
      "Ep:13, loss:0.00020, loss_test:0.09779, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:32.151, tt:450.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00019, loss_test:0.09462, lr:1.00e-02, fs:0.72811 (r=0.798,p=0.669),  time:32.201, tt:483.014\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09219, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:32.220, tt:515.516\n",
      "Ep:16, loss:0.00018, loss_test:0.09043, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:32.212, tt:547.599\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.08910, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:32.270, tt:580.858\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08717, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:32.368, tt:614.983\n",
      "Ep:19, loss:0.00017, loss_test:0.08558, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:32.372, tt:647.447\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08456, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:32.440, tt:681.236\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08238, lr:1.00e-02, fs:0.80180 (r=0.899,p=0.724),  time:32.519, tt:715.408\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08081, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:32.564, tt:748.982\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08034, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:32.545, tt:781.087\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07945, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:32.558, tt:813.953\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07825, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:32.607, tt:847.775\n",
      "Ep:26, loss:0.00014, loss_test:0.07729, lr:1.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:32.568, tt:879.336\n",
      "Ep:27, loss:0.00013, loss_test:0.07650, lr:1.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:32.571, tt:911.985\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07557, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:32.562, tt:944.294\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.07534, lr:1.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:32.621, tt:978.628\n",
      "Ep:30, loss:0.00012, loss_test:0.07457, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:32.644, tt:1011.970\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07415, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:32.595, tt:1043.030\n",
      "Ep:32, loss:0.00012, loss_test:0.07323, lr:1.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:32.580, tt:1075.133\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00012, loss_test:0.07271, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:32.582, tt:1107.782\n",
      "Ep:34, loss:0.00011, loss_test:0.07144, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:32.550, tt:1139.242\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07107, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:32.530, tt:1171.079\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.06966, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:32.510, tt:1267.902\n",
      "Ep:39, loss:0.00010, loss_test:0.06956, lr:1.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:32.505, tt:1300.209\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.06882, lr:1.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:32.498, tt:1332.428\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.06809, lr:1.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:32.483, tt:1364.304\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00009, loss_test:0.06753, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:32.485, tt:1396.868\n",
      "Ep:43, loss:0.00009, loss_test:0.06738, lr:1.00e-02, fs:0.85586 (r=0.960,p=0.772),  time:32.479, tt:1429.059\n",
      "Ep:44, loss:0.00009, loss_test:0.06688, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:32.459, tt:1460.675\n",
      "Ep:45, loss:0.00009, loss_test:0.06624, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:32.471, tt:1493.670\n",
      "Ep:46, loss:0.00008, loss_test:0.06606, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:32.478, tt:1526.469\n",
      "Ep:47, loss:0.00008, loss_test:0.06549, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:32.431, tt:1556.667\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.06499, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:32.393, tt:1587.242\n",
      "Ep:49, loss:0.00008, loss_test:0.06412, lr:1.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:32.391, tt:1619.553\n",
      "Ep:50, loss:0.00008, loss_test:0.06424, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:32.347, tt:1649.693\n",
      "Ep:51, loss:0.00008, loss_test:0.06376, lr:1.00e-02, fs:0.86996 (r=0.980,p=0.782),  time:32.376, tt:1683.574\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.06346, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:32.354, tt:1714.772\n",
      "Ep:53, loss:0.00007, loss_test:0.06265, lr:1.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:32.338, tt:1746.230\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00007, loss_test:0.06412, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:32.316, tt:1777.406\n",
      "Ep:55, loss:0.00007, loss_test:0.06198, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:32.314, tt:1809.606\n",
      "Ep:56, loss:0.00007, loss_test:0.06252, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:32.272, tt:1839.522\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00007, loss_test:0.06260, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:32.288, tt:1872.706\n",
      "Ep:58, loss:0.00007, loss_test:0.06048, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:32.296, tt:1905.438\n",
      "Ep:59, loss:0.00007, loss_test:0.06233, lr:1.00e-02, fs:0.87324 (r=0.939,p=0.816),  time:32.288, tt:1937.257\n",
      "Ep:60, loss:0.00006, loss_test:0.06025, lr:1.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:32.279, tt:1968.995\n",
      "Ep:61, loss:0.00006, loss_test:0.06169, lr:1.00e-02, fs:0.87685 (r=0.899,p=0.856),  time:32.252, tt:1999.622\n",
      "Ep:62, loss:0.00006, loss_test:0.06061, lr:1.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:32.242, tt:2031.266\n",
      "Ep:63, loss:0.00006, loss_test:0.06105, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:32.237, tt:2063.137\n",
      "Ep:64, loss:0.00006, loss_test:0.05964, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:32.214, tt:2093.896\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00006, loss_test:0.05965, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.187, tt:2124.312\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.05871, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:32.187, tt:2156.537\n",
      "Ep:67, loss:0.00005, loss_test:0.05982, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:32.177, tt:2188.021\n",
      "Ep:68, loss:0.00005, loss_test:0.05791, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:32.181, tt:2220.492\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00005, loss_test:0.05810, lr:1.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:32.194, tt:2253.573\n",
      "Ep:70, loss:0.00005, loss_test:0.05808, lr:1.00e-02, fs:0.90566 (r=0.970,p=0.850),  time:32.172, tt:2284.244\n",
      "Ep:71, loss:0.00005, loss_test:0.05821, lr:1.00e-02, fs:0.90233 (r=0.980,p=0.836),  time:32.168, tt:2316.130\n",
      "Ep:72, loss:0.00005, loss_test:0.05753, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:32.183, tt:2349.366\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00005, loss_test:0.05765, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:32.215, tt:2383.909\n",
      "Ep:74, loss:0.00005, loss_test:0.05750, lr:1.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:32.212, tt:2415.892\n",
      "Ep:75, loss:0.00005, loss_test:0.05726, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:32.200, tt:2447.183\n",
      "Ep:76, loss:0.00005, loss_test:0.05707, lr:1.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:32.199, tt:2479.303\n",
      "Ep:77, loss:0.00005, loss_test:0.05727, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:32.202, tt:2511.759\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00004, loss_test:0.05621, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:32.212, tt:2544.711\n",
      "Ep:79, loss:0.00004, loss_test:0.05735, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:32.222, tt:2577.757\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00004, loss_test:0.05606, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:32.233, tt:2610.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00004, loss_test:0.05635, lr:1.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:32.233, tt:2643.137\n",
      "Ep:82, loss:0.00004, loss_test:0.05669, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:32.230, tt:2675.099\n",
      "Ep:83, loss:0.00004, loss_test:0.05529, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:32.237, tt:2707.948\n",
      "Ep:84, loss:0.00004, loss_test:0.05587, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:32.244, tt:2740.767\n",
      "Ep:85, loss:0.00004, loss_test:0.05495, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:32.246, tt:2773.162\n",
      "Ep:86, loss:0.00004, loss_test:0.05626, lr:1.00e-02, fs:0.89216 (r=0.919,p=0.867),  time:32.235, tt:2804.437\n",
      "Ep:87, loss:0.00004, loss_test:0.05459, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:32.237, tt:2836.852\n",
      "Ep:88, loss:0.00004, loss_test:0.05534, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:32.248, tt:2870.043\n",
      "Ep:89, loss:0.00004, loss_test:0.05491, lr:1.00e-02, fs:0.91176 (r=0.939,p=0.886),  time:32.260, tt:2903.373\n",
      "Ep:90, loss:0.00004, loss_test:0.05506, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:32.254, tt:2935.097\n",
      "Ep:91, loss:0.00004, loss_test:0.05405, lr:9.90e-03, fs:0.93532 (r=0.949,p=0.922),  time:32.251, tt:2967.116\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00004, loss_test:0.05487, lr:9.90e-03, fs:0.90291 (r=0.939,p=0.869),  time:32.249, tt:2999.202\n",
      "Ep:93, loss:0.00003, loss_test:0.05399, lr:9.90e-03, fs:0.92079 (r=0.939,p=0.903),  time:32.257, tt:3032.113\n",
      "Ep:94, loss:0.00003, loss_test:0.05431, lr:9.90e-03, fs:0.91371 (r=0.909,p=0.918),  time:32.253, tt:3064.024\n",
      "Ep:95, loss:0.00003, loss_test:0.05425, lr:9.90e-03, fs:0.90196 (r=0.929,p=0.876),  time:32.233, tt:3094.347\n",
      "Ep:96, loss:0.00003, loss_test:0.05327, lr:9.90e-03, fs:0.92857 (r=0.919,p=0.938),  time:32.229, tt:3126.197\n",
      "Ep:97, loss:0.00003, loss_test:0.05404, lr:9.90e-03, fs:0.90909 (r=0.909,p=0.909),  time:32.233, tt:3158.813\n",
      "Ep:98, loss:0.00003, loss_test:0.05334, lr:9.90e-03, fs:0.91837 (r=0.909,p=0.928),  time:32.221, tt:3189.900\n",
      "Ep:99, loss:0.00003, loss_test:0.05378, lr:9.90e-03, fs:0.90099 (r=0.919,p=0.883),  time:32.215, tt:3221.460\n",
      "Ep:100, loss:0.00003, loss_test:0.05286, lr:9.90e-03, fs:0.93467 (r=0.939,p=0.930),  time:32.212, tt:3253.434\n",
      "Ep:101, loss:0.00003, loss_test:0.05376, lr:9.90e-03, fs:0.90355 (r=0.899,p=0.908),  time:32.197, tt:3284.081\n",
      "Ep:102, loss:0.00003, loss_test:0.05309, lr:9.90e-03, fs:0.91626 (r=0.939,p=0.894),  time:32.183, tt:3314.804\n",
      "Ep:103, loss:0.00003, loss_test:0.05295, lr:9.80e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.193, tt:3348.095\n",
      "Ep:104, loss:0.00003, loss_test:0.05356, lr:9.70e-03, fs:0.90816 (r=0.899,p=0.918),  time:32.160, tt:3376.763\n",
      "Ep:105, loss:0.00003, loss_test:0.05345, lr:9.61e-03, fs:0.89119 (r=0.869,p=0.915),  time:32.179, tt:3410.946\n",
      "Ep:106, loss:0.00003, loss_test:0.05292, lr:9.51e-03, fs:0.91282 (r=0.899,p=0.927),  time:32.180, tt:3443.269\n",
      "Ep:107, loss:0.00003, loss_test:0.05322, lr:9.41e-03, fs:0.89796 (r=0.889,p=0.907),  time:32.167, tt:3474.012\n",
      "Ep:108, loss:0.00003, loss_test:0.05336, lr:9.32e-03, fs:0.88298 (r=0.838,p=0.933),  time:32.145, tt:3503.827\n",
      "Ep:109, loss:0.00003, loss_test:0.05260, lr:9.23e-03, fs:0.90909 (r=0.909,p=0.909),  time:32.130, tt:3534.264\n",
      "Ep:110, loss:0.00003, loss_test:0.05310, lr:9.14e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.116, tt:3564.847\n",
      "Ep:111, loss:0.00003, loss_test:0.05261, lr:9.04e-03, fs:0.89691 (r=0.879,p=0.916),  time:32.130, tt:3598.555\n",
      "Ep:112, loss:0.00003, loss_test:0.05357, lr:8.95e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.130, tt:3630.717\n",
      "Ep:113, loss:0.00003, loss_test:0.05270, lr:8.86e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.124, tt:3662.189\n",
      "Ep:114, loss:0.00003, loss_test:0.05225, lr:8.78e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.119, tt:3693.716\n",
      "Ep:115, loss:0.00003, loss_test:0.05260, lr:8.69e-03, fs:0.87097 (r=0.818,p=0.931),  time:32.110, tt:3724.740\n",
      "Ep:116, loss:0.00002, loss_test:0.05275, lr:8.60e-03, fs:0.87368 (r=0.838,p=0.912),  time:32.090, tt:3754.515\n",
      "Ep:117, loss:0.00002, loss_test:0.05240, lr:8.51e-03, fs:0.88889 (r=0.848,p=0.933),  time:32.086, tt:3786.126\n",
      "Ep:118, loss:0.00002, loss_test:0.05209, lr:8.43e-03, fs:0.87958 (r=0.848,p=0.913),  time:32.086, tt:3818.250\n",
      "Ep:119, loss:0.00002, loss_test:0.05209, lr:8.35e-03, fs:0.87097 (r=0.818,p=0.931),  time:32.087, tt:3850.386\n",
      "Ep:120, loss:0.00002, loss_test:0.05179, lr:8.26e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.082, tt:3881.973\n",
      "Ep:121, loss:0.00002, loss_test:0.05189, lr:8.18e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.076, tt:3913.244\n",
      "Ep:122, loss:0.00002, loss_test:0.05242, lr:8.10e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.077, tt:3945.517\n",
      "Ep:123, loss:0.00002, loss_test:0.05197, lr:8.02e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.068, tt:3976.453\n",
      "Ep:124, loss:0.00002, loss_test:0.05153, lr:7.94e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.078, tt:4009.807\n",
      "Ep:125, loss:0.00002, loss_test:0.05138, lr:7.86e-03, fs:0.89583 (r=0.869,p=0.925),  time:32.077, tt:4041.701\n",
      "Ep:126, loss:0.00002, loss_test:0.05235, lr:7.78e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.072, tt:4073.196\n",
      "Ep:127, loss:0.00002, loss_test:0.05131, lr:7.70e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.060, tt:4103.623\n",
      "Ep:128, loss:0.00002, loss_test:0.05150, lr:7.62e-03, fs:0.87831 (r=0.838,p=0.922),  time:32.047, tt:4134.093\n",
      "Ep:129, loss:0.00002, loss_test:0.05193, lr:7.55e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.038, tt:4164.954\n",
      "Ep:130, loss:0.00002, loss_test:0.05119, lr:7.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.031, tt:4196.049\n",
      "Ep:131, loss:0.00002, loss_test:0.05194, lr:7.40e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.017, tt:4226.288\n",
      "Ep:132, loss:0.00002, loss_test:0.05204, lr:7.32e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.015, tt:4257.956\n",
      "Ep:133, loss:0.00002, loss_test:0.05150, lr:7.25e-03, fs:0.87701 (r=0.828,p=0.932),  time:32.012, tt:4289.635\n",
      "Ep:134, loss:0.00002, loss_test:0.05170, lr:7.18e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.005, tt:4320.610\n",
      "Ep:135, loss:0.00002, loss_test:0.05130, lr:7.11e-03, fs:0.87568 (r=0.818,p=0.942),  time:32.008, tt:4353.086\n",
      "Ep:136, loss:0.00002, loss_test:0.05110, lr:7.03e-03, fs:0.88172 (r=0.828,p=0.943),  time:32.001, tt:4384.100\n",
      "Ep:137, loss:0.00002, loss_test:0.05190, lr:6.96e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.997, tt:4415.628\n",
      "Ep:138, loss:0.00002, loss_test:0.05116, lr:6.89e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.988, tt:4446.396\n",
      "Ep:139, loss:0.00002, loss_test:0.05128, lr:6.83e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.983, tt:4477.575\n",
      "Ep:140, loss:0.00002, loss_test:0.05080, lr:6.76e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.993, tt:4511.018\n",
      "Ep:141, loss:0.00002, loss_test:0.05100, lr:6.69e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.994, tt:4543.165\n",
      "Ep:142, loss:0.00002, loss_test:0.05165, lr:6.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.986, tt:4573.981\n",
      "Ep:143, loss:0.00002, loss_test:0.05122, lr:6.56e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.968, tt:4603.420\n",
      "Ep:144, loss:0.00002, loss_test:0.05086, lr:6.49e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.973, tt:4636.150\n",
      "Ep:145, loss:0.00002, loss_test:0.05113, lr:6.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.959, tt:4666.015\n",
      "Ep:146, loss:0.00002, loss_test:0.05107, lr:6.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.947, tt:4696.149\n",
      "Ep:147, loss:0.00002, loss_test:0.05033, lr:6.30e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.933, tt:4726.072\n",
      "Ep:148, loss:0.00002, loss_test:0.05159, lr:6.24e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.935, tt:4758.323\n",
      "Ep:149, loss:0.00002, loss_test:0.05212, lr:6.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.926, tt:4788.959\n",
      "Ep:150, loss:0.00002, loss_test:0.05029, lr:6.11e-03, fs:0.88172 (r=0.828,p=0.943),  time:31.936, tt:4822.282\n",
      "Ep:151, loss:0.00002, loss_test:0.05114, lr:6.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.936, tt:4854.265\n",
      "Ep:152, loss:0.00002, loss_test:0.05186, lr:5.99e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.933, tt:4885.760\n",
      "Ep:153, loss:0.00002, loss_test:0.05025, lr:5.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.931, tt:4917.414\n",
      "Ep:154, loss:0.00002, loss_test:0.05112, lr:5.87e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.930, tt:4949.113\n",
      "Ep:155, loss:0.00002, loss_test:0.05171, lr:5.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.926, tt:4980.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:156, loss:0.00002, loss_test:0.05064, lr:5.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.925, tt:5012.196\n",
      "Ep:157, loss:0.00002, loss_test:0.05074, lr:5.70e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.925, tt:5044.162\n",
      "Ep:158, loss:0.00002, loss_test:0.05135, lr:5.64e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.920, tt:5075.290\n",
      "Ep:159, loss:0.00002, loss_test:0.05076, lr:5.58e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.928, tt:5108.453\n",
      "Ep:160, loss:0.00002, loss_test:0.05051, lr:5.53e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.925, tt:5139.988\n",
      "Ep:161, loss:0.00002, loss_test:0.05133, lr:5.47e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.927, tt:5172.099\n",
      "Ep:162, loss:0.00002, loss_test:0.05090, lr:5.42e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.924, tt:5203.583\n",
      "Ep:163, loss:0.00002, loss_test:0.05055, lr:5.36e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.924, tt:5235.475\n",
      "Ep:164, loss:0.00001, loss_test:0.05084, lr:5.31e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.920, tt:5266.856\n",
      "Ep:165, loss:0.00001, loss_test:0.05119, lr:5.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.916, tt:5297.986\n",
      "Ep:166, loss:0.00001, loss_test:0.05076, lr:5.20e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.914, tt:5329.557\n",
      "Ep:167, loss:0.00001, loss_test:0.05078, lr:5.15e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.908, tt:5360.589\n",
      "Ep:168, loss:0.00001, loss_test:0.05070, lr:5.10e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.898, tt:5390.790\n",
      "Ep:169, loss:0.00001, loss_test:0.05068, lr:5.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.902, tt:5423.262\n",
      "Ep:170, loss:0.00001, loss_test:0.05079, lr:5.00e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.904, tt:5455.569\n",
      "Ep:171, loss:0.00001, loss_test:0.05084, lr:4.95e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.903, tt:5487.383\n",
      "Ep:172, loss:0.00001, loss_test:0.05052, lr:4.90e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.899, tt:5518.486\n",
      "Ep:173, loss:0.00001, loss_test:0.05076, lr:4.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.898, tt:5550.168\n",
      "Ep:174, loss:0.00001, loss_test:0.05081, lr:4.80e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.896, tt:5581.799\n",
      "Ep:175, loss:0.00001, loss_test:0.05068, lr:4.75e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.889, tt:5612.437\n",
      "Ep:176, loss:0.00001, loss_test:0.05069, lr:4.71e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.890, tt:5644.546\n",
      "Ep:177, loss:0.00001, loss_test:0.05056, lr:4.66e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.883, tt:5675.129\n",
      "Ep:178, loss:0.00001, loss_test:0.05062, lr:4.61e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.883, tt:5707.020\n",
      "Ep:179, loss:0.00001, loss_test:0.05078, lr:4.57e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.881, tt:5738.567\n",
      "Ep:180, loss:0.00001, loss_test:0.05059, lr:4.52e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.881, tt:5770.410\n",
      "Ep:181, loss:0.00001, loss_test:0.05069, lr:4.48e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.882, tt:5802.526\n",
      "Ep:182, loss:0.00001, loss_test:0.05082, lr:4.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.875, tt:5833.216\n",
      "Ep:183, loss:0.00001, loss_test:0.05076, lr:4.39e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.873, tt:5864.588\n",
      "Ep:184, loss:0.00001, loss_test:0.05060, lr:4.34e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.880, tt:5897.839\n",
      "Ep:185, loss:0.00001, loss_test:0.05089, lr:4.30e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.882, tt:5930.122\n",
      "Ep:186, loss:0.00001, loss_test:0.05072, lr:4.26e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.907, tt:5966.558\n",
      "Ep:187, loss:0.00001, loss_test:0.05101, lr:4.21e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.900, tt:5997.183\n",
      "Ep:188, loss:0.00001, loss_test:0.05096, lr:4.17e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.894, tt:6027.934\n",
      "Ep:189, loss:0.00001, loss_test:0.05087, lr:4.13e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.895, tt:6059.985\n",
      "Ep:190, loss:0.00001, loss_test:0.05094, lr:4.09e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.899, tt:6092.681\n",
      "Ep:191, loss:0.00001, loss_test:0.05075, lr:4.05e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.887, tt:6122.363\n",
      "Ep:192, loss:0.00001, loss_test:0.05082, lr:4.01e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.890, tt:6154.692\n",
      "Ep:193, loss:0.00001, loss_test:0.05141, lr:3.97e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.887, tt:6186.139\n",
      "Ep:194, loss:0.00001, loss_test:0.05112, lr:3.93e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.889, tt:6218.302\n",
      "Ep:195, loss:0.00001, loss_test:0.05080, lr:3.89e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.887, tt:6249.822\n",
      "Ep:196, loss:0.00001, loss_test:0.05093, lr:3.85e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.890, tt:6282.377\n",
      "Ep:197, loss:0.00001, loss_test:0.05095, lr:3.81e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.888, tt:6313.735\n",
      "Ep:198, loss:0.00001, loss_test:0.05089, lr:3.77e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.888, tt:6345.632\n",
      "Ep:199, loss:0.00001, loss_test:0.05110, lr:3.73e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.872, tt:6374.397\n",
      "Ep:200, loss:0.00001, loss_test:0.05078, lr:3.70e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.864, tt:6404.685\n",
      "Ep:201, loss:0.00001, loss_test:0.05077, lr:3.66e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.851, tt:6433.999\n",
      "Ep:202, loss:0.00001, loss_test:0.05088, lr:3.62e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.841, tt:6463.748\n",
      "Ep:203, loss:0.00001, loss_test:0.05080, lr:3.59e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.829, tt:6493.042\n",
      "Ep:204, loss:0.00001, loss_test:0.05096, lr:3.55e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.790, tt:6516.852\n",
      "Ep:205, loss:0.00001, loss_test:0.05112, lr:3.52e-03, fs:0.88043 (r=0.818,p=0.953),  time:31.731, tt:6536.587\n",
      "Ep:206, loss:0.00001, loss_test:0.05105, lr:3.48e-03, fs:0.88649 (r=0.828,p=0.953),  time:31.709, tt:6563.787\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01984, lr:6.00e-02, fs:0.65098 (r=0.838,p=0.532),  time:30.922, tt:30.922\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02214, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:30.744, tt:61.488\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02386, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.821, tt:92.462\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02414, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.902, tt:123.608\n",
      "Ep:4, loss:0.00005, loss_test:0.02366, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.944, tt:154.718\n",
      "Ep:5, loss:0.00005, loss_test:0.02262, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:31.073, tt:186.437\n",
      "Ep:6, loss:0.00004, loss_test:0.02135, lr:6.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:31.266, tt:218.864\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02023, lr:6.00e-02, fs:0.66192 (r=0.939,p=0.511),  time:31.289, tt:250.308\n",
      "Ep:8, loss:0.00004, loss_test:0.01948, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:31.258, tt:281.320\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:31.296, tt:312.957\n",
      "Ep:10, loss:0.00004, loss_test:0.01868, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:31.080, tt:341.881\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01838, lr:6.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:31.183, tt:374.194\n",
      "Ep:12, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:31.249, tt:406.232\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01806, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:31.343, tt:438.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00004, loss_test:0.01787, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:31.403, tt:471.046\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.70896 (r=0.960,p=0.562),  time:31.375, tt:502.003\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:31.358, tt:533.093\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01692, lr:6.00e-02, fs:0.72180 (r=0.970,p=0.575),  time:31.393, tt:565.075\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.71970 (r=0.960,p=0.576),  time:31.377, tt:596.168\n",
      "Ep:19, loss:0.00003, loss_test:0.01632, lr:6.00e-02, fs:0.73077 (r=0.960,p=0.590),  time:31.425, tt:628.499\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01606, lr:6.00e-02, fs:0.72868 (r=0.949,p=0.591),  time:31.394, tt:659.277\n",
      "Ep:21, loss:0.00003, loss_test:0.01583, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:31.366, tt:690.056\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.75000 (r=0.970,p=0.611),  time:31.342, tt:720.870\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01539, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:31.340, tt:752.154\n",
      "Ep:24, loss:0.00003, loss_test:0.01519, lr:6.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:31.332, tt:783.297\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01499, lr:6.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:31.291, tt:813.577\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01482, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:31.381, tt:847.295\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01466, lr:6.00e-02, fs:0.76860 (r=0.939,p=0.650),  time:31.337, tt:877.429\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01454, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:31.326, tt:908.451\n",
      "Ep:29, loss:0.00003, loss_test:0.01443, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:31.300, tt:938.992\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01433, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:31.279, tt:969.645\n",
      "Ep:31, loss:0.00003, loss_test:0.01423, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:31.286, tt:1001.140\n",
      "Ep:32, loss:0.00003, loss_test:0.01413, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:31.334, tt:1034.011\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01404, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:31.349, tt:1065.880\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:31.312, tt:1095.937\n",
      "Ep:35, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:31.316, tt:1127.364\n",
      "Ep:36, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:31.316, tt:1158.680\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.78151 (r=0.939,p=0.669),  time:31.231, tt:1186.781\n",
      "Ep:38, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:31.224, tt:1217.749\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01359, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:31.224, tt:1248.978\n",
      "Ep:40, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:31.163, tt:1277.664\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:31.137, tt:1307.742\n",
      "Ep:42, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.79487 (r=0.939,p=0.689),  time:31.153, tt:1339.578\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:31.106, tt:1368.661\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:31.075, tt:1398.378\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:31.062, tt:1428.863\n",
      "Ep:46, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:31.051, tt:1459.375\n",
      "Ep:47, loss:0.00002, loss_test:0.01307, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:31.031, tt:1489.489\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:30.983, tt:1518.158\n",
      "Ep:49, loss:0.00002, loss_test:0.01296, lr:6.00e-02, fs:0.81034 (r=0.949,p=0.707),  time:30.971, tt:1548.532\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:30.963, tt:1579.137\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:30.954, tt:1609.613\n",
      "Ep:52, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:30.962, tt:1640.996\n",
      "Ep:53, loss:0.00002, loss_test:0.01274, lr:6.00e-02, fs:0.81223 (r=0.939,p=0.715),  time:30.960, tt:1671.848\n",
      "Ep:54, loss:0.00002, loss_test:0.01269, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.926, tt:1700.955\n",
      "Ep:55, loss:0.00002, loss_test:0.01263, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.902, tt:1730.518\n",
      "Ep:56, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.898, tt:1761.168\n",
      "Ep:57, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:30.898, tt:1792.107\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:30.935, tt:1825.177\n",
      "Ep:59, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:30.903, tt:1854.164\n",
      "Ep:60, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:30.876, tt:1883.427\n",
      "Ep:61, loss:0.00002, loss_test:0.01240, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:30.859, tt:1913.274\n",
      "Ep:62, loss:0.00002, loss_test:0.01235, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.828, tt:1942.189\n",
      "Ep:63, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.793, tt:1970.773\n",
      "Ep:64, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.758, tt:1999.291\n",
      "Ep:65, loss:0.00002, loss_test:0.01221, lr:6.00e-02, fs:0.80000 (r=0.909,p=0.714),  time:30.738, tt:2028.722\n",
      "Ep:66, loss:0.00002, loss_test:0.01218, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:30.724, tt:2058.530\n",
      "Ep:67, loss:0.00002, loss_test:0.01215, lr:6.00e-02, fs:0.79464 (r=0.899,p=0.712),  time:30.710, tt:2088.300\n",
      "Ep:68, loss:0.00002, loss_test:0.01213, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:30.703, tt:2118.495\n",
      "Ep:69, loss:0.00002, loss_test:0.01209, lr:5.94e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.699, tt:2148.941\n",
      "Ep:70, loss:0.00002, loss_test:0.01205, lr:5.88e-02, fs:0.79821 (r=0.899,p=0.718),  time:30.710, tt:2180.376\n",
      "Ep:71, loss:0.00002, loss_test:0.01203, lr:5.82e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.703, tt:2210.631\n",
      "Ep:72, loss:0.00001, loss_test:0.01200, lr:5.76e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.712, tt:2241.954\n",
      "Ep:73, loss:0.00001, loss_test:0.01198, lr:5.71e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.714, tt:2272.804\n",
      "Ep:74, loss:0.00001, loss_test:0.01196, lr:5.65e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.718, tt:2303.851\n",
      "Ep:75, loss:0.00001, loss_test:0.01194, lr:5.59e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.706, tt:2333.622\n",
      "Ep:76, loss:0.00001, loss_test:0.01193, lr:5.54e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.713, tt:2364.893\n",
      "Ep:77, loss:0.00001, loss_test:0.01190, lr:5.48e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.693, tt:2394.087\n",
      "Ep:78, loss:0.00001, loss_test:0.01188, lr:5.43e-02, fs:0.80180 (r=0.899,p=0.724),  time:30.694, tt:2424.818\n",
      "Ep:79, loss:0.00001, loss_test:0.01186, lr:5.37e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.701, tt:2456.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00001, loss_test:0.01183, lr:5.32e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.698, tt:2486.498\n",
      "Ep:81, loss:0.00001, loss_test:0.01181, lr:5.27e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.696, tt:2517.070\n",
      "Ep:82, loss:0.00001, loss_test:0.01181, lr:5.21e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.702, tt:2548.236\n",
      "Ep:83, loss:0.00001, loss_test:0.01179, lr:5.16e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.707, tt:2579.355\n",
      "Ep:84, loss:0.00001, loss_test:0.01178, lr:5.11e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.716, tt:2610.842\n",
      "Ep:85, loss:0.00001, loss_test:0.01175, lr:5.06e-02, fs:0.80543 (r=0.899,p=0.730),  time:30.703, tt:2640.421\n",
      "Ep:86, loss:0.00001, loss_test:0.01174, lr:5.01e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.691, tt:2670.141\n",
      "Ep:87, loss:0.00001, loss_test:0.01173, lr:4.96e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.689, tt:2700.660\n",
      "Ep:88, loss:0.00001, loss_test:0.01174, lr:4.91e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.686, tt:2731.067\n",
      "Ep:89, loss:0.00001, loss_test:0.01174, lr:4.86e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.673, tt:2760.586\n",
      "Ep:90, loss:0.00001, loss_test:0.01174, lr:4.81e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.670, tt:2791.010\n",
      "Ep:91, loss:0.00001, loss_test:0.01172, lr:4.76e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.653, tt:2820.093\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01169, lr:4.76e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.642, tt:2849.737\n",
      "Ep:93, loss:0.00001, loss_test:0.01167, lr:4.76e-02, fs:0.81818 (r=0.909,p=0.744),  time:30.634, tt:2879.643\n",
      "Ep:94, loss:0.00001, loss_test:0.01169, lr:4.76e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.644, tt:2911.166\n",
      "Ep:95, loss:0.00001, loss_test:0.01167, lr:4.76e-02, fs:0.81279 (r=0.899,p=0.742),  time:30.635, tt:2940.990\n",
      "Ep:96, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.81651 (r=0.899,p=0.748),  time:30.660, tt:2974.068\n",
      "Ep:97, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.82028 (r=0.899,p=0.754),  time:30.640, tt:3002.736\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.82407 (r=0.899,p=0.761),  time:30.657, tt:3035.056\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01167, lr:4.76e-02, fs:0.83178 (r=0.899,p=0.774),  time:30.659, tt:3065.862\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01167, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.656, tt:3096.281\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.01165, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.658, tt:3127.071\n",
      "Ep:102, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.670, tt:3159.017\n",
      "Ep:103, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.678, tt:3190.488\n",
      "Ep:104, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.646, tt:3217.835\n",
      "Ep:105, loss:0.00001, loss_test:0.01160, lr:4.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:30.628, tt:3246.610\n",
      "Ep:106, loss:0.00001, loss_test:0.01162, lr:4.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.631, tt:3277.549\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.631, tt:3308.196\n",
      "Ep:108, loss:0.00001, loss_test:0.01162, lr:4.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.621, tt:3337.663\n",
      "Ep:109, loss:0.00001, loss_test:0.01161, lr:4.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.622, tt:3368.469\n",
      "Ep:110, loss:0.00001, loss_test:0.01160, lr:4.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:30.617, tt:3398.468\n",
      "Ep:111, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.618, tt:3429.197\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.625, tt:3460.617\n",
      "Ep:113, loss:0.00001, loss_test:0.01162, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.615, tt:3490.069\n",
      "Ep:114, loss:0.00001, loss_test:0.01159, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.614, tt:3520.647\n",
      "Ep:115, loss:0.00001, loss_test:0.01161, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.610, tt:3550.811\n",
      "Ep:116, loss:0.00001, loss_test:0.01161, lr:4.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.591, tt:3579.118\n",
      "Ep:117, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.589, tt:3609.493\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.602, tt:3641.686\n",
      "Ep:119, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.601, tt:3672.130\n",
      "Ep:120, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.596, tt:3702.078\n",
      "Ep:121, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.598, tt:3733.012\n",
      "Ep:122, loss:0.00001, loss_test:0.01164, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.595, tt:3763.186\n",
      "Ep:123, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.587, tt:3792.826\n",
      "Ep:124, loss:0.00001, loss_test:0.01167, lr:4.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.584, tt:3823.020\n",
      "Ep:125, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:30.583, tt:3853.511\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:30.581, tt:3883.820\n",
      "Ep:127, loss:0.00001, loss_test:0.01163, lr:4.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:30.581, tt:3914.384\n",
      "Ep:128, loss:0.00001, loss_test:0.01165, lr:4.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:30.584, tt:3945.384\n",
      "Ep:129, loss:0.00001, loss_test:0.01166, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.589, tt:3976.591\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00001, loss_test:0.01168, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.601, tt:4008.785\n",
      "Ep:131, loss:0.00001, loss_test:0.01169, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.601, tt:4039.343\n",
      "Ep:132, loss:0.00001, loss_test:0.01170, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.605, tt:4070.463\n",
      "Ep:133, loss:0.00001, loss_test:0.01170, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.602, tt:4100.634\n",
      "Ep:134, loss:0.00001, loss_test:0.01169, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.602, tt:4131.217\n",
      "Ep:135, loss:0.00001, loss_test:0.01169, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.616, tt:4163.789\n",
      "Ep:136, loss:0.00001, loss_test:0.01171, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.618, tt:4194.599\n",
      "Ep:137, loss:0.00001, loss_test:0.01173, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.612, tt:4224.502\n",
      "Ep:138, loss:0.00001, loss_test:0.01175, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.618, tt:4255.944\n",
      "Ep:139, loss:0.00001, loss_test:0.01174, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.617, tt:4286.360\n",
      "Ep:140, loss:0.00001, loss_test:0.01173, lr:4.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.607, tt:4315.643\n",
      "Ep:141, loss:0.00001, loss_test:0.01176, lr:4.71e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.599, tt:4345.106\n",
      "Ep:142, loss:0.00001, loss_test:0.01174, lr:4.67e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.592, tt:4374.585\n",
      "Ep:143, loss:0.00001, loss_test:0.01178, lr:4.62e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.582, tt:4403.808\n",
      "Ep:144, loss:0.00001, loss_test:0.01182, lr:4.57e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.588, tt:4435.239\n",
      "Ep:145, loss:0.00001, loss_test:0.01180, lr:4.53e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.576, tt:4464.059\n",
      "Ep:146, loss:0.00001, loss_test:0.01178, lr:4.48e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.576, tt:4494.642\n",
      "Ep:147, loss:0.00001, loss_test:0.01180, lr:4.44e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.583, tt:4526.216\n",
      "Ep:148, loss:0.00001, loss_test:0.01179, lr:4.39e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.591, tt:4558.028\n",
      "Ep:149, loss:0.00001, loss_test:0.01183, lr:4.35e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.590, tt:4588.486\n",
      "Ep:150, loss:0.00001, loss_test:0.01184, lr:4.31e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.595, tt:4619.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00001, loss_test:0.01182, lr:4.26e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.595, tt:4650.378\n",
      "Ep:152, loss:0.00001, loss_test:0.01184, lr:4.22e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.595, tt:4680.991\n",
      "Ep:153, loss:0.00001, loss_test:0.01188, lr:4.18e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.597, tt:4711.926\n",
      "Ep:154, loss:0.00001, loss_test:0.01187, lr:4.14e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.590, tt:4741.417\n",
      "Ep:155, loss:0.00001, loss_test:0.01187, lr:4.10e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.585, tt:4771.197\n",
      "Ep:156, loss:0.00001, loss_test:0.01189, lr:4.05e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.591, tt:4802.798\n",
      "Ep:157, loss:0.00001, loss_test:0.01189, lr:4.01e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.589, tt:4833.085\n",
      "Ep:158, loss:0.00001, loss_test:0.01189, lr:3.97e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.602, tt:4865.703\n",
      "Ep:159, loss:0.00001, loss_test:0.01190, lr:3.93e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.605, tt:4896.782\n",
      "Ep:160, loss:0.00001, loss_test:0.01195, lr:3.89e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.607, tt:4927.775\n",
      "Ep:161, loss:0.00001, loss_test:0.01196, lr:3.86e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.614, tt:4959.430\n",
      "Ep:162, loss:0.00001, loss_test:0.01195, lr:3.82e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.616, tt:4990.397\n",
      "Ep:163, loss:0.00001, loss_test:0.01194, lr:3.78e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.614, tt:5020.623\n",
      "Ep:164, loss:0.00001, loss_test:0.01196, lr:3.74e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.609, tt:5050.561\n",
      "Ep:165, loss:0.00001, loss_test:0.01194, lr:3.70e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.609, tt:5081.112\n",
      "Ep:166, loss:0.00001, loss_test:0.01197, lr:3.67e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.606, tt:5111.138\n",
      "Ep:167, loss:0.00001, loss_test:0.01199, lr:3.63e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.614, tt:5143.222\n",
      "Ep:168, loss:0.00001, loss_test:0.01199, lr:3.59e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.610, tt:5173.030\n",
      "Ep:169, loss:0.00001, loss_test:0.01201, lr:3.56e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.607, tt:5203.225\n",
      "Ep:170, loss:0.00001, loss_test:0.01203, lr:3.52e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.613, tt:5234.766\n",
      "Ep:171, loss:0.00001, loss_test:0.01202, lr:3.49e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.613, tt:5265.354\n",
      "Ep:172, loss:0.00001, loss_test:0.01202, lr:3.45e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.618, tt:5296.934\n",
      "Ep:173, loss:0.00001, loss_test:0.01205, lr:3.42e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.625, tt:5328.787\n",
      "Ep:174, loss:0.00001, loss_test:0.01207, lr:3.38e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.624, tt:5359.217\n",
      "Ep:175, loss:0.00001, loss_test:0.01205, lr:3.35e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.629, tt:5390.700\n",
      "Ep:176, loss:0.00001, loss_test:0.01207, lr:3.32e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.636, tt:5422.604\n",
      "Ep:177, loss:0.00001, loss_test:0.01207, lr:3.28e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.646, tt:5454.903\n",
      "Ep:178, loss:0.00001, loss_test:0.01207, lr:3.25e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.637, tt:5483.958\n",
      "Ep:179, loss:0.00001, loss_test:0.01209, lr:3.22e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.630, tt:5513.438\n",
      "Ep:180, loss:0.00001, loss_test:0.01212, lr:3.19e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.629, tt:5543.785\n",
      "Ep:181, loss:0.00001, loss_test:0.01213, lr:3.15e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.629, tt:5574.512\n",
      "Ep:182, loss:0.00001, loss_test:0.01212, lr:3.12e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.626, tt:5604.644\n",
      "Ep:183, loss:0.00001, loss_test:0.01211, lr:3.09e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.618, tt:5633.635\n",
      "Ep:184, loss:0.00001, loss_test:0.01212, lr:3.06e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.617, tt:5664.165\n",
      "Ep:185, loss:0.00001, loss_test:0.01214, lr:3.03e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.612, tt:5693.783\n",
      "Ep:186, loss:0.00001, loss_test:0.01215, lr:3.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.605, tt:5723.154\n",
      "Ep:187, loss:0.00001, loss_test:0.01217, lr:2.97e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.603, tt:5753.421\n",
      "Ep:188, loss:0.00001, loss_test:0.01218, lr:2.94e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.599, tt:5783.218\n",
      "Ep:189, loss:0.00001, loss_test:0.01219, lr:2.91e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.598, tt:5813.667\n",
      "Ep:190, loss:0.00001, loss_test:0.01220, lr:2.88e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.597, tt:5844.108\n",
      "Ep:191, loss:0.00001, loss_test:0.01219, lr:2.85e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.600, tt:5875.159\n",
      "Ep:192, loss:0.00001, loss_test:0.01220, lr:2.82e-02, fs:0.86408 (r=0.899,p=0.832),  time:30.600, tt:5905.888\n",
      "Ep:193, loss:0.00001, loss_test:0.01221, lr:2.80e-02, fs:0.86829 (r=0.899,p=0.840),  time:30.601, tt:5936.631\n",
      "##########Best model found so far##########\n",
      "Ep:194, loss:0.00001, loss_test:0.01222, lr:2.80e-02, fs:0.86829 (r=0.899,p=0.840),  time:30.597, tt:5966.363\n",
      "Ep:195, loss:0.00001, loss_test:0.01221, lr:2.80e-02, fs:0.86829 (r=0.899,p=0.840),  time:30.594, tt:5996.494\n",
      "Ep:196, loss:0.00001, loss_test:0.01222, lr:2.80e-02, fs:0.86829 (r=0.899,p=0.840),  time:30.588, tt:6025.770\n",
      "Ep:197, loss:0.00001, loss_test:0.01223, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.580, tt:6054.748\n",
      "##########Best model found so far##########\n",
      "Ep:198, loss:0.00001, loss_test:0.01225, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.575, tt:6084.376\n",
      "Ep:199, loss:0.00001, loss_test:0.01224, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.579, tt:6115.883\n",
      "Ep:200, loss:0.00001, loss_test:0.01225, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.573, tt:6145.229\n",
      "Ep:201, loss:0.00001, loss_test:0.01228, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.561, tt:6173.255\n",
      "Ep:202, loss:0.00001, loss_test:0.01229, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.560, tt:6203.742\n",
      "Ep:203, loss:0.00001, loss_test:0.01229, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.552, tt:6232.520\n",
      "Ep:204, loss:0.00000, loss_test:0.01229, lr:2.80e-02, fs:0.87255 (r=0.899,p=0.848),  time:30.545, tt:6261.755\n",
      "Ep:205, loss:0.00000, loss_test:0.01229, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.532, tt:6289.525\n",
      "##########Best model found so far##########\n",
      "Ep:206, loss:0.00000, loss_test:0.01230, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.516, tt:6316.788\n",
      "Ep:207, loss:0.00000, loss_test:0.01231, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.506, tt:6345.343\n",
      "Ep:208, loss:0.00000, loss_test:0.01231, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.483, tt:6370.870\n",
      "Ep:209, loss:0.00000, loss_test:0.01234, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.471, tt:6398.896\n",
      "Ep:210, loss:0.00000, loss_test:0.01236, lr:2.80e-02, fs:0.87685 (r=0.899,p=0.856),  time:30.466, tt:6428.379\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13988, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.536, tt:33.536\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13803, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.209, tt:66.418\n",
      "Ep:2, loss:0.00027, loss_test:0.13472, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.502, tt:100.506\n",
      "Ep:3, loss:0.00027, loss_test:0.12940, lr:1.00e-02, fs:0.67361 (r=0.980,p=0.513),  time:33.418, tt:133.671\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12215, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:33.456, tt:167.281\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11508, lr:1.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:33.475, tt:200.850\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11203, lr:1.00e-02, fs:0.68996 (r=0.798,p=0.608),  time:33.512, tt:234.584\n",
      "Ep:7, loss:0.00023, loss_test:0.11034, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:33.632, tt:269.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00022, loss_test:0.10950, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:33.463, tt:301.168\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10895, lr:1.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:33.784, tt:337.839\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10622, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:33.853, tt:372.380\n",
      "Ep:11, loss:0.00021, loss_test:0.10257, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:33.816, tt:405.787\n",
      "Ep:12, loss:0.00020, loss_test:0.10033, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:33.710, tt:438.231\n",
      "Ep:13, loss:0.00019, loss_test:0.09861, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:33.651, tt:471.110\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09616, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:33.604, tt:504.061\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09399, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:33.602, tt:537.630\n",
      "Ep:16, loss:0.00018, loss_test:0.09242, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:33.643, tt:571.933\n",
      "Ep:17, loss:0.00017, loss_test:0.09112, lr:1.00e-02, fs:0.74886 (r=0.828,p=0.683),  time:33.598, tt:604.769\n",
      "Ep:18, loss:0.00017, loss_test:0.08896, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:33.497, tt:636.448\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08763, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:33.413, tt:668.266\n",
      "Ep:20, loss:0.00016, loss_test:0.08660, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:33.374, tt:700.861\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08443, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:33.410, tt:735.011\n",
      "Ep:22, loss:0.00015, loss_test:0.08379, lr:1.00e-02, fs:0.78899 (r=0.869,p=0.723),  time:33.411, tt:768.454\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08247, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:33.453, tt:802.863\n",
      "Ep:24, loss:0.00014, loss_test:0.08152, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:33.515, tt:837.869\n",
      "Ep:25, loss:0.00014, loss_test:0.08115, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:33.488, tt:870.694\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07917, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:33.440, tt:902.884\n",
      "Ep:27, loss:0.00013, loss_test:0.07908, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:33.379, tt:934.599\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.07792, lr:1.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:33.364, tt:967.556\n",
      "Ep:29, loss:0.00012, loss_test:0.07646, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:33.323, tt:999.679\n",
      "Ep:30, loss:0.00012, loss_test:0.07730, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:33.325, tt:1033.062\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.07523, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:33.324, tt:1066.367\n",
      "Ep:32, loss:0.00011, loss_test:0.07476, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:33.273, tt:1098.011\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07382, lr:1.00e-02, fs:0.83254 (r=0.879,p=0.791),  time:33.285, tt:1131.700\n",
      "Ep:34, loss:0.00011, loss_test:0.07368, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:33.274, tt:1164.595\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00011, loss_test:0.07264, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:33.271, tt:1197.756\n",
      "Ep:36, loss:0.00010, loss_test:0.07154, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:33.253, tt:1230.347\n",
      "Ep:37, loss:0.00010, loss_test:0.07144, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:33.214, tt:1262.134\n",
      "Ep:38, loss:0.00010, loss_test:0.07041, lr:1.00e-02, fs:0.81340 (r=0.859,p=0.773),  time:33.183, tt:1294.121\n",
      "Ep:39, loss:0.00010, loss_test:0.07001, lr:1.00e-02, fs:0.82297 (r=0.869,p=0.782),  time:33.147, tt:1325.897\n",
      "Ep:40, loss:0.00009, loss_test:0.06927, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:33.161, tt:1359.612\n",
      "Ep:41, loss:0.00009, loss_test:0.06853, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:33.137, tt:1391.759\n",
      "Ep:42, loss:0.00009, loss_test:0.06746, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:33.096, tt:1423.119\n",
      "Ep:43, loss:0.00009, loss_test:0.06738, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:33.086, tt:1455.794\n",
      "Ep:44, loss:0.00009, loss_test:0.06777, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:33.058, tt:1487.616\n",
      "Ep:45, loss:0.00008, loss_test:0.06603, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:33.023, tt:1519.061\n",
      "Ep:46, loss:0.00008, loss_test:0.06696, lr:9.90e-03, fs:0.82857 (r=0.879,p=0.784),  time:32.988, tt:1550.451\n",
      "Ep:47, loss:0.00008, loss_test:0.06499, lr:9.80e-03, fs:0.84422 (r=0.848,p=0.840),  time:32.994, tt:1583.693\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00008, loss_test:0.06479, lr:9.80e-03, fs:0.82297 (r=0.869,p=0.782),  time:32.960, tt:1615.053\n",
      "Ep:49, loss:0.00008, loss_test:0.06433, lr:9.80e-03, fs:0.84577 (r=0.859,p=0.833),  time:32.940, tt:1647.021\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00008, loss_test:0.06376, lr:9.80e-03, fs:0.84729 (r=0.869,p=0.827),  time:32.892, tt:1677.493\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.06342, lr:9.80e-03, fs:0.85000 (r=0.859,p=0.842),  time:32.849, tt:1708.170\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00007, loss_test:0.06248, lr:9.80e-03, fs:0.83744 (r=0.859,p=0.817),  time:32.831, tt:1740.065\n",
      "Ep:53, loss:0.00007, loss_test:0.06352, lr:9.80e-03, fs:0.84466 (r=0.879,p=0.813),  time:32.819, tt:1772.208\n",
      "Ep:54, loss:0.00007, loss_test:0.06118, lr:9.80e-03, fs:0.84848 (r=0.848,p=0.848),  time:32.764, tt:1802.047\n",
      "Ep:55, loss:0.00007, loss_test:0.06249, lr:9.80e-03, fs:0.84466 (r=0.879,p=0.813),  time:32.781, tt:1835.719\n",
      "Ep:56, loss:0.00007, loss_test:0.06142, lr:9.80e-03, fs:0.86154 (r=0.848,p=0.875),  time:32.746, tt:1866.542\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00006, loss_test:0.06068, lr:9.80e-03, fs:0.85149 (r=0.869,p=0.835),  time:32.738, tt:1898.796\n",
      "Ep:58, loss:0.00006, loss_test:0.06080, lr:9.80e-03, fs:0.85572 (r=0.869,p=0.843),  time:32.730, tt:1931.097\n",
      "Ep:59, loss:0.00006, loss_test:0.06025, lr:9.80e-03, fs:0.85427 (r=0.859,p=0.850),  time:32.706, tt:1962.356\n",
      "Ep:60, loss:0.00006, loss_test:0.06027, lr:9.80e-03, fs:0.85572 (r=0.869,p=0.843),  time:32.687, tt:1993.924\n",
      "Ep:61, loss:0.00006, loss_test:0.05970, lr:9.80e-03, fs:0.86000 (r=0.869,p=0.851),  time:32.666, tt:2025.275\n",
      "Ep:62, loss:0.00006, loss_test:0.05907, lr:9.80e-03, fs:0.86000 (r=0.869,p=0.851),  time:32.640, tt:2056.291\n",
      "Ep:63, loss:0.00006, loss_test:0.05861, lr:9.80e-03, fs:0.86000 (r=0.869,p=0.851),  time:32.623, tt:2087.866\n",
      "Ep:64, loss:0.00006, loss_test:0.05853, lr:9.80e-03, fs:0.85294 (r=0.879,p=0.829),  time:32.608, tt:2119.536\n",
      "Ep:65, loss:0.00005, loss_test:0.05867, lr:9.80e-03, fs:0.86000 (r=0.869,p=0.851),  time:32.589, tt:2150.857\n",
      "Ep:66, loss:0.00005, loss_test:0.05769, lr:9.80e-03, fs:0.85714 (r=0.879,p=0.837),  time:32.586, tt:2183.252\n",
      "Ep:67, loss:0.00005, loss_test:0.05830, lr:9.80e-03, fs:0.86432 (r=0.869,p=0.860),  time:32.580, tt:2215.463\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00005, loss_test:0.05722, lr:9.80e-03, fs:0.86139 (r=0.879,p=0.845),  time:32.578, tt:2247.867\n",
      "Ep:69, loss:0.00005, loss_test:0.05803, lr:9.80e-03, fs:0.88083 (r=0.859,p=0.904),  time:32.566, tt:2279.634\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00005, loss_test:0.05714, lr:9.80e-03, fs:0.86567 (r=0.879,p=0.853),  time:32.580, tt:2313.210\n",
      "Ep:71, loss:0.00005, loss_test:0.05770, lr:9.80e-03, fs:0.88660 (r=0.869,p=0.905),  time:32.589, tt:2346.415\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.05659, lr:9.80e-03, fs:0.87629 (r=0.859,p=0.895),  time:32.599, tt:2379.740\n",
      "Ep:73, loss:0.00005, loss_test:0.05897, lr:9.80e-03, fs:0.86700 (r=0.889,p=0.846),  time:32.599, tt:2412.359\n",
      "Ep:74, loss:0.00005, loss_test:0.05623, lr:9.80e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.571, tt:2442.835\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:75, loss:0.00005, loss_test:0.05750, lr:9.80e-03, fs:0.85714 (r=0.879,p=0.837),  time:32.561, tt:2474.631\n",
      "Ep:76, loss:0.00004, loss_test:0.05583, lr:9.80e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.557, tt:2506.878\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00004, loss_test:0.05755, lr:9.80e-03, fs:0.85854 (r=0.889,p=0.830),  time:32.537, tt:2537.886\n",
      "Ep:78, loss:0.00004, loss_test:0.05670, lr:9.80e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.526, tt:2569.584\n",
      "Ep:79, loss:0.00004, loss_test:0.05520, lr:9.80e-03, fs:0.87437 (r=0.879,p=0.870),  time:32.522, tt:2601.759\n",
      "Ep:80, loss:0.00004, loss_test:0.05694, lr:9.80e-03, fs:0.87629 (r=0.859,p=0.895),  time:32.521, tt:2634.192\n",
      "Ep:81, loss:0.00004, loss_test:0.05357, lr:9.80e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.514, tt:2666.131\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00004, loss_test:0.05705, lr:9.80e-03, fs:0.87310 (r=0.869,p=0.878),  time:32.536, tt:2700.502\n",
      "Ep:83, loss:0.00004, loss_test:0.05438, lr:9.80e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.540, tt:2733.325\n",
      "Ep:84, loss:0.00004, loss_test:0.05695, lr:9.80e-03, fs:0.88442 (r=0.889,p=0.880),  time:32.545, tt:2766.294\n",
      "Ep:85, loss:0.00004, loss_test:0.05319, lr:9.80e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.564, tt:2800.531\n",
      "Ep:86, loss:0.00004, loss_test:0.05646, lr:9.80e-03, fs:0.88442 (r=0.889,p=0.880),  time:32.580, tt:2834.489\n",
      "Ep:87, loss:0.00004, loss_test:0.05364, lr:9.80e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.592, tt:2868.084\n",
      "Ep:88, loss:0.00004, loss_test:0.05530, lr:9.80e-03, fs:0.88325 (r=0.879,p=0.888),  time:32.598, tt:2901.199\n",
      "Ep:89, loss:0.00003, loss_test:0.05362, lr:9.80e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.595, tt:2933.558\n",
      "Ep:90, loss:0.00003, loss_test:0.05457, lr:9.80e-03, fs:0.88325 (r=0.879,p=0.888),  time:32.599, tt:2966.506\n",
      "Ep:91, loss:0.00003, loss_test:0.05458, lr:9.80e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.594, tt:2998.670\n",
      "Ep:92, loss:0.00003, loss_test:0.05435, lr:9.80e-03, fs:0.87310 (r=0.869,p=0.878),  time:32.599, tt:3031.722\n",
      "Ep:93, loss:0.00003, loss_test:0.05396, lr:9.70e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.580, tt:3062.541\n",
      "Ep:94, loss:0.00003, loss_test:0.05434, lr:9.61e-03, fs:0.88205 (r=0.869,p=0.896),  time:32.589, tt:3095.908\n",
      "Ep:95, loss:0.00003, loss_test:0.05507, lr:9.51e-03, fs:0.89474 (r=0.859,p=0.934),  time:32.581, tt:3127.775\n",
      "Ep:96, loss:0.00003, loss_test:0.05326, lr:9.41e-03, fs:0.90052 (r=0.869,p=0.935),  time:32.563, tt:3158.649\n",
      "Ep:97, loss:0.00003, loss_test:0.05435, lr:9.32e-03, fs:0.90052 (r=0.869,p=0.935),  time:32.575, tt:3192.380\n",
      "Ep:98, loss:0.00003, loss_test:0.05385, lr:9.23e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.574, tt:3224.850\n",
      "Ep:99, loss:0.00003, loss_test:0.05339, lr:9.14e-03, fs:0.89583 (r=0.869,p=0.925),  time:32.563, tt:3256.292\n",
      "Ep:100, loss:0.00003, loss_test:0.05505, lr:9.04e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.564, tt:3288.992\n",
      "Ep:101, loss:0.00003, loss_test:0.05322, lr:8.95e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.565, tt:3321.606\n",
      "Ep:102, loss:0.00003, loss_test:0.05465, lr:8.86e-03, fs:0.90052 (r=0.869,p=0.935),  time:32.589, tt:3356.702\n",
      "Ep:103, loss:0.00003, loss_test:0.05325, lr:8.78e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.583, tt:3388.610\n",
      "Ep:104, loss:0.00003, loss_test:0.05337, lr:8.69e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.574, tt:3420.220\n",
      "Ep:105, loss:0.00003, loss_test:0.05335, lr:8.60e-03, fs:0.92228 (r=0.899,p=0.947),  time:32.564, tt:3451.799\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00003, loss_test:0.05335, lr:8.60e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.553, tt:3483.201\n",
      "Ep:107, loss:0.00003, loss_test:0.05290, lr:8.60e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.530, tt:3513.237\n",
      "Ep:108, loss:0.00003, loss_test:0.05364, lr:8.60e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.496, tt:3542.026\n",
      "Ep:109, loss:0.00003, loss_test:0.05242, lr:8.60e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.473, tt:3572.044\n",
      "Ep:110, loss:0.00002, loss_test:0.05367, lr:8.60e-03, fs:0.92708 (r=0.899,p=0.957),  time:32.466, tt:3603.675\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00002, loss_test:0.05230, lr:8.60e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.457, tt:3635.239\n",
      "Ep:112, loss:0.00002, loss_test:0.05340, lr:8.60e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.446, tt:3666.423\n",
      "Ep:113, loss:0.00002, loss_test:0.05170, lr:8.60e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.444, tt:3698.594\n",
      "Ep:114, loss:0.00002, loss_test:0.05318, lr:8.60e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.430, tt:3729.477\n",
      "Ep:115, loss:0.00002, loss_test:0.05221, lr:8.60e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.431, tt:3761.992\n",
      "Ep:116, loss:0.00002, loss_test:0.05274, lr:8.60e-03, fs:0.90625 (r=0.879,p=0.935),  time:32.425, tt:3793.763\n",
      "Ep:117, loss:0.00002, loss_test:0.05214, lr:8.60e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.412, tt:3824.669\n",
      "Ep:118, loss:0.00002, loss_test:0.05299, lr:8.60e-03, fs:0.90052 (r=0.869,p=0.935),  time:32.412, tt:3856.976\n",
      "Ep:119, loss:0.00002, loss_test:0.05120, lr:8.60e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.411, tt:3889.299\n",
      "Ep:120, loss:0.00002, loss_test:0.05415, lr:8.60e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.418, tt:3922.598\n",
      "Ep:121, loss:0.00002, loss_test:0.05116, lr:8.60e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.405, tt:3953.407\n",
      "Ep:122, loss:0.00002, loss_test:0.05351, lr:8.51e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.406, tt:3985.898\n",
      "Ep:123, loss:0.00002, loss_test:0.05089, lr:8.43e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.428, tt:4021.121\n",
      "Ep:124, loss:0.00002, loss_test:0.05232, lr:8.35e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.427, tt:4053.345\n",
      "Ep:125, loss:0.00002, loss_test:0.05178, lr:8.26e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.416, tt:4084.419\n",
      "Ep:126, loss:0.00002, loss_test:0.05379, lr:8.18e-03, fs:0.88043 (r=0.818,p=0.953),  time:32.417, tt:4116.978\n",
      "Ep:127, loss:0.00002, loss_test:0.05286, lr:8.10e-03, fs:0.90323 (r=0.848,p=0.966),  time:32.411, tt:4148.610\n",
      "Ep:128, loss:0.00002, loss_test:0.05220, lr:8.02e-03, fs:0.90526 (r=0.869,p=0.945),  time:32.415, tt:4181.590\n",
      "Ep:129, loss:0.00002, loss_test:0.05273, lr:7.94e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.408, tt:4213.089\n",
      "Ep:130, loss:0.00002, loss_test:0.05221, lr:7.86e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.415, tt:4246.412\n",
      "Ep:131, loss:0.00002, loss_test:0.05161, lr:7.78e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.413, tt:4278.546\n",
      "Ep:132, loss:0.00002, loss_test:0.05224, lr:7.70e-03, fs:0.92708 (r=0.899,p=0.957),  time:32.411, tt:4310.636\n",
      "Ep:133, loss:0.00002, loss_test:0.05091, lr:7.62e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.394, tt:4340.846\n",
      "Ep:134, loss:0.00002, loss_test:0.05221, lr:7.55e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.389, tt:4372.553\n",
      "Ep:135, loss:0.00002, loss_test:0.05177, lr:7.47e-03, fs:0.93194 (r=0.899,p=0.967),  time:32.379, tt:4403.569\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00002, loss_test:0.05111, lr:7.47e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.363, tt:4433.762\n",
      "Ep:137, loss:0.00002, loss_test:0.05164, lr:7.47e-03, fs:0.93194 (r=0.899,p=0.967),  time:32.358, tt:4465.360\n",
      "Ep:138, loss:0.00002, loss_test:0.05223, lr:7.47e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.348, tt:4496.351\n",
      "Ep:139, loss:0.00002, loss_test:0.05187, lr:7.47e-03, fs:0.89947 (r=0.859,p=0.944),  time:32.346, tt:4528.493\n",
      "Ep:140, loss:0.00002, loss_test:0.05271, lr:7.47e-03, fs:0.92708 (r=0.899,p=0.957),  time:32.344, tt:4560.543\n",
      "Ep:141, loss:0.00002, loss_test:0.05107, lr:7.47e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.341, tt:4592.410\n",
      "Ep:142, loss:0.00002, loss_test:0.05230, lr:7.47e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.340, tt:4624.554\n",
      "Ep:143, loss:0.00002, loss_test:0.05182, lr:7.47e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.331, tt:4655.714\n",
      "Ep:144, loss:0.00002, loss_test:0.05221, lr:7.47e-03, fs:0.91099 (r=0.879,p=0.946),  time:32.350, tt:4690.741\n",
      "Ep:145, loss:0.00002, loss_test:0.05158, lr:7.47e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.343, tt:4722.081\n",
      "Ep:146, loss:0.00002, loss_test:0.05175, lr:7.47e-03, fs:0.92147 (r=0.889,p=0.957),  time:32.338, tt:4753.637\n",
      "Ep:147, loss:0.00002, loss_test:0.05109, lr:7.40e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.337, tt:4785.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:148, loss:0.00002, loss_test:0.05179, lr:7.32e-03, fs:0.93194 (r=0.899,p=0.967),  time:32.332, tt:4817.420\n",
      "Ep:149, loss:0.00002, loss_test:0.05237, lr:7.25e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.325, tt:4848.791\n",
      "Ep:150, loss:0.00002, loss_test:0.05079, lr:7.18e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.323, tt:4880.718\n",
      "Ep:151, loss:0.00002, loss_test:0.05304, lr:7.11e-03, fs:0.92147 (r=0.889,p=0.957),  time:32.322, tt:4912.869\n",
      "Ep:152, loss:0.00002, loss_test:0.05075, lr:7.03e-03, fs:0.92632 (r=0.889,p=0.967),  time:32.323, tt:4945.457\n",
      "Ep:153, loss:0.00002, loss_test:0.05224, lr:6.96e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.317, tt:4976.880\n",
      "Ep:154, loss:0.00002, loss_test:0.05170, lr:6.89e-03, fs:0.93194 (r=0.899,p=0.967),  time:32.309, tt:5007.959\n",
      "Ep:155, loss:0.00002, loss_test:0.05163, lr:6.83e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.310, tt:5040.380\n",
      "Ep:156, loss:0.00002, loss_test:0.05204, lr:6.76e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.312, tt:5073.042\n",
      "Ep:157, loss:0.00001, loss_test:0.05190, lr:6.69e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.302, tt:5103.641\n",
      "Ep:158, loss:0.00001, loss_test:0.05219, lr:6.62e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.288, tt:5133.796\n",
      "Ep:159, loss:0.00001, loss_test:0.05073, lr:6.56e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.282, tt:5165.124\n",
      "Ep:160, loss:0.00001, loss_test:0.05351, lr:6.49e-03, fs:0.89840 (r=0.848,p=0.955),  time:32.285, tt:5197.920\n",
      "Ep:161, loss:0.00001, loss_test:0.05200, lr:6.43e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.280, tt:5229.283\n",
      "Ep:162, loss:0.00001, loss_test:0.05105, lr:6.36e-03, fs:0.92147 (r=0.889,p=0.957),  time:32.279, tt:5261.546\n",
      "Ep:163, loss:0.00001, loss_test:0.05295, lr:6.30e-03, fs:0.92063 (r=0.879,p=0.967),  time:32.279, tt:5293.710\n",
      "Ep:164, loss:0.00001, loss_test:0.05120, lr:6.24e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.271, tt:5324.713\n",
      "Ep:165, loss:0.00001, loss_test:0.05226, lr:6.17e-03, fs:0.91579 (r=0.879,p=0.956),  time:32.258, tt:5354.779\n",
      "Ep:166, loss:0.00001, loss_test:0.05218, lr:6.11e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.250, tt:5385.752\n",
      "Ep:167, loss:0.00001, loss_test:0.05130, lr:6.05e-03, fs:0.92147 (r=0.889,p=0.957),  time:32.237, tt:5415.752\n",
      "Ep:168, loss:0.00001, loss_test:0.05194, lr:5.99e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.221, tt:5445.415\n",
      "Ep:169, loss:0.00001, loss_test:0.05129, lr:5.93e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.208, tt:5475.295\n",
      "Ep:170, loss:0.00001, loss_test:0.05244, lr:5.87e-03, fs:0.92147 (r=0.889,p=0.957),  time:32.197, tt:5505.698\n",
      "Ep:171, loss:0.00001, loss_test:0.05160, lr:5.81e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.195, tt:5537.466\n",
      "Ep:172, loss:0.00001, loss_test:0.05096, lr:5.75e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.191, tt:5569.102\n",
      "Ep:173, loss:0.00001, loss_test:0.05216, lr:5.70e-03, fs:0.92708 (r=0.899,p=0.957),  time:32.185, tt:5600.230\n",
      "Ep:174, loss:0.00001, loss_test:0.05185, lr:5.64e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.179, tt:5631.358\n",
      "Ep:175, loss:0.00001, loss_test:0.05212, lr:5.58e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.178, tt:5663.406\n",
      "Ep:176, loss:0.00001, loss_test:0.05184, lr:5.53e-03, fs:0.92228 (r=0.899,p=0.947),  time:32.170, tt:5694.174\n",
      "Ep:177, loss:0.00001, loss_test:0.05109, lr:5.47e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.168, tt:5725.926\n",
      "Ep:178, loss:0.00001, loss_test:0.05219, lr:5.42e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.168, tt:5758.045\n",
      "Ep:179, loss:0.00001, loss_test:0.05130, lr:5.36e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.164, tt:5789.464\n",
      "Ep:180, loss:0.00001, loss_test:0.05127, lr:5.31e-03, fs:0.91398 (r=0.859,p=0.977),  time:32.179, tt:5824.354\n",
      "Ep:181, loss:0.00001, loss_test:0.05229, lr:5.26e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.176, tt:5856.025\n",
      "Ep:182, loss:0.00001, loss_test:0.05071, lr:5.20e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.176, tt:5888.287\n",
      "Ep:183, loss:0.00001, loss_test:0.05158, lr:5.15e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.179, tt:5920.902\n",
      "Ep:184, loss:0.00001, loss_test:0.05135, lr:5.10e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.184, tt:5954.073\n",
      "Ep:185, loss:0.00001, loss_test:0.05101, lr:5.05e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.180, tt:5985.393\n",
      "Ep:186, loss:0.00001, loss_test:0.05169, lr:5.00e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.176, tt:6016.900\n",
      "Ep:187, loss:0.00001, loss_test:0.05088, lr:4.95e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.179, tt:6049.679\n",
      "Ep:188, loss:0.00001, loss_test:0.05185, lr:4.90e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.181, tt:6082.174\n",
      "Ep:189, loss:0.00001, loss_test:0.05126, lr:4.85e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.184, tt:6115.028\n",
      "Ep:190, loss:0.00001, loss_test:0.05117, lr:4.80e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.190, tt:6148.362\n",
      "Ep:191, loss:0.00001, loss_test:0.05170, lr:4.75e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.191, tt:6180.709\n",
      "Ep:192, loss:0.00001, loss_test:0.05058, lr:4.71e-03, fs:0.91489 (r=0.869,p=0.966),  time:32.198, tt:6214.128\n",
      "Ep:193, loss:0.00001, loss_test:0.05174, lr:4.66e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.198, tt:6246.375\n",
      "Ep:194, loss:0.00001, loss_test:0.05196, lr:4.61e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.198, tt:6278.622\n",
      "Ep:195, loss:0.00001, loss_test:0.05065, lr:4.57e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.192, tt:6309.641\n",
      "Ep:196, loss:0.00001, loss_test:0.05151, lr:4.52e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.191, tt:6341.560\n",
      "Ep:197, loss:0.00001, loss_test:0.05142, lr:4.48e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.190, tt:6373.627\n",
      "Ep:198, loss:0.00001, loss_test:0.05089, lr:4.43e-03, fs:0.90426 (r=0.859,p=0.955),  time:32.195, tt:6406.747\n",
      "Ep:199, loss:0.00001, loss_test:0.05133, lr:4.39e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.200, tt:6439.938\n",
      "Ep:200, loss:0.00001, loss_test:0.05148, lr:4.34e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.181, tt:6468.393\n",
      "Ep:201, loss:0.00001, loss_test:0.05090, lr:4.30e-03, fs:0.90909 (r=0.859,p=0.966),  time:32.189, tt:6502.192\n",
      "Ep:202, loss:0.00001, loss_test:0.05104, lr:4.26e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.183, tt:6533.197\n",
      "Ep:203, loss:0.00001, loss_test:0.05103, lr:4.21e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.180, tt:6564.704\n",
      "Ep:204, loss:0.00001, loss_test:0.05176, lr:4.17e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.152, tt:6591.187\n",
      "Ep:205, loss:0.00001, loss_test:0.05092, lr:4.13e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.132, tt:6619.263\n",
      "Ep:206, loss:0.00001, loss_test:0.05144, lr:4.09e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.080, tt:6640.478\n",
      "Ep:207, loss:0.00001, loss_test:0.05132, lr:4.05e-03, fs:0.91005 (r=0.869,p=0.956),  time:32.026, tt:6661.513\n",
      "Ep:208, loss:0.00001, loss_test:0.05066, lr:4.01e-03, fs:0.90909 (r=0.859,p=0.966),  time:31.990, tt:6685.839\n",
      "Ep:209, loss:0.00001, loss_test:0.05152, lr:3.97e-03, fs:0.91005 (r=0.869,p=0.956),  time:31.989, tt:6717.726\n",
      "Ep:210, loss:0.00001, loss_test:0.05132, lr:3.93e-03, fs:0.91005 (r=0.869,p=0.956),  time:31.979, tt:6747.669\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.01961, lr:6.00e-02, fs:0.65625 (r=0.848,p=0.535),  time:29.516, tt:29.516\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.105, tt:60.210\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02277, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.029, tt:90.087\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02237, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.370, tt:121.481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00004, loss_test:0.02111, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.333, tt:151.665\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01978, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:30.534, tt:183.202\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:30.575, tt:214.023\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:30.443, tt:243.545\n",
      "Ep:8, loss:0.00004, loss_test:0.01849, lr:6.00e-02, fs:0.63934 (r=0.788,p=0.538),  time:30.280, tt:272.520\n",
      "Ep:9, loss:0.00004, loss_test:0.01819, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:30.328, tt:303.279\n",
      "Ep:10, loss:0.00004, loss_test:0.01787, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:30.340, tt:333.742\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.70896 (r=0.960,p=0.562),  time:30.347, tt:364.159\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01748, lr:6.00e-02, fs:0.71375 (r=0.970,p=0.565),  time:30.397, tt:395.162\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01717, lr:6.00e-02, fs:0.71375 (r=0.970,p=0.565),  time:30.413, tt:425.786\n",
      "Ep:14, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:30.383, tt:455.749\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.72374 (r=0.939,p=0.589),  time:30.247, tt:483.958\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01633, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:30.211, tt:513.590\n",
      "Ep:17, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:30.230, tt:544.139\n",
      "Ep:18, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.73984 (r=0.919,p=0.619),  time:30.208, tt:573.943\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.73387 (r=0.919,p=0.611),  time:30.177, tt:603.545\n",
      "Ep:20, loss:0.00003, loss_test:0.01546, lr:6.00e-02, fs:0.74494 (r=0.929,p=0.622),  time:30.170, tt:633.568\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01525, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:30.313, tt:666.877\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01510, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:30.330, tt:697.597\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01493, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:30.390, tt:729.359\n",
      "Ep:24, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:30.334, tt:758.337\n",
      "Ep:25, loss:0.00003, loss_test:0.01465, lr:6.00e-02, fs:0.74262 (r=0.889,p=0.638),  time:30.394, tt:790.236\n",
      "Ep:26, loss:0.00003, loss_test:0.01450, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:30.422, tt:821.402\n",
      "Ep:27, loss:0.00002, loss_test:0.01437, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:30.412, tt:851.525\n",
      "Ep:28, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:30.406, tt:881.760\n",
      "Ep:29, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:30.405, tt:912.157\n",
      "Ep:30, loss:0.00002, loss_test:0.01407, lr:6.00e-02, fs:0.75983 (r=0.879,p=0.669),  time:30.374, tt:941.584\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01399, lr:6.00e-02, fs:0.76316 (r=0.879,p=0.674),  time:30.369, tt:971.818\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:30.343, tt:1001.305\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.76991 (r=0.879,p=0.685),  time:30.319, tt:1030.861\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01372, lr:6.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:30.304, tt:1060.636\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01362, lr:6.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:30.319, tt:1091.493\n",
      "Ep:36, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:30.346, tt:1122.789\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:30.355, tt:1153.501\n",
      "Ep:38, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.318, tt:1182.420\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.78571 (r=0.889,p=0.704),  time:30.320, tt:1212.785\n",
      "Ep:40, loss:0.00002, loss_test:0.01324, lr:6.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:30.332, tt:1243.624\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01318, lr:6.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:30.362, tt:1275.209\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:30.357, tt:1305.362\n",
      "Ep:43, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:30.389, tt:1337.123\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.425, tt:1369.123\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.397, tt:1398.263\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01290, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.413, tt:1429.427\n",
      "Ep:47, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:30.411, tt:1459.719\n",
      "Ep:48, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.409, tt:1490.031\n",
      "Ep:49, loss:0.00002, loss_test:0.01277, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.398, tt:1519.922\n",
      "Ep:50, loss:0.00002, loss_test:0.01273, lr:6.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:30.386, tt:1549.675\n",
      "Ep:51, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:30.358, tt:1578.639\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:30.380, tt:1610.166\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01262, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.375, tt:1640.262\n",
      "Ep:54, loss:0.00002, loss_test:0.01258, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.389, tt:1671.406\n",
      "Ep:55, loss:0.00002, loss_test:0.01254, lr:6.00e-02, fs:0.79630 (r=0.869,p=0.735),  time:30.406, tt:1702.762\n",
      "Ep:56, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.387, tt:1732.077\n",
      "Ep:57, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.365, tt:1761.196\n",
      "Ep:58, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:30.388, tt:1792.871\n",
      "Ep:59, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:30.402, tt:1824.142\n",
      "Ep:60, loss:0.00001, loss_test:0.01242, lr:6.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:30.392, tt:1853.899\n",
      "Ep:61, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.369, tt:1882.889\n",
      "Ep:62, loss:0.00001, loss_test:0.01239, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.365, tt:1912.984\n",
      "Ep:63, loss:0.00001, loss_test:0.01236, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.367, tt:1943.475\n",
      "Ep:64, loss:0.00001, loss_test:0.01234, lr:5.94e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.373, tt:1974.248\n",
      "Ep:65, loss:0.00001, loss_test:0.01234, lr:5.88e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.361, tt:2003.798\n",
      "Ep:66, loss:0.00001, loss_test:0.01233, lr:5.82e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.356, tt:2033.849\n",
      "Ep:67, loss:0.00001, loss_test:0.01229, lr:5.76e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.371, tt:2065.237\n",
      "Ep:68, loss:0.00001, loss_test:0.01228, lr:5.71e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.368, tt:2095.364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.01228, lr:5.65e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.389, tt:2127.261\n",
      "Ep:70, loss:0.00001, loss_test:0.01229, lr:5.59e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.370, tt:2156.293\n",
      "Ep:71, loss:0.00001, loss_test:0.01227, lr:5.54e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.370, tt:2186.652\n",
      "Ep:72, loss:0.00001, loss_test:0.01224, lr:5.48e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.370, tt:2217.026\n",
      "Ep:73, loss:0.00001, loss_test:0.01225, lr:5.43e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.361, tt:2246.706\n",
      "Ep:74, loss:0.00001, loss_test:0.01224, lr:5.37e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.379, tt:2278.390\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01224, lr:5.37e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.394, tt:2309.942\n",
      "Ep:76, loss:0.00001, loss_test:0.01219, lr:5.37e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.377, tt:2339.039\n",
      "Ep:77, loss:0.00001, loss_test:0.01223, lr:5.37e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.379, tt:2369.591\n",
      "Ep:78, loss:0.00001, loss_test:0.01223, lr:5.37e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.360, tt:2398.425\n",
      "Ep:79, loss:0.00001, loss_test:0.01221, lr:5.37e-02, fs:0.81132 (r=0.869,p=0.761),  time:30.372, tt:2429.720\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01219, lr:5.37e-02, fs:0.80569 (r=0.859,p=0.759),  time:30.361, tt:2459.217\n",
      "Ep:81, loss:0.00001, loss_test:0.01221, lr:5.37e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.367, tt:2490.129\n",
      "Ep:82, loss:0.00001, loss_test:0.01222, lr:5.37e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.371, tt:2520.805\n",
      "Ep:83, loss:0.00001, loss_test:0.01221, lr:5.37e-02, fs:0.80952 (r=0.859,p=0.766),  time:30.355, tt:2549.837\n",
      "Ep:84, loss:0.00001, loss_test:0.01224, lr:5.37e-02, fs:0.80383 (r=0.848,p=0.764),  time:30.354, tt:2580.088\n",
      "Ep:85, loss:0.00001, loss_test:0.01222, lr:5.37e-02, fs:0.80769 (r=0.848,p=0.771),  time:30.365, tt:2611.380\n",
      "Ep:86, loss:0.00001, loss_test:0.01220, lr:5.37e-02, fs:0.81731 (r=0.859,p=0.780),  time:30.390, tt:2643.935\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01221, lr:5.37e-02, fs:0.81159 (r=0.848,p=0.778),  time:30.390, tt:2674.308\n",
      "Ep:88, loss:0.00001, loss_test:0.01228, lr:5.37e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.369, tt:2702.847\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01228, lr:5.37e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.358, tt:2732.236\n",
      "Ep:90, loss:0.00001, loss_test:0.01227, lr:5.37e-02, fs:0.81951 (r=0.848,p=0.792),  time:30.344, tt:2761.280\n",
      "Ep:91, loss:0.00001, loss_test:0.01223, lr:5.37e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.335, tt:2790.866\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01227, lr:5.37e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.341, tt:2821.723\n",
      "Ep:93, loss:0.00001, loss_test:0.01227, lr:5.37e-02, fs:0.82126 (r=0.859,p=0.787),  time:30.338, tt:2851.738\n",
      "Ep:94, loss:0.00001, loss_test:0.01232, lr:5.37e-02, fs:0.82759 (r=0.848,p=0.808),  time:30.335, tt:2881.870\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01229, lr:5.37e-02, fs:0.83744 (r=0.859,p=0.817),  time:30.333, tt:2911.947\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01230, lr:5.37e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.328, tt:2941.809\n",
      "Ep:97, loss:0.00001, loss_test:0.01232, lr:5.37e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.344, tt:2973.680\n",
      "Ep:98, loss:0.00001, loss_test:0.01239, lr:5.37e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.333, tt:3002.946\n",
      "Ep:99, loss:0.00001, loss_test:0.01237, lr:5.37e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.345, tt:3034.461\n",
      "Ep:100, loss:0.00001, loss_test:0.01234, lr:5.37e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.343, tt:3064.652\n",
      "Ep:101, loss:0.00001, loss_test:0.01239, lr:5.37e-02, fs:0.82587 (r=0.838,p=0.814),  time:30.355, tt:3096.175\n",
      "Ep:102, loss:0.00001, loss_test:0.01240, lr:5.37e-02, fs:0.83000 (r=0.838,p=0.822),  time:30.325, tt:3123.513\n",
      "Ep:103, loss:0.00001, loss_test:0.01238, lr:5.37e-02, fs:0.83000 (r=0.838,p=0.822),  time:30.297, tt:3150.857\n",
      "Ep:104, loss:0.00001, loss_test:0.01235, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.297, tt:3181.165\n",
      "Ep:105, loss:0.00001, loss_test:0.01237, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.291, tt:3210.816\n",
      "Ep:106, loss:0.00001, loss_test:0.01241, lr:5.37e-02, fs:0.83417 (r=0.838,p=0.830),  time:30.286, tt:3240.631\n",
      "Ep:107, loss:0.00001, loss_test:0.01245, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.280, tt:3270.240\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00001, loss_test:0.01243, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.270, tt:3299.436\n",
      "Ep:109, loss:0.00001, loss_test:0.01247, lr:5.32e-02, fs:0.83838 (r=0.838,p=0.838),  time:30.260, tt:3328.568\n",
      "Ep:110, loss:0.00001, loss_test:0.01248, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.260, tt:3358.827\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01248, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.253, tt:3388.304\n",
      "Ep:112, loss:0.00001, loss_test:0.01249, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.249, tt:3418.146\n",
      "Ep:113, loss:0.00001, loss_test:0.01250, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.265, tt:3450.218\n",
      "Ep:114, loss:0.00001, loss_test:0.01250, lr:5.32e-02, fs:0.84422 (r=0.848,p=0.840),  time:30.263, tt:3480.261\n",
      "Ep:115, loss:0.00001, loss_test:0.01255, lr:5.32e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.264, tt:3510.668\n",
      "Ep:116, loss:0.00001, loss_test:0.01256, lr:5.32e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.266, tt:3541.147\n",
      "Ep:117, loss:0.00001, loss_test:0.01256, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:30.256, tt:3570.193\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.01259, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.268, tt:3601.884\n",
      "Ep:119, loss:0.00001, loss_test:0.01259, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.302, tt:3636.181\n",
      "Ep:120, loss:0.00001, loss_test:0.01258, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.300, tt:3666.297\n",
      "Ep:121, loss:0.00001, loss_test:0.01259, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.312, tt:3698.076\n",
      "Ep:122, loss:0.00001, loss_test:0.01262, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.313, tt:3728.503\n",
      "Ep:123, loss:0.00001, loss_test:0.01271, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.315, tt:3759.049\n",
      "Ep:124, loss:0.00001, loss_test:0.01268, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.317, tt:3789.676\n",
      "Ep:125, loss:0.00001, loss_test:0.01270, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.321, tt:3820.496\n",
      "Ep:126, loss:0.00001, loss_test:0.01272, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.325, tt:3851.331\n",
      "Ep:127, loss:0.00001, loss_test:0.01276, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.328, tt:3882.013\n",
      "Ep:128, loss:0.00001, loss_test:0.01273, lr:5.32e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.330, tt:3912.605\n",
      "Ep:129, loss:0.00001, loss_test:0.01274, lr:5.27e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.322, tt:3941.906\n",
      "Ep:130, loss:0.00001, loss_test:0.01280, lr:5.21e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.325, tt:3972.527\n",
      "Ep:131, loss:0.00001, loss_test:0.01279, lr:5.16e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.319, tt:4002.042\n",
      "Ep:132, loss:0.00001, loss_test:0.01282, lr:5.11e-02, fs:0.83673 (r=0.828,p=0.845),  time:30.305, tt:4030.569\n",
      "Ep:133, loss:0.00001, loss_test:0.01285, lr:5.06e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.301, tt:4060.380\n",
      "Ep:134, loss:0.00001, loss_test:0.01288, lr:5.01e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.304, tt:4091.051\n",
      "Ep:135, loss:0.00001, loss_test:0.01289, lr:4.96e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.295, tt:4120.090\n",
      "Ep:136, loss:0.00001, loss_test:0.01288, lr:4.91e-02, fs:0.84103 (r=0.828,p=0.854),  time:30.291, tt:4149.892\n",
      "Ep:137, loss:0.00001, loss_test:0.01288, lr:4.86e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.300, tt:4181.419\n",
      "Ep:138, loss:0.00001, loss_test:0.01292, lr:4.81e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.303, tt:4212.165\n",
      "Ep:139, loss:0.00001, loss_test:0.01298, lr:4.76e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.302, tt:4242.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:140, loss:0.00001, loss_test:0.01297, lr:4.71e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.302, tt:4272.531\n",
      "Ep:141, loss:0.00001, loss_test:0.01300, lr:4.67e-02, fs:0.84536 (r=0.828,p=0.863),  time:30.302, tt:4302.870\n",
      "Ep:142, loss:0.00001, loss_test:0.01306, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.293, tt:4331.931\n",
      "##########Best model found so far##########\n",
      "Ep:143, loss:0.00001, loss_test:0.01306, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.296, tt:4362.578\n",
      "Ep:144, loss:0.00001, loss_test:0.01308, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.297, tt:4392.996\n",
      "Ep:145, loss:0.00001, loss_test:0.01311, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.299, tt:4423.614\n",
      "Ep:146, loss:0.00001, loss_test:0.01310, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.316, tt:4456.411\n",
      "Ep:147, loss:0.00001, loss_test:0.01308, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.316, tt:4486.766\n",
      "Ep:148, loss:0.00001, loss_test:0.01316, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.327, tt:4518.726\n",
      "Ep:149, loss:0.00001, loss_test:0.01319, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.329, tt:4549.405\n",
      "Ep:150, loss:0.00000, loss_test:0.01318, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.331, tt:4579.979\n",
      "Ep:151, loss:0.00000, loss_test:0.01322, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.330, tt:4610.142\n",
      "Ep:152, loss:0.00000, loss_test:0.01324, lr:4.62e-02, fs:0.84974 (r=0.828,p=0.872),  time:30.335, tt:4641.185\n",
      "Ep:153, loss:0.00000, loss_test:0.01326, lr:4.62e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.336, tt:4671.729\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00000, loss_test:0.01326, lr:4.62e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.334, tt:4701.844\n",
      "Ep:155, loss:0.00000, loss_test:0.01330, lr:4.62e-02, fs:0.85417 (r=0.828,p=0.882),  time:30.338, tt:4732.739\n",
      "Ep:156, loss:0.00000, loss_test:0.01329, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.337, tt:4762.863\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00000, loss_test:0.01334, lr:4.62e-02, fs:0.85864 (r=0.828,p=0.891),  time:30.338, tt:4793.372\n",
      "Ep:158, loss:0.00000, loss_test:0.01337, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.347, tt:4825.150\n",
      "Ep:159, loss:0.00000, loss_test:0.01339, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.355, tt:4856.730\n",
      "Ep:160, loss:0.00000, loss_test:0.01339, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.360, tt:4887.978\n",
      "Ep:161, loss:0.00000, loss_test:0.01345, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:30.367, tt:4919.393\n",
      "Ep:162, loss:0.00000, loss_test:0.01349, lr:4.62e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.386, tt:4952.927\n",
      "Ep:163, loss:0.00000, loss_test:0.01346, lr:4.62e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.380, tt:4982.326\n",
      "Ep:164, loss:0.00000, loss_test:0.01346, lr:4.62e-02, fs:0.84656 (r=0.808,p=0.889),  time:30.380, tt:5012.637\n",
      "Ep:165, loss:0.00000, loss_test:0.01351, lr:4.62e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.372, tt:5041.732\n",
      "Ep:166, loss:0.00000, loss_test:0.01355, lr:4.62e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.372, tt:5072.191\n",
      "Ep:167, loss:0.00000, loss_test:0.01356, lr:4.62e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.377, tt:5103.294\n",
      "Ep:168, loss:0.00000, loss_test:0.01359, lr:4.57e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.378, tt:5133.889\n",
      "Ep:169, loss:0.00000, loss_test:0.01360, lr:4.53e-02, fs:0.84043 (r=0.798,p=0.888),  time:30.376, tt:5163.875\n",
      "Ep:170, loss:0.00000, loss_test:0.01363, lr:4.48e-02, fs:0.83422 (r=0.788,p=0.886),  time:30.377, tt:5194.531\n",
      "Ep:171, loss:0.00000, loss_test:0.01364, lr:4.44e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.376, tt:5224.754\n",
      "Ep:172, loss:0.00000, loss_test:0.01365, lr:4.39e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.376, tt:5255.001\n",
      "Ep:173, loss:0.00000, loss_test:0.01368, lr:4.35e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.372, tt:5284.736\n",
      "Ep:174, loss:0.00000, loss_test:0.01370, lr:4.31e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.365, tt:5313.822\n",
      "Ep:175, loss:0.00000, loss_test:0.01371, lr:4.26e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.364, tt:5344.122\n",
      "Ep:176, loss:0.00000, loss_test:0.01372, lr:4.22e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.360, tt:5373.801\n",
      "Ep:177, loss:0.00000, loss_test:0.01373, lr:4.18e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.354, tt:5403.029\n",
      "Ep:178, loss:0.00000, loss_test:0.01379, lr:4.14e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.357, tt:5433.904\n",
      "Ep:179, loss:0.00000, loss_test:0.01380, lr:4.10e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.353, tt:5463.451\n",
      "Ep:180, loss:0.00000, loss_test:0.01379, lr:4.05e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.349, tt:5493.150\n",
      "Ep:181, loss:0.00000, loss_test:0.01381, lr:4.01e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.343, tt:5522.335\n",
      "Ep:182, loss:0.00000, loss_test:0.01388, lr:3.97e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.343, tt:5552.850\n",
      "Ep:183, loss:0.00000, loss_test:0.01387, lr:3.93e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.335, tt:5581.634\n",
      "Ep:184, loss:0.00000, loss_test:0.01387, lr:3.89e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.350, tt:5614.670\n",
      "Ep:185, loss:0.00000, loss_test:0.01388, lr:3.86e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.353, tt:5645.649\n",
      "Ep:186, loss:0.00000, loss_test:0.01393, lr:3.82e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.355, tt:5676.359\n",
      "Ep:187, loss:0.00000, loss_test:0.01395, lr:3.78e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.356, tt:5706.959\n",
      "Ep:188, loss:0.00000, loss_test:0.01393, lr:3.74e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.355, tt:5737.182\n",
      "Ep:189, loss:0.00000, loss_test:0.01398, lr:3.70e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.349, tt:5766.369\n",
      "Ep:190, loss:0.00000, loss_test:0.01400, lr:3.67e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.346, tt:5796.098\n",
      "Ep:191, loss:0.00000, loss_test:0.01398, lr:3.63e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.348, tt:5826.767\n",
      "Ep:192, loss:0.00000, loss_test:0.01400, lr:3.59e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.341, tt:5855.858\n",
      "Ep:193, loss:0.00000, loss_test:0.01405, lr:3.56e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.343, tt:5886.538\n",
      "Ep:194, loss:0.00000, loss_test:0.01407, lr:3.52e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.340, tt:5916.309\n",
      "Ep:195, loss:0.00000, loss_test:0.01410, lr:3.49e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.348, tt:5948.257\n",
      "Ep:196, loss:0.00000, loss_test:0.01411, lr:3.45e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.349, tt:5978.812\n",
      "Ep:197, loss:0.00000, loss_test:0.01411, lr:3.42e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.356, tt:6010.439\n",
      "Ep:198, loss:0.00000, loss_test:0.01411, lr:3.38e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.354, tt:6040.515\n",
      "Ep:199, loss:0.00000, loss_test:0.01415, lr:3.35e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.360, tt:6071.915\n",
      "Ep:200, loss:0.00000, loss_test:0.01413, lr:3.32e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.378, tt:6106.030\n",
      "Ep:201, loss:0.00000, loss_test:0.01416, lr:3.28e-02, fs:0.83243 (r=0.778,p=0.895),  time:30.360, tt:6132.773\n",
      "Ep:202, loss:0.00000, loss_test:0.01418, lr:3.25e-02, fs:0.83871 (r=0.788,p=0.897),  time:30.358, tt:6162.672\n",
      "Ep:203, loss:0.00000, loss_test:0.01420, lr:3.22e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.349, tt:6191.167\n",
      "Ep:204, loss:0.00000, loss_test:0.01422, lr:3.19e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.338, tt:6219.310\n",
      "Ep:205, loss:0.00000, loss_test:0.01423, lr:3.15e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.333, tt:6248.613\n",
      "Ep:206, loss:0.00000, loss_test:0.01423, lr:3.12e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.313, tt:6274.792\n",
      "Ep:207, loss:0.00000, loss_test:0.01425, lr:3.09e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.312, tt:6304.998\n",
      "Ep:208, loss:0.00000, loss_test:0.01426, lr:3.06e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.308, tt:6334.339\n",
      "Ep:209, loss:0.00000, loss_test:0.01428, lr:3.03e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.301, tt:6363.242\n",
      "Ep:210, loss:0.00000, loss_test:0.01430, lr:3.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.301, tt:6393.426\n",
      "Ep:211, loss:0.00000, loss_test:0.01432, lr:2.97e-02, fs:0.82609 (r=0.768,p=0.894),  time:30.298, tt:6423.100\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:2, loss:0.00028, loss_test:0.14160, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.670, tt:98.010\n",
      "Ep:3, loss:0.00028, loss_test:0.13961, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.310, tt:129.242\n",
      "Ep:4, loss:0.00027, loss_test:0.13664, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:32.433, tt:162.165\n",
      "Ep:5, loss:0.00026, loss_test:0.13248, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:32.563, tt:195.376\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00026, loss_test:0.12659, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:32.648, tt:228.533\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11915, lr:1.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:32.548, tt:260.384\n",
      "Ep:8, loss:0.00023, loss_test:0.11333, lr:1.00e-02, fs:0.66376 (r=0.768,p=0.585),  time:32.470, tt:292.231\n",
      "Ep:9, loss:0.00023, loss_test:0.11034, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:32.603, tt:326.035\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10886, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:32.592, tt:358.509\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00022, loss_test:0.10879, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:32.424, tt:389.091\n",
      "Ep:12, loss:0.00021, loss_test:0.10650, lr:1.00e-02, fs:0.69828 (r=0.818,p=0.609),  time:32.342, tt:420.447\n",
      "Ep:13, loss:0.00021, loss_test:0.10317, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:32.304, tt:452.263\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00020, loss_test:0.10015, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:32.250, tt:483.748\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09820, lr:1.00e-02, fs:0.72321 (r=0.818,p=0.648),  time:32.166, tt:514.657\n",
      "Ep:16, loss:0.00019, loss_test:0.09592, lr:1.00e-02, fs:0.73394 (r=0.808,p=0.672),  time:32.152, tt:546.588\n",
      "Ep:17, loss:0.00018, loss_test:0.09339, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:32.172, tt:579.094\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00018, loss_test:0.09163, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:32.132, tt:610.512\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00017, loss_test:0.09039, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:32.046, tt:640.918\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00017, loss_test:0.08732, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:32.095, tt:673.996\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08606, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:32.092, tt:706.016\n",
      "Ep:22, loss:0.00016, loss_test:0.08581, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:32.152, tt:739.487\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.08322, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:32.116, tt:770.789\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00015, loss_test:0.08159, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:32.113, tt:802.833\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00015, loss_test:0.08032, lr:1.00e-02, fs:0.80909 (r=0.899,p=0.736),  time:32.154, tt:836.013\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00014, loss_test:0.07915, lr:1.00e-02, fs:0.79812 (r=0.859,p=0.746),  time:32.114, tt:867.082\n",
      "Ep:27, loss:0.00014, loss_test:0.07887, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:32.106, tt:898.958\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00014, loss_test:0.07748, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:32.061, tt:929.762\n",
      "Ep:29, loss:0.00013, loss_test:0.07688, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:32.043, tt:961.286\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07561, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:32.091, tt:994.831\n",
      "Ep:31, loss:0.00013, loss_test:0.07529, lr:1.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:32.140, tt:1028.495\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00012, loss_test:0.07454, lr:1.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:32.164, tt:1061.412\n",
      "Ep:33, loss:0.00012, loss_test:0.07448, lr:1.00e-02, fs:0.84071 (r=0.960,p=0.748),  time:32.163, tt:1093.549\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00012, loss_test:0.07322, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:32.166, tt:1125.794\n",
      "Ep:35, loss:0.00012, loss_test:0.07317, lr:1.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:32.202, tt:1159.280\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.07176, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:32.209, tt:1191.741\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.07139, lr:1.00e-02, fs:0.84651 (r=0.919,p=0.784),  time:32.146, tt:1221.565\n",
      "Ep:38, loss:0.00011, loss_test:0.07113, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:32.100, tt:1251.888\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.07020, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:32.112, tt:1284.481\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.06942, lr:1.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:32.097, tt:1315.962\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00010, loss_test:0.06977, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:32.112, tt:1348.702\n",
      "Ep:42, loss:0.00010, loss_test:0.06884, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:32.094, tt:1380.051\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.06829, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:32.084, tt:1411.688\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.06813, lr:1.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:32.061, tt:1442.741\n",
      "Ep:45, loss:0.00009, loss_test:0.06785, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:32.064, tt:1474.940\n",
      "Ep:46, loss:0.00009, loss_test:0.06652, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:32.061, tt:1506.872\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00009, loss_test:0.06629, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:32.061, tt:1538.919\n",
      "Ep:48, loss:0.00009, loss_test:0.06725, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:32.041, tt:1570.032\n",
      "Ep:49, loss:0.00008, loss_test:0.06526, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:32.012, tt:1600.588\n",
      "Ep:50, loss:0.00008, loss_test:0.06634, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:31.991, tt:1631.540\n",
      "Ep:51, loss:0.00008, loss_test:0.06585, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:31.974, tt:1662.670\n",
      "Ep:52, loss:0.00008, loss_test:0.06477, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:31.992, tt:1695.560\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00008, loss_test:0.06547, lr:1.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:32.019, tt:1729.022\n",
      "Ep:54, loss:0.00008, loss_test:0.06407, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:32.024, tt:1761.312\n",
      "Ep:55, loss:0.00007, loss_test:0.06419, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:32.016, tt:1792.911\n",
      "Ep:56, loss:0.00007, loss_test:0.06392, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:32.031, tt:1825.750\n",
      "Ep:57, loss:0.00007, loss_test:0.06259, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:32.029, tt:1857.709\n",
      "Ep:58, loss:0.00007, loss_test:0.06392, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:32.043, tt:1890.555\n",
      "Ep:59, loss:0.00007, loss_test:0.06179, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:32.035, tt:1922.113\n",
      "Ep:60, loss:0.00007, loss_test:0.06368, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:32.039, tt:1954.361\n",
      "Ep:61, loss:0.00007, loss_test:0.06066, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:32.019, tt:1985.161\n",
      "Ep:62, loss:0.00007, loss_test:0.06359, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:32.017, tt:2017.100\n",
      "Ep:63, loss:0.00006, loss_test:0.06057, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:31.988, tt:2047.262\n",
      "Ep:64, loss:0.00007, loss_test:0.06424, lr:9.90e-03, fs:0.82353 (r=0.778,p=0.875),  time:31.994, tt:2079.622\n",
      "Ep:65, loss:0.00007, loss_test:0.06405, lr:9.80e-03, fs:0.83495 (r=0.869,p=0.804),  time:31.998, tt:2111.869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00007, loss_test:0.05981, lr:9.70e-03, fs:0.84974 (r=0.828,p=0.872),  time:31.996, tt:2143.733\n",
      "Ep:67, loss:0.00006, loss_test:0.06600, lr:9.61e-03, fs:0.81818 (r=0.818,p=0.818),  time:31.986, tt:2175.037\n",
      "Ep:68, loss:0.00006, loss_test:0.06097, lr:9.51e-03, fs:0.85437 (r=0.889,p=0.822),  time:31.959, tt:2205.172\n",
      "Ep:69, loss:0.00006, loss_test:0.06448, lr:9.41e-03, fs:0.81720 (r=0.768,p=0.874),  time:31.963, tt:2237.436\n",
      "Ep:70, loss:0.00006, loss_test:0.06393, lr:9.32e-03, fs:0.82243 (r=0.889,p=0.765),  time:31.969, tt:2269.823\n",
      "Ep:71, loss:0.00006, loss_test:0.05969, lr:9.23e-03, fs:0.84656 (r=0.808,p=0.889),  time:31.961, tt:2301.185\n",
      "Ep:72, loss:0.00006, loss_test:0.06424, lr:9.14e-03, fs:0.84507 (r=0.909,p=0.789),  time:31.937, tt:2331.405\n",
      "Ep:73, loss:0.00006, loss_test:0.05808, lr:9.04e-03, fs:0.87629 (r=0.859,p=0.895),  time:31.918, tt:2361.951\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00005, loss_test:0.06139, lr:9.04e-03, fs:0.83673 (r=0.828,p=0.845),  time:31.910, tt:2393.287\n",
      "Ep:75, loss:0.00005, loss_test:0.05827, lr:9.04e-03, fs:0.84817 (r=0.818,p=0.880),  time:31.889, tt:2423.601\n",
      "Ep:76, loss:0.00005, loss_test:0.05808, lr:9.04e-03, fs:0.84974 (r=0.828,p=0.872),  time:31.894, tt:2455.848\n",
      "Ep:77, loss:0.00005, loss_test:0.06007, lr:9.04e-03, fs:0.85279 (r=0.848,p=0.857),  time:31.900, tt:2488.183\n",
      "Ep:78, loss:0.00005, loss_test:0.05774, lr:9.04e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.890, tt:2519.279\n",
      "Ep:79, loss:0.00005, loss_test:0.06018, lr:9.04e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.900, tt:2552.031\n",
      "Ep:80, loss:0.00005, loss_test:0.05666, lr:9.04e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.916, tt:2585.218\n",
      "Ep:81, loss:0.00005, loss_test:0.06063, lr:9.04e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.909, tt:2616.553\n",
      "Ep:82, loss:0.00005, loss_test:0.05639, lr:9.04e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.937, tt:2650.811\n",
      "Ep:83, loss:0.00004, loss_test:0.05944, lr:9.04e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.937, tt:2682.675\n",
      "Ep:84, loss:0.00004, loss_test:0.05756, lr:9.04e-03, fs:0.84536 (r=0.828,p=0.863),  time:31.922, tt:2713.409\n",
      "Ep:85, loss:0.00004, loss_test:0.05704, lr:8.95e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.927, tt:2745.681\n",
      "Ep:86, loss:0.00004, loss_test:0.05906, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.928, tt:2777.737\n",
      "Ep:87, loss:0.00004, loss_test:0.05552, lr:8.78e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.925, tt:2809.395\n",
      "Ep:88, loss:0.00004, loss_test:0.05919, lr:8.69e-03, fs:0.83938 (r=0.818,p=0.862),  time:31.901, tt:2839.187\n",
      "Ep:89, loss:0.00004, loss_test:0.05585, lr:8.60e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.907, tt:2871.629\n",
      "Ep:90, loss:0.00004, loss_test:0.05703, lr:8.51e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.901, tt:2903.004\n",
      "Ep:91, loss:0.00004, loss_test:0.05647, lr:8.43e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.889, tt:2933.803\n",
      "Ep:92, loss:0.00004, loss_test:0.05695, lr:8.35e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.910, tt:2967.590\n",
      "Ep:93, loss:0.00004, loss_test:0.05616, lr:8.26e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.918, tt:3000.280\n",
      "Ep:94, loss:0.00004, loss_test:0.05700, lr:8.18e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.923, tt:3032.647\n",
      "Ep:95, loss:0.00004, loss_test:0.05600, lr:8.10e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.922, tt:3064.560\n",
      "Ep:96, loss:0.00004, loss_test:0.05578, lr:8.02e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.911, tt:3095.361\n",
      "Ep:97, loss:0.00004, loss_test:0.05688, lr:7.94e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.909, tt:3127.038\n",
      "Ep:98, loss:0.00004, loss_test:0.05593, lr:7.86e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.913, tt:3159.410\n",
      "Ep:99, loss:0.00004, loss_test:0.05690, lr:7.78e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.905, tt:3190.506\n",
      "Ep:100, loss:0.00003, loss_test:0.05561, lr:7.70e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.879, tt:3219.816\n",
      "Ep:101, loss:0.00003, loss_test:0.05568, lr:7.62e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.865, tt:3250.240\n",
      "Ep:102, loss:0.00003, loss_test:0.05637, lr:7.55e-03, fs:0.85714 (r=0.848,p=0.866),  time:31.862, tt:3281.814\n",
      "Ep:103, loss:0.00003, loss_test:0.05666, lr:7.47e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.839, tt:3311.301\n",
      "Ep:104, loss:0.00003, loss_test:0.05566, lr:7.40e-03, fs:0.85128 (r=0.838,p=0.865),  time:31.828, tt:3341.973\n",
      "Ep:105, loss:0.00003, loss_test:0.05667, lr:7.32e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.803, tt:3371.079\n",
      "Ep:106, loss:0.00003, loss_test:0.05513, lr:7.25e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.787, tt:3401.245\n",
      "Ep:107, loss:0.00003, loss_test:0.05634, lr:7.18e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.775, tt:3431.688\n",
      "Ep:108, loss:0.00003, loss_test:0.05525, lr:7.11e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.768, tt:3462.699\n",
      "Ep:109, loss:0.00003, loss_test:0.05533, lr:7.03e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.778, tt:3495.618\n",
      "Ep:110, loss:0.00003, loss_test:0.05509, lr:6.96e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.776, tt:3527.150\n",
      "Ep:111, loss:0.00003, loss_test:0.05648, lr:6.89e-03, fs:0.85417 (r=0.828,p=0.882),  time:31.781, tt:3559.462\n",
      "Ep:112, loss:0.00003, loss_test:0.05510, lr:6.83e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.791, tt:3592.440\n",
      "Ep:113, loss:0.00003, loss_test:0.05626, lr:6.76e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.784, tt:3623.348\n",
      "Ep:114, loss:0.00003, loss_test:0.05544, lr:6.69e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.779, tt:3654.575\n",
      "Ep:115, loss:0.00003, loss_test:0.05625, lr:6.62e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.781, tt:3686.550\n",
      "Ep:116, loss:0.00003, loss_test:0.05634, lr:6.56e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.779, tt:3718.158\n",
      "Ep:117, loss:0.00003, loss_test:0.05482, lr:6.49e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.792, tt:3751.470\n",
      "Ep:118, loss:0.00003, loss_test:0.05657, lr:6.43e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.792, tt:3783.200\n",
      "Ep:119, loss:0.00003, loss_test:0.05456, lr:6.36e-03, fs:0.85567 (r=0.838,p=0.874),  time:31.790, tt:3814.772\n",
      "Ep:120, loss:0.00003, loss_test:0.05640, lr:6.30e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.794, tt:3847.106\n",
      "Ep:121, loss:0.00003, loss_test:0.05557, lr:6.24e-03, fs:0.86010 (r=0.838,p=0.883),  time:31.794, tt:3878.894\n",
      "Ep:122, loss:0.00003, loss_test:0.05442, lr:6.17e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.775, tt:3908.300\n",
      "Ep:123, loss:0.00003, loss_test:0.05566, lr:6.11e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.765, tt:3938.906\n",
      "Ep:124, loss:0.00003, loss_test:0.05442, lr:6.05e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.765, tt:3970.608\n",
      "Ep:125, loss:0.00003, loss_test:0.05535, lr:5.99e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.767, tt:4002.626\n",
      "Ep:126, loss:0.00003, loss_test:0.05478, lr:5.93e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.768, tt:4034.533\n",
      "Ep:127, loss:0.00003, loss_test:0.05427, lr:5.87e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.770, tt:4066.620\n",
      "Ep:128, loss:0.00003, loss_test:0.05537, lr:5.81e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.769, tt:4098.258\n",
      "Ep:129, loss:0.00003, loss_test:0.05463, lr:5.75e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.770, tt:4130.141\n",
      "Ep:130, loss:0.00003, loss_test:0.05524, lr:5.70e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.773, tt:4162.256\n",
      "Ep:131, loss:0.00003, loss_test:0.05384, lr:5.64e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.784, tt:4195.525\n",
      "Ep:132, loss:0.00002, loss_test:0.05419, lr:5.58e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.784, tt:4227.266\n",
      "Ep:133, loss:0.00002, loss_test:0.05438, lr:5.53e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.780, tt:4258.544\n",
      "Ep:134, loss:0.00002, loss_test:0.05463, lr:5.47e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.768, tt:4288.740\n",
      "Ep:135, loss:0.00002, loss_test:0.05397, lr:5.42e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.788, tt:4323.172\n",
      "Ep:136, loss:0.00002, loss_test:0.05459, lr:5.36e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.794, tt:4355.726\n",
      "Ep:137, loss:0.00002, loss_test:0.05411, lr:5.31e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.800, tt:4388.394\n",
      "Ep:138, loss:0.00002, loss_test:0.05449, lr:5.26e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.795, tt:4419.525\n",
      "Ep:139, loss:0.00002, loss_test:0.05380, lr:5.20e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.809, tt:4453.197\n",
      "Ep:140, loss:0.00002, loss_test:0.05411, lr:5.15e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.819, tt:4486.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:141, loss:0.00002, loss_test:0.05419, lr:5.10e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.824, tt:4518.958\n",
      "Ep:142, loss:0.00002, loss_test:0.05370, lr:5.05e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.824, tt:4550.781\n",
      "Ep:143, loss:0.00002, loss_test:0.05475, lr:5.00e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.823, tt:4582.455\n",
      "Ep:144, loss:0.00002, loss_test:0.05405, lr:4.95e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.832, tt:4615.702\n",
      "Ep:145, loss:0.00002, loss_test:0.05418, lr:4.90e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.846, tt:4649.557\n",
      "Ep:146, loss:0.00002, loss_test:0.05519, lr:4.85e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.857, tt:4682.953\n",
      "Ep:147, loss:0.00002, loss_test:0.05327, lr:4.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.855, tt:4714.523\n",
      "Ep:148, loss:0.00002, loss_test:0.05447, lr:4.75e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.858, tt:4746.821\n",
      "Ep:149, loss:0.00002, loss_test:0.05505, lr:4.71e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.868, tt:4780.184\n",
      "Ep:150, loss:0.00002, loss_test:0.05361, lr:4.66e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.880, tt:4813.932\n",
      "Ep:151, loss:0.00002, loss_test:0.05500, lr:4.61e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.882, tt:4846.134\n",
      "Ep:152, loss:0.00002, loss_test:0.05418, lr:4.57e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.898, tt:4880.332\n",
      "Ep:153, loss:0.00002, loss_test:0.05358, lr:4.52e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.898, tt:4912.257\n",
      "Ep:154, loss:0.00002, loss_test:0.05506, lr:4.48e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.898, tt:4944.172\n",
      "Ep:155, loss:0.00002, loss_test:0.05354, lr:4.43e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.895, tt:4975.685\n",
      "Ep:156, loss:0.00002, loss_test:0.05356, lr:4.39e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.898, tt:5008.020\n",
      "Ep:157, loss:0.00002, loss_test:0.05479, lr:4.34e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.899, tt:5039.971\n",
      "Ep:158, loss:0.00002, loss_test:0.05361, lr:4.30e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.903, tt:5072.499\n",
      "Ep:159, loss:0.00002, loss_test:0.05336, lr:4.26e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.909, tt:5105.422\n",
      "Ep:160, loss:0.00002, loss_test:0.05411, lr:4.21e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.933, tt:5141.209\n",
      "Ep:161, loss:0.00002, loss_test:0.05365, lr:4.17e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.933, tt:5173.145\n",
      "Ep:162, loss:0.00002, loss_test:0.05402, lr:4.13e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.932, tt:5204.947\n",
      "Ep:163, loss:0.00002, loss_test:0.05349, lr:4.09e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.937, tt:5237.746\n",
      "Ep:164, loss:0.00002, loss_test:0.05405, lr:4.05e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.943, tt:5270.565\n",
      "Ep:165, loss:0.00002, loss_test:0.05405, lr:4.01e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.955, tt:5304.547\n",
      "Ep:166, loss:0.00002, loss_test:0.05360, lr:3.97e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.953, tt:5336.147\n",
      "Ep:167, loss:0.00002, loss_test:0.05348, lr:3.93e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.945, tt:5366.686\n",
      "Ep:168, loss:0.00002, loss_test:0.05359, lr:3.89e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5398.081\n",
      "Ep:169, loss:0.00002, loss_test:0.05366, lr:3.85e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.946, tt:5430.904\n",
      "Ep:170, loss:0.00002, loss_test:0.05359, lr:3.81e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.949, tt:5463.267\n",
      "Ep:171, loss:0.00002, loss_test:0.05364, lr:3.77e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.950, tt:5495.413\n",
      "Ep:172, loss:0.00002, loss_test:0.05358, lr:3.73e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.950, tt:5527.397\n",
      "Ep:173, loss:0.00002, loss_test:0.05324, lr:3.70e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.948, tt:5558.876\n",
      "Ep:174, loss:0.00002, loss_test:0.05383, lr:3.66e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5589.705\n",
      "Ep:175, loss:0.00002, loss_test:0.05381, lr:3.62e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5621.573\n",
      "Ep:176, loss:0.00002, loss_test:0.05343, lr:3.59e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.942, tt:5653.708\n",
      "Ep:177, loss:0.00002, loss_test:0.05359, lr:3.55e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5685.579\n",
      "Ep:178, loss:0.00002, loss_test:0.05373, lr:3.52e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5717.451\n",
      "Ep:179, loss:0.00002, loss_test:0.05352, lr:3.48e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.931, tt:5747.598\n",
      "Ep:180, loss:0.00002, loss_test:0.05332, lr:3.45e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.928, tt:5778.902\n",
      "Ep:181, loss:0.00002, loss_test:0.05356, lr:3.41e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.953, tt:5815.372\n",
      "Ep:182, loss:0.00002, loss_test:0.05368, lr:3.38e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.954, tt:5847.550\n",
      "Ep:183, loss:0.00002, loss_test:0.05361, lr:3.34e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.950, tt:5878.768\n",
      "Ep:184, loss:0.00002, loss_test:0.05341, lr:3.31e-03, fs:0.86911 (r=0.838,p=0.902),  time:31.942, tt:5909.180\n",
      "Ep:185, loss:0.00002, loss_test:0.05361, lr:3.28e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.944, tt:5941.563\n",
      "Ep:186, loss:0.00002, loss_test:0.05365, lr:3.24e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.941, tt:5972.905\n",
      "Ep:187, loss:0.00002, loss_test:0.05314, lr:3.21e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.948, tt:6006.175\n",
      "Ep:188, loss:0.00002, loss_test:0.05384, lr:3.18e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.946, tt:6037.826\n",
      "Ep:189, loss:0.00002, loss_test:0.05362, lr:3.15e-03, fs:0.85864 (r=0.828,p=0.891),  time:31.942, tt:6068.885\n",
      "Ep:190, loss:0.00002, loss_test:0.05311, lr:3.12e-03, fs:0.86458 (r=0.838,p=0.892),  time:31.942, tt:6100.899\n",
      "Ep:191, loss:0.00002, loss_test:0.05386, lr:3.09e-03, fs:0.87234 (r=0.828,p=0.921),  time:31.933, tt:6131.127\n",
      "Ep:192, loss:0.00002, loss_test:0.05385, lr:3.05e-03, fs:0.86316 (r=0.828,p=0.901),  time:31.924, tt:6161.387\n",
      "Ep:193, loss:0.00002, loss_test:0.05330, lr:3.02e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.919, tt:6192.235\n",
      "Ep:194, loss:0.00002, loss_test:0.05364, lr:2.99e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.907, tt:6221.814\n",
      "Ep:195, loss:0.00002, loss_test:0.05379, lr:2.96e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.902, tt:6252.829\n",
      "Ep:196, loss:0.00002, loss_test:0.05360, lr:2.93e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.901, tt:6284.556\n",
      "Ep:197, loss:0.00002, loss_test:0.05341, lr:2.90e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.900, tt:6316.116\n",
      "Ep:198, loss:0.00002, loss_test:0.05363, lr:2.88e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.906, tt:6349.358\n",
      "Ep:199, loss:0.00002, loss_test:0.05348, lr:2.85e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.909, tt:6381.713\n",
      "Ep:200, loss:0.00002, loss_test:0.05354, lr:2.82e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.903, tt:6412.477\n",
      "Ep:201, loss:0.00002, loss_test:0.05350, lr:2.79e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.898, tt:6443.356\n",
      "Ep:202, loss:0.00002, loss_test:0.05361, lr:2.76e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.903, tt:6476.220\n",
      "Ep:203, loss:0.00002, loss_test:0.05364, lr:2.73e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.910, tt:6509.675\n",
      "Ep:204, loss:0.00002, loss_test:0.05347, lr:2.71e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.892, tt:6537.762\n",
      "Ep:205, loss:0.00002, loss_test:0.05363, lr:2.68e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.859, tt:6562.958\n",
      "Ep:206, loss:0.00002, loss_test:0.05342, lr:2.65e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.806, tt:6583.810\n",
      "Ep:207, loss:0.00002, loss_test:0.05371, lr:2.63e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.765, tt:6607.112\n",
      "Ep:208, loss:0.00002, loss_test:0.05402, lr:2.60e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.746, tt:6634.916\n",
      "Ep:209, loss:0.00002, loss_test:0.05333, lr:2.57e-03, fs:0.87368 (r=0.838,p=0.912),  time:31.738, tt:6665.067\n",
      "Ep:210, loss:0.00002, loss_test:0.05360, lr:2.55e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.721, tt:6693.041\n",
      "Ep:211, loss:0.00002, loss_test:0.05390, lr:2.52e-03, fs:0.86772 (r=0.828,p=0.911),  time:31.709, tt:6722.308\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02024, lr:6.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:30.908, tt:30.908\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02055, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.548, tt:61.095\n",
      "Ep:2, loss:0.00004, loss_test:0.02323, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.477, tt:91.430\n",
      "Ep:3, loss:0.00005, loss_test:0.02460, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.965, tt:119.862\n",
      "Ep:4, loss:0.00005, loss_test:0.02505, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.082, tt:150.411\n",
      "Ep:5, loss:0.00005, loss_test:0.02482, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.064, tt:180.387\n",
      "Ep:6, loss:0.00005, loss_test:0.02400, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.896, tt:209.273\n",
      "Ep:7, loss:0.00005, loss_test:0.02274, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.776, tt:238.204\n",
      "Ep:8, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:29.873, tt:268.860\n",
      "Ep:9, loss:0.00004, loss_test:0.01973, lr:6.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:29.919, tt:299.192\n",
      "Ep:10, loss:0.00004, loss_test:0.01841, lr:6.00e-02, fs:0.67596 (r=0.980,p=0.516),  time:30.108, tt:331.188\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01756, lr:6.00e-02, fs:0.67658 (r=0.919,p=0.535),  time:30.218, tt:362.613\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01728, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:30.235, tt:393.053\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01728, lr:6.00e-02, fs:0.70996 (r=0.828,p=0.621),  time:30.264, tt:423.690\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01705, lr:6.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:30.297, tt:454.459\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:30.294, tt:484.712\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:30.237, tt:514.034\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01587, lr:6.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:30.130, tt:542.338\n",
      "Ep:18, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:30.087, tt:571.657\n",
      "Ep:19, loss:0.00003, loss_test:0.01549, lr:6.00e-02, fs:0.73764 (r=0.980,p=0.591),  time:30.071, tt:601.420\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01521, lr:6.00e-02, fs:0.74708 (r=0.970,p=0.608),  time:30.039, tt:630.823\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01495, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:30.006, tt:660.128\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:30.054, tt:691.238\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.80702 (r=0.929,p=0.713),  time:30.094, tt:722.268\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01459, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.098, tt:752.461\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01444, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:30.094, tt:782.440\n",
      "Ep:26, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:30.091, tt:812.447\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01411, lr:6.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:30.100, tt:842.803\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01397, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:30.086, tt:872.481\n",
      "Ep:29, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:30.104, tt:903.112\n",
      "Ep:30, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:30.111, tt:933.454\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01364, lr:6.00e-02, fs:0.82906 (r=0.980,p=0.719),  time:30.095, tt:963.056\n",
      "Ep:32, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.83262 (r=0.980,p=0.724),  time:30.116, tt:993.843\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:30.141, tt:1024.800\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:30.088, tt:1053.065\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.85088 (r=0.980,p=0.752),  time:30.071, tt:1082.570\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01331, lr:6.00e-02, fs:0.85463 (r=0.980,p=0.758),  time:30.108, tt:1113.987\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:30.109, tt:1144.152\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.86344 (r=0.990,p=0.766),  time:30.151, tt:1175.887\n",
      "Ep:39, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.86222 (r=0.980,p=0.770),  time:30.155, tt:1206.195\n",
      "Ep:40, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:30.174, tt:1237.136\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01292, lr:6.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:30.184, tt:1267.744\n",
      "Ep:42, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.86099 (r=0.970,p=0.774),  time:30.189, tt:1298.129\n",
      "Ep:43, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:30.195, tt:1328.561\n",
      "Ep:44, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.85973 (r=0.960,p=0.779),  time:30.191, tt:1358.578\n",
      "Ep:45, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.212, tt:1389.753\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.230, tt:1420.798\n",
      "Ep:47, loss:0.00002, loss_test:0.01264, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.256, tt:1452.277\n",
      "Ep:48, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:30.292, tt:1484.320\n",
      "Ep:49, loss:0.00002, loss_test:0.01257, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:30.288, tt:1514.408\n",
      "Ep:50, loss:0.00002, loss_test:0.01254, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:30.320, tt:1546.307\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01250, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:30.310, tt:1576.111\n",
      "Ep:52, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:30.325, tt:1607.238\n",
      "Ep:53, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:30.350, tt:1638.921\n",
      "Ep:54, loss:0.00001, loss_test:0.01242, lr:6.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:30.360, tt:1669.785\n",
      "Ep:55, loss:0.00001, loss_test:0.01240, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.357, tt:1699.988\n",
      "Ep:56, loss:0.00001, loss_test:0.01238, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.356, tt:1730.283\n",
      "Ep:57, loss:0.00001, loss_test:0.01236, lr:6.00e-02, fs:0.85577 (r=0.899,p=0.817),  time:30.373, tt:1761.630\n",
      "Ep:58, loss:0.00001, loss_test:0.01234, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.360, tt:1791.221\n",
      "Ep:59, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.387, tt:1823.246\n",
      "Ep:60, loss:0.00001, loss_test:0.01230, lr:6.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:30.408, tt:1854.909\n",
      "Ep:61, loss:0.00001, loss_test:0.01229, lr:6.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.403, tt:1884.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01227, lr:5.94e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.408, tt:1915.674\n",
      "Ep:63, loss:0.00001, loss_test:0.01227, lr:5.88e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.405, tt:1945.924\n",
      "Ep:64, loss:0.00001, loss_test:0.01228, lr:5.82e-02, fs:0.85572 (r=0.869,p=0.843),  time:30.405, tt:1976.343\n",
      "Ep:65, loss:0.00001, loss_test:0.01227, lr:5.76e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.409, tt:2006.992\n",
      "Ep:66, loss:0.00001, loss_test:0.01228, lr:5.71e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.406, tt:2037.189\n",
      "Ep:67, loss:0.00001, loss_test:0.01228, lr:5.65e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.391, tt:2066.620\n",
      "Ep:68, loss:0.00001, loss_test:0.01227, lr:5.59e-02, fs:0.85000 (r=0.859,p=0.842),  time:30.408, tt:2098.167\n",
      "Ep:69, loss:0.00001, loss_test:0.01229, lr:5.54e-02, fs:0.85427 (r=0.859,p=0.850),  time:30.397, tt:2127.782\n",
      "Ep:70, loss:0.00001, loss_test:0.01230, lr:5.48e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.387, tt:2157.501\n",
      "Ep:71, loss:0.00001, loss_test:0.01229, lr:5.43e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.389, tt:2187.977\n",
      "Ep:72, loss:0.00001, loss_test:0.01230, lr:5.37e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.389, tt:2218.428\n",
      "Ep:73, loss:0.00001, loss_test:0.01229, lr:5.32e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.400, tt:2249.622\n",
      "Ep:74, loss:0.00001, loss_test:0.01229, lr:5.27e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.399, tt:2279.959\n",
      "Ep:75, loss:0.00001, loss_test:0.01231, lr:5.21e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.391, tt:2309.713\n",
      "Ep:76, loss:0.00001, loss_test:0.01233, lr:5.16e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.402, tt:2340.955\n",
      "Ep:77, loss:0.00001, loss_test:0.01234, lr:5.11e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.396, tt:2370.894\n",
      "Ep:78, loss:0.00001, loss_test:0.01234, lr:5.06e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.406, tt:2402.077\n",
      "Ep:79, loss:0.00001, loss_test:0.01234, lr:5.01e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.412, tt:2432.967\n",
      "Ep:80, loss:0.00001, loss_test:0.01237, lr:4.96e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.417, tt:2463.814\n",
      "Ep:81, loss:0.00001, loss_test:0.01239, lr:4.91e-02, fs:0.84264 (r=0.838,p=0.847),  time:30.437, tt:2495.861\n",
      "Ep:82, loss:0.00001, loss_test:0.01241, lr:4.86e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.430, tt:2525.680\n",
      "Ep:83, loss:0.00001, loss_test:0.01241, lr:4.81e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.448, tt:2557.599\n",
      "Ep:84, loss:0.00001, loss_test:0.01242, lr:4.76e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.441, tt:2587.514\n",
      "Ep:85, loss:0.00001, loss_test:0.01245, lr:4.71e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.431, tt:2617.094\n",
      "Ep:86, loss:0.00001, loss_test:0.01246, lr:4.67e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.435, tt:2647.852\n",
      "Ep:87, loss:0.00001, loss_test:0.01248, lr:4.62e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.436, tt:2678.379\n",
      "Ep:88, loss:0.00001, loss_test:0.01249, lr:4.57e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.426, tt:2707.911\n",
      "Ep:89, loss:0.00001, loss_test:0.01251, lr:4.53e-02, fs:0.84694 (r=0.838,p=0.856),  time:30.429, tt:2738.569\n",
      "Ep:90, loss:0.00001, loss_test:0.01252, lr:4.48e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.426, tt:2768.784\n",
      "Ep:91, loss:0.00001, loss_test:0.01255, lr:4.44e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.433, tt:2799.800\n",
      "Ep:92, loss:0.00001, loss_test:0.01256, lr:4.39e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.442, tt:2831.149\n",
      "Ep:93, loss:0.00001, loss_test:0.01257, lr:4.35e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.446, tt:2861.908\n",
      "Ep:94, loss:0.00001, loss_test:0.01257, lr:4.31e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.434, tt:2891.199\n",
      "Ep:95, loss:0.00001, loss_test:0.01260, lr:4.26e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.433, tt:2921.566\n",
      "Ep:96, loss:0.00001, loss_test:0.01262, lr:4.22e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.431, tt:2951.849\n",
      "Ep:97, loss:0.00001, loss_test:0.01262, lr:4.18e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.440, tt:2983.152\n",
      "Ep:98, loss:0.00001, loss_test:0.01264, lr:4.14e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.456, tt:3015.115\n",
      "Ep:99, loss:0.00001, loss_test:0.01265, lr:4.10e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.449, tt:3044.935\n",
      "Ep:100, loss:0.00001, loss_test:0.01267, lr:4.05e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.436, tt:3074.062\n",
      "Ep:101, loss:0.00001, loss_test:0.01271, lr:4.01e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.437, tt:3104.570\n",
      "Ep:102, loss:0.00001, loss_test:0.01272, lr:3.97e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.439, tt:3135.189\n",
      "Ep:103, loss:0.00001, loss_test:0.01274, lr:3.93e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.440, tt:3165.791\n",
      "Ep:104, loss:0.00001, loss_test:0.01275, lr:3.89e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.451, tt:3197.360\n",
      "Ep:105, loss:0.00001, loss_test:0.01276, lr:3.86e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.453, tt:3228.067\n",
      "Ep:106, loss:0.00001, loss_test:0.01278, lr:3.82e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.454, tt:3258.542\n",
      "Ep:107, loss:0.00001, loss_test:0.01278, lr:3.78e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.445, tt:3288.058\n",
      "Ep:108, loss:0.00001, loss_test:0.01280, lr:3.74e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.447, tt:3318.718\n",
      "Ep:109, loss:0.00001, loss_test:0.01282, lr:3.70e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.446, tt:3349.044\n",
      "Ep:110, loss:0.00001, loss_test:0.01284, lr:3.67e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.448, tt:3379.743\n",
      "Ep:111, loss:0.00001, loss_test:0.01286, lr:3.63e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.439, tt:3409.194\n",
      "Ep:112, loss:0.00001, loss_test:0.01287, lr:3.59e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.457, tt:3441.682\n",
      "Ep:113, loss:0.00001, loss_test:0.01288, lr:3.56e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.481, tt:3474.865\n",
      "Ep:114, loss:0.00001, loss_test:0.01289, lr:3.52e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.479, tt:3505.106\n",
      "Ep:115, loss:0.00001, loss_test:0.01290, lr:3.49e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.489, tt:3536.769\n",
      "Ep:116, loss:0.00001, loss_test:0.01293, lr:3.45e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.491, tt:3567.432\n",
      "Ep:117, loss:0.00001, loss_test:0.01295, lr:3.42e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.494, tt:3598.244\n",
      "Ep:118, loss:0.00001, loss_test:0.01295, lr:3.38e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.478, tt:3626.852\n",
      "Ep:119, loss:0.00001, loss_test:0.01297, lr:3.35e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.472, tt:3656.604\n",
      "Ep:120, loss:0.00001, loss_test:0.01299, lr:3.32e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.477, tt:3687.688\n",
      "Ep:121, loss:0.00001, loss_test:0.01301, lr:3.28e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.482, tt:3718.840\n",
      "Ep:122, loss:0.00001, loss_test:0.01302, lr:3.25e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.488, tt:3749.983\n",
      "Ep:123, loss:0.00001, loss_test:0.01304, lr:3.22e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.479, tt:3779.346\n",
      "Ep:124, loss:0.00001, loss_test:0.01305, lr:3.19e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.485, tt:3810.577\n",
      "Ep:125, loss:0.00001, loss_test:0.01307, lr:3.15e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.489, tt:3841.652\n",
      "Ep:126, loss:0.00001, loss_test:0.01309, lr:3.12e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.481, tt:3871.063\n",
      "Ep:127, loss:0.00001, loss_test:0.01310, lr:3.09e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.483, tt:3901.789\n",
      "Ep:128, loss:0.00001, loss_test:0.01312, lr:3.06e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.481, tt:3932.096\n",
      "Ep:129, loss:0.00001, loss_test:0.01313, lr:3.03e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.493, tt:3964.027\n",
      "Ep:130, loss:0.00001, loss_test:0.01314, lr:3.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.493, tt:3994.645\n",
      "Ep:131, loss:0.00001, loss_test:0.01316, lr:2.97e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.493, tt:4025.116\n",
      "Ep:132, loss:0.00001, loss_test:0.01317, lr:2.94e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.500, tt:4056.440\n",
      "Ep:133, loss:0.00001, loss_test:0.01318, lr:2.91e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.493, tt:4086.053\n",
      "Ep:134, loss:0.00001, loss_test:0.01320, lr:2.88e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.505, tt:4118.216\n",
      "Ep:135, loss:0.00001, loss_test:0.01322, lr:2.85e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.537, tt:4153.049\n",
      "Ep:136, loss:0.00001, loss_test:0.01323, lr:2.82e-02, fs:0.86010 (r=0.838,p=0.883),  time:30.544, tt:4184.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00001, loss_test:0.01324, lr:2.80e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.546, tt:4215.376\n",
      "Ep:138, loss:0.00001, loss_test:0.01326, lr:2.77e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.541, tt:4245.223\n",
      "Ep:139, loss:0.00001, loss_test:0.01327, lr:2.74e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.542, tt:4275.845\n",
      "Ep:140, loss:0.00001, loss_test:0.01329, lr:2.71e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.547, tt:4307.056\n",
      "Ep:141, loss:0.00001, loss_test:0.01330, lr:2.69e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.549, tt:4338.018\n",
      "Ep:142, loss:0.00001, loss_test:0.01332, lr:2.66e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.554, tt:4369.282\n",
      "Ep:143, loss:0.00001, loss_test:0.01332, lr:2.63e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.551, tt:4399.337\n",
      "Ep:144, loss:0.00001, loss_test:0.01334, lr:2.61e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.554, tt:4430.331\n",
      "Ep:145, loss:0.00001, loss_test:0.01335, lr:2.58e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.561, tt:4461.922\n",
      "Ep:146, loss:0.00001, loss_test:0.01337, lr:2.55e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.558, tt:4492.025\n",
      "Ep:147, loss:0.00001, loss_test:0.01338, lr:2.53e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.555, tt:4522.196\n",
      "Ep:148, loss:0.00001, loss_test:0.01339, lr:2.50e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.554, tt:4552.615\n",
      "Ep:149, loss:0.00001, loss_test:0.01341, lr:2.48e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.556, tt:4583.391\n",
      "Ep:150, loss:0.00001, loss_test:0.01342, lr:2.45e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.556, tt:4613.994\n",
      "Ep:151, loss:0.00001, loss_test:0.01343, lr:2.43e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.551, tt:4643.728\n",
      "Ep:152, loss:0.00001, loss_test:0.01344, lr:2.40e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.552, tt:4674.514\n",
      "Ep:153, loss:0.00001, loss_test:0.01346, lr:2.38e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.552, tt:4705.050\n",
      "Ep:154, loss:0.00001, loss_test:0.01348, lr:2.36e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.556, tt:4736.178\n",
      "Ep:155, loss:0.00001, loss_test:0.01348, lr:2.33e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.561, tt:4767.509\n",
      "Ep:156, loss:0.00001, loss_test:0.01350, lr:2.31e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.570, tt:4799.540\n",
      "Ep:157, loss:0.00001, loss_test:0.01351, lr:2.29e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.564, tt:4829.163\n",
      "Ep:158, loss:0.00001, loss_test:0.01353, lr:2.26e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.567, tt:4860.222\n",
      "Ep:159, loss:0.00001, loss_test:0.01355, lr:2.24e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.562, tt:4889.909\n",
      "Ep:160, loss:0.00001, loss_test:0.01355, lr:2.22e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.571, tt:4921.897\n",
      "Ep:161, loss:0.00001, loss_test:0.01357, lr:2.20e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.569, tt:4952.176\n",
      "Ep:162, loss:0.00001, loss_test:0.01358, lr:2.17e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.574, tt:4983.627\n",
      "Ep:163, loss:0.00001, loss_test:0.01360, lr:2.15e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.575, tt:5014.256\n",
      "Ep:164, loss:0.00001, loss_test:0.01361, lr:2.13e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.578, tt:5045.323\n",
      "Ep:165, loss:0.00000, loss_test:0.01362, lr:2.11e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.578, tt:5075.936\n",
      "Ep:166, loss:0.00000, loss_test:0.01363, lr:2.09e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.578, tt:5106.607\n",
      "Ep:167, loss:0.00000, loss_test:0.01364, lr:2.07e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.590, tt:5139.199\n",
      "Ep:168, loss:0.00000, loss_test:0.01365, lr:2.05e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.593, tt:5170.258\n",
      "Ep:169, loss:0.00000, loss_test:0.01367, lr:2.03e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.593, tt:5200.775\n",
      "Ep:170, loss:0.00000, loss_test:0.01368, lr:2.01e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.588, tt:5230.571\n",
      "Ep:171, loss:0.00000, loss_test:0.01369, lr:1.99e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.592, tt:5261.759\n",
      "Ep:172, loss:0.00000, loss_test:0.01370, lr:1.97e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.596, tt:5293.162\n",
      "Ep:173, loss:0.00000, loss_test:0.01371, lr:1.95e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.585, tt:5321.784\n",
      "Ep:174, loss:0.00000, loss_test:0.01373, lr:1.93e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.585, tt:5352.362\n",
      "Ep:175, loss:0.00000, loss_test:0.01373, lr:1.91e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.590, tt:5383.849\n",
      "Ep:176, loss:0.00000, loss_test:0.01374, lr:1.89e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.587, tt:5413.876\n",
      "Ep:177, loss:0.00000, loss_test:0.01376, lr:1.87e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.583, tt:5443.690\n",
      "Ep:178, loss:0.00000, loss_test:0.01377, lr:1.85e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.590, tt:5475.525\n",
      "Ep:179, loss:0.00000, loss_test:0.01377, lr:1.83e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.588, tt:5505.903\n",
      "Ep:180, loss:0.00000, loss_test:0.01378, lr:1.81e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.593, tt:5537.379\n",
      "Ep:181, loss:0.00000, loss_test:0.01379, lr:1.80e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.592, tt:5567.775\n",
      "Ep:182, loss:0.00000, loss_test:0.01380, lr:1.78e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.593, tt:5598.582\n",
      "Ep:183, loss:0.00000, loss_test:0.01381, lr:1.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.588, tt:5628.239\n",
      "Ep:184, loss:0.00000, loss_test:0.01382, lr:1.74e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.586, tt:5658.352\n",
      "Ep:185, loss:0.00000, loss_test:0.01383, lr:1.73e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.590, tt:5689.711\n",
      "Ep:186, loss:0.00000, loss_test:0.01384, lr:1.71e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.588, tt:5719.912\n",
      "Ep:187, loss:0.00000, loss_test:0.01384, lr:1.69e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.583, tt:5749.628\n",
      "Ep:188, loss:0.00000, loss_test:0.01386, lr:1.67e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.592, tt:5781.914\n",
      "Ep:189, loss:0.00000, loss_test:0.01387, lr:1.66e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.579, tt:5810.053\n",
      "Ep:190, loss:0.00000, loss_test:0.01388, lr:1.64e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.577, tt:5840.280\n",
      "Ep:191, loss:0.00000, loss_test:0.01388, lr:1.62e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.579, tt:5871.156\n",
      "Ep:192, loss:0.00000, loss_test:0.01389, lr:1.61e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.555, tt:5897.023\n",
      "Ep:193, loss:0.00000, loss_test:0.01390, lr:1.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:30.531, tt:5923.090\n",
      "Ep:194, loss:0.00000, loss_test:0.01391, lr:1.58e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.504, tt:5948.354\n",
      "Ep:195, loss:0.00000, loss_test:0.01391, lr:1.56e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.486, tt:5975.267\n",
      "Ep:196, loss:0.00000, loss_test:0.01392, lr:1.54e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.475, tt:6003.653\n",
      "Ep:197, loss:0.00000, loss_test:0.01392, lr:1.53e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.473, tt:6033.576\n",
      "Ep:198, loss:0.00000, loss_test:0.01393, lr:1.51e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.467, tt:6063.010\n",
      "Ep:199, loss:0.00000, loss_test:0.01394, lr:1.50e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.465, tt:6093.053\n",
      "Ep:200, loss:0.00000, loss_test:0.01394, lr:1.48e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.468, tt:6124.168\n",
      "Ep:201, loss:0.00000, loss_test:0.01395, lr:1.47e-02, fs:0.86911 (r=0.838,p=0.902),  time:30.472, tt:6155.409\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13973, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.844, tt:31.844\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13829, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.212, tt:62.424\n",
      "Ep:2, loss:0.00027, loss_test:0.13579, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:30.962, tt:92.887\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.13183, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:31.047, tt:124.190\n",
      "Ep:4, loss:0.00025, loss_test:0.12598, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:30.955, tt:154.773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:5, loss:0.00024, loss_test:0.11924, lr:1.00e-02, fs:0.67811 (r=0.798,p=0.590),  time:31.281, tt:187.688\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11492, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:31.143, tt:218.004\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.11192, lr:1.00e-02, fs:0.68367 (r=0.677,p=0.691),  time:31.179, tt:249.433\n",
      "Ep:8, loss:0.00022, loss_test:0.11165, lr:1.00e-02, fs:0.73684 (r=0.848,p=0.651),  time:31.145, tt:280.305\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.11017, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:31.232, tt:312.317\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10585, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:31.271, tt:343.979\n",
      "Ep:11, loss:0.00019, loss_test:0.10390, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:31.377, tt:376.527\n",
      "Ep:12, loss:0.00019, loss_test:0.10235, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:31.474, tt:409.166\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10109, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:31.432, tt:440.049\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09909, lr:1.00e-02, fs:0.74747 (r=0.747,p=0.747),  time:31.460, tt:471.906\n",
      "Ep:15, loss:0.00017, loss_test:0.09769, lr:1.00e-02, fs:0.72539 (r=0.707,p=0.745),  time:31.433, tt:502.922\n",
      "Ep:16, loss:0.00017, loss_test:0.09691, lr:1.00e-02, fs:0.75728 (r=0.788,p=0.729),  time:31.459, tt:534.797\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09567, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:31.431, tt:565.753\n",
      "Ep:18, loss:0.00015, loss_test:0.09343, lr:1.00e-02, fs:0.75258 (r=0.737,p=0.768),  time:31.418, tt:596.937\n",
      "Ep:19, loss:0.00015, loss_test:0.09188, lr:1.00e-02, fs:0.76142 (r=0.758,p=0.765),  time:31.403, tt:628.056\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09063, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:31.425, tt:659.919\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08952, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.439, tt:691.648\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08834, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:31.479, tt:724.010\n",
      "Ep:23, loss:0.00013, loss_test:0.08688, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.538, tt:756.909\n",
      "Ep:24, loss:0.00012, loss_test:0.08613, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.520, tt:788.004\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08504, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:31.541, tt:820.062\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.08358, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:31.539, tt:851.563\n",
      "Ep:27, loss:0.00011, loss_test:0.08292, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:31.563, tt:883.770\n",
      "Ep:28, loss:0.00011, loss_test:0.08206, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:31.535, tt:914.521\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08087, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:31.533, tt:945.994\n",
      "Ep:30, loss:0.00010, loss_test:0.08079, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:31.522, tt:977.194\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.08010, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.520, tt:1008.648\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.07905, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:31.551, tt:1041.177\n",
      "Ep:33, loss:0.00009, loss_test:0.07910, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:31.553, tt:1072.808\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00009, loss_test:0.07816, lr:1.00e-02, fs:0.80208 (r=0.778,p=0.828),  time:31.549, tt:1104.205\n",
      "Ep:35, loss:0.00008, loss_test:0.07744, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:31.541, tt:1135.489\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.07764, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:31.528, tt:1166.550\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.07706, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:31.511, tt:1197.434\n",
      "Ep:38, loss:0.00008, loss_test:0.07634, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:31.475, tt:1227.530\n",
      "Ep:39, loss:0.00007, loss_test:0.07603, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:31.483, tt:1259.333\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.07480, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:31.504, tt:1291.666\n",
      "Ep:41, loss:0.00007, loss_test:0.07513, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.465, tt:1321.529\n",
      "Ep:42, loss:0.00007, loss_test:0.07456, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:31.469, tt:1353.152\n",
      "Ep:43, loss:0.00006, loss_test:0.07346, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:31.455, tt:1383.999\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.07396, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.485, tt:1416.803\n",
      "Ep:45, loss:0.00006, loss_test:0.07310, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:31.450, tt:1446.705\n",
      "Ep:46, loss:0.00006, loss_test:0.07308, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.436, tt:1477.484\n",
      "Ep:47, loss:0.00006, loss_test:0.07268, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:31.421, tt:1508.219\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.07243, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:31.422, tt:1539.702\n",
      "Ep:49, loss:0.00005, loss_test:0.07241, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.412, tt:1570.597\n",
      "Ep:50, loss:0.00005, loss_test:0.07144, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:31.432, tt:1603.023\n",
      "Ep:51, loss:0.00005, loss_test:0.07221, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.425, tt:1634.111\n",
      "Ep:52, loss:0.00005, loss_test:0.07206, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:31.457, tt:1667.227\n",
      "Ep:53, loss:0.00005, loss_test:0.07139, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:31.454, tt:1698.510\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.07135, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.467, tt:1730.674\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.07131, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:31.462, tt:1761.888\n",
      "Ep:56, loss:0.00004, loss_test:0.07108, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.447, tt:1792.487\n",
      "Ep:57, loss:0.00004, loss_test:0.07051, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:31.424, tt:1822.586\n",
      "Ep:58, loss:0.00004, loss_test:0.07096, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.415, tt:1853.485\n",
      "Ep:59, loss:0.00004, loss_test:0.07053, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.412, tt:1884.744\n",
      "Ep:60, loss:0.00004, loss_test:0.07065, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.409, tt:1915.965\n",
      "Ep:61, loss:0.00004, loss_test:0.07095, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:31.378, tt:1945.443\n",
      "Ep:62, loss:0.00004, loss_test:0.07025, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:31.371, tt:1976.386\n",
      "Ep:63, loss:0.00004, loss_test:0.07093, lr:1.00e-02, fs:0.84615 (r=0.778,p=0.928),  time:31.367, tt:2007.513\n",
      "Ep:64, loss:0.00004, loss_test:0.07022, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:31.334, tt:2036.724\n",
      "Ep:65, loss:0.00003, loss_test:0.07043, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:31.306, tt:2066.216\n",
      "Ep:66, loss:0.00003, loss_test:0.07033, lr:9.90e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.308, tt:2097.603\n",
      "Ep:67, loss:0.00003, loss_test:0.07009, lr:9.80e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.305, tt:2128.770\n",
      "Ep:68, loss:0.00003, loss_test:0.06970, lr:9.70e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.290, tt:2159.029\n",
      "Ep:69, loss:0.00003, loss_test:0.07042, lr:9.61e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.299, tt:2190.964\n",
      "Ep:70, loss:0.00003, loss_test:0.06999, lr:9.51e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.296, tt:2222.019\n",
      "Ep:71, loss:0.00003, loss_test:0.07000, lr:9.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.297, tt:2253.379\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00003, loss_test:0.07050, lr:9.41e-03, fs:0.84324 (r=0.788,p=0.907),  time:31.312, tt:2285.747\n",
      "Ep:73, loss:0.00003, loss_test:0.07041, lr:9.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.340, tt:2319.182\n",
      "Ep:74, loss:0.00003, loss_test:0.06996, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.378, tt:2353.318\n",
      "Ep:75, loss:0.00003, loss_test:0.07018, lr:9.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:31.425, tt:2388.269\n",
      "Ep:76, loss:0.00003, loss_test:0.07043, lr:9.41e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.427, tt:2419.881\n",
      "Ep:77, loss:0.00003, loss_test:0.07003, lr:9.41e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.431, tt:2451.623\n",
      "Ep:78, loss:0.00003, loss_test:0.07041, lr:9.41e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.435, tt:2483.326\n",
      "Ep:79, loss:0.00003, loss_test:0.07013, lr:9.41e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.445, tt:2515.590\n",
      "Ep:80, loss:0.00002, loss_test:0.07059, lr:9.41e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.463, tt:2548.484\n",
      "Ep:81, loss:0.00002, loss_test:0.07060, lr:9.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:31.483, tt:2581.571\n",
      "Ep:82, loss:0.00002, loss_test:0.07036, lr:9.41e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.492, tt:2613.838\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00002, loss_test:0.07021, lr:9.41e-03, fs:0.82682 (r=0.747,p=0.925),  time:31.500, tt:2646.004\n",
      "Ep:84, loss:0.00002, loss_test:0.06983, lr:9.41e-03, fs:0.84492 (r=0.798,p=0.898),  time:31.500, tt:2677.512\n",
      "Ep:85, loss:0.00002, loss_test:0.07099, lr:9.41e-03, fs:0.81143 (r=0.717,p=0.934),  time:31.515, tt:2710.287\n",
      "Ep:86, loss:0.00002, loss_test:0.07087, lr:9.41e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.521, tt:2742.343\n",
      "Ep:87, loss:0.00002, loss_test:0.07054, lr:9.41e-03, fs:0.82222 (r=0.747,p=0.914),  time:31.530, tt:2774.652\n",
      "Ep:88, loss:0.00002, loss_test:0.07079, lr:9.41e-03, fs:0.80682 (r=0.717,p=0.922),  time:31.517, tt:2805.051\n",
      "Ep:89, loss:0.00002, loss_test:0.07018, lr:9.41e-03, fs:0.82873 (r=0.758,p=0.915),  time:31.503, tt:2835.270\n",
      "Ep:90, loss:0.00002, loss_test:0.07106, lr:9.41e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.486, tt:2865.253\n",
      "Ep:91, loss:0.00002, loss_test:0.07077, lr:9.41e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.492, tt:2897.247\n",
      "Ep:92, loss:0.00002, loss_test:0.07035, lr:9.41e-03, fs:0.80899 (r=0.727,p=0.911),  time:31.490, tt:2928.575\n",
      "Ep:93, loss:0.00002, loss_test:0.07076, lr:9.41e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.489, tt:2959.930\n",
      "Ep:94, loss:0.00002, loss_test:0.07013, lr:9.32e-03, fs:0.81564 (r=0.737,p=0.912),  time:31.493, tt:2991.866\n",
      "Ep:95, loss:0.00002, loss_test:0.07057, lr:9.23e-03, fs:0.80925 (r=0.707,p=0.946),  time:31.515, tt:3025.405\n",
      "Ep:96, loss:0.00002, loss_test:0.07034, lr:9.14e-03, fs:0.80460 (r=0.707,p=0.933),  time:31.562, tt:3061.500\n",
      "Ep:97, loss:0.00002, loss_test:0.07079, lr:9.04e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.563, tt:3093.220\n",
      "Ep:98, loss:0.00002, loss_test:0.07105, lr:8.95e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.579, tt:3126.356\n",
      "Ep:99, loss:0.00002, loss_test:0.07017, lr:8.86e-03, fs:0.81356 (r=0.727,p=0.923),  time:31.588, tt:3158.765\n",
      "Ep:100, loss:0.00002, loss_test:0.07136, lr:8.78e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.593, tt:3190.924\n",
      "Ep:101, loss:0.00002, loss_test:0.07114, lr:8.69e-03, fs:0.80000 (r=0.687,p=0.958),  time:31.588, tt:3221.975\n",
      "Ep:102, loss:0.00002, loss_test:0.07041, lr:8.60e-03, fs:0.80702 (r=0.697,p=0.958),  time:31.599, tt:3254.738\n",
      "Ep:103, loss:0.00002, loss_test:0.07106, lr:8.51e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.613, tt:3287.757\n",
      "Ep:104, loss:0.00002, loss_test:0.07090, lr:8.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.634, tt:3321.540\n",
      "Ep:105, loss:0.00002, loss_test:0.07108, lr:8.35e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.634, tt:3353.256\n",
      "Ep:106, loss:0.00002, loss_test:0.07110, lr:8.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.650, tt:3386.523\n",
      "Ep:107, loss:0.00002, loss_test:0.07112, lr:8.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.649, tt:3418.110\n",
      "Ep:108, loss:0.00002, loss_test:0.07095, lr:8.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.630, tt:3447.647\n",
      "Ep:109, loss:0.00001, loss_test:0.07094, lr:8.02e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.620, tt:3478.163\n",
      "Ep:110, loss:0.00001, loss_test:0.07037, lr:7.94e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.622, tt:3510.043\n",
      "Ep:111, loss:0.00001, loss_test:0.07193, lr:7.86e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.630, tt:3542.558\n",
      "Ep:112, loss:0.00001, loss_test:0.07140, lr:7.78e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.610, tt:3571.937\n",
      "Ep:113, loss:0.00001, loss_test:0.07117, lr:7.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.579, tt:3599.974\n",
      "Ep:114, loss:0.00001, loss_test:0.07117, lr:7.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.554, tt:3628.705\n",
      "Ep:115, loss:0.00001, loss_test:0.07067, lr:7.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.560, tt:3660.988\n",
      "Ep:116, loss:0.00001, loss_test:0.07123, lr:7.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.565, tt:3693.108\n",
      "Ep:117, loss:0.00001, loss_test:0.07128, lr:7.40e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.575, tt:3725.792\n",
      "Ep:118, loss:0.00001, loss_test:0.07109, lr:7.32e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.559, tt:3755.495\n",
      "Ep:119, loss:0.00001, loss_test:0.07113, lr:7.25e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.564, tt:3787.687\n",
      "Ep:120, loss:0.00001, loss_test:0.07109, lr:7.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.576, tt:3820.670\n",
      "Ep:121, loss:0.00001, loss_test:0.07102, lr:7.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.576, tt:3852.290\n",
      "Ep:122, loss:0.00001, loss_test:0.07088, lr:7.03e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.598, tt:3886.600\n",
      "Ep:123, loss:0.00001, loss_test:0.07129, lr:6.96e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.605, tt:3919.003\n",
      "Ep:124, loss:0.00001, loss_test:0.07111, lr:6.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.603, tt:3950.423\n",
      "Ep:125, loss:0.00001, loss_test:0.07098, lr:6.83e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.602, tt:3981.850\n",
      "Ep:126, loss:0.00001, loss_test:0.07132, lr:6.76e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.612, tt:4014.780\n",
      "Ep:127, loss:0.00001, loss_test:0.07108, lr:6.69e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.624, tt:4047.866\n",
      "Ep:128, loss:0.00001, loss_test:0.07117, lr:6.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.626, tt:4079.716\n",
      "Ep:129, loss:0.00001, loss_test:0.07128, lr:6.56e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.627, tt:4111.540\n",
      "Ep:130, loss:0.00001, loss_test:0.07104, lr:6.49e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.632, tt:4143.836\n",
      "Ep:131, loss:0.00001, loss_test:0.07173, lr:6.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.634, tt:4175.631\n",
      "Ep:132, loss:0.00001, loss_test:0.07155, lr:6.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.638, tt:4207.829\n",
      "Ep:133, loss:0.00001, loss_test:0.07097, lr:6.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.643, tt:4240.120\n",
      "Ep:134, loss:0.00001, loss_test:0.07183, lr:6.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.650, tt:4272.747\n",
      "Ep:135, loss:0.00001, loss_test:0.07138, lr:6.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.655, tt:4305.072\n",
      "Ep:136, loss:0.00001, loss_test:0.07119, lr:6.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.662, tt:4337.644\n",
      "Ep:137, loss:0.00001, loss_test:0.07168, lr:6.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.666, tt:4369.844\n",
      "Ep:138, loss:0.00001, loss_test:0.07170, lr:5.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.673, tt:4402.529\n",
      "Ep:139, loss:0.00001, loss_test:0.07156, lr:5.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.675, tt:4434.491\n",
      "Ep:140, loss:0.00001, loss_test:0.07096, lr:5.87e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.671, tt:4465.641\n",
      "Ep:141, loss:0.00001, loss_test:0.07176, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.670, tt:4497.204\n",
      "Ep:142, loss:0.00001, loss_test:0.07149, lr:5.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.661, tt:4527.504\n",
      "Ep:143, loss:0.00001, loss_test:0.07151, lr:5.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.684, tt:4562.432\n",
      "Ep:144, loss:0.00001, loss_test:0.07144, lr:5.64e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.696, tt:4595.893\n",
      "Ep:145, loss:0.00001, loss_test:0.07115, lr:5.58e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.698, tt:4627.944\n",
      "Ep:146, loss:0.00001, loss_test:0.07183, lr:5.53e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.704, tt:4660.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.07185, lr:5.47e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.715, tt:4693.806\n",
      "Ep:148, loss:0.00001, loss_test:0.07138, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.719, tt:4726.124\n",
      "Ep:149, loss:0.00001, loss_test:0.07193, lr:5.36e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.719, tt:4757.859\n",
      "Ep:150, loss:0.00001, loss_test:0.07150, lr:5.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.724, tt:4790.386\n",
      "Ep:151, loss:0.00001, loss_test:0.07112, lr:5.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.731, tt:4823.133\n",
      "Ep:152, loss:0.00001, loss_test:0.07163, lr:5.20e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.727, tt:4854.275\n",
      "Ep:153, loss:0.00001, loss_test:0.07156, lr:5.15e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.731, tt:4886.574\n",
      "Ep:154, loss:0.00001, loss_test:0.07104, lr:5.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.731, tt:4918.241\n",
      "Ep:155, loss:0.00001, loss_test:0.07171, lr:5.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.737, tt:4951.040\n",
      "Ep:156, loss:0.00001, loss_test:0.07201, lr:5.00e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.739, tt:4983.072\n",
      "Ep:157, loss:0.00001, loss_test:0.07142, lr:4.95e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.734, tt:5013.963\n",
      "Ep:158, loss:0.00001, loss_test:0.07120, lr:4.90e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.728, tt:5044.691\n",
      "Ep:159, loss:0.00001, loss_test:0.07147, lr:4.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.729, tt:5076.659\n",
      "Ep:160, loss:0.00001, loss_test:0.07132, lr:4.80e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.741, tt:5110.258\n",
      "Ep:161, loss:0.00001, loss_test:0.07137, lr:4.75e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.750, tt:5143.453\n",
      "Ep:162, loss:0.00001, loss_test:0.07152, lr:4.71e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.747, tt:5174.713\n",
      "Ep:163, loss:0.00001, loss_test:0.07154, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.748, tt:5206.672\n",
      "Ep:164, loss:0.00001, loss_test:0.07150, lr:4.61e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.756, tt:5239.661\n",
      "Ep:165, loss:0.00001, loss_test:0.07110, lr:4.57e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.758, tt:5271.765\n",
      "Ep:166, loss:0.00001, loss_test:0.07114, lr:4.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.763, tt:5304.466\n",
      "Ep:167, loss:0.00001, loss_test:0.07161, lr:4.48e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.746, tt:5333.269\n",
      "Ep:168, loss:0.00001, loss_test:0.07139, lr:4.43e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.747, tt:5365.228\n",
      "Ep:169, loss:0.00001, loss_test:0.07127, lr:4.39e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.762, tt:5399.587\n",
      "Ep:170, loss:0.00001, loss_test:0.07103, lr:4.34e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.773, tt:5433.181\n",
      "Ep:171, loss:0.00001, loss_test:0.07113, lr:4.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.777, tt:5465.569\n",
      "Ep:172, loss:0.00001, loss_test:0.07124, lr:4.26e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.779, tt:5497.769\n",
      "Ep:173, loss:0.00001, loss_test:0.07115, lr:4.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.780, tt:5529.804\n",
      "Ep:174, loss:0.00001, loss_test:0.07127, lr:4.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.781, tt:5561.619\n",
      "Ep:175, loss:0.00001, loss_test:0.07112, lr:4.13e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.781, tt:5593.402\n",
      "Ep:176, loss:0.00001, loss_test:0.07115, lr:4.09e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.784, tt:5625.703\n",
      "Ep:177, loss:0.00001, loss_test:0.07115, lr:4.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.776, tt:5656.174\n",
      "Ep:178, loss:0.00001, loss_test:0.07141, lr:4.01e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.769, tt:5686.575\n",
      "Ep:179, loss:0.00001, loss_test:0.07119, lr:3.97e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.774, tt:5719.270\n",
      "Ep:180, loss:0.00001, loss_test:0.07127, lr:3.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.770, tt:5750.442\n",
      "Ep:181, loss:0.00001, loss_test:0.07114, lr:3.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.771, tt:5782.289\n",
      "Ep:182, loss:0.00001, loss_test:0.07104, lr:3.85e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.765, tt:5812.908\n",
      "Ep:183, loss:0.00001, loss_test:0.07140, lr:3.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.762, tt:5844.132\n",
      "Ep:184, loss:0.00001, loss_test:0.07115, lr:3.77e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.759, tt:5875.363\n",
      "Ep:185, loss:0.00001, loss_test:0.07116, lr:3.73e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.764, tt:5908.171\n",
      "Ep:186, loss:0.00001, loss_test:0.07110, lr:3.70e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.770, tt:5941.018\n",
      "Ep:187, loss:0.00001, loss_test:0.07109, lr:3.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.769, tt:5972.609\n",
      "Ep:188, loss:0.00001, loss_test:0.07096, lr:3.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.770, tt:6004.451\n",
      "Ep:189, loss:0.00001, loss_test:0.07117, lr:3.59e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.774, tt:6036.978\n",
      "Ep:190, loss:0.00001, loss_test:0.07106, lr:3.55e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.760, tt:6066.254\n",
      "Ep:191, loss:0.00001, loss_test:0.07132, lr:3.52e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.745, tt:6095.016\n",
      "Ep:192, loss:0.00001, loss_test:0.07134, lr:3.48e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.728, tt:6123.426\n",
      "Ep:193, loss:0.00001, loss_test:0.07110, lr:3.45e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.701, tt:6150.019\n",
      "Ep:194, loss:0.00001, loss_test:0.07111, lr:3.41e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.678, tt:6177.155\n",
      "Ep:195, loss:0.00001, loss_test:0.07099, lr:3.38e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.656, tt:6204.614\n",
      "Ep:196, loss:0.00001, loss_test:0.07112, lr:3.34e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.620, tt:6229.165\n",
      "Ep:197, loss:0.00001, loss_test:0.07119, lr:3.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.594, tt:6255.648\n",
      "Ep:198, loss:0.00001, loss_test:0.07140, lr:3.28e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.556, tt:6279.576\n",
      "Ep:199, loss:0.00001, loss_test:0.07106, lr:3.24e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.547, tt:6309.330\n",
      "Ep:200, loss:0.00001, loss_test:0.07125, lr:3.21e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.549, tt:6341.381\n",
      "Ep:201, loss:0.00001, loss_test:0.07128, lr:3.18e-03, fs:0.80473 (r=0.687,p=0.971),  time:31.546, tt:6372.388\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02001, lr:6.00e-02, fs:0.64062 (r=0.828,p=0.522),  time:25.883, tt:25.883\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02263, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.296, tt:52.591\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02468, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.850, tt:77.549\n",
      "Ep:3, loss:0.00005, loss_test:0.02517, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.664, tt:102.655\n",
      "Ep:4, loss:0.00005, loss_test:0.02488, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.405, tt:127.027\n",
      "Ep:5, loss:0.00005, loss_test:0.02402, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.573, tt:153.437\n",
      "Ep:6, loss:0.00005, loss_test:0.02284, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:25.645, tt:179.517\n",
      "Ep:7, loss:0.00004, loss_test:0.02157, lr:6.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:25.585, tt:204.676\n",
      "Ep:8, loss:0.00004, loss_test:0.02050, lr:6.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:25.464, tt:229.175\n",
      "Ep:9, loss:0.00004, loss_test:0.01996, lr:6.00e-02, fs:0.66667 (r=0.859,p=0.545),  time:25.454, tt:254.542\n",
      "Ep:10, loss:0.00004, loss_test:0.01985, lr:6.00e-02, fs:0.67206 (r=0.838,p=0.561),  time:25.419, tt:279.607\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01972, lr:6.00e-02, fs:0.67755 (r=0.838,p=0.568),  time:25.348, tt:304.173\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00004, loss_test:0.01937, lr:6.00e-02, fs:0.68033 (r=0.838,p=0.572),  time:25.326, tt:329.232\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01900, lr:6.00e-02, fs:0.68548 (r=0.859,p=0.570),  time:25.337, tt:354.721\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01882, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:25.312, tt:379.683\n",
      "Ep:15, loss:0.00004, loss_test:0.01869, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:25.231, tt:403.702\n",
      "Ep:16, loss:0.00003, loss_test:0.01849, lr:6.00e-02, fs:0.68441 (r=0.909,p=0.549),  time:25.196, tt:428.329\n",
      "Ep:17, loss:0.00003, loss_test:0.01824, lr:6.00e-02, fs:0.67954 (r=0.889,p=0.550),  time:25.140, tt:452.525\n",
      "Ep:18, loss:0.00003, loss_test:0.01799, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:25.158, tt:478.004\n",
      "Ep:19, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:25.179, tt:503.571\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:25.174, tt:528.655\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01740, lr:6.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:25.115, tt:552.541\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01720, lr:6.00e-02, fs:0.71311 (r=0.879,p=0.600),  time:25.171, tt:578.939\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:25.188, tt:604.522\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01685, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:25.196, tt:629.909\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01671, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:25.164, tt:654.258\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01656, lr:6.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:25.213, tt:680.738\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.72131 (r=0.889,p=0.607),  time:25.226, tt:706.322\n",
      "Ep:28, loss:0.00003, loss_test:0.01630, lr:6.00e-02, fs:0.73333 (r=0.889,p=0.624),  time:25.249, tt:732.228\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01619, lr:6.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:25.241, tt:757.230\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:25.275, tt:783.521\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:25.289, tt:809.250\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01591, lr:6.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:25.315, tt:835.386\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01580, lr:6.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:25.329, tt:861.176\n",
      "Ep:34, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:25.337, tt:886.807\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01559, lr:6.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:25.356, tt:912.825\n",
      "Ep:36, loss:0.00002, loss_test:0.01548, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:25.377, tt:938.943\n",
      "Ep:37, loss:0.00002, loss_test:0.01538, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:25.382, tt:964.502\n",
      "Ep:38, loss:0.00002, loss_test:0.01530, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:25.359, tt:989.008\n",
      "Ep:39, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:25.384, tt:1015.369\n",
      "Ep:40, loss:0.00002, loss_test:0.01517, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:25.394, tt:1041.159\n",
      "Ep:41, loss:0.00002, loss_test:0.01510, lr:6.00e-02, fs:0.76522 (r=0.889,p=0.672),  time:25.377, tt:1065.850\n",
      "Ep:42, loss:0.00002, loss_test:0.01503, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:25.391, tt:1091.805\n",
      "Ep:43, loss:0.00002, loss_test:0.01498, lr:6.00e-02, fs:0.75652 (r=0.879,p=0.664),  time:25.392, tt:1117.228\n",
      "Ep:44, loss:0.00002, loss_test:0.01495, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:25.380, tt:1142.099\n",
      "Ep:45, loss:0.00002, loss_test:0.01493, lr:6.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:25.400, tt:1168.406\n",
      "Ep:46, loss:0.00002, loss_test:0.01494, lr:5.94e-02, fs:0.76652 (r=0.879,p=0.680),  time:25.391, tt:1193.393\n",
      "Ep:47, loss:0.00002, loss_test:0.01491, lr:5.88e-02, fs:0.76652 (r=0.879,p=0.680),  time:25.381, tt:1218.268\n",
      "Ep:48, loss:0.00002, loss_test:0.01486, lr:5.82e-02, fs:0.76106 (r=0.869,p=0.677),  time:25.385, tt:1243.852\n",
      "Ep:49, loss:0.00002, loss_test:0.01483, lr:5.76e-02, fs:0.75556 (r=0.859,p=0.675),  time:25.385, tt:1269.228\n",
      "Ep:50, loss:0.00002, loss_test:0.01479, lr:5.71e-02, fs:0.75000 (r=0.848,p=0.672),  time:25.395, tt:1295.164\n",
      "Ep:51, loss:0.00002, loss_test:0.01474, lr:5.65e-02, fs:0.75000 (r=0.848,p=0.672),  time:25.388, tt:1320.176\n",
      "Ep:52, loss:0.00002, loss_test:0.01472, lr:5.59e-02, fs:0.75336 (r=0.848,p=0.677),  time:25.385, tt:1345.431\n",
      "Ep:53, loss:0.00002, loss_test:0.01469, lr:5.54e-02, fs:0.74545 (r=0.828,p=0.678),  time:25.383, tt:1370.705\n",
      "Ep:54, loss:0.00002, loss_test:0.01465, lr:5.48e-02, fs:0.75229 (r=0.828,p=0.689),  time:25.389, tt:1396.381\n",
      "Ep:55, loss:0.00002, loss_test:0.01465, lr:5.43e-02, fs:0.74654 (r=0.818,p=0.686),  time:25.376, tt:1421.061\n",
      "Ep:56, loss:0.00002, loss_test:0.01464, lr:5.37e-02, fs:0.74654 (r=0.818,p=0.686),  time:25.358, tt:1445.428\n",
      "Ep:57, loss:0.00001, loss_test:0.01462, lr:5.32e-02, fs:0.74654 (r=0.818,p=0.686),  time:25.375, tt:1471.751\n",
      "Ep:58, loss:0.00001, loss_test:0.01459, lr:5.27e-02, fs:0.74654 (r=0.818,p=0.686),  time:25.381, tt:1497.450\n",
      "Ep:59, loss:0.00001, loss_test:0.01457, lr:5.21e-02, fs:0.74419 (r=0.808,p=0.690),  time:25.370, tt:1522.173\n",
      "Ep:60, loss:0.00001, loss_test:0.01454, lr:5.16e-02, fs:0.74766 (r=0.808,p=0.696),  time:25.352, tt:1546.465\n",
      "Ep:61, loss:0.00001, loss_test:0.01455, lr:5.11e-02, fs:0.74766 (r=0.808,p=0.696),  time:25.350, tt:1571.687\n",
      "Ep:62, loss:0.00001, loss_test:0.01454, lr:5.06e-02, fs:0.75117 (r=0.808,p=0.702),  time:25.363, tt:1597.838\n",
      "Ep:63, loss:0.00001, loss_test:0.01452, lr:5.01e-02, fs:0.75472 (r=0.808,p=0.708),  time:25.373, tt:1623.852\n",
      "Ep:64, loss:0.00001, loss_test:0.01450, lr:4.96e-02, fs:0.75472 (r=0.808,p=0.708),  time:25.358, tt:1648.255\n",
      "Ep:65, loss:0.00001, loss_test:0.01448, lr:4.91e-02, fs:0.75472 (r=0.808,p=0.708),  time:25.356, tt:1673.482\n",
      "Ep:66, loss:0.00001, loss_test:0.01448, lr:4.86e-02, fs:0.75472 (r=0.808,p=0.708),  time:25.339, tt:1697.715\n",
      "Ep:67, loss:0.00001, loss_test:0.01447, lr:4.81e-02, fs:0.76056 (r=0.818,p=0.711),  time:25.353, tt:1724.030\n",
      "Ep:68, loss:0.00001, loss_test:0.01445, lr:4.76e-02, fs:0.76415 (r=0.818,p=0.717),  time:25.353, tt:1749.366\n",
      "Ep:69, loss:0.00001, loss_test:0.01445, lr:4.71e-02, fs:0.76777 (r=0.818,p=0.723),  time:25.369, tt:1775.828\n",
      "Ep:70, loss:0.00001, loss_test:0.01445, lr:4.67e-02, fs:0.76777 (r=0.818,p=0.723),  time:25.394, tt:1803.003\n",
      "Ep:71, loss:0.00001, loss_test:0.01444, lr:4.62e-02, fs:0.77143 (r=0.818,p=0.730),  time:25.400, tt:1828.766\n",
      "Ep:72, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.77512 (r=0.818,p=0.736),  time:25.420, tt:1855.652\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.77885 (r=0.818,p=0.743),  time:25.421, tt:1881.121\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.77885 (r=0.818,p=0.743),  time:25.421, tt:1906.587\n",
      "Ep:75, loss:0.00001, loss_test:0.01447, lr:4.57e-02, fs:0.77885 (r=0.818,p=0.743),  time:25.436, tt:1933.159\n",
      "Ep:76, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.78261 (r=0.818,p=0.750),  time:25.429, tt:1958.002\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78261 (r=0.818,p=0.750),  time:25.431, tt:1983.647\n",
      "Ep:78, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78261 (r=0.818,p=0.750),  time:25.429, tt:2008.918\n",
      "Ep:79, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.78261 (r=0.818,p=0.750),  time:25.426, tt:2034.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.78261 (r=0.818,p=0.750),  time:25.435, tt:2060.259\n",
      "Ep:81, loss:0.00001, loss_test:0.01442, lr:4.57e-02, fs:0.78431 (r=0.808,p=0.762),  time:25.451, tt:2086.982\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01440, lr:4.57e-02, fs:0.78431 (r=0.808,p=0.762),  time:25.467, tt:2113.784\n",
      "Ep:83, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.477, tt:2140.104\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.500, tt:2167.492\n",
      "Ep:85, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.502, tt:2193.170\n",
      "Ep:86, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.508, tt:2219.201\n",
      "Ep:87, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.520, tt:2245.759\n",
      "Ep:88, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.527, tt:2271.938\n",
      "Ep:89, loss:0.00001, loss_test:0.01440, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.536, tt:2298.215\n",
      "Ep:90, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.78818 (r=0.808,p=0.769),  time:25.545, tt:2324.566\n",
      "Ep:91, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.79208 (r=0.808,p=0.777),  time:25.549, tt:2350.469\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01442, lr:4.57e-02, fs:0.79208 (r=0.808,p=0.777),  time:25.544, tt:2375.580\n",
      "Ep:93, loss:0.00001, loss_test:0.01441, lr:4.57e-02, fs:0.79208 (r=0.808,p=0.777),  time:25.550, tt:2401.686\n",
      "Ep:94, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.79602 (r=0.808,p=0.784),  time:25.563, tt:2428.519\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.79602 (r=0.808,p=0.784),  time:25.572, tt:2454.907\n",
      "Ep:96, loss:0.00001, loss_test:0.01442, lr:4.57e-02, fs:0.79602 (r=0.808,p=0.784),  time:25.588, tt:2482.050\n",
      "Ep:97, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.79602 (r=0.808,p=0.784),  time:25.592, tt:2507.973\n",
      "Ep:98, loss:0.00001, loss_test:0.01445, lr:4.57e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.577, tt:2532.108\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.586, tt:2558.617\n",
      "Ep:100, loss:0.00001, loss_test:0.01443, lr:4.57e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.596, tt:2585.159\n",
      "Ep:101, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.599, tt:2611.068\n",
      "Ep:102, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.80402 (r=0.808,p=0.800),  time:25.602, tt:2637.021\n",
      "Ep:103, loss:0.00001, loss_test:0.01447, lr:4.57e-02, fs:0.81633 (r=0.808,p=0.825),  time:25.586, tt:2660.895\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.01444, lr:4.57e-02, fs:0.81633 (r=0.808,p=0.825),  time:25.587, tt:2686.659\n",
      "Ep:105, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.81633 (r=0.808,p=0.825),  time:25.591, tt:2712.622\n",
      "Ep:106, loss:0.00001, loss_test:0.01450, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.588, tt:2737.905\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.81633 (r=0.808,p=0.825),  time:25.594, tt:2764.124\n",
      "Ep:108, loss:0.00001, loss_test:0.01447, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.591, tt:2789.421\n",
      "Ep:109, loss:0.00001, loss_test:0.01449, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.586, tt:2814.414\n",
      "Ep:110, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.581, tt:2839.489\n",
      "Ep:111, loss:0.00001, loss_test:0.01448, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.581, tt:2865.104\n",
      "Ep:112, loss:0.00001, loss_test:0.01446, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.573, tt:2889.748\n",
      "Ep:113, loss:0.00001, loss_test:0.01450, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.571, tt:2915.120\n",
      "Ep:114, loss:0.00001, loss_test:0.01453, lr:4.57e-02, fs:0.82051 (r=0.808,p=0.833),  time:25.582, tt:2941.914\n",
      "Ep:115, loss:0.00001, loss_test:0.01453, lr:4.57e-02, fs:0.82474 (r=0.808,p=0.842),  time:25.582, tt:2967.545\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.01456, lr:4.57e-02, fs:0.82474 (r=0.808,p=0.842),  time:25.577, tt:2992.557\n",
      "Ep:117, loss:0.00001, loss_test:0.01458, lr:4.57e-02, fs:0.82902 (r=0.808,p=0.851),  time:25.570, tt:3017.268\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00001, loss_test:0.01457, lr:4.57e-02, fs:0.82902 (r=0.808,p=0.851),  time:25.569, tt:3042.695\n",
      "Ep:119, loss:0.00001, loss_test:0.01457, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.569, tt:3068.234\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.01458, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.566, tt:3093.437\n",
      "Ep:121, loss:0.00001, loss_test:0.01458, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.556, tt:3117.784\n",
      "Ep:122, loss:0.00001, loss_test:0.01457, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.546, tt:3142.119\n",
      "Ep:123, loss:0.00001, loss_test:0.01461, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.544, tt:3167.482\n",
      "Ep:124, loss:0.00001, loss_test:0.01461, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.544, tt:3192.987\n",
      "Ep:125, loss:0.00001, loss_test:0.01462, lr:4.57e-02, fs:0.83333 (r=0.808,p=0.860),  time:25.543, tt:3218.453\n",
      "Ep:126, loss:0.00001, loss_test:0.01466, lr:4.57e-02, fs:0.84211 (r=0.808,p=0.879),  time:25.542, tt:3243.888\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00001, loss_test:0.01468, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.549, tt:3270.230\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00001, loss_test:0.01468, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.549, tt:3295.872\n",
      "Ep:129, loss:0.00001, loss_test:0.01468, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.538, tt:3319.882\n",
      "Ep:130, loss:0.00001, loss_test:0.01471, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.537, tt:3345.389\n",
      "Ep:131, loss:0.00001, loss_test:0.01474, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.536, tt:3370.752\n",
      "Ep:132, loss:0.00001, loss_test:0.01475, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.529, tt:3395.336\n",
      "Ep:133, loss:0.00001, loss_test:0.01474, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.530, tt:3421.076\n",
      "Ep:134, loss:0.00001, loss_test:0.01477, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.538, tt:3447.598\n",
      "Ep:135, loss:0.00001, loss_test:0.01482, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.535, tt:3472.701\n",
      "Ep:136, loss:0.00001, loss_test:0.01483, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.531, tt:3497.707\n",
      "Ep:137, loss:0.00001, loss_test:0.01480, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.532, tt:3523.378\n",
      "Ep:138, loss:0.00001, loss_test:0.01482, lr:4.57e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.535, tt:3549.347\n",
      "Ep:139, loss:0.00001, loss_test:0.01485, lr:4.53e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.542, tt:3575.866\n",
      "Ep:140, loss:0.00001, loss_test:0.01486, lr:4.48e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.547, tt:3602.170\n",
      "Ep:141, loss:0.00001, loss_test:0.01492, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.549, tt:3627.908\n",
      "##########Best model found so far##########\n",
      "Ep:142, loss:0.00001, loss_test:0.01494, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.551, tt:3653.783\n",
      "Ep:143, loss:0.00001, loss_test:0.01492, lr:4.44e-02, fs:0.84656 (r=0.808,p=0.889),  time:25.554, tt:3679.834\n",
      "Ep:144, loss:0.00001, loss_test:0.01497, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.561, tt:3706.306\n",
      "Ep:145, loss:0.00001, loss_test:0.01501, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.551, tt:3730.469\n",
      "Ep:146, loss:0.00001, loss_test:0.01503, lr:4.44e-02, fs:0.85106 (r=0.808,p=0.899),  time:25.547, tt:3755.440\n",
      "Ep:147, loss:0.00001, loss_test:0.01505, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.557, tt:3782.396\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00001, loss_test:0.01507, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.567, tt:3809.439\n",
      "Ep:149, loss:0.00001, loss_test:0.01510, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.568, tt:3835.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:150, loss:0.00001, loss_test:0.01511, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.564, tt:3860.220\n",
      "Ep:151, loss:0.00001, loss_test:0.01514, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.564, tt:3885.767\n",
      "Ep:152, loss:0.00001, loss_test:0.01518, lr:4.44e-02, fs:0.85561 (r=0.808,p=0.909),  time:25.566, tt:3911.549\n",
      "Ep:153, loss:0.00001, loss_test:0.01519, lr:4.44e-02, fs:0.86022 (r=0.808,p=0.920),  time:25.568, tt:3937.432\n",
      "##########Best model found so far##########\n",
      "Ep:154, loss:0.00000, loss_test:0.01518, lr:4.44e-02, fs:0.86022 (r=0.808,p=0.920),  time:25.570, tt:3963.377\n",
      "Ep:155, loss:0.00000, loss_test:0.01523, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.575, tt:3989.755\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00000, loss_test:0.01525, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.570, tt:4014.446\n",
      "Ep:157, loss:0.00000, loss_test:0.01528, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.577, tt:4041.169\n",
      "Ep:158, loss:0.00000, loss_test:0.01530, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.586, tt:4068.235\n",
      "Ep:159, loss:0.00000, loss_test:0.01530, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.592, tt:4094.754\n",
      "Ep:160, loss:0.00000, loss_test:0.01531, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.593, tt:4120.513\n",
      "Ep:161, loss:0.00000, loss_test:0.01536, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.591, tt:4145.787\n",
      "Ep:162, loss:0.00000, loss_test:0.01542, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.588, tt:4170.882\n",
      "Ep:163, loss:0.00000, loss_test:0.01544, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.589, tt:4196.637\n",
      "Ep:164, loss:0.00000, loss_test:0.01545, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.594, tt:4223.038\n",
      "Ep:165, loss:0.00000, loss_test:0.01547, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.598, tt:4249.197\n",
      "Ep:166, loss:0.00000, loss_test:0.01549, lr:4.44e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.598, tt:4274.873\n",
      "Ep:167, loss:0.00000, loss_test:0.01551, lr:4.39e-02, fs:0.86486 (r=0.808,p=0.930),  time:25.598, tt:4300.541\n",
      "Ep:168, loss:0.00000, loss_test:0.01555, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.599, tt:4326.174\n",
      "##########Best model found so far##########\n",
      "Ep:169, loss:0.00000, loss_test:0.01558, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.600, tt:4352.035\n",
      "Ep:170, loss:0.00000, loss_test:0.01560, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.601, tt:4377.830\n",
      "Ep:171, loss:0.00000, loss_test:0.01562, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.600, tt:4403.274\n",
      "Ep:172, loss:0.00000, loss_test:0.01566, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.603, tt:4429.249\n",
      "Ep:173, loss:0.00000, loss_test:0.01568, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.605, tt:4455.197\n",
      "Ep:174, loss:0.00000, loss_test:0.01570, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.606, tt:4481.130\n",
      "Ep:175, loss:0.00000, loss_test:0.01571, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.616, tt:4508.428\n",
      "Ep:176, loss:0.00000, loss_test:0.01573, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.622, tt:4535.024\n",
      "Ep:177, loss:0.00000, loss_test:0.01577, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.619, tt:4560.204\n",
      "Ep:178, loss:0.00000, loss_test:0.01577, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.621, tt:4586.174\n",
      "Ep:179, loss:0.00000, loss_test:0.01582, lr:4.35e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.619, tt:4611.333\n",
      "Ep:180, loss:0.00000, loss_test:0.01584, lr:4.31e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.621, tt:4637.315\n",
      "Ep:181, loss:0.00000, loss_test:0.01586, lr:4.26e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.623, tt:4663.396\n",
      "Ep:182, loss:0.00000, loss_test:0.01588, lr:4.22e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.618, tt:4688.042\n",
      "Ep:183, loss:0.00000, loss_test:0.01592, lr:4.18e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.626, tt:4715.117\n",
      "Ep:184, loss:0.00000, loss_test:0.01593, lr:4.14e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.623, tt:4740.303\n",
      "Ep:185, loss:0.00000, loss_test:0.01593, lr:4.10e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.619, tt:4765.162\n",
      "Ep:186, loss:0.00000, loss_test:0.01596, lr:4.05e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.608, tt:4788.674\n",
      "Ep:187, loss:0.00000, loss_test:0.01598, lr:4.01e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.605, tt:4813.778\n",
      "Ep:188, loss:0.00000, loss_test:0.01600, lr:3.97e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.594, tt:4837.350\n",
      "Ep:189, loss:0.00000, loss_test:0.01603, lr:3.93e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.575, tt:4859.213\n",
      "Ep:190, loss:0.00000, loss_test:0.01607, lr:3.89e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.566, tt:4883.191\n",
      "Ep:191, loss:0.00000, loss_test:0.01609, lr:3.86e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.564, tt:4908.253\n",
      "Ep:192, loss:0.00000, loss_test:0.01609, lr:3.82e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.539, tt:4928.950\n",
      "Ep:193, loss:0.00000, loss_test:0.01612, lr:3.78e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.519, tt:4950.625\n",
      "Ep:194, loss:0.00000, loss_test:0.01615, lr:3.74e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.503, tt:4973.141\n",
      "Ep:195, loss:0.00000, loss_test:0.01616, lr:3.70e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.497, tt:4997.453\n",
      "Ep:196, loss:0.00000, loss_test:0.01619, lr:3.67e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.501, tt:5023.652\n",
      "Ep:197, loss:0.00000, loss_test:0.01621, lr:3.63e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.496, tt:5048.150\n",
      "Ep:198, loss:0.00000, loss_test:0.01623, lr:3.59e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.495, tt:5073.580\n",
      "Ep:199, loss:0.00000, loss_test:0.01625, lr:3.56e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.503, tt:5100.676\n",
      "Ep:200, loss:0.00000, loss_test:0.01628, lr:3.52e-02, fs:0.86957 (r=0.808,p=0.941),  time:25.501, tt:5125.800\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14059, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.648, tt:26.648\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13862, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:26.369, tt:52.738\n",
      "Ep:2, loss:0.00027, loss_test:0.13468, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:26.738, tt:80.213\n",
      "Ep:3, loss:0.00026, loss_test:0.12774, lr:1.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:26.853, tt:107.411\n",
      "Ep:4, loss:0.00025, loss_test:0.11818, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:26.870, tt:134.351\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11449, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:26.711, tt:160.266\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11443, lr:1.00e-02, fs:0.69955 (r=0.788,p=0.629),  time:26.765, tt:187.355\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11520, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:26.766, tt:214.125\n",
      "Ep:8, loss:0.00022, loss_test:0.11516, lr:1.00e-02, fs:0.69959 (r=0.859,p=0.590),  time:26.710, tt:240.391\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.11193, lr:1.00e-02, fs:0.70248 (r=0.859,p=0.594),  time:26.669, tt:266.693\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10801, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:26.704, tt:293.739\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10702, lr:1.00e-02, fs:0.70796 (r=0.808,p=0.630),  time:26.648, tt:319.774\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10752, lr:1.00e-02, fs:0.70742 (r=0.818,p=0.623),  time:26.613, tt:345.964\n",
      "Ep:13, loss:0.00020, loss_test:0.10486, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:26.588, tt:372.239\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.10225, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:26.667, tt:400.001\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:15, loss:0.00019, loss_test:0.10177, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:26.655, tt:426.482\n",
      "Ep:16, loss:0.00018, loss_test:0.10117, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:26.602, tt:452.234\n",
      "Ep:17, loss:0.00017, loss_test:0.09944, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:26.605, tt:478.881\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09866, lr:1.00e-02, fs:0.71930 (r=0.828,p=0.636),  time:26.639, tt:506.139\n",
      "Ep:19, loss:0.00016, loss_test:0.09959, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:26.628, tt:532.563\n",
      "Ep:20, loss:0.00016, loss_test:0.09756, lr:1.00e-02, fs:0.72398 (r=0.808,p=0.656),  time:26.625, tt:559.118\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.09704, lr:1.00e-02, fs:0.72889 (r=0.828,p=0.651),  time:26.599, tt:585.171\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.09681, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:26.563, tt:610.940\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.09420, lr:1.00e-02, fs:0.73874 (r=0.828,p=0.667),  time:26.560, tt:637.438\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.09423, lr:1.00e-02, fs:0.74775 (r=0.838,p=0.675),  time:26.542, tt:663.554\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.09274, lr:1.00e-02, fs:0.75113 (r=0.838,p=0.680),  time:26.578, tt:691.016\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.09131, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:26.598, tt:718.153\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.09121, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:26.616, tt:745.261\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00013, loss_test:0.08896, lr:1.00e-02, fs:0.77934 (r=0.838,p=0.728),  time:26.620, tt:771.991\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.08864, lr:1.00e-02, fs:0.76699 (r=0.798,p=0.738),  time:26.622, tt:798.657\n",
      "Ep:30, loss:0.00012, loss_test:0.08641, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:26.654, tt:826.272\n",
      "Ep:31, loss:0.00011, loss_test:0.08730, lr:1.00e-02, fs:0.76555 (r=0.808,p=0.727),  time:26.666, tt:853.311\n",
      "Ep:32, loss:0.00011, loss_test:0.08515, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:26.633, tt:878.892\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.08341, lr:1.00e-02, fs:0.81188 (r=0.828,p=0.796),  time:26.641, tt:905.786\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.08470, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:26.622, tt:931.770\n",
      "Ep:35, loss:0.00010, loss_test:0.08037, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:26.655, tt:959.598\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00010, loss_test:0.08232, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:26.659, tt:986.371\n",
      "Ep:37, loss:0.00009, loss_test:0.07850, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:26.686, tt:1014.055\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00009, loss_test:0.07842, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:26.681, tt:1040.572\n",
      "Ep:39, loss:0.00009, loss_test:0.07739, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:26.683, tt:1067.327\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00009, loss_test:0.07601, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:26.681, tt:1093.939\n",
      "Ep:41, loss:0.00008, loss_test:0.07698, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:26.698, tt:1121.310\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00008, loss_test:0.07519, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:26.695, tt:1147.864\n",
      "Ep:43, loss:0.00008, loss_test:0.07448, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:26.688, tt:1174.291\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.07251, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:26.700, tt:1201.497\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07401, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:26.697, tt:1228.083\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.07108, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:26.750, tt:1257.270\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00007, loss_test:0.07275, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:26.765, tt:1284.702\n",
      "Ep:48, loss:0.00007, loss_test:0.07097, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.779, tt:1312.193\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.07008, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:26.783, tt:1339.162\n",
      "Ep:50, loss:0.00006, loss_test:0.06902, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.792, tt:1366.381\n",
      "Ep:51, loss:0.00006, loss_test:0.06935, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.808, tt:1394.013\n",
      "Ep:52, loss:0.00006, loss_test:0.07011, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:26.813, tt:1421.084\n",
      "Ep:53, loss:0.00006, loss_test:0.06757, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:26.838, tt:1449.260\n",
      "Ep:54, loss:0.00006, loss_test:0.06820, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.831, tt:1475.696\n",
      "Ep:55, loss:0.00005, loss_test:0.06725, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.845, tt:1503.323\n",
      "Ep:56, loss:0.00005, loss_test:0.06747, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.851, tt:1530.534\n",
      "Ep:57, loss:0.00005, loss_test:0.06788, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.866, tt:1558.202\n",
      "Ep:58, loss:0.00005, loss_test:0.06664, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.869, tt:1585.298\n",
      "Ep:59, loss:0.00005, loss_test:0.06757, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:26.885, tt:1613.125\n",
      "Ep:60, loss:0.00005, loss_test:0.06636, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:26.888, tt:1640.144\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00005, loss_test:0.06669, lr:9.90e-03, fs:0.88542 (r=0.859,p=0.914),  time:26.867, tt:1665.739\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00005, loss_test:0.06757, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:26.864, tt:1692.402\n",
      "Ep:63, loss:0.00005, loss_test:0.06550, lr:9.90e-03, fs:0.88660 (r=0.869,p=0.905),  time:26.858, tt:1718.898\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.06613, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:26.861, tt:1745.970\n",
      "Ep:65, loss:0.00004, loss_test:0.06562, lr:9.90e-03, fs:0.89474 (r=0.859,p=0.934),  time:26.841, tt:1771.503\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.06625, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:26.850, tt:1798.926\n",
      "Ep:67, loss:0.00004, loss_test:0.06622, lr:9.90e-03, fs:0.89362 (r=0.848,p=0.944),  time:26.848, tt:1825.673\n",
      "Ep:68, loss:0.00004, loss_test:0.06466, lr:9.90e-03, fs:0.89583 (r=0.869,p=0.925),  time:26.873, tt:1854.213\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00004, loss_test:0.06780, lr:9.90e-03, fs:0.87958 (r=0.848,p=0.913),  time:26.898, tt:1882.886\n",
      "Ep:70, loss:0.00004, loss_test:0.06404, lr:9.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:26.911, tt:1910.698\n",
      "Ep:71, loss:0.00004, loss_test:0.06752, lr:9.90e-03, fs:0.89005 (r=0.859,p=0.924),  time:26.920, tt:1938.267\n",
      "Ep:72, loss:0.00004, loss_test:0.06356, lr:9.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:26.924, tt:1965.449\n",
      "Ep:73, loss:0.00004, loss_test:0.06762, lr:9.90e-03, fs:0.89005 (r=0.859,p=0.924),  time:26.935, tt:1993.212\n",
      "Ep:74, loss:0.00004, loss_test:0.06252, lr:9.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:26.926, tt:2019.471\n",
      "Ep:75, loss:0.00003, loss_test:0.06870, lr:9.90e-03, fs:0.87701 (r=0.828,p=0.932),  time:26.931, tt:2046.727\n",
      "Ep:76, loss:0.00003, loss_test:0.06366, lr:9.90e-03, fs:0.89119 (r=0.869,p=0.915),  time:26.926, tt:2073.332\n",
      "Ep:77, loss:0.00003, loss_test:0.06771, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:26.921, tt:2099.819\n",
      "Ep:78, loss:0.00003, loss_test:0.06447, lr:9.90e-03, fs:0.88421 (r=0.848,p=0.923),  time:26.920, tt:2126.714\n",
      "Ep:79, loss:0.00003, loss_test:0.06681, lr:9.90e-03, fs:0.89947 (r=0.859,p=0.944),  time:26.923, tt:2153.854\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00003, loss_test:0.06671, lr:9.90e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.932, tt:2181.493\n",
      "Ep:81, loss:0.00003, loss_test:0.06357, lr:9.90e-03, fs:0.89583 (r=0.869,p=0.925),  time:26.957, tt:2210.505\n",
      "Ep:82, loss:0.00003, loss_test:0.06893, lr:9.90e-03, fs:0.88298 (r=0.838,p=0.933),  time:26.972, tt:2238.665\n",
      "Ep:83, loss:0.00003, loss_test:0.06462, lr:9.90e-03, fs:0.88889 (r=0.848,p=0.933),  time:26.986, tt:2266.800\n",
      "Ep:84, loss:0.00003, loss_test:0.06515, lr:9.90e-03, fs:0.89947 (r=0.859,p=0.944),  time:27.002, tt:2295.144\n",
      "Ep:85, loss:0.00003, loss_test:0.06632, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.021, tt:2323.778\n",
      "Ep:86, loss:0.00003, loss_test:0.06395, lr:9.90e-03, fs:0.89947 (r=0.859,p=0.944),  time:27.027, tt:2351.341\n",
      "Ep:87, loss:0.00003, loss_test:0.06769, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.027, tt:2378.376\n",
      "Ep:88, loss:0.00003, loss_test:0.06569, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.050, tt:2407.407\n",
      "Ep:89, loss:0.00002, loss_test:0.06597, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.067, tt:2435.997\n",
      "Ep:90, loss:0.00002, loss_test:0.06629, lr:9.90e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.076, tt:2463.946\n",
      "Ep:91, loss:0.00002, loss_test:0.06518, lr:9.80e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.074, tt:2490.824\n",
      "Ep:92, loss:0.00002, loss_test:0.06658, lr:9.70e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.084, tt:2518.787\n",
      "Ep:93, loss:0.00002, loss_test:0.06656, lr:9.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.084, tt:2545.850\n",
      "Ep:94, loss:0.00002, loss_test:0.06489, lr:9.51e-03, fs:0.89362 (r=0.848,p=0.944),  time:27.078, tt:2572.381\n",
      "Ep:95, loss:0.00002, loss_test:0.06651, lr:9.41e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.093, tt:2600.960\n",
      "Ep:96, loss:0.00002, loss_test:0.06528, lr:9.32e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.112, tt:2629.903\n",
      "Ep:97, loss:0.00002, loss_test:0.06515, lr:9.23e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.122, tt:2657.942\n",
      "Ep:98, loss:0.00002, loss_test:0.06579, lr:9.14e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.131, tt:2685.941\n",
      "Ep:99, loss:0.00002, loss_test:0.06578, lr:9.04e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.135, tt:2713.518\n",
      "Ep:100, loss:0.00002, loss_test:0.06603, lr:8.95e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.137, tt:2740.852\n",
      "Ep:101, loss:0.00002, loss_test:0.06620, lr:8.86e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.148, tt:2769.052\n",
      "Ep:102, loss:0.00002, loss_test:0.06472, lr:8.78e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.156, tt:2797.096\n",
      "Ep:103, loss:0.00002, loss_test:0.06688, lr:8.69e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.166, tt:2825.292\n",
      "Ep:104, loss:0.00002, loss_test:0.06495, lr:8.60e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.177, tt:2853.607\n",
      "Ep:105, loss:0.00002, loss_test:0.06602, lr:8.51e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.178, tt:2880.915\n",
      "Ep:106, loss:0.00002, loss_test:0.06632, lr:8.43e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.170, tt:2907.178\n",
      "Ep:107, loss:0.00002, loss_test:0.06526, lr:8.35e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.185, tt:2935.961\n",
      "Ep:108, loss:0.00002, loss_test:0.06607, lr:8.26e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.194, tt:2964.129\n",
      "Ep:109, loss:0.00002, loss_test:0.06440, lr:8.18e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.204, tt:2992.424\n",
      "Ep:110, loss:0.00002, loss_test:0.06687, lr:8.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.207, tt:3020.011\n",
      "Ep:111, loss:0.00002, loss_test:0.06570, lr:8.02e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.211, tt:3047.658\n",
      "Ep:112, loss:0.00002, loss_test:0.06528, lr:7.94e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.213, tt:3075.028\n",
      "Ep:113, loss:0.00002, loss_test:0.06592, lr:7.86e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.192, tt:3099.903\n",
      "Ep:114, loss:0.00001, loss_test:0.06529, lr:7.78e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.200, tt:3127.995\n",
      "Ep:115, loss:0.00001, loss_test:0.06635, lr:7.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.209, tt:3156.186\n",
      "Ep:116, loss:0.00001, loss_test:0.06602, lr:7.62e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.212, tt:3183.770\n",
      "Ep:117, loss:0.00001, loss_test:0.06529, lr:7.55e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.230, tt:3213.141\n",
      "Ep:118, loss:0.00001, loss_test:0.06606, lr:7.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.250, tt:3242.809\n",
      "Ep:119, loss:0.00001, loss_test:0.06519, lr:7.40e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.249, tt:3269.848\n",
      "Ep:120, loss:0.00001, loss_test:0.06576, lr:7.32e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.278, tt:3300.607\n",
      "Ep:121, loss:0.00001, loss_test:0.06497, lr:7.25e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.285, tt:3328.779\n",
      "Ep:122, loss:0.00001, loss_test:0.06634, lr:7.18e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.286, tt:3356.234\n",
      "Ep:123, loss:0.00001, loss_test:0.06575, lr:7.11e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.280, tt:3382.773\n",
      "Ep:124, loss:0.00001, loss_test:0.06556, lr:7.03e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.279, tt:3409.856\n",
      "Ep:125, loss:0.00001, loss_test:0.06747, lr:6.96e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.276, tt:3436.776\n",
      "Ep:126, loss:0.00001, loss_test:0.06546, lr:6.89e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.273, tt:3463.719\n",
      "Ep:127, loss:0.00001, loss_test:0.06584, lr:6.83e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.270, tt:3490.520\n",
      "Ep:128, loss:0.00001, loss_test:0.06701, lr:6.76e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.274, tt:3518.390\n",
      "Ep:129, loss:0.00001, loss_test:0.06536, lr:6.69e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.283, tt:3546.810\n",
      "Ep:130, loss:0.00001, loss_test:0.06608, lr:6.62e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.284, tt:3574.215\n",
      "Ep:131, loss:0.00001, loss_test:0.06624, lr:6.56e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.285, tt:3601.553\n",
      "Ep:132, loss:0.00001, loss_test:0.06491, lr:6.49e-03, fs:0.88770 (r=0.838,p=0.943),  time:27.285, tt:3628.860\n",
      "Ep:133, loss:0.00001, loss_test:0.06679, lr:6.43e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.309, tt:3659.405\n",
      "Ep:134, loss:0.00001, loss_test:0.06560, lr:6.36e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.317, tt:3687.771\n",
      "Ep:135, loss:0.00001, loss_test:0.06529, lr:6.30e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.301, tt:3712.875\n",
      "Ep:136, loss:0.00001, loss_test:0.06652, lr:6.24e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.294, tt:3739.210\n",
      "Ep:137, loss:0.00001, loss_test:0.06533, lr:6.17e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.272, tt:3763.494\n",
      "Ep:138, loss:0.00001, loss_test:0.06568, lr:6.11e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.259, tt:3789.005\n",
      "Ep:139, loss:0.00001, loss_test:0.06579, lr:6.05e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.243, tt:3814.012\n",
      "Ep:140, loss:0.00001, loss_test:0.06538, lr:5.99e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.248, tt:3842.023\n",
      "Ep:141, loss:0.00001, loss_test:0.06567, lr:5.93e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.243, tt:3868.475\n",
      "Ep:142, loss:0.00001, loss_test:0.06600, lr:5.87e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.232, tt:3894.225\n",
      "Ep:143, loss:0.00001, loss_test:0.06540, lr:5.81e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.232, tt:3921.352\n",
      "Ep:144, loss:0.00001, loss_test:0.06559, lr:5.75e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.234, tt:3948.949\n",
      "Ep:145, loss:0.00001, loss_test:0.06583, lr:5.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.246, tt:3977.856\n",
      "Ep:146, loss:0.00001, loss_test:0.06593, lr:5.64e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.250, tt:4005.723\n",
      "Ep:147, loss:0.00001, loss_test:0.06616, lr:5.58e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.249, tt:4032.882\n",
      "Ep:148, loss:0.00001, loss_test:0.06532, lr:5.53e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.244, tt:4059.398\n",
      "Ep:149, loss:0.00001, loss_test:0.06622, lr:5.47e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.236, tt:4085.424\n",
      "Ep:150, loss:0.00001, loss_test:0.06587, lr:5.42e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.232, tt:4112.059\n",
      "Ep:151, loss:0.00001, loss_test:0.06576, lr:5.36e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.226, tt:4138.398\n",
      "Ep:152, loss:0.00001, loss_test:0.06592, lr:5.31e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.223, tt:4165.145\n",
      "Ep:153, loss:0.00001, loss_test:0.06582, lr:5.26e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.224, tt:4192.478\n",
      "Ep:154, loss:0.00001, loss_test:0.06565, lr:5.20e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.215, tt:4218.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00001, loss_test:0.06601, lr:5.15e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.205, tt:4243.946\n",
      "Ep:156, loss:0.00001, loss_test:0.06589, lr:5.10e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.198, tt:4270.112\n",
      "Ep:157, loss:0.00001, loss_test:0.06588, lr:5.05e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.185, tt:4295.195\n",
      "Ep:158, loss:0.00001, loss_test:0.06613, lr:5.00e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.180, tt:4321.614\n",
      "Ep:159, loss:0.00001, loss_test:0.06579, lr:4.95e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.179, tt:4348.609\n",
      "Ep:160, loss:0.00001, loss_test:0.06596, lr:4.90e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.175, tt:4375.219\n",
      "Ep:161, loss:0.00001, loss_test:0.06635, lr:4.85e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.179, tt:4402.970\n",
      "Ep:162, loss:0.00001, loss_test:0.06611, lr:4.80e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.173, tt:4429.153\n",
      "Ep:163, loss:0.00001, loss_test:0.06587, lr:4.75e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.166, tt:4455.243\n",
      "Ep:164, loss:0.00001, loss_test:0.06618, lr:4.71e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.160, tt:4481.419\n",
      "Ep:165, loss:0.00001, loss_test:0.06581, lr:4.66e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.156, tt:4507.903\n",
      "Ep:166, loss:0.00001, loss_test:0.06622, lr:4.61e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.152, tt:4534.432\n",
      "Ep:167, loss:0.00001, loss_test:0.06641, lr:4.57e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.143, tt:4560.024\n",
      "Ep:168, loss:0.00001, loss_test:0.06577, lr:4.52e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.135, tt:4585.873\n",
      "Ep:169, loss:0.00001, loss_test:0.06607, lr:4.48e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.131, tt:4612.204\n",
      "Ep:170, loss:0.00001, loss_test:0.06673, lr:4.43e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.127, tt:4638.753\n",
      "Ep:171, loss:0.00001, loss_test:0.06611, lr:4.39e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.112, tt:4663.317\n",
      "Ep:172, loss:0.00001, loss_test:0.06632, lr:4.34e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.106, tt:4689.271\n",
      "Ep:173, loss:0.00001, loss_test:0.06632, lr:4.30e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.085, tt:4712.795\n",
      "Ep:174, loss:0.00001, loss_test:0.06601, lr:4.26e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.084, tt:4739.763\n",
      "Ep:175, loss:0.00001, loss_test:0.06613, lr:4.21e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.071, tt:4764.491\n",
      "Ep:176, loss:0.00001, loss_test:0.06632, lr:4.17e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.085, tt:4794.015\n",
      "Ep:177, loss:0.00001, loss_test:0.06643, lr:4.13e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.081, tt:4820.417\n",
      "Ep:178, loss:0.00001, loss_test:0.06636, lr:4.09e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.078, tt:4847.007\n",
      "Ep:179, loss:0.00001, loss_test:0.06642, lr:4.05e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.074, tt:4873.323\n",
      "Ep:180, loss:0.00001, loss_test:0.06633, lr:4.01e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.081, tt:4901.658\n",
      "Ep:181, loss:0.00001, loss_test:0.06617, lr:3.97e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.077, tt:4928.071\n",
      "Ep:182, loss:0.00001, loss_test:0.06627, lr:3.93e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.074, tt:4954.626\n",
      "Ep:183, loss:0.00001, loss_test:0.06650, lr:3.89e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.071, tt:4981.105\n",
      "Ep:184, loss:0.00001, loss_test:0.06649, lr:3.85e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.069, tt:5007.733\n",
      "Ep:185, loss:0.00001, loss_test:0.06666, lr:3.81e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.061, tt:5033.336\n",
      "Ep:186, loss:0.00001, loss_test:0.06643, lr:3.77e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.061, tt:5060.495\n",
      "Ep:187, loss:0.00001, loss_test:0.06643, lr:3.73e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.052, tt:5085.750\n",
      "Ep:188, loss:0.00001, loss_test:0.06697, lr:3.70e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.049, tt:5112.185\n",
      "Ep:189, loss:0.00001, loss_test:0.06663, lr:3.66e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.032, tt:5136.011\n",
      "Ep:190, loss:0.00001, loss_test:0.06631, lr:3.62e-03, fs:0.88172 (r=0.828,p=0.943),  time:27.016, tt:5159.970\n",
      "Ep:191, loss:0.00001, loss_test:0.06676, lr:3.59e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.985, tt:5181.077\n",
      "Ep:192, loss:0.00001, loss_test:0.06678, lr:3.55e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.965, tt:5204.285\n",
      "Ep:193, loss:0.00001, loss_test:0.06646, lr:3.52e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.943, tt:5226.944\n",
      "Ep:194, loss:0.00001, loss_test:0.06684, lr:3.48e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.915, tt:5248.345\n",
      "Ep:195, loss:0.00001, loss_test:0.06687, lr:3.45e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.874, tt:5267.276\n",
      "Ep:196, loss:0.00001, loss_test:0.06623, lr:3.41e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.857, tt:5290.834\n",
      "Ep:197, loss:0.00001, loss_test:0.06707, lr:3.38e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.832, tt:5312.770\n",
      "Ep:198, loss:0.00001, loss_test:0.06753, lr:3.34e-03, fs:0.86339 (r=0.798,p=0.940),  time:26.818, tt:5336.730\n",
      "Ep:199, loss:0.00001, loss_test:0.06682, lr:3.31e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.815, tt:5363.077\n",
      "Ep:200, loss:0.00001, loss_test:0.06672, lr:3.28e-03, fs:0.88172 (r=0.828,p=0.943),  time:26.811, tt:5388.996\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02145, lr:6.00e-02, fs:0.64444 (r=0.879,p=0.509),  time:34.372, tt:34.372\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02585, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.427, tt:68.853\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02823, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.299, tt:105.897\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02841, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.409, tt:141.637\n",
      "Ep:4, loss:0.00005, loss_test:0.02753, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.113, tt:175.564\n",
      "Ep:5, loss:0.00005, loss_test:0.02612, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.363, tt:212.178\n",
      "Ep:6, loss:0.00005, loss_test:0.02424, lr:6.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:35.271, tt:246.894\n",
      "Ep:7, loss:0.00005, loss_test:0.02235, lr:6.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:35.387, tt:283.097\n",
      "Ep:8, loss:0.00004, loss_test:0.02091, lr:6.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:35.377, tt:318.393\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01975, lr:6.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:35.246, tt:352.457\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01897, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.073, tt:385.806\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01876, lr:6.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:34.995, tt:419.935\n",
      "Ep:12, loss:0.00004, loss_test:0.01843, lr:6.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:34.917, tt:453.918\n",
      "Ep:13, loss:0.00004, loss_test:0.01789, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:34.964, tt:489.501\n",
      "Ep:14, loss:0.00004, loss_test:0.01741, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:34.881, tt:523.212\n",
      "Ep:15, loss:0.00004, loss_test:0.01702, lr:6.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:34.811, tt:556.983\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01665, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:34.747, tt:590.700\n",
      "Ep:17, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.70588 (r=0.909,p=0.577),  time:34.684, tt:624.307\n",
      "Ep:18, loss:0.00003, loss_test:0.01584, lr:6.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:34.591, tt:657.222\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:19, loss:0.00003, loss_test:0.01545, lr:6.00e-02, fs:0.72000 (r=0.909,p=0.596),  time:34.511, tt:690.224\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01508, lr:6.00e-02, fs:0.74074 (r=0.909,p=0.625),  time:34.621, tt:727.040\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01475, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.568, tt:760.490\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01450, lr:6.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:34.571, tt:795.139\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01427, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.630, tt:831.111\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01406, lr:6.00e-02, fs:0.78298 (r=0.929,p=0.676),  time:34.557, tt:863.914\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01387, lr:6.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:34.595, tt:899.475\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01368, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:34.547, tt:932.768\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01350, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:34.564, tt:967.779\n",
      "Ep:28, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:34.601, tt:1003.427\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.582, tt:1037.465\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.600, tt:1072.588\n",
      "Ep:31, loss:0.00002, loss_test:0.01289, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.634, tt:1108.295\n",
      "Ep:32, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:34.633, tt:1142.886\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:34.646, tt:1177.973\n",
      "Ep:34, loss:0.00002, loss_test:0.01260, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.629, tt:1212.025\n",
      "Ep:35, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.690, tt:1248.825\n",
      "Ep:36, loss:0.00002, loss_test:0.01247, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.747, tt:1285.653\n",
      "Ep:37, loss:0.00002, loss_test:0.01243, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.743, tt:1320.224\n",
      "Ep:38, loss:0.00002, loss_test:0.01236, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.765, tt:1355.852\n",
      "Ep:39, loss:0.00002, loss_test:0.01231, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.798, tt:1391.907\n",
      "Ep:40, loss:0.00002, loss_test:0.01225, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:34.822, tt:1427.713\n",
      "Ep:41, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.82203 (r=0.980,p=0.708),  time:34.818, tt:1462.367\n",
      "Ep:42, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:34.837, tt:1497.998\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:34.828, tt:1532.428\n",
      "Ep:44, loss:0.00002, loss_test:0.01187, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:34.844, tt:1568.003\n",
      "Ep:45, loss:0.00002, loss_test:0.01181, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:34.857, tt:1603.415\n",
      "Ep:46, loss:0.00002, loss_test:0.01174, lr:6.00e-02, fs:0.82553 (r=0.980,p=0.713),  time:34.876, tt:1639.175\n",
      "Ep:47, loss:0.00002, loss_test:0.01172, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:34.910, tt:1675.675\n",
      "Ep:48, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.927, tt:1711.406\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01159, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:34.950, tt:1747.510\n",
      "Ep:50, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.962, tt:1783.041\n",
      "Ep:51, loss:0.00001, loss_test:0.01153, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.942, tt:1816.994\n",
      "Ep:52, loss:0.00001, loss_test:0.01150, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.951, tt:1852.378\n",
      "Ep:53, loss:0.00001, loss_test:0.01142, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:34.963, tt:1888.009\n",
      "Ep:54, loss:0.00001, loss_test:0.01143, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.975, tt:1923.649\n",
      "Ep:55, loss:0.00001, loss_test:0.01138, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.990, tt:1959.435\n",
      "Ep:56, loss:0.00001, loss_test:0.01136, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.017, tt:1995.956\n",
      "Ep:57, loss:0.00001, loss_test:0.01135, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.027, tt:2031.545\n",
      "Ep:58, loss:0.00001, loss_test:0.01131, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:35.049, tt:2067.890\n",
      "Ep:59, loss:0.00001, loss_test:0.01127, lr:6.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:35.051, tt:2103.081\n",
      "Ep:60, loss:0.00001, loss_test:0.01128, lr:5.94e-02, fs:0.82883 (r=0.929,p=0.748),  time:35.068, tt:2139.152\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01126, lr:5.94e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.094, tt:2175.801\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01122, lr:5.94e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.103, tt:2211.465\n",
      "Ep:63, loss:0.00001, loss_test:0.01124, lr:5.94e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.115, tt:2247.383\n",
      "Ep:64, loss:0.00001, loss_test:0.01118, lr:5.94e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.129, tt:2283.375\n",
      "Ep:65, loss:0.00001, loss_test:0.01122, lr:5.94e-02, fs:0.82569 (r=0.909,p=0.756),  time:35.141, tt:2319.335\n",
      "Ep:66, loss:0.00001, loss_test:0.01116, lr:5.94e-02, fs:0.82192 (r=0.909,p=0.750),  time:35.158, tt:2355.616\n",
      "Ep:67, loss:0.00001, loss_test:0.01117, lr:5.94e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.160, tt:2390.908\n",
      "Ep:68, loss:0.00001, loss_test:0.01114, lr:5.94e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.154, tt:2425.619\n",
      "Ep:69, loss:0.00001, loss_test:0.01119, lr:5.94e-02, fs:0.83486 (r=0.919,p=0.765),  time:35.152, tt:2460.622\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01112, lr:5.94e-02, fs:0.83105 (r=0.919,p=0.758),  time:35.149, tt:2495.561\n",
      "Ep:71, loss:0.00001, loss_test:0.01119, lr:5.94e-02, fs:0.83486 (r=0.919,p=0.765),  time:35.169, tt:2532.137\n",
      "Ep:72, loss:0.00001, loss_test:0.01112, lr:5.94e-02, fs:0.83871 (r=0.919,p=0.771),  time:35.186, tt:2568.600\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01115, lr:5.94e-02, fs:0.83871 (r=0.919,p=0.771),  time:35.179, tt:2603.215\n",
      "Ep:74, loss:0.00001, loss_test:0.01118, lr:5.94e-02, fs:0.83721 (r=0.909,p=0.776),  time:35.193, tt:2639.502\n",
      "Ep:75, loss:0.00001, loss_test:0.01116, lr:5.94e-02, fs:0.83721 (r=0.909,p=0.776),  time:35.189, tt:2674.361\n",
      "Ep:76, loss:0.00001, loss_test:0.01112, lr:5.94e-02, fs:0.84507 (r=0.909,p=0.789),  time:35.201, tt:2710.463\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01126, lr:5.94e-02, fs:0.84507 (r=0.909,p=0.789),  time:35.223, tt:2747.381\n",
      "Ep:78, loss:0.00001, loss_test:0.01111, lr:5.94e-02, fs:0.84507 (r=0.909,p=0.789),  time:35.214, tt:2781.924\n",
      "Ep:79, loss:0.00001, loss_test:0.01114, lr:5.94e-02, fs:0.84507 (r=0.909,p=0.789),  time:35.229, tt:2818.309\n",
      "Ep:80, loss:0.00001, loss_test:0.01120, lr:5.94e-02, fs:0.85308 (r=0.909,p=0.804),  time:35.236, tt:2854.103\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01122, lr:5.94e-02, fs:0.85714 (r=0.909,p=0.811),  time:35.270, tt:2892.181\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01125, lr:5.94e-02, fs:0.86124 (r=0.909,p=0.818),  time:35.283, tt:2928.461\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01130, lr:5.94e-02, fs:0.85714 (r=0.909,p=0.811),  time:35.280, tt:2963.498\n",
      "Ep:84, loss:0.00001, loss_test:0.01123, lr:5.94e-02, fs:0.85714 (r=0.909,p=0.811),  time:35.276, tt:2998.472\n",
      "Ep:85, loss:0.00001, loss_test:0.01133, lr:5.94e-02, fs:0.85714 (r=0.909,p=0.811),  time:35.274, tt:3033.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:86, loss:0.00001, loss_test:0.01140, lr:5.94e-02, fs:0.86538 (r=0.909,p=0.826),  time:35.279, tt:3069.241\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01133, lr:5.94e-02, fs:0.86538 (r=0.909,p=0.826),  time:35.280, tt:3104.632\n",
      "Ep:88, loss:0.00001, loss_test:0.01134, lr:5.94e-02, fs:0.86538 (r=0.909,p=0.826),  time:35.277, tt:3139.642\n",
      "Ep:89, loss:0.00001, loss_test:0.01138, lr:5.94e-02, fs:0.86957 (r=0.909,p=0.833),  time:35.284, tt:3175.597\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01142, lr:5.94e-02, fs:0.86957 (r=0.909,p=0.833),  time:35.285, tt:3210.968\n",
      "Ep:91, loss:0.00001, loss_test:0.01152, lr:5.94e-02, fs:0.86957 (r=0.909,p=0.833),  time:35.297, tt:3247.302\n",
      "Ep:92, loss:0.00001, loss_test:0.01158, lr:5.94e-02, fs:0.86957 (r=0.909,p=0.833),  time:35.297, tt:3282.658\n",
      "Ep:93, loss:0.00001, loss_test:0.01151, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:35.318, tt:3319.858\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01164, lr:5.94e-02, fs:0.86957 (r=0.909,p=0.833),  time:35.309, tt:3354.347\n",
      "Ep:95, loss:0.00000, loss_test:0.01154, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:35.310, tt:3389.763\n",
      "Ep:96, loss:0.00000, loss_test:0.01174, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:35.315, tt:3425.534\n",
      "Ep:97, loss:0.00000, loss_test:0.01170, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:35.311, tt:3460.463\n",
      "Ep:98, loss:0.00000, loss_test:0.01177, lr:5.94e-02, fs:0.87379 (r=0.909,p=0.841),  time:35.313, tt:3496.007\n",
      "Ep:99, loss:0.00000, loss_test:0.01181, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.333, tt:3533.274\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00000, loss_test:0.01194, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.369, tt:3572.292\n",
      "Ep:101, loss:0.00000, loss_test:0.01201, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.365, tt:3607.251\n",
      "Ep:102, loss:0.00000, loss_test:0.01203, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.361, tt:3642.178\n",
      "Ep:103, loss:0.00000, loss_test:0.01203, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.356, tt:3677.036\n",
      "Ep:104, loss:0.00000, loss_test:0.01213, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.353, tt:3712.107\n",
      "Ep:105, loss:0.00000, loss_test:0.01213, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.346, tt:3746.722\n",
      "Ep:106, loss:0.00000, loss_test:0.01233, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.359, tt:3783.373\n",
      "Ep:107, loss:0.00000, loss_test:0.01222, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.343, tt:3817.021\n",
      "Ep:108, loss:0.00000, loss_test:0.01222, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.349, tt:3853.044\n",
      "Ep:109, loss:0.00000, loss_test:0.01240, lr:5.94e-02, fs:0.87255 (r=0.899,p=0.848),  time:35.342, tt:3887.627\n",
      "Ep:110, loss:0.00000, loss_test:0.01240, lr:5.94e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.339, tt:3922.667\n",
      "Ep:111, loss:0.00000, loss_test:0.01240, lr:5.88e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.353, tt:3959.481\n",
      "Ep:112, loss:0.00000, loss_test:0.01268, lr:5.82e-02, fs:0.88235 (r=0.909,p=0.857),  time:35.359, tt:3995.565\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.01242, lr:5.82e-02, fs:0.87805 (r=0.909,p=0.849),  time:35.362, tt:4031.278\n",
      "Ep:114, loss:0.00000, loss_test:0.01265, lr:5.82e-02, fs:0.88235 (r=0.909,p=0.857),  time:35.363, tt:4066.769\n",
      "Ep:115, loss:0.00000, loss_test:0.01256, lr:5.82e-02, fs:0.88235 (r=0.909,p=0.857),  time:35.362, tt:4101.996\n",
      "Ep:116, loss:0.00000, loss_test:0.01262, lr:5.82e-02, fs:0.88235 (r=0.909,p=0.857),  time:35.361, tt:4137.236\n",
      "Ep:117, loss:0.00000, loss_test:0.01277, lr:5.82e-02, fs:0.88557 (r=0.899,p=0.873),  time:35.370, tt:4173.712\n",
      "##########Best model found so far##########\n",
      "Ep:118, loss:0.00000, loss_test:0.01276, lr:5.82e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.362, tt:4208.037\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00000, loss_test:0.01277, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.369, tt:4244.304\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00000, loss_test:0.01285, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.365, tt:4279.154\n",
      "Ep:121, loss:0.00000, loss_test:0.01288, lr:5.82e-02, fs:0.88670 (r=0.909,p=0.865),  time:35.351, tt:4312.797\n",
      "Ep:122, loss:0.00000, loss_test:0.01311, lr:5.82e-02, fs:0.89000 (r=0.899,p=0.881),  time:35.357, tt:4348.911\n",
      "Ep:123, loss:0.00000, loss_test:0.01292, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.357, tt:4384.233\n",
      "Ep:124, loss:0.00000, loss_test:0.01293, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.395, tt:4424.319\n",
      "Ep:125, loss:0.00000, loss_test:0.01304, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.396, tt:4459.852\n",
      "##########Best model found so far##########\n",
      "Ep:126, loss:0.00000, loss_test:0.01296, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.398, tt:4495.583\n",
      "Ep:127, loss:0.00000, loss_test:0.01318, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.401, tt:4531.265\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.01321, lr:5.82e-02, fs:0.89109 (r=0.909,p=0.874),  time:35.393, tt:4565.740\n",
      "Ep:129, loss:0.00000, loss_test:0.01311, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.399, tt:4601.872\n",
      "Ep:130, loss:0.00000, loss_test:0.01326, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.386, tt:4635.607\n",
      "Ep:131, loss:0.00000, loss_test:0.01326, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.389, tt:4671.311\n",
      "Ep:132, loss:0.00000, loss_test:0.01329, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.391, tt:4707.000\n",
      "Ep:133, loss:0.00000, loss_test:0.01335, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.397, tt:4743.255\n",
      "Ep:134, loss:0.00000, loss_test:0.01328, lr:5.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:35.390, tt:4777.714\n",
      "Ep:135, loss:0.00000, loss_test:0.01350, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.391, tt:4813.130\n",
      "Ep:136, loss:0.00000, loss_test:0.01365, lr:5.82e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.397, tt:4849.438\n",
      "Ep:137, loss:0.00000, loss_test:0.01362, lr:5.82e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.396, tt:4884.589\n",
      "Ep:138, loss:0.00000, loss_test:0.01334, lr:5.82e-02, fs:0.89000 (r=0.899,p=0.881),  time:35.377, tt:4917.393\n",
      "Ep:139, loss:0.00000, loss_test:0.01353, lr:5.76e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.372, tt:4952.015\n",
      "Ep:140, loss:0.00000, loss_test:0.01359, lr:5.71e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.369, tt:4987.067\n",
      "Ep:141, loss:0.00000, loss_test:0.01356, lr:5.65e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.361, tt:5021.266\n",
      "Ep:142, loss:0.00000, loss_test:0.01380, lr:5.59e-02, fs:0.88889 (r=0.889,p=0.889),  time:35.347, tt:5054.586\n",
      "Ep:143, loss:0.00000, loss_test:0.01369, lr:5.54e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.334, tt:5088.050\n",
      "Ep:144, loss:0.00000, loss_test:0.01364, lr:5.48e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.325, tt:5122.069\n",
      "Ep:145, loss:0.00000, loss_test:0.01378, lr:5.43e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.306, tt:5154.740\n",
      "Ep:146, loss:0.00000, loss_test:0.01365, lr:5.37e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.295, tt:5188.403\n",
      "Ep:147, loss:0.00000, loss_test:0.01381, lr:5.32e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.282, tt:5221.702\n",
      "Ep:148, loss:0.00000, loss_test:0.01392, lr:5.27e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.279, tt:5256.512\n",
      "Ep:149, loss:0.00000, loss_test:0.01386, lr:5.21e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.269, tt:5290.280\n",
      "Ep:150, loss:0.00000, loss_test:0.01381, lr:5.16e-02, fs:0.88889 (r=0.889,p=0.889),  time:35.263, tt:5324.779\n",
      "Ep:151, loss:0.00000, loss_test:0.01398, lr:5.11e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.263, tt:5360.006\n",
      "Ep:152, loss:0.00000, loss_test:0.01395, lr:5.06e-02, fs:0.88889 (r=0.889,p=0.889),  time:35.262, tt:5395.034\n",
      "Ep:153, loss:0.00000, loss_test:0.01385, lr:5.01e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.259, tt:5429.952\n",
      "Ep:154, loss:0.00000, loss_test:0.01399, lr:4.96e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.260, tt:5465.297\n",
      "Ep:155, loss:0.00000, loss_test:0.01398, lr:4.91e-02, fs:0.88889 (r=0.889,p=0.889),  time:35.260, tt:5500.624\n",
      "Ep:156, loss:0.00000, loss_test:0.01391, lr:4.86e-02, fs:0.87755 (r=0.869,p=0.887),  time:35.257, tt:5535.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:157, loss:0.00000, loss_test:0.01400, lr:4.81e-02, fs:0.87755 (r=0.869,p=0.887),  time:35.257, tt:5570.531\n",
      "Ep:158, loss:0.00000, loss_test:0.01408, lr:4.76e-02, fs:0.88325 (r=0.879,p=0.888),  time:35.250, tt:5604.765\n",
      "Ep:159, loss:0.00000, loss_test:0.01417, lr:4.71e-02, fs:0.87755 (r=0.869,p=0.887),  time:35.239, tt:5638.308\n",
      "Ep:160, loss:0.00000, loss_test:0.01411, lr:4.67e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.235, tt:5672.908\n",
      "Ep:161, loss:0.00000, loss_test:0.01409, lr:4.62e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.230, tt:5707.200\n",
      "Ep:162, loss:0.00000, loss_test:0.01420, lr:4.57e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.231, tt:5742.687\n",
      "Ep:163, loss:0.00000, loss_test:0.01419, lr:4.53e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.226, tt:5777.066\n",
      "Ep:164, loss:0.00000, loss_test:0.01418, lr:4.48e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.226, tt:5812.285\n",
      "Ep:165, loss:0.00000, loss_test:0.01418, lr:4.44e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.225, tt:5847.322\n",
      "Ep:166, loss:0.00000, loss_test:0.01424, lr:4.39e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.229, tt:5883.268\n",
      "Ep:167, loss:0.00000, loss_test:0.01423, lr:4.35e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.228, tt:5918.240\n",
      "Ep:168, loss:0.00000, loss_test:0.01428, lr:4.31e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.225, tt:5952.951\n",
      "Ep:169, loss:0.00000, loss_test:0.01429, lr:4.26e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.209, tt:5985.468\n",
      "Ep:170, loss:0.00000, loss_test:0.01434, lr:4.22e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.203, tt:6019.799\n",
      "Ep:171, loss:0.00000, loss_test:0.01431, lr:4.18e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.202, tt:6054.716\n",
      "Ep:172, loss:0.00000, loss_test:0.01432, lr:4.14e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.203, tt:6090.051\n",
      "Ep:173, loss:0.00000, loss_test:0.01444, lr:4.10e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.204, tt:6125.446\n",
      "Ep:174, loss:0.00000, loss_test:0.01434, lr:4.05e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.207, tt:6161.198\n",
      "Ep:175, loss:0.00000, loss_test:0.01444, lr:4.01e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.200, tt:6195.261\n",
      "Ep:176, loss:0.00000, loss_test:0.01434, lr:3.97e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.200, tt:6230.447\n",
      "Ep:177, loss:0.00000, loss_test:0.01452, lr:3.93e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.214, tt:6268.158\n",
      "Ep:178, loss:0.00000, loss_test:0.01436, lr:3.89e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.214, tt:6303.236\n",
      "Ep:179, loss:0.00000, loss_test:0.01447, lr:3.86e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.219, tt:6339.417\n",
      "Ep:180, loss:0.00000, loss_test:0.01445, lr:3.82e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.215, tt:6373.917\n",
      "Ep:181, loss:0.00000, loss_test:0.01450, lr:3.78e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.221, tt:6410.210\n",
      "Ep:182, loss:0.00000, loss_test:0.01446, lr:3.74e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.216, tt:6444.454\n",
      "Ep:183, loss:0.00000, loss_test:0.01453, lr:3.70e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.218, tt:6480.166\n",
      "Ep:184, loss:0.00000, loss_test:0.01455, lr:3.67e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.219, tt:6515.516\n",
      "Ep:185, loss:0.00000, loss_test:0.01460, lr:3.63e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.222, tt:6551.354\n",
      "Ep:186, loss:0.00000, loss_test:0.01457, lr:3.59e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.227, tt:6587.461\n",
      "Ep:187, loss:0.00000, loss_test:0.01456, lr:3.56e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.222, tt:6621.757\n",
      "Ep:188, loss:0.00000, loss_test:0.01465, lr:3.52e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.211, tt:6654.879\n",
      "Ep:189, loss:0.00000, loss_test:0.01456, lr:3.49e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.214, tt:6690.570\n",
      "Ep:190, loss:0.00000, loss_test:0.01472, lr:3.45e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.215, tt:6726.033\n",
      "Ep:191, loss:0.00000, loss_test:0.01459, lr:3.42e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.215, tt:6761.209\n",
      "Ep:192, loss:0.00000, loss_test:0.01469, lr:3.38e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.217, tt:6796.851\n",
      "Ep:193, loss:0.00000, loss_test:0.01462, lr:3.35e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.223, tt:6833.286\n",
      "Ep:194, loss:0.00000, loss_test:0.01466, lr:3.32e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.221, tt:6868.155\n",
      "Ep:195, loss:0.00000, loss_test:0.01465, lr:3.28e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.220, tt:6903.178\n",
      "Ep:196, loss:0.00000, loss_test:0.01473, lr:3.25e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.204, tt:6935.145\n",
      "Ep:197, loss:0.00000, loss_test:0.01468, lr:3.22e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.191, tt:6967.724\n",
      "Ep:198, loss:0.00000, loss_test:0.01471, lr:3.19e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.186, tt:7002.098\n",
      "Ep:199, loss:0.00000, loss_test:0.01471, lr:3.15e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.158, tt:7031.701\n",
      "Ep:200, loss:0.00000, loss_test:0.01479, lr:3.12e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.156, tt:7066.411\n",
      "Ep:201, loss:0.00000, loss_test:0.01474, lr:3.09e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.144, tt:7099.010\n",
      "Ep:202, loss:0.00000, loss_test:0.01476, lr:3.06e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.143, tt:7134.059\n",
      "Ep:203, loss:0.00000, loss_test:0.01475, lr:3.03e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.139, tt:7168.363\n",
      "Ep:204, loss:0.00000, loss_test:0.01477, lr:3.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.126, tt:7200.857\n",
      "Ep:205, loss:0.00000, loss_test:0.01478, lr:2.97e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.133, tt:7237.399\n",
      "Ep:206, loss:0.00000, loss_test:0.01483, lr:2.94e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.127, tt:7271.198\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13423, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:36.315, tt:36.315\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12941, lr:1.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:36.435, tt:72.870\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12291, lr:1.00e-02, fs:0.68462 (r=0.899,p=0.553),  time:36.250, tt:108.751\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11648, lr:1.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:36.262, tt:145.048\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11208, lr:1.00e-02, fs:0.70293 (r=0.848,p=0.600),  time:36.109, tt:180.545\n",
      "Ep:5, loss:0.00024, loss_test:0.10946, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:36.447, tt:218.682\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10722, lr:1.00e-02, fs:0.72500 (r=0.879,p=0.617),  time:36.650, tt:256.550\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10491, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:36.767, tt:294.139\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10084, lr:1.00e-02, fs:0.74009 (r=0.848,p=0.656),  time:36.768, tt:330.913\n",
      "Ep:9, loss:0.00021, loss_test:0.09869, lr:1.00e-02, fs:0.76190 (r=0.889,p=0.667),  time:36.834, tt:368.335\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09710, lr:1.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:36.917, tt:406.084\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09480, lr:1.00e-02, fs:0.76395 (r=0.899,p=0.664),  time:36.964, tt:443.566\n",
      "Ep:12, loss:0.00019, loss_test:0.09320, lr:1.00e-02, fs:0.75325 (r=0.879,p=0.659),  time:36.835, tt:478.856\n",
      "Ep:13, loss:0.00019, loss_test:0.09187, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:36.793, tt:515.096\n",
      "Ep:14, loss:0.00018, loss_test:0.08909, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:36.761, tt:551.415\n",
      "Ep:15, loss:0.00018, loss_test:0.08798, lr:1.00e-02, fs:0.74890 (r=0.859,p=0.664),  time:36.677, tt:586.837\n",
      "Ep:16, loss:0.00017, loss_test:0.08592, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:36.547, tt:621.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00017, loss_test:0.08382, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:36.511, tt:657.194\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00016, loss_test:0.08244, lr:1.00e-02, fs:0.77828 (r=0.869,p=0.705),  time:36.549, tt:694.427\n",
      "Ep:19, loss:0.00016, loss_test:0.08069, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:36.560, tt:731.190\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.07896, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:36.557, tt:767.706\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.07794, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:36.474, tt:802.434\n",
      "Ep:22, loss:0.00014, loss_test:0.07578, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:36.448, tt:838.298\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07423, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:36.361, tt:872.666\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07313, lr:1.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:36.388, tt:909.711\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07214, lr:1.00e-02, fs:0.80930 (r=0.879,p=0.750),  time:36.351, tt:945.131\n",
      "Ep:26, loss:0.00013, loss_test:0.07083, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:36.352, tt:981.511\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07012, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:36.267, tt:1015.487\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.06983, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:36.198, tt:1049.750\n",
      "Ep:29, loss:0.00011, loss_test:0.06884, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:36.182, tt:1085.449\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.06750, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:36.164, tt:1121.097\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.06675, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:36.139, tt:1156.444\n",
      "Ep:32, loss:0.00010, loss_test:0.06570, lr:1.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:36.096, tt:1191.179\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.06568, lr:1.00e-02, fs:0.86758 (r=0.960,p=0.792),  time:36.053, tt:1225.803\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06372, lr:1.00e-02, fs:0.86607 (r=0.980,p=0.776),  time:36.014, tt:1260.474\n",
      "Ep:35, loss:0.00009, loss_test:0.06466, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.992, tt:1295.725\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00009, loss_test:0.06258, lr:1.00e-02, fs:0.88182 (r=0.980,p=0.802),  time:35.967, tt:1330.770\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.06417, lr:1.00e-02, fs:0.87387 (r=0.980,p=0.789),  time:35.984, tt:1367.394\n",
      "Ep:38, loss:0.00008, loss_test:0.06098, lr:1.00e-02, fs:0.86486 (r=0.970,p=0.780),  time:36.002, tt:1404.089\n",
      "Ep:39, loss:0.00008, loss_test:0.06328, lr:1.00e-02, fs:0.87671 (r=0.970,p=0.800),  time:35.991, tt:1439.624\n",
      "Ep:40, loss:0.00008, loss_test:0.06106, lr:1.00e-02, fs:0.89815 (r=0.980,p=0.829),  time:35.961, tt:1474.391\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.05955, lr:1.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:35.978, tt:1511.095\n",
      "Ep:42, loss:0.00007, loss_test:0.06163, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:35.967, tt:1546.571\n",
      "Ep:43, loss:0.00007, loss_test:0.05802, lr:1.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:35.942, tt:1581.454\n",
      "Ep:44, loss:0.00007, loss_test:0.06104, lr:1.00e-02, fs:0.88785 (r=0.960,p=0.826),  time:35.959, tt:1618.166\n",
      "Ep:45, loss:0.00007, loss_test:0.05730, lr:1.00e-02, fs:0.88584 (r=0.980,p=0.808),  time:35.966, tt:1654.441\n",
      "Ep:46, loss:0.00006, loss_test:0.06092, lr:1.00e-02, fs:0.88479 (r=0.970,p=0.814),  time:35.937, tt:1689.056\n",
      "Ep:47, loss:0.00006, loss_test:0.05573, lr:1.00e-02, fs:0.88991 (r=0.980,p=0.815),  time:35.914, tt:1723.868\n",
      "Ep:48, loss:0.00006, loss_test:0.06027, lr:1.00e-02, fs:0.88889 (r=0.929,p=0.852),  time:35.942, tt:1761.155\n",
      "Ep:49, loss:0.00006, loss_test:0.05520, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:35.899, tt:1794.972\n",
      "Ep:50, loss:0.00006, loss_test:0.06392, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.903, tt:1831.036\n",
      "Ep:51, loss:0.00006, loss_test:0.05342, lr:1.00e-02, fs:0.89091 (r=0.990,p=0.810),  time:35.926, tt:1868.146\n",
      "Ep:52, loss:0.00006, loss_test:0.06147, lr:9.90e-03, fs:0.87879 (r=0.879,p=0.879),  time:35.967, tt:1906.265\n",
      "Ep:53, loss:0.00006, loss_test:0.05708, lr:9.80e-03, fs:0.87892 (r=0.990,p=0.790),  time:35.984, tt:1943.139\n",
      "Ep:54, loss:0.00006, loss_test:0.05608, lr:9.70e-03, fs:0.90909 (r=0.960,p=0.864),  time:36.015, tt:1980.805\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.05232, lr:9.70e-03, fs:0.87736 (r=0.939,p=0.823),  time:36.030, tt:2017.662\n",
      "Ep:56, loss:0.00005, loss_test:0.05516, lr:9.70e-03, fs:0.89423 (r=0.939,p=0.853),  time:36.045, tt:2054.570\n",
      "Ep:57, loss:0.00005, loss_test:0.05253, lr:9.70e-03, fs:0.86916 (r=0.939,p=0.809),  time:36.068, tt:2091.936\n",
      "Ep:58, loss:0.00005, loss_test:0.05372, lr:9.70e-03, fs:0.89855 (r=0.939,p=0.861),  time:36.079, tt:2128.635\n",
      "Ep:59, loss:0.00005, loss_test:0.05469, lr:9.70e-03, fs:0.88995 (r=0.939,p=0.845),  time:36.081, tt:2164.842\n",
      "Ep:60, loss:0.00004, loss_test:0.05299, lr:9.70e-03, fs:0.87324 (r=0.939,p=0.816),  time:36.104, tt:2202.337\n",
      "Ep:61, loss:0.00004, loss_test:0.05407, lr:9.70e-03, fs:0.90732 (r=0.939,p=0.877),  time:36.117, tt:2239.243\n",
      "Ep:62, loss:0.00004, loss_test:0.05154, lr:9.70e-03, fs:0.87324 (r=0.939,p=0.816),  time:36.104, tt:2274.567\n",
      "Ep:63, loss:0.00004, loss_test:0.05933, lr:9.70e-03, fs:0.87685 (r=0.899,p=0.856),  time:36.087, tt:2309.594\n",
      "Ep:64, loss:0.00004, loss_test:0.05157, lr:9.70e-03, fs:0.88995 (r=0.939,p=0.845),  time:36.124, tt:2348.059\n",
      "Ep:65, loss:0.00004, loss_test:0.05442, lr:9.70e-03, fs:0.90732 (r=0.939,p=0.877),  time:36.119, tt:2383.879\n",
      "Ep:66, loss:0.00004, loss_test:0.05295, lr:9.61e-03, fs:0.90141 (r=0.970,p=0.842),  time:36.132, tt:2420.840\n",
      "Ep:67, loss:0.00004, loss_test:0.05346, lr:9.51e-03, fs:0.91176 (r=0.939,p=0.886),  time:36.159, tt:2458.787\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00004, loss_test:0.05189, lr:9.51e-03, fs:0.89423 (r=0.939,p=0.853),  time:36.169, tt:2495.675\n",
      "Ep:69, loss:0.00004, loss_test:0.05633, lr:9.51e-03, fs:0.86700 (r=0.889,p=0.846),  time:36.187, tt:2533.122\n",
      "Ep:70, loss:0.00004, loss_test:0.05118, lr:9.51e-03, fs:0.90732 (r=0.939,p=0.877),  time:36.205, tt:2570.582\n",
      "Ep:71, loss:0.00004, loss_test:0.05225, lr:9.51e-03, fs:0.90732 (r=0.939,p=0.877),  time:36.197, tt:2606.168\n",
      "Ep:72, loss:0.00003, loss_test:0.05117, lr:9.51e-03, fs:0.91626 (r=0.939,p=0.894),  time:36.201, tt:2642.668\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00004, loss_test:0.05130, lr:9.51e-03, fs:0.91626 (r=0.939,p=0.894),  time:36.213, tt:2679.758\n",
      "Ep:74, loss:0.00003, loss_test:0.05703, lr:9.51e-03, fs:0.87923 (r=0.919,p=0.843),  time:36.227, tt:2717.055\n",
      "Ep:75, loss:0.00004, loss_test:0.05021, lr:9.51e-03, fs:0.92079 (r=0.939,p=0.903),  time:36.236, tt:2753.950\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00003, loss_test:0.04935, lr:9.51e-03, fs:0.90099 (r=0.919,p=0.883),  time:36.229, tt:2789.605\n",
      "Ep:77, loss:0.00003, loss_test:0.05495, lr:9.51e-03, fs:0.88557 (r=0.899,p=0.873),  time:36.233, tt:2826.140\n",
      "Ep:78, loss:0.00003, loss_test:0.04854, lr:9.51e-03, fs:0.92079 (r=0.939,p=0.903),  time:36.226, tt:2861.835\n",
      "Ep:79, loss:0.00003, loss_test:0.05223, lr:9.51e-03, fs:0.90732 (r=0.939,p=0.877),  time:36.200, tt:2896.014\n",
      "Ep:80, loss:0.00003, loss_test:0.04974, lr:9.51e-03, fs:0.92079 (r=0.939,p=0.903),  time:36.175, tt:2930.205\n",
      "Ep:81, loss:0.00003, loss_test:0.05132, lr:9.51e-03, fs:0.89855 (r=0.939,p=0.861),  time:36.163, tt:2965.358\n",
      "Ep:82, loss:0.00003, loss_test:0.05397, lr:9.51e-03, fs:0.88889 (r=0.889,p=0.889),  time:36.167, tt:3001.851\n",
      "Ep:83, loss:0.00003, loss_test:0.04706, lr:9.51e-03, fs:0.90547 (r=0.919,p=0.892),  time:36.184, tt:3039.430\n",
      "Ep:84, loss:0.00003, loss_test:0.05464, lr:9.51e-03, fs:0.88670 (r=0.909,p=0.865),  time:36.178, tt:3075.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:85, loss:0.00003, loss_test:0.05066, lr:9.51e-03, fs:0.91000 (r=0.919,p=0.901),  time:36.183, tt:3111.705\n",
      "Ep:86, loss:0.00003, loss_test:0.04884, lr:9.51e-03, fs:0.91429 (r=0.970,p=0.865),  time:36.185, tt:3148.109\n",
      "Ep:87, loss:0.00003, loss_test:0.06035, lr:9.41e-03, fs:0.85417 (r=0.828,p=0.882),  time:36.206, tt:3186.109\n",
      "Ep:88, loss:0.00003, loss_test:0.04667, lr:9.32e-03, fs:0.88670 (r=0.909,p=0.865),  time:36.203, tt:3222.044\n",
      "Ep:89, loss:0.00003, loss_test:0.06151, lr:9.23e-03, fs:0.88442 (r=0.889,p=0.880),  time:36.191, tt:3257.163\n",
      "Ep:90, loss:0.00003, loss_test:0.04491, lr:9.14e-03, fs:0.89552 (r=0.909,p=0.882),  time:36.189, tt:3293.236\n",
      "Ep:91, loss:0.00003, loss_test:0.06213, lr:9.04e-03, fs:0.86154 (r=0.848,p=0.875),  time:36.194, tt:3329.813\n",
      "Ep:92, loss:0.00003, loss_test:0.04540, lr:8.95e-03, fs:0.89109 (r=0.909,p=0.874),  time:36.189, tt:3365.531\n",
      "Ep:93, loss:0.00003, loss_test:0.05975, lr:8.86e-03, fs:0.90452 (r=0.909,p=0.900),  time:36.168, tt:3399.836\n",
      "Ep:94, loss:0.00003, loss_test:0.04754, lr:8.78e-03, fs:0.90000 (r=0.909,p=0.891),  time:36.165, tt:3435.655\n",
      "Ep:95, loss:0.00003, loss_test:0.05933, lr:8.69e-03, fs:0.89655 (r=0.919,p=0.875),  time:36.167, tt:3472.006\n",
      "Ep:96, loss:0.00003, loss_test:0.04652, lr:8.60e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.176, tt:3509.078\n",
      "Ep:97, loss:0.00003, loss_test:0.05381, lr:8.51e-03, fs:0.90000 (r=0.909,p=0.891),  time:36.164, tt:3544.058\n",
      "Ep:98, loss:0.00003, loss_test:0.04370, lr:8.43e-03, fs:0.91919 (r=0.919,p=0.919),  time:36.166, tt:3580.390\n",
      "Ep:99, loss:0.00002, loss_test:0.04940, lr:8.35e-03, fs:0.92683 (r=0.960,p=0.896),  time:36.179, tt:3617.877\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.04991, lr:8.35e-03, fs:0.89119 (r=0.869,p=0.915),  time:36.181, tt:3654.281\n",
      "Ep:101, loss:0.00002, loss_test:0.04608, lr:8.35e-03, fs:0.91787 (r=0.960,p=0.880),  time:36.184, tt:3690.723\n",
      "Ep:102, loss:0.00002, loss_test:0.04901, lr:8.35e-03, fs:0.90155 (r=0.879,p=0.926),  time:36.181, tt:3726.670\n",
      "Ep:103, loss:0.00002, loss_test:0.04514, lr:8.35e-03, fs:0.92000 (r=0.929,p=0.911),  time:36.191, tt:3763.861\n",
      "Ep:104, loss:0.00002, loss_test:0.04838, lr:8.35e-03, fs:0.93939 (r=0.939,p=0.939),  time:36.188, tt:3799.766\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.04687, lr:8.35e-03, fs:0.89231 (r=0.879,p=0.906),  time:36.177, tt:3834.770\n",
      "Ep:106, loss:0.00002, loss_test:0.04468, lr:8.35e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.175, tt:3870.710\n",
      "Ep:107, loss:0.00002, loss_test:0.04772, lr:8.35e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.165, tt:3905.826\n",
      "Ep:108, loss:0.00002, loss_test:0.04326, lr:8.35e-03, fs:0.92462 (r=0.929,p=0.920),  time:36.165, tt:3941.977\n",
      "Ep:109, loss:0.00002, loss_test:0.04679, lr:8.35e-03, fs:0.95000 (r=0.960,p=0.941),  time:36.167, tt:3978.360\n",
      "##########Best model found so far##########\n",
      "Ep:110, loss:0.00002, loss_test:0.04376, lr:8.35e-03, fs:0.94000 (r=0.949,p=0.931),  time:36.171, tt:4014.969\n",
      "Ep:111, loss:0.00002, loss_test:0.04548, lr:8.35e-03, fs:0.93939 (r=0.939,p=0.939),  time:36.173, tt:4051.336\n",
      "Ep:112, loss:0.00002, loss_test:0.04431, lr:8.35e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.181, tt:4088.420\n",
      "Ep:113, loss:0.00002, loss_test:0.04332, lr:8.35e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.185, tt:4125.123\n",
      "Ep:114, loss:0.00002, loss_test:0.04662, lr:8.35e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.177, tt:4160.396\n",
      "Ep:115, loss:0.00002, loss_test:0.04310, lr:8.35e-03, fs:0.93000 (r=0.939,p=0.921),  time:36.169, tt:4195.647\n",
      "Ep:116, loss:0.00002, loss_test:0.04459, lr:8.35e-03, fs:0.93939 (r=0.939,p=0.939),  time:36.176, tt:4232.566\n",
      "Ep:117, loss:0.00002, loss_test:0.04312, lr:8.35e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.184, tt:4269.689\n",
      "Ep:118, loss:0.00002, loss_test:0.04435, lr:8.35e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.188, tt:4306.404\n",
      "Ep:119, loss:0.00002, loss_test:0.04434, lr:8.35e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.172, tt:4340.609\n",
      "Ep:120, loss:0.00001, loss_test:0.04385, lr:8.35e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.171, tt:4376.735\n",
      "Ep:121, loss:0.00001, loss_test:0.04347, lr:8.26e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.172, tt:4412.926\n",
      "Ep:122, loss:0.00001, loss_test:0.04536, lr:8.18e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.170, tt:4448.956\n",
      "Ep:123, loss:0.00001, loss_test:0.04231, lr:8.10e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.175, tt:4485.739\n",
      "Ep:124, loss:0.00001, loss_test:0.04649, lr:8.02e-03, fs:0.89583 (r=0.869,p=0.925),  time:36.179, tt:4522.386\n",
      "Ep:125, loss:0.00001, loss_test:0.04188, lr:7.94e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.172, tt:4557.621\n",
      "Ep:126, loss:0.00001, loss_test:0.04470, lr:7.86e-03, fs:0.94527 (r=0.960,p=0.931),  time:36.168, tt:4593.380\n",
      "Ep:127, loss:0.00001, loss_test:0.04406, lr:7.78e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.177, tt:4630.663\n",
      "Ep:128, loss:0.00001, loss_test:0.04275, lr:7.70e-03, fs:0.93939 (r=0.939,p=0.939),  time:36.170, tt:4665.953\n",
      "Ep:129, loss:0.00001, loss_test:0.04502, lr:7.62e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.176, tt:4702.905\n",
      "Ep:130, loss:0.00001, loss_test:0.04161, lr:7.55e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.178, tt:4739.280\n",
      "Ep:131, loss:0.00001, loss_test:0.04469, lr:7.47e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.185, tt:4776.439\n",
      "Ep:132, loss:0.00001, loss_test:0.04311, lr:7.40e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.192, tt:4813.533\n",
      "Ep:133, loss:0.00001, loss_test:0.04370, lr:7.32e-03, fs:0.94527 (r=0.960,p=0.931),  time:36.186, tt:4848.870\n",
      "Ep:134, loss:0.00001, loss_test:0.04377, lr:7.25e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.181, tt:4884.456\n",
      "Ep:135, loss:0.00001, loss_test:0.04259, lr:7.18e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.169, tt:4919.017\n",
      "Ep:136, loss:0.00001, loss_test:0.04419, lr:7.11e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.180, tt:4956.700\n",
      "Ep:137, loss:0.00001, loss_test:0.04218, lr:7.03e-03, fs:0.91919 (r=0.919,p=0.919),  time:36.180, tt:4992.839\n",
      "Ep:138, loss:0.00001, loss_test:0.04600, lr:6.96e-03, fs:0.90155 (r=0.879,p=0.926),  time:36.175, tt:5028.296\n",
      "Ep:139, loss:0.00001, loss_test:0.04245, lr:6.89e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.169, tt:5063.647\n",
      "Ep:140, loss:0.00001, loss_test:0.04426, lr:6.83e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.171, tt:5100.121\n",
      "Ep:141, loss:0.00001, loss_test:0.04167, lr:6.76e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.174, tt:5136.663\n",
      "Ep:142, loss:0.00001, loss_test:0.04424, lr:6.69e-03, fs:0.90155 (r=0.879,p=0.926),  time:36.171, tt:5172.450\n",
      "Ep:143, loss:0.00001, loss_test:0.04250, lr:6.62e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.175, tt:5209.150\n",
      "Ep:144, loss:0.00001, loss_test:0.04309, lr:6.56e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.177, tt:5245.673\n",
      "Ep:145, loss:0.00001, loss_test:0.04391, lr:6.49e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.178, tt:5281.956\n",
      "Ep:146, loss:0.00001, loss_test:0.04445, lr:6.43e-03, fs:0.93939 (r=0.939,p=0.939),  time:36.169, tt:5316.887\n",
      "Ep:147, loss:0.00001, loss_test:0.04285, lr:6.36e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.171, tt:5353.326\n",
      "Ep:148, loss:0.00001, loss_test:0.04425, lr:6.30e-03, fs:0.93401 (r=0.929,p=0.939),  time:36.173, tt:5389.841\n",
      "Ep:149, loss:0.00001, loss_test:0.04241, lr:6.24e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.180, tt:5426.932\n",
      "Ep:150, loss:0.00001, loss_test:0.04474, lr:6.17e-03, fs:0.89005 (r=0.859,p=0.924),  time:36.170, tt:5461.647\n",
      "Ep:151, loss:0.00001, loss_test:0.04255, lr:6.11e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.171, tt:5497.939\n",
      "Ep:152, loss:0.00001, loss_test:0.04446, lr:6.05e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.167, tt:5533.584\n",
      "Ep:153, loss:0.00001, loss_test:0.04226, lr:5.99e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.164, tt:5569.241\n",
      "Ep:154, loss:0.00001, loss_test:0.04371, lr:5.93e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.167, tt:5605.831\n",
      "Ep:155, loss:0.00001, loss_test:0.04256, lr:5.87e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.174, tt:5643.155\n",
      "Ep:156, loss:0.00001, loss_test:0.04212, lr:5.81e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.180, tt:5680.187\n",
      "Ep:157, loss:0.00001, loss_test:0.04356, lr:5.75e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.184, tt:5717.022\n",
      "Ep:158, loss:0.00001, loss_test:0.04431, lr:5.70e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.184, tt:5753.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:159, loss:0.00001, loss_test:0.04169, lr:5.64e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.191, tt:5790.551\n",
      "Ep:160, loss:0.00001, loss_test:0.04443, lr:5.58e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.197, tt:5827.694\n",
      "Ep:161, loss:0.00001, loss_test:0.04339, lr:5.53e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.201, tt:5864.566\n",
      "Ep:162, loss:0.00001, loss_test:0.04315, lr:5.47e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.204, tt:5901.249\n",
      "Ep:163, loss:0.00001, loss_test:0.04217, lr:5.42e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.212, tt:5938.849\n",
      "Ep:164, loss:0.00001, loss_test:0.04528, lr:5.36e-03, fs:0.92929 (r=0.929,p=0.929),  time:36.206, tt:5974.006\n",
      "Ep:165, loss:0.00001, loss_test:0.04212, lr:5.31e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.212, tt:6011.181\n",
      "Ep:166, loss:0.00001, loss_test:0.04399, lr:5.26e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.218, tt:6048.384\n",
      "Ep:167, loss:0.00001, loss_test:0.04367, lr:5.20e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.223, tt:6085.443\n",
      "Ep:168, loss:0.00001, loss_test:0.04273, lr:5.15e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.214, tt:6120.102\n",
      "Ep:169, loss:0.00001, loss_test:0.04440, lr:5.10e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.205, tt:6154.861\n",
      "Ep:170, loss:0.00001, loss_test:0.04279, lr:5.05e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.209, tt:6191.776\n",
      "Ep:171, loss:0.00001, loss_test:0.04368, lr:5.00e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.211, tt:6228.328\n",
      "Ep:172, loss:0.00001, loss_test:0.04313, lr:4.95e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.216, tt:6265.286\n",
      "Ep:173, loss:0.00001, loss_test:0.04264, lr:4.90e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.233, tt:6304.562\n",
      "Ep:174, loss:0.00001, loss_test:0.04392, lr:4.85e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.238, tt:6341.658\n",
      "Ep:175, loss:0.00001, loss_test:0.04303, lr:4.80e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.239, tt:6378.097\n",
      "Ep:176, loss:0.00001, loss_test:0.04299, lr:4.75e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.244, tt:6415.216\n",
      "Ep:177, loss:0.00001, loss_test:0.04506, lr:4.71e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.250, tt:6452.563\n",
      "Ep:178, loss:0.00001, loss_test:0.04283, lr:4.66e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.255, tt:6489.634\n",
      "Ep:179, loss:0.00001, loss_test:0.04391, lr:4.61e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.254, tt:6525.728\n",
      "Ep:180, loss:0.00001, loss_test:0.04457, lr:4.57e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.259, tt:6562.906\n",
      "Ep:181, loss:0.00001, loss_test:0.04254, lr:4.52e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.276, tt:6602.161\n",
      "Ep:182, loss:0.00001, loss_test:0.04495, lr:4.48e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.282, tt:6639.520\n",
      "Ep:183, loss:0.00001, loss_test:0.04261, lr:4.43e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.280, tt:6675.507\n",
      "Ep:184, loss:0.00001, loss_test:0.04285, lr:4.39e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.274, tt:6710.688\n",
      "Ep:185, loss:0.00001, loss_test:0.04433, lr:4.34e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.277, tt:6747.567\n",
      "Ep:186, loss:0.00001, loss_test:0.04301, lr:4.30e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.283, tt:6784.869\n",
      "Ep:187, loss:0.00001, loss_test:0.04279, lr:4.26e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.284, tt:6821.448\n",
      "Ep:188, loss:0.00001, loss_test:0.04450, lr:4.21e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.296, tt:6859.871\n",
      "Ep:189, loss:0.00001, loss_test:0.04289, lr:4.17e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.296, tt:6896.269\n",
      "Ep:190, loss:0.00001, loss_test:0.04344, lr:4.13e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.291, tt:6931.644\n",
      "Ep:191, loss:0.00001, loss_test:0.04386, lr:4.09e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.297, tt:6968.977\n",
      "Ep:192, loss:0.00001, loss_test:0.04312, lr:4.05e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.300, tt:7005.803\n",
      "Ep:193, loss:0.00001, loss_test:0.04365, lr:4.01e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.304, tt:7043.031\n",
      "Ep:194, loss:0.00001, loss_test:0.04324, lr:3.97e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.311, tt:7080.710\n",
      "Ep:195, loss:0.00001, loss_test:0.04336, lr:3.93e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.304, tt:7115.589\n",
      "Ep:196, loss:0.00001, loss_test:0.04359, lr:3.89e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.292, tt:7149.580\n",
      "Ep:197, loss:0.00001, loss_test:0.04319, lr:3.85e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.287, tt:7184.868\n",
      "Ep:198, loss:0.00001, loss_test:0.04395, lr:3.81e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.278, tt:7219.325\n",
      "Ep:199, loss:0.00001, loss_test:0.04340, lr:3.77e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.255, tt:7251.053\n",
      "Ep:200, loss:0.00001, loss_test:0.04345, lr:3.73e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.225, tt:7281.233\n",
      "Ep:201, loss:0.00001, loss_test:0.04364, lr:3.70e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.186, tt:7309.644\n",
      "Ep:202, loss:0.00001, loss_test:0.04279, lr:3.66e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.160, tt:7340.535\n",
      "Ep:203, loss:0.00001, loss_test:0.04351, lr:3.62e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.150, tt:7374.593\n",
      "Ep:204, loss:0.00001, loss_test:0.04339, lr:3.59e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.141, tt:7408.984\n",
      "Ep:205, loss:0.00001, loss_test:0.04392, lr:3.55e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.121, tt:7440.902\n",
      "Ep:206, loss:0.00001, loss_test:0.04334, lr:3.52e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.132, tt:7479.249\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.02144, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:34.489, tt:34.489\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02529, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.513, tt:69.027\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02752, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.512, tt:103.536\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02788, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.004, tt:136.014\n",
      "Ep:4, loss:0.00005, loss_test:0.02715, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.695, tt:168.473\n",
      "Ep:5, loss:0.00005, loss_test:0.02583, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:33.869, tt:203.217\n",
      "Ep:6, loss:0.00005, loss_test:0.02413, lr:6.00e-02, fs:0.65263 (r=0.939,p=0.500),  time:33.777, tt:236.440\n",
      "Ep:7, loss:0.00005, loss_test:0.02266, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:33.734, tt:269.874\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.02162, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:33.591, tt:302.315\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.02082, lr:6.00e-02, fs:0.67969 (r=0.879,p=0.554),  time:33.711, tt:337.107\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.02024, lr:6.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:33.681, tt:370.488\n",
      "Ep:11, loss:0.00004, loss_test:0.02002, lr:6.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:33.653, tt:403.830\n",
      "Ep:12, loss:0.00004, loss_test:0.01981, lr:6.00e-02, fs:0.69118 (r=0.949,p=0.543),  time:33.792, tt:439.297\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01946, lr:6.00e-02, fs:0.66667 (r=0.889,p=0.533),  time:33.836, tt:473.704\n",
      "Ep:14, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.66667 (r=0.869,p=0.541),  time:33.849, tt:507.736\n",
      "Ep:15, loss:0.00004, loss_test:0.01889, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:33.875, tt:541.999\n",
      "Ep:16, loss:0.00004, loss_test:0.01858, lr:6.00e-02, fs:0.67460 (r=0.859,p=0.556),  time:33.924, tt:576.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00004, loss_test:0.01818, lr:6.00e-02, fs:0.68217 (r=0.889,p=0.553),  time:33.907, tt:610.328\n",
      "Ep:18, loss:0.00003, loss_test:0.01776, lr:6.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:33.902, tt:644.143\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01732, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:33.864, tt:677.271\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:33.850, tt:710.854\n",
      "Ep:21, loss:0.00003, loss_test:0.01646, lr:6.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:33.846, tt:744.605\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01610, lr:6.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:33.942, tt:780.673\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:33.963, tt:815.113\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01540, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:33.945, tt:848.634\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01510, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:33.886, tt:881.036\n",
      "Ep:26, loss:0.00003, loss_test:0.01479, lr:6.00e-02, fs:0.75918 (r=0.939,p=0.637),  time:33.897, tt:915.221\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01453, lr:6.00e-02, fs:0.78008 (r=0.949,p=0.662),  time:33.881, tt:948.675\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01431, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:33.880, tt:982.534\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01408, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:33.896, tt:1016.895\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01390, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:33.899, tt:1050.867\n",
      "Ep:31, loss:0.00003, loss_test:0.01375, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:33.894, tt:1084.593\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:33.883, tt:1118.132\n",
      "Ep:33, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:33.905, tt:1152.771\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01326, lr:6.00e-02, fs:0.79498 (r=0.960,p=0.679),  time:33.901, tt:1186.526\n",
      "Ep:35, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:33.871, tt:1219.343\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:33.841, tt:1252.128\n",
      "Ep:37, loss:0.00002, loss_test:0.01292, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:33.848, tt:1286.208\n",
      "Ep:38, loss:0.00002, loss_test:0.01281, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:33.847, tt:1320.019\n",
      "Ep:39, loss:0.00002, loss_test:0.01265, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:33.854, tt:1354.161\n",
      "Ep:40, loss:0.00002, loss_test:0.01252, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:33.876, tt:1388.899\n",
      "Ep:41, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:33.841, tt:1421.338\n",
      "Ep:42, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:33.831, tt:1454.752\n",
      "Ep:43, loss:0.00002, loss_test:0.01228, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:33.797, tt:1487.076\n",
      "Ep:44, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:33.797, tt:1520.852\n",
      "Ep:45, loss:0.00002, loss_test:0.01204, lr:6.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:33.802, tt:1554.895\n",
      "Ep:46, loss:0.00002, loss_test:0.01201, lr:6.00e-02, fs:0.79111 (r=0.899,p=0.706),  time:33.777, tt:1587.500\n",
      "Ep:47, loss:0.00002, loss_test:0.01194, lr:5.94e-02, fs:0.78571 (r=0.889,p=0.704),  time:33.788, tt:1621.802\n",
      "Ep:48, loss:0.00002, loss_test:0.01183, lr:5.88e-02, fs:0.79279 (r=0.889,p=0.715),  time:33.746, tt:1653.558\n",
      "Ep:49, loss:0.00002, loss_test:0.01173, lr:5.82e-02, fs:0.80365 (r=0.889,p=0.733),  time:33.752, tt:1687.585\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01163, lr:5.82e-02, fs:0.80365 (r=0.889,p=0.733),  time:33.766, tt:1722.050\n",
      "Ep:51, loss:0.00002, loss_test:0.01159, lr:5.82e-02, fs:0.80734 (r=0.889,p=0.739),  time:33.768, tt:1755.929\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01145, lr:5.82e-02, fs:0.80365 (r=0.889,p=0.733),  time:33.776, tt:1790.149\n",
      "Ep:53, loss:0.00001, loss_test:0.01144, lr:5.82e-02, fs:0.81106 (r=0.889,p=0.746),  time:33.779, tt:1824.080\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01141, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.792, tt:1858.563\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01134, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.802, tt:1892.911\n",
      "Ep:56, loss:0.00001, loss_test:0.01134, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.834, tt:1928.531\n",
      "Ep:57, loss:0.00001, loss_test:0.01130, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.880, tt:1965.018\n",
      "Ep:58, loss:0.00001, loss_test:0.01120, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:33.892, tt:1999.608\n",
      "Ep:59, loss:0.00001, loss_test:0.01126, lr:5.82e-02, fs:0.81860 (r=0.889,p=0.759),  time:33.927, tt:2035.642\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01123, lr:5.82e-02, fs:0.81860 (r=0.889,p=0.759),  time:33.955, tt:2071.246\n",
      "Ep:61, loss:0.00001, loss_test:0.01116, lr:5.82e-02, fs:0.81860 (r=0.889,p=0.759),  time:33.997, tt:2107.839\n",
      "Ep:62, loss:0.00001, loss_test:0.01122, lr:5.82e-02, fs:0.81860 (r=0.889,p=0.759),  time:34.010, tt:2142.601\n",
      "Ep:63, loss:0.00001, loss_test:0.01120, lr:5.82e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.027, tt:2177.749\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01120, lr:5.82e-02, fs:0.82791 (r=0.899,p=0.767),  time:34.042, tt:2212.725\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01123, lr:5.82e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.042, tt:2246.783\n",
      "Ep:66, loss:0.00001, loss_test:0.01141, lr:5.82e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.068, tt:2282.559\n",
      "Ep:67, loss:0.00001, loss_test:0.01117, lr:5.82e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.083, tt:2317.611\n",
      "Ep:68, loss:0.00001, loss_test:0.01167, lr:5.82e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.097, tt:2352.714\n",
      "Ep:69, loss:0.00001, loss_test:0.01120, lr:5.82e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.138, tt:2389.630\n",
      "Ep:70, loss:0.00001, loss_test:0.01157, lr:5.82e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.129, tt:2423.125\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01122, lr:5.82e-02, fs:0.82464 (r=0.879,p=0.777),  time:34.140, tt:2458.049\n",
      "Ep:72, loss:0.00001, loss_test:0.01154, lr:5.82e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.159, tt:2493.612\n",
      "Ep:73, loss:0.00001, loss_test:0.01130, lr:5.82e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.190, tt:2530.093\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01159, lr:5.82e-02, fs:0.83019 (r=0.889,p=0.779),  time:34.209, tt:2565.699\n",
      "Ep:75, loss:0.00001, loss_test:0.01126, lr:5.82e-02, fs:0.83254 (r=0.879,p=0.791),  time:34.212, tt:2600.143\n",
      "Ep:76, loss:0.00001, loss_test:0.01188, lr:5.82e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.169, tt:2631.027\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01133, lr:5.82e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.183, tt:2666.279\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01177, lr:5.82e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.182, tt:2700.392\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01145, lr:5.82e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.188, tt:2735.038\n",
      "Ep:80, loss:0.00001, loss_test:0.01191, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.173, tt:2767.982\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01165, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.159, tt:2801.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:82, loss:0.00001, loss_test:0.01178, lr:5.82e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.145, tt:2834.018\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01161, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.135, tt:2867.328\n",
      "Ep:84, loss:0.00001, loss_test:0.01211, lr:5.82e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.154, tt:2903.060\n",
      "Ep:85, loss:0.00001, loss_test:0.01198, lr:5.82e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.154, tt:2937.228\n",
      "Ep:86, loss:0.00001, loss_test:0.01154, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.158, tt:2971.783\n",
      "Ep:87, loss:0.00001, loss_test:0.01261, lr:5.82e-02, fs:0.83902 (r=0.869,p=0.811),  time:34.171, tt:3007.025\n",
      "Ep:88, loss:0.00001, loss_test:0.01175, lr:5.82e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.196, tt:3043.468\n",
      "Ep:89, loss:0.00001, loss_test:0.01231, lr:5.82e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.174, tt:3075.663\n",
      "Ep:90, loss:0.00001, loss_test:0.01177, lr:5.82e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.178, tt:3110.203\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.01206, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.188, tt:3145.327\n",
      "Ep:92, loss:0.00001, loss_test:0.01231, lr:5.82e-02, fs:0.85024 (r=0.889,p=0.815),  time:34.198, tt:3180.394\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01198, lr:5.82e-02, fs:0.84211 (r=0.889,p=0.800),  time:34.202, tt:3214.962\n",
      "Ep:94, loss:0.00001, loss_test:0.01243, lr:5.82e-02, fs:0.85854 (r=0.889,p=0.830),  time:34.194, tt:3248.465\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.01221, lr:5.82e-02, fs:0.85437 (r=0.889,p=0.822),  time:34.182, tt:3281.490\n",
      "Ep:96, loss:0.00001, loss_test:0.01265, lr:5.82e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.176, tt:3315.024\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01229, lr:5.82e-02, fs:0.85854 (r=0.889,p=0.830),  time:34.164, tt:3348.026\n",
      "Ep:98, loss:0.00001, loss_test:0.01241, lr:5.82e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.170, tt:3382.818\n",
      "Ep:99, loss:0.00001, loss_test:0.01274, lr:5.82e-02, fs:0.86275 (r=0.889,p=0.838),  time:34.177, tt:3417.702\n",
      "Ep:100, loss:0.00001, loss_test:0.01253, lr:5.82e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.164, tt:3450.552\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00000, loss_test:0.01297, lr:5.82e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.147, tt:3482.957\n",
      "Ep:102, loss:0.00000, loss_test:0.01266, lr:5.82e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.134, tt:3515.800\n",
      "Ep:103, loss:0.00000, loss_test:0.01291, lr:5.82e-02, fs:0.86700 (r=0.889,p=0.846),  time:34.127, tt:3549.166\n",
      "Ep:104, loss:0.00000, loss_test:0.01304, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.125, tt:3583.102\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.01277, lr:5.82e-02, fs:0.87255 (r=0.899,p=0.848),  time:34.111, tt:3615.741\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00000, loss_test:0.01304, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.108, tt:3649.525\n",
      "Ep:107, loss:0.00000, loss_test:0.01317, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.102, tt:3682.977\n",
      "Ep:108, loss:0.00000, loss_test:0.01311, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.113, tt:3718.364\n",
      "Ep:109, loss:0.00000, loss_test:0.01329, lr:5.82e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.113, tt:3752.475\n",
      "Ep:110, loss:0.00000, loss_test:0.01328, lr:5.82e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.122, tt:3787.525\n",
      "Ep:111, loss:0.00000, loss_test:0.01343, lr:5.82e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.133, tt:3822.948\n",
      "Ep:112, loss:0.00000, loss_test:0.01373, lr:5.82e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.157, tt:3859.714\n",
      "Ep:113, loss:0.00000, loss_test:0.01359, lr:5.82e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.176, tt:3896.037\n",
      "Ep:114, loss:0.00000, loss_test:0.01354, lr:5.82e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.189, tt:3931.716\n",
      "Ep:115, loss:0.00000, loss_test:0.01374, lr:5.82e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.201, tt:3967.295\n",
      "Ep:116, loss:0.00000, loss_test:0.01393, lr:5.82e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.213, tt:4002.954\n",
      "##########Best model found so far##########\n",
      "Ep:117, loss:0.00000, loss_test:0.01389, lr:5.82e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.218, tt:4037.757\n",
      "Ep:118, loss:0.00000, loss_test:0.01409, lr:5.82e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.215, tt:4071.638\n",
      "Ep:119, loss:0.00000, loss_test:0.01414, lr:5.82e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.227, tt:4107.261\n",
      "Ep:120, loss:0.00000, loss_test:0.01423, lr:5.82e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.228, tt:4141.580\n",
      "Ep:121, loss:0.00000, loss_test:0.01405, lr:5.82e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.236, tt:4176.799\n",
      "Ep:122, loss:0.00000, loss_test:0.01416, lr:5.82e-02, fs:0.85714 (r=0.848,p=0.866),  time:34.245, tt:4212.178\n",
      "Ep:123, loss:0.00000, loss_test:0.01442, lr:5.82e-02, fs:0.86735 (r=0.859,p=0.876),  time:34.246, tt:4246.455\n",
      "Ep:124, loss:0.00000, loss_test:0.01462, lr:5.82e-02, fs:0.86598 (r=0.848,p=0.884),  time:34.253, tt:4281.589\n",
      "Ep:125, loss:0.00000, loss_test:0.01458, lr:5.82e-02, fs:0.84817 (r=0.818,p=0.880),  time:34.259, tt:4316.619\n",
      "Ep:126, loss:0.00000, loss_test:0.01477, lr:5.82e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.273, tt:4352.713\n",
      "Ep:127, loss:0.00000, loss_test:0.01498, lr:5.82e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.283, tt:4388.195\n",
      "Ep:128, loss:0.00000, loss_test:0.01470, lr:5.76e-02, fs:0.85417 (r=0.828,p=0.882),  time:34.297, tt:4424.357\n",
      "Ep:129, loss:0.00000, loss_test:0.01455, lr:5.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.307, tt:4459.964\n",
      "Ep:130, loss:0.00000, loss_test:0.01491, lr:5.65e-02, fs:0.84211 (r=0.808,p=0.879),  time:34.315, tt:4495.327\n",
      "Ep:131, loss:0.00000, loss_test:0.01527, lr:5.59e-02, fs:0.82796 (r=0.778,p=0.885),  time:34.327, tt:4531.224\n",
      "Ep:132, loss:0.00000, loss_test:0.01483, lr:5.54e-02, fs:0.85864 (r=0.828,p=0.891),  time:34.334, tt:4566.448\n",
      "Ep:133, loss:0.00000, loss_test:0.01486, lr:5.48e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.345, tt:4602.196\n",
      "Ep:134, loss:0.00000, loss_test:0.01535, lr:5.43e-02, fs:0.79781 (r=0.737,p=0.869),  time:34.357, tt:4638.142\n",
      "Ep:135, loss:0.00000, loss_test:0.01508, lr:5.37e-02, fs:0.82353 (r=0.778,p=0.875),  time:34.368, tt:4674.102\n",
      "Ep:136, loss:0.00000, loss_test:0.01521, lr:5.32e-02, fs:0.82979 (r=0.788,p=0.876),  time:34.385, tt:4710.717\n",
      "Ep:137, loss:0.00000, loss_test:0.01554, lr:5.27e-02, fs:0.79558 (r=0.727,p=0.878),  time:34.409, tt:4748.485\n",
      "Ep:138, loss:0.00000, loss_test:0.01542, lr:5.21e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.411, tt:4783.148\n",
      "Ep:139, loss:0.00000, loss_test:0.01556, lr:5.16e-02, fs:0.80226 (r=0.717,p=0.910),  time:34.409, tt:4817.268\n",
      "Ep:140, loss:0.00000, loss_test:0.01578, lr:5.11e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.418, tt:4852.884\n",
      "Ep:141, loss:0.00000, loss_test:0.01563, lr:5.06e-02, fs:0.81111 (r=0.737,p=0.901),  time:34.435, tt:4889.727\n",
      "Ep:142, loss:0.00000, loss_test:0.01568, lr:5.01e-02, fs:0.78652 (r=0.707,p=0.886),  time:34.450, tt:4926.421\n",
      "Ep:143, loss:0.00000, loss_test:0.01588, lr:4.96e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.453, tt:4961.271\n",
      "Ep:144, loss:0.00000, loss_test:0.01577, lr:4.91e-02, fs:0.79545 (r=0.707,p=0.909),  time:34.464, tt:4997.351\n",
      "Ep:145, loss:0.00000, loss_test:0.01567, lr:4.86e-02, fs:0.82222 (r=0.747,p=0.914),  time:34.479, tt:5033.930\n",
      "Ep:146, loss:0.00000, loss_test:0.01607, lr:4.81e-02, fs:0.77966 (r=0.697,p=0.885),  time:34.494, tt:5070.594\n",
      "Ep:147, loss:0.00000, loss_test:0.01581, lr:4.76e-02, fs:0.78857 (r=0.697,p=0.908),  time:34.502, tt:5106.370\n",
      "Ep:148, loss:0.00000, loss_test:0.01592, lr:4.71e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.515, tt:5142.670\n",
      "Ep:149, loss:0.00000, loss_test:0.01622, lr:4.67e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.507, tt:5176.021\n",
      "Ep:150, loss:0.00000, loss_test:0.01591, lr:4.62e-02, fs:0.79310 (r=0.697,p=0.920),  time:34.517, tt:5212.032\n",
      "Ep:151, loss:0.00000, loss_test:0.01611, lr:4.57e-02, fs:0.78161 (r=0.687,p=0.907),  time:34.521, tt:5247.124\n",
      "Ep:152, loss:0.00000, loss_test:0.01635, lr:4.53e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.518, tt:5281.271\n",
      "Ep:153, loss:0.00000, loss_test:0.01617, lr:4.48e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.516, tt:5315.419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:154, loss:0.00000, loss_test:0.01623, lr:4.44e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.519, tt:5350.414\n",
      "Ep:155, loss:0.00000, loss_test:0.01627, lr:4.39e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.532, tt:5386.946\n",
      "Ep:156, loss:0.00000, loss_test:0.01630, lr:4.35e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.518, tt:5419.341\n",
      "Ep:157, loss:0.00000, loss_test:0.01663, lr:4.31e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.516, tt:5453.568\n",
      "Ep:158, loss:0.00000, loss_test:0.01645, lr:4.26e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.522, tt:5489.031\n",
      "Ep:159, loss:0.00000, loss_test:0.01650, lr:4.22e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.518, tt:5522.822\n",
      "Ep:160, loss:0.00000, loss_test:0.01664, lr:4.18e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.521, tt:5557.873\n",
      "Ep:161, loss:0.00000, loss_test:0.01641, lr:4.14e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.531, tt:5593.981\n",
      "Ep:162, loss:0.00000, loss_test:0.01683, lr:4.10e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.534, tt:5629.096\n",
      "Ep:163, loss:0.00000, loss_test:0.01655, lr:4.05e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.543, tt:5664.995\n",
      "Ep:164, loss:0.00000, loss_test:0.01662, lr:4.01e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.551, tt:5700.950\n",
      "Ep:165, loss:0.00000, loss_test:0.01681, lr:3.97e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.551, tt:5735.530\n",
      "Ep:166, loss:0.00000, loss_test:0.01664, lr:3.93e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.559, tt:5771.270\n",
      "Ep:167, loss:0.00000, loss_test:0.01676, lr:3.89e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.574, tt:5808.360\n",
      "Ep:168, loss:0.00000, loss_test:0.01689, lr:3.86e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.565, tt:5841.536\n",
      "Ep:169, loss:0.00000, loss_test:0.01667, lr:3.82e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.573, tt:5877.382\n",
      "Ep:170, loss:0.00000, loss_test:0.01681, lr:3.78e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.587, tt:5914.425\n",
      "Ep:171, loss:0.00000, loss_test:0.01697, lr:3.74e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.581, tt:5947.984\n",
      "Ep:172, loss:0.00000, loss_test:0.01682, lr:3.70e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.578, tt:5982.064\n",
      "Ep:173, loss:0.00000, loss_test:0.01714, lr:3.67e-02, fs:0.77457 (r=0.677,p=0.905),  time:34.581, tt:6017.159\n",
      "Ep:174, loss:0.00000, loss_test:0.01685, lr:3.63e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.575, tt:6050.704\n",
      "Ep:175, loss:0.00000, loss_test:0.01704, lr:3.59e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.572, tt:6084.663\n",
      "Ep:176, loss:0.00000, loss_test:0.01708, lr:3.56e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.567, tt:6118.439\n",
      "Ep:177, loss:0.00000, loss_test:0.01690, lr:3.52e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.582, tt:6155.539\n",
      "Ep:178, loss:0.00000, loss_test:0.01726, lr:3.49e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.586, tt:6190.863\n",
      "Ep:179, loss:0.00000, loss_test:0.01690, lr:3.45e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.591, tt:6226.442\n",
      "Ep:180, loss:0.00000, loss_test:0.01728, lr:3.42e-02, fs:0.77907 (r=0.677,p=0.918),  time:34.593, tt:6261.272\n",
      "Ep:181, loss:0.00000, loss_test:0.01709, lr:3.38e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.597, tt:6296.742\n",
      "Ep:182, loss:0.00000, loss_test:0.01717, lr:3.35e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.595, tt:6330.889\n",
      "Ep:183, loss:0.00000, loss_test:0.01716, lr:3.32e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.601, tt:6366.605\n",
      "Ep:184, loss:0.00000, loss_test:0.01718, lr:3.28e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.619, tt:6404.514\n",
      "Ep:185, loss:0.00000, loss_test:0.01721, lr:3.25e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.626, tt:6440.346\n",
      "Ep:186, loss:0.00000, loss_test:0.01729, lr:3.22e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.625, tt:6474.883\n",
      "Ep:187, loss:0.00000, loss_test:0.01718, lr:3.19e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.636, tt:6511.583\n",
      "Ep:188, loss:0.00000, loss_test:0.01733, lr:3.15e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.635, tt:6545.974\n",
      "Ep:189, loss:0.00000, loss_test:0.01731, lr:3.12e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.643, tt:6582.190\n",
      "Ep:190, loss:0.00000, loss_test:0.01734, lr:3.09e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.654, tt:6618.976\n",
      "Ep:191, loss:0.00000, loss_test:0.01742, lr:3.06e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.649, tt:6652.569\n",
      "Ep:192, loss:0.00000, loss_test:0.01730, lr:3.03e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.654, tt:6688.145\n",
      "Ep:193, loss:0.00000, loss_test:0.01748, lr:3.00e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.660, tt:6724.069\n",
      "Ep:194, loss:0.00000, loss_test:0.01736, lr:2.97e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.664, tt:6759.536\n",
      "Ep:195, loss:0.00000, loss_test:0.01755, lr:2.94e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.670, tt:6795.398\n",
      "Ep:196, loss:0.00000, loss_test:0.01741, lr:2.91e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.682, tt:6832.308\n",
      "Ep:197, loss:0.00000, loss_test:0.01763, lr:2.88e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.684, tt:6867.495\n",
      "Ep:198, loss:0.00000, loss_test:0.01744, lr:2.85e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.683, tt:6901.910\n",
      "Ep:199, loss:0.00000, loss_test:0.01760, lr:2.82e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.694, tt:6938.800\n",
      "Ep:200, loss:0.00000, loss_test:0.01749, lr:2.80e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.706, tt:6975.907\n",
      "Ep:201, loss:0.00000, loss_test:0.01756, lr:2.77e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.704, tt:7010.307\n",
      "Ep:202, loss:0.00000, loss_test:0.01762, lr:2.74e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.699, tt:7043.942\n",
      "Ep:203, loss:0.00000, loss_test:0.01755, lr:2.71e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.687, tt:7076.245\n",
      "Ep:204, loss:0.00000, loss_test:0.01765, lr:2.69e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.690, tt:7111.505\n",
      "Ep:205, loss:0.00000, loss_test:0.01752, lr:2.66e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.679, tt:7143.850\n",
      "Ep:206, loss:0.00000, loss_test:0.01770, lr:2.63e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.648, tt:7172.105\n",
      "Ep:207, loss:0.00000, loss_test:0.01761, lr:2.61e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.627, tt:7202.499\n",
      "Ep:208, loss:0.00000, loss_test:0.01771, lr:2.58e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.633, tt:7238.318\n",
      "Ep:209, loss:0.00000, loss_test:0.01769, lr:2.55e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.626, tt:7271.454\n",
      "Ep:210, loss:0.00000, loss_test:0.01772, lr:2.53e-02, fs:0.78363 (r=0.677,p=0.931),  time:34.630, tt:7306.896\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13266, lr:1.00e-02, fs:0.64493 (r=0.899,p=0.503),  time:35.848, tt:35.848\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00026, loss_test:0.12788, lr:1.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:36.841, tt:73.682\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12211, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:36.614, tt:109.843\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11736, lr:1.00e-02, fs:0.67742 (r=0.848,p=0.564),  time:37.183, tt:148.731\n",
      "Ep:4, loss:0.00025, loss_test:0.11423, lr:1.00e-02, fs:0.68852 (r=0.848,p=0.579),  time:37.139, tt:185.694\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11170, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:37.152, tt:222.910\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11004, lr:1.00e-02, fs:0.71667 (r=0.869,p=0.610),  time:36.842, tt:257.891\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10903, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:36.794, tt:294.352\n",
      "Ep:8, loss:0.00023, loss_test:0.10821, lr:1.00e-02, fs:0.70339 (r=0.838,p=0.606),  time:36.611, tt:329.502\n",
      "Ep:9, loss:0.00022, loss_test:0.10729, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:36.721, tt:367.206\n",
      "Ep:10, loss:0.00022, loss_test:0.10607, lr:1.00e-02, fs:0.71186 (r=0.848,p=0.613),  time:36.766, tt:404.429\n",
      "Ep:11, loss:0.00021, loss_test:0.10385, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:36.861, tt:442.328\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:12, loss:0.00020, loss_test:0.10098, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:36.825, tt:478.725\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09893, lr:1.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:36.837, tt:515.713\n",
      "Ep:14, loss:0.00019, loss_test:0.09690, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:36.945, tt:554.177\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09412, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:36.933, tt:590.923\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09185, lr:1.00e-02, fs:0.76652 (r=0.879,p=0.680),  time:36.897, tt:627.255\n",
      "Ep:17, loss:0.00017, loss_test:0.08989, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:36.902, tt:664.231\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08693, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:36.950, tt:702.044\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08581, lr:1.00e-02, fs:0.76444 (r=0.869,p=0.683),  time:37.010, tt:740.195\n",
      "Ep:20, loss:0.00016, loss_test:0.08322, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:37.099, tt:779.082\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08220, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:37.134, tt:816.943\n",
      "Ep:22, loss:0.00015, loss_test:0.08037, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:37.158, tt:854.643\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07969, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:37.216, tt:893.185\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07792, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:37.197, tt:929.916\n",
      "Ep:25, loss:0.00014, loss_test:0.07797, lr:1.00e-02, fs:0.81081 (r=0.909,p=0.732),  time:37.245, tt:968.369\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07552, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:37.208, tt:1004.619\n",
      "Ep:27, loss:0.00013, loss_test:0.07499, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:37.231, tt:1042.467\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07357, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:37.224, tt:1079.485\n",
      "Ep:29, loss:0.00012, loss_test:0.07377, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:37.199, tt:1115.980\n",
      "Ep:30, loss:0.00012, loss_test:0.07166, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:37.203, tt:1153.298\n",
      "Ep:31, loss:0.00011, loss_test:0.07054, lr:1.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:37.220, tt:1191.025\n",
      "Ep:32, loss:0.00011, loss_test:0.07140, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:37.213, tt:1228.016\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07093, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:37.209, tt:1265.091\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.06956, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:37.169, tt:1300.924\n",
      "Ep:35, loss:0.00010, loss_test:0.06885, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:37.151, tt:1337.439\n",
      "Ep:36, loss:0.00010, loss_test:0.06813, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:37.172, tt:1375.374\n",
      "Ep:37, loss:0.00009, loss_test:0.06701, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:37.203, tt:1413.709\n",
      "Ep:38, loss:0.00009, loss_test:0.06605, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:37.183, tt:1450.133\n",
      "Ep:39, loss:0.00009, loss_test:0.06800, lr:1.00e-02, fs:0.83258 (r=0.929,p=0.754),  time:37.184, tt:1487.340\n",
      "Ep:40, loss:0.00009, loss_test:0.06541, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:37.216, tt:1525.852\n",
      "Ep:41, loss:0.00009, loss_test:0.06555, lr:1.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:37.233, tt:1563.796\n",
      "Ep:42, loss:0.00008, loss_test:0.06942, lr:1.00e-02, fs:0.85202 (r=0.960,p=0.766),  time:37.205, tt:1599.795\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06611, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:37.189, tt:1636.332\n",
      "Ep:44, loss:0.00009, loss_test:0.06300, lr:1.00e-02, fs:0.86256 (r=0.919,p=0.812),  time:37.187, tt:1673.415\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00008, loss_test:0.06450, lr:1.00e-02, fs:0.84545 (r=0.939,p=0.769),  time:37.190, tt:1710.761\n",
      "Ep:46, loss:0.00008, loss_test:0.06346, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:37.177, tt:1747.324\n",
      "Ep:47, loss:0.00007, loss_test:0.06320, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:37.182, tt:1784.748\n",
      "Ep:48, loss:0.00007, loss_test:0.06172, lr:1.00e-02, fs:0.85294 (r=0.879,p=0.829),  time:37.207, tt:1823.155\n",
      "Ep:49, loss:0.00007, loss_test:0.06201, lr:1.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:37.195, tt:1859.742\n",
      "Ep:50, loss:0.00007, loss_test:0.06096, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:37.171, tt:1895.733\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00007, loss_test:0.05960, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:37.183, tt:1933.497\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.06023, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:37.202, tt:1971.711\n",
      "Ep:53, loss:0.00006, loss_test:0.05943, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:37.177, tt:2007.546\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.05969, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:37.173, tt:2044.526\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00006, loss_test:0.05886, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:37.143, tt:2080.031\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00006, loss_test:0.06494, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:37.120, tt:2115.833\n",
      "Ep:57, loss:0.00006, loss_test:0.05841, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:37.146, tt:2154.476\n",
      "Ep:58, loss:0.00006, loss_test:0.05742, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:37.153, tt:2192.012\n",
      "Ep:59, loss:0.00006, loss_test:0.05811, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:37.137, tt:2228.242\n",
      "Ep:60, loss:0.00005, loss_test:0.05609, lr:1.00e-02, fs:0.89447 (r=0.899,p=0.890),  time:37.121, tt:2264.379\n",
      "Ep:61, loss:0.00005, loss_test:0.05807, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:37.116, tt:2301.198\n",
      "Ep:62, loss:0.00005, loss_test:0.05640, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:37.092, tt:2336.793\n",
      "Ep:63, loss:0.00005, loss_test:0.05774, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:37.069, tt:2372.392\n",
      "Ep:64, loss:0.00005, loss_test:0.05612, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:37.068, tt:2409.420\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00005, loss_test:0.05717, lr:1.00e-02, fs:0.88462 (r=0.929,p=0.844),  time:37.030, tt:2443.992\n",
      "Ep:66, loss:0.00005, loss_test:0.05574, lr:1.00e-02, fs:0.89552 (r=0.909,p=0.882),  time:37.032, tt:2481.164\n",
      "Ep:67, loss:0.00005, loss_test:0.05601, lr:1.00e-02, fs:0.88889 (r=0.889,p=0.889),  time:37.013, tt:2516.907\n",
      "Ep:68, loss:0.00004, loss_test:0.05919, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:36.980, tt:2551.610\n",
      "Ep:69, loss:0.00005, loss_test:0.05836, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:36.981, tt:2588.637\n",
      "Ep:70, loss:0.00004, loss_test:0.05827, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:36.965, tt:2624.540\n",
      "Ep:71, loss:0.00005, loss_test:0.05522, lr:1.00e-02, fs:0.89474 (r=0.859,p=0.934),  time:36.985, tt:2662.905\n",
      "Ep:72, loss:0.00005, loss_test:0.06314, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:36.990, tt:2700.244\n",
      "Ep:73, loss:0.00005, loss_test:0.05698, lr:1.00e-02, fs:0.88660 (r=0.869,p=0.905),  time:36.960, tt:2735.008\n",
      "Ep:74, loss:0.00005, loss_test:0.05320, lr:1.00e-02, fs:0.91457 (r=0.919,p=0.910),  time:36.941, tt:2770.598\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00005, loss_test:0.05986, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:36.940, tt:2807.452\n",
      "Ep:76, loss:0.00005, loss_test:0.06018, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:36.926, tt:2843.330\n",
      "Ep:77, loss:0.00005, loss_test:0.05638, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:36.925, tt:2880.187\n",
      "Ep:78, loss:0.00005, loss_test:0.05710, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:36.905, tt:2915.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:79, loss:0.00005, loss_test:0.05984, lr:1.00e-02, fs:0.88350 (r=0.919,p=0.850),  time:36.891, tt:2951.283\n",
      "Ep:80, loss:0.00005, loss_test:0.05614, lr:1.00e-02, fs:0.87879 (r=0.879,p=0.879),  time:36.887, tt:2987.822\n",
      "Ep:81, loss:0.00004, loss_test:0.05621, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.879, tt:3024.041\n",
      "Ep:82, loss:0.00004, loss_test:0.05417, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:36.859, tt:3059.261\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00004, loss_test:0.05527, lr:1.00e-02, fs:0.88325 (r=0.879,p=0.888),  time:36.832, tt:3093.857\n",
      "Ep:84, loss:0.00004, loss_test:0.05420, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:36.838, tt:3131.267\n",
      "Ep:85, loss:0.00004, loss_test:0.05448, lr:1.00e-02, fs:0.89340 (r=0.889,p=0.898),  time:36.835, tt:3167.768\n",
      "Ep:86, loss:0.00003, loss_test:0.05380, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:36.826, tt:3203.882\n",
      "Ep:87, loss:0.00003, loss_test:0.05305, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:36.828, tt:3240.889\n",
      "Ep:88, loss:0.00003, loss_test:0.05346, lr:1.00e-02, fs:0.89231 (r=0.879,p=0.906),  time:36.830, tt:3277.905\n",
      "Ep:89, loss:0.00003, loss_test:0.05424, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.817, tt:3313.551\n",
      "Ep:90, loss:0.00003, loss_test:0.05136, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.834, tt:3351.891\n",
      "Ep:91, loss:0.00003, loss_test:0.05303, lr:1.00e-02, fs:0.90000 (r=0.909,p=0.891),  time:36.824, tt:3387.810\n",
      "Ep:92, loss:0.00003, loss_test:0.05286, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.817, tt:3423.953\n",
      "Ep:93, loss:0.00003, loss_test:0.05282, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:36.798, tt:3459.013\n",
      "Ep:94, loss:0.00003, loss_test:0.05474, lr:9.90e-03, fs:0.90452 (r=0.909,p=0.900),  time:36.801, tt:3496.056\n",
      "Ep:95, loss:0.00003, loss_test:0.05283, lr:9.80e-03, fs:0.90000 (r=0.909,p=0.891),  time:36.795, tt:3532.278\n",
      "Ep:96, loss:0.00003, loss_test:0.05401, lr:9.70e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.790, tt:3568.599\n",
      "Ep:97, loss:0.00003, loss_test:0.05348, lr:9.61e-03, fs:0.90452 (r=0.909,p=0.900),  time:36.790, tt:3605.373\n",
      "Ep:98, loss:0.00003, loss_test:0.05288, lr:9.51e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.793, tt:3642.552\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00002, loss_test:0.05268, lr:9.51e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.782, tt:3678.241\n",
      "Ep:100, loss:0.00002, loss_test:0.05336, lr:9.51e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.778, tt:3714.580\n",
      "Ep:101, loss:0.00002, loss_test:0.05277, lr:9.51e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.774, tt:3750.987\n",
      "Ep:102, loss:0.00002, loss_test:0.05217, lr:9.51e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.770, tt:3787.354\n",
      "Ep:103, loss:0.00002, loss_test:0.05359, lr:9.51e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.778, tt:3824.893\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00003, loss_test:0.05362, lr:9.51e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.773, tt:3861.193\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00002, loss_test:0.05342, lr:9.51e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.784, tt:3899.094\n",
      "Ep:106, loss:0.00002, loss_test:0.05424, lr:9.51e-03, fs:0.89552 (r=0.909,p=0.882),  time:36.795, tt:3937.050\n",
      "Ep:107, loss:0.00002, loss_test:0.05429, lr:9.51e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.801, tt:3974.529\n",
      "Ep:108, loss:0.00002, loss_test:0.05516, lr:9.51e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.807, tt:4011.915\n",
      "Ep:109, loss:0.00002, loss_test:0.05797, lr:9.51e-03, fs:0.89000 (r=0.899,p=0.881),  time:36.811, tt:4049.224\n",
      "Ep:110, loss:0.00002, loss_test:0.05530, lr:9.51e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.809, tt:4085.854\n",
      "Ep:111, loss:0.00002, loss_test:0.05374, lr:9.51e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.816, tt:4123.372\n",
      "Ep:112, loss:0.00002, loss_test:0.05691, lr:9.51e-03, fs:0.89552 (r=0.909,p=0.882),  time:36.803, tt:4158.744\n",
      "Ep:113, loss:0.00002, loss_test:0.05526, lr:9.51e-03, fs:0.89474 (r=0.859,p=0.934),  time:36.796, tt:4194.727\n",
      "Ep:114, loss:0.00002, loss_test:0.05656, lr:9.51e-03, fs:0.88670 (r=0.909,p=0.865),  time:36.799, tt:4231.902\n",
      "Ep:115, loss:0.00002, loss_test:0.05395, lr:9.51e-03, fs:0.91005 (r=0.869,p=0.956),  time:36.795, tt:4268.261\n",
      "Ep:116, loss:0.00002, loss_test:0.05707, lr:9.41e-03, fs:0.89109 (r=0.909,p=0.874),  time:36.799, tt:4305.510\n",
      "Ep:117, loss:0.00002, loss_test:0.05359, lr:9.32e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.801, tt:4342.540\n",
      "Ep:118, loss:0.00002, loss_test:0.05461, lr:9.23e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.809, tt:4380.279\n",
      "Ep:119, loss:0.00002, loss_test:0.05232, lr:9.14e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.813, tt:4417.533\n",
      "Ep:120, loss:0.00002, loss_test:0.05480, lr:9.04e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.807, tt:4453.684\n",
      "Ep:121, loss:0.00002, loss_test:0.05275, lr:8.95e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.805, tt:4490.221\n",
      "Ep:122, loss:0.00002, loss_test:0.05359, lr:8.86e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.797, tt:4526.092\n",
      "Ep:123, loss:0.00002, loss_test:0.05367, lr:8.78e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.788, tt:4561.716\n",
      "Ep:124, loss:0.00002, loss_test:0.05408, lr:8.69e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.784, tt:4597.960\n",
      "Ep:125, loss:0.00001, loss_test:0.05311, lr:8.60e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.774, tt:4633.474\n",
      "Ep:126, loss:0.00002, loss_test:0.05442, lr:8.51e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.787, tt:4671.989\n",
      "Ep:127, loss:0.00001, loss_test:0.05249, lr:8.43e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.781, tt:4707.967\n",
      "Ep:128, loss:0.00001, loss_test:0.05391, lr:8.35e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.765, tt:4742.668\n",
      "Ep:129, loss:0.00001, loss_test:0.05328, lr:8.26e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.767, tt:4779.675\n",
      "Ep:130, loss:0.00001, loss_test:0.05362, lr:8.18e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.777, tt:4817.726\n",
      "Ep:131, loss:0.00001, loss_test:0.05386, lr:8.10e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.781, tt:4855.126\n",
      "Ep:132, loss:0.00001, loss_test:0.05436, lr:8.02e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.787, tt:4892.700\n",
      "Ep:133, loss:0.00001, loss_test:0.05374, lr:7.94e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.786, tt:4929.322\n",
      "Ep:134, loss:0.00001, loss_test:0.05380, lr:7.86e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.784, tt:4965.809\n",
      "Ep:135, loss:0.00001, loss_test:0.05366, lr:7.78e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.792, tt:5003.704\n",
      "Ep:136, loss:0.00001, loss_test:0.05426, lr:7.70e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.795, tt:5040.874\n",
      "Ep:137, loss:0.00001, loss_test:0.05407, lr:7.62e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.804, tt:5078.978\n",
      "Ep:138, loss:0.00001, loss_test:0.05447, lr:7.55e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.802, tt:5115.446\n",
      "Ep:139, loss:0.00001, loss_test:0.05503, lr:7.47e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.792, tt:5150.925\n",
      "Ep:140, loss:0.00001, loss_test:0.05418, lr:7.40e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.788, tt:5187.096\n",
      "Ep:141, loss:0.00001, loss_test:0.05425, lr:7.32e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.773, tt:5221.716\n",
      "Ep:142, loss:0.00001, loss_test:0.05447, lr:7.25e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.763, tt:5257.166\n",
      "Ep:143, loss:0.00001, loss_test:0.05389, lr:7.18e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.768, tt:5294.565\n",
      "Ep:144, loss:0.00001, loss_test:0.05604, lr:7.11e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.753, tt:5329.152\n",
      "Ep:145, loss:0.00001, loss_test:0.05407, lr:7.03e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.756, tt:5366.446\n",
      "Ep:146, loss:0.00001, loss_test:0.05537, lr:6.96e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.759, tt:5403.582\n",
      "Ep:147, loss:0.00001, loss_test:0.05330, lr:6.89e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.759, tt:5440.278\n",
      "Ep:148, loss:0.00001, loss_test:0.05635, lr:6.83e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.753, tt:5476.244\n",
      "Ep:149, loss:0.00001, loss_test:0.05420, lr:6.76e-03, fs:0.93264 (r=0.909,p=0.957),  time:36.752, tt:5512.828\n",
      "##########Best model found so far##########\n",
      "Ep:150, loss:0.00001, loss_test:0.05675, lr:6.76e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.741, tt:5547.912\n",
      "Ep:151, loss:0.00001, loss_test:0.05496, lr:6.76e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.741, tt:5584.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00001, loss_test:0.05687, lr:6.76e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.743, tt:5621.722\n",
      "Ep:153, loss:0.00001, loss_test:0.05592, lr:6.76e-03, fs:0.92784 (r=0.909,p=0.947),  time:36.738, tt:5657.689\n",
      "Ep:154, loss:0.00001, loss_test:0.05734, lr:6.76e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.731, tt:5693.288\n",
      "Ep:155, loss:0.00001, loss_test:0.05576, lr:6.76e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.729, tt:5729.727\n",
      "Ep:156, loss:0.00001, loss_test:0.05553, lr:6.76e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.726, tt:5766.035\n",
      "Ep:157, loss:0.00001, loss_test:0.05485, lr:6.76e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.724, tt:5802.402\n",
      "Ep:158, loss:0.00001, loss_test:0.05657, lr:6.76e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.708, tt:5836.526\n",
      "Ep:159, loss:0.00001, loss_test:0.05439, lr:6.76e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.700, tt:5871.966\n",
      "Ep:160, loss:0.00001, loss_test:0.05430, lr:6.76e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.691, tt:5907.296\n",
      "Ep:161, loss:0.00001, loss_test:0.05594, lr:6.69e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.692, tt:5944.139\n",
      "Ep:162, loss:0.00001, loss_test:0.05476, lr:6.62e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.689, tt:5980.335\n",
      "Ep:163, loss:0.00001, loss_test:0.05495, lr:6.56e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.708, tt:6020.049\n",
      "Ep:164, loss:0.00001, loss_test:0.05474, lr:6.49e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.706, tt:6056.419\n",
      "Ep:165, loss:0.00001, loss_test:0.05552, lr:6.43e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.700, tt:6092.166\n",
      "Ep:166, loss:0.00001, loss_test:0.05504, lr:6.36e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.704, tt:6129.615\n",
      "Ep:167, loss:0.00001, loss_test:0.05523, lr:6.30e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.691, tt:6164.018\n",
      "Ep:168, loss:0.00001, loss_test:0.05497, lr:6.24e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.693, tt:6201.066\n",
      "Ep:169, loss:0.00001, loss_test:0.05541, lr:6.17e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.691, tt:6237.468\n",
      "Ep:170, loss:0.00001, loss_test:0.05485, lr:6.11e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.689, tt:6273.774\n",
      "Ep:171, loss:0.00001, loss_test:0.05535, lr:6.05e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.686, tt:6310.012\n",
      "Ep:172, loss:0.00001, loss_test:0.05534, lr:5.99e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.680, tt:6345.658\n",
      "Ep:173, loss:0.00001, loss_test:0.05487, lr:5.93e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.679, tt:6382.062\n",
      "Ep:174, loss:0.00001, loss_test:0.05541, lr:5.87e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.678, tt:6418.652\n",
      "Ep:175, loss:0.00001, loss_test:0.05551, lr:5.81e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.669, tt:6453.784\n",
      "Ep:176, loss:0.00001, loss_test:0.05534, lr:5.75e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.662, tt:6489.090\n",
      "Ep:177, loss:0.00001, loss_test:0.05513, lr:5.70e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.653, tt:6524.253\n",
      "Ep:178, loss:0.00001, loss_test:0.05549, lr:5.64e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.654, tt:6561.081\n",
      "Ep:179, loss:0.00001, loss_test:0.05535, lr:5.58e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.649, tt:6596.755\n",
      "Ep:180, loss:0.00001, loss_test:0.05561, lr:5.53e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.633, tt:6630.494\n",
      "Ep:181, loss:0.00001, loss_test:0.05574, lr:5.47e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.628, tt:6666.228\n",
      "Ep:182, loss:0.00001, loss_test:0.05563, lr:5.42e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.624, tt:6702.110\n",
      "Ep:183, loss:0.00001, loss_test:0.05578, lr:5.36e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.618, tt:6737.738\n",
      "Ep:184, loss:0.00001, loss_test:0.05629, lr:5.31e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.622, tt:6775.106\n",
      "Ep:185, loss:0.00001, loss_test:0.05560, lr:5.26e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.625, tt:6812.196\n",
      "Ep:186, loss:0.00001, loss_test:0.05607, lr:5.20e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.622, tt:6848.227\n",
      "Ep:187, loss:0.00001, loss_test:0.05561, lr:5.15e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.622, tt:6884.909\n",
      "Ep:188, loss:0.00001, loss_test:0.05663, lr:5.10e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.613, tt:6919.825\n",
      "Ep:189, loss:0.00001, loss_test:0.05619, lr:5.05e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.615, tt:6956.846\n",
      "Ep:190, loss:0.00001, loss_test:0.05622, lr:5.00e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.611, tt:6992.746\n",
      "Ep:191, loss:0.00001, loss_test:0.05566, lr:4.95e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.612, tt:7029.477\n",
      "Ep:192, loss:0.00001, loss_test:0.05555, lr:4.90e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.608, tt:7065.433\n",
      "Ep:193, loss:0.00001, loss_test:0.05604, lr:4.85e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.606, tt:7101.611\n",
      "Ep:194, loss:0.00001, loss_test:0.05611, lr:4.80e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.607, tt:7138.418\n",
      "Ep:195, loss:0.00001, loss_test:0.05627, lr:4.75e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.600, tt:7173.584\n",
      "Ep:196, loss:0.00001, loss_test:0.05542, lr:4.71e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.599, tt:7209.915\n",
      "Ep:197, loss:0.00001, loss_test:0.05594, lr:4.66e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.599, tt:7246.684\n",
      "Ep:198, loss:0.00001, loss_test:0.05598, lr:4.61e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.578, tt:7279.052\n",
      "Ep:199, loss:0.00001, loss_test:0.05549, lr:4.57e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.566, tt:7313.138\n",
      "Ep:200, loss:0.00001, loss_test:0.05605, lr:4.52e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.552, tt:7346.865\n",
      "Ep:201, loss:0.00001, loss_test:0.05602, lr:4.48e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.534, tt:7379.899\n",
      "Ep:202, loss:0.00001, loss_test:0.05587, lr:4.43e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.509, tt:7411.337\n",
      "Ep:203, loss:0.00001, loss_test:0.05574, lr:4.39e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.491, tt:7444.192\n",
      "Ep:204, loss:0.00001, loss_test:0.05627, lr:4.34e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.479, tt:7478.216\n",
      "Ep:205, loss:0.00001, loss_test:0.05610, lr:4.30e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.444, tt:7507.378\n",
      "Ep:206, loss:0.00001, loss_test:0.05573, lr:4.26e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.396, tt:7533.889\n",
      "Ep:207, loss:0.00001, loss_test:0.05599, lr:4.21e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.366, tt:7564.076\n",
      "Ep:208, loss:0.00001, loss_test:0.05621, lr:4.17e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.352, tt:7597.507\n",
      "Ep:209, loss:0.00001, loss_test:0.05604, lr:4.13e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.337, tt:7630.693\n",
      "Ep:210, loss:0.00001, loss_test:0.05607, lr:4.09e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.323, tt:7664.096\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.02195, lr:6.00e-02, fs:0.64684 (r=0.879,p=0.512),  time:35.108, tt:35.108\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02659, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:34.383, tt:68.767\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02893, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.191, tt:105.573\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00006, loss_test:0.02941, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.136, tt:140.545\n",
      "Ep:4, loss:0.00006, loss_test:0.02882, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.045, tt:175.227\n",
      "Ep:5, loss:0.00005, loss_test:0.02740, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:34.925, tt:209.549\n",
      "Ep:6, loss:0.00005, loss_test:0.02566, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:34.917, tt:244.418\n",
      "Ep:7, loss:0.00005, loss_test:0.02395, lr:6.00e-02, fs:0.64311 (r=0.919,p=0.495),  time:35.069, tt:280.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00005, loss_test:0.02266, lr:6.00e-02, fs:0.65909 (r=0.879,p=0.527),  time:35.078, tt:315.700\n",
      "Ep:9, loss:0.00005, loss_test:0.02197, lr:6.00e-02, fs:0.65873 (r=0.838,p=0.542),  time:35.027, tt:350.268\n",
      "Ep:10, loss:0.00005, loss_test:0.02124, lr:6.00e-02, fs:0.66142 (r=0.848,p=0.542),  time:35.054, tt:385.591\n",
      "Ep:11, loss:0.00004, loss_test:0.02088, lr:6.00e-02, fs:0.66423 (r=0.919,p=0.520),  time:35.129, tt:421.551\n",
      "Ep:12, loss:0.00004, loss_test:0.02103, lr:6.00e-02, fs:0.67384 (r=0.949,p=0.522),  time:35.160, tt:457.082\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02067, lr:6.00e-02, fs:0.67148 (r=0.939,p=0.522),  time:35.042, tt:490.591\n",
      "Ep:14, loss:0.00004, loss_test:0.02010, lr:6.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:35.033, tt:525.502\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01983, lr:6.00e-02, fs:0.65891 (r=0.859,p=0.535),  time:35.087, tt:561.387\n",
      "Ep:16, loss:0.00004, loss_test:0.01959, lr:6.00e-02, fs:0.65882 (r=0.848,p=0.538),  time:35.118, tt:597.001\n",
      "Ep:17, loss:0.00004, loss_test:0.01933, lr:6.00e-02, fs:0.65637 (r=0.859,p=0.531),  time:35.174, tt:633.139\n",
      "Ep:18, loss:0.00004, loss_test:0.01915, lr:6.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:35.281, tt:670.334\n",
      "Ep:19, loss:0.00004, loss_test:0.01890, lr:6.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:35.300, tt:705.995\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01859, lr:6.00e-02, fs:0.66409 (r=0.869,p=0.537),  time:35.301, tt:741.331\n",
      "Ep:21, loss:0.00004, loss_test:0.01830, lr:6.00e-02, fs:0.67442 (r=0.879,p=0.547),  time:35.453, tt:779.967\n",
      "Ep:22, loss:0.00003, loss_test:0.01796, lr:6.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:35.447, tt:815.278\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01760, lr:6.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:35.467, tt:851.206\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01725, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:35.461, tt:886.523\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:35.383, tt:919.950\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:35.415, tt:956.208\n",
      "Ep:27, loss:0.00003, loss_test:0.01638, lr:6.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:35.410, tt:991.479\n",
      "Ep:28, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.72727 (r=0.929,p=0.597),  time:35.446, tt:1027.938\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.73725 (r=0.949,p=0.603),  time:35.457, tt:1063.707\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01562, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:35.427, tt:1098.234\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01537, lr:6.00e-02, fs:0.74900 (r=0.949,p=0.618),  time:35.392, tt:1132.549\n",
      "Ep:32, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:35.384, tt:1167.663\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01494, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.380, tt:1202.937\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01478, lr:6.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:35.346, tt:1237.094\n",
      "Ep:35, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.77108 (r=0.970,p=0.640),  time:35.344, tt:1272.366\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01446, lr:6.00e-02, fs:0.77733 (r=0.970,p=0.649),  time:35.371, tt:1308.723\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.01428, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:35.371, tt:1344.096\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.78689 (r=0.970,p=0.662),  time:35.361, tt:1379.076\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:35.376, tt:1415.043\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01394, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:35.417, tt:1452.083\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:35.399, tt:1486.768\n",
      "Ep:42, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:35.408, tt:1522.563\n",
      "Ep:43, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:35.414, tt:1558.221\n",
      "Ep:44, loss:0.00002, loss_test:0.01354, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:35.445, tt:1595.005\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01338, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:35.454, tt:1630.880\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:35.489, tt:1667.965\n",
      "Ep:47, loss:0.00002, loss_test:0.01310, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:35.529, tt:1705.395\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01302, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:35.525, tt:1740.734\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01299, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:35.522, tt:1776.110\n",
      "Ep:50, loss:0.00002, loss_test:0.01292, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:35.530, tt:1812.026\n",
      "Ep:51, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:35.542, tt:1848.209\n",
      "Ep:52, loss:0.00002, loss_test:0.01272, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:35.547, tt:1883.976\n",
      "Ep:53, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:35.563, tt:1920.384\n",
      "Ep:54, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:35.557, tt:1955.633\n",
      "Ep:55, loss:0.00002, loss_test:0.01234, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:35.569, tt:1991.860\n",
      "Ep:56, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:35.571, tt:2027.551\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00001, loss_test:0.01224, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:35.578, tt:2063.513\n",
      "Ep:58, loss:0.00001, loss_test:0.01214, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:35.579, tt:2099.172\n",
      "Ep:59, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:35.589, tt:2135.335\n",
      "Ep:60, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:35.608, tt:2172.086\n",
      "Ep:61, loss:0.00001, loss_test:0.01195, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:35.619, tt:2208.397\n",
      "Ep:62, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:35.610, tt:2243.445\n",
      "Ep:63, loss:0.00001, loss_test:0.01197, lr:6.00e-02, fs:0.80734 (r=0.889,p=0.739),  time:35.638, tt:2280.805\n",
      "Ep:64, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.80365 (r=0.889,p=0.733),  time:35.627, tt:2315.723\n",
      "Ep:65, loss:0.00001, loss_test:0.01196, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:35.648, tt:2352.790\n",
      "Ep:66, loss:0.00001, loss_test:0.01193, lr:6.00e-02, fs:0.81106 (r=0.889,p=0.746),  time:35.645, tt:2388.218\n",
      "Ep:67, loss:0.00001, loss_test:0.01205, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:35.644, tt:2423.761\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:35.656, tt:2460.232\n",
      "Ep:69, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.81481 (r=0.889,p=0.752),  time:35.657, tt:2496.003\n",
      "Ep:70, loss:0.00001, loss_test:0.01218, lr:6.00e-02, fs:0.80751 (r=0.869,p=0.754),  time:35.638, tt:2530.282\n",
      "Ep:71, loss:0.00001, loss_test:0.01192, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:35.643, tt:2566.278\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01234, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.608, tt:2599.415\n",
      "Ep:73, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:35.605, tt:2634.778\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:74, loss:0.00001, loss_test:0.01225, lr:6.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:35.611, tt:2670.811\n",
      "Ep:75, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:35.636, tt:2708.342\n",
      "Ep:76, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:35.639, tt:2744.238\n",
      "Ep:77, loss:0.00001, loss_test:0.01192, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:35.602, tt:2776.958\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01195, lr:6.00e-02, fs:0.81905 (r=0.869,p=0.775),  time:35.587, tt:2811.346\n",
      "Ep:79, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.577, tt:2846.157\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.561, tt:2880.468\n",
      "Ep:81, loss:0.00001, loss_test:0.01246, lr:6.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:35.559, tt:2915.820\n",
      "Ep:82, loss:0.00001, loss_test:0.01211, lr:6.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:35.566, tt:2951.983\n",
      "Ep:83, loss:0.00001, loss_test:0.01225, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:35.564, tt:2987.401\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01239, lr:6.00e-02, fs:0.83495 (r=0.869,p=0.804),  time:35.586, tt:3024.810\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01221, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:35.595, tt:3061.159\n",
      "Ep:86, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.607, tt:3097.834\n",
      "##########Best model found so far##########\n",
      "Ep:87, loss:0.00001, loss_test:0.01245, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.600, tt:3132.801\n",
      "Ep:88, loss:0.00001, loss_test:0.01244, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.596, tt:3168.013\n",
      "Ep:89, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.593, tt:3203.372\n",
      "Ep:90, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.600, tt:3239.610\n",
      "Ep:91, loss:0.00001, loss_test:0.01241, lr:6.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:35.607, tt:3275.885\n",
      "Ep:92, loss:0.00001, loss_test:0.01269, lr:6.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:35.616, tt:3312.251\n",
      "Ep:93, loss:0.00001, loss_test:0.01242, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.632, tt:3349.366\n",
      "Ep:94, loss:0.00001, loss_test:0.01238, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.651, tt:3386.817\n",
      "Ep:95, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.83582 (r=0.848,p=0.824),  time:35.647, tt:3422.108\n",
      "Ep:96, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.641, tt:3457.155\n",
      "Ep:97, loss:0.00001, loss_test:0.01253, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:35.666, tt:3495.254\n",
      "Ep:98, loss:0.00001, loss_test:0.01297, lr:5.94e-02, fs:0.82759 (r=0.848,p=0.808),  time:35.688, tt:3533.105\n",
      "Ep:99, loss:0.00001, loss_test:0.01270, lr:5.88e-02, fs:0.84878 (r=0.879,p=0.821),  time:35.696, tt:3569.649\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01267, lr:5.88e-02, fs:0.83333 (r=0.859,p=0.810),  time:35.695, tt:3605.234\n",
      "Ep:101, loss:0.00001, loss_test:0.01257, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:35.701, tt:3641.505\n",
      "Ep:102, loss:0.00001, loss_test:0.01264, lr:5.88e-02, fs:0.84729 (r=0.869,p=0.827),  time:35.714, tt:3678.551\n",
      "Ep:103, loss:0.00001, loss_test:0.01282, lr:5.88e-02, fs:0.84158 (r=0.859,p=0.825),  time:35.727, tt:3715.642\n",
      "Ep:104, loss:0.00001, loss_test:0.01278, lr:5.88e-02, fs:0.85000 (r=0.859,p=0.842),  time:35.739, tt:3752.582\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00001, loss_test:0.01310, lr:5.88e-02, fs:0.84158 (r=0.859,p=0.825),  time:35.756, tt:3790.135\n",
      "Ep:106, loss:0.00001, loss_test:0.01296, lr:5.88e-02, fs:0.85572 (r=0.869,p=0.843),  time:35.773, tt:3827.722\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01285, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:35.766, tt:3862.725\n",
      "Ep:108, loss:0.00001, loss_test:0.01325, lr:5.88e-02, fs:0.85149 (r=0.869,p=0.835),  time:35.760, tt:3897.882\n",
      "Ep:109, loss:0.00000, loss_test:0.01323, lr:5.88e-02, fs:0.85427 (r=0.859,p=0.850),  time:35.757, tt:3933.255\n",
      "Ep:110, loss:0.00000, loss_test:0.01349, lr:5.88e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.757, tt:3968.992\n",
      "Ep:111, loss:0.00001, loss_test:0.01319, lr:5.88e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.753, tt:4004.307\n",
      "Ep:112, loss:0.00000, loss_test:0.01323, lr:5.88e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.754, tt:4040.219\n",
      "Ep:113, loss:0.00000, loss_test:0.01358, lr:5.88e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.738, tt:4074.122\n",
      "Ep:114, loss:0.00000, loss_test:0.01312, lr:5.88e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.721, tt:4107.884\n",
      "Ep:115, loss:0.00000, loss_test:0.01335, lr:5.88e-02, fs:0.84000 (r=0.848,p=0.832),  time:35.713, tt:4142.727\n",
      "Ep:116, loss:0.00000, loss_test:0.01373, lr:5.88e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.721, tt:4179.314\n",
      "Ep:117, loss:0.00000, loss_test:0.01325, lr:5.88e-02, fs:0.84422 (r=0.848,p=0.840),  time:35.740, tt:4217.302\n",
      "Ep:118, loss:0.00000, loss_test:0.01341, lr:5.82e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.731, tt:4251.989\n",
      "Ep:119, loss:0.00000, loss_test:0.01364, lr:5.76e-02, fs:0.84577 (r=0.859,p=0.833),  time:35.721, tt:4286.557\n",
      "Ep:120, loss:0.00000, loss_test:0.01360, lr:5.71e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.724, tt:4322.632\n",
      "Ep:121, loss:0.00000, loss_test:0.01397, lr:5.65e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.733, tt:4359.371\n",
      "Ep:122, loss:0.00000, loss_test:0.01384, lr:5.59e-02, fs:0.82828 (r=0.828,p=0.828),  time:35.724, tt:4394.046\n",
      "Ep:123, loss:0.00000, loss_test:0.01384, lr:5.54e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.720, tt:4429.326\n",
      "Ep:124, loss:0.00000, loss_test:0.01384, lr:5.48e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.723, tt:4465.376\n",
      "Ep:125, loss:0.00000, loss_test:0.01386, lr:5.43e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.725, tt:4501.375\n",
      "Ep:126, loss:0.00000, loss_test:0.01419, lr:5.37e-02, fs:0.82653 (r=0.818,p=0.835),  time:35.728, tt:4537.410\n",
      "Ep:127, loss:0.00000, loss_test:0.01413, lr:5.32e-02, fs:0.84848 (r=0.848,p=0.848),  time:35.717, tt:4571.734\n",
      "Ep:128, loss:0.00000, loss_test:0.01400, lr:5.27e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.717, tt:4607.532\n",
      "Ep:129, loss:0.00000, loss_test:0.01425, lr:5.21e-02, fs:0.82653 (r=0.818,p=0.835),  time:35.709, tt:4642.132\n",
      "Ep:130, loss:0.00000, loss_test:0.01403, lr:5.16e-02, fs:0.84264 (r=0.838,p=0.847),  time:35.697, tt:4676.243\n",
      "Ep:131, loss:0.00000, loss_test:0.01411, lr:5.11e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.681, tt:4709.914\n",
      "Ep:132, loss:0.00000, loss_test:0.01418, lr:5.06e-02, fs:0.85279 (r=0.848,p=0.857),  time:35.664, tt:4743.301\n",
      "Ep:133, loss:0.00000, loss_test:0.01429, lr:5.01e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.662, tt:4778.705\n",
      "Ep:134, loss:0.00000, loss_test:0.01440, lr:4.96e-02, fs:0.82105 (r=0.788,p=0.857),  time:35.653, tt:4813.188\n",
      "Ep:135, loss:0.00000, loss_test:0.01430, lr:4.91e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.646, tt:4847.811\n",
      "Ep:136, loss:0.00000, loss_test:0.01448, lr:4.86e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.651, tt:4884.154\n",
      "Ep:137, loss:0.00000, loss_test:0.01452, lr:4.81e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.660, tt:4921.037\n",
      "Ep:138, loss:0.00000, loss_test:0.01445, lr:4.76e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.659, tt:4956.627\n",
      "Ep:139, loss:0.00000, loss_test:0.01453, lr:4.71e-02, fs:0.84536 (r=0.828,p=0.863),  time:35.661, tt:4992.492\n",
      "Ep:140, loss:0.00000, loss_test:0.01461, lr:4.67e-02, fs:0.83770 (r=0.808,p=0.870),  time:35.666, tt:5028.840\n",
      "Ep:141, loss:0.00000, loss_test:0.01454, lr:4.62e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.646, tt:5061.664\n",
      "Ep:142, loss:0.00000, loss_test:0.01470, lr:4.57e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.641, tt:5096.728\n",
      "Ep:143, loss:0.00000, loss_test:0.01462, lr:4.53e-02, fs:0.84375 (r=0.818,p=0.871),  time:35.635, tt:5131.431\n",
      "Ep:144, loss:0.00000, loss_test:0.01467, lr:4.48e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.628, tt:5165.993\n",
      "##########Best model found so far##########\n",
      "Ep:145, loss:0.00000, loss_test:0.01469, lr:4.48e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.634, tt:5202.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.01474, lr:4.48e-02, fs:0.86010 (r=0.838,p=0.883),  time:35.632, tt:5237.941\n",
      "Ep:147, loss:0.00000, loss_test:0.01485, lr:4.48e-02, fs:0.80000 (r=0.747,p=0.860),  time:35.630, tt:5273.195\n",
      "Ep:148, loss:0.00000, loss_test:0.01468, lr:4.48e-02, fs:0.83938 (r=0.818,p=0.862),  time:35.626, tt:5308.206\n",
      "Ep:149, loss:0.00000, loss_test:0.01495, lr:4.48e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.625, tt:5343.722\n",
      "Ep:150, loss:0.00000, loss_test:0.01472, lr:4.48e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.620, tt:5378.581\n",
      "Ep:151, loss:0.00000, loss_test:0.01468, lr:4.48e-02, fs:0.83333 (r=0.808,p=0.860),  time:35.619, tt:5414.063\n",
      "Ep:152, loss:0.00000, loss_test:0.01501, lr:4.48e-02, fs:0.78919 (r=0.737,p=0.849),  time:35.607, tt:5447.930\n",
      "Ep:153, loss:0.00000, loss_test:0.01456, lr:4.48e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.598, tt:5482.101\n",
      "Ep:154, loss:0.00000, loss_test:0.01472, lr:4.48e-02, fs:0.80645 (r=0.758,p=0.862),  time:35.591, tt:5516.633\n",
      "Ep:155, loss:0.00000, loss_test:0.01480, lr:4.48e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.585, tt:5551.303\n",
      "Ep:156, loss:0.00000, loss_test:0.01479, lr:4.44e-02, fs:0.84211 (r=0.808,p=0.879),  time:35.579, tt:5585.870\n",
      "Ep:157, loss:0.00000, loss_test:0.01492, lr:4.39e-02, fs:0.79348 (r=0.737,p=0.859),  time:35.558, tt:5618.190\n",
      "Ep:158, loss:0.00000, loss_test:0.01472, lr:4.35e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.544, tt:5651.570\n",
      "Ep:159, loss:0.00000, loss_test:0.01488, lr:4.31e-02, fs:0.82979 (r=0.788,p=0.876),  time:35.526, tt:5684.179\n",
      "Ep:160, loss:0.00000, loss_test:0.01495, lr:4.26e-02, fs:0.80435 (r=0.747,p=0.871),  time:35.514, tt:5717.778\n",
      "Ep:161, loss:0.00000, loss_test:0.01485, lr:4.22e-02, fs:0.83598 (r=0.798,p=0.878),  time:35.516, tt:5753.511\n",
      "Ep:162, loss:0.00000, loss_test:0.01519, lr:4.18e-02, fs:0.78689 (r=0.727,p=0.857),  time:35.510, tt:5788.198\n",
      "Ep:163, loss:0.00000, loss_test:0.01488, lr:4.14e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.503, tt:5822.413\n",
      "Ep:164, loss:0.00000, loss_test:0.01509, lr:4.10e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.500, tt:5857.572\n",
      "Ep:165, loss:0.00000, loss_test:0.01511, lr:4.05e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.503, tt:5893.448\n",
      "Ep:166, loss:0.00000, loss_test:0.01502, lr:4.01e-02, fs:0.84492 (r=0.798,p=0.898),  time:35.491, tt:5926.926\n",
      "Ep:167, loss:0.00000, loss_test:0.01517, lr:3.97e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.485, tt:5961.451\n",
      "Ep:168, loss:0.00000, loss_test:0.01501, lr:3.93e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.478, tt:5995.700\n",
      "Ep:169, loss:0.00000, loss_test:0.01522, lr:3.89e-02, fs:0.77095 (r=0.697,p=0.863),  time:35.472, tt:6030.226\n",
      "Ep:170, loss:0.00000, loss_test:0.01514, lr:3.86e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.474, tt:6066.082\n",
      "Ep:171, loss:0.00000, loss_test:0.01525, lr:3.82e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.466, tt:6100.102\n",
      "Ep:172, loss:0.00000, loss_test:0.01516, lr:3.78e-02, fs:0.83243 (r=0.778,p=0.895),  time:35.465, tt:6135.425\n",
      "Ep:173, loss:0.00000, loss_test:0.01526, lr:3.74e-02, fs:0.79330 (r=0.717,p=0.887),  time:35.458, tt:6169.690\n",
      "Ep:174, loss:0.00000, loss_test:0.01533, lr:3.70e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.444, tt:6202.719\n",
      "Ep:175, loss:0.00000, loss_test:0.01536, lr:3.67e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.433, tt:6236.233\n",
      "Ep:176, loss:0.00000, loss_test:0.01540, lr:3.63e-02, fs:0.77528 (r=0.697,p=0.873),  time:35.437, tt:6272.261\n",
      "Ep:177, loss:0.00000, loss_test:0.01541, lr:3.59e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.436, tt:6307.624\n",
      "Ep:178, loss:0.00000, loss_test:0.01540, lr:3.56e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.434, tt:6342.676\n",
      "Ep:179, loss:0.00000, loss_test:0.01541, lr:3.52e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.425, tt:6376.576\n",
      "Ep:180, loss:0.00000, loss_test:0.01549, lr:3.49e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.417, tt:6410.407\n",
      "Ep:181, loss:0.00000, loss_test:0.01552, lr:3.45e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.414, tt:6445.264\n",
      "Ep:182, loss:0.00000, loss_test:0.01552, lr:3.42e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.412, tt:6480.388\n",
      "Ep:183, loss:0.00000, loss_test:0.01547, lr:3.38e-02, fs:0.80000 (r=0.727,p=0.889),  time:35.413, tt:6515.986\n",
      "Ep:184, loss:0.00000, loss_test:0.01561, lr:3.35e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.413, tt:6551.425\n",
      "Ep:185, loss:0.00000, loss_test:0.01549, lr:3.32e-02, fs:0.81319 (r=0.747,p=0.892),  time:35.402, tt:6584.780\n",
      "Ep:186, loss:0.00000, loss_test:0.01558, lr:3.28e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.404, tt:6620.604\n",
      "Ep:187, loss:0.00000, loss_test:0.01549, lr:3.25e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.394, tt:6654.062\n",
      "Ep:188, loss:0.00000, loss_test:0.01555, lr:3.22e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.393, tt:6689.185\n",
      "Ep:189, loss:0.00000, loss_test:0.01559, lr:3.19e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.377, tt:6721.660\n",
      "Ep:190, loss:0.00000, loss_test:0.01560, lr:3.15e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.383, tt:6758.114\n",
      "Ep:191, loss:0.00000, loss_test:0.01561, lr:3.12e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.380, tt:6792.873\n",
      "Ep:192, loss:0.00000, loss_test:0.01563, lr:3.09e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.380, tt:6828.262\n",
      "Ep:193, loss:0.00000, loss_test:0.01571, lr:3.06e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.374, tt:6862.605\n",
      "Ep:194, loss:0.00000, loss_test:0.01563, lr:3.03e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.365, tt:6896.260\n",
      "Ep:195, loss:0.00000, loss_test:0.01569, lr:3.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.365, tt:6931.446\n",
      "Ep:196, loss:0.00000, loss_test:0.01564, lr:2.97e-02, fs:0.77273 (r=0.687,p=0.883),  time:35.355, tt:6965.026\n",
      "Ep:197, loss:0.00000, loss_test:0.01571, lr:2.94e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.355, tt:7000.309\n",
      "Ep:198, loss:0.00000, loss_test:0.01568, lr:2.91e-02, fs:0.78652 (r=0.707,p=0.886),  time:35.356, tt:7035.851\n",
      "Ep:199, loss:0.00000, loss_test:0.01574, lr:2.88e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.363, tt:7072.677\n",
      "Ep:200, loss:0.00000, loss_test:0.01566, lr:2.85e-02, fs:0.79096 (r=0.707,p=0.897),  time:35.348, tt:7104.996\n",
      "Ep:201, loss:0.00000, loss_test:0.01578, lr:2.82e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.336, tt:7137.887\n",
      "Ep:202, loss:0.00000, loss_test:0.01566, lr:2.80e-02, fs:0.78409 (r=0.697,p=0.896),  time:35.322, tt:7170.350\n",
      "Ep:203, loss:0.00000, loss_test:0.01578, lr:2.77e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.306, tt:7202.409\n",
      "Ep:204, loss:0.00000, loss_test:0.01570, lr:2.74e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.288, tt:7234.098\n",
      "Ep:205, loss:0.00000, loss_test:0.01579, lr:2.71e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.269, tt:7265.485\n",
      "Ep:206, loss:0.00000, loss_test:0.01572, lr:2.69e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.236, tt:7293.874\n",
      "Ep:207, loss:0.00000, loss_test:0.01583, lr:2.66e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.229, tt:7327.590\n",
      "Ep:208, loss:0.00000, loss_test:0.01579, lr:2.63e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.223, tt:7361.656\n",
      "Ep:209, loss:0.00000, loss_test:0.01584, lr:2.61e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.226, tt:7397.505\n",
      "Ep:210, loss:0.00000, loss_test:0.01583, lr:2.58e-02, fs:0.77011 (r=0.677,p=0.893),  time:35.224, tt:7432.223\n",
      "Ep:211, loss:0.00000, loss_test:0.01582, lr:2.55e-02, fs:0.77714 (r=0.687,p=0.895),  time:35.214, tt:7465.459\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13573, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:33.399, tt:33.399\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13036, lr:1.00e-02, fs:0.65704 (r=0.919,p=0.511),  time:34.150, tt:68.299\n",
      "Ep:2, loss:0.00026, loss_test:0.12339, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:34.433, tt:103.298\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.11880, lr:1.00e-02, fs:0.68313 (r=0.838,p=0.576),  time:34.552, tt:138.207\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00025, loss_test:0.11592, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:34.741, tt:173.704\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11437, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.114, tt:210.685\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11424, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:35.528, tt:248.696\n",
      "Ep:7, loss:0.00023, loss_test:0.11181, lr:1.00e-02, fs:0.71074 (r=0.869,p=0.601),  time:35.657, tt:285.259\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10882, lr:1.00e-02, fs:0.70588 (r=0.848,p=0.604),  time:35.746, tt:321.710\n",
      "Ep:9, loss:0.00022, loss_test:0.10663, lr:1.00e-02, fs:0.71730 (r=0.859,p=0.616),  time:35.801, tt:358.014\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10491, lr:1.00e-02, fs:0.72803 (r=0.879,p=0.621),  time:35.903, tt:394.934\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10312, lr:1.00e-02, fs:0.73640 (r=0.889,p=0.629),  time:35.976, tt:431.714\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10147, lr:1.00e-02, fs:0.73950 (r=0.889,p=0.633),  time:36.004, tt:468.047\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09939, lr:1.00e-02, fs:0.74043 (r=0.879,p=0.640),  time:36.085, tt:505.196\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.09683, lr:1.00e-02, fs:0.75000 (r=0.879,p=0.654),  time:36.245, tt:543.678\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09489, lr:1.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:36.372, tt:581.954\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09252, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:36.427, tt:619.265\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.09053, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:36.387, tt:654.970\n",
      "Ep:18, loss:0.00016, loss_test:0.08891, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:36.343, tt:690.513\n",
      "Ep:19, loss:0.00016, loss_test:0.08787, lr:1.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:36.303, tt:726.064\n",
      "Ep:20, loss:0.00015, loss_test:0.08642, lr:1.00e-02, fs:0.78414 (r=0.899,p=0.695),  time:36.370, tt:763.760\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08502, lr:1.00e-02, fs:0.78761 (r=0.899,p=0.701),  time:36.418, tt:801.197\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08399, lr:1.00e-02, fs:0.77729 (r=0.899,p=0.685),  time:36.380, tt:836.746\n",
      "Ep:23, loss:0.00014, loss_test:0.08361, lr:1.00e-02, fs:0.78539 (r=0.869,p=0.717),  time:36.352, tt:872.440\n",
      "Ep:24, loss:0.00014, loss_test:0.08301, lr:1.00e-02, fs:0.79825 (r=0.919,p=0.705),  time:36.397, tt:909.924\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.08093, lr:1.00e-02, fs:0.78924 (r=0.889,p=0.710),  time:36.431, tt:947.201\n",
      "Ep:26, loss:0.00013, loss_test:0.08180, lr:1.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:36.465, tt:984.556\n",
      "Ep:27, loss:0.00013, loss_test:0.07988, lr:1.00e-02, fs:0.80189 (r=0.859,p=0.752),  time:36.505, tt:1022.146\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.08077, lr:1.00e-02, fs:0.77447 (r=0.919,p=0.669),  time:36.563, tt:1060.328\n",
      "Ep:29, loss:0.00012, loss_test:0.07661, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:36.566, tt:1096.984\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00012, loss_test:0.07801, lr:1.00e-02, fs:0.80176 (r=0.919,p=0.711),  time:36.641, tt:1135.876\n",
      "Ep:31, loss:0.00011, loss_test:0.07501, lr:1.00e-02, fs:0.81818 (r=0.909,p=0.744),  time:36.671, tt:1173.472\n",
      "Ep:32, loss:0.00012, loss_test:0.07509, lr:1.00e-02, fs:0.83105 (r=0.919,p=0.758),  time:36.680, tt:1210.427\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.07332, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:36.690, tt:1247.472\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00010, loss_test:0.07254, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:36.708, tt:1284.763\n",
      "Ep:35, loss:0.00010, loss_test:0.07153, lr:1.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:36.668, tt:1320.063\n",
      "Ep:36, loss:0.00010, loss_test:0.07169, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:36.709, tt:1358.230\n",
      "Ep:37, loss:0.00009, loss_test:0.07057, lr:1.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:36.743, tt:1396.244\n",
      "Ep:38, loss:0.00009, loss_test:0.07090, lr:1.00e-02, fs:0.85714 (r=0.939,p=0.788),  time:36.732, tt:1432.547\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.06944, lr:1.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:36.722, tt:1468.892\n",
      "Ep:40, loss:0.00008, loss_test:0.06745, lr:1.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:36.734, tt:1506.087\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.06847, lr:1.00e-02, fs:0.82949 (r=0.909,p=0.763),  time:36.720, tt:1542.227\n",
      "Ep:42, loss:0.00008, loss_test:0.06889, lr:1.00e-02, fs:0.85981 (r=0.929,p=0.800),  time:36.728, tt:1579.286\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.06897, lr:1.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:36.705, tt:1615.022\n",
      "Ep:44, loss:0.00008, loss_test:0.06614, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:36.691, tt:1651.117\n",
      "Ep:45, loss:0.00008, loss_test:0.06487, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:36.684, tt:1687.457\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00007, loss_test:0.06691, lr:1.00e-02, fs:0.83178 (r=0.899,p=0.774),  time:36.619, tt:1721.079\n",
      "Ep:47, loss:0.00007, loss_test:0.06963, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:36.640, tt:1758.726\n",
      "Ep:48, loss:0.00007, loss_test:0.06395, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:36.615, tt:1794.154\n",
      "Ep:49, loss:0.00007, loss_test:0.06373, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.611, tt:1830.558\n",
      "Ep:50, loss:0.00007, loss_test:0.06767, lr:1.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:36.612, tt:1867.216\n",
      "Ep:51, loss:0.00007, loss_test:0.06277, lr:1.00e-02, fs:0.87805 (r=0.909,p=0.849),  time:36.621, tt:1904.302\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00006, loss_test:0.06337, lr:1.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:36.607, tt:1940.193\n",
      "Ep:53, loss:0.00006, loss_test:0.06055, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:36.608, tt:1976.846\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.06187, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:36.646, tt:2015.525\n",
      "Ep:55, loss:0.00006, loss_test:0.06442, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:36.631, tt:2051.312\n",
      "Ep:56, loss:0.00006, loss_test:0.06906, lr:1.00e-02, fs:0.83784 (r=0.939,p=0.756),  time:36.645, tt:2088.793\n",
      "Ep:57, loss:0.00006, loss_test:0.05894, lr:1.00e-02, fs:0.86538 (r=0.909,p=0.826),  time:36.648, tt:2125.589\n",
      "Ep:58, loss:0.00006, loss_test:0.05920, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:36.645, tt:2162.083\n",
      "Ep:59, loss:0.00006, loss_test:0.06532, lr:1.00e-02, fs:0.85185 (r=0.929,p=0.786),  time:36.631, tt:2197.854\n",
      "Ep:60, loss:0.00006, loss_test:0.05759, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:36.629, tt:2234.350\n",
      "Ep:61, loss:0.00006, loss_test:0.06199, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:36.647, tt:2272.142\n",
      "Ep:62, loss:0.00005, loss_test:0.06254, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:36.641, tt:2308.401\n",
      "Ep:63, loss:0.00005, loss_test:0.05673, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:36.624, tt:2343.916\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00006, loss_test:0.06599, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:36.644, tt:2381.889\n",
      "Ep:65, loss:0.00006, loss_test:0.05448, lr:1.00e-02, fs:0.90909 (r=0.909,p=0.909),  time:36.659, tt:2419.500\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00005, loss_test:0.06178, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:36.673, tt:2457.066\n",
      "Ep:67, loss:0.00005, loss_test:0.05816, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:36.672, tt:2493.681\n",
      "Ep:68, loss:0.00005, loss_test:0.05982, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:36.676, tt:2530.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00004, loss_test:0.05606, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:36.689, tt:2568.241\n",
      "Ep:70, loss:0.00004, loss_test:0.06151, lr:1.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:36.677, tt:2604.055\n",
      "Ep:71, loss:0.00004, loss_test:0.05430, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:36.680, tt:2640.950\n",
      "Ep:72, loss:0.00004, loss_test:0.05990, lr:1.00e-02, fs:0.87619 (r=0.929,p=0.829),  time:36.667, tt:2676.727\n",
      "Ep:73, loss:0.00004, loss_test:0.05467, lr:1.00e-02, fs:0.89000 (r=0.899,p=0.881),  time:36.685, tt:2714.707\n",
      "Ep:74, loss:0.00004, loss_test:0.06004, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:36.699, tt:2752.419\n",
      "Ep:75, loss:0.00004, loss_test:0.05336, lr:1.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:36.707, tt:2789.719\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00004, loss_test:0.05881, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:36.715, tt:2827.039\n",
      "Ep:77, loss:0.00004, loss_test:0.05544, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:36.711, tt:2863.466\n",
      "Ep:78, loss:0.00004, loss_test:0.05665, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:36.710, tt:2900.102\n",
      "Ep:79, loss:0.00004, loss_test:0.05518, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:36.712, tt:2936.954\n",
      "Ep:80, loss:0.00003, loss_test:0.05628, lr:1.00e-02, fs:0.85714 (r=0.879,p=0.837),  time:36.676, tt:2970.737\n",
      "Ep:81, loss:0.00003, loss_test:0.05347, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.654, tt:3005.648\n",
      "Ep:82, loss:0.00003, loss_test:0.05720, lr:1.00e-02, fs:0.86154 (r=0.848,p=0.875),  time:36.666, tt:3043.271\n",
      "Ep:83, loss:0.00003, loss_test:0.05349, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:36.665, tt:3079.858\n",
      "Ep:84, loss:0.00003, loss_test:0.05471, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:36.673, tt:3117.221\n",
      "Ep:85, loss:0.00003, loss_test:0.05289, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:36.696, tt:3155.828\n",
      "Ep:86, loss:0.00003, loss_test:0.05522, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:36.721, tt:3194.743\n",
      "Ep:87, loss:0.00003, loss_test:0.05462, lr:9.90e-03, fs:0.87629 (r=0.859,p=0.895),  time:36.747, tt:3233.698\n",
      "Ep:88, loss:0.00003, loss_test:0.05031, lr:9.80e-03, fs:0.91542 (r=0.929,p=0.902),  time:36.754, tt:3271.138\n",
      "Ep:89, loss:0.00003, loss_test:0.06642, lr:9.70e-03, fs:0.82353 (r=0.848,p=0.800),  time:36.745, tt:3307.074\n",
      "Ep:90, loss:0.00003, loss_test:0.05035, lr:9.61e-03, fs:0.91457 (r=0.919,p=0.910),  time:36.758, tt:3344.948\n",
      "Ep:91, loss:0.00003, loss_test:0.05937, lr:9.51e-03, fs:0.87255 (r=0.899,p=0.848),  time:36.769, tt:3382.740\n",
      "Ep:92, loss:0.00003, loss_test:0.05105, lr:9.41e-03, fs:0.90355 (r=0.899,p=0.908),  time:36.781, tt:3420.600\n",
      "Ep:93, loss:0.00003, loss_test:0.05554, lr:9.32e-03, fs:0.87805 (r=0.909,p=0.849),  time:36.797, tt:3458.896\n",
      "Ep:94, loss:0.00003, loss_test:0.05235, lr:9.23e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.804, tt:3496.403\n",
      "Ep:95, loss:0.00003, loss_test:0.05145, lr:9.14e-03, fs:0.88889 (r=0.889,p=0.889),  time:36.811, tt:3533.850\n",
      "Ep:96, loss:0.00002, loss_test:0.05238, lr:9.04e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.811, tt:3570.715\n",
      "Ep:97, loss:0.00002, loss_test:0.05554, lr:8.95e-03, fs:0.88889 (r=0.889,p=0.889),  time:36.805, tt:3606.922\n",
      "Ep:98, loss:0.00002, loss_test:0.04919, lr:8.86e-03, fs:0.90547 (r=0.919,p=0.892),  time:36.808, tt:3643.959\n",
      "Ep:99, loss:0.00002, loss_test:0.05831, lr:8.78e-03, fs:0.84375 (r=0.818,p=0.871),  time:36.828, tt:3682.753\n",
      "Ep:100, loss:0.00002, loss_test:0.04944, lr:8.69e-03, fs:0.91000 (r=0.919,p=0.901),  time:36.835, tt:3720.364\n",
      "Ep:101, loss:0.00002, loss_test:0.05617, lr:8.60e-03, fs:0.87562 (r=0.889,p=0.863),  time:36.836, tt:3757.247\n",
      "Ep:102, loss:0.00002, loss_test:0.05083, lr:8.51e-03, fs:0.89231 (r=0.879,p=0.906),  time:36.846, tt:3795.167\n",
      "Ep:103, loss:0.00002, loss_test:0.05201, lr:8.43e-03, fs:0.89552 (r=0.909,p=0.882),  time:36.832, tt:3830.547\n",
      "Ep:104, loss:0.00002, loss_test:0.05196, lr:8.35e-03, fs:0.88205 (r=0.869,p=0.896),  time:36.828, tt:3866.944\n",
      "Ep:105, loss:0.00002, loss_test:0.05158, lr:8.26e-03, fs:0.87755 (r=0.869,p=0.887),  time:36.824, tt:3903.352\n",
      "Ep:106, loss:0.00002, loss_test:0.05147, lr:8.18e-03, fs:0.89899 (r=0.899,p=0.899),  time:36.820, tt:3939.706\n",
      "Ep:107, loss:0.00002, loss_test:0.05157, lr:8.10e-03, fs:0.88205 (r=0.869,p=0.896),  time:36.827, tt:3977.333\n",
      "Ep:108, loss:0.00002, loss_test:0.04924, lr:8.02e-03, fs:0.90355 (r=0.899,p=0.908),  time:36.844, tt:4015.968\n",
      "Ep:109, loss:0.00002, loss_test:0.05281, lr:7.94e-03, fs:0.87755 (r=0.869,p=0.887),  time:36.846, tt:4053.086\n",
      "Ep:110, loss:0.00002, loss_test:0.05148, lr:7.86e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.852, tt:4090.562\n",
      "Ep:111, loss:0.00002, loss_test:0.05145, lr:7.78e-03, fs:0.88776 (r=0.879,p=0.897),  time:36.849, tt:4127.049\n",
      "Ep:112, loss:0.00002, loss_test:0.05132, lr:7.70e-03, fs:0.89899 (r=0.899,p=0.899),  time:36.854, tt:4164.469\n",
      "Ep:113, loss:0.00002, loss_test:0.05033, lr:7.62e-03, fs:0.89340 (r=0.889,p=0.898),  time:36.855, tt:4201.463\n",
      "Ep:114, loss:0.00002, loss_test:0.05211, lr:7.55e-03, fs:0.90547 (r=0.919,p=0.892),  time:36.858, tt:4238.715\n",
      "Ep:115, loss:0.00002, loss_test:0.04929, lr:7.47e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.851, tt:4274.685\n",
      "Ep:116, loss:0.00002, loss_test:0.05311, lr:7.40e-03, fs:0.88325 (r=0.879,p=0.888),  time:36.858, tt:4312.368\n",
      "Ep:117, loss:0.00002, loss_test:0.04966, lr:7.32e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.845, tt:4347.767\n",
      "Ep:118, loss:0.00002, loss_test:0.05049, lr:7.25e-03, fs:0.91000 (r=0.919,p=0.901),  time:36.840, tt:4383.943\n",
      "Ep:119, loss:0.00002, loss_test:0.04991, lr:7.18e-03, fs:0.90909 (r=0.909,p=0.909),  time:36.844, tt:4421.253\n",
      "Ep:120, loss:0.00002, loss_test:0.05053, lr:7.11e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.839, tt:4457.552\n",
      "Ep:121, loss:0.00002, loss_test:0.05094, lr:7.03e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.842, tt:4494.766\n",
      "Ep:122, loss:0.00002, loss_test:0.04950, lr:6.96e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.844, tt:4531.823\n",
      "Ep:123, loss:0.00002, loss_test:0.05014, lr:6.89e-03, fs:0.90452 (r=0.909,p=0.900),  time:36.851, tt:4569.464\n",
      "Ep:124, loss:0.00002, loss_test:0.04934, lr:6.83e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.852, tt:4606.475\n",
      "Ep:125, loss:0.00002, loss_test:0.05016, lr:6.76e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.850, tt:4643.150\n",
      "Ep:126, loss:0.00001, loss_test:0.04901, lr:6.69e-03, fs:0.91457 (r=0.919,p=0.910),  time:36.842, tt:4678.965\n",
      "Ep:127, loss:0.00001, loss_test:0.05097, lr:6.62e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.850, tt:4716.863\n",
      "Ep:128, loss:0.00001, loss_test:0.04867, lr:6.56e-03, fs:0.92000 (r=0.929,p=0.911),  time:36.832, tt:4751.349\n",
      "Ep:129, loss:0.00001, loss_test:0.05012, lr:6.49e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.839, tt:4789.120\n",
      "Ep:130, loss:0.00001, loss_test:0.04963, lr:6.43e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.844, tt:4826.579\n",
      "Ep:131, loss:0.00001, loss_test:0.04850, lr:6.36e-03, fs:0.89340 (r=0.889,p=0.898),  time:36.855, tt:4864.910\n",
      "Ep:132, loss:0.00001, loss_test:0.04996, lr:6.30e-03, fs:0.91371 (r=0.909,p=0.918),  time:36.866, tt:4903.162\n",
      "Ep:133, loss:0.00001, loss_test:0.05074, lr:6.24e-03, fs:0.89796 (r=0.889,p=0.907),  time:36.873, tt:4940.973\n",
      "Ep:134, loss:0.00001, loss_test:0.04879, lr:6.17e-03, fs:0.93467 (r=0.939,p=0.930),  time:36.871, tt:4977.582\n",
      "##########Best model found so far##########\n",
      "Ep:135, loss:0.00001, loss_test:0.05011, lr:6.17e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.868, tt:5014.081\n",
      "Ep:136, loss:0.00001, loss_test:0.04870, lr:6.17e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.862, tt:5050.118\n",
      "Ep:137, loss:0.00001, loss_test:0.04895, lr:6.17e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.862, tt:5086.924\n",
      "Ep:138, loss:0.00001, loss_test:0.04901, lr:6.17e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.859, tt:5123.452\n",
      "Ep:139, loss:0.00001, loss_test:0.04890, lr:6.17e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.880, tt:5163.231\n",
      "Ep:140, loss:0.00001, loss_test:0.05013, lr:6.17e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.882, tt:5200.414\n",
      "Ep:141, loss:0.00001, loss_test:0.04800, lr:6.17e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.876, tt:5236.336\n",
      "Ep:142, loss:0.00001, loss_test:0.04973, lr:6.17e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.878, tt:5273.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.04875, lr:6.17e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.881, tt:5310.795\n",
      "Ep:144, loss:0.00001, loss_test:0.04861, lr:6.17e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.885, tt:5348.293\n",
      "Ep:145, loss:0.00001, loss_test:0.04965, lr:6.17e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.887, tt:5385.565\n",
      "Ep:146, loss:0.00001, loss_test:0.04835, lr:6.11e-03, fs:0.92308 (r=0.909,p=0.938),  time:36.885, tt:5422.109\n",
      "Ep:147, loss:0.00001, loss_test:0.04890, lr:6.05e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.888, tt:5459.420\n",
      "Ep:148, loss:0.00001, loss_test:0.04944, lr:5.99e-03, fs:0.90256 (r=0.889,p=0.917),  time:36.901, tt:5498.183\n",
      "Ep:149, loss:0.00001, loss_test:0.04833, lr:5.93e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.902, tt:5535.234\n",
      "Ep:150, loss:0.00001, loss_test:0.04905, lr:5.87e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.899, tt:5571.682\n",
      "Ep:151, loss:0.00001, loss_test:0.04799, lr:5.81e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.914, tt:5610.944\n",
      "Ep:152, loss:0.00001, loss_test:0.04818, lr:5.75e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.903, tt:5646.219\n",
      "Ep:153, loss:0.00001, loss_test:0.04975, lr:5.70e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.916, tt:5685.006\n",
      "Ep:154, loss:0.00001, loss_test:0.04790, lr:5.64e-03, fs:0.93401 (r=0.929,p=0.939),  time:36.920, tt:5722.634\n",
      "Ep:155, loss:0.00001, loss_test:0.05022, lr:5.58e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.929, tt:5760.865\n",
      "Ep:156, loss:0.00001, loss_test:0.04887, lr:5.53e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.932, tt:5798.332\n",
      "Ep:157, loss:0.00001, loss_test:0.04854, lr:5.47e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.934, tt:5835.566\n",
      "Ep:158, loss:0.00001, loss_test:0.04898, lr:5.42e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.959, tt:5876.430\n",
      "Ep:159, loss:0.00001, loss_test:0.04858, lr:5.36e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.952, tt:5912.244\n",
      "Ep:160, loss:0.00001, loss_test:0.04775, lr:5.31e-03, fs:0.91753 (r=0.899,p=0.937),  time:36.965, tt:5951.355\n",
      "Ep:161, loss:0.00001, loss_test:0.05009, lr:5.26e-03, fs:0.90816 (r=0.899,p=0.918),  time:36.970, tt:5989.186\n",
      "Ep:162, loss:0.00001, loss_test:0.04819, lr:5.20e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.972, tt:6026.381\n",
      "Ep:163, loss:0.00001, loss_test:0.04916, lr:5.15e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.972, tt:6063.476\n",
      "Ep:164, loss:0.00001, loss_test:0.04887, lr:5.10e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.969, tt:6099.883\n",
      "Ep:165, loss:0.00001, loss_test:0.04787, lr:5.05e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.959, tt:6135.187\n",
      "Ep:166, loss:0.00001, loss_test:0.04914, lr:5.00e-03, fs:0.92386 (r=0.919,p=0.929),  time:36.976, tt:6174.991\n",
      "Ep:167, loss:0.00001, loss_test:0.04868, lr:4.95e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.979, tt:6212.398\n",
      "Ep:168, loss:0.00001, loss_test:0.04852, lr:4.90e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.978, tt:6249.338\n",
      "Ep:169, loss:0.00001, loss_test:0.04898, lr:4.85e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.986, tt:6287.648\n",
      "Ep:170, loss:0.00001, loss_test:0.04848, lr:4.80e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.982, tt:6324.003\n",
      "Ep:171, loss:0.00001, loss_test:0.04856, lr:4.75e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.985, tt:6361.434\n",
      "Ep:172, loss:0.00001, loss_test:0.04867, lr:4.71e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.988, tt:6398.862\n",
      "Ep:173, loss:0.00001, loss_test:0.04853, lr:4.66e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.987, tt:6435.823\n",
      "Ep:174, loss:0.00001, loss_test:0.04816, lr:4.61e-03, fs:0.91837 (r=0.909,p=0.928),  time:36.981, tt:6471.682\n",
      "Ep:175, loss:0.00001, loss_test:0.04881, lr:4.57e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.982, tt:6508.885\n",
      "Ep:176, loss:0.00001, loss_test:0.04795, lr:4.52e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.987, tt:6546.657\n",
      "Ep:177, loss:0.00001, loss_test:0.04838, lr:4.48e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.985, tt:6583.416\n",
      "Ep:178, loss:0.00001, loss_test:0.04821, lr:4.43e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.984, tt:6620.074\n",
      "Ep:179, loss:0.00001, loss_test:0.04872, lr:4.39e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.976, tt:6655.745\n",
      "Ep:180, loss:0.00001, loss_test:0.04839, lr:4.34e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.972, tt:6691.996\n",
      "Ep:181, loss:0.00001, loss_test:0.04852, lr:4.30e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.971, tt:6728.703\n",
      "Ep:182, loss:0.00001, loss_test:0.04848, lr:4.26e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.967, tt:6764.946\n",
      "Ep:183, loss:0.00001, loss_test:0.04815, lr:4.21e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.972, tt:6802.862\n",
      "Ep:184, loss:0.00001, loss_test:0.04835, lr:4.17e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.970, tt:6839.489\n",
      "Ep:185, loss:0.00001, loss_test:0.04841, lr:4.13e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.967, tt:6875.901\n",
      "Ep:186, loss:0.00001, loss_test:0.04803, lr:4.09e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.970, tt:6913.417\n",
      "Ep:187, loss:0.00001, loss_test:0.04824, lr:4.05e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.966, tt:6949.600\n",
      "Ep:188, loss:0.00001, loss_test:0.04884, lr:4.01e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.973, tt:6987.826\n",
      "Ep:189, loss:0.00001, loss_test:0.04829, lr:3.97e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.969, tt:7024.153\n",
      "Ep:190, loss:0.00001, loss_test:0.04823, lr:3.93e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.959, tt:7059.111\n",
      "Ep:191, loss:0.00001, loss_test:0.04890, lr:3.89e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.965, tt:7097.346\n",
      "Ep:192, loss:0.00001, loss_test:0.04776, lr:3.85e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.956, tt:7132.463\n",
      "Ep:193, loss:0.00001, loss_test:0.04837, lr:3.81e-03, fs:0.91282 (r=0.899,p=0.927),  time:36.951, tt:7168.548\n",
      "Ep:194, loss:0.00001, loss_test:0.04866, lr:3.77e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.944, tt:7204.134\n",
      "Ep:195, loss:0.00001, loss_test:0.04831, lr:3.73e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.942, tt:7240.706\n",
      "Ep:196, loss:0.00001, loss_test:0.04793, lr:3.70e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.934, tt:7276.081\n",
      "Ep:197, loss:0.00001, loss_test:0.04821, lr:3.66e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.934, tt:7312.860\n",
      "Ep:198, loss:0.00001, loss_test:0.04872, lr:3.62e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.934, tt:7349.868\n",
      "Ep:199, loss:0.00001, loss_test:0.04804, lr:3.59e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.939, tt:7387.763\n",
      "Ep:200, loss:0.00001, loss_test:0.04836, lr:3.55e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.930, tt:7422.972\n",
      "Ep:201, loss:0.00001, loss_test:0.04889, lr:3.52e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.906, tt:7455.004\n",
      "Ep:202, loss:0.00001, loss_test:0.04831, lr:3.48e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.886, tt:7487.859\n",
      "Ep:203, loss:0.00001, loss_test:0.04777, lr:3.45e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.863, tt:7520.047\n",
      "Ep:204, loss:0.00001, loss_test:0.04876, lr:3.41e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.838, tt:7551.745\n",
      "Ep:205, loss:0.00001, loss_test:0.04847, lr:3.38e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.808, tt:7582.395\n",
      "Ep:206, loss:0.00001, loss_test:0.04784, lr:3.34e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.754, tt:7608.159\n",
      "Ep:207, loss:0.00001, loss_test:0.04799, lr:3.31e-03, fs:0.91192 (r=0.889,p=0.936),  time:36.714, tt:7636.438\n",
      "Ep:208, loss:0.00001, loss_test:0.04853, lr:3.28e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.704, tt:7671.106\n",
      "Ep:209, loss:0.00001, loss_test:0.04785, lr:3.24e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.706, tt:7708.218\n",
      "Ep:210, loss:0.00001, loss_test:0.04812, lr:3.21e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.701, tt:7743.964\n",
      "Ep:211, loss:0.00001, loss_test:0.04838, lr:3.18e-03, fs:0.90722 (r=0.889,p=0.926),  time:36.677, tt:7775.623\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02256, lr:6.00e-02, fs:0.66960 (r=0.768,p=0.594),  time:35.559, tt:35.559\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02248, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:35.532, tt:71.065\n",
      "Ep:2, loss:0.00005, loss_test:0.02627, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.472, tt:106.417\n",
      "Ep:3, loss:0.00005, loss_test:0.02800, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.293, tt:141.173\n",
      "Ep:4, loss:0.00005, loss_test:0.02840, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.360, tt:176.798\n",
      "Ep:5, loss:0.00005, loss_test:0.02782, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.378, tt:212.268\n",
      "Ep:6, loss:0.00005, loss_test:0.02683, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.268, tt:246.875\n",
      "Ep:7, loss:0.00005, loss_test:0.02538, lr:6.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:35.306, tt:282.446\n",
      "Ep:8, loss:0.00005, loss_test:0.02383, lr:6.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:35.328, tt:317.948\n",
      "Ep:9, loss:0.00005, loss_test:0.02259, lr:6.00e-02, fs:0.66906 (r=0.939,p=0.520),  time:35.242, tt:352.423\n",
      "Ep:10, loss:0.00004, loss_test:0.02170, lr:6.00e-02, fs:0.67433 (r=0.889,p=0.543),  time:35.549, tt:391.042\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.02103, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:35.587, tt:427.038\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.02032, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:35.600, tt:462.802\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01965, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.539, tt:497.544\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01917, lr:6.00e-02, fs:0.69697 (r=0.929,p=0.558),  time:35.600, tt:533.997\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.01878, lr:6.00e-02, fs:0.68914 (r=0.929,p=0.548),  time:35.647, tt:570.347\n",
      "Ep:16, loss:0.00004, loss_test:0.01839, lr:6.00e-02, fs:0.68421 (r=0.919,p=0.545),  time:35.585, tt:604.942\n",
      "Ep:17, loss:0.00004, loss_test:0.01797, lr:6.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:35.590, tt:640.622\n",
      "Ep:18, loss:0.00003, loss_test:0.01763, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:35.596, tt:676.318\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01742, lr:6.00e-02, fs:0.72065 (r=0.899,p=0.601),  time:35.596, tt:711.923\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01721, lr:6.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:35.659, tt:748.836\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01696, lr:6.00e-02, fs:0.74380 (r=0.909,p=0.629),  time:35.571, tt:782.564\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01670, lr:6.00e-02, fs:0.74286 (r=0.919,p=0.623),  time:35.608, tt:818.977\n",
      "Ep:23, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:35.653, tt:855.661\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01618, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:35.726, tt:893.161\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01593, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:35.708, tt:928.397\n",
      "Ep:26, loss:0.00003, loss_test:0.01571, lr:6.00e-02, fs:0.73729 (r=0.879,p=0.635),  time:35.724, tt:964.553\n",
      "Ep:27, loss:0.00003, loss_test:0.01550, lr:6.00e-02, fs:0.74359 (r=0.879,p=0.644),  time:35.719, tt:1000.131\n",
      "Ep:28, loss:0.00002, loss_test:0.01528, lr:6.00e-02, fs:0.75424 (r=0.899,p=0.650),  time:35.731, tt:1036.193\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01507, lr:6.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:35.745, tt:1072.348\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01486, lr:6.00e-02, fs:0.76923 (r=0.909,p=0.667),  time:35.759, tt:1108.540\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.77253 (r=0.909,p=0.672),  time:35.746, tt:1143.881\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.78448 (r=0.919,p=0.684),  time:35.766, tt:1180.279\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:35.773, tt:1216.295\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01406, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:35.782, tt:1252.367\n",
      "Ep:35, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.78603 (r=0.909,p=0.692),  time:35.745, tt:1286.835\n",
      "Ep:36, loss:0.00002, loss_test:0.01375, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:35.707, tt:1321.174\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01360, lr:6.00e-02, fs:0.79476 (r=0.919,p=0.700),  time:35.715, tt:1357.166\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.79130 (r=0.919,p=0.695),  time:35.712, tt:1392.783\n",
      "Ep:39, loss:0.00002, loss_test:0.01339, lr:6.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:35.680, tt:1427.183\n",
      "Ep:40, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:35.654, tt:1461.803\n",
      "Ep:41, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:35.625, tt:1496.270\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01315, lr:6.00e-02, fs:0.80357 (r=0.909,p=0.720),  time:35.617, tt:1531.549\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:35.660, tt:1569.038\n",
      "Ep:44, loss:0.00001, loss_test:0.01306, lr:6.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:35.666, tt:1604.969\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01299, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:35.648, tt:1639.808\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:35.626, tt:1674.431\n",
      "Ep:47, loss:0.00001, loss_test:0.01297, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:35.589, tt:1708.275\n",
      "Ep:48, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.81860 (r=0.889,p=0.759),  time:35.562, tt:1742.518\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:35.560, tt:1778.003\n",
      "Ep:50, loss:0.00001, loss_test:0.01294, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.520, tt:1811.523\n",
      "Ep:51, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.516, tt:1846.854\n",
      "Ep:52, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:35.522, tt:1882.641\n",
      "Ep:53, loss:0.00001, loss_test:0.01298, lr:6.00e-02, fs:0.80569 (r=0.859,p=0.759),  time:35.492, tt:1916.576\n",
      "Ep:54, loss:0.00001, loss_test:0.01303, lr:6.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:35.490, tt:1951.939\n",
      "Ep:55, loss:0.00001, loss_test:0.01305, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.466, tt:1986.078\n",
      "Ep:56, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.421, tt:2018.974\n",
      "Ep:57, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:35.411, tt:2053.857\n",
      "Ep:58, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:35.399, tt:2088.537\n",
      "Ep:59, loss:0.00001, loss_test:0.01314, lr:6.00e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.365, tt:2121.929\n",
      "Ep:60, loss:0.00001, loss_test:0.01320, lr:5.94e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.370, tt:2157.550\n",
      "Ep:61, loss:0.00001, loss_test:0.01328, lr:5.88e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.354, tt:2191.948\n",
      "Ep:62, loss:0.00001, loss_test:0.01334, lr:5.82e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.349, tt:2227.011\n",
      "Ep:63, loss:0.00001, loss_test:0.01339, lr:5.76e-02, fs:0.80976 (r=0.838,p=0.783),  time:35.335, tt:2261.440\n",
      "Ep:64, loss:0.00001, loss_test:0.01347, lr:5.71e-02, fs:0.81373 (r=0.838,p=0.790),  time:35.349, tt:2297.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:65, loss:0.00001, loss_test:0.01354, lr:5.65e-02, fs:0.81773 (r=0.838,p=0.798),  time:35.333, tt:2332.006\n",
      "Ep:66, loss:0.00001, loss_test:0.01359, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.344, tt:2368.037\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01366, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.318, tt:2401.600\n",
      "Ep:68, loss:0.00001, loss_test:0.01377, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.309, tt:2436.306\n",
      "Ep:69, loss:0.00001, loss_test:0.01386, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.302, tt:2471.157\n",
      "Ep:70, loss:0.00001, loss_test:0.01393, lr:5.59e-02, fs:0.82178 (r=0.838,p=0.806),  time:35.294, tt:2505.892\n",
      "Ep:71, loss:0.00001, loss_test:0.01399, lr:5.59e-02, fs:0.82587 (r=0.838,p=0.814),  time:35.279, tt:2540.123\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01408, lr:5.59e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.299, tt:2576.850\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.01418, lr:5.59e-02, fs:0.83000 (r=0.838,p=0.822),  time:35.298, tt:2612.025\n",
      "Ep:74, loss:0.00001, loss_test:0.01427, lr:5.59e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.267, tt:2645.053\n",
      "Ep:75, loss:0.00001, loss_test:0.01434, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.251, tt:2679.051\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01438, lr:5.59e-02, fs:0.83417 (r=0.838,p=0.830),  time:35.244, tt:2713.801\n",
      "Ep:77, loss:0.00001, loss_test:0.01443, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.241, tt:2748.776\n",
      "Ep:78, loss:0.00001, loss_test:0.01450, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.241, tt:2784.043\n",
      "Ep:79, loss:0.00001, loss_test:0.01459, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.230, tt:2818.374\n",
      "Ep:80, loss:0.00001, loss_test:0.01468, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.229, tt:2853.561\n",
      "Ep:81, loss:0.00001, loss_test:0.01476, lr:5.59e-02, fs:0.83838 (r=0.838,p=0.838),  time:35.221, tt:2888.091\n",
      "Ep:82, loss:0.00001, loss_test:0.01484, lr:5.59e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.224, tt:2923.583\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01491, lr:5.59e-02, fs:0.84694 (r=0.838,p=0.856),  time:35.214, tt:2957.941\n",
      "Ep:84, loss:0.00001, loss_test:0.01499, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.216, tt:2993.349\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01505, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.199, tt:3027.077\n",
      "Ep:86, loss:0.00000, loss_test:0.01511, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.186, tt:3061.188\n",
      "Ep:87, loss:0.00000, loss_test:0.01516, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.182, tt:3096.035\n",
      "Ep:88, loss:0.00000, loss_test:0.01524, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.178, tt:3130.869\n",
      "Ep:89, loss:0.00000, loss_test:0.01530, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.173, tt:3165.569\n",
      "Ep:90, loss:0.00000, loss_test:0.01537, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.143, tt:3198.057\n",
      "Ep:91, loss:0.00000, loss_test:0.01545, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.142, tt:3233.101\n",
      "Ep:92, loss:0.00000, loss_test:0.01550, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.137, tt:3267.785\n",
      "Ep:93, loss:0.00000, loss_test:0.01556, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.145, tt:3303.636\n",
      "Ep:94, loss:0.00000, loss_test:0.01560, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.150, tt:3339.213\n",
      "Ep:95, loss:0.00000, loss_test:0.01569, lr:5.59e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.141, tt:3373.529\n",
      "Ep:96, loss:0.00000, loss_test:0.01578, lr:5.54e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.119, tt:3406.548\n",
      "Ep:97, loss:0.00000, loss_test:0.01584, lr:5.48e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.123, tt:3442.095\n",
      "Ep:98, loss:0.00000, loss_test:0.01588, lr:5.43e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.121, tt:3476.941\n",
      "Ep:99, loss:0.00000, loss_test:0.01592, lr:5.37e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.118, tt:3511.840\n",
      "Ep:100, loss:0.00000, loss_test:0.01599, lr:5.32e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.123, tt:3547.403\n",
      "Ep:101, loss:0.00000, loss_test:0.01605, lr:5.27e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.111, tt:3581.349\n",
      "Ep:102, loss:0.00000, loss_test:0.01611, lr:5.21e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.094, tt:3614.724\n",
      "Ep:103, loss:0.00000, loss_test:0.01618, lr:5.16e-02, fs:0.85128 (r=0.838,p=0.865),  time:35.102, tt:3650.655\n",
      "Ep:104, loss:0.00000, loss_test:0.01625, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.099, tt:3685.387\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.01629, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.102, tt:3720.799\n",
      "Ep:106, loss:0.00000, loss_test:0.01633, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.084, tt:3754.039\n",
      "Ep:107, loss:0.00000, loss_test:0.01638, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.078, tt:3788.409\n",
      "Ep:108, loss:0.00000, loss_test:0.01644, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.067, tt:3822.336\n",
      "Ep:109, loss:0.00000, loss_test:0.01649, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.053, tt:3855.835\n",
      "Ep:110, loss:0.00000, loss_test:0.01655, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.052, tt:3890.822\n",
      "Ep:111, loss:0.00000, loss_test:0.01661, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.051, tt:3925.662\n",
      "Ep:112, loss:0.00000, loss_test:0.01665, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.038, tt:3959.317\n",
      "Ep:113, loss:0.00000, loss_test:0.01671, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.026, tt:3993.004\n",
      "Ep:114, loss:0.00000, loss_test:0.01678, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.013, tt:4026.515\n",
      "Ep:115, loss:0.00000, loss_test:0.01685, lr:5.11e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.987, tt:4058.470\n",
      "Ep:116, loss:0.00000, loss_test:0.01690, lr:5.06e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.974, tt:4091.917\n",
      "Ep:117, loss:0.00000, loss_test:0.01694, lr:5.01e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.963, tt:4125.664\n",
      "Ep:118, loss:0.00000, loss_test:0.01698, lr:4.96e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.961, tt:4160.354\n",
      "Ep:119, loss:0.00000, loss_test:0.01703, lr:4.91e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.960, tt:4195.233\n",
      "Ep:120, loss:0.00000, loss_test:0.01707, lr:4.86e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.956, tt:4229.672\n",
      "Ep:121, loss:0.00000, loss_test:0.01712, lr:4.81e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.940, tt:4262.675\n",
      "Ep:122, loss:0.00000, loss_test:0.01716, lr:4.76e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.931, tt:4296.453\n",
      "Ep:123, loss:0.00000, loss_test:0.01719, lr:4.71e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.926, tt:4330.848\n",
      "Ep:124, loss:0.00000, loss_test:0.01723, lr:4.67e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.907, tt:4363.388\n",
      "Ep:125, loss:0.00000, loss_test:0.01726, lr:4.62e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.899, tt:4397.309\n",
      "Ep:126, loss:0.00000, loss_test:0.01730, lr:4.57e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.895, tt:4431.711\n",
      "Ep:127, loss:0.00000, loss_test:0.01734, lr:4.53e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.908, tt:4468.231\n",
      "Ep:128, loss:0.00000, loss_test:0.01739, lr:4.48e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.904, tt:4502.596\n",
      "Ep:129, loss:0.00000, loss_test:0.01744, lr:4.44e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.901, tt:4537.153\n",
      "Ep:130, loss:0.00000, loss_test:0.01747, lr:4.39e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.911, tt:4573.280\n",
      "Ep:131, loss:0.00000, loss_test:0.01751, lr:4.35e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.922, tt:4609.699\n",
      "Ep:132, loss:0.00000, loss_test:0.01754, lr:4.31e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.924, tt:4644.943\n",
      "Ep:133, loss:0.00000, loss_test:0.01757, lr:4.26e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.926, tt:4680.127\n",
      "Ep:134, loss:0.00000, loss_test:0.01762, lr:4.22e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.931, tt:4715.647\n",
      "Ep:135, loss:0.00000, loss_test:0.01766, lr:4.18e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.935, tt:4751.181\n",
      "Ep:136, loss:0.00000, loss_test:0.01768, lr:4.14e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.936, tt:4786.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.01771, lr:4.10e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.932, tt:4820.670\n",
      "Ep:138, loss:0.00000, loss_test:0.01775, lr:4.05e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.945, tt:4857.362\n",
      "Ep:139, loss:0.00000, loss_test:0.01781, lr:4.01e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.958, tt:4894.106\n",
      "Ep:140, loss:0.00000, loss_test:0.01783, lr:3.97e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.964, tt:4929.943\n",
      "Ep:141, loss:0.00000, loss_test:0.01785, lr:3.93e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.965, tt:4965.024\n",
      "Ep:142, loss:0.00000, loss_test:0.01787, lr:3.89e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.960, tt:4999.347\n",
      "Ep:143, loss:0.00000, loss_test:0.01792, lr:3.86e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.953, tt:5033.229\n",
      "Ep:144, loss:0.00000, loss_test:0.01795, lr:3.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.951, tt:5067.909\n",
      "Ep:145, loss:0.00000, loss_test:0.01799, lr:3.78e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.950, tt:5102.673\n",
      "Ep:146, loss:0.00000, loss_test:0.01800, lr:3.74e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.955, tt:5138.402\n",
      "Ep:147, loss:0.00000, loss_test:0.01802, lr:3.70e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.947, tt:5172.172\n",
      "Ep:148, loss:0.00000, loss_test:0.01805, lr:3.67e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.940, tt:5206.008\n",
      "Ep:149, loss:0.00000, loss_test:0.01807, lr:3.63e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.937, tt:5240.621\n",
      "Ep:150, loss:0.00000, loss_test:0.01810, lr:3.59e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.938, tt:5275.680\n",
      "Ep:151, loss:0.00000, loss_test:0.01815, lr:3.56e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.939, tt:5310.792\n",
      "Ep:152, loss:0.00000, loss_test:0.01817, lr:3.52e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.947, tt:5346.934\n",
      "Ep:153, loss:0.00000, loss_test:0.01821, lr:3.49e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.967, tt:5384.857\n",
      "Ep:154, loss:0.00000, loss_test:0.01823, lr:3.45e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.969, tt:5420.192\n",
      "Ep:155, loss:0.00000, loss_test:0.01825, lr:3.42e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.976, tt:5456.184\n",
      "Ep:156, loss:0.00000, loss_test:0.01827, lr:3.38e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.975, tt:5491.049\n",
      "Ep:157, loss:0.00000, loss_test:0.01830, lr:3.35e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.974, tt:5525.863\n",
      "Ep:158, loss:0.00000, loss_test:0.01832, lr:3.32e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.980, tt:5561.767\n",
      "Ep:159, loss:0.00000, loss_test:0.01833, lr:3.28e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.979, tt:5596.602\n",
      "Ep:160, loss:0.00000, loss_test:0.01837, lr:3.25e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.990, tt:5633.345\n",
      "Ep:161, loss:0.00000, loss_test:0.01839, lr:3.22e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.991, tt:5668.553\n",
      "Ep:162, loss:0.00000, loss_test:0.01841, lr:3.19e-02, fs:0.85567 (r=0.838,p=0.874),  time:34.998, tt:5704.652\n",
      "Ep:163, loss:0.00000, loss_test:0.01842, lr:3.15e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.009, tt:5741.424\n",
      "Ep:164, loss:0.00000, loss_test:0.01845, lr:3.12e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.012, tt:5776.946\n",
      "Ep:165, loss:0.00000, loss_test:0.01847, lr:3.09e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.021, tt:5813.537\n",
      "Ep:166, loss:0.00000, loss_test:0.01849, lr:3.06e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.021, tt:5848.500\n",
      "Ep:167, loss:0.00000, loss_test:0.01851, lr:3.03e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.027, tt:5884.454\n",
      "Ep:168, loss:0.00000, loss_test:0.01853, lr:3.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.042, tt:5922.181\n",
      "Ep:169, loss:0.00000, loss_test:0.01856, lr:2.97e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.049, tt:5958.372\n",
      "Ep:170, loss:0.00000, loss_test:0.01858, lr:2.94e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.060, tt:5995.176\n",
      "Ep:171, loss:0.00000, loss_test:0.01860, lr:2.91e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.067, tt:6031.560\n",
      "Ep:172, loss:0.00000, loss_test:0.01862, lr:2.88e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.073, tt:6067.559\n",
      "Ep:173, loss:0.00000, loss_test:0.01863, lr:2.85e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.082, tt:6104.245\n",
      "Ep:174, loss:0.00000, loss_test:0.01864, lr:2.82e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.092, tt:6141.117\n",
      "Ep:175, loss:0.00000, loss_test:0.01867, lr:2.80e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.098, tt:6177.299\n",
      "Ep:176, loss:0.00000, loss_test:0.01869, lr:2.77e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.102, tt:6213.142\n",
      "Ep:177, loss:0.00000, loss_test:0.01870, lr:2.74e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.122, tt:6251.796\n",
      "Ep:178, loss:0.00000, loss_test:0.01871, lr:2.71e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.126, tt:6287.542\n",
      "Ep:179, loss:0.00000, loss_test:0.01872, lr:2.69e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.130, tt:6323.392\n",
      "Ep:180, loss:0.00000, loss_test:0.01874, lr:2.66e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.130, tt:6358.589\n",
      "Ep:181, loss:0.00000, loss_test:0.01877, lr:2.63e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.132, tt:6393.960\n",
      "Ep:182, loss:0.00000, loss_test:0.01879, lr:2.61e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.133, tt:6429.373\n",
      "Ep:183, loss:0.00000, loss_test:0.01881, lr:2.58e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.138, tt:6465.340\n",
      "Ep:184, loss:0.00000, loss_test:0.01882, lr:2.55e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.139, tt:6500.684\n",
      "Ep:185, loss:0.00000, loss_test:0.01883, lr:2.53e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.142, tt:6536.439\n",
      "Ep:186, loss:0.00000, loss_test:0.01884, lr:2.50e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.144, tt:6571.976\n",
      "Ep:187, loss:0.00000, loss_test:0.01885, lr:2.48e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.151, tt:6608.396\n",
      "Ep:188, loss:0.00000, loss_test:0.01887, lr:2.45e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.154, tt:6644.198\n",
      "Ep:189, loss:0.00000, loss_test:0.01888, lr:2.43e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.154, tt:6679.214\n",
      "Ep:190, loss:0.00000, loss_test:0.01890, lr:2.40e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.140, tt:6711.790\n",
      "Ep:191, loss:0.00000, loss_test:0.01891, lr:2.38e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.145, tt:6747.920\n",
      "Ep:192, loss:0.00000, loss_test:0.01893, lr:2.36e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.137, tt:6781.507\n",
      "Ep:193, loss:0.00000, loss_test:0.01895, lr:2.33e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.131, tt:6815.353\n",
      "Ep:194, loss:0.00000, loss_test:0.01896, lr:2.31e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.124, tt:6849.100\n",
      "Ep:195, loss:0.00000, loss_test:0.01896, lr:2.29e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.108, tt:6881.105\n",
      "Ep:196, loss:0.00000, loss_test:0.01896, lr:2.26e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.094, tt:6913.524\n",
      "Ep:197, loss:0.00000, loss_test:0.01898, lr:2.24e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.086, tt:6947.023\n",
      "Ep:198, loss:0.00000, loss_test:0.01899, lr:2.22e-02, fs:0.84974 (r=0.828,p=0.872),  time:35.082, tt:6981.284\n",
      "Ep:199, loss:0.00000, loss_test:0.01901, lr:2.20e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.087, tt:7017.307\n",
      "Ep:200, loss:0.00000, loss_test:0.01903, lr:2.17e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.086, tt:7052.198\n",
      "Ep:201, loss:0.00000, loss_test:0.01905, lr:2.15e-02, fs:0.85567 (r=0.838,p=0.874),  time:35.066, tt:7083.365\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12829, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:36.114, tt:36.114\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12666, lr:1.00e-02, fs:0.65934 (r=0.909,p=0.517),  time:37.124, tt:74.248\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12453, lr:1.00e-02, fs:0.67170 (r=0.899,p=0.536),  time:37.227, tt:111.682\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12231, lr:1.00e-02, fs:0.67939 (r=0.899,p=0.546),  time:37.208, tt:148.832\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00026, loss_test:0.12055, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:37.405, tt:187.023\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11935, lr:1.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:37.443, tt:224.659\n",
      "Ep:6, loss:0.00025, loss_test:0.11835, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:37.615, tt:263.302\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00025, loss_test:0.11715, lr:1.00e-02, fs:0.69804 (r=0.899,p=0.571),  time:37.493, tt:299.947\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00024, loss_test:0.11603, lr:1.00e-02, fs:0.70312 (r=0.909,p=0.573),  time:37.602, tt:338.420\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.11495, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:37.599, tt:375.992\n",
      "Ep:10, loss:0.00024, loss_test:0.11348, lr:1.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:37.689, tt:414.581\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.11153, lr:1.00e-02, fs:0.68826 (r=0.859,p=0.574),  time:37.778, tt:453.341\n",
      "Ep:12, loss:0.00023, loss_test:0.10944, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:37.961, tt:493.494\n",
      "Ep:13, loss:0.00022, loss_test:0.10788, lr:1.00e-02, fs:0.70833 (r=0.859,p=0.603),  time:38.091, tt:533.280\n",
      "Ep:14, loss:0.00021, loss_test:0.10627, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:38.203, tt:573.042\n",
      "Ep:15, loss:0.00021, loss_test:0.10548, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:38.226, tt:611.622\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00020, loss_test:0.10430, lr:1.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:38.263, tt:650.468\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00020, loss_test:0.10374, lr:1.00e-02, fs:0.72340 (r=0.859,p=0.625),  time:38.290, tt:689.216\n",
      "Ep:18, loss:0.00019, loss_test:0.10297, lr:1.00e-02, fs:0.72650 (r=0.859,p=0.630),  time:38.329, tt:728.256\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00019, loss_test:0.10212, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:38.368, tt:767.359\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00018, loss_test:0.10091, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:38.381, tt:805.998\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00018, loss_test:0.10103, lr:1.00e-02, fs:0.74459 (r=0.869,p=0.652),  time:38.420, tt:845.247\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00017, loss_test:0.10041, lr:1.00e-02, fs:0.74783 (r=0.869,p=0.656),  time:38.452, tt:884.404\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00016, loss_test:0.09864, lr:1.00e-02, fs:0.75109 (r=0.869,p=0.662),  time:38.461, tt:923.056\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00016, loss_test:0.09979, lr:1.00e-02, fs:0.74138 (r=0.869,p=0.647),  time:38.543, tt:963.568\n",
      "Ep:25, loss:0.00015, loss_test:0.09797, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:38.582, tt:1003.143\n",
      "Ep:26, loss:0.00015, loss_test:0.09647, lr:1.00e-02, fs:0.74654 (r=0.818,p=0.686),  time:38.613, tt:1042.546\n",
      "Ep:27, loss:0.00014, loss_test:0.09788, lr:1.00e-02, fs:0.72247 (r=0.828,p=0.641),  time:38.572, tt:1080.030\n",
      "Ep:28, loss:0.00014, loss_test:0.09517, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:38.553, tt:1118.033\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09592, lr:1.00e-02, fs:0.71749 (r=0.808,p=0.645),  time:38.516, tt:1155.490\n",
      "Ep:30, loss:0.00012, loss_test:0.09412, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:38.485, tt:1193.037\n",
      "Ep:31, loss:0.00012, loss_test:0.09347, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:38.427, tt:1229.653\n",
      "Ep:32, loss:0.00011, loss_test:0.09300, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:38.389, tt:1266.844\n",
      "Ep:33, loss:0.00011, loss_test:0.09164, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:38.387, tt:1305.172\n",
      "Ep:34, loss:0.00011, loss_test:0.08977, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:38.361, tt:1342.646\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00010, loss_test:0.08918, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:38.358, tt:1380.902\n",
      "Ep:36, loss:0.00010, loss_test:0.08647, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:38.357, tt:1419.205\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00009, loss_test:0.08769, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:38.312, tt:1455.873\n",
      "Ep:38, loss:0.00009, loss_test:0.08530, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:38.294, tt:1493.484\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00009, loss_test:0.08411, lr:1.00e-02, fs:0.78302 (r=0.838,p=0.735),  time:38.266, tt:1530.630\n",
      "Ep:40, loss:0.00008, loss_test:0.08271, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:38.238, tt:1567.775\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00008, loss_test:0.08165, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:38.253, tt:1606.635\n",
      "Ep:42, loss:0.00008, loss_test:0.08152, lr:1.00e-02, fs:0.80193 (r=0.838,p=0.769),  time:38.245, tt:1644.551\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.08042, lr:1.00e-02, fs:0.79808 (r=0.838,p=0.761),  time:38.238, tt:1682.480\n",
      "Ep:44, loss:0.00007, loss_test:0.07929, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:38.309, tt:1723.923\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.07985, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:38.290, tt:1761.356\n",
      "Ep:46, loss:0.00007, loss_test:0.08009, lr:1.00e-02, fs:0.81373 (r=0.838,p=0.790),  time:38.271, tt:1798.728\n",
      "Ep:47, loss:0.00006, loss_test:0.07590, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:38.241, tt:1835.586\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.08029, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:38.202, tt:1871.900\n",
      "Ep:49, loss:0.00006, loss_test:0.07387, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:38.183, tt:1909.140\n",
      "Ep:50, loss:0.00006, loss_test:0.08033, lr:1.00e-02, fs:0.82692 (r=0.869,p=0.789),  time:38.154, tt:1945.879\n",
      "Ep:51, loss:0.00006, loss_test:0.07342, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:38.144, tt:1983.513\n",
      "Ep:52, loss:0.00006, loss_test:0.07670, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:38.130, tt:2020.904\n",
      "Ep:53, loss:0.00005, loss_test:0.07504, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:38.134, tt:2059.223\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.07409, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:38.114, tt:2096.280\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.07656, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:38.094, tt:2133.271\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00005, loss_test:0.07247, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:38.092, tt:2171.254\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00005, loss_test:0.07619, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:38.069, tt:2207.991\n",
      "Ep:58, loss:0.00004, loss_test:0.07401, lr:1.00e-02, fs:0.87310 (r=0.869,p=0.878),  time:38.068, tt:2245.998\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00004, loss_test:0.07543, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:38.043, tt:2282.602\n",
      "Ep:60, loss:0.00004, loss_test:0.07291, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:38.015, tt:2318.937\n",
      "Ep:61, loss:0.00004, loss_test:0.07450, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:37.989, tt:2355.324\n",
      "Ep:62, loss:0.00004, loss_test:0.07456, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:37.962, tt:2391.635\n",
      "Ep:63, loss:0.00004, loss_test:0.07200, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:37.952, tt:2428.943\n",
      "Ep:64, loss:0.00004, loss_test:0.07421, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:37.941, tt:2466.182\n",
      "Ep:65, loss:0.00004, loss_test:0.07144, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:37.936, tt:2503.767\n",
      "Ep:66, loss:0.00004, loss_test:0.07347, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:37.921, tt:2540.685\n",
      "Ep:67, loss:0.00003, loss_test:0.07125, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:37.890, tt:2576.509\n",
      "Ep:68, loss:0.00003, loss_test:0.07299, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:37.880, tt:2613.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00003, loss_test:0.07300, lr:1.00e-02, fs:0.87179 (r=0.859,p=0.885),  time:37.878, tt:2651.432\n",
      "Ep:70, loss:0.00003, loss_test:0.07091, lr:9.90e-03, fs:0.85864 (r=0.828,p=0.891),  time:37.863, tt:2688.259\n",
      "Ep:71, loss:0.00003, loss_test:0.07412, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:37.862, tt:2726.046\n",
      "Ep:72, loss:0.00003, loss_test:0.06963, lr:9.70e-03, fs:0.86735 (r=0.859,p=0.876),  time:37.845, tt:2762.693\n",
      "Ep:73, loss:0.00003, loss_test:0.07401, lr:9.61e-03, fs:0.86154 (r=0.848,p=0.875),  time:37.845, tt:2800.551\n",
      "Ep:74, loss:0.00003, loss_test:0.07100, lr:9.51e-03, fs:0.87755 (r=0.869,p=0.887),  time:37.838, tt:2837.822\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00003, loss_test:0.07227, lr:9.51e-03, fs:0.85864 (r=0.828,p=0.891),  time:37.824, tt:2874.624\n",
      "Ep:76, loss:0.00003, loss_test:0.07077, lr:9.51e-03, fs:0.87179 (r=0.859,p=0.885),  time:37.830, tt:2912.911\n",
      "Ep:77, loss:0.00003, loss_test:0.07207, lr:9.51e-03, fs:0.87755 (r=0.869,p=0.887),  time:37.833, tt:2950.947\n",
      "Ep:78, loss:0.00003, loss_test:0.07206, lr:9.51e-03, fs:0.87234 (r=0.828,p=0.921),  time:37.839, tt:2989.281\n",
      "Ep:79, loss:0.00003, loss_test:0.07136, lr:9.51e-03, fs:0.88083 (r=0.859,p=0.904),  time:37.824, tt:3025.888\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.07385, lr:9.51e-03, fs:0.86458 (r=0.838,p=0.892),  time:37.822, tt:3063.598\n",
      "Ep:81, loss:0.00002, loss_test:0.06952, lr:9.51e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.828, tt:3101.876\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.07356, lr:9.51e-03, fs:0.86598 (r=0.848,p=0.884),  time:37.796, tt:3137.102\n",
      "Ep:83, loss:0.00002, loss_test:0.06870, lr:9.51e-03, fs:0.89362 (r=0.848,p=0.944),  time:37.786, tt:3174.061\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00002, loss_test:0.07293, lr:9.51e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.767, tt:3210.215\n",
      "Ep:85, loss:0.00002, loss_test:0.06986, lr:9.51e-03, fs:0.88542 (r=0.859,p=0.914),  time:37.747, tt:3246.210\n",
      "Ep:86, loss:0.00002, loss_test:0.07116, lr:9.51e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.752, tt:3284.442\n",
      "Ep:87, loss:0.00002, loss_test:0.07338, lr:9.51e-03, fs:0.87958 (r=0.848,p=0.913),  time:37.721, tt:3319.429\n",
      "Ep:88, loss:0.00002, loss_test:0.07055, lr:9.51e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.675, tt:3353.035\n",
      "Ep:89, loss:0.00002, loss_test:0.07136, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.642, tt:3387.744\n",
      "Ep:90, loss:0.00002, loss_test:0.07187, lr:9.51e-03, fs:0.88083 (r=0.859,p=0.904),  time:37.631, tt:3424.423\n",
      "Ep:91, loss:0.00002, loss_test:0.07282, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.625, tt:3461.472\n",
      "Ep:92, loss:0.00002, loss_test:0.07063, lr:9.51e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.620, tt:3498.620\n",
      "Ep:93, loss:0.00002, loss_test:0.07329, lr:9.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.598, tt:3534.203\n",
      "Ep:94, loss:0.00002, loss_test:0.07141, lr:9.51e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.577, tt:3569.801\n",
      "Ep:95, loss:0.00002, loss_test:0.07177, lr:9.41e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.596, tt:3609.236\n",
      "Ep:96, loss:0.00002, loss_test:0.07219, lr:9.32e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.581, tt:3645.340\n",
      "Ep:97, loss:0.00002, loss_test:0.07102, lr:9.23e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.577, tt:3682.550\n",
      "Ep:98, loss:0.00002, loss_test:0.07173, lr:9.14e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.580, tt:3720.459\n",
      "Ep:99, loss:0.00002, loss_test:0.07167, lr:9.04e-03, fs:0.86486 (r=0.808,p=0.930),  time:37.571, tt:3757.067\n",
      "Ep:100, loss:0.00002, loss_test:0.07222, lr:8.95e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.553, tt:3792.883\n",
      "Ep:101, loss:0.00001, loss_test:0.07155, lr:8.86e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.545, tt:3829.583\n",
      "Ep:102, loss:0.00001, loss_test:0.07201, lr:8.78e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.527, tt:3865.250\n",
      "Ep:103, loss:0.00001, loss_test:0.07091, lr:8.69e-03, fs:0.87097 (r=0.818,p=0.931),  time:37.529, tt:3903.045\n",
      "Ep:104, loss:0.00001, loss_test:0.07286, lr:8.60e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.520, tt:3939.573\n",
      "Ep:105, loss:0.00001, loss_test:0.07168, lr:8.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:37.508, tt:3975.864\n",
      "Ep:106, loss:0.00001, loss_test:0.07169, lr:8.43e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.496, tt:4012.087\n",
      "Ep:107, loss:0.00001, loss_test:0.07185, lr:8.35e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.492, tt:4049.175\n",
      "Ep:108, loss:0.00001, loss_test:0.07221, lr:8.26e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.506, tt:4088.117\n",
      "Ep:109, loss:0.00001, loss_test:0.07158, lr:8.18e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.507, tt:4125.796\n",
      "Ep:110, loss:0.00001, loss_test:0.07120, lr:8.10e-03, fs:0.86022 (r=0.808,p=0.920),  time:37.509, tt:4163.522\n",
      "Ep:111, loss:0.00001, loss_test:0.07288, lr:8.02e-03, fs:0.83516 (r=0.768,p=0.916),  time:37.504, tt:4200.489\n",
      "Ep:112, loss:0.00001, loss_test:0.07116, lr:7.94e-03, fs:0.87097 (r=0.818,p=0.931),  time:37.497, tt:4237.197\n",
      "Ep:113, loss:0.00001, loss_test:0.07098, lr:7.86e-03, fs:0.87097 (r=0.818,p=0.931),  time:37.484, tt:4273.127\n",
      "Ep:114, loss:0.00001, loss_test:0.07149, lr:7.78e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.477, tt:4309.913\n",
      "Ep:115, loss:0.00001, loss_test:0.07138, lr:7.70e-03, fs:0.85405 (r=0.798,p=0.919),  time:37.469, tt:4346.373\n",
      "Ep:116, loss:0.00001, loss_test:0.07164, lr:7.62e-03, fs:0.86631 (r=0.818,p=0.920),  time:37.457, tt:4382.512\n",
      "Ep:117, loss:0.00001, loss_test:0.07165, lr:7.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.449, tt:4418.954\n",
      "Ep:118, loss:0.00001, loss_test:0.07179, lr:7.47e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.447, tt:4456.214\n",
      "Ep:119, loss:0.00001, loss_test:0.07086, lr:7.40e-03, fs:0.87097 (r=0.818,p=0.931),  time:37.439, tt:4492.643\n",
      "Ep:120, loss:0.00001, loss_test:0.07158, lr:7.32e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.428, tt:4528.734\n",
      "Ep:121, loss:0.00001, loss_test:0.07241, lr:7.25e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.414, tt:4564.466\n",
      "Ep:122, loss:0.00001, loss_test:0.07209, lr:7.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.382, tt:4598.044\n",
      "Ep:123, loss:0.00001, loss_test:0.07126, lr:7.11e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.369, tt:4633.743\n",
      "Ep:124, loss:0.00001, loss_test:0.07199, lr:7.03e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.339, tt:4667.436\n",
      "Ep:125, loss:0.00001, loss_test:0.07124, lr:6.96e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.322, tt:4702.523\n",
      "Ep:126, loss:0.00001, loss_test:0.07179, lr:6.89e-03, fs:0.83978 (r=0.768,p=0.927),  time:37.321, tt:4739.722\n",
      "Ep:127, loss:0.00001, loss_test:0.07207, lr:6.83e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.307, tt:4775.241\n",
      "Ep:128, loss:0.00001, loss_test:0.07180, lr:6.76e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.300, tt:4811.688\n",
      "Ep:129, loss:0.00001, loss_test:0.07140, lr:6.69e-03, fs:0.85870 (r=0.798,p=0.929),  time:37.277, tt:4846.007\n",
      "Ep:130, loss:0.00001, loss_test:0.07181, lr:6.62e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.260, tt:4881.052\n",
      "Ep:131, loss:0.00001, loss_test:0.07252, lr:6.56e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.249, tt:4916.827\n",
      "Ep:132, loss:0.00001, loss_test:0.07211, lr:6.49e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.239, tt:4952.778\n",
      "Ep:133, loss:0.00001, loss_test:0.07182, lr:6.43e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.231, tt:4988.937\n",
      "Ep:134, loss:0.00001, loss_test:0.07300, lr:6.36e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.217, tt:5024.351\n",
      "Ep:135, loss:0.00001, loss_test:0.07091, lr:6.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.220, tt:5061.870\n",
      "Ep:136, loss:0.00001, loss_test:0.07347, lr:6.24e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.220, tt:5099.132\n",
      "Ep:137, loss:0.00001, loss_test:0.07178, lr:6.17e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.219, tt:5136.269\n",
      "Ep:138, loss:0.00001, loss_test:0.07125, lr:6.11e-03, fs:0.80000 (r=0.707,p=0.921),  time:37.209, tt:5172.080\n",
      "Ep:139, loss:0.00001, loss_test:0.07256, lr:6.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.202, tt:5208.273\n",
      "Ep:140, loss:0.00001, loss_test:0.07165, lr:5.99e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.191, tt:5243.885\n",
      "Ep:141, loss:0.00001, loss_test:0.07234, lr:5.93e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.191, tt:5281.180\n",
      "Ep:142, loss:0.00001, loss_test:0.07165, lr:5.87e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.185, tt:5317.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.07172, lr:5.81e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.168, tt:5352.170\n",
      "Ep:144, loss:0.00001, loss_test:0.07131, lr:5.75e-03, fs:0.79310 (r=0.697,p=0.920),  time:37.163, tt:5388.629\n",
      "Ep:145, loss:0.00001, loss_test:0.07146, lr:5.70e-03, fs:0.79310 (r=0.697,p=0.920),  time:37.155, tt:5424.612\n",
      "Ep:146, loss:0.00001, loss_test:0.07181, lr:5.64e-03, fs:0.79310 (r=0.697,p=0.920),  time:37.163, tt:5463.002\n",
      "Ep:147, loss:0.00001, loss_test:0.07122, lr:5.58e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.143, tt:5497.101\n",
      "Ep:148, loss:0.00001, loss_test:0.07199, lr:5.53e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.134, tt:5532.944\n",
      "Ep:149, loss:0.00001, loss_test:0.07157, lr:5.47e-03, fs:0.79310 (r=0.697,p=0.920),  time:37.126, tt:5568.835\n",
      "Ep:150, loss:0.00001, loss_test:0.07219, lr:5.42e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.109, tt:5603.386\n",
      "Ep:151, loss:0.00001, loss_test:0.07112, lr:5.36e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.097, tt:5638.801\n",
      "Ep:152, loss:0.00001, loss_test:0.07168, lr:5.31e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.092, tt:5675.146\n",
      "Ep:153, loss:0.00001, loss_test:0.07218, lr:5.26e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.097, tt:5712.974\n",
      "Ep:154, loss:0.00001, loss_test:0.07132, lr:5.20e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.095, tt:5749.721\n",
      "Ep:155, loss:0.00001, loss_test:0.07173, lr:5.15e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.093, tt:5786.527\n",
      "Ep:156, loss:0.00001, loss_test:0.07172, lr:5.10e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.090, tt:5823.158\n",
      "Ep:157, loss:0.00001, loss_test:0.07160, lr:5.05e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.088, tt:5859.842\n",
      "Ep:158, loss:0.00001, loss_test:0.07140, lr:5.00e-03, fs:0.78613 (r=0.687,p=0.919),  time:37.079, tt:5895.610\n",
      "Ep:159, loss:0.00001, loss_test:0.07195, lr:4.95e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.068, tt:5930.804\n",
      "Ep:160, loss:0.00001, loss_test:0.07203, lr:4.90e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.064, tt:5967.336\n",
      "Ep:161, loss:0.00001, loss_test:0.07149, lr:4.85e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.055, tt:6002.988\n",
      "Ep:162, loss:0.00001, loss_test:0.07195, lr:4.80e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.054, tt:6039.760\n",
      "Ep:163, loss:0.00001, loss_test:0.07170, lr:4.75e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.042, tt:6074.951\n",
      "Ep:164, loss:0.00001, loss_test:0.07209, lr:4.71e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.062, tt:6115.294\n",
      "Ep:165, loss:0.00001, loss_test:0.07147, lr:4.66e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.061, tt:6152.193\n",
      "Ep:166, loss:0.00001, loss_test:0.07188, lr:4.61e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.066, tt:6190.030\n",
      "Ep:167, loss:0.00001, loss_test:0.07186, lr:4.57e-03, fs:0.77907 (r=0.677,p=0.918),  time:37.069, tt:6227.641\n",
      "Ep:168, loss:0.00001, loss_test:0.07118, lr:4.52e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.070, tt:6264.849\n",
      "Ep:169, loss:0.00001, loss_test:0.07192, lr:4.48e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.080, tt:6303.515\n",
      "Ep:170, loss:0.00001, loss_test:0.07185, lr:4.43e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.072, tt:6339.243\n",
      "Ep:171, loss:0.00001, loss_test:0.07163, lr:4.39e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.066, tt:6375.374\n",
      "Ep:172, loss:0.00001, loss_test:0.07154, lr:4.34e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.068, tt:6412.825\n",
      "Ep:173, loss:0.00001, loss_test:0.07191, lr:4.30e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.067, tt:6449.692\n",
      "Ep:174, loss:0.00001, loss_test:0.07175, lr:4.26e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.072, tt:6487.530\n",
      "Ep:175, loss:0.00001, loss_test:0.07157, lr:4.21e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.076, tt:6525.294\n",
      "Ep:176, loss:0.00001, loss_test:0.07185, lr:4.17e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.073, tt:6561.996\n",
      "Ep:177, loss:0.00001, loss_test:0.07133, lr:4.13e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.072, tt:6598.738\n",
      "Ep:178, loss:0.00001, loss_test:0.07195, lr:4.09e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.065, tt:6634.681\n",
      "Ep:179, loss:0.00001, loss_test:0.07195, lr:4.05e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.063, tt:6671.273\n",
      "Ep:180, loss:0.00001, loss_test:0.07198, lr:4.01e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.057, tt:6707.292\n",
      "Ep:181, loss:0.00001, loss_test:0.07131, lr:3.97e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.056, tt:6744.243\n",
      "Ep:182, loss:0.00001, loss_test:0.07135, lr:3.93e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.058, tt:6781.682\n",
      "Ep:183, loss:0.00001, loss_test:0.07183, lr:3.89e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.065, tt:6820.006\n",
      "Ep:184, loss:0.00001, loss_test:0.07121, lr:3.85e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.070, tt:6857.915\n",
      "Ep:185, loss:0.00001, loss_test:0.07177, lr:3.81e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.069, tt:6894.915\n",
      "Ep:186, loss:0.00001, loss_test:0.07199, lr:3.77e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.067, tt:6931.453\n",
      "Ep:187, loss:0.00001, loss_test:0.07177, lr:3.73e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.072, tt:6969.593\n",
      "Ep:188, loss:0.00001, loss_test:0.07134, lr:3.70e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.071, tt:7006.500\n",
      "Ep:189, loss:0.00001, loss_test:0.07172, lr:3.66e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.070, tt:7043.230\n",
      "Ep:190, loss:0.00001, loss_test:0.07183, lr:3.62e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.051, tt:7076.809\n",
      "Ep:191, loss:0.00001, loss_test:0.07159, lr:3.59e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.039, tt:7111.497\n",
      "Ep:192, loss:0.00001, loss_test:0.07133, lr:3.55e-03, fs:0.78363 (r=0.677,p=0.931),  time:37.003, tt:7141.656\n",
      "Ep:193, loss:0.00001, loss_test:0.07142, lr:3.52e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.974, tt:7173.029\n",
      "Ep:194, loss:0.00001, loss_test:0.07173, lr:3.48e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.944, tt:7204.088\n",
      "Ep:195, loss:0.00001, loss_test:0.07189, lr:3.45e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.889, tt:7230.167\n",
      "Ep:196, loss:0.00001, loss_test:0.07130, lr:3.41e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.839, tt:7257.284\n",
      "Ep:197, loss:0.00001, loss_test:0.07162, lr:3.38e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.819, tt:7290.106\n",
      "Ep:198, loss:0.00001, loss_test:0.07168, lr:3.34e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.816, tt:7326.354\n",
      "Ep:199, loss:0.00001, loss_test:0.07170, lr:3.31e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.813, tt:7362.645\n",
      "Ep:200, loss:0.00001, loss_test:0.07139, lr:3.28e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.802, tt:7397.125\n",
      "Ep:201, loss:0.00001, loss_test:0.07132, lr:3.24e-03, fs:0.78363 (r=0.677,p=0.931),  time:36.788, tt:7431.249\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00012, loss_test:0.02095, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:29.918, tt:29.918\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02502, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.635, tt:61.270\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02754, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.228, tt:90.683\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00005, loss_test:0.02833, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.301, tt:121.204\n",
      "Ep:4, loss:0.00006, loss_test:0.02833, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.263, tt:151.315\n",
      "Ep:5, loss:0.00005, loss_test:0.02743, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:30.177, tt:181.061\n",
      "Ep:6, loss:0.00005, loss_test:0.02594, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:30.249, tt:211.742\n",
      "Ep:7, loss:0.00005, loss_test:0.02433, lr:6.00e-02, fs:0.64808 (r=0.939,p=0.495),  time:30.503, tt:244.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00005, loss_test:0.02302, lr:6.00e-02, fs:0.64000 (r=0.889,p=0.500),  time:30.519, tt:274.668\n",
      "Ep:9, loss:0.00005, loss_test:0.02232, lr:6.00e-02, fs:0.65900 (r=0.869,p=0.531),  time:30.519, tt:305.188\n",
      "Ep:10, loss:0.00004, loss_test:0.02203, lr:6.00e-02, fs:0.66667 (r=0.838,p=0.553),  time:30.490, tt:335.387\n",
      "Ep:11, loss:0.00004, loss_test:0.02165, lr:6.00e-02, fs:0.66129 (r=0.828,p=0.550),  time:30.483, tt:365.793\n",
      "Ep:12, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.67984 (r=0.869,p=0.558),  time:30.501, tt:396.509\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.02081, lr:6.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:30.482, tt:426.752\n",
      "Ep:14, loss:0.00004, loss_test:0.02064, lr:6.00e-02, fs:0.66667 (r=0.899,p=0.530),  time:30.472, tt:457.080\n",
      "Ep:15, loss:0.00004, loss_test:0.02038, lr:6.00e-02, fs:0.66917 (r=0.899,p=0.533),  time:30.376, tt:486.015\n",
      "Ep:16, loss:0.00004, loss_test:0.02012, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:30.324, tt:515.506\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01998, lr:6.00e-02, fs:0.69355 (r=0.869,p=0.577),  time:30.271, tt:544.881\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01990, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:30.308, tt:575.851\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01984, lr:6.00e-02, fs:0.69636 (r=0.869,p=0.581),  time:30.333, tt:606.656\n",
      "Ep:20, loss:0.00004, loss_test:0.01976, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.362, tt:637.607\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01966, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.332, tt:667.294\n",
      "Ep:22, loss:0.00004, loss_test:0.01951, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.340, tt:697.810\n",
      "Ep:23, loss:0.00004, loss_test:0.01936, lr:6.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:30.402, tt:729.650\n",
      "Ep:24, loss:0.00004, loss_test:0.01919, lr:6.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:30.415, tt:760.378\n",
      "Ep:25, loss:0.00004, loss_test:0.01899, lr:6.00e-02, fs:0.68526 (r=0.869,p=0.566),  time:30.364, tt:789.453\n",
      "Ep:26, loss:0.00004, loss_test:0.01881, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:30.344, tt:819.301\n",
      "Ep:27, loss:0.00004, loss_test:0.01865, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:30.301, tt:848.433\n",
      "Ep:28, loss:0.00004, loss_test:0.01845, lr:6.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:30.291, tt:878.431\n",
      "Ep:29, loss:0.00003, loss_test:0.01824, lr:6.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:30.273, tt:908.189\n",
      "Ep:30, loss:0.00003, loss_test:0.01797, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:30.273, tt:938.457\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01768, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:30.275, tt:968.812\n",
      "Ep:32, loss:0.00003, loss_test:0.01747, lr:6.00e-02, fs:0.70445 (r=0.879,p=0.588),  time:30.275, tt:999.078\n",
      "Ep:33, loss:0.00003, loss_test:0.01724, lr:6.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:30.297, tt:1030.102\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01699, lr:6.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:30.329, tt:1061.519\n",
      "Ep:35, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:30.346, tt:1092.441\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01643, lr:6.00e-02, fs:0.71774 (r=0.899,p=0.597),  time:30.358, tt:1123.232\n",
      "Ep:37, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:30.427, tt:1156.232\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:30.454, tt:1187.709\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01564, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:30.451, tt:1218.042\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:30.430, tt:1247.623\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01498, lr:6.00e-02, fs:0.75304 (r=0.939,p=0.628),  time:30.388, tt:1276.298\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01465, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.385, tt:1306.557\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:30.375, tt:1336.519\n",
      "Ep:44, loss:0.00002, loss_test:0.01413, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:30.357, tt:1366.071\n",
      "Ep:45, loss:0.00002, loss_test:0.01389, lr:6.00e-02, fs:0.77686 (r=0.949,p=0.657),  time:30.322, tt:1394.799\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01366, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:30.303, tt:1424.253\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:30.266, tt:1452.746\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:30.213, tt:1480.461\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.181, tt:1509.045\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01290, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:30.170, tt:1538.692\n",
      "Ep:51, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:30.152, tt:1567.888\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01258, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:30.129, tt:1596.815\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00002, loss_test:0.01249, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:30.109, tt:1625.904\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01240, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:30.091, tt:1654.996\n",
      "Ep:55, loss:0.00002, loss_test:0.01233, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:30.082, tt:1684.575\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:30.057, tt:1713.276\n",
      "Ep:57, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:30.042, tt:1742.415\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:30.027, tt:1771.571\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01199, lr:6.00e-02, fs:0.83478 (r=0.970,p=0.733),  time:30.026, tt:1801.562\n",
      "Ep:60, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:30.069, tt:1834.193\n",
      "Ep:61, loss:0.00001, loss_test:0.01191, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:30.081, tt:1865.048\n",
      "Ep:62, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:30.061, tt:1893.825\n",
      "Ep:63, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.060, tt:1923.857\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:30.048, tt:1953.089\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00001, loss_test:0.01172, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.040, tt:1982.635\n",
      "Ep:66, loss:0.00001, loss_test:0.01170, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:30.042, tt:2012.826\n",
      "Ep:67, loss:0.00001, loss_test:0.01165, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:30.023, tt:2041.593\n",
      "Ep:68, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:30.027, tt:2071.836\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.01165, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:30.036, tt:2102.523\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01154, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:30.041, tt:2132.933\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01157, lr:6.00e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.045, tt:2163.233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:30.040, tt:2192.904\n",
      "Ep:73, loss:0.00001, loss_test:0.01161, lr:6.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:30.019, tt:2221.440\n",
      "Ep:74, loss:0.00001, loss_test:0.01167, lr:6.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:30.024, tt:2251.768\n",
      "Ep:75, loss:0.00001, loss_test:0.01174, lr:6.00e-02, fs:0.84762 (r=0.899,p=0.802),  time:30.027, tt:2282.046\n",
      "Ep:76, loss:0.00001, loss_test:0.01161, lr:6.00e-02, fs:0.85024 (r=0.889,p=0.815),  time:30.040, tt:2313.110\n",
      "Ep:77, loss:0.00001, loss_test:0.01172, lr:6.00e-02, fs:0.84615 (r=0.889,p=0.807),  time:30.034, tt:2342.657\n",
      "Ep:78, loss:0.00001, loss_test:0.01174, lr:6.00e-02, fs:0.85437 (r=0.889,p=0.822),  time:30.031, tt:2372.422\n",
      "Ep:79, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.83744 (r=0.859,p=0.817),  time:30.025, tt:2402.032\n",
      "Ep:80, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:30.025, tt:2432.011\n",
      "Ep:81, loss:0.00001, loss_test:0.01180, lr:6.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:30.017, tt:2461.360\n",
      "Ep:82, loss:0.00001, loss_test:0.01183, lr:5.94e-02, fs:0.83168 (r=0.848,p=0.816),  time:30.003, tt:2490.239\n",
      "Ep:83, loss:0.00001, loss_test:0.01189, lr:5.88e-02, fs:0.83744 (r=0.859,p=0.817),  time:30.003, tt:2520.247\n",
      "Ep:84, loss:0.00001, loss_test:0.01191, lr:5.82e-02, fs:0.83168 (r=0.848,p=0.816),  time:29.988, tt:2548.955\n",
      "Ep:85, loss:0.00001, loss_test:0.01197, lr:5.76e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.987, tt:2578.923\n",
      "Ep:86, loss:0.00001, loss_test:0.01192, lr:5.71e-02, fs:0.82587 (r=0.838,p=0.814),  time:29.998, tt:2609.831\n",
      "Ep:87, loss:0.00001, loss_test:0.01207, lr:5.65e-02, fs:0.83000 (r=0.838,p=0.822),  time:29.997, tt:2639.735\n",
      "Ep:88, loss:0.00001, loss_test:0.01211, lr:5.59e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.988, tt:2668.930\n",
      "Ep:89, loss:0.00001, loss_test:0.01220, lr:5.54e-02, fs:0.81818 (r=0.818,p=0.818),  time:29.980, tt:2698.242\n",
      "Ep:90, loss:0.00001, loss_test:0.01222, lr:5.48e-02, fs:0.82412 (r=0.828,p=0.820),  time:29.974, tt:2727.620\n",
      "Ep:91, loss:0.00001, loss_test:0.01221, lr:5.43e-02, fs:0.82234 (r=0.818,p=0.827),  time:29.967, tt:2757.004\n",
      "Ep:92, loss:0.00001, loss_test:0.01231, lr:5.37e-02, fs:0.81218 (r=0.808,p=0.816),  time:29.945, tt:2784.922\n",
      "Ep:93, loss:0.00001, loss_test:0.01236, lr:5.32e-02, fs:0.81818 (r=0.818,p=0.818),  time:29.942, tt:2814.581\n",
      "Ep:94, loss:0.00001, loss_test:0.01240, lr:5.27e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.938, tt:2844.115\n",
      "Ep:95, loss:0.00001, loss_test:0.01252, lr:5.21e-02, fs:0.80612 (r=0.798,p=0.814),  time:29.936, tt:2873.886\n",
      "Ep:96, loss:0.00001, loss_test:0.01254, lr:5.16e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.925, tt:2902.760\n",
      "Ep:97, loss:0.00001, loss_test:0.01259, lr:5.11e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.920, tt:2932.116\n",
      "Ep:98, loss:0.00001, loss_test:0.01269, lr:5.06e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.913, tt:2961.359\n",
      "Ep:99, loss:0.00001, loss_test:0.01274, lr:5.01e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.887, tt:2988.686\n",
      "Ep:100, loss:0.00001, loss_test:0.01280, lr:4.96e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.868, tt:3016.637\n",
      "Ep:101, loss:0.00001, loss_test:0.01293, lr:4.91e-02, fs:0.81026 (r=0.798,p=0.823),  time:29.856, tt:3045.263\n",
      "Ep:102, loss:0.00001, loss_test:0.01298, lr:4.86e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.862, tt:3075.766\n",
      "Ep:103, loss:0.00001, loss_test:0.01314, lr:4.81e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.866, tt:3106.029\n",
      "Ep:104, loss:0.00000, loss_test:0.01308, lr:4.76e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.844, tt:3133.592\n",
      "Ep:105, loss:0.00000, loss_test:0.01318, lr:4.71e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.848, tt:3163.899\n",
      "Ep:106, loss:0.00000, loss_test:0.01334, lr:4.67e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.857, tt:3194.667\n",
      "Ep:107, loss:0.00000, loss_test:0.01331, lr:4.62e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.854, tt:3224.278\n",
      "Ep:108, loss:0.00000, loss_test:0.01352, lr:4.57e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.853, tt:3254.027\n",
      "Ep:109, loss:0.00000, loss_test:0.01349, lr:4.53e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.844, tt:3282.855\n",
      "Ep:110, loss:0.00000, loss_test:0.01361, lr:4.48e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.838, tt:3311.986\n",
      "Ep:111, loss:0.00000, loss_test:0.01365, lr:4.44e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.830, tt:3340.981\n",
      "Ep:112, loss:0.00000, loss_test:0.01377, lr:4.39e-02, fs:0.80208 (r=0.778,p=0.828),  time:29.814, tt:3369.038\n",
      "Ep:113, loss:0.00000, loss_test:0.01376, lr:4.35e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.818, tt:3399.229\n",
      "Ep:114, loss:0.00000, loss_test:0.01385, lr:4.31e-02, fs:0.81443 (r=0.798,p=0.832),  time:29.825, tt:3429.929\n",
      "Ep:115, loss:0.00000, loss_test:0.01403, lr:4.26e-02, fs:0.80829 (r=0.788,p=0.830),  time:29.824, tt:3459.593\n",
      "Ep:116, loss:0.00000, loss_test:0.01410, lr:4.22e-02, fs:0.80628 (r=0.778,p=0.837),  time:29.827, tt:3489.780\n",
      "Ep:117, loss:0.00000, loss_test:0.01408, lr:4.18e-02, fs:0.81250 (r=0.788,p=0.839),  time:29.826, tt:3519.455\n",
      "Ep:118, loss:0.00000, loss_test:0.01427, lr:4.14e-02, fs:0.80628 (r=0.778,p=0.837),  time:29.833, tt:3550.097\n",
      "Ep:119, loss:0.00000, loss_test:0.01429, lr:4.10e-02, fs:0.81675 (r=0.788,p=0.848),  time:29.842, tt:3581.048\n",
      "Ep:120, loss:0.00000, loss_test:0.01430, lr:4.05e-02, fs:0.81250 (r=0.788,p=0.839),  time:29.835, tt:3610.056\n",
      "Ep:121, loss:0.00000, loss_test:0.01448, lr:4.01e-02, fs:0.82105 (r=0.788,p=0.857),  time:29.847, tt:3641.317\n",
      "Ep:122, loss:0.00000, loss_test:0.01454, lr:3.97e-02, fs:0.80000 (r=0.768,p=0.835),  time:29.844, tt:3670.780\n",
      "Ep:123, loss:0.00000, loss_test:0.01457, lr:3.93e-02, fs:0.81053 (r=0.778,p=0.846),  time:29.823, tt:3698.111\n",
      "Ep:124, loss:0.00000, loss_test:0.01469, lr:3.89e-02, fs:0.80851 (r=0.768,p=0.854),  time:29.820, tt:3727.554\n",
      "Ep:125, loss:0.00000, loss_test:0.01473, lr:3.86e-02, fs:0.80851 (r=0.768,p=0.854),  time:29.831, tt:3758.646\n",
      "Ep:126, loss:0.00000, loss_test:0.01475, lr:3.82e-02, fs:0.81283 (r=0.768,p=0.864),  time:29.838, tt:3789.402\n",
      "Ep:127, loss:0.00000, loss_test:0.01496, lr:3.78e-02, fs:0.79570 (r=0.747,p=0.851),  time:29.849, tt:3820.732\n",
      "Ep:128, loss:0.00000, loss_test:0.01499, lr:3.74e-02, fs:0.80214 (r=0.758,p=0.852),  time:29.854, tt:3851.147\n",
      "Ep:129, loss:0.00000, loss_test:0.01513, lr:3.70e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.858, tt:3881.583\n",
      "Ep:130, loss:0.00000, loss_test:0.01516, lr:3.67e-02, fs:0.79348 (r=0.737,p=0.859),  time:29.864, tt:3912.214\n",
      "Ep:131, loss:0.00000, loss_test:0.01514, lr:3.63e-02, fs:0.79781 (r=0.737,p=0.869),  time:29.864, tt:3942.114\n",
      "Ep:132, loss:0.00000, loss_test:0.01533, lr:3.59e-02, fs:0.78889 (r=0.717,p=0.877),  time:29.865, tt:3972.107\n",
      "Ep:133, loss:0.00000, loss_test:0.01541, lr:3.56e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.865, tt:4001.976\n",
      "Ep:134, loss:0.00000, loss_test:0.01543, lr:3.52e-02, fs:0.77778 (r=0.707,p=0.864),  time:29.862, tt:4031.422\n",
      "Ep:135, loss:0.00000, loss_test:0.01554, lr:3.49e-02, fs:0.77095 (r=0.697,p=0.863),  time:29.861, tt:4061.037\n",
      "Ep:136, loss:0.00000, loss_test:0.01558, lr:3.45e-02, fs:0.77095 (r=0.697,p=0.863),  time:29.861, tt:4091.025\n",
      "Ep:137, loss:0.00000, loss_test:0.01563, lr:3.42e-02, fs:0.78652 (r=0.707,p=0.886),  time:29.854, tt:4119.905\n",
      "Ep:138, loss:0.00000, loss_test:0.01570, lr:3.38e-02, fs:0.77095 (r=0.697,p=0.863),  time:29.848, tt:4148.875\n",
      "Ep:139, loss:0.00000, loss_test:0.01584, lr:3.35e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.858, tt:4180.166\n",
      "Ep:140, loss:0.00000, loss_test:0.01583, lr:3.32e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.851, tt:4208.966\n",
      "Ep:141, loss:0.00000, loss_test:0.01597, lr:3.28e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.848, tt:4238.357\n",
      "Ep:142, loss:0.00000, loss_test:0.01607, lr:3.25e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.843, tt:4267.569\n",
      "Ep:143, loss:0.00000, loss_test:0.01604, lr:3.22e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.839, tt:4296.852\n",
      "Ep:144, loss:0.00000, loss_test:0.01617, lr:3.19e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.826, tt:4324.841\n",
      "Ep:145, loss:0.00000, loss_test:0.01621, lr:3.15e-02, fs:0.77966 (r=0.697,p=0.885),  time:29.819, tt:4353.541\n",
      "Ep:146, loss:0.00000, loss_test:0.01627, lr:3.12e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.821, tt:4383.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00000, loss_test:0.01637, lr:3.09e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.823, tt:4413.801\n",
      "Ep:148, loss:0.00000, loss_test:0.01644, lr:3.06e-02, fs:0.77273 (r=0.687,p=0.883),  time:29.828, tt:4444.352\n",
      "Ep:149, loss:0.00000, loss_test:0.01648, lr:3.03e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.819, tt:4472.804\n",
      "Ep:150, loss:0.00000, loss_test:0.01648, lr:3.00e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.820, tt:4502.760\n",
      "Ep:151, loss:0.00000, loss_test:0.01661, lr:2.97e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.822, tt:4532.872\n",
      "Ep:152, loss:0.00000, loss_test:0.01668, lr:2.94e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.824, tt:4563.083\n",
      "Ep:153, loss:0.00000, loss_test:0.01671, lr:2.91e-02, fs:0.77714 (r=0.687,p=0.895),  time:29.826, tt:4593.243\n",
      "Ep:154, loss:0.00000, loss_test:0.01676, lr:2.88e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.822, tt:4622.342\n",
      "Ep:155, loss:0.00000, loss_test:0.01688, lr:2.85e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.815, tt:4651.212\n",
      "Ep:156, loss:0.00000, loss_test:0.01693, lr:2.82e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.813, tt:4680.680\n",
      "Ep:157, loss:0.00000, loss_test:0.01696, lr:2.80e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.813, tt:4710.414\n",
      "Ep:158, loss:0.00000, loss_test:0.01703, lr:2.77e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.815, tt:4740.536\n",
      "Ep:159, loss:0.00000, loss_test:0.01709, lr:2.74e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.819, tt:4770.971\n",
      "Ep:160, loss:0.00000, loss_test:0.01715, lr:2.71e-02, fs:0.78161 (r=0.687,p=0.907),  time:29.809, tt:4799.207\n",
      "Ep:161, loss:0.00000, loss_test:0.01713, lr:2.69e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.804, tt:4828.306\n",
      "Ep:162, loss:0.00000, loss_test:0.01728, lr:2.66e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.796, tt:4856.770\n",
      "Ep:163, loss:0.00000, loss_test:0.01731, lr:2.63e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.802, tt:4887.466\n",
      "Ep:164, loss:0.00000, loss_test:0.01732, lr:2.61e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.800, tt:4916.923\n",
      "Ep:165, loss:0.00000, loss_test:0.01740, lr:2.58e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.798, tt:4946.390\n",
      "Ep:166, loss:0.00000, loss_test:0.01747, lr:2.55e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.789, tt:4974.721\n",
      "Ep:167, loss:0.00000, loss_test:0.01751, lr:2.53e-02, fs:0.78613 (r=0.687,p=0.919),  time:29.788, tt:5004.431\n",
      "Ep:168, loss:0.00000, loss_test:0.01755, lr:2.50e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.781, tt:5032.979\n",
      "Ep:169, loss:0.00000, loss_test:0.01756, lr:2.48e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.783, tt:5063.062\n",
      "Ep:170, loss:0.00000, loss_test:0.01766, lr:2.45e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.780, tt:5092.405\n",
      "Ep:171, loss:0.00000, loss_test:0.01769, lr:2.43e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.772, tt:5120.856\n",
      "Ep:172, loss:0.00000, loss_test:0.01770, lr:2.40e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.782, tt:5152.255\n",
      "Ep:173, loss:0.00000, loss_test:0.01776, lr:2.38e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.772, tt:5180.310\n",
      "Ep:174, loss:0.00000, loss_test:0.01783, lr:2.36e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.771, tt:5209.947\n",
      "Ep:175, loss:0.00000, loss_test:0.01784, lr:2.33e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.768, tt:5239.201\n",
      "Ep:176, loss:0.00000, loss_test:0.01786, lr:2.31e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.761, tt:5267.753\n",
      "Ep:177, loss:0.00000, loss_test:0.01795, lr:2.29e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.757, tt:5296.676\n",
      "Ep:178, loss:0.00000, loss_test:0.01798, lr:2.26e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.748, tt:5324.870\n",
      "Ep:179, loss:0.00000, loss_test:0.01795, lr:2.24e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.764, tt:5357.521\n",
      "Ep:180, loss:0.00000, loss_test:0.01803, lr:2.22e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.759, tt:5386.464\n",
      "Ep:181, loss:0.00000, loss_test:0.01810, lr:2.20e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.755, tt:5415.423\n",
      "Ep:182, loss:0.00000, loss_test:0.01808, lr:2.17e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.750, tt:5444.286\n",
      "Ep:183, loss:0.00000, loss_test:0.01813, lr:2.15e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.750, tt:5474.021\n",
      "Ep:184, loss:0.00000, loss_test:0.01826, lr:2.13e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.750, tt:5503.682\n",
      "Ep:185, loss:0.00000, loss_test:0.01827, lr:2.11e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.746, tt:5532.665\n",
      "Ep:186, loss:0.00000, loss_test:0.01826, lr:2.09e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.728, tt:5559.191\n",
      "Ep:187, loss:0.00000, loss_test:0.01831, lr:2.07e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.723, tt:5587.839\n",
      "Ep:188, loss:0.00000, loss_test:0.01836, lr:2.05e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.718, tt:5616.783\n",
      "Ep:189, loss:0.00000, loss_test:0.01837, lr:2.03e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.703, tt:5643.604\n",
      "Ep:190, loss:0.00000, loss_test:0.01840, lr:2.01e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.687, tt:5670.179\n",
      "Ep:191, loss:0.00000, loss_test:0.01844, lr:1.99e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.681, tt:5698.666\n",
      "Ep:192, loss:0.00000, loss_test:0.01849, lr:1.97e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.658, tt:5723.937\n",
      "Ep:193, loss:0.00000, loss_test:0.01853, lr:1.95e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.642, tt:5750.451\n",
      "Ep:194, loss:0.00000, loss_test:0.01856, lr:1.93e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.631, tt:5778.058\n",
      "Ep:195, loss:0.00000, loss_test:0.01862, lr:1.91e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.626, tt:5806.778\n",
      "Ep:196, loss:0.00000, loss_test:0.01863, lr:1.89e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.625, tt:5836.077\n",
      "Ep:197, loss:0.00000, loss_test:0.01862, lr:1.87e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.626, tt:5865.960\n",
      "Ep:198, loss:0.00000, loss_test:0.01867, lr:1.85e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.630, tt:5896.394\n",
      "Ep:199, loss:0.00000, loss_test:0.01875, lr:1.83e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.626, tt:5925.134\n",
      "Ep:200, loss:0.00000, loss_test:0.01875, lr:1.81e-02, fs:0.79070 (r=0.687,p=0.932),  time:29.613, tt:5952.218\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_300_300_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13236, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:34.992, tt:34.992\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12904, lr:1.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:33.499, tt:66.997\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12481, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:32.977, tt:98.930\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12105, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:32.538, tt:130.150\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11856, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:32.509, tt:162.545\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11642, lr:1.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:32.513, tt:195.079\n",
      "Ep:6, loss:0.00025, loss_test:0.11420, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:32.651, tt:228.554\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11222, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:32.712, tt:261.699\n",
      "Ep:8, loss:0.00024, loss_test:0.11042, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:32.684, tt:294.158\n",
      "Ep:9, loss:0.00023, loss_test:0.10964, lr:1.00e-02, fs:0.68670 (r=0.808,p=0.597),  time:32.652, tt:326.524\n",
      "Ep:10, loss:0.00023, loss_test:0.10987, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:32.535, tt:357.883\n",
      "Ep:11, loss:0.00023, loss_test:0.10980, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:32.509, tt:390.111\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00022, loss_test:0.10895, lr:1.00e-02, fs:0.71245 (r=0.838,p=0.619),  time:32.519, tt:422.747\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00022, loss_test:0.10822, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:32.524, tt:455.340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00021, loss_test:0.10752, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:32.536, tt:488.045\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00021, loss_test:0.10683, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:32.602, tt:521.633\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00021, loss_test:0.10692, lr:1.00e-02, fs:0.71861 (r=0.838,p=0.629),  time:32.554, tt:553.410\n",
      "Ep:17, loss:0.00020, loss_test:0.10639, lr:1.00e-02, fs:0.70690 (r=0.828,p=0.617),  time:32.527, tt:585.495\n",
      "Ep:18, loss:0.00020, loss_test:0.10473, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:32.472, tt:616.970\n",
      "Ep:19, loss:0.00019, loss_test:0.10419, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:32.486, tt:649.718\n",
      "Ep:20, loss:0.00019, loss_test:0.10372, lr:1.00e-02, fs:0.72174 (r=0.838,p=0.634),  time:32.437, tt:681.170\n",
      "Ep:21, loss:0.00018, loss_test:0.10212, lr:1.00e-02, fs:0.72961 (r=0.859,p=0.634),  time:32.434, tt:713.541\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00018, loss_test:0.10059, lr:1.00e-02, fs:0.73593 (r=0.859,p=0.644),  time:32.361, tt:744.294\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00018, loss_test:0.10193, lr:1.00e-02, fs:0.74576 (r=0.889,p=0.642),  time:32.363, tt:776.718\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.09966, lr:1.00e-02, fs:0.74894 (r=0.889,p=0.647),  time:32.365, tt:809.120\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00017, loss_test:0.09826, lr:1.00e-02, fs:0.75214 (r=0.889,p=0.652),  time:32.350, tt:841.108\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00016, loss_test:0.09664, lr:1.00e-02, fs:0.76271 (r=0.909,p=0.657),  time:32.391, tt:874.565\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00016, loss_test:0.09543, lr:1.00e-02, fs:0.76068 (r=0.899,p=0.659),  time:32.429, tt:908.011\n",
      "Ep:28, loss:0.00015, loss_test:0.09426, lr:1.00e-02, fs:0.76724 (r=0.899,p=0.669),  time:32.418, tt:940.112\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00015, loss_test:0.09237, lr:1.00e-02, fs:0.77586 (r=0.909,p=0.677),  time:32.369, tt:971.077\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00014, loss_test:0.09122, lr:1.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:32.330, tt:1002.218\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00014, loss_test:0.08812, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:32.253, tt:1032.095\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.08872, lr:1.00e-02, fs:0.79646 (r=0.909,p=0.709),  time:32.256, tt:1064.440\n",
      "Ep:33, loss:0.00013, loss_test:0.08641, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:32.241, tt:1096.200\n",
      "Ep:34, loss:0.00012, loss_test:0.08399, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:32.193, tt:1126.744\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.08542, lr:1.00e-02, fs:0.80543 (r=0.899,p=0.730),  time:32.149, tt:1157.369\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08154, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:32.126, tt:1188.647\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.08345, lr:1.00e-02, fs:0.81448 (r=0.909,p=0.738),  time:32.116, tt:1220.395\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00010, loss_test:0.08139, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:32.123, tt:1252.800\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00010, loss_test:0.08086, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:32.142, tt:1285.677\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.08188, lr:1.00e-02, fs:0.82075 (r=0.879,p=0.770),  time:32.150, tt:1318.130\n",
      "Ep:41, loss:0.00009, loss_test:0.07895, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:32.132, tt:1349.538\n",
      "Ep:42, loss:0.00009, loss_test:0.08335, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:32.114, tt:1380.897\n",
      "Ep:43, loss:0.00009, loss_test:0.07581, lr:1.00e-02, fs:0.82178 (r=0.838,p=0.806),  time:32.085, tt:1411.735\n",
      "Ep:44, loss:0.00008, loss_test:0.08048, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:32.040, tt:1441.798\n",
      "Ep:45, loss:0.00008, loss_test:0.07445, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:31.984, tt:1471.278\n",
      "Ep:46, loss:0.00008, loss_test:0.07770, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:31.952, tt:1501.734\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00008, loss_test:0.07607, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:31.944, tt:1533.298\n",
      "Ep:48, loss:0.00007, loss_test:0.07617, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:31.916, tt:1563.892\n",
      "Ep:49, loss:0.00007, loss_test:0.07423, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:31.895, tt:1594.748\n",
      "Ep:50, loss:0.00007, loss_test:0.07681, lr:1.00e-02, fs:0.75789 (r=0.727,p=0.791),  time:31.864, tt:1625.044\n",
      "Ep:51, loss:0.00007, loss_test:0.07282, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:31.836, tt:1655.488\n",
      "Ep:52, loss:0.00007, loss_test:0.07550, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:31.849, tt:1687.988\n",
      "Ep:53, loss:0.00007, loss_test:0.07186, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.864, tt:1720.639\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00006, loss_test:0.07229, lr:1.00e-02, fs:0.83249 (r=0.828,p=0.837),  time:31.851, tt:1751.789\n",
      "Ep:55, loss:0.00006, loss_test:0.07413, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:31.826, tt:1782.229\n",
      "Ep:56, loss:0.00006, loss_test:0.06889, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:31.814, tt:1813.422\n",
      "Ep:57, loss:0.00006, loss_test:0.07024, lr:1.00e-02, fs:0.83505 (r=0.818,p=0.853),  time:31.803, tt:1844.581\n",
      "Ep:58, loss:0.00005, loss_test:0.06943, lr:1.00e-02, fs:0.80899 (r=0.727,p=0.911),  time:31.804, tt:1876.414\n",
      "Ep:59, loss:0.00005, loss_test:0.07086, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:31.805, tt:1908.323\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.06719, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:31.820, tt:1941.047\n",
      "Ep:61, loss:0.00005, loss_test:0.07003, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:31.806, tt:1971.986\n",
      "Ep:62, loss:0.00004, loss_test:0.06415, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:31.803, tt:2003.558\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00004, loss_test:0.07058, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:31.794, tt:2034.798\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00004, loss_test:0.06433, lr:1.00e-02, fs:0.84946 (r=0.798,p=0.908),  time:31.762, tt:2064.558\n",
      "Ep:65, loss:0.00004, loss_test:0.06705, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:31.778, tt:2097.365\n",
      "Ep:66, loss:0.00004, loss_test:0.06344, lr:1.00e-02, fs:0.85870 (r=0.798,p=0.929),  time:31.762, tt:2128.044\n",
      "Ep:67, loss:0.00004, loss_test:0.06483, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:31.767, tt:2160.163\n",
      "Ep:68, loss:0.00004, loss_test:0.06372, lr:1.00e-02, fs:0.85714 (r=0.788,p=0.940),  time:31.752, tt:2190.885\n",
      "Ep:69, loss:0.00004, loss_test:0.06481, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:31.741, tt:2221.876\n",
      "Ep:70, loss:0.00004, loss_test:0.06260, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:31.709, tt:2251.355\n",
      "Ep:71, loss:0.00003, loss_test:0.06305, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.706, tt:2282.862\n",
      "Ep:72, loss:0.00003, loss_test:0.06247, lr:1.00e-02, fs:0.86486 (r=0.808,p=0.930),  time:31.708, tt:2314.654\n",
      "Ep:73, loss:0.00003, loss_test:0.06271, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:31.700, tt:2345.817\n",
      "Ep:74, loss:0.00003, loss_test:0.06170, lr:1.00e-02, fs:0.85405 (r=0.798,p=0.919),  time:31.708, tt:2378.112\n",
      "Ep:75, loss:0.00003, loss_test:0.06157, lr:9.90e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.705, tt:2409.615\n",
      "Ep:76, loss:0.00003, loss_test:0.06019, lr:9.80e-03, fs:0.84946 (r=0.798,p=0.908),  time:31.664, tt:2438.110\n",
      "Ep:77, loss:0.00003, loss_test:0.06344, lr:9.70e-03, fs:0.86022 (r=0.808,p=0.920),  time:31.651, tt:2468.764\n",
      "Ep:78, loss:0.00003, loss_test:0.05955, lr:9.61e-03, fs:0.84783 (r=0.788,p=0.918),  time:31.637, tt:2499.320\n",
      "Ep:79, loss:0.00003, loss_test:0.06305, lr:9.51e-03, fs:0.86486 (r=0.808,p=0.930),  time:31.652, tt:2532.151\n",
      "Ep:80, loss:0.00003, loss_test:0.05961, lr:9.41e-03, fs:0.85405 (r=0.798,p=0.919),  time:31.675, tt:2565.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:81, loss:0.00003, loss_test:0.06433, lr:9.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.674, tt:2597.287\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00003, loss_test:0.05901, lr:9.32e-03, fs:0.87432 (r=0.808,p=0.952),  time:31.661, tt:2627.842\n",
      "Ep:83, loss:0.00003, loss_test:0.06353, lr:9.32e-03, fs:0.86957 (r=0.808,p=0.941),  time:31.655, tt:2659.058\n",
      "Ep:84, loss:0.00003, loss_test:0.05839, lr:9.32e-03, fs:0.85561 (r=0.808,p=0.909),  time:31.651, tt:2690.358\n",
      "Ep:85, loss:0.00002, loss_test:0.06288, lr:9.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:31.626, tt:2719.866\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.05774, lr:9.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.641, tt:2752.760\n",
      "Ep:87, loss:0.00002, loss_test:0.06111, lr:9.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:31.645, tt:2784.770\n",
      "Ep:88, loss:0.00002, loss_test:0.05709, lr:9.32e-03, fs:0.85870 (r=0.798,p=0.929),  time:31.648, tt:2816.698\n",
      "Ep:89, loss:0.00002, loss_test:0.06119, lr:9.32e-03, fs:0.87912 (r=0.808,p=0.964),  time:31.631, tt:2846.789\n",
      "Ep:90, loss:0.00002, loss_test:0.05830, lr:9.32e-03, fs:0.86339 (r=0.798,p=0.940),  time:31.635, tt:2878.777\n",
      "Ep:91, loss:0.00002, loss_test:0.06193, lr:9.32e-03, fs:0.88398 (r=0.808,p=0.976),  time:31.637, tt:2910.604\n",
      "Ep:92, loss:0.00002, loss_test:0.05868, lr:9.32e-03, fs:0.84615 (r=0.778,p=0.928),  time:31.619, tt:2940.544\n",
      "Ep:93, loss:0.00002, loss_test:0.05991, lr:9.32e-03, fs:0.87640 (r=0.788,p=0.987),  time:31.606, tt:2970.967\n",
      "Ep:94, loss:0.00002, loss_test:0.05860, lr:9.32e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.610, tt:3002.971\n",
      "Ep:95, loss:0.00002, loss_test:0.05756, lr:9.32e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.599, tt:3033.501\n",
      "Ep:96, loss:0.00002, loss_test:0.05741, lr:9.32e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.599, tt:3065.087\n",
      "Ep:97, loss:0.00002, loss_test:0.05718, lr:9.23e-03, fs:0.87912 (r=0.808,p=0.964),  time:31.590, tt:3095.827\n",
      "Ep:98, loss:0.00002, loss_test:0.05783, lr:9.14e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.607, tt:3129.076\n",
      "Ep:99, loss:0.00002, loss_test:0.05674, lr:9.04e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.618, tt:3161.797\n",
      "Ep:100, loss:0.00002, loss_test:0.05879, lr:8.95e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.617, tt:3193.313\n",
      "Ep:101, loss:0.00002, loss_test:0.05789, lr:8.86e-03, fs:0.86188 (r=0.788,p=0.951),  time:31.624, tt:3225.613\n",
      "Ep:102, loss:0.00002, loss_test:0.05721, lr:8.78e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.610, tt:3255.817\n",
      "Ep:103, loss:0.00002, loss_test:0.05993, lr:8.69e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.608, tt:3287.282\n",
      "Ep:104, loss:0.00002, loss_test:0.05552, lr:8.60e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.604, tt:3318.430\n",
      "Ep:105, loss:0.00002, loss_test:0.06125, lr:8.51e-03, fs:0.88268 (r=0.798,p=0.988),  time:31.593, tt:3348.825\n",
      "Ep:106, loss:0.00002, loss_test:0.05758, lr:8.43e-03, fs:0.85083 (r=0.778,p=0.939),  time:31.584, tt:3379.474\n",
      "Ep:107, loss:0.00002, loss_test:0.05860, lr:8.35e-03, fs:0.89617 (r=0.828,p=0.976),  time:31.575, tt:3410.076\n",
      "##########Best model found so far##########\n",
      "Ep:108, loss:0.00002, loss_test:0.05846, lr:8.35e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.587, tt:3443.021\n",
      "Ep:109, loss:0.00002, loss_test:0.05816, lr:8.35e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.577, tt:3473.461\n",
      "Ep:110, loss:0.00002, loss_test:0.05598, lr:8.35e-03, fs:0.83429 (r=0.737,p=0.961),  time:31.563, tt:3503.509\n",
      "Ep:111, loss:0.00002, loss_test:0.06093, lr:8.35e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.555, tt:3534.199\n",
      "Ep:112, loss:0.00002, loss_test:0.05589, lr:8.35e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.538, tt:3563.830\n",
      "Ep:113, loss:0.00001, loss_test:0.05764, lr:8.35e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.525, tt:3593.805\n",
      "Ep:114, loss:0.00001, loss_test:0.05694, lr:8.35e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.516, tt:3624.394\n",
      "Ep:115, loss:0.00001, loss_test:0.05744, lr:8.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:31.508, tt:3654.913\n",
      "Ep:116, loss:0.00001, loss_test:0.05684, lr:8.35e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.492, tt:3684.522\n",
      "Ep:117, loss:0.00001, loss_test:0.05730, lr:8.35e-03, fs:0.85227 (r=0.758,p=0.974),  time:31.484, tt:3715.129\n",
      "Ep:118, loss:0.00001, loss_test:0.05678, lr:8.35e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.479, tt:3746.031\n",
      "Ep:119, loss:0.00001, loss_test:0.05634, lr:8.26e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.487, tt:3778.410\n",
      "Ep:120, loss:0.00001, loss_test:0.05926, lr:8.18e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.477, tt:3808.757\n",
      "Ep:121, loss:0.00001, loss_test:0.05612, lr:8.10e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.471, tt:3839.445\n",
      "Ep:122, loss:0.00001, loss_test:0.05922, lr:8.02e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.464, tt:3870.055\n",
      "Ep:123, loss:0.00001, loss_test:0.05781, lr:7.94e-03, fs:0.81818 (r=0.727,p=0.935),  time:31.456, tt:3900.602\n",
      "Ep:124, loss:0.00001, loss_test:0.05671, lr:7.86e-03, fs:0.88525 (r=0.818,p=0.964),  time:31.443, tt:3930.344\n",
      "Ep:125, loss:0.00001, loss_test:0.05955, lr:7.78e-03, fs:0.84091 (r=0.747,p=0.961),  time:31.443, tt:3961.796\n",
      "Ep:126, loss:0.00001, loss_test:0.05600, lr:7.70e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.452, tt:3994.438\n",
      "Ep:127, loss:0.00001, loss_test:0.05826, lr:7.62e-03, fs:0.85556 (r=0.778,p=0.951),  time:31.460, tt:4026.893\n",
      "Ep:128, loss:0.00001, loss_test:0.05592, lr:7.55e-03, fs:0.86813 (r=0.798,p=0.952),  time:31.461, tt:4058.478\n",
      "Ep:129, loss:0.00001, loss_test:0.05636, lr:7.47e-03, fs:0.86667 (r=0.788,p=0.963),  time:31.471, tt:4091.171\n",
      "Ep:130, loss:0.00001, loss_test:0.05678, lr:7.40e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.477, tt:4123.476\n",
      "Ep:131, loss:0.00001, loss_test:0.05589, lr:7.32e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.476, tt:4154.855\n",
      "Ep:132, loss:0.00001, loss_test:0.05821, lr:7.25e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.481, tt:4187.018\n",
      "Ep:133, loss:0.00001, loss_test:0.05577, lr:7.18e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.493, tt:4220.037\n",
      "Ep:134, loss:0.00001, loss_test:0.05732, lr:7.11e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.500, tt:4252.536\n",
      "Ep:135, loss:0.00001, loss_test:0.05750, lr:7.03e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.507, tt:4284.966\n",
      "Ep:136, loss:0.00001, loss_test:0.05609, lr:6.96e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.505, tt:4316.188\n",
      "Ep:137, loss:0.00001, loss_test:0.05753, lr:6.89e-03, fs:0.87151 (r=0.788,p=0.975),  time:31.508, tt:4348.084\n",
      "Ep:138, loss:0.00001, loss_test:0.05678, lr:6.83e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.511, tt:4380.007\n",
      "Ep:139, loss:0.00001, loss_test:0.05738, lr:6.76e-03, fs:0.86517 (r=0.778,p=0.975),  time:31.519, tt:4412.597\n",
      "Ep:140, loss:0.00001, loss_test:0.05723, lr:6.69e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.521, tt:4444.485\n",
      "Ep:141, loss:0.00001, loss_test:0.05645, lr:6.62e-03, fs:0.83908 (r=0.737,p=0.973),  time:31.511, tt:4474.553\n",
      "Ep:142, loss:0.00001, loss_test:0.05838, lr:6.56e-03, fs:0.89011 (r=0.818,p=0.976),  time:31.508, tt:4505.707\n",
      "Ep:143, loss:0.00001, loss_test:0.05710, lr:6.49e-03, fs:0.83799 (r=0.758,p=0.938),  time:31.490, tt:4534.539\n",
      "Ep:144, loss:0.00001, loss_test:0.05668, lr:6.43e-03, fs:0.87778 (r=0.798,p=0.975),  time:31.491, tt:4566.243\n",
      "Ep:145, loss:0.00001, loss_test:0.05910, lr:6.36e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.499, tt:4598.848\n",
      "Ep:146, loss:0.00001, loss_test:0.05609, lr:6.30e-03, fs:0.84746 (r=0.758,p=0.962),  time:31.500, tt:4630.461\n",
      "Ep:147, loss:0.00001, loss_test:0.05768, lr:6.24e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.503, tt:4662.404\n",
      "Ep:148, loss:0.00001, loss_test:0.05805, lr:6.17e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.506, tt:4694.319\n",
      "Ep:149, loss:0.00001, loss_test:0.05559, lr:6.11e-03, fs:0.87293 (r=0.798,p=0.963),  time:31.501, tt:4725.170\n",
      "Ep:150, loss:0.00001, loss_test:0.05787, lr:6.05e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.501, tt:4756.653\n",
      "Ep:151, loss:0.00001, loss_test:0.05757, lr:5.99e-03, fs:0.84091 (r=0.747,p=0.961),  time:31.506, tt:4788.962\n",
      "Ep:152, loss:0.00001, loss_test:0.05572, lr:5.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:31.522, tt:4822.805\n",
      "Ep:153, loss:0.00001, loss_test:0.05734, lr:5.87e-03, fs:0.83146 (r=0.747,p=0.937),  time:31.517, tt:4853.641\n",
      "Ep:154, loss:0.00001, loss_test:0.05653, lr:5.81e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.523, tt:4886.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00001, loss_test:0.05660, lr:5.75e-03, fs:0.84270 (r=0.758,p=0.949),  time:31.524, tt:4917.693\n",
      "Ep:156, loss:0.00001, loss_test:0.05727, lr:5.70e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:4949.042\n",
      "Ep:157, loss:0.00001, loss_test:0.05638, lr:5.64e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.527, tt:4981.238\n",
      "Ep:158, loss:0.00001, loss_test:0.05690, lr:5.58e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.526, tt:5012.584\n",
      "Ep:159, loss:0.00001, loss_test:0.05692, lr:5.53e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.528, tt:5044.459\n",
      "Ep:160, loss:0.00001, loss_test:0.05632, lr:5.47e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.528, tt:5075.942\n",
      "Ep:161, loss:0.00001, loss_test:0.05709, lr:5.42e-03, fs:0.84571 (r=0.747,p=0.974),  time:31.520, tt:5106.265\n",
      "Ep:162, loss:0.00001, loss_test:0.05655, lr:5.36e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.526, tt:5138.776\n",
      "Ep:163, loss:0.00001, loss_test:0.05644, lr:5.31e-03, fs:0.85876 (r=0.768,p=0.974),  time:31.515, tt:5168.409\n",
      "Ep:164, loss:0.00001, loss_test:0.05707, lr:5.26e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.519, tt:5200.568\n",
      "Ep:165, loss:0.00001, loss_test:0.05668, lr:5.20e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:5232.843\n",
      "Ep:166, loss:0.00001, loss_test:0.05707, lr:5.15e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.521, tt:5264.043\n",
      "Ep:167, loss:0.00001, loss_test:0.05740, lr:5.10e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.525, tt:5296.186\n",
      "Ep:168, loss:0.00001, loss_test:0.05654, lr:5.05e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:5327.437\n",
      "Ep:169, loss:0.00001, loss_test:0.05685, lr:5.00e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:5358.829\n",
      "Ep:170, loss:0.00001, loss_test:0.05704, lr:4.95e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.521, tt:5390.011\n",
      "Ep:171, loss:0.00001, loss_test:0.05635, lr:4.90e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:5421.892\n",
      "Ep:172, loss:0.00001, loss_test:0.05692, lr:4.85e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.522, tt:5453.339\n",
      "Ep:173, loss:0.00001, loss_test:0.05652, lr:4.80e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.520, tt:5484.472\n",
      "Ep:174, loss:0.00001, loss_test:0.05650, lr:4.75e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.523, tt:5516.583\n",
      "Ep:175, loss:0.00001, loss_test:0.05689, lr:4.71e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.522, tt:5547.959\n",
      "Ep:176, loss:0.00001, loss_test:0.05657, lr:4.66e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.513, tt:5577.771\n",
      "Ep:177, loss:0.00001, loss_test:0.05685, lr:4.61e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.520, tt:5610.614\n",
      "Ep:178, loss:0.00001, loss_test:0.05622, lr:4.57e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.516, tt:5641.347\n",
      "Ep:179, loss:0.00001, loss_test:0.05736, lr:4.52e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.515, tt:5672.758\n",
      "Ep:180, loss:0.00001, loss_test:0.05735, lr:4.48e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.517, tt:5704.630\n",
      "Ep:181, loss:0.00001, loss_test:0.05623, lr:4.43e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.515, tt:5735.821\n",
      "Ep:182, loss:0.00001, loss_test:0.05770, lr:4.39e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.514, tt:5767.012\n",
      "Ep:183, loss:0.00001, loss_test:0.05692, lr:4.34e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.503, tt:5796.496\n",
      "Ep:184, loss:0.00001, loss_test:0.05636, lr:4.30e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.497, tt:5826.975\n",
      "Ep:185, loss:0.00001, loss_test:0.05763, lr:4.26e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.486, tt:5856.356\n",
      "Ep:186, loss:0.00001, loss_test:0.05706, lr:4.21e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.475, tt:5885.896\n",
      "Ep:187, loss:0.00001, loss_test:0.05608, lr:4.17e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.457, tt:5913.923\n",
      "Ep:188, loss:0.00001, loss_test:0.05758, lr:4.13e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.437, tt:5941.611\n",
      "Ep:189, loss:0.00001, loss_test:0.05689, lr:4.09e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.425, tt:5970.814\n",
      "Ep:190, loss:0.00001, loss_test:0.05631, lr:4.05e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.409, tt:5999.154\n",
      "Ep:191, loss:0.00001, loss_test:0.05703, lr:4.01e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.376, tt:6024.175\n",
      "Ep:192, loss:0.00001, loss_test:0.05707, lr:3.97e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.330, tt:6046.657\n",
      "Ep:193, loss:0.00001, loss_test:0.05651, lr:3.93e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.286, tt:6069.397\n",
      "Ep:194, loss:0.00001, loss_test:0.05672, lr:3.89e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.266, tt:6096.804\n",
      "Ep:195, loss:0.00001, loss_test:0.05666, lr:3.85e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.251, tt:6125.114\n",
      "Ep:196, loss:0.00001, loss_test:0.05687, lr:3.81e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.241, tt:6154.572\n",
      "Ep:197, loss:0.00001, loss_test:0.05687, lr:3.77e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.241, tt:6185.815\n",
      "Ep:198, loss:0.00001, loss_test:0.05690, lr:3.73e-03, fs:0.82955 (r=0.737,p=0.948),  time:31.235, tt:6215.789\n",
      "Ep:199, loss:0.00001, loss_test:0.05655, lr:3.70e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.230, tt:6245.966\n",
      "Ep:200, loss:0.00001, loss_test:0.05664, lr:3.66e-03, fs:0.83616 (r=0.747,p=0.949),  time:31.212, tt:6273.571\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_300_300_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00009, loss_test:0.01906, lr:6.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:29.399, tt:29.399\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02403, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.942, tt:65.884\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02733, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.083, tt:105.249\n",
      "Ep:3, loss:0.00005, loss_test:0.02841, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.304, tt:145.216\n",
      "Ep:4, loss:0.00005, loss_test:0.02832, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.978, tt:184.889\n",
      "Ep:5, loss:0.00005, loss_test:0.02736, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.241, tt:223.445\n",
      "Ep:6, loss:0.00005, loss_test:0.02579, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.638, tt:263.464\n",
      "Ep:7, loss:0.00005, loss_test:0.02375, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.028, tt:304.224\n",
      "Ep:8, loss:0.00004, loss_test:0.02168, lr:6.00e-02, fs:0.65763 (r=0.980,p=0.495),  time:38.330, tt:344.967\n",
      "Ep:9, loss:0.00004, loss_test:0.02009, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:38.417, tt:384.168\n",
      "Ep:10, loss:0.00004, loss_test:0.01934, lr:6.00e-02, fs:0.68726 (r=0.899,p=0.556),  time:38.498, tt:423.475\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01898, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:38.641, tt:463.690\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01836, lr:6.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:38.870, tt:505.311\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01786, lr:6.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:39.066, tt:546.930\n",
      "Ep:14, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:39.074, tt:586.108\n",
      "Ep:15, loss:0.00003, loss_test:0.01741, lr:6.00e-02, fs:0.68592 (r=0.960,p=0.534),  time:39.151, tt:626.412\n",
      "Ep:16, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.70632 (r=0.960,p=0.559),  time:39.294, tt:667.998\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.72093 (r=0.939,p=0.585),  time:39.195, tt:705.510\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01629, lr:6.00e-02, fs:0.74194 (r=0.929,p=0.617),  time:39.307, tt:746.839\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01612, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:39.384, tt:787.689\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:39.437, tt:828.171\n",
      "Ep:21, loss:0.00003, loss_test:0.01567, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:39.453, tt:867.971\n",
      "Ep:22, loss:0.00003, loss_test:0.01545, lr:6.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:39.462, tt:907.626\n",
      "Ep:23, loss:0.00003, loss_test:0.01524, lr:6.00e-02, fs:0.75099 (r=0.960,p=0.617),  time:39.520, tt:948.487\n",
      "Ep:24, loss:0.00003, loss_test:0.01503, lr:6.00e-02, fs:0.75889 (r=0.970,p=0.623),  time:39.582, tt:989.550\n",
      "Ep:25, loss:0.00002, loss_test:0.01481, lr:6.00e-02, fs:0.76494 (r=0.970,p=0.632),  time:39.607, tt:1029.784\n",
      "Ep:26, loss:0.00002, loss_test:0.01461, lr:6.00e-02, fs:0.79012 (r=0.970,p=0.667),  time:39.726, tt:1072.591\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01445, lr:6.00e-02, fs:0.79339 (r=0.970,p=0.671),  time:39.757, tt:1113.206\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01430, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:39.741, tt:1152.500\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:39.701, tt:1191.034\n",
      "Ep:30, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:39.666, tt:1229.646\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:39.723, tt:1271.135\n",
      "Ep:32, loss:0.00002, loss_test:0.01370, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:39.683, tt:1309.529\n",
      "Ep:33, loss:0.00002, loss_test:0.01358, lr:6.00e-02, fs:0.80508 (r=0.960,p=0.693),  time:39.675, tt:1348.956\n",
      "Ep:34, loss:0.00002, loss_test:0.01347, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:39.691, tt:1389.195\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:39.739, tt:1430.590\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01327, lr:6.00e-02, fs:0.81702 (r=0.970,p=0.706),  time:39.762, tt:1471.182\n",
      "Ep:37, loss:0.00002, loss_test:0.01316, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:39.787, tt:1511.892\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01305, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:39.800, tt:1552.219\n",
      "Ep:39, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:39.793, tt:1591.729\n",
      "Ep:40, loss:0.00002, loss_test:0.01286, lr:6.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:39.785, tt:1631.186\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01279, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:39.817, tt:1672.323\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01271, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:39.867, tt:1714.293\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01263, lr:6.00e-02, fs:0.83843 (r=0.970,p=0.738),  time:39.888, tt:1755.057\n",
      "Ep:44, loss:0.00001, loss_test:0.01257, lr:6.00e-02, fs:0.83700 (r=0.960,p=0.742),  time:39.888, tt:1794.976\n",
      "Ep:45, loss:0.00001, loss_test:0.01250, lr:6.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:39.926, tt:1836.574\n",
      "Ep:46, loss:0.00001, loss_test:0.01243, lr:6.00e-02, fs:0.83408 (r=0.939,p=0.750),  time:39.934, tt:1876.884\n",
      "Ep:47, loss:0.00001, loss_test:0.01237, lr:6.00e-02, fs:0.83636 (r=0.929,p=0.760),  time:39.940, tt:1917.115\n",
      "Ep:48, loss:0.00001, loss_test:0.01232, lr:6.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:39.965, tt:1958.285\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01227, lr:6.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:39.997, tt:1999.869\n",
      "Ep:50, loss:0.00001, loss_test:0.01223, lr:6.00e-02, fs:0.84259 (r=0.919,p=0.778),  time:40.023, tt:2041.168\n",
      "Ep:51, loss:0.00001, loss_test:0.01220, lr:6.00e-02, fs:0.83568 (r=0.899,p=0.781),  time:40.027, tt:2081.422\n",
      "Ep:52, loss:0.00001, loss_test:0.01217, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:40.143, tt:2127.589\n",
      "Ep:53, loss:0.00001, loss_test:0.01215, lr:6.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:40.146, tt:2167.903\n",
      "Ep:54, loss:0.00001, loss_test:0.01213, lr:6.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:40.159, tt:2208.770\n",
      "Ep:55, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:40.189, tt:2250.593\n",
      "Ep:56, loss:0.00001, loss_test:0.01210, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:40.132, tt:2287.526\n",
      "Ep:57, loss:0.00001, loss_test:0.01209, lr:6.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:40.146, tt:2328.493\n",
      "Ep:58, loss:0.00001, loss_test:0.01208, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:40.147, tt:2368.672\n",
      "Ep:59, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.83092 (r=0.869,p=0.796),  time:40.143, tt:2408.604\n",
      "Ep:60, loss:0.00001, loss_test:0.01203, lr:5.94e-02, fs:0.83495 (r=0.869,p=0.804),  time:40.137, tt:2448.380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01202, lr:5.88e-02, fs:0.82927 (r=0.859,p=0.802),  time:40.139, tt:2488.594\n",
      "Ep:62, loss:0.00001, loss_test:0.01203, lr:5.82e-02, fs:0.82927 (r=0.859,p=0.802),  time:40.125, tt:2527.846\n",
      "Ep:63, loss:0.00001, loss_test:0.01202, lr:5.76e-02, fs:0.82927 (r=0.859,p=0.802),  time:40.135, tt:2568.609\n",
      "Ep:64, loss:0.00001, loss_test:0.01202, lr:5.71e-02, fs:0.83333 (r=0.859,p=0.810),  time:40.128, tt:2608.333\n",
      "Ep:65, loss:0.00001, loss_test:0.01202, lr:5.65e-02, fs:0.83333 (r=0.859,p=0.810),  time:40.132, tt:2648.690\n",
      "Ep:66, loss:0.00001, loss_test:0.01203, lr:5.59e-02, fs:0.83744 (r=0.859,p=0.817),  time:40.099, tt:2686.605\n",
      "Ep:67, loss:0.00001, loss_test:0.01207, lr:5.54e-02, fs:0.83744 (r=0.859,p=0.817),  time:40.100, tt:2726.804\n",
      "Ep:68, loss:0.00001, loss_test:0.01210, lr:5.48e-02, fs:0.83744 (r=0.859,p=0.817),  time:40.095, tt:2766.580\n",
      "Ep:69, loss:0.00001, loss_test:0.01210, lr:5.43e-02, fs:0.83744 (r=0.859,p=0.817),  time:40.172, tt:2812.063\n",
      "Ep:70, loss:0.00001, loss_test:0.01212, lr:5.37e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.145, tt:2850.331\n",
      "Ep:71, loss:0.00001, loss_test:0.01214, lr:5.32e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.116, tt:2888.322\n",
      "Ep:72, loss:0.00001, loss_test:0.01216, lr:5.27e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.092, tt:2926.699\n",
      "Ep:73, loss:0.00001, loss_test:0.01218, lr:5.21e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.098, tt:2967.230\n",
      "Ep:74, loss:0.00001, loss_test:0.01220, lr:5.16e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.105, tt:3007.843\n",
      "Ep:75, loss:0.00001, loss_test:0.01221, lr:5.11e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.123, tt:3049.383\n",
      "Ep:76, loss:0.00001, loss_test:0.01224, lr:5.06e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.115, tt:3088.855\n",
      "Ep:77, loss:0.00001, loss_test:0.01228, lr:5.01e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.150, tt:3131.709\n",
      "Ep:78, loss:0.00001, loss_test:0.01230, lr:4.96e-02, fs:0.84158 (r=0.859,p=0.825),  time:40.128, tt:3170.104\n",
      "Ep:79, loss:0.00001, loss_test:0.01231, lr:4.91e-02, fs:0.84577 (r=0.859,p=0.833),  time:40.106, tt:3208.484\n",
      "Ep:80, loss:0.00001, loss_test:0.01234, lr:4.86e-02, fs:0.85000 (r=0.859,p=0.842),  time:40.098, tt:3247.960\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01237, lr:4.86e-02, fs:0.85000 (r=0.859,p=0.842),  time:40.085, tt:3287.001\n",
      "Ep:82, loss:0.00001, loss_test:0.01241, lr:4.86e-02, fs:0.85859 (r=0.859,p=0.859),  time:40.098, tt:3328.112\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01243, lr:4.86e-02, fs:0.85859 (r=0.859,p=0.859),  time:40.089, tt:3367.469\n",
      "Ep:84, loss:0.00001, loss_test:0.01246, lr:4.86e-02, fs:0.86294 (r=0.859,p=0.867),  time:40.095, tt:3408.111\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.01251, lr:4.86e-02, fs:0.86735 (r=0.859,p=0.876),  time:40.095, tt:3448.164\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01254, lr:4.86e-02, fs:0.86735 (r=0.859,p=0.876),  time:40.114, tt:3489.904\n",
      "Ep:87, loss:0.00001, loss_test:0.01257, lr:4.86e-02, fs:0.86735 (r=0.859,p=0.876),  time:40.103, tt:3529.043\n",
      "Ep:88, loss:0.00001, loss_test:0.01259, lr:4.86e-02, fs:0.86735 (r=0.859,p=0.876),  time:40.142, tt:3572.636\n",
      "Ep:89, loss:0.00001, loss_test:0.01261, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.163, tt:3614.713\n",
      "Ep:90, loss:0.00001, loss_test:0.01263, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.183, tt:3656.655\n",
      "Ep:91, loss:0.00001, loss_test:0.01267, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.196, tt:3698.025\n",
      "Ep:92, loss:0.00001, loss_test:0.01270, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.200, tt:3738.564\n",
      "Ep:93, loss:0.00001, loss_test:0.01274, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.215, tt:3780.204\n",
      "Ep:94, loss:0.00001, loss_test:0.01276, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.244, tt:3823.200\n",
      "Ep:95, loss:0.00001, loss_test:0.01281, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.264, tt:3865.326\n",
      "Ep:96, loss:0.00001, loss_test:0.01283, lr:4.86e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.268, tt:3905.957\n",
      "Ep:97, loss:0.00001, loss_test:0.01287, lr:4.81e-02, fs:0.86598 (r=0.848,p=0.884),  time:40.263, tt:3945.784\n",
      "Ep:98, loss:0.00001, loss_test:0.01291, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.268, tt:3986.491\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01296, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.273, tt:4027.320\n",
      "Ep:100, loss:0.00000, loss_test:0.01300, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.283, tt:4068.563\n",
      "Ep:101, loss:0.00000, loss_test:0.01304, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.283, tt:4108.858\n",
      "Ep:102, loss:0.00000, loss_test:0.01306, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.291, tt:4150.001\n",
      "Ep:103, loss:0.00000, loss_test:0.01308, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:40.292, tt:4190.332\n",
      "Ep:104, loss:0.00000, loss_test:0.01311, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.288, tt:4230.242\n",
      "##########Best model found so far##########\n",
      "Ep:105, loss:0.00000, loss_test:0.01315, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.285, tt:4270.254\n",
      "Ep:106, loss:0.00000, loss_test:0.01320, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.272, tt:4309.056\n",
      "Ep:107, loss:0.00000, loss_test:0.01323, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.265, tt:4348.630\n",
      "Ep:108, loss:0.00000, loss_test:0.01327, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.267, tt:4389.141\n",
      "Ep:109, loss:0.00000, loss_test:0.01331, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.257, tt:4428.280\n",
      "Ep:110, loss:0.00000, loss_test:0.01334, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.257, tt:4468.539\n",
      "Ep:111, loss:0.00000, loss_test:0.01340, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.278, tt:4511.128\n",
      "Ep:112, loss:0.00000, loss_test:0.01344, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.265, tt:4549.982\n",
      "Ep:113, loss:0.00000, loss_test:0.01346, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.266, tt:4590.295\n",
      "Ep:114, loss:0.00000, loss_test:0.01350, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.283, tt:4632.510\n",
      "Ep:115, loss:0.00000, loss_test:0.01354, lr:4.76e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.300, tt:4674.786\n",
      "Ep:116, loss:0.00000, loss_test:0.01359, lr:4.71e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.328, tt:4718.329\n",
      "Ep:117, loss:0.00000, loss_test:0.01363, lr:4.67e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.353, tt:4761.643\n",
      "Ep:118, loss:0.00000, loss_test:0.01366, lr:4.62e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.368, tt:4803.846\n",
      "Ep:119, loss:0.00000, loss_test:0.01370, lr:4.57e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.396, tt:4847.573\n",
      "Ep:120, loss:0.00000, loss_test:0.01372, lr:4.53e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.420, tt:4890.773\n",
      "Ep:121, loss:0.00000, loss_test:0.01376, lr:4.48e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.420, tt:4931.248\n",
      "Ep:122, loss:0.00000, loss_test:0.01380, lr:4.44e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.427, tt:4972.573\n",
      "Ep:123, loss:0.00000, loss_test:0.01384, lr:4.39e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.436, tt:5014.047\n",
      "Ep:124, loss:0.00000, loss_test:0.01385, lr:4.35e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.440, tt:5054.957\n",
      "Ep:125, loss:0.00000, loss_test:0.01387, lr:4.31e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.436, tt:5094.900\n",
      "Ep:126, loss:0.00000, loss_test:0.01391, lr:4.26e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.427, tt:5134.240\n",
      "Ep:127, loss:0.00000, loss_test:0.01396, lr:4.22e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.454, tt:5178.058\n",
      "Ep:128, loss:0.00000, loss_test:0.01400, lr:4.18e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.416, tt:5213.705\n",
      "Ep:129, loss:0.00000, loss_test:0.01403, lr:4.14e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.412, tt:5253.558\n",
      "Ep:130, loss:0.00000, loss_test:0.01405, lr:4.10e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.429, tt:5296.185\n",
      "Ep:131, loss:0.00000, loss_test:0.01408, lr:4.05e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.429, tt:5336.693\n",
      "Ep:132, loss:0.00000, loss_test:0.01411, lr:4.01e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.427, tt:5376.759\n",
      "Ep:133, loss:0.00000, loss_test:0.01414, lr:3.97e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.436, tt:5418.467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00000, loss_test:0.01416, lr:3.93e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.441, tt:5459.518\n",
      "Ep:135, loss:0.00000, loss_test:0.01420, lr:3.89e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.446, tt:5500.693\n",
      "Ep:136, loss:0.00000, loss_test:0.01422, lr:3.86e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.464, tt:5543.629\n",
      "Ep:137, loss:0.00000, loss_test:0.01425, lr:3.82e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.469, tt:5584.680\n",
      "Ep:138, loss:0.00000, loss_test:0.01427, lr:3.78e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.480, tt:5626.661\n",
      "Ep:139, loss:0.00000, loss_test:0.01432, lr:3.74e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.475, tt:5666.569\n",
      "Ep:140, loss:0.00000, loss_test:0.01436, lr:3.70e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.467, tt:5705.900\n",
      "Ep:141, loss:0.00000, loss_test:0.01437, lr:3.67e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.464, tt:5745.952\n",
      "Ep:142, loss:0.00000, loss_test:0.01439, lr:3.63e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.465, tt:5786.531\n",
      "Ep:143, loss:0.00000, loss_test:0.01441, lr:3.59e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.469, tt:5827.483\n",
      "Ep:144, loss:0.00000, loss_test:0.01443, lr:3.56e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.481, tt:5869.779\n",
      "Ep:145, loss:0.00000, loss_test:0.01446, lr:3.52e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.487, tt:5911.163\n",
      "Ep:146, loss:0.00000, loss_test:0.01448, lr:3.49e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.487, tt:5951.614\n",
      "Ep:147, loss:0.00000, loss_test:0.01450, lr:3.45e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.491, tt:5992.671\n",
      "Ep:148, loss:0.00000, loss_test:0.01453, lr:3.42e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.478, tt:6031.197\n",
      "Ep:149, loss:0.00000, loss_test:0.01454, lr:3.38e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.485, tt:6072.679\n",
      "Ep:150, loss:0.00000, loss_test:0.01456, lr:3.35e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.486, tt:6113.453\n",
      "Ep:151, loss:0.00000, loss_test:0.01459, lr:3.32e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.484, tt:6153.497\n",
      "Ep:152, loss:0.00000, loss_test:0.01462, lr:3.28e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.474, tt:6192.567\n",
      "Ep:153, loss:0.00000, loss_test:0.01465, lr:3.25e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.460, tt:6230.874\n",
      "Ep:154, loss:0.00000, loss_test:0.01467, lr:3.22e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.467, tt:6272.448\n",
      "Ep:155, loss:0.00000, loss_test:0.01468, lr:3.19e-02, fs:0.87500 (r=0.848,p=0.903),  time:40.469, tt:6313.220\n",
      "Ep:156, loss:0.00000, loss_test:0.01470, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.480, tt:6355.368\n",
      "##########Best model found so far##########\n",
      "Ep:157, loss:0.00000, loss_test:0.01473, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.476, tt:6395.139\n",
      "Ep:158, loss:0.00000, loss_test:0.01474, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.462, tt:6433.412\n",
      "Ep:159, loss:0.00000, loss_test:0.01476, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.460, tt:6473.581\n",
      "Ep:160, loss:0.00000, loss_test:0.01479, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.452, tt:6512.810\n",
      "Ep:161, loss:0.00000, loss_test:0.01481, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.432, tt:6550.042\n",
      "Ep:162, loss:0.00000, loss_test:0.01484, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.427, tt:6589.538\n",
      "Ep:163, loss:0.00000, loss_test:0.01485, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.433, tt:6631.089\n",
      "Ep:164, loss:0.00000, loss_test:0.01487, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.434, tt:6671.642\n",
      "Ep:165, loss:0.00000, loss_test:0.01490, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.425, tt:6710.542\n",
      "Ep:166, loss:0.00000, loss_test:0.01491, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.431, tt:6752.016\n",
      "Ep:167, loss:0.00000, loss_test:0.01492, lr:3.15e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.434, tt:6792.920\n",
      "Ep:168, loss:0.00000, loss_test:0.01494, lr:3.12e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.428, tt:6832.316\n",
      "Ep:169, loss:0.00000, loss_test:0.01496, lr:3.09e-02, fs:0.88421 (r=0.848,p=0.923),  time:40.428, tt:6872.704\n",
      "##########Best model found so far##########\n",
      "Ep:170, loss:0.00000, loss_test:0.01499, lr:3.09e-02, fs:0.87958 (r=0.848,p=0.913),  time:40.419, tt:6911.568\n",
      "Ep:171, loss:0.00000, loss_test:0.01501, lr:3.09e-02, fs:0.88889 (r=0.848,p=0.933),  time:40.415, tt:6951.426\n",
      "##########Best model found so far##########\n",
      "Ep:172, loss:0.00000, loss_test:0.01504, lr:3.09e-02, fs:0.88889 (r=0.848,p=0.933),  time:40.408, tt:6990.539\n",
      "Ep:173, loss:0.00000, loss_test:0.01505, lr:3.09e-02, fs:0.88889 (r=0.848,p=0.933),  time:40.407, tt:7030.762\n",
      "Ep:174, loss:0.00000, loss_test:0.01506, lr:3.09e-02, fs:0.88889 (r=0.848,p=0.933),  time:40.406, tt:7071.094\n",
      "Ep:175, loss:0.00000, loss_test:0.01508, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.400, tt:7110.405\n",
      "Ep:176, loss:0.00000, loss_test:0.01509, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.407, tt:7152.120\n",
      "Ep:177, loss:0.00000, loss_test:0.01512, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.435, tt:7197.386\n",
      "Ep:178, loss:0.00000, loss_test:0.01513, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.438, tt:7238.474\n",
      "Ep:179, loss:0.00000, loss_test:0.01516, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.438, tt:7278.762\n",
      "Ep:180, loss:0.00000, loss_test:0.01518, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.431, tt:7318.080\n",
      "Ep:181, loss:0.00000, loss_test:0.01520, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.426, tt:7357.614\n",
      "Ep:182, loss:0.00000, loss_test:0.01522, lr:3.09e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.429, tt:7398.564\n",
      "Ep:183, loss:0.00000, loss_test:0.01524, lr:3.06e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.436, tt:7440.148\n",
      "Ep:184, loss:0.00000, loss_test:0.01526, lr:3.03e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.437, tt:7480.935\n",
      "Ep:185, loss:0.00000, loss_test:0.01527, lr:3.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.431, tt:7520.198\n",
      "Ep:186, loss:0.00000, loss_test:0.01529, lr:2.97e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.423, tt:7559.089\n",
      "Ep:187, loss:0.00000, loss_test:0.01532, lr:2.94e-02, fs:0.88298 (r=0.838,p=0.933),  time:40.435, tt:7601.732\n",
      "Ep:188, loss:0.00000, loss_test:0.01534, lr:2.91e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.431, tt:7641.412\n",
      "Ep:189, loss:0.00000, loss_test:0.01535, lr:2.88e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.431, tt:7681.884\n",
      "Ep:190, loss:0.00000, loss_test:0.01537, lr:2.85e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.441, tt:7724.209\n",
      "Ep:191, loss:0.00000, loss_test:0.01538, lr:2.82e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.434, tt:7763.393\n",
      "Ep:192, loss:0.00000, loss_test:0.01539, lr:2.80e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.438, tt:7804.576\n",
      "Ep:193, loss:0.00000, loss_test:0.01541, lr:2.77e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.437, tt:7844.815\n",
      "Ep:194, loss:0.00000, loss_test:0.01544, lr:2.74e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.436, tt:7885.062\n",
      "Ep:195, loss:0.00000, loss_test:0.01545, lr:2.71e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.437, tt:7925.576\n",
      "Ep:196, loss:0.00000, loss_test:0.01545, lr:2.69e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.434, tt:7965.456\n",
      "Ep:197, loss:0.00000, loss_test:0.01547, lr:2.66e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.429, tt:8004.959\n",
      "Ep:198, loss:0.00000, loss_test:0.01549, lr:2.63e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.455, tt:8050.603\n",
      "Ep:199, loss:0.00000, loss_test:0.01551, lr:2.61e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.445, tt:8088.933\n",
      "Ep:200, loss:0.00000, loss_test:0.01552, lr:2.58e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.438, tt:8127.957\n",
      "Ep:201, loss:0.00000, loss_test:0.01554, lr:2.55e-02, fs:0.88770 (r=0.838,p=0.943),  time:40.389, tt:8158.496\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN5\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14130, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.931, tt:31.931\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:1, loss:0.00028, loss_test:0.13993, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.711, tt:71.423\n",
      "Ep:2, loss:0.00027, loss_test:0.13750, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:37.794, tt:113.382\n",
      "Ep:3, loss:0.00027, loss_test:0.13383, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:38.266, tt:153.065\n",
      "Ep:4, loss:0.00026, loss_test:0.12798, lr:1.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:39.076, tt:195.380\n",
      "Ep:5, loss:0.00025, loss_test:0.11989, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:39.655, tt:237.931\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11375, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:39.916, tt:279.410\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11080, lr:1.00e-02, fs:0.70192 (r=0.737,p=0.670),  time:40.073, tt:320.583\n",
      "Ep:8, loss:0.00022, loss_test:0.10940, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:40.247, tt:362.221\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10793, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:40.479, tt:404.789\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.10401, lr:1.00e-02, fs:0.74419 (r=0.808,p=0.690),  time:40.499, tt:445.490\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10157, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:40.643, tt:487.711\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09909, lr:1.00e-02, fs:0.74882 (r=0.798,p=0.705),  time:40.838, tt:530.894\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09699, lr:1.00e-02, fs:0.78140 (r=0.848,p=0.724),  time:41.031, tt:574.429\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09499, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:41.112, tt:616.684\n",
      "Ep:15, loss:0.00016, loss_test:0.09334, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:41.165, tt:658.640\n",
      "Ep:16, loss:0.00015, loss_test:0.09128, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:41.247, tt:701.192\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00014, loss_test:0.08964, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:41.319, tt:743.735\n",
      "Ep:18, loss:0.00014, loss_test:0.08860, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:41.389, tt:786.392\n",
      "Ep:19, loss:0.00013, loss_test:0.08680, lr:1.00e-02, fs:0.81517 (r=0.869,p=0.768),  time:41.445, tt:828.907\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00012, loss_test:0.08511, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:41.488, tt:871.245\n",
      "Ep:21, loss:0.00012, loss_test:0.08301, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:41.588, tt:914.940\n",
      "Ep:22, loss:0.00011, loss_test:0.08271, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:41.656, tt:958.092\n",
      "Ep:23, loss:0.00011, loss_test:0.08206, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:41.667, tt:1000.007\n",
      "Ep:24, loss:0.00010, loss_test:0.07968, lr:1.00e-02, fs:0.80788 (r=0.828,p=0.788),  time:41.655, tt:1041.387\n",
      "Ep:25, loss:0.00010, loss_test:0.08011, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:41.643, tt:1082.714\n",
      "Ep:26, loss:0.00009, loss_test:0.07825, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:41.701, tt:1125.917\n",
      "Ep:27, loss:0.00009, loss_test:0.07775, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.786, tt:1170.020\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00008, loss_test:0.07737, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:41.865, tt:1214.071\n",
      "Ep:29, loss:0.00008, loss_test:0.07580, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:41.839, tt:1255.156\n",
      "Ep:30, loss:0.00008, loss_test:0.07601, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:41.802, tt:1295.855\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00007, loss_test:0.07521, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:41.688, tt:1334.023\n",
      "Ep:32, loss:0.00007, loss_test:0.07406, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:41.733, tt:1377.184\n",
      "Ep:33, loss:0.00007, loss_test:0.07515, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.731, tt:1418.860\n",
      "Ep:34, loss:0.00006, loss_test:0.07355, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:41.738, tt:1460.846\n",
      "Ep:35, loss:0.00006, loss_test:0.07413, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.747, tt:1502.875\n",
      "Ep:36, loss:0.00006, loss_test:0.07369, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:41.747, tt:1544.647\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00006, loss_test:0.07313, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:41.732, tt:1585.800\n",
      "Ep:38, loss:0.00005, loss_test:0.07402, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:41.765, tt:1628.848\n",
      "Ep:39, loss:0.00005, loss_test:0.07269, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.781, tt:1671.222\n",
      "Ep:40, loss:0.00005, loss_test:0.07310, lr:1.00e-02, fs:0.83333 (r=0.808,p=0.860),  time:41.753, tt:1711.855\n",
      "Ep:41, loss:0.00005, loss_test:0.07362, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:41.736, tt:1752.905\n",
      "Ep:42, loss:0.00005, loss_test:0.07133, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.752, tt:1795.357\n",
      "Ep:43, loss:0.00004, loss_test:0.07281, lr:1.00e-02, fs:0.82105 (r=0.788,p=0.857),  time:41.791, tt:1838.820\n",
      "Ep:44, loss:0.00004, loss_test:0.07227, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:41.785, tt:1880.304\n",
      "Ep:45, loss:0.00004, loss_test:0.07104, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:41.770, tt:1921.435\n",
      "Ep:46, loss:0.00004, loss_test:0.07310, lr:1.00e-02, fs:0.79348 (r=0.737,p=0.859),  time:41.752, tt:1962.342\n",
      "Ep:47, loss:0.00004, loss_test:0.07121, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:41.730, tt:2003.053\n",
      "Ep:48, loss:0.00004, loss_test:0.07172, lr:9.90e-03, fs:0.84324 (r=0.788,p=0.907),  time:41.719, tt:2044.222\n",
      "Ep:49, loss:0.00003, loss_test:0.07163, lr:9.80e-03, fs:0.82418 (r=0.758,p=0.904),  time:41.694, tt:2084.706\n",
      "Ep:50, loss:0.00003, loss_test:0.07063, lr:9.70e-03, fs:0.84783 (r=0.788,p=0.918),  time:41.672, tt:2125.257\n",
      "Ep:51, loss:0.00003, loss_test:0.07154, lr:9.61e-03, fs:0.81111 (r=0.737,p=0.901),  time:41.668, tt:2166.716\n",
      "Ep:52, loss:0.00003, loss_test:0.07197, lr:9.51e-03, fs:0.80899 (r=0.727,p=0.911),  time:41.645, tt:2207.210\n",
      "Ep:53, loss:0.00003, loss_test:0.07077, lr:9.41e-03, fs:0.82873 (r=0.758,p=0.915),  time:41.650, tt:2249.105\n",
      "Ep:54, loss:0.00003, loss_test:0.07209, lr:9.32e-03, fs:0.80226 (r=0.717,p=0.910),  time:41.685, tt:2292.672\n",
      "Ep:55, loss:0.00003, loss_test:0.07076, lr:9.23e-03, fs:0.82222 (r=0.747,p=0.914),  time:41.701, tt:2335.252\n",
      "Ep:56, loss:0.00003, loss_test:0.07133, lr:9.14e-03, fs:0.79545 (r=0.707,p=0.909),  time:41.715, tt:2377.784\n",
      "Ep:57, loss:0.00003, loss_test:0.07101, lr:9.04e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.709, tt:2419.107\n",
      "Ep:58, loss:0.00002, loss_test:0.06937, lr:8.95e-03, fs:0.83516 (r=0.768,p=0.916),  time:41.718, tt:2461.373\n",
      "Ep:59, loss:0.00002, loss_test:0.07105, lr:8.86e-03, fs:0.80226 (r=0.717,p=0.910),  time:41.713, tt:2502.785\n",
      "Ep:60, loss:0.00002, loss_test:0.07132, lr:8.78e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.731, tt:2545.619\n",
      "Ep:61, loss:0.00002, loss_test:0.06964, lr:8.69e-03, fs:0.80899 (r=0.727,p=0.911),  time:41.750, tt:2588.506\n",
      "Ep:62, loss:0.00002, loss_test:0.07124, lr:8.60e-03, fs:0.78161 (r=0.687,p=0.907),  time:41.720, tt:2628.383\n",
      "Ep:63, loss:0.00002, loss_test:0.07155, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:41.710, tt:2669.433\n",
      "Ep:64, loss:0.00002, loss_test:0.06932, lr:8.43e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.787, tt:2716.175\n",
      "Ep:65, loss:0.00002, loss_test:0.07172, lr:8.35e-03, fs:0.76023 (r=0.657,p=0.903),  time:41.797, tt:2758.608\n",
      "Ep:66, loss:0.00002, loss_test:0.07129, lr:8.26e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.774, tt:2798.836\n",
      "Ep:67, loss:0.00002, loss_test:0.06905, lr:8.18e-03, fs:0.81564 (r=0.737,p=0.912),  time:41.778, tt:2840.917\n",
      "Ep:68, loss:0.00002, loss_test:0.07272, lr:8.10e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.782, tt:2882.940\n",
      "Ep:69, loss:0.00002, loss_test:0.07057, lr:8.02e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.786, tt:2924.989\n",
      "Ep:70, loss:0.00002, loss_test:0.06887, lr:7.94e-03, fs:0.80682 (r=0.717,p=0.922),  time:41.772, tt:2965.784\n",
      "Ep:71, loss:0.00002, loss_test:0.07050, lr:7.86e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.788, tt:3008.730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:72, loss:0.00002, loss_test:0.07016, lr:7.78e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.798, tt:3051.234\n",
      "Ep:73, loss:0.00002, loss_test:0.06959, lr:7.70e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.771, tt:3091.071\n",
      "Ep:74, loss:0.00002, loss_test:0.06959, lr:7.62e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.757, tt:3131.806\n",
      "Ep:75, loss:0.00002, loss_test:0.06996, lr:7.55e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.756, tt:3173.435\n",
      "Ep:76, loss:0.00002, loss_test:0.06905, lr:7.47e-03, fs:0.75740 (r=0.646,p=0.914),  time:41.760, tt:3215.550\n",
      "Ep:77, loss:0.00001, loss_test:0.07017, lr:7.40e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.754, tt:3256.841\n",
      "Ep:78, loss:0.00001, loss_test:0.06927, lr:7.32e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.754, tt:3298.551\n",
      "Ep:79, loss:0.00001, loss_test:0.06934, lr:7.25e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.774, tt:3341.915\n",
      "Ep:80, loss:0.00001, loss_test:0.06968, lr:7.18e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.804, tt:3386.098\n",
      "Ep:81, loss:0.00001, loss_test:0.06912, lr:7.11e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.808, tt:3428.225\n",
      "Ep:82, loss:0.00001, loss_test:0.06943, lr:7.03e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.835, tt:3472.341\n",
      "Ep:83, loss:0.00001, loss_test:0.06925, lr:6.96e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.824, tt:3513.225\n",
      "Ep:84, loss:0.00001, loss_test:0.06910, lr:6.89e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.910, tt:3562.312\n",
      "Ep:85, loss:0.00001, loss_test:0.06962, lr:6.83e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.929, tt:3605.925\n",
      "Ep:86, loss:0.00001, loss_test:0.06902, lr:6.76e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.944, tt:3649.169\n",
      "Ep:87, loss:0.00001, loss_test:0.06911, lr:6.69e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.983, tt:3694.484\n",
      "Ep:88, loss:0.00001, loss_test:0.06912, lr:6.62e-03, fs:0.76647 (r=0.646,p=0.941),  time:42.014, tt:3739.279\n",
      "Ep:89, loss:0.00001, loss_test:0.06909, lr:6.56e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.036, tt:3783.282\n",
      "Ep:90, loss:0.00001, loss_test:0.06889, lr:6.49e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.052, tt:3826.721\n",
      "Ep:91, loss:0.00001, loss_test:0.07010, lr:6.43e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.066, tt:3870.063\n",
      "Ep:92, loss:0.00001, loss_test:0.06939, lr:6.36e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.089, tt:3914.300\n",
      "Ep:93, loss:0.00001, loss_test:0.06875, lr:6.30e-03, fs:0.76647 (r=0.646,p=0.941),  time:42.093, tt:3956.778\n",
      "Ep:94, loss:0.00001, loss_test:0.06993, lr:6.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.105, tt:4000.014\n",
      "Ep:95, loss:0.00001, loss_test:0.06902, lr:6.17e-03, fs:0.76647 (r=0.646,p=0.941),  time:42.122, tt:4043.734\n",
      "Ep:96, loss:0.00001, loss_test:0.06910, lr:6.11e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.142, tt:4087.806\n",
      "Ep:97, loss:0.00001, loss_test:0.06890, lr:6.05e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.158, tt:4131.468\n",
      "Ep:98, loss:0.00001, loss_test:0.06872, lr:5.99e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.140, tt:4171.822\n",
      "Ep:99, loss:0.00001, loss_test:0.06898, lr:5.93e-03, fs:0.77108 (r=0.646,p=0.955),  time:42.147, tt:4214.672\n",
      "Ep:100, loss:0.00001, loss_test:0.06851, lr:5.87e-03, fs:0.76647 (r=0.646,p=0.941),  time:42.157, tt:4257.868\n",
      "Ep:101, loss:0.00001, loss_test:0.06896, lr:5.81e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.142, tt:4298.488\n",
      "Ep:102, loss:0.00001, loss_test:0.06964, lr:5.75e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.155, tt:4341.950\n",
      "Ep:103, loss:0.00001, loss_test:0.06849, lr:5.70e-03, fs:0.76647 (r=0.646,p=0.941),  time:42.201, tt:4388.932\n",
      "Ep:104, loss:0.00001, loss_test:0.06906, lr:5.64e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.193, tt:4430.260\n",
      "Ep:105, loss:0.00001, loss_test:0.06996, lr:5.58e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.188, tt:4471.955\n",
      "Ep:106, loss:0.00001, loss_test:0.06879, lr:5.53e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.188, tt:4514.150\n",
      "Ep:107, loss:0.00001, loss_test:0.06890, lr:5.47e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.225, tt:4560.303\n",
      "Ep:108, loss:0.00001, loss_test:0.06991, lr:5.42e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.223, tt:4602.344\n",
      "Ep:109, loss:0.00001, loss_test:0.06907, lr:5.36e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.232, tt:4645.572\n",
      "Ep:110, loss:0.00001, loss_test:0.06856, lr:5.31e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.252, tt:4689.956\n",
      "Ep:111, loss:0.00001, loss_test:0.06953, lr:5.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.256, tt:4732.670\n",
      "Ep:112, loss:0.00001, loss_test:0.06893, lr:5.20e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.270, tt:4776.541\n",
      "Ep:113, loss:0.00001, loss_test:0.06853, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.264, tt:4818.073\n",
      "Ep:114, loss:0.00001, loss_test:0.06899, lr:5.10e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.282, tt:4862.410\n",
      "Ep:115, loss:0.00001, loss_test:0.06918, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.277, tt:4904.187\n",
      "Ep:116, loss:0.00001, loss_test:0.06867, lr:5.00e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.270, tt:4945.628\n",
      "Ep:117, loss:0.00001, loss_test:0.06879, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:42.282, tt:4989.259\n",
      "Ep:118, loss:0.00001, loss_test:0.06875, lr:4.90e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.283, tt:5031.706\n",
      "Ep:119, loss:0.00001, loss_test:0.06856, lr:4.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.286, tt:5074.269\n",
      "Ep:120, loss:0.00001, loss_test:0.06886, lr:4.80e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.293, tt:5117.399\n",
      "Ep:121, loss:0.00001, loss_test:0.06905, lr:4.75e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.294, tt:5159.811\n",
      "Ep:122, loss:0.00001, loss_test:0.06871, lr:4.71e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.308, tt:5203.885\n",
      "Ep:123, loss:0.00001, loss_test:0.06961, lr:4.66e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.329, tt:5248.735\n",
      "Ep:124, loss:0.00001, loss_test:0.07128, lr:4.61e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.344, tt:5293.029\n",
      "Ep:125, loss:0.00001, loss_test:0.07071, lr:4.57e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.360, tt:5337.350\n",
      "Ep:126, loss:0.00001, loss_test:0.06937, lr:4.52e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.370, tt:5380.941\n",
      "Ep:127, loss:0.00001, loss_test:0.06889, lr:4.48e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.378, tt:5424.399\n",
      "Ep:128, loss:0.00001, loss_test:0.06933, lr:4.43e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.380, tt:5466.992\n",
      "Ep:129, loss:0.00001, loss_test:0.06944, lr:4.39e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.359, tt:5506.677\n",
      "Ep:130, loss:0.00001, loss_test:0.06918, lr:4.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.334, tt:5545.701\n",
      "Ep:131, loss:0.00001, loss_test:0.06950, lr:4.30e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.346, tt:5589.625\n",
      "Ep:132, loss:0.00001, loss_test:0.06934, lr:4.26e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.337, tt:5630.776\n",
      "Ep:133, loss:0.00001, loss_test:0.06884, lr:4.21e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.341, tt:5673.663\n",
      "Ep:134, loss:0.00001, loss_test:0.06932, lr:4.17e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.339, tt:5715.823\n",
      "Ep:135, loss:0.00001, loss_test:0.06986, lr:4.13e-03, fs:0.78049 (r=0.646,p=0.985),  time:42.331, tt:5757.073\n",
      "Ep:136, loss:0.00001, loss_test:0.06950, lr:4.09e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.325, tt:5798.471\n",
      "Ep:137, loss:0.00001, loss_test:0.06939, lr:4.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.323, tt:5840.545\n",
      "Ep:138, loss:0.00001, loss_test:0.06998, lr:4.01e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.323, tt:5882.897\n",
      "Ep:139, loss:0.00001, loss_test:0.06961, lr:3.97e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.319, tt:5924.650\n",
      "Ep:140, loss:0.00001, loss_test:0.06908, lr:3.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.313, tt:5966.149\n",
      "Ep:141, loss:0.00001, loss_test:0.06954, lr:3.89e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.303, tt:6007.011\n",
      "Ep:142, loss:0.00001, loss_test:0.06952, lr:3.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.300, tt:6048.935\n",
      "Ep:143, loss:0.00001, loss_test:0.06931, lr:3.81e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.303, tt:6091.570\n",
      "Ep:144, loss:0.00001, loss_test:0.06952, lr:3.77e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.298, tt:6133.249\n",
      "Ep:145, loss:0.00001, loss_test:0.06976, lr:3.73e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.292, tt:6174.692\n",
      "Ep:146, loss:0.00001, loss_test:0.06979, lr:3.70e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.306, tt:6218.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:147, loss:0.00001, loss_test:0.06966, lr:3.66e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.293, tt:6259.297\n",
      "Ep:148, loss:0.00001, loss_test:0.06967, lr:3.62e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.282, tt:6300.020\n",
      "Ep:149, loss:0.00001, loss_test:0.06949, lr:3.59e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.262, tt:6339.330\n",
      "Ep:150, loss:0.00001, loss_test:0.06998, lr:3.55e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.252, tt:6380.102\n",
      "Ep:151, loss:0.00001, loss_test:0.07046, lr:3.52e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.245, tt:6421.317\n",
      "Ep:152, loss:0.00001, loss_test:0.07051, lr:3.48e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.237, tt:6462.231\n",
      "Ep:153, loss:0.00001, loss_test:0.06997, lr:3.45e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.225, tt:6502.578\n",
      "Ep:154, loss:0.00001, loss_test:0.06981, lr:3.41e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.201, tt:6541.153\n",
      "Ep:155, loss:0.00001, loss_test:0.07013, lr:3.38e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.192, tt:6581.948\n",
      "Ep:156, loss:0.00000, loss_test:0.07011, lr:3.34e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.184, tt:6622.826\n",
      "Ep:157, loss:0.00000, loss_test:0.07015, lr:3.31e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.181, tt:6664.602\n",
      "Ep:158, loss:0.00000, loss_test:0.07048, lr:3.28e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.185, tt:6707.417\n",
      "Ep:159, loss:0.00000, loss_test:0.07042, lr:3.24e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.196, tt:6751.348\n",
      "Ep:160, loss:0.00000, loss_test:0.07025, lr:3.21e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.191, tt:6792.773\n",
      "Ep:161, loss:0.00000, loss_test:0.07026, lr:3.18e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.182, tt:6833.425\n",
      "Ep:162, loss:0.00000, loss_test:0.07082, lr:3.15e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.170, tt:6873.704\n",
      "Ep:163, loss:0.00000, loss_test:0.07058, lr:3.12e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.167, tt:6915.361\n",
      "Ep:164, loss:0.00000, loss_test:0.07034, lr:3.09e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.165, tt:6957.208\n",
      "Ep:165, loss:0.00000, loss_test:0.07048, lr:3.05e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.162, tt:6998.914\n",
      "Ep:166, loss:0.00000, loss_test:0.07066, lr:3.02e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.162, tt:7041.081\n",
      "Ep:167, loss:0.00000, loss_test:0.07053, lr:2.99e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.153, tt:7081.735\n",
      "Ep:168, loss:0.00000, loss_test:0.07058, lr:2.96e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.141, tt:7121.896\n",
      "Ep:169, loss:0.00000, loss_test:0.07073, lr:2.93e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.135, tt:7162.907\n",
      "Ep:170, loss:0.00000, loss_test:0.07065, lr:2.90e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.129, tt:7203.985\n",
      "Ep:171, loss:0.00000, loss_test:0.07044, lr:2.88e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.111, tt:7243.025\n",
      "Ep:172, loss:0.00000, loss_test:0.07093, lr:2.85e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.105, tt:7284.153\n",
      "Ep:173, loss:0.00000, loss_test:0.07120, lr:2.82e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.095, tt:7324.499\n",
      "Ep:174, loss:0.00000, loss_test:0.07096, lr:2.79e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.094, tt:7366.378\n",
      "Ep:175, loss:0.00000, loss_test:0.07097, lr:2.76e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.092, tt:7408.125\n",
      "Ep:176, loss:0.00000, loss_test:0.07101, lr:2.73e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.097, tt:7451.112\n",
      "Ep:177, loss:0.00000, loss_test:0.07101, lr:2.71e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.094, tt:7492.809\n",
      "Ep:178, loss:0.00000, loss_test:0.07104, lr:2.68e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.093, tt:7534.565\n",
      "Ep:179, loss:0.00000, loss_test:0.07127, lr:2.65e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.120, tt:7581.600\n",
      "Ep:180, loss:0.00000, loss_test:0.07137, lr:2.63e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.117, tt:7623.127\n",
      "Ep:181, loss:0.00000, loss_test:0.07155, lr:2.60e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.116, tt:7665.166\n",
      "Ep:182, loss:0.00000, loss_test:0.07132, lr:2.57e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.115, tt:7707.081\n",
      "Ep:183, loss:0.00000, loss_test:0.07137, lr:2.55e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.117, tt:7749.518\n",
      "Ep:184, loss:0.00000, loss_test:0.07155, lr:2.52e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.123, tt:7792.749\n",
      "Ep:185, loss:0.00000, loss_test:0.07162, lr:2.50e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.138, tt:7837.586\n",
      "Ep:186, loss:0.00000, loss_test:0.07168, lr:2.47e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.134, tt:7879.068\n",
      "Ep:187, loss:0.00000, loss_test:0.07159, lr:2.45e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.147, tt:7923.679\n",
      "Ep:188, loss:0.00000, loss_test:0.07153, lr:2.42e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.143, tt:7965.083\n",
      "Ep:189, loss:0.00000, loss_test:0.07173, lr:2.40e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.140, tt:8006.683\n",
      "Ep:190, loss:0.00000, loss_test:0.07206, lr:2.38e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.146, tt:8049.805\n",
      "Ep:191, loss:0.00000, loss_test:0.07211, lr:2.35e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.143, tt:8091.545\n",
      "Ep:192, loss:0.00000, loss_test:0.07171, lr:2.33e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.143, tt:8133.669\n",
      "Ep:193, loss:0.00000, loss_test:0.07184, lr:2.31e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.142, tt:8175.471\n",
      "Ep:194, loss:0.00000, loss_test:0.07202, lr:2.28e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.140, tt:8217.362\n",
      "Ep:195, loss:0.00000, loss_test:0.07208, lr:2.26e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.133, tt:8258.060\n",
      "Ep:196, loss:0.00000, loss_test:0.07183, lr:2.24e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.141, tt:8301.712\n",
      "Ep:197, loss:0.00000, loss_test:0.07174, lr:2.21e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.145, tt:8344.715\n",
      "Ep:198, loss:0.00000, loss_test:0.07179, lr:2.19e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.141, tt:8386.077\n",
      "Ep:199, loss:0.00000, loss_test:0.07171, lr:2.17e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.121, tt:8424.136\n",
      "Ep:200, loss:0.00000, loss_test:0.07192, lr:2.15e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.080, tt:8458.039\n",
      "Ep:201, loss:0.00000, loss_test:0.07211, lr:2.13e-03, fs:0.78528 (r=0.646,p=1.000),  time:42.018, tt:8487.573\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02014, lr:6.00e-02, fs:0.64706 (r=0.889,p=0.509),  time:30.940, tt:30.940\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02234, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.178, tt:62.357\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02321, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.719, tt:98.157\n",
      "Ep:3, loss:0.00004, loss_test:0.02227, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.186, tt:132.743\n",
      "Ep:4, loss:0.00004, loss_test:0.02071, lr:6.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:33.631, tt:168.154\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01941, lr:6.00e-02, fs:0.66667 (r=0.909,p=0.526),  time:33.741, tt:202.446\n",
      "Ep:6, loss:0.00004, loss_test:0.01913, lr:6.00e-02, fs:0.68016 (r=0.848,p=0.568),  time:33.884, tt:237.190\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01906, lr:6.00e-02, fs:0.70042 (r=0.838,p=0.601),  time:33.905, tt:271.242\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01840, lr:6.00e-02, fs:0.71605 (r=0.879,p=0.604),  time:33.982, tt:305.837\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01792, lr:6.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:34.029, tt:340.290\n",
      "Ep:10, loss:0.00003, loss_test:0.01774, lr:6.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:34.040, tt:374.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:11, loss:0.00003, loss_test:0.01741, lr:6.00e-02, fs:0.69888 (r=0.949,p=0.553),  time:33.950, tt:407.396\n",
      "Ep:12, loss:0.00003, loss_test:0.01697, lr:6.00e-02, fs:0.72308 (r=0.949,p=0.584),  time:34.006, tt:442.079\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01667, lr:6.00e-02, fs:0.72874 (r=0.909,p=0.608),  time:34.004, tt:476.050\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01644, lr:6.00e-02, fs:0.73859 (r=0.899,p=0.627),  time:34.075, tt:511.126\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01613, lr:6.00e-02, fs:0.74477 (r=0.899,p=0.636),  time:34.121, tt:545.934\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01585, lr:6.00e-02, fs:0.75410 (r=0.929,p=0.634),  time:34.152, tt:580.591\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01559, lr:6.00e-02, fs:0.75397 (r=0.960,p=0.621),  time:34.196, tt:615.532\n",
      "Ep:18, loss:0.00003, loss_test:0.01534, lr:6.00e-02, fs:0.78367 (r=0.970,p=0.658),  time:34.213, tt:650.039\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01515, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:34.205, tt:684.109\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01505, lr:6.00e-02, fs:0.79325 (r=0.949,p=0.681),  time:34.231, tt:718.843\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.295, tt:754.496\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:34.315, tt:789.255\n",
      "Ep:23, loss:0.00002, loss_test:0.01463, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.331, tt:823.954\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01451, lr:6.00e-02, fs:0.80672 (r=0.970,p=0.691),  time:34.279, tt:856.972\n",
      "Ep:25, loss:0.00002, loss_test:0.01444, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.273, tt:891.100\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01438, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.337, tt:927.097\n",
      "Ep:27, loss:0.00002, loss_test:0.01428, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.365, tt:962.217\n",
      "Ep:28, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.82051 (r=0.970,p=0.711),  time:34.299, tt:994.684\n",
      "Ep:29, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:34.315, tt:1029.455\n",
      "Ep:30, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.81739 (r=0.949,p=0.718),  time:34.331, tt:1064.252\n",
      "Ep:31, loss:0.00002, loss_test:0.01387, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:34.327, tt:1098.475\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01381, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.302, tt:1131.980\n",
      "Ep:33, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:34.334, tt:1167.343\n",
      "Ep:34, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.336, tt:1201.750\n",
      "Ep:35, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:34.356, tt:1236.826\n",
      "Ep:36, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:34.398, tt:1272.709\n",
      "Ep:37, loss:0.00001, loss_test:0.01360, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.388, tt:1306.752\n",
      "Ep:38, loss:0.00001, loss_test:0.01357, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.413, tt:1342.115\n",
      "Ep:39, loss:0.00001, loss_test:0.01359, lr:6.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:34.401, tt:1376.050\n",
      "Ep:40, loss:0.00001, loss_test:0.01355, lr:6.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:34.423, tt:1411.361\n",
      "Ep:41, loss:0.00001, loss_test:0.01351, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.433, tt:1446.188\n",
      "Ep:42, loss:0.00001, loss_test:0.01352, lr:6.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:34.479, tt:1482.595\n",
      "Ep:43, loss:0.00001, loss_test:0.01348, lr:5.94e-02, fs:0.81106 (r=0.889,p=0.746),  time:34.482, tt:1517.214\n",
      "Ep:44, loss:0.00001, loss_test:0.01348, lr:5.88e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.566, tt:1555.450\n",
      "Ep:45, loss:0.00001, loss_test:0.01347, lr:5.82e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.577, tt:1590.532\n",
      "Ep:46, loss:0.00001, loss_test:0.01349, lr:5.76e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.565, tt:1624.532\n",
      "Ep:47, loss:0.00001, loss_test:0.01354, lr:5.71e-02, fs:0.81481 (r=0.889,p=0.752),  time:34.573, tt:1659.521\n",
      "Ep:48, loss:0.00001, loss_test:0.01355, lr:5.65e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.587, tt:1694.760\n",
      "Ep:49, loss:0.00001, loss_test:0.01354, lr:5.59e-02, fs:0.82075 (r=0.879,p=0.770),  time:34.600, tt:1730.006\n",
      "Ep:50, loss:0.00001, loss_test:0.01357, lr:5.54e-02, fs:0.82297 (r=0.869,p=0.782),  time:34.619, tt:1765.573\n",
      "Ep:51, loss:0.00001, loss_test:0.01359, lr:5.48e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.612, tt:1799.819\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01359, lr:5.48e-02, fs:0.82857 (r=0.879,p=0.784),  time:34.612, tt:1834.453\n",
      "Ep:53, loss:0.00001, loss_test:0.01359, lr:5.48e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.600, tt:1868.381\n",
      "Ep:54, loss:0.00001, loss_test:0.01363, lr:5.48e-02, fs:0.82692 (r=0.869,p=0.789),  time:34.601, tt:1903.070\n",
      "Ep:55, loss:0.00001, loss_test:0.01368, lr:5.48e-02, fs:0.81373 (r=0.838,p=0.790),  time:34.599, tt:1937.533\n",
      "Ep:56, loss:0.00001, loss_test:0.01367, lr:5.48e-02, fs:0.82353 (r=0.848,p=0.800),  time:34.630, tt:1973.932\n",
      "Ep:57, loss:0.00001, loss_test:0.01373, lr:5.48e-02, fs:0.81773 (r=0.838,p=0.798),  time:34.609, tt:2007.350\n",
      "Ep:58, loss:0.00001, loss_test:0.01380, lr:5.48e-02, fs:0.83000 (r=0.838,p=0.822),  time:34.622, tt:2042.697\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01381, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.612, tt:2076.727\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01379, lr:5.48e-02, fs:0.83168 (r=0.848,p=0.816),  time:34.626, tt:2112.205\n",
      "Ep:61, loss:0.00001, loss_test:0.01379, lr:5.48e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.657, tt:2148.734\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01385, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:34.653, tt:2183.133\n",
      "Ep:63, loss:0.00001, loss_test:0.01389, lr:5.48e-02, fs:0.84000 (r=0.848,p=0.832),  time:34.644, tt:2217.201\n",
      "Ep:64, loss:0.00001, loss_test:0.01388, lr:5.48e-02, fs:0.83417 (r=0.838,p=0.830),  time:34.669, tt:2253.508\n",
      "Ep:65, loss:0.00001, loss_test:0.01392, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.673, tt:2288.439\n",
      "Ep:66, loss:0.00001, loss_test:0.01398, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.681, tt:2323.637\n",
      "Ep:67, loss:0.00001, loss_test:0.01400, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.703, tt:2359.776\n",
      "Ep:68, loss:0.00001, loss_test:0.01403, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.707, tt:2394.751\n",
      "Ep:69, loss:0.00001, loss_test:0.01413, lr:5.48e-02, fs:0.82653 (r=0.818,p=0.835),  time:34.717, tt:2430.205\n",
      "Ep:70, loss:0.00001, loss_test:0.01418, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.725, tt:2465.480\n",
      "Ep:71, loss:0.00001, loss_test:0.01420, lr:5.48e-02, fs:0.82234 (r=0.818,p=0.827),  time:34.729, tt:2500.507\n",
      "Ep:72, loss:0.00001, loss_test:0.01424, lr:5.48e-02, fs:0.82474 (r=0.808,p=0.842),  time:34.728, tt:2535.174\n",
      "Ep:73, loss:0.00001, loss_test:0.01430, lr:5.43e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.745, tt:2571.104\n",
      "Ep:74, loss:0.00001, loss_test:0.01433, lr:5.37e-02, fs:0.82292 (r=0.798,p=0.849),  time:34.742, tt:2605.655\n",
      "Ep:75, loss:0.00001, loss_test:0.01438, lr:5.32e-02, fs:0.82723 (r=0.798,p=0.859),  time:34.746, tt:2640.703\n",
      "Ep:76, loss:0.00001, loss_test:0.01442, lr:5.27e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.739, tt:2674.890\n",
      "Ep:77, loss:0.00001, loss_test:0.01449, lr:5.21e-02, fs:0.83598 (r=0.798,p=0.878),  time:34.734, tt:2709.256\n",
      "Ep:78, loss:0.00001, loss_test:0.01454, lr:5.16e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.728, tt:2743.496\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.01457, lr:5.16e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.721, tt:2777.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:80, loss:0.00001, loss_test:0.01463, lr:5.16e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.725, tt:2812.696\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.01463, lr:5.16e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.751, tt:2849.580\n",
      "Ep:82, loss:0.00001, loss_test:0.01470, lr:5.16e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.753, tt:2884.523\n",
      "Ep:83, loss:0.00001, loss_test:0.01478, lr:5.16e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.765, tt:2920.238\n",
      "Ep:84, loss:0.00001, loss_test:0.01483, lr:5.16e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.766, tt:2955.070\n",
      "Ep:85, loss:0.00001, loss_test:0.01489, lr:5.16e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.779, tt:2991.008\n",
      "Ep:86, loss:0.00001, loss_test:0.01494, lr:5.16e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.748, tt:3023.043\n",
      "Ep:87, loss:0.00001, loss_test:0.01503, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.755, tt:3058.459\n",
      "Ep:88, loss:0.00001, loss_test:0.01505, lr:5.16e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.754, tt:3093.149\n",
      "Ep:89, loss:0.00001, loss_test:0.01511, lr:5.16e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.746, tt:3127.146\n",
      "Ep:90, loss:0.00001, loss_test:0.01513, lr:5.16e-02, fs:0.83060 (r=0.768,p=0.905),  time:34.732, tt:3160.596\n",
      "Ep:91, loss:0.00001, loss_test:0.01523, lr:5.16e-02, fs:0.80000 (r=0.727,p=0.889),  time:34.738, tt:3195.926\n",
      "Ep:92, loss:0.00001, loss_test:0.01527, lr:5.11e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.737, tt:3230.561\n",
      "Ep:93, loss:0.00000, loss_test:0.01532, lr:5.06e-02, fs:0.80447 (r=0.727,p=0.900),  time:34.743, tt:3265.881\n",
      "Ep:94, loss:0.00000, loss_test:0.01536, lr:5.01e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.733, tt:3299.632\n",
      "Ep:95, loss:0.00000, loss_test:0.01543, lr:4.96e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.734, tt:3334.439\n",
      "Ep:96, loss:0.00000, loss_test:0.01547, lr:4.91e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.732, tt:3368.984\n",
      "Ep:97, loss:0.00000, loss_test:0.01556, lr:4.86e-02, fs:0.79096 (r=0.707,p=0.897),  time:34.733, tt:3403.840\n",
      "Ep:98, loss:0.00000, loss_test:0.01558, lr:4.81e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.733, tt:3438.552\n",
      "Ep:99, loss:0.00000, loss_test:0.01560, lr:4.76e-02, fs:0.79775 (r=0.717,p=0.899),  time:34.720, tt:3472.030\n",
      "Ep:100, loss:0.00000, loss_test:0.01576, lr:4.71e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.717, tt:3506.418\n",
      "Ep:101, loss:0.00000, loss_test:0.01579, lr:4.67e-02, fs:0.77714 (r=0.687,p=0.895),  time:34.718, tt:3541.227\n",
      "Ep:102, loss:0.00000, loss_test:0.01580, lr:4.62e-02, fs:0.78409 (r=0.697,p=0.896),  time:34.734, tt:3577.645\n",
      "Ep:103, loss:0.00000, loss_test:0.01589, lr:4.57e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.760, tt:3615.085\n",
      "Ep:104, loss:0.00000, loss_test:0.01596, lr:4.53e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.757, tt:3649.489\n",
      "Ep:105, loss:0.00000, loss_test:0.01596, lr:4.48e-02, fs:0.77011 (r=0.677,p=0.893),  time:34.765, tt:3685.043\n",
      "Ep:106, loss:0.00000, loss_test:0.01602, lr:4.44e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.760, tt:3719.324\n",
      "Ep:107, loss:0.00000, loss_test:0.01607, lr:4.39e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.767, tt:3754.879\n",
      "Ep:108, loss:0.00000, loss_test:0.01613, lr:4.35e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.759, tt:3788.774\n",
      "Ep:109, loss:0.00000, loss_test:0.01619, lr:4.31e-02, fs:0.75294 (r=0.646,p=0.901),  time:34.749, tt:3822.393\n",
      "Ep:110, loss:0.00000, loss_test:0.01626, lr:4.26e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.734, tt:3855.420\n",
      "Ep:111, loss:0.00000, loss_test:0.01629, lr:4.22e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.710, tt:3887.528\n",
      "Ep:112, loss:0.00000, loss_test:0.01636, lr:4.18e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.707, tt:3921.885\n",
      "Ep:113, loss:0.00000, loss_test:0.01639, lr:4.14e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.708, tt:3956.672\n",
      "Ep:114, loss:0.00000, loss_test:0.01640, lr:4.10e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.707, tt:3991.255\n",
      "Ep:115, loss:0.00000, loss_test:0.01647, lr:4.05e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.706, tt:4025.906\n",
      "Ep:116, loss:0.00000, loss_test:0.01652, lr:4.01e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.715, tt:4061.618\n",
      "Ep:117, loss:0.00000, loss_test:0.01655, lr:3.97e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.716, tt:4096.450\n",
      "Ep:118, loss:0.00000, loss_test:0.01665, lr:3.93e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.724, tt:4132.169\n",
      "Ep:119, loss:0.00000, loss_test:0.01669, lr:3.89e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.722, tt:4166.700\n",
      "Ep:120, loss:0.00000, loss_test:0.01668, lr:3.86e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.717, tt:4200.708\n",
      "Ep:121, loss:0.00000, loss_test:0.01672, lr:3.82e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.711, tt:4234.770\n",
      "Ep:122, loss:0.00000, loss_test:0.01677, lr:3.78e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.718, tt:4270.314\n",
      "Ep:123, loss:0.00000, loss_test:0.01680, lr:3.74e-02, fs:0.74556 (r=0.636,p=0.900),  time:34.734, tt:4307.074\n",
      "Ep:124, loss:0.00000, loss_test:0.01685, lr:3.70e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.729, tt:4341.130\n",
      "Ep:125, loss:0.00000, loss_test:0.01691, lr:3.67e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.719, tt:4374.584\n",
      "Ep:126, loss:0.00000, loss_test:0.01693, lr:3.63e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.715, tt:4408.847\n",
      "Ep:127, loss:0.00000, loss_test:0.01699, lr:3.59e-02, fs:0.73810 (r=0.626,p=0.899),  time:34.725, tt:4444.861\n",
      "Ep:128, loss:0.00000, loss_test:0.01703, lr:3.56e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.741, tt:4481.645\n",
      "Ep:129, loss:0.00000, loss_test:0.01705, lr:3.52e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.740, tt:4516.207\n",
      "Ep:130, loss:0.00000, loss_test:0.01709, lr:3.49e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.742, tt:4551.211\n",
      "Ep:131, loss:0.00000, loss_test:0.01714, lr:3.45e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.761, tt:4588.507\n",
      "Ep:132, loss:0.00000, loss_test:0.01717, lr:3.42e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.764, tt:4623.602\n",
      "Ep:133, loss:0.00000, loss_test:0.01722, lr:3.38e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.797, tt:4662.839\n",
      "Ep:134, loss:0.00000, loss_test:0.01723, lr:3.35e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.798, tt:4697.689\n",
      "Ep:135, loss:0.00000, loss_test:0.01726, lr:3.32e-02, fs:0.74251 (r=0.626,p=0.912),  time:34.796, tt:4732.231\n",
      "Ep:136, loss:0.00000, loss_test:0.01733, lr:3.28e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.804, tt:4768.119\n",
      "Ep:137, loss:0.00000, loss_test:0.01736, lr:3.25e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.805, tt:4803.142\n",
      "Ep:138, loss:0.00000, loss_test:0.01738, lr:3.22e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.807, tt:4838.209\n",
      "Ep:139, loss:0.00000, loss_test:0.01742, lr:3.19e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.815, tt:4874.096\n",
      "Ep:140, loss:0.00000, loss_test:0.01746, lr:3.15e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.821, tt:4909.725\n",
      "Ep:141, loss:0.00000, loss_test:0.01749, lr:3.12e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.821, tt:4944.612\n",
      "Ep:142, loss:0.00000, loss_test:0.01750, lr:3.09e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.819, tt:4979.049\n",
      "Ep:143, loss:0.00000, loss_test:0.01752, lr:3.06e-02, fs:0.73494 (r=0.616,p=0.910),  time:34.816, tt:5013.565\n",
      "Ep:144, loss:0.00000, loss_test:0.01760, lr:3.03e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.818, tt:5048.647\n",
      "Ep:145, loss:0.00000, loss_test:0.01763, lr:3.00e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.828, tt:5084.865\n",
      "Ep:146, loss:0.00000, loss_test:0.01764, lr:2.97e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.837, tt:5121.036\n",
      "Ep:147, loss:0.00000, loss_test:0.01766, lr:2.94e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.828, tt:5154.540\n",
      "Ep:148, loss:0.00000, loss_test:0.01768, lr:2.91e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.827, tt:5189.292\n",
      "Ep:149, loss:0.00000, loss_test:0.01772, lr:2.88e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.835, tt:5225.275\n",
      "Ep:150, loss:0.00000, loss_test:0.01776, lr:2.85e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.826, tt:5258.674\n",
      "Ep:151, loss:0.00000, loss_test:0.01780, lr:2.82e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.814, tt:5291.729\n",
      "Ep:152, loss:0.00000, loss_test:0.01781, lr:2.80e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.817, tt:5326.977\n",
      "Ep:153, loss:0.00000, loss_test:0.01783, lr:2.77e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.818, tt:5361.908\n",
      "Ep:154, loss:0.00000, loss_test:0.01788, lr:2.74e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.814, tt:5396.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:155, loss:0.00000, loss_test:0.01794, lr:2.71e-02, fs:0.72727 (r=0.606,p=0.909),  time:34.812, tt:5430.627\n",
      "Ep:156, loss:0.00000, loss_test:0.01795, lr:2.69e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.817, tt:5466.337\n",
      "Ep:157, loss:0.00000, loss_test:0.01799, lr:2.66e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.846, tt:5505.664\n",
      "Ep:158, loss:0.00000, loss_test:0.01802, lr:2.63e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.843, tt:5539.981\n",
      "Ep:159, loss:0.00000, loss_test:0.01805, lr:2.61e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.842, tt:5574.776\n",
      "Ep:160, loss:0.00000, loss_test:0.01803, lr:2.58e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.840, tt:5609.219\n",
      "Ep:161, loss:0.00000, loss_test:0.01807, lr:2.55e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.833, tt:5643.010\n",
      "Ep:162, loss:0.00000, loss_test:0.01811, lr:2.53e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.847, tt:5679.996\n",
      "Ep:163, loss:0.00000, loss_test:0.01814, lr:2.50e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.849, tt:5715.172\n",
      "Ep:164, loss:0.00000, loss_test:0.01816, lr:2.48e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.843, tt:5749.087\n",
      "Ep:165, loss:0.00000, loss_test:0.01820, lr:2.45e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.839, tt:5783.347\n",
      "Ep:166, loss:0.00000, loss_test:0.01821, lr:2.43e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.843, tt:5818.801\n",
      "Ep:167, loss:0.00000, loss_test:0.01824, lr:2.40e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.838, tt:5852.781\n",
      "Ep:168, loss:0.00000, loss_test:0.01826, lr:2.38e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.840, tt:5888.012\n",
      "Ep:169, loss:0.00000, loss_test:0.01827, lr:2.36e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.830, tt:5921.099\n",
      "Ep:170, loss:0.00000, loss_test:0.01829, lr:2.33e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.828, tt:5955.555\n",
      "Ep:171, loss:0.00000, loss_test:0.01832, lr:2.31e-02, fs:0.73171 (r=0.606,p=0.923),  time:34.826, tt:5990.025\n",
      "Ep:172, loss:0.00000, loss_test:0.01836, lr:2.29e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.832, tt:6025.936\n",
      "Ep:173, loss:0.00000, loss_test:0.01837, lr:2.26e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.837, tt:6061.635\n",
      "Ep:174, loss:0.00000, loss_test:0.01840, lr:2.24e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.823, tt:6094.014\n",
      "Ep:175, loss:0.00000, loss_test:0.01842, lr:2.22e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.822, tt:6128.617\n",
      "Ep:176, loss:0.00000, loss_test:0.01843, lr:2.20e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.814, tt:6162.096\n",
      "Ep:177, loss:0.00000, loss_test:0.01845, lr:2.17e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.832, tt:6200.128\n",
      "Ep:178, loss:0.00000, loss_test:0.01849, lr:2.15e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.834, tt:6235.275\n",
      "Ep:179, loss:0.00000, loss_test:0.01850, lr:2.13e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.833, tt:6269.970\n",
      "Ep:180, loss:0.00000, loss_test:0.01852, lr:2.11e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.821, tt:6302.609\n",
      "Ep:181, loss:0.00000, loss_test:0.01856, lr:2.09e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.816, tt:6336.461\n",
      "Ep:182, loss:0.00000, loss_test:0.01856, lr:2.07e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.809, tt:6370.136\n",
      "Ep:183, loss:0.00000, loss_test:0.01858, lr:2.05e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.803, tt:6403.666\n",
      "Ep:184, loss:0.00000, loss_test:0.01861, lr:2.03e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.800, tt:6438.009\n",
      "Ep:185, loss:0.00000, loss_test:0.01863, lr:2.01e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.800, tt:6472.728\n",
      "Ep:186, loss:0.00000, loss_test:0.01862, lr:1.99e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.788, tt:6505.367\n",
      "Ep:187, loss:0.00000, loss_test:0.01862, lr:1.97e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.785, tt:6539.650\n",
      "Ep:188, loss:0.00000, loss_test:0.01864, lr:1.95e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.781, tt:6573.589\n",
      "Ep:189, loss:0.00000, loss_test:0.01868, lr:1.93e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.778, tt:6607.860\n",
      "Ep:190, loss:0.00000, loss_test:0.01870, lr:1.91e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.768, tt:6640.684\n",
      "Ep:191, loss:0.00000, loss_test:0.01871, lr:1.89e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.764, tt:6674.634\n",
      "Ep:192, loss:0.00000, loss_test:0.01874, lr:1.87e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.761, tt:6708.786\n",
      "Ep:193, loss:0.00000, loss_test:0.01874, lr:1.85e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.754, tt:6742.340\n",
      "Ep:194, loss:0.00000, loss_test:0.01876, lr:1.83e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.750, tt:6776.207\n",
      "Ep:195, loss:0.00000, loss_test:0.01877, lr:1.81e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.745, tt:6809.994\n",
      "Ep:196, loss:0.00000, loss_test:0.01880, lr:1.80e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.735, tt:6842.856\n",
      "Ep:197, loss:0.00000, loss_test:0.01881, lr:1.78e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.725, tt:6875.471\n",
      "Ep:198, loss:0.00000, loss_test:0.01882, lr:1.76e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.711, tt:6907.510\n",
      "Ep:199, loss:0.00000, loss_test:0.01883, lr:1.74e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.693, tt:6938.595\n",
      "Ep:200, loss:0.00000, loss_test:0.01886, lr:1.73e-02, fs:0.73620 (r=0.606,p=0.938),  time:34.645, tt:6963.680\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT_SIMPLE_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext_600_300 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14363, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.892, tt:32.892\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14254, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.489, tt:66.978\n",
      "Ep:2, loss:0.00028, loss_test:0.14057, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.267, tt:102.802\n",
      "Ep:3, loss:0.00027, loss_test:0.13707, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.369, tt:137.477\n",
      "Ep:4, loss:0.00027, loss_test:0.13086, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:34.527, tt:172.633\n",
      "Ep:5, loss:0.00025, loss_test:0.11975, lr:1.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:34.902, tt:209.413\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11360, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:35.246, tt:246.724\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11370, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:35.443, tt:283.541\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11531, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:35.480, tt:319.323\n",
      "Ep:9, loss:0.00022, loss_test:0.11310, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:35.563, tt:355.626\n",
      "Ep:10, loss:0.00021, loss_test:0.10795, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:35.596, tt:391.557\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10573, lr:1.00e-02, fs:0.73733 (r=0.808,p=0.678),  time:35.557, tt:426.681\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10594, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:35.490, tt:461.368\n",
      "Ep:13, loss:0.00019, loss_test:0.10279, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:35.615, tt:498.616\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09913, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:35.673, tt:535.093\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09887, lr:1.00e-02, fs:0.76577 (r=0.859,p=0.691),  time:35.610, tt:569.766\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.09788, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:35.551, tt:604.362\n",
      "Ep:17, loss:0.00016, loss_test:0.09438, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:35.483, tt:638.690\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09280, lr:1.00e-02, fs:0.77778 (r=0.848,p=0.718),  time:35.400, tt:672.601\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.09226, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:35.478, tt:709.569\n",
      "Ep:20, loss:0.00014, loss_test:0.09119, lr:1.00e-02, fs:0.77725 (r=0.828,p=0.732),  time:35.468, tt:744.820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:21, loss:0.00013, loss_test:0.08810, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:35.428, tt:779.424\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08819, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:35.431, tt:814.908\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.08546, lr:1.00e-02, fs:0.81592 (r=0.828,p=0.804),  time:35.391, tt:849.376\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.08373, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:35.371, tt:884.284\n",
      "Ep:25, loss:0.00011, loss_test:0.08235, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:35.328, tt:918.523\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00010, loss_test:0.08115, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:35.317, tt:953.571\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00009, loss_test:0.08135, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:35.290, tt:988.122\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.08058, lr:1.00e-02, fs:0.80423 (r=0.768,p=0.844),  time:35.287, tt:1023.323\n",
      "Ep:29, loss:0.00009, loss_test:0.07968, lr:1.00e-02, fs:0.82902 (r=0.808,p=0.851),  time:35.291, tt:1058.723\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00008, loss_test:0.07967, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.264, tt:1093.183\n",
      "Ep:31, loss:0.00008, loss_test:0.07973, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:35.219, tt:1127.021\n",
      "Ep:32, loss:0.00007, loss_test:0.07904, lr:1.00e-02, fs:0.80447 (r=0.727,p=0.900),  time:35.190, tt:1161.269\n",
      "Ep:33, loss:0.00007, loss_test:0.08011, lr:1.00e-02, fs:0.80645 (r=0.758,p=0.862),  time:35.172, tt:1195.849\n",
      "Ep:34, loss:0.00007, loss_test:0.07621, lr:1.00e-02, fs:0.83158 (r=0.798,p=0.868),  time:35.204, tt:1232.140\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00006, loss_test:0.08007, lr:1.00e-02, fs:0.77778 (r=0.707,p=0.864),  time:35.181, tt:1266.506\n",
      "Ep:36, loss:0.00006, loss_test:0.07506, lr:1.00e-02, fs:0.82540 (r=0.788,p=0.867),  time:35.140, tt:1300.185\n",
      "Ep:37, loss:0.00006, loss_test:0.07718, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:35.155, tt:1335.892\n",
      "Ep:38, loss:0.00006, loss_test:0.07574, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:35.135, tt:1370.267\n",
      "Ep:39, loss:0.00005, loss_test:0.07633, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:35.122, tt:1404.883\n",
      "Ep:40, loss:0.00005, loss_test:0.07633, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:35.130, tt:1440.315\n",
      "Ep:41, loss:0.00005, loss_test:0.07440, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:35.151, tt:1476.362\n",
      "Ep:42, loss:0.00005, loss_test:0.07426, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:35.150, tt:1511.441\n",
      "Ep:43, loss:0.00004, loss_test:0.07675, lr:1.00e-02, fs:0.74699 (r=0.626,p=0.925),  time:35.161, tt:1547.097\n",
      "Ep:44, loss:0.00004, loss_test:0.07347, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:35.180, tt:1583.081\n",
      "Ep:45, loss:0.00004, loss_test:0.07177, lr:1.00e-02, fs:0.82022 (r=0.737,p=0.924),  time:35.163, tt:1617.477\n",
      "Ep:46, loss:0.00004, loss_test:0.07661, lr:9.90e-03, fs:0.74699 (r=0.626,p=0.925),  time:35.146, tt:1651.868\n",
      "Ep:47, loss:0.00004, loss_test:0.07216, lr:9.80e-03, fs:0.80447 (r=0.727,p=0.900),  time:35.357, tt:1697.136\n",
      "Ep:48, loss:0.00004, loss_test:0.07642, lr:9.70e-03, fs:0.74251 (r=0.626,p=0.912),  time:35.314, tt:1730.382\n",
      "Ep:49, loss:0.00004, loss_test:0.07260, lr:9.61e-03, fs:0.79532 (r=0.687,p=0.944),  time:35.251, tt:1762.541\n",
      "Ep:50, loss:0.00003, loss_test:0.07169, lr:9.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:35.225, tt:1796.479\n",
      "Ep:51, loss:0.00003, loss_test:0.07773, lr:9.41e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.203, tt:1830.560\n",
      "Ep:52, loss:0.00003, loss_test:0.07250, lr:9.32e-03, fs:0.73620 (r=0.606,p=0.938),  time:35.177, tt:1864.359\n",
      "Ep:53, loss:0.00003, loss_test:0.07376, lr:9.23e-03, fs:0.75145 (r=0.657,p=0.878),  time:35.284, tt:1905.330\n",
      "Ep:54, loss:0.00003, loss_test:0.07013, lr:9.14e-03, fs:0.77381 (r=0.657,p=0.942),  time:35.237, tt:1938.041\n",
      "Ep:55, loss:0.00003, loss_test:0.07371, lr:9.04e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.205, tt:1971.476\n",
      "Ep:56, loss:0.00003, loss_test:0.07033, lr:8.95e-03, fs:0.80682 (r=0.717,p=0.922),  time:35.156, tt:2003.887\n",
      "Ep:57, loss:0.00003, loss_test:0.07434, lr:8.86e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.141, tt:2038.162\n",
      "Ep:58, loss:0.00003, loss_test:0.07153, lr:8.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.098, tt:2070.781\n",
      "Ep:59, loss:0.00002, loss_test:0.07099, lr:8.69e-03, fs:0.80233 (r=0.697,p=0.945),  time:35.059, tt:2103.543\n",
      "Ep:60, loss:0.00002, loss_test:0.07147, lr:8.60e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.032, tt:2136.966\n",
      "Ep:61, loss:0.00002, loss_test:0.07157, lr:8.51e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.018, tt:2171.117\n",
      "Ep:62, loss:0.00002, loss_test:0.07291, lr:8.43e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.015, tt:2205.924\n",
      "Ep:63, loss:0.00002, loss_test:0.07053, lr:8.35e-03, fs:0.76647 (r=0.646,p=0.941),  time:35.009, tt:2240.548\n",
      "Ep:64, loss:0.00002, loss_test:0.07396, lr:8.26e-03, fs:0.72840 (r=0.596,p=0.937),  time:35.011, tt:2275.698\n",
      "Ep:65, loss:0.00002, loss_test:0.06978, lr:8.18e-03, fs:0.78824 (r=0.677,p=0.944),  time:34.979, tt:2308.640\n",
      "Ep:66, loss:0.00002, loss_test:0.07293, lr:8.10e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.931, tt:2340.410\n",
      "Ep:67, loss:0.00002, loss_test:0.07359, lr:8.02e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.917, tt:2374.356\n",
      "Ep:68, loss:0.00002, loss_test:0.07155, lr:7.94e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.900, tt:2408.083\n",
      "Ep:69, loss:0.00002, loss_test:0.07224, lr:7.86e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.882, tt:2441.737\n",
      "Ep:70, loss:0.00002, loss_test:0.07181, lr:7.78e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.844, tt:2473.921\n",
      "Ep:71, loss:0.00002, loss_test:0.07058, lr:7.70e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.801, tt:2505.660\n",
      "Ep:72, loss:0.00002, loss_test:0.07329, lr:7.62e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.790, tt:2539.691\n",
      "Ep:73, loss:0.00002, loss_test:0.06870, lr:7.55e-03, fs:0.73620 (r=0.606,p=0.938),  time:34.788, tt:2574.318\n",
      "Ep:74, loss:0.00001, loss_test:0.07426, lr:7.47e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.784, tt:2608.786\n",
      "Ep:75, loss:0.00001, loss_test:0.07053, lr:7.40e-03, fs:0.72840 (r=0.596,p=0.937),  time:34.813, tt:2645.777\n",
      "Ep:76, loss:0.00001, loss_test:0.07497, lr:7.32e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.795, tt:2679.224\n",
      "Ep:77, loss:0.00001, loss_test:0.07056, lr:7.25e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.777, tt:2712.605\n",
      "Ep:78, loss:0.00001, loss_test:0.07406, lr:7.18e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.769, tt:2746.760\n",
      "Ep:79, loss:0.00001, loss_test:0.07054, lr:7.11e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.744, tt:2779.492\n",
      "Ep:80, loss:0.00001, loss_test:0.07436, lr:7.03e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.737, tt:2813.691\n",
      "Ep:81, loss:0.00001, loss_test:0.07079, lr:6.96e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.723, tt:2847.311\n",
      "Ep:82, loss:0.00001, loss_test:0.07492, lr:6.89e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.715, tt:2881.330\n",
      "Ep:83, loss:0.00001, loss_test:0.07169, lr:6.83e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.688, tt:2913.777\n",
      "Ep:84, loss:0.00001, loss_test:0.07424, lr:6.76e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.682, tt:2948.008\n",
      "Ep:85, loss:0.00001, loss_test:0.07198, lr:6.69e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.677, tt:2982.216\n",
      "Ep:86, loss:0.00001, loss_test:0.07352, lr:6.62e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.678, tt:3017.023\n",
      "Ep:87, loss:0.00001, loss_test:0.07215, lr:6.56e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.681, tt:3051.934\n",
      "Ep:88, loss:0.00001, loss_test:0.07435, lr:6.49e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.675, tt:3086.072\n",
      "Ep:89, loss:0.00001, loss_test:0.07308, lr:6.43e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.669, tt:3120.203\n",
      "Ep:90, loss:0.00001, loss_test:0.07262, lr:6.36e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.677, tt:3155.595\n",
      "Ep:91, loss:0.00001, loss_test:0.07319, lr:6.30e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.666, tt:3189.287\n",
      "Ep:92, loss:0.00001, loss_test:0.07411, lr:6.24e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.666, tt:3223.926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00001, loss_test:0.07452, lr:6.17e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.654, tt:3257.485\n",
      "Ep:94, loss:0.00001, loss_test:0.07494, lr:6.11e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.655, tt:3292.204\n",
      "Ep:95, loss:0.00001, loss_test:0.07386, lr:6.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.647, tt:3326.127\n",
      "Ep:96, loss:0.00001, loss_test:0.07447, lr:5.99e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.651, tt:3361.154\n",
      "Ep:97, loss:0.00001, loss_test:0.07611, lr:5.93e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.656, tt:3396.321\n",
      "Ep:98, loss:0.00001, loss_test:0.07232, lr:5.87e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.657, tt:3431.084\n",
      "Ep:99, loss:0.00001, loss_test:0.07910, lr:5.81e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.652, tt:3465.200\n",
      "Ep:100, loss:0.00001, loss_test:0.07511, lr:5.75e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.647, tt:3499.396\n",
      "Ep:101, loss:0.00001, loss_test:0.07451, lr:5.70e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.631, tt:3532.374\n",
      "Ep:102, loss:0.00001, loss_test:0.07505, lr:5.64e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.611, tt:3564.984\n",
      "Ep:103, loss:0.00001, loss_test:0.07482, lr:5.58e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.625, tt:3600.988\n",
      "Ep:104, loss:0.00001, loss_test:0.07595, lr:5.53e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.614, tt:3634.491\n",
      "Ep:105, loss:0.00001, loss_test:0.07434, lr:5.47e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.620, tt:3669.757\n",
      "Ep:106, loss:0.00001, loss_test:0.07445, lr:5.42e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.624, tt:3704.753\n",
      "Ep:107, loss:0.00001, loss_test:0.07570, lr:5.36e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.617, tt:3738.652\n",
      "Ep:108, loss:0.00001, loss_test:0.07506, lr:5.31e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.615, tt:3773.023\n",
      "Ep:109, loss:0.00001, loss_test:0.07592, lr:5.26e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.604, tt:3806.398\n",
      "Ep:110, loss:0.00001, loss_test:0.07520, lr:5.20e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.603, tt:3840.929\n",
      "Ep:111, loss:0.00001, loss_test:0.07587, lr:5.15e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.582, tt:3873.232\n",
      "Ep:112, loss:0.00001, loss_test:0.07821, lr:5.10e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.579, tt:3907.443\n",
      "Ep:113, loss:0.00001, loss_test:0.07495, lr:5.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.582, tt:3942.324\n",
      "Ep:114, loss:0.00001, loss_test:0.07701, lr:5.00e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.579, tt:3976.639\n",
      "Ep:115, loss:0.00001, loss_test:0.07753, lr:4.95e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.541, tt:4006.762\n",
      "Ep:116, loss:0.00001, loss_test:0.07385, lr:4.90e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.514, tt:4038.136\n",
      "Ep:117, loss:0.00001, loss_test:0.07778, lr:4.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.466, tt:4067.040\n",
      "Ep:118, loss:0.00001, loss_test:0.07790, lr:4.80e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.430, tt:4097.210\n",
      "Ep:119, loss:0.00001, loss_test:0.07479, lr:4.75e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.392, tt:4127.088\n",
      "Ep:120, loss:0.00001, loss_test:0.07703, lr:4.71e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.355, tt:4156.996\n",
      "Ep:121, loss:0.00001, loss_test:0.07698, lr:4.66e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.334, tt:4188.758\n",
      "Ep:122, loss:0.00001, loss_test:0.07493, lr:4.61e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.319, tt:4221.226\n",
      "Ep:123, loss:0.00001, loss_test:0.07644, lr:4.57e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.262, tt:4248.541\n",
      "Ep:124, loss:0.00001, loss_test:0.07643, lr:4.52e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.236, tt:4279.457\n",
      "Ep:125, loss:0.00001, loss_test:0.07523, lr:4.48e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.222, tt:4311.940\n",
      "Ep:126, loss:0.00001, loss_test:0.07585, lr:4.43e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.185, tt:4341.506\n",
      "Ep:127, loss:0.00001, loss_test:0.07675, lr:4.39e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.145, tt:4370.496\n",
      "Ep:128, loss:0.00001, loss_test:0.07668, lr:4.34e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.127, tt:4402.415\n",
      "Ep:129, loss:0.00000, loss_test:0.07581, lr:4.30e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.104, tt:4433.459\n",
      "Ep:130, loss:0.00000, loss_test:0.07716, lr:4.26e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.099, tt:4466.993\n",
      "Ep:131, loss:0.00000, loss_test:0.07712, lr:4.21e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.080, tt:4498.619\n",
      "Ep:132, loss:0.00000, loss_test:0.07544, lr:4.17e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.052, tt:4528.855\n",
      "Ep:133, loss:0.00000, loss_test:0.07770, lr:4.13e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.040, tt:4561.343\n",
      "Ep:134, loss:0.00000, loss_test:0.07641, lr:4.09e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.028, tt:4593.790\n",
      "Ep:135, loss:0.00000, loss_test:0.07556, lr:4.05e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.015, tt:4626.026\n",
      "Ep:136, loss:0.00000, loss_test:0.07703, lr:4.01e-03, fs:0.73292 (r=0.596,p=0.952),  time:34.000, tt:4658.033\n",
      "Ep:137, loss:0.00000, loss_test:0.07549, lr:3.97e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.977, tt:4688.879\n",
      "Ep:138, loss:0.00000, loss_test:0.07770, lr:3.93e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.961, tt:4720.537\n",
      "Ep:139, loss:0.00000, loss_test:0.08003, lr:3.89e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.953, tt:4753.379\n",
      "Ep:140, loss:0.00000, loss_test:0.07726, lr:3.85e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.927, tt:4783.747\n",
      "Ep:141, loss:0.00000, loss_test:0.07611, lr:3.81e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.915, tt:4815.990\n",
      "Ep:142, loss:0.00000, loss_test:0.07698, lr:3.77e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.909, tt:4848.933\n",
      "Ep:143, loss:0.00000, loss_test:0.07664, lr:3.73e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.904, tt:4882.215\n",
      "Ep:144, loss:0.00000, loss_test:0.07751, lr:3.70e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.890, tt:4914.010\n",
      "Ep:145, loss:0.00000, loss_test:0.07804, lr:3.66e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.872, tt:4945.345\n",
      "Ep:146, loss:0.00000, loss_test:0.07631, lr:3.62e-03, fs:0.73292 (r=0.596,p=0.952),  time:33.850, tt:4976.017\n",
      "Ep:147, loss:0.00000, loss_test:0.07652, lr:3.59e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.833, tt:5007.268\n",
      "Ep:148, loss:0.00000, loss_test:0.07783, lr:3.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.815, tt:5038.411\n",
      "Ep:149, loss:0.00000, loss_test:0.07691, lr:3.52e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.789, tt:5068.335\n",
      "Ep:150, loss:0.00000, loss_test:0.07584, lr:3.48e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.764, tt:5098.440\n",
      "Ep:151, loss:0.00000, loss_test:0.07867, lr:3.45e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.737, tt:5127.952\n",
      "Ep:152, loss:0.00000, loss_test:0.07741, lr:3.41e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.722, tt:5159.470\n",
      "Ep:153, loss:0.00000, loss_test:0.07602, lr:3.38e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.705, tt:5190.590\n",
      "Ep:154, loss:0.00000, loss_test:0.07773, lr:3.34e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.688, tt:5221.717\n",
      "Ep:155, loss:0.00000, loss_test:0.07822, lr:3.31e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.671, tt:5252.675\n",
      "Ep:156, loss:0.00000, loss_test:0.07602, lr:3.28e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.667, tt:5285.643\n",
      "Ep:157, loss:0.00000, loss_test:0.07729, lr:3.24e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.651, tt:5316.814\n",
      "Ep:158, loss:0.00000, loss_test:0.07921, lr:3.21e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.630, tt:5347.188\n",
      "Ep:159, loss:0.00000, loss_test:0.07796, lr:3.18e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.615, tt:5378.339\n",
      "Ep:160, loss:0.00000, loss_test:0.07665, lr:3.15e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.597, tt:5409.098\n",
      "Ep:161, loss:0.00000, loss_test:0.07698, lr:3.12e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.577, tt:5439.490\n",
      "Ep:162, loss:0.00000, loss_test:0.07696, lr:3.09e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.568, tt:5471.607\n",
      "Ep:163, loss:0.00000, loss_test:0.07647, lr:3.05e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.554, tt:5502.938\n",
      "Ep:164, loss:0.00000, loss_test:0.07739, lr:3.02e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.540, tt:5534.171\n",
      "Ep:165, loss:0.00000, loss_test:0.07774, lr:2.99e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.531, tt:5566.198\n",
      "Ep:166, loss:0.00000, loss_test:0.07625, lr:2.96e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.518, tt:5597.485\n",
      "Ep:167, loss:0.00000, loss_test:0.07642, lr:2.93e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.517, tt:5630.880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:168, loss:0.00000, loss_test:0.07771, lr:2.90e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.511, tt:5663.386\n",
      "Ep:169, loss:0.00000, loss_test:0.07686, lr:2.88e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.506, tt:5695.942\n",
      "Ep:170, loss:0.00000, loss_test:0.07586, lr:2.85e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.497, tt:5727.995\n",
      "Ep:171, loss:0.00000, loss_test:0.07687, lr:2.82e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.485, tt:5759.412\n",
      "Ep:172, loss:0.00000, loss_test:0.07754, lr:2.79e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.470, tt:5790.367\n",
      "Ep:173, loss:0.00000, loss_test:0.07646, lr:2.76e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.452, tt:5820.597\n",
      "Ep:174, loss:0.00000, loss_test:0.07696, lr:2.73e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.445, tt:5852.871\n",
      "Ep:175, loss:0.00000, loss_test:0.07785, lr:2.71e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.440, tt:5885.389\n",
      "Ep:176, loss:0.00000, loss_test:0.07687, lr:2.68e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.423, tt:5915.808\n",
      "Ep:177, loss:0.00000, loss_test:0.07652, lr:2.65e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.411, tt:5947.082\n",
      "Ep:178, loss:0.00000, loss_test:0.07699, lr:2.63e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.401, tt:5978.721\n",
      "Ep:179, loss:0.00000, loss_test:0.07704, lr:2.60e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.390, tt:6010.156\n",
      "Ep:180, loss:0.00000, loss_test:0.07625, lr:2.57e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.376, tt:6041.047\n",
      "Ep:181, loss:0.00000, loss_test:0.07688, lr:2.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.373, tt:6073.810\n",
      "Ep:182, loss:0.00000, loss_test:0.07692, lr:2.52e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.367, tt:6106.241\n",
      "Ep:183, loss:0.00000, loss_test:0.07684, lr:2.50e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.354, tt:6137.173\n",
      "Ep:184, loss:0.00000, loss_test:0.07693, lr:2.47e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.340, tt:6167.856\n",
      "Ep:185, loss:0.00000, loss_test:0.07670, lr:2.45e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.328, tt:6198.983\n",
      "Ep:186, loss:0.00000, loss_test:0.07672, lr:2.42e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.318, tt:6230.402\n",
      "Ep:187, loss:0.00000, loss_test:0.07667, lr:2.40e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.301, tt:6260.629\n",
      "Ep:188, loss:0.00000, loss_test:0.07660, lr:2.38e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.298, tt:6293.272\n",
      "Ep:189, loss:0.00000, loss_test:0.07678, lr:2.35e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.285, tt:6324.136\n",
      "Ep:190, loss:0.00000, loss_test:0.07619, lr:2.33e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.288, tt:6358.030\n",
      "Ep:191, loss:0.00000, loss_test:0.07783, lr:2.31e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.287, tt:6391.182\n",
      "Ep:192, loss:0.00000, loss_test:0.07743, lr:2.28e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.280, tt:6423.017\n",
      "Ep:193, loss:0.00000, loss_test:0.07654, lr:2.26e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.265, tt:6453.452\n",
      "Ep:194, loss:0.00000, loss_test:0.07672, lr:2.24e-03, fs:0.73750 (r=0.596,p=0.967),  time:33.262, tt:6486.083\n",
      "Ep:195, loss:0.00000, loss_test:0.07778, lr:2.21e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.259, tt:6518.777\n",
      "Ep:196, loss:0.00000, loss_test:0.07751, lr:2.19e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.224, tt:6545.147\n",
      "Ep:197, loss:0.00000, loss_test:0.07643, lr:2.17e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.191, tt:6571.742\n",
      "Ep:198, loss:0.00000, loss_test:0.07669, lr:2.15e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.159, tt:6598.726\n",
      "Ep:199, loss:0.00000, loss_test:0.07720, lr:2.13e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.110, tt:6621.922\n",
      "Ep:200, loss:0.00000, loss_test:0.07680, lr:2.11e-03, fs:0.74214 (r=0.596,p=0.983),  time:33.023, tt:6637.598\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN5\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,202,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT_SIMPLE_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext_600_300\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,201,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02286, lr:6.00e-02, fs:0.63025 (r=0.862,p=0.497),  time:31.258, tt:31.258\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02396, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.623, tt:71.246\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02470, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.792, tt:113.376\n",
      "Ep:3, loss:0.00005, loss_test:0.02401, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.315, tt:153.259\n",
      "Ep:4, loss:0.00004, loss_test:0.02277, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.928, tt:194.639\n",
      "Ep:5, loss:0.00004, loss_test:0.02168, lr:6.00e-02, fs:0.65354 (r=0.954,p=0.497),  time:39.236, tt:235.415\n",
      "Ep:6, loss:0.00004, loss_test:0.02151, lr:6.00e-02, fs:0.63636 (r=0.805,p=0.526),  time:39.239, tt:274.670\n",
      "Ep:7, loss:0.00004, loss_test:0.02190, lr:6.00e-02, fs:0.60914 (r=0.690,p=0.545),  time:39.654, tt:317.236\n",
      "Ep:8, loss:0.00003, loss_test:0.02115, lr:6.00e-02, fs:0.61538 (r=0.690,p=0.556),  time:39.857, tt:358.710\n",
      "Ep:9, loss:0.00003, loss_test:0.01994, lr:6.00e-02, fs:0.67281 (r=0.839,p=0.562),  time:40.008, tt:400.077\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01922, lr:6.00e-02, fs:0.69264 (r=0.920,p=0.556),  time:40.041, tt:440.448\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01870, lr:6.00e-02, fs:0.70085 (r=0.943,p=0.558),  time:40.005, tt:480.065\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01822, lr:6.00e-02, fs:0.71366 (r=0.931,p=0.579),  time:40.052, tt:520.679\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:40.095, tt:561.335\n",
      "Ep:14, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.70531 (r=0.839,p=0.608),  time:40.169, tt:602.530\n",
      "Ep:15, loss:0.00003, loss_test:0.01739, lr:6.00e-02, fs:0.71569 (r=0.839,p=0.624),  time:40.178, tt:642.841\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01692, lr:6.00e-02, fs:0.73077 (r=0.874,p=0.628),  time:40.236, tt:684.020\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01654, lr:6.00e-02, fs:0.74286 (r=0.897,p=0.634),  time:40.312, tt:725.624\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.74286 (r=0.897,p=0.634),  time:40.272, tt:765.172\n",
      "Ep:19, loss:0.00003, loss_test:0.01606, lr:6.00e-02, fs:0.74882 (r=0.908,p=0.637),  time:40.337, tt:806.731\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:40.352, tt:847.386\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01570, lr:6.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:40.332, tt:887.294\n",
      "Ep:22, loss:0.00002, loss_test:0.01551, lr:6.00e-02, fs:0.76699 (r=0.908,p=0.664),  time:40.386, tt:928.880\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01537, lr:6.00e-02, fs:0.78049 (r=0.920,p=0.678),  time:40.572, tt:973.740\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01526, lr:6.00e-02, fs:0.78049 (r=0.920,p=0.678),  time:40.637, tt:1015.932\n",
      "Ep:25, loss:0.00002, loss_test:0.01515, lr:6.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:40.675, tt:1057.543\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01496, lr:6.00e-02, fs:0.79208 (r=0.920,p=0.696),  time:40.691, tt:1098.664\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01479, lr:6.00e-02, fs:0.79803 (r=0.931,p=0.698),  time:40.694, tt:1139.439\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01458, lr:6.00e-02, fs:0.80198 (r=0.931,p=0.704),  time:40.727, tt:1181.081\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.82178 (r=0.954,p=0.722),  time:40.765, tt:1222.952\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.82178 (r=0.954,p=0.722),  time:40.782, tt:1264.250\n",
      "Ep:31, loss:0.00002, loss_test:0.01424, lr:6.00e-02, fs:0.82587 (r=0.954,p=0.728),  time:40.775, tt:1304.792\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01410, lr:6.00e-02, fs:0.83168 (r=0.966,p=0.730),  time:40.793, tt:1346.168\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.84422 (r=0.966,p=0.750),  time:40.839, tt:1388.517\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.85714 (r=0.966,p=0.771),  time:40.871, tt:1430.488\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01384, lr:6.00e-02, fs:0.86735 (r=0.977,p=0.780),  time:40.932, tt:1473.544\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.87179 (r=0.977,p=0.787),  time:41.000, tt:1517.003\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.87179 (r=0.977,p=0.787),  time:41.036, tt:1559.375\n",
      "Ep:38, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.87179 (r=0.977,p=0.787),  time:41.002, tt:1599.091\n",
      "Ep:39, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.87629 (r=0.977,p=0.794),  time:41.029, tt:1641.146\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.88083 (r=0.977,p=0.802),  time:41.013, tt:1681.538\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01332, lr:6.00e-02, fs:0.88542 (r=0.977,p=0.810),  time:41.079, tt:1725.304\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00001, loss_test:0.01327, lr:6.00e-02, fs:0.89005 (r=0.977,p=0.817),  time:41.100, tt:1767.281\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01325, lr:6.00e-02, fs:0.88889 (r=0.966,p=0.824),  time:41.137, tt:1810.020\n",
      "Ep:44, loss:0.00001, loss_test:0.01319, lr:6.00e-02, fs:0.89362 (r=0.966,p=0.832),  time:41.150, tt:1851.732\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01320, lr:6.00e-02, fs:0.89362 (r=0.966,p=0.832),  time:41.179, tt:1894.222\n",
      "Ep:46, loss:0.00001, loss_test:0.01316, lr:6.00e-02, fs:0.88770 (r=0.954,p=0.830),  time:41.171, tt:1935.054\n",
      "Ep:47, loss:0.00001, loss_test:0.01314, lr:6.00e-02, fs:0.88649 (r=0.943,p=0.837),  time:41.172, tt:1976.265\n",
      "Ep:48, loss:0.00001, loss_test:0.01312, lr:6.00e-02, fs:0.88525 (r=0.931,p=0.844),  time:41.197, tt:2018.670\n",
      "Ep:49, loss:0.00001, loss_test:0.01308, lr:6.00e-02, fs:0.88525 (r=0.931,p=0.844),  time:41.184, tt:2059.196\n",
      "Ep:50, loss:0.00001, loss_test:0.01309, lr:6.00e-02, fs:0.88525 (r=0.931,p=0.844),  time:41.235, tt:2102.975\n",
      "Ep:51, loss:0.00001, loss_test:0.01314, lr:6.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:41.250, tt:2144.989\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00001, loss_test:0.01310, lr:6.00e-02, fs:0.89503 (r=0.931,p=0.862),  time:41.255, tt:2186.526\n",
      "Ep:53, loss:0.00001, loss_test:0.01313, lr:6.00e-02, fs:0.88268 (r=0.908,p=0.859),  time:41.243, tt:2227.124\n",
      "Ep:54, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:41.251, tt:2268.791\n",
      "Ep:55, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:41.286, tt:2312.007\n",
      "Ep:56, loss:0.00001, loss_test:0.01324, lr:6.00e-02, fs:0.87006 (r=0.885,p=0.856),  time:41.282, tt:2353.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00001, loss_test:0.01329, lr:6.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:41.298, tt:2395.273\n",
      "Ep:58, loss:0.00001, loss_test:0.01331, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:41.243, tt:2433.309\n",
      "Ep:59, loss:0.00001, loss_test:0.01326, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:41.232, tt:2473.929\n",
      "Ep:60, loss:0.00001, loss_test:0.01335, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:41.259, tt:2516.775\n",
      "Ep:61, loss:0.00001, loss_test:0.01335, lr:6.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:41.230, tt:2556.274\n",
      "Ep:62, loss:0.00001, loss_test:0.01339, lr:6.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.203, tt:2595.779\n",
      "Ep:63, loss:0.00001, loss_test:0.01340, lr:5.94e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.191, tt:2636.226\n",
      "Ep:64, loss:0.00001, loss_test:0.01344, lr:5.88e-02, fs:0.83529 (r=0.816,p=0.855),  time:41.173, tt:2676.249\n",
      "Ep:65, loss:0.00001, loss_test:0.01346, lr:5.82e-02, fs:0.82840 (r=0.805,p=0.854),  time:41.152, tt:2716.036\n",
      "Ep:66, loss:0.00001, loss_test:0.01354, lr:5.76e-02, fs:0.82635 (r=0.793,p=0.863),  time:41.152, tt:2757.215\n",
      "Ep:67, loss:0.00001, loss_test:0.01356, lr:5.71e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.153, tt:2798.413\n",
      "Ep:68, loss:0.00001, loss_test:0.01356, lr:5.65e-02, fs:0.80488 (r=0.759,p=0.857),  time:41.135, tt:2838.323\n",
      "Ep:69, loss:0.00001, loss_test:0.01361, lr:5.59e-02, fs:0.79012 (r=0.736,p=0.853),  time:41.120, tt:2878.394\n",
      "Ep:70, loss:0.00001, loss_test:0.01366, lr:5.54e-02, fs:0.78261 (r=0.724,p=0.851),  time:41.103, tt:2918.293\n",
      "Ep:71, loss:0.00001, loss_test:0.01369, lr:5.48e-02, fs:0.79503 (r=0.736,p=0.865),  time:41.090, tt:2958.514\n",
      "Ep:72, loss:0.00001, loss_test:0.01375, lr:5.43e-02, fs:0.77987 (r=0.713,p=0.861),  time:41.093, tt:2999.804\n",
      "Ep:73, loss:0.00001, loss_test:0.01376, lr:5.37e-02, fs:0.77987 (r=0.713,p=0.861),  time:41.092, tt:3040.833\n",
      "Ep:74, loss:0.00001, loss_test:0.01379, lr:5.32e-02, fs:0.77215 (r=0.701,p=0.859),  time:41.078, tt:3080.873\n",
      "Ep:75, loss:0.00001, loss_test:0.01387, lr:5.27e-02, fs:0.77215 (r=0.701,p=0.859),  time:41.056, tt:3120.244\n",
      "Ep:76, loss:0.00001, loss_test:0.01390, lr:5.21e-02, fs:0.77215 (r=0.701,p=0.859),  time:41.045, tt:3160.442\n",
      "Ep:77, loss:0.00001, loss_test:0.01388, lr:5.16e-02, fs:0.77215 (r=0.701,p=0.859),  time:41.051, tt:3201.940\n",
      "Ep:78, loss:0.00001, loss_test:0.01391, lr:5.11e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.043, tt:3242.372\n",
      "Ep:79, loss:0.00001, loss_test:0.01397, lr:5.06e-02, fs:0.76923 (r=0.690,p=0.870),  time:41.032, tt:3282.539\n",
      "Ep:80, loss:0.00001, loss_test:0.01404, lr:5.01e-02, fs:0.75325 (r=0.667,p=0.866),  time:41.036, tt:3323.898\n",
      "Ep:81, loss:0.00001, loss_test:0.01405, lr:4.96e-02, fs:0.75325 (r=0.667,p=0.866),  time:41.024, tt:3363.953\n",
      "Ep:82, loss:0.00001, loss_test:0.01409, lr:4.91e-02, fs:0.75325 (r=0.667,p=0.866),  time:41.016, tt:3404.317\n",
      "Ep:83, loss:0.00001, loss_test:0.01415, lr:4.86e-02, fs:0.75325 (r=0.667,p=0.866),  time:40.994, tt:3443.531\n",
      "Ep:84, loss:0.00001, loss_test:0.01417, lr:4.81e-02, fs:0.75325 (r=0.667,p=0.866),  time:41.017, tt:3486.415\n",
      "Ep:85, loss:0.00001, loss_test:0.01427, lr:4.76e-02, fs:0.75817 (r=0.667,p=0.879),  time:41.144, tt:3538.382\n",
      "Ep:86, loss:0.00001, loss_test:0.01433, lr:4.71e-02, fs:0.75817 (r=0.667,p=0.879),  time:41.147, tt:3579.785\n",
      "Ep:87, loss:0.00001, loss_test:0.01434, lr:4.67e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.154, tt:3621.528\n",
      "Ep:88, loss:0.00001, loss_test:0.01439, lr:4.62e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.165, tt:3663.698\n",
      "Ep:89, loss:0.00001, loss_test:0.01448, lr:4.57e-02, fs:0.75497 (r=0.655,p=0.891),  time:41.175, tt:3705.732\n",
      "Ep:90, loss:0.00001, loss_test:0.01449, lr:4.53e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.175, tt:3746.941\n",
      "Ep:91, loss:0.00001, loss_test:0.01453, lr:4.48e-02, fs:0.75497 (r=0.655,p=0.891),  time:41.179, tt:3788.496\n",
      "Ep:92, loss:0.00001, loss_test:0.01458, lr:4.44e-02, fs:0.75497 (r=0.655,p=0.891),  time:41.179, tt:3829.693\n",
      "Ep:93, loss:0.00001, loss_test:0.01461, lr:4.39e-02, fs:0.74667 (r=0.644,p=0.889),  time:41.175, tt:3870.445\n",
      "Ep:94, loss:0.00001, loss_test:0.01462, lr:4.35e-02, fs:0.75497 (r=0.655,p=0.891),  time:41.169, tt:3911.094\n",
      "Ep:95, loss:0.00001, loss_test:0.01464, lr:4.31e-02, fs:0.76316 (r=0.667,p=0.892),  time:41.172, tt:3952.474\n",
      "Ep:96, loss:0.00001, loss_test:0.01477, lr:4.26e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.174, tt:3993.880\n",
      "Ep:97, loss:0.00001, loss_test:0.01478, lr:4.22e-02, fs:0.72973 (r=0.621,p=0.885),  time:41.184, tt:4035.988\n",
      "Ep:98, loss:0.00001, loss_test:0.01480, lr:4.18e-02, fs:0.75168 (r=0.644,p=0.903),  time:41.168, tt:4075.611\n",
      "Ep:99, loss:0.00001, loss_test:0.01489, lr:4.14e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.169, tt:4116.885\n",
      "Ep:100, loss:0.00000, loss_test:0.01489, lr:4.10e-02, fs:0.74830 (r=0.632,p=0.917),  time:41.169, tt:4158.057\n",
      "Ep:101, loss:0.00000, loss_test:0.01493, lr:4.05e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.172, tt:4199.499\n",
      "Ep:102, loss:0.00000, loss_test:0.01496, lr:4.01e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.159, tt:4239.388\n",
      "Ep:103, loss:0.00000, loss_test:0.01499, lr:3.97e-02, fs:0.73973 (r=0.621,p=0.915),  time:41.153, tt:4279.907\n",
      "Ep:104, loss:0.00000, loss_test:0.01507, lr:3.93e-02, fs:0.72727 (r=0.598,p=0.929),  time:41.143, tt:4320.015\n",
      "Ep:105, loss:0.00000, loss_test:0.01508, lr:3.89e-02, fs:0.73103 (r=0.609,p=0.914),  time:41.134, tt:4360.206\n",
      "Ep:106, loss:0.00000, loss_test:0.01512, lr:3.86e-02, fs:0.72727 (r=0.598,p=0.929),  time:41.129, tt:4400.789\n",
      "Ep:107, loss:0.00000, loss_test:0.01514, lr:3.82e-02, fs:0.72727 (r=0.598,p=0.929),  time:41.126, tt:4441.600\n",
      "Ep:108, loss:0.00000, loss_test:0.01514, lr:3.78e-02, fs:0.73611 (r=0.609,p=0.930),  time:41.102, tt:4480.090\n",
      "Ep:109, loss:0.00000, loss_test:0.01519, lr:3.74e-02, fs:0.72727 (r=0.598,p=0.929),  time:41.107, tt:4521.757\n",
      "Ep:110, loss:0.00000, loss_test:0.01521, lr:3.70e-02, fs:0.72727 (r=0.598,p=0.929),  time:41.093, tt:4561.299\n",
      "Ep:111, loss:0.00000, loss_test:0.01528, lr:3.67e-02, fs:0.73239 (r=0.598,p=0.945),  time:41.091, tt:4602.199\n",
      "Ep:112, loss:0.00000, loss_test:0.01535, lr:3.63e-02, fs:0.73239 (r=0.598,p=0.945),  time:41.102, tt:4644.519\n",
      "Ep:113, loss:0.00000, loss_test:0.01537, lr:3.59e-02, fs:0.73239 (r=0.598,p=0.945),  time:41.111, tt:4686.701\n",
      "Ep:114, loss:0.00000, loss_test:0.01539, lr:3.56e-02, fs:0.71429 (r=0.575,p=0.943),  time:41.103, tt:4726.848\n",
      "Ep:115, loss:0.00000, loss_test:0.01540, lr:3.52e-02, fs:0.72340 (r=0.586,p=0.944),  time:41.096, tt:4767.174\n",
      "Ep:116, loss:0.00000, loss_test:0.01547, lr:3.49e-02, fs:0.72340 (r=0.586,p=0.944),  time:41.099, tt:4808.528\n",
      "Ep:117, loss:0.00000, loss_test:0.01548, lr:3.45e-02, fs:0.72340 (r=0.586,p=0.944),  time:41.105, tt:4850.411\n",
      "Ep:118, loss:0.00000, loss_test:0.01551, lr:3.42e-02, fs:0.71429 (r=0.575,p=0.943),  time:41.100, tt:4890.846\n",
      "Ep:119, loss:0.00000, loss_test:0.01553, lr:3.38e-02, fs:0.72340 (r=0.586,p=0.944),  time:41.090, tt:4930.845\n",
      "Ep:120, loss:0.00000, loss_test:0.01559, lr:3.35e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.081, tt:4970.860\n",
      "Ep:121, loss:0.00000, loss_test:0.01564, lr:3.32e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.084, tt:5012.222\n",
      "Ep:122, loss:0.00000, loss_test:0.01566, lr:3.28e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.107, tt:5056.117\n",
      "Ep:123, loss:0.00000, loss_test:0.01569, lr:3.25e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.111, tt:5097.788\n",
      "Ep:124, loss:0.00000, loss_test:0.01569, lr:3.22e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.112, tt:5138.995\n",
      "Ep:125, loss:0.00000, loss_test:0.01574, lr:3.19e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.110, tt:5179.822\n",
      "Ep:126, loss:0.00000, loss_test:0.01579, lr:3.15e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.145, tt:5225.394\n",
      "Ep:127, loss:0.00000, loss_test:0.01581, lr:3.12e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.140, tt:5265.885\n",
      "Ep:128, loss:0.00000, loss_test:0.01581, lr:3.09e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.141, tt:5307.219\n",
      "Ep:129, loss:0.00000, loss_test:0.01585, lr:3.06e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.154, tt:5350.030\n",
      "Ep:130, loss:0.00000, loss_test:0.01589, lr:3.03e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.160, tt:5392.014\n",
      "Ep:131, loss:0.00000, loss_test:0.01593, lr:3.00e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.163, tt:5433.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:132, loss:0.00000, loss_test:0.01597, lr:2.97e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.160, tt:5474.299\n",
      "Ep:133, loss:0.00000, loss_test:0.01598, lr:2.94e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.166, tt:5516.225\n",
      "Ep:134, loss:0.00000, loss_test:0.01598, lr:2.91e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.168, tt:5557.630\n",
      "Ep:135, loss:0.00000, loss_test:0.01606, lr:2.88e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.175, tt:5599.805\n",
      "Ep:136, loss:0.00000, loss_test:0.01607, lr:2.85e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.178, tt:5641.421\n",
      "Ep:137, loss:0.00000, loss_test:0.01606, lr:2.82e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.170, tt:5681.519\n",
      "Ep:138, loss:0.00000, loss_test:0.01610, lr:2.80e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.159, tt:5721.156\n",
      "Ep:139, loss:0.00000, loss_test:0.01615, lr:2.77e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.161, tt:5762.595\n",
      "Ep:140, loss:0.00000, loss_test:0.01615, lr:2.74e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.162, tt:5803.807\n",
      "Ep:141, loss:0.00000, loss_test:0.01615, lr:2.71e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.157, tt:5844.270\n",
      "Ep:142, loss:0.00000, loss_test:0.01620, lr:2.69e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.160, tt:5885.937\n",
      "Ep:143, loss:0.00000, loss_test:0.01620, lr:2.66e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.168, tt:5928.151\n",
      "Ep:144, loss:0.00000, loss_test:0.01624, lr:2.63e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.169, tt:5969.565\n",
      "Ep:145, loss:0.00000, loss_test:0.01625, lr:2.61e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.187, tt:6013.324\n",
      "Ep:146, loss:0.00000, loss_test:0.01629, lr:2.58e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.194, tt:6055.505\n",
      "Ep:147, loss:0.00000, loss_test:0.01631, lr:2.55e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.233, tt:6102.464\n",
      "Ep:148, loss:0.00000, loss_test:0.01633, lr:2.53e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.226, tt:6142.639\n",
      "Ep:149, loss:0.00000, loss_test:0.01634, lr:2.50e-02, fs:0.69565 (r=0.552,p=0.941),  time:41.221, tt:6183.173\n",
      "Ep:150, loss:0.00000, loss_test:0.01639, lr:2.48e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.228, tt:6225.440\n",
      "Ep:151, loss:0.00000, loss_test:0.01640, lr:2.45e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.229, tt:6266.826\n",
      "Ep:152, loss:0.00000, loss_test:0.01642, lr:2.43e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.240, tt:6309.745\n",
      "Ep:153, loss:0.00000, loss_test:0.01645, lr:2.40e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.247, tt:6352.016\n",
      "Ep:154, loss:0.00000, loss_test:0.01645, lr:2.38e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.262, tt:6395.652\n",
      "Ep:155, loss:0.00000, loss_test:0.01648, lr:2.36e-02, fs:0.68613 (r=0.540,p=0.940),  time:41.265, tt:6437.278\n",
      "Ep:156, loss:0.00000, loss_test:0.01650, lr:2.33e-02, fs:0.67647 (r=0.529,p=0.939),  time:41.256, tt:6477.138\n",
      "Ep:157, loss:0.00000, loss_test:0.01652, lr:2.31e-02, fs:0.66667 (r=0.517,p=0.938),  time:41.252, tt:6517.830\n",
      "Ep:158, loss:0.00000, loss_test:0.01654, lr:2.29e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.262, tt:6560.685\n",
      "Ep:159, loss:0.00000, loss_test:0.01657, lr:2.26e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.268, tt:6602.807\n",
      "Ep:160, loss:0.00000, loss_test:0.01659, lr:2.24e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.276, tt:6645.502\n",
      "Ep:161, loss:0.00000, loss_test:0.01660, lr:2.22e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.264, tt:6684.736\n",
      "Ep:162, loss:0.00000, loss_test:0.01662, lr:2.20e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.267, tt:6726.459\n",
      "Ep:163, loss:0.00000, loss_test:0.01665, lr:2.17e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.267, tt:6767.869\n",
      "Ep:164, loss:0.00000, loss_test:0.01665, lr:2.15e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.271, tt:6809.733\n",
      "Ep:165, loss:0.00000, loss_test:0.01667, lr:2.13e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.268, tt:6850.491\n",
      "Ep:166, loss:0.00000, loss_test:0.01670, lr:2.11e-02, fs:0.65672 (r=0.506,p=0.936),  time:41.261, tt:6890.615\n",
      "Ep:167, loss:0.00000, loss_test:0.01670, lr:2.09e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.263, tt:6932.222\n",
      "Ep:168, loss:0.00000, loss_test:0.01673, lr:2.07e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.269, tt:6974.483\n",
      "Ep:169, loss:0.00000, loss_test:0.01676, lr:2.05e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.274, tt:7016.557\n",
      "Ep:170, loss:0.00000, loss_test:0.01676, lr:2.03e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.270, tt:7057.155\n",
      "Ep:171, loss:0.00000, loss_test:0.01676, lr:2.01e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.272, tt:7098.730\n",
      "Ep:172, loss:0.00000, loss_test:0.01678, lr:1.99e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.273, tt:7140.211\n",
      "Ep:173, loss:0.00000, loss_test:0.01681, lr:1.97e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.280, tt:7182.759\n",
      "Ep:174, loss:0.00000, loss_test:0.01680, lr:1.95e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.282, tt:7224.346\n",
      "Ep:175, loss:0.00000, loss_test:0.01682, lr:1.93e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.286, tt:7266.409\n",
      "Ep:176, loss:0.00000, loss_test:0.01685, lr:1.91e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.281, tt:7306.703\n",
      "Ep:177, loss:0.00000, loss_test:0.01688, lr:1.89e-02, fs:0.64662 (r=0.494,p=0.935),  time:41.280, tt:7347.846\n",
      "Ep:178, loss:0.00000, loss_test:0.01689, lr:1.87e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.271, tt:7387.429\n",
      "Ep:179, loss:0.00000, loss_test:0.01691, lr:1.85e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.270, tt:7428.606\n",
      "Ep:180, loss:0.00000, loss_test:0.01693, lr:1.83e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.270, tt:7469.836\n",
      "Ep:181, loss:0.00000, loss_test:0.01695, lr:1.81e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.263, tt:7509.944\n",
      "Ep:182, loss:0.00000, loss_test:0.01694, lr:1.80e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.259, tt:7550.435\n",
      "Ep:183, loss:0.00000, loss_test:0.01696, lr:1.78e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.262, tt:7592.159\n",
      "Ep:184, loss:0.00000, loss_test:0.01697, lr:1.76e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.264, tt:7633.902\n",
      "Ep:185, loss:0.00000, loss_test:0.01698, lr:1.74e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.261, tt:7674.621\n",
      "Ep:186, loss:0.00000, loss_test:0.01701, lr:1.73e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.263, tt:7716.220\n",
      "Ep:187, loss:0.00000, loss_test:0.01703, lr:1.71e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.261, tt:7757.015\n",
      "Ep:188, loss:0.00000, loss_test:0.01702, lr:1.69e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.299, tt:7805.570\n",
      "Ep:189, loss:0.00000, loss_test:0.01704, lr:1.67e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.291, tt:7845.309\n",
      "Ep:190, loss:0.00000, loss_test:0.01707, lr:1.66e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.287, tt:7885.847\n",
      "Ep:191, loss:0.00000, loss_test:0.01708, lr:1.64e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.281, tt:7925.877\n",
      "Ep:192, loss:0.00000, loss_test:0.01707, lr:1.62e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.280, tt:7967.131\n",
      "Ep:193, loss:0.00000, loss_test:0.01709, lr:1.61e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.284, tt:8009.016\n",
      "Ep:194, loss:0.00000, loss_test:0.01710, lr:1.59e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.280, tt:8049.594\n",
      "Ep:195, loss:0.00000, loss_test:0.01713, lr:1.58e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.281, tt:8091.053\n",
      "Ep:196, loss:0.00000, loss_test:0.01715, lr:1.56e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.264, tt:8128.912\n",
      "Ep:197, loss:0.00000, loss_test:0.01716, lr:1.54e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.259, tt:8169.204\n",
      "Ep:198, loss:0.00000, loss_test:0.01717, lr:1.53e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.251, tt:8208.951\n",
      "Ep:199, loss:0.00000, loss_test:0.01717, lr:1.51e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.244, tt:8248.828\n",
      "Ep:200, loss:0.00000, loss_test:0.01719, lr:1.50e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.235, tt:8288.310\n",
      "Ep:201, loss:0.00000, loss_test:0.01721, lr:1.48e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.224, tt:8327.201\n",
      "Ep:202, loss:0.00000, loss_test:0.01722, lr:1.47e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.224, tt:8368.464\n",
      "Ep:203, loss:0.00000, loss_test:0.01724, lr:1.45e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.220, tt:8408.830\n",
      "Ep:204, loss:0.00000, loss_test:0.01724, lr:1.44e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.217, tt:8449.565\n",
      "Ep:205, loss:0.00000, loss_test:0.01726, lr:1.43e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.216, tt:8490.495\n",
      "Ep:206, loss:0.00000, loss_test:0.01726, lr:1.41e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.211, tt:8530.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:207, loss:0.00000, loss_test:0.01728, lr:1.40e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.210, tt:8571.668\n",
      "Ep:208, loss:0.00000, loss_test:0.01728, lr:1.38e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.189, tt:8608.559\n",
      "Ep:209, loss:0.00000, loss_test:0.01729, lr:1.37e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.193, tt:8650.501\n",
      "Ep:210, loss:0.00000, loss_test:0.01731, lr:1.36e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.175, tt:8687.979\n",
      "Ep:211, loss:0.00000, loss_test:0.01732, lr:1.34e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.126, tt:8718.654\n",
      "Ep:212, loss:0.00000, loss_test:0.01734, lr:1.33e-02, fs:0.63636 (r=0.483,p=0.933),  time:41.109, tt:8756.297\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14914, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.282, tt:41.282\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14868, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.156, tt:82.311\n",
      "Ep:2, loss:0.00027, loss_test:0.14782, lr:1.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:41.569, tt:124.707\n",
      "Ep:3, loss:0.00027, loss_test:0.14611, lr:1.00e-02, fs:0.64286 (r=0.931,p=0.491),  time:42.284, tt:169.135\n",
      "Ep:4, loss:0.00025, loss_test:0.14235, lr:1.00e-02, fs:0.64681 (r=0.874,p=0.514),  time:42.196, tt:210.982\n",
      "Ep:5, loss:0.00024, loss_test:0.14008, lr:1.00e-02, fs:0.53039 (r=0.552,p=0.511),  time:42.010, tt:252.061\n",
      "Ep:6, loss:0.00022, loss_test:0.14216, lr:1.00e-02, fs:0.47742 (r=0.425,p=0.544),  time:42.623, tt:298.360\n",
      "Ep:7, loss:0.00022, loss_test:0.13538, lr:1.00e-02, fs:0.52121 (r=0.494,p=0.551),  time:42.798, tt:342.383\n",
      "Ep:8, loss:0.00021, loss_test:0.13216, lr:1.00e-02, fs:0.65025 (r=0.759,p=0.569),  time:42.869, tt:385.819\n",
      "Ep:9, loss:0.00020, loss_test:0.12954, lr:1.00e-02, fs:0.61290 (r=0.655,p=0.576),  time:42.943, tt:429.434\n",
      "Ep:10, loss:0.00020, loss_test:0.13065, lr:1.00e-02, fs:0.50955 (r=0.460,p=0.571),  time:42.930, tt:472.233\n",
      "Ep:11, loss:0.00019, loss_test:0.12479, lr:1.00e-02, fs:0.55422 (r=0.529,p=0.582),  time:43.173, tt:518.081\n",
      "Ep:12, loss:0.00018, loss_test:0.11969, lr:9.90e-03, fs:0.66667 (r=0.724,p=0.618),  time:43.180, tt:561.337\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.11574, lr:9.90e-03, fs:0.65193 (r=0.678,p=0.628),  time:42.961, tt:601.457\n",
      "Ep:14, loss:0.00017, loss_test:0.11339, lr:9.90e-03, fs:0.62791 (r=0.621,p=0.635),  time:42.867, tt:643.012\n",
      "Ep:15, loss:0.00016, loss_test:0.10953, lr:9.90e-03, fs:0.65922 (r=0.678,p=0.641),  time:42.904, tt:686.471\n",
      "Ep:16, loss:0.00016, loss_test:0.10666, lr:9.90e-03, fs:0.68156 (r=0.701,p=0.663),  time:42.879, tt:728.945\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.10543, lr:9.90e-03, fs:0.66265 (r=0.632,p=0.696),  time:42.881, tt:771.861\n",
      "Ep:18, loss:0.00015, loss_test:0.10144, lr:9.90e-03, fs:0.69048 (r=0.667,p=0.716),  time:42.800, tt:813.193\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09838, lr:9.90e-03, fs:0.73988 (r=0.736,p=0.744),  time:42.777, tt:855.532\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09674, lr:9.90e-03, fs:0.72289 (r=0.690,p=0.759),  time:42.842, tt:899.692\n",
      "Ep:21, loss:0.00013, loss_test:0.09485, lr:9.90e-03, fs:0.74419 (r=0.736,p=0.753),  time:42.811, tt:941.832\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.09401, lr:9.90e-03, fs:0.70303 (r=0.667,p=0.744),  time:42.792, tt:984.219\n",
      "Ep:23, loss:0.00012, loss_test:0.09224, lr:9.90e-03, fs:0.73373 (r=0.713,p=0.756),  time:42.923, tt:1030.150\n",
      "Ep:24, loss:0.00012, loss_test:0.09235, lr:9.90e-03, fs:0.70732 (r=0.667,p=0.753),  time:42.964, tt:1074.094\n",
      "Ep:25, loss:0.00011, loss_test:0.09056, lr:9.90e-03, fs:0.70732 (r=0.667,p=0.753),  time:42.952, tt:1116.759\n",
      "Ep:26, loss:0.00011, loss_test:0.08812, lr:9.90e-03, fs:0.75581 (r=0.747,p=0.765),  time:42.973, tt:1160.271\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.08939, lr:9.90e-03, fs:0.75294 (r=0.736,p=0.771),  time:43.006, tt:1204.171\n",
      "Ep:28, loss:0.00010, loss_test:0.08826, lr:9.90e-03, fs:0.76023 (r=0.747,p=0.774),  time:42.989, tt:1246.694\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08756, lr:9.90e-03, fs:0.76923 (r=0.747,p=0.793),  time:43.014, tt:1290.420\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.08728, lr:9.90e-03, fs:0.76647 (r=0.736,p=0.800),  time:43.034, tt:1334.054\n",
      "Ep:31, loss:0.00009, loss_test:0.08545, lr:9.90e-03, fs:0.77576 (r=0.736,p=0.821),  time:43.058, tt:1377.864\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00008, loss_test:0.08852, lr:9.90e-03, fs:0.75000 (r=0.690,p=0.822),  time:43.052, tt:1420.730\n",
      "Ep:33, loss:0.00008, loss_test:0.08419, lr:9.90e-03, fs:0.77844 (r=0.747,p=0.812),  time:43.094, tt:1465.200\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08704, lr:9.90e-03, fs:0.76623 (r=0.678,p=0.881),  time:43.095, tt:1508.319\n",
      "Ep:35, loss:0.00007, loss_test:0.08336, lr:9.90e-03, fs:0.79070 (r=0.782,p=0.800),  time:43.129, tt:1552.636\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00007, loss_test:0.08598, lr:9.90e-03, fs:0.77419 (r=0.690,p=0.882),  time:43.135, tt:1595.992\n",
      "Ep:37, loss:0.00007, loss_test:0.08351, lr:9.90e-03, fs:0.75472 (r=0.690,p=0.833),  time:43.119, tt:1638.509\n",
      "Ep:38, loss:0.00007, loss_test:0.08329, lr:9.90e-03, fs:0.77419 (r=0.690,p=0.882),  time:43.145, tt:1682.655\n",
      "Ep:39, loss:0.00006, loss_test:0.08309, lr:9.90e-03, fs:0.75949 (r=0.690,p=0.845),  time:43.179, tt:1727.154\n",
      "Ep:40, loss:0.00006, loss_test:0.08174, lr:9.90e-03, fs:0.76433 (r=0.690,p=0.857),  time:43.212, tt:1771.685\n",
      "Ep:41, loss:0.00006, loss_test:0.08330, lr:9.90e-03, fs:0.76923 (r=0.690,p=0.870),  time:43.230, tt:1815.659\n",
      "Ep:42, loss:0.00005, loss_test:0.08702, lr:9.90e-03, fs:0.75817 (r=0.667,p=0.879),  time:43.188, tt:1857.090\n",
      "Ep:43, loss:0.00005, loss_test:0.08391, lr:9.90e-03, fs:0.76923 (r=0.690,p=0.870),  time:43.228, tt:1902.049\n",
      "Ep:44, loss:0.00005, loss_test:0.08299, lr:9.90e-03, fs:0.76433 (r=0.690,p=0.857),  time:43.225, tt:1945.113\n",
      "Ep:45, loss:0.00005, loss_test:0.09038, lr:9.90e-03, fs:0.74830 (r=0.632,p=0.917),  time:43.248, tt:1989.424\n",
      "Ep:46, loss:0.00004, loss_test:0.08007, lr:9.90e-03, fs:0.76923 (r=0.690,p=0.870),  time:43.261, tt:2033.251\n",
      "Ep:47, loss:0.00004, loss_test:0.09294, lr:9.80e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.256, tt:2076.305\n",
      "Ep:48, loss:0.00004, loss_test:0.07886, lr:9.70e-03, fs:0.76433 (r=0.690,p=0.857),  time:43.282, tt:2120.798\n",
      "Ep:49, loss:0.00004, loss_test:0.09198, lr:9.61e-03, fs:0.76510 (r=0.655,p=0.919),  time:43.293, tt:2164.657\n",
      "Ep:50, loss:0.00004, loss_test:0.08016, lr:9.51e-03, fs:0.76923 (r=0.690,p=0.870),  time:43.316, tt:2209.132\n",
      "Ep:51, loss:0.00004, loss_test:0.09106, lr:9.41e-03, fs:0.77333 (r=0.667,p=0.921),  time:43.259, tt:2249.447\n",
      "Ep:52, loss:0.00003, loss_test:0.08279, lr:9.32e-03, fs:0.78431 (r=0.690,p=0.909),  time:43.269, tt:2293.239\n",
      "Ep:53, loss:0.00003, loss_test:0.08705, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.289, tt:2337.594\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.08255, lr:9.23e-03, fs:0.78431 (r=0.690,p=0.909),  time:43.305, tt:2381.798\n",
      "Ep:55, loss:0.00003, loss_test:0.08276, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.291, tt:2424.269\n",
      "Ep:56, loss:0.00003, loss_test:0.08951, lr:9.23e-03, fs:0.78431 (r=0.690,p=0.909),  time:43.281, tt:2467.036\n",
      "Ep:57, loss:0.00003, loss_test:0.08108, lr:9.23e-03, fs:0.78947 (r=0.690,p=0.923),  time:43.281, tt:2510.311\n",
      "Ep:58, loss:0.00003, loss_test:0.08515, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.252, tt:2551.890\n",
      "Ep:59, loss:0.00002, loss_test:0.08390, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.247, tt:2594.799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00002, loss_test:0.08290, lr:9.23e-03, fs:0.78947 (r=0.690,p=0.923),  time:43.212, tt:2635.912\n",
      "Ep:61, loss:0.00002, loss_test:0.08580, lr:9.23e-03, fs:0.80000 (r=0.690,p=0.952),  time:43.230, tt:2680.239\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.07686, lr:9.23e-03, fs:0.78947 (r=0.690,p=0.923),  time:43.198, tt:2721.449\n",
      "Ep:63, loss:0.00002, loss_test:0.08529, lr:9.23e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.203, tt:2765.004\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.08686, lr:9.23e-03, fs:0.80000 (r=0.690,p=0.952),  time:43.183, tt:2806.922\n",
      "Ep:65, loss:0.00002, loss_test:0.08267, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.201, tt:2851.270\n",
      "Ep:66, loss:0.00002, loss_test:0.08282, lr:9.23e-03, fs:0.78947 (r=0.690,p=0.923),  time:43.189, tt:2893.651\n",
      "Ep:67, loss:0.00002, loss_test:0.08430, lr:9.23e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.189, tt:2936.831\n",
      "Ep:68, loss:0.00002, loss_test:0.08112, lr:9.23e-03, fs:0.78947 (r=0.690,p=0.923),  time:43.189, tt:2980.037\n",
      "Ep:69, loss:0.00002, loss_test:0.08647, lr:9.23e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.180, tt:3022.611\n",
      "Ep:70, loss:0.00002, loss_test:0.08386, lr:9.23e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.186, tt:3066.179\n",
      "Ep:71, loss:0.00002, loss_test:0.08960, lr:9.23e-03, fs:0.78912 (r=0.667,p=0.967),  time:43.211, tt:3111.158\n",
      "Ep:72, loss:0.00002, loss_test:0.08710, lr:9.23e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.237, tt:3156.267\n",
      "Ep:73, loss:0.00002, loss_test:0.08459, lr:9.23e-03, fs:0.80000 (r=0.690,p=0.952),  time:43.239, tt:3199.685\n",
      "Ep:74, loss:0.00001, loss_test:0.09037, lr:9.23e-03, fs:0.78912 (r=0.667,p=0.967),  time:43.260, tt:3244.506\n",
      "Ep:75, loss:0.00001, loss_test:0.08070, lr:9.14e-03, fs:0.79470 (r=0.690,p=0.938),  time:43.304, tt:3291.114\n",
      "Ep:76, loss:0.00001, loss_test:0.09234, lr:9.04e-03, fs:0.77241 (r=0.644,p=0.966),  time:43.325, tt:3336.048\n",
      "Ep:77, loss:0.00001, loss_test:0.08446, lr:8.95e-03, fs:0.80000 (r=0.690,p=0.952),  time:43.345, tt:3380.890\n",
      "Ep:78, loss:0.00001, loss_test:0.08442, lr:8.86e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.355, tt:3425.025\n",
      "Ep:79, loss:0.00001, loss_test:0.09130, lr:8.78e-03, fs:0.78912 (r=0.667,p=0.967),  time:43.384, tt:3470.688\n",
      "Ep:80, loss:0.00001, loss_test:0.08497, lr:8.69e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.394, tt:3514.946\n",
      "Ep:81, loss:0.00001, loss_test:0.08756, lr:8.60e-03, fs:0.78082 (r=0.655,p=0.966),  time:43.421, tt:3560.531\n",
      "Ep:82, loss:0.00001, loss_test:0.08619, lr:8.51e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.446, tt:3606.010\n",
      "Ep:83, loss:0.00001, loss_test:0.08407, lr:8.43e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.473, tt:3651.714\n",
      "Ep:84, loss:0.00001, loss_test:0.08764, lr:8.35e-03, fs:0.78082 (r=0.655,p=0.966),  time:43.483, tt:3696.016\n",
      "Ep:85, loss:0.00001, loss_test:0.08630, lr:8.26e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.492, tt:3740.271\n",
      "Ep:86, loss:0.00001, loss_test:0.08670, lr:8.18e-03, fs:0.78082 (r=0.655,p=0.966),  time:43.489, tt:3783.539\n",
      "Ep:87, loss:0.00001, loss_test:0.08876, lr:8.10e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.500, tt:3827.995\n",
      "Ep:88, loss:0.00001, loss_test:0.08792, lr:8.02e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.513, tt:3872.672\n",
      "Ep:89, loss:0.00001, loss_test:0.09046, lr:7.94e-03, fs:0.72857 (r=0.586,p=0.962),  time:43.524, tt:3917.188\n",
      "Ep:90, loss:0.00001, loss_test:0.08754, lr:7.86e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.514, tt:3959.752\n",
      "Ep:91, loss:0.00001, loss_test:0.08881, lr:7.78e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.525, tt:4004.290\n",
      "Ep:92, loss:0.00001, loss_test:0.09006, lr:7.70e-03, fs:0.73759 (r=0.598,p=0.963),  time:43.533, tt:4048.601\n",
      "Ep:93, loss:0.00001, loss_test:0.09029, lr:7.62e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.539, tt:4092.640\n",
      "Ep:94, loss:0.00001, loss_test:0.08745, lr:7.55e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.544, tt:4136.707\n",
      "Ep:95, loss:0.00001, loss_test:0.09178, lr:7.47e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.570, tt:4182.759\n",
      "Ep:96, loss:0.00001, loss_test:0.08691, lr:7.40e-03, fs:0.80537 (r=0.690,p=0.968),  time:43.558, tt:4225.155\n",
      "Ep:97, loss:0.00001, loss_test:0.08939, lr:7.32e-03, fs:0.74648 (r=0.609,p=0.964),  time:43.530, tt:4265.903\n",
      "Ep:98, loss:0.00001, loss_test:0.08919, lr:7.25e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.524, tt:4308.854\n",
      "Ep:99, loss:0.00001, loss_test:0.08701, lr:7.18e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.497, tt:4349.738\n",
      "Ep:100, loss:0.00001, loss_test:0.09230, lr:7.11e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.485, tt:4392.003\n",
      "Ep:101, loss:0.00001, loss_test:0.08939, lr:7.03e-03, fs:0.79730 (r=0.678,p=0.967),  time:43.481, tt:4435.094\n",
      "Ep:102, loss:0.00001, loss_test:0.08967, lr:6.96e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.471, tt:4477.528\n",
      "Ep:103, loss:0.00001, loss_test:0.09009, lr:6.89e-03, fs:0.78082 (r=0.655,p=0.966),  time:43.453, tt:4519.107\n",
      "Ep:104, loss:0.00001, loss_test:0.09193, lr:6.83e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.431, tt:4560.286\n",
      "Ep:105, loss:0.00001, loss_test:0.08912, lr:6.76e-03, fs:0.78082 (r=0.655,p=0.966),  time:43.409, tt:4601.343\n",
      "Ep:106, loss:0.00001, loss_test:0.09204, lr:6.69e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.394, tt:4643.210\n",
      "Ep:107, loss:0.00001, loss_test:0.09047, lr:6.62e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.372, tt:4684.177\n",
      "Ep:108, loss:0.00001, loss_test:0.09084, lr:6.56e-03, fs:0.78912 (r=0.667,p=0.967),  time:43.324, tt:4722.365\n",
      "Ep:109, loss:0.00001, loss_test:0.09464, lr:6.49e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.297, tt:4762.634\n",
      "Ep:110, loss:0.00001, loss_test:0.09220, lr:6.43e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.288, tt:4805.000\n",
      "Ep:111, loss:0.00001, loss_test:0.09159, lr:6.36e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.279, tt:4847.259\n",
      "Ep:112, loss:0.00001, loss_test:0.09353, lr:6.30e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.278, tt:4890.443\n",
      "Ep:113, loss:0.00001, loss_test:0.09129, lr:6.24e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.260, tt:4931.585\n",
      "Ep:114, loss:0.00001, loss_test:0.09277, lr:6.17e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.224, tt:4970.792\n",
      "Ep:115, loss:0.00000, loss_test:0.09361, lr:6.11e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.266, tt:5018.898\n",
      "Ep:116, loss:0.00000, loss_test:0.09143, lr:6.05e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.249, tt:5060.153\n",
      "Ep:117, loss:0.00000, loss_test:0.09235, lr:5.99e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.219, tt:5099.865\n",
      "Ep:118, loss:0.00000, loss_test:0.09238, lr:5.93e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.196, tt:5140.352\n",
      "Ep:119, loss:0.00000, loss_test:0.09261, lr:5.87e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.199, tt:5183.832\n",
      "Ep:120, loss:0.00000, loss_test:0.09319, lr:5.81e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.178, tt:5224.487\n",
      "Ep:121, loss:0.00000, loss_test:0.09278, lr:5.75e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.153, tt:5264.677\n",
      "Ep:122, loss:0.00000, loss_test:0.09286, lr:5.70e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.150, tt:5307.428\n",
      "Ep:123, loss:0.00000, loss_test:0.09375, lr:5.64e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.134, tt:5348.672\n",
      "Ep:124, loss:0.00000, loss_test:0.09251, lr:5.58e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.145, tt:5393.075\n",
      "Ep:125, loss:0.00000, loss_test:0.09339, lr:5.53e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.152, tt:5437.128\n",
      "Ep:126, loss:0.00000, loss_test:0.09362, lr:5.47e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.149, tt:5479.931\n",
      "Ep:127, loss:0.00000, loss_test:0.09180, lr:5.42e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.147, tt:5522.786\n",
      "Ep:128, loss:0.00000, loss_test:0.09410, lr:5.36e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.144, tt:5565.632\n",
      "Ep:129, loss:0.00000, loss_test:0.09327, lr:5.31e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.149, tt:5609.335\n",
      "Ep:130, loss:0.00000, loss_test:0.09208, lr:5.26e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.139, tt:5651.163\n",
      "Ep:131, loss:0.00000, loss_test:0.09489, lr:5.20e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.115, tt:5691.163\n",
      "Ep:132, loss:0.00000, loss_test:0.09329, lr:5.15e-03, fs:0.71014 (r=0.563,p=0.961),  time:43.100, tt:5732.330\n",
      "Ep:133, loss:0.00000, loss_test:0.09385, lr:5.10e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.083, tt:5773.169\n",
      "Ep:134, loss:0.00000, loss_test:0.09409, lr:5.05e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.078, tt:5815.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:135, loss:0.00000, loss_test:0.09306, lr:5.00e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.055, tt:5855.445\n",
      "Ep:136, loss:0.00000, loss_test:0.09362, lr:4.95e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.049, tt:5897.684\n",
      "Ep:137, loss:0.00000, loss_test:0.09366, lr:4.90e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.033, tt:5938.542\n",
      "Ep:138, loss:0.00000, loss_test:0.09405, lr:4.85e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.023, tt:5980.200\n",
      "Ep:139, loss:0.00000, loss_test:0.09373, lr:4.80e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.037, tt:6025.176\n",
      "Ep:140, loss:0.00000, loss_test:0.09332, lr:4.75e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.024, tt:6066.441\n",
      "Ep:141, loss:0.00000, loss_test:0.09484, lr:4.71e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.011, tt:6107.507\n",
      "Ep:142, loss:0.00000, loss_test:0.09347, lr:4.66e-03, fs:0.71533 (r=0.563,p=0.980),  time:43.003, tt:6149.404\n",
      "Ep:143, loss:0.00000, loss_test:0.09420, lr:4.61e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.991, tt:6190.759\n",
      "Ep:144, loss:0.00000, loss_test:0.09369, lr:4.57e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.998, tt:6234.659\n",
      "Ep:145, loss:0.00000, loss_test:0.09418, lr:4.52e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.985, tt:6275.859\n",
      "Ep:146, loss:0.00000, loss_test:0.09455, lr:4.48e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.973, tt:6317.050\n",
      "Ep:147, loss:0.00000, loss_test:0.09357, lr:4.43e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.962, tt:6358.421\n",
      "Ep:148, loss:0.00000, loss_test:0.09443, lr:4.39e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.950, tt:6399.525\n",
      "Ep:149, loss:0.00000, loss_test:0.09336, lr:4.34e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.939, tt:6440.798\n",
      "Ep:150, loss:0.00000, loss_test:0.09285, lr:4.30e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.920, tt:6480.903\n",
      "Ep:151, loss:0.00000, loss_test:0.09528, lr:4.26e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.913, tt:6522.811\n",
      "Ep:152, loss:0.00000, loss_test:0.09295, lr:4.21e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.905, tt:6564.513\n",
      "Ep:153, loss:0.00000, loss_test:0.09528, lr:4.17e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.904, tt:6607.172\n",
      "Ep:154, loss:0.00000, loss_test:0.09369, lr:4.13e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.888, tt:6647.631\n",
      "Ep:155, loss:0.00000, loss_test:0.09334, lr:4.09e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.884, tt:6689.873\n",
      "Ep:156, loss:0.00000, loss_test:0.09414, lr:4.05e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.858, tt:6728.718\n",
      "Ep:157, loss:0.00000, loss_test:0.09352, lr:4.01e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.840, tt:6768.705\n",
      "Ep:158, loss:0.00000, loss_test:0.09432, lr:3.97e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.831, tt:6810.144\n",
      "Ep:159, loss:0.00000, loss_test:0.09329, lr:3.93e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.830, tt:6852.743\n",
      "Ep:160, loss:0.00000, loss_test:0.09393, lr:3.89e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.822, tt:6894.275\n",
      "Ep:161, loss:0.00000, loss_test:0.09445, lr:3.85e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.809, tt:6935.110\n",
      "Ep:162, loss:0.00000, loss_test:0.09276, lr:3.81e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.798, tt:6976.120\n",
      "Ep:163, loss:0.00000, loss_test:0.09488, lr:3.77e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.791, tt:7017.671\n",
      "Ep:164, loss:0.00000, loss_test:0.09346, lr:3.73e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.769, tt:7056.963\n",
      "Ep:165, loss:0.00000, loss_test:0.09348, lr:3.70e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.758, tt:7097.759\n",
      "Ep:166, loss:0.00000, loss_test:0.09475, lr:3.66e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.741, tt:7137.738\n",
      "Ep:167, loss:0.00000, loss_test:0.09298, lr:3.62e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.721, tt:7177.205\n",
      "Ep:168, loss:0.00000, loss_test:0.09380, lr:3.59e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.717, tt:7219.209\n",
      "Ep:169, loss:0.00000, loss_test:0.09394, lr:3.55e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.704, tt:7259.687\n",
      "Ep:170, loss:0.00000, loss_test:0.09390, lr:3.52e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.701, tt:7301.918\n",
      "Ep:171, loss:0.00000, loss_test:0.09427, lr:3.48e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.696, tt:7343.639\n",
      "Ep:172, loss:0.00000, loss_test:0.09364, lr:3.45e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.691, tt:7385.462\n",
      "Ep:173, loss:0.00000, loss_test:0.09384, lr:3.41e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.674, tt:7425.347\n",
      "Ep:174, loss:0.00000, loss_test:0.09402, lr:3.38e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.659, tt:7465.247\n",
      "Ep:175, loss:0.00000, loss_test:0.09347, lr:3.34e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.636, tt:7503.941\n",
      "Ep:176, loss:0.00000, loss_test:0.09367, lr:3.31e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.622, tt:7544.012\n",
      "Ep:177, loss:0.00000, loss_test:0.09478, lr:3.28e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.619, tt:7586.206\n",
      "Ep:178, loss:0.00000, loss_test:0.09370, lr:3.24e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.605, tt:7626.293\n",
      "Ep:179, loss:0.00000, loss_test:0.09305, lr:3.21e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.605, tt:7668.825\n",
      "Ep:180, loss:0.00000, loss_test:0.09415, lr:3.18e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.596, tt:7709.789\n",
      "Ep:181, loss:0.00000, loss_test:0.09370, lr:3.15e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.580, tt:7749.648\n",
      "Ep:182, loss:0.00000, loss_test:0.09327, lr:3.12e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.584, tt:7792.884\n",
      "Ep:183, loss:0.00000, loss_test:0.09343, lr:3.09e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.578, tt:7834.363\n",
      "Ep:184, loss:0.00000, loss_test:0.09371, lr:3.05e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.583, tt:7877.937\n",
      "Ep:185, loss:0.00000, loss_test:0.09343, lr:3.02e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.568, tt:7917.572\n",
      "Ep:186, loss:0.00000, loss_test:0.09366, lr:2.99e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.555, tt:7957.795\n",
      "Ep:187, loss:0.00000, loss_test:0.09390, lr:2.96e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.543, tt:7998.154\n",
      "Ep:188, loss:0.00000, loss_test:0.09287, lr:2.93e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.545, tt:8041.065\n",
      "Ep:189, loss:0.00000, loss_test:0.09378, lr:2.90e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.539, tt:8082.447\n",
      "Ep:190, loss:0.00000, loss_test:0.09446, lr:2.88e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.541, tt:8125.415\n",
      "Ep:191, loss:0.00000, loss_test:0.09336, lr:2.85e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.528, tt:8165.469\n",
      "Ep:192, loss:0.00000, loss_test:0.09339, lr:2.82e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.530, tt:8208.199\n",
      "Ep:193, loss:0.00000, loss_test:0.09415, lr:2.79e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.526, tt:8250.063\n",
      "Ep:194, loss:0.00000, loss_test:0.09421, lr:2.76e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.519, tt:8291.252\n",
      "Ep:195, loss:0.00000, loss_test:0.09360, lr:2.73e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.523, tt:8334.414\n",
      "Ep:196, loss:0.00000, loss_test:0.09332, lr:2.71e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.521, tt:8376.597\n",
      "Ep:197, loss:0.00000, loss_test:0.09341, lr:2.68e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.497, tt:8414.342\n",
      "Ep:198, loss:0.00000, loss_test:0.09344, lr:2.65e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.485, tt:8454.488\n",
      "Ep:199, loss:0.00000, loss_test:0.09342, lr:2.63e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.480, tt:8496.019\n",
      "Ep:200, loss:0.00000, loss_test:0.09366, lr:2.60e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.467, tt:8535.880\n",
      "Ep:201, loss:0.00000, loss_test:0.09367, lr:2.57e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.454, tt:8575.670\n",
      "Ep:202, loss:0.00000, loss_test:0.09339, lr:2.55e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.450, tt:8617.353\n",
      "Ep:203, loss:0.00000, loss_test:0.09375, lr:2.52e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.453, tt:8660.411\n",
      "Ep:204, loss:0.00000, loss_test:0.09398, lr:2.50e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.447, tt:8701.714\n",
      "Ep:205, loss:0.00000, loss_test:0.09358, lr:2.47e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.447, tt:8744.032\n",
      "Ep:206, loss:0.00000, loss_test:0.09373, lr:2.45e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.428, tt:8782.536\n",
      "Ep:207, loss:0.00000, loss_test:0.09369, lr:2.42e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.426, tt:8824.665\n",
      "Ep:208, loss:0.00000, loss_test:0.09346, lr:2.40e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.412, tt:8864.143\n",
      "Ep:209, loss:0.00000, loss_test:0.09363, lr:2.38e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.379, tt:8899.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:210, loss:0.00000, loss_test:0.09354, lr:2.35e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.344, tt:8934.514\n",
      "Ep:211, loss:0.00000, loss_test:0.09338, lr:2.33e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.292, tt:8965.941\n",
      "Ep:212, loss:0.00000, loss_test:0.09330, lr:2.31e-03, fs:0.71533 (r=0.563,p=0.980),  time:42.233, tt:8995.572\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02217, lr:6.00e-02, fs:0.61404 (r=0.805,p=0.496),  time:38.915, tt:38.915\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02279, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.536, tt:79.072\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02354, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.896, tt:119.687\n",
      "Ep:3, loss:0.00004, loss_test:0.02298, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:40.115, tt:160.462\n",
      "Ep:4, loss:0.00004, loss_test:0.02182, lr:6.00e-02, fs:0.66667 (r=0.989,p=0.503),  time:39.484, tt:197.421\n",
      "Ep:5, loss:0.00004, loss_test:0.02072, lr:6.00e-02, fs:0.66942 (r=0.931,p=0.523),  time:39.699, tt:238.192\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.02070, lr:6.00e-02, fs:0.66063 (r=0.839,p=0.545),  time:39.677, tt:277.742\n",
      "Ep:7, loss:0.00004, loss_test:0.02108, lr:6.00e-02, fs:0.66000 (r=0.759,p=0.584),  time:39.766, tt:318.130\n",
      "Ep:8, loss:0.00004, loss_test:0.02025, lr:6.00e-02, fs:0.71770 (r=0.862,p=0.615),  time:39.745, tt:357.706\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01913, lr:6.00e-02, fs:0.68421 (r=0.897,p=0.553),  time:39.693, tt:396.928\n",
      "Ep:10, loss:0.00003, loss_test:0.01864, lr:6.00e-02, fs:0.68670 (r=0.920,p=0.548),  time:39.665, tt:436.319\n",
      "Ep:11, loss:0.00003, loss_test:0.01826, lr:6.00e-02, fs:0.68670 (r=0.920,p=0.548),  time:39.606, tt:475.267\n",
      "Ep:12, loss:0.00003, loss_test:0.01791, lr:6.00e-02, fs:0.69869 (r=0.920,p=0.563),  time:39.540, tt:514.018\n",
      "Ep:13, loss:0.00003, loss_test:0.01769, lr:6.00e-02, fs:0.70588 (r=0.897,p=0.582),  time:39.474, tt:552.634\n",
      "Ep:14, loss:0.00003, loss_test:0.01751, lr:6.00e-02, fs:0.73333 (r=0.885,p=0.626),  time:39.474, tt:592.105\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.73684 (r=0.885,p=0.631),  time:39.568, tt:633.090\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01663, lr:6.00e-02, fs:0.72222 (r=0.897,p=0.605),  time:39.602, tt:673.226\n",
      "Ep:17, loss:0.00003, loss_test:0.01624, lr:6.00e-02, fs:0.71493 (r=0.908,p=0.590),  time:39.549, tt:711.877\n",
      "Ep:18, loss:0.00003, loss_test:0.01588, lr:6.00e-02, fs:0.71889 (r=0.897,p=0.600),  time:39.473, tt:749.984\n",
      "Ep:19, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.73585 (r=0.897,p=0.624),  time:39.465, tt:789.292\n",
      "Ep:20, loss:0.00002, loss_test:0.01523, lr:6.00e-02, fs:0.76098 (r=0.897,p=0.661),  time:39.547, tt:830.478\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01484, lr:6.00e-02, fs:0.76699 (r=0.908,p=0.664),  time:39.555, tt:870.203\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01449, lr:6.00e-02, fs:0.79808 (r=0.954,p=0.686),  time:39.723, tt:913.623\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01422, lr:6.00e-02, fs:0.79227 (r=0.943,p=0.683),  time:39.784, tt:954.809\n",
      "Ep:24, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.79227 (r=0.943,p=0.683),  time:39.744, tt:993.600\n",
      "Ep:25, loss:0.00002, loss_test:0.01382, lr:6.00e-02, fs:0.79612 (r=0.943,p=0.689),  time:39.841, tt:1035.872\n",
      "Ep:26, loss:0.00002, loss_test:0.01363, lr:6.00e-02, fs:0.80193 (r=0.954,p=0.692),  time:39.832, tt:1075.477\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01344, lr:6.00e-02, fs:0.81159 (r=0.966,p=0.700),  time:39.787, tt:1114.047\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.82126 (r=0.977,p=0.708),  time:39.832, tt:1155.115\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01311, lr:6.00e-02, fs:0.83902 (r=0.989,p=0.729),  time:39.805, tt:1194.155\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01300, lr:6.00e-02, fs:0.84466 (r=1.000,p=0.731),  time:39.756, tt:1232.423\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01294, lr:6.00e-02, fs:0.84729 (r=0.989,p=0.741),  time:39.816, tt:1274.100\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.85149 (r=0.989,p=0.748),  time:39.836, tt:1314.572\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01267, lr:6.00e-02, fs:0.85294 (r=1.000,p=0.744),  time:39.860, tt:1355.255\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01255, lr:6.00e-02, fs:0.85294 (r=1.000,p=0.744),  time:39.884, tt:1395.926\n",
      "Ep:35, loss:0.00002, loss_test:0.01252, lr:6.00e-02, fs:0.85294 (r=1.000,p=0.744),  time:39.942, tt:1437.899\n",
      "Ep:36, loss:0.00002, loss_test:0.01247, lr:6.00e-02, fs:0.86139 (r=1.000,p=0.757),  time:39.988, tt:1479.545\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01240, lr:6.00e-02, fs:0.86139 (r=1.000,p=0.757),  time:39.997, tt:1519.897\n",
      "Ep:38, loss:0.00002, loss_test:0.01231, lr:6.00e-02, fs:0.86139 (r=1.000,p=0.757),  time:40.004, tt:1560.152\n",
      "Ep:39, loss:0.00002, loss_test:0.01228, lr:6.00e-02, fs:0.86567 (r=1.000,p=0.763),  time:39.973, tt:1598.907\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01223, lr:6.00e-02, fs:0.87437 (r=1.000,p=0.777),  time:39.982, tt:1639.277\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.87879 (r=1.000,p=0.784),  time:40.040, tt:1681.680\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.01209, lr:6.00e-02, fs:0.88325 (r=1.000,p=0.791),  time:40.079, tt:1723.414\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00001, loss_test:0.01204, lr:6.00e-02, fs:0.88325 (r=1.000,p=0.791),  time:40.031, tt:1761.384\n",
      "Ep:44, loss:0.00001, loss_test:0.01202, lr:6.00e-02, fs:0.88776 (r=1.000,p=0.798),  time:40.018, tt:1800.795\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01200, lr:6.00e-02, fs:0.89231 (r=1.000,p=0.806),  time:40.050, tt:1842.283\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01198, lr:6.00e-02, fs:0.89231 (r=1.000,p=0.806),  time:40.052, tt:1882.426\n",
      "Ep:47, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.89691 (r=1.000,p=0.813),  time:40.053, tt:1922.561\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.89691 (r=1.000,p=0.813),  time:40.081, tt:1963.962\n",
      "Ep:49, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.90625 (r=1.000,p=0.829),  time:40.102, tt:2005.084\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01190, lr:6.00e-02, fs:0.90625 (r=1.000,p=0.829),  time:40.136, tt:2046.922\n",
      "Ep:51, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.89583 (r=0.989,p=0.819),  time:40.159, tt:2088.264\n",
      "Ep:52, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.90052 (r=0.989,p=0.827),  time:40.155, tt:2128.200\n",
      "Ep:53, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.90052 (r=0.989,p=0.827),  time:40.154, tt:2168.338\n",
      "Ep:54, loss:0.00001, loss_test:0.01181, lr:6.00e-02, fs:0.90052 (r=0.989,p=0.827),  time:40.201, tt:2211.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00001, loss_test:0.01184, lr:6.00e-02, fs:0.90052 (r=0.989,p=0.827),  time:40.211, tt:2251.815\n",
      "Ep:56, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.90526 (r=0.989,p=0.835),  time:40.236, tt:2293.461\n",
      "Ep:57, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.90526 (r=0.989,p=0.835),  time:40.237, tt:2333.768\n",
      "Ep:58, loss:0.00001, loss_test:0.01186, lr:6.00e-02, fs:0.91005 (r=0.989,p=0.843),  time:40.201, tt:2371.849\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01180, lr:6.00e-02, fs:0.91005 (r=0.989,p=0.843),  time:40.187, tt:2411.217\n",
      "Ep:60, loss:0.00001, loss_test:0.01178, lr:6.00e-02, fs:0.91005 (r=0.989,p=0.843),  time:40.237, tt:2454.472\n",
      "Ep:61, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.91005 (r=0.989,p=0.843),  time:40.237, tt:2494.670\n",
      "Ep:62, loss:0.00001, loss_test:0.01179, lr:6.00e-02, fs:0.90323 (r=0.966,p=0.848),  time:40.259, tt:2536.290\n",
      "Ep:63, loss:0.00001, loss_test:0.01186, lr:6.00e-02, fs:0.90909 (r=0.977,p=0.850),  time:40.268, tt:2577.167\n",
      "Ep:64, loss:0.00001, loss_test:0.01183, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:40.277, tt:2617.980\n",
      "Ep:65, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:40.284, tt:2658.722\n",
      "Ep:66, loss:0.00001, loss_test:0.01186, lr:6.00e-02, fs:0.89730 (r=0.954,p=0.847),  time:40.310, tt:2700.745\n",
      "Ep:67, loss:0.00001, loss_test:0.01185, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:40.323, tt:2741.972\n",
      "Ep:68, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.89130 (r=0.943,p=0.845),  time:40.346, tt:2783.848\n",
      "Ep:69, loss:0.00001, loss_test:0.01182, lr:6.00e-02, fs:0.88398 (r=0.920,p=0.851),  time:40.348, tt:2824.387\n",
      "Ep:70, loss:0.00001, loss_test:0.01185, lr:5.94e-02, fs:0.87778 (r=0.908,p=0.849),  time:40.317, tt:2862.534\n",
      "Ep:71, loss:0.00001, loss_test:0.01187, lr:5.88e-02, fs:0.88268 (r=0.908,p=0.859),  time:40.332, tt:2903.934\n",
      "Ep:72, loss:0.00001, loss_test:0.01189, lr:5.82e-02, fs:0.87640 (r=0.897,p=0.857),  time:40.373, tt:2947.207\n",
      "Ep:73, loss:0.00001, loss_test:0.01195, lr:5.76e-02, fs:0.87006 (r=0.885,p=0.856),  time:40.375, tt:2987.782\n",
      "Ep:74, loss:0.00001, loss_test:0.01194, lr:5.71e-02, fs:0.87006 (r=0.885,p=0.856),  time:40.398, tt:3029.836\n",
      "Ep:75, loss:0.00001, loss_test:0.01190, lr:5.65e-02, fs:0.87006 (r=0.885,p=0.856),  time:40.409, tt:3071.116\n",
      "Ep:76, loss:0.00001, loss_test:0.01194, lr:5.59e-02, fs:0.87006 (r=0.885,p=0.856),  time:40.418, tt:3112.204\n",
      "Ep:77, loss:0.00001, loss_test:0.01193, lr:5.54e-02, fs:0.87006 (r=0.885,p=0.856),  time:40.410, tt:3152.019\n",
      "Ep:78, loss:0.00001, loss_test:0.01190, lr:5.48e-02, fs:0.86364 (r=0.874,p=0.854),  time:40.393, tt:3191.014\n",
      "Ep:79, loss:0.00001, loss_test:0.01198, lr:5.43e-02, fs:0.87500 (r=0.885,p=0.865),  time:40.407, tt:3232.582\n",
      "Ep:80, loss:0.00001, loss_test:0.01202, lr:5.37e-02, fs:0.87356 (r=0.874,p=0.874),  time:40.406, tt:3272.916\n",
      "Ep:81, loss:0.00001, loss_test:0.01198, lr:5.32e-02, fs:0.86857 (r=0.874,p=0.864),  time:40.414, tt:3313.927\n",
      "Ep:82, loss:0.00001, loss_test:0.01206, lr:5.27e-02, fs:0.86207 (r=0.862,p=0.862),  time:40.425, tt:3355.304\n",
      "Ep:83, loss:0.00001, loss_test:0.01209, lr:5.21e-02, fs:0.86047 (r=0.851,p=0.871),  time:40.421, tt:3395.375\n",
      "Ep:84, loss:0.00001, loss_test:0.01217, lr:5.16e-02, fs:0.85380 (r=0.839,p=0.869),  time:40.412, tt:3435.038\n",
      "Ep:85, loss:0.00001, loss_test:0.01214, lr:5.11e-02, fs:0.84706 (r=0.828,p=0.867),  time:40.425, tt:3476.556\n",
      "Ep:86, loss:0.00001, loss_test:0.01217, lr:5.06e-02, fs:0.84024 (r=0.816,p=0.866),  time:40.421, tt:3516.619\n",
      "Ep:87, loss:0.00001, loss_test:0.01219, lr:5.01e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.396, tt:3554.872\n",
      "Ep:88, loss:0.00001, loss_test:0.01224, lr:4.96e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.388, tt:3594.513\n",
      "Ep:89, loss:0.00001, loss_test:0.01227, lr:4.91e-02, fs:0.83333 (r=0.805,p=0.864),  time:40.397, tt:3635.699\n",
      "Ep:90, loss:0.00001, loss_test:0.01230, lr:4.86e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.377, tt:3674.328\n",
      "Ep:91, loss:0.00001, loss_test:0.01229, lr:4.81e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.381, tt:3715.047\n",
      "Ep:92, loss:0.00001, loss_test:0.01234, lr:4.76e-02, fs:0.81707 (r=0.770,p=0.870),  time:40.357, tt:3753.234\n",
      "Ep:93, loss:0.00001, loss_test:0.01235, lr:4.71e-02, fs:0.80982 (r=0.759,p=0.868),  time:40.380, tt:3795.741\n",
      "Ep:94, loss:0.00001, loss_test:0.01240, lr:4.67e-02, fs:0.79503 (r=0.736,p=0.865),  time:40.359, tt:3834.145\n",
      "Ep:95, loss:0.00001, loss_test:0.01248, lr:4.62e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.357, tt:3874.271\n",
      "Ep:96, loss:0.00001, loss_test:0.01247, lr:4.57e-02, fs:0.76433 (r=0.690,p=0.857),  time:40.341, tt:3913.122\n",
      "Ep:97, loss:0.00001, loss_test:0.01253, lr:4.53e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.339, tt:3953.217\n",
      "Ep:98, loss:0.00001, loss_test:0.01253, lr:4.48e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.334, tt:3993.048\n",
      "Ep:99, loss:0.00001, loss_test:0.01259, lr:4.44e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.330, tt:4032.969\n",
      "Ep:100, loss:0.00001, loss_test:0.01258, lr:4.39e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.327, tt:4072.977\n",
      "Ep:101, loss:0.00001, loss_test:0.01253, lr:4.35e-02, fs:0.76923 (r=0.690,p=0.870),  time:40.314, tt:4112.035\n",
      "Ep:102, loss:0.00001, loss_test:0.01262, lr:4.31e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.314, tt:4152.320\n",
      "Ep:103, loss:0.00001, loss_test:0.01269, lr:4.26e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.304, tt:4191.592\n",
      "Ep:104, loss:0.00001, loss_test:0.01271, lr:4.22e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.300, tt:4231.479\n",
      "Ep:105, loss:0.00001, loss_test:0.01275, lr:4.18e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.302, tt:4272.012\n",
      "Ep:106, loss:0.00001, loss_test:0.01272, lr:4.14e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.308, tt:4312.931\n",
      "Ep:107, loss:0.00000, loss_test:0.01281, lr:4.10e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.313, tt:4353.778\n",
      "Ep:108, loss:0.00000, loss_test:0.01280, lr:4.05e-02, fs:0.77419 (r=0.690,p=0.882),  time:40.326, tt:4395.584\n",
      "Ep:109, loss:0.00000, loss_test:0.01283, lr:4.01e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.332, tt:4436.491\n",
      "Ep:110, loss:0.00000, loss_test:0.01285, lr:3.97e-02, fs:0.78431 (r=0.690,p=0.909),  time:40.369, tt:4480.942\n",
      "Ep:111, loss:0.00000, loss_test:0.01286, lr:3.93e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.367, tt:4521.088\n",
      "Ep:112, loss:0.00000, loss_test:0.01289, lr:3.89e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.366, tt:4561.322\n",
      "Ep:113, loss:0.00000, loss_test:0.01294, lr:3.86e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.356, tt:4600.630\n",
      "Ep:114, loss:0.00000, loss_test:0.01296, lr:3.82e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.366, tt:4642.054\n",
      "Ep:115, loss:0.00000, loss_test:0.01295, lr:3.78e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.376, tt:4683.606\n",
      "Ep:116, loss:0.00000, loss_test:0.01304, lr:3.74e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.379, tt:4724.344\n",
      "Ep:117, loss:0.00000, loss_test:0.01306, lr:3.70e-02, fs:0.77922 (r=0.690,p=0.896),  time:40.373, tt:4764.042\n",
      "Ep:118, loss:0.00000, loss_test:0.01304, lr:3.67e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.370, tt:4804.009\n",
      "Ep:119, loss:0.00000, loss_test:0.01305, lr:3.63e-02, fs:0.78431 (r=0.690,p=0.909),  time:40.362, tt:4843.398\n",
      "Ep:120, loss:0.00000, loss_test:0.01308, lr:3.59e-02, fs:0.78431 (r=0.690,p=0.909),  time:40.375, tt:4885.350\n",
      "Ep:121, loss:0.00000, loss_test:0.01311, lr:3.56e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.373, tt:4925.482\n",
      "Ep:122, loss:0.00000, loss_test:0.01315, lr:3.52e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.385, tt:4967.357\n",
      "Ep:123, loss:0.00000, loss_test:0.01315, lr:3.49e-02, fs:0.78431 (r=0.690,p=0.909),  time:40.390, tt:5008.402\n",
      "Ep:124, loss:0.00000, loss_test:0.01319, lr:3.45e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.393, tt:5049.144\n",
      "Ep:125, loss:0.00000, loss_test:0.01321, lr:3.42e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.383, tt:5088.246\n",
      "Ep:126, loss:0.00000, loss_test:0.01325, lr:3.38e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.356, tt:5125.150\n",
      "Ep:127, loss:0.00000, loss_test:0.01325, lr:3.35e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.337, tt:5163.178\n",
      "Ep:128, loss:0.00000, loss_test:0.01328, lr:3.32e-02, fs:0.78431 (r=0.690,p=0.909),  time:40.339, tt:5203.781\n",
      "Ep:129, loss:0.00000, loss_test:0.01329, lr:3.28e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.338, tt:5243.911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.01332, lr:3.25e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.332, tt:5283.477\n",
      "Ep:131, loss:0.00000, loss_test:0.01336, lr:3.22e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.334, tt:5324.123\n",
      "Ep:132, loss:0.00000, loss_test:0.01335, lr:3.19e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.329, tt:5363.785\n",
      "Ep:133, loss:0.00000, loss_test:0.01337, lr:3.15e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.318, tt:5402.548\n",
      "Ep:134, loss:0.00000, loss_test:0.01339, lr:3.12e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.320, tt:5443.238\n",
      "Ep:135, loss:0.00000, loss_test:0.01343, lr:3.09e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.309, tt:5482.009\n",
      "Ep:136, loss:0.00000, loss_test:0.01343, lr:3.06e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.302, tt:5521.334\n",
      "Ep:137, loss:0.00000, loss_test:0.01347, lr:3.03e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.308, tt:5562.490\n",
      "Ep:138, loss:0.00000, loss_test:0.01346, lr:3.00e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.287, tt:5599.946\n",
      "Ep:139, loss:0.00000, loss_test:0.01343, lr:2.97e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.289, tt:5640.413\n",
      "Ep:140, loss:0.00000, loss_test:0.01356, lr:2.94e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.290, tt:5680.921\n",
      "Ep:141, loss:0.00000, loss_test:0.01357, lr:2.91e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.297, tt:5722.198\n",
      "Ep:142, loss:0.00000, loss_test:0.01352, lr:2.88e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.304, tt:5763.488\n",
      "Ep:143, loss:0.00000, loss_test:0.01358, lr:2.85e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.353, tt:5810.803\n",
      "Ep:144, loss:0.00000, loss_test:0.01360, lr:2.82e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.354, tt:5851.334\n",
      "Ep:145, loss:0.00000, loss_test:0.01358, lr:2.80e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.346, tt:5890.545\n",
      "Ep:146, loss:0.00000, loss_test:0.01362, lr:2.77e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:5931.533\n",
      "Ep:147, loss:0.00000, loss_test:0.01366, lr:2.74e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.365, tt:5974.040\n",
      "Ep:148, loss:0.00000, loss_test:0.01367, lr:2.71e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.365, tt:6014.439\n",
      "Ep:149, loss:0.00000, loss_test:0.01364, lr:2.69e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.366, tt:6054.858\n",
      "Ep:150, loss:0.00000, loss_test:0.01368, lr:2.66e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.355, tt:6093.670\n",
      "Ep:151, loss:0.00000, loss_test:0.01373, lr:2.63e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.345, tt:6132.366\n",
      "Ep:152, loss:0.00000, loss_test:0.01370, lr:2.61e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.359, tt:6174.933\n",
      "Ep:153, loss:0.00000, loss_test:0.01373, lr:2.58e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.357, tt:6215.000\n",
      "Ep:154, loss:0.00000, loss_test:0.01375, lr:2.55e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.363, tt:6256.332\n",
      "Ep:155, loss:0.00000, loss_test:0.01375, lr:2.53e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.355, tt:6295.307\n",
      "Ep:156, loss:0.00000, loss_test:0.01378, lr:2.50e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.352, tt:6335.187\n",
      "Ep:157, loss:0.00000, loss_test:0.01382, lr:2.48e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.353, tt:6375.850\n",
      "Ep:158, loss:0.00000, loss_test:0.01383, lr:2.45e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:6415.867\n",
      "Ep:159, loss:0.00000, loss_test:0.01383, lr:2.43e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.353, tt:6456.470\n",
      "Ep:160, loss:0.00000, loss_test:0.01385, lr:2.40e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:6496.521\n",
      "Ep:161, loss:0.00000, loss_test:0.01387, lr:2.38e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.350, tt:6536.631\n",
      "Ep:162, loss:0.00000, loss_test:0.01387, lr:2.36e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.355, tt:6577.941\n",
      "Ep:163, loss:0.00000, loss_test:0.01389, lr:2.33e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.356, tt:6618.416\n",
      "Ep:164, loss:0.00000, loss_test:0.01391, lr:2.31e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.363, tt:6659.817\n",
      "Ep:165, loss:0.00000, loss_test:0.01392, lr:2.29e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.363, tt:6700.200\n",
      "Ep:166, loss:0.00000, loss_test:0.01392, lr:2.26e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.368, tt:6741.438\n",
      "Ep:167, loss:0.00000, loss_test:0.01395, lr:2.24e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.368, tt:6781.857\n",
      "Ep:168, loss:0.00000, loss_test:0.01396, lr:2.22e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.364, tt:6821.544\n",
      "Ep:169, loss:0.00000, loss_test:0.01398, lr:2.20e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.369, tt:6862.799\n",
      "Ep:170, loss:0.00000, loss_test:0.01400, lr:2.17e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.363, tt:6902.078\n",
      "Ep:171, loss:0.00000, loss_test:0.01399, lr:2.15e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.357, tt:6941.373\n",
      "Ep:172, loss:0.00000, loss_test:0.01400, lr:2.13e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.356, tt:6981.537\n",
      "Ep:173, loss:0.00000, loss_test:0.01403, lr:2.11e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.360, tt:7022.718\n",
      "Ep:174, loss:0.00000, loss_test:0.01404, lr:2.09e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:7061.381\n",
      "Ep:175, loss:0.00000, loss_test:0.01404, lr:2.07e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.347, tt:7101.010\n",
      "Ep:176, loss:0.00000, loss_test:0.01406, lr:2.05e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.343, tt:7140.638\n",
      "Ep:177, loss:0.00000, loss_test:0.01409, lr:2.03e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:7182.425\n",
      "Ep:178, loss:0.00000, loss_test:0.01407, lr:2.01e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.351, tt:7222.775\n",
      "Ep:179, loss:0.00000, loss_test:0.01404, lr:1.99e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.345, tt:7262.045\n",
      "Ep:180, loss:0.00000, loss_test:0.01413, lr:1.97e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.343, tt:7302.147\n",
      "Ep:181, loss:0.00000, loss_test:0.01414, lr:1.95e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.350, tt:7343.697\n",
      "Ep:182, loss:0.00000, loss_test:0.01412, lr:1.93e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.342, tt:7382.592\n",
      "Ep:183, loss:0.00000, loss_test:0.01412, lr:1.91e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.329, tt:7420.461\n",
      "Ep:184, loss:0.00000, loss_test:0.01416, lr:1.89e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.319, tt:7458.950\n",
      "Ep:185, loss:0.00000, loss_test:0.01417, lr:1.87e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.307, tt:7497.017\n",
      "Ep:186, loss:0.00000, loss_test:0.01416, lr:1.85e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.303, tt:7536.621\n",
      "Ep:187, loss:0.00000, loss_test:0.01420, lr:1.83e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.306, tt:7577.535\n",
      "Ep:188, loss:0.00000, loss_test:0.01423, lr:1.81e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.309, tt:7618.400\n",
      "Ep:189, loss:0.00000, loss_test:0.01422, lr:1.80e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.311, tt:7659.155\n",
      "Ep:190, loss:0.00000, loss_test:0.01421, lr:1.78e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.300, tt:7697.314\n",
      "Ep:191, loss:0.00000, loss_test:0.01425, lr:1.76e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.296, tt:7736.916\n",
      "Ep:192, loss:0.00000, loss_test:0.01426, lr:1.74e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.286, tt:7775.248\n",
      "Ep:193, loss:0.00000, loss_test:0.01427, lr:1.73e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.282, tt:7814.779\n",
      "Ep:194, loss:0.00000, loss_test:0.01426, lr:1.71e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.282, tt:7855.037\n",
      "Ep:195, loss:0.00000, loss_test:0.01429, lr:1.69e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.276, tt:7894.007\n",
      "Ep:196, loss:0.00000, loss_test:0.01432, lr:1.67e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.261, tt:7931.330\n",
      "Ep:197, loss:0.00000, loss_test:0.01432, lr:1.66e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.260, tt:7971.488\n",
      "Ep:198, loss:0.00000, loss_test:0.01431, lr:1.64e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.248, tt:8009.442\n",
      "Ep:199, loss:0.00000, loss_test:0.01434, lr:1.62e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.244, tt:8048.751\n",
      "Ep:200, loss:0.00000, loss_test:0.01436, lr:1.61e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.244, tt:8089.083\n",
      "Ep:201, loss:0.00000, loss_test:0.01435, lr:1.59e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.234, tt:8127.350\n",
      "Ep:202, loss:0.00000, loss_test:0.01434, lr:1.58e-02, fs:0.78947 (r=0.690,p=0.923),  time:40.234, tt:8167.436\n",
      "Ep:203, loss:0.00000, loss_test:0.01436, lr:1.56e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.232, tt:8207.388\n",
      "Ep:204, loss:0.00000, loss_test:0.01437, lr:1.54e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.233, tt:8247.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.01438, lr:1.53e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.231, tt:8287.552\n",
      "Ep:206, loss:0.00000, loss_test:0.01439, lr:1.51e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.258, tt:8333.391\n",
      "Ep:207, loss:0.00000, loss_test:0.01440, lr:1.50e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.256, tt:8373.245\n",
      "Ep:208, loss:0.00000, loss_test:0.01441, lr:1.48e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.258, tt:8413.927\n",
      "Ep:209, loss:0.00000, loss_test:0.01441, lr:1.47e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.234, tt:8449.039\n",
      "Ep:210, loss:0.00000, loss_test:0.01442, lr:1.45e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.213, tt:8484.854\n",
      "Ep:211, loss:0.00000, loss_test:0.01445, lr:1.44e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.186, tt:8519.531\n",
      "Ep:212, loss:0.00000, loss_test:0.01446, lr:1.43e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.160, tt:8554.043\n",
      "Ep:213, loss:0.00000, loss_test:0.01445, lr:1.41e-02, fs:0.79470 (r=0.690,p=0.938),  time:40.148, tt:8591.696\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.14424, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.774, tt:41.774\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.14141, lr:1.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:41.504, tt:83.009\n",
      "Ep:2, loss:0.00026, loss_test:0.13587, lr:1.00e-02, fs:0.64681 (r=0.874,p=0.514),  time:41.621, tt:124.864\n",
      "Ep:3, loss:0.00024, loss_test:0.13251, lr:1.00e-02, fs:0.61386 (r=0.713,p=0.539),  time:41.919, tt:167.675\n",
      "Ep:4, loss:0.00022, loss_test:0.13340, lr:1.00e-02, fs:0.55422 (r=0.529,p=0.582),  time:41.934, tt:209.670\n",
      "Ep:5, loss:0.00022, loss_test:0.12781, lr:1.00e-02, fs:0.56180 (r=0.575,p=0.549),  time:41.646, tt:249.877\n",
      "Ep:6, loss:0.00021, loss_test:0.12419, lr:1.00e-02, fs:0.64615 (r=0.724,p=0.583),  time:41.594, tt:291.156\n",
      "Ep:7, loss:0.00021, loss_test:0.12207, lr:1.00e-02, fs:0.63441 (r=0.678,p=0.596),  time:41.691, tt:333.531\n",
      "Ep:8, loss:0.00020, loss_test:0.12106, lr:1.00e-02, fs:0.62428 (r=0.621,p=0.628),  time:41.662, tt:374.958\n",
      "Ep:9, loss:0.00019, loss_test:0.11731, lr:1.00e-02, fs:0.66304 (r=0.701,p=0.629),  time:41.635, tt:416.354\n",
      "Ep:10, loss:0.00019, loss_test:0.11339, lr:1.00e-02, fs:0.70769 (r=0.793,p=0.639),  time:41.680, tt:458.485\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.11088, lr:1.00e-02, fs:0.72727 (r=0.782,p=0.680),  time:41.776, tt:501.309\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.10808, lr:1.00e-02, fs:0.72928 (r=0.759,p=0.702),  time:42.154, tt:547.996\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.10516, lr:1.00e-02, fs:0.77596 (r=0.816,p=0.740),  time:42.103, tt:589.435\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00016, loss_test:0.10193, lr:1.00e-02, fs:0.79365 (r=0.862,p=0.735),  time:42.224, tt:633.356\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09921, lr:1.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:42.223, tt:675.574\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09697, lr:1.00e-02, fs:0.81522 (r=0.862,p=0.773),  time:42.176, tt:716.998\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09433, lr:1.00e-02, fs:0.81915 (r=0.885,p=0.762),  time:42.089, tt:757.603\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09203, lr:1.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:42.120, tt:800.289\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09027, lr:1.00e-02, fs:0.84324 (r=0.897,p=0.796),  time:42.142, tt:842.844\n",
      "Ep:20, loss:0.00013, loss_test:0.08802, lr:1.00e-02, fs:0.86339 (r=0.908,p=0.823),  time:42.062, tt:883.302\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.08577, lr:1.00e-02, fs:0.87432 (r=0.920,p=0.833),  time:42.010, tt:924.213\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.08491, lr:1.00e-02, fs:0.87234 (r=0.943,p=0.812),  time:42.018, tt:966.408\n",
      "Ep:23, loss:0.00012, loss_test:0.08378, lr:1.00e-02, fs:0.87151 (r=0.897,p=0.848),  time:42.083, tt:1009.994\n",
      "Ep:24, loss:0.00012, loss_test:0.08235, lr:1.00e-02, fs:0.89362 (r=0.966,p=0.832),  time:42.107, tt:1052.665\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.08078, lr:1.00e-02, fs:0.90110 (r=0.943,p=0.863),  time:42.119, tt:1095.086\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00011, loss_test:0.07913, lr:1.00e-02, fs:0.91209 (r=0.954,p=0.874),  time:42.206, tt:1139.570\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.07778, lr:1.00e-02, fs:0.91304 (r=0.966,p=0.866),  time:42.223, tt:1182.242\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00010, loss_test:0.07692, lr:1.00e-02, fs:0.92308 (r=0.966,p=0.884),  time:42.255, tt:1225.381\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.07706, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:42.216, tt:1266.471\n",
      "Ep:30, loss:0.00010, loss_test:0.07618, lr:1.00e-02, fs:0.86705 (r=0.862,p=0.872),  time:42.179, tt:1307.543\n",
      "Ep:31, loss:0.00009, loss_test:0.07465, lr:1.00e-02, fs:0.86391 (r=0.839,p=0.890),  time:42.170, tt:1349.440\n",
      "Ep:32, loss:0.00009, loss_test:0.07481, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:42.189, tt:1392.223\n",
      "Ep:33, loss:0.00009, loss_test:0.07378, lr:1.00e-02, fs:0.81761 (r=0.747,p=0.903),  time:42.123, tt:1432.173\n",
      "Ep:34, loss:0.00008, loss_test:0.07341, lr:1.00e-02, fs:0.85207 (r=0.828,p=0.878),  time:42.121, tt:1474.220\n",
      "Ep:35, loss:0.00008, loss_test:0.07323, lr:1.00e-02, fs:0.80255 (r=0.724,p=0.900),  time:42.137, tt:1516.933\n",
      "Ep:36, loss:0.00008, loss_test:0.07382, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:42.226, tt:1562.345\n",
      "Ep:37, loss:0.00008, loss_test:0.07100, lr:1.00e-02, fs:0.77419 (r=0.690,p=0.882),  time:42.215, tt:1604.182\n",
      "Ep:38, loss:0.00007, loss_test:0.07662, lr:1.00e-02, fs:0.84146 (r=0.793,p=0.896),  time:42.230, tt:1646.978\n",
      "Ep:39, loss:0.00007, loss_test:0.07283, lr:1.00e-02, fs:0.75497 (r=0.655,p=0.891),  time:42.248, tt:1689.917\n",
      "Ep:40, loss:0.00007, loss_test:0.07480, lr:9.90e-03, fs:0.83832 (r=0.805,p=0.875),  time:42.200, tt:1730.179\n",
      "Ep:41, loss:0.00007, loss_test:0.07311, lr:9.80e-03, fs:0.76000 (r=0.655,p=0.905),  time:42.195, tt:1772.186\n",
      "Ep:42, loss:0.00007, loss_test:0.07243, lr:9.70e-03, fs:0.82143 (r=0.793,p=0.852),  time:42.270, tt:1817.621\n",
      "Ep:43, loss:0.00006, loss_test:0.07742, lr:9.61e-03, fs:0.78667 (r=0.678,p=0.937),  time:42.264, tt:1859.618\n",
      "Ep:44, loss:0.00006, loss_test:0.07425, lr:9.51e-03, fs:0.79268 (r=0.747,p=0.844),  time:42.214, tt:1899.612\n",
      "Ep:45, loss:0.00006, loss_test:0.08015, lr:9.41e-03, fs:0.76712 (r=0.644,p=0.949),  time:42.216, tt:1941.940\n",
      "Ep:46, loss:0.00006, loss_test:0.07600, lr:9.32e-03, fs:0.76923 (r=0.690,p=0.870),  time:42.220, tt:1984.334\n",
      "Ep:47, loss:0.00005, loss_test:0.07818, lr:9.23e-03, fs:0.76000 (r=0.655,p=0.905),  time:42.205, tt:2025.817\n",
      "Ep:48, loss:0.00005, loss_test:0.07681, lr:9.14e-03, fs:0.78947 (r=0.690,p=0.923),  time:42.252, tt:2070.366\n",
      "Ep:49, loss:0.00005, loss_test:0.07279, lr:9.04e-03, fs:0.77852 (r=0.667,p=0.935),  time:42.262, tt:2113.115\n",
      "Ep:50, loss:0.00005, loss_test:0.07978, lr:8.95e-03, fs:0.76730 (r=0.701,p=0.847),  time:42.273, tt:2155.947\n",
      "Ep:51, loss:0.00005, loss_test:0.07490, lr:8.86e-03, fs:0.77027 (r=0.655,p=0.934),  time:42.266, tt:2197.817\n",
      "Ep:52, loss:0.00004, loss_test:0.07456, lr:8.78e-03, fs:0.76250 (r=0.701,p=0.836),  time:42.238, tt:2238.601\n",
      "Ep:53, loss:0.00004, loss_test:0.08858, lr:8.69e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.270, tt:2282.575\n",
      "Ep:54, loss:0.00004, loss_test:0.07195, lr:8.60e-03, fs:0.77419 (r=0.690,p=0.882),  time:42.284, tt:2325.624\n",
      "Ep:55, loss:0.00004, loss_test:0.08688, lr:8.51e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.271, tt:2367.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00004, loss_test:0.07495, lr:8.43e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.233, tt:2407.286\n",
      "Ep:57, loss:0.00004, loss_test:0.08206, lr:8.35e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.268, tt:2451.561\n",
      "Ep:58, loss:0.00004, loss_test:0.07862, lr:8.26e-03, fs:0.76510 (r=0.655,p=0.919),  time:42.287, tt:2494.956\n",
      "Ep:59, loss:0.00003, loss_test:0.08027, lr:8.18e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.293, tt:2537.552\n",
      "Ep:60, loss:0.00004, loss_test:0.08107, lr:8.10e-03, fs:0.78082 (r=0.655,p=0.966),  time:42.304, tt:2580.563\n",
      "Ep:61, loss:0.00003, loss_test:0.07627, lr:8.02e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.280, tt:2621.330\n",
      "Ep:62, loss:0.00003, loss_test:0.07968, lr:7.94e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.278, tt:2663.526\n",
      "Ep:63, loss:0.00003, loss_test:0.07860, lr:7.86e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.286, tt:2706.278\n",
      "Ep:64, loss:0.00003, loss_test:0.07978, lr:7.78e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.286, tt:2748.618\n",
      "Ep:65, loss:0.00003, loss_test:0.08567, lr:7.70e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.317, tt:2792.901\n",
      "Ep:66, loss:0.00003, loss_test:0.07611, lr:7.62e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.322, tt:2835.548\n",
      "Ep:67, loss:0.00003, loss_test:0.08759, lr:7.55e-03, fs:0.80000 (r=0.690,p=0.952),  time:42.313, tt:2877.267\n",
      "Ep:68, loss:0.00003, loss_test:0.07618, lr:7.47e-03, fs:0.80537 (r=0.690,p=0.968),  time:42.347, tt:2921.974\n",
      "Ep:69, loss:0.00003, loss_test:0.08527, lr:7.40e-03, fs:0.77778 (r=0.644,p=0.982),  time:42.337, tt:2963.624\n",
      "Ep:70, loss:0.00002, loss_test:0.08292, lr:7.32e-03, fs:0.77778 (r=0.644,p=0.982),  time:42.317, tt:3004.482\n",
      "Ep:71, loss:0.00002, loss_test:0.08100, lr:7.25e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.339, tt:3048.428\n",
      "Ep:72, loss:0.00002, loss_test:0.08730, lr:7.18e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.354, tt:3091.836\n",
      "Ep:73, loss:0.00002, loss_test:0.08164, lr:7.11e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.338, tt:3133.031\n",
      "Ep:74, loss:0.00002, loss_test:0.08707, lr:7.03e-03, fs:0.76923 (r=0.632,p=0.982),  time:42.359, tt:3176.927\n",
      "Ep:75, loss:0.00002, loss_test:0.08041, lr:6.96e-03, fs:0.79452 (r=0.667,p=0.983),  time:42.368, tt:3219.977\n",
      "Ep:76, loss:0.00002, loss_test:0.08409, lr:6.89e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.391, tt:3264.117\n",
      "Ep:77, loss:0.00002, loss_test:0.08511, lr:6.83e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.421, tt:3308.858\n",
      "Ep:78, loss:0.00002, loss_test:0.08288, lr:6.76e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.433, tt:3352.205\n",
      "Ep:79, loss:0.00002, loss_test:0.08569, lr:6.69e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.428, tt:3394.269\n",
      "Ep:80, loss:0.00002, loss_test:0.08234, lr:6.62e-03, fs:0.80272 (r=0.678,p=0.983),  time:42.429, tt:3436.761\n",
      "Ep:81, loss:0.00002, loss_test:0.08471, lr:6.56e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.438, tt:3479.889\n",
      "Ep:82, loss:0.00002, loss_test:0.08206, lr:6.49e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.461, tt:3524.222\n",
      "Ep:83, loss:0.00002, loss_test:0.08780, lr:6.43e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.453, tt:3566.088\n",
      "Ep:84, loss:0.00002, loss_test:0.08321, lr:6.36e-03, fs:0.81081 (r=0.690,p=0.984),  time:42.447, tt:3608.003\n",
      "Ep:85, loss:0.00002, loss_test:0.09332, lr:6.30e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.453, tt:3650.978\n",
      "Ep:86, loss:0.00002, loss_test:0.08610, lr:6.24e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.451, tt:3693.261\n",
      "Ep:87, loss:0.00001, loss_test:0.08344, lr:6.17e-03, fs:0.76923 (r=0.632,p=0.982),  time:42.441, tt:3734.821\n",
      "Ep:88, loss:0.00001, loss_test:0.09369, lr:6.11e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.460, tt:3778.911\n",
      "Ep:89, loss:0.00001, loss_test:0.08427, lr:6.05e-03, fs:0.77778 (r=0.644,p=0.982),  time:42.450, tt:3820.539\n",
      "Ep:90, loss:0.00001, loss_test:0.08679, lr:5.99e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.454, tt:3863.341\n",
      "Ep:91, loss:0.00001, loss_test:0.08768, lr:5.93e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.472, tt:3907.439\n",
      "Ep:92, loss:0.00001, loss_test:0.08612, lr:5.87e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.472, tt:3949.929\n",
      "Ep:93, loss:0.00001, loss_test:0.08986, lr:5.81e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.463, tt:3991.497\n",
      "Ep:94, loss:0.00001, loss_test:0.08485, lr:5.75e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.436, tt:4031.407\n",
      "Ep:95, loss:0.00001, loss_test:0.08758, lr:5.70e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.450, tt:4075.177\n",
      "Ep:96, loss:0.00001, loss_test:0.08890, lr:5.64e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.442, tt:4116.921\n",
      "Ep:97, loss:0.00001, loss_test:0.08399, lr:5.58e-03, fs:0.78621 (r=0.655,p=0.983),  time:42.437, tt:4158.829\n",
      "Ep:98, loss:0.00001, loss_test:0.08633, lr:5.53e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.428, tt:4200.420\n",
      "Ep:99, loss:0.00001, loss_test:0.08930, lr:5.47e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.434, tt:4243.378\n",
      "Ep:100, loss:0.00001, loss_test:0.08576, lr:5.42e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.430, tt:4285.429\n",
      "Ep:101, loss:0.00001, loss_test:0.08797, lr:5.36e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.438, tt:4328.716\n",
      "Ep:102, loss:0.00001, loss_test:0.08479, lr:5.31e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.436, tt:4370.925\n",
      "Ep:103, loss:0.00001, loss_test:0.08908, lr:5.26e-03, fs:0.76056 (r=0.621,p=0.982),  time:42.443, tt:4414.043\n",
      "Ep:104, loss:0.00001, loss_test:0.08640, lr:5.20e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.441, tt:4456.337\n",
      "Ep:105, loss:0.00001, loss_test:0.08772, lr:5.15e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.418, tt:4496.315\n",
      "Ep:106, loss:0.00001, loss_test:0.08605, lr:5.10e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.408, tt:4537.687\n",
      "Ep:107, loss:0.00001, loss_test:0.08731, lr:5.05e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.416, tt:4580.885\n",
      "Ep:108, loss:0.00001, loss_test:0.08884, lr:5.00e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.410, tt:4622.729\n",
      "Ep:109, loss:0.00001, loss_test:0.09034, lr:4.95e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.414, tt:4665.571\n",
      "Ep:110, loss:0.00001, loss_test:0.08575, lr:4.90e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.409, tt:4707.391\n",
      "Ep:111, loss:0.00001, loss_test:0.08938, lr:4.85e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.404, tt:4749.229\n",
      "Ep:112, loss:0.00001, loss_test:0.08693, lr:4.80e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.401, tt:4791.296\n",
      "Ep:113, loss:0.00001, loss_test:0.08773, lr:4.75e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.382, tt:4831.582\n",
      "Ep:114, loss:0.00001, loss_test:0.08819, lr:4.71e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.394, tt:4875.266\n",
      "Ep:115, loss:0.00001, loss_test:0.08723, lr:4.66e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.405, tt:4918.924\n",
      "Ep:116, loss:0.00001, loss_test:0.08744, lr:4.61e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.397, tt:4960.466\n",
      "Ep:117, loss:0.00001, loss_test:0.08960, lr:4.57e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.386, tt:5001.584\n",
      "Ep:118, loss:0.00001, loss_test:0.08569, lr:4.52e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.408, tt:5046.514\n",
      "Ep:119, loss:0.00001, loss_test:0.08806, lr:4.48e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.406, tt:5088.669\n",
      "Ep:120, loss:0.00001, loss_test:0.08904, lr:4.43e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.409, tt:5131.537\n",
      "Ep:121, loss:0.00001, loss_test:0.08743, lr:4.39e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.407, tt:5173.656\n",
      "Ep:122, loss:0.00001, loss_test:0.08891, lr:4.34e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.399, tt:5215.058\n",
      "Ep:123, loss:0.00001, loss_test:0.08908, lr:4.30e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.387, tt:5256.034\n",
      "Ep:124, loss:0.00001, loss_test:0.08788, lr:4.26e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.375, tt:5296.901\n",
      "Ep:125, loss:0.00001, loss_test:0.08760, lr:4.21e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.383, tt:5340.220\n",
      "Ep:126, loss:0.00001, loss_test:0.08961, lr:4.17e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.378, tt:5382.061\n",
      "Ep:127, loss:0.00001, loss_test:0.08735, lr:4.13e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.384, tt:5425.097\n",
      "Ep:128, loss:0.00001, loss_test:0.08811, lr:4.09e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.386, tt:5467.755\n",
      "Ep:129, loss:0.00001, loss_test:0.08923, lr:4.05e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.371, tt:5508.206\n",
      "Ep:130, loss:0.00001, loss_test:0.08806, lr:4.01e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.368, tt:5550.239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00001, loss_test:0.08883, lr:3.97e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.368, tt:5592.641\n",
      "Ep:132, loss:0.00001, loss_test:0.08848, lr:3.93e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.374, tt:5635.716\n",
      "Ep:133, loss:0.00001, loss_test:0.08842, lr:3.89e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.379, tt:5678.826\n",
      "Ep:134, loss:0.00001, loss_test:0.08780, lr:3.85e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.367, tt:5719.577\n",
      "Ep:135, loss:0.00001, loss_test:0.08953, lr:3.81e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.358, tt:5760.705\n",
      "Ep:136, loss:0.00001, loss_test:0.08947, lr:3.77e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.362, tt:5803.650\n",
      "Ep:137, loss:0.00001, loss_test:0.08988, lr:3.73e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.366, tt:5846.506\n",
      "Ep:138, loss:0.00001, loss_test:0.09090, lr:3.70e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.354, tt:5887.205\n",
      "Ep:139, loss:0.00001, loss_test:0.08863, lr:3.66e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.351, tt:5929.172\n",
      "Ep:140, loss:0.00001, loss_test:0.08837, lr:3.62e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.360, tt:5972.774\n",
      "Ep:141, loss:0.00001, loss_test:0.09005, lr:3.59e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.352, tt:6013.969\n",
      "Ep:142, loss:0.00001, loss_test:0.08951, lr:3.55e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.350, tt:6056.048\n",
      "Ep:143, loss:0.00001, loss_test:0.08929, lr:3.52e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.344, tt:6097.602\n",
      "Ep:144, loss:0.00001, loss_test:0.09014, lr:3.48e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.341, tt:6139.466\n",
      "Ep:145, loss:0.00001, loss_test:0.08877, lr:3.45e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.337, tt:6181.239\n",
      "Ep:146, loss:0.00001, loss_test:0.08869, lr:3.41e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.334, tt:6223.071\n",
      "Ep:147, loss:0.00001, loss_test:0.08980, lr:3.38e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.324, tt:6264.021\n",
      "Ep:148, loss:0.00001, loss_test:0.08897, lr:3.34e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.322, tt:6305.904\n",
      "Ep:149, loss:0.00001, loss_test:0.08991, lr:3.31e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.309, tt:6346.355\n",
      "Ep:150, loss:0.00001, loss_test:0.08964, lr:3.28e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.299, tt:6387.186\n",
      "Ep:151, loss:0.00001, loss_test:0.08971, lr:3.24e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.292, tt:6428.348\n",
      "Ep:152, loss:0.00001, loss_test:0.08929, lr:3.21e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.284, tt:6469.420\n",
      "Ep:153, loss:0.00001, loss_test:0.08967, lr:3.18e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.282, tt:6511.406\n",
      "Ep:154, loss:0.00001, loss_test:0.09109, lr:3.15e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.271, tt:6552.044\n",
      "Ep:155, loss:0.00001, loss_test:0.08990, lr:3.12e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.259, tt:6592.426\n",
      "Ep:156, loss:0.00001, loss_test:0.08974, lr:3.09e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.256, tt:6634.237\n",
      "Ep:157, loss:0.00000, loss_test:0.09002, lr:3.05e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.257, tt:6676.555\n",
      "Ep:158, loss:0.00000, loss_test:0.08992, lr:3.02e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.253, tt:6718.205\n",
      "Ep:159, loss:0.00000, loss_test:0.09010, lr:2.99e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.242, tt:6758.673\n",
      "Ep:160, loss:0.00000, loss_test:0.09074, lr:2.96e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.230, tt:6799.005\n",
      "Ep:161, loss:0.00000, loss_test:0.09167, lr:2.93e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.232, tt:6841.596\n",
      "Ep:162, loss:0.00000, loss_test:0.08949, lr:2.90e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.225, tt:6882.715\n",
      "Ep:163, loss:0.00000, loss_test:0.09072, lr:2.88e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.218, tt:6923.684\n",
      "Ep:164, loss:0.00000, loss_test:0.09087, lr:2.85e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.222, tt:6966.557\n",
      "Ep:165, loss:0.00000, loss_test:0.08969, lr:2.82e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.237, tt:7011.308\n",
      "Ep:166, loss:0.00000, loss_test:0.09060, lr:2.79e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.239, tt:7053.958\n",
      "Ep:167, loss:0.00000, loss_test:0.08989, lr:2.76e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.222, tt:7093.377\n",
      "Ep:168, loss:0.00000, loss_test:0.09038, lr:2.73e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.216, tt:7134.523\n",
      "Ep:169, loss:0.00000, loss_test:0.09188, lr:2.71e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.200, tt:7173.991\n",
      "Ep:170, loss:0.00000, loss_test:0.09062, lr:2.68e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.204, tt:7216.835\n",
      "Ep:171, loss:0.00000, loss_test:0.08999, lr:2.65e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.196, tt:7257.697\n",
      "Ep:172, loss:0.00000, loss_test:0.09091, lr:2.63e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.194, tt:7299.540\n",
      "Ep:173, loss:0.00000, loss_test:0.09125, lr:2.60e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.198, tt:7342.407\n",
      "Ep:174, loss:0.00000, loss_test:0.09140, lr:2.57e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.188, tt:7382.933\n",
      "Ep:175, loss:0.00000, loss_test:0.09048, lr:2.55e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.192, tt:7425.788\n",
      "Ep:176, loss:0.00000, loss_test:0.09011, lr:2.52e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.188, tt:7467.247\n",
      "Ep:177, loss:0.00000, loss_test:0.09173, lr:2.50e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.193, tt:7510.282\n",
      "Ep:178, loss:0.00000, loss_test:0.09102, lr:2.47e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.195, tt:7552.845\n",
      "Ep:179, loss:0.00000, loss_test:0.09037, lr:2.45e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.200, tt:7596.051\n",
      "Ep:180, loss:0.00000, loss_test:0.09104, lr:2.42e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.194, tt:7637.142\n",
      "Ep:181, loss:0.00000, loss_test:0.09153, lr:2.40e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.190, tt:7678.623\n",
      "Ep:182, loss:0.00000, loss_test:0.09134, lr:2.38e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.197, tt:7721.969\n",
      "Ep:183, loss:0.00000, loss_test:0.09053, lr:2.35e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.190, tt:7763.036\n",
      "Ep:184, loss:0.00000, loss_test:0.09081, lr:2.33e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.185, tt:7804.151\n",
      "Ep:185, loss:0.00000, loss_test:0.09069, lr:2.31e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.183, tt:7846.086\n",
      "Ep:186, loss:0.00000, loss_test:0.09108, lr:2.28e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.186, tt:7888.766\n",
      "Ep:187, loss:0.00000, loss_test:0.09146, lr:2.26e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.194, tt:7932.444\n",
      "Ep:188, loss:0.00000, loss_test:0.09128, lr:2.24e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.198, tt:7975.339\n",
      "Ep:189, loss:0.00000, loss_test:0.09131, lr:2.21e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.207, tt:8019.389\n",
      "Ep:190, loss:0.00000, loss_test:0.09111, lr:2.19e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.210, tt:8062.024\n",
      "Ep:191, loss:0.00000, loss_test:0.09119, lr:2.17e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.208, tt:8103.874\n",
      "Ep:192, loss:0.00000, loss_test:0.09113, lr:2.15e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.210, tt:8146.622\n",
      "Ep:193, loss:0.00000, loss_test:0.09140, lr:2.13e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.207, tt:8188.211\n",
      "Ep:194, loss:0.00000, loss_test:0.09171, lr:2.11e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.209, tt:8230.799\n",
      "Ep:195, loss:0.00000, loss_test:0.09154, lr:2.08e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.207, tt:8272.487\n",
      "Ep:196, loss:0.00000, loss_test:0.09164, lr:2.06e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.205, tt:8314.345\n",
      "Ep:197, loss:0.00000, loss_test:0.09143, lr:2.04e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.199, tt:8355.396\n",
      "Ep:198, loss:0.00000, loss_test:0.09154, lr:2.02e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.202, tt:8398.198\n",
      "Ep:199, loss:0.00000, loss_test:0.09162, lr:2.00e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.192, tt:8438.422\n",
      "Ep:200, loss:0.00000, loss_test:0.09184, lr:1.98e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.192, tt:8480.676\n",
      "Ep:201, loss:0.00000, loss_test:0.09137, lr:1.96e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.184, tt:8521.108\n",
      "Ep:202, loss:0.00000, loss_test:0.09187, lr:1.94e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.178, tt:8562.051\n",
      "Ep:203, loss:0.00000, loss_test:0.09219, lr:1.92e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.174, tt:8603.569\n",
      "Ep:204, loss:0.00000, loss_test:0.09179, lr:1.90e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.175, tt:8645.904\n",
      "Ep:205, loss:0.00000, loss_test:0.09156, lr:1.89e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.181, tt:8689.278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.09166, lr:1.87e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.184, tt:8732.026\n",
      "Ep:207, loss:0.00000, loss_test:0.09176, lr:1.85e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.185, tt:8774.570\n",
      "Ep:208, loss:0.00000, loss_test:0.09184, lr:1.83e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.197, tt:8819.204\n",
      "Ep:209, loss:0.00000, loss_test:0.09246, lr:1.81e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.190, tt:8859.823\n",
      "Ep:210, loss:0.00000, loss_test:0.09218, lr:1.79e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.138, tt:8891.143\n",
      "Ep:211, loss:0.00000, loss_test:0.09211, lr:1.78e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.086, tt:8922.210\n",
      "Ep:212, loss:0.00000, loss_test:0.09220, lr:1.76e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.039, tt:8954.228\n",
      "Ep:213, loss:0.00000, loss_test:0.09194, lr:1.74e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.998, tt:8987.587\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00005, loss_test:0.02350, lr:6.00e-02, fs:0.60633 (r=0.770,p=0.500),  time:37.109, tt:37.109\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02331, lr:6.00e-02, fs:0.66154 (r=0.989,p=0.497),  time:40.169, tt:80.338\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02350, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.265, tt:123.795\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02252, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.253, tt:165.010\n",
      "Ep:4, loss:0.00004, loss_test:0.02160, lr:6.00e-02, fs:0.64800 (r=0.931,p=0.497),  time:41.182, tt:205.910\n",
      "Ep:5, loss:0.00004, loss_test:0.02142, lr:6.00e-02, fs:0.63677 (r=0.816,p=0.522),  time:41.384, tt:248.306\n",
      "Ep:6, loss:0.00003, loss_test:0.02164, lr:6.00e-02, fs:0.64423 (r=0.770,p=0.554),  time:41.202, tt:288.411\n",
      "Ep:7, loss:0.00003, loss_test:0.02123, lr:6.00e-02, fs:0.66667 (r=0.805,p=0.569),  time:41.029, tt:328.229\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00003, loss_test:0.02046, lr:6.00e-02, fs:0.68778 (r=0.874,p=0.567),  time:41.039, tt:369.349\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01982, lr:6.00e-02, fs:0.69604 (r=0.908,p=0.564),  time:40.903, tt:409.033\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01933, lr:6.00e-02, fs:0.69912 (r=0.908,p=0.568),  time:41.182, tt:452.997\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01893, lr:6.00e-02, fs:0.70536 (r=0.908,p=0.577),  time:41.540, tt:498.480\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01855, lr:6.00e-02, fs:0.71818 (r=0.908,p=0.594),  time:41.676, tt:541.794\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01817, lr:6.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:41.628, tt:582.799\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01766, lr:6.00e-02, fs:0.73148 (r=0.908,p=0.612),  time:41.634, tt:624.517\n",
      "Ep:15, loss:0.00003, loss_test:0.01716, lr:6.00e-02, fs:0.73148 (r=0.908,p=0.612),  time:41.546, tt:664.736\n",
      "Ep:16, loss:0.00003, loss_test:0.01672, lr:6.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:41.544, tt:706.242\n",
      "Ep:17, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.74528 (r=0.908,p=0.632),  time:41.656, tt:749.804\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01615, lr:6.00e-02, fs:0.76329 (r=0.908,p=0.658),  time:41.631, tt:790.980\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01588, lr:6.00e-02, fs:0.76329 (r=0.908,p=0.658),  time:41.668, tt:833.361\n",
      "Ep:20, loss:0.00002, loss_test:0.01565, lr:6.00e-02, fs:0.75962 (r=0.908,p=0.653),  time:41.627, tt:874.166\n",
      "Ep:21, loss:0.00002, loss_test:0.01541, lr:6.00e-02, fs:0.77073 (r=0.908,p=0.669),  time:41.649, tt:916.278\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01519, lr:6.00e-02, fs:0.77451 (r=0.908,p=0.675),  time:41.591, tt:956.592\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01503, lr:6.00e-02, fs:0.78607 (r=0.908,p=0.693),  time:41.532, tt:996.768\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01491, lr:6.00e-02, fs:0.78607 (r=0.908,p=0.693),  time:41.580, tt:1039.512\n",
      "Ep:25, loss:0.00002, loss_test:0.01472, lr:6.00e-02, fs:0.78218 (r=0.908,p=0.687),  time:41.737, tt:1085.171\n",
      "Ep:26, loss:0.00002, loss_test:0.01459, lr:6.00e-02, fs:0.79397 (r=0.908,p=0.705),  time:41.762, tt:1127.566\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01450, lr:6.00e-02, fs:0.79798 (r=0.908,p=0.712),  time:41.756, tt:1169.181\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01442, lr:6.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:41.810, tt:1212.480\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01436, lr:6.00e-02, fs:0.80203 (r=0.908,p=0.718),  time:41.813, tt:1254.393\n",
      "Ep:30, loss:0.00002, loss_test:0.01426, lr:6.00e-02, fs:0.81000 (r=0.931,p=0.717),  time:41.801, tt:1295.828\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01420, lr:6.00e-02, fs:0.81407 (r=0.931,p=0.723),  time:41.876, tt:1340.020\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01414, lr:6.00e-02, fs:0.82412 (r=0.943,p=0.732),  time:41.922, tt:1383.411\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.82412 (r=0.943,p=0.732),  time:41.915, tt:1425.124\n",
      "Ep:34, loss:0.00002, loss_test:0.01400, lr:6.00e-02, fs:0.83077 (r=0.931,p=0.750),  time:41.978, tt:1469.235\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01405, lr:6.00e-02, fs:0.83077 (r=0.931,p=0.750),  time:42.103, tt:1515.706\n",
      "Ep:36, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.83505 (r=0.931,p=0.757),  time:42.056, tt:1556.056\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:42.032, tt:1597.223\n",
      "Ep:38, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.81675 (r=0.897,p=0.750),  time:42.069, tt:1640.693\n",
      "Ep:39, loss:0.00002, loss_test:0.01404, lr:6.00e-02, fs:0.80851 (r=0.874,p=0.752),  time:42.039, tt:1681.575\n",
      "Ep:40, loss:0.00002, loss_test:0.01398, lr:6.00e-02, fs:0.81481 (r=0.885,p=0.755),  time:41.997, tt:1721.863\n",
      "Ep:41, loss:0.00002, loss_test:0.01402, lr:6.00e-02, fs:0.79570 (r=0.851,p=0.747),  time:41.979, tt:1763.106\n",
      "Ep:42, loss:0.00002, loss_test:0.01401, lr:6.00e-02, fs:0.80000 (r=0.851,p=0.755),  time:41.970, tt:1804.714\n",
      "Ep:43, loss:0.00001, loss_test:0.01408, lr:6.00e-02, fs:0.79781 (r=0.839,p=0.760),  time:41.979, tt:1847.062\n",
      "Ep:44, loss:0.00001, loss_test:0.01416, lr:6.00e-02, fs:0.78453 (r=0.816,p=0.755),  time:42.003, tt:1890.129\n",
      "Ep:45, loss:0.00001, loss_test:0.01411, lr:6.00e-02, fs:0.78022 (r=0.816,p=0.747),  time:41.991, tt:1931.591\n",
      "Ep:46, loss:0.00001, loss_test:0.01417, lr:6.00e-02, fs:0.78453 (r=0.816,p=0.755),  time:42.017, tt:1974.778\n",
      "Ep:47, loss:0.00001, loss_test:0.01424, lr:6.00e-02, fs:0.78453 (r=0.816,p=0.755),  time:42.058, tt:2018.769\n",
      "Ep:48, loss:0.00001, loss_test:0.01434, lr:5.94e-02, fs:0.77348 (r=0.805,p=0.745),  time:42.040, tt:2059.969\n",
      "Ep:49, loss:0.00001, loss_test:0.01441, lr:5.88e-02, fs:0.78212 (r=0.805,p=0.761),  time:42.025, tt:2101.273\n",
      "Ep:50, loss:0.00001, loss_test:0.01445, lr:5.82e-02, fs:0.77778 (r=0.805,p=0.753),  time:41.981, tt:2141.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:51, loss:0.00001, loss_test:0.01454, lr:5.76e-02, fs:0.77095 (r=0.793,p=0.750),  time:41.969, tt:2182.391\n",
      "Ep:52, loss:0.00001, loss_test:0.01476, lr:5.71e-02, fs:0.77714 (r=0.782,p=0.773),  time:41.935, tt:2222.542\n",
      "Ep:53, loss:0.00001, loss_test:0.01484, lr:5.65e-02, fs:0.78409 (r=0.793,p=0.775),  time:41.943, tt:2264.921\n",
      "Ep:54, loss:0.00001, loss_test:0.01470, lr:5.59e-02, fs:0.78409 (r=0.793,p=0.775),  time:41.903, tt:2304.645\n",
      "Ep:55, loss:0.00001, loss_test:0.01487, lr:5.54e-02, fs:0.77714 (r=0.782,p=0.773),  time:41.904, tt:2346.602\n",
      "Ep:56, loss:0.00001, loss_test:0.01505, lr:5.48e-02, fs:0.76471 (r=0.747,p=0.783),  time:41.917, tt:2389.293\n",
      "Ep:57, loss:0.00001, loss_test:0.01513, lr:5.43e-02, fs:0.75740 (r=0.736,p=0.780),  time:41.930, tt:2431.965\n",
      "Ep:58, loss:0.00001, loss_test:0.01514, lr:5.37e-02, fs:0.78363 (r=0.770,p=0.798),  time:41.921, tt:2473.328\n",
      "Ep:59, loss:0.00001, loss_test:0.01522, lr:5.32e-02, fs:0.76647 (r=0.736,p=0.800),  time:41.928, tt:2515.656\n",
      "Ep:60, loss:0.00001, loss_test:0.01521, lr:5.27e-02, fs:0.75740 (r=0.736,p=0.780),  time:41.931, tt:2557.799\n",
      "Ep:61, loss:0.00001, loss_test:0.01534, lr:5.21e-02, fs:0.75904 (r=0.724,p=0.797),  time:41.932, tt:2599.763\n",
      "Ep:62, loss:0.00001, loss_test:0.01545, lr:5.16e-02, fs:0.76364 (r=0.724,p=0.808),  time:41.938, tt:2642.102\n",
      "Ep:63, loss:0.00001, loss_test:0.01555, lr:5.11e-02, fs:0.74390 (r=0.701,p=0.792),  time:41.968, tt:2685.974\n",
      "Ep:64, loss:0.00001, loss_test:0.01551, lr:5.06e-02, fs:0.75309 (r=0.701,p=0.813),  time:41.987, tt:2729.146\n",
      "Ep:65, loss:0.00001, loss_test:0.01569, lr:5.01e-02, fs:0.74214 (r=0.678,p=0.819),  time:41.973, tt:2770.202\n",
      "Ep:66, loss:0.00001, loss_test:0.01579, lr:4.96e-02, fs:0.73750 (r=0.678,p=0.808),  time:41.951, tt:2810.749\n",
      "Ep:67, loss:0.00001, loss_test:0.01565, lr:4.91e-02, fs:0.72152 (r=0.655,p=0.803),  time:41.938, tt:2851.780\n",
      "Ep:68, loss:0.00001, loss_test:0.01582, lr:4.86e-02, fs:0.71795 (r=0.644,p=0.812),  time:41.943, tt:2894.063\n",
      "Ep:69, loss:0.00001, loss_test:0.01598, lr:4.81e-02, fs:0.71429 (r=0.632,p=0.821),  time:41.935, tt:2935.442\n",
      "Ep:70, loss:0.00001, loss_test:0.01606, lr:4.76e-02, fs:0.69677 (r=0.621,p=0.794),  time:41.914, tt:2975.869\n",
      "Ep:71, loss:0.00001, loss_test:0.01605, lr:4.71e-02, fs:0.68421 (r=0.598,p=0.800),  time:41.872, tt:3014.805\n",
      "Ep:72, loss:0.00001, loss_test:0.01620, lr:4.67e-02, fs:0.69737 (r=0.609,p=0.815),  time:41.849, tt:3054.995\n",
      "Ep:73, loss:0.00001, loss_test:0.01629, lr:4.62e-02, fs:0.69737 (r=0.609,p=0.815),  time:41.863, tt:3097.886\n",
      "Ep:74, loss:0.00001, loss_test:0.01623, lr:4.57e-02, fs:0.68874 (r=0.598,p=0.812),  time:41.835, tt:3137.636\n",
      "Ep:75, loss:0.00001, loss_test:0.01636, lr:4.53e-02, fs:0.68000 (r=0.586,p=0.810),  time:41.848, tt:3180.430\n",
      "Ep:76, loss:0.00001, loss_test:0.01655, lr:4.48e-02, fs:0.67568 (r=0.575,p=0.820),  time:41.834, tt:3221.214\n",
      "Ep:77, loss:0.00001, loss_test:0.01656, lr:4.44e-02, fs:0.67568 (r=0.575,p=0.820),  time:41.837, tt:3263.256\n",
      "Ep:78, loss:0.00001, loss_test:0.01665, lr:4.39e-02, fs:0.67568 (r=0.575,p=0.820),  time:41.849, tt:3306.040\n",
      "Ep:79, loss:0.00001, loss_test:0.01676, lr:4.35e-02, fs:0.66667 (r=0.563,p=0.817),  time:41.845, tt:3347.630\n",
      "Ep:80, loss:0.00001, loss_test:0.01683, lr:4.31e-02, fs:0.66667 (r=0.563,p=0.817),  time:41.838, tt:3388.854\n",
      "Ep:81, loss:0.00001, loss_test:0.01687, lr:4.26e-02, fs:0.66667 (r=0.563,p=0.817),  time:41.838, tt:3430.680\n",
      "Ep:82, loss:0.00001, loss_test:0.01694, lr:4.22e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.830, tt:3471.883\n",
      "Ep:83, loss:0.00001, loss_test:0.01705, lr:4.18e-02, fs:0.66667 (r=0.563,p=0.817),  time:41.794, tt:3510.727\n",
      "Ep:84, loss:0.00001, loss_test:0.01710, lr:4.14e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.791, tt:3552.229\n",
      "Ep:85, loss:0.00001, loss_test:0.01716, lr:4.10e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.760, tt:3591.380\n",
      "Ep:86, loss:0.00001, loss_test:0.01732, lr:4.05e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.734, tt:3630.864\n",
      "Ep:87, loss:0.00001, loss_test:0.01729, lr:4.01e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.730, tt:3672.239\n",
      "Ep:88, loss:0.00001, loss_test:0.01734, lr:3.97e-02, fs:0.67123 (r=0.563,p=0.831),  time:41.724, tt:3713.402\n",
      "Ep:89, loss:0.00001, loss_test:0.01749, lr:3.93e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.704, tt:3753.369\n",
      "Ep:90, loss:0.00001, loss_test:0.01752, lr:3.89e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.690, tt:3793.783\n",
      "Ep:91, loss:0.00001, loss_test:0.01753, lr:3.86e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.670, tt:3833.666\n",
      "Ep:92, loss:0.00001, loss_test:0.01778, lr:3.82e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.682, tt:3876.385\n",
      "Ep:93, loss:0.00001, loss_test:0.01775, lr:3.78e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.670, tt:3916.973\n",
      "Ep:94, loss:0.00001, loss_test:0.01774, lr:3.74e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.652, tt:3956.943\n",
      "Ep:95, loss:0.00001, loss_test:0.01786, lr:3.70e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.625, tt:3996.043\n",
      "Ep:96, loss:0.00001, loss_test:0.01788, lr:3.67e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.599, tt:4035.103\n",
      "Ep:97, loss:0.00001, loss_test:0.01798, lr:3.63e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.598, tt:4076.625\n",
      "Ep:98, loss:0.00001, loss_test:0.01804, lr:3.59e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.596, tt:4118.010\n",
      "Ep:99, loss:0.00001, loss_test:0.01813, lr:3.56e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.605, tt:4160.536\n",
      "Ep:100, loss:0.00001, loss_test:0.01817, lr:3.52e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.599, tt:4201.539\n",
      "Ep:101, loss:0.00001, loss_test:0.01829, lr:3.49e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.605, tt:4243.719\n",
      "Ep:102, loss:0.00001, loss_test:0.01834, lr:3.45e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.604, tt:4285.173\n",
      "Ep:103, loss:0.00001, loss_test:0.01829, lr:3.42e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.573, tt:4323.636\n",
      "Ep:104, loss:0.00001, loss_test:0.01844, lr:3.38e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.591, tt:4367.083\n",
      "Ep:105, loss:0.00001, loss_test:0.01855, lr:3.35e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.585, tt:4407.974\n",
      "Ep:106, loss:0.00001, loss_test:0.01845, lr:3.32e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.582, tt:4449.321\n",
      "Ep:107, loss:0.00001, loss_test:0.01849, lr:3.28e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.568, tt:4489.296\n",
      "Ep:108, loss:0.00001, loss_test:0.01861, lr:3.25e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.554, tt:4529.388\n",
      "Ep:109, loss:0.00001, loss_test:0.01871, lr:3.22e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.550, tt:4570.515\n",
      "Ep:110, loss:0.00001, loss_test:0.01871, lr:3.19e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.544, tt:4611.349\n",
      "Ep:111, loss:0.00001, loss_test:0.01877, lr:3.15e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.532, tt:4651.607\n",
      "Ep:112, loss:0.00001, loss_test:0.01888, lr:3.12e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.524, tt:4692.205\n",
      "Ep:113, loss:0.00001, loss_test:0.01891, lr:3.09e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.520, tt:4733.313\n",
      "Ep:114, loss:0.00001, loss_test:0.01893, lr:3.06e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.520, tt:4774.795\n",
      "Ep:115, loss:0.00001, loss_test:0.01899, lr:3.03e-02, fs:0.67586 (r=0.563,p=0.845),  time:41.529, tt:4817.345\n",
      "Ep:116, loss:0.00001, loss_test:0.01904, lr:3.00e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.532, tt:4859.259\n",
      "Ep:117, loss:0.00001, loss_test:0.01912, lr:2.97e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.521, tt:4899.438\n",
      "Ep:118, loss:0.00001, loss_test:0.01915, lr:2.94e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.520, tt:4940.869\n",
      "Ep:119, loss:0.00001, loss_test:0.01919, lr:2.91e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.523, tt:4982.785\n",
      "Ep:120, loss:0.00001, loss_test:0.01926, lr:2.88e-02, fs:0.68056 (r=0.563,p=0.860),  time:41.523, tt:5024.263\n",
      "Ep:121, loss:0.00001, loss_test:0.01929, lr:2.85e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.522, tt:5065.674\n",
      "Ep:122, loss:0.00001, loss_test:0.01937, lr:2.82e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.513, tt:5106.061\n",
      "Ep:123, loss:0.00001, loss_test:0.01941, lr:2.80e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.499, tt:5145.929\n",
      "Ep:124, loss:0.00000, loss_test:0.01949, lr:2.77e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.506, tt:5188.235\n",
      "Ep:125, loss:0.00000, loss_test:0.01953, lr:2.74e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.511, tt:5230.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:126, loss:0.00000, loss_test:0.01953, lr:2.71e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.502, tt:5270.746\n",
      "Ep:127, loss:0.00000, loss_test:0.01964, lr:2.69e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.487, tt:5310.349\n",
      "Ep:128, loss:0.00000, loss_test:0.01961, lr:2.66e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.476, tt:5350.376\n",
      "Ep:129, loss:0.00000, loss_test:0.01968, lr:2.63e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.474, tt:5391.683\n",
      "Ep:130, loss:0.00000, loss_test:0.01973, lr:2.61e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.465, tt:5431.942\n",
      "Ep:131, loss:0.00000, loss_test:0.01983, lr:2.58e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.457, tt:5472.341\n",
      "Ep:132, loss:0.00000, loss_test:0.01980, lr:2.55e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.472, tt:5515.739\n",
      "Ep:133, loss:0.00000, loss_test:0.01987, lr:2.53e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.480, tt:5558.338\n",
      "Ep:134, loss:0.00000, loss_test:0.01992, lr:2.50e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.474, tt:5599.016\n",
      "Ep:135, loss:0.00000, loss_test:0.01998, lr:2.48e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.483, tt:5641.738\n",
      "Ep:136, loss:0.00000, loss_test:0.01998, lr:2.45e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.487, tt:5683.762\n",
      "Ep:137, loss:0.00000, loss_test:0.02001, lr:2.43e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.486, tt:5725.133\n",
      "Ep:138, loss:0.00000, loss_test:0.02006, lr:2.40e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.477, tt:5765.309\n",
      "Ep:139, loss:0.00000, loss_test:0.02012, lr:2.38e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.477, tt:5806.847\n",
      "Ep:140, loss:0.00000, loss_test:0.02015, lr:2.36e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.481, tt:5848.883\n",
      "Ep:141, loss:0.00000, loss_test:0.02026, lr:2.33e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.502, tt:5893.334\n",
      "Ep:142, loss:0.00000, loss_test:0.02028, lr:2.31e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.501, tt:5934.711\n",
      "Ep:143, loss:0.00000, loss_test:0.02026, lr:2.29e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.515, tt:5978.189\n",
      "Ep:144, loss:0.00000, loss_test:0.02027, lr:2.26e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.521, tt:6020.552\n",
      "Ep:145, loss:0.00000, loss_test:0.02033, lr:2.24e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.528, tt:6063.115\n",
      "Ep:146, loss:0.00000, loss_test:0.02040, lr:2.22e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.535, tt:6105.648\n",
      "Ep:147, loss:0.00000, loss_test:0.02046, lr:2.20e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.540, tt:6147.943\n",
      "Ep:148, loss:0.00000, loss_test:0.02046, lr:2.17e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.547, tt:6190.550\n",
      "Ep:149, loss:0.00000, loss_test:0.02052, lr:2.15e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.547, tt:6232.004\n",
      "Ep:150, loss:0.00000, loss_test:0.02054, lr:2.13e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.549, tt:6273.923\n",
      "Ep:151, loss:0.00000, loss_test:0.02057, lr:2.11e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.552, tt:6315.954\n",
      "Ep:152, loss:0.00000, loss_test:0.02058, lr:2.09e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.559, tt:6358.565\n",
      "Ep:153, loss:0.00000, loss_test:0.02066, lr:2.07e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.577, tt:6402.782\n",
      "Ep:154, loss:0.00000, loss_test:0.02070, lr:2.05e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.595, tt:6447.173\n",
      "Ep:155, loss:0.00000, loss_test:0.02073, lr:2.03e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.612, tt:6491.540\n",
      "Ep:156, loss:0.00000, loss_test:0.02075, lr:2.01e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.634, tt:6536.565\n",
      "Ep:157, loss:0.00000, loss_test:0.02077, lr:1.99e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.637, tt:6578.660\n",
      "Ep:158, loss:0.00000, loss_test:0.02082, lr:1.97e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.655, tt:6623.223\n",
      "Ep:159, loss:0.00000, loss_test:0.02082, lr:1.95e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.667, tt:6666.749\n",
      "Ep:160, loss:0.00000, loss_test:0.02084, lr:1.93e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.685, tt:6711.365\n",
      "Ep:161, loss:0.00000, loss_test:0.02092, lr:1.91e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.708, tt:6756.773\n",
      "Ep:162, loss:0.00000, loss_test:0.02095, lr:1.89e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.725, tt:6801.226\n",
      "Ep:163, loss:0.00000, loss_test:0.02095, lr:1.87e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.727, tt:6843.289\n",
      "Ep:164, loss:0.00000, loss_test:0.02098, lr:1.85e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.757, tt:6889.864\n",
      "Ep:165, loss:0.00000, loss_test:0.02102, lr:1.83e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.788, tt:6936.886\n",
      "Ep:166, loss:0.00000, loss_test:0.02105, lr:1.81e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.800, tt:6980.543\n",
      "Ep:167, loss:0.00000, loss_test:0.02114, lr:1.80e-02, fs:0.68531 (r=0.563,p=0.875),  time:41.812, tt:7024.487\n",
      "Ep:168, loss:0.00000, loss_test:0.02115, lr:1.78e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.827, tt:7068.716\n",
      "Ep:169, loss:0.00000, loss_test:0.02114, lr:1.76e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.840, tt:7112.839\n",
      "Ep:170, loss:0.00000, loss_test:0.02117, lr:1.74e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.864, tt:7158.669\n",
      "Ep:171, loss:0.00000, loss_test:0.02122, lr:1.73e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.876, tt:7202.653\n",
      "Ep:172, loss:0.00000, loss_test:0.02125, lr:1.71e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.889, tt:7246.711\n",
      "Ep:173, loss:0.00000, loss_test:0.02126, lr:1.69e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.890, tt:7288.886\n",
      "Ep:174, loss:0.00000, loss_test:0.02128, lr:1.67e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.899, tt:7332.281\n",
      "Ep:175, loss:0.00000, loss_test:0.02135, lr:1.66e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.906, tt:7375.432\n",
      "Ep:176, loss:0.00000, loss_test:0.02134, lr:1.64e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.904, tt:7417.007\n",
      "Ep:177, loss:0.00000, loss_test:0.02137, lr:1.62e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.906, tt:7459.274\n",
      "Ep:178, loss:0.00000, loss_test:0.02140, lr:1.61e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.902, tt:7500.522\n",
      "Ep:179, loss:0.00000, loss_test:0.02144, lr:1.59e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.915, tt:7544.737\n",
      "Ep:180, loss:0.00000, loss_test:0.02146, lr:1.58e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.923, tt:7588.031\n",
      "Ep:181, loss:0.00000, loss_test:0.02147, lr:1.56e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.929, tt:7631.135\n",
      "Ep:182, loss:0.00000, loss_test:0.02150, lr:1.54e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.932, tt:7673.553\n",
      "Ep:183, loss:0.00000, loss_test:0.02154, lr:1.53e-02, fs:0.69014 (r=0.563,p=0.891),  time:41.926, tt:7714.412\n",
      "Ep:184, loss:0.00000, loss_test:0.02157, lr:1.51e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.927, tt:7756.411\n",
      "Ep:185, loss:0.00000, loss_test:0.02159, lr:1.50e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.934, tt:7799.683\n",
      "Ep:186, loss:0.00000, loss_test:0.02165, lr:1.48e-02, fs:0.68085 (r=0.552,p=0.889),  time:41.935, tt:7841.939\n",
      "Ep:187, loss:0.00000, loss_test:0.02166, lr:1.47e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.935, tt:7883.771\n",
      "Ep:188, loss:0.00000, loss_test:0.02167, lr:1.45e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.939, tt:7926.494\n",
      "Ep:189, loss:0.00000, loss_test:0.02169, lr:1.44e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.955, tt:7971.405\n",
      "Ep:190, loss:0.00000, loss_test:0.02170, lr:1.43e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.955, tt:8013.359\n",
      "Ep:191, loss:0.00000, loss_test:0.02175, lr:1.41e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.957, tt:8055.675\n",
      "Ep:192, loss:0.00000, loss_test:0.02178, lr:1.40e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.959, tt:8098.009\n",
      "Ep:193, loss:0.00000, loss_test:0.02178, lr:1.38e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.962, tt:8140.605\n",
      "Ep:194, loss:0.00000, loss_test:0.02180, lr:1.37e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.973, tt:8184.640\n",
      "Ep:195, loss:0.00000, loss_test:0.02180, lr:1.36e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.966, tt:8225.257\n",
      "Ep:196, loss:0.00000, loss_test:0.02185, lr:1.34e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.964, tt:8266.937\n",
      "Ep:197, loss:0.00000, loss_test:0.02186, lr:1.33e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.969, tt:8309.843\n",
      "Ep:198, loss:0.00000, loss_test:0.02188, lr:1.32e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.970, tt:8352.107\n",
      "Ep:199, loss:0.00000, loss_test:0.02189, lr:1.30e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.968, tt:8393.582\n",
      "Ep:200, loss:0.00000, loss_test:0.02193, lr:1.29e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.967, tt:8435.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:201, loss:0.00000, loss_test:0.02194, lr:1.28e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.963, tt:8476.498\n",
      "Ep:202, loss:0.00000, loss_test:0.02195, lr:1.26e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.964, tt:8518.597\n",
      "Ep:203, loss:0.00000, loss_test:0.02199, lr:1.25e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.963, tt:8560.449\n",
      "Ep:204, loss:0.00000, loss_test:0.02204, lr:1.24e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.971, tt:8604.127\n",
      "Ep:205, loss:0.00000, loss_test:0.02204, lr:1.23e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.990, tt:8649.897\n",
      "Ep:206, loss:0.00000, loss_test:0.02202, lr:1.21e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.988, tt:8691.596\n",
      "Ep:207, loss:0.00000, loss_test:0.02205, lr:1.20e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.975, tt:8730.800\n",
      "Ep:208, loss:0.00000, loss_test:0.02209, lr:1.19e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.968, tt:8771.246\n",
      "Ep:209, loss:0.00000, loss_test:0.02212, lr:1.18e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.964, tt:8812.495\n",
      "Ep:210, loss:0.00000, loss_test:0.02210, lr:1.17e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.957, tt:8852.895\n",
      "Ep:211, loss:0.00000, loss_test:0.02213, lr:1.15e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.916, tt:8886.169\n",
      "Ep:212, loss:0.00000, loss_test:0.02214, lr:1.14e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.873, tt:8918.899\n",
      "Ep:213, loss:0.00000, loss_test:0.02216, lr:1.13e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.850, tt:8955.940\n",
      "Ep:214, loss:0.00000, loss_test:0.02217, lr:1.12e-02, fs:0.67143 (r=0.540,p=0.887),  time:41.828, tt:8992.990\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1824 Test samples: 174\n",
      "Train positive samples: 912 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14946, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.460, tt:42.460\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14914, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.775, tt:83.550\n",
      "Ep:2, loss:0.00028, loss_test:0.14857, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.339, tt:127.018\n",
      "Ep:3, loss:0.00027, loss_test:0.14744, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.519, tt:170.077\n",
      "Ep:4, loss:0.00026, loss_test:0.14532, lr:1.00e-02, fs:0.63673 (r=0.897,p=0.494),  time:42.859, tt:214.293\n",
      "Ep:5, loss:0.00025, loss_test:0.14228, lr:1.00e-02, fs:0.59091 (r=0.747,p=0.489),  time:43.102, tt:258.612\n",
      "Ep:6, loss:0.00023, loss_test:0.14308, lr:1.00e-02, fs:0.52809 (r=0.540,p=0.516),  time:42.846, tt:299.921\n",
      "Ep:7, loss:0.00022, loss_test:0.13930, lr:1.00e-02, fs:0.55556 (r=0.575,p=0.538),  time:43.006, tt:344.044\n",
      "Ep:8, loss:0.00022, loss_test:0.13425, lr:1.00e-02, fs:0.62745 (r=0.736,p=0.547),  time:43.070, tt:387.627\n",
      "Ep:9, loss:0.00021, loss_test:0.13143, lr:1.00e-02, fs:0.65686 (r=0.770,p=0.573),  time:43.225, tt:432.247\n",
      "Ep:10, loss:0.00020, loss_test:0.13112, lr:1.00e-02, fs:0.65193 (r=0.678,p=0.628),  time:43.558, tt:479.143\n",
      "Ep:11, loss:0.00020, loss_test:0.12818, lr:1.00e-02, fs:0.65574 (r=0.690,p=0.625),  time:43.661, tt:523.937\n",
      "Ep:12, loss:0.00019, loss_test:0.12353, lr:9.90e-03, fs:0.67005 (r=0.759,p=0.600),  time:43.580, tt:566.541\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.12024, lr:9.90e-03, fs:0.69565 (r=0.736,p=0.660),  time:43.499, tt:608.991\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.11796, lr:9.90e-03, fs:0.68605 (r=0.678,p=0.694),  time:43.381, tt:650.717\n",
      "Ep:15, loss:0.00017, loss_test:0.11411, lr:9.90e-03, fs:0.73196 (r=0.816,p=0.664),  time:43.352, tt:693.631\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.11091, lr:9.90e-03, fs:0.74866 (r=0.805,p=0.700),  time:43.342, tt:736.808\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.10729, lr:9.90e-03, fs:0.76923 (r=0.805,p=0.737),  time:43.344, tt:780.192\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.10422, lr:9.90e-03, fs:0.76344 (r=0.816,p=0.717),  time:43.292, tt:822.540\n",
      "Ep:19, loss:0.00015, loss_test:0.10344, lr:9.90e-03, fs:0.76836 (r=0.782,p=0.756),  time:43.318, tt:866.351\n",
      "Ep:20, loss:0.00014, loss_test:0.09928, lr:9.90e-03, fs:0.79365 (r=0.862,p=0.735),  time:43.323, tt:909.778\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.09859, lr:9.90e-03, fs:0.74854 (r=0.736,p=0.762),  time:43.270, tt:951.935\n",
      "Ep:22, loss:0.00013, loss_test:0.09476, lr:9.90e-03, fs:0.81443 (r=0.908,p=0.738),  time:43.224, tt:994.158\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.09373, lr:9.90e-03, fs:0.80226 (r=0.816,p=0.789),  time:43.266, tt:1038.388\n",
      "Ep:24, loss:0.00012, loss_test:0.09055, lr:9.90e-03, fs:0.82051 (r=0.920,p=0.741),  time:43.333, tt:1083.327\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.09254, lr:9.90e-03, fs:0.76647 (r=0.736,p=0.800),  time:43.366, tt:1127.520\n",
      "Ep:26, loss:0.00011, loss_test:0.08712, lr:9.90e-03, fs:0.85417 (r=0.943,p=0.781),  time:43.304, tt:1169.211\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.08809, lr:9.90e-03, fs:0.82081 (r=0.816,p=0.826),  time:43.309, tt:1212.657\n",
      "Ep:28, loss:0.00010, loss_test:0.08397, lr:9.90e-03, fs:0.86458 (r=0.954,p=0.790),  time:43.307, tt:1255.897\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08456, lr:9.90e-03, fs:0.80925 (r=0.805,p=0.814),  time:43.353, tt:1300.596\n",
      "Ep:30, loss:0.00010, loss_test:0.08199, lr:9.90e-03, fs:0.87568 (r=0.931,p=0.827),  time:43.325, tt:1343.068\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.08258, lr:9.90e-03, fs:0.83616 (r=0.851,p=0.822),  time:43.277, tt:1384.860\n",
      "Ep:32, loss:0.00009, loss_test:0.08162, lr:9.90e-03, fs:0.86188 (r=0.897,p=0.830),  time:43.283, tt:1428.327\n",
      "Ep:33, loss:0.00009, loss_test:0.08140, lr:9.90e-03, fs:0.78571 (r=0.759,p=0.815),  time:43.217, tt:1469.378\n",
      "Ep:34, loss:0.00008, loss_test:0.08214, lr:9.90e-03, fs:0.76543 (r=0.713,p=0.827),  time:43.227, tt:1512.937\n",
      "Ep:35, loss:0.00008, loss_test:0.08085, lr:9.90e-03, fs:0.77019 (r=0.713,p=0.838),  time:43.222, tt:1555.975\n",
      "Ep:36, loss:0.00008, loss_test:0.08161, lr:9.90e-03, fs:0.76074 (r=0.713,p=0.816),  time:43.206, tt:1598.630\n",
      "Ep:37, loss:0.00008, loss_test:0.07582, lr:9.90e-03, fs:0.81871 (r=0.805,p=0.833),  time:43.146, tt:1639.542\n",
      "Ep:38, loss:0.00007, loss_test:0.08235, lr:9.90e-03, fs:0.74359 (r=0.667,p=0.841),  time:43.135, tt:1682.245\n",
      "Ep:39, loss:0.00007, loss_test:0.07627, lr:9.90e-03, fs:0.73885 (r=0.667,p=0.829),  time:43.119, tt:1724.760\n",
      "Ep:40, loss:0.00007, loss_test:0.08196, lr:9.90e-03, fs:0.72368 (r=0.632,p=0.846),  time:43.109, tt:1767.455\n",
      "Ep:41, loss:0.00007, loss_test:0.08008, lr:9.90e-03, fs:0.74510 (r=0.655,p=0.864),  time:43.062, tt:1808.584\n",
      "Ep:42, loss:0.00006, loss_test:0.08096, lr:9.80e-03, fs:0.72483 (r=0.621,p=0.871),  time:43.011, tt:1849.458\n",
      "Ep:43, loss:0.00006, loss_test:0.07687, lr:9.70e-03, fs:0.74026 (r=0.655,p=0.851),  time:42.991, tt:1891.585\n",
      "Ep:44, loss:0.00006, loss_test:0.08111, lr:9.61e-03, fs:0.74510 (r=0.655,p=0.864),  time:42.934, tt:1932.052\n",
      "Ep:45, loss:0.00005, loss_test:0.07913, lr:9.51e-03, fs:0.73333 (r=0.632,p=0.873),  time:42.908, tt:1973.791\n",
      "Ep:46, loss:0.00005, loss_test:0.07964, lr:9.41e-03, fs:0.76433 (r=0.690,p=0.857),  time:42.895, tt:2016.086\n",
      "Ep:47, loss:0.00005, loss_test:0.08702, lr:9.32e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.928, tt:2060.538\n",
      "Ep:48, loss:0.00005, loss_test:0.08148, lr:9.23e-03, fs:0.77632 (r=0.678,p=0.908),  time:42.912, tt:2102.693\n",
      "Ep:49, loss:0.00005, loss_test:0.08532, lr:9.14e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.870, tt:2143.504\n",
      "Ep:50, loss:0.00005, loss_test:0.07690, lr:9.04e-03, fs:0.76129 (r=0.678,p=0.868),  time:42.842, tt:2184.954\n",
      "Ep:51, loss:0.00004, loss_test:0.08424, lr:8.95e-03, fs:0.75342 (r=0.632,p=0.932),  time:42.832, tt:2227.250\n",
      "Ep:52, loss:0.00004, loss_test:0.07726, lr:8.86e-03, fs:0.74324 (r=0.632,p=0.902),  time:42.781, tt:2267.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:53, loss:0.00004, loss_test:0.08026, lr:8.78e-03, fs:0.73973 (r=0.621,p=0.915),  time:42.704, tt:2306.032\n",
      "Ep:54, loss:0.00004, loss_test:0.08614, lr:8.69e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.660, tt:2346.304\n",
      "Ep:55, loss:0.00004, loss_test:0.07671, lr:8.60e-03, fs:0.74667 (r=0.644,p=0.889),  time:42.634, tt:2387.491\n",
      "Ep:56, loss:0.00004, loss_test:0.08875, lr:8.51e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.611, tt:2428.809\n",
      "Ep:57, loss:0.00003, loss_test:0.07262, lr:8.43e-03, fs:0.75000 (r=0.655,p=0.877),  time:42.608, tt:2471.269\n",
      "Ep:58, loss:0.00003, loss_test:0.09737, lr:8.35e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.644, tt:2516.025\n",
      "Ep:59, loss:0.00003, loss_test:0.07745, lr:8.26e-03, fs:0.76821 (r=0.667,p=0.906),  time:42.629, tt:2557.733\n",
      "Ep:60, loss:0.00003, loss_test:0.08515, lr:8.18e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.633, tt:2600.608\n",
      "Ep:61, loss:0.00003, loss_test:0.08259, lr:8.10e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.613, tt:2641.979\n",
      "Ep:62, loss:0.00003, loss_test:0.08552, lr:8.02e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.619, tt:2685.001\n",
      "Ep:63, loss:0.00003, loss_test:0.08214, lr:7.94e-03, fs:0.72603 (r=0.609,p=0.898),  time:42.588, tt:2725.656\n",
      "Ep:64, loss:0.00003, loss_test:0.08784, lr:7.86e-03, fs:0.79195 (r=0.678,p=0.952),  time:42.601, tt:2769.084\n",
      "Ep:65, loss:0.00003, loss_test:0.09064, lr:7.78e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.625, tt:2813.255\n",
      "Ep:66, loss:0.00003, loss_test:0.07923, lr:7.70e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.626, tt:2855.911\n",
      "Ep:67, loss:0.00003, loss_test:0.08722, lr:7.62e-03, fs:0.67164 (r=0.517,p=0.957),  time:42.570, tt:2894.775\n",
      "Ep:68, loss:0.00003, loss_test:0.07986, lr:7.55e-03, fs:0.73469 (r=0.621,p=0.900),  time:42.580, tt:2938.025\n",
      "Ep:69, loss:0.00002, loss_test:0.08075, lr:7.47e-03, fs:0.76712 (r=0.644,p=0.949),  time:42.591, tt:2981.365\n",
      "Ep:70, loss:0.00002, loss_test:0.08730, lr:7.40e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.581, tt:3023.238\n",
      "Ep:71, loss:0.00002, loss_test:0.08248, lr:7.32e-03, fs:0.75168 (r=0.644,p=0.903),  time:42.576, tt:3065.505\n",
      "Ep:72, loss:0.00002, loss_test:0.08621, lr:7.25e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.579, tt:3108.286\n",
      "Ep:73, loss:0.00002, loss_test:0.08141, lr:7.18e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.567, tt:3149.928\n",
      "Ep:74, loss:0.00002, loss_test:0.08578, lr:7.11e-03, fs:0.73611 (r=0.609,p=0.930),  time:42.572, tt:3192.916\n",
      "Ep:75, loss:0.00002, loss_test:0.08706, lr:7.03e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.556, tt:3234.233\n",
      "Ep:76, loss:0.00002, loss_test:0.08227, lr:6.96e-03, fs:0.77333 (r=0.667,p=0.921),  time:42.564, tt:3277.418\n",
      "Ep:77, loss:0.00002, loss_test:0.08697, lr:6.89e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.553, tt:3319.160\n",
      "Ep:78, loss:0.00002, loss_test:0.08506, lr:6.83e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.569, tt:3362.923\n",
      "Ep:79, loss:0.00001, loss_test:0.08170, lr:6.76e-03, fs:0.73103 (r=0.609,p=0.914),  time:42.571, tt:3405.690\n",
      "Ep:80, loss:0.00001, loss_test:0.08943, lr:6.69e-03, fs:0.73381 (r=0.586,p=0.981),  time:42.551, tt:3446.607\n",
      "Ep:81, loss:0.00001, loss_test:0.08443, lr:6.62e-03, fs:0.73611 (r=0.609,p=0.930),  time:42.553, tt:3489.312\n",
      "Ep:82, loss:0.00001, loss_test:0.08439, lr:6.56e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.539, tt:3530.701\n",
      "Ep:83, loss:0.00001, loss_test:0.08839, lr:6.49e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.514, tt:3571.180\n",
      "Ep:84, loss:0.00001, loss_test:0.08398, lr:6.43e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.500, tt:3612.507\n",
      "Ep:85, loss:0.00001, loss_test:0.08609, lr:6.36e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.475, tt:3652.819\n",
      "Ep:86, loss:0.00001, loss_test:0.08618, lr:6.30e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.474, tt:3695.254\n",
      "Ep:87, loss:0.00001, loss_test:0.08573, lr:6.24e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.452, tt:3735.797\n",
      "Ep:88, loss:0.00001, loss_test:0.08615, lr:6.17e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.430, tt:3776.309\n",
      "Ep:89, loss:0.00001, loss_test:0.08575, lr:6.11e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.408, tt:3816.747\n",
      "Ep:90, loss:0.00001, loss_test:0.09089, lr:6.05e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.382, tt:3856.720\n",
      "Ep:91, loss:0.00001, loss_test:0.08672, lr:5.99e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.353, tt:3896.514\n",
      "Ep:92, loss:0.00001, loss_test:0.08878, lr:5.93e-03, fs:0.74126 (r=0.609,p=0.946),  time:42.345, tt:3938.079\n",
      "Ep:93, loss:0.00001, loss_test:0.08762, lr:5.87e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.305, tt:3976.625\n",
      "Ep:94, loss:0.00001, loss_test:0.08843, lr:5.81e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.317, tt:4020.075\n",
      "Ep:95, loss:0.00001, loss_test:0.09031, lr:5.75e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.289, tt:4059.792\n",
      "Ep:96, loss:0.00001, loss_test:0.09044, lr:5.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.280, tt:4101.119\n",
      "Ep:97, loss:0.00001, loss_test:0.09038, lr:5.64e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.279, tt:4143.325\n",
      "Ep:98, loss:0.00001, loss_test:0.09188, lr:5.58e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.263, tt:4184.017\n",
      "Ep:99, loss:0.00001, loss_test:0.09065, lr:5.53e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.258, tt:4225.780\n",
      "Ep:100, loss:0.00001, loss_test:0.09030, lr:5.47e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.256, tt:4267.846\n",
      "Ep:101, loss:0.00001, loss_test:0.08841, lr:5.42e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.266, tt:4311.126\n",
      "Ep:102, loss:0.00001, loss_test:0.09087, lr:5.36e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.257, tt:4352.498\n",
      "Ep:103, loss:0.00001, loss_test:0.08996, lr:5.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.221, tt:4390.956\n",
      "Ep:104, loss:0.00001, loss_test:0.09088, lr:5.26e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.206, tt:4431.600\n",
      "Ep:105, loss:0.00001, loss_test:0.09030, lr:5.20e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.190, tt:4472.110\n",
      "Ep:106, loss:0.00001, loss_test:0.08897, lr:5.15e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.191, tt:4514.404\n",
      "Ep:107, loss:0.00001, loss_test:0.09155, lr:5.10e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.180, tt:4555.416\n",
      "Ep:108, loss:0.00001, loss_test:0.08787, lr:5.05e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.155, tt:4594.923\n",
      "Ep:109, loss:0.00001, loss_test:0.09375, lr:5.00e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.137, tt:4635.122\n",
      "Ep:110, loss:0.00001, loss_test:0.08912, lr:4.95e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.121, tt:4675.449\n",
      "Ep:111, loss:0.00001, loss_test:0.09297, lr:4.90e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.122, tt:4717.675\n",
      "Ep:112, loss:0.00001, loss_test:0.09217, lr:4.85e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.125, tt:4760.113\n",
      "Ep:113, loss:0.00001, loss_test:0.09059, lr:4.80e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.118, tt:4801.403\n",
      "Ep:114, loss:0.00001, loss_test:0.09344, lr:4.75e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.111, tt:4842.787\n",
      "Ep:115, loss:0.00001, loss_test:0.08931, lr:4.71e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.093, tt:4882.845\n",
      "Ep:116, loss:0.00000, loss_test:0.09384, lr:4.66e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.074, tt:4922.648\n",
      "Ep:117, loss:0.00000, loss_test:0.08914, lr:4.61e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.068, tt:4964.045\n",
      "Ep:118, loss:0.00000, loss_test:0.09418, lr:4.57e-03, fs:0.75177 (r=0.609,p=0.981),  time:42.066, tt:5005.902\n",
      "Ep:119, loss:0.00000, loss_test:0.09383, lr:4.52e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.040, tt:5044.773\n",
      "Ep:120, loss:0.00000, loss_test:0.08963, lr:4.48e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.030, tt:5085.624\n",
      "Ep:121, loss:0.00000, loss_test:0.09329, lr:4.43e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.023, tt:5126.839\n",
      "Ep:122, loss:0.00000, loss_test:0.09174, lr:4.39e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.008, tt:5166.926\n",
      "Ep:123, loss:0.00000, loss_test:0.09187, lr:4.34e-03, fs:0.74648 (r=0.609,p=0.964),  time:42.002, tt:5208.289\n",
      "Ep:124, loss:0.00000, loss_test:0.09034, lr:4.30e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.964, tt:5245.486\n",
      "Ep:125, loss:0.00000, loss_test:0.08930, lr:4.26e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.971, tt:5288.365\n",
      "Ep:126, loss:0.00000, loss_test:0.09331, lr:4.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.957, tt:5328.585\n",
      "Ep:127, loss:0.00000, loss_test:0.09239, lr:4.17e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.951, tt:5369.709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:128, loss:0.00000, loss_test:0.09079, lr:4.13e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.948, tt:5411.276\n",
      "Ep:129, loss:0.00000, loss_test:0.09417, lr:4.09e-03, fs:0.75177 (r=0.609,p=0.981),  time:41.947, tt:5453.059\n",
      "Ep:130, loss:0.00000, loss_test:0.09010, lr:4.05e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.959, tt:5496.694\n",
      "Ep:131, loss:0.00000, loss_test:0.09173, lr:4.01e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.960, tt:5538.773\n",
      "Ep:132, loss:0.00000, loss_test:0.09307, lr:3.97e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.962, tt:5580.956\n",
      "Ep:133, loss:0.00000, loss_test:0.09058, lr:3.93e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.955, tt:5621.980\n",
      "Ep:134, loss:0.00000, loss_test:0.09183, lr:3.89e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.955, tt:5663.971\n",
      "Ep:135, loss:0.00000, loss_test:0.09270, lr:3.85e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.951, tt:5705.374\n",
      "Ep:136, loss:0.00000, loss_test:0.09123, lr:3.81e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.945, tt:5746.401\n",
      "Ep:137, loss:0.00000, loss_test:0.09134, lr:3.77e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.953, tt:5789.499\n",
      "Ep:138, loss:0.00000, loss_test:0.09146, lr:3.73e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.962, tt:5832.667\n",
      "Ep:139, loss:0.00000, loss_test:0.09172, lr:3.70e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.965, tt:5875.050\n",
      "Ep:140, loss:0.00000, loss_test:0.09226, lr:3.66e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.972, tt:5918.084\n",
      "Ep:141, loss:0.00000, loss_test:0.09188, lr:3.62e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.964, tt:5958.957\n",
      "Ep:142, loss:0.00000, loss_test:0.09095, lr:3.59e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.960, tt:6000.272\n",
      "Ep:143, loss:0.00000, loss_test:0.09308, lr:3.55e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.960, tt:6042.183\n",
      "Ep:144, loss:0.00000, loss_test:0.09283, lr:3.52e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.962, tt:6084.489\n",
      "Ep:145, loss:0.00000, loss_test:0.09135, lr:3.48e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.949, tt:6124.602\n",
      "Ep:146, loss:0.00000, loss_test:0.09378, lr:3.45e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.951, tt:6166.729\n",
      "Ep:147, loss:0.00000, loss_test:0.09374, lr:3.41e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.937, tt:6206.688\n",
      "Ep:148, loss:0.00000, loss_test:0.09311, lr:3.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.917, tt:6245.639\n",
      "Ep:149, loss:0.00000, loss_test:0.09336, lr:3.34e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.915, tt:6287.198\n",
      "Ep:150, loss:0.00000, loss_test:0.09274, lr:3.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.902, tt:6327.270\n",
      "Ep:151, loss:0.00000, loss_test:0.09306, lr:3.28e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.930, tt:6373.308\n",
      "Ep:152, loss:0.00000, loss_test:0.09327, lr:3.24e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.923, tt:6414.178\n",
      "Ep:153, loss:0.00000, loss_test:0.09295, lr:3.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.928, tt:6456.977\n",
      "Ep:154, loss:0.00000, loss_test:0.09308, lr:3.18e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.926, tt:6498.541\n",
      "Ep:155, loss:0.00000, loss_test:0.09350, lr:3.15e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.927, tt:6540.611\n",
      "Ep:156, loss:0.00000, loss_test:0.09365, lr:3.12e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.916, tt:6580.834\n",
      "Ep:157, loss:0.00000, loss_test:0.09333, lr:3.09e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.901, tt:6620.310\n",
      "Ep:158, loss:0.00000, loss_test:0.09328, lr:3.05e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.890, tt:6660.480\n",
      "Ep:159, loss:0.00000, loss_test:0.09316, lr:3.02e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.882, tt:6701.049\n",
      "Ep:160, loss:0.00000, loss_test:0.09403, lr:2.99e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.873, tt:6741.584\n",
      "Ep:161, loss:0.00000, loss_test:0.09451, lr:2.96e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.862, tt:6781.695\n",
      "Ep:162, loss:0.00000, loss_test:0.09388, lr:2.93e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.847, tt:6821.067\n",
      "Ep:163, loss:0.00000, loss_test:0.09405, lr:2.90e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.841, tt:6861.917\n",
      "Ep:164, loss:0.00000, loss_test:0.09527, lr:2.88e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.835, tt:6902.839\n",
      "Ep:165, loss:0.00000, loss_test:0.09446, lr:2.85e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.824, tt:6942.774\n",
      "Ep:166, loss:0.00000, loss_test:0.09348, lr:2.82e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.813, tt:6982.693\n",
      "Ep:167, loss:0.00000, loss_test:0.09488, lr:2.79e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.806, tt:7023.348\n",
      "Ep:168, loss:0.00000, loss_test:0.09519, lr:2.76e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.789, tt:7062.403\n",
      "Ep:169, loss:0.00000, loss_test:0.09386, lr:2.73e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.782, tt:7102.863\n",
      "Ep:170, loss:0.00000, loss_test:0.09421, lr:2.71e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.784, tt:7145.030\n",
      "Ep:171, loss:0.00000, loss_test:0.09531, lr:2.68e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.785, tt:7187.101\n",
      "Ep:172, loss:0.00000, loss_test:0.09469, lr:2.65e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.769, tt:7226.047\n",
      "Ep:173, loss:0.00000, loss_test:0.09466, lr:2.63e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.758, tt:7265.978\n",
      "Ep:174, loss:0.00000, loss_test:0.09520, lr:2.60e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.744, tt:7305.131\n",
      "Ep:175, loss:0.00000, loss_test:0.09445, lr:2.57e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.770, tt:7351.459\n",
      "Ep:176, loss:0.00000, loss_test:0.09533, lr:2.55e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.769, tt:7393.170\n",
      "Ep:177, loss:0.00000, loss_test:0.09635, lr:2.52e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.755, tt:7432.472\n",
      "Ep:178, loss:0.00000, loss_test:0.09567, lr:2.50e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.745, tt:7472.339\n",
      "Ep:179, loss:0.00000, loss_test:0.09536, lr:2.47e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.730, tt:7511.473\n",
      "Ep:180, loss:0.00000, loss_test:0.09465, lr:2.45e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.716, tt:7550.570\n",
      "Ep:181, loss:0.00000, loss_test:0.09576, lr:2.42e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.714, tt:7591.862\n",
      "Ep:182, loss:0.00000, loss_test:0.09550, lr:2.40e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.712, tt:7633.217\n",
      "Ep:183, loss:0.00000, loss_test:0.09485, lr:2.38e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.701, tt:7672.972\n",
      "Ep:184, loss:0.00000, loss_test:0.09436, lr:2.35e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.680, tt:7710.852\n",
      "Ep:185, loss:0.00000, loss_test:0.09496, lr:2.33e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.674, tt:7751.369\n",
      "Ep:186, loss:0.00000, loss_test:0.09521, lr:2.31e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.676, tt:7793.407\n",
      "Ep:187, loss:0.00000, loss_test:0.09524, lr:2.28e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.676, tt:7835.018\n",
      "Ep:188, loss:0.00000, loss_test:0.09509, lr:2.26e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.691, tt:7879.681\n",
      "Ep:189, loss:0.00000, loss_test:0.09452, lr:2.24e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.684, tt:7919.972\n",
      "Ep:190, loss:0.00000, loss_test:0.09548, lr:2.21e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.681, tt:7961.143\n",
      "Ep:191, loss:0.00000, loss_test:0.09615, lr:2.19e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.676, tt:8001.835\n",
      "Ep:192, loss:0.00000, loss_test:0.09610, lr:2.17e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.675, tt:8043.277\n",
      "Ep:193, loss:0.00000, loss_test:0.09479, lr:2.15e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.667, tt:8083.368\n",
      "Ep:194, loss:0.00000, loss_test:0.09547, lr:2.13e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.655, tt:8122.738\n",
      "Ep:195, loss:0.00000, loss_test:0.09609, lr:2.11e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.652, tt:8163.779\n",
      "Ep:196, loss:0.00000, loss_test:0.09582, lr:2.08e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.654, tt:8205.885\n",
      "Ep:197, loss:0.00000, loss_test:0.09527, lr:2.06e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.654, tt:8247.436\n",
      "Ep:198, loss:0.00000, loss_test:0.09526, lr:2.04e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.646, tt:8287.468\n",
      "Ep:199, loss:0.00000, loss_test:0.09540, lr:2.02e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.646, tt:8329.122\n",
      "Ep:200, loss:0.00000, loss_test:0.09537, lr:2.00e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.667, tt:8375.114\n",
      "Ep:201, loss:0.00000, loss_test:0.09527, lr:1.98e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.666, tt:8416.577\n",
      "Ep:202, loss:0.00000, loss_test:0.09588, lr:1.96e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.663, tt:8457.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.09584, lr:1.94e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.656, tt:8497.919\n",
      "Ep:204, loss:0.00000, loss_test:0.09528, lr:1.92e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.657, tt:8539.590\n",
      "Ep:205, loss:0.00000, loss_test:0.09526, lr:1.90e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.658, tt:8581.580\n",
      "Ep:206, loss:0.00000, loss_test:0.09550, lr:1.89e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.657, tt:8623.100\n",
      "Ep:207, loss:0.00000, loss_test:0.09565, lr:1.87e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.658, tt:8664.958\n",
      "Ep:208, loss:0.00000, loss_test:0.09503, lr:1.85e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.657, tt:8706.288\n",
      "Ep:209, loss:0.00000, loss_test:0.09550, lr:1.83e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.652, tt:8746.935\n",
      "Ep:210, loss:0.00000, loss_test:0.09569, lr:1.81e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.645, tt:8787.138\n",
      "Ep:211, loss:0.00000, loss_test:0.09534, lr:1.79e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.624, tt:8824.306\n",
      "Ep:212, loss:0.00000, loss_test:0.09497, lr:1.78e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.563, tt:8852.984\n",
      "Ep:213, loss:0.00000, loss_test:0.09488, lr:1.76e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.466, tt:8873.758\n",
      "Ep:214, loss:0.00000, loss_test:0.09536, lr:1.74e-03, fs:0.74648 (r=0.609,p=0.964),  time:41.341, tt:8888.303\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,213,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,214,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,215,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.01963, lr:6.00e-02, fs:0.65693 (r=0.909,p=0.514),  time:34.495, tt:34.495\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02303, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.114, tt:76.229\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02402, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.099, tt:117.296\n",
      "Ep:3, loss:0.00005, loss_test:0.02288, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:39.504, tt:158.015\n",
      "Ep:4, loss:0.00004, loss_test:0.02114, lr:6.00e-02, fs:0.67354 (r=0.990,p=0.510),  time:39.282, tt:196.411\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.01975, lr:6.00e-02, fs:0.66667 (r=0.919,p=0.523),  time:39.955, tt:239.728\n",
      "Ep:6, loss:0.00004, loss_test:0.01906, lr:6.00e-02, fs:0.67451 (r=0.869,p=0.551),  time:39.986, tt:279.902\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01855, lr:6.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:40.017, tt:320.138\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01815, lr:6.00e-02, fs:0.67692 (r=0.889,p=0.547),  time:40.047, tt:360.419\n",
      "Ep:9, loss:0.00004, loss_test:0.01796, lr:6.00e-02, fs:0.70149 (r=0.949,p=0.556),  time:40.161, tt:401.607\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01775, lr:6.00e-02, fs:0.70849 (r=0.970,p=0.558),  time:40.400, tt:444.402\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01735, lr:6.00e-02, fs:0.71587 (r=0.980,p=0.564),  time:40.460, tt:485.518\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01682, lr:6.00e-02, fs:0.72932 (r=0.980,p=0.581),  time:40.420, tt:525.459\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01634, lr:6.00e-02, fs:0.71538 (r=0.939,p=0.578),  time:40.356, tt:564.990\n",
      "Ep:14, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.70866 (r=0.909,p=0.581),  time:40.399, tt:605.990\n",
      "Ep:15, loss:0.00003, loss_test:0.01560, lr:6.00e-02, fs:0.73437 (r=0.949,p=0.599),  time:40.450, tt:647.193\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01527, lr:6.00e-02, fs:0.74809 (r=0.990,p=0.601),  time:40.464, tt:687.885\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01496, lr:6.00e-02, fs:0.75676 (r=0.990,p=0.613),  time:40.439, tt:727.907\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01465, lr:6.00e-02, fs:0.76265 (r=0.990,p=0.620),  time:40.479, tt:769.110\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01436, lr:6.00e-02, fs:0.77778 (r=0.990,p=0.641),  time:40.518, tt:810.364\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01407, lr:6.00e-02, fs:0.78049 (r=0.970,p=0.653),  time:40.487, tt:850.219\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01383, lr:6.00e-02, fs:0.79668 (r=0.970,p=0.676),  time:40.528, tt:891.619\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:40.577, tt:933.267\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01340, lr:6.00e-02, fs:0.81013 (r=0.970,p=0.696),  time:40.513, tt:972.303\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01322, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:40.492, tt:1012.289\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01308, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:40.479, tt:1052.462\n",
      "Ep:26, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.81356 (r=0.970,p=0.701),  time:40.528, tt:1094.265\n",
      "Ep:27, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:40.676, tt:1138.932\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:40.668, tt:1179.378\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:40.692, tt:1220.768\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:40.618, tt:1259.146\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.82759 (r=0.970,p=0.722),  time:40.674, tt:1301.558\n",
      "Ep:32, loss:0.00002, loss_test:0.01215, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:40.694, tt:1342.908\n",
      "Ep:33, loss:0.00002, loss_test:0.01203, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:40.728, tt:1384.751\n",
      "Ep:34, loss:0.00002, loss_test:0.01194, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:40.657, tt:1422.978\n",
      "Ep:35, loss:0.00002, loss_test:0.01183, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:40.637, tt:1462.934\n",
      "Ep:36, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:40.646, tt:1503.897\n",
      "Ep:37, loss:0.00002, loss_test:0.01163, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:40.633, tt:1544.035\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01154, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:40.606, tt:1583.621\n",
      "Ep:39, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:40.596, tt:1623.822\n",
      "Ep:40, loss:0.00002, loss_test:0.01138, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:40.557, tt:1662.845\n",
      "Ep:41, loss:0.00002, loss_test:0.01131, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:40.585, tt:1704.560\n",
      "Ep:42, loss:0.00002, loss_test:0.01122, lr:6.00e-02, fs:0.82667 (r=0.939,p=0.738),  time:40.572, tt:1744.575\n",
      "Ep:43, loss:0.00002, loss_test:0.01115, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:40.598, tt:1786.330\n",
      "Ep:44, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:40.619, tt:1827.841\n",
      "Ep:45, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:40.567, tt:1866.105\n",
      "Ep:46, loss:0.00001, loss_test:0.01096, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:40.596, tt:1907.996\n",
      "Ep:47, loss:0.00001, loss_test:0.01091, lr:6.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:40.600, tt:1948.805\n",
      "Ep:48, loss:0.00001, loss_test:0.01087, lr:6.00e-02, fs:0.82727 (r=0.919,p=0.752),  time:40.596, tt:1989.201\n",
      "Ep:49, loss:0.00001, loss_test:0.01082, lr:5.94e-02, fs:0.82028 (r=0.899,p=0.754),  time:40.608, tt:2030.417\n",
      "Ep:50, loss:0.00001, loss_test:0.01078, lr:5.88e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.629, tt:2072.064\n",
      "Ep:51, loss:0.00001, loss_test:0.01073, lr:5.82e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.630, tt:2112.750\n",
      "Ep:52, loss:0.00001, loss_test:0.01073, lr:5.76e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.621, tt:2152.921\n",
      "Ep:53, loss:0.00001, loss_test:0.01066, lr:5.71e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.608, tt:2192.819\n",
      "Ep:54, loss:0.00001, loss_test:0.01061, lr:5.65e-02, fs:0.81860 (r=0.889,p=0.759),  time:40.611, tt:2233.630\n",
      "Ep:55, loss:0.00001, loss_test:0.01058, lr:5.59e-02, fs:0.82407 (r=0.899,p=0.761),  time:40.582, tt:2272.568\n",
      "Ep:56, loss:0.00001, loss_test:0.01055, lr:5.54e-02, fs:0.82407 (r=0.899,p=0.761),  time:40.590, tt:2313.655\n",
      "Ep:57, loss:0.00001, loss_test:0.01055, lr:5.48e-02, fs:0.83178 (r=0.899,p=0.774),  time:40.553, tt:2352.098\n",
      "Ep:58, loss:0.00001, loss_test:0.01052, lr:5.43e-02, fs:0.83178 (r=0.899,p=0.774),  time:40.544, tt:2392.086\n",
      "Ep:59, loss:0.00001, loss_test:0.01048, lr:5.37e-02, fs:0.83178 (r=0.899,p=0.774),  time:40.556, tt:2433.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:60, loss:0.00001, loss_test:0.01047, lr:5.32e-02, fs:0.83178 (r=0.899,p=0.774),  time:40.573, tt:2474.978\n",
      "Ep:61, loss:0.00001, loss_test:0.01045, lr:5.27e-02, fs:0.83568 (r=0.899,p=0.781),  time:40.565, tt:2515.057\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01040, lr:5.27e-02, fs:0.83568 (r=0.899,p=0.781),  time:40.579, tt:2556.483\n",
      "Ep:63, loss:0.00001, loss_test:0.01039, lr:5.27e-02, fs:0.83962 (r=0.899,p=0.788),  time:40.568, tt:2596.379\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.01036, lr:5.27e-02, fs:0.83962 (r=0.899,p=0.788),  time:40.538, tt:2635.000\n",
      "Ep:65, loss:0.00001, loss_test:0.01032, lr:5.27e-02, fs:0.83568 (r=0.899,p=0.781),  time:40.556, tt:2676.706\n",
      "Ep:66, loss:0.00001, loss_test:0.01033, lr:5.27e-02, fs:0.83962 (r=0.899,p=0.788),  time:40.554, tt:2717.121\n",
      "Ep:67, loss:0.00001, loss_test:0.01027, lr:5.27e-02, fs:0.84360 (r=0.899,p=0.795),  time:40.545, tt:2757.036\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01024, lr:5.27e-02, fs:0.84360 (r=0.899,p=0.795),  time:40.551, tt:2798.014\n",
      "Ep:69, loss:0.00001, loss_test:0.01031, lr:5.27e-02, fs:0.84360 (r=0.899,p=0.795),  time:40.584, tt:2840.857\n",
      "Ep:70, loss:0.00001, loss_test:0.01024, lr:5.27e-02, fs:0.84360 (r=0.899,p=0.795),  time:40.591, tt:2881.983\n",
      "Ep:71, loss:0.00001, loss_test:0.01022, lr:5.27e-02, fs:0.84360 (r=0.899,p=0.795),  time:40.583, tt:2921.989\n",
      "Ep:72, loss:0.00001, loss_test:0.01023, lr:5.27e-02, fs:0.83810 (r=0.889,p=0.793),  time:40.597, tt:2963.556\n",
      "Ep:73, loss:0.00001, loss_test:0.01019, lr:5.27e-02, fs:0.84615 (r=0.889,p=0.807),  time:40.642, tt:3007.543\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.01021, lr:5.27e-02, fs:0.84211 (r=0.889,p=0.800),  time:40.646, tt:3048.482\n",
      "Ep:75, loss:0.00001, loss_test:0.01020, lr:5.27e-02, fs:0.84615 (r=0.889,p=0.807),  time:40.631, tt:3087.938\n",
      "Ep:76, loss:0.00001, loss_test:0.01020, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.626, tt:3128.201\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01017, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.617, tt:3168.093\n",
      "Ep:78, loss:0.00001, loss_test:0.01017, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.621, tt:3209.060\n",
      "Ep:79, loss:0.00001, loss_test:0.01017, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.600, tt:3247.998\n",
      "Ep:80, loss:0.00001, loss_test:0.01012, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.595, tt:3288.204\n",
      "Ep:81, loss:0.00001, loss_test:0.01015, lr:5.27e-02, fs:0.85024 (r=0.889,p=0.815),  time:40.602, tt:3329.334\n",
      "Ep:82, loss:0.00001, loss_test:0.01018, lr:5.27e-02, fs:0.86275 (r=0.889,p=0.838),  time:40.592, tt:3369.105\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.01012, lr:5.27e-02, fs:0.86275 (r=0.889,p=0.838),  time:40.580, tt:3408.681\n",
      "Ep:84, loss:0.00001, loss_test:0.01011, lr:5.27e-02, fs:0.86275 (r=0.889,p=0.838),  time:40.564, tt:3447.916\n",
      "Ep:85, loss:0.00001, loss_test:0.01015, lr:5.27e-02, fs:0.86700 (r=0.889,p=0.846),  time:40.611, tt:3492.532\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.01012, lr:5.27e-02, fs:0.86700 (r=0.889,p=0.846),  time:40.611, tt:3533.128\n",
      "Ep:87, loss:0.00001, loss_test:0.01014, lr:5.27e-02, fs:0.87129 (r=0.889,p=0.854),  time:40.578, tt:3570.867\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.01011, lr:5.27e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.565, tt:3610.296\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.01011, lr:5.27e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.560, tt:3650.361\n",
      "Ep:90, loss:0.00001, loss_test:0.01015, lr:5.27e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.540, tt:3689.152\n",
      "Ep:91, loss:0.00001, loss_test:0.01013, lr:5.27e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.533, tt:3729.051\n",
      "Ep:92, loss:0.00001, loss_test:0.01014, lr:5.27e-02, fs:0.87562 (r=0.889,p=0.863),  time:40.535, tt:3769.770\n",
      "Ep:93, loss:0.00001, loss_test:0.01013, lr:5.27e-02, fs:0.88442 (r=0.889,p=0.880),  time:40.534, tt:3810.230\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01011, lr:5.27e-02, fs:0.88000 (r=0.889,p=0.871),  time:40.539, tt:3851.169\n",
      "Ep:95, loss:0.00001, loss_test:0.01014, lr:5.27e-02, fs:0.89000 (r=0.899,p=0.881),  time:40.519, tt:3889.820\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01015, lr:5.27e-02, fs:0.88442 (r=0.889,p=0.880),  time:40.520, tt:3930.463\n",
      "Ep:97, loss:0.00001, loss_test:0.01016, lr:5.27e-02, fs:0.89000 (r=0.899,p=0.881),  time:40.509, tt:3969.878\n",
      "Ep:98, loss:0.00001, loss_test:0.01019, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.512, tt:4010.669\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01016, lr:5.27e-02, fs:0.89447 (r=0.899,p=0.890),  time:40.501, tt:4050.121\n",
      "Ep:100, loss:0.00001, loss_test:0.01018, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.486, tt:4089.127\n",
      "Ep:101, loss:0.00001, loss_test:0.01022, lr:5.27e-02, fs:0.88889 (r=0.889,p=0.889),  time:40.487, tt:4129.723\n",
      "Ep:102, loss:0.00001, loss_test:0.01022, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.495, tt:4170.935\n",
      "Ep:103, loss:0.00001, loss_test:0.01022, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.502, tt:4212.194\n",
      "Ep:104, loss:0.00001, loss_test:0.01023, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.490, tt:4251.441\n",
      "Ep:105, loss:0.00001, loss_test:0.01024, lr:5.27e-02, fs:0.89899 (r=0.899,p=0.899),  time:40.487, tt:4291.663\n",
      "Ep:106, loss:0.00001, loss_test:0.01025, lr:5.27e-02, fs:0.90816 (r=0.899,p=0.918),  time:40.482, tt:4331.597\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00000, loss_test:0.01027, lr:5.27e-02, fs:0.90355 (r=0.899,p=0.908),  time:40.499, tt:4373.889\n",
      "Ep:108, loss:0.00000, loss_test:0.01031, lr:5.27e-02, fs:0.90816 (r=0.899,p=0.918),  time:40.498, tt:4414.272\n",
      "Ep:109, loss:0.00000, loss_test:0.01030, lr:5.27e-02, fs:0.90816 (r=0.899,p=0.918),  time:40.499, tt:4454.846\n",
      "Ep:110, loss:0.00000, loss_test:0.01029, lr:5.27e-02, fs:0.91282 (r=0.899,p=0.927),  time:40.491, tt:4494.552\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.01030, lr:5.27e-02, fs:0.91282 (r=0.899,p=0.927),  time:40.483, tt:4534.108\n",
      "Ep:112, loss:0.00000, loss_test:0.01036, lr:5.27e-02, fs:0.91282 (r=0.899,p=0.927),  time:40.481, tt:4574.343\n",
      "Ep:113, loss:0.00000, loss_test:0.01037, lr:5.27e-02, fs:0.91282 (r=0.899,p=0.927),  time:40.463, tt:4612.772\n",
      "Ep:114, loss:0.00000, loss_test:0.01040, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.456, tt:4652.456\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00000, loss_test:0.01042, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.461, tt:4693.466\n",
      "Ep:116, loss:0.00000, loss_test:0.01039, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.455, tt:4733.271\n",
      "Ep:117, loss:0.00000, loss_test:0.01044, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.458, tt:4774.014\n",
      "Ep:118, loss:0.00000, loss_test:0.01049, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.446, tt:4813.029\n",
      "Ep:119, loss:0.00000, loss_test:0.01048, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.445, tt:4853.380\n",
      "Ep:120, loss:0.00000, loss_test:0.01051, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.443, tt:4893.622\n",
      "Ep:121, loss:0.00000, loss_test:0.01053, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.446, tt:4934.428\n",
      "Ep:122, loss:0.00000, loss_test:0.01056, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.452, tt:4975.562\n",
      "Ep:123, loss:0.00000, loss_test:0.01050, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.447, tt:5015.472\n",
      "Ep:124, loss:0.00000, loss_test:0.01060, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.444, tt:5055.479\n",
      "Ep:125, loss:0.00000, loss_test:0.01061, lr:5.27e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.441, tt:5095.603\n",
      "Ep:126, loss:0.00000, loss_test:0.01065, lr:5.21e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.434, tt:5135.121\n",
      "Ep:127, loss:0.00000, loss_test:0.01063, lr:5.16e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.426, tt:5174.579\n",
      "Ep:128, loss:0.00000, loss_test:0.01069, lr:5.11e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.432, tt:5215.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00000, loss_test:0.01072, lr:5.06e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.430, tt:5255.949\n",
      "Ep:130, loss:0.00000, loss_test:0.01073, lr:5.01e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.433, tt:5296.696\n",
      "Ep:131, loss:0.00000, loss_test:0.01079, lr:4.96e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.433, tt:5337.107\n",
      "Ep:132, loss:0.00000, loss_test:0.01071, lr:4.91e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.425, tt:5376.538\n",
      "Ep:133, loss:0.00000, loss_test:0.01083, lr:4.86e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.423, tt:5416.712\n",
      "Ep:134, loss:0.00000, loss_test:0.01080, lr:4.81e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.425, tt:5457.387\n",
      "Ep:135, loss:0.00000, loss_test:0.01086, lr:4.76e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.415, tt:5496.375\n",
      "Ep:136, loss:0.00000, loss_test:0.01088, lr:4.71e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.414, tt:5536.663\n",
      "Ep:137, loss:0.00000, loss_test:0.01085, lr:4.67e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.420, tt:5578.022\n",
      "Ep:138, loss:0.00000, loss_test:0.01093, lr:4.62e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.425, tt:5619.093\n",
      "Ep:139, loss:0.00000, loss_test:0.01091, lr:4.57e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.423, tt:5659.243\n",
      "Ep:140, loss:0.00000, loss_test:0.01101, lr:4.53e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.435, tt:5701.399\n",
      "Ep:141, loss:0.00000, loss_test:0.01094, lr:4.48e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.440, tt:5742.469\n",
      "Ep:142, loss:0.00000, loss_test:0.01101, lr:4.44e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.447, tt:5783.852\n",
      "Ep:143, loss:0.00000, loss_test:0.01104, lr:4.39e-02, fs:0.92228 (r=0.899,p=0.947),  time:40.453, tt:5825.198\n",
      "##########Best model found so far##########\n",
      "Ep:144, loss:0.00000, loss_test:0.01105, lr:4.39e-02, fs:0.91753 (r=0.899,p=0.937),  time:40.474, tt:5868.723\n",
      "Ep:145, loss:0.00000, loss_test:0.01107, lr:4.39e-02, fs:0.92228 (r=0.899,p=0.947),  time:40.480, tt:5910.134\n",
      "Ep:146, loss:0.00000, loss_test:0.01104, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.478, tt:5950.319\n",
      "##########Best model found so far##########\n",
      "Ep:147, loss:0.00000, loss_test:0.01113, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.480, tt:5991.031\n",
      "Ep:148, loss:0.00000, loss_test:0.01111, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.491, tt:6033.180\n",
      "Ep:149, loss:0.00000, loss_test:0.01115, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.488, tt:6073.270\n",
      "Ep:150, loss:0.00000, loss_test:0.01114, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.489, tt:6113.768\n",
      "Ep:151, loss:0.00000, loss_test:0.01118, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.484, tt:6153.551\n",
      "Ep:152, loss:0.00000, loss_test:0.01122, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.480, tt:6193.477\n",
      "Ep:153, loss:0.00000, loss_test:0.01119, lr:4.39e-02, fs:0.92147 (r=0.889,p=0.957),  time:40.470, tt:6232.368\n",
      "Ep:154, loss:0.00000, loss_test:0.01123, lr:4.39e-02, fs:0.92708 (r=0.899,p=0.957),  time:40.472, tt:6273.137\n",
      "Ep:155, loss:0.00000, loss_test:0.01122, lr:4.39e-02, fs:0.92147 (r=0.889,p=0.957),  time:40.481, tt:6314.995\n",
      "Ep:156, loss:0.00000, loss_test:0.01131, lr:4.39e-02, fs:0.91579 (r=0.879,p=0.956),  time:40.481, tt:6355.494\n",
      "Ep:157, loss:0.00000, loss_test:0.01131, lr:4.39e-02, fs:0.91579 (r=0.879,p=0.956),  time:40.480, tt:6395.784\n",
      "Ep:158, loss:0.00000, loss_test:0.01134, lr:4.35e-02, fs:0.90426 (r=0.859,p=0.955),  time:40.480, tt:6436.331\n",
      "Ep:159, loss:0.00000, loss_test:0.01133, lr:4.31e-02, fs:0.90426 (r=0.859,p=0.955),  time:40.476, tt:6476.081\n",
      "Ep:160, loss:0.00000, loss_test:0.01138, lr:4.26e-02, fs:0.90426 (r=0.859,p=0.955),  time:40.467, tt:6515.193\n",
      "Ep:161, loss:0.00000, loss_test:0.01140, lr:4.22e-02, fs:0.89840 (r=0.848,p=0.955),  time:40.476, tt:6557.050\n",
      "Ep:162, loss:0.00000, loss_test:0.01141, lr:4.18e-02, fs:0.90426 (r=0.859,p=0.955),  time:40.484, tt:6598.921\n",
      "Ep:163, loss:0.00000, loss_test:0.01146, lr:4.14e-02, fs:0.89247 (r=0.838,p=0.954),  time:40.485, tt:6639.532\n",
      "Ep:164, loss:0.00000, loss_test:0.01146, lr:4.10e-02, fs:0.89840 (r=0.848,p=0.955),  time:40.498, tt:6682.159\n",
      "Ep:165, loss:0.00000, loss_test:0.01149, lr:4.05e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.502, tt:6723.266\n",
      "Ep:166, loss:0.00000, loss_test:0.01145, lr:4.01e-02, fs:0.88649 (r=0.828,p=0.953),  time:40.489, tt:6761.615\n",
      "Ep:167, loss:0.00000, loss_test:0.01154, lr:3.97e-02, fs:0.89247 (r=0.838,p=0.954),  time:40.484, tt:6801.262\n",
      "Ep:168, loss:0.00000, loss_test:0.01154, lr:3.93e-02, fs:0.87432 (r=0.808,p=0.952),  time:40.487, tt:6842.368\n",
      "Ep:169, loss:0.00000, loss_test:0.01153, lr:3.89e-02, fs:0.88649 (r=0.828,p=0.953),  time:40.475, tt:6880.675\n",
      "Ep:170, loss:0.00000, loss_test:0.01159, lr:3.86e-02, fs:0.88043 (r=0.818,p=0.953),  time:40.477, tt:6921.541\n",
      "Ep:171, loss:0.00000, loss_test:0.01156, lr:3.82e-02, fs:0.86813 (r=0.798,p=0.952),  time:40.478, tt:6962.284\n",
      "Ep:172, loss:0.00000, loss_test:0.01163, lr:3.78e-02, fs:0.87432 (r=0.808,p=0.952),  time:40.483, tt:7003.535\n",
      "Ep:173, loss:0.00000, loss_test:0.01164, lr:3.74e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.486, tt:7044.518\n",
      "Ep:174, loss:0.00000, loss_test:0.01160, lr:3.70e-02, fs:0.87432 (r=0.808,p=0.952),  time:40.481, tt:7084.176\n",
      "Ep:175, loss:0.00000, loss_test:0.01168, lr:3.67e-02, fs:0.86813 (r=0.798,p=0.952),  time:40.486, tt:7125.523\n",
      "Ep:176, loss:0.00000, loss_test:0.01168, lr:3.63e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.487, tt:7166.185\n",
      "Ep:177, loss:0.00000, loss_test:0.01169, lr:3.59e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.487, tt:7206.769\n",
      "Ep:178, loss:0.00000, loss_test:0.01168, lr:3.56e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.516, tt:7252.320\n",
      "Ep:179, loss:0.00000, loss_test:0.01171, lr:3.52e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.521, tt:7293.700\n",
      "Ep:180, loss:0.00000, loss_test:0.01175, lr:3.49e-02, fs:0.85556 (r=0.778,p=0.951),  time:40.519, tt:7333.874\n",
      "Ep:181, loss:0.00000, loss_test:0.01175, lr:3.45e-02, fs:0.86188 (r=0.788,p=0.951),  time:40.520, tt:7374.572\n",
      "Ep:182, loss:0.00000, loss_test:0.01175, lr:3.42e-02, fs:0.85556 (r=0.778,p=0.951),  time:40.508, tt:7412.916\n",
      "Ep:183, loss:0.00000, loss_test:0.01177, lr:3.38e-02, fs:0.85556 (r=0.778,p=0.951),  time:40.502, tt:7452.290\n",
      "Ep:184, loss:0.00000, loss_test:0.01182, lr:3.35e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.503, tt:7493.097\n",
      "Ep:185, loss:0.00000, loss_test:0.01179, lr:3.32e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.500, tt:7532.975\n",
      "Ep:186, loss:0.00000, loss_test:0.01181, lr:3.28e-02, fs:0.85556 (r=0.778,p=0.951),  time:40.503, tt:7574.106\n",
      "Ep:187, loss:0.00000, loss_test:0.01186, lr:3.25e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.507, tt:7615.355\n",
      "Ep:188, loss:0.00000, loss_test:0.01183, lr:3.22e-02, fs:0.84916 (r=0.768,p=0.950),  time:40.507, tt:7655.869\n",
      "Ep:189, loss:0.00000, loss_test:0.01187, lr:3.19e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.505, tt:7695.970\n",
      "Ep:190, loss:0.00000, loss_test:0.01190, lr:3.15e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.503, tt:7735.994\n",
      "Ep:191, loss:0.00000, loss_test:0.01190, lr:3.12e-02, fs:0.84270 (r=0.758,p=0.949),  time:40.493, tt:7774.588\n",
      "Ep:192, loss:0.00000, loss_test:0.01193, lr:3.09e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.500, tt:7816.419\n",
      "Ep:193, loss:0.00000, loss_test:0.01193, lr:3.06e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.500, tt:7856.994\n",
      "Ep:194, loss:0.00000, loss_test:0.01193, lr:3.03e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.502, tt:7897.793\n",
      "Ep:195, loss:0.00000, loss_test:0.01196, lr:3.00e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.500, tt:7937.990\n",
      "Ep:196, loss:0.00000, loss_test:0.01198, lr:2.97e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.498, tt:7978.044\n",
      "Ep:197, loss:0.00000, loss_test:0.01196, lr:2.94e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.498, tt:8018.604\n",
      "Ep:198, loss:0.00000, loss_test:0.01199, lr:2.91e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.503, tt:8060.119\n",
      "Ep:199, loss:0.00000, loss_test:0.01202, lr:2.88e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.504, tt:8100.841\n",
      "Ep:200, loss:0.00000, loss_test:0.01203, lr:2.85e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.504, tt:8141.256\n",
      "Ep:201, loss:0.00000, loss_test:0.01203, lr:2.82e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.495, tt:8180.066\n",
      "Ep:202, loss:0.00000, loss_test:0.01205, lr:2.80e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.494, tt:8220.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.01207, lr:2.77e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.499, tt:8261.888\n",
      "Ep:204, loss:0.00000, loss_test:0.01207, lr:2.74e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.503, tt:8303.188\n",
      "Ep:205, loss:0.00000, loss_test:0.01208, lr:2.71e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.514, tt:8345.943\n",
      "Ep:206, loss:0.00000, loss_test:0.01212, lr:2.69e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.518, tt:8387.235\n",
      "Ep:207, loss:0.00000, loss_test:0.01209, lr:2.66e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.551, tt:8434.513\n",
      "Ep:208, loss:0.00000, loss_test:0.01212, lr:2.63e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.539, tt:8472.643\n",
      "Ep:209, loss:0.00000, loss_test:0.01214, lr:2.61e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.513, tt:8507.664\n",
      "Ep:210, loss:0.00000, loss_test:0.01212, lr:2.58e-02, fs:0.83616 (r=0.747,p=0.949),  time:40.452, tt:8535.435\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13976, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.683, tt:31.683\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13740, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:36.739, tt:73.478\n",
      "Ep:2, loss:0.00027, loss_test:0.13294, lr:1.00e-02, fs:0.66897 (r=0.980,p=0.508),  time:38.321, tt:114.962\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12528, lr:1.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:39.196, tt:156.785\n",
      "Ep:4, loss:0.00024, loss_test:0.11666, lr:1.00e-02, fs:0.68293 (r=0.848,p=0.571),  time:39.711, tt:198.557\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11100, lr:1.00e-02, fs:0.67568 (r=0.758,p=0.610),  time:40.253, tt:241.517\n",
      "Ep:6, loss:0.00023, loss_test:0.10954, lr:1.00e-02, fs:0.68807 (r=0.758,p=0.630),  time:40.672, tt:284.705\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10887, lr:1.00e-02, fs:0.69058 (r=0.778,p=0.621),  time:40.738, tt:325.901\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10713, lr:1.00e-02, fs:0.70175 (r=0.808,p=0.620),  time:40.906, tt:368.157\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10258, lr:1.00e-02, fs:0.72072 (r=0.808,p=0.650),  time:41.008, tt:410.081\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09905, lr:1.00e-02, fs:0.73488 (r=0.798,p=0.681),  time:41.161, tt:452.768\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09741, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:41.240, tt:494.885\n",
      "Ep:12, loss:0.00018, loss_test:0.09574, lr:1.00e-02, fs:0.73059 (r=0.808,p=0.667),  time:41.133, tt:534.732\n",
      "Ep:13, loss:0.00018, loss_test:0.09351, lr:1.00e-02, fs:0.72897 (r=0.788,p=0.678),  time:41.200, tt:576.807\n",
      "Ep:14, loss:0.00017, loss_test:0.09184, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.190, tt:617.854\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08960, lr:1.00e-02, fs:0.75349 (r=0.818,p=0.698),  time:41.201, tt:659.210\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08743, lr:1.00e-02, fs:0.76415 (r=0.818,p=0.717),  time:41.306, tt:702.196\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08576, lr:1.00e-02, fs:0.76056 (r=0.818,p=0.711),  time:41.318, tt:743.731\n",
      "Ep:18, loss:0.00014, loss_test:0.08362, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:41.404, tt:786.678\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08228, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:41.387, tt:827.736\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00013, loss_test:0.08089, lr:1.00e-02, fs:0.79426 (r=0.838,p=0.755),  time:41.396, tt:869.306\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.07924, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:41.419, tt:911.228\n",
      "Ep:22, loss:0.00012, loss_test:0.07803, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:41.460, tt:953.570\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00012, loss_test:0.07686, lr:1.00e-02, fs:0.81731 (r=0.859,p=0.780),  time:41.524, tt:996.578\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00011, loss_test:0.07548, lr:1.00e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.517, tt:1037.916\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07441, lr:1.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:41.459, tt:1077.930\n",
      "Ep:26, loss:0.00011, loss_test:0.07407, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:41.442, tt:1118.941\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00010, loss_test:0.07324, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:41.488, tt:1161.669\n",
      "Ep:28, loss:0.00010, loss_test:0.07278, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:41.550, tt:1204.956\n",
      "Ep:29, loss:0.00009, loss_test:0.07181, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:41.638, tt:1249.142\n",
      "Ep:30, loss:0.00009, loss_test:0.07125, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:41.658, tt:1291.409\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00009, loss_test:0.07079, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:41.707, tt:1334.633\n",
      "Ep:32, loss:0.00009, loss_test:0.06895, lr:1.00e-02, fs:0.84000 (r=0.848,p=0.832),  time:41.654, tt:1374.577\n",
      "Ep:33, loss:0.00008, loss_test:0.06980, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.681, tt:1417.148\n",
      "Ep:34, loss:0.00008, loss_test:0.06870, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:41.685, tt:1458.961\n",
      "Ep:35, loss:0.00007, loss_test:0.06892, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:41.701, tt:1501.225\n",
      "Ep:36, loss:0.00007, loss_test:0.06668, lr:1.00e-02, fs:0.84158 (r=0.859,p=0.825),  time:41.590, tt:1538.814\n",
      "Ep:37, loss:0.00007, loss_test:0.06786, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:41.609, tt:1581.132\n",
      "Ep:38, loss:0.00007, loss_test:0.06784, lr:1.00e-02, fs:0.84314 (r=0.869,p=0.819),  time:41.617, tt:1623.059\n",
      "Ep:39, loss:0.00006, loss_test:0.06764, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:41.632, tt:1665.286\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.06808, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:41.679, tt:1708.840\n",
      "Ep:41, loss:0.00006, loss_test:0.06621, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:41.660, tt:1749.710\n",
      "Ep:42, loss:0.00006, loss_test:0.06565, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.642, tt:1790.589\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00005, loss_test:0.06696, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.614, tt:1831.007\n",
      "Ep:44, loss:0.00005, loss_test:0.06388, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:41.596, tt:1871.805\n",
      "Ep:45, loss:0.00005, loss_test:0.06699, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:41.574, tt:1912.410\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00005, loss_test:0.06484, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.579, tt:1954.224\n",
      "Ep:47, loss:0.00005, loss_test:0.06489, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:41.551, tt:1994.466\n",
      "Ep:48, loss:0.00005, loss_test:0.06426, lr:1.00e-02, fs:0.86735 (r=0.859,p=0.876),  time:41.504, tt:2033.689\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.06320, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:41.525, tt:2076.230\n",
      "Ep:50, loss:0.00004, loss_test:0.06460, lr:1.00e-02, fs:0.87755 (r=0.869,p=0.887),  time:41.492, tt:2116.070\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.06268, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:41.483, tt:2157.129\n",
      "Ep:52, loss:0.00004, loss_test:0.06462, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:41.470, tt:2197.920\n",
      "Ep:53, loss:0.00004, loss_test:0.06544, lr:1.00e-02, fs:0.85572 (r=0.869,p=0.843),  time:41.455, tt:2238.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:54, loss:0.00004, loss_test:0.06502, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:41.503, tt:2282.680\n",
      "Ep:55, loss:0.00004, loss_test:0.06209, lr:1.00e-02, fs:0.86869 (r=0.869,p=0.869),  time:41.470, tt:2322.311\n",
      "Ep:56, loss:0.00004, loss_test:0.06781, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:41.467, tt:2363.635\n",
      "Ep:57, loss:0.00004, loss_test:0.06267, lr:1.00e-02, fs:0.87437 (r=0.879,p=0.870),  time:41.489, tt:2406.334\n",
      "Ep:58, loss:0.00003, loss_test:0.06529, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:41.446, tt:2445.286\n",
      "Ep:59, loss:0.00003, loss_test:0.06180, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.433, tt:2485.993\n",
      "Ep:60, loss:0.00003, loss_test:0.06756, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:41.440, tt:2527.829\n",
      "Ep:61, loss:0.00003, loss_test:0.06423, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.443, tt:2569.463\n",
      "Ep:62, loss:0.00003, loss_test:0.06345, lr:9.90e-03, fs:0.87047 (r=0.848,p=0.894),  time:41.431, tt:2610.185\n",
      "Ep:63, loss:0.00003, loss_test:0.06575, lr:9.80e-03, fs:0.83243 (r=0.778,p=0.895),  time:41.435, tt:2651.832\n",
      "Ep:64, loss:0.00003, loss_test:0.06332, lr:9.70e-03, fs:0.87629 (r=0.859,p=0.895),  time:41.428, tt:2692.823\n",
      "Ep:65, loss:0.00003, loss_test:0.06565, lr:9.61e-03, fs:0.84043 (r=0.798,p=0.888),  time:41.427, tt:2734.210\n",
      "Ep:66, loss:0.00003, loss_test:0.06569, lr:9.51e-03, fs:0.85083 (r=0.778,p=0.939),  time:41.440, tt:2776.458\n",
      "Ep:67, loss:0.00003, loss_test:0.06348, lr:9.41e-03, fs:0.87047 (r=0.848,p=0.894),  time:41.401, tt:2815.241\n",
      "Ep:68, loss:0.00003, loss_test:0.06763, lr:9.32e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.416, tt:2857.688\n",
      "Ep:69, loss:0.00003, loss_test:0.06245, lr:9.23e-03, fs:0.87500 (r=0.848,p=0.903),  time:41.366, tt:2895.643\n",
      "Ep:70, loss:0.00003, loss_test:0.06611, lr:9.14e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.350, tt:2935.829\n",
      "Ep:71, loss:0.00002, loss_test:0.06700, lr:9.04e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.353, tt:2977.402\n",
      "Ep:72, loss:0.00002, loss_test:0.06417, lr:8.95e-03, fs:0.85561 (r=0.808,p=0.909),  time:41.343, tt:3018.057\n",
      "Ep:73, loss:0.00002, loss_test:0.06858, lr:8.86e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.335, tt:3058.788\n",
      "Ep:74, loss:0.00002, loss_test:0.06527, lr:8.78e-03, fs:0.81319 (r=0.747,p=0.892),  time:41.346, tt:3100.951\n",
      "Ep:75, loss:0.00002, loss_test:0.06476, lr:8.69e-03, fs:0.86339 (r=0.798,p=0.940),  time:41.325, tt:3140.716\n",
      "Ep:76, loss:0.00002, loss_test:0.06721, lr:8.60e-03, fs:0.75294 (r=0.646,p=0.901),  time:41.358, tt:3184.560\n",
      "Ep:77, loss:0.00002, loss_test:0.06407, lr:8.51e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.393, tt:3228.631\n",
      "Ep:78, loss:0.00002, loss_test:0.06816, lr:8.43e-03, fs:0.73810 (r=0.626,p=0.899),  time:41.397, tt:3270.352\n",
      "Ep:79, loss:0.00002, loss_test:0.06818, lr:8.35e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.400, tt:3311.963\n",
      "Ep:80, loss:0.00002, loss_test:0.06415, lr:8.26e-03, fs:0.82873 (r=0.758,p=0.915),  time:41.430, tt:3355.838\n",
      "Ep:81, loss:0.00002, loss_test:0.06857, lr:8.18e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.421, tt:3396.560\n",
      "Ep:82, loss:0.00002, loss_test:0.06683, lr:8.10e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.428, tt:3438.557\n",
      "Ep:83, loss:0.00002, loss_test:0.06732, lr:8.02e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.427, tt:3479.884\n",
      "Ep:84, loss:0.00002, loss_test:0.06705, lr:7.94e-03, fs:0.73171 (r=0.606,p=0.923),  time:41.425, tt:3521.139\n",
      "Ep:85, loss:0.00002, loss_test:0.06812, lr:7.86e-03, fs:0.79290 (r=0.677,p=0.957),  time:41.419, tt:3561.994\n",
      "Ep:86, loss:0.00002, loss_test:0.06639, lr:7.78e-03, fs:0.76647 (r=0.646,p=0.941),  time:41.412, tt:3602.859\n",
      "Ep:87, loss:0.00002, loss_test:0.06786, lr:7.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.418, tt:3644.791\n",
      "Ep:88, loss:0.00001, loss_test:0.06770, lr:7.62e-03, fs:0.73939 (r=0.616,p=0.924),  time:41.428, tt:3687.078\n",
      "Ep:89, loss:0.00001, loss_test:0.06708, lr:7.55e-03, fs:0.80702 (r=0.697,p=0.958),  time:41.443, tt:3729.865\n",
      "Ep:90, loss:0.00001, loss_test:0.06842, lr:7.47e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.452, tt:3772.143\n",
      "Ep:91, loss:0.00001, loss_test:0.06807, lr:7.40e-03, fs:0.82081 (r=0.717,p=0.959),  time:41.463, tt:3814.569\n",
      "Ep:92, loss:0.00001, loss_test:0.06825, lr:7.32e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.473, tt:3856.965\n",
      "Ep:93, loss:0.00001, loss_test:0.06650, lr:7.25e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.514, tt:3902.348\n",
      "Ep:94, loss:0.00001, loss_test:0.06798, lr:7.18e-03, fs:0.73171 (r=0.606,p=0.923),  time:41.534, tt:3945.734\n",
      "Ep:95, loss:0.00001, loss_test:0.06715, lr:7.11e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.536, tt:3987.450\n",
      "Ep:96, loss:0.00001, loss_test:0.06801, lr:7.03e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.550, tt:4030.386\n",
      "Ep:97, loss:0.00001, loss_test:0.06641, lr:6.96e-03, fs:0.85556 (r=0.778,p=0.951),  time:41.562, tt:4073.097\n",
      "Ep:98, loss:0.00001, loss_test:0.06726, lr:6.89e-03, fs:0.74699 (r=0.626,p=0.925),  time:41.569, tt:4115.315\n",
      "Ep:99, loss:0.00001, loss_test:0.06796, lr:6.83e-03, fs:0.80000 (r=0.687,p=0.958),  time:41.588, tt:4158.802\n",
      "Ep:100, loss:0.00001, loss_test:0.06670, lr:6.76e-03, fs:0.75449 (r=0.636,p=0.926),  time:41.583, tt:4199.921\n",
      "Ep:101, loss:0.00001, loss_test:0.06706, lr:6.69e-03, fs:0.78824 (r=0.677,p=0.944),  time:41.619, tt:4245.163\n",
      "Ep:102, loss:0.00001, loss_test:0.06817, lr:6.62e-03, fs:0.73620 (r=0.606,p=0.938),  time:41.642, tt:4289.114\n",
      "Ep:103, loss:0.00001, loss_test:0.06647, lr:6.56e-03, fs:0.78824 (r=0.677,p=0.944),  time:41.647, tt:4331.257\n",
      "Ep:104, loss:0.00001, loss_test:0.06831, lr:6.49e-03, fs:0.72840 (r=0.596,p=0.937),  time:41.663, tt:4374.646\n",
      "Ep:105, loss:0.00001, loss_test:0.06557, lr:6.43e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.663, tt:4416.279\n",
      "Ep:106, loss:0.00001, loss_test:0.06813, lr:6.36e-03, fs:0.77381 (r=0.657,p=0.942),  time:41.682, tt:4459.942\n",
      "Ep:107, loss:0.00001, loss_test:0.06758, lr:6.30e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.698, tt:4503.340\n",
      "Ep:108, loss:0.00001, loss_test:0.06501, lr:6.24e-03, fs:0.86188 (r=0.788,p=0.951),  time:41.719, tt:4547.317\n",
      "Ep:109, loss:0.00001, loss_test:0.06816, lr:6.17e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.737, tt:4591.067\n",
      "Ep:110, loss:0.00001, loss_test:0.06629, lr:6.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:41.771, tt:4636.576\n",
      "Ep:111, loss:0.00001, loss_test:0.06571, lr:6.05e-03, fs:0.79070 (r=0.687,p=0.932),  time:41.782, tt:4679.569\n",
      "Ep:112, loss:0.00001, loss_test:0.06901, lr:5.99e-03, fs:0.76364 (r=0.636,p=0.955),  time:41.806, tt:4724.097\n",
      "Ep:113, loss:0.00001, loss_test:0.06650, lr:5.93e-03, fs:0.75449 (r=0.636,p=0.926),  time:41.828, tt:4768.367\n",
      "Ep:114, loss:0.00001, loss_test:0.06645, lr:5.87e-03, fs:0.86188 (r=0.788,p=0.951),  time:41.834, tt:4810.870\n",
      "Ep:115, loss:0.00001, loss_test:0.06742, lr:5.81e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.874, tt:4857.436\n",
      "Ep:116, loss:0.00001, loss_test:0.06664, lr:5.75e-03, fs:0.84270 (r=0.758,p=0.949),  time:41.909, tt:4903.372\n",
      "Ep:117, loss:0.00001, loss_test:0.06586, lr:5.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:41.928, tt:4947.445\n",
      "Ep:118, loss:0.00001, loss_test:0.06790, lr:5.64e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.929, tt:4989.517\n",
      "Ep:119, loss:0.00001, loss_test:0.06641, lr:5.58e-03, fs:0.76190 (r=0.646,p=0.928),  time:41.961, tt:5035.295\n",
      "Ep:120, loss:0.00001, loss_test:0.06644, lr:5.53e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.975, tt:5078.999\n",
      "Ep:121, loss:0.00001, loss_test:0.06775, lr:5.47e-03, fs:0.72393 (r=0.596,p=0.922),  time:41.988, tt:5122.573\n",
      "Ep:122, loss:0.00001, loss_test:0.06639, lr:5.42e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.001, tt:5166.167\n",
      "Ep:123, loss:0.00001, loss_test:0.06667, lr:5.36e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.017, tt:5210.067\n",
      "Ep:124, loss:0.00001, loss_test:0.06674, lr:5.31e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.009, tt:5251.109\n",
      "Ep:125, loss:0.00001, loss_test:0.06690, lr:5.26e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.019, tt:5294.353\n",
      "Ep:126, loss:0.00001, loss_test:0.06587, lr:5.20e-03, fs:0.83146 (r=0.747,p=0.937),  time:42.038, tt:5338.884\n",
      "Ep:127, loss:0.00001, loss_test:0.06824, lr:5.15e-03, fs:0.76190 (r=0.646,p=0.928),  time:42.035, tt:5380.427\n",
      "Ep:128, loss:0.00001, loss_test:0.06633, lr:5.10e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.056, tt:5425.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.06860, lr:5.05e-03, fs:0.75152 (r=0.626,p=0.939),  time:42.052, tt:5466.724\n",
      "Ep:130, loss:0.00001, loss_test:0.06685, lr:5.00e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.072, tt:5511.431\n",
      "Ep:131, loss:0.00001, loss_test:0.06640, lr:4.95e-03, fs:0.82486 (r=0.737,p=0.936),  time:42.088, tt:5555.602\n",
      "Ep:132, loss:0.00001, loss_test:0.06785, lr:4.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.084, tt:5597.132\n",
      "Ep:133, loss:0.00001, loss_test:0.06686, lr:4.85e-03, fs:0.75449 (r=0.636,p=0.926),  time:42.085, tt:5639.351\n",
      "Ep:134, loss:0.00001, loss_test:0.06730, lr:4.80e-03, fs:0.85556 (r=0.778,p=0.951),  time:42.087, tt:5681.723\n",
      "Ep:135, loss:0.00001, loss_test:0.06779, lr:4.75e-03, fs:0.77647 (r=0.667,p=0.930),  time:42.097, tt:5725.213\n",
      "Ep:136, loss:0.00001, loss_test:0.06739, lr:4.71e-03, fs:0.77381 (r=0.657,p=0.942),  time:42.109, tt:5768.997\n",
      "Ep:137, loss:0.00001, loss_test:0.06706, lr:4.66e-03, fs:0.82955 (r=0.737,p=0.948),  time:42.108, tt:5810.968\n",
      "Ep:138, loss:0.00001, loss_test:0.06728, lr:4.61e-03, fs:0.77647 (r=0.667,p=0.930),  time:42.124, tt:5855.232\n",
      "Ep:139, loss:0.00001, loss_test:0.06719, lr:4.57e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.127, tt:5897.767\n",
      "Ep:140, loss:0.00001, loss_test:0.06689, lr:4.52e-03, fs:0.78363 (r=0.677,p=0.931),  time:42.170, tt:5945.966\n",
      "Ep:141, loss:0.00001, loss_test:0.06713, lr:4.48e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.162, tt:5986.984\n",
      "Ep:142, loss:0.00001, loss_test:0.06719, lr:4.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:42.157, tt:6028.499\n",
      "Ep:143, loss:0.00001, loss_test:0.06706, lr:4.39e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.168, tt:6072.252\n",
      "Ep:144, loss:0.00001, loss_test:0.06795, lr:4.34e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.173, tt:6115.077\n",
      "Ep:145, loss:0.00001, loss_test:0.06629, lr:4.30e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.194, tt:6160.362\n",
      "Ep:146, loss:0.00001, loss_test:0.06814, lr:4.26e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.209, tt:6204.758\n",
      "Ep:147, loss:0.00001, loss_test:0.06820, lr:4.21e-03, fs:0.72393 (r=0.596,p=0.922),  time:42.211, tt:6247.177\n",
      "Ep:148, loss:0.00001, loss_test:0.06639, lr:4.17e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.220, tt:6290.845\n",
      "Ep:149, loss:0.00001, loss_test:0.06838, lr:4.13e-03, fs:0.75904 (r=0.636,p=0.940),  time:42.224, tt:6333.590\n",
      "Ep:150, loss:0.00001, loss_test:0.06828, lr:4.09e-03, fs:0.77647 (r=0.667,p=0.930),  time:42.234, tt:6377.345\n",
      "Ep:151, loss:0.00001, loss_test:0.06691, lr:4.05e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.235, tt:6419.688\n",
      "Ep:152, loss:0.00001, loss_test:0.06746, lr:4.01e-03, fs:0.75449 (r=0.636,p=0.926),  time:42.242, tt:6463.087\n",
      "Ep:153, loss:0.00001, loss_test:0.06785, lr:3.97e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.258, tt:6507.810\n",
      "Ep:154, loss:0.00001, loss_test:0.06828, lr:3.93e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.276, tt:6552.780\n",
      "Ep:155, loss:0.00001, loss_test:0.06625, lr:3.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.285, tt:6596.516\n",
      "Ep:156, loss:0.00001, loss_test:0.06811, lr:3.85e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.291, tt:6639.672\n",
      "Ep:157, loss:0.00001, loss_test:0.06896, lr:3.81e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.288, tt:6681.470\n",
      "Ep:158, loss:0.00000, loss_test:0.06663, lr:3.77e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.296, tt:6725.116\n",
      "Ep:159, loss:0.00000, loss_test:0.06862, lr:3.73e-03, fs:0.77381 (r=0.657,p=0.942),  time:42.296, tt:6767.387\n",
      "Ep:160, loss:0.00000, loss_test:0.06981, lr:3.70e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.303, tt:6810.845\n",
      "Ep:161, loss:0.00000, loss_test:0.06765, lr:3.66e-03, fs:0.78824 (r=0.677,p=0.944),  time:42.304, tt:6853.249\n",
      "Ep:162, loss:0.00000, loss_test:0.06728, lr:3.62e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.315, tt:6897.335\n",
      "Ep:163, loss:0.00000, loss_test:0.06785, lr:3.59e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.309, tt:6938.667\n",
      "Ep:164, loss:0.00000, loss_test:0.06851, lr:3.55e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.302, tt:6979.792\n",
      "Ep:165, loss:0.00000, loss_test:0.06741, lr:3.52e-03, fs:0.82286 (r=0.727,p=0.947),  time:42.303, tt:7022.343\n",
      "Ep:166, loss:0.00000, loss_test:0.06631, lr:3.48e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.306, tt:7065.139\n",
      "Ep:167, loss:0.00000, loss_test:0.06893, lr:3.45e-03, fs:0.74390 (r=0.616,p=0.938),  time:42.309, tt:7107.852\n",
      "Ep:168, loss:0.00000, loss_test:0.06822, lr:3.41e-03, fs:0.78107 (r=0.667,p=0.943),  time:42.298, tt:7148.368\n",
      "Ep:169, loss:0.00000, loss_test:0.06684, lr:3.38e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.299, tt:7190.788\n",
      "Ep:170, loss:0.00000, loss_test:0.06783, lr:3.34e-03, fs:0.84916 (r=0.768,p=0.950),  time:42.303, tt:7233.822\n",
      "Ep:171, loss:0.00000, loss_test:0.06746, lr:3.31e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.309, tt:7277.123\n",
      "Ep:172, loss:0.00000, loss_test:0.06742, lr:3.28e-03, fs:0.83799 (r=0.758,p=0.938),  time:42.313, tt:7320.181\n",
      "Ep:173, loss:0.00000, loss_test:0.06712, lr:3.24e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.319, tt:7363.488\n",
      "Ep:174, loss:0.00000, loss_test:0.06769, lr:3.21e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.327, tt:7407.195\n",
      "Ep:175, loss:0.00000, loss_test:0.06761, lr:3.18e-03, fs:0.79532 (r=0.687,p=0.944),  time:42.339, tt:7451.747\n",
      "Ep:176, loss:0.00000, loss_test:0.06725, lr:3.15e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.336, tt:7493.388\n",
      "Ep:177, loss:0.00000, loss_test:0.06745, lr:3.12e-03, fs:0.83616 (r=0.747,p=0.949),  time:42.335, tt:7535.710\n",
      "Ep:178, loss:0.00000, loss_test:0.06791, lr:3.09e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.338, tt:7578.430\n",
      "Ep:179, loss:0.00000, loss_test:0.06792, lr:3.05e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.343, tt:7621.684\n",
      "Ep:180, loss:0.00000, loss_test:0.06736, lr:3.02e-03, fs:0.84270 (r=0.758,p=0.949),  time:42.361, tt:7667.299\n",
      "Ep:181, loss:0.00000, loss_test:0.06738, lr:2.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:42.376, tt:7712.409\n",
      "Ep:182, loss:0.00000, loss_test:0.06735, lr:2.96e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.382, tt:7755.976\n",
      "Ep:183, loss:0.00000, loss_test:0.06736, lr:2.93e-03, fs:0.80925 (r=0.707,p=0.946),  time:42.400, tt:7801.677\n",
      "Ep:184, loss:0.00000, loss_test:0.06810, lr:2.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:42.397, tt:7843.427\n",
      "Ep:185, loss:0.00000, loss_test:0.06727, lr:2.88e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.406, tt:7887.582\n",
      "Ep:186, loss:0.00000, loss_test:0.06721, lr:2.85e-03, fs:0.86188 (r=0.788,p=0.951),  time:42.406, tt:7930.003\n",
      "Ep:187, loss:0.00000, loss_test:0.06775, lr:2.82e-03, fs:0.81609 (r=0.717,p=0.947),  time:42.411, tt:7973.195\n",
      "Ep:188, loss:0.00000, loss_test:0.06781, lr:2.79e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.412, tt:8015.826\n",
      "Ep:189, loss:0.00000, loss_test:0.06718, lr:2.76e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.416, tt:8058.948\n",
      "Ep:190, loss:0.00000, loss_test:0.06731, lr:2.73e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.419, tt:8102.007\n",
      "Ep:191, loss:0.00000, loss_test:0.06799, lr:2.71e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.417, tt:8143.986\n",
      "Ep:192, loss:0.00000, loss_test:0.06859, lr:2.68e-03, fs:0.77844 (r=0.657,p=0.956),  time:42.425, tt:8187.993\n",
      "Ep:193, loss:0.00000, loss_test:0.06739, lr:2.65e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.431, tt:8231.596\n",
      "Ep:194, loss:0.00000, loss_test:0.06773, lr:2.63e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.435, tt:8274.860\n",
      "Ep:195, loss:0.00000, loss_test:0.06877, lr:2.60e-03, fs:0.78571 (r=0.667,p=0.957),  time:42.465, tt:8323.046\n",
      "Ep:196, loss:0.00000, loss_test:0.06774, lr:2.57e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.484, tt:8369.357\n",
      "Ep:197, loss:0.00000, loss_test:0.06711, lr:2.55e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.485, tt:8412.023\n",
      "Ep:198, loss:0.00000, loss_test:0.06805, lr:2.52e-03, fs:0.82081 (r=0.717,p=0.959),  time:42.480, tt:8453.560\n",
      "Ep:199, loss:0.00000, loss_test:0.06791, lr:2.50e-03, fs:0.79290 (r=0.677,p=0.957),  time:42.485, tt:8497.054\n",
      "Ep:200, loss:0.00000, loss_test:0.06803, lr:2.47e-03, fs:0.84746 (r=0.758,p=0.962),  time:42.488, tt:8540.021\n",
      "Ep:201, loss:0.00000, loss_test:0.06761, lr:2.45e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.505, tt:8585.917\n",
      "Ep:202, loss:0.00000, loss_test:0.06752, lr:2.42e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.509, tt:8629.288\n",
      "Ep:203, loss:0.00000, loss_test:0.06815, lr:2.40e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.519, tt:8673.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:204, loss:0.00000, loss_test:0.06807, lr:2.38e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.525, tt:8717.603\n",
      "Ep:205, loss:0.00000, loss_test:0.06723, lr:2.35e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.538, tt:8762.848\n",
      "Ep:206, loss:0.00000, loss_test:0.06732, lr:2.33e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.549, tt:8807.603\n",
      "Ep:207, loss:0.00000, loss_test:0.06838, lr:2.31e-03, fs:0.79290 (r=0.677,p=0.957),  time:42.539, tt:8848.047\n",
      "Ep:208, loss:0.00000, loss_test:0.06809, lr:2.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:42.506, tt:8883.810\n",
      "Ep:209, loss:0.00000, loss_test:0.06730, lr:2.26e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.482, tt:8921.213\n",
      "Ep:210, loss:0.00000, loss_test:0.06799, lr:2.24e-03, fs:0.86667 (r=0.788,p=0.963),  time:42.428, tt:8952.217\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01969, lr:6.00e-02, fs:0.65942 (r=0.919,p=0.514),  time:39.624, tt:39.624\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02350, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.587, tt:83.173\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02467, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:41.941, tt:125.824\n",
      "Ep:3, loss:0.00005, loss_test:0.02409, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.309, tt:169.235\n",
      "Ep:4, loss:0.00005, loss_test:0.02242, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:42.617, tt:213.083\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02057, lr:6.00e-02, fs:0.67133 (r=0.970,p=0.513),  time:42.652, tt:255.909\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.01921, lr:6.00e-02, fs:0.67407 (r=0.919,p=0.532),  time:42.482, tt:297.374\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01847, lr:6.00e-02, fs:0.67194 (r=0.859,p=0.552),  time:42.415, tt:339.318\n",
      "Ep:8, loss:0.00004, loss_test:0.01785, lr:6.00e-02, fs:0.69048 (r=0.879,p=0.569),  time:42.516, tt:382.640\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01758, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:42.533, tt:425.332\n",
      "Ep:10, loss:0.00003, loss_test:0.01750, lr:6.00e-02, fs:0.71111 (r=0.970,p=0.561),  time:42.581, tt:468.387\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01723, lr:6.00e-02, fs:0.71375 (r=0.970,p=0.565),  time:43.106, tt:517.267\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01676, lr:6.00e-02, fs:0.71970 (r=0.960,p=0.576),  time:43.214, tt:561.777\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01626, lr:6.00e-02, fs:0.73004 (r=0.970,p=0.585),  time:43.178, tt:604.497\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01582, lr:6.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:43.084, tt:646.267\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01543, lr:6.00e-02, fs:0.74803 (r=0.960,p=0.613),  time:43.094, tt:689.509\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01511, lr:6.00e-02, fs:0.76680 (r=0.980,p=0.630),  time:43.177, tt:734.016\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01485, lr:6.00e-02, fs:0.76984 (r=0.980,p=0.634),  time:43.253, tt:778.552\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01461, lr:6.00e-02, fs:0.78715 (r=0.990,p=0.653),  time:43.300, tt:822.696\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01440, lr:6.00e-02, fs:0.78862 (r=0.980,p=0.660),  time:43.264, tt:865.288\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01420, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:43.208, tt:907.374\n",
      "Ep:21, loss:0.00003, loss_test:0.01404, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:43.167, tt:949.680\n",
      "Ep:22, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:43.151, tt:992.478\n",
      "Ep:23, loss:0.00002, loss_test:0.01380, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:43.161, tt:1035.853\n",
      "Ep:24, loss:0.00002, loss_test:0.01371, lr:6.00e-02, fs:0.78838 (r=0.960,p=0.669),  time:43.101, tt:1077.523\n",
      "Ep:25, loss:0.00002, loss_test:0.01361, lr:6.00e-02, fs:0.79167 (r=0.960,p=0.674),  time:43.007, tt:1118.177\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01349, lr:6.00e-02, fs:0.79832 (r=0.960,p=0.683),  time:42.922, tt:1158.884\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01336, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:42.816, tt:1198.857\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.80687 (r=0.949,p=0.701),  time:42.821, tt:1241.816\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01314, lr:6.00e-02, fs:0.80519 (r=0.939,p=0.705),  time:42.716, tt:1281.470\n",
      "Ep:30, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.80172 (r=0.939,p=0.699),  time:42.710, tt:1324.007\n",
      "Ep:31, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.80000 (r=0.929,p=0.702),  time:42.704, tt:1366.520\n",
      "Ep:32, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:42.673, tt:1408.205\n",
      "Ep:33, loss:0.00002, loss_test:0.01276, lr:6.00e-02, fs:0.79654 (r=0.929,p=0.697),  time:42.655, tt:1450.283\n",
      "Ep:34, loss:0.00002, loss_test:0.01271, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:42.612, tt:1491.418\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01267, lr:6.00e-02, fs:0.80889 (r=0.919,p=0.722),  time:42.582, tt:1532.938\n",
      "Ep:36, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:42.531, tt:1573.657\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.81614 (r=0.919,p=0.734),  time:42.524, tt:1615.912\n",
      "Ep:38, loss:0.00002, loss_test:0.01244, lr:6.00e-02, fs:0.81250 (r=0.919,p=0.728),  time:42.457, tt:1655.837\n",
      "Ep:39, loss:0.00002, loss_test:0.01237, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:42.468, tt:1698.727\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:42.439, tt:1739.996\n",
      "Ep:41, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:42.431, tt:1782.108\n",
      "Ep:42, loss:0.00002, loss_test:0.01214, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:42.416, tt:1823.875\n",
      "Ep:43, loss:0.00002, loss_test:0.01212, lr:6.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:42.425, tt:1866.678\n",
      "Ep:44, loss:0.00001, loss_test:0.01206, lr:6.00e-02, fs:0.81651 (r=0.899,p=0.748),  time:42.372, tt:1906.737\n",
      "Ep:45, loss:0.00001, loss_test:0.01201, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:42.292, tt:1945.424\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00001, loss_test:0.01195, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:42.255, tt:1985.972\n",
      "Ep:47, loss:0.00001, loss_test:0.01194, lr:6.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:42.239, tt:2027.453\n",
      "Ep:48, loss:0.00001, loss_test:0.01187, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:42.215, tt:2068.535\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01179, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:42.238, tt:2111.908\n",
      "Ep:50, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:42.259, tt:2155.231\n",
      "Ep:51, loss:0.00001, loss_test:0.01177, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.239, tt:2196.420\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:52, loss:0.00001, loss_test:0.01171, lr:6.00e-02, fs:0.82629 (r=0.889,p=0.772),  time:42.242, tt:2238.851\n",
      "Ep:53, loss:0.00001, loss_test:0.01167, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.227, tt:2280.250\n",
      "Ep:54, loss:0.00001, loss_test:0.01166, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.196, tt:2320.765\n",
      "Ep:55, loss:0.00001, loss_test:0.01163, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.198, tt:2363.101\n",
      "Ep:56, loss:0.00001, loss_test:0.01162, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.148, tt:2402.447\n",
      "Ep:57, loss:0.00001, loss_test:0.01163, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:42.135, tt:2443.834\n",
      "Ep:58, loss:0.00001, loss_test:0.01157, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.105, tt:2484.224\n",
      "Ep:59, loss:0.00001, loss_test:0.01152, lr:6.00e-02, fs:0.83019 (r=0.889,p=0.779),  time:42.093, tt:2525.559\n",
      "Ep:60, loss:0.00001, loss_test:0.01156, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:42.081, tt:2566.940\n",
      "Ep:61, loss:0.00001, loss_test:0.01155, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:42.081, tt:2609.043\n",
      "Ep:62, loss:0.00001, loss_test:0.01148, lr:6.00e-02, fs:0.82464 (r=0.879,p=0.777),  time:42.079, tt:2651.002\n",
      "Ep:63, loss:0.00001, loss_test:0.01151, lr:5.94e-02, fs:0.82857 (r=0.879,p=0.784),  time:42.075, tt:2692.809\n",
      "Ep:64, loss:0.00001, loss_test:0.01149, lr:5.88e-02, fs:0.81731 (r=0.859,p=0.780),  time:42.069, tt:2734.475\n",
      "Ep:65, loss:0.00001, loss_test:0.01150, lr:5.82e-02, fs:0.81731 (r=0.859,p=0.780),  time:42.061, tt:2776.050\n",
      "Ep:66, loss:0.00001, loss_test:0.01147, lr:5.76e-02, fs:0.82126 (r=0.859,p=0.787),  time:42.033, tt:2816.216\n",
      "Ep:67, loss:0.00001, loss_test:0.01148, lr:5.71e-02, fs:0.82126 (r=0.859,p=0.787),  time:42.021, tt:2857.451\n",
      "Ep:68, loss:0.00001, loss_test:0.01152, lr:5.65e-02, fs:0.82126 (r=0.859,p=0.787),  time:42.000, tt:2898.029\n",
      "Ep:69, loss:0.00001, loss_test:0.01144, lr:5.59e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.996, tt:2939.725\n",
      "Ep:70, loss:0.00001, loss_test:0.01150, lr:5.54e-02, fs:0.82126 (r=0.859,p=0.787),  time:42.013, tt:2982.904\n",
      "Ep:71, loss:0.00001, loss_test:0.01146, lr:5.48e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.989, tt:3023.181\n",
      "Ep:72, loss:0.00001, loss_test:0.01145, lr:5.43e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.971, tt:3063.864\n",
      "Ep:73, loss:0.00001, loss_test:0.01147, lr:5.37e-02, fs:0.82126 (r=0.859,p=0.787),  time:41.984, tt:3106.840\n",
      "Ep:74, loss:0.00001, loss_test:0.01149, lr:5.32e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.972, tt:3147.896\n",
      "Ep:75, loss:0.00001, loss_test:0.01148, lr:5.27e-02, fs:0.82524 (r=0.859,p=0.794),  time:41.964, tt:3189.239\n",
      "Ep:76, loss:0.00001, loss_test:0.01145, lr:5.21e-02, fs:0.82927 (r=0.859,p=0.802),  time:41.929, tt:3228.566\n",
      "Ep:77, loss:0.00001, loss_test:0.01151, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.911, tt:3269.026\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.01150, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.893, tt:3309.567\n",
      "Ep:79, loss:0.00001, loss_test:0.01150, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.862, tt:3348.974\n",
      "Ep:80, loss:0.00001, loss_test:0.01150, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.847, tt:3389.593\n",
      "Ep:81, loss:0.00001, loss_test:0.01151, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.849, tt:3431.609\n",
      "Ep:82, loss:0.00001, loss_test:0.01149, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.866, tt:3474.907\n",
      "Ep:83, loss:0.00001, loss_test:0.01151, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.883, tt:3518.171\n",
      "Ep:84, loss:0.00001, loss_test:0.01148, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.906, tt:3561.971\n",
      "Ep:85, loss:0.00001, loss_test:0.01154, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.914, tt:3604.570\n",
      "Ep:86, loss:0.00001, loss_test:0.01151, lr:5.16e-02, fs:0.83744 (r=0.859,p=0.817),  time:41.943, tt:3649.054\n",
      "Ep:87, loss:0.00001, loss_test:0.01154, lr:5.16e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.986, tt:3694.756\n",
      "Ep:88, loss:0.00001, loss_test:0.01152, lr:5.16e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.006, tt:3738.548\n",
      "Ep:89, loss:0.00001, loss_test:0.01151, lr:5.11e-02, fs:0.84000 (r=0.848,p=0.832),  time:42.026, tt:3782.320\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01159, lr:5.11e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.011, tt:3823.015\n",
      "Ep:91, loss:0.00001, loss_test:0.01156, lr:5.11e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.009, tt:3864.803\n",
      "Ep:92, loss:0.00001, loss_test:0.01155, lr:5.11e-02, fs:0.83582 (r=0.848,p=0.824),  time:42.017, tt:3907.617\n",
      "Ep:93, loss:0.00001, loss_test:0.01162, lr:5.11e-02, fs:0.84000 (r=0.848,p=0.832),  time:42.019, tt:3949.776\n",
      "Ep:94, loss:0.00001, loss_test:0.01162, lr:5.11e-02, fs:0.84000 (r=0.848,p=0.832),  time:42.021, tt:3991.951\n",
      "Ep:95, loss:0.00001, loss_test:0.01155, lr:5.11e-02, fs:0.83582 (r=0.848,p=0.824),  time:41.998, tt:4031.798\n",
      "Ep:96, loss:0.00001, loss_test:0.01166, lr:5.11e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.993, tt:4073.289\n",
      "##########Best model found so far##########\n",
      "Ep:97, loss:0.00001, loss_test:0.01165, lr:5.11e-02, fs:0.85279 (r=0.848,p=0.857),  time:41.993, tt:4115.345\n",
      "Ep:98, loss:0.00001, loss_test:0.01158, lr:5.11e-02, fs:0.84848 (r=0.848,p=0.848),  time:41.991, tt:4157.124\n",
      "Ep:99, loss:0.00001, loss_test:0.01172, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.984, tt:4198.435\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01171, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.974, tt:4239.391\n",
      "Ep:101, loss:0.00001, loss_test:0.01164, lr:5.11e-02, fs:0.85714 (r=0.848,p=0.866),  time:41.968, tt:4280.751\n",
      "Ep:102, loss:0.00001, loss_test:0.01172, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.960, tt:4321.843\n",
      "Ep:103, loss:0.00001, loss_test:0.01174, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.952, tt:4362.962\n",
      "Ep:104, loss:0.00001, loss_test:0.01176, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.948, tt:4404.545\n",
      "Ep:105, loss:0.00001, loss_test:0.01180, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.932, tt:4444.840\n",
      "Ep:106, loss:0.00000, loss_test:0.01172, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.934, tt:4486.967\n",
      "Ep:107, loss:0.00000, loss_test:0.01176, lr:5.11e-02, fs:0.86154 (r=0.848,p=0.875),  time:41.896, tt:4524.715\n",
      "Ep:108, loss:0.00000, loss_test:0.01180, lr:5.11e-02, fs:0.86598 (r=0.848,p=0.884),  time:41.895, tt:4566.535\n",
      "##########Best model found so far##########\n",
      "Ep:109, loss:0.00000, loss_test:0.01176, lr:5.11e-02, fs:0.86598 (r=0.848,p=0.884),  time:41.890, tt:4607.943\n",
      "Ep:110, loss:0.00000, loss_test:0.01190, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.888, tt:4649.522\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00000, loss_test:0.01182, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.878, tt:4690.340\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.01184, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.867, tt:4730.963\n",
      "Ep:113, loss:0.00000, loss_test:0.01192, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.860, tt:4772.014\n",
      "Ep:114, loss:0.00000, loss_test:0.01189, lr:5.11e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.851, tt:4812.913\n",
      "Ep:115, loss:0.00000, loss_test:0.01191, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.836, tt:4852.983\n",
      "Ep:116, loss:0.00000, loss_test:0.01197, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.815, tt:4892.389\n",
      "Ep:117, loss:0.00000, loss_test:0.01198, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.795, tt:4931.801\n",
      "Ep:118, loss:0.00000, loss_test:0.01196, lr:5.11e-02, fs:0.87500 (r=0.848,p=0.903),  time:41.773, tt:4970.993\n",
      "Ep:119, loss:0.00000, loss_test:0.01198, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.762, tt:5011.388\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00000, loss_test:0.01201, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.753, tt:5052.107\n",
      "Ep:121, loss:0.00000, loss_test:0.01204, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.746, tt:5093.062\n",
      "Ep:122, loss:0.00000, loss_test:0.01208, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.726, tt:5132.306\n",
      "Ep:123, loss:0.00000, loss_test:0.01210, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.707, tt:5171.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:124, loss:0.00000, loss_test:0.01205, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.701, tt:5212.644\n",
      "Ep:125, loss:0.00000, loss_test:0.01214, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.674, tt:5250.944\n",
      "Ep:126, loss:0.00000, loss_test:0.01217, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.649, tt:5289.431\n",
      "Ep:127, loss:0.00000, loss_test:0.01217, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.635, tt:5329.258\n",
      "Ep:128, loss:0.00000, loss_test:0.01222, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.630, tt:5370.226\n",
      "Ep:129, loss:0.00000, loss_test:0.01225, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.627, tt:5411.493\n",
      "Ep:130, loss:0.00000, loss_test:0.01229, lr:5.11e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.621, tt:5452.304\n",
      "Ep:131, loss:0.00000, loss_test:0.01230, lr:5.06e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.619, tt:5493.715\n",
      "Ep:132, loss:0.00000, loss_test:0.01227, lr:5.01e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.613, tt:5534.574\n",
      "Ep:133, loss:0.00000, loss_test:0.01232, lr:4.96e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.606, tt:5575.253\n",
      "Ep:134, loss:0.00000, loss_test:0.01237, lr:4.91e-02, fs:0.87958 (r=0.848,p=0.913),  time:41.591, tt:5614.737\n",
      "Ep:135, loss:0.00000, loss_test:0.01238, lr:4.86e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.574, tt:5654.003\n",
      "##########Best model found so far##########\n",
      "Ep:136, loss:0.00000, loss_test:0.01239, lr:4.86e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.562, tt:5694.034\n",
      "Ep:137, loss:0.00000, loss_test:0.01239, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.558, tt:5735.025\n",
      "##########Best model found so far##########\n",
      "Ep:138, loss:0.00000, loss_test:0.01243, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.563, tt:5777.312\n",
      "Ep:139, loss:0.00000, loss_test:0.01245, lr:4.86e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.565, tt:5819.079\n",
      "Ep:140, loss:0.00000, loss_test:0.01247, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.555, tt:5859.317\n",
      "Ep:141, loss:0.00000, loss_test:0.01245, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.555, tt:5900.791\n",
      "Ep:142, loss:0.00000, loss_test:0.01254, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.536, tt:5939.658\n",
      "Ep:143, loss:0.00000, loss_test:0.01252, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.526, tt:5979.760\n",
      "Ep:144, loss:0.00000, loss_test:0.01259, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.519, tt:6020.241\n",
      "Ep:145, loss:0.00000, loss_test:0.01259, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.520, tt:6061.858\n",
      "Ep:146, loss:0.00000, loss_test:0.01260, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.506, tt:6101.357\n",
      "Ep:147, loss:0.00000, loss_test:0.01260, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.503, tt:6142.389\n",
      "Ep:148, loss:0.00000, loss_test:0.01266, lr:4.86e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.507, tt:6184.505\n",
      "Ep:149, loss:0.00000, loss_test:0.01268, lr:4.81e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.499, tt:6224.876\n",
      "Ep:150, loss:0.00000, loss_test:0.01268, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.498, tt:6266.183\n",
      "##########Best model found so far##########\n",
      "Ep:151, loss:0.00000, loss_test:0.01268, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.509, tt:6309.355\n",
      "Ep:152, loss:0.00000, loss_test:0.01278, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.501, tt:6349.711\n",
      "Ep:153, loss:0.00000, loss_test:0.01274, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.496, tt:6390.326\n",
      "Ep:154, loss:0.00000, loss_test:0.01276, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.526, tt:6436.600\n",
      "Ep:155, loss:0.00000, loss_test:0.01279, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.522, tt:6477.358\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00000, loss_test:0.01282, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.519, tt:6518.464\n",
      "Ep:157, loss:0.00000, loss_test:0.01284, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.514, tt:6559.168\n",
      "Ep:158, loss:0.00000, loss_test:0.01287, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.504, tt:6599.187\n",
      "Ep:159, loss:0.00000, loss_test:0.01286, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.511, tt:6641.778\n",
      "Ep:160, loss:0.00000, loss_test:0.01291, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.506, tt:6682.415\n",
      "Ep:161, loss:0.00000, loss_test:0.01294, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.503, tt:6723.438\n",
      "Ep:162, loss:0.00000, loss_test:0.01293, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.500, tt:6764.562\n",
      "Ep:163, loss:0.00000, loss_test:0.01295, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.489, tt:6804.146\n",
      "Ep:164, loss:0.00000, loss_test:0.01297, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.485, tt:6845.037\n",
      "Ep:165, loss:0.00000, loss_test:0.01298, lr:4.76e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.478, tt:6885.422\n",
      "Ep:166, loss:0.00000, loss_test:0.01302, lr:4.76e-02, fs:0.89474 (r=0.859,p=0.934),  time:41.474, tt:6926.105\n",
      "Ep:167, loss:0.00000, loss_test:0.01306, lr:4.71e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.458, tt:6964.964\n",
      "Ep:168, loss:0.00000, loss_test:0.01306, lr:4.67e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.443, tt:7003.924\n",
      "Ep:169, loss:0.00000, loss_test:0.01306, lr:4.62e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.442, tt:7045.123\n",
      "Ep:170, loss:0.00000, loss_test:0.01310, lr:4.57e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.433, tt:7085.006\n",
      "Ep:171, loss:0.00000, loss_test:0.01311, lr:4.53e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.438, tt:7127.324\n",
      "Ep:172, loss:0.00000, loss_test:0.01315, lr:4.48e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.451, tt:7170.963\n",
      "Ep:173, loss:0.00000, loss_test:0.01315, lr:4.44e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.455, tt:7213.119\n",
      "Ep:174, loss:0.00000, loss_test:0.01321, lr:4.39e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.451, tt:7253.847\n",
      "Ep:175, loss:0.00000, loss_test:0.01321, lr:4.35e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.445, tt:7294.284\n",
      "Ep:176, loss:0.00000, loss_test:0.01325, lr:4.31e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.440, tt:7334.911\n",
      "Ep:177, loss:0.00000, loss_test:0.01322, lr:4.26e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.445, tt:7377.163\n",
      "Ep:178, loss:0.00000, loss_test:0.01326, lr:4.22e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.434, tt:7416.705\n",
      "Ep:179, loss:0.00000, loss_test:0.01329, lr:4.18e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.425, tt:7456.504\n",
      "Ep:180, loss:0.00000, loss_test:0.01328, lr:4.14e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.422, tt:7497.348\n",
      "Ep:181, loss:0.00000, loss_test:0.01332, lr:4.10e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.410, tt:7536.651\n",
      "Ep:182, loss:0.00000, loss_test:0.01335, lr:4.05e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.406, tt:7577.234\n",
      "Ep:183, loss:0.00000, loss_test:0.01336, lr:4.01e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.397, tt:7617.074\n",
      "Ep:184, loss:0.00000, loss_test:0.01337, lr:3.97e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.380, tt:7655.378\n",
      "Ep:185, loss:0.00000, loss_test:0.01340, lr:3.93e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.374, tt:7695.635\n",
      "Ep:186, loss:0.00000, loss_test:0.01341, lr:3.89e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.367, tt:7735.634\n",
      "Ep:187, loss:0.00000, loss_test:0.01343, lr:3.86e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.355, tt:7774.687\n",
      "Ep:188, loss:0.00000, loss_test:0.01341, lr:3.82e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.349, tt:7814.881\n",
      "Ep:189, loss:0.00000, loss_test:0.01345, lr:3.78e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.340, tt:7854.517\n",
      "Ep:190, loss:0.00000, loss_test:0.01345, lr:3.74e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.330, tt:7894.089\n",
      "Ep:191, loss:0.00000, loss_test:0.01346, lr:3.70e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.326, tt:7934.556\n",
      "Ep:192, loss:0.00000, loss_test:0.01349, lr:3.67e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.316, tt:7974.014\n",
      "Ep:193, loss:0.00000, loss_test:0.01352, lr:3.63e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.311, tt:8014.409\n",
      "Ep:194, loss:0.00000, loss_test:0.01349, lr:3.59e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.305, tt:8054.464\n",
      "Ep:195, loss:0.00000, loss_test:0.01353, lr:3.56e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.301, tt:8095.095\n",
      "Ep:196, loss:0.00000, loss_test:0.01356, lr:3.52e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.302, tt:8136.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.01357, lr:3.49e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.290, tt:8175.387\n",
      "Ep:198, loss:0.00000, loss_test:0.01356, lr:3.45e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.272, tt:8213.058\n",
      "Ep:199, loss:0.00000, loss_test:0.01359, lr:3.42e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.261, tt:8252.121\n",
      "Ep:200, loss:0.00000, loss_test:0.01363, lr:3.38e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.239, tt:8289.135\n",
      "Ep:201, loss:0.00000, loss_test:0.01364, lr:3.35e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.228, tt:8327.978\n",
      "Ep:202, loss:0.00000, loss_test:0.01364, lr:3.32e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.219, tt:8367.537\n",
      "Ep:203, loss:0.00000, loss_test:0.01366, lr:3.28e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.226, tt:8410.200\n",
      "Ep:204, loss:0.00000, loss_test:0.01368, lr:3.25e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.220, tt:8450.158\n",
      "Ep:205, loss:0.00000, loss_test:0.01367, lr:3.22e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.206, tt:8488.357\n",
      "Ep:206, loss:0.00000, loss_test:0.01371, lr:3.19e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.199, tt:8528.136\n",
      "Ep:207, loss:0.00000, loss_test:0.01371, lr:3.15e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.195, tt:8568.527\n",
      "Ep:208, loss:0.00000, loss_test:0.01370, lr:3.12e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.169, tt:8604.309\n",
      "Ep:209, loss:0.00000, loss_test:0.01375, lr:3.09e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.151, tt:8641.759\n",
      "Ep:210, loss:0.00000, loss_test:0.01375, lr:3.06e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.124, tt:8677.236\n",
      "Ep:211, loss:0.00000, loss_test:0.01373, lr:3.03e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.086, tt:8710.250\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13959, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.000, tt:38.000\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.13694, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:38.978, tt:77.955\n",
      "Ep:2, loss:0.00027, loss_test:0.13179, lr:1.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:39.732, tt:119.196\n",
      "Ep:3, loss:0.00026, loss_test:0.12309, lr:1.00e-02, fs:0.67897 (r=0.929,p=0.535),  time:40.248, tt:160.992\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11376, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:41.260, tt:206.300\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.10834, lr:1.00e-02, fs:0.69767 (r=0.758,p=0.647),  time:41.353, tt:248.121\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10678, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:41.166, tt:288.162\n",
      "Ep:7, loss:0.00022, loss_test:0.10703, lr:1.00e-02, fs:0.71429 (r=0.859,p=0.612),  time:41.156, tt:329.246\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10426, lr:1.00e-02, fs:0.72727 (r=0.848,p=0.636),  time:41.164, tt:370.476\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09933, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:41.078, tt:410.778\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09611, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:40.786, tt:448.647\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09431, lr:1.00e-02, fs:0.76856 (r=0.889,p=0.677),  time:41.060, tt:492.718\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09072, lr:1.00e-02, fs:0.79091 (r=0.879,p=0.719),  time:40.947, tt:532.310\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.08907, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:40.910, tt:572.740\n",
      "Ep:14, loss:0.00017, loss_test:0.08610, lr:1.00e-02, fs:0.79279 (r=0.889,p=0.715),  time:40.822, tt:612.323\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.08403, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:40.918, tt:654.695\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08292, lr:1.00e-02, fs:0.80870 (r=0.939,p=0.710),  time:40.955, tt:696.239\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08091, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:40.973, tt:737.510\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08159, lr:1.00e-02, fs:0.80342 (r=0.949,p=0.696),  time:40.970, tt:778.424\n",
      "Ep:19, loss:0.00014, loss_test:0.07911, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:41.003, tt:820.055\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07876, lr:1.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:41.173, tt:864.627\n",
      "Ep:21, loss:0.00013, loss_test:0.07628, lr:1.00e-02, fs:0.85167 (r=0.899,p=0.809),  time:41.192, tt:906.218\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.07635, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:41.147, tt:946.391\n",
      "Ep:23, loss:0.00012, loss_test:0.07544, lr:1.00e-02, fs:0.84577 (r=0.859,p=0.833),  time:41.235, tt:989.641\n",
      "Ep:24, loss:0.00012, loss_test:0.07579, lr:1.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:41.224, tt:1030.589\n",
      "Ep:25, loss:0.00012, loss_test:0.07285, lr:1.00e-02, fs:0.84422 (r=0.848,p=0.840),  time:41.287, tt:1073.455\n",
      "Ep:26, loss:0.00011, loss_test:0.07265, lr:1.00e-02, fs:0.84211 (r=0.970,p=0.744),  time:41.252, tt:1113.808\n",
      "Ep:27, loss:0.00011, loss_test:0.06988, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:41.248, tt:1154.940\n",
      "Ep:28, loss:0.00010, loss_test:0.07099, lr:1.00e-02, fs:0.84444 (r=0.960,p=0.754),  time:41.193, tt:1194.595\n",
      "Ep:29, loss:0.00010, loss_test:0.06737, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:41.210, tt:1236.294\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00009, loss_test:0.07005, lr:1.00e-02, fs:0.84821 (r=0.960,p=0.760),  time:41.223, tt:1277.902\n",
      "Ep:31, loss:0.00009, loss_test:0.06680, lr:1.00e-02, fs:0.87562 (r=0.889,p=0.863),  time:41.229, tt:1319.340\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06819, lr:1.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:41.244, tt:1361.065\n",
      "Ep:33, loss:0.00009, loss_test:0.06556, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:41.252, tt:1402.559\n",
      "Ep:34, loss:0.00008, loss_test:0.06523, lr:1.00e-02, fs:0.84906 (r=0.909,p=0.796),  time:41.239, tt:1443.353\n",
      "Ep:35, loss:0.00008, loss_test:0.06493, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.196, tt:1483.072\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.06324, lr:1.00e-02, fs:0.85990 (r=0.899,p=0.824),  time:41.264, tt:1526.763\n",
      "Ep:37, loss:0.00007, loss_test:0.06384, lr:1.00e-02, fs:0.87629 (r=0.859,p=0.895),  time:41.276, tt:1568.486\n",
      "Ep:38, loss:0.00007, loss_test:0.06047, lr:1.00e-02, fs:0.86294 (r=0.859,p=0.867),  time:41.247, tt:1608.616\n",
      "Ep:39, loss:0.00007, loss_test:0.06255, lr:1.00e-02, fs:0.88000 (r=0.889,p=0.871),  time:41.266, tt:1650.636\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00006, loss_test:0.06014, lr:1.00e-02, fs:0.88421 (r=0.848,p=0.923),  time:41.320, tt:1694.129\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.06055, lr:1.00e-02, fs:0.88442 (r=0.889,p=0.880),  time:41.373, tt:1737.668\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.05964, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.393, tt:1779.919\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.05891, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:41.401, tt:1821.648\n",
      "Ep:44, loss:0.00005, loss_test:0.05908, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:41.389, tt:1862.499\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00005, loss_test:0.05766, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:41.360, tt:1902.558\n",
      "Ep:46, loss:0.00005, loss_test:0.05920, lr:1.00e-02, fs:0.89691 (r=0.879,p=0.916),  time:41.361, tt:1943.985\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:47, loss:0.00005, loss_test:0.05733, lr:1.00e-02, fs:0.89583 (r=0.869,p=0.925),  time:41.326, tt:1983.627\n",
      "Ep:48, loss:0.00005, loss_test:0.05631, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:41.275, tt:2022.472\n",
      "Ep:49, loss:0.00004, loss_test:0.06192, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:41.220, tt:2061.006\n",
      "Ep:50, loss:0.00004, loss_test:0.05835, lr:1.00e-02, fs:0.86000 (r=0.869,p=0.851),  time:41.177, tt:2100.022\n",
      "Ep:51, loss:0.00004, loss_test:0.05925, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:41.185, tt:2141.638\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00004, loss_test:0.05589, lr:1.00e-02, fs:0.88542 (r=0.859,p=0.914),  time:41.221, tt:2184.731\n",
      "Ep:53, loss:0.00004, loss_test:0.05718, lr:1.00e-02, fs:0.88172 (r=0.828,p=0.943),  time:41.235, tt:2226.698\n",
      "Ep:54, loss:0.00004, loss_test:0.06405, lr:1.00e-02, fs:0.87097 (r=0.818,p=0.931),  time:41.261, tt:2269.362\n",
      "Ep:55, loss:0.00004, loss_test:0.05519, lr:1.00e-02, fs:0.89005 (r=0.859,p=0.924),  time:41.241, tt:2309.473\n",
      "Ep:56, loss:0.00004, loss_test:0.06591, lr:1.00e-02, fs:0.84091 (r=0.747,p=0.961),  time:41.233, tt:2350.307\n",
      "Ep:57, loss:0.00004, loss_test:0.05572, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:41.246, tt:2392.255\n",
      "Ep:58, loss:0.00003, loss_test:0.06078, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:41.266, tt:2434.678\n",
      "Ep:59, loss:0.00003, loss_test:0.05599, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.314, tt:2478.817\n",
      "Ep:60, loss:0.00003, loss_test:0.05592, lr:1.00e-02, fs:0.89130 (r=0.828,p=0.965),  time:41.357, tt:2522.789\n",
      "Ep:61, loss:0.00003, loss_test:0.06061, lr:1.00e-02, fs:0.85083 (r=0.778,p=0.939),  time:41.341, tt:2563.171\n",
      "Ep:62, loss:0.00003, loss_test:0.05604, lr:1.00e-02, fs:0.89947 (r=0.859,p=0.944),  time:41.352, tt:2605.183\n",
      "Ep:63, loss:0.00003, loss_test:0.05701, lr:9.90e-03, fs:0.90811 (r=0.848,p=0.977),  time:41.357, tt:2646.869\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.06021, lr:9.90e-03, fs:0.84444 (r=0.768,p=0.938),  time:41.372, tt:2689.178\n",
      "Ep:65, loss:0.00002, loss_test:0.05623, lr:9.90e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.387, tt:2731.529\n",
      "Ep:66, loss:0.00002, loss_test:0.06236, lr:9.90e-03, fs:0.78824 (r=0.677,p=0.944),  time:41.355, tt:2770.760\n",
      "Ep:67, loss:0.00002, loss_test:0.05615, lr:9.90e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.375, tt:2813.477\n",
      "Ep:68, loss:0.00002, loss_test:0.06090, lr:9.90e-03, fs:0.85714 (r=0.788,p=0.940),  time:41.371, tt:2854.596\n",
      "Ep:69, loss:0.00002, loss_test:0.05846, lr:9.90e-03, fs:0.89840 (r=0.848,p=0.955),  time:41.378, tt:2896.466\n",
      "Ep:70, loss:0.00002, loss_test:0.05733, lr:9.90e-03, fs:0.90526 (r=0.869,p=0.945),  time:41.379, tt:2937.922\n",
      "Ep:71, loss:0.00002, loss_test:0.06081, lr:9.90e-03, fs:0.85556 (r=0.778,p=0.951),  time:41.364, tt:2978.221\n",
      "Ep:72, loss:0.00002, loss_test:0.06414, lr:9.90e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.400, tt:3022.213\n",
      "Ep:73, loss:0.00002, loss_test:0.06166, lr:9.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:41.386, tt:3062.580\n",
      "Ep:74, loss:0.00002, loss_test:0.06615, lr:9.90e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.377, tt:3103.295\n",
      "Ep:75, loss:0.00002, loss_test:0.05759, lr:9.80e-03, fs:0.90426 (r=0.859,p=0.955),  time:41.343, tt:3142.103\n",
      "Ep:76, loss:0.00001, loss_test:0.06464, lr:9.70e-03, fs:0.79532 (r=0.687,p=0.944),  time:41.333, tt:3182.670\n",
      "Ep:77, loss:0.00001, loss_test:0.06209, lr:9.61e-03, fs:0.85556 (r=0.778,p=0.951),  time:41.348, tt:3225.126\n",
      "Ep:78, loss:0.00001, loss_test:0.06251, lr:9.51e-03, fs:0.84746 (r=0.758,p=0.962),  time:41.347, tt:3266.377\n",
      "Ep:79, loss:0.00001, loss_test:0.06465, lr:9.41e-03, fs:0.78824 (r=0.677,p=0.944),  time:41.328, tt:3306.244\n",
      "Ep:80, loss:0.00001, loss_test:0.06258, lr:9.32e-03, fs:0.84746 (r=0.758,p=0.962),  time:41.335, tt:3348.108\n",
      "Ep:81, loss:0.00001, loss_test:0.06407, lr:9.23e-03, fs:0.80925 (r=0.707,p=0.946),  time:41.327, tt:3388.839\n",
      "Ep:82, loss:0.00001, loss_test:0.06569, lr:9.14e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.331, tt:3430.451\n",
      "Ep:83, loss:0.00001, loss_test:0.06474, lr:9.04e-03, fs:0.79310 (r=0.697,p=0.920),  time:41.332, tt:3471.925\n",
      "Ep:84, loss:0.00001, loss_test:0.06541, lr:8.95e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.326, tt:3512.684\n",
      "Ep:85, loss:0.00001, loss_test:0.06318, lr:8.86e-03, fs:0.84746 (r=0.758,p=0.962),  time:41.312, tt:3552.790\n",
      "Ep:86, loss:0.00001, loss_test:0.06448, lr:8.78e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.308, tt:3593.816\n",
      "Ep:87, loss:0.00001, loss_test:0.06267, lr:8.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:41.302, tt:3634.571\n",
      "Ep:88, loss:0.00001, loss_test:0.06377, lr:8.60e-03, fs:0.80682 (r=0.717,p=0.922),  time:41.280, tt:3673.886\n",
      "Ep:89, loss:0.00001, loss_test:0.06441, lr:8.51e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.266, tt:3713.930\n",
      "Ep:90, loss:0.00001, loss_test:0.06372, lr:8.43e-03, fs:0.80233 (r=0.697,p=0.945),  time:41.258, tt:3754.472\n",
      "Ep:91, loss:0.00001, loss_test:0.06598, lr:8.35e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.236, tt:3793.730\n",
      "Ep:92, loss:0.00001, loss_test:0.06496, lr:8.26e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.241, tt:3835.439\n",
      "Ep:93, loss:0.00001, loss_test:0.06573, lr:8.18e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.248, tt:3877.336\n",
      "Ep:94, loss:0.00001, loss_test:0.06626, lr:8.10e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.236, tt:3917.427\n",
      "Ep:95, loss:0.00001, loss_test:0.06555, lr:8.02e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.201, tt:3955.314\n",
      "Ep:96, loss:0.00001, loss_test:0.06558, lr:7.94e-03, fs:0.76364 (r=0.636,p=0.955),  time:41.187, tt:3995.125\n",
      "Ep:97, loss:0.00001, loss_test:0.06674, lr:7.86e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.184, tt:4036.052\n",
      "Ep:98, loss:0.00001, loss_test:0.06625, lr:7.78e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.195, tt:4078.332\n",
      "Ep:99, loss:0.00001, loss_test:0.06496, lr:7.70e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.202, tt:4120.189\n",
      "Ep:100, loss:0.00001, loss_test:0.06912, lr:7.62e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.188, tt:4159.989\n",
      "Ep:101, loss:0.00001, loss_test:0.06534, lr:7.55e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.191, tt:4201.440\n",
      "Ep:102, loss:0.00001, loss_test:0.06745, lr:7.47e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.183, tt:4241.888\n",
      "Ep:103, loss:0.00001, loss_test:0.06720, lr:7.40e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.176, tt:4282.295\n",
      "Ep:104, loss:0.00001, loss_test:0.06549, lr:7.32e-03, fs:0.78107 (r=0.667,p=0.943),  time:41.173, tt:4323.127\n",
      "Ep:105, loss:0.00001, loss_test:0.06600, lr:7.25e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.192, tt:4366.378\n",
      "Ep:106, loss:0.00000, loss_test:0.06796, lr:7.18e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.200, tt:4408.419\n",
      "Ep:107, loss:0.00000, loss_test:0.06483, lr:7.11e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.212, tt:4450.869\n",
      "Ep:108, loss:0.00000, loss_test:0.07132, lr:7.03e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.204, tt:4491.252\n",
      "Ep:109, loss:0.00000, loss_test:0.06414, lr:6.96e-03, fs:0.82759 (r=0.727,p=0.960),  time:41.197, tt:4531.655\n",
      "Ep:110, loss:0.00000, loss_test:0.06888, lr:6.89e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.176, tt:4570.505\n",
      "Ep:111, loss:0.00000, loss_test:0.06791, lr:6.83e-03, fs:0.75610 (r=0.626,p=0.954),  time:41.181, tt:4612.304\n",
      "Ep:112, loss:0.00000, loss_test:0.06510, lr:6.76e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.179, tt:4653.215\n",
      "Ep:113, loss:0.00000, loss_test:0.06714, lr:6.69e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.176, tt:4694.050\n",
      "Ep:114, loss:0.00000, loss_test:0.06738, lr:6.62e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.180, tt:4735.666\n",
      "Ep:115, loss:0.00000, loss_test:0.06723, lr:6.56e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.167, tt:4775.375\n",
      "Ep:116, loss:0.00000, loss_test:0.06628, lr:6.49e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.173, tt:4817.275\n",
      "Ep:117, loss:0.00000, loss_test:0.06681, lr:6.43e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.159, tt:4856.720\n",
      "Ep:118, loss:0.00000, loss_test:0.06540, lr:6.36e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.157, tt:4897.688\n",
      "Ep:119, loss:0.00000, loss_test:0.06778, lr:6.30e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.164, tt:4939.622\n",
      "Ep:120, loss:0.00000, loss_test:0.06744, lr:6.24e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.155, tt:4979.754\n",
      "Ep:121, loss:0.00000, loss_test:0.06541, lr:6.17e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.147, tt:5019.947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:122, loss:0.00000, loss_test:0.06810, lr:6.11e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.150, tt:5061.430\n",
      "Ep:123, loss:0.00000, loss_test:0.06841, lr:6.05e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.136, tt:5100.834\n",
      "Ep:124, loss:0.00000, loss_test:0.06499, lr:5.99e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.118, tt:5139.709\n",
      "Ep:125, loss:0.00000, loss_test:0.06784, lr:5.93e-03, fs:0.77844 (r=0.657,p=0.956),  time:41.164, tt:5186.649\n",
      "Ep:126, loss:0.00000, loss_test:0.06799, lr:5.87e-03, fs:0.73292 (r=0.596,p=0.952),  time:41.154, tt:5226.581\n",
      "Ep:127, loss:0.00000, loss_test:0.06655, lr:5.81e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.153, tt:5267.523\n",
      "Ep:128, loss:0.00000, loss_test:0.06664, lr:5.75e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.151, tt:5308.521\n",
      "Ep:129, loss:0.00000, loss_test:0.06813, lr:5.70e-03, fs:0.77108 (r=0.646,p=0.955),  time:41.133, tt:5347.239\n",
      "Ep:130, loss:0.00000, loss_test:0.06563, lr:5.64e-03, fs:0.78571 (r=0.667,p=0.957),  time:41.124, tt:5387.217\n",
      "Ep:131, loss:0.00000, loss_test:0.06739, lr:5.58e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.129, tt:5429.009\n",
      "Ep:132, loss:0.00000, loss_test:0.06919, lr:5.53e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.136, tt:5471.120\n",
      "Ep:133, loss:0.00000, loss_test:0.06583, lr:5.47e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.132, tt:5511.723\n",
      "Ep:134, loss:0.00000, loss_test:0.06640, lr:5.42e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.138, tt:5553.658\n",
      "Ep:135, loss:0.00000, loss_test:0.06688, lr:5.36e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.152, tt:5596.710\n",
      "Ep:136, loss:0.00000, loss_test:0.06752, lr:5.31e-03, fs:0.74847 (r=0.616,p=0.953),  time:41.148, tt:5637.321\n",
      "Ep:137, loss:0.00000, loss_test:0.06684, lr:5.26e-03, fs:0.74074 (r=0.606,p=0.952),  time:41.164, tt:5680.669\n",
      "Ep:138, loss:0.00000, loss_test:0.06682, lr:5.20e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.170, tt:5722.657\n",
      "Ep:139, loss:0.00000, loss_test:0.06714, lr:5.15e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.187, tt:5766.168\n",
      "Ep:140, loss:0.00000, loss_test:0.06613, lr:5.10e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.201, tt:5809.367\n",
      "Ep:141, loss:0.00000, loss_test:0.06690, lr:5.05e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.210, tt:5851.758\n",
      "Ep:142, loss:0.00000, loss_test:0.06767, lr:5.00e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.205, tt:5892.333\n",
      "Ep:143, loss:0.00000, loss_test:0.06644, lr:4.95e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.199, tt:5932.660\n",
      "Ep:144, loss:0.00000, loss_test:0.06738, lr:4.90e-03, fs:0.75309 (r=0.616,p=0.968),  time:41.207, tt:5974.967\n",
      "Ep:145, loss:0.00000, loss_test:0.06676, lr:4.85e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.207, tt:6016.170\n",
      "Ep:146, loss:0.00000, loss_test:0.06751, lr:4.80e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.207, tt:6057.454\n",
      "Ep:147, loss:0.00000, loss_test:0.06772, lr:4.75e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.202, tt:6097.941\n",
      "Ep:148, loss:0.00000, loss_test:0.06657, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.209, tt:6140.116\n",
      "Ep:149, loss:0.00000, loss_test:0.06768, lr:4.66e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.200, tt:6180.059\n",
      "Ep:150, loss:0.00000, loss_test:0.06658, lr:4.61e-03, fs:0.76829 (r=0.636,p=0.969),  time:41.189, tt:6219.501\n",
      "Ep:151, loss:0.00000, loss_test:0.06789, lr:4.57e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.191, tt:6261.008\n",
      "Ep:152, loss:0.00000, loss_test:0.06677, lr:4.52e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.196, tt:6302.930\n",
      "Ep:153, loss:0.00000, loss_test:0.06767, lr:4.48e-03, fs:0.75309 (r=0.616,p=0.968),  time:41.205, tt:6345.605\n",
      "Ep:154, loss:0.00000, loss_test:0.06836, lr:4.43e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.197, tt:6385.595\n",
      "Ep:155, loss:0.00000, loss_test:0.06728, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.191, tt:6425.812\n",
      "Ep:156, loss:0.00000, loss_test:0.06711, lr:4.34e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.187, tt:6466.283\n",
      "Ep:157, loss:0.00000, loss_test:0.06654, lr:4.30e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.191, tt:6508.106\n",
      "Ep:158, loss:0.00000, loss_test:0.06678, lr:4.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:41.191, tt:6549.401\n",
      "Ep:159, loss:0.00000, loss_test:0.06715, lr:4.21e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.193, tt:6590.921\n",
      "Ep:160, loss:0.00000, loss_test:0.06646, lr:4.17e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.195, tt:6632.456\n",
      "Ep:161, loss:0.00000, loss_test:0.06737, lr:4.13e-03, fs:0.75309 (r=0.616,p=0.968),  time:41.193, tt:6673.234\n",
      "Ep:162, loss:0.00000, loss_test:0.06668, lr:4.09e-03, fs:0.77576 (r=0.646,p=0.970),  time:41.188, tt:6713.621\n",
      "Ep:163, loss:0.00000, loss_test:0.06660, lr:4.05e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.179, tt:6753.277\n",
      "Ep:164, loss:0.00000, loss_test:0.06757, lr:4.01e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.182, tt:6795.091\n",
      "Ep:165, loss:0.00000, loss_test:0.06705, lr:3.97e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.184, tt:6836.559\n",
      "Ep:166, loss:0.00000, loss_test:0.06662, lr:3.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:41.213, tt:6882.632\n",
      "Ep:167, loss:0.00000, loss_test:0.06676, lr:3.89e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.222, tt:6925.327\n",
      "Ep:168, loss:0.00000, loss_test:0.06716, lr:3.85e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.212, tt:6964.897\n",
      "Ep:169, loss:0.00000, loss_test:0.06754, lr:3.81e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.199, tt:7003.841\n",
      "Ep:170, loss:0.00000, loss_test:0.06707, lr:3.77e-03, fs:0.75309 (r=0.616,p=0.968),  time:41.202, tt:7045.528\n",
      "Ep:171, loss:0.00000, loss_test:0.06704, lr:3.73e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.212, tt:7088.381\n",
      "Ep:172, loss:0.00000, loss_test:0.06771, lr:3.70e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.201, tt:7127.755\n",
      "Ep:173, loss:0.00000, loss_test:0.06755, lr:3.66e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.205, tt:7169.695\n",
      "Ep:174, loss:0.00000, loss_test:0.06685, lr:3.62e-03, fs:0.75309 (r=0.616,p=0.968),  time:41.203, tt:7210.586\n",
      "Ep:175, loss:0.00000, loss_test:0.06694, lr:3.59e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.203, tt:7251.645\n",
      "Ep:176, loss:0.00000, loss_test:0.06723, lr:3.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.211, tt:7294.416\n",
      "Ep:177, loss:0.00000, loss_test:0.06721, lr:3.52e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.212, tt:7335.759\n",
      "Ep:178, loss:0.00000, loss_test:0.06668, lr:3.48e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.216, tt:7377.637\n",
      "Ep:179, loss:0.00000, loss_test:0.06714, lr:3.45e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.219, tt:7419.441\n",
      "Ep:180, loss:0.00000, loss_test:0.06702, lr:3.41e-03, fs:0.74534 (r=0.606,p=0.968),  time:41.223, tt:7461.287\n",
      "Ep:181, loss:0.00000, loss_test:0.06726, lr:3.38e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.221, tt:7502.157\n",
      "Ep:182, loss:0.00000, loss_test:0.06706, lr:3.34e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.234, tt:7545.789\n",
      "Ep:183, loss:0.00000, loss_test:0.06712, lr:3.31e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.238, tt:7587.873\n",
      "Ep:184, loss:0.00000, loss_test:0.06672, lr:3.28e-03, fs:0.76074 (r=0.626,p=0.969),  time:41.245, tt:7630.249\n",
      "Ep:185, loss:0.00000, loss_test:0.06746, lr:3.24e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.261, tt:7674.496\n",
      "Ep:186, loss:0.00000, loss_test:0.06744, lr:3.21e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.257, tt:7715.096\n",
      "Ep:187, loss:0.00000, loss_test:0.06740, lr:3.18e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.265, tt:7757.736\n",
      "Ep:188, loss:0.00000, loss_test:0.06739, lr:3.15e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.261, tt:7798.384\n",
      "Ep:189, loss:0.00000, loss_test:0.06718, lr:3.12e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.264, tt:7840.158\n",
      "Ep:190, loss:0.00000, loss_test:0.06759, lr:3.09e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.270, tt:7882.605\n",
      "Ep:191, loss:0.00000, loss_test:0.06699, lr:3.05e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.260, tt:7921.969\n",
      "Ep:192, loss:0.00000, loss_test:0.06694, lr:3.02e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.257, tt:7962.652\n",
      "Ep:193, loss:0.00000, loss_test:0.06736, lr:2.99e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.253, tt:8003.014\n",
      "Ep:194, loss:0.00000, loss_test:0.06704, lr:2.96e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.277, tt:8049.093\n",
      "Ep:195, loss:0.00000, loss_test:0.06716, lr:2.93e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.281, tt:8091.060\n",
      "Ep:196, loss:0.00000, loss_test:0.06724, lr:2.90e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.276, tt:8131.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:197, loss:0.00000, loss_test:0.06727, lr:2.88e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.284, tt:8174.143\n",
      "Ep:198, loss:0.00000, loss_test:0.06756, lr:2.85e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.277, tt:8214.166\n",
      "Ep:199, loss:0.00000, loss_test:0.06734, lr:2.82e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.284, tt:8256.709\n",
      "Ep:200, loss:0.00000, loss_test:0.06696, lr:2.79e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.285, tt:8298.292\n",
      "Ep:201, loss:0.00000, loss_test:0.06726, lr:2.76e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.289, tt:8340.288\n",
      "Ep:202, loss:0.00000, loss_test:0.06737, lr:2.73e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.289, tt:8381.724\n",
      "Ep:203, loss:0.00000, loss_test:0.06734, lr:2.71e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.283, tt:8421.798\n",
      "Ep:204, loss:0.00000, loss_test:0.06657, lr:2.68e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.282, tt:8462.853\n",
      "Ep:205, loss:0.00000, loss_test:0.06714, lr:2.65e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.288, tt:8505.304\n",
      "Ep:206, loss:0.00000, loss_test:0.06814, lr:2.63e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.285, tt:8546.033\n",
      "Ep:207, loss:0.00000, loss_test:0.06748, lr:2.60e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.286, tt:8587.530\n",
      "Ep:208, loss:0.00000, loss_test:0.06689, lr:2.57e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.251, tt:8621.541\n",
      "Ep:209, loss:0.00000, loss_test:0.06706, lr:2.55e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.210, tt:8654.109\n",
      "Ep:210, loss:0.00000, loss_test:0.06706, lr:2.52e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.124, tt:8677.252\n",
      "Ep:211, loss:0.00000, loss_test:0.06730, lr:2.50e-03, fs:0.73750 (r=0.596,p=0.967),  time:41.022, tt:8696.594\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,211,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,212,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02060, lr:6.00e-02, fs:0.65455 (r=0.828,p=0.541),  time:30.095, tt:30.095\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02295, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.496, tt:66.992\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02409, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.979, tt:107.937\n",
      "Ep:3, loss:0.00005, loss_test:0.02334, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.772, tt:147.088\n",
      "Ep:4, loss:0.00005, loss_test:0.02195, lr:6.00e-02, fs:0.65600 (r=0.943,p=0.503),  time:37.322, tt:186.608\n",
      "Ep:5, loss:0.00005, loss_test:0.02086, lr:6.00e-02, fs:0.66102 (r=0.897,p=0.523),  time:37.755, tt:226.531\n",
      "Ep:6, loss:0.00004, loss_test:0.02088, lr:6.00e-02, fs:0.67890 (r=0.851,p=0.565),  time:37.784, tt:264.490\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02179, lr:6.00e-02, fs:0.66667 (r=0.770,p=0.588),  time:37.849, tt:302.790\n",
      "Ep:8, loss:0.00004, loss_test:0.02191, lr:6.00e-02, fs:0.64948 (r=0.724,p=0.589),  time:38.395, tt:345.554\n",
      "Ep:9, loss:0.00004, loss_test:0.02030, lr:6.00e-02, fs:0.68020 (r=0.770,p=0.609),  time:38.329, tt:383.287\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01885, lr:6.00e-02, fs:0.69484 (r=0.851,p=0.587),  time:38.420, tt:422.620\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01831, lr:6.00e-02, fs:0.70270 (r=0.897,p=0.578),  time:38.469, tt:461.624\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01806, lr:6.00e-02, fs:0.70000 (r=0.885,p=0.579),  time:38.397, tt:499.164\n",
      "Ep:13, loss:0.00003, loss_test:0.01792, lr:6.00e-02, fs:0.71028 (r=0.874,p=0.598),  time:38.346, tt:536.844\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01782, lr:6.00e-02, fs:0.68317 (r=0.793,p=0.600),  time:38.209, tt:573.140\n",
      "Ep:15, loss:0.00003, loss_test:0.01757, lr:6.00e-02, fs:0.67005 (r=0.759,p=0.600),  time:38.145, tt:610.323\n",
      "Ep:16, loss:0.00003, loss_test:0.01701, lr:6.00e-02, fs:0.68687 (r=0.782,p=0.613),  time:38.091, tt:647.545\n",
      "Ep:17, loss:0.00003, loss_test:0.01642, lr:6.00e-02, fs:0.72195 (r=0.851,p=0.627),  time:38.110, tt:685.980\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01594, lr:6.00e-02, fs:0.75362 (r=0.897,p=0.650),  time:38.112, tt:724.125\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01558, lr:6.00e-02, fs:0.76098 (r=0.897,p=0.661),  time:38.155, tt:763.105\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01528, lr:6.00e-02, fs:0.76142 (r=0.862,p=0.682),  time:38.117, tt:800.450\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01499, lr:6.00e-02, fs:0.75897 (r=0.851,p=0.685),  time:38.170, tt:839.746\n",
      "Ep:22, loss:0.00003, loss_test:0.01469, lr:6.00e-02, fs:0.79793 (r=0.885,p=0.726),  time:38.194, tt:878.473\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01434, lr:6.00e-02, fs:0.81218 (r=0.920,p=0.727),  time:38.221, tt:917.298\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01408, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:38.213, tt:955.331\n",
      "Ep:25, loss:0.00002, loss_test:0.01385, lr:6.00e-02, fs:0.80829 (r=0.897,p=0.736),  time:38.101, tt:990.634\n",
      "Ep:26, loss:0.00002, loss_test:0.01365, lr:6.00e-02, fs:0.82105 (r=0.897,p=0.757),  time:38.080, tt:1028.169\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01345, lr:6.00e-02, fs:0.82105 (r=0.897,p=0.757),  time:38.115, tt:1067.208\n",
      "Ep:28, loss:0.00002, loss_test:0.01330, lr:6.00e-02, fs:0.82105 (r=0.897,p=0.757),  time:38.142, tt:1106.111\n",
      "Ep:29, loss:0.00002, loss_test:0.01317, lr:6.00e-02, fs:0.82105 (r=0.897,p=0.757),  time:38.111, tt:1143.321\n",
      "Ep:30, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.81481 (r=0.885,p=0.755),  time:38.107, tt:1181.311\n",
      "Ep:31, loss:0.00002, loss_test:0.01293, lr:6.00e-02, fs:0.84153 (r=0.885,p=0.802),  time:38.104, tt:1219.339\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01285, lr:6.00e-02, fs:0.85083 (r=0.885,p=0.819),  time:38.071, tt:1256.351\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.86813 (r=0.908,p=0.832),  time:38.152, tt:1297.169\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.87293 (r=0.908,p=0.840),  time:38.166, tt:1335.811\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01270, lr:6.00e-02, fs:0.85227 (r=0.862,p=0.843),  time:38.188, tt:1374.755\n",
      "Ep:36, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.85714 (r=0.862,p=0.852),  time:38.193, tt:1413.151\n",
      "Ep:37, loss:0.00002, loss_test:0.01271, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:38.207, tt:1451.862\n",
      "Ep:38, loss:0.00002, loss_test:0.01261, lr:6.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:38.232, tt:1491.040\n",
      "Ep:39, loss:0.00001, loss_test:0.01259, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:38.221, tt:1528.850\n",
      "Ep:40, loss:0.00001, loss_test:0.01260, lr:6.00e-02, fs:0.82558 (r=0.816,p=0.835),  time:38.206, tt:1566.461\n",
      "Ep:41, loss:0.00001, loss_test:0.01265, lr:6.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:38.195, tt:1604.178\n",
      "Ep:42, loss:0.00001, loss_test:0.01273, lr:6.00e-02, fs:0.81928 (r=0.782,p=0.861),  time:38.186, tt:1642.001\n",
      "Ep:43, loss:0.00001, loss_test:0.01276, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:38.166, tt:1679.316\n",
      "Ep:44, loss:0.00001, loss_test:0.01288, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:38.164, tt:1717.359\n",
      "Ep:45, loss:0.00001, loss_test:0.01293, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:38.200, tt:1757.186\n",
      "Ep:46, loss:0.00001, loss_test:0.01302, lr:5.94e-02, fs:0.80982 (r=0.759,p=0.868),  time:38.192, tt:1795.001\n",
      "Ep:47, loss:0.00001, loss_test:0.01304, lr:5.88e-02, fs:0.80488 (r=0.759,p=0.857),  time:38.203, tt:1833.753\n",
      "Ep:48, loss:0.00001, loss_test:0.01316, lr:5.82e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.245, tt:1873.999\n",
      "Ep:49, loss:0.00001, loss_test:0.01330, lr:5.76e-02, fs:0.80982 (r=0.759,p=0.868),  time:38.293, tt:1914.643\n",
      "Ep:50, loss:0.00001, loss_test:0.01342, lr:5.71e-02, fs:0.80982 (r=0.759,p=0.868),  time:38.345, tt:1955.579\n",
      "Ep:51, loss:0.00001, loss_test:0.01353, lr:5.65e-02, fs:0.80982 (r=0.759,p=0.868),  time:38.373, tt:1995.391\n",
      "Ep:52, loss:0.00001, loss_test:0.01365, lr:5.59e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.455, tt:2038.118\n",
      "Ep:53, loss:0.00001, loss_test:0.01386, lr:5.54e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.479, tt:2077.877\n",
      "Ep:54, loss:0.00001, loss_test:0.01398, lr:5.48e-02, fs:0.80982 (r=0.759,p=0.868),  time:38.466, tt:2115.641\n",
      "Ep:55, loss:0.00001, loss_test:0.01408, lr:5.43e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.491, tt:2155.516\n",
      "Ep:56, loss:0.00001, loss_test:0.01427, lr:5.37e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.514, tt:2195.318\n",
      "Ep:57, loss:0.00001, loss_test:0.01446, lr:5.32e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.559, tt:2236.419\n",
      "Ep:58, loss:0.00001, loss_test:0.01458, lr:5.27e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.576, tt:2275.965\n",
      "Ep:59, loss:0.00001, loss_test:0.01476, lr:5.21e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.609, tt:2316.530\n",
      "Ep:60, loss:0.00001, loss_test:0.01491, lr:5.16e-02, fs:0.81481 (r=0.759,p=0.880),  time:38.637, tt:2356.868\n",
      "Ep:61, loss:0.00001, loss_test:0.01503, lr:5.11e-02, fs:0.81988 (r=0.759,p=0.892),  time:38.668, tt:2397.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01516, lr:5.06e-02, fs:0.81988 (r=0.759,p=0.892),  time:38.692, tt:2437.604\n",
      "Ep:63, loss:0.00001, loss_test:0.01533, lr:5.01e-02, fs:0.81988 (r=0.759,p=0.892),  time:38.739, tt:2479.299\n",
      "Ep:64, loss:0.00001, loss_test:0.01552, lr:4.96e-02, fs:0.81988 (r=0.759,p=0.892),  time:38.766, tt:2519.804\n",
      "Ep:65, loss:0.00001, loss_test:0.01568, lr:4.91e-02, fs:0.82500 (r=0.759,p=0.904),  time:38.804, tt:2561.053\n",
      "Ep:66, loss:0.00001, loss_test:0.01585, lr:4.86e-02, fs:0.81529 (r=0.736,p=0.914),  time:38.850, tt:2602.976\n",
      "Ep:67, loss:0.00001, loss_test:0.01605, lr:4.81e-02, fs:0.83544 (r=0.759,p=0.930),  time:38.889, tt:2644.480\n",
      "Ep:68, loss:0.00001, loss_test:0.01624, lr:4.76e-02, fs:0.82051 (r=0.736,p=0.928),  time:38.917, tt:2685.295\n",
      "Ep:69, loss:0.00001, loss_test:0.01641, lr:4.71e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.051, tt:2733.554\n",
      "Ep:70, loss:0.00001, loss_test:0.01654, lr:4.67e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.067, tt:2773.751\n",
      "Ep:71, loss:0.00001, loss_test:0.01675, lr:4.62e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.096, tt:2814.890\n",
      "Ep:72, loss:0.00001, loss_test:0.01691, lr:4.57e-02, fs:0.82051 (r=0.736,p=0.928),  time:39.109, tt:2854.950\n",
      "Ep:73, loss:0.00001, loss_test:0.01706, lr:4.53e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.147, tt:2896.894\n",
      "Ep:74, loss:0.00001, loss_test:0.01724, lr:4.48e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.187, tt:2939.038\n",
      "Ep:75, loss:0.00001, loss_test:0.01743, lr:4.44e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.233, tt:2981.745\n",
      "Ep:76, loss:0.00001, loss_test:0.01761, lr:4.39e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.232, tt:3020.873\n",
      "Ep:77, loss:0.00001, loss_test:0.01780, lr:4.35e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.256, tt:3061.939\n",
      "Ep:78, loss:0.00001, loss_test:0.01797, lr:4.31e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.292, tt:3104.087\n",
      "Ep:79, loss:0.00001, loss_test:0.01816, lr:4.26e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.306, tt:3144.466\n",
      "Ep:80, loss:0.00000, loss_test:0.01828, lr:4.22e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.311, tt:3184.153\n",
      "Ep:81, loss:0.00000, loss_test:0.01843, lr:4.18e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.321, tt:3224.286\n",
      "Ep:82, loss:0.00000, loss_test:0.01860, lr:4.14e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.303, tt:3262.172\n",
      "Ep:83, loss:0.00000, loss_test:0.01873, lr:4.10e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.319, tt:3302.758\n",
      "Ep:84, loss:0.00000, loss_test:0.01890, lr:4.05e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.312, tt:3341.546\n",
      "Ep:85, loss:0.00000, loss_test:0.01910, lr:4.01e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.305, tt:3380.265\n",
      "Ep:86, loss:0.00000, loss_test:0.01920, lr:3.97e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.299, tt:3418.972\n",
      "Ep:87, loss:0.00000, loss_test:0.01936, lr:3.93e-02, fs:0.82581 (r=0.736,p=0.941),  time:39.327, tt:3460.759\n",
      "Ep:88, loss:0.00000, loss_test:0.01949, lr:3.89e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.321, tt:3499.607\n",
      "Ep:89, loss:0.00000, loss_test:0.01966, lr:3.86e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.324, tt:3539.181\n",
      "Ep:90, loss:0.00000, loss_test:0.01983, lr:3.82e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.331, tt:3579.085\n",
      "Ep:91, loss:0.00000, loss_test:0.01997, lr:3.78e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.345, tt:3619.718\n",
      "Ep:92, loss:0.00000, loss_test:0.02006, lr:3.74e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.369, tt:3661.278\n",
      "Ep:93, loss:0.00000, loss_test:0.02026, lr:3.70e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.373, tt:3701.077\n",
      "Ep:94, loss:0.00000, loss_test:0.02039, lr:3.67e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.394, tt:3742.399\n",
      "Ep:95, loss:0.00000, loss_test:0.02055, lr:3.63e-02, fs:0.83117 (r=0.736,p=0.955),  time:39.394, tt:3781.811\n",
      "Ep:96, loss:0.00000, loss_test:0.02063, lr:3.59e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.432, tt:3824.889\n",
      "Ep:97, loss:0.00000, loss_test:0.02077, lr:3.56e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.454, tt:3866.489\n",
      "Ep:98, loss:0.00000, loss_test:0.02097, lr:3.52e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.449, tt:3905.472\n",
      "Ep:99, loss:0.00000, loss_test:0.02107, lr:3.49e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.465, tt:3946.510\n",
      "Ep:100, loss:0.00000, loss_test:0.02120, lr:3.45e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.465, tt:3986.000\n",
      "Ep:101, loss:0.00000, loss_test:0.02133, lr:3.42e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.499, tt:4028.853\n",
      "Ep:102, loss:0.00000, loss_test:0.02144, lr:3.38e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.513, tt:4069.818\n",
      "Ep:103, loss:0.00000, loss_test:0.02161, lr:3.35e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.523, tt:4110.400\n",
      "Ep:104, loss:0.00000, loss_test:0.02172, lr:3.32e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.514, tt:4148.939\n",
      "Ep:105, loss:0.00000, loss_test:0.02184, lr:3.28e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.514, tt:4188.450\n",
      "Ep:106, loss:0.00000, loss_test:0.02199, lr:3.25e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.527, tt:4229.410\n",
      "Ep:107, loss:0.00000, loss_test:0.02213, lr:3.22e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.538, tt:4270.130\n",
      "Ep:108, loss:0.00000, loss_test:0.02218, lr:3.19e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.556, tt:4311.657\n",
      "Ep:109, loss:0.00000, loss_test:0.02232, lr:3.15e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.531, tt:4348.395\n",
      "Ep:110, loss:0.00000, loss_test:0.02247, lr:3.12e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.542, tt:4389.121\n",
      "Ep:111, loss:0.00000, loss_test:0.02256, lr:3.09e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.535, tt:4427.904\n",
      "Ep:112, loss:0.00000, loss_test:0.02269, lr:3.06e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.585, tt:4473.118\n",
      "Ep:113, loss:0.00000, loss_test:0.02272, lr:3.03e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.586, tt:4512.814\n",
      "Ep:114, loss:0.00000, loss_test:0.02283, lr:3.00e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.590, tt:4552.793\n",
      "Ep:115, loss:0.00000, loss_test:0.02299, lr:2.97e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.588, tt:4592.228\n",
      "Ep:116, loss:0.00000, loss_test:0.02302, lr:2.94e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.594, tt:4632.499\n",
      "Ep:117, loss:0.00000, loss_test:0.02318, lr:2.91e-02, fs:0.82353 (r=0.724,p=0.955),  time:39.599, tt:4672.635\n",
      "Ep:118, loss:0.00000, loss_test:0.02329, lr:2.88e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.601, tt:4712.487\n",
      "Ep:119, loss:0.00000, loss_test:0.02336, lr:2.85e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.607, tt:4752.870\n",
      "Ep:120, loss:0.00000, loss_test:0.02348, lr:2.82e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.601, tt:4791.702\n",
      "Ep:121, loss:0.00000, loss_test:0.02350, lr:2.80e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.605, tt:4831.800\n",
      "Ep:122, loss:0.00000, loss_test:0.02360, lr:2.77e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.605, tt:4871.446\n",
      "Ep:123, loss:0.00000, loss_test:0.02376, lr:2.74e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.605, tt:4910.967\n",
      "Ep:124, loss:0.00000, loss_test:0.02379, lr:2.71e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.602, tt:4950.262\n",
      "Ep:125, loss:0.00000, loss_test:0.02391, lr:2.69e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.607, tt:4990.453\n",
      "Ep:126, loss:0.00000, loss_test:0.02406, lr:2.66e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.602, tt:5029.398\n",
      "Ep:127, loss:0.00000, loss_test:0.02410, lr:2.63e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.611, tt:5070.238\n",
      "Ep:128, loss:0.00000, loss_test:0.02416, lr:2.61e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.613, tt:5110.046\n",
      "Ep:129, loss:0.00000, loss_test:0.02424, lr:2.58e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.606, tt:5148.756\n",
      "Ep:130, loss:0.00000, loss_test:0.02427, lr:2.55e-02, fs:0.82119 (r=0.713,p=0.969),  time:39.615, tt:5189.535\n",
      "Ep:131, loss:0.00000, loss_test:0.02438, lr:2.53e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.620, tt:5229.904\n",
      "Ep:132, loss:0.00000, loss_test:0.02450, lr:2.50e-02, fs:0.82895 (r=0.724,p=0.969),  time:39.609, tt:5267.965\n",
      "Ep:133, loss:0.00000, loss_test:0.02452, lr:2.48e-02, fs:0.82119 (r=0.713,p=0.969),  time:39.626, tt:5309.865\n",
      "Ep:134, loss:0.00000, loss_test:0.02465, lr:2.45e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.628, tt:5349.740\n",
      "Ep:135, loss:0.00000, loss_test:0.02472, lr:2.43e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.620, tt:5388.345\n",
      "Ep:136, loss:0.00000, loss_test:0.02480, lr:2.40e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.623, tt:5428.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02489, lr:2.38e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.625, tt:5468.264\n",
      "Ep:138, loss:0.00000, loss_test:0.02495, lr:2.36e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.623, tt:5507.580\n",
      "Ep:139, loss:0.00000, loss_test:0.02499, lr:2.33e-02, fs:0.81333 (r=0.701,p=0.968),  time:39.625, tt:5547.467\n",
      "Ep:140, loss:0.00000, loss_test:0.02510, lr:2.31e-02, fs:0.80537 (r=0.690,p=0.968),  time:39.622, tt:5586.742\n",
      "Ep:141, loss:0.00000, loss_test:0.02515, lr:2.29e-02, fs:0.80537 (r=0.690,p=0.968),  time:39.619, tt:5625.966\n",
      "Ep:142, loss:0.00000, loss_test:0.02520, lr:2.26e-02, fs:0.79730 (r=0.678,p=0.967),  time:39.627, tt:5666.615\n",
      "Ep:143, loss:0.00000, loss_test:0.02527, lr:2.24e-02, fs:0.78912 (r=0.667,p=0.967),  time:39.639, tt:5708.082\n",
      "Ep:144, loss:0.00000, loss_test:0.02531, lr:2.22e-02, fs:0.78082 (r=0.655,p=0.966),  time:39.629, tt:5746.189\n",
      "Ep:145, loss:0.00000, loss_test:0.02537, lr:2.20e-02, fs:0.78082 (r=0.655,p=0.966),  time:39.637, tt:5787.040\n",
      "Ep:146, loss:0.00000, loss_test:0.02541, lr:2.17e-02, fs:0.78912 (r=0.667,p=0.967),  time:39.634, tt:5826.181\n",
      "Ep:147, loss:0.00000, loss_test:0.02544, lr:2.15e-02, fs:0.78082 (r=0.655,p=0.966),  time:39.646, tt:5867.621\n",
      "Ep:148, loss:0.00000, loss_test:0.02551, lr:2.13e-02, fs:0.78082 (r=0.655,p=0.966),  time:39.654, tt:5908.407\n",
      "Ep:149, loss:0.00000, loss_test:0.02557, lr:2.11e-02, fs:0.77241 (r=0.644,p=0.966),  time:39.671, tt:5950.610\n",
      "Ep:150, loss:0.00000, loss_test:0.02565, lr:2.09e-02, fs:0.78082 (r=0.655,p=0.966),  time:39.717, tt:5997.272\n",
      "Ep:151, loss:0.00000, loss_test:0.02572, lr:2.07e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.746, tt:6041.360\n",
      "Ep:152, loss:0.00000, loss_test:0.02576, lr:2.05e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.756, tt:6082.622\n",
      "Ep:153, loss:0.00000, loss_test:0.02582, lr:2.03e-02, fs:0.76389 (r=0.632,p=0.965),  time:39.782, tt:6126.353\n",
      "Ep:154, loss:0.00000, loss_test:0.02588, lr:2.01e-02, fs:0.75524 (r=0.621,p=0.964),  time:39.793, tt:6167.919\n",
      "Ep:155, loss:0.00000, loss_test:0.02594, lr:1.99e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.819, tt:6211.830\n",
      "Ep:156, loss:0.00000, loss_test:0.02597, lr:1.97e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.835, tt:6254.049\n",
      "Ep:157, loss:0.00000, loss_test:0.02600, lr:1.95e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.861, tt:6298.013\n",
      "Ep:158, loss:0.00000, loss_test:0.02604, lr:1.93e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.870, tt:6339.383\n",
      "Ep:159, loss:0.00000, loss_test:0.02610, lr:1.91e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.883, tt:6381.320\n",
      "Ep:160, loss:0.00000, loss_test:0.02615, lr:1.89e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.890, tt:6422.363\n",
      "Ep:161, loss:0.00000, loss_test:0.02620, lr:1.87e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.888, tt:6461.901\n",
      "Ep:162, loss:0.00000, loss_test:0.02623, lr:1.85e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.891, tt:6502.263\n",
      "Ep:163, loss:0.00000, loss_test:0.02629, lr:1.83e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.903, tt:6544.149\n",
      "Ep:164, loss:0.00000, loss_test:0.02632, lr:1.81e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.898, tt:6583.193\n",
      "Ep:165, loss:0.00000, loss_test:0.02637, lr:1.80e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.901, tt:6623.552\n",
      "Ep:166, loss:0.00000, loss_test:0.02643, lr:1.78e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.895, tt:6662.431\n",
      "Ep:167, loss:0.00000, loss_test:0.02645, lr:1.76e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.921, tt:6706.745\n",
      "Ep:168, loss:0.00000, loss_test:0.02648, lr:1.74e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.924, tt:6747.128\n",
      "Ep:169, loss:0.00000, loss_test:0.02653, lr:1.73e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.920, tt:6786.345\n",
      "Ep:170, loss:0.00000, loss_test:0.02654, lr:1.71e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.925, tt:6827.116\n",
      "Ep:171, loss:0.00000, loss_test:0.02661, lr:1.69e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.917, tt:6865.676\n",
      "Ep:172, loss:0.00000, loss_test:0.02664, lr:1.67e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.911, tt:6904.672\n",
      "Ep:173, loss:0.00000, loss_test:0.02665, lr:1.66e-02, fs:0.74648 (r=0.609,p=0.964),  time:39.909, tt:6944.223\n",
      "Ep:174, loss:0.00000, loss_test:0.02669, lr:1.64e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.904, tt:6983.197\n",
      "Ep:175, loss:0.00000, loss_test:0.02672, lr:1.62e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.906, tt:7023.460\n",
      "Ep:176, loss:0.00000, loss_test:0.02675, lr:1.61e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.906, tt:7063.307\n",
      "Ep:177, loss:0.00000, loss_test:0.02680, lr:1.59e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.912, tt:7104.373\n",
      "Ep:178, loss:0.00000, loss_test:0.02683, lr:1.58e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.904, tt:7142.834\n",
      "Ep:179, loss:0.00000, loss_test:0.02685, lr:1.56e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.906, tt:7183.092\n",
      "Ep:180, loss:0.00000, loss_test:0.02690, lr:1.54e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.903, tt:7222.434\n",
      "Ep:181, loss:0.00000, loss_test:0.02692, lr:1.53e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.897, tt:7261.202\n",
      "Ep:182, loss:0.00000, loss_test:0.02695, lr:1.51e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.897, tt:7301.165\n",
      "Ep:183, loss:0.00000, loss_test:0.02697, lr:1.50e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.892, tt:7340.096\n",
      "Ep:184, loss:0.00000, loss_test:0.02702, lr:1.48e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.894, tt:7380.463\n",
      "Ep:185, loss:0.00000, loss_test:0.02707, lr:1.47e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.886, tt:7418.704\n",
      "Ep:186, loss:0.00000, loss_test:0.02710, lr:1.45e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.882, tt:7457.901\n",
      "Ep:187, loss:0.00000, loss_test:0.02710, lr:1.44e-02, fs:0.73759 (r=0.598,p=0.963),  time:39.881, tt:7497.542\n",
      "Ep:188, loss:0.00000, loss_test:0.02713, lr:1.43e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.889, tt:7539.042\n",
      "Ep:189, loss:0.00000, loss_test:0.02717, lr:1.41e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.895, tt:7580.004\n",
      "Ep:190, loss:0.00000, loss_test:0.02719, lr:1.40e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.897, tt:7620.282\n",
      "Ep:191, loss:0.00000, loss_test:0.02722, lr:1.38e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.897, tt:7660.141\n",
      "Ep:192, loss:0.00000, loss_test:0.02722, lr:1.37e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.897, tt:7700.172\n",
      "Ep:193, loss:0.00000, loss_test:0.02727, lr:1.36e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.888, tt:7738.337\n",
      "Ep:194, loss:0.00000, loss_test:0.02730, lr:1.34e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.880, tt:7776.527\n",
      "Ep:195, loss:0.00000, loss_test:0.02734, lr:1.33e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.878, tt:7816.122\n",
      "Ep:196, loss:0.00000, loss_test:0.02736, lr:1.32e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.870, tt:7854.419\n",
      "Ep:197, loss:0.00000, loss_test:0.02738, lr:1.30e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.865, tt:7893.313\n",
      "Ep:198, loss:0.00000, loss_test:0.02740, lr:1.29e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.860, tt:7932.159\n",
      "Ep:199, loss:0.00000, loss_test:0.02742, lr:1.28e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.862, tt:7972.418\n",
      "Ep:200, loss:0.00000, loss_test:0.02743, lr:1.26e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.866, tt:8012.968\n",
      "Ep:201, loss:0.00000, loss_test:0.02746, lr:1.25e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.858, tt:8051.217\n",
      "Ep:202, loss:0.00000, loss_test:0.02750, lr:1.24e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.842, tt:8088.016\n",
      "Ep:203, loss:0.00000, loss_test:0.02752, lr:1.23e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.840, tt:8127.267\n",
      "Ep:204, loss:0.00000, loss_test:0.02755, lr:1.21e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.840, tt:8167.238\n",
      "Ep:205, loss:0.00000, loss_test:0.02756, lr:1.20e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.829, tt:8204.725\n",
      "Ep:206, loss:0.00000, loss_test:0.02757, lr:1.19e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.815, tt:8241.714\n",
      "Ep:207, loss:0.00000, loss_test:0.02760, lr:1.18e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.820, tt:8282.492\n",
      "Ep:208, loss:0.00000, loss_test:0.02763, lr:1.17e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.819, tt:8322.094\n",
      "Ep:209, loss:0.00000, loss_test:0.02765, lr:1.15e-02, fs:0.72857 (r=0.586,p=0.962),  time:39.813, tt:8360.741\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN4\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14009, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:31.758, tt:31.758\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13837, lr:1.00e-02, fs:0.66923 (r=1.000,p=0.503),  time:32.737, tt:65.475\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13543, lr:1.00e-02, fs:0.65079 (r=0.943,p=0.497),  time:35.125, tt:105.374\n",
      "Ep:3, loss:0.00027, loss_test:0.13055, lr:1.00e-02, fs:0.64777 (r=0.920,p=0.500),  time:36.188, tt:144.753\n",
      "Ep:4, loss:0.00026, loss_test:0.12304, lr:1.00e-02, fs:0.67249 (r=0.885,p=0.542),  time:37.039, tt:185.193\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11503, lr:1.00e-02, fs:0.67961 (r=0.805,p=0.588),  time:37.692, tt:226.150\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11372, lr:1.00e-02, fs:0.69892 (r=0.747,p=0.657),  time:38.104, tt:266.726\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11465, lr:1.00e-02, fs:0.68478 (r=0.724,p=0.649),  time:39.214, tt:313.715\n",
      "Ep:8, loss:0.00022, loss_test:0.11123, lr:1.00e-02, fs:0.70526 (r=0.770,p=0.650),  time:39.544, tt:355.894\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10902, lr:1.00e-02, fs:0.70833 (r=0.782,p=0.648),  time:39.710, tt:397.100\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.10798, lr:1.00e-02, fs:0.67760 (r=0.713,p=0.646),  time:40.041, tt:440.455\n",
      "Ep:11, loss:0.00020, loss_test:0.10910, lr:1.00e-02, fs:0.67429 (r=0.678,p=0.670),  time:40.202, tt:482.423\n",
      "Ep:12, loss:0.00020, loss_test:0.10556, lr:1.00e-02, fs:0.67797 (r=0.690,p=0.667),  time:40.208, tt:522.702\n",
      "Ep:13, loss:0.00019, loss_test:0.10125, lr:1.00e-02, fs:0.70330 (r=0.736,p=0.674),  time:40.279, tt:563.909\n",
      "Ep:14, loss:0.00018, loss_test:0.09941, lr:1.00e-02, fs:0.69274 (r=0.713,p=0.674),  time:40.162, tt:602.437\n",
      "Ep:15, loss:0.00017, loss_test:0.09844, lr:1.00e-02, fs:0.67456 (r=0.655,p=0.695),  time:40.255, tt:644.080\n",
      "Ep:16, loss:0.00017, loss_test:0.09401, lr:1.00e-02, fs:0.71186 (r=0.724,p=0.700),  time:40.410, tt:686.964\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09236, lr:1.00e-02, fs:0.69364 (r=0.690,p=0.698),  time:40.391, tt:727.042\n",
      "Ep:18, loss:0.00015, loss_test:0.09028, lr:1.00e-02, fs:0.71345 (r=0.701,p=0.726),  time:40.437, tt:768.305\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08732, lr:1.00e-02, fs:0.74444 (r=0.770,p=0.720),  time:40.474, tt:809.476\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.08510, lr:1.00e-02, fs:0.77273 (r=0.782,p=0.764),  time:40.466, tt:849.790\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08336, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:40.529, tt:891.636\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.08191, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:40.626, tt:934.394\n",
      "Ep:23, loss:0.00012, loss_test:0.08013, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.712, tt:977.097\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.07922, lr:1.00e-02, fs:0.84746 (r=0.862,p=0.833),  time:40.716, tt:1017.904\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.07629, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:40.667, tt:1057.344\n",
      "Ep:26, loss:0.00011, loss_test:0.07546, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:40.697, tt:1098.828\n",
      "Ep:27, loss:0.00010, loss_test:0.07274, lr:1.00e-02, fs:0.84571 (r=0.851,p=0.841),  time:40.741, tt:1140.742\n",
      "Ep:28, loss:0.00010, loss_test:0.07403, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:40.750, tt:1181.737\n",
      "Ep:29, loss:0.00009, loss_test:0.07018, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:40.705, tt:1221.148\n",
      "Ep:30, loss:0.00009, loss_test:0.07190, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:40.764, tt:1263.675\n",
      "Ep:31, loss:0.00008, loss_test:0.06867, lr:1.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:40.798, tt:1305.535\n",
      "Ep:32, loss:0.00008, loss_test:0.06956, lr:1.00e-02, fs:0.82716 (r=0.770,p=0.893),  time:40.829, tt:1347.355\n",
      "Ep:33, loss:0.00007, loss_test:0.06897, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:40.853, tt:1388.992\n",
      "Ep:34, loss:0.00007, loss_test:0.06700, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:40.860, tt:1430.094\n",
      "Ep:35, loss:0.00007, loss_test:0.06684, lr:1.00e-02, fs:0.83951 (r=0.782,p=0.907),  time:40.962, tt:1474.636\n",
      "Ep:36, loss:0.00006, loss_test:0.06700, lr:9.90e-03, fs:0.83951 (r=0.782,p=0.907),  time:41.044, tt:1518.612\n",
      "Ep:37, loss:0.00006, loss_test:0.06551, lr:9.80e-03, fs:0.84146 (r=0.793,p=0.896),  time:41.102, tt:1561.870\n",
      "Ep:38, loss:0.00006, loss_test:0.07251, lr:9.70e-03, fs:0.83750 (r=0.770,p=0.918),  time:41.159, tt:1605.201\n",
      "Ep:39, loss:0.00006, loss_test:0.06593, lr:9.61e-03, fs:0.83436 (r=0.782,p=0.895),  time:41.202, tt:1648.100\n",
      "Ep:40, loss:0.00005, loss_test:0.06869, lr:9.51e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.252, tt:1691.324\n",
      "Ep:41, loss:0.00005, loss_test:0.06842, lr:9.41e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.272, tt:1733.436\n",
      "Ep:42, loss:0.00005, loss_test:0.06835, lr:9.32e-03, fs:0.85000 (r=0.782,p=0.932),  time:41.304, tt:1776.066\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00004, loss_test:0.06868, lr:9.32e-03, fs:0.83750 (r=0.770,p=0.918),  time:41.338, tt:1818.857\n",
      "Ep:44, loss:0.00004, loss_test:0.06848, lr:9.32e-03, fs:0.83750 (r=0.770,p=0.918),  time:41.386, tt:1862.360\n",
      "Ep:45, loss:0.00004, loss_test:0.07110, lr:9.32e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.465, tt:1907.385\n",
      "Ep:46, loss:0.00004, loss_test:0.07183, lr:9.32e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.484, tt:1949.769\n",
      "Ep:47, loss:0.00004, loss_test:0.07551, lr:9.32e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.509, tt:1992.452\n",
      "Ep:48, loss:0.00003, loss_test:0.06784, lr:9.32e-03, fs:0.83750 (r=0.770,p=0.918),  time:41.566, tt:2036.742\n",
      "Ep:49, loss:0.00003, loss_test:0.08136, lr:9.32e-03, fs:0.83333 (r=0.747,p=0.942),  time:41.592, tt:2079.609\n",
      "Ep:50, loss:0.00003, loss_test:0.07569, lr:9.32e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.627, tt:2122.993\n",
      "Ep:51, loss:0.00003, loss_test:0.07285, lr:9.32e-03, fs:0.84810 (r=0.770,p=0.944),  time:41.672, tt:2166.955\n",
      "Ep:52, loss:0.00003, loss_test:0.07122, lr:9.32e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.624, tt:2206.098\n",
      "Ep:53, loss:0.00003, loss_test:0.07810, lr:9.32e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.650, tt:2249.086\n",
      "Ep:54, loss:0.00003, loss_test:0.07666, lr:9.23e-03, fs:0.84810 (r=0.770,p=0.944),  time:41.584, tt:2287.113\n",
      "Ep:55, loss:0.00003, loss_test:0.06937, lr:9.14e-03, fs:0.83544 (r=0.759,p=0.930),  time:41.585, tt:2328.739\n",
      "Ep:56, loss:0.00002, loss_test:0.08388, lr:9.04e-03, fs:0.81818 (r=0.724,p=0.940),  time:41.572, tt:2369.619\n",
      "Ep:57, loss:0.00002, loss_test:0.07783, lr:8.95e-03, fs:0.84277 (r=0.770,p=0.931),  time:41.536, tt:2409.099\n",
      "Ep:58, loss:0.00002, loss_test:0.07809, lr:8.86e-03, fs:0.85535 (r=0.782,p=0.944),  time:41.464, tt:2446.394\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.08735, lr:8.86e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.481, tt:2488.862\n",
      "Ep:60, loss:0.00002, loss_test:0.07830, lr:8.86e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.450, tt:2528.457\n",
      "Ep:61, loss:0.00002, loss_test:0.08433, lr:8.86e-03, fs:0.84810 (r=0.770,p=0.944),  time:41.451, tt:2569.967\n",
      "Ep:62, loss:0.00002, loss_test:0.07768, lr:8.86e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.438, tt:2610.566\n",
      "Ep:63, loss:0.00002, loss_test:0.08578, lr:8.86e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.445, tt:2652.462\n",
      "Ep:64, loss:0.00001, loss_test:0.08497, lr:8.86e-03, fs:0.84810 (r=0.770,p=0.944),  time:41.459, tt:2694.813\n",
      "Ep:65, loss:0.00001, loss_test:0.08147, lr:8.86e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.470, tt:2737.016\n",
      "Ep:66, loss:0.00001, loss_test:0.08846, lr:8.86e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.456, tt:2777.529\n",
      "Ep:67, loss:0.00001, loss_test:0.08268, lr:8.86e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.464, tt:2819.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.08814, lr:8.86e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.432, tt:2858.790\n",
      "Ep:69, loss:0.00001, loss_test:0.08558, lr:8.86e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.411, tt:2898.788\n",
      "Ep:70, loss:0.00001, loss_test:0.08408, lr:8.78e-03, fs:0.83333 (r=0.747,p=0.942),  time:41.389, tt:2938.589\n",
      "Ep:71, loss:0.00001, loss_test:0.08883, lr:8.69e-03, fs:0.83333 (r=0.747,p=0.942),  time:41.423, tt:2982.471\n",
      "Ep:72, loss:0.00001, loss_test:0.08771, lr:8.60e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.424, tt:3023.931\n",
      "Ep:73, loss:0.00001, loss_test:0.08462, lr:8.51e-03, fs:0.84076 (r=0.759,p=0.943),  time:41.401, tt:3063.666\n",
      "Ep:74, loss:0.00001, loss_test:0.08846, lr:8.43e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.400, tt:3104.989\n",
      "Ep:75, loss:0.00001, loss_test:0.08738, lr:8.35e-03, fs:0.84416 (r=0.747,p=0.970),  time:41.407, tt:3146.939\n",
      "Ep:76, loss:0.00001, loss_test:0.08590, lr:8.26e-03, fs:0.83871 (r=0.747,p=0.956),  time:41.420, tt:3189.334\n",
      "Ep:77, loss:0.00001, loss_test:0.08920, lr:8.18e-03, fs:0.83660 (r=0.736,p=0.970),  time:41.419, tt:3230.654\n",
      "Ep:78, loss:0.00001, loss_test:0.08574, lr:8.10e-03, fs:0.83117 (r=0.736,p=0.955),  time:41.415, tt:3271.793\n",
      "Ep:79, loss:0.00000, loss_test:0.08768, lr:8.02e-03, fs:0.83871 (r=0.747,p=0.956),  time:41.409, tt:3312.703\n",
      "Ep:80, loss:0.00000, loss_test:0.08629, lr:7.94e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.398, tt:3353.269\n",
      "Ep:81, loss:0.00000, loss_test:0.08502, lr:7.86e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.391, tt:3394.053\n",
      "Ep:82, loss:0.00000, loss_test:0.08749, lr:7.78e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.369, tt:3433.605\n",
      "Ep:83, loss:0.00000, loss_test:0.08628, lr:7.70e-03, fs:0.83871 (r=0.747,p=0.956),  time:41.381, tt:3475.965\n",
      "Ep:84, loss:0.00000, loss_test:0.08597, lr:7.62e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.371, tt:3516.500\n",
      "Ep:85, loss:0.00000, loss_test:0.08755, lr:7.55e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.370, tt:3557.796\n",
      "Ep:86, loss:0.00000, loss_test:0.08742, lr:7.47e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.393, tt:3601.176\n",
      "Ep:87, loss:0.00000, loss_test:0.08650, lr:7.40e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.397, tt:3642.946\n",
      "Ep:88, loss:0.00000, loss_test:0.08756, lr:7.32e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.409, tt:3685.406\n",
      "Ep:89, loss:0.00000, loss_test:0.08777, lr:7.25e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.450, tt:3730.486\n",
      "Ep:90, loss:0.00000, loss_test:0.08679, lr:7.18e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.476, tt:3774.296\n",
      "Ep:91, loss:0.00000, loss_test:0.08671, lr:7.11e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.485, tt:3816.629\n",
      "Ep:92, loss:0.00000, loss_test:0.08687, lr:7.03e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.481, tt:3857.736\n",
      "Ep:93, loss:0.00000, loss_test:0.08651, lr:6.96e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.457, tt:3896.948\n",
      "Ep:94, loss:0.00000, loss_test:0.08740, lr:6.89e-03, fs:0.84615 (r=0.759,p=0.957),  time:41.453, tt:3938.027\n",
      "Ep:95, loss:0.00000, loss_test:0.08747, lr:6.83e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.460, tt:3980.188\n",
      "Ep:96, loss:0.00000, loss_test:0.08592, lr:6.76e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.468, tt:4022.391\n",
      "Ep:97, loss:0.00000, loss_test:0.08835, lr:6.69e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.479, tt:4064.937\n",
      "Ep:98, loss:0.00000, loss_test:0.08787, lr:6.62e-03, fs:0.83871 (r=0.747,p=0.956),  time:41.478, tt:4106.277\n",
      "Ep:99, loss:0.00000, loss_test:0.08735, lr:6.56e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.489, tt:4148.875\n",
      "Ep:100, loss:0.00000, loss_test:0.08677, lr:6.49e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.474, tt:4188.871\n",
      "Ep:101, loss:0.00000, loss_test:0.08842, lr:6.43e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.476, tt:4230.534\n",
      "Ep:102, loss:0.00000, loss_test:0.08683, lr:6.36e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.493, tt:4273.824\n",
      "Ep:103, loss:0.00000, loss_test:0.08753, lr:6.30e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.492, tt:4315.202\n",
      "Ep:104, loss:0.00000, loss_test:0.08837, lr:6.24e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.497, tt:4357.193\n",
      "Ep:105, loss:0.00000, loss_test:0.08779, lr:6.17e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.493, tt:4398.289\n",
      "Ep:106, loss:0.00000, loss_test:0.08810, lr:6.11e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.482, tt:4438.561\n",
      "Ep:107, loss:0.00000, loss_test:0.08853, lr:6.05e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.473, tt:4479.128\n",
      "Ep:108, loss:0.00000, loss_test:0.08810, lr:5.99e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.482, tt:4521.519\n",
      "Ep:109, loss:0.00000, loss_test:0.08712, lr:5.93e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.496, tt:4564.581\n",
      "Ep:110, loss:0.00000, loss_test:0.08735, lr:5.87e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.497, tt:4606.180\n",
      "Ep:111, loss:0.00000, loss_test:0.08783, lr:5.81e-03, fs:0.83871 (r=0.747,p=0.956),  time:41.499, tt:4647.923\n",
      "Ep:112, loss:0.00000, loss_test:0.08809, lr:5.75e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.550, tt:4695.162\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00000, loss_test:0.08707, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.553, tt:4737.028\n",
      "Ep:114, loss:0.00000, loss_test:0.08775, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.554, tt:4778.697\n",
      "Ep:115, loss:0.00000, loss_test:0.08789, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.531, tt:4817.588\n",
      "Ep:116, loss:0.00000, loss_test:0.08753, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.532, tt:4859.263\n",
      "Ep:117, loss:0.00000, loss_test:0.08743, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.530, tt:4900.538\n",
      "Ep:118, loss:0.00000, loss_test:0.08692, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.537, tt:4942.925\n",
      "Ep:119, loss:0.00000, loss_test:0.08722, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.542, tt:4985.057\n",
      "Ep:120, loss:0.00000, loss_test:0.08722, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.539, tt:5026.182\n",
      "Ep:121, loss:0.00000, loss_test:0.08709, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.552, tt:5069.304\n",
      "Ep:122, loss:0.00000, loss_test:0.08726, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.565, tt:5112.482\n",
      "Ep:123, loss:0.00000, loss_test:0.08708, lr:5.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.587, tt:5156.834\n",
      "Ep:124, loss:0.00000, loss_test:0.08726, lr:5.70e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.593, tt:5199.092\n",
      "Ep:125, loss:0.00000, loss_test:0.08785, lr:5.64e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.588, tt:5240.134\n",
      "Ep:126, loss:0.00000, loss_test:0.08772, lr:5.58e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.584, tt:5281.222\n",
      "Ep:127, loss:0.00000, loss_test:0.08715, lr:5.53e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.577, tt:5321.914\n",
      "Ep:128, loss:0.00000, loss_test:0.08721, lr:5.47e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.578, tt:5363.622\n",
      "Ep:129, loss:0.00000, loss_test:0.08750, lr:5.42e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.571, tt:5404.205\n",
      "Ep:130, loss:0.00000, loss_test:0.08686, lr:5.36e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.561, tt:5444.468\n",
      "Ep:131, loss:0.00000, loss_test:0.08671, lr:5.31e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.543, tt:5483.635\n",
      "Ep:132, loss:0.00000, loss_test:0.08770, lr:5.26e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.590, tt:5531.435\n",
      "Ep:133, loss:0.00000, loss_test:0.08704, lr:5.20e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.577, tt:5571.301\n",
      "Ep:134, loss:0.00000, loss_test:0.08663, lr:5.15e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.575, tt:5612.656\n",
      "Ep:135, loss:0.00000, loss_test:0.08770, lr:5.10e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.571, tt:5653.662\n",
      "Ep:136, loss:0.00000, loss_test:0.08787, lr:5.05e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.578, tt:5696.171\n",
      "Ep:137, loss:0.00000, loss_test:0.08687, lr:5.00e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.569, tt:5736.478\n",
      "Ep:138, loss:0.00000, loss_test:0.08706, lr:4.95e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.569, tt:5778.141\n",
      "Ep:139, loss:0.00000, loss_test:0.08720, lr:4.90e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.548, tt:5816.656\n",
      "Ep:140, loss:0.00000, loss_test:0.08710, lr:4.85e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.537, tt:5856.724\n",
      "Ep:141, loss:0.00000, loss_test:0.08694, lr:4.80e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.543, tt:5899.126\n",
      "Ep:142, loss:0.00000, loss_test:0.08708, lr:4.75e-03, fs:0.85350 (r=0.770,p=0.957),  time:41.534, tt:5939.425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.08695, lr:4.71e-03, fs:0.86076 (r=0.782,p=0.958),  time:41.530, tt:5980.364\n",
      "Ep:144, loss:0.00000, loss_test:0.08693, lr:4.66e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.526, tt:6021.200\n",
      "Ep:145, loss:0.00000, loss_test:0.08674, lr:4.61e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.514, tt:6061.047\n",
      "Ep:146, loss:0.00000, loss_test:0.08694, lr:4.57e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.506, tt:6101.317\n",
      "Ep:147, loss:0.00000, loss_test:0.08696, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.513, tt:6143.991\n",
      "##########Best model found so far##########\n",
      "Ep:148, loss:0.00000, loss_test:0.08664, lr:4.52e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.518, tt:6186.193\n",
      "Ep:149, loss:0.00000, loss_test:0.08648, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.515, tt:6227.189\n",
      "Ep:150, loss:0.00000, loss_test:0.08696, lr:4.52e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.520, tt:6269.445\n",
      "Ep:151, loss:0.00000, loss_test:0.08760, lr:4.52e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.525, tt:6311.725\n",
      "Ep:152, loss:0.00000, loss_test:0.08725, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.511, tt:6351.150\n",
      "Ep:153, loss:0.00000, loss_test:0.08695, lr:4.52e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.505, tt:6391.824\n",
      "Ep:154, loss:0.00000, loss_test:0.08717, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.486, tt:6430.335\n",
      "Ep:155, loss:0.00000, loss_test:0.08690, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.476, tt:6470.220\n",
      "Ep:156, loss:0.00000, loss_test:0.08669, lr:4.52e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.481, tt:6512.539\n",
      "Ep:157, loss:0.00000, loss_test:0.08684, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.463, tt:6551.210\n",
      "Ep:158, loss:0.00000, loss_test:0.08656, lr:4.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.460, tt:6592.159\n",
      "Ep:159, loss:0.00000, loss_test:0.08696, lr:4.48e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.461, tt:6633.814\n",
      "Ep:160, loss:0.00000, loss_test:0.08701, lr:4.43e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.461, tt:6675.217\n",
      "Ep:161, loss:0.00000, loss_test:0.08689, lr:4.39e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.450, tt:6714.888\n",
      "Ep:162, loss:0.00000, loss_test:0.08672, lr:4.34e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.446, tt:6755.646\n",
      "Ep:163, loss:0.00000, loss_test:0.08694, lr:4.30e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.444, tt:6796.830\n",
      "Ep:164, loss:0.00000, loss_test:0.08741, lr:4.26e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.434, tt:6836.677\n",
      "Ep:165, loss:0.00000, loss_test:0.08731, lr:4.21e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.419, tt:6875.512\n",
      "Ep:166, loss:0.00000, loss_test:0.08730, lr:4.17e-03, fs:0.85897 (r=0.770,p=0.971),  time:41.417, tt:6916.694\n",
      "Ep:167, loss:0.00000, loss_test:0.08764, lr:4.13e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.402, tt:6955.591\n",
      "Ep:168, loss:0.00000, loss_test:0.08725, lr:4.09e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.394, tt:6995.657\n",
      "Ep:169, loss:0.00000, loss_test:0.08701, lr:4.05e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.393, tt:7036.832\n",
      "Ep:170, loss:0.00000, loss_test:0.08733, lr:4.01e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.394, tt:7078.439\n",
      "Ep:171, loss:0.00000, loss_test:0.08741, lr:3.97e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.385, tt:7118.241\n",
      "Ep:172, loss:0.00000, loss_test:0.08734, lr:3.93e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.377, tt:7158.301\n",
      "Ep:173, loss:0.00000, loss_test:0.08733, lr:3.89e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.395, tt:7202.733\n",
      "Ep:174, loss:0.00000, loss_test:0.08710, lr:3.85e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.389, tt:7243.034\n",
      "Ep:175, loss:0.00000, loss_test:0.08713, lr:3.81e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.375, tt:7282.087\n",
      "Ep:176, loss:0.00000, loss_test:0.08713, lr:3.77e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.370, tt:7322.572\n",
      "Ep:177, loss:0.00000, loss_test:0.08714, lr:3.73e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.370, tt:7363.943\n",
      "Ep:178, loss:0.00000, loss_test:0.08744, lr:3.70e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.360, tt:7403.478\n",
      "Ep:179, loss:0.00000, loss_test:0.08738, lr:3.66e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.359, tt:7444.645\n",
      "Ep:180, loss:0.00000, loss_test:0.08730, lr:3.62e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.347, tt:7483.893\n",
      "Ep:181, loss:0.00000, loss_test:0.08737, lr:3.59e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.350, tt:7525.743\n",
      "Ep:182, loss:0.00000, loss_test:0.08715, lr:3.55e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.351, tt:7567.262\n",
      "Ep:183, loss:0.00000, loss_test:0.08721, lr:3.52e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.344, tt:7607.281\n",
      "Ep:184, loss:0.00000, loss_test:0.08770, lr:3.48e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.340, tt:7647.844\n",
      "Ep:185, loss:0.00000, loss_test:0.08741, lr:3.45e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.332, tt:7687.680\n",
      "Ep:186, loss:0.00000, loss_test:0.08742, lr:3.41e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.333, tt:7729.184\n",
      "Ep:187, loss:0.00000, loss_test:0.08752, lr:3.38e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.324, tt:7768.875\n",
      "Ep:188, loss:0.00000, loss_test:0.08758, lr:3.34e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.320, tt:7809.442\n",
      "Ep:189, loss:0.00000, loss_test:0.08765, lr:3.31e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.315, tt:7849.785\n",
      "Ep:190, loss:0.00000, loss_test:0.08753, lr:3.28e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.308, tt:7889.848\n",
      "Ep:191, loss:0.00000, loss_test:0.08731, lr:3.24e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.312, tt:7931.888\n",
      "Ep:192, loss:0.00000, loss_test:0.08739, lr:3.21e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.310, tt:7972.750\n",
      "Ep:193, loss:0.00000, loss_test:0.08755, lr:3.18e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.302, tt:8012.520\n",
      "Ep:194, loss:0.00000, loss_test:0.08754, lr:3.15e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.324, tt:8058.112\n",
      "Ep:195, loss:0.00000, loss_test:0.08747, lr:3.12e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.326, tt:8099.962\n",
      "Ep:196, loss:0.00000, loss_test:0.08748, lr:3.09e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.327, tt:8141.454\n",
      "Ep:197, loss:0.00000, loss_test:0.08756, lr:3.05e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.313, tt:8179.978\n",
      "Ep:198, loss:0.00000, loss_test:0.08759, lr:3.02e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.318, tt:8222.280\n",
      "Ep:199, loss:0.00000, loss_test:0.08755, lr:2.99e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.318, tt:8263.624\n",
      "Ep:200, loss:0.00000, loss_test:0.08767, lr:2.96e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.317, tt:8304.813\n",
      "Ep:201, loss:0.00000, loss_test:0.08770, lr:2.93e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.311, tt:8344.749\n",
      "Ep:202, loss:0.00000, loss_test:0.08774, lr:2.90e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.308, tt:8385.619\n",
      "Ep:203, loss:0.00000, loss_test:0.08766, lr:2.88e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.298, tt:8424.830\n",
      "Ep:204, loss:0.00000, loss_test:0.08777, lr:2.85e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.299, tt:8466.270\n",
      "Ep:205, loss:0.00000, loss_test:0.08768, lr:2.82e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.283, tt:8504.389\n",
      "Ep:206, loss:0.00000, loss_test:0.08780, lr:2.79e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.261, tt:8541.088\n",
      "Ep:207, loss:0.00000, loss_test:0.08786, lr:2.76e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.246, tt:8579.211\n",
      "Ep:208, loss:0.00000, loss_test:0.08782, lr:2.73e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.222, tt:8615.501\n",
      "Ep:209, loss:0.00000, loss_test:0.08783, lr:2.71e-03, fs:0.86624 (r=0.782,p=0.971),  time:41.199, tt:8651.841\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN4\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,210,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02010, lr:6.00e-02, fs:0.65455 (r=0.828,p=0.541),  time:23.317, tt:23.317\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02121, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.739, tt:51.478\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02167, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:26.742, tt:80.227\n",
      "Ep:3, loss:0.00004, loss_test:0.02065, lr:6.00e-02, fs:0.67451 (r=0.989,p=0.512),  time:27.445, tt:109.778\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.01963, lr:6.00e-02, fs:0.66667 (r=0.908,p=0.527),  time:28.128, tt:140.640\n",
      "Ep:5, loss:0.00004, loss_test:0.01968, lr:6.00e-02, fs:0.66977 (r=0.828,p=0.562),  time:28.481, tt:170.888\n",
      "Ep:6, loss:0.00004, loss_test:0.02075, lr:6.00e-02, fs:0.65969 (r=0.724,p=0.606),  time:28.647, tt:200.532\n",
      "Ep:7, loss:0.00003, loss_test:0.02047, lr:6.00e-02, fs:0.65591 (r=0.701,p=0.616),  time:28.679, tt:229.430\n",
      "Ep:8, loss:0.00003, loss_test:0.01890, lr:6.00e-02, fs:0.68020 (r=0.770,p=0.609),  time:28.816, tt:259.342\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01782, lr:6.00e-02, fs:0.68246 (r=0.828,p=0.581),  time:29.035, tt:290.349\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01729, lr:6.00e-02, fs:0.68778 (r=0.874,p=0.567),  time:29.193, tt:321.126\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01688, lr:6.00e-02, fs:0.71698 (r=0.874,p=0.608),  time:29.354, tt:352.247\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01658, lr:6.00e-02, fs:0.73171 (r=0.862,p=0.636),  time:29.346, tt:381.499\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01639, lr:6.00e-02, fs:0.72539 (r=0.805,p=0.660),  time:29.379, tt:411.299\n",
      "Ep:14, loss:0.00003, loss_test:0.01611, lr:6.00e-02, fs:0.73196 (r=0.816,p=0.664),  time:29.516, tt:442.746\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01569, lr:6.00e-02, fs:0.77612 (r=0.897,p=0.684),  time:29.621, tt:473.941\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01535, lr:6.00e-02, fs:0.77612 (r=0.897,p=0.684),  time:29.629, tt:503.698\n",
      "Ep:17, loss:0.00002, loss_test:0.01511, lr:6.00e-02, fs:0.77612 (r=0.897,p=0.684),  time:29.632, tt:533.376\n",
      "Ep:18, loss:0.00002, loss_test:0.01494, lr:6.00e-02, fs:0.78788 (r=0.897,p=0.703),  time:29.572, tt:561.859\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01474, lr:6.00e-02, fs:0.80402 (r=0.920,p=0.714),  time:29.507, tt:590.134\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01452, lr:6.00e-02, fs:0.81218 (r=0.920,p=0.727),  time:29.463, tt:618.722\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01433, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:29.454, tt:647.986\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01415, lr:6.00e-02, fs:0.83871 (r=0.897,p=0.788),  time:29.407, tt:676.362\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01387, lr:6.00e-02, fs:0.84324 (r=0.897,p=0.796),  time:29.385, tt:705.248\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.84783 (r=0.897,p=0.804),  time:29.361, tt:734.026\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:29.412, tt:764.718\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01355, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:29.436, tt:794.782\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:29.471, tt:825.184\n",
      "Ep:28, loss:0.00002, loss_test:0.01334, lr:6.00e-02, fs:0.87640 (r=0.897,p=0.857),  time:29.527, tt:856.275\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:29.558, tt:886.741\n",
      "Ep:30, loss:0.00002, loss_test:0.01333, lr:6.00e-02, fs:0.87861 (r=0.874,p=0.884),  time:29.589, tt:917.252\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00001, loss_test:0.01323, lr:6.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:29.628, tt:948.091\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00001, loss_test:0.01334, lr:6.00e-02, fs:0.88372 (r=0.874,p=0.894),  time:29.614, tt:977.275\n",
      "Ep:33, loss:0.00001, loss_test:0.01327, lr:6.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:29.570, tt:1005.386\n",
      "Ep:34, loss:0.00001, loss_test:0.01319, lr:6.00e-02, fs:0.87719 (r=0.862,p=0.893),  time:29.559, tt:1034.560\n",
      "Ep:35, loss:0.00001, loss_test:0.01328, lr:6.00e-02, fs:0.86391 (r=0.839,p=0.890),  time:29.544, tt:1063.587\n",
      "Ep:36, loss:0.00001, loss_test:0.01329, lr:6.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:29.561, tt:1093.741\n",
      "Ep:37, loss:0.00001, loss_test:0.01329, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.558, tt:1123.205\n",
      "Ep:38, loss:0.00001, loss_test:0.01333, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.561, tt:1152.864\n",
      "Ep:39, loss:0.00001, loss_test:0.01337, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.562, tt:1182.495\n",
      "Ep:40, loss:0.00001, loss_test:0.01335, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.507, tt:1209.784\n",
      "Ep:41, loss:0.00001, loss_test:0.01361, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.519, tt:1239.794\n",
      "Ep:42, loss:0.00001, loss_test:0.01361, lr:6.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.511, tt:1268.977\n",
      "Ep:43, loss:0.00001, loss_test:0.01366, lr:5.94e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.497, tt:1297.889\n",
      "Ep:44, loss:0.00001, loss_test:0.01377, lr:5.88e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.522, tt:1328.512\n",
      "Ep:45, loss:0.00001, loss_test:0.01373, lr:5.82e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.533, tt:1358.527\n",
      "Ep:46, loss:0.00001, loss_test:0.01390, lr:5.76e-02, fs:0.84848 (r=0.805,p=0.897),  time:29.568, tt:1389.682\n",
      "Ep:47, loss:0.00001, loss_test:0.01406, lr:5.71e-02, fs:0.84472 (r=0.782,p=0.919),  time:29.589, tt:1420.283\n",
      "Ep:48, loss:0.00001, loss_test:0.01418, lr:5.65e-02, fs:0.85000 (r=0.782,p=0.932),  time:29.642, tt:1452.450\n",
      "Ep:49, loss:0.00001, loss_test:0.01427, lr:5.59e-02, fs:0.85000 (r=0.782,p=0.932),  time:29.669, tt:1483.425\n",
      "Ep:50, loss:0.00001, loss_test:0.01440, lr:5.54e-02, fs:0.85000 (r=0.782,p=0.932),  time:29.680, tt:1513.676\n",
      "Ep:51, loss:0.00001, loss_test:0.01451, lr:5.48e-02, fs:0.84277 (r=0.770,p=0.931),  time:29.697, tt:1544.231\n",
      "Ep:52, loss:0.00001, loss_test:0.01467, lr:5.43e-02, fs:0.84277 (r=0.770,p=0.931),  time:29.728, tt:1575.607\n",
      "Ep:53, loss:0.00001, loss_test:0.01479, lr:5.37e-02, fs:0.84277 (r=0.770,p=0.931),  time:29.667, tt:1602.027\n",
      "Ep:54, loss:0.00001, loss_test:0.01514, lr:5.32e-02, fs:0.84277 (r=0.770,p=0.931),  time:29.672, tt:1631.984\n",
      "Ep:55, loss:0.00001, loss_test:0.01508, lr:5.27e-02, fs:0.82803 (r=0.747,p=0.929),  time:29.672, tt:1661.630\n",
      "Ep:56, loss:0.00001, loss_test:0.01529, lr:5.21e-02, fs:0.83333 (r=0.747,p=0.942),  time:29.668, tt:1691.096\n",
      "Ep:57, loss:0.00001, loss_test:0.01546, lr:5.16e-02, fs:0.83333 (r=0.747,p=0.942),  time:29.655, tt:1719.962\n",
      "Ep:58, loss:0.00001, loss_test:0.01546, lr:5.11e-02, fs:0.83333 (r=0.747,p=0.942),  time:29.662, tt:1750.082\n",
      "Ep:59, loss:0.00001, loss_test:0.01581, lr:5.06e-02, fs:0.83333 (r=0.747,p=0.942),  time:29.644, tt:1778.665\n",
      "Ep:60, loss:0.00001, loss_test:0.01582, lr:5.01e-02, fs:0.82581 (r=0.736,p=0.941),  time:29.680, tt:1810.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.01602, lr:4.96e-02, fs:0.82581 (r=0.736,p=0.941),  time:29.692, tt:1840.923\n",
      "Ep:62, loss:0.00001, loss_test:0.01623, lr:4.91e-02, fs:0.82581 (r=0.736,p=0.941),  time:29.696, tt:1870.819\n",
      "Ep:63, loss:0.00001, loss_test:0.01624, lr:4.86e-02, fs:0.82581 (r=0.736,p=0.941),  time:29.676, tt:1899.291\n",
      "Ep:64, loss:0.00001, loss_test:0.01652, lr:4.81e-02, fs:0.81818 (r=0.724,p=0.940),  time:29.680, tt:1929.198\n",
      "Ep:65, loss:0.00001, loss_test:0.01658, lr:4.76e-02, fs:0.81818 (r=0.724,p=0.940),  time:29.669, tt:1958.139\n",
      "Ep:66, loss:0.00000, loss_test:0.01656, lr:4.71e-02, fs:0.81818 (r=0.724,p=0.940),  time:29.658, tt:1987.107\n",
      "Ep:67, loss:0.00000, loss_test:0.01685, lr:4.67e-02, fs:0.81818 (r=0.724,p=0.940),  time:29.672, tt:2017.677\n",
      "Ep:68, loss:0.00000, loss_test:0.01694, lr:4.62e-02, fs:0.82353 (r=0.724,p=0.955),  time:29.686, tt:2048.300\n",
      "Ep:69, loss:0.00000, loss_test:0.01708, lr:4.57e-02, fs:0.82353 (r=0.724,p=0.955),  time:29.686, tt:2078.007\n",
      "Ep:70, loss:0.00000, loss_test:0.01729, lr:4.53e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.676, tt:2106.990\n",
      "Ep:71, loss:0.00000, loss_test:0.01744, lr:4.48e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.724, tt:2140.124\n",
      "Ep:72, loss:0.00000, loss_test:0.01745, lr:4.44e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.685, tt:2167.019\n",
      "Ep:73, loss:0.00000, loss_test:0.01756, lr:4.39e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.671, tt:2195.650\n",
      "Ep:74, loss:0.00000, loss_test:0.01770, lr:4.35e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.691, tt:2226.854\n",
      "Ep:75, loss:0.00000, loss_test:0.01789, lr:4.31e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.692, tt:2256.577\n",
      "Ep:76, loss:0.00000, loss_test:0.01797, lr:4.26e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.682, tt:2285.477\n",
      "Ep:77, loss:0.00000, loss_test:0.01810, lr:4.22e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.670, tt:2314.236\n",
      "Ep:78, loss:0.00000, loss_test:0.01813, lr:4.18e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.681, tt:2344.823\n",
      "Ep:79, loss:0.00000, loss_test:0.01831, lr:4.14e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.700, tt:2375.970\n",
      "Ep:80, loss:0.00000, loss_test:0.01841, lr:4.10e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.714, tt:2406.830\n",
      "Ep:81, loss:0.00000, loss_test:0.01853, lr:4.05e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.688, tt:2434.396\n",
      "Ep:82, loss:0.00000, loss_test:0.01862, lr:4.01e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.716, tt:2466.416\n",
      "Ep:83, loss:0.00000, loss_test:0.01877, lr:3.97e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.714, tt:2496.008\n",
      "Ep:84, loss:0.00000, loss_test:0.01883, lr:3.93e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.735, tt:2527.451\n",
      "Ep:85, loss:0.00000, loss_test:0.01897, lr:3.89e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.736, tt:2557.327\n",
      "Ep:86, loss:0.00000, loss_test:0.01907, lr:3.86e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.744, tt:2587.763\n",
      "Ep:87, loss:0.00000, loss_test:0.01905, lr:3.82e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.770, tt:2619.772\n",
      "Ep:88, loss:0.00000, loss_test:0.01931, lr:3.78e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.782, tt:2650.575\n",
      "Ep:89, loss:0.00000, loss_test:0.01923, lr:3.74e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.815, tt:2683.371\n",
      "Ep:90, loss:0.00000, loss_test:0.01940, lr:3.70e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.843, tt:2715.746\n",
      "Ep:91, loss:0.00000, loss_test:0.01948, lr:3.67e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.857, tt:2746.831\n",
      "Ep:92, loss:0.00000, loss_test:0.01954, lr:3.63e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.881, tt:2778.963\n",
      "Ep:93, loss:0.00000, loss_test:0.01971, lr:3.59e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.934, tt:2813.798\n",
      "Ep:94, loss:0.00000, loss_test:0.01970, lr:3.56e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.928, tt:2843.196\n",
      "Ep:95, loss:0.00000, loss_test:0.01974, lr:3.52e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.922, tt:2872.557\n",
      "Ep:96, loss:0.00000, loss_test:0.01995, lr:3.49e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.937, tt:2903.937\n",
      "Ep:97, loss:0.00000, loss_test:0.01998, lr:3.45e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.939, tt:2933.980\n",
      "Ep:98, loss:0.00000, loss_test:0.02002, lr:3.42e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.960, tt:2966.070\n",
      "Ep:99, loss:0.00000, loss_test:0.02025, lr:3.38e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.976, tt:2997.633\n",
      "Ep:100, loss:0.00000, loss_test:0.02013, lr:3.35e-02, fs:0.82895 (r=0.724,p=0.969),  time:29.981, tt:3028.079\n",
      "Ep:101, loss:0.00000, loss_test:0.02028, lr:3.32e-02, fs:0.83444 (r=0.724,p=0.984),  time:29.987, tt:3058.673\n",
      "Ep:102, loss:0.00000, loss_test:0.02040, lr:3.28e-02, fs:0.83444 (r=0.724,p=0.984),  time:29.997, tt:3089.689\n",
      "Ep:103, loss:0.00000, loss_test:0.02037, lr:3.25e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.010, tt:3121.056\n",
      "Ep:104, loss:0.00000, loss_test:0.02056, lr:3.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.032, tt:3153.342\n",
      "Ep:105, loss:0.00000, loss_test:0.02055, lr:3.19e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.050, tt:3185.300\n",
      "Ep:106, loss:0.00000, loss_test:0.02055, lr:3.15e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.075, tt:3218.043\n",
      "Ep:107, loss:0.00000, loss_test:0.02067, lr:3.12e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.099, tt:3250.699\n",
      "Ep:108, loss:0.00000, loss_test:0.02073, lr:3.09e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.120, tt:3283.050\n",
      "Ep:109, loss:0.00000, loss_test:0.02082, lr:3.06e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.107, tt:3311.806\n",
      "Ep:110, loss:0.00000, loss_test:0.02091, lr:3.03e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.118, tt:3343.142\n",
      "Ep:111, loss:0.00000, loss_test:0.02089, lr:3.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.122, tt:3373.718\n",
      "Ep:112, loss:0.00000, loss_test:0.02104, lr:2.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.132, tt:3404.970\n",
      "Ep:113, loss:0.00000, loss_test:0.02105, lr:2.94e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.130, tt:3434.854\n",
      "Ep:114, loss:0.00000, loss_test:0.02108, lr:2.91e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.124, tt:3464.247\n",
      "Ep:115, loss:0.00000, loss_test:0.02125, lr:2.88e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.128, tt:3494.906\n",
      "Ep:116, loss:0.00000, loss_test:0.02124, lr:2.85e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.135, tt:3525.808\n",
      "Ep:117, loss:0.00000, loss_test:0.02121, lr:2.82e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.151, tt:3557.780\n",
      "Ep:118, loss:0.00000, loss_test:0.02137, lr:2.80e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.157, tt:3588.711\n",
      "Ep:119, loss:0.00000, loss_test:0.02133, lr:2.77e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.159, tt:3619.077\n",
      "Ep:120, loss:0.00000, loss_test:0.02140, lr:2.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.217, tt:3656.225\n",
      "Ep:121, loss:0.00000, loss_test:0.02152, lr:2.71e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.226, tt:3687.520\n",
      "Ep:122, loss:0.00000, loss_test:0.02151, lr:2.69e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.230, tt:3718.335\n",
      "Ep:123, loss:0.00000, loss_test:0.02159, lr:2.66e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.254, tt:3751.496\n",
      "Ep:124, loss:0.00000, loss_test:0.02170, lr:2.63e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.265, tt:3783.159\n",
      "Ep:125, loss:0.00000, loss_test:0.02165, lr:2.61e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.282, tt:3815.486\n",
      "Ep:126, loss:0.00000, loss_test:0.02176, lr:2.58e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.263, tt:3843.427\n",
      "Ep:127, loss:0.00000, loss_test:0.02180, lr:2.55e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.255, tt:3872.683\n",
      "Ep:128, loss:0.00000, loss_test:0.02183, lr:2.53e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.252, tt:3902.506\n",
      "Ep:129, loss:0.00000, loss_test:0.02191, lr:2.50e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.252, tt:3932.732\n",
      "Ep:130, loss:0.00000, loss_test:0.02193, lr:2.48e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.258, tt:3963.803\n",
      "Ep:131, loss:0.00000, loss_test:0.02197, lr:2.45e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.253, tt:3993.393\n",
      "Ep:132, loss:0.00000, loss_test:0.02199, lr:2.43e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.268, tt:4025.614\n",
      "Ep:133, loss:0.00000, loss_test:0.02208, lr:2.40e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.286, tt:4058.293\n",
      "Ep:134, loss:0.00000, loss_test:0.02209, lr:2.38e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.288, tt:4088.936\n",
      "Ep:135, loss:0.00000, loss_test:0.02212, lr:2.36e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.294, tt:4120.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.02219, lr:2.33e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.302, tt:4151.327\n",
      "Ep:137, loss:0.00000, loss_test:0.02221, lr:2.31e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.312, tt:4183.015\n",
      "Ep:138, loss:0.00000, loss_test:0.02224, lr:2.29e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.300, tt:4211.701\n",
      "Ep:139, loss:0.00000, loss_test:0.02234, lr:2.26e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.302, tt:4242.254\n",
      "Ep:140, loss:0.00000, loss_test:0.02230, lr:2.24e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.300, tt:4272.293\n",
      "Ep:141, loss:0.00000, loss_test:0.02236, lr:2.22e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.313, tt:4304.444\n",
      "Ep:142, loss:0.00000, loss_test:0.02243, lr:2.20e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.336, tt:4338.023\n",
      "Ep:143, loss:0.00000, loss_test:0.02243, lr:2.17e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.338, tt:4368.642\n",
      "Ep:144, loss:0.00000, loss_test:0.02247, lr:2.15e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.333, tt:4398.286\n",
      "Ep:145, loss:0.00000, loss_test:0.02252, lr:2.13e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.348, tt:4430.804\n",
      "Ep:146, loss:0.00000, loss_test:0.02252, lr:2.11e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.347, tt:4460.952\n",
      "Ep:147, loss:0.00000, loss_test:0.02258, lr:2.09e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.357, tt:4492.771\n",
      "Ep:148, loss:0.00000, loss_test:0.02264, lr:2.07e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.367, tt:4524.713\n",
      "Ep:149, loss:0.00000, loss_test:0.02262, lr:2.05e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.380, tt:4556.947\n",
      "Ep:150, loss:0.00000, loss_test:0.02268, lr:2.03e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.395, tt:4589.635\n",
      "Ep:151, loss:0.00000, loss_test:0.02273, lr:2.01e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.409, tt:4622.199\n",
      "Ep:152, loss:0.00000, loss_test:0.02269, lr:1.99e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.417, tt:4653.850\n",
      "Ep:153, loss:0.00000, loss_test:0.02273, lr:1.97e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.416, tt:4683.999\n",
      "Ep:154, loss:0.00000, loss_test:0.02281, lr:1.95e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.424, tt:4715.764\n",
      "Ep:155, loss:0.00000, loss_test:0.02282, lr:1.93e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.440, tt:4748.642\n",
      "Ep:156, loss:0.00000, loss_test:0.02284, lr:1.91e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.431, tt:4777.707\n",
      "Ep:157, loss:0.00000, loss_test:0.02287, lr:1.89e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.442, tt:4809.816\n",
      "Ep:158, loss:0.00000, loss_test:0.02291, lr:1.87e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.453, tt:4842.087\n",
      "Ep:159, loss:0.00000, loss_test:0.02296, lr:1.85e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.459, tt:4873.477\n",
      "Ep:160, loss:0.00000, loss_test:0.02294, lr:1.83e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.460, tt:4904.105\n",
      "Ep:161, loss:0.00000, loss_test:0.02298, lr:1.81e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.453, tt:4933.374\n",
      "Ep:162, loss:0.00000, loss_test:0.02305, lr:1.80e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.437, tt:4961.229\n",
      "Ep:163, loss:0.00000, loss_test:0.02302, lr:1.78e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.431, tt:4990.674\n",
      "Ep:164, loss:0.00000, loss_test:0.02306, lr:1.76e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.431, tt:5021.173\n",
      "Ep:165, loss:0.00000, loss_test:0.02312, lr:1.74e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.437, tt:5052.543\n",
      "Ep:166, loss:0.00000, loss_test:0.02314, lr:1.73e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.430, tt:5081.782\n",
      "Ep:167, loss:0.00000, loss_test:0.02318, lr:1.71e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.446, tt:5114.849\n",
      "Ep:168, loss:0.00000, loss_test:0.02320, lr:1.69e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.430, tt:5142.745\n",
      "Ep:169, loss:0.00000, loss_test:0.02323, lr:1.67e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.438, tt:5174.516\n",
      "Ep:170, loss:0.00000, loss_test:0.02324, lr:1.66e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.450, tt:5206.923\n",
      "Ep:171, loss:0.00000, loss_test:0.02328, lr:1.64e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.464, tt:5239.781\n",
      "Ep:172, loss:0.00000, loss_test:0.02330, lr:1.62e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.471, tt:5271.427\n",
      "Ep:173, loss:0.00000, loss_test:0.02330, lr:1.61e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.480, tt:5303.483\n",
      "Ep:174, loss:0.00000, loss_test:0.02331, lr:1.59e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.489, tt:5335.625\n",
      "Ep:175, loss:0.00000, loss_test:0.02337, lr:1.58e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.513, tt:5370.319\n",
      "Ep:176, loss:0.00000, loss_test:0.02338, lr:1.56e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.530, tt:5403.725\n",
      "Ep:177, loss:0.00000, loss_test:0.02337, lr:1.54e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.540, tt:5436.033\n",
      "Ep:178, loss:0.00000, loss_test:0.02341, lr:1.53e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.543, tt:5467.249\n",
      "Ep:179, loss:0.00000, loss_test:0.02346, lr:1.51e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.548, tt:5498.654\n",
      "Ep:180, loss:0.00000, loss_test:0.02347, lr:1.50e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.550, tt:5529.484\n",
      "Ep:181, loss:0.00000, loss_test:0.02345, lr:1.48e-02, fs:0.83444 (r=0.724,p=0.984),  time:30.558, tt:5561.550\n",
      "Ep:182, loss:0.00000, loss_test:0.02346, lr:1.47e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.566, tt:5593.609\n",
      "Ep:183, loss:0.00000, loss_test:0.02353, lr:1.45e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.583, tt:5627.225\n",
      "Ep:184, loss:0.00000, loss_test:0.02352, lr:1.44e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.591, tt:5659.288\n",
      "Ep:185, loss:0.00000, loss_test:0.02351, lr:1.43e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.599, tt:5691.405\n",
      "Ep:186, loss:0.00000, loss_test:0.02355, lr:1.41e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.612, tt:5724.392\n",
      "Ep:187, loss:0.00000, loss_test:0.02358, lr:1.40e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.618, tt:5756.126\n",
      "Ep:188, loss:0.00000, loss_test:0.02359, lr:1.38e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.626, tt:5788.390\n",
      "Ep:189, loss:0.00000, loss_test:0.02358, lr:1.37e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.635, tt:5820.716\n",
      "Ep:190, loss:0.00000, loss_test:0.02362, lr:1.36e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.641, tt:5852.406\n",
      "Ep:191, loss:0.00000, loss_test:0.02365, lr:1.34e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.634, tt:5881.672\n",
      "Ep:192, loss:0.00000, loss_test:0.02366, lr:1.33e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.631, tt:5911.826\n",
      "Ep:193, loss:0.00000, loss_test:0.02369, lr:1.32e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.624, tt:5941.093\n",
      "Ep:194, loss:0.00000, loss_test:0.02369, lr:1.30e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.627, tt:5972.281\n",
      "Ep:195, loss:0.00000, loss_test:0.02372, lr:1.29e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.640, tt:6005.517\n",
      "Ep:196, loss:0.00000, loss_test:0.02374, lr:1.28e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.647, tt:6037.523\n",
      "Ep:197, loss:0.00000, loss_test:0.02376, lr:1.26e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.667, tt:6071.973\n",
      "Ep:198, loss:0.00000, loss_test:0.02379, lr:1.25e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.669, tt:6103.063\n",
      "Ep:199, loss:0.00000, loss_test:0.02381, lr:1.24e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.661, tt:6132.273\n",
      "Ep:200, loss:0.00000, loss_test:0.02382, lr:1.23e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.664, tt:6163.394\n",
      "Ep:201, loss:0.00000, loss_test:0.02383, lr:1.21e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.655, tt:6192.333\n",
      "Ep:202, loss:0.00000, loss_test:0.02385, lr:1.20e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.620, tt:6215.831\n",
      "Ep:203, loss:0.00000, loss_test:0.02386, lr:1.19e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.599, tt:6242.182\n",
      "Ep:204, loss:0.00000, loss_test:0.02387, lr:1.18e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.597, tt:6272.400\n",
      "Ep:205, loss:0.00000, loss_test:0.02388, lr:1.17e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.591, tt:6301.795\n",
      "Ep:206, loss:0.00000, loss_test:0.02391, lr:1.15e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.558, tt:6325.598\n",
      "Ep:207, loss:0.00000, loss_test:0.02392, lr:1.14e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.541, tt:6352.570\n",
      "Ep:208, loss:0.00000, loss_test:0.02393, lr:1.13e-02, fs:0.82667 (r=0.713,p=0.984),  time:30.506, tt:6375.777\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN3\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13723, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.312, tt:25.312\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13381, lr:1.00e-02, fs:0.64822 (r=0.943,p=0.494),  time:26.787, tt:53.574\n",
      "Ep:2, loss:0.00027, loss_test:0.12703, lr:1.00e-02, fs:0.65000 (r=0.897,p=0.510),  time:27.747, tt:83.240\n",
      "Ep:3, loss:0.00026, loss_test:0.11799, lr:1.00e-02, fs:0.67593 (r=0.839,p=0.566),  time:28.277, tt:113.109\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00024, loss_test:0.11403, lr:1.00e-02, fs:0.71875 (r=0.793,p=0.657),  time:29.066, tt:145.329\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00023, loss_test:0.11386, lr:1.00e-02, fs:0.69613 (r=0.724,p=0.670),  time:29.401, tt:176.407\n",
      "Ep:6, loss:0.00022, loss_test:0.11027, lr:1.00e-02, fs:0.69613 (r=0.724,p=0.670),  time:29.518, tt:206.628\n",
      "Ep:7, loss:0.00021, loss_test:0.10681, lr:1.00e-02, fs:0.70899 (r=0.770,p=0.657),  time:29.344, tt:234.748\n",
      "Ep:8, loss:0.00021, loss_test:0.10414, lr:1.00e-02, fs:0.67033 (r=0.701,p=0.642),  time:29.422, tt:264.795\n",
      "Ep:9, loss:0.00020, loss_test:0.10313, lr:1.00e-02, fs:0.67429 (r=0.678,p=0.670),  time:29.471, tt:294.706\n",
      "Ep:10, loss:0.00019, loss_test:0.09912, lr:1.00e-02, fs:0.67836 (r=0.667,p=0.690),  time:29.461, tt:324.070\n",
      "Ep:11, loss:0.00018, loss_test:0.09527, lr:1.00e-02, fs:0.69412 (r=0.678,p=0.711),  time:29.389, tt:352.673\n",
      "Ep:12, loss:0.00017, loss_test:0.09364, lr:1.00e-02, fs:0.73939 (r=0.701,p=0.782),  time:29.523, tt:383.804\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.09050, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:29.658, tt:415.208\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00015, loss_test:0.08776, lr:1.00e-02, fs:0.81143 (r=0.816,p=0.807),  time:29.555, tt:443.319\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00014, loss_test:0.08568, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:29.594, tt:473.511\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00014, loss_test:0.08373, lr:1.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:29.569, tt:502.671\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00013, loss_test:0.08116, lr:1.00e-02, fs:0.80233 (r=0.793,p=0.812),  time:29.690, tt:534.423\n",
      "Ep:18, loss:0.00012, loss_test:0.07957, lr:1.00e-02, fs:0.84706 (r=0.828,p=0.867),  time:29.637, tt:563.109\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00012, loss_test:0.07934, lr:1.00e-02, fs:0.83133 (r=0.793,p=0.873),  time:29.587, tt:591.736\n",
      "Ep:20, loss:0.00011, loss_test:0.07706, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:29.689, tt:623.474\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00010, loss_test:0.07568, lr:1.00e-02, fs:0.82209 (r=0.770,p=0.882),  time:29.769, tt:654.908\n",
      "Ep:22, loss:0.00010, loss_test:0.07267, lr:1.00e-02, fs:0.84337 (r=0.805,p=0.886),  time:29.728, tt:683.747\n",
      "Ep:23, loss:0.00009, loss_test:0.07474, lr:1.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:29.640, tt:711.372\n",
      "Ep:24, loss:0.00008, loss_test:0.07137, lr:1.00e-02, fs:0.79747 (r=0.724,p=0.887),  time:29.713, tt:742.815\n",
      "Ep:25, loss:0.00008, loss_test:0.07362, lr:1.00e-02, fs:0.77333 (r=0.667,p=0.921),  time:29.724, tt:772.812\n",
      "Ep:26, loss:0.00007, loss_test:0.07129, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:29.733, tt:802.780\n",
      "Ep:27, loss:0.00007, loss_test:0.07336, lr:1.00e-02, fs:0.77632 (r=0.678,p=0.908),  time:29.714, tt:831.999\n",
      "Ep:28, loss:0.00006, loss_test:0.07044, lr:1.00e-02, fs:0.80769 (r=0.724,p=0.913),  time:29.691, tt:861.047\n",
      "Ep:29, loss:0.00006, loss_test:0.07727, lr:1.00e-02, fs:0.82581 (r=0.736,p=0.941),  time:29.682, tt:890.454\n",
      "Ep:30, loss:0.00005, loss_test:0.06634, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:29.648, tt:919.089\n",
      "Ep:31, loss:0.00006, loss_test:0.06761, lr:1.00e-02, fs:0.78947 (r=0.690,p=0.923),  time:29.674, tt:949.561\n",
      "Ep:32, loss:0.00005, loss_test:0.07376, lr:9.90e-03, fs:0.82278 (r=0.747,p=0.915),  time:29.681, tt:979.489\n",
      "Ep:33, loss:0.00005, loss_test:0.06833, lr:9.80e-03, fs:0.81818 (r=0.724,p=0.940),  time:29.702, tt:1009.880\n",
      "Ep:34, loss:0.00004, loss_test:0.07226, lr:9.70e-03, fs:0.83333 (r=0.747,p=0.942),  time:29.712, tt:1039.924\n",
      "Ep:35, loss:0.00004, loss_test:0.07269, lr:9.61e-03, fs:0.81818 (r=0.724,p=0.940),  time:29.697, tt:1069.092\n",
      "Ep:36, loss:0.00004, loss_test:0.06921, lr:9.51e-03, fs:0.81579 (r=0.713,p=0.954),  time:29.689, tt:1098.484\n",
      "Ep:37, loss:0.00003, loss_test:0.07092, lr:9.41e-03, fs:0.79470 (r=0.690,p=0.938),  time:29.825, tt:1133.365\n",
      "Ep:38, loss:0.00003, loss_test:0.07891, lr:9.32e-03, fs:0.84615 (r=0.759,p=0.957),  time:29.879, tt:1165.288\n",
      "Ep:39, loss:0.00003, loss_test:0.06617, lr:9.23e-03, fs:0.80000 (r=0.690,p=0.952),  time:29.916, tt:1196.623\n",
      "Ep:40, loss:0.00003, loss_test:0.08018, lr:9.14e-03, fs:0.85350 (r=0.770,p=0.957),  time:29.943, tt:1227.660\n",
      "Ep:41, loss:0.00003, loss_test:0.06858, lr:9.04e-03, fs:0.81290 (r=0.724,p=0.926),  time:30.000, tt:1259.995\n",
      "Ep:42, loss:0.00003, loss_test:0.07450, lr:8.95e-03, fs:0.78378 (r=0.667,p=0.951),  time:30.028, tt:1291.191\n",
      "Ep:43, loss:0.00002, loss_test:0.07452, lr:8.86e-03, fs:0.82581 (r=0.736,p=0.941),  time:30.023, tt:1320.996\n",
      "Ep:44, loss:0.00002, loss_test:0.06993, lr:8.78e-03, fs:0.79195 (r=0.678,p=0.952),  time:30.033, tt:1351.484\n",
      "Ep:45, loss:0.00002, loss_test:0.08245, lr:8.69e-03, fs:0.77241 (r=0.644,p=0.966),  time:30.040, tt:1381.831\n",
      "Ep:46, loss:0.00002, loss_test:0.07101, lr:8.60e-03, fs:0.80263 (r=0.701,p=0.938),  time:30.080, tt:1413.782\n",
      "Ep:47, loss:0.00002, loss_test:0.07366, lr:8.51e-03, fs:0.78378 (r=0.667,p=0.951),  time:30.129, tt:1446.172\n",
      "Ep:48, loss:0.00002, loss_test:0.08039, lr:8.43e-03, fs:0.78082 (r=0.655,p=0.966),  time:30.152, tt:1477.459\n",
      "Ep:49, loss:0.00001, loss_test:0.07267, lr:8.35e-03, fs:0.77852 (r=0.667,p=0.935),  time:30.173, tt:1508.650\n",
      "Ep:50, loss:0.00001, loss_test:0.07747, lr:8.26e-03, fs:0.78378 (r=0.667,p=0.951),  time:30.204, tt:1540.425\n",
      "Ep:51, loss:0.00001, loss_test:0.07713, lr:8.18e-03, fs:0.81333 (r=0.701,p=0.968),  time:30.176, tt:1569.168\n",
      "Ep:52, loss:0.00001, loss_test:0.07418, lr:8.10e-03, fs:0.79195 (r=0.678,p=0.952),  time:30.199, tt:1600.542\n",
      "Ep:53, loss:0.00001, loss_test:0.07484, lr:8.02e-03, fs:0.82895 (r=0.724,p=0.969),  time:30.220, tt:1631.882\n",
      "Ep:54, loss:0.00001, loss_test:0.07622, lr:7.94e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.226, tt:1662.425\n",
      "Ep:55, loss:0.00001, loss_test:0.07636, lr:7.86e-03, fs:0.78912 (r=0.667,p=0.967),  time:30.172, tt:1689.625\n",
      "Ep:56, loss:0.00001, loss_test:0.07741, lr:7.78e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.208, tt:1721.883\n",
      "Ep:57, loss:0.00001, loss_test:0.07652, lr:7.70e-03, fs:0.81333 (r=0.701,p=0.968),  time:30.208, tt:1752.057\n",
      "Ep:58, loss:0.00001, loss_test:0.07785, lr:7.62e-03, fs:0.81333 (r=0.701,p=0.968),  time:30.247, tt:1784.599\n",
      "Ep:59, loss:0.00001, loss_test:0.07577, lr:7.55e-03, fs:0.81333 (r=0.701,p=0.968),  time:30.282, tt:1816.933\n",
      "Ep:60, loss:0.00001, loss_test:0.07453, lr:7.47e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.357, tt:1851.775\n",
      "Ep:61, loss:0.00001, loss_test:0.07611, lr:7.40e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.470, tt:1889.117\n",
      "Ep:62, loss:0.00001, loss_test:0.07603, lr:7.32e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.558, tt:1925.156\n",
      "Ep:63, loss:0.00000, loss_test:0.07571, lr:7.25e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.652, tt:1961.724\n",
      "Ep:64, loss:0.00000, loss_test:0.07659, lr:7.18e-03, fs:0.82119 (r=0.713,p=0.969),  time:30.719, tt:1996.746\n",
      "Ep:65, loss:0.00000, loss_test:0.07504, lr:7.11e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.828, tt:2034.627\n",
      "Ep:66, loss:0.00000, loss_test:0.07533, lr:7.03e-03, fs:0.79730 (r=0.678,p=0.967),  time:30.910, tt:2070.974\n",
      "Ep:67, loss:0.00000, loss_test:0.07528, lr:6.96e-03, fs:0.80537 (r=0.690,p=0.968),  time:30.957, tt:2105.057\n",
      "Ep:68, loss:0.00000, loss_test:0.07530, lr:6.89e-03, fs:0.79730 (r=0.678,p=0.967),  time:31.040, tt:2141.764\n",
      "Ep:69, loss:0.00000, loss_test:0.07470, lr:6.83e-03, fs:0.78912 (r=0.667,p=0.967),  time:31.104, tt:2177.275\n",
      "Ep:70, loss:0.00000, loss_test:0.07531, lr:6.76e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.166, tt:2212.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:71, loss:0.00000, loss_test:0.07549, lr:6.69e-03, fs:0.78912 (r=0.667,p=0.967),  time:31.248, tt:2249.854\n",
      "Ep:72, loss:0.00000, loss_test:0.07460, lr:6.62e-03, fs:0.81333 (r=0.701,p=0.968),  time:31.289, tt:2284.113\n",
      "Ep:73, loss:0.00000, loss_test:0.07572, lr:6.56e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.328, tt:2318.255\n",
      "Ep:74, loss:0.00000, loss_test:0.07557, lr:6.49e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.393, tt:2354.483\n",
      "Ep:75, loss:0.00000, loss_test:0.07512, lr:6.43e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.443, tt:2389.689\n",
      "Ep:76, loss:0.00000, loss_test:0.07477, lr:6.36e-03, fs:0.81333 (r=0.701,p=0.968),  time:31.466, tt:2422.885\n",
      "Ep:77, loss:0.00000, loss_test:0.07461, lr:6.30e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.534, tt:2459.682\n",
      "Ep:78, loss:0.00000, loss_test:0.07650, lr:6.24e-03, fs:0.79730 (r=0.678,p=0.967),  time:31.584, tt:2495.138\n",
      "Ep:79, loss:0.00000, loss_test:0.07588, lr:6.17e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.627, tt:2530.168\n",
      "Ep:80, loss:0.00000, loss_test:0.07415, lr:6.11e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.662, tt:2564.626\n",
      "Ep:81, loss:0.00000, loss_test:0.07541, lr:6.05e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.727, tt:2601.580\n",
      "Ep:82, loss:0.00000, loss_test:0.07727, lr:5.99e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.759, tt:2636.022\n",
      "Ep:83, loss:0.00000, loss_test:0.07623, lr:5.93e-03, fs:0.80537 (r=0.690,p=0.968),  time:31.820, tt:2672.842\n",
      "Ep:84, loss:0.00000, loss_test:0.07522, lr:5.87e-03, fs:0.82119 (r=0.713,p=0.969),  time:31.875, tt:2709.404\n",
      "Ep:85, loss:0.00000, loss_test:0.07444, lr:5.81e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.912, tt:2744.415\n",
      "Ep:86, loss:0.00000, loss_test:0.07456, lr:5.75e-03, fs:0.82895 (r=0.724,p=0.969),  time:31.966, tt:2781.074\n",
      "Ep:87, loss:0.00000, loss_test:0.07583, lr:5.70e-03, fs:0.82119 (r=0.713,p=0.969),  time:32.025, tt:2818.220\n",
      "Ep:88, loss:0.00000, loss_test:0.07519, lr:5.64e-03, fs:0.81333 (r=0.701,p=0.968),  time:32.082, tt:2855.272\n",
      "Ep:89, loss:0.00000, loss_test:0.07494, lr:5.58e-03, fs:0.80537 (r=0.690,p=0.968),  time:32.106, tt:2889.572\n",
      "Ep:90, loss:0.00000, loss_test:0.07530, lr:5.53e-03, fs:0.79730 (r=0.678,p=0.967),  time:32.154, tt:2925.982\n",
      "Ep:91, loss:0.00000, loss_test:0.07507, lr:5.47e-03, fs:0.81333 (r=0.701,p=0.968),  time:32.194, tt:2961.817\n",
      "Ep:92, loss:0.00000, loss_test:0.07516, lr:5.42e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.214, tt:2995.888\n",
      "Ep:93, loss:0.00000, loss_test:0.07510, lr:5.36e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.239, tt:3030.424\n",
      "Ep:94, loss:0.00000, loss_test:0.07431, lr:5.31e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.276, tt:3066.211\n",
      "Ep:95, loss:0.00000, loss_test:0.07465, lr:5.26e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.288, tt:3099.690\n",
      "Ep:96, loss:0.00000, loss_test:0.07519, lr:5.20e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.332, tt:3136.176\n",
      "Ep:97, loss:0.00000, loss_test:0.07493, lr:5.15e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.354, tt:3170.723\n",
      "Ep:98, loss:0.00000, loss_test:0.07422, lr:5.10e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.377, tt:3205.326\n",
      "Ep:99, loss:0.00000, loss_test:0.07525, lr:5.05e-03, fs:0.81333 (r=0.701,p=0.968),  time:32.393, tt:3239.289\n",
      "Ep:100, loss:0.00000, loss_test:0.07510, lr:5.00e-03, fs:0.79730 (r=0.678,p=0.967),  time:32.388, tt:3271.183\n",
      "Ep:101, loss:0.00000, loss_test:0.07471, lr:4.95e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.407, tt:3305.485\n",
      "Ep:102, loss:0.00000, loss_test:0.07474, lr:4.90e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.445, tt:3341.872\n",
      "Ep:103, loss:0.00000, loss_test:0.07465, lr:4.85e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.474, tt:3377.329\n",
      "Ep:104, loss:0.00000, loss_test:0.07434, lr:4.80e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.510, tt:3413.556\n",
      "Ep:105, loss:0.00000, loss_test:0.07407, lr:4.75e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.543, tt:3449.544\n",
      "Ep:106, loss:0.00000, loss_test:0.07456, lr:4.71e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.566, tt:3484.576\n",
      "Ep:107, loss:0.00000, loss_test:0.07491, lr:4.66e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.602, tt:3521.014\n",
      "Ep:108, loss:0.00000, loss_test:0.07483, lr:4.61e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.630, tt:3556.650\n",
      "Ep:109, loss:0.00000, loss_test:0.07472, lr:4.57e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.650, tt:3591.519\n",
      "Ep:110, loss:0.00000, loss_test:0.07476, lr:4.52e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.670, tt:3626.331\n",
      "Ep:111, loss:0.00000, loss_test:0.07478, lr:4.48e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.691, tt:3661.442\n",
      "Ep:112, loss:0.00000, loss_test:0.07454, lr:4.43e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.715, tt:3696.746\n",
      "Ep:113, loss:0.00000, loss_test:0.07469, lr:4.39e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.738, tt:3732.142\n",
      "Ep:114, loss:0.00000, loss_test:0.07487, lr:4.34e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.776, tt:3769.213\n",
      "Ep:115, loss:0.00000, loss_test:0.07456, lr:4.30e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.774, tt:3801.756\n",
      "Ep:116, loss:0.00000, loss_test:0.07442, lr:4.26e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.773, tt:3834.477\n",
      "Ep:117, loss:0.00000, loss_test:0.07445, lr:4.21e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.787, tt:3868.871\n",
      "Ep:118, loss:0.00000, loss_test:0.07465, lr:4.17e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.799, tt:3903.083\n",
      "Ep:119, loss:0.00000, loss_test:0.07480, lr:4.13e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.810, tt:3937.191\n",
      "Ep:120, loss:0.00000, loss_test:0.07455, lr:4.09e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.807, tt:3969.674\n",
      "Ep:121, loss:0.00000, loss_test:0.07414, lr:4.05e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.823, tt:4004.385\n",
      "Ep:122, loss:0.00000, loss_test:0.07439, lr:4.01e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.850, tt:4040.509\n",
      "Ep:123, loss:0.00000, loss_test:0.07458, lr:3.97e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.859, tt:4074.458\n",
      "Ep:124, loss:0.00000, loss_test:0.07435, lr:3.93e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.884, tt:4110.560\n",
      "Ep:125, loss:0.00000, loss_test:0.07397, lr:3.89e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.895, tt:4144.754\n",
      "Ep:126, loss:0.00000, loss_test:0.07401, lr:3.85e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.896, tt:4177.811\n",
      "Ep:127, loss:0.00000, loss_test:0.07436, lr:3.81e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.922, tt:4213.975\n",
      "Ep:128, loss:0.00000, loss_test:0.07438, lr:3.77e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.935, tt:4248.650\n",
      "Ep:129, loss:0.00000, loss_test:0.07437, lr:3.73e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.971, tt:4286.185\n",
      "Ep:130, loss:0.00000, loss_test:0.07434, lr:3.70e-03, fs:0.78912 (r=0.667,p=0.967),  time:32.993, tt:4322.037\n",
      "Ep:131, loss:0.00000, loss_test:0.07421, lr:3.66e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.022, tt:4358.921\n",
      "Ep:132, loss:0.00000, loss_test:0.07439, lr:3.62e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.040, tt:4394.291\n",
      "Ep:133, loss:0.00000, loss_test:0.07473, lr:3.59e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.051, tt:4428.833\n",
      "Ep:134, loss:0.00000, loss_test:0.07457, lr:3.55e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.082, tt:4466.080\n",
      "Ep:135, loss:0.00000, loss_test:0.07452, lr:3.52e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.109, tt:4502.852\n",
      "Ep:136, loss:0.00000, loss_test:0.07443, lr:3.48e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.127, tt:4538.418\n",
      "Ep:137, loss:0.00000, loss_test:0.07433, lr:3.45e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.138, tt:4573.007\n",
      "Ep:138, loss:0.00000, loss_test:0.07422, lr:3.41e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.154, tt:4608.346\n",
      "Ep:139, loss:0.00000, loss_test:0.07433, lr:3.38e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.164, tt:4642.982\n",
      "Ep:140, loss:0.00000, loss_test:0.07430, lr:3.34e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.168, tt:4676.686\n",
      "Ep:141, loss:0.00000, loss_test:0.07420, lr:3.31e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.186, tt:4712.353\n",
      "Ep:142, loss:0.00000, loss_test:0.07408, lr:3.28e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.201, tt:4747.791\n",
      "Ep:143, loss:0.00000, loss_test:0.07448, lr:3.24e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.194, tt:4779.906\n",
      "Ep:144, loss:0.00000, loss_test:0.07466, lr:3.21e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.232, tt:4818.613\n",
      "Ep:145, loss:0.00000, loss_test:0.07443, lr:3.18e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.239, tt:4852.835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:146, loss:0.00000, loss_test:0.07409, lr:3.15e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.248, tt:4887.485\n",
      "Ep:147, loss:0.00000, loss_test:0.07404, lr:3.12e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.271, tt:4924.094\n",
      "Ep:148, loss:0.00000, loss_test:0.07395, lr:3.09e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.289, tt:4960.009\n",
      "Ep:149, loss:0.00000, loss_test:0.07412, lr:3.05e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.306, tt:4995.944\n",
      "Ep:150, loss:0.00000, loss_test:0.07419, lr:3.02e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.325, tt:5032.003\n",
      "Ep:151, loss:0.00000, loss_test:0.07417, lr:2.99e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.337, tt:5067.287\n",
      "Ep:152, loss:0.00000, loss_test:0.07407, lr:2.96e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.351, tt:5102.705\n",
      "Ep:153, loss:0.00000, loss_test:0.07406, lr:2.93e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.361, tt:5137.601\n",
      "Ep:154, loss:0.00000, loss_test:0.07404, lr:2.90e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.373, tt:5172.836\n",
      "Ep:155, loss:0.00000, loss_test:0.07412, lr:2.88e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.381, tt:5207.378\n",
      "Ep:156, loss:0.00000, loss_test:0.07423, lr:2.85e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.409, tt:5245.205\n",
      "Ep:157, loss:0.00000, loss_test:0.07408, lr:2.82e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.437, tt:5283.040\n",
      "Ep:158, loss:0.00000, loss_test:0.07401, lr:2.79e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.466, tt:5321.086\n",
      "Ep:159, loss:0.00000, loss_test:0.07441, lr:2.76e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.479, tt:5356.585\n",
      "Ep:160, loss:0.00000, loss_test:0.07451, lr:2.73e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.497, tt:5392.950\n",
      "Ep:161, loss:0.00000, loss_test:0.07436, lr:2.71e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.509, tt:5428.501\n",
      "Ep:162, loss:0.00000, loss_test:0.07433, lr:2.68e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.512, tt:5462.409\n",
      "Ep:163, loss:0.00000, loss_test:0.07441, lr:2.65e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.522, tt:5497.577\n",
      "Ep:164, loss:0.00000, loss_test:0.07433, lr:2.63e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.548, tt:5535.460\n",
      "Ep:165, loss:0.00000, loss_test:0.07414, lr:2.60e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.552, tt:5569.586\n",
      "Ep:166, loss:0.00000, loss_test:0.07402, lr:2.57e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.569, tt:5605.966\n",
      "Ep:167, loss:0.00000, loss_test:0.07406, lr:2.55e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.584, tt:5642.195\n",
      "Ep:168, loss:0.00000, loss_test:0.07408, lr:2.52e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.600, tt:5678.430\n",
      "Ep:169, loss:0.00000, loss_test:0.07401, lr:2.50e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.616, tt:5714.697\n",
      "Ep:170, loss:0.00000, loss_test:0.07387, lr:2.47e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.631, tt:5750.836\n",
      "Ep:171, loss:0.00000, loss_test:0.07380, lr:2.45e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.665, tt:5790.456\n",
      "Ep:172, loss:0.00000, loss_test:0.07382, lr:2.42e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.676, tt:5825.924\n",
      "Ep:173, loss:0.00000, loss_test:0.07388, lr:2.40e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.689, tt:5861.810\n",
      "Ep:174, loss:0.00000, loss_test:0.07390, lr:2.38e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.697, tt:5897.000\n",
      "Ep:175, loss:0.00000, loss_test:0.07391, lr:2.35e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.709, tt:5932.722\n",
      "Ep:176, loss:0.00000, loss_test:0.07442, lr:2.33e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.724, tt:5969.081\n",
      "Ep:177, loss:0.00000, loss_test:0.07452, lr:2.31e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.747, tt:6006.912\n",
      "Ep:178, loss:0.00000, loss_test:0.07431, lr:2.28e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.751, tt:6041.516\n",
      "Ep:179, loss:0.00000, loss_test:0.07403, lr:2.26e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.755, tt:6075.830\n",
      "Ep:180, loss:0.00000, loss_test:0.07405, lr:2.24e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.758, tt:6110.240\n",
      "Ep:181, loss:0.00000, loss_test:0.07414, lr:2.21e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.765, tt:6145.147\n",
      "Ep:182, loss:0.00000, loss_test:0.07423, lr:2.19e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.763, tt:6178.622\n",
      "Ep:183, loss:0.00000, loss_test:0.07419, lr:2.17e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.764, tt:6212.613\n",
      "Ep:184, loss:0.00000, loss_test:0.07418, lr:2.15e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.766, tt:6246.711\n",
      "Ep:185, loss:0.00000, loss_test:0.07428, lr:2.13e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.777, tt:6282.604\n",
      "Ep:186, loss:0.00000, loss_test:0.07437, lr:2.11e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.785, tt:6317.737\n",
      "Ep:187, loss:0.00000, loss_test:0.07422, lr:2.08e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.785, tt:6351.605\n",
      "Ep:188, loss:0.00000, loss_test:0.07394, lr:2.06e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.788, tt:6385.939\n",
      "Ep:189, loss:0.00000, loss_test:0.07381, lr:2.04e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.794, tt:6420.886\n",
      "Ep:190, loss:0.00000, loss_test:0.07390, lr:2.02e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.804, tt:6456.485\n",
      "Ep:191, loss:0.00000, loss_test:0.07396, lr:2.00e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.808, tt:6491.157\n",
      "Ep:192, loss:0.00000, loss_test:0.07391, lr:1.98e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.818, tt:6526.803\n",
      "Ep:193, loss:0.00000, loss_test:0.07382, lr:1.96e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.829, tt:6562.830\n",
      "Ep:194, loss:0.00000, loss_test:0.07375, lr:1.94e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.847, tt:6600.145\n",
      "Ep:195, loss:0.00000, loss_test:0.07384, lr:1.92e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.862, tt:6636.987\n",
      "Ep:196, loss:0.00000, loss_test:0.07396, lr:1.90e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.858, tt:6670.122\n",
      "Ep:197, loss:0.00000, loss_test:0.07393, lr:1.89e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.856, tt:6703.518\n",
      "Ep:198, loss:0.00000, loss_test:0.07381, lr:1.87e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.851, tt:6736.411\n",
      "Ep:199, loss:0.00000, loss_test:0.07373, lr:1.85e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.858, tt:6771.626\n",
      "Ep:200, loss:0.00000, loss_test:0.07385, lr:1.83e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.860, tt:6805.909\n",
      "Ep:201, loss:0.00000, loss_test:0.07396, lr:1.81e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.872, tt:6842.113\n",
      "Ep:202, loss:0.00000, loss_test:0.07398, lr:1.79e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.875, tt:6876.630\n",
      "Ep:203, loss:0.00000, loss_test:0.07393, lr:1.78e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.874, tt:6910.206\n",
      "Ep:204, loss:0.00000, loss_test:0.07386, lr:1.76e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.825, tt:6934.122\n",
      "Ep:205, loss:0.00000, loss_test:0.07380, lr:1.74e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.787, tt:6960.090\n",
      "Ep:206, loss:0.00000, loss_test:0.07381, lr:1.72e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.748, tt:6985.750\n",
      "Ep:207, loss:0.00000, loss_test:0.07391, lr:1.71e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.674, tt:7004.124\n",
      "Ep:208, loss:0.00000, loss_test:0.07403, lr:1.69e-03, fs:0.78912 (r=0.667,p=0.967),  time:33.581, tt:7018.469\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN3\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,209,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02146, lr:6.00e-02, fs:0.65049 (r=0.770,p=0.563),  time:28.219, tt:28.219\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02065, lr:6.00e-02, fs:0.64542 (r=0.931,p=0.494),  time:32.400, tt:64.801\n",
      "Ep:2, loss:0.00004, loss_test:0.02125, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.528, tt:100.584\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02054, lr:6.00e-02, fs:0.66409 (r=0.989,p=0.500),  time:34.163, tt:136.652\n",
      "Ep:4, loss:0.00004, loss_test:0.01955, lr:6.00e-02, fs:0.66387 (r=0.908,p=0.523),  time:34.598, tt:172.991\n",
      "Ep:5, loss:0.00004, loss_test:0.01921, lr:6.00e-02, fs:0.66055 (r=0.828,p=0.550),  time:34.902, tt:209.412\n",
      "Ep:6, loss:0.00004, loss_test:0.01970, lr:6.00e-02, fs:0.67000 (r=0.770,p=0.593),  time:34.659, tt:242.611\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.01995, lr:6.00e-02, fs:0.66667 (r=0.724,p=0.618),  time:34.885, tt:279.079\n",
      "Ep:8, loss:0.00003, loss_test:0.01879, lr:6.00e-02, fs:0.67016 (r=0.736,p=0.615),  time:35.150, tt:316.346\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00003, loss_test:0.01758, lr:6.00e-02, fs:0.71090 (r=0.862,p=0.605),  time:35.211, tt:352.111\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00003, loss_test:0.01702, lr:6.00e-02, fs:0.70320 (r=0.885,p=0.583),  time:35.355, tt:388.900\n",
      "Ep:11, loss:0.00003, loss_test:0.01661, lr:6.00e-02, fs:0.70642 (r=0.885,p=0.588),  time:35.262, tt:423.148\n",
      "Ep:12, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.73059 (r=0.920,p=0.606),  time:35.259, tt:458.364\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01599, lr:6.00e-02, fs:0.74510 (r=0.874,p=0.650),  time:35.385, tt:495.395\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01574, lr:6.00e-02, fs:0.75393 (r=0.828,p=0.692),  time:35.347, tt:530.201\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.79581 (r=0.874,p=0.731),  time:35.458, tt:567.326\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01488, lr:6.00e-02, fs:0.81250 (r=0.897,p=0.743),  time:35.542, tt:604.214\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00002, loss_test:0.01448, lr:6.00e-02, fs:0.81443 (r=0.908,p=0.738),  time:35.571, tt:640.270\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.82474 (r=0.920,p=0.748),  time:35.627, tt:676.922\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00002, loss_test:0.01396, lr:6.00e-02, fs:0.83770 (r=0.920,p=0.769),  time:35.893, tt:717.852\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00002, loss_test:0.01383, lr:6.00e-02, fs:0.84656 (r=0.920,p=0.784),  time:35.854, tt:752.944\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00002, loss_test:0.01374, lr:6.00e-02, fs:0.85714 (r=0.897,p=0.821),  time:35.820, tt:788.033\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01351, lr:6.00e-02, fs:0.86188 (r=0.897,p=0.830),  time:35.902, tt:825.753\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00002, loss_test:0.01329, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:36.002, tt:864.038\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00002, loss_test:0.01313, lr:6.00e-02, fs:0.86667 (r=0.897,p=0.839),  time:36.019, tt:900.478\n",
      "Ep:25, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.85393 (r=0.874,p=0.835),  time:35.987, tt:935.669\n",
      "Ep:26, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.85876 (r=0.874,p=0.844),  time:35.981, tt:971.496\n",
      "Ep:27, loss:0.00002, loss_test:0.01309, lr:6.00e-02, fs:0.85057 (r=0.851,p=0.851),  time:35.981, tt:1007.480\n",
      "Ep:28, loss:0.00002, loss_test:0.01303, lr:6.00e-02, fs:0.83721 (r=0.828,p=0.847),  time:35.999, tt:1043.981\n",
      "Ep:29, loss:0.00002, loss_test:0.01295, lr:6.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:35.939, tt:1078.166\n",
      "Ep:30, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:35.937, tt:1114.036\n",
      "Ep:31, loss:0.00001, loss_test:0.01291, lr:6.00e-02, fs:0.82353 (r=0.805,p=0.843),  time:35.917, tt:1149.330\n",
      "Ep:32, loss:0.00001, loss_test:0.01289, lr:6.00e-02, fs:0.82840 (r=0.805,p=0.854),  time:35.912, tt:1185.112\n",
      "Ep:33, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.81437 (r=0.782,p=0.850),  time:35.924, tt:1221.428\n",
      "Ep:34, loss:0.00001, loss_test:0.01286, lr:6.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:35.939, tt:1257.864\n",
      "Ep:35, loss:0.00001, loss_test:0.01288, lr:5.94e-02, fs:0.80488 (r=0.759,p=0.857),  time:35.947, tt:1294.090\n",
      "Ep:36, loss:0.00001, loss_test:0.01294, lr:5.88e-02, fs:0.80982 (r=0.759,p=0.868),  time:35.988, tt:1331.545\n",
      "Ep:37, loss:0.00001, loss_test:0.01301, lr:5.82e-02, fs:0.80982 (r=0.759,p=0.868),  time:36.004, tt:1368.166\n",
      "Ep:38, loss:0.00001, loss_test:0.01309, lr:5.76e-02, fs:0.80982 (r=0.759,p=0.868),  time:36.035, tt:1405.352\n",
      "Ep:39, loss:0.00001, loss_test:0.01313, lr:5.71e-02, fs:0.80982 (r=0.759,p=0.868),  time:36.018, tt:1440.730\n",
      "Ep:40, loss:0.00001, loss_test:0.01316, lr:5.65e-02, fs:0.80982 (r=0.759,p=0.868),  time:36.040, tt:1477.636\n",
      "Ep:41, loss:0.00001, loss_test:0.01324, lr:5.59e-02, fs:0.81988 (r=0.759,p=0.892),  time:36.061, tt:1514.551\n",
      "Ep:42, loss:0.00001, loss_test:0.01330, lr:5.54e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.099, tt:1552.246\n",
      "Ep:43, loss:0.00001, loss_test:0.01336, lr:5.48e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.127, tt:1589.609\n",
      "Ep:44, loss:0.00001, loss_test:0.01344, lr:5.43e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.153, tt:1626.899\n",
      "Ep:45, loss:0.00001, loss_test:0.01349, lr:5.37e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.138, tt:1662.342\n",
      "Ep:46, loss:0.00001, loss_test:0.01356, lr:5.32e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.138, tt:1698.476\n",
      "Ep:47, loss:0.00001, loss_test:0.01370, lr:5.27e-02, fs:0.81761 (r=0.747,p=0.903),  time:36.075, tt:1731.607\n",
      "Ep:48, loss:0.00001, loss_test:0.01380, lr:5.21e-02, fs:0.82278 (r=0.747,p=0.915),  time:36.072, tt:1767.531\n",
      "Ep:49, loss:0.00001, loss_test:0.01386, lr:5.16e-02, fs:0.82278 (r=0.747,p=0.915),  time:36.104, tt:1805.185\n",
      "Ep:50, loss:0.00001, loss_test:0.01396, lr:5.11e-02, fs:0.82803 (r=0.747,p=0.929),  time:36.088, tt:1840.483\n",
      "Ep:51, loss:0.00001, loss_test:0.01408, lr:5.06e-02, fs:0.82803 (r=0.747,p=0.929),  time:36.104, tt:1877.394\n",
      "Ep:52, loss:0.00001, loss_test:0.01419, lr:5.01e-02, fs:0.82803 (r=0.747,p=0.929),  time:36.110, tt:1913.854\n",
      "Ep:53, loss:0.00001, loss_test:0.01428, lr:4.96e-02, fs:0.82051 (r=0.736,p=0.928),  time:36.140, tt:1951.554\n",
      "Ep:54, loss:0.00001, loss_test:0.01441, lr:4.91e-02, fs:0.82051 (r=0.736,p=0.928),  time:36.159, tt:1988.765\n",
      "Ep:55, loss:0.00001, loss_test:0.01450, lr:4.86e-02, fs:0.82051 (r=0.736,p=0.928),  time:36.152, tt:2024.532\n",
      "Ep:56, loss:0.00001, loss_test:0.01460, lr:4.81e-02, fs:0.82051 (r=0.736,p=0.928),  time:36.128, tt:2059.275\n",
      "Ep:57, loss:0.00001, loss_test:0.01473, lr:4.76e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.125, tt:2095.235\n",
      "Ep:58, loss:0.00001, loss_test:0.01485, lr:4.71e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.100, tt:2129.908\n",
      "Ep:59, loss:0.00001, loss_test:0.01492, lr:4.67e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.094, tt:2165.616\n",
      "Ep:60, loss:0.00001, loss_test:0.01499, lr:4.62e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.090, tt:2201.480\n",
      "Ep:61, loss:0.00001, loss_test:0.01513, lr:4.57e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.218, tt:2245.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:62, loss:0.00001, loss_test:0.01526, lr:4.53e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.219, tt:2281.810\n",
      "Ep:63, loss:0.00001, loss_test:0.01537, lr:4.48e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.188, tt:2316.008\n",
      "Ep:64, loss:0.00001, loss_test:0.01549, lr:4.44e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.177, tt:2351.535\n",
      "Ep:65, loss:0.00001, loss_test:0.01557, lr:4.39e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.165, tt:2386.919\n",
      "Ep:66, loss:0.00000, loss_test:0.01568, lr:4.35e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.184, tt:2424.310\n",
      "Ep:67, loss:0.00000, loss_test:0.01579, lr:4.31e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.207, tt:2462.102\n",
      "Ep:68, loss:0.00000, loss_test:0.01591, lr:4.26e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.209, tt:2498.444\n",
      "Ep:69, loss:0.00000, loss_test:0.01601, lr:4.22e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.226, tt:2535.840\n",
      "Ep:70, loss:0.00000, loss_test:0.01612, lr:4.18e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.241, tt:2573.088\n",
      "Ep:71, loss:0.00000, loss_test:0.01622, lr:4.14e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.231, tt:2608.620\n",
      "Ep:72, loss:0.00000, loss_test:0.01634, lr:4.10e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.248, tt:2646.135\n",
      "Ep:73, loss:0.00000, loss_test:0.01646, lr:4.05e-02, fs:0.81290 (r=0.724,p=0.926),  time:36.268, tt:2683.842\n",
      "Ep:74, loss:0.00000, loss_test:0.01657, lr:4.01e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.238, tt:2717.876\n",
      "Ep:75, loss:0.00000, loss_test:0.01666, lr:3.97e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.235, tt:2753.896\n",
      "Ep:76, loss:0.00000, loss_test:0.01675, lr:3.93e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.221, tt:2789.020\n",
      "Ep:77, loss:0.00000, loss_test:0.01684, lr:3.89e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.219, tt:2825.100\n",
      "Ep:78, loss:0.00000, loss_test:0.01696, lr:3.86e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.232, tt:2862.330\n",
      "Ep:79, loss:0.00000, loss_test:0.01705, lr:3.82e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.230, tt:2898.415\n",
      "Ep:80, loss:0.00000, loss_test:0.01716, lr:3.78e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.231, tt:2934.702\n",
      "Ep:81, loss:0.00000, loss_test:0.01726, lr:3.74e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.231, tt:2970.977\n",
      "Ep:82, loss:0.00000, loss_test:0.01736, lr:3.70e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.216, tt:3005.909\n",
      "Ep:83, loss:0.00000, loss_test:0.01744, lr:3.67e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.206, tt:3041.264\n",
      "Ep:84, loss:0.00000, loss_test:0.01752, lr:3.63e-02, fs:0.80519 (r=0.713,p=0.925),  time:36.166, tt:3074.140\n",
      "Ep:85, loss:0.00000, loss_test:0.01762, lr:3.59e-02, fs:0.79739 (r=0.701,p=0.924),  time:36.180, tt:3111.499\n",
      "Ep:86, loss:0.00000, loss_test:0.01770, lr:3.56e-02, fs:0.80263 (r=0.701,p=0.938),  time:36.171, tt:3146.874\n",
      "Ep:87, loss:0.00000, loss_test:0.01780, lr:3.52e-02, fs:0.80263 (r=0.701,p=0.938),  time:36.162, tt:3182.257\n",
      "Ep:88, loss:0.00000, loss_test:0.01790, lr:3.49e-02, fs:0.79470 (r=0.690,p=0.938),  time:36.160, tt:3218.263\n",
      "Ep:89, loss:0.00000, loss_test:0.01797, lr:3.45e-02, fs:0.78667 (r=0.678,p=0.937),  time:36.179, tt:3256.066\n",
      "Ep:90, loss:0.00000, loss_test:0.01803, lr:3.42e-02, fs:0.77852 (r=0.667,p=0.935),  time:36.178, tt:3292.230\n",
      "Ep:91, loss:0.00000, loss_test:0.01812, lr:3.38e-02, fs:0.77852 (r=0.667,p=0.935),  time:36.189, tt:3329.370\n",
      "Ep:92, loss:0.00000, loss_test:0.01820, lr:3.35e-02, fs:0.75342 (r=0.632,p=0.932),  time:36.191, tt:3365.722\n",
      "Ep:93, loss:0.00000, loss_test:0.01829, lr:3.32e-02, fs:0.74483 (r=0.621,p=0.931),  time:36.184, tt:3401.309\n",
      "Ep:94, loss:0.00000, loss_test:0.01837, lr:3.28e-02, fs:0.73611 (r=0.609,p=0.930),  time:36.194, tt:3438.388\n",
      "Ep:95, loss:0.00000, loss_test:0.01845, lr:3.25e-02, fs:0.72727 (r=0.598,p=0.929),  time:36.186, tt:3473.840\n",
      "Ep:96, loss:0.00000, loss_test:0.01853, lr:3.22e-02, fs:0.72727 (r=0.598,p=0.929),  time:36.186, tt:3510.010\n",
      "Ep:97, loss:0.00000, loss_test:0.01862, lr:3.19e-02, fs:0.72727 (r=0.598,p=0.929),  time:36.182, tt:3545.834\n",
      "Ep:98, loss:0.00000, loss_test:0.01869, lr:3.15e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.176, tt:3581.465\n",
      "Ep:99, loss:0.00000, loss_test:0.01878, lr:3.12e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.176, tt:3617.619\n",
      "Ep:100, loss:0.00000, loss_test:0.01885, lr:3.09e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.180, tt:3654.199\n",
      "Ep:101, loss:0.00000, loss_test:0.01891, lr:3.06e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.182, tt:3690.602\n",
      "Ep:102, loss:0.00000, loss_test:0.01897, lr:3.03e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.190, tt:3727.609\n",
      "Ep:103, loss:0.00000, loss_test:0.01905, lr:3.00e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.192, tt:3763.921\n",
      "Ep:104, loss:0.00000, loss_test:0.01909, lr:2.97e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.194, tt:3800.392\n",
      "Ep:105, loss:0.00000, loss_test:0.01915, lr:2.94e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.158, tt:3832.767\n",
      "Ep:106, loss:0.00000, loss_test:0.01920, lr:2.91e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.104, tt:3863.134\n",
      "Ep:107, loss:0.00000, loss_test:0.01927, lr:2.88e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.033, tt:3891.554\n",
      "Ep:108, loss:0.00000, loss_test:0.01933, lr:2.85e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.971, tt:3920.833\n",
      "Ep:109, loss:0.00000, loss_test:0.01940, lr:2.82e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.923, tt:3951.481\n",
      "Ep:110, loss:0.00000, loss_test:0.01945, lr:2.80e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.886, tt:3983.355\n",
      "Ep:111, loss:0.00000, loss_test:0.01950, lr:2.77e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.864, tt:4016.749\n",
      "Ep:112, loss:0.00000, loss_test:0.01958, lr:2.74e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.833, tt:4049.077\n",
      "Ep:113, loss:0.00000, loss_test:0.01963, lr:2.71e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.809, tt:4082.241\n",
      "Ep:114, loss:0.00000, loss_test:0.01969, lr:2.69e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.812, tt:4118.358\n",
      "Ep:115, loss:0.00000, loss_test:0.01973, lr:2.66e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.812, tt:4154.233\n",
      "Ep:116, loss:0.00000, loss_test:0.01979, lr:2.63e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.822, tt:4191.200\n",
      "Ep:117, loss:0.00000, loss_test:0.01985, lr:2.61e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.831, tt:4228.068\n",
      "Ep:118, loss:0.00000, loss_test:0.01989, lr:2.58e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.848, tt:4265.940\n",
      "Ep:119, loss:0.00000, loss_test:0.01995, lr:2.55e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.845, tt:4301.352\n",
      "Ep:120, loss:0.00000, loss_test:0.02000, lr:2.53e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.844, tt:4337.084\n",
      "Ep:121, loss:0.00000, loss_test:0.02003, lr:2.50e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.848, tt:4373.490\n",
      "Ep:122, loss:0.00000, loss_test:0.02008, lr:2.48e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.865, tt:4411.424\n",
      "Ep:123, loss:0.00000, loss_test:0.02012, lr:2.45e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.860, tt:4446.639\n",
      "Ep:124, loss:0.00000, loss_test:0.02017, lr:2.43e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.863, tt:4482.922\n",
      "Ep:125, loss:0.00000, loss_test:0.02022, lr:2.40e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.873, tt:4519.936\n",
      "Ep:126, loss:0.00000, loss_test:0.02027, lr:2.38e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.877, tt:4556.384\n",
      "Ep:127, loss:0.00000, loss_test:0.02033, lr:2.36e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.873, tt:4591.776\n",
      "Ep:128, loss:0.00000, loss_test:0.02037, lr:2.33e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.886, tt:4629.323\n",
      "Ep:129, loss:0.00000, loss_test:0.02041, lr:2.31e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.896, tt:4666.478\n",
      "Ep:130, loss:0.00000, loss_test:0.02044, lr:2.29e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.903, tt:4703.242\n",
      "Ep:131, loss:0.00000, loss_test:0.02048, lr:2.26e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.909, tt:4740.033\n",
      "Ep:132, loss:0.00000, loss_test:0.02051, lr:2.24e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.903, tt:4775.116\n",
      "Ep:133, loss:0.00000, loss_test:0.02054, lr:2.22e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.898, tt:4810.315\n",
      "Ep:134, loss:0.00000, loss_test:0.02059, lr:2.20e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.883, tt:4844.166\n",
      "Ep:135, loss:0.00000, loss_test:0.02063, lr:2.17e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.883, tt:4880.116\n",
      "Ep:136, loss:0.00000, loss_test:0.02065, lr:2.15e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.885, tt:4916.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:137, loss:0.00000, loss_test:0.02071, lr:2.13e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.917, tt:4956.604\n",
      "Ep:138, loss:0.00000, loss_test:0.02073, lr:2.11e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.919, tt:4992.682\n",
      "Ep:139, loss:0.00000, loss_test:0.02077, lr:2.09e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.925, tt:5029.437\n",
      "Ep:140, loss:0.00000, loss_test:0.02081, lr:2.07e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.944, tt:5068.128\n",
      "Ep:141, loss:0.00000, loss_test:0.02085, lr:2.05e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.979, tt:5109.087\n",
      "Ep:142, loss:0.00000, loss_test:0.02087, lr:2.03e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.976, tt:5144.556\n",
      "Ep:143, loss:0.00000, loss_test:0.02090, lr:2.01e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.978, tt:5180.767\n",
      "Ep:144, loss:0.00000, loss_test:0.02093, lr:1.99e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.982, tt:5217.327\n",
      "Ep:145, loss:0.00000, loss_test:0.02096, lr:1.97e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.978, tt:5252.771\n",
      "Ep:146, loss:0.00000, loss_test:0.02099, lr:1.95e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.975, tt:5288.273\n",
      "Ep:147, loss:0.00000, loss_test:0.02102, lr:1.93e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.965, tt:5322.763\n",
      "Ep:148, loss:0.00000, loss_test:0.02104, lr:1.91e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.966, tt:5358.918\n",
      "Ep:149, loss:0.00000, loss_test:0.02106, lr:1.89e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.965, tt:5394.682\n",
      "Ep:150, loss:0.00000, loss_test:0.02110, lr:1.87e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.967, tt:5430.989\n",
      "Ep:151, loss:0.00000, loss_test:0.02113, lr:1.85e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.973, tt:5467.843\n",
      "Ep:152, loss:0.00000, loss_test:0.02116, lr:1.83e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.987, tt:5505.971\n",
      "Ep:153, loss:0.00000, loss_test:0.02120, lr:1.81e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.982, tt:5541.158\n",
      "Ep:154, loss:0.00000, loss_test:0.02123, lr:1.80e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.979, tt:5576.729\n",
      "Ep:155, loss:0.00000, loss_test:0.02125, lr:1.78e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.981, tt:5613.063\n",
      "Ep:156, loss:0.00000, loss_test:0.02128, lr:1.76e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.965, tt:5646.431\n",
      "Ep:157, loss:0.00000, loss_test:0.02132, lr:1.74e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.968, tt:5682.913\n",
      "Ep:158, loss:0.00000, loss_test:0.02134, lr:1.73e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.967, tt:5718.828\n",
      "Ep:159, loss:0.00000, loss_test:0.02135, lr:1.71e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.964, tt:5754.279\n",
      "Ep:160, loss:0.00000, loss_test:0.02138, lr:1.69e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.969, tt:5790.999\n",
      "Ep:161, loss:0.00000, loss_test:0.02141, lr:1.67e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.972, tt:5827.486\n",
      "Ep:162, loss:0.00000, loss_test:0.02143, lr:1.66e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.964, tt:5862.130\n",
      "Ep:163, loss:0.00000, loss_test:0.02146, lr:1.64e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.975, tt:5899.962\n",
      "Ep:164, loss:0.00000, loss_test:0.02148, lr:1.62e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.963, tt:5933.913\n",
      "Ep:165, loss:0.00000, loss_test:0.02151, lr:1.61e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.963, tt:5969.924\n",
      "Ep:166, loss:0.00000, loss_test:0.02153, lr:1.59e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.959, tt:6005.224\n",
      "Ep:167, loss:0.00000, loss_test:0.02154, lr:1.58e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.968, tt:6042.703\n",
      "Ep:168, loss:0.00000, loss_test:0.02157, lr:1.56e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.974, tt:6079.638\n",
      "Ep:169, loss:0.00000, loss_test:0.02160, lr:1.54e-02, fs:0.71831 (r=0.586,p=0.927),  time:35.994, tt:6118.957\n",
      "Ep:170, loss:0.00000, loss_test:0.02162, lr:1.53e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.003, tt:6156.541\n",
      "Ep:171, loss:0.00000, loss_test:0.02164, lr:1.51e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.014, tt:6194.444\n",
      "Ep:172, loss:0.00000, loss_test:0.02167, lr:1.50e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.020, tt:6231.492\n",
      "Ep:173, loss:0.00000, loss_test:0.02168, lr:1.48e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.019, tt:6267.379\n",
      "Ep:174, loss:0.00000, loss_test:0.02170, lr:1.47e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.024, tt:6304.227\n",
      "Ep:175, loss:0.00000, loss_test:0.02172, lr:1.45e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.034, tt:6342.014\n",
      "Ep:176, loss:0.00000, loss_test:0.02174, lr:1.44e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.038, tt:6378.776\n",
      "Ep:177, loss:0.00000, loss_test:0.02176, lr:1.43e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.043, tt:6415.703\n",
      "Ep:178, loss:0.00000, loss_test:0.02178, lr:1.41e-02, fs:0.71831 (r=0.586,p=0.927),  time:36.052, tt:6453.231\n",
      "Ep:179, loss:0.00000, loss_test:0.02180, lr:1.40e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.057, tt:6490.333\n",
      "Ep:180, loss:0.00000, loss_test:0.02182, lr:1.38e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.055, tt:6525.905\n",
      "Ep:181, loss:0.00000, loss_test:0.02184, lr:1.37e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.054, tt:6561.875\n",
      "Ep:182, loss:0.00000, loss_test:0.02185, lr:1.36e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.056, tt:6598.166\n",
      "Ep:183, loss:0.00000, loss_test:0.02186, lr:1.34e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.069, tt:6636.661\n",
      "Ep:184, loss:0.00000, loss_test:0.02188, lr:1.33e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.068, tt:6672.667\n",
      "Ep:185, loss:0.00000, loss_test:0.02190, lr:1.32e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.065, tt:6708.137\n",
      "Ep:186, loss:0.00000, loss_test:0.02192, lr:1.30e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.061, tt:6743.368\n",
      "Ep:187, loss:0.00000, loss_test:0.02194, lr:1.29e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.061, tt:6779.390\n",
      "Ep:188, loss:0.00000, loss_test:0.02196, lr:1.28e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.080, tt:6819.084\n",
      "Ep:189, loss:0.00000, loss_test:0.02198, lr:1.26e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.083, tt:6855.823\n",
      "Ep:190, loss:0.00000, loss_test:0.02199, lr:1.25e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.092, tt:6893.506\n",
      "Ep:191, loss:0.00000, loss_test:0.02201, lr:1.24e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.098, tt:6930.748\n",
      "Ep:192, loss:0.00000, loss_test:0.02203, lr:1.23e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.102, tt:6967.594\n",
      "Ep:193, loss:0.00000, loss_test:0.02204, lr:1.21e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.095, tt:7002.523\n",
      "Ep:194, loss:0.00000, loss_test:0.02205, lr:1.20e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.090, tt:7037.514\n",
      "Ep:195, loss:0.00000, loss_test:0.02207, lr:1.19e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.092, tt:7073.937\n",
      "Ep:196, loss:0.00000, loss_test:0.02209, lr:1.18e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.083, tt:7108.373\n",
      "Ep:197, loss:0.00000, loss_test:0.02210, lr:1.17e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.092, tt:7146.120\n",
      "Ep:198, loss:0.00000, loss_test:0.02211, lr:1.15e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.097, tt:7183.232\n",
      "Ep:199, loss:0.00000, loss_test:0.02213, lr:1.14e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.099, tt:7219.722\n",
      "Ep:200, loss:0.00000, loss_test:0.02215, lr:1.13e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.096, tt:7255.249\n",
      "Ep:201, loss:0.00000, loss_test:0.02216, lr:1.12e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.095, tt:7291.170\n",
      "Ep:202, loss:0.00000, loss_test:0.02218, lr:1.11e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.099, tt:7328.127\n",
      "Ep:203, loss:0.00000, loss_test:0.02219, lr:1.10e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.100, tt:7364.378\n",
      "Ep:204, loss:0.00000, loss_test:0.02221, lr:1.09e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.080, tt:7396.485\n",
      "Ep:205, loss:0.00000, loss_test:0.02222, lr:1.08e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.074, tt:7431.251\n",
      "Ep:206, loss:0.00000, loss_test:0.02223, lr:1.07e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.071, tt:7466.601\n",
      "Ep:207, loss:0.00000, loss_test:0.02225, lr:1.05e-02, fs:0.72340 (r=0.586,p=0.944),  time:36.052, tt:7498.718\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1528 Test samples: 174\n",
      "Train positive samples: 764 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14153, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:37.410, tt:37.410\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14010, lr:1.00e-02, fs:0.64062 (r=0.943,p=0.485),  time:34.696, tt:69.392\n",
      "Ep:2, loss:0.00028, loss_test:0.13766, lr:1.00e-02, fs:0.64567 (r=0.943,p=0.491),  time:34.837, tt:104.512\n",
      "Ep:3, loss:0.00028, loss_test:0.13384, lr:1.00e-02, fs:0.65060 (r=0.931,p=0.500),  time:34.860, tt:139.440\n",
      "Ep:4, loss:0.00027, loss_test:0.12823, lr:1.00e-02, fs:0.65833 (r=0.908,p=0.516),  time:34.920, tt:174.599\n",
      "Ep:5, loss:0.00026, loss_test:0.12133, lr:1.00e-02, fs:0.67273 (r=0.851,p=0.556),  time:34.895, tt:209.369\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11608, lr:1.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:34.861, tt:244.025\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.11490, lr:1.00e-02, fs:0.71264 (r=0.713,p=0.713),  time:34.945, tt:279.557\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11493, lr:1.00e-02, fs:0.72515 (r=0.713,p=0.738),  time:35.254, tt:317.283\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.10936, lr:1.00e-02, fs:0.70000 (r=0.724,p=0.677),  time:35.390, tt:353.899\n",
      "Ep:10, loss:0.00021, loss_test:0.10629, lr:1.00e-02, fs:0.70330 (r=0.736,p=0.674),  time:35.427, tt:389.693\n",
      "Ep:11, loss:0.00020, loss_test:0.10447, lr:1.00e-02, fs:0.72000 (r=0.724,p=0.716),  time:35.472, tt:425.660\n",
      "Ep:12, loss:0.00019, loss_test:0.10255, lr:1.00e-02, fs:0.72093 (r=0.713,p=0.729),  time:35.761, tt:464.891\n",
      "Ep:13, loss:0.00019, loss_test:0.09710, lr:1.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:35.891, tt:502.479\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09338, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:35.913, tt:538.702\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09041, lr:1.00e-02, fs:0.76190 (r=0.736,p=0.790),  time:35.911, tt:574.578\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.08759, lr:1.00e-02, fs:0.78788 (r=0.747,p=0.833),  time:35.901, tt:610.324\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.08625, lr:1.00e-02, fs:0.78049 (r=0.736,p=0.831),  time:35.860, tt:645.488\n",
      "Ep:18, loss:0.00015, loss_test:0.08320, lr:1.00e-02, fs:0.80723 (r=0.770,p=0.848),  time:35.989, tt:683.791\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.08080, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:35.954, tt:719.084\n",
      "Ep:20, loss:0.00013, loss_test:0.07970, lr:1.00e-02, fs:0.79503 (r=0.736,p=0.865),  time:35.906, tt:754.025\n",
      "Ep:21, loss:0.00012, loss_test:0.07604, lr:1.00e-02, fs:0.87356 (r=0.874,p=0.874),  time:35.820, tt:788.046\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00012, loss_test:0.07521, lr:1.00e-02, fs:0.86550 (r=0.851,p=0.881),  time:35.867, tt:824.931\n",
      "Ep:23, loss:0.00011, loss_test:0.07358, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:35.936, tt:862.454\n",
      "Ep:24, loss:0.00010, loss_test:0.07240, lr:1.00e-02, fs:0.89017 (r=0.885,p=0.895),  time:35.987, tt:899.663\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00010, loss_test:0.07214, lr:1.00e-02, fs:0.90805 (r=0.908,p=0.908),  time:35.949, tt:934.663\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00009, loss_test:0.07132, lr:1.00e-02, fs:0.90395 (r=0.920,p=0.889),  time:35.939, tt:970.352\n",
      "Ep:27, loss:0.00009, loss_test:0.07245, lr:1.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:35.955, tt:1006.732\n",
      "Ep:28, loss:0.00008, loss_test:0.07013, lr:1.00e-02, fs:0.90286 (r=0.908,p=0.898),  time:35.956, tt:1042.727\n",
      "Ep:29, loss:0.00007, loss_test:0.06982, lr:1.00e-02, fs:0.90805 (r=0.908,p=0.908),  time:35.890, tt:1076.687\n",
      "Ep:30, loss:0.00007, loss_test:0.06814, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:35.939, tt:1114.119\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00006, loss_test:0.06849, lr:1.00e-02, fs:0.91525 (r=0.931,p=0.900),  time:35.884, tt:1148.285\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00006, loss_test:0.07024, lr:1.00e-02, fs:0.84848 (r=0.805,p=0.897),  time:35.916, tt:1185.221\n",
      "Ep:33, loss:0.00005, loss_test:0.06700, lr:1.00e-02, fs:0.92571 (r=0.931,p=0.920),  time:35.922, tt:1221.361\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00005, loss_test:0.06620, lr:1.00e-02, fs:0.90909 (r=0.920,p=0.899),  time:35.985, tt:1259.474\n",
      "Ep:35, loss:0.00005, loss_test:0.06804, lr:1.00e-02, fs:0.87574 (r=0.851,p=0.902),  time:36.011, tt:1296.395\n",
      "Ep:36, loss:0.00004, loss_test:0.06661, lr:1.00e-02, fs:0.89412 (r=0.874,p=0.916),  time:35.987, tt:1331.526\n",
      "Ep:37, loss:0.00004, loss_test:0.06631, lr:1.00e-02, fs:0.93567 (r=0.920,p=0.952),  time:35.965, tt:1366.663\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00004, loss_test:0.06796, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:35.965, tt:1402.636\n",
      "Ep:39, loss:0.00003, loss_test:0.06905, lr:1.00e-02, fs:0.83544 (r=0.759,p=0.930),  time:35.936, tt:1437.448\n",
      "Ep:40, loss:0.00003, loss_test:0.06684, lr:1.00e-02, fs:0.90361 (r=0.862,p=0.949),  time:35.900, tt:1471.908\n",
      "Ep:41, loss:0.00003, loss_test:0.06968, lr:1.00e-02, fs:0.82803 (r=0.747,p=0.929),  time:35.901, tt:1507.824\n",
      "Ep:42, loss:0.00003, loss_test:0.06784, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.896, tt:1543.548\n",
      "Ep:43, loss:0.00002, loss_test:0.06836, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.883, tt:1578.834\n",
      "Ep:44, loss:0.00002, loss_test:0.07026, lr:1.00e-02, fs:0.83117 (r=0.736,p=0.955),  time:35.889, tt:1614.986\n",
      "Ep:45, loss:0.00002, loss_test:0.06878, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.905, tt:1651.646\n",
      "Ep:46, loss:0.00002, loss_test:0.06754, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.903, tt:1687.458\n",
      "Ep:47, loss:0.00002, loss_test:0.07191, lr:1.00e-02, fs:0.83333 (r=0.747,p=0.942),  time:35.922, tt:1724.270\n",
      "Ep:48, loss:0.00002, loss_test:0.06888, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:35.963, tt:1762.197\n",
      "Ep:49, loss:0.00002, loss_test:0.06962, lr:9.90e-03, fs:0.84615 (r=0.759,p=0.957),  time:35.994, tt:1799.717\n",
      "Ep:50, loss:0.00001, loss_test:0.07155, lr:9.80e-03, fs:0.81818 (r=0.724,p=0.940),  time:36.029, tt:1837.481\n",
      "Ep:51, loss:0.00001, loss_test:0.06971, lr:9.70e-03, fs:0.85350 (r=0.770,p=0.957),  time:36.065, tt:1875.363\n",
      "Ep:52, loss:0.00001, loss_test:0.06988, lr:9.61e-03, fs:0.84076 (r=0.759,p=0.943),  time:36.112, tt:1913.927\n",
      "Ep:53, loss:0.00001, loss_test:0.07190, lr:9.51e-03, fs:0.79730 (r=0.678,p=0.967),  time:36.130, tt:1951.018\n",
      "Ep:54, loss:0.00001, loss_test:0.07182, lr:9.41e-03, fs:0.83444 (r=0.724,p=0.984),  time:36.180, tt:1989.910\n",
      "Ep:55, loss:0.00001, loss_test:0.07046, lr:9.32e-03, fs:0.85897 (r=0.770,p=0.971),  time:36.188, tt:2026.505\n",
      "Ep:56, loss:0.00001, loss_test:0.07369, lr:9.23e-03, fs:0.72857 (r=0.586,p=0.962),  time:36.192, tt:2062.957\n",
      "Ep:57, loss:0.00001, loss_test:0.07206, lr:9.14e-03, fs:0.84967 (r=0.747,p=0.985),  time:36.205, tt:2099.918\n",
      "Ep:58, loss:0.00001, loss_test:0.07311, lr:9.04e-03, fs:0.78082 (r=0.655,p=0.966),  time:36.218, tt:2136.878\n",
      "Ep:59, loss:0.00001, loss_test:0.07120, lr:8.95e-03, fs:0.84211 (r=0.736,p=0.985),  time:36.233, tt:2173.990\n",
      "Ep:60, loss:0.00001, loss_test:0.07422, lr:8.86e-03, fs:0.73759 (r=0.598,p=0.963),  time:36.215, tt:2209.093\n",
      "Ep:61, loss:0.00001, loss_test:0.07259, lr:8.78e-03, fs:0.80272 (r=0.678,p=0.983),  time:36.237, tt:2246.688\n",
      "Ep:62, loss:0.00001, loss_test:0.07406, lr:8.69e-03, fs:0.73759 (r=0.598,p=0.963),  time:36.260, tt:2284.375\n",
      "Ep:63, loss:0.00001, loss_test:0.07280, lr:8.60e-03, fs:0.83444 (r=0.724,p=0.984),  time:36.286, tt:2322.311\n",
      "Ep:64, loss:0.00001, loss_test:0.07329, lr:8.51e-03, fs:0.75524 (r=0.621,p=0.964),  time:36.282, tt:2358.355\n",
      "Ep:65, loss:0.00001, loss_test:0.07432, lr:8.43e-03, fs:0.77241 (r=0.644,p=0.966),  time:36.299, tt:2395.726\n",
      "Ep:66, loss:0.00001, loss_test:0.07414, lr:8.35e-03, fs:0.73759 (r=0.598,p=0.963),  time:36.306, tt:2432.477\n",
      "Ep:67, loss:0.00001, loss_test:0.07370, lr:8.26e-03, fs:0.80537 (r=0.690,p=0.968),  time:36.308, tt:2468.931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00001, loss_test:0.07419, lr:8.18e-03, fs:0.70073 (r=0.552,p=0.960),  time:36.343, tt:2507.658\n",
      "Ep:69, loss:0.00001, loss_test:0.07605, lr:8.10e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.360, tt:2545.181\n",
      "Ep:70, loss:0.00001, loss_test:0.07479, lr:8.02e-03, fs:0.78621 (r=0.655,p=0.983),  time:36.388, tt:2583.568\n",
      "Ep:71, loss:0.00001, loss_test:0.07494, lr:7.94e-03, fs:0.70073 (r=0.552,p=0.960),  time:36.380, tt:2619.396\n",
      "Ep:72, loss:0.00001, loss_test:0.07462, lr:7.86e-03, fs:0.77241 (r=0.644,p=0.966),  time:36.388, tt:2656.288\n",
      "Ep:73, loss:0.00001, loss_test:0.07396, lr:7.78e-03, fs:0.76056 (r=0.621,p=0.982),  time:36.397, tt:2693.371\n",
      "Ep:74, loss:0.00001, loss_test:0.07614, lr:7.70e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.405, tt:2730.353\n",
      "Ep:75, loss:0.00001, loss_test:0.07418, lr:7.62e-03, fs:0.77778 (r=0.644,p=0.982),  time:36.394, tt:2765.939\n",
      "Ep:76, loss:0.00000, loss_test:0.07508, lr:7.55e-03, fs:0.71942 (r=0.575,p=0.962),  time:36.370, tt:2800.524\n",
      "Ep:77, loss:0.00000, loss_test:0.07574, lr:7.47e-03, fs:0.70588 (r=0.552,p=0.980),  time:36.345, tt:2834.947\n",
      "Ep:78, loss:0.00000, loss_test:0.07522, lr:7.40e-03, fs:0.70073 (r=0.552,p=0.960),  time:36.332, tt:2870.190\n",
      "Ep:79, loss:0.00000, loss_test:0.07618, lr:7.32e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.316, tt:2905.272\n",
      "Ep:80, loss:0.00000, loss_test:0.07573, lr:7.25e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.325, tt:2942.320\n",
      "Ep:81, loss:0.00000, loss_test:0.07471, lr:7.18e-03, fs:0.71942 (r=0.575,p=0.962),  time:36.318, tt:2978.055\n",
      "Ep:82, loss:0.00000, loss_test:0.07667, lr:7.11e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.296, tt:3012.559\n",
      "Ep:83, loss:0.00000, loss_test:0.07623, lr:7.03e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.308, tt:3049.838\n",
      "Ep:84, loss:0.00000, loss_test:0.07574, lr:6.96e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.293, tt:3084.900\n",
      "Ep:85, loss:0.00000, loss_test:0.07799, lr:6.89e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.317, tt:3123.267\n",
      "Ep:86, loss:0.00000, loss_test:0.07562, lr:6.83e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.328, tt:3160.519\n",
      "Ep:87, loss:0.00000, loss_test:0.07687, lr:6.76e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.343, tt:3198.226\n",
      "Ep:88, loss:0.00000, loss_test:0.07702, lr:6.69e-03, fs:0.69118 (r=0.540,p=0.959),  time:36.347, tt:3234.857\n",
      "Ep:89, loss:0.00000, loss_test:0.07797, lr:6.62e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.362, tt:3272.624\n",
      "Ep:90, loss:0.00000, loss_test:0.07793, lr:6.56e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.378, tt:3310.388\n",
      "Ep:91, loss:0.00000, loss_test:0.07749, lr:6.49e-03, fs:0.67164 (r=0.517,p=0.957),  time:36.401, tt:3348.880\n",
      "Ep:92, loss:0.00000, loss_test:0.07716, lr:6.43e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.420, tt:3387.046\n",
      "Ep:93, loss:0.00000, loss_test:0.07791, lr:6.36e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.435, tt:3424.919\n",
      "Ep:94, loss:0.00000, loss_test:0.07807, lr:6.30e-03, fs:0.67164 (r=0.517,p=0.957),  time:36.428, tt:3460.645\n",
      "Ep:95, loss:0.00000, loss_test:0.07840, lr:6.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.443, tt:3498.480\n",
      "Ep:96, loss:0.00000, loss_test:0.07843, lr:6.17e-03, fs:0.67164 (r=0.517,p=0.957),  time:36.443, tt:3534.945\n",
      "Ep:97, loss:0.00000, loss_test:0.07763, lr:6.11e-03, fs:0.68148 (r=0.529,p=0.958),  time:36.443, tt:3571.412\n",
      "Ep:98, loss:0.00000, loss_test:0.07843, lr:6.05e-03, fs:0.67164 (r=0.517,p=0.957),  time:36.445, tt:3608.087\n",
      "Ep:99, loss:0.00000, loss_test:0.07796, lr:5.99e-03, fs:0.67164 (r=0.517,p=0.957),  time:36.450, tt:3644.987\n",
      "Ep:100, loss:0.00000, loss_test:0.07799, lr:5.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.454, tt:3681.866\n",
      "Ep:101, loss:0.00000, loss_test:0.07873, lr:5.87e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.456, tt:3718.514\n",
      "Ep:102, loss:0.00000, loss_test:0.07778, lr:5.81e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.463, tt:3755.702\n",
      "Ep:103, loss:0.00000, loss_test:0.07838, lr:5.75e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.417, tt:3787.397\n",
      "Ep:104, loss:0.00000, loss_test:0.07885, lr:5.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.356, tt:3817.418\n",
      "Ep:105, loss:0.00000, loss_test:0.07839, lr:5.64e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.317, tt:3849.570\n",
      "Ep:106, loss:0.00000, loss_test:0.07836, lr:5.58e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.292, tt:3883.260\n",
      "Ep:107, loss:0.00000, loss_test:0.07846, lr:5.53e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.246, tt:3914.551\n",
      "Ep:108, loss:0.00000, loss_test:0.07839, lr:5.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.213, tt:3947.221\n",
      "Ep:109, loss:0.00000, loss_test:0.07799, lr:5.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.162, tt:3977.798\n",
      "Ep:110, loss:0.00000, loss_test:0.07823, lr:5.36e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.112, tt:4008.383\n",
      "Ep:111, loss:0.00000, loss_test:0.07872, lr:5.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.073, tt:4040.145\n",
      "Ep:112, loss:0.00000, loss_test:0.07837, lr:5.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.060, tt:4074.732\n",
      "Ep:113, loss:0.00000, loss_test:0.07912, lr:5.20e-03, fs:0.67669 (r=0.517,p=0.978),  time:36.000, tt:4103.989\n",
      "Ep:114, loss:0.00000, loss_test:0.07871, lr:5.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.967, tt:4136.151\n",
      "Ep:115, loss:0.00000, loss_test:0.07904, lr:5.10e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.921, tt:4166.869\n",
      "Ep:116, loss:0.00000, loss_test:0.07887, lr:5.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.885, tt:4198.496\n",
      "Ep:117, loss:0.00000, loss_test:0.07849, lr:5.00e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.841, tt:4229.246\n",
      "Ep:118, loss:0.00000, loss_test:0.07890, lr:4.95e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.787, tt:4258.705\n",
      "Ep:119, loss:0.00000, loss_test:0.07897, lr:4.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.755, tt:4290.656\n",
      "Ep:120, loss:0.00000, loss_test:0.07979, lr:4.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.732, tt:4323.536\n",
      "Ep:121, loss:0.00000, loss_test:0.07943, lr:4.80e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.704, tt:4355.829\n",
      "Ep:122, loss:0.00000, loss_test:0.07884, lr:4.75e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.667, tt:4387.038\n",
      "Ep:123, loss:0.00000, loss_test:0.07924, lr:4.71e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.645, tt:4420.026\n",
      "Ep:124, loss:0.00000, loss_test:0.07881, lr:4.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.622, tt:4452.789\n",
      "Ep:125, loss:0.00000, loss_test:0.07907, lr:4.61e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.591, tt:4484.423\n",
      "Ep:126, loss:0.00000, loss_test:0.07959, lr:4.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.541, tt:4513.708\n",
      "Ep:127, loss:0.00000, loss_test:0.07932, lr:4.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.526, tt:4547.318\n",
      "Ep:128, loss:0.00000, loss_test:0.07920, lr:4.48e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.489, tt:4578.095\n",
      "Ep:129, loss:0.00000, loss_test:0.07915, lr:4.43e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.459, tt:4609.704\n",
      "Ep:130, loss:0.00000, loss_test:0.07910, lr:4.39e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.420, tt:4640.031\n",
      "Ep:131, loss:0.00000, loss_test:0.07912, lr:4.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.378, tt:4669.959\n",
      "Ep:132, loss:0.00000, loss_test:0.07921, lr:4.30e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.350, tt:4701.601\n",
      "Ep:133, loss:0.00000, loss_test:0.07911, lr:4.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.300, tt:4730.242\n",
      "Ep:134, loss:0.00000, loss_test:0.07892, lr:4.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.245, tt:4758.017\n",
      "Ep:135, loss:0.00000, loss_test:0.07915, lr:4.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.192, tt:4786.085\n",
      "Ep:136, loss:0.00000, loss_test:0.07943, lr:4.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.158, tt:4816.683\n",
      "Ep:137, loss:0.00000, loss_test:0.07933, lr:4.09e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.118, tt:4846.217\n",
      "Ep:138, loss:0.00000, loss_test:0.07914, lr:4.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.079, tt:4875.989\n",
      "Ep:139, loss:0.00000, loss_test:0.07934, lr:4.01e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.053, tt:4907.386\n",
      "Ep:140, loss:0.00000, loss_test:0.07944, lr:3.97e-03, fs:0.67669 (r=0.517,p=0.978),  time:35.015, tt:4937.114\n",
      "Ep:141, loss:0.00000, loss_test:0.07933, lr:3.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.980, tt:4967.155\n",
      "Ep:142, loss:0.00000, loss_test:0.07917, lr:3.89e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.959, tt:4999.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00000, loss_test:0.07927, lr:3.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.958, tt:5033.901\n",
      "Ep:144, loss:0.00000, loss_test:0.07915, lr:3.81e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.923, tt:5063.789\n",
      "Ep:145, loss:0.00000, loss_test:0.07926, lr:3.77e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.904, tt:5095.944\n",
      "Ep:146, loss:0.00000, loss_test:0.07942, lr:3.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.873, tt:5126.322\n",
      "Ep:147, loss:0.00000, loss_test:0.07970, lr:3.70e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.864, tt:5159.798\n",
      "Ep:148, loss:0.00000, loss_test:0.07950, lr:3.66e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.838, tt:5190.841\n",
      "Ep:149, loss:0.00000, loss_test:0.07931, lr:3.62e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.802, tt:5220.253\n",
      "Ep:150, loss:0.00000, loss_test:0.07969, lr:3.59e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.780, tt:5251.746\n",
      "Ep:151, loss:0.00000, loss_test:0.07965, lr:3.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.763, tt:5283.957\n",
      "Ep:152, loss:0.00000, loss_test:0.07952, lr:3.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.756, tt:5317.612\n",
      "Ep:153, loss:0.00000, loss_test:0.07944, lr:3.48e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.742, tt:5350.311\n",
      "Ep:154, loss:0.00000, loss_test:0.07997, lr:3.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.732, tt:5383.494\n",
      "Ep:155, loss:0.00000, loss_test:0.07993, lr:3.41e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.715, tt:5415.578\n",
      "Ep:156, loss:0.00000, loss_test:0.07967, lr:3.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.699, tt:5447.737\n",
      "Ep:157, loss:0.00000, loss_test:0.07957, lr:3.34e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.668, tt:5477.557\n",
      "Ep:158, loss:0.00000, loss_test:0.07952, lr:3.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.641, tt:5507.952\n",
      "Ep:159, loss:0.00000, loss_test:0.07953, lr:3.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.617, tt:5538.710\n",
      "Ep:160, loss:0.00000, loss_test:0.08004, lr:3.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.592, tt:5569.288\n",
      "Ep:161, loss:0.00000, loss_test:0.08014, lr:3.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.571, tt:5600.558\n",
      "Ep:162, loss:0.00000, loss_test:0.07980, lr:3.18e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.542, tt:5630.320\n",
      "Ep:163, loss:0.00000, loss_test:0.07976, lr:3.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.524, tt:5661.997\n",
      "Ep:164, loss:0.00000, loss_test:0.07983, lr:3.12e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.495, tt:5691.757\n",
      "Ep:165, loss:0.00000, loss_test:0.07979, lr:3.09e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.470, tt:5721.972\n",
      "Ep:166, loss:0.00000, loss_test:0.07990, lr:3.05e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.453, tt:5753.653\n",
      "Ep:167, loss:0.00000, loss_test:0.07966, lr:3.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.428, tt:5783.859\n",
      "Ep:168, loss:0.00000, loss_test:0.07972, lr:2.99e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.399, tt:5813.434\n",
      "Ep:169, loss:0.00000, loss_test:0.07976, lr:2.96e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.374, tt:5843.603\n",
      "Ep:170, loss:0.00000, loss_test:0.07991, lr:2.93e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.342, tt:5872.470\n",
      "Ep:171, loss:0.00000, loss_test:0.07976, lr:2.90e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.323, tt:5903.493\n",
      "Ep:172, loss:0.00000, loss_test:0.07981, lr:2.88e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.302, tt:5934.205\n",
      "Ep:173, loss:0.00000, loss_test:0.07981, lr:2.85e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.284, tt:5965.419\n",
      "Ep:174, loss:0.00000, loss_test:0.07982, lr:2.82e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.265, tt:5996.460\n",
      "Ep:175, loss:0.00000, loss_test:0.08017, lr:2.79e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.244, tt:6026.980\n",
      "Ep:176, loss:0.00000, loss_test:0.08004, lr:2.76e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.216, tt:6056.265\n",
      "Ep:177, loss:0.00000, loss_test:0.07993, lr:2.73e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.199, tt:6087.425\n",
      "Ep:178, loss:0.00000, loss_test:0.08006, lr:2.71e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.187, tt:6119.430\n",
      "Ep:179, loss:0.00000, loss_test:0.07996, lr:2.68e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.175, tt:6151.461\n",
      "Ep:180, loss:0.00000, loss_test:0.08002, lr:2.65e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.163, tt:6183.476\n",
      "Ep:181, loss:0.00000, loss_test:0.08044, lr:2.63e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.136, tt:6212.743\n",
      "Ep:182, loss:0.00000, loss_test:0.08047, lr:2.60e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.121, tt:6244.072\n",
      "Ep:183, loss:0.00000, loss_test:0.08015, lr:2.57e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.095, tt:6273.518\n",
      "Ep:184, loss:0.00000, loss_test:0.08025, lr:2.55e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.064, tt:6301.798\n",
      "Ep:185, loss:0.00000, loss_test:0.08054, lr:2.52e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.041, tt:6331.673\n",
      "Ep:186, loss:0.00000, loss_test:0.08038, lr:2.50e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.056, tt:6368.405\n",
      "Ep:187, loss:0.00000, loss_test:0.08019, lr:2.47e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.040, tt:6399.438\n",
      "Ep:188, loss:0.00000, loss_test:0.08031, lr:2.45e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.029, tt:6431.473\n",
      "Ep:189, loss:0.00000, loss_test:0.08072, lr:2.42e-03, fs:0.67669 (r=0.517,p=0.978),  time:34.003, tt:6460.660\n",
      "Ep:190, loss:0.00000, loss_test:0.08087, lr:2.40e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.989, tt:6491.987\n",
      "Ep:191, loss:0.00000, loss_test:0.08086, lr:2.38e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.973, tt:6522.779\n",
      "Ep:192, loss:0.00000, loss_test:0.08069, lr:2.35e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.966, tt:6555.427\n",
      "Ep:193, loss:0.00000, loss_test:0.08061, lr:2.33e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.951, tt:6586.425\n",
      "Ep:194, loss:0.00000, loss_test:0.08059, lr:2.31e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.932, tt:6616.737\n",
      "Ep:195, loss:0.00000, loss_test:0.08032, lr:2.28e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.917, tt:6647.686\n",
      "Ep:196, loss:0.00000, loss_test:0.08017, lr:2.26e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.911, tt:6680.485\n",
      "Ep:197, loss:0.00000, loss_test:0.08033, lr:2.24e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.889, tt:6709.986\n",
      "Ep:198, loss:0.00000, loss_test:0.08065, lr:2.21e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.876, tt:6741.336\n",
      "Ep:199, loss:0.00000, loss_test:0.08070, lr:2.19e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.854, tt:6770.865\n",
      "Ep:200, loss:0.00000, loss_test:0.08042, lr:2.17e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.844, tt:6802.621\n",
      "Ep:201, loss:0.00000, loss_test:0.08043, lr:2.15e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.842, tt:6836.030\n",
      "Ep:202, loss:0.00000, loss_test:0.08082, lr:2.13e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.839, tt:6869.412\n",
      "Ep:203, loss:0.00000, loss_test:0.08078, lr:2.11e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.832, tt:6901.726\n",
      "Ep:204, loss:0.00000, loss_test:0.08062, lr:2.08e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.808, tt:6930.618\n",
      "Ep:205, loss:0.00000, loss_test:0.08044, lr:2.06e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.757, tt:6953.850\n",
      "Ep:206, loss:0.00000, loss_test:0.08053, lr:2.04e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.720, tt:6980.004\n",
      "Ep:207, loss:0.00000, loss_test:0.08057, lr:2.02e-03, fs:0.67669 (r=0.517,p=0.978),  time:33.669, tt:7003.120\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,208,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00006, loss_test:0.02008, lr:6.00e-02, fs:0.64207 (r=0.879,p=0.506),  time:33.764, tt:33.764\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02269, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.803, tt:69.605\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02384, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.410, tt:106.229\n",
      "Ep:3, loss:0.00005, loss_test:0.02336, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.607, tt:146.428\n",
      "Ep:4, loss:0.00004, loss_test:0.02209, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:37.264, tt:186.318\n",
      "Ep:5, loss:0.00004, loss_test:0.02051, lr:6.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:37.605, tt:225.630\n",
      "Ep:6, loss:0.00004, loss_test:0.01903, lr:6.00e-02, fs:0.66187 (r=0.929,p=0.514),  time:38.367, tt:268.571\n",
      "Ep:7, loss:0.00004, loss_test:0.01816, lr:6.00e-02, fs:0.67470 (r=0.848,p=0.560),  time:38.437, tt:307.494\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01739, lr:6.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:38.220, tt:343.978\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01661, lr:6.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:37.948, tt:379.479\n",
      "Ep:10, loss:0.00003, loss_test:0.01625, lr:6.00e-02, fs:0.69962 (r=0.929,p=0.561),  time:37.681, tt:414.494\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.01601, lr:6.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:37.498, tt:449.970\n",
      "Ep:12, loss:0.00003, loss_test:0.01557, lr:6.00e-02, fs:0.71373 (r=0.919,p=0.583),  time:37.756, tt:490.824\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01512, lr:6.00e-02, fs:0.73092 (r=0.919,p=0.607),  time:37.700, tt:527.804\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01480, lr:6.00e-02, fs:0.73770 (r=0.909,p=0.621),  time:37.674, tt:565.114\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01460, lr:6.00e-02, fs:0.73554 (r=0.899,p=0.622),  time:37.523, tt:600.373\n",
      "Ep:16, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.75207 (r=0.919,p=0.636),  time:37.313, tt:634.316\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01428, lr:6.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:37.094, tt:667.685\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01406, lr:6.00e-02, fs:0.77049 (r=0.949,p=0.648),  time:36.954, tt:702.121\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01379, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:36.929, tt:738.589\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01352, lr:6.00e-02, fs:0.77637 (r=0.929,p=0.667),  time:36.871, tt:774.285\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01328, lr:6.00e-02, fs:0.78261 (r=0.909,p=0.687),  time:36.826, tt:810.178\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00002, loss_test:0.01306, lr:6.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:36.812, tt:846.677\n",
      "Ep:23, loss:0.00002, loss_test:0.01287, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:36.711, tt:881.061\n",
      "Ep:24, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.78070 (r=0.899,p=0.690),  time:36.675, tt:916.884\n",
      "Ep:25, loss:0.00002, loss_test:0.01251, lr:6.00e-02, fs:0.78947 (r=0.909,p=0.698),  time:36.720, tt:954.731\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01237, lr:6.00e-02, fs:0.79295 (r=0.909,p=0.703),  time:36.670, tt:990.087\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01222, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:36.642, tt:1025.982\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01208, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:36.557, tt:1060.163\n",
      "Ep:29, loss:0.00002, loss_test:0.01194, lr:6.00e-02, fs:0.80531 (r=0.919,p=0.717),  time:36.510, tt:1095.287\n",
      "Ep:30, loss:0.00002, loss_test:0.01180, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:36.502, tt:1131.576\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01164, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:36.446, tt:1166.265\n",
      "Ep:32, loss:0.00002, loss_test:0.01154, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:36.368, tt:1200.153\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.01145, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:36.333, tt:1235.313\n",
      "Ep:34, loss:0.00002, loss_test:0.01134, lr:6.00e-02, fs:0.81938 (r=0.939,p=0.727),  time:36.310, tt:1270.850\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01124, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:36.246, tt:1304.865\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01113, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:36.196, tt:1339.269\n",
      "Ep:37, loss:0.00002, loss_test:0.01103, lr:6.00e-02, fs:0.83186 (r=0.949,p=0.740),  time:36.115, tt:1372.356\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01093, lr:6.00e-02, fs:0.83929 (r=0.949,p=0.752),  time:36.114, tt:1408.463\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01085, lr:6.00e-02, fs:0.84305 (r=0.949,p=0.758),  time:36.137, tt:1445.470\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00002, loss_test:0.01077, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:36.113, tt:1480.618\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00001, loss_test:0.01070, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:36.132, tt:1517.552\n",
      "Ep:42, loss:0.00001, loss_test:0.01063, lr:6.00e-02, fs:0.85068 (r=0.949,p=0.770),  time:36.107, tt:1552.590\n",
      "Ep:43, loss:0.00001, loss_test:0.01053, lr:6.00e-02, fs:0.84685 (r=0.949,p=0.764),  time:36.075, tt:1587.314\n",
      "Ep:44, loss:0.00001, loss_test:0.01049, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:36.046, tt:1622.053\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00001, loss_test:0.01043, lr:6.00e-02, fs:0.85455 (r=0.949,p=0.777),  time:36.015, tt:1656.684\n",
      "Ep:46, loss:0.00001, loss_test:0.01036, lr:6.00e-02, fs:0.85845 (r=0.949,p=0.783),  time:36.010, tt:1692.475\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00001, loss_test:0.01030, lr:6.00e-02, fs:0.86239 (r=0.949,p=0.790),  time:35.978, tt:1726.953\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01027, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:35.958, tt:1761.960\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01020, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:35.963, tt:1798.156\n",
      "Ep:50, loss:0.00001, loss_test:0.01011, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.957, tt:1833.815\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01005, lr:6.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:35.941, tt:1868.938\n",
      "Ep:52, loss:0.00001, loss_test:0.01003, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.926, tt:1904.069\n",
      "Ep:53, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.929, tt:1940.176\n",
      "Ep:54, loss:0.00001, loss_test:0.00991, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.903, tt:1974.686\n",
      "Ep:55, loss:0.00001, loss_test:0.00989, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:35.939, tt:2012.587\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00001, loss_test:0.00985, lr:6.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:35.935, tt:2048.292\n",
      "Ep:57, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:35.897, tt:2081.999\n",
      "Ep:58, loss:0.00001, loss_test:0.00980, lr:6.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:35.898, tt:2117.959\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.00978, lr:6.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:35.907, tt:2154.450\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.00973, lr:6.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:35.902, tt:2190.044\n",
      "Ep:61, loss:0.00001, loss_test:0.00971, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.878, tt:2224.451\n",
      "Ep:62, loss:0.00001, loss_test:0.00967, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.854, tt:2258.791\n",
      "Ep:63, loss:0.00001, loss_test:0.00964, lr:6.00e-02, fs:0.88152 (r=0.939,p=0.830),  time:35.861, tt:2295.126\n",
      "Ep:64, loss:0.00001, loss_test:0.00960, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.852, tt:2330.368\n",
      "Ep:65, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.849, tt:2366.015\n",
      "Ep:66, loss:0.00001, loss_test:0.00961, lr:6.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:35.823, tt:2400.109\n",
      "Ep:67, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.841, tt:2437.181\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.881, tt:2475.781\n",
      "Ep:69, loss:0.00001, loss_test:0.00955, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.881, tt:2511.671\n",
      "Ep:70, loss:0.00001, loss_test:0.00956, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.897, tt:2548.697\n",
      "Ep:71, loss:0.00001, loss_test:0.00949, lr:6.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:35.873, tt:2582.851\n",
      "Ep:72, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.845, tt:2616.678\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.00952, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.840, tt:2652.128\n",
      "Ep:74, loss:0.00001, loss_test:0.00948, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.811, tt:2685.831\n",
      "Ep:75, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.787, tt:2719.834\n",
      "Ep:76, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.765, tt:2753.913\n",
      "Ep:77, loss:0.00001, loss_test:0.00943, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.753, tt:2788.709\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.89423 (r=0.939,p=0.853),  time:35.751, tt:2824.316\n",
      "Ep:79, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.751, tt:2860.049\n",
      "Ep:80, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:35.731, tt:2894.252\n",
      "Ep:81, loss:0.00001, loss_test:0.00948, lr:6.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:35.719, tt:2928.929\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.728, tt:2965.422\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.730, tt:3001.337\n",
      "Ep:84, loss:0.00001, loss_test:0.00949, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.724, tt:3036.557\n",
      "Ep:85, loss:0.00001, loss_test:0.00945, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.743, tt:3073.909\n",
      "Ep:86, loss:0.00001, loss_test:0.00946, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.747, tt:3110.002\n",
      "Ep:87, loss:0.00001, loss_test:0.00950, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.813, tt:3151.551\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00001, loss_test:0.00947, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.802, tt:3186.366\n",
      "Ep:89, loss:0.00001, loss_test:0.00954, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.806, tt:3222.530\n",
      "Ep:90, loss:0.00001, loss_test:0.00953, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.790, tt:3256.851\n",
      "Ep:91, loss:0.00001, loss_test:0.00951, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.766, tt:3290.509\n",
      "Ep:92, loss:0.00001, loss_test:0.00955, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.755, tt:3325.184\n",
      "Ep:93, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.736, tt:3359.148\n",
      "Ep:94, loss:0.00001, loss_test:0.00957, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.721, tt:3393.540\n",
      "Ep:95, loss:0.00001, loss_test:0.00958, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.712, tt:3428.375\n",
      "Ep:96, loss:0.00001, loss_test:0.00962, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.703, tt:3463.204\n",
      "Ep:97, loss:0.00000, loss_test:0.00964, lr:6.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.703, tt:3498.847\n",
      "Ep:98, loss:0.00000, loss_test:0.00963, lr:6.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.668, tt:3531.144\n",
      "Ep:99, loss:0.00000, loss_test:0.00967, lr:5.94e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.654, tt:3565.355\n",
      "Ep:100, loss:0.00000, loss_test:0.00969, lr:5.88e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.639, tt:3599.537\n",
      "Ep:101, loss:0.00000, loss_test:0.00968, lr:5.82e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.628, tt:3634.084\n",
      "Ep:102, loss:0.00000, loss_test:0.00972, lr:5.76e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.614, tt:3668.203\n",
      "Ep:103, loss:0.00000, loss_test:0.00977, lr:5.71e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.602, tt:3702.559\n",
      "Ep:104, loss:0.00000, loss_test:0.00975, lr:5.65e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.600, tt:3738.000\n",
      "Ep:105, loss:0.00000, loss_test:0.00977, lr:5.59e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.592, tt:3772.783\n",
      "Ep:106, loss:0.00000, loss_test:0.00981, lr:5.54e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.593, tt:3808.450\n",
      "Ep:107, loss:0.00000, loss_test:0.00981, lr:5.48e-02, fs:0.90821 (r=0.949,p=0.870),  time:35.593, tt:3844.033\n",
      "Ep:108, loss:0.00000, loss_test:0.00983, lr:5.43e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.592, tt:3879.537\n",
      "Ep:109, loss:0.00000, loss_test:0.00986, lr:5.37e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.598, tt:3915.737\n",
      "Ep:110, loss:0.00000, loss_test:0.00986, lr:5.32e-02, fs:0.91262 (r=0.949,p=0.879),  time:35.591, tt:3950.581\n",
      "Ep:111, loss:0.00000, loss_test:0.00993, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.575, tt:3984.412\n",
      "##########Best model found so far##########\n",
      "Ep:112, loss:0.00000, loss_test:0.00993, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.550, tt:4017.113\n",
      "Ep:113, loss:0.00000, loss_test:0.00992, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.538, tt:4051.386\n",
      "Ep:114, loss:0.00000, loss_test:0.00997, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.533, tt:4086.300\n",
      "Ep:115, loss:0.00000, loss_test:0.00997, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.518, tt:4120.095\n",
      "Ep:116, loss:0.00000, loss_test:0.01000, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.559, tt:4160.439\n",
      "Ep:117, loss:0.00000, loss_test:0.01004, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.558, tt:4195.894\n",
      "Ep:118, loss:0.00000, loss_test:0.01007, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.553, tt:4230.784\n",
      "Ep:119, loss:0.00000, loss_test:0.01006, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.561, tt:4267.351\n",
      "Ep:120, loss:0.00000, loss_test:0.01009, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.538, tt:4300.046\n",
      "Ep:121, loss:0.00000, loss_test:0.01011, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.537, tt:4335.526\n",
      "Ep:122, loss:0.00000, loss_test:0.01015, lr:5.27e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.535, tt:4370.828\n",
      "Ep:123, loss:0.00000, loss_test:0.01018, lr:5.21e-02, fs:0.92157 (r=0.949,p=0.895),  time:35.519, tt:4404.303\n",
      "Ep:124, loss:0.00000, loss_test:0.01018, lr:5.16e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.519, tt:4439.846\n",
      "Ep:125, loss:0.00000, loss_test:0.01022, lr:5.11e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.511, tt:4474.337\n",
      "Ep:126, loss:0.00000, loss_test:0.01021, lr:5.06e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.517, tt:4510.602\n",
      "Ep:127, loss:0.00000, loss_test:0.01026, lr:5.01e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.509, tt:4545.181\n",
      "Ep:128, loss:0.00000, loss_test:0.01027, lr:4.96e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.495, tt:4578.913\n",
      "Ep:129, loss:0.00000, loss_test:0.01029, lr:4.91e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.486, tt:4613.180\n",
      "Ep:130, loss:0.00000, loss_test:0.01034, lr:4.86e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.491, tt:4649.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.01032, lr:4.81e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.483, tt:4683.742\n",
      "Ep:132, loss:0.00000, loss_test:0.01035, lr:4.76e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.493, tt:4720.560\n",
      "Ep:133, loss:0.00000, loss_test:0.01042, lr:4.71e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.505, tt:4757.629\n",
      "Ep:134, loss:0.00000, loss_test:0.01036, lr:4.67e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.500, tt:4792.444\n",
      "Ep:135, loss:0.00000, loss_test:0.01042, lr:4.62e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.490, tt:4826.590\n",
      "Ep:136, loss:0.00000, loss_test:0.01046, lr:4.57e-02, fs:0.91089 (r=0.929,p=0.893),  time:35.473, tt:4859.767\n",
      "Ep:137, loss:0.00000, loss_test:0.01046, lr:4.53e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.475, tt:4895.557\n",
      "Ep:138, loss:0.00000, loss_test:0.01048, lr:4.48e-02, fs:0.91626 (r=0.939,p=0.894),  time:35.465, tt:4929.687\n",
      "Ep:139, loss:0.00000, loss_test:0.01053, lr:4.44e-02, fs:0.91089 (r=0.929,p=0.893),  time:35.457, tt:4963.945\n",
      "Ep:140, loss:0.00000, loss_test:0.01051, lr:4.39e-02, fs:0.90547 (r=0.919,p=0.892),  time:35.502, tt:5005.724\n",
      "Ep:141, loss:0.00000, loss_test:0.01052, lr:4.35e-02, fs:0.90547 (r=0.919,p=0.892),  time:35.487, tt:5039.163\n",
      "Ep:142, loss:0.00000, loss_test:0.01057, lr:4.31e-02, fs:0.89447 (r=0.899,p=0.890),  time:35.477, tt:5073.146\n",
      "Ep:143, loss:0.00000, loss_test:0.01057, lr:4.26e-02, fs:0.90547 (r=0.919,p=0.892),  time:35.452, tt:5105.151\n",
      "Ep:144, loss:0.00000, loss_test:0.01060, lr:4.22e-02, fs:0.90000 (r=0.909,p=0.891),  time:35.440, tt:5138.842\n",
      "Ep:145, loss:0.00000, loss_test:0.01063, lr:4.18e-02, fs:0.89899 (r=0.899,p=0.899),  time:35.432, tt:5173.099\n",
      "Ep:146, loss:0.00000, loss_test:0.01062, lr:4.14e-02, fs:0.89899 (r=0.899,p=0.899),  time:35.417, tt:5206.286\n",
      "Ep:147, loss:0.00000, loss_test:0.01064, lr:4.10e-02, fs:0.89340 (r=0.889,p=0.898),  time:35.423, tt:5242.534\n",
      "Ep:148, loss:0.00000, loss_test:0.01068, lr:4.05e-02, fs:0.88660 (r=0.869,p=0.905),  time:35.417, tt:5277.121\n",
      "Ep:149, loss:0.00000, loss_test:0.01069, lr:4.01e-02, fs:0.89231 (r=0.879,p=0.906),  time:35.405, tt:5310.796\n",
      "Ep:150, loss:0.00000, loss_test:0.01070, lr:3.97e-02, fs:0.88660 (r=0.869,p=0.905),  time:35.403, tt:5345.885\n",
      "Ep:151, loss:0.00000, loss_test:0.01071, lr:3.93e-02, fs:0.88660 (r=0.869,p=0.905),  time:35.402, tt:5381.164\n",
      "Ep:152, loss:0.00000, loss_test:0.01075, lr:3.89e-02, fs:0.88083 (r=0.859,p=0.904),  time:35.395, tt:5415.426\n",
      "Ep:153, loss:0.00000, loss_test:0.01075, lr:3.86e-02, fs:0.88542 (r=0.859,p=0.914),  time:35.389, tt:5449.849\n",
      "Ep:154, loss:0.00000, loss_test:0.01077, lr:3.82e-02, fs:0.87958 (r=0.848,p=0.913),  time:35.394, tt:5486.076\n",
      "Ep:155, loss:0.00000, loss_test:0.01081, lr:3.78e-02, fs:0.87368 (r=0.838,p=0.912),  time:35.379, tt:5519.126\n",
      "Ep:156, loss:0.00000, loss_test:0.01081, lr:3.74e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.371, tt:5553.302\n",
      "Ep:157, loss:0.00000, loss_test:0.01083, lr:3.70e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.367, tt:5587.966\n",
      "Ep:158, loss:0.00000, loss_test:0.01085, lr:3.67e-02, fs:0.86170 (r=0.818,p=0.910),  time:35.351, tt:5620.877\n",
      "Ep:159, loss:0.00000, loss_test:0.01087, lr:3.63e-02, fs:0.85561 (r=0.808,p=0.909),  time:35.351, tt:5656.123\n",
      "Ep:160, loss:0.00000, loss_test:0.01087, lr:3.59e-02, fs:0.85561 (r=0.808,p=0.909),  time:35.334, tt:5688.804\n",
      "Ep:161, loss:0.00000, loss_test:0.01089, lr:3.56e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.330, tt:5723.502\n",
      "Ep:162, loss:0.00000, loss_test:0.01089, lr:3.52e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.333, tt:5759.328\n",
      "Ep:163, loss:0.00000, loss_test:0.01092, lr:3.49e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.325, tt:5793.288\n",
      "Ep:164, loss:0.00000, loss_test:0.01094, lr:3.45e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.319, tt:5827.555\n",
      "Ep:165, loss:0.00000, loss_test:0.01092, lr:3.42e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.314, tt:5862.066\n",
      "Ep:166, loss:0.00000, loss_test:0.01098, lr:3.38e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.304, tt:5895.771\n",
      "Ep:167, loss:0.00000, loss_test:0.01098, lr:3.35e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.299, tt:5930.231\n",
      "Ep:168, loss:0.00000, loss_test:0.01098, lr:3.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.304, tt:5966.459\n",
      "Ep:169, loss:0.00000, loss_test:0.01100, lr:3.28e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.302, tt:6001.409\n",
      "Ep:170, loss:0.00000, loss_test:0.01103, lr:3.25e-02, fs:0.84946 (r=0.798,p=0.908),  time:35.300, tt:6036.361\n",
      "Ep:171, loss:0.00000, loss_test:0.01101, lr:3.22e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.295, tt:6070.704\n",
      "Ep:172, loss:0.00000, loss_test:0.01104, lr:3.19e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.287, tt:6104.609\n",
      "Ep:173, loss:0.00000, loss_test:0.01109, lr:3.15e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.272, tt:6137.315\n",
      "Ep:174, loss:0.00000, loss_test:0.01108, lr:3.12e-02, fs:0.84324 (r=0.788,p=0.907),  time:35.270, tt:6172.267\n",
      "Ep:175, loss:0.00000, loss_test:0.01106, lr:3.09e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.261, tt:6205.919\n",
      "Ep:176, loss:0.00000, loss_test:0.01110, lr:3.06e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.256, tt:6240.325\n",
      "Ep:177, loss:0.00000, loss_test:0.01110, lr:3.03e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.251, tt:6274.660\n",
      "Ep:178, loss:0.00000, loss_test:0.01110, lr:3.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.238, tt:6307.620\n",
      "Ep:179, loss:0.00000, loss_test:0.01114, lr:2.97e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.219, tt:6339.359\n",
      "Ep:180, loss:0.00000, loss_test:0.01115, lr:2.94e-02, fs:0.83696 (r=0.778,p=0.906),  time:35.202, tt:6371.553\n",
      "Ep:181, loss:0.00000, loss_test:0.01115, lr:2.91e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.188, tt:6404.188\n",
      "Ep:182, loss:0.00000, loss_test:0.01116, lr:2.88e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.182, tt:6438.218\n",
      "Ep:183, loss:0.00000, loss_test:0.01118, lr:2.85e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.175, tt:6472.122\n",
      "Ep:184, loss:0.00000, loss_test:0.01118, lr:2.82e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.166, tt:6505.686\n",
      "Ep:185, loss:0.00000, loss_test:0.01120, lr:2.80e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.161, tt:6539.858\n",
      "Ep:186, loss:0.00000, loss_test:0.01121, lr:2.77e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.149, tt:6572.940\n",
      "Ep:187, loss:0.00000, loss_test:0.01122, lr:2.74e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.147, tt:6607.667\n",
      "Ep:188, loss:0.00000, loss_test:0.01123, lr:2.71e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.145, tt:6642.415\n",
      "Ep:189, loss:0.00000, loss_test:0.01124, lr:2.69e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.158, tt:6680.018\n",
      "Ep:190, loss:0.00000, loss_test:0.01125, lr:2.66e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.154, tt:6714.326\n",
      "Ep:191, loss:0.00000, loss_test:0.01126, lr:2.63e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.148, tt:6748.362\n",
      "Ep:192, loss:0.00000, loss_test:0.01127, lr:2.61e-02, fs:0.83060 (r=0.768,p=0.905),  time:35.140, tt:6782.072\n",
      "Ep:193, loss:0.00000, loss_test:0.01128, lr:2.58e-02, fs:0.83516 (r=0.768,p=0.916),  time:35.140, tt:6817.147\n",
      "Ep:194, loss:0.00000, loss_test:0.01129, lr:2.55e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.145, tt:6853.249\n",
      "Ep:195, loss:0.00000, loss_test:0.01129, lr:2.53e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.141, tt:6887.591\n",
      "Ep:196, loss:0.00000, loss_test:0.01131, lr:2.50e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.132, tt:6920.946\n",
      "Ep:197, loss:0.00000, loss_test:0.01132, lr:2.48e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.119, tt:6953.538\n",
      "Ep:198, loss:0.00000, loss_test:0.01133, lr:2.45e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.111, tt:6987.174\n",
      "Ep:199, loss:0.00000, loss_test:0.01134, lr:2.43e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.107, tt:7021.425\n",
      "Ep:200, loss:0.00000, loss_test:0.01135, lr:2.40e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.104, tt:7055.880\n",
      "Ep:201, loss:0.00000, loss_test:0.01135, lr:2.38e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.106, tt:7091.343\n",
      "Ep:202, loss:0.00000, loss_test:0.01137, lr:2.36e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.113, tt:7127.891\n",
      "Ep:203, loss:0.00000, loss_test:0.01138, lr:2.33e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.109, tt:7162.150\n",
      "Ep:204, loss:0.00000, loss_test:0.01137, lr:2.31e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.101, tt:7195.803\n",
      "Ep:205, loss:0.00000, loss_test:0.01138, lr:2.29e-02, fs:0.82873 (r=0.758,p=0.915),  time:35.073, tt:7225.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00000, loss_test:0.01140, lr:2.26e-02, fs:0.83333 (r=0.758,p=0.926),  time:34.999, tt:7244.783\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00011, loss_test:0.03288, lr:1.00e-02, fs:0.62921 (r=0.566,p=0.709),  time:32.132, tt:32.132\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.02268, lr:1.00e-02, fs:0.61739 (r=0.717,p=0.542),  time:34.239, tt:68.478\n",
      "Ep:2, loss:0.00005, loss_test:0.02142, lr:1.00e-02, fs:0.65926 (r=0.899,p=0.520),  time:34.739, tt:104.217\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02247, lr:1.00e-02, fs:0.65965 (r=0.949,p=0.505),  time:34.707, tt:138.829\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02363, lr:1.00e-02, fs:0.66438 (r=0.980,p=0.503),  time:35.003, tt:175.013\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00005, loss_test:0.02438, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.202, tt:211.211\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00005, loss_test:0.02470, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.389, tt:247.724\n",
      "Ep:7, loss:0.00005, loss_test:0.02469, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.366, tt:282.931\n",
      "Ep:8, loss:0.00005, loss_test:0.02443, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.347, tt:318.119\n",
      "Ep:9, loss:0.00005, loss_test:0.02395, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:35.319, tt:353.190\n",
      "Ep:10, loss:0.00005, loss_test:0.02335, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:35.217, tt:387.390\n",
      "Ep:11, loss:0.00004, loss_test:0.02265, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:35.268, tt:423.214\n",
      "Ep:12, loss:0.00004, loss_test:0.02192, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:35.244, tt:458.173\n",
      "Ep:13, loss:0.00004, loss_test:0.02121, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:35.322, tt:494.512\n",
      "Ep:14, loss:0.00004, loss_test:0.02056, lr:1.00e-02, fs:0.66901 (r=0.960,p=0.514),  time:35.425, tt:531.375\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.02001, lr:1.00e-02, fs:0.67616 (r=0.960,p=0.522),  time:35.379, tt:566.056\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01955, lr:1.00e-02, fs:0.67870 (r=0.949,p=0.528),  time:35.423, tt:602.188\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01919, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:35.443, tt:637.967\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01891, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:35.430, tt:673.173\n",
      "Ep:19, loss:0.00004, loss_test:0.01869, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:35.447, tt:708.940\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01851, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.625, tt:748.116\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01835, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.662, tt:784.571\n",
      "Ep:22, loss:0.00004, loss_test:0.01822, lr:1.00e-02, fs:0.70543 (r=0.919,p=0.572),  time:35.676, tt:820.542\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00004, loss_test:0.01810, lr:1.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:35.613, tt:854.715\n",
      "Ep:24, loss:0.00004, loss_test:0.01801, lr:1.00e-02, fs:0.69231 (r=0.909,p=0.559),  time:35.546, tt:888.655\n",
      "Ep:25, loss:0.00004, loss_test:0.01792, lr:1.00e-02, fs:0.68966 (r=0.909,p=0.556),  time:35.512, tt:923.318\n",
      "Ep:26, loss:0.00004, loss_test:0.01783, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:35.552, tt:959.915\n",
      "Ep:27, loss:0.00004, loss_test:0.01773, lr:1.00e-02, fs:0.69434 (r=0.929,p=0.554),  time:35.556, tt:995.574\n",
      "Ep:28, loss:0.00004, loss_test:0.01762, lr:1.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:35.520, tt:1030.077\n",
      "Ep:29, loss:0.00003, loss_test:0.01749, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:35.463, tt:1063.897\n",
      "Ep:30, loss:0.00003, loss_test:0.01736, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.413, tt:1097.805\n",
      "Ep:31, loss:0.00003, loss_test:0.01724, lr:1.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:35.380, tt:1132.153\n",
      "Ep:32, loss:0.00003, loss_test:0.01712, lr:1.00e-02, fs:0.69261 (r=0.899,p=0.563),  time:35.391, tt:1167.907\n",
      "Ep:33, loss:0.00003, loss_test:0.01701, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:35.407, tt:1203.831\n",
      "Ep:34, loss:0.00003, loss_test:0.01691, lr:9.90e-03, fs:0.69531 (r=0.899,p=0.567),  time:35.399, tt:1238.954\n",
      "Ep:35, loss:0.00003, loss_test:0.01681, lr:9.80e-03, fs:0.70079 (r=0.899,p=0.574),  time:35.385, tt:1273.874\n",
      "Ep:36, loss:0.00003, loss_test:0.01671, lr:9.70e-03, fs:0.70356 (r=0.899,p=0.578),  time:35.414, tt:1310.328\n",
      "Ep:37, loss:0.00003, loss_test:0.01662, lr:9.61e-03, fs:0.70079 (r=0.899,p=0.574),  time:35.370, tt:1344.073\n",
      "Ep:38, loss:0.00003, loss_test:0.01653, lr:9.51e-03, fs:0.69804 (r=0.899,p=0.571),  time:35.369, tt:1379.379\n",
      "Ep:39, loss:0.00003, loss_test:0.01644, lr:9.41e-03, fs:0.70356 (r=0.899,p=0.578),  time:35.472, tt:1418.870\n",
      "Ep:40, loss:0.00003, loss_test:0.01636, lr:9.32e-03, fs:0.70635 (r=0.899,p=0.582),  time:35.440, tt:1453.021\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01627, lr:9.32e-03, fs:0.71146 (r=0.909,p=0.584),  time:35.421, tt:1487.676\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01619, lr:9.32e-03, fs:0.71146 (r=0.909,p=0.584),  time:35.420, tt:1523.072\n",
      "Ep:43, loss:0.00003, loss_test:0.01610, lr:9.32e-03, fs:0.71937 (r=0.919,p=0.591),  time:35.425, tt:1558.689\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01601, lr:9.32e-03, fs:0.72441 (r=0.929,p=0.594),  time:35.422, tt:1593.972\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00003, loss_test:0.01592, lr:9.32e-03, fs:0.72441 (r=0.929,p=0.594),  time:35.449, tt:1630.652\n",
      "Ep:46, loss:0.00003, loss_test:0.01583, lr:9.32e-03, fs:0.73518 (r=0.939,p=0.604),  time:35.448, tt:1666.075\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00003, loss_test:0.01575, lr:9.32e-03, fs:0.73518 (r=0.939,p=0.604),  time:35.432, tt:1700.734\n",
      "Ep:48, loss:0.00003, loss_test:0.01568, lr:9.32e-03, fs:0.73810 (r=0.939,p=0.608),  time:35.437, tt:1736.413\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00003, loss_test:0.01560, lr:9.32e-03, fs:0.74603 (r=0.949,p=0.614),  time:35.446, tt:1772.320\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00003, loss_test:0.01553, lr:9.32e-03, fs:0.75591 (r=0.970,p=0.619),  time:35.433, tt:1807.108\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00003, loss_test:0.01546, lr:9.32e-03, fs:0.75889 (r=0.970,p=0.623),  time:35.420, tt:1841.861\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00003, loss_test:0.01539, lr:9.32e-03, fs:0.76190 (r=0.970,p=0.627),  time:35.397, tt:1876.019\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01532, lr:9.32e-03, fs:0.76190 (r=0.970,p=0.627),  time:35.361, tt:1909.488\n",
      "Ep:54, loss:0.00003, loss_test:0.01526, lr:9.32e-03, fs:0.76190 (r=0.970,p=0.627),  time:35.345, tt:1943.962\n",
      "Ep:55, loss:0.00003, loss_test:0.01519, lr:9.32e-03, fs:0.76494 (r=0.970,p=0.632),  time:35.313, tt:1977.539\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.01513, lr:9.32e-03, fs:0.76800 (r=0.970,p=0.636),  time:35.310, tt:2012.654\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01506, lr:9.32e-03, fs:0.77108 (r=0.970,p=0.640),  time:35.296, tt:2047.188\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01500, lr:9.32e-03, fs:0.77108 (r=0.970,p=0.640),  time:35.299, tt:2082.629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.01493, lr:9.32e-03, fs:0.77733 (r=0.970,p=0.649),  time:35.300, tt:2118.020\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.01486, lr:9.32e-03, fs:0.77733 (r=0.970,p=0.649),  time:35.252, tt:2150.377\n",
      "Ep:61, loss:0.00003, loss_test:0.01479, lr:9.32e-03, fs:0.77733 (r=0.970,p=0.649),  time:35.259, tt:2186.059\n",
      "Ep:62, loss:0.00003, loss_test:0.01473, lr:9.32e-03, fs:0.78049 (r=0.970,p=0.653),  time:35.234, tt:2219.765\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.01466, lr:9.32e-03, fs:0.77733 (r=0.970,p=0.649),  time:35.271, tt:2257.318\n",
      "Ep:64, loss:0.00003, loss_test:0.01460, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.281, tt:2293.253\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00003, loss_test:0.01453, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.289, tt:2329.054\n",
      "Ep:66, loss:0.00003, loss_test:0.01447, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.308, tt:2365.641\n",
      "Ep:67, loss:0.00003, loss_test:0.01442, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.319, tt:2401.695\n",
      "Ep:68, loss:0.00003, loss_test:0.01436, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.317, tt:2436.907\n",
      "Ep:69, loss:0.00003, loss_test:0.01431, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.322, tt:2472.547\n",
      "Ep:70, loss:0.00003, loss_test:0.01425, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.330, tt:2508.455\n",
      "Ep:71, loss:0.00003, loss_test:0.01420, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.340, tt:2544.490\n",
      "Ep:72, loss:0.00003, loss_test:0.01414, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.351, tt:2580.634\n",
      "Ep:73, loss:0.00003, loss_test:0.01410, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.364, tt:2616.965\n",
      "Ep:74, loss:0.00003, loss_test:0.01404, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.392, tt:2654.377\n",
      "Ep:75, loss:0.00003, loss_test:0.01399, lr:9.32e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.401, tt:2690.443\n",
      "Ep:76, loss:0.00003, loss_test:0.01394, lr:9.23e-03, fs:0.78689 (r=0.970,p=0.662),  time:35.407, tt:2726.354\n",
      "Ep:77, loss:0.00003, loss_test:0.01390, lr:9.14e-03, fs:0.79675 (r=0.990,p=0.667),  time:35.412, tt:2762.153\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00003, loss_test:0.01385, lr:9.14e-03, fs:0.79675 (r=0.990,p=0.667),  time:35.420, tt:2798.153\n",
      "Ep:79, loss:0.00002, loss_test:0.01381, lr:9.14e-03, fs:0.79675 (r=0.990,p=0.667),  time:35.421, tt:2833.710\n",
      "Ep:80, loss:0.00002, loss_test:0.01377, lr:9.14e-03, fs:0.80000 (r=0.990,p=0.671),  time:35.414, tt:2868.504\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00002, loss_test:0.01372, lr:9.14e-03, fs:0.80328 (r=0.990,p=0.676),  time:35.425, tt:2904.875\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00002, loss_test:0.01368, lr:9.14e-03, fs:0.80328 (r=0.990,p=0.676),  time:35.422, tt:2939.993\n",
      "Ep:83, loss:0.00002, loss_test:0.01364, lr:9.14e-03, fs:0.80328 (r=0.990,p=0.676),  time:35.427, tt:2975.903\n",
      "Ep:84, loss:0.00002, loss_test:0.01360, lr:9.14e-03, fs:0.80992 (r=0.990,p=0.685),  time:35.435, tt:3011.978\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00002, loss_test:0.01356, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.437, tt:3047.600\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.01352, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.451, tt:3084.212\n",
      "Ep:87, loss:0.00002, loss_test:0.01348, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.466, tt:3121.027\n",
      "Ep:88, loss:0.00002, loss_test:0.01344, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.475, tt:3157.314\n",
      "Ep:89, loss:0.00002, loss_test:0.01341, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.462, tt:3191.612\n",
      "Ep:90, loss:0.00002, loss_test:0.01337, lr:9.14e-03, fs:0.81328 (r=0.990,p=0.690),  time:35.461, tt:3226.979\n",
      "Ep:91, loss:0.00002, loss_test:0.01334, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.466, tt:3262.866\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.01331, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.459, tt:3297.724\n",
      "Ep:93, loss:0.00002, loss_test:0.01327, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.470, tt:3334.176\n",
      "Ep:94, loss:0.00002, loss_test:0.01324, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.475, tt:3370.087\n",
      "Ep:95, loss:0.00002, loss_test:0.01321, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.466, tt:3404.730\n",
      "Ep:96, loss:0.00002, loss_test:0.01317, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.472, tt:3440.778\n",
      "Ep:97, loss:0.00002, loss_test:0.01314, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.479, tt:3476.901\n",
      "Ep:98, loss:0.00002, loss_test:0.01311, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.478, tt:3512.299\n",
      "Ep:99, loss:0.00002, loss_test:0.01307, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.479, tt:3547.871\n",
      "Ep:100, loss:0.00002, loss_test:0.01304, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.469, tt:3582.364\n",
      "Ep:101, loss:0.00002, loss_test:0.01301, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.468, tt:3617.716\n",
      "Ep:102, loss:0.00002, loss_test:0.01298, lr:9.14e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.460, tt:3652.390\n",
      "Ep:103, loss:0.00002, loss_test:0.01296, lr:9.04e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.459, tt:3687.785\n",
      "Ep:104, loss:0.00002, loss_test:0.01293, lr:8.95e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.466, tt:3723.893\n",
      "Ep:105, loss:0.00002, loss_test:0.01291, lr:8.86e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.459, tt:3758.651\n",
      "Ep:106, loss:0.00002, loss_test:0.01288, lr:8.78e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.455, tt:3793.650\n",
      "Ep:107, loss:0.00002, loss_test:0.01286, lr:8.69e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.457, tt:3829.336\n",
      "Ep:108, loss:0.00002, loss_test:0.01284, lr:8.60e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.455, tt:3864.583\n",
      "Ep:109, loss:0.00002, loss_test:0.01281, lr:8.51e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.458, tt:3900.418\n",
      "Ep:110, loss:0.00002, loss_test:0.01279, lr:8.43e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.461, tt:3936.218\n",
      "Ep:111, loss:0.00002, loss_test:0.01276, lr:8.35e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.471, tt:3972.746\n",
      "Ep:112, loss:0.00002, loss_test:0.01275, lr:8.26e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.469, tt:4007.965\n",
      "Ep:113, loss:0.00002, loss_test:0.01272, lr:8.18e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.465, tt:4043.046\n",
      "Ep:114, loss:0.00002, loss_test:0.01270, lr:8.10e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.451, tt:4076.869\n",
      "Ep:115, loss:0.00002, loss_test:0.01268, lr:8.02e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.451, tt:4112.362\n",
      "Ep:116, loss:0.00002, loss_test:0.01266, lr:7.94e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.459, tt:4148.754\n",
      "Ep:117, loss:0.00002, loss_test:0.01264, lr:7.86e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.463, tt:4184.600\n",
      "Ep:118, loss:0.00002, loss_test:0.01262, lr:7.78e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.460, tt:4219.684\n",
      "Ep:119, loss:0.00002, loss_test:0.01260, lr:7.70e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.451, tt:4254.072\n",
      "Ep:120, loss:0.00002, loss_test:0.01258, lr:7.62e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.441, tt:4288.407\n",
      "Ep:121, loss:0.00002, loss_test:0.01257, lr:7.55e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.441, tt:4323.763\n",
      "Ep:122, loss:0.00002, loss_test:0.01255, lr:7.47e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.445, tt:4359.743\n",
      "Ep:123, loss:0.00002, loss_test:0.01254, lr:7.40e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.440, tt:4394.558\n",
      "Ep:124, loss:0.00002, loss_test:0.01252, lr:7.32e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.442, tt:4430.244\n",
      "Ep:125, loss:0.00002, loss_test:0.01251, lr:7.25e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.444, tt:4465.984\n",
      "Ep:126, loss:0.00002, loss_test:0.01250, lr:7.18e-03, fs:0.81667 (r=0.990,p=0.695),  time:35.460, tt:4503.372\n",
      "Ep:127, loss:0.00002, loss_test:0.01249, lr:7.11e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.450, tt:4537.588\n",
      "Ep:128, loss:0.00002, loss_test:0.01248, lr:7.03e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.451, tt:4573.171\n",
      "Ep:129, loss:0.00002, loss_test:0.01246, lr:6.96e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.450, tt:4608.522\n",
      "Ep:130, loss:0.00002, loss_test:0.01244, lr:6.89e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.441, tt:4642.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00002, loss_test:0.01243, lr:6.83e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.444, tt:4678.612\n",
      "Ep:132, loss:0.00002, loss_test:0.01242, lr:6.76e-03, fs:0.80672 (r=0.970,p=0.691),  time:35.424, tt:4711.420\n",
      "Ep:133, loss:0.00002, loss_test:0.01242, lr:6.69e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.415, tt:4745.599\n",
      "Ep:134, loss:0.00002, loss_test:0.01240, lr:6.62e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.418, tt:4781.442\n",
      "Ep:135, loss:0.00002, loss_test:0.01239, lr:6.56e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.416, tt:4816.534\n",
      "Ep:136, loss:0.00002, loss_test:0.01238, lr:6.49e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.407, tt:4850.713\n",
      "Ep:137, loss:0.00002, loss_test:0.01237, lr:6.43e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.407, tt:4886.190\n",
      "Ep:138, loss:0.00002, loss_test:0.01236, lr:6.36e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.406, tt:4921.421\n",
      "Ep:139, loss:0.00002, loss_test:0.01236, lr:6.30e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.397, tt:4955.600\n",
      "Ep:140, loss:0.00002, loss_test:0.01235, lr:6.24e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.399, tt:4991.307\n",
      "Ep:141, loss:0.00002, loss_test:0.01233, lr:6.17e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.409, tt:5028.134\n",
      "Ep:142, loss:0.00002, loss_test:0.01232, lr:6.11e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.403, tt:5062.672\n",
      "Ep:143, loss:0.00002, loss_test:0.01232, lr:6.05e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.395, tt:5096.900\n",
      "Ep:144, loss:0.00002, loss_test:0.01231, lr:5.99e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.397, tt:5132.619\n",
      "Ep:145, loss:0.00002, loss_test:0.01230, lr:5.93e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.396, tt:5167.770\n",
      "Ep:146, loss:0.00002, loss_test:0.01229, lr:5.87e-03, fs:0.80508 (r=0.960,p=0.693),  time:35.389, tt:5202.182\n",
      "Ep:147, loss:0.00002, loss_test:0.01228, lr:5.81e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.396, tt:5238.626\n",
      "Ep:148, loss:0.00002, loss_test:0.01228, lr:5.75e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.401, tt:5274.814\n",
      "Ep:149, loss:0.00002, loss_test:0.01227, lr:5.70e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.410, tt:5311.479\n",
      "Ep:150, loss:0.00002, loss_test:0.01226, lr:5.64e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.417, tt:5348.005\n",
      "Ep:151, loss:0.00002, loss_test:0.01225, lr:5.58e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.408, tt:5382.067\n",
      "Ep:152, loss:0.00002, loss_test:0.01224, lr:5.53e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.405, tt:5416.931\n",
      "Ep:153, loss:0.00002, loss_test:0.01223, lr:5.47e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.412, tt:5453.506\n",
      "Ep:154, loss:0.00002, loss_test:0.01222, lr:5.42e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.399, tt:5486.881\n",
      "Ep:155, loss:0.00002, loss_test:0.01222, lr:5.36e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.397, tt:5521.869\n",
      "Ep:156, loss:0.00002, loss_test:0.01221, lr:5.31e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.394, tt:5556.850\n",
      "Ep:157, loss:0.00002, loss_test:0.01220, lr:5.26e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.388, tt:5591.317\n",
      "Ep:158, loss:0.00002, loss_test:0.01219, lr:5.20e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.385, tt:5626.251\n",
      "Ep:159, loss:0.00002, loss_test:0.01218, lr:5.15e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.398, tt:5663.695\n",
      "Ep:160, loss:0.00002, loss_test:0.01217, lr:5.10e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.396, tt:5698.703\n",
      "Ep:161, loss:0.00002, loss_test:0.01217, lr:5.05e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.391, tt:5733.302\n",
      "Ep:162, loss:0.00002, loss_test:0.01216, lr:5.00e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.392, tt:5768.828\n",
      "Ep:163, loss:0.00002, loss_test:0.01215, lr:4.95e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.386, tt:5803.295\n",
      "Ep:164, loss:0.00002, loss_test:0.01214, lr:4.90e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.380, tt:5837.667\n",
      "Ep:165, loss:0.00002, loss_test:0.01214, lr:4.85e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.378, tt:5872.726\n",
      "Ep:166, loss:0.00002, loss_test:0.01213, lr:4.80e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.382, tt:5908.864\n",
      "Ep:167, loss:0.00002, loss_test:0.01212, lr:4.75e-03, fs:0.80851 (r=0.960,p=0.699),  time:35.381, tt:5943.963\n",
      "Ep:168, loss:0.00002, loss_test:0.01212, lr:4.71e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.382, tt:5979.635\n",
      "Ep:169, loss:0.00002, loss_test:0.01211, lr:4.66e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.383, tt:6015.118\n",
      "Ep:170, loss:0.00002, loss_test:0.01210, lr:4.61e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.386, tt:6051.034\n",
      "Ep:171, loss:0.00002, loss_test:0.01210, lr:4.57e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.372, tt:6083.996\n",
      "Ep:172, loss:0.00002, loss_test:0.01209, lr:4.52e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.363, tt:6117.824\n",
      "Ep:173, loss:0.00002, loss_test:0.01208, lr:4.48e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.355, tt:6151.707\n",
      "Ep:174, loss:0.00002, loss_test:0.01207, lr:4.43e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.355, tt:6187.163\n",
      "Ep:175, loss:0.00002, loss_test:0.01207, lr:4.39e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.349, tt:6221.469\n",
      "Ep:176, loss:0.00002, loss_test:0.01206, lr:4.34e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.346, tt:6256.285\n",
      "Ep:177, loss:0.00002, loss_test:0.01206, lr:4.30e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.344, tt:6291.303\n",
      "Ep:178, loss:0.00002, loss_test:0.01205, lr:4.26e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.348, tt:6327.373\n",
      "Ep:179, loss:0.00002, loss_test:0.01205, lr:4.21e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.355, tt:6363.942\n",
      "Ep:180, loss:0.00002, loss_test:0.01204, lr:4.17e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.358, tt:6399.710\n",
      "Ep:181, loss:0.00002, loss_test:0.01204, lr:4.13e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.355, tt:6434.594\n",
      "Ep:182, loss:0.00002, loss_test:0.01203, lr:4.09e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.355, tt:6470.043\n",
      "Ep:183, loss:0.00002, loss_test:0.01203, lr:4.05e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.347, tt:6503.757\n",
      "Ep:184, loss:0.00002, loss_test:0.01202, lr:4.01e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.335, tt:6536.917\n",
      "Ep:185, loss:0.00002, loss_test:0.01202, lr:3.97e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.332, tt:6571.701\n",
      "Ep:186, loss:0.00002, loss_test:0.01201, lr:3.93e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.333, tt:6607.268\n",
      "Ep:187, loss:0.00002, loss_test:0.01201, lr:3.89e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.332, tt:6642.426\n",
      "Ep:188, loss:0.00002, loss_test:0.01200, lr:3.85e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.335, tt:6678.350\n",
      "Ep:189, loss:0.00002, loss_test:0.01199, lr:3.81e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.331, tt:6712.964\n",
      "Ep:190, loss:0.00002, loss_test:0.01199, lr:3.77e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.329, tt:6747.919\n",
      "Ep:191, loss:0.00002, loss_test:0.01198, lr:3.73e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.327, tt:6782.833\n",
      "Ep:192, loss:0.00002, loss_test:0.01198, lr:3.70e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.323, tt:6817.250\n",
      "Ep:193, loss:0.00002, loss_test:0.01197, lr:3.66e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.316, tt:6851.348\n",
      "Ep:194, loss:0.00002, loss_test:0.01196, lr:3.62e-03, fs:0.81197 (r=0.960,p=0.704),  time:35.319, tt:6887.163\n",
      "Ep:195, loss:0.00002, loss_test:0.01196, lr:3.59e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.315, tt:6921.731\n",
      "Ep:196, loss:0.00002, loss_test:0.01195, lr:3.55e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.313, tt:6956.671\n",
      "Ep:197, loss:0.00002, loss_test:0.01195, lr:3.52e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.312, tt:6991.717\n",
      "Ep:198, loss:0.00002, loss_test:0.01194, lr:3.48e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.316, tt:7027.840\n",
      "Ep:199, loss:0.00002, loss_test:0.01194, lr:3.45e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.316, tt:7063.198\n",
      "Ep:200, loss:0.00002, loss_test:0.01193, lr:3.41e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.313, tt:7097.893\n",
      "Ep:201, loss:0.00002, loss_test:0.01193, lr:3.38e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.308, tt:7132.296\n",
      "Ep:202, loss:0.00002, loss_test:0.01192, lr:3.34e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.317, tt:7169.327\n",
      "Ep:203, loss:0.00002, loss_test:0.01192, lr:3.31e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.321, tt:7205.422\n",
      "Ep:204, loss:0.00002, loss_test:0.01192, lr:3.28e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.312, tt:7238.933\n",
      "Ep:205, loss:0.00002, loss_test:0.01191, lr:3.24e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.268, tt:7265.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:206, loss:0.00002, loss_test:0.01191, lr:3.21e-03, fs:0.80687 (r=0.949,p=0.701),  time:35.238, tt:7294.231\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00010, loss_test:0.03213, lr:1.00e-02, fs:0.59459 (r=0.444,p=0.898),  time:34.138, tt:34.138\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00007, loss_test:0.02171, lr:1.00e-02, fs:0.61682 (r=0.667,p=0.574),  time:36.647, tt:73.294\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02004, lr:1.00e-02, fs:0.64234 (r=0.889,p=0.503),  time:37.193, tt:111.579\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.02117, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:37.582, tt:150.328\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.02238, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.121, tt:190.604\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.02317, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.001, tt:228.004\n",
      "Ep:6, loss:0.00004, loss_test:0.02352, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.206, tt:267.444\n",
      "Ep:7, loss:0.00005, loss_test:0.02351, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.066, tt:304.527\n",
      "Ep:8, loss:0.00004, loss_test:0.02322, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.254, tt:344.285\n",
      "Ep:9, loss:0.00004, loss_test:0.02275, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.391, tt:383.909\n",
      "Ep:10, loss:0.00004, loss_test:0.02215, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.493, tt:423.425\n",
      "Ep:11, loss:0.00004, loss_test:0.02150, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.671, tt:464.049\n",
      "Ep:12, loss:0.00004, loss_test:0.02081, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:38.590, tt:501.676\n",
      "Ep:13, loss:0.00004, loss_test:0.02013, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:38.600, tt:540.403\n",
      "Ep:14, loss:0.00004, loss_test:0.01952, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:38.605, tt:579.082\n",
      "Ep:15, loss:0.00004, loss_test:0.01899, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:38.602, tt:617.625\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00004, loss_test:0.01855, lr:1.00e-02, fs:0.68100 (r=0.960,p=0.528),  time:38.495, tt:654.418\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00004, loss_test:0.01820, lr:1.00e-02, fs:0.68635 (r=0.939,p=0.541),  time:38.558, tt:694.042\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.01791, lr:1.00e-02, fs:0.68679 (r=0.919,p=0.548),  time:38.593, tt:733.273\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.01767, lr:1.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:38.577, tt:771.544\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.01745, lr:1.00e-02, fs:0.68702 (r=0.909,p=0.552),  time:38.602, tt:810.639\n",
      "Ep:21, loss:0.00004, loss_test:0.01726, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:38.684, tt:851.039\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01712, lr:1.00e-02, fs:0.69466 (r=0.919,p=0.558),  time:38.635, tt:888.615\n",
      "Ep:23, loss:0.00003, loss_test:0.01700, lr:1.00e-02, fs:0.69202 (r=0.919,p=0.555),  time:38.673, tt:928.162\n",
      "Ep:24, loss:0.00003, loss_test:0.01691, lr:1.00e-02, fs:0.70189 (r=0.939,p=0.560),  time:38.628, tt:965.709\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01682, lr:1.00e-02, fs:0.70677 (r=0.949,p=0.563),  time:38.644, tt:1004.748\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01673, lr:1.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:38.706, tt:1045.063\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01663, lr:1.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:38.712, tt:1083.923\n",
      "Ep:28, loss:0.00003, loss_test:0.01653, lr:1.00e-02, fs:0.71161 (r=0.960,p=0.565),  time:38.647, tt:1120.751\n",
      "Ep:29, loss:0.00003, loss_test:0.01644, lr:1.00e-02, fs:0.71429 (r=0.960,p=0.569),  time:38.678, tt:1160.326\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.01635, lr:1.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:38.668, tt:1198.709\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.01626, lr:1.00e-02, fs:0.71698 (r=0.960,p=0.572),  time:38.717, tt:1238.954\n",
      "Ep:32, loss:0.00003, loss_test:0.01617, lr:1.00e-02, fs:0.72243 (r=0.960,p=0.579),  time:38.692, tt:1276.840\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01608, lr:1.00e-02, fs:0.72519 (r=0.960,p=0.583),  time:38.678, tt:1315.067\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01599, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:38.703, tt:1354.594\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.01591, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:38.721, tt:1393.955\n",
      "Ep:36, loss:0.00003, loss_test:0.01584, lr:1.00e-02, fs:0.73359 (r=0.960,p=0.594),  time:38.772, tt:1434.565\n",
      "Ep:37, loss:0.00003, loss_test:0.01576, lr:1.00e-02, fs:0.73930 (r=0.960,p=0.601),  time:38.793, tt:1474.128\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01569, lr:1.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:38.805, tt:1513.404\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01563, lr:1.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:38.857, tt:1554.283\n",
      "Ep:40, loss:0.00003, loss_test:0.01556, lr:1.00e-02, fs:0.74219 (r=0.960,p=0.605),  time:38.908, tt:1595.239\n",
      "Ep:41, loss:0.00003, loss_test:0.01550, lr:1.00e-02, fs:0.74708 (r=0.970,p=0.608),  time:38.921, tt:1634.663\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01545, lr:1.00e-02, fs:0.74708 (r=0.970,p=0.608),  time:38.915, tt:1673.326\n",
      "Ep:43, loss:0.00003, loss_test:0.01539, lr:1.00e-02, fs:0.75000 (r=0.970,p=0.611),  time:38.943, tt:1713.485\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00003, loss_test:0.01534, lr:1.00e-02, fs:0.74708 (r=0.970,p=0.608),  time:38.961, tt:1753.250\n",
      "Ep:45, loss:0.00003, loss_test:0.01528, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:38.976, tt:1792.900\n",
      "Ep:46, loss:0.00003, loss_test:0.01522, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:38.947, tt:1830.487\n",
      "Ep:47, loss:0.00003, loss_test:0.01517, lr:1.00e-02, fs:0.74016 (r=0.949,p=0.606),  time:38.957, tt:1869.944\n",
      "Ep:48, loss:0.00003, loss_test:0.01510, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:38.978, tt:1909.916\n",
      "Ep:49, loss:0.00003, loss_test:0.01505, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:39.002, tt:1950.078\n",
      "Ep:50, loss:0.00003, loss_test:0.01500, lr:1.00e-02, fs:0.74308 (r=0.949,p=0.610),  time:39.008, tt:1989.397\n",
      "Ep:51, loss:0.00003, loss_test:0.01495, lr:1.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:38.999, tt:2027.928\n",
      "Ep:52, loss:0.00003, loss_test:0.01490, lr:1.00e-02, fs:0.75200 (r=0.949,p=0.623),  time:38.992, tt:2066.560\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00003, loss_test:0.01485, lr:1.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:38.983, tt:2105.099\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.01480, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:38.964, tt:2143.028\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.01475, lr:1.00e-02, fs:0.75806 (r=0.949,p=0.631),  time:38.984, tt:2183.091\n",
      "Ep:56, loss:0.00003, loss_test:0.01471, lr:1.00e-02, fs:0.76113 (r=0.949,p=0.635),  time:39.001, tt:2223.060\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.01466, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:39.004, tt:2262.243\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00003, loss_test:0.01462, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:39.023, tt:2302.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00003, loss_test:0.01458, lr:1.00e-02, fs:0.76735 (r=0.949,p=0.644),  time:39.062, tt:2343.728\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00003, loss_test:0.01454, lr:1.00e-02, fs:0.76423 (r=0.949,p=0.639),  time:39.048, tt:2381.923\n",
      "Ep:61, loss:0.00003, loss_test:0.01450, lr:1.00e-02, fs:0.75720 (r=0.929,p=0.639),  time:39.064, tt:2421.983\n",
      "Ep:62, loss:0.00003, loss_test:0.01446, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:39.088, tt:2462.530\n",
      "Ep:63, loss:0.00003, loss_test:0.01442, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:39.078, tt:2500.976\n",
      "Ep:64, loss:0.00003, loss_test:0.01439, lr:1.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:39.109, tt:2542.091\n",
      "Ep:65, loss:0.00003, loss_test:0.01435, lr:1.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:39.189, tt:2586.492\n",
      "Ep:66, loss:0.00003, loss_test:0.01431, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:39.198, tt:2626.286\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00003, loss_test:0.01426, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:39.172, tt:2663.700\n",
      "Ep:68, loss:0.00003, loss_test:0.01422, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:39.188, tt:2704.004\n",
      "Ep:69, loss:0.00003, loss_test:0.01418, lr:1.00e-02, fs:0.77311 (r=0.929,p=0.662),  time:39.201, tt:2744.067\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00003, loss_test:0.01414, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:39.202, tt:2783.336\n",
      "Ep:71, loss:0.00002, loss_test:0.01410, lr:1.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:39.204, tt:2822.721\n",
      "Ep:72, loss:0.00002, loss_test:0.01405, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.220, tt:2863.060\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.01401, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.240, tt:2903.762\n",
      "Ep:74, loss:0.00002, loss_test:0.01397, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.259, tt:2944.397\n",
      "Ep:75, loss:0.00002, loss_test:0.01393, lr:1.00e-02, fs:0.78481 (r=0.939,p=0.674),  time:39.265, tt:2984.148\n",
      "Ep:76, loss:0.00002, loss_test:0.01390, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.285, tt:3024.956\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00002, loss_test:0.01387, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.285, tt:3064.217\n",
      "Ep:78, loss:0.00002, loss_test:0.01384, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.279, tt:3103.008\n",
      "Ep:79, loss:0.00002, loss_test:0.01381, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:39.268, tt:3141.472\n",
      "##########Best model found so far##########\n",
      "Ep:80, loss:0.00002, loss_test:0.01377, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:39.280, tt:3181.653\n",
      "Ep:81, loss:0.00002, loss_test:0.01374, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.284, tt:3221.275\n",
      "Ep:82, loss:0.00002, loss_test:0.01371, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.291, tt:3261.171\n",
      "Ep:83, loss:0.00002, loss_test:0.01367, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.292, tt:3300.501\n",
      "Ep:84, loss:0.00002, loss_test:0.01364, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.271, tt:3338.044\n",
      "Ep:85, loss:0.00002, loss_test:0.01361, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.258, tt:3376.221\n",
      "Ep:86, loss:0.00002, loss_test:0.01357, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.254, tt:3415.069\n",
      "Ep:87, loss:0.00002, loss_test:0.01354, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.239, tt:3452.996\n",
      "Ep:88, loss:0.00002, loss_test:0.01351, lr:1.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:39.224, tt:3490.968\n",
      "Ep:89, loss:0.00002, loss_test:0.01348, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:39.215, tt:3529.327\n",
      "Ep:90, loss:0.00002, loss_test:0.01345, lr:1.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:39.181, tt:3565.507\n",
      "Ep:91, loss:0.00002, loss_test:0.01343, lr:9.90e-03, fs:0.79487 (r=0.939,p=0.689),  time:39.177, tt:3604.282\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00002, loss_test:0.01340, lr:9.90e-03, fs:0.79487 (r=0.939,p=0.689),  time:39.165, tt:3642.335\n",
      "Ep:93, loss:0.00002, loss_test:0.01337, lr:9.90e-03, fs:0.79487 (r=0.939,p=0.689),  time:39.164, tt:3681.446\n",
      "Ep:94, loss:0.00002, loss_test:0.01335, lr:9.90e-03, fs:0.79828 (r=0.939,p=0.694),  time:39.153, tt:3719.566\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00002, loss_test:0.01332, lr:9.90e-03, fs:0.80172 (r=0.939,p=0.699),  time:39.175, tt:3760.773\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00002, loss_test:0.01329, lr:9.90e-03, fs:0.80172 (r=0.939,p=0.699),  time:39.172, tt:3799.662\n",
      "Ep:97, loss:0.00002, loss_test:0.01327, lr:9.90e-03, fs:0.80519 (r=0.939,p=0.705),  time:39.156, tt:3837.326\n",
      "##########Best model found so far##########\n",
      "Ep:98, loss:0.00002, loss_test:0.01324, lr:9.90e-03, fs:0.80519 (r=0.939,p=0.705),  time:39.142, tt:3875.033\n",
      "Ep:99, loss:0.00002, loss_test:0.01322, lr:9.90e-03, fs:0.80870 (r=0.939,p=0.710),  time:39.135, tt:3913.536\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00002, loss_test:0.01319, lr:9.90e-03, fs:0.80870 (r=0.939,p=0.710),  time:39.145, tt:3953.682\n",
      "Ep:101, loss:0.00002, loss_test:0.01317, lr:9.90e-03, fs:0.80870 (r=0.939,p=0.710),  time:39.147, tt:3992.974\n",
      "Ep:102, loss:0.00002, loss_test:0.01314, lr:9.90e-03, fs:0.80870 (r=0.939,p=0.710),  time:39.143, tt:4031.682\n",
      "Ep:103, loss:0.00002, loss_test:0.01312, lr:9.90e-03, fs:0.81223 (r=0.939,p=0.715),  time:39.115, tt:4067.975\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.01309, lr:9.90e-03, fs:0.81223 (r=0.939,p=0.715),  time:39.122, tt:4107.765\n",
      "Ep:105, loss:0.00002, loss_test:0.01307, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.119, tt:4146.624\n",
      "##########Best model found so far##########\n",
      "Ep:106, loss:0.00002, loss_test:0.01304, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.108, tt:4184.552\n",
      "Ep:107, loss:0.00002, loss_test:0.01302, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.117, tt:4224.679\n",
      "Ep:108, loss:0.00002, loss_test:0.01299, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.114, tt:4263.410\n",
      "Ep:109, loss:0.00002, loss_test:0.01297, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.108, tt:4301.873\n",
      "Ep:110, loss:0.00002, loss_test:0.01295, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.121, tt:4342.432\n",
      "Ep:111, loss:0.00002, loss_test:0.01293, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.126, tt:4382.136\n",
      "Ep:112, loss:0.00002, loss_test:0.01291, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.120, tt:4420.601\n",
      "Ep:113, loss:0.00002, loss_test:0.01289, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.109, tt:4458.409\n",
      "Ep:114, loss:0.00002, loss_test:0.01287, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.083, tt:4494.593\n",
      "Ep:115, loss:0.00002, loss_test:0.01285, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.070, tt:4532.151\n",
      "Ep:116, loss:0.00002, loss_test:0.01283, lr:9.90e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.069, tt:4571.095\n",
      "Ep:117, loss:0.00002, loss_test:0.01281, lr:9.80e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.057, tt:4608.703\n",
      "Ep:118, loss:0.00002, loss_test:0.01279, lr:9.70e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.029, tt:4644.483\n",
      "Ep:119, loss:0.00002, loss_test:0.01276, lr:9.61e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.026, tt:4683.115\n",
      "Ep:120, loss:0.00002, loss_test:0.01274, lr:9.51e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.015, tt:4720.778\n",
      "Ep:121, loss:0.00002, loss_test:0.01272, lr:9.41e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.042, tt:4763.102\n",
      "Ep:122, loss:0.00002, loss_test:0.01270, lr:9.32e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.052, tt:4803.368\n",
      "Ep:123, loss:0.00002, loss_test:0.01268, lr:9.23e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.054, tt:4842.751\n",
      "Ep:124, loss:0.00002, loss_test:0.01267, lr:9.14e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.042, tt:4880.252\n",
      "Ep:125, loss:0.00002, loss_test:0.01265, lr:9.04e-03, fs:0.81579 (r=0.939,p=0.721),  time:39.045, tt:4919.646\n",
      "Ep:126, loss:0.00002, loss_test:0.01264, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:39.048, tt:4959.053\n",
      "##########Best model found so far##########\n",
      "Ep:127, loss:0.00002, loss_test:0.01262, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:39.035, tt:4996.428\n",
      "Ep:128, loss:0.00002, loss_test:0.01261, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:39.012, tt:5032.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00002, loss_test:0.01259, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.999, tt:5069.810\n",
      "Ep:130, loss:0.00002, loss_test:0.01258, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.990, tt:5107.710\n",
      "Ep:131, loss:0.00002, loss_test:0.01256, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.980, tt:5145.409\n",
      "Ep:132, loss:0.00002, loss_test:0.01254, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.978, tt:5184.026\n",
      "Ep:133, loss:0.00002, loss_test:0.01253, lr:8.95e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.969, tt:5221.843\n",
      "Ep:134, loss:0.00002, loss_test:0.01251, lr:8.95e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.963, tt:5260.007\n",
      "Ep:135, loss:0.00002, loss_test:0.01250, lr:8.95e-03, fs:0.81579 (r=0.939,p=0.721),  time:38.968, tt:5299.618\n",
      "Ep:136, loss:0.00002, loss_test:0.01248, lr:8.95e-03, fs:0.81579 (r=0.939,p=0.721),  time:38.957, tt:5337.170\n",
      "Ep:137, loss:0.00002, loss_test:0.01246, lr:8.95e-03, fs:0.81579 (r=0.939,p=0.721),  time:38.939, tt:5373.580\n",
      "Ep:138, loss:0.00002, loss_test:0.01245, lr:8.86e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.942, tt:5412.972\n",
      "Ep:139, loss:0.00002, loss_test:0.01243, lr:8.78e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.943, tt:5452.040\n",
      "Ep:140, loss:0.00002, loss_test:0.01241, lr:8.69e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.936, tt:5490.015\n",
      "Ep:141, loss:0.00002, loss_test:0.01240, lr:8.60e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.929, tt:5527.877\n",
      "Ep:142, loss:0.00002, loss_test:0.01238, lr:8.51e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.923, tt:5566.048\n",
      "Ep:143, loss:0.00002, loss_test:0.01237, lr:8.43e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.925, tt:5605.263\n",
      "Ep:144, loss:0.00002, loss_test:0.01236, lr:8.35e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.928, tt:5644.566\n",
      "Ep:145, loss:0.00002, loss_test:0.01235, lr:8.26e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.932, tt:5684.024\n",
      "Ep:146, loss:0.00002, loss_test:0.01233, lr:8.18e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.929, tt:5722.515\n",
      "Ep:147, loss:0.00002, loss_test:0.01232, lr:8.10e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.932, tt:5761.970\n",
      "Ep:148, loss:0.00002, loss_test:0.01230, lr:8.02e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.943, tt:5802.562\n",
      "Ep:149, loss:0.00002, loss_test:0.01229, lr:7.94e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.940, tt:5840.955\n",
      "Ep:150, loss:0.00002, loss_test:0.01228, lr:7.86e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.936, tt:5879.398\n",
      "Ep:151, loss:0.00002, loss_test:0.01227, lr:7.78e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.937, tt:5918.432\n",
      "Ep:152, loss:0.00002, loss_test:0.01226, lr:7.70e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.935, tt:5957.119\n",
      "Ep:153, loss:0.00002, loss_test:0.01225, lr:7.62e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.948, tt:5998.054\n",
      "Ep:154, loss:0.00002, loss_test:0.01223, lr:7.55e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.943, tt:6036.093\n",
      "Ep:155, loss:0.00002, loss_test:0.01222, lr:7.47e-03, fs:0.81938 (r=0.939,p=0.727),  time:38.936, tt:6073.952\n",
      "Ep:156, loss:0.00002, loss_test:0.01221, lr:7.40e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.926, tt:6111.400\n",
      "Ep:157, loss:0.00002, loss_test:0.01220, lr:7.32e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.922, tt:6149.719\n",
      "Ep:158, loss:0.00002, loss_test:0.01219, lr:7.25e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.929, tt:6189.781\n",
      "Ep:159, loss:0.00002, loss_test:0.01219, lr:7.18e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.908, tt:6225.224\n",
      "Ep:160, loss:0.00002, loss_test:0.01218, lr:7.11e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.921, tt:6266.300\n",
      "Ep:161, loss:0.00002, loss_test:0.01217, lr:7.03e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.910, tt:6303.458\n",
      "Ep:162, loss:0.00002, loss_test:0.01216, lr:6.96e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.920, tt:6343.901\n",
      "Ep:163, loss:0.00002, loss_test:0.01215, lr:6.89e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.896, tt:6378.959\n",
      "##########Best model found so far##########\n",
      "Ep:164, loss:0.00002, loss_test:0.01214, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.901, tt:6418.634\n",
      "Ep:165, loss:0.00002, loss_test:0.01213, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.895, tt:6456.496\n",
      "Ep:166, loss:0.00002, loss_test:0.01212, lr:6.89e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.903, tt:6496.767\n",
      "Ep:167, loss:0.00002, loss_test:0.01211, lr:6.89e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.918, tt:6538.242\n",
      "Ep:168, loss:0.00002, loss_test:0.01210, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.920, tt:6577.450\n",
      "Ep:169, loss:0.00002, loss_test:0.01209, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.933, tt:6618.529\n",
      "Ep:170, loss:0.00002, loss_test:0.01209, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.921, tt:6655.460\n",
      "Ep:171, loss:0.00002, loss_test:0.01208, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.916, tt:6693.526\n",
      "Ep:172, loss:0.00002, loss_test:0.01207, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.917, tt:6732.581\n",
      "Ep:173, loss:0.00002, loss_test:0.01206, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.914, tt:6770.991\n",
      "Ep:174, loss:0.00002, loss_test:0.01205, lr:6.89e-03, fs:0.82301 (r=0.939,p=0.732),  time:38.918, tt:6810.694\n",
      "Ep:175, loss:0.00002, loss_test:0.01204, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.911, tt:6848.249\n",
      "##########Best model found so far##########\n",
      "Ep:176, loss:0.00002, loss_test:0.01203, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.900, tt:6885.292\n",
      "Ep:177, loss:0.00002, loss_test:0.01202, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.918, tt:6927.347\n",
      "Ep:178, loss:0.00002, loss_test:0.01202, lr:6.83e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.922, tt:6967.001\n",
      "Ep:179, loss:0.00002, loss_test:0.01201, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.919, tt:7005.364\n",
      "Ep:180, loss:0.00002, loss_test:0.01200, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.909, tt:7042.590\n",
      "Ep:181, loss:0.00002, loss_test:0.01199, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.906, tt:7080.869\n",
      "Ep:182, loss:0.00002, loss_test:0.01198, lr:6.83e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.898, tt:7118.392\n",
      "Ep:183, loss:0.00002, loss_test:0.01197, lr:6.83e-03, fs:0.82667 (r=0.939,p=0.738),  time:38.889, tt:7155.547\n",
      "Ep:184, loss:0.00002, loss_test:0.01197, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.893, tt:7195.184\n",
      "Ep:185, loss:0.00002, loss_test:0.01197, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.890, tt:7233.539\n",
      "Ep:186, loss:0.00002, loss_test:0.01195, lr:6.83e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.897, tt:7273.814\n",
      "Ep:187, loss:0.00002, loss_test:0.01195, lr:6.76e-03, fs:0.83036 (r=0.939,p=0.744),  time:38.912, tt:7315.425\n",
      "Ep:188, loss:0.00002, loss_test:0.01194, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.917, tt:7355.280\n",
      "##########Best model found so far##########\n",
      "Ep:189, loss:0.00001, loss_test:0.01194, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.921, tt:7394.999\n",
      "Ep:190, loss:0.00001, loss_test:0.01193, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.934, tt:7436.414\n",
      "Ep:191, loss:0.00001, loss_test:0.01192, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.934, tt:7475.328\n",
      "Ep:192, loss:0.00001, loss_test:0.01192, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.929, tt:7513.383\n",
      "Ep:193, loss:0.00001, loss_test:0.01191, lr:6.69e-03, fs:0.83784 (r=0.939,p=0.756),  time:38.913, tt:7549.083\n",
      "Ep:194, loss:0.00001, loss_test:0.01190, lr:6.69e-03, fs:0.84305 (r=0.949,p=0.758),  time:38.930, tt:7591.290\n",
      "##########Best model found so far##########\n",
      "Ep:195, loss:0.00001, loss_test:0.01189, lr:6.69e-03, fs:0.84305 (r=0.949,p=0.758),  time:38.926, tt:7629.477\n",
      "Ep:196, loss:0.00001, loss_test:0.01189, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.923, tt:7667.852\n",
      "##########Best model found so far##########\n",
      "Ep:197, loss:0.00001, loss_test:0.01188, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.916, tt:7705.287\n",
      "Ep:198, loss:0.00001, loss_test:0.01188, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.916, tt:7744.230\n",
      "Ep:199, loss:0.00001, loss_test:0.01187, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.914, tt:7782.886\n",
      "Ep:200, loss:0.00001, loss_test:0.01186, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.919, tt:7822.706\n",
      "Ep:201, loss:0.00001, loss_test:0.01186, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.921, tt:7862.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:202, loss:0.00001, loss_test:0.01185, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.917, tt:7900.111\n",
      "Ep:203, loss:0.00001, loss_test:0.01185, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.910, tt:7937.586\n",
      "Ep:204, loss:0.00001, loss_test:0.01184, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.901, tt:7974.798\n",
      "Ep:205, loss:0.00001, loss_test:0.01183, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.884, tt:8010.154\n",
      "Ep:206, loss:0.00001, loss_test:0.01183, lr:6.69e-03, fs:0.84685 (r=0.949,p=0.764),  time:38.829, tt:8037.589\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13934, lr:1.00e-02, fs:0.65517 (r=0.960,p=0.497),  time:31.239, tt:31.239\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13693, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:31.478, tt:62.956\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13274, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:31.306, tt:93.917\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00026, loss_test:0.12681, lr:1.00e-02, fs:0.68382 (r=0.939,p=0.538),  time:32.823, tt:131.290\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.12078, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:33.752, tt:168.759\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11611, lr:1.00e-02, fs:0.70732 (r=0.879,p=0.592),  time:34.378, tt:206.268\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11320, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:34.797, tt:243.577\n",
      "Ep:7, loss:0.00024, loss_test:0.11038, lr:1.00e-02, fs:0.69198 (r=0.828,p=0.594),  time:34.803, tt:278.422\n",
      "Ep:8, loss:0.00023, loss_test:0.10790, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:34.948, tt:314.536\n",
      "Ep:9, loss:0.00022, loss_test:0.10580, lr:1.00e-02, fs:0.72034 (r=0.859,p=0.620),  time:35.023, tt:350.233\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10432, lr:1.00e-02, fs:0.71489 (r=0.848,p=0.618),  time:35.108, tt:386.184\n",
      "Ep:11, loss:0.00021, loss_test:0.10235, lr:1.00e-02, fs:0.70435 (r=0.818,p=0.618),  time:35.290, tt:423.478\n",
      "Ep:12, loss:0.00020, loss_test:0.09998, lr:1.00e-02, fs:0.71366 (r=0.818,p=0.633),  time:35.533, tt:461.930\n",
      "Ep:13, loss:0.00020, loss_test:0.09833, lr:1.00e-02, fs:0.71616 (r=0.828,p=0.631),  time:35.499, tt:496.989\n",
      "Ep:14, loss:0.00019, loss_test:0.09622, lr:1.00e-02, fs:0.72566 (r=0.828,p=0.646),  time:35.586, tt:533.785\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.09408, lr:1.00e-02, fs:0.73543 (r=0.828,p=0.661),  time:35.769, tt:572.306\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09232, lr:1.00e-02, fs:0.73778 (r=0.838,p=0.659),  time:35.877, tt:609.910\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08961, lr:1.00e-02, fs:0.75229 (r=0.828,p=0.689),  time:35.901, tt:646.221\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08738, lr:1.00e-02, fs:0.75799 (r=0.838,p=0.692),  time:36.016, tt:684.309\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08643, lr:1.00e-02, fs:0.77679 (r=0.879,p=0.696),  time:36.081, tt:721.625\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08384, lr:1.00e-02, fs:0.78341 (r=0.859,p=0.720),  time:36.107, tt:758.251\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00015, loss_test:0.08323, lr:1.00e-02, fs:0.77982 (r=0.859,p=0.714),  time:36.087, tt:793.917\n",
      "Ep:22, loss:0.00015, loss_test:0.08158, lr:1.00e-02, fs:0.80374 (r=0.869,p=0.748),  time:36.110, tt:830.529\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07990, lr:1.00e-02, fs:0.79638 (r=0.889,p=0.721),  time:36.045, tt:865.075\n",
      "Ep:24, loss:0.00014, loss_test:0.07948, lr:1.00e-02, fs:0.80556 (r=0.879,p=0.744),  time:36.080, tt:901.999\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00013, loss_test:0.07843, lr:1.00e-02, fs:0.80000 (r=0.869,p=0.741),  time:36.088, tt:938.276\n",
      "Ep:26, loss:0.00013, loss_test:0.07758, lr:1.00e-02, fs:0.82028 (r=0.899,p=0.754),  time:36.079, tt:974.125\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07759, lr:1.00e-02, fs:0.82407 (r=0.899,p=0.761),  time:36.069, tt:1009.932\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00012, loss_test:0.07594, lr:1.00e-02, fs:0.82791 (r=0.899,p=0.767),  time:36.118, tt:1047.424\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07546, lr:1.00e-02, fs:0.82857 (r=0.879,p=0.784),  time:36.102, tt:1083.047\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.07477, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:36.165, tt:1121.101\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00011, loss_test:0.07492, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:36.197, tt:1158.318\n",
      "Ep:32, loss:0.00011, loss_test:0.07316, lr:1.00e-02, fs:0.84018 (r=0.929,p=0.767),  time:36.186, tt:1194.142\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00010, loss_test:0.07495, lr:1.00e-02, fs:0.82828 (r=0.828,p=0.828),  time:36.174, tt:1229.933\n",
      "Ep:34, loss:0.00010, loss_test:0.07402, lr:1.00e-02, fs:0.83556 (r=0.949,p=0.746),  time:36.201, tt:1267.050\n",
      "Ep:35, loss:0.00010, loss_test:0.07305, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:36.206, tt:1303.410\n",
      "Ep:36, loss:0.00009, loss_test:0.07192, lr:1.00e-02, fs:0.83962 (r=0.899,p=0.788),  time:36.244, tt:1341.025\n",
      "Ep:37, loss:0.00009, loss_test:0.07247, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:36.248, tt:1377.428\n",
      "Ep:38, loss:0.00008, loss_test:0.07180, lr:1.00e-02, fs:0.81773 (r=0.838,p=0.798),  time:36.280, tt:1414.936\n",
      "Ep:39, loss:0.00008, loss_test:0.07127, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:36.293, tt:1451.735\n",
      "Ep:40, loss:0.00008, loss_test:0.07114, lr:1.00e-02, fs:0.82587 (r=0.838,p=0.814),  time:36.277, tt:1487.342\n",
      "Ep:41, loss:0.00007, loss_test:0.07023, lr:1.00e-02, fs:0.84058 (r=0.879,p=0.806),  time:36.355, tt:1526.928\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.06977, lr:1.00e-02, fs:0.83902 (r=0.869,p=0.811),  time:36.353, tt:1563.160\n",
      "Ep:43, loss:0.00007, loss_test:0.07016, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:36.374, tt:1600.440\n",
      "Ep:44, loss:0.00007, loss_test:0.06983, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:36.424, tt:1639.079\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00007, loss_test:0.06859, lr:1.00e-02, fs:0.84729 (r=0.869,p=0.827),  time:36.397, tt:1674.278\n",
      "Ep:46, loss:0.00006, loss_test:0.06880, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:36.385, tt:1710.109\n",
      "Ep:47, loss:0.00006, loss_test:0.06740, lr:1.00e-02, fs:0.85308 (r=0.909,p=0.804),  time:36.385, tt:1746.461\n",
      "Ep:48, loss:0.00006, loss_test:0.06740, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:36.387, tt:1782.946\n",
      "Ep:49, loss:0.00006, loss_test:0.07041, lr:1.00e-02, fs:0.86275 (r=0.889,p=0.838),  time:36.403, tt:1820.157\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.06762, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:36.421, tt:1857.464\n",
      "Ep:51, loss:0.00006, loss_test:0.06520, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:36.439, tt:1894.825\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.07030, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.413, tt:1929.905\n",
      "Ep:53, loss:0.00006, loss_test:0.06611, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:36.391, tt:1965.110\n",
      "Ep:54, loss:0.00006, loss_test:0.06208, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:36.410, tt:2002.532\n",
      "Ep:55, loss:0.00005, loss_test:0.06409, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.414, tt:2039.207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:56, loss:0.00005, loss_test:0.06487, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:36.406, tt:2075.167\n",
      "Ep:57, loss:0.00005, loss_test:0.06553, lr:1.00e-02, fs:0.83770 (r=0.808,p=0.870),  time:36.408, tt:2111.686\n",
      "Ep:58, loss:0.00004, loss_test:0.06407, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:36.431, tt:2149.445\n",
      "Ep:59, loss:0.00004, loss_test:0.06088, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:36.476, tt:2188.572\n",
      "Ep:60, loss:0.00004, loss_test:0.06111, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:36.501, tt:2226.590\n",
      "Ep:61, loss:0.00004, loss_test:0.06176, lr:1.00e-02, fs:0.87081 (r=0.919,p=0.827),  time:36.492, tt:2262.498\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00004, loss_test:0.06125, lr:1.00e-02, fs:0.82292 (r=0.798,p=0.849),  time:36.506, tt:2299.884\n",
      "Ep:63, loss:0.00004, loss_test:0.06139, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:36.531, tt:2338.007\n",
      "Ep:64, loss:0.00004, loss_test:0.06110, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:36.565, tt:2376.750\n",
      "Ep:65, loss:0.00004, loss_test:0.06284, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:36.574, tt:2413.863\n",
      "Ep:66, loss:0.00004, loss_test:0.05990, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:36.587, tt:2451.330\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.06206, lr:1.00e-02, fs:0.82723 (r=0.798,p=0.859),  time:36.575, tt:2487.106\n",
      "Ep:68, loss:0.00003, loss_test:0.06080, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:36.599, tt:2525.342\n",
      "Ep:69, loss:0.00003, loss_test:0.06058, lr:1.00e-02, fs:0.87000 (r=0.879,p=0.861),  time:36.630, tt:2564.117\n",
      "Ep:70, loss:0.00003, loss_test:0.05927, lr:1.00e-02, fs:0.83938 (r=0.818,p=0.862),  time:36.653, tt:2602.389\n",
      "Ep:71, loss:0.00003, loss_test:0.06103, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:36.681, tt:2641.023\n",
      "Ep:72, loss:0.00003, loss_test:0.05916, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:36.702, tt:2679.215\n",
      "Ep:73, loss:0.00003, loss_test:0.06163, lr:1.00e-02, fs:0.82979 (r=0.788,p=0.876),  time:36.692, tt:2715.222\n",
      "Ep:74, loss:0.00003, loss_test:0.05809, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:36.710, tt:2753.234\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00003, loss_test:0.06217, lr:1.00e-02, fs:0.83673 (r=0.828,p=0.845),  time:36.743, tt:2792.488\n",
      "Ep:76, loss:0.00003, loss_test:0.06127, lr:1.00e-02, fs:0.85417 (r=0.828,p=0.882),  time:36.778, tt:2831.904\n",
      "Ep:77, loss:0.00003, loss_test:0.06077, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:36.782, tt:2868.963\n",
      "Ep:78, loss:0.00003, loss_test:0.05803, lr:1.00e-02, fs:0.84375 (r=0.818,p=0.871),  time:36.796, tt:2906.864\n",
      "Ep:79, loss:0.00003, loss_test:0.06878, lr:1.00e-02, fs:0.84817 (r=0.818,p=0.880),  time:36.816, tt:2945.299\n",
      "Ep:80, loss:0.00004, loss_test:0.06124, lr:1.00e-02, fs:0.85581 (r=0.929,p=0.793),  time:36.840, tt:2984.043\n",
      "Ep:81, loss:0.00004, loss_test:0.06370, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:36.853, tt:3021.938\n",
      "Ep:82, loss:0.00003, loss_test:0.05971, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:36.874, tt:3060.517\n",
      "Ep:83, loss:0.00003, loss_test:0.05913, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:36.890, tt:3098.781\n",
      "Ep:84, loss:0.00003, loss_test:0.05963, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:36.901, tt:3136.560\n",
      "Ep:85, loss:0.00003, loss_test:0.05686, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:36.900, tt:3173.363\n",
      "Ep:86, loss:0.00003, loss_test:0.06022, lr:9.90e-03, fs:0.82105 (r=0.788,p=0.857),  time:36.908, tt:3210.954\n",
      "Ep:87, loss:0.00002, loss_test:0.05702, lr:9.80e-03, fs:0.85263 (r=0.818,p=0.890),  time:36.915, tt:3248.546\n",
      "Ep:88, loss:0.00002, loss_test:0.05625, lr:9.70e-03, fs:0.83422 (r=0.788,p=0.886),  time:36.936, tt:3287.316\n",
      "Ep:89, loss:0.00002, loss_test:0.05494, lr:9.61e-03, fs:0.85864 (r=0.828,p=0.891),  time:36.930, tt:3323.727\n",
      "Ep:90, loss:0.00002, loss_test:0.05809, lr:9.51e-03, fs:0.84211 (r=0.808,p=0.879),  time:36.953, tt:3362.747\n",
      "Ep:91, loss:0.00002, loss_test:0.05748, lr:9.41e-03, fs:0.83871 (r=0.788,p=0.897),  time:36.962, tt:3400.533\n",
      "Ep:92, loss:0.00002, loss_test:0.05485, lr:9.32e-03, fs:0.89899 (r=0.899,p=0.899),  time:36.971, tt:3438.350\n",
      "Ep:93, loss:0.00002, loss_test:0.05621, lr:9.23e-03, fs:0.84043 (r=0.798,p=0.888),  time:36.984, tt:3476.475\n",
      "Ep:94, loss:0.00002, loss_test:0.05534, lr:9.14e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.005, tt:3515.517\n",
      "Ep:95, loss:0.00002, loss_test:0.05547, lr:9.04e-03, fs:0.84375 (r=0.818,p=0.871),  time:37.004, tt:3552.362\n",
      "Ep:96, loss:0.00002, loss_test:0.05626, lr:8.95e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.015, tt:3590.481\n",
      "Ep:97, loss:0.00002, loss_test:0.05470, lr:8.86e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.022, tt:3628.131\n",
      "Ep:98, loss:0.00002, loss_test:0.05503, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.018, tt:3664.782\n",
      "Ep:99, loss:0.00002, loss_test:0.05730, lr:8.69e-03, fs:0.83422 (r=0.788,p=0.886),  time:37.029, tt:3702.881\n",
      "Ep:100, loss:0.00002, loss_test:0.05549, lr:8.60e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.031, tt:3740.172\n",
      "Ep:101, loss:0.00002, loss_test:0.05613, lr:8.51e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.028, tt:3776.812\n",
      "Ep:102, loss:0.00002, loss_test:0.05472, lr:8.43e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.036, tt:3814.699\n",
      "Ep:103, loss:0.00002, loss_test:0.05600, lr:8.35e-03, fs:0.84946 (r=0.798,p=0.908),  time:37.050, tt:3853.166\n",
      "Ep:104, loss:0.00002, loss_test:0.05495, lr:8.26e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.054, tt:3890.708\n",
      "Ep:105, loss:0.00001, loss_test:0.05507, lr:8.18e-03, fs:0.84043 (r=0.798,p=0.888),  time:37.056, tt:3927.944\n",
      "Ep:106, loss:0.00001, loss_test:0.05501, lr:8.10e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.065, tt:3965.922\n",
      "Ep:107, loss:0.00001, loss_test:0.05475, lr:8.02e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.078, tt:4004.464\n",
      "Ep:108, loss:0.00001, loss_test:0.05522, lr:7.94e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.084, tt:4042.183\n",
      "Ep:109, loss:0.00001, loss_test:0.05466, lr:7.86e-03, fs:0.84656 (r=0.808,p=0.889),  time:37.088, tt:4079.683\n",
      "Ep:110, loss:0.00001, loss_test:0.05552, lr:7.78e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.087, tt:4116.626\n",
      "Ep:111, loss:0.00001, loss_test:0.05506, lr:7.70e-03, fs:0.85263 (r=0.818,p=0.890),  time:37.077, tt:4152.582\n",
      "Ep:112, loss:0.00001, loss_test:0.05522, lr:7.62e-03, fs:0.83422 (r=0.788,p=0.886),  time:37.063, tt:4188.094\n",
      "Ep:113, loss:0.00001, loss_test:0.05622, lr:7.55e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.072, tt:4226.206\n",
      "Ep:114, loss:0.00001, loss_test:0.05550, lr:7.47e-03, fs:0.84492 (r=0.798,p=0.898),  time:37.066, tt:4262.633\n",
      "Ep:115, loss:0.00001, loss_test:0.05596, lr:7.40e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.084, tt:4301.771\n",
      "Ep:116, loss:0.00001, loss_test:0.05636, lr:7.32e-03, fs:0.83422 (r=0.788,p=0.886),  time:37.076, tt:4337.910\n",
      "Ep:117, loss:0.00001, loss_test:0.05510, lr:7.25e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.086, tt:4376.103\n",
      "Ep:118, loss:0.00001, loss_test:0.05614, lr:7.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.087, tt:4413.364\n",
      "Ep:119, loss:0.00001, loss_test:0.05603, lr:7.11e-03, fs:0.83422 (r=0.788,p=0.886),  time:37.085, tt:4450.156\n",
      "Ep:120, loss:0.00001, loss_test:0.05656, lr:7.03e-03, fs:0.86188 (r=0.788,p=0.951),  time:37.092, tt:4488.122\n",
      "Ep:121, loss:0.00001, loss_test:0.05659, lr:6.96e-03, fs:0.84043 (r=0.798,p=0.888),  time:37.103, tt:4526.532\n",
      "Ep:122, loss:0.00001, loss_test:0.05678, lr:6.89e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.108, tt:4564.247\n",
      "Ep:123, loss:0.00001, loss_test:0.05565, lr:6.83e-03, fs:0.84324 (r=0.788,p=0.907),  time:37.105, tt:4601.063\n",
      "Ep:124, loss:0.00001, loss_test:0.05662, lr:6.76e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.111, tt:4638.870\n",
      "Ep:125, loss:0.00001, loss_test:0.05708, lr:6.69e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.119, tt:4676.992\n",
      "Ep:126, loss:0.00001, loss_test:0.05659, lr:6.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.102, tt:4711.941\n",
      "Ep:127, loss:0.00001, loss_test:0.05713, lr:6.56e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.096, tt:4748.260\n",
      "Ep:128, loss:0.00001, loss_test:0.05709, lr:6.49e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.095, tt:4785.203\n",
      "Ep:129, loss:0.00001, loss_test:0.05743, lr:6.43e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.097, tt:4822.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00001, loss_test:0.05686, lr:6.36e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.113, tt:4861.859\n",
      "Ep:131, loss:0.00001, loss_test:0.05752, lr:6.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.119, tt:4899.743\n",
      "Ep:132, loss:0.00001, loss_test:0.05705, lr:6.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.106, tt:4935.101\n",
      "Ep:133, loss:0.00001, loss_test:0.05767, lr:6.17e-03, fs:0.84783 (r=0.788,p=0.918),  time:37.156, tt:4978.947\n",
      "Ep:134, loss:0.00001, loss_test:0.05649, lr:6.11e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.170, tt:5017.913\n",
      "Ep:135, loss:0.00001, loss_test:0.05722, lr:6.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.161, tt:5053.960\n",
      "Ep:136, loss:0.00001, loss_test:0.05805, lr:5.99e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.160, tt:5090.945\n",
      "Ep:137, loss:0.00001, loss_test:0.05747, lr:5.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.159, tt:5127.969\n",
      "Ep:138, loss:0.00001, loss_test:0.05781, lr:5.87e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.158, tt:5165.016\n",
      "Ep:139, loss:0.00001, loss_test:0.05758, lr:5.81e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.157, tt:5201.999\n",
      "Ep:140, loss:0.00001, loss_test:0.05795, lr:5.75e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.161, tt:5239.726\n",
      "Ep:141, loss:0.00001, loss_test:0.05761, lr:5.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.168, tt:5277.805\n",
      "Ep:142, loss:0.00001, loss_test:0.05789, lr:5.64e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.177, tt:5316.311\n",
      "Ep:143, loss:0.00001, loss_test:0.05741, lr:5.58e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.162, tt:5351.358\n",
      "Ep:144, loss:0.00001, loss_test:0.05804, lr:5.53e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.159, tt:5388.078\n",
      "Ep:145, loss:0.00001, loss_test:0.05842, lr:5.47e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.164, tt:5425.995\n",
      "Ep:146, loss:0.00001, loss_test:0.05786, lr:5.42e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.170, tt:5463.935\n",
      "Ep:147, loss:0.00001, loss_test:0.05913, lr:5.36e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.171, tt:5501.251\n",
      "Ep:148, loss:0.00001, loss_test:0.05820, lr:5.31e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.161, tt:5537.058\n",
      "Ep:149, loss:0.00001, loss_test:0.05800, lr:5.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.160, tt:5574.062\n",
      "Ep:150, loss:0.00001, loss_test:0.05836, lr:5.20e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.145, tt:5608.956\n",
      "Ep:151, loss:0.00001, loss_test:0.05861, lr:5.15e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.150, tt:5646.751\n",
      "Ep:152, loss:0.00001, loss_test:0.05826, lr:5.10e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.137, tt:5681.991\n",
      "Ep:153, loss:0.00001, loss_test:0.05829, lr:5.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.142, tt:5719.838\n",
      "Ep:154, loss:0.00001, loss_test:0.05823, lr:5.00e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.141, tt:5756.830\n",
      "Ep:155, loss:0.00001, loss_test:0.05845, lr:4.95e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.138, tt:5793.537\n",
      "Ep:156, loss:0.00001, loss_test:0.05846, lr:4.90e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.175, tt:5836.402\n",
      "Ep:157, loss:0.00001, loss_test:0.05861, lr:4.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.164, tt:5871.909\n",
      "Ep:158, loss:0.00001, loss_test:0.05827, lr:4.80e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.163, tt:5908.877\n",
      "Ep:159, loss:0.00001, loss_test:0.05856, lr:4.75e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.154, tt:5944.696\n",
      "Ep:160, loss:0.00001, loss_test:0.05891, lr:4.71e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.140, tt:5979.554\n",
      "Ep:161, loss:0.00001, loss_test:0.05831, lr:4.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.139, tt:6016.593\n",
      "Ep:162, loss:0.00001, loss_test:0.05903, lr:4.61e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.143, tt:6054.271\n",
      "Ep:163, loss:0.00001, loss_test:0.05864, lr:4.57e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.138, tt:6090.623\n",
      "Ep:164, loss:0.00001, loss_test:0.05876, lr:4.52e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.132, tt:6126.807\n",
      "Ep:165, loss:0.00001, loss_test:0.05874, lr:4.48e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.134, tt:6164.282\n",
      "Ep:166, loss:0.00001, loss_test:0.05854, lr:4.43e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.133, tt:6201.169\n",
      "Ep:167, loss:0.00001, loss_test:0.05852, lr:4.39e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.126, tt:6237.104\n",
      "Ep:168, loss:0.00001, loss_test:0.05925, lr:4.34e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.122, tt:6273.631\n",
      "Ep:169, loss:0.00001, loss_test:0.05926, lr:4.30e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.119, tt:6310.302\n",
      "Ep:170, loss:0.00001, loss_test:0.05877, lr:4.26e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.119, tt:6347.350\n",
      "Ep:171, loss:0.00001, loss_test:0.05840, lr:4.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.113, tt:6383.416\n",
      "Ep:172, loss:0.00001, loss_test:0.05953, lr:4.17e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.113, tt:6420.487\n",
      "Ep:173, loss:0.00001, loss_test:0.05879, lr:4.13e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.101, tt:6455.585\n",
      "Ep:174, loss:0.00001, loss_test:0.05945, lr:4.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.089, tt:6490.548\n",
      "Ep:175, loss:0.00001, loss_test:0.05864, lr:4.05e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.080, tt:6526.153\n",
      "Ep:176, loss:0.00001, loss_test:0.05894, lr:4.01e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.067, tt:6560.915\n",
      "Ep:177, loss:0.00001, loss_test:0.05888, lr:3.97e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.058, tt:6596.339\n",
      "Ep:178, loss:0.00001, loss_test:0.05912, lr:3.93e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.053, tt:6632.533\n",
      "Ep:179, loss:0.00001, loss_test:0.05909, lr:3.89e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.070, tt:6672.561\n",
      "Ep:180, loss:0.00001, loss_test:0.05897, lr:3.85e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.074, tt:6710.368\n",
      "Ep:181, loss:0.00001, loss_test:0.05928, lr:3.81e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.074, tt:6747.551\n",
      "Ep:182, loss:0.00001, loss_test:0.05894, lr:3.77e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.065, tt:6782.862\n",
      "Ep:183, loss:0.00001, loss_test:0.05930, lr:3.73e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.066, tt:6820.221\n",
      "Ep:184, loss:0.00001, loss_test:0.05914, lr:3.70e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.059, tt:6855.898\n",
      "Ep:185, loss:0.00001, loss_test:0.05917, lr:3.66e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.058, tt:6892.773\n",
      "Ep:186, loss:0.00001, loss_test:0.05889, lr:3.62e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.054, tt:6929.100\n",
      "Ep:187, loss:0.00001, loss_test:0.05900, lr:3.59e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.049, tt:6965.123\n",
      "Ep:188, loss:0.00001, loss_test:0.05918, lr:3.55e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.050, tt:7002.458\n",
      "Ep:189, loss:0.00001, loss_test:0.05908, lr:3.52e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.048, tt:7039.042\n",
      "Ep:190, loss:0.00001, loss_test:0.05939, lr:3.48e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.042, tt:7074.981\n",
      "Ep:191, loss:0.00001, loss_test:0.05919, lr:3.45e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.038, tt:7111.253\n",
      "Ep:192, loss:0.00001, loss_test:0.05958, lr:3.41e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.029, tt:7146.632\n",
      "Ep:193, loss:0.00001, loss_test:0.05926, lr:3.38e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.023, tt:7182.542\n",
      "Ep:194, loss:0.00001, loss_test:0.05936, lr:3.34e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.020, tt:7218.850\n",
      "Ep:195, loss:0.00001, loss_test:0.05993, lr:3.31e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.022, tt:7256.350\n",
      "Ep:196, loss:0.00001, loss_test:0.05900, lr:3.28e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.036, tt:7296.092\n",
      "Ep:197, loss:0.00001, loss_test:0.05959, lr:3.24e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.028, tt:7331.590\n",
      "Ep:198, loss:0.00001, loss_test:0.05953, lr:3.21e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.023, tt:7367.501\n",
      "Ep:199, loss:0.00001, loss_test:0.05943, lr:3.18e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.010, tt:7401.996\n",
      "Ep:200, loss:0.00001, loss_test:0.05941, lr:3.15e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.013, tt:7439.614\n",
      "Ep:201, loss:0.00001, loss_test:0.05908, lr:3.12e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.018, tt:7477.601\n",
      "Ep:202, loss:0.00001, loss_test:0.05937, lr:3.09e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.027, tt:7516.423\n",
      "Ep:203, loss:0.00000, loss_test:0.05975, lr:3.05e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.022, tt:7552.385\n",
      "Ep:204, loss:0.00000, loss_test:0.05938, lr:3.02e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.024, tt:7589.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.05944, lr:2.99e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.015, tt:7625.077\n",
      "Ep:206, loss:0.00000, loss_test:0.05977, lr:2.96e-03, fs:0.85714 (r=0.788,p=0.940),  time:37.005, tt:7660.128\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14460, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.166, tt:34.166\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14388, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:34.365, tt:68.730\n",
      "Ep:2, loss:0.00028, loss_test:0.14268, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.263, tt:99.788\n",
      "Ep:3, loss:0.00028, loss_test:0.14073, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:34.746, tt:138.986\n",
      "Ep:4, loss:0.00027, loss_test:0.13765, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:35.026, tt:175.131\n",
      "Ep:5, loss:0.00027, loss_test:0.13247, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:35.466, tt:212.794\n",
      "Ep:6, loss:0.00026, loss_test:0.12404, lr:1.00e-02, fs:0.64906 (r=0.869,p=0.518),  time:35.646, tt:249.522\n",
      "Ep:7, loss:0.00024, loss_test:0.11450, lr:1.00e-02, fs:0.68067 (r=0.818,p=0.583),  time:36.070, tt:288.557\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10814, lr:1.00e-02, fs:0.68571 (r=0.727,p=0.649),  time:36.325, tt:326.921\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10475, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:36.518, tt:365.184\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10482, lr:1.00e-02, fs:0.72414 (r=0.848,p=0.632),  time:36.633, tt:402.961\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10113, lr:1.00e-02, fs:0.72807 (r=0.838,p=0.643),  time:36.746, tt:440.949\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09654, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:36.853, tt:479.087\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09475, lr:1.00e-02, fs:0.73832 (r=0.798,p=0.687),  time:36.999, tt:517.985\n",
      "Ep:14, loss:0.00019, loss_test:0.09461, lr:1.00e-02, fs:0.74439 (r=0.838,p=0.669),  time:37.089, tt:556.336\n",
      "Ep:15, loss:0.00018, loss_test:0.09076, lr:1.00e-02, fs:0.76498 (r=0.838,p=0.703),  time:37.080, tt:593.286\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08820, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:37.048, tt:629.822\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08712, lr:1.00e-02, fs:0.78733 (r=0.879,p=0.713),  time:37.231, tt:670.154\n",
      "Ep:18, loss:0.00016, loss_test:0.08522, lr:1.00e-02, fs:0.79817 (r=0.879,p=0.731),  time:37.285, tt:708.421\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08320, lr:1.00e-02, fs:0.81308 (r=0.879,p=0.757),  time:37.223, tt:744.465\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.08187, lr:1.00e-02, fs:0.79821 (r=0.899,p=0.718),  time:37.192, tt:781.032\n",
      "Ep:21, loss:0.00015, loss_test:0.07848, lr:1.00e-02, fs:0.82243 (r=0.889,p=0.765),  time:37.267, tt:819.872\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.07734, lr:1.00e-02, fs:0.83333 (r=0.909,p=0.769),  time:37.257, tt:856.912\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.07549, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:37.238, tt:893.708\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.07458, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:37.280, tt:931.995\n",
      "Ep:25, loss:0.00013, loss_test:0.07355, lr:1.00e-02, fs:0.84793 (r=0.929,p=0.780),  time:37.279, tt:969.258\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.07283, lr:1.00e-02, fs:0.86792 (r=0.929,p=0.814),  time:37.287, tt:1006.753\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00012, loss_test:0.07205, lr:1.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:37.346, tt:1045.701\n",
      "Ep:28, loss:0.00011, loss_test:0.07121, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:37.375, tt:1083.884\n",
      "Ep:29, loss:0.00011, loss_test:0.07024, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:37.385, tt:1121.555\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.06899, lr:1.00e-02, fs:0.88372 (r=0.960,p=0.819),  time:37.588, tt:1165.237\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.06836, lr:1.00e-02, fs:0.87156 (r=0.960,p=0.798),  time:37.593, tt:1202.977\n",
      "Ep:32, loss:0.00010, loss_test:0.06807, lr:1.00e-02, fs:0.88679 (r=0.949,p=0.832),  time:37.599, tt:1240.780\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.06717, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:37.681, tt:1281.171\n",
      "Ep:34, loss:0.00009, loss_test:0.06737, lr:1.00e-02, fs:0.88995 (r=0.939,p=0.845),  time:37.839, tt:1324.358\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00009, loss_test:0.06603, lr:1.00e-02, fs:0.86636 (r=0.949,p=0.797),  time:37.868, tt:1363.234\n",
      "Ep:36, loss:0.00008, loss_test:0.06629, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:37.868, tt:1401.114\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00008, loss_test:0.06529, lr:1.00e-02, fs:0.88263 (r=0.949,p=0.825),  time:37.887, tt:1439.705\n",
      "Ep:38, loss:0.00008, loss_test:0.06349, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:37.899, tt:1478.065\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00008, loss_test:0.06440, lr:1.00e-02, fs:0.87558 (r=0.960,p=0.805),  time:37.889, tt:1515.564\n",
      "Ep:40, loss:0.00007, loss_test:0.06334, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:37.853, tt:1551.976\n",
      "Ep:41, loss:0.00007, loss_test:0.06182, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:37.837, tt:1589.174\n",
      "Ep:42, loss:0.00007, loss_test:0.06241, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:37.798, tt:1625.316\n",
      "Ep:43, loss:0.00007, loss_test:0.06086, lr:1.00e-02, fs:0.92157 (r=0.949,p=0.895),  time:37.749, tt:1660.944\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00006, loss_test:0.06147, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:37.783, tt:1700.230\n",
      "Ep:45, loss:0.00006, loss_test:0.05954, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:37.798, tt:1738.730\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.06112, lr:1.00e-02, fs:0.90732 (r=0.939,p=0.877),  time:37.808, tt:1776.975\n",
      "Ep:47, loss:0.00006, loss_test:0.05854, lr:1.00e-02, fs:0.92308 (r=0.970,p=0.881),  time:37.774, tt:1813.153\n",
      "Ep:48, loss:0.00006, loss_test:0.06165, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:37.868, tt:1855.534\n",
      "Ep:49, loss:0.00005, loss_test:0.05803, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:37.854, tt:1892.722\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00005, loss_test:0.06015, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:37.844, tt:1930.063\n",
      "Ep:51, loss:0.00005, loss_test:0.05798, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:37.911, tt:1971.349\n",
      "Ep:52, loss:0.00005, loss_test:0.05823, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:37.907, tt:2009.066\n",
      "Ep:53, loss:0.00005, loss_test:0.05802, lr:1.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:37.881, tt:2045.561\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00005, loss_test:0.05783, lr:1.00e-02, fs:0.93596 (r=0.960,p=0.913),  time:37.862, tt:2082.392\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00004, loss_test:0.05734, lr:1.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:37.833, tt:2118.648\n",
      "Ep:56, loss:0.00004, loss_test:0.05615, lr:1.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:37.845, tt:2157.152\n",
      "Ep:57, loss:0.00004, loss_test:0.05743, lr:1.00e-02, fs:0.90816 (r=0.899,p=0.918),  time:37.860, tt:2195.859\n",
      "Ep:58, loss:0.00004, loss_test:0.05711, lr:1.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:37.857, tt:2233.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00004, loss_test:0.05537, lr:1.00e-02, fs:0.93532 (r=0.949,p=0.922),  time:37.841, tt:2270.450\n",
      "Ep:60, loss:0.00004, loss_test:0.05587, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:37.833, tt:2307.805\n",
      "Ep:61, loss:0.00004, loss_test:0.05563, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:37.844, tt:2346.344\n",
      "Ep:62, loss:0.00003, loss_test:0.05624, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:37.864, tt:2385.451\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00003, loss_test:0.05554, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:37.877, tt:2424.153\n",
      "Ep:64, loss:0.00003, loss_test:0.05717, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:37.876, tt:2461.952\n",
      "Ep:65, loss:0.00003, loss_test:0.05443, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:37.836, tt:2497.163\n",
      "Ep:66, loss:0.00003, loss_test:0.05486, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:37.814, tt:2533.518\n",
      "Ep:67, loss:0.00003, loss_test:0.05535, lr:1.00e-02, fs:0.93939 (r=0.939,p=0.939),  time:37.810, tt:2571.068\n",
      "Ep:68, loss:0.00003, loss_test:0.05448, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:37.849, tt:2611.578\n",
      "Ep:69, loss:0.00003, loss_test:0.05703, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:37.865, tt:2650.554\n",
      "Ep:70, loss:0.00003, loss_test:0.05585, lr:1.00e-02, fs:0.88889 (r=0.848,p=0.933),  time:37.888, tt:2690.041\n",
      "Ep:71, loss:0.00003, loss_test:0.05587, lr:1.00e-02, fs:0.91192 (r=0.889,p=0.936),  time:37.871, tt:2726.725\n",
      "Ep:72, loss:0.00002, loss_test:0.05454, lr:1.00e-02, fs:0.91753 (r=0.899,p=0.937),  time:37.863, tt:2764.017\n",
      "Ep:73, loss:0.00002, loss_test:0.05538, lr:1.00e-02, fs:0.92308 (r=0.909,p=0.938),  time:37.885, tt:2803.492\n",
      "Ep:74, loss:0.00002, loss_test:0.05533, lr:9.90e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.888, tt:2841.568\n",
      "Ep:75, loss:0.00002, loss_test:0.05688, lr:9.80e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.925, tt:2882.318\n",
      "Ep:76, loss:0.00002, loss_test:0.05640, lr:9.70e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.933, tt:2920.841\n",
      "Ep:77, loss:0.00002, loss_test:0.05644, lr:9.61e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.951, tt:2960.144\n",
      "Ep:78, loss:0.00002, loss_test:0.05651, lr:9.51e-03, fs:0.87701 (r=0.828,p=0.932),  time:37.919, tt:2995.591\n",
      "Ep:79, loss:0.00002, loss_test:0.05563, lr:9.41e-03, fs:0.88889 (r=0.848,p=0.933),  time:37.932, tt:3034.538\n",
      "Ep:80, loss:0.00002, loss_test:0.05710, lr:9.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:37.952, tt:3074.103\n",
      "Ep:81, loss:0.00002, loss_test:0.05616, lr:9.23e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.959, tt:3112.642\n",
      "Ep:82, loss:0.00002, loss_test:0.05738, lr:9.14e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.958, tt:3150.542\n",
      "Ep:83, loss:0.00002, loss_test:0.05747, lr:9.04e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.970, tt:3189.439\n",
      "Ep:84, loss:0.00002, loss_test:0.05572, lr:8.95e-03, fs:0.88298 (r=0.838,p=0.933),  time:37.987, tt:3228.925\n",
      "Ep:85, loss:0.00002, loss_test:0.05931, lr:8.86e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.974, tt:3265.801\n",
      "Ep:86, loss:0.00002, loss_test:0.05686, lr:8.78e-03, fs:0.89474 (r=0.859,p=0.934),  time:37.970, tt:3303.392\n",
      "Ep:87, loss:0.00002, loss_test:0.05749, lr:8.69e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.961, tt:3340.611\n",
      "Ep:88, loss:0.00002, loss_test:0.05896, lr:8.60e-03, fs:0.85556 (r=0.778,p=0.951),  time:37.967, tt:3379.091\n",
      "Ep:89, loss:0.00002, loss_test:0.05782, lr:8.51e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.962, tt:3416.547\n",
      "Ep:90, loss:0.00002, loss_test:0.05977, lr:8.43e-03, fs:0.87701 (r=0.828,p=0.932),  time:37.961, tt:3454.446\n",
      "Ep:91, loss:0.00002, loss_test:0.05776, lr:8.35e-03, fs:0.85246 (r=0.788,p=0.929),  time:37.948, tt:3491.253\n",
      "Ep:92, loss:0.00001, loss_test:0.06016, lr:8.26e-03, fs:0.83146 (r=0.747,p=0.937),  time:37.952, tt:3529.568\n",
      "Ep:93, loss:0.00001, loss_test:0.05790, lr:8.18e-03, fs:0.82022 (r=0.737,p=0.924),  time:37.953, tt:3567.579\n",
      "Ep:94, loss:0.00001, loss_test:0.06041, lr:8.10e-03, fs:0.83799 (r=0.758,p=0.938),  time:37.957, tt:3605.901\n",
      "Ep:95, loss:0.00001, loss_test:0.05777, lr:8.02e-03, fs:0.82682 (r=0.747,p=0.925),  time:37.953, tt:3643.503\n",
      "Ep:96, loss:0.00001, loss_test:0.06233, lr:7.94e-03, fs:0.81818 (r=0.727,p=0.935),  time:37.947, tt:3680.887\n",
      "Ep:97, loss:0.00001, loss_test:0.05871, lr:7.86e-03, fs:0.84615 (r=0.778,p=0.928),  time:37.946, tt:3718.719\n",
      "Ep:98, loss:0.00001, loss_test:0.06027, lr:7.78e-03, fs:0.82486 (r=0.737,p=0.936),  time:37.937, tt:3755.725\n",
      "Ep:99, loss:0.00001, loss_test:0.05913, lr:7.70e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.922, tt:3792.185\n",
      "Ep:100, loss:0.00001, loss_test:0.05906, lr:7.62e-03, fs:0.81818 (r=0.727,p=0.935),  time:37.937, tt:3831.620\n",
      "Ep:101, loss:0.00001, loss_test:0.06028, lr:7.55e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.937, tt:3869.556\n",
      "Ep:102, loss:0.00001, loss_test:0.05936, lr:7.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.940, tt:3907.831\n",
      "Ep:103, loss:0.00001, loss_test:0.05889, lr:7.40e-03, fs:0.80682 (r=0.717,p=0.922),  time:37.944, tt:3946.141\n",
      "Ep:104, loss:0.00001, loss_test:0.06062, lr:7.32e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.950, tt:3984.788\n",
      "Ep:105, loss:0.00001, loss_test:0.05828, lr:7.25e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.950, tt:4022.692\n",
      "Ep:106, loss:0.00001, loss_test:0.05887, lr:7.18e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.978, tt:4063.632\n",
      "Ep:107, loss:0.00001, loss_test:0.05973, lr:7.11e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.970, tt:4100.729\n",
      "Ep:108, loss:0.00001, loss_test:0.05938, lr:7.03e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.970, tt:4138.784\n",
      "Ep:109, loss:0.00001, loss_test:0.05995, lr:6.96e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.971, tt:4176.759\n",
      "Ep:110, loss:0.00001, loss_test:0.06119, lr:6.89e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.977, tt:4215.455\n",
      "Ep:111, loss:0.00001, loss_test:0.05942, lr:6.83e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.977, tt:4253.414\n",
      "Ep:112, loss:0.00001, loss_test:0.05950, lr:6.76e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.975, tt:4291.221\n",
      "Ep:113, loss:0.00001, loss_test:0.06120, lr:6.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.981, tt:4329.780\n",
      "Ep:114, loss:0.00001, loss_test:0.06022, lr:6.62e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.985, tt:4368.279\n",
      "Ep:115, loss:0.00001, loss_test:0.06097, lr:6.56e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.983, tt:4405.994\n",
      "Ep:116, loss:0.00001, loss_test:0.05947, lr:6.49e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.991, tt:4444.970\n",
      "Ep:117, loss:0.00001, loss_test:0.06140, lr:6.43e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.985, tt:4482.173\n",
      "Ep:118, loss:0.00001, loss_test:0.06007, lr:6.36e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.975, tt:4519.028\n",
      "Ep:119, loss:0.00001, loss_test:0.06092, lr:6.30e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.983, tt:4557.988\n",
      "Ep:120, loss:0.00001, loss_test:0.06118, lr:6.24e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.988, tt:4596.495\n",
      "Ep:121, loss:0.00001, loss_test:0.06051, lr:6.17e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.983, tt:4633.956\n",
      "Ep:122, loss:0.00001, loss_test:0.06067, lr:6.11e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.992, tt:4672.971\n",
      "Ep:123, loss:0.00001, loss_test:0.06272, lr:6.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.982, tt:4709.826\n",
      "Ep:124, loss:0.00001, loss_test:0.06152, lr:5.99e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.002, tt:4750.201\n",
      "Ep:125, loss:0.00001, loss_test:0.06123, lr:5.93e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.993, tt:4787.117\n",
      "Ep:126, loss:0.00001, loss_test:0.06235, lr:5.87e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.983, tt:4823.841\n",
      "Ep:127, loss:0.00001, loss_test:0.06206, lr:5.81e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.991, tt:4862.820\n",
      "Ep:128, loss:0.00001, loss_test:0.06053, lr:5.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.984, tt:4899.963\n",
      "Ep:129, loss:0.00001, loss_test:0.06157, lr:5.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.979, tt:4937.279\n",
      "Ep:130, loss:0.00001, loss_test:0.06181, lr:5.64e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.991, tt:4976.878\n",
      "Ep:131, loss:0.00001, loss_test:0.06154, lr:5.58e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.005, tt:5016.706\n",
      "Ep:132, loss:0.00001, loss_test:0.06169, lr:5.53e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.007, tt:5054.886\n",
      "Ep:133, loss:0.00001, loss_test:0.06107, lr:5.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.010, tt:5093.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:134, loss:0.00001, loss_test:0.06258, lr:5.42e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.003, tt:5130.393\n",
      "Ep:135, loss:0.00001, loss_test:0.06113, lr:5.36e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.010, tt:5169.292\n",
      "Ep:136, loss:0.00001, loss_test:0.06192, lr:5.31e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.013, tt:5207.829\n",
      "Ep:137, loss:0.00001, loss_test:0.06324, lr:5.26e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.010, tt:5245.432\n",
      "Ep:138, loss:0.00001, loss_test:0.06160, lr:5.20e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.017, tt:5284.383\n",
      "Ep:139, loss:0.00001, loss_test:0.06130, lr:5.15e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.017, tt:5322.402\n",
      "Ep:140, loss:0.00001, loss_test:0.06201, lr:5.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.014, tt:5360.033\n",
      "Ep:141, loss:0.00001, loss_test:0.06225, lr:5.05e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.007, tt:5396.986\n",
      "Ep:142, loss:0.00000, loss_test:0.06133, lr:5.00e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.024, tt:5437.433\n",
      "Ep:143, loss:0.00000, loss_test:0.06255, lr:4.95e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.020, tt:5474.867\n",
      "Ep:144, loss:0.00000, loss_test:0.06213, lr:4.90e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.015, tt:5512.229\n",
      "Ep:145, loss:0.00000, loss_test:0.06086, lr:4.85e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.012, tt:5549.760\n",
      "Ep:146, loss:0.00000, loss_test:0.06158, lr:4.80e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.014, tt:5588.071\n",
      "Ep:147, loss:0.00000, loss_test:0.06240, lr:4.75e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.013, tt:5625.958\n",
      "Ep:148, loss:0.00000, loss_test:0.06170, lr:4.71e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.010, tt:5663.468\n",
      "Ep:149, loss:0.00000, loss_test:0.06084, lr:4.66e-03, fs:0.81143 (r=0.717,p=0.934),  time:38.003, tt:5700.441\n",
      "Ep:150, loss:0.00000, loss_test:0.06223, lr:4.61e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.996, tt:5737.400\n",
      "Ep:151, loss:0.00000, loss_test:0.06244, lr:4.57e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.991, tt:5774.576\n",
      "Ep:152, loss:0.00000, loss_test:0.06128, lr:4.52e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.990, tt:5812.423\n",
      "Ep:153, loss:0.00000, loss_test:0.06188, lr:4.48e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.969, tt:5847.207\n",
      "Ep:154, loss:0.00000, loss_test:0.06195, lr:4.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.956, tt:5883.258\n",
      "Ep:155, loss:0.00000, loss_test:0.06207, lr:4.39e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.942, tt:5918.934\n",
      "Ep:156, loss:0.00000, loss_test:0.06214, lr:4.34e-03, fs:0.81143 (r=0.717,p=0.934),  time:37.928, tt:5954.716\n",
      "Ep:157, loss:0.00000, loss_test:0.06094, lr:4.30e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.924, tt:5991.943\n",
      "Ep:158, loss:0.00000, loss_test:0.06178, lr:4.26e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.914, tt:6028.382\n",
      "Ep:159, loss:0.00000, loss_test:0.06215, lr:4.21e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.904, tt:6064.577\n",
      "Ep:160, loss:0.00000, loss_test:0.06147, lr:4.17e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.887, tt:6099.840\n",
      "Ep:161, loss:0.00000, loss_test:0.06138, lr:4.13e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.878, tt:6136.271\n",
      "Ep:162, loss:0.00000, loss_test:0.06126, lr:4.09e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.865, tt:6171.942\n",
      "Ep:163, loss:0.00000, loss_test:0.06136, lr:4.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.860, tt:6209.050\n",
      "Ep:164, loss:0.00000, loss_test:0.06156, lr:4.01e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.849, tt:6245.070\n",
      "Ep:165, loss:0.00000, loss_test:0.06163, lr:3.97e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.844, tt:6282.033\n",
      "Ep:166, loss:0.00000, loss_test:0.06200, lr:3.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.835, tt:6318.365\n",
      "Ep:167, loss:0.00000, loss_test:0.06139, lr:3.89e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.823, tt:6354.220\n",
      "Ep:168, loss:0.00000, loss_test:0.06137, lr:3.85e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.816, tt:6390.953\n",
      "Ep:169, loss:0.00000, loss_test:0.06136, lr:3.81e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.815, tt:6428.537\n",
      "Ep:170, loss:0.00000, loss_test:0.06172, lr:3.77e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.812, tt:6465.824\n",
      "Ep:171, loss:0.00000, loss_test:0.06167, lr:3.73e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.807, tt:6502.743\n",
      "Ep:172, loss:0.00000, loss_test:0.06092, lr:3.70e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.801, tt:6539.621\n",
      "Ep:173, loss:0.00000, loss_test:0.06161, lr:3.66e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.793, tt:6575.907\n",
      "Ep:174, loss:0.00000, loss_test:0.06228, lr:3.62e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.793, tt:6613.790\n",
      "Ep:175, loss:0.00000, loss_test:0.06177, lr:3.59e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.787, tt:6650.569\n",
      "Ep:176, loss:0.00000, loss_test:0.06109, lr:3.55e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.783, tt:6687.629\n",
      "Ep:177, loss:0.00000, loss_test:0.06138, lr:3.52e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.774, tt:6723.691\n",
      "Ep:178, loss:0.00000, loss_test:0.06194, lr:3.48e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.769, tt:6760.726\n",
      "Ep:179, loss:0.00000, loss_test:0.06155, lr:3.45e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.766, tt:6797.962\n",
      "Ep:180, loss:0.00000, loss_test:0.06134, lr:3.41e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.766, tt:6835.611\n",
      "Ep:181, loss:0.00000, loss_test:0.06184, lr:3.38e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.749, tt:6870.340\n",
      "Ep:182, loss:0.00000, loss_test:0.06194, lr:3.34e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.731, tt:6904.779\n",
      "Ep:183, loss:0.00000, loss_test:0.06138, lr:3.31e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.730, tt:6942.382\n",
      "Ep:184, loss:0.00000, loss_test:0.06117, lr:3.28e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.727, tt:6979.574\n",
      "Ep:185, loss:0.00000, loss_test:0.06224, lr:3.24e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.724, tt:7016.588\n",
      "Ep:186, loss:0.00000, loss_test:0.06180, lr:3.21e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.718, tt:7053.340\n",
      "Ep:187, loss:0.00000, loss_test:0.06103, lr:3.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.748, tt:7096.555\n",
      "Ep:188, loss:0.00000, loss_test:0.06178, lr:3.15e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.746, tt:7133.926\n",
      "Ep:189, loss:0.00000, loss_test:0.06217, lr:3.12e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.749, tt:7172.299\n",
      "Ep:190, loss:0.00000, loss_test:0.06170, lr:3.09e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.746, tt:7209.410\n",
      "Ep:191, loss:0.00000, loss_test:0.06135, lr:3.05e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.743, tt:7246.577\n",
      "Ep:192, loss:0.00000, loss_test:0.06134, lr:3.02e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.735, tt:7282.827\n",
      "Ep:193, loss:0.00000, loss_test:0.06151, lr:2.99e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.730, tt:7319.570\n",
      "Ep:194, loss:0.00000, loss_test:0.06216, lr:2.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.723, tt:7355.901\n",
      "Ep:195, loss:0.00000, loss_test:0.06156, lr:2.93e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.720, tt:7393.036\n",
      "Ep:196, loss:0.00000, loss_test:0.06104, lr:2.90e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.713, tt:7429.427\n",
      "Ep:197, loss:0.00000, loss_test:0.06151, lr:2.88e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.714, tt:7467.302\n",
      "Ep:198, loss:0.00000, loss_test:0.06226, lr:2.85e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.714, tt:7505.057\n",
      "Ep:199, loss:0.00000, loss_test:0.06177, lr:2.82e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.715, tt:7542.948\n",
      "Ep:200, loss:0.00000, loss_test:0.06122, lr:2.79e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.709, tt:7579.426\n",
      "Ep:201, loss:0.00000, loss_test:0.06124, lr:2.76e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.703, tt:7615.913\n",
      "Ep:202, loss:0.00000, loss_test:0.06146, lr:2.73e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.692, tt:7651.485\n",
      "Ep:203, loss:0.00000, loss_test:0.06150, lr:2.71e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.682, tt:7687.116\n",
      "Ep:204, loss:0.00000, loss_test:0.06146, lr:2.68e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.675, tt:7723.474\n",
      "Ep:205, loss:0.00000, loss_test:0.06151, lr:2.65e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.680, tt:7762.072\n",
      "Ep:206, loss:0.00000, loss_test:0.06149, lr:2.63e-03, fs:0.81609 (r=0.717,p=0.947),  time:37.675, tt:7798.727\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,207,cv_number,2,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00078, loss_test:0.01841, lr:1.00e-02, fs:0.68122 (r=0.897,p=0.549),  time:652.106, tt:652.106\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00058, loss_test:0.01698, lr:1.00e-02, fs:0.68868 (r=0.839,p=0.584),  time:656.348, tt:1312.696\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00049, loss_test:0.01635, lr:1.00e-02, fs:0.73000 (r=0.839,p=0.646),  time:658.872, tt:1976.616\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00043, loss_test:0.01573, lr:1.00e-02, fs:0.75648 (r=0.839,p=0.689),  time:658.309, tt:2633.235\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00038, loss_test:0.01532, lr:1.00e-02, fs:0.78075 (r=0.839,p=0.730),  time:658.207, tt:3291.036\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00034, loss_test:0.01509, lr:1.00e-02, fs:0.80000 (r=0.828,p=0.774),  time:657.214, tt:3943.282\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00031, loss_test:0.01500, lr:1.00e-02, fs:0.82286 (r=0.828,p=0.818),  time:656.302, tt:4594.111\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00028, loss_test:0.01505, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:657.317, tt:5258.536\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00025, loss_test:0.01505, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:656.661, tt:5909.951\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00022, loss_test:0.01518, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:656.802, tt:6568.022\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.01535, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:656.563, tt:7222.196\n",
      "Ep:11, loss:0.00019, loss_test:0.01556, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:656.065, tt:7872.774\n",
      "Ep:12, loss:0.00017, loss_test:0.01577, lr:1.00e-02, fs:0.87425 (r=0.839,p=0.912),  time:656.715, tt:8537.293\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00016, loss_test:0.01618, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:656.371, tt:9189.190\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00014, loss_test:0.01663, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:655.674, tt:9835.114\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00013, loss_test:0.01700, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:655.524, tt:10488.378\n",
      "Ep:16, loss:0.00012, loss_test:0.01726, lr:1.00e-02, fs:0.89571 (r=0.839,p=0.961),  time:655.669, tt:11146.377\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00011, loss_test:0.01782, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:655.561, tt:11800.097\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00010, loss_test:0.01858, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:655.828, tt:12460.736\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00010, loss_test:0.01920, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:656.427, tt:13128.538\n",
      "Ep:20, loss:0.00009, loss_test:0.01960, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:656.571, tt:13787.991\n",
      "Ep:21, loss:0.00009, loss_test:0.02033, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:656.919, tt:14452.225\n",
      "Ep:22, loss:0.00008, loss_test:0.02059, lr:1.00e-02, fs:0.90000 (r=0.828,p=0.986),  time:657.179, tt:15115.120\n",
      "Ep:23, loss:0.00008, loss_test:0.02130, lr:1.00e-02, fs:0.87179 (r=0.782,p=0.986),  time:657.885, tt:15789.239\n",
      "Ep:24, loss:0.00007, loss_test:0.02195, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:657.758, tt:16443.961\n",
      "Ep:25, loss:0.00007, loss_test:0.02255, lr:1.00e-02, fs:0.83221 (r=0.713,p=1.000),  time:658.007, tt:17108.193\n",
      "Ep:26, loss:0.00006, loss_test:0.02298, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:656.152, tt:17716.115\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00082, loss_test:0.01917, lr:1.00e-02, fs:0.66383 (r=0.897,p=0.527),  time:664.908, tt:664.908\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01617, lr:1.00e-02, fs:0.73488 (r=0.908,p=0.617),  time:668.163, tt:1336.326\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00052, loss_test:0.01494, lr:1.00e-02, fs:0.77228 (r=0.897,p=0.678),  time:670.402, tt:2011.205\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00045, loss_test:0.01448, lr:1.00e-02, fs:0.76289 (r=0.851,p=0.692),  time:671.345, tt:2685.380\n",
      "Ep:4, loss:0.00040, loss_test:0.01433, lr:1.00e-02, fs:0.78307 (r=0.851,p=0.725),  time:670.797, tt:3353.983\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00036, loss_test:0.01433, lr:1.00e-02, fs:0.79570 (r=0.851,p=0.747),  time:672.672, tt:4036.031\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00032, loss_test:0.01432, lr:1.00e-02, fs:0.81319 (r=0.851,p=0.779),  time:673.452, tt:4714.164\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00029, loss_test:0.01453, lr:1.00e-02, fs:0.83146 (r=0.851,p=0.813),  time:674.157, tt:5393.254\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00026, loss_test:0.01472, lr:1.00e-02, fs:0.84393 (r=0.839,p=0.849),  time:673.804, tt:6064.237\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00024, loss_test:0.01497, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:673.278, tt:6732.782\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.01511, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:672.844, tt:7401.287\n",
      "Ep:11, loss:0.00020, loss_test:0.01541, lr:1.00e-02, fs:0.87425 (r=0.839,p=0.912),  time:673.010, tt:8076.115\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.01585, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:672.221, tt:8738.871\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.01608, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:672.638, tt:9416.937\n",
      "Ep:14, loss:0.00016, loss_test:0.01642, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:672.954, tt:10094.305\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00014, loss_test:0.01694, lr:1.00e-02, fs:0.87342 (r=0.793,p=0.972),  time:672.521, tt:10760.332\n",
      "Ep:16, loss:0.00013, loss_test:0.01744, lr:1.00e-02, fs:0.84211 (r=0.736,p=0.985),  time:673.052, tt:11441.877\n",
      "Ep:17, loss:0.00012, loss_test:0.01778, lr:1.00e-02, fs:0.82895 (r=0.724,p=0.969),  time:673.565, tt:12124.173\n",
      "Ep:18, loss:0.00012, loss_test:0.01813, lr:1.00e-02, fs:0.83444 (r=0.724,p=0.984),  time:673.508, tt:12796.646\n",
      "Ep:19, loss:0.00011, loss_test:0.01868, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:674.176, tt:13483.524\n",
      "Ep:20, loss:0.00010, loss_test:0.01920, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:674.598, tt:14166.556\n",
      "Ep:21, loss:0.00010, loss_test:0.01961, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:674.721, tt:14843.854\n",
      "Ep:22, loss:0.00009, loss_test:0.02005, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:674.445, tt:15512.233\n",
      "Ep:23, loss:0.00009, loss_test:0.02048, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:674.134, tt:16179.209\n",
      "Ep:24, loss:0.00008, loss_test:0.02100, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:673.553, tt:16838.831\n",
      "Ep:25, loss:0.00008, loss_test:0.02137, lr:1.00e-02, fs:0.82667 (r=0.713,p=0.984),  time:672.296, tt:17479.684\n",
      "Ep:26, loss:0.00007, loss_test:0.02174, lr:9.90e-03, fs:0.82667 (r=0.713,p=0.984),  time:670.848, tt:18112.888\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00080, loss_test:0.01968, lr:1.00e-02, fs:0.67742 (r=0.966,p=0.522),  time:694.240, tt:694.240\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00062, loss_test:0.01841, lr:1.00e-02, fs:0.68161 (r=0.874,p=0.559),  time:694.195, tt:1388.390\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01777, lr:1.00e-02, fs:0.71698 (r=0.874,p=0.608),  time:696.138, tt:2088.415\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00052, loss_test:0.01734, lr:1.00e-02, fs:0.72637 (r=0.839,p=0.640),  time:697.166, tt:2788.663\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00049, loss_test:0.01701, lr:1.00e-02, fs:0.69519 (r=0.747,p=0.650),  time:695.689, tt:3478.447\n",
      "Ep:5, loss:0.00046, loss_test:0.01681, lr:1.00e-02, fs:0.70330 (r=0.736,p=0.674),  time:696.445, tt:4178.670\n",
      "Ep:6, loss:0.00043, loss_test:0.01663, lr:1.00e-02, fs:0.71508 (r=0.736,p=0.696),  time:696.958, tt:4878.705\n",
      "Ep:7, loss:0.00041, loss_test:0.01653, lr:1.00e-02, fs:0.70857 (r=0.713,p=0.705),  time:696.384, tt:5571.071\n",
      "Ep:8, loss:0.00039, loss_test:0.01639, lr:1.00e-02, fs:0.70520 (r=0.701,p=0.709),  time:695.861, tt:6262.746\n",
      "Ep:9, loss:0.00037, loss_test:0.01635, lr:1.00e-02, fs:0.71345 (r=0.701,p=0.726),  time:695.670, tt:6956.697\n",
      "Ep:10, loss:0.00035, loss_test:0.01634, lr:1.00e-02, fs:0.71765 (r=0.701,p=0.735),  time:696.389, tt:7660.276\n",
      "Ep:11, loss:0.00033, loss_test:0.01629, lr:1.00e-02, fs:0.73494 (r=0.701,p=0.772),  time:696.733, tt:8360.791\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00031, loss_test:0.01634, lr:1.00e-02, fs:0.73494 (r=0.701,p=0.772),  time:696.353, tt:9052.585\n",
      "Ep:13, loss:0.00030, loss_test:0.01639, lr:1.00e-02, fs:0.74390 (r=0.701,p=0.792),  time:696.339, tt:9748.749\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00028, loss_test:0.01647, lr:1.00e-02, fs:0.76250 (r=0.701,p=0.836),  time:696.555, tt:10448.331\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00027, loss_test:0.01643, lr:1.00e-02, fs:0.76250 (r=0.701,p=0.836),  time:697.076, tt:11153.210\n",
      "Ep:16, loss:0.00026, loss_test:0.01653, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:697.543, tt:11858.234\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00024, loss_test:0.01657, lr:1.00e-02, fs:0.77707 (r=0.701,p=0.871),  time:698.049, tt:12564.875\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00023, loss_test:0.01672, lr:1.00e-02, fs:0.78710 (r=0.701,p=0.897),  time:697.932, tt:13260.702\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00022, loss_test:0.01673, lr:1.00e-02, fs:0.79739 (r=0.701,p=0.924),  time:698.456, tt:13969.116\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00021, loss_test:0.01684, lr:1.00e-02, fs:0.80263 (r=0.701,p=0.938),  time:698.575, tt:14670.078\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00020, loss_test:0.01692, lr:1.00e-02, fs:0.80263 (r=0.701,p=0.938),  time:698.754, tt:15372.585\n",
      "Ep:22, loss:0.00019, loss_test:0.01709, lr:1.00e-02, fs:0.80263 (r=0.701,p=0.938),  time:698.366, tt:16062.426\n",
      "Ep:23, loss:0.00018, loss_test:0.01714, lr:1.00e-02, fs:0.80795 (r=0.701,p=0.953),  time:698.441, tt:16762.573\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00017, loss_test:0.01733, lr:1.00e-02, fs:0.80795 (r=0.701,p=0.953),  time:698.337, tt:17458.423\n",
      "Ep:25, loss:0.00016, loss_test:0.01748, lr:1.00e-02, fs:0.80795 (r=0.701,p=0.953),  time:697.604, tt:18137.698\n",
      "Ep:26, loss:0.00016, loss_test:0.01766, lr:1.00e-02, fs:0.80795 (r=0.701,p=0.953),  time:697.284, tt:18826.674\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.02008, lr:1.00e-02, fs:0.66935 (r=0.954,p=0.516),  time:692.338, tt:692.338\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00063, loss_test:0.01878, lr:1.00e-02, fs:0.66667 (r=0.851,p=0.548),  time:695.879, tt:1391.758\n",
      "Ep:2, loss:0.00059, loss_test:0.01808, lr:1.00e-02, fs:0.69159 (r=0.851,p=0.583),  time:694.370, tt:2083.110\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00055, loss_test:0.01761, lr:1.00e-02, fs:0.65672 (r=0.759,p=0.579),  time:694.460, tt:2777.840\n",
      "Ep:4, loss:0.00053, loss_test:0.01734, lr:1.00e-02, fs:0.69072 (r=0.770,p=0.626),  time:696.635, tt:3483.174\n",
      "Ep:5, loss:0.00050, loss_test:0.01717, lr:1.00e-02, fs:0.69474 (r=0.759,p=0.641),  time:706.404, tt:4238.424\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00048, loss_test:0.01700, lr:1.00e-02, fs:0.70588 (r=0.759,p=0.660),  time:706.728, tt:4947.099\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00046, loss_test:0.01692, lr:1.00e-02, fs:0.71351 (r=0.759,p=0.673),  time:705.940, tt:5647.521\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00044, loss_test:0.01684, lr:1.00e-02, fs:0.74444 (r=0.770,p=0.720),  time:704.165, tt:6337.481\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00043, loss_test:0.01683, lr:1.00e-02, fs:0.74157 (r=0.759,p=0.725),  time:704.652, tt:7046.517\n",
      "Ep:10, loss:0.00041, loss_test:0.01684, lr:1.00e-02, fs:0.74286 (r=0.747,p=0.739),  time:704.750, tt:7752.247\n",
      "Ep:11, loss:0.00040, loss_test:0.01685, lr:1.00e-02, fs:0.75145 (r=0.747,p=0.756),  time:704.239, tt:8450.873\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00038, loss_test:0.01685, lr:1.00e-02, fs:0.75145 (r=0.747,p=0.756),  time:704.003, tt:9152.044\n",
      "Ep:13, loss:0.00037, loss_test:0.01686, lr:1.00e-02, fs:0.74419 (r=0.736,p=0.753),  time:703.817, tt:9853.443\n",
      "Ep:14, loss:0.00036, loss_test:0.01691, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:703.627, tt:10554.398\n",
      "Ep:15, loss:0.00034, loss_test:0.01695, lr:1.00e-02, fs:0.74556 (r=0.724,p=0.768),  time:703.580, tt:11257.279\n",
      "Ep:16, loss:0.00033, loss_test:0.01696, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.709, tt:11963.050\n",
      "Ep:17, loss:0.00032, loss_test:0.01702, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.559, tt:12664.056\n",
      "Ep:18, loss:0.00031, loss_test:0.01708, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.940, tt:13374.852\n",
      "Ep:19, loss:0.00030, loss_test:0.01707, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.587, tt:14071.733\n",
      "Ep:20, loss:0.00029, loss_test:0.01721, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.273, tt:14768.738\n",
      "Ep:21, loss:0.00028, loss_test:0.01720, lr:1.00e-02, fs:0.74251 (r=0.713,p=0.775),  time:703.132, tt:15468.912\n",
      "Ep:22, loss:0.00027, loss_test:0.01725, lr:1.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:703.247, tt:16174.672\n",
      "Ep:23, loss:0.00026, loss_test:0.01746, lr:9.90e-03, fs:0.74847 (r=0.701,p=0.803),  time:702.705, tt:16864.911\n",
      "Ep:24, loss:0.00025, loss_test:0.01751, lr:9.80e-03, fs:0.74847 (r=0.701,p=0.803),  time:702.540, tt:17563.509\n",
      "Ep:25, loss:0.00025, loss_test:0.01763, lr:9.70e-03, fs:0.74847 (r=0.701,p=0.803),  time:702.971, tt:18277.253\n",
      "Ep:26, loss:0.00024, loss_test:0.01774, lr:9.61e-03, fs:0.74847 (r=0.701,p=0.803),  time:703.014, tt:18981.386\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00077, loss_test:0.01978, lr:1.00e-02, fs:0.66942 (r=0.931,p=0.523),  time:615.080, tt:615.080\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00061, loss_test:0.01872, lr:1.00e-02, fs:0.68142 (r=0.885,p=0.554),  time:606.365, tt:1212.730\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00056, loss_test:0.01825, lr:1.00e-02, fs:0.67633 (r=0.805,p=0.583),  time:602.952, tt:1808.856\n",
      "Ep:3, loss:0.00051, loss_test:0.01797, lr:1.00e-02, fs:0.70352 (r=0.805,p=0.625),  time:600.353, tt:2401.410\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00048, loss_test:0.01785, lr:1.00e-02, fs:0.71277 (r=0.770,p=0.663),  time:599.050, tt:2995.251\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00045, loss_test:0.01775, lr:1.00e-02, fs:0.74317 (r=0.782,p=0.708),  time:598.516, tt:3591.094\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00042, loss_test:0.01773, lr:1.00e-02, fs:0.75138 (r=0.782,p=0.723),  time:597.147, tt:4180.026\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.01768, lr:1.00e-02, fs:0.73743 (r=0.759,p=0.717),  time:597.353, tt:4778.828\n",
      "Ep:8, loss:0.00037, loss_test:0.01768, lr:1.00e-02, fs:0.75281 (r=0.770,p=0.736),  time:597.526, tt:5377.730\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00035, loss_test:0.01764, lr:1.00e-02, fs:0.75706 (r=0.770,p=0.744),  time:597.892, tt:5978.922\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00033, loss_test:0.01768, lr:1.00e-02, fs:0.75429 (r=0.759,p=0.750),  time:597.637, tt:6574.004\n",
      "Ep:11, loss:0.00031, loss_test:0.01760, lr:1.00e-02, fs:0.74713 (r=0.747,p=0.747),  time:597.659, tt:7171.907\n",
      "Ep:12, loss:0.00030, loss_test:0.01771, lr:1.00e-02, fs:0.74118 (r=0.724,p=0.759),  time:597.198, tt:7763.574\n",
      "Ep:13, loss:0.00028, loss_test:0.01781, lr:1.00e-02, fs:0.73810 (r=0.713,p=0.765),  time:597.803, tt:8369.242\n",
      "Ep:14, loss:0.00027, loss_test:0.01785, lr:1.00e-02, fs:0.75610 (r=0.713,p=0.805),  time:597.694, tt:8965.405\n",
      "Ep:15, loss:0.00025, loss_test:0.01792, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:597.878, tt:9566.055\n",
      "Ep:16, loss:0.00024, loss_test:0.01807, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:597.565, tt:10158.601\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00023, loss_test:0.01824, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:597.360, tt:10752.479\n",
      "Ep:18, loss:0.00022, loss_test:0.01824, lr:1.00e-02, fs:0.76730 (r=0.701,p=0.847),  time:597.202, tt:11346.837\n",
      "Ep:19, loss:0.00021, loss_test:0.01854, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:596.942, tt:11938.836\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00020, loss_test:0.01863, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:596.721, tt:12531.143\n",
      "Ep:21, loss:0.00019, loss_test:0.01876, lr:1.00e-02, fs:0.77215 (r=0.701,p=0.859),  time:596.596, tt:13125.122\n",
      "Ep:22, loss:0.00018, loss_test:0.01904, lr:1.00e-02, fs:0.76433 (r=0.690,p=0.857),  time:596.043, tt:13708.997\n",
      "Ep:23, loss:0.00017, loss_test:0.01922, lr:1.00e-02, fs:0.76923 (r=0.690,p=0.870),  time:592.746, tt:14225.905\n",
      "Ep:24, loss:0.00016, loss_test:0.01946, lr:1.00e-02, fs:0.77922 (r=0.690,p=0.896),  time:590.382, tt:14759.546\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00016, loss_test:0.01958, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:588.299, tt:15295.770\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00015, loss_test:0.01979, lr:1.00e-02, fs:0.78431 (r=0.690,p=0.909),  time:586.067, tt:15823.816\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00098, loss_test:0.02078, lr:1.00e-02, fs:0.67826 (r=0.897,p=0.545),  time:603.671, tt:603.671\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00070, loss_test:0.01618, lr:1.00e-02, fs:0.70536 (r=0.908,p=0.577),  time:599.368, tt:1198.736\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00057, loss_test:0.01445, lr:1.00e-02, fs:0.76279 (r=0.943,p=0.641),  time:600.060, tt:1800.180\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:3, loss:0.00048, loss_test:0.01404, lr:1.00e-02, fs:0.78818 (r=0.920,p=0.690),  time:600.439, tt:2401.755\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01435, lr:1.00e-02, fs:0.76684 (r=0.851,p=0.698),  time:600.072, tt:3000.362\n",
      "Ep:5, loss:0.00035, loss_test:0.01482, lr:1.00e-02, fs:0.78307 (r=0.851,p=0.725),  time:600.259, tt:3601.557\n",
      "Ep:6, loss:0.00030, loss_test:0.01540, lr:1.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:599.861, tt:4199.029\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00026, loss_test:0.01626, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:599.923, tt:4799.381\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.01749, lr:1.00e-02, fs:0.82486 (r=0.839,p=0.811),  time:600.402, tt:5403.615\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00019, loss_test:0.01865, lr:1.00e-02, fs:0.83237 (r=0.828,p=0.837),  time:600.560, tt:6005.599\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00016, loss_test:0.02025, lr:1.00e-02, fs:0.79268 (r=0.747,p=0.844),  time:600.314, tt:6603.453\n",
      "Ep:11, loss:0.00014, loss_test:0.02192, lr:1.00e-02, fs:0.77500 (r=0.713,p=0.849),  time:600.249, tt:7202.986\n",
      "Ep:12, loss:0.00012, loss_test:0.02330, lr:1.00e-02, fs:0.78481 (r=0.713,p=0.873),  time:600.595, tt:7807.741\n",
      "Ep:13, loss:0.00011, loss_test:0.02490, lr:1.00e-02, fs:0.78981 (r=0.713,p=0.886),  time:600.724, tt:8410.141\n",
      "Ep:14, loss:0.00009, loss_test:0.02669, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:600.269, tt:9004.028\n",
      "Ep:15, loss:0.00008, loss_test:0.02813, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:600.067, tt:9601.079\n",
      "Ep:16, loss:0.00007, loss_test:0.02986, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:600.066, tt:10201.127\n",
      "Ep:17, loss:0.00007, loss_test:0.03116, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:599.926, tt:10798.667\n",
      "Ep:18, loss:0.00006, loss_test:0.03277, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:598.811, tt:11377.414\n",
      "Ep:19, loss:0.00005, loss_test:0.03422, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:594.667, tt:11893.339\n",
      "Ep:20, loss:0.00005, loss_test:0.03497, lr:1.00e-02, fs:0.80000 (r=0.713,p=0.912),  time:587.490, tt:12337.284\n",
      "Ep:21, loss:0.00005, loss_test:0.03642, lr:9.90e-03, fs:0.80000 (r=0.713,p=0.912),  time:581.471, tt:12792.368\n",
      "Ep:22, loss:0.00004, loss_test:0.03748, lr:9.80e-03, fs:0.80519 (r=0.713,p=0.925),  time:572.293, tt:13162.738\n",
      "Ep:23, loss:0.00004, loss_test:0.03864, lr:9.70e-03, fs:0.81046 (r=0.713,p=0.939),  time:560.313, tt:13447.504\n",
      "Ep:24, loss:0.00004, loss_test:0.03996, lr:9.61e-03, fs:0.81046 (r=0.713,p=0.939),  time:547.379, tt:13684.476\n",
      "Ep:25, loss:0.00003, loss_test:0.04097, lr:9.51e-03, fs:0.81046 (r=0.713,p=0.939),  time:534.844, tt:13905.941\n",
      "Ep:26, loss:0.00003, loss_test:0.04196, lr:9.41e-03, fs:0.81046 (r=0.713,p=0.939),  time:521.443, tt:14078.963\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00075, loss_test:0.01815, lr:1.00e-02, fs:0.66957 (r=0.885,p=0.538),  time:705.194, tt:705.194\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00057, loss_test:0.01628, lr:1.00e-02, fs:0.73733 (r=0.920,p=0.615),  time:684.468, tt:1368.935\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00050, loss_test:0.01534, lr:1.00e-02, fs:0.78218 (r=0.908,p=0.687),  time:679.190, tt:2037.570\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00044, loss_test:0.01477, lr:1.00e-02, fs:0.81865 (r=0.908,p=0.745),  time:676.128, tt:2704.510\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00040, loss_test:0.01438, lr:1.00e-02, fs:0.79348 (r=0.839,p=0.753),  time:675.508, tt:3377.542\n",
      "Ep:5, loss:0.00036, loss_test:0.01423, lr:1.00e-02, fs:0.80220 (r=0.839,p=0.768),  time:673.350, tt:4040.101\n",
      "Ep:6, loss:0.00033, loss_test:0.01408, lr:1.00e-02, fs:0.80663 (r=0.839,p=0.777),  time:673.268, tt:4712.874\n",
      "Ep:7, loss:0.00031, loss_test:0.01396, lr:1.00e-02, fs:0.82955 (r=0.839,p=0.820),  time:672.877, tt:5383.015\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00028, loss_test:0.01394, lr:1.00e-02, fs:0.83908 (r=0.839,p=0.839),  time:673.094, tt:6057.848\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00026, loss_test:0.01396, lr:1.00e-02, fs:0.84884 (r=0.839,p=0.859),  time:677.301, tt:6773.012\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00024, loss_test:0.01400, lr:1.00e-02, fs:0.85380 (r=0.839,p=0.869),  time:685.292, tt:7538.211\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00023, loss_test:0.01393, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:691.556, tt:8298.675\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.01409, lr:1.00e-02, fs:0.85882 (r=0.839,p=0.880),  time:696.614, tt:9055.976\n",
      "Ep:13, loss:0.00020, loss_test:0.01421, lr:1.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:701.548, tt:9821.665\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.01430, lr:1.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:705.441, tt:10581.613\n",
      "Ep:15, loss:0.00017, loss_test:0.01441, lr:1.00e-02, fs:0.87952 (r=0.839,p=0.924),  time:708.915, tt:11342.644\n",
      "Ep:16, loss:0.00016, loss_test:0.01469, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:711.677, tt:12098.502\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.01482, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:714.601, tt:12862.821\n",
      "Ep:18, loss:0.00014, loss_test:0.01493, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:716.596, tt:13615.322\n",
      "Ep:19, loss:0.00013, loss_test:0.01520, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:718.615, tt:14372.292\n",
      "Ep:20, loss:0.00013, loss_test:0.01540, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:720.817, tt:15137.160\n",
      "Ep:21, loss:0.00012, loss_test:0.01563, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:722.341, tt:15891.511\n",
      "Ep:22, loss:0.00011, loss_test:0.01585, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:724.021, tt:16652.476\n",
      "Ep:23, loss:0.00011, loss_test:0.01604, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:725.630, tt:17415.109\n",
      "Ep:24, loss:0.00010, loss_test:0.01629, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:727.275, tt:18181.882\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00009, loss_test:0.01667, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:728.264, tt:18934.859\n",
      "Ep:26, loss:0.00009, loss_test:0.01677, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:728.903, tt:19680.391\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,27,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14458, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.083, tt:43.083\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.14369, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.151, tt:90.301\n",
      "Ep:2, loss:0.00001, loss_test:0.14214, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:45.799, tt:137.396\n",
      "Ep:3, loss:0.00001, loss_test:0.13965, lr:1.00e-02, fs:0.66926 (r=0.989,p=0.506),  time:46.715, tt:186.859\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00001, loss_test:0.13559, lr:1.00e-02, fs:0.65613 (r=0.954,p=0.500),  time:46.695, tt:233.474\n",
      "Ep:5, loss:0.00001, loss_test:0.12922, lr:1.00e-02, fs:0.66129 (r=0.943,p=0.509),  time:47.173, tt:283.038\n",
      "Ep:6, loss:0.00001, loss_test:0.11974, lr:1.00e-02, fs:0.67257 (r=0.874,p=0.547),  time:46.978, tt:328.848\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.10930, lr:1.00e-02, fs:0.72043 (r=0.770,p=0.677),  time:46.940, tt:375.521\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00001, loss_test:0.10584, lr:1.00e-02, fs:0.71591 (r=0.724,p=0.708),  time:47.134, tt:424.204\n",
      "Ep:9, loss:0.00001, loss_test:0.10537, lr:1.00e-02, fs:0.73118 (r=0.782,p=0.687),  time:47.529, tt:475.291\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.10716, lr:1.00e-02, fs:0.72362 (r=0.828,p=0.643),  time:47.698, tt:524.674\n",
      "Ep:11, loss:0.00001, loss_test:0.10066, lr:1.00e-02, fs:0.72727 (r=0.782,p=0.680),  time:47.914, tt:574.973\n",
      "Ep:12, loss:0.00001, loss_test:0.09763, lr:1.00e-02, fs:0.69880 (r=0.667,p=0.734),  time:47.867, tt:622.273\n",
      "Ep:13, loss:0.00001, loss_test:0.09764, lr:1.00e-02, fs:0.67836 (r=0.667,p=0.690),  time:47.968, tt:671.548\n",
      "Ep:14, loss:0.00001, loss_test:0.09665, lr:1.00e-02, fs:0.70857 (r=0.713,p=0.705),  time:48.496, tt:727.447\n",
      "Ep:15, loss:0.00001, loss_test:0.09245, lr:1.00e-02, fs:0.73810 (r=0.713,p=0.765),  time:48.721, tt:779.535\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.09039, lr:1.00e-02, fs:0.75449 (r=0.724,p=0.787),  time:48.809, tt:829.745\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.09061, lr:1.00e-02, fs:0.76023 (r=0.747,p=0.774),  time:48.738, tt:877.290\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.08917, lr:1.00e-02, fs:0.77193 (r=0.759,p=0.786),  time:48.811, tt:927.407\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08766, lr:1.00e-02, fs:0.77647 (r=0.759,p=0.795),  time:48.777, tt:975.538\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.08714, lr:1.00e-02, fs:0.79310 (r=0.793,p=0.793),  time:48.782, tt:1024.414\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.08575, lr:1.00e-02, fs:0.79769 (r=0.793,p=0.802),  time:48.747, tt:1072.432\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.08461, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:48.697, tt:1120.024\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00001, loss_test:0.08432, lr:1.00e-02, fs:0.80702 (r=0.793,p=0.821),  time:48.664, tt:1167.930\n",
      "Ep:24, loss:0.00001, loss_test:0.08401, lr:1.00e-02, fs:0.81657 (r=0.793,p=0.841),  time:48.742, tt:1218.541\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.08371, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:48.703, tt:1266.267\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00001, loss_test:0.08241, lr:1.00e-02, fs:0.83041 (r=0.816,p=0.845),  time:48.640, tt:1313.275\n",
      "Ep:27, loss:0.00001, loss_test:0.08164, lr:1.00e-02, fs:0.83529 (r=0.816,p=0.855),  time:48.592, tt:1360.583\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00001, loss_test:0.08131, lr:1.00e-02, fs:0.84024 (r=0.816,p=0.866),  time:48.541, tt:1407.698\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00001, loss_test:0.08043, lr:1.00e-02, fs:0.84524 (r=0.816,p=0.877),  time:48.436, tt:1453.084\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00001, loss_test:0.07941, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:48.379, tt:1499.754\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00001, loss_test:0.07825, lr:1.00e-02, fs:0.85714 (r=0.828,p=0.889),  time:48.396, tt:1548.685\n",
      "Ep:32, loss:0.00001, loss_test:0.07809, lr:1.00e-02, fs:0.86228 (r=0.828,p=0.900),  time:48.451, tt:1598.889\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.07694, lr:1.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:48.381, tt:1644.949\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00000, loss_test:0.07628, lr:1.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:48.382, tt:1693.357\n",
      "Ep:35, loss:0.00000, loss_test:0.07564, lr:1.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:48.339, tt:1740.205\n",
      "Ep:36, loss:0.00000, loss_test:0.07545, lr:1.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:48.341, tt:1788.608\n",
      "Ep:37, loss:0.00000, loss_test:0.07518, lr:1.00e-02, fs:0.87805 (r=0.828,p=0.935),  time:48.325, tt:1836.367\n",
      "Ep:38, loss:0.00000, loss_test:0.07407, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:48.313, tt:1884.201\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00000, loss_test:0.07402, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:48.281, tt:1931.228\n",
      "Ep:40, loss:0.00000, loss_test:0.07294, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:48.266, tt:1978.922\n",
      "Ep:41, loss:0.00000, loss_test:0.07176, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:48.235, tt:2025.873\n",
      "Ep:42, loss:0.00000, loss_test:0.07292, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:48.168, tt:2071.234\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00000, loss_test:0.07072, lr:1.00e-02, fs:0.89571 (r=0.839,p=0.961),  time:48.169, tt:2119.448\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00000, loss_test:0.07157, lr:1.00e-02, fs:0.89571 (r=0.839,p=0.961),  time:48.162, tt:2167.299\n",
      "Ep:45, loss:0.00000, loss_test:0.07085, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:48.177, tt:2216.141\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00000, loss_test:0.07052, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:48.183, tt:2264.604\n",
      "Ep:47, loss:0.00000, loss_test:0.07174, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:48.151, tt:2311.236\n",
      "Ep:48, loss:0.00000, loss_test:0.07060, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:48.162, tt:2359.919\n",
      "Ep:49, loss:0.00000, loss_test:0.07115, lr:1.00e-02, fs:0.90123 (r=0.839,p=0.973),  time:48.178, tt:2408.890\n",
      "Ep:50, loss:0.00000, loss_test:0.07104, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.199, tt:2458.168\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00000, loss_test:0.06968, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.229, tt:2507.925\n",
      "Ep:52, loss:0.00000, loss_test:0.07128, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.228, tt:2556.065\n",
      "Ep:53, loss:0.00000, loss_test:0.06921, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.201, tt:2602.860\n",
      "Ep:54, loss:0.00000, loss_test:0.07084, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.218, tt:2651.972\n",
      "Ep:55, loss:0.00000, loss_test:0.06918, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.207, tt:2699.571\n",
      "Ep:56, loss:0.00000, loss_test:0.06924, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.216, tt:2748.335\n",
      "Ep:57, loss:0.00000, loss_test:0.07041, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.174, tt:2794.106\n",
      "Ep:58, loss:0.00000, loss_test:0.06909, lr:1.00e-02, fs:0.90683 (r=0.839,p=0.986),  time:48.185, tt:2842.892\n",
      "Ep:59, loss:0.00000, loss_test:0.06971, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.173, tt:2890.363\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00000, loss_test:0.06958, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.157, tt:2937.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00000, loss_test:0.06976, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.153, tt:2985.467\n",
      "Ep:62, loss:0.00000, loss_test:0.07032, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.162, tt:3034.230\n",
      "Ep:63, loss:0.00000, loss_test:0.06924, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.151, tt:3081.649\n",
      "Ep:64, loss:0.00000, loss_test:0.07040, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.144, tt:3129.372\n",
      "Ep:65, loss:0.00000, loss_test:0.06967, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.122, tt:3176.055\n",
      "Ep:66, loss:0.00000, loss_test:0.06966, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.109, tt:3223.326\n",
      "Ep:67, loss:0.00000, loss_test:0.06959, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.096, tt:3270.558\n",
      "Ep:68, loss:0.00000, loss_test:0.07062, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.103, tt:3319.120\n",
      "Ep:69, loss:0.00000, loss_test:0.07041, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.116, tt:3368.152\n",
      "Ep:70, loss:0.00000, loss_test:0.07096, lr:1.00e-02, fs:0.91250 (r=0.839,p=1.000),  time:48.112, tt:3415.955\n",
      "Ep:71, loss:0.00000, loss_test:0.07188, lr:9.90e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.133, tt:3465.569\n",
      "Ep:72, loss:0.00000, loss_test:0.06987, lr:9.80e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.138, tt:3514.080\n",
      "Ep:73, loss:0.00000, loss_test:0.07093, lr:9.70e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.122, tt:3560.992\n",
      "Ep:74, loss:0.00000, loss_test:0.07232, lr:9.61e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.126, tt:3609.428\n",
      "Ep:75, loss:0.00000, loss_test:0.07094, lr:9.51e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.112, tt:3656.515\n",
      "Ep:76, loss:0.00000, loss_test:0.07212, lr:9.41e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.092, tt:3703.105\n",
      "Ep:77, loss:0.00000, loss_test:0.07149, lr:9.32e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.098, tt:3751.620\n",
      "Ep:78, loss:0.00000, loss_test:0.07235, lr:9.23e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.120, tt:3801.486\n",
      "Ep:79, loss:0.00000, loss_test:0.07197, lr:9.14e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.122, tt:3849.732\n",
      "Ep:80, loss:0.00000, loss_test:0.07173, lr:9.04e-03, fs:0.91250 (r=0.839,p=1.000),  time:48.111, tt:3897.027\n",
      "Ep:81, loss:0.00000, loss_test:0.07276, lr:8.95e-03, fs:0.89873 (r=0.816,p=1.000),  time:48.106, tt:3944.698\n",
      "Ep:82, loss:0.00000, loss_test:0.07266, lr:8.86e-03, fs:0.89172 (r=0.805,p=1.000),  time:48.122, tt:3994.162\n",
      "Ep:83, loss:0.00000, loss_test:0.07306, lr:8.78e-03, fs:0.85526 (r=0.747,p=1.000),  time:48.117, tt:4041.860\n",
      "Ep:84, loss:0.00000, loss_test:0.07279, lr:8.69e-03, fs:0.84000 (r=0.724,p=1.000),  time:48.116, tt:4089.843\n",
      "Ep:85, loss:0.00000, loss_test:0.07341, lr:8.60e-03, fs:0.83221 (r=0.713,p=1.000),  time:48.135, tt:4139.574\n",
      "Ep:86, loss:0.00000, loss_test:0.07418, lr:8.51e-03, fs:0.82432 (r=0.701,p=1.000),  time:48.135, tt:4187.704\n",
      "Ep:87, loss:0.00000, loss_test:0.07363, lr:8.43e-03, fs:0.82432 (r=0.701,p=1.000),  time:48.132, tt:4235.584\n",
      "Ep:88, loss:0.00000, loss_test:0.07418, lr:8.35e-03, fs:0.82432 (r=0.701,p=1.000),  time:48.133, tt:4283.868\n",
      "Ep:89, loss:0.00000, loss_test:0.07562, lr:8.26e-03, fs:0.82432 (r=0.701,p=1.000),  time:48.132, tt:4331.858\n",
      "Ep:90, loss:0.00000, loss_test:0.07403, lr:8.18e-03, fs:0.82432 (r=0.701,p=1.000),  time:48.048, tt:4372.354\n",
      "Ep:91, loss:0.00000, loss_test:0.07517, lr:8.10e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.979, tt:4414.101\n",
      "Ep:92, loss:0.00000, loss_test:0.07565, lr:8.02e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.916, tt:4456.224\n",
      "Ep:93, loss:0.00000, loss_test:0.07495, lr:7.94e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.863, tt:4499.091\n",
      "Ep:94, loss:0.00000, loss_test:0.07650, lr:7.86e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.792, tt:4540.277\n",
      "Ep:95, loss:0.00000, loss_test:0.07528, lr:7.78e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.766, tt:4585.546\n",
      "Ep:96, loss:0.00000, loss_test:0.07642, lr:7.70e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.726, tt:4629.383\n",
      "Ep:97, loss:0.00000, loss_test:0.07669, lr:7.62e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.663, tt:4670.927\n",
      "Ep:98, loss:0.00000, loss_test:0.07611, lr:7.55e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.604, tt:4712.771\n",
      "Ep:99, loss:0.00000, loss_test:0.07663, lr:7.47e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.548, tt:4754.835\n",
      "Ep:100, loss:0.00000, loss_test:0.07711, lr:7.40e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.469, tt:4794.369\n",
      "Ep:101, loss:0.00000, loss_test:0.07675, lr:7.32e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.422, tt:4837.021\n",
      "Ep:102, loss:0.00000, loss_test:0.07671, lr:7.25e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.421, tt:4884.317\n",
      "Ep:103, loss:0.00000, loss_test:0.07767, lr:7.18e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.316, tt:4920.856\n",
      "Ep:104, loss:0.00000, loss_test:0.07708, lr:7.11e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.180, tt:4953.882\n",
      "Ep:105, loss:0.00000, loss_test:0.07751, lr:7.03e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.015, tt:4983.615\n",
      "Ep:106, loss:0.00000, loss_test:0.07760, lr:6.96e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.832, tt:5011.002\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 35760 Test samples: 174\n",
      "Train positive samples: 17880 Test positive samples: 87\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 20000: \n",
      "Ep:0, loss:0.00001, loss_test:0.14159, lr:1.00e-02, fs:0.67181 (r=1.000,p=0.506),  time:37.863, tt:37.863\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00001, loss_test:0.13888, lr:1.00e-02, fs:0.66142 (r=0.966,p=0.503),  time:42.242, tt:84.484\n",
      "Ep:2, loss:0.00001, loss_test:0.13356, lr:1.00e-02, fs:0.65873 (r=0.954,p=0.503),  time:44.182, tt:132.546\n",
      "Ep:3, loss:0.00001, loss_test:0.12535, lr:1.00e-02, fs:0.65560 (r=0.908,p=0.513),  time:45.625, tt:182.498\n",
      "Ep:4, loss:0.00001, loss_test:0.11427, lr:1.00e-02, fs:0.68020 (r=0.770,p=0.609),  time:45.982, tt:229.909\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00001, loss_test:0.10791, lr:1.00e-02, fs:0.68263 (r=0.655,p=0.713),  time:46.042, tt:276.253\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00001, loss_test:0.10643, lr:1.00e-02, fs:0.69006 (r=0.678,p=0.702),  time:46.447, tt:325.130\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00001, loss_test:0.10634, lr:1.00e-02, fs:0.68449 (r=0.736,p=0.640),  time:47.772, tt:382.178\n",
      "Ep:8, loss:0.00001, loss_test:0.10349, lr:1.00e-02, fs:0.69892 (r=0.747,p=0.657),  time:47.834, tt:430.509\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00001, loss_test:0.09993, lr:1.00e-02, fs:0.74854 (r=0.736,p=0.762),  time:47.792, tt:477.924\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00001, loss_test:0.09835, lr:1.00e-02, fs:0.71006 (r=0.690,p=0.732),  time:47.877, tt:526.648\n",
      "Ep:11, loss:0.00001, loss_test:0.09667, lr:1.00e-02, fs:0.73143 (r=0.736,p=0.727),  time:48.055, tt:576.663\n",
      "Ep:12, loss:0.00001, loss_test:0.09353, lr:1.00e-02, fs:0.71515 (r=0.678,p=0.756),  time:48.000, tt:624.002\n",
      "Ep:13, loss:0.00001, loss_test:0.09221, lr:1.00e-02, fs:0.73620 (r=0.690,p=0.789),  time:48.063, tt:672.885\n",
      "Ep:14, loss:0.00001, loss_test:0.09128, lr:1.00e-02, fs:0.74699 (r=0.713,p=0.785),  time:48.018, tt:720.267\n",
      "Ep:15, loss:0.00001, loss_test:0.08882, lr:1.00e-02, fs:0.75309 (r=0.701,p=0.813),  time:48.003, tt:768.055\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00001, loss_test:0.08686, lr:1.00e-02, fs:0.76074 (r=0.713,p=0.816),  time:48.040, tt:816.674\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00001, loss_test:0.08520, lr:1.00e-02, fs:0.76829 (r=0.724,p=0.818),  time:48.075, tt:865.351\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00001, loss_test:0.08336, lr:1.00e-02, fs:0.78528 (r=0.736,p=0.842),  time:48.044, tt:912.844\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00001, loss_test:0.08136, lr:1.00e-02, fs:0.80240 (r=0.770,p=0.838),  time:48.040, tt:960.797\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00001, loss_test:0.07971, lr:1.00e-02, fs:0.80488 (r=0.759,p=0.857),  time:48.013, tt:1008.280\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00001, loss_test:0.07891, lr:1.00e-02, fs:0.81212 (r=0.770,p=0.859),  time:48.026, tt:1056.577\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00001, loss_test:0.07825, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:47.999, tt:1103.988\n",
      "Ep:23, loss:0.00001, loss_test:0.07777, lr:1.00e-02, fs:0.80982 (r=0.759,p=0.868),  time:48.024, tt:1152.578\n",
      "Ep:24, loss:0.00001, loss_test:0.07715, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:47.992, tt:1199.796\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00001, loss_test:0.07735, lr:1.00e-02, fs:0.81707 (r=0.770,p=0.870),  time:48.085, tt:1250.210\n",
      "Ep:26, loss:0.00001, loss_test:0.07669, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:48.064, tt:1297.718\n",
      "Ep:27, loss:0.00000, loss_test:0.07689, lr:1.00e-02, fs:0.82424 (r=0.782,p=0.872),  time:48.103, tt:1346.874\n",
      "Ep:28, loss:0.00000, loss_test:0.07630, lr:1.00e-02, fs:0.85366 (r=0.805,p=0.909),  time:48.137, tt:1395.970\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00000, loss_test:0.07631, lr:1.00e-02, fs:0.83636 (r=0.793,p=0.885),  time:48.163, tt:1444.888\n",
      "Ep:30, loss:0.00000, loss_test:0.07725, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:48.099, tt:1491.064\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00000, loss_test:0.07660, lr:1.00e-02, fs:0.85542 (r=0.816,p=0.899),  time:48.087, tt:1538.787\n",
      "Ep:32, loss:0.00000, loss_test:0.07641, lr:1.00e-02, fs:0.87117 (r=0.816,p=0.934),  time:48.034, tt:1585.136\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00000, loss_test:0.07714, lr:1.00e-02, fs:0.85714 (r=0.793,p=0.932),  time:48.017, tt:1632.593\n",
      "Ep:34, loss:0.00000, loss_test:0.07538, lr:1.00e-02, fs:0.88485 (r=0.839,p=0.936),  time:48.005, tt:1680.188\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00000, loss_test:0.07755, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:47.974, tt:1727.057\n",
      "Ep:36, loss:0.00000, loss_test:0.07469, lr:1.00e-02, fs:0.89024 (r=0.839,p=0.948),  time:47.960, tt:1774.508\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00000, loss_test:0.07702, lr:1.00e-02, fs:0.84810 (r=0.770,p=0.944),  time:47.930, tt:1821.356\n",
      "Ep:38, loss:0.00000, loss_test:0.07663, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:47.912, tt:1868.549\n",
      "Ep:39, loss:0.00000, loss_test:0.07561, lr:1.00e-02, fs:0.86792 (r=0.793,p=0.958),  time:47.918, tt:1916.720\n",
      "Ep:40, loss:0.00000, loss_test:0.07658, lr:1.00e-02, fs:0.85350 (r=0.770,p=0.957),  time:47.934, tt:1965.304\n",
      "Ep:41, loss:0.00000, loss_test:0.07730, lr:1.00e-02, fs:0.84615 (r=0.759,p=0.957),  time:47.929, tt:2013.031\n",
      "Ep:42, loss:0.00000, loss_test:0.07554, lr:1.00e-02, fs:0.86076 (r=0.782,p=0.958),  time:47.905, tt:2059.911\n",
      "Ep:43, loss:0.00000, loss_test:0.07823, lr:1.00e-02, fs:0.84416 (r=0.747,p=0.970),  time:47.812, tt:2103.750\n",
      "Ep:44, loss:0.00000, loss_test:0.07429, lr:1.00e-02, fs:0.88199 (r=0.816,p=0.959),  time:47.648, tt:2144.170\n",
      "Ep:45, loss:0.00000, loss_test:0.07790, lr:1.00e-02, fs:0.83871 (r=0.747,p=0.956),  time:47.512, tt:2185.545\n",
      "Ep:46, loss:0.00000, loss_test:0.07572, lr:1.00e-02, fs:0.85897 (r=0.770,p=0.971),  time:47.362, tt:2226.037\n",
      "Ep:47, loss:0.00000, loss_test:0.07625, lr:1.00e-02, fs:0.84416 (r=0.747,p=0.970),  time:47.299, tt:2270.371\n",
      "Ep:48, loss:0.00000, loss_test:0.07684, lr:9.90e-03, fs:0.83660 (r=0.736,p=0.970),  time:47.280, tt:2316.738\n",
      "Ep:49, loss:0.00000, loss_test:0.07613, lr:9.80e-03, fs:0.83660 (r=0.736,p=0.970),  time:47.251, tt:2362.565\n",
      "Ep:50, loss:0.00000, loss_test:0.07771, lr:9.70e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.252, tt:2409.849\n",
      "Ep:51, loss:0.00000, loss_test:0.07756, lr:9.61e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.235, tt:2456.245\n",
      "Ep:52, loss:0.00000, loss_test:0.07888, lr:9.51e-03, fs:0.81333 (r=0.701,p=0.968),  time:47.218, tt:2502.555\n",
      "Ep:53, loss:0.00000, loss_test:0.07749, lr:9.41e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.206, tt:2549.114\n",
      "Ep:54, loss:0.00000, loss_test:0.07981, lr:9.32e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.176, tt:2594.689\n",
      "Ep:55, loss:0.00000, loss_test:0.07829, lr:9.23e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.178, tt:2641.971\n",
      "Ep:56, loss:0.00000, loss_test:0.07885, lr:9.14e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.176, tt:2689.026\n",
      "Ep:57, loss:0.00000, loss_test:0.07891, lr:9.04e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.160, tt:2735.294\n",
      "Ep:58, loss:0.00000, loss_test:0.07852, lr:8.95e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.139, tt:2781.219\n",
      "Ep:59, loss:0.00000, loss_test:0.08018, lr:8.86e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.163, tt:2829.794\n",
      "Ep:60, loss:0.00000, loss_test:0.07919, lr:8.78e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.182, tt:2878.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00000, loss_test:0.07885, lr:8.69e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.191, tt:2925.828\n",
      "Ep:62, loss:0.00000, loss_test:0.07989, lr:8.60e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.236, tt:2975.895\n",
      "Ep:63, loss:0.00000, loss_test:0.07968, lr:8.51e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.231, tt:3022.808\n",
      "Ep:64, loss:0.00000, loss_test:0.07964, lr:8.43e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.267, tt:3072.346\n",
      "Ep:65, loss:0.00000, loss_test:0.07908, lr:8.35e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.250, tt:3118.494\n",
      "Ep:66, loss:0.00000, loss_test:0.08084, lr:8.26e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.221, tt:3163.788\n",
      "Ep:67, loss:0.00000, loss_test:0.07932, lr:8.18e-03, fs:0.81879 (r=0.701,p=0.984),  time:47.244, tt:3212.587\n",
      "Ep:68, loss:0.00000, loss_test:0.08050, lr:8.10e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.256, tt:3260.638\n",
      "Ep:69, loss:0.00000, loss_test:0.07952, lr:8.02e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.277, tt:3309.365\n",
      "Ep:70, loss:0.00000, loss_test:0.08140, lr:7.94e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.271, tt:3356.276\n",
      "Ep:71, loss:0.00000, loss_test:0.07938, lr:7.86e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.267, tt:3403.222\n",
      "Ep:72, loss:0.00000, loss_test:0.08138, lr:7.78e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.276, tt:3451.156\n",
      "Ep:73, loss:0.00000, loss_test:0.07920, lr:7.70e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.249, tt:3496.448\n",
      "Ep:74, loss:0.00000, loss_test:0.08150, lr:7.62e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.236, tt:3542.727\n",
      "Ep:75, loss:0.00000, loss_test:0.07920, lr:7.55e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.220, tt:3588.696\n",
      "Ep:76, loss:0.00000, loss_test:0.08142, lr:7.47e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.222, tt:3636.110\n",
      "Ep:77, loss:0.00000, loss_test:0.07962, lr:7.40e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.261, tt:3686.364\n",
      "Ep:78, loss:0.00000, loss_test:0.08156, lr:7.32e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.269, tt:3734.239\n",
      "Ep:79, loss:0.00000, loss_test:0.07931, lr:7.25e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.268, tt:3781.476\n",
      "Ep:80, loss:0.00000, loss_test:0.08135, lr:7.18e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.271, tt:3828.982\n",
      "Ep:81, loss:0.00000, loss_test:0.07933, lr:7.11e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.258, tt:3875.158\n",
      "Ep:82, loss:0.00000, loss_test:0.08122, lr:7.03e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.240, tt:3920.899\n",
      "Ep:83, loss:0.00000, loss_test:0.07979, lr:6.96e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.230, tt:3967.326\n",
      "Ep:84, loss:0.00000, loss_test:0.08124, lr:6.89e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.220, tt:4013.718\n",
      "Ep:85, loss:0.00000, loss_test:0.08045, lr:6.83e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.238, tt:4062.457\n",
      "Ep:86, loss:0.00000, loss_test:0.08121, lr:6.76e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.240, tt:4109.900\n",
      "Ep:87, loss:0.00000, loss_test:0.08081, lr:6.69e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.234, tt:4156.563\n",
      "Ep:88, loss:0.00000, loss_test:0.08134, lr:6.62e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.219, tt:4202.475\n",
      "Ep:89, loss:0.00000, loss_test:0.08120, lr:6.56e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.248, tt:4252.327\n",
      "Ep:90, loss:0.00000, loss_test:0.08132, lr:6.49e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.267, tt:4301.302\n",
      "Ep:91, loss:0.00000, loss_test:0.08139, lr:6.43e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.263, tt:4348.184\n",
      "Ep:92, loss:0.00000, loss_test:0.08177, lr:6.36e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.262, tt:4395.400\n",
      "Ep:93, loss:0.00000, loss_test:0.08123, lr:6.30e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.284, tt:4444.666\n",
      "Ep:94, loss:0.00000, loss_test:0.08165, lr:6.24e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.275, tt:4491.093\n",
      "Ep:95, loss:0.00000, loss_test:0.08164, lr:6.17e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.263, tt:4537.227\n",
      "Ep:96, loss:0.00000, loss_test:0.08231, lr:6.11e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.244, tt:4582.701\n",
      "Ep:97, loss:0.00000, loss_test:0.08160, lr:6.05e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.175, tt:4623.189\n",
      "Ep:98, loss:0.00000, loss_test:0.08220, lr:5.99e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.117, tt:4664.614\n",
      "Ep:99, loss:0.00000, loss_test:0.08198, lr:5.93e-03, fs:0.82432 (r=0.701,p=1.000),  time:47.052, tt:4705.201\n",
      "Ep:100, loss:0.00000, loss_test:0.08246, lr:5.87e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.980, tt:4744.989\n",
      "Ep:101, loss:0.00000, loss_test:0.08205, lr:5.81e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.922, tt:4786.032\n",
      "Ep:102, loss:0.00000, loss_test:0.08262, lr:5.75e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.855, tt:4826.056\n",
      "Ep:103, loss:0.00000, loss_test:0.08229, lr:5.70e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.780, tt:4865.083\n",
      "Ep:104, loss:0.00000, loss_test:0.08258, lr:5.64e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.779, tt:4911.827\n",
      "Ep:105, loss:0.00000, loss_test:0.08260, lr:5.58e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.775, tt:4958.159\n",
      "Ep:106, loss:0.00000, loss_test:0.08273, lr:5.53e-03, fs:0.82432 (r=0.701,p=1.000),  time:46.726, tt:4999.727\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=20000 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,107,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 26722 Test samples: 198\n",
      "Train positive samples: 13361 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00342, loss_test:0.11628, lr:4.00e-03, fs:0.62827 (r=0.606,p=0.652),  time:557.676, tt:557.676\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00242, loss_test:0.10945, lr:4.00e-03, fs:0.64740 (r=0.566,p=0.757),  time:570.606, tt:1141.212\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00173, loss_test:0.10399, lr:4.00e-03, fs:0.67456 (r=0.576,p=0.814),  time:574.717, tt:1724.152\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00124, loss_test:0.10738, lr:4.00e-03, fs:0.70807 (r=0.576,p=0.919),  time:575.410, tt:2301.639\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00086, loss_test:0.10969, lr:4.00e-03, fs:0.67949 (r=0.535,p=0.930),  time:575.103, tt:2875.514\n",
      "Ep:5, loss:0.00057, loss_test:0.11161, lr:4.00e-03, fs:0.70130 (r=0.545,p=0.982),  time:577.469, tt:3464.815\n",
      "Ep:6, loss:0.00038, loss_test:0.11640, lr:4.00e-03, fs:0.70130 (r=0.545,p=0.982),  time:578.962, tt:4052.737\n",
      "Ep:7, loss:0.00026, loss_test:0.11797, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:579.436, tt:4635.484\n",
      "Ep:8, loss:0.00017, loss_test:0.12194, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:580.551, tt:5224.963\n",
      "Ep:9, loss:0.00012, loss_test:0.12554, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:580.496, tt:5804.962\n",
      "Ep:10, loss:0.00009, loss_test:0.12213, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:577.975, tt:6357.729\n",
      "Ep:11, loss:0.00007, loss_test:0.12740, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:573.885, tt:6886.625\n",
      "Ep:12, loss:0.00005, loss_test:0.12792, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:570.399, tt:7415.189\n",
      "Ep:13, loss:0.00004, loss_test:0.12559, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:567.600, tt:7946.403\n",
      "Ep:14, loss:0.00003, loss_test:0.12650, lr:4.00e-03, fs:0.70588 (r=0.545,p=1.000),  time:564.979, tt:8474.678\n",
      "Ep:15, loss:0.00003, loss_test:0.12616, lr:3.96e-03, fs:0.70588 (r=0.545,p=1.000),  time:562.407, tt:8998.508\n",
      "Ep:16, loss:0.00002, loss_test:0.12479, lr:3.92e-03, fs:0.70588 (r=0.545,p=1.000),  time:558.211, tt:9489.581\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,17,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3200 Test samples: 198\n",
      "Train positive samples: 1600 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00055, loss_test:0.13529, lr:4.00e-03, fs:0.66894 (r=0.990,p=0.505),  time:66.030, tt:66.030\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13078, lr:4.00e-03, fs:0.66197 (r=0.949,p=0.508),  time:75.366, tt:150.733\n",
      "Ep:2, loss:0.00052, loss_test:0.12308, lr:4.00e-03, fs:0.64062 (r=0.828,p=0.522),  time:77.053, tt:231.160\n",
      "Ep:3, loss:0.00048, loss_test:0.11650, lr:4.00e-03, fs:0.64151 (r=0.687,p=0.602),  time:78.600, tt:314.399\n",
      "Ep:4, loss:0.00046, loss_test:0.11543, lr:4.00e-03, fs:0.64211 (r=0.616,p=0.670),  time:78.900, tt:394.499\n",
      "Ep:5, loss:0.00044, loss_test:0.11363, lr:4.00e-03, fs:0.66667 (r=0.667,p=0.667),  time:79.733, tt:478.396\n",
      "Ep:6, loss:0.00043, loss_test:0.11120, lr:4.00e-03, fs:0.66667 (r=0.687,p=0.648),  time:80.837, tt:565.856\n",
      "Ep:7, loss:0.00041, loss_test:0.10744, lr:4.00e-03, fs:0.67358 (r=0.657,p=0.691),  time:81.361, tt:650.888\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00039, loss_test:0.10454, lr:4.00e-03, fs:0.68718 (r=0.677,p=0.698),  time:81.538, tt:733.841\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00037, loss_test:0.10297, lr:4.00e-03, fs:0.70051 (r=0.697,p=0.704),  time:81.456, tt:814.556\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00036, loss_test:0.10023, lr:4.00e-03, fs:0.72043 (r=0.677,p=0.770),  time:81.739, tt:899.131\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00034, loss_test:0.09854, lr:4.00e-03, fs:0.73016 (r=0.697,p=0.767),  time:81.825, tt:981.895\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00033, loss_test:0.09697, lr:4.00e-03, fs:0.72727 (r=0.687,p=0.773),  time:82.046, tt:1066.595\n",
      "Ep:13, loss:0.00032, loss_test:0.09446, lr:4.00e-03, fs:0.71429 (r=0.657,p=0.783),  time:82.431, tt:1154.037\n",
      "Ep:14, loss:0.00030, loss_test:0.09321, lr:4.00e-03, fs:0.70652 (r=0.657,p=0.765),  time:82.589, tt:1238.838\n",
      "Ep:15, loss:0.00029, loss_test:0.09205, lr:4.00e-03, fs:0.71111 (r=0.646,p=0.790),  time:82.701, tt:1323.214\n",
      "Ep:16, loss:0.00028, loss_test:0.09105, lr:4.00e-03, fs:0.70787 (r=0.636,p=0.797),  time:82.893, tt:1409.181\n",
      "Ep:17, loss:0.00027, loss_test:0.08992, lr:4.00e-03, fs:0.71111 (r=0.646,p=0.790),  time:82.807, tt:1490.527\n",
      "Ep:18, loss:0.00026, loss_test:0.08918, lr:4.00e-03, fs:0.71508 (r=0.646,p=0.800),  time:82.534, tt:1568.153\n",
      "Ep:19, loss:0.00025, loss_test:0.08836, lr:4.00e-03, fs:0.71910 (r=0.646,p=0.810),  time:82.390, tt:1647.800\n",
      "Ep:20, loss:0.00024, loss_test:0.08728, lr:4.00e-03, fs:0.74157 (r=0.667,p=0.835),  time:82.387, tt:1730.135\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00023, loss_test:0.08673, lr:4.00e-03, fs:0.74576 (r=0.667,p=0.846),  time:82.384, tt:1812.450\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00022, loss_test:0.08567, lr:4.00e-03, fs:0.75706 (r=0.677,p=0.859),  time:82.421, tt:1895.674\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00021, loss_test:0.08664, lr:4.00e-03, fs:0.75145 (r=0.657,p=0.878),  time:82.462, tt:1979.077\n",
      "Ep:24, loss:0.00020, loss_test:0.08449, lr:4.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:82.528, tt:2063.203\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00020, loss_test:0.08508, lr:4.00e-03, fs:0.75862 (r=0.667,p=0.880),  time:82.592, tt:2147.398\n",
      "Ep:26, loss:0.00019, loss_test:0.08489, lr:4.00e-03, fs:0.76571 (r=0.677,p=0.882),  time:82.695, tt:2232.755\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00018, loss_test:0.08372, lr:4.00e-03, fs:0.76571 (r=0.677,p=0.882),  time:82.479, tt:2309.414\n",
      "Ep:28, loss:0.00017, loss_test:0.08524, lr:4.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:82.399, tt:2389.563\n",
      "Ep:29, loss:0.00016, loss_test:0.08356, lr:4.00e-03, fs:0.75145 (r=0.657,p=0.878),  time:82.415, tt:2472.441\n",
      "Ep:30, loss:0.00015, loss_test:0.08527, lr:4.00e-03, fs:0.74118 (r=0.636,p=0.887),  time:82.621, tt:2561.241\n",
      "Ep:31, loss:0.00015, loss_test:0.08196, lr:4.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:82.686, tt:2645.952\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00014, loss_test:0.08412, lr:4.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:82.678, tt:2728.360\n",
      "Ep:33, loss:0.00013, loss_test:0.08192, lr:4.00e-03, fs:0.77011 (r=0.677,p=0.893),  time:82.676, tt:2810.991\n",
      "Ep:34, loss:0.00013, loss_test:0.08264, lr:4.00e-03, fs:0.76744 (r=0.667,p=0.904),  time:82.733, tt:2895.666\n",
      "Ep:35, loss:0.00012, loss_test:0.08081, lr:4.00e-03, fs:0.77457 (r=0.677,p=0.905),  time:82.719, tt:2977.869\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00011, loss_test:0.08385, lr:4.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:82.715, tt:3060.437\n",
      "Ep:37, loss:0.00011, loss_test:0.08351, lr:4.00e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.748, tt:3144.420\n",
      "Ep:38, loss:0.00010, loss_test:0.08053, lr:4.00e-03, fs:0.76744 (r=0.667,p=0.904),  time:82.789, tt:3228.763\n",
      "Ep:39, loss:0.00010, loss_test:0.08196, lr:4.00e-03, fs:0.75294 (r=0.646,p=0.901),  time:82.849, tt:3313.950\n",
      "Ep:40, loss:0.00009, loss_test:0.08219, lr:4.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:82.826, tt:3395.863\n",
      "Ep:41, loss:0.00009, loss_test:0.08106, lr:4.00e-03, fs:0.76744 (r=0.667,p=0.904),  time:82.825, tt:3478.657\n",
      "Ep:42, loss:0.00009, loss_test:0.08293, lr:4.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:82.860, tt:3562.988\n",
      "Ep:43, loss:0.00008, loss_test:0.08336, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:82.912, tt:3648.136\n",
      "Ep:44, loss:0.00008, loss_test:0.08194, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:82.952, tt:3732.832\n",
      "Ep:45, loss:0.00007, loss_test:0.08252, lr:4.00e-03, fs:0.76471 (r=0.657,p=0.915),  time:82.952, tt:3815.795\n",
      "Ep:46, loss:0.00007, loss_test:0.08297, lr:4.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:82.989, tt:3900.463\n",
      "Ep:47, loss:0.00007, loss_test:0.08409, lr:3.96e-03, fs:0.78107 (r=0.667,p=0.943),  time:82.957, tt:3981.953\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00006, loss_test:0.08210, lr:3.96e-03, fs:0.77647 (r=0.667,p=0.930),  time:82.968, tt:4065.414\n",
      "Ep:49, loss:0.00006, loss_test:0.08342, lr:3.96e-03, fs:0.79290 (r=0.677,p=0.957),  time:83.054, tt:4152.721\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00006, loss_test:0.08483, lr:3.96e-03, fs:0.78571 (r=0.667,p=0.957),  time:83.086, tt:4237.369\n",
      "Ep:51, loss:0.00005, loss_test:0.08425, lr:3.96e-03, fs:0.79762 (r=0.677,p=0.971),  time:83.105, tt:4321.461\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00005, loss_test:0.08253, lr:3.96e-03, fs:0.79070 (r=0.687,p=0.932),  time:83.119, tt:4405.290\n",
      "Ep:53, loss:0.00005, loss_test:0.08412, lr:3.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:83.102, tt:4487.518\n",
      "Ep:54, loss:0.00004, loss_test:0.08423, lr:3.96e-03, fs:0.79532 (r=0.687,p=0.944),  time:83.016, tt:4565.893\n",
      "Ep:55, loss:0.00004, loss_test:0.08330, lr:3.96e-03, fs:0.80000 (r=0.687,p=0.958),  time:82.849, tt:4639.528\n",
      "##########Best model found so far##########\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,56,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00434, loss_test:0.09908, lr:4.00e-03, fs:0.73148 (r=0.798,p=0.675),  time:739.195, tt:739.195\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00296, loss_test:0.08670, lr:4.00e-03, fs:0.79803 (r=0.818,p=0.779),  time:741.990, tt:1483.980\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00209, loss_test:0.07618, lr:4.00e-03, fs:0.81633 (r=0.808,p=0.825),  time:747.550, tt:2242.650\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00149, loss_test:0.07210, lr:4.00e-03, fs:0.86339 (r=0.798,p=0.940),  time:749.726, tt:2998.905\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00099, loss_test:0.06645, lr:4.00e-03, fs:0.88172 (r=0.828,p=0.943),  time:750.795, tt:3753.975\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00066, loss_test:0.06452, lr:4.00e-03, fs:0.89011 (r=0.818,p=0.976),  time:748.828, tt:4492.970\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00045, loss_test:0.06159, lr:4.00e-03, fs:0.88398 (r=0.808,p=0.976),  time:747.201, tt:5230.404\n",
      "Ep:7, loss:0.00032, loss_test:0.06293, lr:4.00e-03, fs:0.87006 (r=0.778,p=0.987),  time:745.940, tt:5967.523\n",
      "Ep:8, loss:0.00022, loss_test:0.07204, lr:4.00e-03, fs:0.87006 (r=0.778,p=0.987),  time:744.776, tt:6702.981\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-03ac1e6efb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=4e-3 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2d_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00407, loss_test:0.08556, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:724.397, tt:724.397\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00225, loss_test:0.06219, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:738.968, tt:1477.936\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00123, loss_test:0.04773, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:738.820, tt:2216.461\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00063, loss_test:0.04534, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:742.839, tt:2971.356\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00032, loss_test:0.04207, lr:1.00e-02, fs:0.91304 (r=0.848,p=0.988),  time:743.591, tt:3717.955\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00016, loss_test:0.04509, lr:1.00e-02, fs:0.91892 (r=0.859,p=0.988),  time:744.782, tt:4468.691\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0d0f32b675f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m#forward_backward positive batch sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features, v1, v2)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcn_nn_concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, feature)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=0,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2d_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,16,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 0\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 34644 Test samples: 198\n",
      "Train positive samples: 17322 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00386, loss_test:0.08435, lr:1.00e-02, fs:0.77157 (r=0.768,p=0.776),  time:736.807, tt:736.807\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00202, loss_test:0.06328, lr:1.00e-02, fs:0.86022 (r=0.808,p=0.920),  time:746.841, tt:1493.682\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00102, loss_test:0.05842, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:748.966, tt:2246.898\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00054, loss_test:0.06319, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:752.168, tt:3008.674\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.06892, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:754.359, tt:3771.797\n",
      "Ep:5, loss:0.00015, loss_test:0.07384, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:754.184, tt:4525.102\n",
      "Ep:6, loss:0.00008, loss_test:0.08045, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:752.227, tt:5265.593\n",
      "Ep:7, loss:0.00005, loss_test:0.08215, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:750.369, tt:6002.948\n",
      "Ep:8, loss:0.00003, loss_test:0.08528, lr:1.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:748.477, tt:6736.295\n",
      "Ep:9, loss:0.00002, loss_test:0.08696, lr:1.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:748.146, tt:7481.458\n",
      "Ep:10, loss:0.00002, loss_test:0.08415, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:747.245, tt:8219.698\n",
      "Ep:11, loss:0.00001, loss_test:0.08522, lr:1.00e-02, fs:0.87640 (r=0.788,p=0.987),  time:747.995, tt:8975.941\n",
      "Ep:12, loss:0.00001, loss_test:0.08273, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:749.434, tt:9742.639\n",
      "Ep:13, loss:0.00001, loss_test:0.08431, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:749.534, tt:10493.474\n",
      "Ep:14, loss:0.00001, loss_test:0.08183, lr:1.00e-02, fs:0.87151 (r=0.788,p=0.975),  time:750.511, tt:11257.671\n",
      "Ep:15, loss:0.00001, loss_test:0.08176, lr:9.90e-03, fs:0.87151 (r=0.788,p=0.975),  time:751.190, tt:12019.043\n",
      "Ep:16, loss:0.00001, loss_test:0.08188, lr:9.80e-03, fs:0.87151 (r=0.788,p=0.975),  time:751.508, tt:12775.631\n",
      "Ep:17, loss:0.00001, loss_test:0.08072, lr:9.70e-03, fs:0.87151 (r=0.788,p=0.975),  time:751.985, tt:13535.726\n",
      "Ep:18, loss:0.00001, loss_test:0.08121, lr:9.61e-03, fs:0.87151 (r=0.788,p=0.975),  time:752.043, tt:14288.826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ca8a6ef5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mloss_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.7+mean\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             optimizer_name=\"sgd\" ) #adam or sgd, default adam\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtraining_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(training, iterations, ran, nsample, create)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mload_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_embedding_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtraining_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mpath_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/cv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcnsm/step3/step3_gcnsm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, iterations)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m#loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,66,cv_number,0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14380, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.467, tt:13.467\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14347, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:16.116, tt:32.232\n",
      "Ep:2, loss:0.00004, loss_test:0.14296, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.506, tt:52.519\n",
      "Ep:3, loss:0.00004, loss_test:0.14225, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.971, tt:71.885\n",
      "Ep:4, loss:0.00004, loss_test:0.14128, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:18.106, tt:90.529\n",
      "Ep:5, loss:0.00004, loss_test:0.13999, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:18.295, tt:109.773\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.13828, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:18.507, tt:129.547\n",
      "Ep:7, loss:0.00004, loss_test:0.13605, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:18.660, tt:149.278\n",
      "Ep:8, loss:0.00004, loss_test:0.13311, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:18.770, tt:168.933\n",
      "Ep:9, loss:0.00004, loss_test:0.12930, lr:1.00e-02, fs:0.68571 (r=0.970,p=0.530),  time:18.822, tt:188.216\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.12442, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:18.991, tt:208.903\n",
      "Ep:11, loss:0.00003, loss_test:0.11939, lr:1.00e-02, fs:0.70161 (r=0.879,p=0.584),  time:19.092, tt:229.104\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.11647, lr:1.00e-02, fs:0.66667 (r=0.737,p=0.608),  time:19.087, tt:248.128\n",
      "Ep:13, loss:0.00003, loss_test:0.11618, lr:1.00e-02, fs:0.63682 (r=0.646,p=0.627),  time:19.178, tt:268.499\n",
      "Ep:14, loss:0.00003, loss_test:0.11606, lr:1.00e-02, fs:0.63918 (r=0.626,p=0.653),  time:19.127, tt:286.902\n",
      "Ep:15, loss:0.00003, loss_test:0.11541, lr:1.00e-02, fs:0.65072 (r=0.687,p=0.618),  time:19.150, tt:306.404\n",
      "Ep:16, loss:0.00003, loss_test:0.11563, lr:1.00e-02, fs:0.66968 (r=0.747,p=0.607),  time:19.148, tt:325.508\n",
      "Ep:17, loss:0.00003, loss_test:0.11495, lr:1.00e-02, fs:0.69912 (r=0.798,p=0.622),  time:19.160, tt:344.880\n",
      "Ep:18, loss:0.00003, loss_test:0.11326, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:19.165, tt:364.144\n",
      "Ep:19, loss:0.00003, loss_test:0.11198, lr:1.00e-02, fs:0.67000 (r=0.677,p=0.663),  time:19.089, tt:381.785\n",
      "Ep:20, loss:0.00003, loss_test:0.11193, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:19.059, tt:400.236\n",
      "Ep:21, loss:0.00003, loss_test:0.11170, lr:1.00e-02, fs:0.66667 (r=0.657,p=0.677),  time:19.019, tt:418.411\n",
      "Ep:22, loss:0.00003, loss_test:0.11161, lr:1.00e-02, fs:0.66000 (r=0.667,p=0.653),  time:19.112, tt:439.570\n",
      "Ep:23, loss:0.00003, loss_test:0.11198, lr:9.90e-03, fs:0.68657 (r=0.697,p=0.676),  time:19.187, tt:460.497\n",
      "Ep:24, loss:0.00003, loss_test:0.11176, lr:9.80e-03, fs:0.69000 (r=0.697,p=0.683),  time:19.233, tt:480.836\n",
      "Ep:25, loss:0.00002, loss_test:0.11129, lr:9.70e-03, fs:0.69652 (r=0.707,p=0.686),  time:19.245, tt:500.378\n",
      "Ep:26, loss:0.00002, loss_test:0.11092, lr:9.61e-03, fs:0.68657 (r=0.697,p=0.676),  time:19.269, tt:520.269\n",
      "Ep:27, loss:0.00002, loss_test:0.11043, lr:9.51e-03, fs:0.68317 (r=0.697,p=0.670),  time:19.203, tt:537.684\n",
      "Ep:28, loss:0.00002, loss_test:0.10982, lr:9.41e-03, fs:0.68317 (r=0.697,p=0.670),  time:19.207, tt:557.007\n",
      "Ep:29, loss:0.00002, loss_test:0.10921, lr:9.32e-03, fs:0.69268 (r=0.717,p=0.670),  time:19.260, tt:577.806\n",
      "Ep:30, loss:0.00002, loss_test:0.10869, lr:9.23e-03, fs:0.69608 (r=0.717,p=0.676),  time:19.298, tt:598.238\n",
      "Ep:31, loss:0.00002, loss_test:0.10818, lr:9.14e-03, fs:0.70297 (r=0.717,p=0.689),  time:19.355, tt:619.347\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.10732, lr:9.14e-03, fs:0.70647 (r=0.717,p=0.696),  time:19.287, tt:636.483\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10673, lr:9.14e-03, fs:0.70297 (r=0.717,p=0.689),  time:19.314, tt:656.675\n",
      "Ep:34, loss:0.00002, loss_test:0.10638, lr:9.14e-03, fs:0.70297 (r=0.717,p=0.689),  time:19.283, tt:674.915\n",
      "Ep:35, loss:0.00002, loss_test:0.10625, lr:9.14e-03, fs:0.71795 (r=0.707,p=0.729),  time:19.255, tt:693.194\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.10613, lr:9.14e-03, fs:0.71795 (r=0.707,p=0.729),  time:19.234, tt:711.650\n",
      "Ep:37, loss:0.00002, loss_test:0.10532, lr:9.14e-03, fs:0.71795 (r=0.707,p=0.729),  time:19.223, tt:730.490\n",
      "Ep:38, loss:0.00002, loss_test:0.10445, lr:9.14e-03, fs:0.73000 (r=0.737,p=0.723),  time:19.232, tt:750.036\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.10430, lr:9.14e-03, fs:0.72821 (r=0.717,p=0.740),  time:19.253, tt:770.131\n",
      "Ep:40, loss:0.00002, loss_test:0.10417, lr:9.14e-03, fs:0.72539 (r=0.707,p=0.745),  time:19.258, tt:789.595\n",
      "Ep:41, loss:0.00002, loss_test:0.10353, lr:9.14e-03, fs:0.72917 (r=0.707,p=0.753),  time:19.290, tt:810.167\n",
      "Ep:42, loss:0.00002, loss_test:0.10293, lr:9.14e-03, fs:0.71875 (r=0.697,p=0.742),  time:19.259, tt:828.154\n",
      "Ep:43, loss:0.00002, loss_test:0.10283, lr:9.14e-03, fs:0.71277 (r=0.677,p=0.753),  time:19.261, tt:847.466\n",
      "Ep:44, loss:0.00002, loss_test:0.10237, lr:9.14e-03, fs:0.71277 (r=0.677,p=0.753),  time:19.258, tt:866.592\n",
      "Ep:45, loss:0.00002, loss_test:0.10151, lr:9.14e-03, fs:0.71277 (r=0.677,p=0.753),  time:19.270, tt:886.419\n",
      "Ep:46, loss:0.00002, loss_test:0.10104, lr:9.14e-03, fs:0.71277 (r=0.677,p=0.753),  time:19.251, tt:904.776\n",
      "Ep:47, loss:0.00002, loss_test:0.10057, lr:9.14e-03, fs:0.71658 (r=0.677,p=0.761),  time:19.251, tt:924.043\n",
      "Ep:48, loss:0.00001, loss_test:0.10021, lr:9.14e-03, fs:0.71658 (r=0.677,p=0.761),  time:19.224, tt:941.999\n",
      "Ep:49, loss:0.00001, loss_test:0.10008, lr:9.14e-03, fs:0.71739 (r=0.667,p=0.776),  time:19.233, tt:961.626\n",
      "Ep:50, loss:0.00001, loss_test:0.09979, lr:9.04e-03, fs:0.71739 (r=0.667,p=0.776),  time:19.334, tt:986.046\n",
      "Ep:51, loss:0.00001, loss_test:0.09967, lr:8.95e-03, fs:0.72432 (r=0.677,p=0.779),  time:19.323, tt:1004.800\n",
      "Ep:52, loss:0.00001, loss_test:0.09985, lr:8.86e-03, fs:0.71038 (r=0.657,p=0.774),  time:19.331, tt:1024.518\n",
      "Ep:53, loss:0.00001, loss_test:0.09942, lr:8.78e-03, fs:0.71739 (r=0.667,p=0.776),  time:19.300, tt:1042.220\n",
      "Ep:54, loss:0.00001, loss_test:0.09961, lr:8.69e-03, fs:0.71038 (r=0.657,p=0.774),  time:19.306, tt:1061.815\n",
      "Ep:55, loss:0.00001, loss_test:0.09944, lr:8.60e-03, fs:0.70652 (r=0.657,p=0.765),  time:19.288, tt:1080.148\n",
      "Ep:56, loss:0.00001, loss_test:0.09938, lr:8.51e-03, fs:0.70652 (r=0.657,p=0.765),  time:19.314, tt:1100.902\n",
      "Ep:57, loss:0.00001, loss_test:0.09921, lr:8.43e-03, fs:0.71038 (r=0.657,p=0.774),  time:19.299, tt:1119.365\n",
      "Ep:58, loss:0.00001, loss_test:0.09886, lr:8.35e-03, fs:0.71429 (r=0.657,p=0.783),  time:19.310, tt:1139.263\n",
      "Ep:59, loss:0.00001, loss_test:0.09908, lr:8.26e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.288, tt:1157.308\n",
      "Ep:60, loss:0.00001, loss_test:0.09830, lr:8.18e-03, fs:0.71739 (r=0.667,p=0.776),  time:19.268, tt:1175.355\n",
      "Ep:61, loss:0.00001, loss_test:0.09902, lr:8.10e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.280, tt:1195.351\n",
      "Ep:62, loss:0.00001, loss_test:0.09866, lr:8.02e-03, fs:0.72131 (r=0.667,p=0.786),  time:19.277, tt:1214.460\n",
      "Ep:63, loss:0.00001, loss_test:0.09868, lr:7.94e-03, fs:0.72131 (r=0.667,p=0.786),  time:19.298, tt:1235.071\n",
      "Ep:64, loss:0.00001, loss_test:0.09943, lr:7.86e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.298, tt:1254.350\n",
      "Ep:65, loss:0.00001, loss_test:0.09875, lr:7.78e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.303, tt:1273.993\n",
      "Ep:66, loss:0.00001, loss_test:0.09803, lr:7.70e-03, fs:0.72432 (r=0.677,p=0.779),  time:19.306, tt:1293.475\n",
      "Ep:67, loss:0.00001, loss_test:0.09905, lr:7.62e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.317, tt:1313.582\n",
      "Ep:68, loss:0.00001, loss_test:0.09876, lr:7.55e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.330, tt:1333.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:69, loss:0.00001, loss_test:0.09784, lr:7.47e-03, fs:0.72432 (r=0.677,p=0.779),  time:19.348, tt:1354.386\n",
      "Ep:70, loss:0.00001, loss_test:0.09854, lr:7.40e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.425, tt:1379.140\n",
      "Ep:71, loss:0.00001, loss_test:0.09876, lr:7.32e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.441, tt:1399.759\n",
      "Ep:72, loss:0.00001, loss_test:0.09807, lr:7.25e-03, fs:0.72527 (r=0.667,p=0.795),  time:19.472, tt:1421.479\n",
      "Ep:73, loss:0.00001, loss_test:0.09825, lr:7.18e-03, fs:0.72131 (r=0.667,p=0.786),  time:19.471, tt:1440.865\n",
      "Ep:74, loss:0.00001, loss_test:0.09864, lr:7.11e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.488, tt:1461.574\n",
      "Ep:75, loss:0.00001, loss_test:0.09818, lr:7.03e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.507, tt:1482.516\n",
      "Ep:76, loss:0.00001, loss_test:0.09795, lr:6.96e-03, fs:0.72527 (r=0.667,p=0.795),  time:19.526, tt:1503.479\n",
      "Ep:77, loss:0.00001, loss_test:0.09856, lr:6.89e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.533, tt:1523.578\n",
      "Ep:78, loss:0.00001, loss_test:0.09868, lr:6.83e-03, fs:0.71186 (r=0.636,p=0.808),  time:19.557, tt:1544.990\n",
      "Ep:79, loss:0.00001, loss_test:0.09819, lr:6.76e-03, fs:0.72928 (r=0.667,p=0.805),  time:19.566, tt:1565.253\n",
      "Ep:80, loss:0.00001, loss_test:0.09846, lr:6.69e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.578, tt:1585.816\n",
      "Ep:81, loss:0.00001, loss_test:0.09852, lr:6.62e-03, fs:0.71186 (r=0.636,p=0.808),  time:19.610, tt:1607.986\n",
      "Ep:82, loss:0.00001, loss_test:0.09827, lr:6.56e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.633, tt:1629.522\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.09838, lr:6.56e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.641, tt:1649.828\n",
      "Ep:84, loss:0.00001, loss_test:0.09838, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:19.656, tt:1670.732\n",
      "Ep:85, loss:0.00001, loss_test:0.09812, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:19.658, tt:1690.603\n",
      "Ep:86, loss:0.00001, loss_test:0.09802, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:19.663, tt:1710.682\n",
      "Ep:87, loss:0.00001, loss_test:0.09872, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:19.641, tt:1728.426\n",
      "Ep:88, loss:0.00001, loss_test:0.09873, lr:6.56e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.652, tt:1749.054\n",
      "Ep:89, loss:0.00001, loss_test:0.09877, lr:6.56e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.667, tt:1770.074\n",
      "Ep:90, loss:0.00001, loss_test:0.09839, lr:6.56e-03, fs:0.72626 (r=0.657,p=0.812),  time:19.724, tt:1794.858\n",
      "Ep:91, loss:0.00001, loss_test:0.09860, lr:6.56e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.741, tt:1816.145\n",
      "Ep:92, loss:0.00001, loss_test:0.09868, lr:6.56e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.752, tt:1836.921\n",
      "Ep:93, loss:0.00001, loss_test:0.09838, lr:6.56e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.746, tt:1856.131\n",
      "Ep:94, loss:0.00001, loss_test:0.09841, lr:6.49e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.753, tt:1876.546\n",
      "Ep:95, loss:0.00001, loss_test:0.09808, lr:6.43e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.747, tt:1895.753\n",
      "Ep:96, loss:0.00001, loss_test:0.09882, lr:6.36e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.759, tt:1916.624\n",
      "Ep:97, loss:0.00001, loss_test:0.09871, lr:6.30e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.753, tt:1935.778\n",
      "Ep:98, loss:0.00001, loss_test:0.09831, lr:6.24e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.750, tt:1955.237\n",
      "Ep:99, loss:0.00001, loss_test:0.09854, lr:6.17e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.746, tt:1974.621\n",
      "Ep:100, loss:0.00001, loss_test:0.09829, lr:6.11e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.746, tt:1994.348\n",
      "Ep:101, loss:0.00001, loss_test:0.09866, lr:6.05e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.743, tt:2013.770\n",
      "Ep:102, loss:0.00001, loss_test:0.09862, lr:5.99e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.758, tt:2035.044\n",
      "Ep:103, loss:0.00001, loss_test:0.09816, lr:5.93e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.748, tt:2053.779\n",
      "Ep:104, loss:0.00001, loss_test:0.09885, lr:5.87e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.750, tt:2073.751\n",
      "Ep:105, loss:0.00001, loss_test:0.09903, lr:5.81e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.759, tt:2094.442\n",
      "Ep:106, loss:0.00001, loss_test:0.09858, lr:5.75e-03, fs:0.71429 (r=0.657,p=0.783),  time:19.773, tt:2115.684\n",
      "Ep:107, loss:0.00001, loss_test:0.10028, lr:5.70e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.769, tt:2135.054\n",
      "Ep:108, loss:0.00001, loss_test:0.10054, lr:5.64e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.771, tt:2155.077\n",
      "Ep:109, loss:0.00001, loss_test:0.09910, lr:5.58e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.779, tt:2175.687\n",
      "Ep:110, loss:0.00001, loss_test:0.09864, lr:5.53e-03, fs:0.71351 (r=0.667,p=0.767),  time:19.783, tt:2195.903\n",
      "Ep:111, loss:0.00001, loss_test:0.10111, lr:5.47e-03, fs:0.70857 (r=0.626,p=0.816),  time:19.788, tt:2216.230\n",
      "Ep:112, loss:0.00001, loss_test:0.10196, lr:5.42e-03, fs:0.70520 (r=0.616,p=0.824),  time:19.794, tt:2236.721\n",
      "Ep:113, loss:0.00001, loss_test:0.09999, lr:5.36e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.793, tt:2256.388\n",
      "Ep:114, loss:0.00000, loss_test:0.09839, lr:5.31e-03, fs:0.72043 (r=0.677,p=0.770),  time:19.791, tt:2275.947\n",
      "Ep:115, loss:0.00001, loss_test:0.09948, lr:5.26e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.791, tt:2295.714\n",
      "Ep:116, loss:0.00000, loss_test:0.10076, lr:5.20e-03, fs:0.70857 (r=0.626,p=0.816),  time:19.843, tt:2321.662\n",
      "Ep:117, loss:0.00000, loss_test:0.10021, lr:5.15e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.853, tt:2342.684\n",
      "Ep:118, loss:0.00000, loss_test:0.09860, lr:5.10e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.864, tt:2363.831\n",
      "Ep:119, loss:0.00000, loss_test:0.09856, lr:5.05e-03, fs:0.73333 (r=0.667,p=0.815),  time:19.877, tt:2385.228\n",
      "Ep:120, loss:0.00000, loss_test:0.09953, lr:5.00e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.880, tt:2405.499\n",
      "Ep:121, loss:0.00000, loss_test:0.09996, lr:4.95e-03, fs:0.70857 (r=0.626,p=0.816),  time:19.877, tt:2424.989\n",
      "Ep:122, loss:0.00000, loss_test:0.09915, lr:4.90e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.887, tt:2446.120\n",
      "Ep:123, loss:0.00000, loss_test:0.09851, lr:4.85e-03, fs:0.72527 (r=0.667,p=0.795),  time:19.895, tt:2467.012\n",
      "Ep:124, loss:0.00000, loss_test:0.09943, lr:4.80e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.896, tt:2487.020\n",
      "Ep:125, loss:0.00000, loss_test:0.10006, lr:4.75e-03, fs:0.70857 (r=0.626,p=0.816),  time:19.900, tt:2507.376\n",
      "Ep:126, loss:0.00000, loss_test:0.09941, lr:4.71e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.906, tt:2528.027\n",
      "Ep:127, loss:0.00000, loss_test:0.09868, lr:4.66e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.908, tt:2548.170\n",
      "Ep:128, loss:0.00000, loss_test:0.09921, lr:4.61e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.904, tt:2567.571\n",
      "Ep:129, loss:0.00000, loss_test:0.09974, lr:4.57e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.896, tt:2586.441\n",
      "Ep:130, loss:0.00000, loss_test:0.09903, lr:4.52e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.896, tt:2606.356\n",
      "Ep:131, loss:0.00000, loss_test:0.09830, lr:4.48e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.895, tt:2626.202\n",
      "Ep:132, loss:0.00000, loss_test:0.09922, lr:4.43e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.890, tt:2645.385\n",
      "Ep:133, loss:0.00000, loss_test:0.09945, lr:4.39e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.886, tt:2664.680\n",
      "Ep:134, loss:0.00000, loss_test:0.09874, lr:4.34e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.880, tt:2683.788\n",
      "Ep:135, loss:0.00000, loss_test:0.09835, lr:4.30e-03, fs:0.70718 (r=0.646,p=0.780),  time:19.880, tt:2703.722\n",
      "Ep:136, loss:0.00000, loss_test:0.09915, lr:4.26e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.882, tt:2723.864\n",
      "Ep:137, loss:0.00000, loss_test:0.09976, lr:4.21e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.877, tt:2742.980\n",
      "Ep:138, loss:0.00000, loss_test:0.09913, lr:4.17e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.880, tt:2763.339\n",
      "Ep:139, loss:0.00000, loss_test:0.09839, lr:4.13e-03, fs:0.70718 (r=0.646,p=0.780),  time:19.868, tt:2781.578\n",
      "Ep:140, loss:0.00000, loss_test:0.09928, lr:4.09e-03, fs:0.72316 (r=0.646,p=0.821),  time:19.875, tt:2802.425\n",
      "Ep:141, loss:0.00000, loss_test:0.09926, lr:4.05e-03, fs:0.72727 (r=0.646,p=0.831),  time:19.870, tt:2821.532\n",
      "Ep:142, loss:0.00000, loss_test:0.09865, lr:4.01e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.865, tt:2840.722\n",
      "Ep:143, loss:0.00000, loss_test:0.09868, lr:3.97e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.852, tt:2858.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:144, loss:0.00000, loss_test:0.09879, lr:3.93e-03, fs:0.71910 (r=0.646,p=0.810),  time:19.863, tt:2880.092\n",
      "Ep:145, loss:0.00000, loss_test:0.09870, lr:3.89e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.871, tt:2901.144\n",
      "Ep:146, loss:0.00000, loss_test:0.09924, lr:3.85e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.871, tt:2921.101\n",
      "Ep:147, loss:0.00000, loss_test:0.09886, lr:3.81e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.868, tt:2940.492\n",
      "Ep:148, loss:0.00000, loss_test:0.09824, lr:3.77e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.873, tt:2961.062\n",
      "Ep:149, loss:0.00000, loss_test:0.09906, lr:3.73e-03, fs:0.72727 (r=0.646,p=0.831),  time:19.915, tt:2987.266\n",
      "Ep:150, loss:0.00000, loss_test:0.09926, lr:3.70e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.925, tt:3008.633\n",
      "Ep:151, loss:0.00000, loss_test:0.09848, lr:3.66e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.932, tt:3029.644\n",
      "Ep:152, loss:0.00000, loss_test:0.09814, lr:3.62e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.935, tt:3050.038\n",
      "Ep:153, loss:0.00000, loss_test:0.09904, lr:3.59e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.930, tt:3069.164\n",
      "Ep:154, loss:0.00000, loss_test:0.09935, lr:3.55e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.938, tt:3090.416\n",
      "Ep:155, loss:0.00000, loss_test:0.09877, lr:3.52e-03, fs:0.73446 (r=0.657,p=0.833),  time:19.939, tt:3110.439\n",
      "##########Best model found so far##########\n",
      "Ep:156, loss:0.00000, loss_test:0.09827, lr:3.52e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.947, tt:3131.633\n",
      "Ep:157, loss:0.00000, loss_test:0.09825, lr:3.52e-03, fs:0.71508 (r=0.646,p=0.800),  time:19.949, tt:3151.873\n",
      "Ep:158, loss:0.00000, loss_test:0.09857, lr:3.52e-03, fs:0.73034 (r=0.657,p=0.823),  time:19.957, tt:3173.158\n",
      "Ep:159, loss:0.00000, loss_test:0.09860, lr:3.52e-03, fs:0.73446 (r=0.657,p=0.833),  time:19.963, tt:3194.021\n",
      "Ep:160, loss:0.00000, loss_test:0.09893, lr:3.52e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.968, tt:3214.928\n",
      "Ep:161, loss:0.00000, loss_test:0.09851, lr:3.52e-03, fs:0.72414 (r=0.636,p=0.840),  time:19.973, tt:3235.696\n",
      "Ep:162, loss:0.00000, loss_test:0.09813, lr:3.52e-03, fs:0.71823 (r=0.657,p=0.793),  time:19.976, tt:3256.059\n",
      "Ep:163, loss:0.00000, loss_test:0.09871, lr:3.52e-03, fs:0.73446 (r=0.657,p=0.833),  time:19.976, tt:3275.987\n",
      "Ep:164, loss:0.00000, loss_test:0.09954, lr:3.52e-03, fs:0.72414 (r=0.636,p=0.840),  time:19.977, tt:3296.217\n",
      "Ep:165, loss:0.00000, loss_test:0.09934, lr:3.52e-03, fs:0.72000 (r=0.636,p=0.829),  time:19.984, tt:3317.319\n",
      "Ep:166, loss:0.00000, loss_test:0.09827, lr:3.52e-03, fs:0.71591 (r=0.636,p=0.818),  time:19.985, tt:3337.442\n",
      "Ep:167, loss:0.00000, loss_test:0.09777, lr:3.48e-03, fs:0.72222 (r=0.657,p=0.802),  time:19.986, tt:3357.726\n",
      "Ep:168, loss:0.00000, loss_test:0.09916, lr:3.45e-03, fs:0.72414 (r=0.636,p=0.840),  time:19.989, tt:3378.069\n",
      "Ep:169, loss:0.00000, loss_test:0.09990, lr:3.41e-03, fs:0.72832 (r=0.636,p=0.851),  time:19.992, tt:3398.708\n",
      "Ep:170, loss:0.00000, loss_test:0.09931, lr:3.38e-03, fs:0.72414 (r=0.636,p=0.840),  time:20.000, tt:3420.019\n",
      "Ep:171, loss:0.00000, loss_test:0.09813, lr:3.34e-03, fs:0.72626 (r=0.657,p=0.812),  time:20.006, tt:3440.991\n",
      "Ep:172, loss:0.00000, loss_test:0.09788, lr:3.31e-03, fs:0.72222 (r=0.657,p=0.802),  time:20.016, tt:3462.777\n",
      "Ep:173, loss:0.00000, loss_test:0.09873, lr:3.28e-03, fs:0.72414 (r=0.636,p=0.840),  time:20.022, tt:3483.784\n",
      "Ep:174, loss:0.00000, loss_test:0.09925, lr:3.24e-03, fs:0.72832 (r=0.636,p=0.851),  time:20.025, tt:3504.435\n",
      "Ep:175, loss:0.00000, loss_test:0.09907, lr:3.21e-03, fs:0.72832 (r=0.636,p=0.851),  time:20.033, tt:3525.738\n",
      "Ep:176, loss:0.00000, loss_test:0.09835, lr:3.18e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.032, tt:3545.674\n",
      "Ep:177, loss:0.00000, loss_test:0.09781, lr:3.15e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.043, tt:3567.709\n",
      "Ep:178, loss:0.00000, loss_test:0.09813, lr:3.12e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.050, tt:3588.997\n",
      "Ep:179, loss:0.00000, loss_test:0.09851, lr:3.09e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.056, tt:3610.098\n",
      "Ep:180, loss:0.00000, loss_test:0.09852, lr:3.05e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.057, tt:3630.404\n",
      "Ep:181, loss:0.00000, loss_test:0.09836, lr:3.02e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.054, tt:3649.803\n",
      "Ep:182, loss:0.00000, loss_test:0.09799, lr:2.99e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.060, tt:3671.002\n",
      "Ep:183, loss:0.00000, loss_test:0.09792, lr:2.96e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.068, tt:3692.520\n",
      "Ep:184, loss:0.00000, loss_test:0.09881, lr:2.93e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.071, tt:3713.223\n",
      "Ep:185, loss:0.00000, loss_test:0.09905, lr:2.90e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.079, tt:3734.755\n",
      "##########Best model found so far##########\n",
      "Ep:186, loss:0.00000, loss_test:0.09854, lr:2.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.075, tt:3754.045\n",
      "Ep:187, loss:0.00000, loss_test:0.09786, lr:2.90e-03, fs:0.72626 (r=0.657,p=0.812),  time:20.080, tt:3775.121\n",
      "Ep:188, loss:0.00000, loss_test:0.09798, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.090, tt:3796.937\n",
      "Ep:189, loss:0.00000, loss_test:0.09842, lr:2.90e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.093, tt:3817.671\n",
      "Ep:190, loss:0.00000, loss_test:0.09860, lr:2.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.102, tt:3839.466\n",
      "Ep:191, loss:0.00000, loss_test:0.09839, lr:2.90e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.104, tt:3859.901\n",
      "Ep:192, loss:0.00000, loss_test:0.09813, lr:2.90e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.108, tt:3880.790\n",
      "Ep:193, loss:0.00000, loss_test:0.09776, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.108, tt:3901.045\n",
      "Ep:194, loss:0.00000, loss_test:0.09794, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.111, tt:3921.679\n",
      "Ep:195, loss:0.00000, loss_test:0.09837, lr:2.90e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.114, tt:3942.327\n",
      "##########Best model found so far##########\n",
      "Ep:196, loss:0.00000, loss_test:0.09830, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.120, tt:3963.658\n",
      "Ep:197, loss:0.00000, loss_test:0.09800, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.126, tt:3984.864\n",
      "Ep:198, loss:0.00000, loss_test:0.09803, lr:2.90e-03, fs:0.72316 (r=0.646,p=0.821),  time:20.124, tt:4004.704\n",
      "Ep:199, loss:0.00000, loss_test:0.09785, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.123, tt:4024.655\n",
      "Ep:200, loss:0.00000, loss_test:0.09854, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.125, tt:4045.051\n",
      "Ep:201, loss:0.00000, loss_test:0.09861, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.132, tt:4066.681\n",
      "Ep:202, loss:0.00000, loss_test:0.09819, lr:2.90e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.136, tt:4087.628\n",
      "Ep:203, loss:0.00000, loss_test:0.09779, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.146, tt:4109.859\n",
      "Ep:204, loss:0.00000, loss_test:0.09788, lr:2.90e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.150, tt:4130.743\n",
      "Ep:205, loss:0.00000, loss_test:0.09838, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.153, tt:4151.466\n",
      "Ep:206, loss:0.00000, loss_test:0.09848, lr:2.90e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.155, tt:4172.041\n",
      "Ep:207, loss:0.00000, loss_test:0.09803, lr:2.88e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.159, tt:4193.019\n",
      "Ep:208, loss:0.00000, loss_test:0.09770, lr:2.85e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.160, tt:4213.342\n",
      "Ep:209, loss:0.00000, loss_test:0.09812, lr:2.82e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.160, tt:4233.599\n",
      "Ep:210, loss:0.00000, loss_test:0.09826, lr:2.79e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.165, tt:4254.735\n",
      "Ep:211, loss:0.00000, loss_test:0.09803, lr:2.76e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.163, tt:4274.608\n",
      "Ep:212, loss:0.00000, loss_test:0.09822, lr:2.73e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.161, tt:4294.395\n",
      "Ep:213, loss:0.00000, loss_test:0.09834, lr:2.71e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.162, tt:4314.666\n",
      "Ep:214, loss:0.00000, loss_test:0.09819, lr:2.68e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.182, tt:4339.044\n",
      "Ep:215, loss:0.00000, loss_test:0.09778, lr:2.65e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.180, tt:4358.786\n",
      "Ep:216, loss:0.00000, loss_test:0.09845, lr:2.63e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.184, tt:4380.034\n",
      "Ep:217, loss:0.00000, loss_test:0.09868, lr:2.60e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.188, tt:4400.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:218, loss:0.00000, loss_test:0.09852, lr:2.57e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.185, tt:4420.506\n",
      "Ep:219, loss:0.00000, loss_test:0.09793, lr:2.55e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.183, tt:4440.217\n",
      "Ep:220, loss:0.00000, loss_test:0.09757, lr:2.52e-03, fs:0.73034 (r=0.657,p=0.823),  time:20.179, tt:4459.497\n",
      "Ep:221, loss:0.00000, loss_test:0.09798, lr:2.50e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.170, tt:4477.785\n",
      "Ep:222, loss:0.00000, loss_test:0.09842, lr:2.47e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.164, tt:4496.682\n",
      "Ep:223, loss:0.00000, loss_test:0.09841, lr:2.45e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.163, tt:4516.537\n",
      "Ep:224, loss:0.00000, loss_test:0.09802, lr:2.42e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.166, tt:4537.432\n",
      "Ep:225, loss:0.00000, loss_test:0.09772, lr:2.40e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.162, tt:4556.612\n",
      "Ep:226, loss:0.00000, loss_test:0.09767, lr:2.38e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.164, tt:4577.238\n",
      "Ep:227, loss:0.00000, loss_test:0.09804, lr:2.35e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.161, tt:4596.714\n",
      "Ep:228, loss:0.00000, loss_test:0.09805, lr:2.33e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.157, tt:4615.957\n",
      "Ep:229, loss:0.00000, loss_test:0.09803, lr:2.31e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.153, tt:4635.099\n",
      "Ep:230, loss:0.00000, loss_test:0.09818, lr:2.28e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.156, tt:4656.137\n",
      "Ep:231, loss:0.00000, loss_test:0.09817, lr:2.26e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.160, tt:4677.037\n",
      "Ep:232, loss:0.00000, loss_test:0.09805, lr:2.24e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.157, tt:4696.517\n",
      "Ep:233, loss:0.00000, loss_test:0.09800, lr:2.21e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.156, tt:4716.576\n",
      "Ep:234, loss:0.00000, loss_test:0.09792, lr:2.19e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.150, tt:4735.296\n",
      "Ep:235, loss:0.00000, loss_test:0.09798, lr:2.17e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.146, tt:4754.376\n",
      "Ep:236, loss:0.00000, loss_test:0.09824, lr:2.15e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.141, tt:4773.372\n",
      "Ep:237, loss:0.00000, loss_test:0.09828, lr:2.13e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.142, tt:4793.711\n",
      "Ep:238, loss:0.00000, loss_test:0.09800, lr:2.11e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.143, tt:4814.090\n",
      "Ep:239, loss:0.00000, loss_test:0.09772, lr:2.08e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.138, tt:4833.206\n",
      "Ep:240, loss:0.00000, loss_test:0.09814, lr:2.06e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.132, tt:4851.856\n",
      "Ep:241, loss:0.00000, loss_test:0.09840, lr:2.04e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.132, tt:4872.060\n",
      "Ep:242, loss:0.00000, loss_test:0.09830, lr:2.02e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.132, tt:4892.010\n",
      "Ep:243, loss:0.00000, loss_test:0.09791, lr:2.00e-03, fs:0.73446 (r=0.657,p=0.833),  time:20.127, tt:4911.090\n",
      "Ep:244, loss:0.00000, loss_test:0.09779, lr:1.98e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.117, tt:4928.668\n",
      "Ep:245, loss:0.00000, loss_test:0.09806, lr:1.96e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.117, tt:4948.723\n",
      "Ep:246, loss:0.00000, loss_test:0.09821, lr:1.94e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.120, tt:4969.529\n",
      "Ep:247, loss:0.00000, loss_test:0.09813, lr:1.92e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.119, tt:4989.421\n",
      "Ep:248, loss:0.00000, loss_test:0.09786, lr:1.90e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.121, tt:5010.177\n",
      "Ep:249, loss:0.00000, loss_test:0.09781, lr:1.89e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.123, tt:5030.802\n",
      "Ep:250, loss:0.00000, loss_test:0.09786, lr:1.87e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.127, tt:5051.796\n",
      "Ep:251, loss:0.00000, loss_test:0.09816, lr:1.85e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.126, tt:5071.851\n",
      "Ep:252, loss:0.00000, loss_test:0.09814, lr:1.83e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.131, tt:5093.258\n",
      "Ep:253, loss:0.00000, loss_test:0.09785, lr:1.81e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.130, tt:5113.138\n",
      "Ep:254, loss:0.00000, loss_test:0.09783, lr:1.79e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.134, tt:5134.134\n",
      "Ep:255, loss:0.00000, loss_test:0.09799, lr:1.78e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.133, tt:5154.107\n",
      "Ep:256, loss:0.00000, loss_test:0.09802, lr:1.76e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.139, tt:5175.649\n",
      "Ep:257, loss:0.00000, loss_test:0.09798, lr:1.74e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.140, tt:5196.160\n",
      "Ep:258, loss:0.00000, loss_test:0.09779, lr:1.72e-03, fs:0.72727 (r=0.646,p=0.831),  time:20.137, tt:5215.506\n",
      "Ep:259, loss:0.00000, loss_test:0.09783, lr:1.71e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.135, tt:5235.223\n",
      "Ep:260, loss:0.00000, loss_test:0.09805, lr:1.69e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.133, tt:5254.686\n",
      "Ep:261, loss:0.00000, loss_test:0.09805, lr:1.67e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.136, tt:5275.696\n",
      "Ep:262, loss:0.00000, loss_test:0.09785, lr:1.65e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.136, tt:5295.641\n",
      "Ep:263, loss:0.00000, loss_test:0.09797, lr:1.64e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.134, tt:5315.278\n",
      "Ep:264, loss:0.00000, loss_test:0.09803, lr:1.62e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.129, tt:5334.143\n",
      "Ep:265, loss:0.00000, loss_test:0.09794, lr:1.61e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.124, tt:5352.966\n",
      "Ep:266, loss:0.00000, loss_test:0.09775, lr:1.59e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.122, tt:5372.646\n",
      "Ep:267, loss:0.00000, loss_test:0.09780, lr:1.57e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.119, tt:5391.805\n",
      "Ep:268, loss:0.00000, loss_test:0.09796, lr:1.56e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.112, tt:5410.080\n",
      "Ep:269, loss:0.00000, loss_test:0.09812, lr:1.54e-03, fs:0.73563 (r=0.646,p=0.853),  time:20.111, tt:5430.090\n",
      "Ep:270, loss:0.00000, loss_test:0.09810, lr:1.53e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.103, tt:5447.965\n",
      "Ep:271, loss:0.00000, loss_test:0.09793, lr:1.51e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.101, tt:5467.603\n",
      "Ep:272, loss:0.00000, loss_test:0.09803, lr:1.50e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.099, tt:5487.150\n",
      "Ep:273, loss:0.00000, loss_test:0.09801, lr:1.48e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.099, tt:5507.098\n",
      "Ep:274, loss:0.00000, loss_test:0.09801, lr:1.47e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.098, tt:5526.888\n",
      "Ep:275, loss:0.00000, loss_test:0.09799, lr:1.45e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.097, tt:5546.791\n",
      "Ep:276, loss:0.00000, loss_test:0.09802, lr:1.44e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.093, tt:5565.861\n",
      "Ep:277, loss:0.00000, loss_test:0.09798, lr:1.42e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.095, tt:5586.469\n",
      "Ep:278, loss:0.00000, loss_test:0.09779, lr:1.41e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.092, tt:5605.578\n",
      "Ep:279, loss:0.00000, loss_test:0.09773, lr:1.39e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.091, tt:5625.551\n",
      "Ep:280, loss:0.00000, loss_test:0.09791, lr:1.38e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.092, tt:5645.773\n",
      "Ep:281, loss:0.00000, loss_test:0.09800, lr:1.37e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.084, tt:5663.600\n",
      "Ep:282, loss:0.00000, loss_test:0.09792, lr:1.35e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.079, tt:5682.279\n",
      "Ep:283, loss:0.00000, loss_test:0.09778, lr:1.34e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.074, tt:5700.999\n",
      "Ep:284, loss:0.00000, loss_test:0.09792, lr:1.33e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.071, tt:5720.146\n",
      "Ep:285, loss:0.00000, loss_test:0.09802, lr:1.31e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.069, tt:5739.781\n",
      "Ep:286, loss:0.00000, loss_test:0.09795, lr:1.30e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.060, tt:5757.153\n",
      "Ep:287, loss:0.00000, loss_test:0.09792, lr:1.29e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.055, tt:5775.718\n",
      "Ep:288, loss:0.00000, loss_test:0.09780, lr:1.27e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.054, tt:5795.593\n",
      "Ep:289, loss:0.00000, loss_test:0.09778, lr:1.26e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.056, tt:5816.247\n",
      "Ep:290, loss:0.00000, loss_test:0.09790, lr:1.25e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.059, tt:5837.091\n",
      "Ep:291, loss:0.00000, loss_test:0.09809, lr:1.24e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.054, tt:5855.855\n",
      "Ep:292, loss:0.00000, loss_test:0.09811, lr:1.22e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.050, tt:5874.682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:293, loss:0.00000, loss_test:0.09798, lr:1.21e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.051, tt:5894.946\n",
      "Ep:294, loss:0.00000, loss_test:0.09781, lr:1.20e-03, fs:0.73864 (r=0.657,p=0.844),  time:20.051, tt:5915.142\n",
      "Ep:295, loss:0.00000, loss_test:0.09796, lr:1.19e-03, fs:0.73143 (r=0.646,p=0.842),  time:20.047, tt:5933.902\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 1\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 888 Test samples: 198\n",
      "Train positive samples: 444 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13541, lr:1.00e-02, fs:0.65744 (r=0.960,p=0.500),  time:12.367, tt:12.367\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13437, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:13.922, tt:27.844\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.13279, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:14.678, tt:44.032\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.13067, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:14.956, tt:59.825\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.12819, lr:1.00e-02, fs:0.67143 (r=0.949,p=0.519),  time:15.271, tt:76.357\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.12554, lr:1.00e-02, fs:0.67636 (r=0.939,p=0.528),  time:15.674, tt:94.044\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.12293, lr:1.00e-02, fs:0.68165 (r=0.919,p=0.542),  time:15.924, tt:111.469\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.12078, lr:1.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:16.100, tt:128.803\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.11892, lr:1.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:16.218, tt:145.962\n",
      "Ep:9, loss:0.00004, loss_test:0.11748, lr:1.00e-02, fs:0.70000 (r=0.848,p=0.596),  time:16.352, tt:163.517\n",
      "Ep:10, loss:0.00003, loss_test:0.11646, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:16.535, tt:181.880\n",
      "Ep:11, loss:0.00003, loss_test:0.11577, lr:1.00e-02, fs:0.68644 (r=0.818,p=0.591),  time:16.662, tt:199.946\n",
      "Ep:12, loss:0.00003, loss_test:0.11494, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:16.716, tt:217.309\n",
      "Ep:13, loss:0.00003, loss_test:0.11405, lr:1.00e-02, fs:0.68398 (r=0.798,p=0.598),  time:16.728, tt:234.197\n",
      "Ep:14, loss:0.00003, loss_test:0.11331, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:16.823, tt:252.338\n",
      "Ep:15, loss:0.00003, loss_test:0.11258, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:16.784, tt:268.548\n",
      "Ep:16, loss:0.00003, loss_test:0.11202, lr:1.00e-02, fs:0.69369 (r=0.778,p=0.626),  time:16.817, tt:285.887\n",
      "Ep:17, loss:0.00003, loss_test:0.11135, lr:1.00e-02, fs:0.68182 (r=0.758,p=0.620),  time:16.841, tt:303.139\n",
      "Ep:18, loss:0.00003, loss_test:0.11068, lr:1.00e-02, fs:0.70320 (r=0.778,p=0.642),  time:16.902, tt:321.136\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.10987, lr:1.00e-02, fs:0.70909 (r=0.788,p=0.645),  time:16.984, tt:339.672\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.10919, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:16.991, tt:356.803\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.10863, lr:1.00e-02, fs:0.71560 (r=0.788,p=0.655),  time:17.070, tt:375.551\n",
      "Ep:22, loss:0.00003, loss_test:0.10828, lr:1.00e-02, fs:0.72146 (r=0.798,p=0.658),  time:17.107, tt:393.467\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10834, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:17.133, tt:411.182\n",
      "Ep:24, loss:0.00003, loss_test:0.10832, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:17.181, tt:429.521\n",
      "Ep:25, loss:0.00003, loss_test:0.10814, lr:1.00e-02, fs:0.69811 (r=0.747,p=0.655),  time:17.327, tt:450.499\n",
      "Ep:26, loss:0.00003, loss_test:0.10765, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:17.361, tt:468.746\n",
      "Ep:27, loss:0.00003, loss_test:0.10717, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:17.367, tt:486.272\n",
      "Ep:28, loss:0.00003, loss_test:0.10670, lr:1.00e-02, fs:0.71698 (r=0.768,p=0.673),  time:17.363, tt:503.534\n",
      "Ep:29, loss:0.00002, loss_test:0.10636, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:17.378, tt:521.338\n",
      "Ep:30, loss:0.00002, loss_test:0.10586, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:17.410, tt:539.713\n",
      "Ep:31, loss:0.00002, loss_test:0.10532, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:17.422, tt:557.520\n",
      "Ep:32, loss:0.00002, loss_test:0.10481, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.431, tt:575.231\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.10446, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.454, tt:593.449\n",
      "Ep:34, loss:0.00002, loss_test:0.10416, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:17.451, tt:610.768\n",
      "Ep:35, loss:0.00002, loss_test:0.10388, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:17.471, tt:628.944\n",
      "Ep:36, loss:0.00002, loss_test:0.10358, lr:1.00e-02, fs:0.72038 (r=0.768,p=0.679),  time:17.511, tt:647.908\n",
      "Ep:37, loss:0.00002, loss_test:0.10335, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:17.525, tt:665.935\n",
      "Ep:38, loss:0.00002, loss_test:0.10327, lr:1.00e-02, fs:0.71154 (r=0.747,p=0.679),  time:17.560, tt:684.832\n",
      "Ep:39, loss:0.00002, loss_test:0.10307, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:17.589, tt:703.572\n",
      "Ep:40, loss:0.00002, loss_test:0.10267, lr:1.00e-02, fs:0.71770 (r=0.758,p=0.682),  time:17.620, tt:722.417\n",
      "Ep:41, loss:0.00002, loss_test:0.10230, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:17.642, tt:740.960\n",
      "Ep:42, loss:0.00002, loss_test:0.10208, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:17.673, tt:759.942\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.10172, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:17.707, tt:779.114\n",
      "Ep:44, loss:0.00002, loss_test:0.10144, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.734, tt:798.024\n",
      "Ep:45, loss:0.00002, loss_test:0.10113, lr:1.00e-02, fs:0.72381 (r=0.768,p=0.685),  time:17.750, tt:816.477\n",
      "Ep:46, loss:0.00002, loss_test:0.10097, lr:1.00e-02, fs:0.73333 (r=0.778,p=0.694),  time:17.768, tt:835.108\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.10086, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.774, tt:853.152\n",
      "Ep:48, loss:0.00002, loss_test:0.10066, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.788, tt:871.596\n",
      "Ep:49, loss:0.00002, loss_test:0.10054, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:17.810, tt:890.488\n",
      "Ep:50, loss:0.00002, loss_test:0.10063, lr:1.00e-02, fs:0.72727 (r=0.768,p=0.691),  time:17.834, tt:909.515\n",
      "Ep:51, loss:0.00002, loss_test:0.10040, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:17.873, tt:929.415\n",
      "Ep:52, loss:0.00002, loss_test:0.10012, lr:1.00e-02, fs:0.73077 (r=0.768,p=0.697),  time:17.891, tt:948.219\n",
      "Ep:53, loss:0.00002, loss_test:0.10019, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:17.911, tt:967.198\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.10012, lr:1.00e-02, fs:0.73786 (r=0.768,p=0.710),  time:17.937, tt:986.512\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00002, loss_test:0.10002, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:17.964, tt:1005.963\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.10041, lr:1.00e-02, fs:0.73430 (r=0.768,p=0.704),  time:17.994, tt:1025.666\n",
      "Ep:57, loss:0.00001, loss_test:0.09994, lr:1.00e-02, fs:0.74146 (r=0.768,p=0.717),  time:18.018, tt:1045.021\n",
      "Ep:58, loss:0.00001, loss_test:0.10035, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:18.035, tt:1064.059\n",
      "Ep:59, loss:0.00001, loss_test:0.09999, lr:1.00e-02, fs:0.74510 (r=0.768,p=0.724),  time:18.036, tt:1082.151\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.10014, lr:1.00e-02, fs:0.74757 (r=0.778,p=0.720),  time:18.048, tt:1100.899\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00001, loss_test:0.09963, lr:1.00e-02, fs:0.74627 (r=0.758,p=0.735),  time:18.069, tt:1120.296\n",
      "Ep:62, loss:0.00001, loss_test:0.09978, lr:1.00e-02, fs:0.75622 (r=0.768,p=0.745),  time:18.083, tt:1139.223\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.09948, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:18.100, tt:1158.401\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00001, loss_test:0.09951, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:18.106, tt:1176.860\n",
      "Ep:65, loss:0.00001, loss_test:0.09966, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:18.141, tt:1197.287\n",
      "Ep:66, loss:0.00001, loss_test:0.09933, lr:1.00e-02, fs:0.75862 (r=0.778,p=0.740),  time:18.144, tt:1215.634\n",
      "Ep:67, loss:0.00001, loss_test:0.09936, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:18.141, tt:1233.621\n",
      "Ep:68, loss:0.00001, loss_test:0.09921, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:18.170, tt:1253.735\n",
      "##########Best model found so far##########\n",
      "Ep:69, loss:0.00001, loss_test:0.09875, lr:1.00e-02, fs:0.77387 (r=0.778,p=0.770),  time:18.191, tt:1273.368\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.09903, lr:1.00e-02, fs:0.75490 (r=0.778,p=0.733),  time:18.208, tt:1292.803\n",
      "Ep:71, loss:0.00001, loss_test:0.09834, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:18.206, tt:1310.861\n",
      "Ep:72, loss:0.00001, loss_test:0.09899, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:18.227, tt:1330.604\n",
      "Ep:73, loss:0.00001, loss_test:0.09853, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:18.239, tt:1349.654\n",
      "Ep:74, loss:0.00001, loss_test:0.09854, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:18.260, tt:1369.466\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.09917, lr:1.00e-02, fs:0.75897 (r=0.747,p=0.771),  time:18.274, tt:1388.861\n",
      "Ep:76, loss:0.00001, loss_test:0.09877, lr:1.00e-02, fs:0.76531 (r=0.758,p=0.773),  time:18.271, tt:1406.896\n",
      "Ep:77, loss:0.00001, loss_test:0.09842, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:18.290, tt:1426.592\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00001, loss_test:0.09888, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:18.297, tt:1445.488\n",
      "Ep:79, loss:0.00001, loss_test:0.09941, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:18.297, tt:1463.787\n",
      "Ep:80, loss:0.00001, loss_test:0.09832, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:18.301, tt:1482.421\n",
      "##########Best model found so far##########\n",
      "Ep:81, loss:0.00001, loss_test:0.09872, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:18.287, tt:1499.498\n",
      "Ep:82, loss:0.00001, loss_test:0.09916, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:18.271, tt:1516.510\n",
      "Ep:83, loss:0.00001, loss_test:0.09819, lr:1.00e-02, fs:0.78218 (r=0.798,p=0.767),  time:18.274, tt:1535.054\n",
      "Ep:84, loss:0.00001, loss_test:0.09826, lr:1.00e-02, fs:0.77143 (r=0.818,p=0.730),  time:18.264, tt:1552.476\n",
      "Ep:85, loss:0.00001, loss_test:0.09786, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:18.267, tt:1570.925\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.09855, lr:1.00e-02, fs:0.77320 (r=0.758,p=0.789),  time:18.272, tt:1589.623\n",
      "Ep:87, loss:0.00001, loss_test:0.09877, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:18.262, tt:1607.047\n",
      "Ep:88, loss:0.00001, loss_test:0.09748, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:18.268, tt:1625.858\n",
      "Ep:89, loss:0.00001, loss_test:0.09993, lr:1.00e-02, fs:0.77720 (r=0.758,p=0.798),  time:18.269, tt:1644.196\n",
      "Ep:90, loss:0.00001, loss_test:0.10042, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:18.273, tt:1662.888\n",
      "Ep:91, loss:0.00001, loss_test:0.09762, lr:1.00e-02, fs:0.77885 (r=0.818,p=0.743),  time:18.265, tt:1680.380\n",
      "Ep:92, loss:0.00001, loss_test:0.09952, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:18.258, tt:1698.019\n",
      "Ep:93, loss:0.00001, loss_test:0.10076, lr:1.00e-02, fs:0.73737 (r=0.737,p=0.737),  time:18.254, tt:1715.915\n",
      "Ep:94, loss:0.00001, loss_test:0.09670, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:18.256, tt:1734.278\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00001, loss_test:0.09626, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:18.253, tt:1752.305\n",
      "Ep:96, loss:0.00001, loss_test:0.09889, lr:1.00e-02, fs:0.74490 (r=0.737,p=0.753),  time:18.244, tt:1769.659\n",
      "Ep:97, loss:0.00001, loss_test:0.09879, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:18.242, tt:1787.755\n",
      "Ep:98, loss:0.00001, loss_test:0.09704, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:18.240, tt:1805.745\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.09800, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:18.228, tt:1822.826\n",
      "Ep:100, loss:0.00001, loss_test:0.09933, lr:1.00e-02, fs:0.77551 (r=0.768,p=0.784),  time:18.223, tt:1840.529\n",
      "Ep:101, loss:0.00001, loss_test:0.09886, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:18.220, tt:1858.448\n",
      "Ep:102, loss:0.00001, loss_test:0.09749, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:18.219, tt:1876.536\n",
      "Ep:103, loss:0.00001, loss_test:0.09833, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:18.218, tt:1894.645\n",
      "Ep:104, loss:0.00001, loss_test:0.09900, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:18.212, tt:1912.311\n",
      "Ep:105, loss:0.00001, loss_test:0.09839, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:18.208, tt:1929.998\n",
      "Ep:106, loss:0.00001, loss_test:0.09780, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:18.197, tt:1947.083\n",
      "Ep:107, loss:0.00001, loss_test:0.09768, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:18.182, tt:1963.649\n",
      "Ep:108, loss:0.00001, loss_test:0.09856, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:18.167, tt:1980.192\n",
      "Ep:109, loss:0.00001, loss_test:0.09905, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:18.162, tt:1997.855\n",
      "Ep:110, loss:0.00001, loss_test:0.09957, lr:9.90e-03, fs:0.80412 (r=0.788,p=0.821),  time:18.149, tt:2014.579\n",
      "Ep:111, loss:0.00001, loss_test:0.09846, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:18.154, tt:2033.225\n",
      "Ep:112, loss:0.00001, loss_test:0.09884, lr:9.70e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.153, tt:2051.265\n",
      "Ep:113, loss:0.00001, loss_test:0.09948, lr:9.61e-03, fs:0.79188 (r=0.788,p=0.796),  time:18.141, tt:2068.122\n",
      "Ep:114, loss:0.00001, loss_test:0.09841, lr:9.51e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.136, tt:2085.629\n",
      "Ep:115, loss:0.00001, loss_test:0.09795, lr:9.41e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.131, tt:2103.212\n",
      "##########Best model found so far##########\n",
      "Ep:116, loss:0.00001, loss_test:0.09854, lr:9.41e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.125, tt:2120.667\n",
      "Ep:117, loss:0.00001, loss_test:0.09885, lr:9.41e-03, fs:0.78607 (r=0.798,p=0.775),  time:18.118, tt:2137.888\n",
      "Ep:118, loss:0.00001, loss_test:0.09893, lr:9.41e-03, fs:0.80203 (r=0.798,p=0.806),  time:18.118, tt:2156.001\n",
      "Ep:119, loss:0.00001, loss_test:0.09775, lr:9.41e-03, fs:0.81633 (r=0.808,p=0.825),  time:18.118, tt:2174.184\n",
      "##########Best model found so far##########\n",
      "Ep:120, loss:0.00001, loss_test:0.09875, lr:9.41e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.109, tt:2191.142\n",
      "Ep:121, loss:0.00001, loss_test:0.09920, lr:9.41e-03, fs:0.79000 (r=0.798,p=0.782),  time:18.105, tt:2208.773\n",
      "Ep:122, loss:0.00001, loss_test:0.09875, lr:9.41e-03, fs:0.80203 (r=0.798,p=0.806),  time:18.089, tt:2224.976\n",
      "Ep:123, loss:0.00001, loss_test:0.09777, lr:9.41e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.092, tt:2243.443\n",
      "Ep:124, loss:0.00001, loss_test:0.09893, lr:9.41e-03, fs:0.80829 (r=0.788,p=0.830),  time:18.089, tt:2261.169\n",
      "Ep:125, loss:0.00000, loss_test:0.09870, lr:9.41e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.087, tt:2279.020\n",
      "Ep:126, loss:0.00000, loss_test:0.09804, lr:9.41e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.083, tt:2296.583\n",
      "Ep:127, loss:0.00000, loss_test:0.09863, lr:9.41e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.081, tt:2314.411\n",
      "##########Best model found so far##########\n",
      "Ep:128, loss:0.00000, loss_test:0.09839, lr:9.41e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.077, tt:2331.906\n",
      "Ep:129, loss:0.00000, loss_test:0.09796, lr:9.41e-03, fs:0.79798 (r=0.798,p=0.798),  time:18.079, tt:2350.313\n",
      "Ep:130, loss:0.00000, loss_test:0.09920, lr:9.41e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.075, tt:2367.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:131, loss:0.00000, loss_test:0.09765, lr:9.41e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.073, tt:2385.692\n",
      "Ep:132, loss:0.00000, loss_test:0.09814, lr:9.41e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.074, tt:2403.838\n",
      "Ep:133, loss:0.00000, loss_test:0.09823, lr:9.41e-03, fs:0.80203 (r=0.798,p=0.806),  time:18.075, tt:2422.005\n",
      "Ep:134, loss:0.00000, loss_test:0.09758, lr:9.41e-03, fs:0.80612 (r=0.798,p=0.814),  time:18.079, tt:2440.653\n",
      "Ep:135, loss:0.00000, loss_test:0.10005, lr:9.41e-03, fs:0.80423 (r=0.768,p=0.844),  time:18.083, tt:2459.300\n",
      "Ep:136, loss:0.00000, loss_test:0.09834, lr:9.41e-03, fs:0.82292 (r=0.798,p=0.849),  time:18.078, tt:2476.731\n",
      "##########Best model found so far##########\n",
      "Ep:137, loss:0.00000, loss_test:0.09713, lr:9.41e-03, fs:0.78818 (r=0.808,p=0.769),  time:18.078, tt:2494.800\n",
      "Ep:138, loss:0.00000, loss_test:0.10159, lr:9.41e-03, fs:0.76596 (r=0.727,p=0.809),  time:18.081, tt:2513.283\n",
      "Ep:139, loss:0.00000, loss_test:0.10093, lr:9.41e-03, fs:0.79144 (r=0.747,p=0.841),  time:18.075, tt:2530.554\n",
      "Ep:140, loss:0.00000, loss_test:0.09631, lr:9.41e-03, fs:0.80402 (r=0.808,p=0.800),  time:18.065, tt:2547.104\n",
      "Ep:141, loss:0.00000, loss_test:0.09901, lr:9.41e-03, fs:0.78974 (r=0.778,p=0.802),  time:18.065, tt:2565.268\n",
      "Ep:142, loss:0.00000, loss_test:0.09930, lr:9.41e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.053, tt:2581.623\n",
      "Ep:143, loss:0.00000, loss_test:0.09692, lr:9.41e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.055, tt:2599.898\n",
      "Ep:144, loss:0.00000, loss_test:0.09845, lr:9.41e-03, fs:0.81053 (r=0.778,p=0.846),  time:18.049, tt:2617.089\n",
      "Ep:145, loss:0.00000, loss_test:0.09795, lr:9.41e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.052, tt:2635.560\n",
      "Ep:146, loss:0.00000, loss_test:0.09656, lr:9.41e-03, fs:0.80808 (r=0.808,p=0.808),  time:18.051, tt:2653.567\n",
      "Ep:147, loss:0.00000, loss_test:0.10070, lr:9.41e-03, fs:0.81481 (r=0.778,p=0.856),  time:18.056, tt:2672.299\n",
      "Ep:148, loss:0.00000, loss_test:0.09950, lr:9.32e-03, fs:0.81053 (r=0.778,p=0.846),  time:18.058, tt:2690.689\n",
      "Ep:149, loss:0.00000, loss_test:0.09591, lr:9.23e-03, fs:0.80808 (r=0.808,p=0.808),  time:18.059, tt:2708.890\n",
      "Ep:150, loss:0.00000, loss_test:0.09869, lr:9.14e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.068, tt:2728.267\n",
      "Ep:151, loss:0.00000, loss_test:0.10026, lr:9.04e-03, fs:0.79787 (r=0.758,p=0.843),  time:18.076, tt:2747.598\n",
      "Ep:152, loss:0.00000, loss_test:0.09759, lr:8.95e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.081, tt:2766.424\n",
      "Ep:153, loss:0.00000, loss_test:0.09733, lr:8.86e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.088, tt:2785.578\n",
      "Ep:154, loss:0.00000, loss_test:0.09905, lr:8.78e-03, fs:0.81250 (r=0.788,p=0.839),  time:18.094, tt:2804.522\n",
      "Ep:155, loss:0.00000, loss_test:0.09924, lr:8.69e-03, fs:0.81675 (r=0.788,p=0.848),  time:18.099, tt:2823.510\n",
      "Ep:156, loss:0.00000, loss_test:0.09747, lr:8.60e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.102, tt:2841.951\n",
      "Ep:157, loss:0.00000, loss_test:0.09795, lr:8.51e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.115, tt:2862.137\n",
      "Ep:158, loss:0.00000, loss_test:0.09831, lr:8.43e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.118, tt:2880.830\n",
      "Ep:159, loss:0.00000, loss_test:0.09813, lr:8.35e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.117, tt:2898.733\n",
      "Ep:160, loss:0.00000, loss_test:0.09897, lr:8.26e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.124, tt:2917.960\n",
      "Ep:161, loss:0.00000, loss_test:0.09856, lr:8.18e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.118, tt:2935.048\n",
      "Ep:162, loss:0.00000, loss_test:0.09740, lr:8.10e-03, fs:0.81633 (r=0.808,p=0.825),  time:18.121, tt:2953.724\n",
      "Ep:163, loss:0.00000, loss_test:0.09841, lr:8.02e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.128, tt:2973.056\n",
      "Ep:164, loss:0.00000, loss_test:0.09922, lr:7.94e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.134, tt:2992.063\n",
      "Ep:165, loss:0.00000, loss_test:0.09802, lr:7.86e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.140, tt:3011.309\n",
      "Ep:166, loss:0.00000, loss_test:0.09814, lr:7.78e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.150, tt:3030.995\n",
      "Ep:167, loss:0.00000, loss_test:0.09858, lr:7.70e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.158, tt:3050.576\n",
      "Ep:168, loss:0.00000, loss_test:0.09750, lr:7.62e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.164, tt:3069.732\n",
      "Ep:169, loss:0.00000, loss_test:0.09767, lr:7.55e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.168, tt:3088.533\n",
      "Ep:170, loss:0.00000, loss_test:0.09886, lr:7.47e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.169, tt:3106.892\n",
      "Ep:171, loss:0.00000, loss_test:0.09708, lr:7.40e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.172, tt:3125.529\n",
      "Ep:172, loss:0.00000, loss_test:0.09827, lr:7.32e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.172, tt:3143.708\n",
      "Ep:173, loss:0.00000, loss_test:0.09914, lr:7.25e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.177, tt:3162.710\n",
      "Ep:174, loss:0.00000, loss_test:0.09763, lr:7.18e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.183, tt:3181.969\n",
      "##########Best model found so far##########\n",
      "Ep:175, loss:0.00000, loss_test:0.09862, lr:7.18e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.191, tt:3201.581\n",
      "Ep:176, loss:0.00000, loss_test:0.09794, lr:7.18e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.198, tt:3220.972\n",
      "Ep:177, loss:0.00000, loss_test:0.09824, lr:7.18e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.207, tt:3240.800\n",
      "Ep:178, loss:0.00000, loss_test:0.09865, lr:7.18e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.212, tt:3260.000\n",
      "Ep:179, loss:0.00000, loss_test:0.09790, lr:7.18e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.217, tt:3278.983\n",
      "Ep:180, loss:0.00000, loss_test:0.09772, lr:7.18e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.215, tt:3296.926\n",
      "Ep:181, loss:0.00000, loss_test:0.09862, lr:7.18e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.221, tt:3316.226\n",
      "Ep:182, loss:0.00000, loss_test:0.09706, lr:7.18e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.226, tt:3335.393\n",
      "Ep:183, loss:0.00000, loss_test:0.09858, lr:7.18e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.232, tt:3354.760\n",
      "Ep:184, loss:0.00000, loss_test:0.09788, lr:7.18e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.233, tt:3373.192\n",
      "Ep:185, loss:0.00000, loss_test:0.09773, lr:7.18e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.229, tt:3390.640\n",
      "Ep:186, loss:0.00000, loss_test:0.09861, lr:7.11e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.237, tt:3410.232\n",
      "Ep:187, loss:0.00000, loss_test:0.09706, lr:7.03e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.245, tt:3430.142\n",
      "Ep:188, loss:0.00000, loss_test:0.09867, lr:6.96e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.247, tt:3448.724\n",
      "Ep:189, loss:0.00000, loss_test:0.09778, lr:6.89e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.253, tt:3468.003\n",
      "Ep:190, loss:0.00000, loss_test:0.09739, lr:6.83e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.259, tt:3487.538\n",
      "Ep:191, loss:0.00000, loss_test:0.09854, lr:6.76e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.266, tt:3507.026\n",
      "Ep:192, loss:0.00000, loss_test:0.09782, lr:6.69e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.276, tt:3527.310\n",
      "Ep:193, loss:0.00000, loss_test:0.09752, lr:6.62e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.283, tt:3546.853\n",
      "Ep:194, loss:0.00000, loss_test:0.09878, lr:6.56e-03, fs:0.81443 (r=0.798,p=0.832),  time:18.287, tt:3565.936\n",
      "Ep:195, loss:0.00000, loss_test:0.09686, lr:6.49e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.287, tt:3584.291\n",
      "Ep:196, loss:0.00000, loss_test:0.09722, lr:6.43e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.285, tt:3602.054\n",
      "Ep:197, loss:0.00000, loss_test:0.09808, lr:6.36e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.290, tt:3621.342\n",
      "Ep:198, loss:0.00000, loss_test:0.09698, lr:6.30e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.298, tt:3641.381\n",
      "Ep:199, loss:0.00000, loss_test:0.09754, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.300, tt:3659.929\n",
      "##########Best model found so far##########\n",
      "Ep:200, loss:0.00000, loss_test:0.09834, lr:6.24e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.304, tt:3679.099\n",
      "Ep:201, loss:0.00000, loss_test:0.09693, lr:6.24e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.308, tt:3698.197\n",
      "Ep:202, loss:0.00000, loss_test:0.09844, lr:6.24e-03, fs:0.82292 (r=0.798,p=0.849),  time:18.311, tt:3717.128\n",
      "Ep:203, loss:0.00000, loss_test:0.09836, lr:6.24e-03, fs:0.82292 (r=0.798,p=0.849),  time:18.316, tt:3736.464\n",
      "Ep:204, loss:0.00000, loss_test:0.09653, lr:6.24e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.323, tt:3756.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:205, loss:0.00000, loss_test:0.09895, lr:6.24e-03, fs:0.81250 (r=0.788,p=0.839),  time:18.326, tt:3775.183\n",
      "Ep:206, loss:0.00000, loss_test:0.09875, lr:6.24e-03, fs:0.83158 (r=0.798,p=0.868),  time:18.332, tt:3794.687\n",
      "##########Best model found so far##########\n",
      "Ep:207, loss:0.00000, loss_test:0.09717, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.335, tt:3813.619\n",
      "Ep:208, loss:0.00000, loss_test:0.09765, lr:6.24e-03, fs:0.81633 (r=0.808,p=0.825),  time:18.342, tt:3833.470\n",
      "Ep:209, loss:0.00000, loss_test:0.09834, lr:6.24e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.343, tt:3851.974\n",
      "Ep:210, loss:0.00000, loss_test:0.09795, lr:6.24e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.346, tt:3871.081\n",
      "##########Best model found so far##########\n",
      "Ep:211, loss:0.00000, loss_test:0.09758, lr:6.24e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.348, tt:3889.857\n",
      "Ep:212, loss:0.00000, loss_test:0.09772, lr:6.24e-03, fs:0.81026 (r=0.798,p=0.823),  time:18.351, tt:3908.697\n",
      "Ep:213, loss:0.00000, loss_test:0.09733, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.356, tt:3928.164\n",
      "Ep:214, loss:0.00000, loss_test:0.09829, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.357, tt:3946.803\n",
      "Ep:215, loss:0.00000, loss_test:0.09855, lr:6.24e-03, fs:0.81865 (r=0.798,p=0.840),  time:18.361, tt:3965.972\n",
      "Ep:216, loss:0.00000, loss_test:0.09718, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.357, tt:3983.575\n",
      "Ep:217, loss:0.00000, loss_test:0.09766, lr:6.24e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.361, tt:4002.748\n",
      "Ep:218, loss:0.00000, loss_test:0.09808, lr:6.24e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.365, tt:4021.926\n",
      "Ep:219, loss:0.00000, loss_test:0.09801, lr:6.24e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.364, tt:4040.057\n",
      "Ep:220, loss:0.00000, loss_test:0.09736, lr:6.24e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.367, tt:4059.126\n",
      "Ep:221, loss:0.00000, loss_test:0.09796, lr:6.24e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.381, tt:4080.549\n",
      "Ep:222, loss:0.00000, loss_test:0.09827, lr:6.17e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.382, tt:4099.249\n",
      "Ep:223, loss:0.00000, loss_test:0.09747, lr:6.11e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.379, tt:4116.828\n",
      "Ep:224, loss:0.00000, loss_test:0.09782, lr:6.05e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.383, tt:4136.166\n",
      "Ep:225, loss:0.00000, loss_test:0.09736, lr:5.99e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.384, tt:4154.807\n",
      "Ep:226, loss:0.00000, loss_test:0.09752, lr:5.93e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.388, tt:4174.082\n",
      "Ep:227, loss:0.00000, loss_test:0.09778, lr:5.87e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.390, tt:4192.815\n",
      "Ep:228, loss:0.00000, loss_test:0.09727, lr:5.81e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.393, tt:4211.983\n",
      "Ep:229, loss:0.00000, loss_test:0.09808, lr:5.75e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.393, tt:4230.433\n",
      "Ep:230, loss:0.00000, loss_test:0.09763, lr:5.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.396, tt:4249.560\n",
      "Ep:231, loss:0.00000, loss_test:0.09831, lr:5.64e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.402, tt:4269.327\n",
      "Ep:232, loss:0.00000, loss_test:0.09779, lr:5.58e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.404, tt:4288.162\n",
      "Ep:233, loss:0.00000, loss_test:0.09711, lr:5.53e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.408, tt:4307.385\n",
      "Ep:234, loss:0.00000, loss_test:0.09890, lr:5.47e-03, fs:0.82723 (r=0.798,p=0.859),  time:18.407, tt:4325.679\n",
      "Ep:235, loss:0.00000, loss_test:0.09876, lr:5.42e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.407, tt:4343.959\n",
      "Ep:236, loss:0.00000, loss_test:0.09752, lr:5.36e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.406, tt:4362.286\n",
      "Ep:237, loss:0.00000, loss_test:0.09747, lr:5.31e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.405, tt:4380.400\n",
      "Ep:238, loss:0.00000, loss_test:0.09833, lr:5.26e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.401, tt:4397.754\n",
      "Ep:239, loss:0.00000, loss_test:0.09753, lr:5.20e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.400, tt:4416.077\n",
      "Ep:240, loss:0.00000, loss_test:0.09807, lr:5.15e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.396, tt:4433.528\n",
      "Ep:241, loss:0.00000, loss_test:0.09812, lr:5.10e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.398, tt:4452.326\n",
      "Ep:242, loss:0.00000, loss_test:0.09703, lr:5.05e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.399, tt:4471.020\n",
      "Ep:243, loss:0.00000, loss_test:0.09810, lr:5.00e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.398, tt:4489.034\n",
      "Ep:244, loss:0.00000, loss_test:0.09838, lr:4.95e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.398, tt:4507.604\n",
      "Ep:245, loss:0.00000, loss_test:0.09778, lr:4.90e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.394, tt:4524.903\n",
      "Ep:246, loss:0.00000, loss_test:0.09809, lr:4.85e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.393, tt:4543.065\n",
      "Ep:247, loss:0.00000, loss_test:0.09814, lr:4.80e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.391, tt:4560.859\n",
      "Ep:248, loss:0.00000, loss_test:0.09750, lr:4.75e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.390, tt:4579.079\n",
      "Ep:249, loss:0.00000, loss_test:0.09834, lr:4.71e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.389, tt:4597.371\n",
      "Ep:250, loss:0.00000, loss_test:0.09821, lr:4.66e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.392, tt:4616.411\n",
      "Ep:251, loss:0.00000, loss_test:0.09686, lr:4.61e-03, fs:0.82051 (r=0.808,p=0.833),  time:18.394, tt:4635.201\n",
      "Ep:252, loss:0.00000, loss_test:0.09884, lr:4.57e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.396, tt:4654.069\n",
      "Ep:253, loss:0.00000, loss_test:0.09922, lr:4.52e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.396, tt:4672.587\n",
      "Ep:254, loss:0.00000, loss_test:0.09813, lr:4.48e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.396, tt:4690.897\n",
      "Ep:255, loss:0.00000, loss_test:0.09765, lr:4.43e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.399, tt:4710.083\n",
      "Ep:256, loss:0.00000, loss_test:0.09794, lr:4.39e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.401, tt:4729.102\n",
      "Ep:257, loss:0.00000, loss_test:0.09824, lr:4.34e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.405, tt:4748.504\n",
      "Ep:258, loss:0.00000, loss_test:0.09877, lr:4.30e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.407, tt:4767.441\n",
      "Ep:259, loss:0.00000, loss_test:0.09842, lr:4.26e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.410, tt:4786.504\n",
      "Ep:260, loss:0.00000, loss_test:0.09746, lr:4.21e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.412, tt:4805.510\n",
      "Ep:261, loss:0.00000, loss_test:0.09746, lr:4.17e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.413, tt:4824.176\n",
      "Ep:262, loss:0.00000, loss_test:0.09848, lr:4.13e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.413, tt:4842.509\n",
      "Ep:263, loss:0.00000, loss_test:0.09845, lr:4.09e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.415, tt:4861.508\n",
      "Ep:264, loss:0.00000, loss_test:0.09775, lr:4.05e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.416, tt:4880.136\n",
      "Ep:265, loss:0.00000, loss_test:0.09785, lr:4.01e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.420, tt:4899.708\n",
      "Ep:266, loss:0.00000, loss_test:0.09806, lr:3.97e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.422, tt:4918.726\n",
      "Ep:267, loss:0.00000, loss_test:0.09763, lr:3.93e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.426, tt:4938.101\n",
      "Ep:268, loss:0.00000, loss_test:0.09784, lr:3.89e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.427, tt:4956.959\n",
      "Ep:269, loss:0.00000, loss_test:0.09816, lr:3.85e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.429, tt:4975.757\n",
      "Ep:270, loss:0.00000, loss_test:0.09795, lr:3.81e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.431, tt:4994.724\n",
      "Ep:271, loss:0.00000, loss_test:0.09724, lr:3.77e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.432, tt:5013.598\n",
      "Ep:272, loss:0.00000, loss_test:0.09802, lr:3.73e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.433, tt:5032.205\n",
      "Ep:273, loss:0.00000, loss_test:0.09839, lr:3.70e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.440, tt:5052.468\n",
      "Ep:274, loss:0.00000, loss_test:0.09810, lr:3.66e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.443, tt:5071.852\n",
      "Ep:275, loss:0.00000, loss_test:0.09756, lr:3.62e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.445, tt:5090.890\n",
      "Ep:276, loss:0.00000, loss_test:0.09775, lr:3.59e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.448, tt:5110.112\n",
      "Ep:277, loss:0.00000, loss_test:0.09835, lr:3.55e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.450, tt:5129.152\n",
      "Ep:278, loss:0.00000, loss_test:0.09828, lr:3.52e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.456, tt:5149.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:279, loss:0.00000, loss_test:0.09779, lr:3.48e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.462, tt:5169.396\n",
      "Ep:280, loss:0.00000, loss_test:0.09769, lr:3.45e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.464, tt:5188.482\n",
      "Ep:281, loss:0.00000, loss_test:0.09828, lr:3.41e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.462, tt:5206.205\n",
      "Ep:282, loss:0.00000, loss_test:0.09812, lr:3.38e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.462, tt:5224.792\n",
      "Ep:283, loss:0.00000, loss_test:0.09799, lr:3.34e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.462, tt:5243.296\n",
      "Ep:284, loss:0.00000, loss_test:0.09770, lr:3.31e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.467, tt:5263.096\n",
      "Ep:285, loss:0.00000, loss_test:0.09777, lr:3.28e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.470, tt:5282.450\n",
      "Ep:286, loss:0.00000, loss_test:0.09820, lr:3.24e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.474, tt:5301.905\n",
      "Ep:287, loss:0.00000, loss_test:0.09799, lr:3.21e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.475, tt:5320.920\n",
      "Ep:288, loss:0.00000, loss_test:0.09752, lr:3.18e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.472, tt:5338.402\n",
      "Ep:289, loss:0.00000, loss_test:0.09797, lr:3.15e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.469, tt:5355.918\n",
      "Ep:290, loss:0.00000, loss_test:0.09789, lr:3.12e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.468, tt:5374.322\n",
      "Ep:291, loss:0.00000, loss_test:0.09762, lr:3.09e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.466, tt:5392.192\n",
      "Ep:292, loss:0.00000, loss_test:0.09796, lr:3.05e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.464, tt:5409.971\n",
      "Ep:293, loss:0.00000, loss_test:0.09809, lr:3.02e-03, fs:0.83333 (r=0.808,p=0.860),  time:18.460, tt:5427.137\n",
      "Ep:294, loss:0.00000, loss_test:0.09764, lr:2.99e-03, fs:0.82474 (r=0.808,p=0.842),  time:18.449, tt:5442.562\n",
      "Ep:295, loss:0.00000, loss_test:0.09758, lr:2.96e-03, fs:0.82902 (r=0.808,p=0.851),  time:18.429, tt:5454.975\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.11934, lr:1.00e-02, fs:0.68992 (r=0.899,p=0.560),  time:12.631, tt:12.631\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.11906, lr:1.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:14.598, tt:29.196\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.11868, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:15.467, tt:46.402\n",
      "Ep:3, loss:0.00004, loss_test:0.11820, lr:1.00e-02, fs:0.69020 (r=0.889,p=0.564),  time:15.711, tt:62.844\n",
      "Ep:4, loss:0.00004, loss_test:0.11772, lr:1.00e-02, fs:0.69291 (r=0.889,p=0.568),  time:16.100, tt:80.501\n",
      "Ep:5, loss:0.00004, loss_test:0.11721, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:16.342, tt:98.052\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00004, loss_test:0.11670, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:16.509, tt:115.561\n",
      "Ep:7, loss:0.00004, loss_test:0.11629, lr:1.00e-02, fs:0.69565 (r=0.889,p=0.571),  time:16.726, tt:133.808\n",
      "Ep:8, loss:0.00004, loss_test:0.11589, lr:1.00e-02, fs:0.69841 (r=0.889,p=0.575),  time:16.833, tt:151.499\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.11547, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:16.935, tt:169.352\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.11497, lr:1.00e-02, fs:0.70120 (r=0.889,p=0.579),  time:16.936, tt:186.301\n",
      "Ep:11, loss:0.00004, loss_test:0.11434, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:16.943, tt:203.317\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.11368, lr:1.00e-02, fs:0.70400 (r=0.889,p=0.583),  time:16.885, tt:219.511\n",
      "Ep:13, loss:0.00004, loss_test:0.11308, lr:1.00e-02, fs:0.70683 (r=0.889,p=0.587),  time:16.900, tt:236.606\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.11258, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:16.930, tt:253.950\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00004, loss_test:0.11214, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:16.938, tt:271.003\n",
      "Ep:16, loss:0.00004, loss_test:0.11168, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:16.903, tt:287.355\n",
      "Ep:17, loss:0.00004, loss_test:0.11124, lr:1.00e-02, fs:0.70968 (r=0.889,p=0.591),  time:16.872, tt:303.701\n",
      "Ep:18, loss:0.00004, loss_test:0.11081, lr:1.00e-02, fs:0.71255 (r=0.889,p=0.595),  time:16.886, tt:320.836\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00004, loss_test:0.11039, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:16.860, tt:337.210\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00004, loss_test:0.10996, lr:1.00e-02, fs:0.71545 (r=0.889,p=0.599),  time:16.871, tt:354.293\n",
      "Ep:21, loss:0.00004, loss_test:0.10948, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.887, tt:371.517\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10912, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.862, tt:387.820\n",
      "Ep:23, loss:0.00003, loss_test:0.10889, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.863, tt:404.719\n",
      "Ep:24, loss:0.00003, loss_test:0.10876, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.835, tt:420.864\n",
      "Ep:25, loss:0.00003, loss_test:0.10870, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.803, tt:436.888\n",
      "Ep:26, loss:0.00003, loss_test:0.10854, lr:1.00e-02, fs:0.71837 (r=0.889,p=0.603),  time:16.778, tt:453.007\n",
      "Ep:27, loss:0.00003, loss_test:0.10829, lr:1.00e-02, fs:0.71020 (r=0.879,p=0.596),  time:16.759, tt:469.263\n",
      "Ep:28, loss:0.00003, loss_test:0.10791, lr:1.00e-02, fs:0.70782 (r=0.869,p=0.597),  time:16.789, tt:486.894\n",
      "Ep:29, loss:0.00003, loss_test:0.10746, lr:1.00e-02, fs:0.69456 (r=0.838,p=0.593),  time:16.755, tt:502.643\n",
      "Ep:30, loss:0.00003, loss_test:0.10714, lr:1.00e-02, fs:0.69492 (r=0.828,p=0.599),  time:16.758, tt:519.491\n",
      "Ep:31, loss:0.00003, loss_test:0.10688, lr:1.00e-02, fs:0.69231 (r=0.818,p=0.600),  time:16.764, tt:536.463\n",
      "Ep:32, loss:0.00003, loss_test:0.10681, lr:1.00e-02, fs:0.69528 (r=0.818,p=0.604),  time:16.753, tt:552.838\n",
      "Ep:33, loss:0.00003, loss_test:0.10688, lr:9.90e-03, fs:0.68966 (r=0.808,p=0.602),  time:16.762, tt:569.905\n",
      "Ep:34, loss:0.00003, loss_test:0.10697, lr:9.80e-03, fs:0.68398 (r=0.798,p=0.598),  time:16.778, tt:587.230\n",
      "Ep:35, loss:0.00003, loss_test:0.10700, lr:9.70e-03, fs:0.68696 (r=0.798,p=0.603),  time:16.815, tt:605.338\n",
      "Ep:36, loss:0.00003, loss_test:0.10676, lr:9.61e-03, fs:0.69604 (r=0.798,p=0.617),  time:16.849, tt:623.402\n",
      "Ep:37, loss:0.00003, loss_test:0.10622, lr:9.51e-03, fs:0.69027 (r=0.788,p=0.614),  time:16.873, tt:641.177\n",
      "Ep:38, loss:0.00003, loss_test:0.10544, lr:9.41e-03, fs:0.69333 (r=0.788,p=0.619),  time:16.884, tt:658.466\n",
      "Ep:39, loss:0.00003, loss_test:0.10457, lr:9.32e-03, fs:0.69643 (r=0.788,p=0.624),  time:16.898, tt:675.903\n",
      "Ep:40, loss:0.00003, loss_test:0.10372, lr:9.23e-03, fs:0.70536 (r=0.798,p=0.632),  time:16.906, tt:693.132\n",
      "Ep:41, loss:0.00003, loss_test:0.10292, lr:9.14e-03, fs:0.71111 (r=0.808,p=0.635),  time:16.907, tt:710.101\n",
      "Ep:42, loss:0.00003, loss_test:0.10230, lr:9.04e-03, fs:0.70852 (r=0.798,p=0.637),  time:16.900, tt:726.681\n",
      "Ep:43, loss:0.00003, loss_test:0.10185, lr:8.95e-03, fs:0.71749 (r=0.808,p=0.645),  time:16.906, tt:743.877\n",
      "Ep:44, loss:0.00003, loss_test:0.10121, lr:8.86e-03, fs:0.71749 (r=0.808,p=0.645),  time:16.897, tt:760.363\n",
      "Ep:45, loss:0.00003, loss_test:0.10046, lr:8.78e-03, fs:0.71429 (r=0.808,p=0.640),  time:16.890, tt:776.949\n",
      "Ep:46, loss:0.00003, loss_test:0.09962, lr:8.69e-03, fs:0.71749 (r=0.808,p=0.645),  time:16.879, tt:793.322\n",
      "Ep:47, loss:0.00003, loss_test:0.09864, lr:8.60e-03, fs:0.72072 (r=0.808,p=0.650),  time:16.859, tt:809.246\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00003, loss_test:0.09781, lr:8.60e-03, fs:0.71560 (r=0.788,p=0.655),  time:16.856, tt:825.964\n",
      "Ep:49, loss:0.00003, loss_test:0.09725, lr:8.60e-03, fs:0.71560 (r=0.788,p=0.655),  time:16.863, tt:843.131\n",
      "Ep:50, loss:0.00003, loss_test:0.09658, lr:8.60e-03, fs:0.71560 (r=0.788,p=0.655),  time:16.818, tt:857.724\n",
      "Ep:51, loss:0.00003, loss_test:0.09573, lr:8.60e-03, fs:0.70968 (r=0.778,p=0.653),  time:16.789, tt:873.015\n",
      "Ep:52, loss:0.00003, loss_test:0.09501, lr:8.60e-03, fs:0.71296 (r=0.778,p=0.658),  time:16.773, tt:888.985\n",
      "Ep:53, loss:0.00003, loss_test:0.09421, lr:8.60e-03, fs:0.72986 (r=0.778,p=0.688),  time:16.756, tt:904.809\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00003, loss_test:0.09290, lr:8.60e-03, fs:0.74038 (r=0.778,p=0.706),  time:16.713, tt:919.222\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.09159, lr:8.60e-03, fs:0.75122 (r=0.778,p=0.726),  time:16.661, tt:932.989\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00003, loss_test:0.09055, lr:8.60e-03, fs:0.76098 (r=0.788,p=0.736),  time:16.642, tt:948.618\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.08954, lr:8.60e-03, fs:0.76471 (r=0.788,p=0.743),  time:16.608, tt:963.277\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00002, loss_test:0.08796, lr:8.60e-03, fs:0.76471 (r=0.788,p=0.743),  time:16.601, tt:979.487\n",
      "Ep:59, loss:0.00002, loss_test:0.08719, lr:8.60e-03, fs:0.77228 (r=0.788,p=0.757),  time:16.545, tt:992.705\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.08682, lr:8.60e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.541, tt:1008.993\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00002, loss_test:0.08587, lr:8.60e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.518, tt:1024.128\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.08566, lr:8.60e-03, fs:0.78000 (r=0.788,p=0.772),  time:16.509, tt:1040.096\n",
      "Ep:63, loss:0.00002, loss_test:0.08580, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.487, tt:1055.158\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:64, loss:0.00002, loss_test:0.08539, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.451, tt:1069.309\n",
      "Ep:65, loss:0.00002, loss_test:0.08450, lr:8.60e-03, fs:0.80597 (r=0.818,p=0.794),  time:16.432, tt:1084.492\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00002, loss_test:0.08421, lr:8.60e-03, fs:0.80597 (r=0.818,p=0.794),  time:16.414, tt:1099.755\n",
      "Ep:67, loss:0.00002, loss_test:0.08268, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.393, tt:1114.731\n",
      "Ep:68, loss:0.00002, loss_test:0.08323, lr:8.60e-03, fs:0.79602 (r=0.808,p=0.784),  time:16.387, tt:1130.672\n",
      "Ep:69, loss:0.00002, loss_test:0.08225, lr:8.60e-03, fs:0.79000 (r=0.798,p=0.782),  time:16.388, tt:1147.194\n",
      "Ep:70, loss:0.00002, loss_test:0.08345, lr:8.60e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.394, tt:1163.955\n",
      "Ep:71, loss:0.00002, loss_test:0.08128, lr:8.60e-03, fs:0.77612 (r=0.788,p=0.765),  time:16.380, tt:1179.362\n",
      "Ep:72, loss:0.00002, loss_test:0.08183, lr:8.60e-03, fs:0.78392 (r=0.788,p=0.780),  time:16.369, tt:1194.944\n",
      "Ep:73, loss:0.00002, loss_test:0.08022, lr:8.60e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.367, tt:1211.192\n",
      "Ep:74, loss:0.00002, loss_test:0.07892, lr:8.60e-03, fs:0.78218 (r=0.798,p=0.767),  time:16.376, tt:1228.217\n",
      "Ep:75, loss:0.00002, loss_test:0.08157, lr:8.60e-03, fs:0.79397 (r=0.798,p=0.790),  time:16.391, tt:1245.692\n",
      "Ep:76, loss:0.00002, loss_test:0.07696, lr:8.60e-03, fs:0.79803 (r=0.818,p=0.779),  time:16.375, tt:1260.871\n",
      "Ep:77, loss:0.00002, loss_test:0.08942, lr:8.51e-03, fs:0.80000 (r=0.808,p=0.792),  time:16.371, tt:1276.959\n",
      "Ep:78, loss:0.00002, loss_test:0.07583, lr:8.43e-03, fs:0.81731 (r=0.859,p=0.780),  time:16.351, tt:1291.743\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00002, loss_test:0.09001, lr:8.43e-03, fs:0.78173 (r=0.778,p=0.786),  time:16.353, tt:1308.213\n",
      "Ep:80, loss:0.00002, loss_test:0.07722, lr:8.43e-03, fs:0.79798 (r=0.798,p=0.798),  time:16.357, tt:1324.922\n",
      "Ep:81, loss:0.00002, loss_test:0.07345, lr:8.43e-03, fs:0.80198 (r=0.818,p=0.786),  time:16.339, tt:1339.806\n",
      "Ep:82, loss:0.00002, loss_test:0.09139, lr:8.43e-03, fs:0.81633 (r=0.808,p=0.825),  time:16.344, tt:1356.572\n",
      "Ep:83, loss:0.00002, loss_test:0.07469, lr:8.43e-03, fs:0.80597 (r=0.818,p=0.794),  time:16.337, tt:1372.280\n",
      "Ep:84, loss:0.00001, loss_test:0.08024, lr:8.43e-03, fs:0.81443 (r=0.798,p=0.832),  time:16.319, tt:1387.148\n",
      "Ep:85, loss:0.00001, loss_test:0.08896, lr:8.43e-03, fs:0.80000 (r=0.768,p=0.835),  time:16.299, tt:1401.683\n",
      "Ep:86, loss:0.00001, loss_test:0.07577, lr:8.43e-03, fs:0.81633 (r=0.808,p=0.825),  time:16.287, tt:1416.977\n",
      "Ep:87, loss:0.00001, loss_test:0.08167, lr:8.43e-03, fs:0.80208 (r=0.778,p=0.828),  time:16.290, tt:1433.521\n",
      "Ep:88, loss:0.00001, loss_test:0.08387, lr:8.43e-03, fs:0.80423 (r=0.768,p=0.844),  time:16.285, tt:1449.382\n",
      "Ep:89, loss:0.00001, loss_test:0.07687, lr:8.43e-03, fs:0.81026 (r=0.798,p=0.823),  time:16.283, tt:1465.450\n",
      "Ep:90, loss:0.00001, loss_test:0.09104, lr:8.35e-03, fs:0.78261 (r=0.727,p=0.847),  time:16.270, tt:1480.599\n",
      "Ep:91, loss:0.00001, loss_test:0.07771, lr:8.26e-03, fs:0.79793 (r=0.778,p=0.819),  time:16.291, tt:1498.739\n",
      "Ep:92, loss:0.00001, loss_test:0.08906, lr:8.18e-03, fs:0.78689 (r=0.727,p=0.857),  time:16.288, tt:1514.762\n",
      "Ep:93, loss:0.00001, loss_test:0.07946, lr:8.10e-03, fs:0.78947 (r=0.758,p=0.824),  time:16.287, tt:1530.977\n",
      "Ep:94, loss:0.00001, loss_test:0.08733, lr:8.02e-03, fs:0.78453 (r=0.717,p=0.866),  time:16.264, tt:1545.055\n",
      "Ep:95, loss:0.00001, loss_test:0.08518, lr:7.94e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.263, tt:1561.256\n",
      "Ep:96, loss:0.00001, loss_test:0.08421, lr:7.86e-03, fs:0.77596 (r=0.717,p=0.845),  time:16.277, tt:1578.906\n",
      "Ep:97, loss:0.00001, loss_test:0.08885, lr:7.78e-03, fs:0.78689 (r=0.727,p=0.857),  time:16.305, tt:1597.926\n",
      "Ep:98, loss:0.00001, loss_test:0.08015, lr:7.70e-03, fs:0.78075 (r=0.737,p=0.830),  time:16.320, tt:1615.655\n",
      "Ep:99, loss:0.00001, loss_test:0.10156, lr:7.62e-03, fs:0.78652 (r=0.707,p=0.886),  time:16.318, tt:1631.772\n",
      "Ep:100, loss:0.00001, loss_test:0.07759, lr:7.55e-03, fs:0.80198 (r=0.818,p=0.786),  time:16.336, tt:1649.967\n",
      "Ep:101, loss:0.00001, loss_test:0.08083, lr:7.47e-03, fs:0.80851 (r=0.768,p=0.854),  time:16.340, tt:1666.685\n",
      "Ep:102, loss:0.00001, loss_test:0.10095, lr:7.40e-03, fs:0.79775 (r=0.717,p=0.899),  time:16.353, tt:1684.347\n",
      "Ep:103, loss:0.00001, loss_test:0.07970, lr:7.32e-03, fs:0.77249 (r=0.737,p=0.811),  time:16.364, tt:1701.885\n",
      "Ep:104, loss:0.00001, loss_test:0.07841, lr:7.25e-03, fs:0.81053 (r=0.778,p=0.846),  time:16.366, tt:1718.421\n",
      "Ep:105, loss:0.00001, loss_test:0.09565, lr:7.18e-03, fs:0.79330 (r=0.717,p=0.887),  time:16.392, tt:1737.597\n",
      "Ep:106, loss:0.00001, loss_test:0.08569, lr:7.11e-03, fs:0.78689 (r=0.727,p=0.857),  time:16.404, tt:1755.221\n",
      "Ep:107, loss:0.00001, loss_test:0.07854, lr:7.03e-03, fs:0.80612 (r=0.798,p=0.814),  time:16.418, tt:1773.098\n",
      "Ep:108, loss:0.00001, loss_test:0.08754, lr:6.96e-03, fs:0.79558 (r=0.727,p=0.878),  time:16.432, tt:1791.099\n",
      "Ep:109, loss:0.00001, loss_test:0.09218, lr:6.89e-03, fs:0.78889 (r=0.717,p=0.877),  time:16.450, tt:1809.526\n",
      "Ep:110, loss:0.00001, loss_test:0.08355, lr:6.83e-03, fs:0.76923 (r=0.707,p=0.843),  time:16.465, tt:1827.611\n",
      "Ep:111, loss:0.00001, loss_test:0.08105, lr:6.76e-03, fs:0.75676 (r=0.707,p=0.814),  time:16.483, tt:1846.067\n",
      "Ep:112, loss:0.00001, loss_test:0.09343, lr:6.69e-03, fs:0.80899 (r=0.727,p=0.911),  time:16.505, tt:1865.034\n",
      "Ep:113, loss:0.00001, loss_test:0.09529, lr:6.62e-03, fs:0.80226 (r=0.717,p=0.910),  time:16.519, tt:1883.162\n",
      "Ep:114, loss:0.00001, loss_test:0.08161, lr:6.56e-03, fs:0.75138 (r=0.687,p=0.829),  time:16.529, tt:1900.886\n",
      "Ep:115, loss:0.00001, loss_test:0.08156, lr:6.49e-03, fs:0.76757 (r=0.717,p=0.826),  time:16.544, tt:1919.052\n",
      "Ep:116, loss:0.00001, loss_test:0.09107, lr:6.43e-03, fs:0.80447 (r=0.727,p=0.900),  time:16.562, tt:1937.720\n",
      "Ep:117, loss:0.00001, loss_test:0.10006, lr:6.36e-03, fs:0.80899 (r=0.727,p=0.911),  time:16.573, tt:1955.656\n",
      "Ep:118, loss:0.00001, loss_test:0.08711, lr:6.30e-03, fs:0.73034 (r=0.657,p=0.823),  time:16.578, tt:1972.804\n",
      "Ep:119, loss:0.00001, loss_test:0.08468, lr:6.24e-03, fs:0.72928 (r=0.667,p=0.805),  time:16.597, tt:1991.633\n",
      "Ep:120, loss:0.00001, loss_test:0.09132, lr:6.17e-03, fs:0.80447 (r=0.727,p=0.900),  time:16.610, tt:2009.768\n",
      "Ep:121, loss:0.00001, loss_test:0.09841, lr:6.11e-03, fs:0.80899 (r=0.727,p=0.911),  time:16.642, tt:2030.270\n",
      "Ep:122, loss:0.00001, loss_test:0.08866, lr:6.05e-03, fs:0.74286 (r=0.657,p=0.855),  time:16.657, tt:2048.850\n",
      "Ep:123, loss:0.00001, loss_test:0.08624, lr:5.99e-03, fs:0.73743 (r=0.667,p=0.825),  time:16.665, tt:2066.458\n",
      "Ep:124, loss:0.00001, loss_test:0.08901, lr:5.93e-03, fs:0.76301 (r=0.667,p=0.892),  time:16.679, tt:2084.822\n",
      "Ep:125, loss:0.00001, loss_test:0.09873, lr:5.87e-03, fs:0.80899 (r=0.727,p=0.911),  time:16.693, tt:2103.313\n",
      "Ep:126, loss:0.00001, loss_test:0.09201, lr:5.81e-03, fs:0.79545 (r=0.707,p=0.909),  time:16.714, tt:2122.709\n",
      "Ep:127, loss:0.00001, loss_test:0.08965, lr:5.75e-03, fs:0.73864 (r=0.657,p=0.844),  time:16.738, tt:2142.487\n",
      "Ep:128, loss:0.00001, loss_test:0.09143, lr:5.70e-03, fs:0.75145 (r=0.657,p=0.878),  time:16.757, tt:2161.595\n",
      "Ep:129, loss:0.00001, loss_test:0.09864, lr:5.64e-03, fs:0.79545 (r=0.707,p=0.909),  time:16.777, tt:2181.005\n",
      "Ep:130, loss:0.00001, loss_test:0.09658, lr:5.58e-03, fs:0.80682 (r=0.717,p=0.922),  time:16.791, tt:2199.643\n",
      "Ep:131, loss:0.00001, loss_test:0.09230, lr:5.53e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.813, tt:2219.306\n",
      "Ep:132, loss:0.00001, loss_test:0.09160, lr:5.47e-03, fs:0.75581 (r=0.657,p=0.890),  time:16.830, tt:2238.326\n",
      "Ep:133, loss:0.00001, loss_test:0.09556, lr:5.42e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.849, tt:2257.777\n",
      "Ep:134, loss:0.00001, loss_test:0.09677, lr:5.36e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.852, tt:2275.065\n",
      "Ep:135, loss:0.00001, loss_test:0.09633, lr:5.31e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.864, tt:2293.541\n",
      "Ep:136, loss:0.00001, loss_test:0.09700, lr:5.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:16.873, tt:2311.556\n",
      "Ep:137, loss:0.00001, loss_test:0.09773, lr:5.20e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.888, tt:2330.585\n",
      "Ep:138, loss:0.00001, loss_test:0.09794, lr:5.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:16.906, tt:2349.885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:139, loss:0.00001, loss_test:0.09827, lr:5.10e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.917, tt:2368.384\n",
      "Ep:140, loss:0.00001, loss_test:0.09902, lr:5.05e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.939, tt:2388.364\n",
      "Ep:141, loss:0.00000, loss_test:0.09711, lr:5.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:16.958, tt:2408.095\n",
      "Ep:142, loss:0.00000, loss_test:0.09634, lr:4.95e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.976, tt:2427.534\n",
      "Ep:143, loss:0.00000, loss_test:0.09936, lr:4.90e-03, fs:0.76471 (r=0.657,p=0.915),  time:16.994, tt:2447.123\n",
      "Ep:144, loss:0.00000, loss_test:0.10201, lr:4.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.010, tt:2466.396\n",
      "Ep:145, loss:0.00000, loss_test:0.09956, lr:4.80e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.021, tt:2485.058\n",
      "Ep:146, loss:0.00000, loss_test:0.09845, lr:4.75e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.036, tt:2504.291\n",
      "Ep:147, loss:0.00000, loss_test:0.10137, lr:4.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.050, tt:2523.471\n",
      "Ep:148, loss:0.00000, loss_test:0.10284, lr:4.66e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.057, tt:2541.491\n",
      "Ep:149, loss:0.00000, loss_test:0.10129, lr:4.61e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.067, tt:2560.101\n",
      "Ep:150, loss:0.00000, loss_test:0.10104, lr:4.57e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.071, tt:2577.656\n",
      "Ep:151, loss:0.00000, loss_test:0.10238, lr:4.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.086, tt:2597.062\n",
      "Ep:152, loss:0.00000, loss_test:0.10254, lr:4.48e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.100, tt:2616.363\n",
      "Ep:153, loss:0.00000, loss_test:0.10315, lr:4.43e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.115, tt:2635.670\n",
      "Ep:154, loss:0.00000, loss_test:0.10419, lr:4.39e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.125, tt:2654.336\n",
      "Ep:155, loss:0.00000, loss_test:0.10361, lr:4.34e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.135, tt:2673.085\n",
      "Ep:156, loss:0.00000, loss_test:0.10347, lr:4.30e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.151, tt:2692.655\n",
      "Ep:157, loss:0.00000, loss_test:0.10461, lr:4.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.164, tt:2711.857\n",
      "Ep:158, loss:0.00000, loss_test:0.10555, lr:4.21e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.186, tt:2732.519\n",
      "Ep:159, loss:0.00000, loss_test:0.10431, lr:4.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.198, tt:2751.675\n",
      "Ep:160, loss:0.00000, loss_test:0.10501, lr:4.13e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.201, tt:2769.348\n",
      "Ep:161, loss:0.00000, loss_test:0.10661, lr:4.09e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.218, tt:2789.272\n",
      "Ep:162, loss:0.00000, loss_test:0.10615, lr:4.05e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.227, tt:2807.995\n",
      "Ep:163, loss:0.00000, loss_test:0.10567, lr:4.01e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.236, tt:2826.780\n",
      "Ep:164, loss:0.00000, loss_test:0.10644, lr:3.97e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.248, tt:2845.907\n",
      "Ep:165, loss:0.00000, loss_test:0.10639, lr:3.93e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.256, tt:2864.435\n",
      "Ep:166, loss:0.00000, loss_test:0.10742, lr:3.89e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.260, tt:2882.348\n",
      "Ep:167, loss:0.00000, loss_test:0.10845, lr:3.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.266, tt:2900.615\n",
      "Ep:168, loss:0.00000, loss_test:0.10817, lr:3.81e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.256, tt:2916.232\n",
      "Ep:169, loss:0.00000, loss_test:0.10732, lr:3.77e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.242, tt:2931.096\n",
      "Ep:170, loss:0.00000, loss_test:0.10788, lr:3.73e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.233, tt:2946.828\n",
      "Ep:171, loss:0.00000, loss_test:0.10845, lr:3.70e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.232, tt:2963.953\n",
      "Ep:172, loss:0.00000, loss_test:0.10828, lr:3.66e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.230, tt:2980.839\n",
      "Ep:173, loss:0.00000, loss_test:0.10815, lr:3.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.232, tt:2998.280\n",
      "Ep:174, loss:0.00000, loss_test:0.10877, lr:3.59e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.228, tt:3014.973\n",
      "Ep:175, loss:0.00000, loss_test:0.10919, lr:3.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.228, tt:3032.141\n",
      "Ep:176, loss:0.00000, loss_test:0.10941, lr:3.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.218, tt:3047.656\n",
      "Ep:177, loss:0.00000, loss_test:0.10953, lr:3.48e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.215, tt:3064.182\n",
      "Ep:178, loss:0.00000, loss_test:0.10895, lr:3.45e-03, fs:0.76471 (r=0.657,p=0.915),  time:17.210, tt:3080.602\n",
      "Ep:179, loss:0.00000, loss_test:0.10972, lr:3.41e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.201, tt:3096.209\n",
      "Ep:180, loss:0.00000, loss_test:0.11035, lr:3.38e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.189, tt:3111.272\n",
      "Ep:181, loss:0.00000, loss_test:0.10983, lr:3.34e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.179, tt:3126.551\n",
      "Ep:182, loss:0.00000, loss_test:0.10989, lr:3.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.181, tt:3144.090\n",
      "Ep:183, loss:0.00000, loss_test:0.11018, lr:3.28e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.176, tt:3160.443\n",
      "Ep:184, loss:0.00000, loss_test:0.11052, lr:3.24e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.175, tt:3177.322\n",
      "Ep:185, loss:0.00000, loss_test:0.11091, lr:3.21e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.171, tt:3193.882\n",
      "Ep:186, loss:0.00000, loss_test:0.11061, lr:3.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.170, tt:3210.786\n",
      "Ep:187, loss:0.00000, loss_test:0.11096, lr:3.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.167, tt:3227.392\n",
      "Ep:188, loss:0.00000, loss_test:0.11171, lr:3.12e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.159, tt:3242.984\n",
      "Ep:189, loss:0.00000, loss_test:0.11136, lr:3.09e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.159, tt:3260.211\n",
      "Ep:190, loss:0.00000, loss_test:0.11163, lr:3.05e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.155, tt:3276.673\n",
      "Ep:191, loss:0.00000, loss_test:0.11193, lr:3.02e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.152, tt:3293.139\n",
      "Ep:192, loss:0.00000, loss_test:0.11185, lr:2.99e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.150, tt:3310.015\n",
      "Ep:193, loss:0.00000, loss_test:0.11240, lr:2.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.144, tt:3325.914\n",
      "Ep:194, loss:0.00000, loss_test:0.11209, lr:2.93e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.138, tt:3341.936\n",
      "Ep:195, loss:0.00000, loss_test:0.11233, lr:2.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.121, tt:3355.696\n",
      "Ep:196, loss:0.00000, loss_test:0.11262, lr:2.88e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.113, tt:3371.291\n",
      "Ep:197, loss:0.00000, loss_test:0.11222, lr:2.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.100, tt:3385.794\n",
      "Ep:198, loss:0.00000, loss_test:0.11320, lr:2.82e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.095, tt:3401.926\n",
      "Ep:199, loss:0.00000, loss_test:0.11316, lr:2.79e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.080, tt:3415.931\n",
      "Ep:200, loss:0.00000, loss_test:0.11304, lr:2.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.073, tt:3431.607\n",
      "Ep:201, loss:0.00000, loss_test:0.11335, lr:2.73e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.067, tt:3447.448\n",
      "Ep:202, loss:0.00000, loss_test:0.11346, lr:2.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.069, tt:3465.053\n",
      "Ep:203, loss:0.00000, loss_test:0.11382, lr:2.68e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.069, tt:3482.124\n",
      "Ep:204, loss:0.00000, loss_test:0.11353, lr:2.65e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.065, tt:3498.230\n",
      "Ep:205, loss:0.00000, loss_test:0.11413, lr:2.63e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.057, tt:3513.806\n",
      "Ep:206, loss:0.00000, loss_test:0.11409, lr:2.60e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.045, tt:3528.245\n",
      "Ep:207, loss:0.00000, loss_test:0.11440, lr:2.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.038, tt:3543.865\n",
      "Ep:208, loss:0.00000, loss_test:0.11460, lr:2.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.028, tt:3558.823\n",
      "Ep:209, loss:0.00000, loss_test:0.11450, lr:2.52e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.022, tt:3574.587\n",
      "Ep:210, loss:0.00000, loss_test:0.11471, lr:2.50e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.019, tt:3591.064\n",
      "Ep:211, loss:0.00000, loss_test:0.11488, lr:2.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.018, tt:3607.852\n",
      "Ep:212, loss:0.00000, loss_test:0.11484, lr:2.45e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.021, tt:3625.436\n",
      "Ep:213, loss:0.00000, loss_test:0.11486, lr:2.42e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.024, tt:3643.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:214, loss:0.00000, loss_test:0.11530, lr:2.40e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.024, tt:3660.239\n",
      "Ep:215, loss:0.00000, loss_test:0.11525, lr:2.38e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.031, tt:3678.657\n",
      "Ep:216, loss:0.00000, loss_test:0.11542, lr:2.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.029, tt:3695.284\n",
      "Ep:217, loss:0.00000, loss_test:0.11550, lr:2.33e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.041, tt:3714.975\n",
      "Ep:218, loss:0.00000, loss_test:0.11552, lr:2.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.044, tt:3732.641\n",
      "Ep:219, loss:0.00000, loss_test:0.11577, lr:2.28e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.050, tt:3750.897\n",
      "Ep:220, loss:0.00000, loss_test:0.11555, lr:2.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.058, tt:3769.840\n",
      "Ep:221, loss:0.00000, loss_test:0.11584, lr:2.24e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.062, tt:3787.657\n",
      "Ep:222, loss:0.00000, loss_test:0.11620, lr:2.21e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.068, tt:3806.253\n",
      "Ep:223, loss:0.00000, loss_test:0.11607, lr:2.19e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.072, tt:3824.047\n",
      "Ep:224, loss:0.00000, loss_test:0.11637, lr:2.17e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.079, tt:3842.797\n",
      "Ep:225, loss:0.00000, loss_test:0.11622, lr:2.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.084, tt:3860.982\n",
      "Ep:226, loss:0.00000, loss_test:0.11608, lr:2.13e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.101, tt:3881.911\n",
      "Ep:227, loss:0.00000, loss_test:0.11636, lr:2.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.108, tt:3900.515\n",
      "Ep:228, loss:0.00000, loss_test:0.11667, lr:2.08e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.112, tt:3918.606\n",
      "Ep:229, loss:0.00000, loss_test:0.11654, lr:2.06e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.114, tt:3936.286\n",
      "Ep:230, loss:0.00000, loss_test:0.11671, lr:2.04e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.124, tt:3955.603\n",
      "Ep:231, loss:0.00000, loss_test:0.11683, lr:2.02e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.132, tt:3974.630\n",
      "Ep:232, loss:0.00000, loss_test:0.11655, lr:2.00e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.140, tt:3993.731\n",
      "Ep:233, loss:0.00000, loss_test:0.11692, lr:1.98e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.152, tt:4013.466\n",
      "Ep:234, loss:0.00000, loss_test:0.11681, lr:1.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.161, tt:4032.927\n",
      "Ep:235, loss:0.00000, loss_test:0.11696, lr:1.94e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.165, tt:4051.045\n",
      "Ep:236, loss:0.00000, loss_test:0.11711, lr:1.92e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.174, tt:4070.174\n",
      "Ep:237, loss:0.00000, loss_test:0.11678, lr:1.90e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.181, tt:4089.052\n",
      "Ep:238, loss:0.00000, loss_test:0.11710, lr:1.89e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.189, tt:4108.113\n",
      "Ep:239, loss:0.00000, loss_test:0.11728, lr:1.87e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.197, tt:4127.253\n",
      "Ep:240, loss:0.00000, loss_test:0.11697, lr:1.85e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.204, tt:4146.249\n",
      "Ep:241, loss:0.00000, loss_test:0.11727, lr:1.83e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.215, tt:4165.932\n",
      "Ep:242, loss:0.00000, loss_test:0.11759, lr:1.81e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.219, tt:4184.336\n",
      "Ep:243, loss:0.00000, loss_test:0.11743, lr:1.79e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.225, tt:4202.897\n",
      "Ep:244, loss:0.00000, loss_test:0.11752, lr:1.78e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.231, tt:4221.642\n",
      "Ep:245, loss:0.00000, loss_test:0.11782, lr:1.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.235, tt:4239.917\n",
      "Ep:246, loss:0.00000, loss_test:0.11765, lr:1.74e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.241, tt:4258.543\n",
      "Ep:247, loss:0.00000, loss_test:0.11802, lr:1.72e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.247, tt:4277.154\n",
      "Ep:248, loss:0.00000, loss_test:0.11797, lr:1.71e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.249, tt:4295.011\n",
      "Ep:249, loss:0.00000, loss_test:0.11797, lr:1.69e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.256, tt:4314.016\n",
      "Ep:250, loss:0.00000, loss_test:0.11804, lr:1.67e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.260, tt:4332.141\n",
      "Ep:251, loss:0.00000, loss_test:0.11812, lr:1.65e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.267, tt:4351.278\n",
      "Ep:252, loss:0.00000, loss_test:0.11819, lr:1.64e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.275, tt:4370.564\n",
      "Ep:253, loss:0.00000, loss_test:0.11843, lr:1.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.277, tt:4388.384\n",
      "Ep:254, loss:0.00000, loss_test:0.11851, lr:1.61e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.279, tt:4406.269\n",
      "Ep:255, loss:0.00000, loss_test:0.11834, lr:1.59e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.284, tt:4424.713\n",
      "Ep:256, loss:0.00000, loss_test:0.11873, lr:1.57e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.287, tt:4442.639\n",
      "Ep:257, loss:0.00000, loss_test:0.11875, lr:1.56e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.288, tt:4460.423\n",
      "Ep:258, loss:0.00000, loss_test:0.11865, lr:1.54e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.298, tt:4480.077\n",
      "Ep:259, loss:0.00000, loss_test:0.11905, lr:1.53e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.302, tt:4498.478\n",
      "Ep:260, loss:0.00000, loss_test:0.11916, lr:1.51e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.306, tt:4516.840\n",
      "Ep:261, loss:0.00000, loss_test:0.11908, lr:1.50e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.312, tt:4535.698\n",
      "Ep:262, loss:0.00000, loss_test:0.11908, lr:1.48e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.323, tt:4555.971\n",
      "Ep:263, loss:0.00000, loss_test:0.11933, lr:1.47e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.330, tt:4575.017\n",
      "Ep:264, loss:0.00000, loss_test:0.11944, lr:1.45e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.335, tt:4593.777\n",
      "Ep:265, loss:0.00000, loss_test:0.11928, lr:1.44e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.343, tt:4613.301\n",
      "Ep:266, loss:0.00000, loss_test:0.11947, lr:1.42e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.348, tt:4631.829\n",
      "Ep:267, loss:0.00000, loss_test:0.11942, lr:1.41e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.353, tt:4650.479\n",
      "Ep:268, loss:0.00000, loss_test:0.11928, lr:1.39e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.360, tt:4669.962\n",
      "Ep:269, loss:0.00000, loss_test:0.11959, lr:1.38e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.367, tt:4689.162\n",
      "Ep:270, loss:0.00000, loss_test:0.11969, lr:1.37e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.374, tt:4708.256\n",
      "Ep:271, loss:0.00000, loss_test:0.11968, lr:1.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.380, tt:4727.278\n",
      "Ep:272, loss:0.00000, loss_test:0.11976, lr:1.34e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.383, tt:4745.674\n",
      "Ep:273, loss:0.00000, loss_test:0.11988, lr:1.33e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.385, tt:4763.406\n",
      "Ep:274, loss:0.00000, loss_test:0.11986, lr:1.31e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.390, tt:4782.278\n",
      "Ep:275, loss:0.00000, loss_test:0.11972, lr:1.30e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.397, tt:4801.597\n",
      "Ep:276, loss:0.00000, loss_test:0.11992, lr:1.29e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.406, tt:4821.414\n",
      "Ep:277, loss:0.00000, loss_test:0.12000, lr:1.27e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.413, tt:4840.712\n",
      "Ep:278, loss:0.00000, loss_test:0.11995, lr:1.26e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.416, tt:4859.165\n",
      "Ep:279, loss:0.00000, loss_test:0.12000, lr:1.25e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.423, tt:4878.429\n",
      "Ep:280, loss:0.00000, loss_test:0.11994, lr:1.24e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.430, tt:4897.805\n",
      "Ep:281, loss:0.00000, loss_test:0.11998, lr:1.22e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.437, tt:4917.345\n",
      "Ep:282, loss:0.00000, loss_test:0.12008, lr:1.21e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.440, tt:4935.547\n",
      "Ep:283, loss:0.00000, loss_test:0.12001, lr:1.20e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.447, tt:4955.066\n",
      "Ep:284, loss:0.00000, loss_test:0.12022, lr:1.19e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.459, tt:4975.691\n",
      "Ep:285, loss:0.00000, loss_test:0.12022, lr:1.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.465, tt:4994.979\n",
      "Ep:286, loss:0.00000, loss_test:0.12012, lr:1.16e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.471, tt:5014.190\n",
      "Ep:287, loss:0.00000, loss_test:0.12012, lr:1.15e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.479, tt:5033.877\n",
      "Ep:288, loss:0.00000, loss_test:0.12019, lr:1.14e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.488, tt:5054.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:289, loss:0.00000, loss_test:0.12024, lr:1.13e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.493, tt:5073.099\n",
      "Ep:290, loss:0.00000, loss_test:0.12024, lr:1.12e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.496, tt:5091.333\n",
      "Ep:291, loss:0.00000, loss_test:0.12031, lr:1.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.499, tt:5109.654\n",
      "Ep:292, loss:0.00000, loss_test:0.12037, lr:1.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.503, tt:5128.250\n",
      "Ep:293, loss:0.00000, loss_test:0.12029, lr:1.08e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.511, tt:5148.124\n",
      "Ep:294, loss:0.00000, loss_test:0.12036, lr:1.07e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.512, tt:5165.997\n",
      "Ep:295, loss:0.00000, loss_test:0.12028, lr:1.06e-03, fs:0.76923 (r=0.657,p=0.929),  time:17.501, tt:5180.399\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14100, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:10.052, tt:10.052\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14064, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:12.833, tt:25.666\n",
      "Ep:2, loss:0.00004, loss_test:0.14010, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:13.915, tt:41.745\n",
      "Ep:3, loss:0.00004, loss_test:0.13935, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:14.479, tt:57.916\n",
      "Ep:4, loss:0.00004, loss_test:0.13838, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:14.813, tt:74.066\n",
      "Ep:5, loss:0.00004, loss_test:0.13715, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.035, tt:90.209\n",
      "Ep:6, loss:0.00004, loss_test:0.13565, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:15.158, tt:106.109\n",
      "Ep:7, loss:0.00004, loss_test:0.13388, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:15.071, tt:120.572\n",
      "Ep:8, loss:0.00004, loss_test:0.13178, lr:1.00e-02, fs:0.65068 (r=0.960,p=0.492),  time:15.031, tt:135.283\n",
      "Ep:9, loss:0.00004, loss_test:0.12921, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:15.063, tt:150.630\n",
      "Ep:10, loss:0.00004, loss_test:0.12609, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:15.133, tt:166.458\n",
      "Ep:11, loss:0.00004, loss_test:0.12244, lr:1.00e-02, fs:0.66154 (r=0.869,p=0.534),  time:15.315, tt:183.777\n",
      "Ep:12, loss:0.00004, loss_test:0.11837, lr:9.90e-03, fs:0.64257 (r=0.808,p=0.533),  time:15.435, tt:200.649\n",
      "Ep:13, loss:0.00003, loss_test:0.11539, lr:9.80e-03, fs:0.67234 (r=0.798,p=0.581),  time:15.448, tt:216.273\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.11288, lr:9.80e-03, fs:0.66964 (r=0.758,p=0.600),  time:15.526, tt:232.884\n",
      "Ep:15, loss:0.00003, loss_test:0.11094, lr:9.80e-03, fs:0.68571 (r=0.727,p=0.649),  time:15.626, tt:250.023\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.10958, lr:9.80e-03, fs:0.67961 (r=0.707,p=0.654),  time:15.641, tt:265.894\n",
      "Ep:17, loss:0.00003, loss_test:0.10829, lr:9.80e-03, fs:0.69652 (r=0.707,p=0.686),  time:15.580, tt:280.438\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.10715, lr:9.80e-03, fs:0.70936 (r=0.727,p=0.692),  time:15.635, tt:297.058\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.10636, lr:9.80e-03, fs:0.70192 (r=0.737,p=0.670),  time:15.664, tt:313.288\n",
      "Ep:20, loss:0.00003, loss_test:0.10616, lr:9.80e-03, fs:0.69124 (r=0.758,p=0.636),  time:15.606, tt:327.719\n",
      "Ep:21, loss:0.00003, loss_test:0.10614, lr:9.80e-03, fs:0.69683 (r=0.778,p=0.631),  time:15.656, tt:344.431\n",
      "Ep:22, loss:0.00003, loss_test:0.10579, lr:9.80e-03, fs:0.69683 (r=0.778,p=0.631),  time:15.664, tt:360.266\n",
      "Ep:23, loss:0.00003, loss_test:0.10485, lr:9.80e-03, fs:0.71560 (r=0.788,p=0.655),  time:15.658, tt:375.784\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10356, lr:9.80e-03, fs:0.69811 (r=0.747,p=0.655),  time:15.659, tt:391.472\n",
      "Ep:25, loss:0.00003, loss_test:0.10238, lr:9.80e-03, fs:0.70531 (r=0.737,p=0.676),  time:15.685, tt:407.808\n",
      "Ep:26, loss:0.00003, loss_test:0.10140, lr:9.80e-03, fs:0.71220 (r=0.737,p=0.689),  time:15.702, tt:423.967\n",
      "Ep:27, loss:0.00003, loss_test:0.10052, lr:9.80e-03, fs:0.72277 (r=0.737,p=0.709),  time:15.721, tt:440.198\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.09949, lr:9.80e-03, fs:0.72637 (r=0.737,p=0.716),  time:15.713, tt:455.687\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.09843, lr:9.80e-03, fs:0.72277 (r=0.737,p=0.709),  time:15.744, tt:472.312\n",
      "Ep:30, loss:0.00003, loss_test:0.09748, lr:9.80e-03, fs:0.72549 (r=0.747,p=0.705),  time:15.758, tt:488.500\n",
      "Ep:31, loss:0.00003, loss_test:0.09658, lr:9.80e-03, fs:0.74038 (r=0.778,p=0.706),  time:15.765, tt:504.466\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.09569, lr:9.80e-03, fs:0.74038 (r=0.778,p=0.706),  time:15.792, tt:521.138\n",
      "Ep:33, loss:0.00003, loss_test:0.09468, lr:9.80e-03, fs:0.74146 (r=0.768,p=0.717),  time:15.801, tt:537.237\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.09367, lr:9.80e-03, fs:0.75862 (r=0.778,p=0.740),  time:15.800, tt:553.010\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.09282, lr:9.80e-03, fs:0.75510 (r=0.747,p=0.763),  time:15.791, tt:568.491\n",
      "Ep:36, loss:0.00003, loss_test:0.09201, lr:9.80e-03, fs:0.75897 (r=0.747,p=0.771),  time:15.811, tt:585.002\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00003, loss_test:0.09147, lr:9.80e-03, fs:0.76142 (r=0.758,p=0.765),  time:15.835, tt:601.739\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.09105, lr:9.80e-03, fs:0.75758 (r=0.758,p=0.758),  time:15.824, tt:617.136\n",
      "Ep:39, loss:0.00002, loss_test:0.09054, lr:9.80e-03, fs:0.75377 (r=0.758,p=0.750),  time:15.820, tt:632.807\n",
      "Ep:40, loss:0.00002, loss_test:0.08983, lr:9.80e-03, fs:0.75758 (r=0.758,p=0.758),  time:15.823, tt:648.750\n",
      "Ep:41, loss:0.00002, loss_test:0.08907, lr:9.80e-03, fs:0.76531 (r=0.758,p=0.773),  time:15.817, tt:664.316\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.08836, lr:9.80e-03, fs:0.77320 (r=0.758,p=0.789),  time:15.812, tt:679.909\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.08784, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:15.859, tt:697.778\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00002, loss_test:0.08751, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:15.853, tt:713.363\n",
      "Ep:45, loss:0.00002, loss_test:0.08720, lr:9.80e-03, fs:0.77720 (r=0.758,p=0.798),  time:15.852, tt:729.186\n",
      "Ep:46, loss:0.00002, loss_test:0.08678, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:15.841, tt:744.509\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.08621, lr:9.80e-03, fs:0.78756 (r=0.768,p=0.809),  time:15.834, tt:760.030\n",
      "Ep:48, loss:0.00002, loss_test:0.08556, lr:9.80e-03, fs:0.79167 (r=0.768,p=0.817),  time:15.817, tt:775.032\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.08494, lr:9.80e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.808, tt:790.388\n",
      "Ep:50, loss:0.00002, loss_test:0.08436, lr:9.80e-03, fs:0.78534 (r=0.758,p=0.815),  time:15.796, tt:805.587\n",
      "Ep:51, loss:0.00002, loss_test:0.08378, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.774, tt:820.258\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.08319, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.743, tt:834.363\n",
      "Ep:53, loss:0.00002, loss_test:0.08266, lr:9.80e-03, fs:0.81026 (r=0.798,p=0.823),  time:15.718, tt:848.750\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.08224, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.698, tt:863.388\n",
      "Ep:55, loss:0.00002, loss_test:0.08191, lr:9.80e-03, fs:0.80412 (r=0.788,p=0.821),  time:15.708, tt:879.668\n",
      "Ep:56, loss:0.00002, loss_test:0.08159, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.723, tt:896.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:57, loss:0.00002, loss_test:0.08127, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.718, tt:911.662\n",
      "Ep:58, loss:0.00002, loss_test:0.08083, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.725, tt:927.769\n",
      "Ep:59, loss:0.00002, loss_test:0.08031, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.721, tt:943.241\n",
      "Ep:60, loss:0.00002, loss_test:0.07984, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.727, tt:959.349\n",
      "Ep:61, loss:0.00002, loss_test:0.07940, lr:9.80e-03, fs:0.80208 (r=0.778,p=0.828),  time:15.714, tt:974.281\n",
      "Ep:62, loss:0.00002, loss_test:0.07906, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.725, tt:990.695\n",
      "Ep:63, loss:0.00002, loss_test:0.07876, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.734, tt:1006.958\n",
      "Ep:64, loss:0.00002, loss_test:0.07841, lr:9.80e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.740, tt:1023.076\n",
      "Ep:65, loss:0.00002, loss_test:0.07802, lr:9.70e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.745, tt:1039.155\n",
      "Ep:66, loss:0.00002, loss_test:0.07768, lr:9.61e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.738, tt:1054.469\n",
      "Ep:67, loss:0.00002, loss_test:0.07745, lr:9.51e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.758, tt:1071.568\n",
      "Ep:68, loss:0.00002, loss_test:0.07728, lr:9.41e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.773, tt:1088.347\n",
      "Ep:69, loss:0.00002, loss_test:0.07710, lr:9.32e-03, fs:0.80628 (r=0.778,p=0.837),  time:15.778, tt:1104.439\n",
      "Ep:70, loss:0.00002, loss_test:0.07689, lr:9.23e-03, fs:0.81250 (r=0.788,p=0.839),  time:15.777, tt:1120.201\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00002, loss_test:0.07666, lr:9.23e-03, fs:0.81250 (r=0.788,p=0.839),  time:15.781, tt:1136.203\n",
      "Ep:72, loss:0.00002, loss_test:0.07647, lr:9.23e-03, fs:0.81865 (r=0.798,p=0.840),  time:15.769, tt:1151.133\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00002, loss_test:0.07635, lr:9.23e-03, fs:0.81865 (r=0.798,p=0.840),  time:15.780, tt:1167.698\n",
      "Ep:74, loss:0.00002, loss_test:0.07621, lr:9.23e-03, fs:0.81865 (r=0.798,p=0.840),  time:15.778, tt:1183.385\n",
      "Ep:75, loss:0.00002, loss_test:0.07600, lr:9.23e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.789, tt:1199.928\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00002, loss_test:0.07583, lr:9.23e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.785, tt:1215.419\n",
      "Ep:77, loss:0.00002, loss_test:0.07574, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.784, tt:1231.163\n",
      "##########Best model found so far##########\n",
      "Ep:78, loss:0.00002, loss_test:0.07573, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.776, tt:1246.324\n",
      "Ep:79, loss:0.00002, loss_test:0.07561, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.785, tt:1262.838\n",
      "Ep:80, loss:0.00002, loss_test:0.07531, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.795, tt:1279.361\n",
      "Ep:81, loss:0.00002, loss_test:0.07500, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.799, tt:1295.524\n",
      "Ep:82, loss:0.00001, loss_test:0.07485, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.813, tt:1312.455\n",
      "Ep:83, loss:0.00001, loss_test:0.07478, lr:9.23e-03, fs:0.83505 (r=0.818,p=0.853),  time:15.829, tt:1329.659\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.07470, lr:9.23e-03, fs:0.83505 (r=0.818,p=0.853),  time:15.849, tt:1347.124\n",
      "Ep:85, loss:0.00001, loss_test:0.07448, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.858, tt:1363.768\n",
      "Ep:86, loss:0.00001, loss_test:0.07431, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.859, tt:1379.744\n",
      "Ep:87, loss:0.00001, loss_test:0.07414, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.875, tt:1396.980\n",
      "Ep:88, loss:0.00001, loss_test:0.07386, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.872, tt:1412.595\n",
      "Ep:89, loss:0.00001, loss_test:0.07367, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.885, tt:1429.688\n",
      "Ep:90, loss:0.00001, loss_test:0.07354, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.904, tt:1447.235\n",
      "Ep:91, loss:0.00001, loss_test:0.07353, lr:9.23e-03, fs:0.83077 (r=0.818,p=0.844),  time:15.913, tt:1463.977\n",
      "Ep:92, loss:0.00001, loss_test:0.07331, lr:9.23e-03, fs:0.82051 (r=0.808,p=0.833),  time:15.920, tt:1480.514\n",
      "Ep:93, loss:0.00001, loss_test:0.07303, lr:9.23e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.923, tt:1496.725\n",
      "Ep:94, loss:0.00001, loss_test:0.07293, lr:9.23e-03, fs:0.82474 (r=0.808,p=0.842),  time:15.934, tt:1513.726\n",
      "Ep:95, loss:0.00001, loss_test:0.07302, lr:9.14e-03, fs:0.82902 (r=0.808,p=0.851),  time:15.946, tt:1530.769\n",
      "Ep:96, loss:0.00001, loss_test:0.07302, lr:9.04e-03, fs:0.82902 (r=0.808,p=0.851),  time:15.954, tt:1547.507\n",
      "Ep:97, loss:0.00001, loss_test:0.07294, lr:8.95e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.966, tt:1564.675\n",
      "Ep:98, loss:0.00001, loss_test:0.07278, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.973, tt:1581.306\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.07264, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.978, tt:1597.801\n",
      "Ep:100, loss:0.00001, loss_test:0.07262, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.972, tt:1613.180\n",
      "Ep:101, loss:0.00001, loss_test:0.07256, lr:8.86e-03, fs:0.83333 (r=0.808,p=0.860),  time:15.966, tt:1628.559\n",
      "Ep:102, loss:0.00001, loss_test:0.07238, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.966, tt:1644.482\n",
      "Ep:103, loss:0.00001, loss_test:0.07210, lr:8.86e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.962, tt:1660.069\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00001, loss_test:0.07202, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.971, tt:1676.972\n",
      "Ep:105, loss:0.00001, loss_test:0.07196, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.977, tt:1693.575\n",
      "Ep:106, loss:0.00001, loss_test:0.07184, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.968, tt:1708.550\n",
      "Ep:107, loss:0.00001, loss_test:0.07169, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.971, tt:1724.881\n",
      "Ep:108, loss:0.00001, loss_test:0.07162, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.979, tt:1741.712\n",
      "Ep:109, loss:0.00001, loss_test:0.07148, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.980, tt:1757.850\n",
      "Ep:110, loss:0.00001, loss_test:0.07137, lr:8.86e-03, fs:0.83938 (r=0.818,p=0.862),  time:15.985, tt:1774.353\n",
      "Ep:111, loss:0.00001, loss_test:0.07123, lr:8.86e-03, fs:0.84536 (r=0.828,p=0.863),  time:15.983, tt:1790.109\n",
      "Ep:112, loss:0.00001, loss_test:0.07124, lr:8.86e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.980, tt:1805.792\n",
      "##########Best model found so far##########\n",
      "Ep:113, loss:0.00001, loss_test:0.07123, lr:8.86e-03, fs:0.84974 (r=0.828,p=0.872),  time:15.979, tt:1821.638\n",
      "Ep:114, loss:0.00001, loss_test:0.07128, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.979, tt:1837.641\n",
      "##########Best model found so far##########\n",
      "Ep:115, loss:0.00001, loss_test:0.07139, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.977, tt:1853.371\n",
      "Ep:116, loss:0.00001, loss_test:0.07143, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.982, tt:1869.887\n",
      "Ep:117, loss:0.00001, loss_test:0.07145, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.977, tt:1885.309\n",
      "Ep:118, loss:0.00001, loss_test:0.07148, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.980, tt:1901.585\n",
      "Ep:119, loss:0.00001, loss_test:0.07145, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.984, tt:1918.053\n",
      "Ep:120, loss:0.00001, loss_test:0.07166, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.986, tt:1934.308\n",
      "Ep:121, loss:0.00001, loss_test:0.07177, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.987, tt:1950.433\n",
      "Ep:122, loss:0.00001, loss_test:0.07150, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.995, tt:1967.325\n",
      "Ep:123, loss:0.00001, loss_test:0.07137, lr:8.86e-03, fs:0.85417 (r=0.828,p=0.882),  time:15.994, tt:1983.256\n",
      "Ep:124, loss:0.00001, loss_test:0.07171, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.988, tt:1998.494\n",
      "Ep:125, loss:0.00001, loss_test:0.07171, lr:8.86e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.981, tt:2013.596\n",
      "Ep:126, loss:0.00001, loss_test:0.07131, lr:8.78e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.984, tt:2029.911\n",
      "Ep:127, loss:0.00001, loss_test:0.07133, lr:8.69e-03, fs:0.85263 (r=0.818,p=0.890),  time:15.979, tt:2045.340\n",
      "Ep:128, loss:0.00001, loss_test:0.07156, lr:8.60e-03, fs:0.84492 (r=0.798,p=0.898),  time:15.974, tt:2060.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.07147, lr:8.51e-03, fs:0.85106 (r=0.808,p=0.899),  time:15.968, tt:2075.815\n",
      "Ep:130, loss:0.00001, loss_test:0.07123, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.964, tt:2091.270\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00001, loss_test:0.07121, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.957, tt:2106.346\n",
      "Ep:132, loss:0.00001, loss_test:0.07132, lr:8.43e-03, fs:0.85106 (r=0.808,p=0.899),  time:15.961, tt:2122.877\n",
      "Ep:133, loss:0.00001, loss_test:0.07131, lr:8.43e-03, fs:0.85106 (r=0.808,p=0.899),  time:15.955, tt:2137.985\n",
      "Ep:134, loss:0.00001, loss_test:0.07113, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.956, tt:2154.117\n",
      "Ep:135, loss:0.00001, loss_test:0.07110, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.952, tt:2169.416\n",
      "Ep:136, loss:0.00001, loss_test:0.07120, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.942, tt:2184.084\n",
      "Ep:137, loss:0.00001, loss_test:0.07125, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.939, tt:2199.548\n",
      "Ep:138, loss:0.00001, loss_test:0.07122, lr:8.43e-03, fs:0.85714 (r=0.818,p=0.900),  time:15.951, tt:2217.123\n",
      "Ep:139, loss:0.00001, loss_test:0.07115, lr:8.43e-03, fs:0.86316 (r=0.828,p=0.901),  time:15.953, tt:2233.371\n",
      "##########Best model found so far##########\n",
      "Ep:140, loss:0.00001, loss_test:0.07130, lr:8.43e-03, fs:0.86022 (r=0.808,p=0.920),  time:15.957, tt:2249.898\n",
      "Ep:141, loss:0.00001, loss_test:0.07129, lr:8.43e-03, fs:0.85561 (r=0.808,p=0.909),  time:15.959, tt:2266.233\n",
      "Ep:142, loss:0.00001, loss_test:0.07126, lr:8.43e-03, fs:0.85561 (r=0.808,p=0.909),  time:15.955, tt:2281.550\n",
      "Ep:143, loss:0.00001, loss_test:0.07129, lr:8.43e-03, fs:0.84946 (r=0.798,p=0.908),  time:15.959, tt:2298.086\n",
      "Ep:144, loss:0.00001, loss_test:0.07123, lr:8.43e-03, fs:0.84783 (r=0.788,p=0.918),  time:15.955, tt:2313.441\n",
      "Ep:145, loss:0.00001, loss_test:0.07121, lr:8.43e-03, fs:0.84783 (r=0.788,p=0.918),  time:15.954, tt:2329.296\n",
      "Ep:146, loss:0.00001, loss_test:0.07121, lr:8.43e-03, fs:0.84783 (r=0.788,p=0.918),  time:15.942, tt:2343.455\n",
      "Ep:147, loss:0.00001, loss_test:0.07140, lr:8.43e-03, fs:0.85246 (r=0.788,p=0.929),  time:15.937, tt:2358.634\n",
      "Ep:148, loss:0.00001, loss_test:0.07140, lr:8.43e-03, fs:0.84615 (r=0.778,p=0.928),  time:15.932, tt:2373.868\n",
      "Ep:149, loss:0.00001, loss_test:0.07137, lr:8.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:15.933, tt:2389.939\n",
      "Ep:150, loss:0.00001, loss_test:0.07138, lr:8.43e-03, fs:0.84153 (r=0.778,p=0.917),  time:15.940, tt:2406.922\n",
      "Ep:151, loss:0.00001, loss_test:0.07131, lr:8.35e-03, fs:0.84153 (r=0.778,p=0.917),  time:15.938, tt:2422.588\n",
      "Ep:152, loss:0.00001, loss_test:0.07127, lr:8.26e-03, fs:0.84153 (r=0.778,p=0.917),  time:15.939, tt:2438.623\n",
      "Ep:153, loss:0.00001, loss_test:0.07152, lr:8.18e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.930, tt:2453.197\n",
      "Ep:154, loss:0.00001, loss_test:0.07159, lr:8.10e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.926, tt:2468.581\n",
      "Ep:155, loss:0.00001, loss_test:0.07148, lr:8.02e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.919, tt:2483.405\n",
      "Ep:156, loss:0.00001, loss_test:0.07170, lr:7.94e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.921, tt:2499.646\n",
      "Ep:157, loss:0.00001, loss_test:0.07150, lr:7.86e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.923, tt:2515.896\n",
      "Ep:158, loss:0.00001, loss_test:0.07136, lr:7.78e-03, fs:0.83516 (r=0.768,p=0.916),  time:15.934, tt:2533.571\n",
      "Ep:159, loss:0.00001, loss_test:0.07140, lr:7.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.933, tt:2549.327\n",
      "Ep:160, loss:0.00001, loss_test:0.07168, lr:7.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.928, tt:2564.366\n",
      "Ep:161, loss:0.00001, loss_test:0.07177, lr:7.55e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.929, tt:2580.577\n",
      "Ep:162, loss:0.00001, loss_test:0.07161, lr:7.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.928, tt:2596.244\n",
      "Ep:163, loss:0.00001, loss_test:0.07169, lr:7.40e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.922, tt:2611.204\n",
      "Ep:164, loss:0.00001, loss_test:0.07181, lr:7.32e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.921, tt:2626.982\n",
      "Ep:165, loss:0.00001, loss_test:0.07194, lr:7.25e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.915, tt:2641.877\n",
      "Ep:166, loss:0.00001, loss_test:0.07186, lr:7.18e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.915, tt:2657.722\n",
      "Ep:167, loss:0.00001, loss_test:0.07189, lr:7.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.911, tt:2673.053\n",
      "Ep:168, loss:0.00001, loss_test:0.07186, lr:7.03e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.911, tt:2689.013\n",
      "Ep:169, loss:0.00001, loss_test:0.07181, lr:6.96e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.908, tt:2704.376\n",
      "Ep:170, loss:0.00001, loss_test:0.07176, lr:6.89e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.906, tt:2719.863\n",
      "Ep:171, loss:0.00001, loss_test:0.07186, lr:6.83e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.903, tt:2735.311\n",
      "Ep:172, loss:0.00001, loss_test:0.07138, lr:6.76e-03, fs:0.82873 (r=0.758,p=0.915),  time:15.909, tt:2752.202\n",
      "Ep:173, loss:0.00001, loss_test:0.07175, lr:6.69e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.912, tt:2768.749\n",
      "Ep:174, loss:0.00001, loss_test:0.07179, lr:6.62e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.910, tt:2784.172\n",
      "Ep:175, loss:0.00001, loss_test:0.07156, lr:6.56e-03, fs:0.82873 (r=0.758,p=0.915),  time:15.910, tt:2800.230\n",
      "Ep:176, loss:0.00001, loss_test:0.07179, lr:6.49e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.908, tt:2815.803\n",
      "Ep:177, loss:0.00001, loss_test:0.07160, lr:6.43e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.903, tt:2830.759\n",
      "Ep:178, loss:0.00001, loss_test:0.07168, lr:6.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.906, tt:2847.132\n",
      "Ep:179, loss:0.00001, loss_test:0.07196, lr:6.30e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.903, tt:2862.526\n",
      "Ep:180, loss:0.00001, loss_test:0.07164, lr:6.24e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.907, tt:2879.174\n",
      "Ep:181, loss:0.00001, loss_test:0.07156, lr:6.17e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.907, tt:2895.033\n",
      "Ep:182, loss:0.00001, loss_test:0.07174, lr:6.11e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.906, tt:2910.764\n",
      "Ep:183, loss:0.00001, loss_test:0.07164, lr:6.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.898, tt:2925.248\n",
      "Ep:184, loss:0.00001, loss_test:0.07175, lr:5.99e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.902, tt:2941.930\n",
      "Ep:185, loss:0.00001, loss_test:0.07160, lr:5.93e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.895, tt:2956.494\n",
      "Ep:186, loss:0.00001, loss_test:0.07152, lr:5.87e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.896, tt:2972.641\n",
      "Ep:187, loss:0.00001, loss_test:0.07205, lr:5.81e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.894, tt:2988.077\n",
      "Ep:188, loss:0.00001, loss_test:0.07203, lr:5.75e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.893, tt:3003.852\n",
      "Ep:189, loss:0.00001, loss_test:0.07153, lr:5.70e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.891, tt:3019.280\n",
      "Ep:190, loss:0.00001, loss_test:0.07158, lr:5.64e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.892, tt:3035.290\n",
      "Ep:191, loss:0.00001, loss_test:0.07214, lr:5.58e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.889, tt:3050.785\n",
      "Ep:192, loss:0.00001, loss_test:0.07209, lr:5.53e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.895, tt:3067.639\n",
      "Ep:193, loss:0.00001, loss_test:0.07173, lr:5.47e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.890, tt:3082.738\n",
      "Ep:194, loss:0.00001, loss_test:0.07184, lr:5.42e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.886, tt:3097.729\n",
      "Ep:195, loss:0.00001, loss_test:0.07227, lr:5.36e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.883, tt:3112.973\n",
      "Ep:196, loss:0.00001, loss_test:0.07236, lr:5.31e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.897, tt:3131.676\n",
      "Ep:197, loss:0.00001, loss_test:0.07205, lr:5.26e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.891, tt:3146.484\n",
      "Ep:198, loss:0.00001, loss_test:0.07187, lr:5.20e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.889, tt:3161.990\n",
      "Ep:199, loss:0.00000, loss_test:0.07225, lr:5.15e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.888, tt:3177.518\n",
      "Ep:200, loss:0.00000, loss_test:0.07253, lr:5.10e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.887, tt:3193.284\n",
      "Ep:201, loss:0.00000, loss_test:0.07221, lr:5.05e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.883, tt:3208.268\n",
      "Ep:202, loss:0.00000, loss_test:0.07209, lr:5.00e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.874, tt:3222.410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:203, loss:0.00000, loss_test:0.07236, lr:4.95e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.870, tt:3237.505\n",
      "Ep:204, loss:0.00000, loss_test:0.07251, lr:4.90e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.864, tt:3252.121\n",
      "Ep:205, loss:0.00000, loss_test:0.07230, lr:4.85e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.863, tt:3267.795\n",
      "Ep:206, loss:0.00000, loss_test:0.07234, lr:4.80e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.853, tt:3281.672\n",
      "Ep:207, loss:0.00000, loss_test:0.07252, lr:4.75e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.849, tt:3296.622\n",
      "Ep:208, loss:0.00000, loss_test:0.07253, lr:4.71e-03, fs:0.83333 (r=0.758,p=0.926),  time:15.845, tt:3311.525\n",
      "Ep:209, loss:0.00000, loss_test:0.07253, lr:4.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.843, tt:3326.963\n",
      "Ep:210, loss:0.00000, loss_test:0.07264, lr:4.61e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.840, tt:3342.307\n",
      "Ep:211, loss:0.00000, loss_test:0.07265, lr:4.57e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.835, tt:3357.022\n",
      "Ep:212, loss:0.00000, loss_test:0.07263, lr:4.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.831, tt:3372.080\n",
      "Ep:213, loss:0.00000, loss_test:0.07275, lr:4.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.831, tt:3387.905\n",
      "Ep:214, loss:0.00000, loss_test:0.07285, lr:4.43e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.834, tt:3404.217\n",
      "Ep:215, loss:0.00000, loss_test:0.07282, lr:4.39e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.827, tt:3418.696\n",
      "Ep:216, loss:0.00000, loss_test:0.07275, lr:4.34e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.823, tt:3433.646\n",
      "Ep:217, loss:0.00000, loss_test:0.07279, lr:4.30e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.819, tt:3448.490\n",
      "Ep:218, loss:0.00000, loss_test:0.07282, lr:4.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.820, tt:3464.612\n",
      "Ep:219, loss:0.00000, loss_test:0.07284, lr:4.21e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.820, tt:3480.367\n",
      "Ep:220, loss:0.00000, loss_test:0.07277, lr:4.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.813, tt:3494.691\n",
      "Ep:221, loss:0.00000, loss_test:0.07280, lr:4.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.810, tt:3509.931\n",
      "Ep:222, loss:0.00000, loss_test:0.07291, lr:4.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.809, tt:3525.414\n",
      "Ep:223, loss:0.00000, loss_test:0.07284, lr:4.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.806, tt:3540.629\n",
      "Ep:224, loss:0.00000, loss_test:0.07282, lr:4.01e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.803, tt:3555.649\n",
      "Ep:225, loss:0.00000, loss_test:0.07291, lr:3.97e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.799, tt:3570.675\n",
      "Ep:226, loss:0.00000, loss_test:0.07285, lr:3.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.800, tt:3586.502\n",
      "Ep:227, loss:0.00000, loss_test:0.07287, lr:3.89e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.800, tt:3602.497\n",
      "Ep:228, loss:0.00000, loss_test:0.07279, lr:3.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.794, tt:3616.932\n",
      "Ep:229, loss:0.00000, loss_test:0.07278, lr:3.81e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.791, tt:3631.887\n",
      "Ep:230, loss:0.00000, loss_test:0.07280, lr:3.77e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.787, tt:3646.797\n",
      "Ep:231, loss:0.00000, loss_test:0.07279, lr:3.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.785, tt:3662.177\n",
      "Ep:232, loss:0.00000, loss_test:0.07281, lr:3.70e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.781, tt:3676.968\n",
      "Ep:233, loss:0.00000, loss_test:0.07287, lr:3.66e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.782, tt:3693.008\n",
      "Ep:234, loss:0.00000, loss_test:0.07277, lr:3.62e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.783, tt:3709.070\n",
      "Ep:235, loss:0.00000, loss_test:0.07298, lr:3.59e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.782, tt:3724.665\n",
      "Ep:236, loss:0.00000, loss_test:0.07298, lr:3.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.792, tt:3742.711\n",
      "Ep:237, loss:0.00000, loss_test:0.07285, lr:3.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.791, tt:3758.158\n",
      "Ep:238, loss:0.00000, loss_test:0.07291, lr:3.48e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.791, tt:3774.026\n",
      "Ep:239, loss:0.00000, loss_test:0.07311, lr:3.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.786, tt:3788.721\n",
      "Ep:240, loss:0.00000, loss_test:0.07302, lr:3.41e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.784, tt:3804.053\n",
      "Ep:241, loss:0.00000, loss_test:0.07288, lr:3.38e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.788, tt:3820.608\n",
      "Ep:242, loss:0.00000, loss_test:0.07302, lr:3.34e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.784, tt:3835.404\n",
      "Ep:243, loss:0.00000, loss_test:0.07318, lr:3.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.785, tt:3851.476\n",
      "Ep:244, loss:0.00000, loss_test:0.07312, lr:3.28e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.788, tt:3867.943\n",
      "Ep:245, loss:0.00000, loss_test:0.07302, lr:3.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.784, tt:3882.950\n",
      "Ep:246, loss:0.00000, loss_test:0.07309, lr:3.21e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.784, tt:3898.612\n",
      "Ep:247, loss:0.00000, loss_test:0.07318, lr:3.18e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.786, tt:3915.011\n",
      "Ep:248, loss:0.00000, loss_test:0.07316, lr:3.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.792, tt:3932.255\n",
      "Ep:249, loss:0.00000, loss_test:0.07313, lr:3.12e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.795, tt:3948.842\n",
      "Ep:250, loss:0.00000, loss_test:0.07320, lr:3.09e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.794, tt:3964.218\n",
      "Ep:251, loss:0.00000, loss_test:0.07318, lr:3.05e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.795, tt:3980.373\n",
      "Ep:252, loss:0.00000, loss_test:0.07312, lr:3.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.799, tt:3997.256\n",
      "Ep:253, loss:0.00000, loss_test:0.07323, lr:2.99e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.800, tt:4013.186\n",
      "Ep:254, loss:0.00000, loss_test:0.07323, lr:2.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.802, tt:4029.486\n",
      "Ep:255, loss:0.00000, loss_test:0.07310, lr:2.93e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.802, tt:4045.409\n",
      "Ep:256, loss:0.00000, loss_test:0.07315, lr:2.90e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.801, tt:4060.976\n",
      "Ep:257, loss:0.00000, loss_test:0.07328, lr:2.88e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.802, tt:4076.831\n",
      "Ep:258, loss:0.00000, loss_test:0.07320, lr:2.85e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.806, tt:4093.720\n",
      "Ep:259, loss:0.00000, loss_test:0.07316, lr:2.82e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.803, tt:4108.860\n",
      "Ep:260, loss:0.00000, loss_test:0.07327, lr:2.79e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.802, tt:4124.307\n",
      "Ep:261, loss:0.00000, loss_test:0.07328, lr:2.76e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.804, tt:4140.717\n",
      "Ep:262, loss:0.00000, loss_test:0.07319, lr:2.73e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.806, tt:4156.912\n",
      "Ep:263, loss:0.00000, loss_test:0.07328, lr:2.71e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.806, tt:4172.732\n",
      "Ep:264, loss:0.00000, loss_test:0.07333, lr:2.68e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.810, tt:4189.521\n",
      "Ep:265, loss:0.00000, loss_test:0.07324, lr:2.65e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.807, tt:4204.653\n",
      "Ep:266, loss:0.00000, loss_test:0.07323, lr:2.63e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.809, tt:4221.068\n",
      "Ep:267, loss:0.00000, loss_test:0.07343, lr:2.60e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.812, tt:4237.503\n",
      "Ep:268, loss:0.00000, loss_test:0.07342, lr:2.57e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.818, tt:4255.161\n",
      "Ep:269, loss:0.00000, loss_test:0.07326, lr:2.55e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.823, tt:4272.120\n",
      "Ep:270, loss:0.00000, loss_test:0.07327, lr:2.52e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.818, tt:4286.571\n",
      "Ep:271, loss:0.00000, loss_test:0.07342, lr:2.50e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.819, tt:4302.682\n",
      "Ep:272, loss:0.00000, loss_test:0.07340, lr:2.47e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.820, tt:4318.968\n",
      "Ep:273, loss:0.00000, loss_test:0.07329, lr:2.45e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.821, tt:4334.907\n",
      "Ep:274, loss:0.00000, loss_test:0.07330, lr:2.42e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.825, tt:4351.817\n",
      "Ep:275, loss:0.00000, loss_test:0.07339, lr:2.40e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.826, tt:4367.947\n",
      "Ep:276, loss:0.00000, loss_test:0.07334, lr:2.38e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.827, tt:4383.943\n",
      "Ep:277, loss:0.00000, loss_test:0.07326, lr:2.35e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.828, tt:4400.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:278, loss:0.00000, loss_test:0.07338, lr:2.33e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.828, tt:4415.936\n",
      "Ep:279, loss:0.00000, loss_test:0.07338, lr:2.31e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.831, tt:4432.658\n",
      "Ep:280, loss:0.00000, loss_test:0.07325, lr:2.28e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.835, tt:4449.523\n",
      "Ep:281, loss:0.00000, loss_test:0.07326, lr:2.26e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.832, tt:4464.714\n",
      "Ep:282, loss:0.00000, loss_test:0.07330, lr:2.24e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.833, tt:4480.770\n",
      "Ep:283, loss:0.00000, loss_test:0.07327, lr:2.21e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.834, tt:4496.813\n",
      "Ep:284, loss:0.00000, loss_test:0.07324, lr:2.19e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.833, tt:4512.361\n",
      "Ep:285, loss:0.00000, loss_test:0.07328, lr:2.17e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.835, tt:4528.753\n",
      "Ep:286, loss:0.00000, loss_test:0.07332, lr:2.15e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.846, tt:4547.666\n",
      "Ep:287, loss:0.00000, loss_test:0.07327, lr:2.13e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.846, tt:4563.653\n",
      "Ep:288, loss:0.00000, loss_test:0.07322, lr:2.11e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.850, tt:4580.700\n",
      "Ep:289, loss:0.00000, loss_test:0.07329, lr:2.08e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.854, tt:4597.702\n",
      "Ep:290, loss:0.00000, loss_test:0.07330, lr:2.06e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.851, tt:4612.593\n",
      "Ep:291, loss:0.00000, loss_test:0.07326, lr:2.04e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.853, tt:4629.004\n",
      "Ep:292, loss:0.00000, loss_test:0.07327, lr:2.02e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.855, tt:4645.497\n",
      "Ep:293, loss:0.00000, loss_test:0.07331, lr:2.00e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.851, tt:4660.115\n",
      "Ep:294, loss:0.00000, loss_test:0.07328, lr:1.98e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.850, tt:4675.806\n",
      "Ep:295, loss:0.00000, loss_test:0.07333, lr:1.96e-03, fs:0.83799 (r=0.758,p=0.938),  time:15.843, tt:4689.404\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.14188, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:17.860, tt:17.860\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.14152, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.247, tt:38.494\n",
      "Ep:2, loss:0.00004, loss_test:0.14096, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.919, tt:59.756\n",
      "Ep:3, loss:0.00004, loss_test:0.14019, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.017, tt:80.069\n",
      "Ep:4, loss:0.00004, loss_test:0.13918, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.052, tt:100.259\n",
      "Ep:5, loss:0.00004, loss_test:0.13791, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.311, tt:121.864\n",
      "Ep:6, loss:0.00004, loss_test:0.13632, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.541, tt:143.787\n",
      "Ep:7, loss:0.00004, loss_test:0.13435, lr:1.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:20.500, tt:164.001\n",
      "Ep:8, loss:0.00004, loss_test:0.13189, lr:1.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:20.598, tt:185.380\n",
      "Ep:9, loss:0.00004, loss_test:0.12873, lr:1.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:20.559, tt:205.587\n",
      "Ep:10, loss:0.00004, loss_test:0.12453, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:20.517, tt:225.686\n",
      "Ep:11, loss:0.00004, loss_test:0.11933, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:20.539, tt:246.474\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.11326, lr:1.00e-02, fs:0.68235 (r=0.879,p=0.558),  time:20.519, tt:266.748\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.10794, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:20.417, tt:285.842\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.10441, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:20.369, tt:305.531\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.10342, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:20.293, tt:324.693\n",
      "Ep:16, loss:0.00003, loss_test:0.10325, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:20.433, tt:347.356\n",
      "Ep:17, loss:0.00003, loss_test:0.10236, lr:1.00e-02, fs:0.71569 (r=0.737,p=0.695),  time:20.434, tt:367.811\n",
      "Ep:18, loss:0.00003, loss_test:0.10116, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:20.454, tt:388.629\n",
      "Ep:19, loss:0.00003, loss_test:0.10109, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:20.477, tt:409.533\n",
      "Ep:20, loss:0.00003, loss_test:0.10098, lr:1.00e-02, fs:0.72477 (r=0.798,p=0.664),  time:20.447, tt:429.380\n",
      "Ep:21, loss:0.00003, loss_test:0.09974, lr:1.00e-02, fs:0.72558 (r=0.788,p=0.672),  time:20.458, tt:450.067\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.09810, lr:1.00e-02, fs:0.74038 (r=0.778,p=0.706),  time:20.437, tt:470.047\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.09660, lr:1.00e-02, fs:0.74877 (r=0.768,p=0.731),  time:20.507, tt:492.166\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.09557, lr:1.00e-02, fs:0.75510 (r=0.747,p=0.763),  time:20.535, tt:513.375\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.09468, lr:1.00e-02, fs:0.76768 (r=0.768,p=0.768),  time:20.575, tt:534.955\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.09392, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:20.565, tt:555.243\n",
      "Ep:27, loss:0.00003, loss_test:0.09338, lr:1.00e-02, fs:0.76238 (r=0.778,p=0.748),  time:20.596, tt:576.695\n",
      "Ep:28, loss:0.00003, loss_test:0.09264, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:20.564, tt:596.351\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.09127, lr:1.00e-02, fs:0.77833 (r=0.798,p=0.760),  time:20.564, tt:616.907\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.08946, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:20.542, tt:636.815\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.08786, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:20.522, tt:656.706\n",
      "Ep:32, loss:0.00003, loss_test:0.08693, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.492, tt:676.243\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00002, loss_test:0.08614, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:20.516, tt:697.554\n",
      "Ep:34, loss:0.00002, loss_test:0.08544, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.545, tt:719.072\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.08490, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.581, tt:740.905\n",
      "Ep:36, loss:0.00002, loss_test:0.08429, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.582, tt:761.540\n",
      "Ep:37, loss:0.00002, loss_test:0.08353, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.591, tt:782.451\n",
      "Ep:38, loss:0.00002, loss_test:0.08282, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.635, tt:804.762\n",
      "Ep:39, loss:0.00002, loss_test:0.08202, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.645, tt:825.785\n",
      "Ep:40, loss:0.00002, loss_test:0.08116, lr:1.00e-02, fs:0.81000 (r=0.818,p=0.802),  time:20.692, tt:848.359\n",
      "Ep:41, loss:0.00002, loss_test:0.08030, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:20.682, tt:868.651\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00002, loss_test:0.07959, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:20.677, tt:889.101\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.07896, lr:1.00e-02, fs:0.82412 (r=0.828,p=0.820),  time:20.688, tt:910.273\n",
      "Ep:44, loss:0.00002, loss_test:0.07843, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:20.694, tt:931.220\n",
      "Ep:45, loss:0.00002, loss_test:0.07800, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.725, tt:953.336\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:46, loss:0.00002, loss_test:0.07750, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:20.731, tt:974.356\n",
      "Ep:47, loss:0.00002, loss_test:0.07696, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:20.756, tt:996.310\n",
      "Ep:48, loss:0.00002, loss_test:0.07652, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.762, tt:1017.334\n",
      "Ep:49, loss:0.00002, loss_test:0.07629, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:20.759, tt:1037.928\n",
      "Ep:50, loss:0.00002, loss_test:0.07621, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:20.773, tt:1059.411\n",
      "Ep:51, loss:0.00002, loss_test:0.07607, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:20.781, tt:1080.609\n",
      "Ep:52, loss:0.00002, loss_test:0.07564, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.792, tt:1101.980\n",
      "Ep:53, loss:0.00002, loss_test:0.07509, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:20.808, tt:1123.651\n",
      "Ep:54, loss:0.00002, loss_test:0.07465, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:20.814, tt:1144.744\n",
      "Ep:55, loss:0.00002, loss_test:0.07443, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:20.804, tt:1165.004\n",
      "Ep:56, loss:0.00002, loss_test:0.07417, lr:1.00e-02, fs:0.82474 (r=0.808,p=0.842),  time:20.815, tt:1186.471\n",
      "Ep:57, loss:0.00002, loss_test:0.07373, lr:9.90e-03, fs:0.82474 (r=0.808,p=0.842),  time:20.803, tt:1206.579\n",
      "Ep:58, loss:0.00002, loss_test:0.07301, lr:9.80e-03, fs:0.83673 (r=0.828,p=0.845),  time:20.818, tt:1228.250\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.07255, lr:9.80e-03, fs:0.84103 (r=0.828,p=0.854),  time:20.808, tt:1248.474\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.07222, lr:9.80e-03, fs:0.84103 (r=0.828,p=0.854),  time:20.792, tt:1268.328\n",
      "Ep:61, loss:0.00002, loss_test:0.07198, lr:9.80e-03, fs:0.84103 (r=0.828,p=0.854),  time:20.790, tt:1288.963\n",
      "Ep:62, loss:0.00002, loss_test:0.07167, lr:9.80e-03, fs:0.84103 (r=0.828,p=0.854),  time:20.785, tt:1309.475\n",
      "Ep:63, loss:0.00001, loss_test:0.07131, lr:9.80e-03, fs:0.83505 (r=0.818,p=0.853),  time:20.805, tt:1331.529\n",
      "Ep:64, loss:0.00001, loss_test:0.07105, lr:9.80e-03, fs:0.83333 (r=0.808,p=0.860),  time:20.804, tt:1352.276\n",
      "Ep:65, loss:0.00001, loss_test:0.07071, lr:9.80e-03, fs:0.83938 (r=0.818,p=0.862),  time:20.807, tt:1373.268\n",
      "Ep:66, loss:0.00001, loss_test:0.07035, lr:9.80e-03, fs:0.84536 (r=0.828,p=0.863),  time:20.819, tt:1394.848\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.07016, lr:9.80e-03, fs:0.83938 (r=0.818,p=0.862),  time:20.833, tt:1416.631\n",
      "Ep:68, loss:0.00001, loss_test:0.06996, lr:9.80e-03, fs:0.84375 (r=0.818,p=0.871),  time:20.847, tt:1438.410\n",
      "Ep:69, loss:0.00001, loss_test:0.06944, lr:9.80e-03, fs:0.84817 (r=0.818,p=0.880),  time:20.849, tt:1459.425\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.06887, lr:9.80e-03, fs:0.85417 (r=0.828,p=0.882),  time:20.852, tt:1480.465\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.06865, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.840, tt:1500.490\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.06873, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.850, tt:1522.034\n",
      "Ep:73, loss:0.00001, loss_test:0.06858, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.836, tt:1541.869\n",
      "Ep:74, loss:0.00001, loss_test:0.06818, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.823, tt:1561.728\n",
      "Ep:75, loss:0.00001, loss_test:0.06801, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.820, tt:1582.300\n",
      "Ep:76, loss:0.00001, loss_test:0.06789, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.818, tt:1603.006\n",
      "Ep:77, loss:0.00001, loss_test:0.06780, lr:9.80e-03, fs:0.85864 (r=0.828,p=0.891),  time:20.797, tt:1622.130\n",
      "Ep:78, loss:0.00001, loss_test:0.06770, lr:9.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:20.784, tt:1641.929\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.06777, lr:9.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:20.789, tt:1663.083\n",
      "Ep:80, loss:0.00001, loss_test:0.06769, lr:9.80e-03, fs:0.86458 (r=0.838,p=0.892),  time:20.793, tt:1684.263\n",
      "Ep:81, loss:0.00001, loss_test:0.06767, lr:9.80e-03, fs:0.87047 (r=0.848,p=0.894),  time:20.779, tt:1703.905\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.06781, lr:9.80e-03, fs:0.86911 (r=0.838,p=0.902),  time:20.776, tt:1724.416\n",
      "Ep:83, loss:0.00001, loss_test:0.06775, lr:9.80e-03, fs:0.87047 (r=0.848,p=0.894),  time:20.768, tt:1744.539\n",
      "Ep:84, loss:0.00001, loss_test:0.06759, lr:9.80e-03, fs:0.87629 (r=0.859,p=0.895),  time:20.765, tt:1765.030\n",
      "##########Best model found so far##########\n",
      "Ep:85, loss:0.00001, loss_test:0.06776, lr:9.80e-03, fs:0.88542 (r=0.859,p=0.914),  time:20.747, tt:1784.219\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00001, loss_test:0.06779, lr:9.80e-03, fs:0.88542 (r=0.859,p=0.914),  time:20.721, tt:1802.731\n",
      "Ep:87, loss:0.00001, loss_test:0.06744, lr:9.80e-03, fs:0.88542 (r=0.859,p=0.914),  time:20.712, tt:1822.693\n",
      "Ep:88, loss:0.00001, loss_test:0.06693, lr:9.80e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.693, tt:1841.700\n",
      "##########Best model found so far##########\n",
      "Ep:89, loss:0.00001, loss_test:0.06722, lr:9.80e-03, fs:0.89119 (r=0.869,p=0.915),  time:20.672, tt:1860.474\n",
      "Ep:90, loss:0.00001, loss_test:0.06685, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.661, tt:1880.154\n",
      "Ep:91, loss:0.00001, loss_test:0.06657, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.644, tt:1899.217\n",
      "Ep:92, loss:0.00001, loss_test:0.06748, lr:9.80e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.621, tt:1917.788\n",
      "Ep:93, loss:0.00001, loss_test:0.06699, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.600, tt:1936.370\n",
      "Ep:94, loss:0.00001, loss_test:0.06648, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.577, tt:1954.805\n",
      "Ep:95, loss:0.00001, loss_test:0.06695, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.555, tt:1973.321\n",
      "Ep:96, loss:0.00001, loss_test:0.06704, lr:9.80e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.533, tt:1991.695\n",
      "Ep:97, loss:0.00001, loss_test:0.06649, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.520, tt:2010.994\n",
      "Ep:98, loss:0.00001, loss_test:0.06634, lr:9.80e-03, fs:0.89231 (r=0.879,p=0.906),  time:20.504, tt:2029.863\n",
      "Ep:99, loss:0.00001, loss_test:0.06672, lr:9.80e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.497, tt:2049.678\n",
      "Ep:100, loss:0.00001, loss_test:0.06678, lr:9.70e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.483, tt:2068.821\n",
      "##########Best model found so far##########\n",
      "Ep:101, loss:0.00001, loss_test:0.06591, lr:9.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.480, tt:2088.913\n",
      "Ep:102, loss:0.00001, loss_test:0.06593, lr:9.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.469, tt:2108.356\n",
      "Ep:103, loss:0.00001, loss_test:0.06638, lr:9.70e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.470, tt:2128.867\n",
      "Ep:104, loss:0.00001, loss_test:0.06573, lr:9.70e-03, fs:0.89691 (r=0.879,p=0.916),  time:20.465, tt:2148.830\n",
      "Ep:105, loss:0.00001, loss_test:0.06548, lr:9.70e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.463, tt:2169.028\n",
      "Ep:106, loss:0.00001, loss_test:0.06563, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.484, tt:2191.820\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.06510, lr:9.70e-03, fs:0.90155 (r=0.879,p=0.926),  time:20.472, tt:2210.964\n",
      "Ep:108, loss:0.00001, loss_test:0.06524, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.466, tt:2230.815\n",
      "Ep:109, loss:0.00001, loss_test:0.06520, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.456, tt:2250.208\n",
      "Ep:110, loss:0.00001, loss_test:0.06476, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.448, tt:2269.728\n",
      "Ep:111, loss:0.00001, loss_test:0.06511, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.443, tt:2289.566\n",
      "Ep:112, loss:0.00001, loss_test:0.06485, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.447, tt:2310.474\n",
      "Ep:113, loss:0.00001, loss_test:0.06437, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.451, tt:2331.397\n",
      "Ep:114, loss:0.00001, loss_test:0.06464, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.454, tt:2352.235\n",
      "Ep:115, loss:0.00001, loss_test:0.06451, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.444, tt:2371.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:116, loss:0.00001, loss_test:0.06405, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.437, tt:2391.081\n",
      "Ep:117, loss:0.00001, loss_test:0.06447, lr:9.70e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.442, tt:2412.183\n",
      "Ep:118, loss:0.00001, loss_test:0.06397, lr:9.61e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.436, tt:2431.922\n",
      "Ep:119, loss:0.00001, loss_test:0.06397, lr:9.51e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.431, tt:2451.757\n",
      "Ep:120, loss:0.00001, loss_test:0.06389, lr:9.41e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.420, tt:2470.824\n",
      "Ep:121, loss:0.00001, loss_test:0.06351, lr:9.32e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.412, tt:2490.267\n",
      "Ep:122, loss:0.00001, loss_test:0.06347, lr:9.23e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.419, tt:2511.551\n",
      "Ep:123, loss:0.00000, loss_test:0.06351, lr:9.14e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.408, tt:2530.578\n",
      "Ep:124, loss:0.00000, loss_test:0.06378, lr:9.04e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.407, tt:2550.914\n",
      "Ep:125, loss:0.00000, loss_test:0.06269, lr:8.95e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.413, tt:2572.065\n",
      "Ep:126, loss:0.00000, loss_test:0.06327, lr:8.86e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.414, tt:2592.521\n",
      "Ep:127, loss:0.00000, loss_test:0.06433, lr:8.78e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.404, tt:2611.692\n",
      "Ep:128, loss:0.00000, loss_test:0.06284, lr:8.69e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.399, tt:2631.506\n",
      "Ep:129, loss:0.00000, loss_test:0.06177, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.393, tt:2651.105\n",
      "##########Best model found so far##########\n",
      "Ep:130, loss:0.00000, loss_test:0.06392, lr:8.60e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.382, tt:2670.101\n",
      "Ep:131, loss:0.00000, loss_test:0.06348, lr:8.60e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.383, tt:2690.540\n",
      "Ep:132, loss:0.00000, loss_test:0.06170, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.387, tt:2711.523\n",
      "Ep:133, loss:0.00000, loss_test:0.06295, lr:8.60e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.382, tt:2731.146\n",
      "Ep:134, loss:0.00000, loss_test:0.06350, lr:8.60e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.379, tt:2751.169\n",
      "Ep:135, loss:0.00000, loss_test:0.06233, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.376, tt:2771.160\n",
      "Ep:136, loss:0.00000, loss_test:0.06246, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.376, tt:2791.483\n",
      "Ep:137, loss:0.00000, loss_test:0.06254, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.372, tt:2811.322\n",
      "Ep:138, loss:0.00000, loss_test:0.06256, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.378, tt:2832.565\n",
      "Ep:139, loss:0.00000, loss_test:0.06306, lr:8.60e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.382, tt:2853.415\n",
      "Ep:140, loss:0.00000, loss_test:0.06220, lr:8.60e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.387, tt:2874.629\n",
      "Ep:141, loss:0.00000, loss_test:0.06169, lr:8.51e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.390, tt:2895.425\n",
      "Ep:142, loss:0.00000, loss_test:0.06347, lr:8.43e-03, fs:0.90526 (r=0.869,p=0.945),  time:20.387, tt:2915.368\n",
      "Ep:143, loss:0.00000, loss_test:0.06286, lr:8.35e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.392, tt:2936.375\n",
      "Ep:144, loss:0.00000, loss_test:0.06108, lr:8.26e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.387, tt:2956.187\n",
      "Ep:145, loss:0.00000, loss_test:0.06231, lr:8.18e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.394, tt:2977.546\n",
      "Ep:146, loss:0.00000, loss_test:0.06300, lr:8.10e-03, fs:0.91099 (r=0.879,p=0.946),  time:20.388, tt:2997.093\n",
      "Ep:147, loss:0.00000, loss_test:0.06210, lr:8.02e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.392, tt:3017.956\n",
      "Ep:148, loss:0.00000, loss_test:0.06122, lr:7.94e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.393, tt:3038.523\n",
      "Ep:149, loss:0.00000, loss_test:0.06313, lr:7.86e-03, fs:0.89947 (r=0.859,p=0.944),  time:20.389, tt:3058.363\n",
      "Ep:150, loss:0.00000, loss_test:0.06346, lr:7.78e-03, fs:0.88770 (r=0.838,p=0.943),  time:20.397, tt:3079.906\n",
      "Ep:151, loss:0.00000, loss_test:0.06206, lr:7.70e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.401, tt:3100.994\n",
      "Ep:152, loss:0.00000, loss_test:0.06144, lr:7.62e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.393, tt:3120.179\n",
      "Ep:153, loss:0.00000, loss_test:0.06282, lr:7.55e-03, fs:0.89947 (r=0.859,p=0.944),  time:20.393, tt:3140.498\n",
      "Ep:154, loss:0.00000, loss_test:0.06317, lr:7.47e-03, fs:0.89362 (r=0.848,p=0.944),  time:20.390, tt:3160.518\n",
      "Ep:155, loss:0.00000, loss_test:0.06223, lr:7.40e-03, fs:0.90625 (r=0.879,p=0.935),  time:20.389, tt:3180.665\n",
      "Ep:156, loss:0.00000, loss_test:0.06163, lr:7.32e-03, fs:0.91192 (r=0.889,p=0.936),  time:20.393, tt:3201.692\n",
      "Ep:157, loss:0.00000, loss_test:0.06233, lr:7.25e-03, fs:0.90526 (r=0.869,p=0.945),  time:20.392, tt:3221.879\n",
      "Ep:158, loss:0.00000, loss_test:0.06301, lr:7.18e-03, fs:0.89947 (r=0.859,p=0.944),  time:20.395, tt:3242.780\n",
      "Ep:159, loss:0.00000, loss_test:0.06275, lr:7.11e-03, fs:0.90052 (r=0.869,p=0.935),  time:20.390, tt:3262.451\n",
      "Ep:160, loss:0.00000, loss_test:0.06215, lr:7.03e-03, fs:0.90526 (r=0.869,p=0.945),  time:20.395, tt:3283.631\n",
      "Ep:161, loss:0.00000, loss_test:0.06196, lr:6.96e-03, fs:0.90526 (r=0.869,p=0.945),  time:20.394, tt:3303.838\n",
      "Ep:162, loss:0.00000, loss_test:0.06267, lr:6.89e-03, fs:0.89474 (r=0.859,p=0.934),  time:20.396, tt:3324.505\n",
      "Ep:163, loss:0.00000, loss_test:0.06338, lr:6.83e-03, fs:0.86339 (r=0.798,p=0.940),  time:20.395, tt:3344.717\n",
      "Ep:164, loss:0.00000, loss_test:0.06317, lr:6.76e-03, fs:0.86339 (r=0.798,p=0.940),  time:20.393, tt:3364.824\n",
      "Ep:165, loss:0.00000, loss_test:0.06254, lr:6.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:20.388, tt:3384.414\n",
      "Ep:166, loss:0.00000, loss_test:0.06243, lr:6.62e-03, fs:0.89947 (r=0.859,p=0.944),  time:20.394, tt:3405.770\n",
      "Ep:167, loss:0.00000, loss_test:0.06300, lr:6.56e-03, fs:0.85714 (r=0.788,p=0.940),  time:20.390, tt:3425.501\n",
      "Ep:168, loss:0.00000, loss_test:0.06341, lr:6.49e-03, fs:0.85714 (r=0.788,p=0.940),  time:20.394, tt:3446.514\n",
      "Ep:169, loss:0.00000, loss_test:0.06332, lr:6.43e-03, fs:0.85714 (r=0.788,p=0.940),  time:20.384, tt:3465.358\n",
      "Ep:170, loss:0.00000, loss_test:0.06297, lr:6.36e-03, fs:0.85714 (r=0.788,p=0.940),  time:20.383, tt:3485.436\n",
      "Ep:171, loss:0.00000, loss_test:0.06306, lr:6.30e-03, fs:0.86188 (r=0.788,p=0.951),  time:20.387, tt:3506.581\n",
      "Ep:172, loss:0.00000, loss_test:0.06345, lr:6.24e-03, fs:0.85556 (r=0.778,p=0.951),  time:20.390, tt:3527.449\n",
      "Ep:173, loss:0.00000, loss_test:0.06367, lr:6.17e-03, fs:0.85556 (r=0.778,p=0.951),  time:20.393, tt:3548.333\n",
      "Ep:174, loss:0.00000, loss_test:0.06358, lr:6.11e-03, fs:0.85556 (r=0.778,p=0.951),  time:20.396, tt:3569.358\n",
      "Ep:175, loss:0.00000, loss_test:0.06350, lr:6.05e-03, fs:0.85556 (r=0.778,p=0.951),  time:20.396, tt:3589.757\n",
      "Ep:176, loss:0.00000, loss_test:0.06335, lr:5.99e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.394, tt:3609.777\n",
      "Ep:177, loss:0.00000, loss_test:0.06337, lr:5.93e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.397, tt:3630.668\n",
      "Ep:178, loss:0.00000, loss_test:0.06353, lr:5.87e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.402, tt:3651.972\n",
      "Ep:179, loss:0.00000, loss_test:0.06365, lr:5.81e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.400, tt:3671.952\n",
      "Ep:180, loss:0.00000, loss_test:0.06347, lr:5.75e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.398, tt:3692.070\n",
      "Ep:181, loss:0.00000, loss_test:0.06338, lr:5.70e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.391, tt:3711.100\n",
      "Ep:182, loss:0.00000, loss_test:0.06369, lr:5.64e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.389, tt:3731.275\n",
      "Ep:183, loss:0.00000, loss_test:0.06390, lr:5.58e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.396, tt:3752.874\n",
      "Ep:184, loss:0.00000, loss_test:0.06373, lr:5.53e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.397, tt:3773.472\n",
      "Ep:185, loss:0.00000, loss_test:0.06356, lr:5.47e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.397, tt:3793.775\n",
      "Ep:186, loss:0.00000, loss_test:0.06384, lr:5.42e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.395, tt:3813.831\n",
      "Ep:187, loss:0.00000, loss_test:0.06416, lr:5.36e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.391, tt:3833.597\n",
      "Ep:188, loss:0.00000, loss_test:0.06412, lr:5.31e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.379, tt:3851.668\n",
      "Ep:189, loss:0.00000, loss_test:0.06397, lr:5.26e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.376, tt:3871.439\n",
      "Ep:190, loss:0.00000, loss_test:0.06415, lr:5.20e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.376, tt:3891.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:191, loss:0.00000, loss_test:0.06427, lr:5.15e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.372, tt:3911.462\n",
      "Ep:192, loss:0.00000, loss_test:0.06420, lr:5.10e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.375, tt:3932.433\n",
      "Ep:193, loss:0.00000, loss_test:0.06417, lr:5.05e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.367, tt:3951.169\n",
      "Ep:194, loss:0.00000, loss_test:0.06432, lr:5.00e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.365, tt:3971.231\n",
      "Ep:195, loss:0.00000, loss_test:0.06441, lr:4.95e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.361, tt:3990.667\n",
      "Ep:196, loss:0.00000, loss_test:0.06427, lr:4.90e-03, fs:0.84916 (r=0.768,p=0.950),  time:20.360, tt:4010.853\n",
      "Ep:197, loss:0.00000, loss_test:0.06438, lr:4.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.357, tt:4030.590\n",
      "Ep:198, loss:0.00000, loss_test:0.06453, lr:4.80e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.352, tt:4049.954\n",
      "Ep:199, loss:0.00000, loss_test:0.06454, lr:4.75e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.343, tt:4068.553\n",
      "Ep:200, loss:0.00000, loss_test:0.06464, lr:4.71e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.332, tt:4086.718\n",
      "Ep:201, loss:0.00000, loss_test:0.06453, lr:4.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.327, tt:4105.994\n",
      "Ep:202, loss:0.00000, loss_test:0.06474, lr:4.61e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.323, tt:4125.505\n",
      "Ep:203, loss:0.00000, loss_test:0.06465, lr:4.57e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.318, tt:4144.916\n",
      "Ep:204, loss:0.00000, loss_test:0.06455, lr:4.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.314, tt:4164.372\n",
      "Ep:205, loss:0.00000, loss_test:0.06483, lr:4.48e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.307, tt:4183.274\n",
      "Ep:206, loss:0.00000, loss_test:0.06488, lr:4.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.305, tt:4203.077\n",
      "Ep:207, loss:0.00000, loss_test:0.06461, lr:4.39e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.300, tt:4222.424\n",
      "Ep:208, loss:0.00000, loss_test:0.06460, lr:4.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.297, tt:4242.086\n",
      "Ep:209, loss:0.00000, loss_test:0.06481, lr:4.30e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.298, tt:4262.625\n",
      "Ep:210, loss:0.00000, loss_test:0.06481, lr:4.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.292, tt:4281.645\n",
      "Ep:211, loss:0.00000, loss_test:0.06478, lr:4.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.292, tt:4301.888\n",
      "Ep:212, loss:0.00000, loss_test:0.06477, lr:4.17e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.282, tt:4320.108\n",
      "Ep:213, loss:0.00000, loss_test:0.06481, lr:4.13e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.283, tt:4340.522\n",
      "Ep:214, loss:0.00000, loss_test:0.06486, lr:4.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.280, tt:4360.130\n",
      "Ep:215, loss:0.00000, loss_test:0.06486, lr:4.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.280, tt:4380.546\n",
      "Ep:216, loss:0.00000, loss_test:0.06479, lr:4.01e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.276, tt:4399.954\n",
      "Ep:217, loss:0.00000, loss_test:0.06497, lr:3.97e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.274, tt:4419.665\n",
      "Ep:218, loss:0.00000, loss_test:0.06490, lr:3.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.273, tt:4439.745\n",
      "Ep:219, loss:0.00000, loss_test:0.06493, lr:3.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.274, tt:4460.325\n",
      "Ep:220, loss:0.00000, loss_test:0.06492, lr:3.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.264, tt:4478.313\n",
      "Ep:221, loss:0.00000, loss_test:0.06492, lr:3.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.259, tt:4497.456\n",
      "Ep:222, loss:0.00000, loss_test:0.06490, lr:3.77e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.255, tt:4516.779\n",
      "Ep:223, loss:0.00000, loss_test:0.06488, lr:3.73e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.253, tt:4536.630\n",
      "Ep:224, loss:0.00000, loss_test:0.06483, lr:3.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.242, tt:4554.388\n",
      "Ep:225, loss:0.00000, loss_test:0.06498, lr:3.66e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.241, tt:4574.486\n",
      "Ep:226, loss:0.00000, loss_test:0.06498, lr:3.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.240, tt:4594.418\n",
      "Ep:227, loss:0.00000, loss_test:0.06489, lr:3.59e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.234, tt:4613.353\n",
      "Ep:228, loss:0.00000, loss_test:0.06495, lr:3.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.231, tt:4632.934\n",
      "Ep:229, loss:0.00000, loss_test:0.06498, lr:3.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.226, tt:4651.890\n",
      "Ep:230, loss:0.00000, loss_test:0.06490, lr:3.48e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.220, tt:4670.899\n",
      "Ep:231, loss:0.00000, loss_test:0.06498, lr:3.45e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.217, tt:4690.454\n",
      "Ep:232, loss:0.00000, loss_test:0.06493, lr:3.41e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.214, tt:4709.909\n",
      "Ep:233, loss:0.00000, loss_test:0.06489, lr:3.38e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.216, tt:4730.467\n",
      "Ep:234, loss:0.00000, loss_test:0.06493, lr:3.34e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.215, tt:4750.616\n",
      "Ep:235, loss:0.00000, loss_test:0.06495, lr:3.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.215, tt:4770.724\n",
      "Ep:236, loss:0.00000, loss_test:0.06488, lr:3.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.210, tt:4789.693\n",
      "Ep:237, loss:0.00000, loss_test:0.06494, lr:3.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.209, tt:4809.744\n",
      "Ep:238, loss:0.00000, loss_test:0.06492, lr:3.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.207, tt:4829.402\n",
      "Ep:239, loss:0.00000, loss_test:0.06489, lr:3.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.205, tt:4849.165\n",
      "Ep:240, loss:0.00000, loss_test:0.06490, lr:3.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.203, tt:4868.863\n",
      "Ep:241, loss:0.00000, loss_test:0.06487, lr:3.12e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.206, tt:4889.962\n",
      "Ep:242, loss:0.00000, loss_test:0.06483, lr:3.09e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.202, tt:4909.201\n",
      "Ep:243, loss:0.00000, loss_test:0.06482, lr:3.05e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.197, tt:4928.156\n",
      "Ep:244, loss:0.00000, loss_test:0.06477, lr:3.02e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.196, tt:4948.008\n",
      "Ep:245, loss:0.00000, loss_test:0.06487, lr:2.99e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.194, tt:4967.804\n",
      "Ep:246, loss:0.00000, loss_test:0.06481, lr:2.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.190, tt:4986.907\n",
      "Ep:247, loss:0.00000, loss_test:0.06483, lr:2.93e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.190, tt:5007.070\n",
      "Ep:248, loss:0.00000, loss_test:0.06484, lr:2.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.206, tt:5031.190\n",
      "Ep:249, loss:0.00000, loss_test:0.06473, lr:2.88e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.212, tt:5052.896\n",
      "Ep:250, loss:0.00000, loss_test:0.06478, lr:2.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.209, tt:5072.552\n",
      "Ep:251, loss:0.00000, loss_test:0.06485, lr:2.82e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.217, tt:5094.642\n",
      "Ep:252, loss:0.00000, loss_test:0.06477, lr:2.79e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.213, tt:5113.848\n",
      "Ep:253, loss:0.00000, loss_test:0.06469, lr:2.76e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.214, tt:5134.411\n",
      "Ep:254, loss:0.00000, loss_test:0.06486, lr:2.73e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.210, tt:5153.642\n",
      "Ep:255, loss:0.00000, loss_test:0.06477, lr:2.71e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.207, tt:5173.105\n",
      "Ep:256, loss:0.00000, loss_test:0.06478, lr:2.68e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.208, tt:5193.543\n",
      "Ep:257, loss:0.00000, loss_test:0.06481, lr:2.65e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.212, tt:5214.631\n",
      "Ep:258, loss:0.00000, loss_test:0.06481, lr:2.63e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.214, tt:5235.438\n",
      "Ep:259, loss:0.00000, loss_test:0.06500, lr:2.60e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.217, tt:5256.461\n",
      "Ep:260, loss:0.00000, loss_test:0.06487, lr:2.57e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.218, tt:5277.024\n",
      "Ep:261, loss:0.00000, loss_test:0.06472, lr:2.55e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.214, tt:5295.948\n",
      "Ep:262, loss:0.00000, loss_test:0.06490, lr:2.52e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.215, tt:5316.667\n",
      "Ep:263, loss:0.00000, loss_test:0.06489, lr:2.50e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.217, tt:5337.194\n",
      "Ep:264, loss:0.00000, loss_test:0.06471, lr:2.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.223, tt:5358.989\n",
      "Ep:265, loss:0.00000, loss_test:0.06490, lr:2.45e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.223, tt:5379.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:266, loss:0.00000, loss_test:0.06491, lr:2.42e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.222, tt:5399.353\n",
      "Ep:267, loss:0.00000, loss_test:0.06468, lr:2.40e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.227, tt:5420.772\n",
      "Ep:268, loss:0.00000, loss_test:0.06485, lr:2.38e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.230, tt:5441.814\n",
      "Ep:269, loss:0.00000, loss_test:0.06488, lr:2.35e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.235, tt:5463.408\n",
      "Ep:270, loss:0.00000, loss_test:0.06471, lr:2.33e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.239, tt:5484.882\n",
      "Ep:271, loss:0.00000, loss_test:0.06477, lr:2.31e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.239, tt:5505.069\n",
      "Ep:272, loss:0.00000, loss_test:0.06486, lr:2.28e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.245, tt:5526.776\n",
      "Ep:273, loss:0.00000, loss_test:0.06467, lr:2.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.247, tt:5547.596\n",
      "Ep:274, loss:0.00000, loss_test:0.06474, lr:2.24e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.255, tt:5570.019\n",
      "Ep:275, loss:0.00000, loss_test:0.06481, lr:2.21e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.261, tt:5591.971\n",
      "Ep:276, loss:0.00000, loss_test:0.06468, lr:2.19e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.264, tt:5613.091\n",
      "Ep:277, loss:0.00000, loss_test:0.06467, lr:2.17e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.262, tt:5632.835\n",
      "Ep:278, loss:0.00000, loss_test:0.06472, lr:2.15e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.266, tt:5654.158\n",
      "Ep:279, loss:0.00000, loss_test:0.06469, lr:2.13e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.267, tt:5674.832\n",
      "Ep:280, loss:0.00000, loss_test:0.06472, lr:2.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.287, tt:5700.527\n",
      "Ep:281, loss:0.00000, loss_test:0.06465, lr:2.08e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.285, tt:5720.429\n",
      "Ep:282, loss:0.00000, loss_test:0.06473, lr:2.06e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.281, tt:5739.609\n",
      "Ep:283, loss:0.00000, loss_test:0.06466, lr:2.04e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.284, tt:5760.551\n",
      "Ep:284, loss:0.00000, loss_test:0.06458, lr:2.02e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.290, tt:5782.544\n",
      "Ep:285, loss:0.00000, loss_test:0.06464, lr:2.00e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.290, tt:5802.946\n",
      "Ep:286, loss:0.00000, loss_test:0.06457, lr:1.98e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.285, tt:5821.788\n",
      "Ep:287, loss:0.00000, loss_test:0.06457, lr:1.96e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.288, tt:5842.835\n",
      "Ep:288, loss:0.00000, loss_test:0.06460, lr:1.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.290, tt:5863.765\n",
      "Ep:289, loss:0.00000, loss_test:0.06455, lr:1.92e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.286, tt:5882.956\n",
      "Ep:290, loss:0.00000, loss_test:0.06449, lr:1.90e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.284, tt:5902.600\n",
      "Ep:291, loss:0.00000, loss_test:0.06465, lr:1.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.285, tt:5923.127\n",
      "Ep:292, loss:0.00000, loss_test:0.06457, lr:1.87e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.286, tt:5943.802\n",
      "Ep:293, loss:0.00000, loss_test:0.06446, lr:1.85e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.285, tt:5963.881\n",
      "Ep:294, loss:0.00000, loss_test:0.06467, lr:1.83e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.276, tt:5981.408\n",
      "Ep:295, loss:0.00000, loss_test:0.06458, lr:1.81e-03, fs:0.85393 (r=0.768,p=0.962),  time:20.255, tt:5995.415\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 3600: \n",
      "Ep:0, loss:0.00004, loss_test:0.13857, lr:1.00e-02, fs:0.65306 (r=0.970,p=0.492),  time:18.825, tt:18.825\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.13789, lr:1.00e-02, fs:0.65306 (r=0.970,p=0.492),  time:18.675, tt:37.351\n",
      "Ep:2, loss:0.00004, loss_test:0.13683, lr:1.00e-02, fs:0.65529 (r=0.970,p=0.495),  time:18.762, tt:56.285\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00004, loss_test:0.13530, lr:1.00e-02, fs:0.65979 (r=0.970,p=0.500),  time:18.628, tt:74.510\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00004, loss_test:0.13321, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:18.500, tt:92.499\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00004, loss_test:0.13053, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:18.415, tt:110.491\n",
      "Ep:6, loss:0.00004, loss_test:0.12728, lr:1.00e-02, fs:0.67626 (r=0.949,p=0.525),  time:18.339, tt:128.370\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.12401, lr:1.00e-02, fs:0.68132 (r=0.939,p=0.534),  time:18.368, tt:146.943\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.12097, lr:1.00e-02, fs:0.67669 (r=0.909,p=0.539),  time:18.345, tt:165.104\n",
      "Ep:9, loss:0.00004, loss_test:0.11832, lr:1.00e-02, fs:0.68504 (r=0.879,p=0.561),  time:18.353, tt:183.531\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.11607, lr:1.00e-02, fs:0.69106 (r=0.859,p=0.578),  time:18.319, tt:201.508\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00003, loss_test:0.11414, lr:1.00e-02, fs:0.69167 (r=0.838,p=0.589),  time:18.329, tt:219.952\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.11257, lr:1.00e-02, fs:0.67797 (r=0.808,p=0.584),  time:18.322, tt:238.182\n",
      "Ep:13, loss:0.00003, loss_test:0.11151, lr:1.00e-02, fs:0.68722 (r=0.788,p=0.609),  time:18.408, tt:257.717\n",
      "Ep:14, loss:0.00003, loss_test:0.11083, lr:1.00e-02, fs:0.68750 (r=0.778,p=0.616),  time:18.555, tt:278.320\n",
      "Ep:15, loss:0.00003, loss_test:0.11042, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:18.588, tt:297.400\n",
      "Ep:16, loss:0.00003, loss_test:0.10994, lr:1.00e-02, fs:0.68468 (r=0.768,p=0.618),  time:18.564, tt:315.592\n",
      "Ep:17, loss:0.00003, loss_test:0.10953, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:18.602, tt:334.828\n",
      "Ep:18, loss:0.00003, loss_test:0.10902, lr:1.00e-02, fs:0.67873 (r=0.758,p=0.615),  time:18.723, tt:355.731\n",
      "Ep:19, loss:0.00003, loss_test:0.10830, lr:1.00e-02, fs:0.68493 (r=0.758,p=0.625),  time:18.765, tt:375.302\n",
      "Ep:20, loss:0.00003, loss_test:0.10756, lr:1.00e-02, fs:0.70046 (r=0.768,p=0.644),  time:18.842, tt:395.677\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.10675, lr:1.00e-02, fs:0.70642 (r=0.778,p=0.647),  time:18.833, tt:414.321\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.10581, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:18.868, tt:433.954\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.10497, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:18.934, tt:454.419\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.10424, lr:1.00e-02, fs:0.72300 (r=0.778,p=0.675),  time:18.949, tt:473.737\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.10363, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:18.931, tt:492.216\n",
      "Ep:26, loss:0.00003, loss_test:0.10289, lr:1.00e-02, fs:0.71296 (r=0.778,p=0.658),  time:18.928, tt:511.066\n",
      "Ep:27, loss:0.00003, loss_test:0.10190, lr:1.00e-02, fs:0.71628 (r=0.778,p=0.664),  time:18.947, tt:530.516\n",
      "Ep:28, loss:0.00003, loss_test:0.10059, lr:1.00e-02, fs:0.72642 (r=0.778,p=0.681),  time:18.968, tt:550.063\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00003, loss_test:0.09939, lr:1.00e-02, fs:0.73934 (r=0.788,p=0.696),  time:18.949, tt:568.477\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00003, loss_test:0.09830, lr:1.00e-02, fs:0.74286 (r=0.788,p=0.703),  time:18.932, tt:586.893\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00003, loss_test:0.09726, lr:1.00e-02, fs:0.74641 (r=0.788,p=0.709),  time:18.951, tt:606.429\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00003, loss_test:0.09626, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:18.966, tt:625.874\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.09519, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:18.965, tt:644.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:34, loss:0.00003, loss_test:0.09404, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:18.986, tt:664.506\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00003, loss_test:0.09295, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:19.019, tt:684.697\n",
      "Ep:36, loss:0.00003, loss_test:0.09192, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:19.022, tt:703.808\n",
      "Ep:37, loss:0.00002, loss_test:0.09110, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:18.993, tt:721.748\n",
      "Ep:38, loss:0.00002, loss_test:0.09054, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:18.991, tt:740.668\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.09013, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:19.013, tt:760.523\n",
      "Ep:40, loss:0.00002, loss_test:0.08979, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:19.003, tt:779.118\n",
      "Ep:41, loss:0.00002, loss_test:0.08941, lr:1.00e-02, fs:0.77612 (r=0.788,p=0.765),  time:19.023, tt:798.964\n",
      "Ep:42, loss:0.00002, loss_test:0.08902, lr:1.00e-02, fs:0.78607 (r=0.798,p=0.775),  time:19.027, tt:818.148\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.08867, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:19.022, tt:836.952\n",
      "Ep:44, loss:0.00002, loss_test:0.08843, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:19.026, tt:856.183\n",
      "Ep:45, loss:0.00002, loss_test:0.08813, lr:1.00e-02, fs:0.78000 (r=0.788,p=0.772),  time:19.047, tt:876.158\n",
      "Ep:46, loss:0.00002, loss_test:0.08779, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:19.045, tt:895.093\n",
      "Ep:47, loss:0.00002, loss_test:0.08754, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:19.048, tt:914.294\n",
      "Ep:48, loss:0.00002, loss_test:0.08725, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:19.049, tt:933.406\n",
      "Ep:49, loss:0.00002, loss_test:0.08702, lr:1.00e-02, fs:0.78392 (r=0.788,p=0.780),  time:19.061, tt:953.066\n",
      "Ep:50, loss:0.00002, loss_test:0.08684, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:19.062, tt:972.185\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.08676, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:19.064, tt:991.321\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.08664, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:19.077, tt:1011.088\n",
      "Ep:53, loss:0.00002, loss_test:0.08652, lr:1.00e-02, fs:0.79397 (r=0.798,p=0.790),  time:19.097, tt:1031.215\n",
      "Ep:54, loss:0.00002, loss_test:0.08650, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:19.095, tt:1050.226\n",
      "Ep:55, loss:0.00002, loss_test:0.08652, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:19.100, tt:1069.618\n",
      "Ep:56, loss:0.00002, loss_test:0.08624, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:19.108, tt:1089.171\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00002, loss_test:0.08570, lr:1.00e-02, fs:0.80402 (r=0.808,p=0.800),  time:19.132, tt:1109.650\n",
      "Ep:58, loss:0.00002, loss_test:0.08519, lr:1.00e-02, fs:0.81407 (r=0.818,p=0.810),  time:19.113, tt:1127.638\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00002, loss_test:0.08486, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:19.128, tt:1147.694\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00002, loss_test:0.08469, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:19.135, tt:1167.210\n",
      "Ep:61, loss:0.00002, loss_test:0.08441, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:19.121, tt:1185.477\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00002, loss_test:0.08409, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:19.132, tt:1205.337\n",
      "Ep:63, loss:0.00002, loss_test:0.08383, lr:1.00e-02, fs:0.82653 (r=0.818,p=0.835),  time:19.128, tt:1224.208\n",
      "##########Best model found so far##########\n",
      "Ep:64, loss:0.00002, loss_test:0.08355, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:19.124, tt:1243.087\n",
      "##########Best model found so far##########\n",
      "Ep:65, loss:0.00002, loss_test:0.08317, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:19.144, tt:1263.495\n",
      "Ep:66, loss:0.00002, loss_test:0.08292, lr:1.00e-02, fs:0.83077 (r=0.818,p=0.844),  time:19.162, tt:1283.823\n",
      "Ep:67, loss:0.00002, loss_test:0.08271, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:19.150, tt:1302.207\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00002, loss_test:0.08255, lr:1.00e-02, fs:0.84103 (r=0.828,p=0.854),  time:19.141, tt:1320.711\n",
      "Ep:69, loss:0.00001, loss_test:0.08244, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:19.135, tt:1339.444\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.08230, lr:1.00e-02, fs:0.84694 (r=0.838,p=0.856),  time:19.136, tt:1358.627\n",
      "Ep:71, loss:0.00001, loss_test:0.08222, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:19.141, tt:1378.179\n",
      "Ep:72, loss:0.00001, loss_test:0.08197, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:19.125, tt:1396.162\n",
      "Ep:73, loss:0.00001, loss_test:0.08177, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:19.128, tt:1415.507\n",
      "Ep:74, loss:0.00001, loss_test:0.08150, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:19.122, tt:1434.151\n",
      "Ep:75, loss:0.00001, loss_test:0.08146, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:19.131, tt:1453.962\n",
      "Ep:76, loss:0.00001, loss_test:0.08148, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:19.135, tt:1473.426\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.08142, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:19.139, tt:1492.817\n",
      "Ep:78, loss:0.00001, loss_test:0.08120, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:19.132, tt:1511.421\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00001, loss_test:0.08104, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:19.133, tt:1530.676\n",
      "Ep:80, loss:0.00001, loss_test:0.08099, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:19.139, tt:1550.231\n",
      "Ep:81, loss:0.00001, loss_test:0.08097, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:19.139, tt:1569.436\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.08091, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.140, tt:1588.581\n",
      "##########Best model found so far##########\n",
      "Ep:83, loss:0.00001, loss_test:0.08070, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.136, tt:1607.398\n",
      "Ep:84, loss:0.00001, loss_test:0.08066, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.139, tt:1626.773\n",
      "Ep:85, loss:0.00001, loss_test:0.08062, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.128, tt:1645.045\n",
      "Ep:86, loss:0.00001, loss_test:0.08061, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.142, tt:1665.372\n",
      "Ep:87, loss:0.00001, loss_test:0.08054, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.128, tt:1683.272\n",
      "Ep:88, loss:0.00001, loss_test:0.08037, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.129, tt:1702.495\n",
      "Ep:89, loss:0.00001, loss_test:0.08047, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:19.136, tt:1722.246\n",
      "Ep:90, loss:0.00001, loss_test:0.08067, lr:1.00e-02, fs:0.86911 (r=0.838,p=0.902),  time:19.136, tt:1741.330\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00001, loss_test:0.08072, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:19.139, tt:1760.797\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.08072, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:19.137, tt:1779.760\n",
      "Ep:93, loss:0.00001, loss_test:0.08074, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:19.120, tt:1797.317\n",
      "Ep:94, loss:0.00001, loss_test:0.08076, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:19.126, tt:1816.961\n",
      "Ep:95, loss:0.00001, loss_test:0.08084, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:19.113, tt:1834.837\n",
      "Ep:96, loss:0.00001, loss_test:0.08107, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:19.119, tt:1854.592\n",
      "Ep:97, loss:0.00001, loss_test:0.08118, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:19.116, tt:1873.385\n",
      "Ep:98, loss:0.00001, loss_test:0.08178, lr:1.00e-02, fs:0.87234 (r=0.828,p=0.921),  time:19.116, tt:1892.448\n",
      "Ep:99, loss:0.00001, loss_test:0.08123, lr:1.00e-02, fs:0.87368 (r=0.838,p=0.912),  time:19.100, tt:1909.978\n",
      "Ep:100, loss:0.00001, loss_test:0.08206, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:19.078, tt:1926.869\n",
      "Ep:101, loss:0.00001, loss_test:0.08169, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:19.060, tt:1944.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:102, loss:0.00001, loss_test:0.08205, lr:1.00e-02, fs:0.86170 (r=0.818,p=0.910),  time:19.060, tt:1963.202\n",
      "Ep:103, loss:0.00001, loss_test:0.08200, lr:9.90e-03, fs:0.85405 (r=0.798,p=0.919),  time:19.048, tt:1980.953\n",
      "Ep:104, loss:0.00001, loss_test:0.08266, lr:9.80e-03, fs:0.84946 (r=0.798,p=0.908),  time:19.026, tt:1997.720\n",
      "Ep:105, loss:0.00001, loss_test:0.08254, lr:9.70e-03, fs:0.84946 (r=0.798,p=0.908),  time:19.020, tt:2016.139\n",
      "Ep:106, loss:0.00001, loss_test:0.08281, lr:9.61e-03, fs:0.84946 (r=0.798,p=0.908),  time:19.013, tt:2034.406\n",
      "Ep:107, loss:0.00001, loss_test:0.08310, lr:9.51e-03, fs:0.84324 (r=0.788,p=0.907),  time:19.014, tt:2053.508\n",
      "Ep:108, loss:0.00001, loss_test:0.08313, lr:9.41e-03, fs:0.83516 (r=0.768,p=0.916),  time:19.003, tt:2071.355\n",
      "Ep:109, loss:0.00001, loss_test:0.08369, lr:9.32e-03, fs:0.83516 (r=0.768,p=0.916),  time:18.988, tt:2088.638\n",
      "Ep:110, loss:0.00001, loss_test:0.08368, lr:9.23e-03, fs:0.82873 (r=0.758,p=0.915),  time:18.985, tt:2107.354\n",
      "Ep:111, loss:0.00001, loss_test:0.08376, lr:9.14e-03, fs:0.82418 (r=0.758,p=0.904),  time:18.973, tt:2124.986\n",
      "Ep:112, loss:0.00001, loss_test:0.08372, lr:9.04e-03, fs:0.82418 (r=0.758,p=0.904),  time:18.969, tt:2143.470\n",
      "Ep:113, loss:0.00001, loss_test:0.08394, lr:8.95e-03, fs:0.81768 (r=0.747,p=0.902),  time:18.964, tt:2161.877\n",
      "Ep:114, loss:0.00001, loss_test:0.08426, lr:8.86e-03, fs:0.81564 (r=0.737,p=0.912),  time:18.962, tt:2180.673\n",
      "Ep:115, loss:0.00001, loss_test:0.08426, lr:8.78e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.964, tt:2199.826\n",
      "Ep:116, loss:0.00001, loss_test:0.08372, lr:8.69e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.959, tt:2218.250\n",
      "Ep:117, loss:0.00001, loss_test:0.08491, lr:8.60e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.963, tt:2237.593\n",
      "Ep:118, loss:0.00001, loss_test:0.08420, lr:8.51e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.965, tt:2256.841\n",
      "Ep:119, loss:0.00001, loss_test:0.08500, lr:8.43e-03, fs:0.81111 (r=0.737,p=0.901),  time:18.968, tt:2276.133\n",
      "Ep:120, loss:0.00001, loss_test:0.08495, lr:8.35e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.961, tt:2294.320\n",
      "Ep:121, loss:0.00001, loss_test:0.08436, lr:8.26e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.956, tt:2312.616\n",
      "Ep:122, loss:0.00001, loss_test:0.08566, lr:8.18e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.960, tt:2332.034\n",
      "Ep:123, loss:0.00001, loss_test:0.08535, lr:8.10e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.961, tt:2351.182\n",
      "Ep:124, loss:0.00001, loss_test:0.08529, lr:8.02e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.966, tt:2370.691\n",
      "Ep:125, loss:0.00001, loss_test:0.08607, lr:7.94e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.984, tt:2391.933\n",
      "Ep:126, loss:0.00001, loss_test:0.08520, lr:7.86e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.976, tt:2409.915\n",
      "Ep:127, loss:0.00001, loss_test:0.08584, lr:7.78e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.974, tt:2428.639\n",
      "Ep:128, loss:0.00001, loss_test:0.08648, lr:7.70e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.971, tt:2447.255\n",
      "Ep:129, loss:0.00001, loss_test:0.08614, lr:7.62e-03, fs:0.79096 (r=0.707,p=0.897),  time:18.968, tt:2465.781\n",
      "Ep:130, loss:0.00001, loss_test:0.08657, lr:7.55e-03, fs:0.80447 (r=0.727,p=0.900),  time:18.963, tt:2484.193\n",
      "Ep:131, loss:0.00001, loss_test:0.08646, lr:7.47e-03, fs:0.79096 (r=0.707,p=0.897),  time:18.955, tt:2502.009\n",
      "Ep:132, loss:0.00001, loss_test:0.08667, lr:7.40e-03, fs:0.79775 (r=0.717,p=0.899),  time:18.946, tt:2519.840\n",
      "Ep:133, loss:0.00001, loss_test:0.08701, lr:7.32e-03, fs:0.79096 (r=0.707,p=0.897),  time:18.947, tt:2538.943\n",
      "Ep:134, loss:0.00001, loss_test:0.08653, lr:7.25e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.936, tt:2556.332\n",
      "Ep:135, loss:0.00001, loss_test:0.08697, lr:7.18e-03, fs:0.80226 (r=0.717,p=0.910),  time:18.929, tt:2574.328\n",
      "Ep:136, loss:0.00001, loss_test:0.08713, lr:7.11e-03, fs:0.78409 (r=0.697,p=0.896),  time:18.923, tt:2592.459\n",
      "Ep:137, loss:0.00001, loss_test:0.08717, lr:7.03e-03, fs:0.77714 (r=0.687,p=0.895),  time:18.924, tt:2611.550\n",
      "Ep:138, loss:0.00001, loss_test:0.08741, lr:6.96e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.923, tt:2630.253\n",
      "Ep:139, loss:0.00000, loss_test:0.08716, lr:6.89e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.913, tt:2647.837\n",
      "Ep:140, loss:0.00000, loss_test:0.08754, lr:6.83e-03, fs:0.79545 (r=0.707,p=0.909),  time:18.910, tt:2666.280\n",
      "Ep:141, loss:0.00000, loss_test:0.08787, lr:6.76e-03, fs:0.76301 (r=0.667,p=0.892),  time:18.904, tt:2684.361\n",
      "Ep:142, loss:0.00000, loss_test:0.08772, lr:6.69e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.896, tt:2702.084\n",
      "Ep:143, loss:0.00000, loss_test:0.08789, lr:6.62e-03, fs:0.78161 (r=0.687,p=0.907),  time:18.882, tt:2718.948\n",
      "Ep:144, loss:0.00000, loss_test:0.08791, lr:6.56e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.871, tt:2736.306\n",
      "Ep:145, loss:0.00000, loss_test:0.08803, lr:6.49e-03, fs:0.78613 (r=0.687,p=0.919),  time:18.866, tt:2754.446\n",
      "Ep:146, loss:0.00000, loss_test:0.08818, lr:6.43e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.856, tt:2771.785\n",
      "Ep:147, loss:0.00000, loss_test:0.08816, lr:6.36e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.839, tt:2788.122\n",
      "Ep:148, loss:0.00000, loss_test:0.08827, lr:6.30e-03, fs:0.77907 (r=0.677,p=0.918),  time:18.832, tt:2805.952\n",
      "Ep:149, loss:0.00000, loss_test:0.08816, lr:6.24e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.824, tt:2823.603\n",
      "Ep:150, loss:0.00000, loss_test:0.08839, lr:6.17e-03, fs:0.76744 (r=0.667,p=0.904),  time:18.817, tt:2841.326\n",
      "Ep:151, loss:0.00000, loss_test:0.08858, lr:6.11e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.819, tt:2860.415\n",
      "Ep:152, loss:0.00000, loss_test:0.08856, lr:6.05e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.807, tt:2877.469\n",
      "Ep:153, loss:0.00000, loss_test:0.08859, lr:5.99e-03, fs:0.77193 (r=0.667,p=0.917),  time:18.799, tt:2895.060\n",
      "Ep:154, loss:0.00000, loss_test:0.08877, lr:5.93e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.796, tt:2913.345\n",
      "Ep:155, loss:0.00000, loss_test:0.08876, lr:5.87e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.789, tt:2931.007\n",
      "Ep:156, loss:0.00000, loss_test:0.08896, lr:5.81e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.776, tt:2947.907\n",
      "Ep:157, loss:0.00000, loss_test:0.08887, lr:5.75e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.771, tt:2965.855\n",
      "Ep:158, loss:0.00000, loss_test:0.08884, lr:5.70e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.766, tt:2983.861\n",
      "Ep:159, loss:0.00000, loss_test:0.08912, lr:5.64e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.769, tt:3003.004\n",
      "Ep:160, loss:0.00000, loss_test:0.08891, lr:5.58e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.771, tt:3022.136\n",
      "Ep:161, loss:0.00000, loss_test:0.08924, lr:5.53e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.775, tt:3041.614\n",
      "Ep:162, loss:0.00000, loss_test:0.08936, lr:5.47e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.771, tt:3059.718\n",
      "Ep:163, loss:0.00000, loss_test:0.08919, lr:5.42e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.773, tt:3078.696\n",
      "Ep:164, loss:0.00000, loss_test:0.08940, lr:5.36e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.771, tt:3097.191\n",
      "Ep:165, loss:0.00000, loss_test:0.08955, lr:5.31e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.764, tt:3114.835\n",
      "Ep:166, loss:0.00000, loss_test:0.08955, lr:5.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.765, tt:3133.715\n",
      "Ep:167, loss:0.00000, loss_test:0.08966, lr:5.20e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.757, tt:3151.129\n",
      "Ep:168, loss:0.00000, loss_test:0.08968, lr:5.15e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.757, tt:3169.869\n",
      "Ep:169, loss:0.00000, loss_test:0.08977, lr:5.10e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.754, tt:3188.209\n",
      "Ep:170, loss:0.00000, loss_test:0.08986, lr:5.05e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.765, tt:3208.749\n",
      "Ep:171, loss:0.00000, loss_test:0.09006, lr:5.00e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.769, tt:3228.237\n",
      "Ep:172, loss:0.00000, loss_test:0.09007, lr:4.95e-03, fs:0.76471 (r=0.657,p=0.915),  time:18.766, tt:3246.441\n",
      "Ep:173, loss:0.00000, loss_test:0.08997, lr:4.90e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.756, tt:3263.488\n",
      "Ep:174, loss:0.00000, loss_test:0.09016, lr:4.85e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.758, tt:3282.619\n",
      "Ep:175, loss:0.00000, loss_test:0.09020, lr:4.80e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.754, tt:3300.702\n",
      "Ep:176, loss:0.00000, loss_test:0.09018, lr:4.75e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.748, tt:3318.376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:177, loss:0.00000, loss_test:0.09045, lr:4.71e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.751, tt:3337.669\n",
      "Ep:178, loss:0.00000, loss_test:0.09062, lr:4.66e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.749, tt:3356.110\n",
      "Ep:179, loss:0.00000, loss_test:0.09039, lr:4.61e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.751, tt:3375.246\n",
      "Ep:180, loss:0.00000, loss_test:0.09057, lr:4.57e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.750, tt:3393.798\n",
      "Ep:181, loss:0.00000, loss_test:0.09078, lr:4.52e-03, fs:0.76023 (r=0.657,p=0.903),  time:18.744, tt:3411.429\n",
      "Ep:182, loss:0.00000, loss_test:0.09068, lr:4.48e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.744, tt:3430.123\n",
      "Ep:183, loss:0.00000, loss_test:0.09089, lr:4.43e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.751, tt:3450.178\n",
      "Ep:184, loss:0.00000, loss_test:0.09104, lr:4.39e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.745, tt:3467.825\n",
      "Ep:185, loss:0.00000, loss_test:0.09087, lr:4.34e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.734, tt:3484.539\n",
      "Ep:186, loss:0.00000, loss_test:0.09081, lr:4.30e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.735, tt:3503.378\n",
      "Ep:187, loss:0.00000, loss_test:0.09099, lr:4.26e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.732, tt:3521.597\n",
      "Ep:188, loss:0.00000, loss_test:0.09121, lr:4.21e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.725, tt:3539.024\n",
      "Ep:189, loss:0.00000, loss_test:0.09109, lr:4.17e-03, fs:0.75581 (r=0.657,p=0.890),  time:18.716, tt:3555.955\n",
      "Ep:190, loss:0.00000, loss_test:0.09110, lr:4.13e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.715, tt:3574.570\n",
      "Ep:191, loss:0.00000, loss_test:0.09133, lr:4.09e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.716, tt:3593.505\n",
      "Ep:192, loss:0.00000, loss_test:0.09135, lr:4.05e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.711, tt:3611.169\n",
      "Ep:193, loss:0.00000, loss_test:0.09108, lr:4.01e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.702, tt:3628.268\n",
      "Ep:194, loss:0.00000, loss_test:0.09123, lr:3.97e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.698, tt:3646.154\n",
      "Ep:195, loss:0.00000, loss_test:0.09158, lr:3.93e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.688, tt:3662.833\n",
      "Ep:196, loss:0.00000, loss_test:0.09160, lr:3.89e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.682, tt:3680.373\n",
      "Ep:197, loss:0.00000, loss_test:0.09149, lr:3.85e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.673, tt:3697.175\n",
      "Ep:198, loss:0.00000, loss_test:0.09149, lr:3.81e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.670, tt:3715.314\n",
      "Ep:199, loss:0.00000, loss_test:0.09153, lr:3.77e-03, fs:0.75145 (r=0.657,p=0.878),  time:18.665, tt:3733.092\n",
      "Ep:200, loss:0.00000, loss_test:0.09152, lr:3.73e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.658, tt:3750.336\n",
      "Ep:201, loss:0.00000, loss_test:0.09169, lr:3.70e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.654, tt:3768.184\n",
      "Ep:202, loss:0.00000, loss_test:0.09179, lr:3.66e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.644, tt:3784.822\n",
      "Ep:203, loss:0.00000, loss_test:0.09168, lr:3.62e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.630, tt:3800.501\n",
      "Ep:204, loss:0.00000, loss_test:0.09158, lr:3.59e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.622, tt:3817.521\n",
      "Ep:205, loss:0.00000, loss_test:0.09178, lr:3.55e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.617, tt:3835.057\n",
      "Ep:206, loss:0.00000, loss_test:0.09198, lr:3.52e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.609, tt:3852.145\n",
      "Ep:207, loss:0.00000, loss_test:0.09198, lr:3.48e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.602, tt:3869.301\n",
      "Ep:208, loss:0.00000, loss_test:0.09195, lr:3.45e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.596, tt:3886.498\n",
      "Ep:209, loss:0.00000, loss_test:0.09210, lr:3.41e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.591, tt:3904.112\n",
      "Ep:210, loss:0.00000, loss_test:0.09217, lr:3.38e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.588, tt:3922.095\n",
      "Ep:211, loss:0.00000, loss_test:0.09215, lr:3.34e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.586, tt:3940.187\n",
      "Ep:212, loss:0.00000, loss_test:0.09210, lr:3.31e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.607, tt:3963.320\n",
      "Ep:213, loss:0.00000, loss_test:0.09224, lr:3.28e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.606, tt:3981.720\n",
      "Ep:214, loss:0.00000, loss_test:0.09240, lr:3.24e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.596, tt:3998.108\n",
      "Ep:215, loss:0.00000, loss_test:0.09237, lr:3.21e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.594, tt:4016.411\n",
      "Ep:216, loss:0.00000, loss_test:0.09228, lr:3.18e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.592, tt:4034.361\n",
      "Ep:217, loss:0.00000, loss_test:0.09237, lr:3.15e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.590, tt:4052.591\n",
      "Ep:218, loss:0.00000, loss_test:0.09257, lr:3.12e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.592, tt:4071.702\n",
      "Ep:219, loss:0.00000, loss_test:0.09260, lr:3.09e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.591, tt:4090.125\n",
      "Ep:220, loss:0.00000, loss_test:0.09251, lr:3.05e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.592, tt:4108.770\n",
      "Ep:221, loss:0.00000, loss_test:0.09252, lr:3.02e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.595, tt:4127.999\n",
      "Ep:222, loss:0.00000, loss_test:0.09260, lr:2.99e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.597, tt:4147.097\n",
      "Ep:223, loss:0.00000, loss_test:0.09269, lr:2.96e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.597, tt:4165.696\n",
      "Ep:224, loss:0.00000, loss_test:0.09272, lr:2.93e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.596, tt:4184.091\n",
      "Ep:225, loss:0.00000, loss_test:0.09267, lr:2.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.600, tt:4203.694\n",
      "Ep:226, loss:0.00000, loss_test:0.09262, lr:2.88e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.607, tt:4223.830\n",
      "Ep:227, loss:0.00000, loss_test:0.09272, lr:2.85e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.615, tt:4244.113\n",
      "Ep:228, loss:0.00000, loss_test:0.09284, lr:2.82e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.617, tt:4263.347\n",
      "Ep:229, loss:0.00000, loss_test:0.09280, lr:2.79e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.626, tt:4284.066\n",
      "Ep:230, loss:0.00000, loss_test:0.09270, lr:2.76e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.633, tt:4304.208\n",
      "Ep:231, loss:0.00000, loss_test:0.09280, lr:2.73e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.632, tt:4322.572\n",
      "Ep:232, loss:0.00000, loss_test:0.09295, lr:2.71e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.636, tt:4342.135\n",
      "Ep:233, loss:0.00000, loss_test:0.09303, lr:2.68e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.638, tt:4361.312\n",
      "Ep:234, loss:0.00000, loss_test:0.09296, lr:2.65e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.644, tt:4381.345\n",
      "Ep:235, loss:0.00000, loss_test:0.09286, lr:2.63e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.653, tt:4402.054\n",
      "Ep:236, loss:0.00000, loss_test:0.09294, lr:2.60e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.657, tt:4421.621\n",
      "Ep:237, loss:0.00000, loss_test:0.09307, lr:2.57e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.660, tt:4441.173\n",
      "Ep:238, loss:0.00000, loss_test:0.09314, lr:2.55e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.667, tt:4461.364\n",
      "Ep:239, loss:0.00000, loss_test:0.09310, lr:2.52e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.673, tt:4481.404\n",
      "Ep:240, loss:0.00000, loss_test:0.09307, lr:2.50e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.676, tt:4500.901\n",
      "Ep:241, loss:0.00000, loss_test:0.09305, lr:2.47e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.691, tt:4523.214\n",
      "Ep:242, loss:0.00000, loss_test:0.09318, lr:2.45e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.698, tt:4543.604\n",
      "Ep:243, loss:0.00000, loss_test:0.09323, lr:2.42e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.703, tt:4563.538\n",
      "Ep:244, loss:0.00000, loss_test:0.09315, lr:2.40e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.710, tt:4583.982\n",
      "Ep:245, loss:0.00000, loss_test:0.09311, lr:2.38e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.719, tt:4604.821\n",
      "Ep:246, loss:0.00000, loss_test:0.09321, lr:2.35e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.726, tt:4625.392\n",
      "Ep:247, loss:0.00000, loss_test:0.09325, lr:2.33e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.729, tt:4644.851\n",
      "Ep:248, loss:0.00000, loss_test:0.09325, lr:2.31e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.731, tt:4663.954\n",
      "Ep:249, loss:0.00000, loss_test:0.09322, lr:2.28e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.736, tt:4683.899\n",
      "Ep:250, loss:0.00000, loss_test:0.09322, lr:2.26e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.741, tt:4703.970\n",
      "Ep:251, loss:0.00000, loss_test:0.09333, lr:2.24e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.749, tt:4724.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:252, loss:0.00000, loss_test:0.09340, lr:2.21e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.749, tt:4743.393\n",
      "Ep:253, loss:0.00000, loss_test:0.09334, lr:2.19e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.748, tt:4762.032\n",
      "Ep:254, loss:0.00000, loss_test:0.09327, lr:2.17e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.751, tt:4781.414\n",
      "Ep:255, loss:0.00000, loss_test:0.09338, lr:2.15e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.755, tt:4801.387\n",
      "Ep:256, loss:0.00000, loss_test:0.09341, lr:2.13e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.762, tt:4821.926\n",
      "Ep:257, loss:0.00000, loss_test:0.09345, lr:2.11e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.764, tt:4841.113\n",
      "Ep:258, loss:0.00000, loss_test:0.09337, lr:2.08e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.766, tt:4860.392\n",
      "Ep:259, loss:0.00000, loss_test:0.09340, lr:2.06e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.770, tt:4880.132\n",
      "Ep:260, loss:0.00000, loss_test:0.09347, lr:2.04e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.773, tt:4899.833\n",
      "Ep:261, loss:0.00000, loss_test:0.09348, lr:2.02e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.775, tt:4919.038\n",
      "Ep:262, loss:0.00000, loss_test:0.09347, lr:2.00e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.770, tt:4936.517\n",
      "Ep:263, loss:0.00000, loss_test:0.09350, lr:1.98e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.770, tt:4955.274\n",
      "Ep:264, loss:0.00000, loss_test:0.09348, lr:1.96e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.765, tt:4972.710\n",
      "Ep:265, loss:0.00000, loss_test:0.09357, lr:1.94e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.759, tt:4989.928\n",
      "Ep:266, loss:0.00000, loss_test:0.09356, lr:1.92e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.758, tt:5008.345\n",
      "Ep:267, loss:0.00000, loss_test:0.09349, lr:1.90e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.755, tt:5026.259\n",
      "Ep:268, loss:0.00000, loss_test:0.09354, lr:1.89e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.747, tt:5043.043\n",
      "Ep:269, loss:0.00000, loss_test:0.09365, lr:1.87e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.750, tt:5062.374\n",
      "Ep:270, loss:0.00000, loss_test:0.09368, lr:1.85e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.740, tt:5078.452\n",
      "Ep:271, loss:0.00000, loss_test:0.09364, lr:1.83e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.729, tt:5094.192\n",
      "Ep:272, loss:0.00000, loss_test:0.09363, lr:1.81e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.724, tt:5111.650\n",
      "Ep:273, loss:0.00000, loss_test:0.09366, lr:1.79e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.714, tt:5127.729\n",
      "Ep:274, loss:0.00000, loss_test:0.09368, lr:1.78e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.704, tt:5143.628\n",
      "Ep:275, loss:0.00000, loss_test:0.09365, lr:1.76e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.698, tt:5160.595\n",
      "Ep:276, loss:0.00000, loss_test:0.09368, lr:1.74e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.687, tt:5176.191\n",
      "Ep:277, loss:0.00000, loss_test:0.09369, lr:1.72e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.678, tt:5192.589\n",
      "Ep:278, loss:0.00000, loss_test:0.09370, lr:1.71e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.672, tt:5209.527\n",
      "Ep:279, loss:0.00000, loss_test:0.09372, lr:1.69e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.663, tt:5225.511\n",
      "Ep:280, loss:0.00000, loss_test:0.09376, lr:1.67e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.656, tt:5242.362\n",
      "Ep:281, loss:0.00000, loss_test:0.09374, lr:1.65e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.644, tt:5257.679\n",
      "Ep:282, loss:0.00000, loss_test:0.09373, lr:1.64e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.638, tt:5274.444\n",
      "Ep:283, loss:0.00000, loss_test:0.09381, lr:1.62e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.633, tt:5291.821\n",
      "Ep:284, loss:0.00000, loss_test:0.09383, lr:1.61e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.628, tt:5309.041\n",
      "Ep:285, loss:0.00000, loss_test:0.09376, lr:1.59e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.623, tt:5326.271\n",
      "Ep:286, loss:0.00000, loss_test:0.09375, lr:1.57e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.620, tt:5343.859\n",
      "Ep:287, loss:0.00000, loss_test:0.09381, lr:1.56e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.615, tt:5361.178\n",
      "Ep:288, loss:0.00000, loss_test:0.09385, lr:1.54e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.610, tt:5378.332\n",
      "Ep:289, loss:0.00000, loss_test:0.09385, lr:1.53e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.603, tt:5394.995\n",
      "Ep:290, loss:0.00000, loss_test:0.09383, lr:1.51e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.598, tt:5411.994\n",
      "Ep:291, loss:0.00000, loss_test:0.09378, lr:1.50e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.594, tt:5429.355\n",
      "Ep:292, loss:0.00000, loss_test:0.09383, lr:1.48e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.588, tt:5446.205\n",
      "Ep:293, loss:0.00000, loss_test:0.09391, lr:1.47e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.585, tt:5463.864\n",
      "Ep:294, loss:0.00000, loss_test:0.09387, lr:1.45e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.575, tt:5479.496\n",
      "Ep:295, loss:0.00000, loss_test:0.09378, lr:1.44e-03, fs:0.74713 (r=0.657,p=0.867),  time:18.538, tt:5487.104\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=3600 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,296,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= True\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Creating simple train/test splits...\n",
      "Train/Test split done\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14680, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:44.262, tt:44.262\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00055, loss_test:0.14487, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.612, tt:103.223\n",
      "Ep:2, loss:0.00053, loss_test:0.14093, lr:1.00e-02, fs:0.66207 (r=0.970,p=0.503),  time:56.413, tt:169.238\n",
      "Ep:3, loss:0.00050, loss_test:0.13407, lr:1.00e-02, fs:0.64032 (r=0.818,p=0.526),  time:58.992, tt:235.969\n",
      "Ep:4, loss:0.00046, loss_test:0.13096, lr:1.00e-02, fs:0.60513 (r=0.596,p=0.615),  time:60.520, tt:302.600\n",
      "Ep:5, loss:0.00044, loss_test:0.12592, lr:1.00e-02, fs:0.65403 (r=0.697,p=0.616),  time:61.457, tt:368.741\n",
      "Ep:6, loss:0.00042, loss_test:0.12167, lr:1.00e-02, fs:0.66986 (r=0.707,p=0.636),  time:62.112, tt:434.784\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00039, loss_test:0.11899, lr:1.00e-02, fs:0.64000 (r=0.646,p=0.634),  time:63.305, tt:506.442\n",
      "Ep:8, loss:0.00037, loss_test:0.11577, lr:1.00e-02, fs:0.64322 (r=0.646,p=0.640),  time:63.660, tt:572.937\n",
      "Ep:9, loss:0.00036, loss_test:0.11430, lr:1.00e-02, fs:0.65306 (r=0.646,p=0.660),  time:63.833, tt:638.327\n",
      "Ep:10, loss:0.00034, loss_test:0.11386, lr:1.00e-02, fs:0.67358 (r=0.657,p=0.691),  time:63.992, tt:703.915\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00032, loss_test:0.11280, lr:1.00e-02, fs:0.67016 (r=0.646,p=0.696),  time:64.010, tt:768.119\n",
      "Ep:12, loss:0.00031, loss_test:0.11258, lr:1.00e-02, fs:0.65193 (r=0.596,p=0.720),  time:64.201, tt:834.618\n",
      "Ep:13, loss:0.00030, loss_test:0.11046, lr:1.00e-02, fs:0.65957 (r=0.626,p=0.697),  time:64.333, tt:900.661\n",
      "Ep:14, loss:0.00028, loss_test:0.11173, lr:1.00e-02, fs:0.62570 (r=0.566,p=0.700),  time:64.442, tt:966.624\n",
      "Ep:15, loss:0.00027, loss_test:0.11273, lr:1.00e-02, fs:0.62921 (r=0.566,p=0.709),  time:64.548, tt:1032.762\n",
      "Ep:16, loss:0.00026, loss_test:0.11125, lr:1.00e-02, fs:0.65946 (r=0.616,p=0.709),  time:64.697, tt:1099.857\n",
      "Ep:17, loss:0.00025, loss_test:0.11304, lr:1.00e-02, fs:0.61714 (r=0.545,p=0.711),  time:64.686, tt:1164.352\n",
      "Ep:18, loss:0.00024, loss_test:0.11107, lr:1.00e-02, fs:0.64835 (r=0.596,p=0.711),  time:64.633, tt:1228.020\n",
      "Ep:19, loss:0.00023, loss_test:0.11400, lr:1.00e-02, fs:0.65089 (r=0.556,p=0.786),  time:64.720, tt:1294.404\n",
      "Ep:20, loss:0.00022, loss_test:0.11262, lr:1.00e-02, fs:0.66667 (r=0.586,p=0.773),  time:64.637, tt:1357.379\n",
      "Ep:21, loss:0.00021, loss_test:0.11340, lr:1.00e-02, fs:0.66667 (r=0.566,p=0.812),  time:64.584, tt:1420.855\n",
      "Ep:22, loss:0.00020, loss_test:0.11349, lr:9.90e-03, fs:0.66279 (r=0.576,p=0.781),  time:64.746, tt:1489.162\n",
      "Ep:23, loss:0.00019, loss_test:0.11356, lr:9.80e-03, fs:0.67059 (r=0.576,p=0.803),  time:64.830, tt:1555.917\n",
      "Ep:24, loss:0.00018, loss_test:0.11414, lr:9.70e-03, fs:0.66667 (r=0.576,p=0.792),  time:64.898, tt:1622.460\n",
      "Ep:25, loss:0.00017, loss_test:0.11388, lr:9.61e-03, fs:0.67456 (r=0.576,p=0.814),  time:65.096, tt:1692.508\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00017, loss_test:0.11759, lr:9.61e-03, fs:0.66265 (r=0.556,p=0.821),  time:65.210, tt:1760.660\n",
      "Ep:27, loss:0.00016, loss_test:0.11634, lr:9.61e-03, fs:0.66667 (r=0.576,p=0.792),  time:65.279, tt:1827.807\n",
      "Ep:28, loss:0.00015, loss_test:0.11530, lr:9.61e-03, fs:0.67059 (r=0.576,p=0.803),  time:65.306, tt:1893.878\n",
      "Ep:29, loss:0.00015, loss_test:0.11610, lr:9.61e-03, fs:0.66667 (r=0.576,p=0.792),  time:65.352, tt:1960.574\n",
      "Ep:30, loss:0.00014, loss_test:0.11447, lr:9.61e-03, fs:0.67442 (r=0.586,p=0.795),  time:65.361, tt:2026.180\n",
      "Ep:31, loss:0.00014, loss_test:0.11611, lr:9.61e-03, fs:0.68639 (r=0.586,p=0.829),  time:65.328, tt:2090.483\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00013, loss_test:0.11767, lr:9.61e-03, fs:0.68639 (r=0.586,p=0.829),  time:65.375, tt:2157.384\n",
      "Ep:33, loss:0.00012, loss_test:0.11807, lr:9.61e-03, fs:0.68639 (r=0.586,p=0.829),  time:65.440, tt:2224.963\n",
      "Ep:34, loss:0.00012, loss_test:0.11954, lr:9.61e-03, fs:0.67857 (r=0.576,p=0.826),  time:65.476, tt:2291.655\n",
      "Ep:35, loss:0.00012, loss_test:0.11961, lr:9.61e-03, fs:0.67857 (r=0.576,p=0.826),  time:65.480, tt:2357.270\n",
      "Ep:36, loss:0.00011, loss_test:0.11795, lr:9.61e-03, fs:0.69822 (r=0.596,p=0.843),  time:65.456, tt:2421.857\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00011, loss_test:0.12315, lr:9.61e-03, fs:0.68293 (r=0.566,p=0.862),  time:65.486, tt:2488.455\n",
      "Ep:38, loss:0.00010, loss_test:0.12197, lr:9.61e-03, fs:0.68675 (r=0.576,p=0.851),  time:65.477, tt:2553.618\n",
      "Ep:39, loss:0.00010, loss_test:0.12277, lr:9.61e-03, fs:0.62025 (r=0.495,p=0.831),  time:65.445, tt:2617.790\n",
      "Ep:40, loss:0.00010, loss_test:0.11723, lr:9.61e-03, fs:0.70175 (r=0.606,p=0.833),  time:65.421, tt:2682.273\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00009, loss_test:0.12115, lr:9.61e-03, fs:0.69461 (r=0.586,p=0.853),  time:65.384, tt:2746.128\n",
      "Ep:42, loss:0.00009, loss_test:0.12653, lr:9.61e-03, fs:0.69512 (r=0.576,p=0.877),  time:65.388, tt:2811.664\n",
      "Ep:43, loss:0.00008, loss_test:0.12141, lr:9.61e-03, fs:0.69880 (r=0.586,p=0.866),  time:65.405, tt:2877.840\n",
      "Ep:44, loss:0.00008, loss_test:0.12297, lr:9.61e-03, fs:0.67485 (r=0.556,p=0.859),  time:65.440, tt:2944.799\n",
      "Ep:45, loss:0.00008, loss_test:0.12057, lr:9.61e-03, fs:0.65839 (r=0.535,p=0.855),  time:65.439, tt:3010.198\n",
      "Ep:46, loss:0.00008, loss_test:0.12073, lr:9.61e-03, fs:0.68712 (r=0.566,p=0.875),  time:65.387, tt:3073.201\n",
      "Ep:47, loss:0.00007, loss_test:0.12356, lr:9.61e-03, fs:0.67500 (r=0.545,p=0.885),  time:65.377, tt:3138.112\n",
      "Ep:48, loss:0.00007, loss_test:0.12714, lr:9.61e-03, fs:0.64968 (r=0.515,p=0.879),  time:65.397, tt:3204.432\n",
      "Ep:49, loss:0.00007, loss_test:0.12036, lr:9.61e-03, fs:0.67879 (r=0.566,p=0.848),  time:65.389, tt:3269.439\n",
      "Ep:50, loss:0.00007, loss_test:0.12648, lr:9.61e-03, fs:0.65823 (r=0.525,p=0.881),  time:65.374, tt:3334.050\n",
      "Ep:51, loss:0.00006, loss_test:0.12242, lr:9.61e-03, fs:0.65409 (r=0.525,p=0.867),  time:65.427, tt:3402.208\n",
      "Ep:52, loss:0.00006, loss_test:0.12415, lr:9.51e-03, fs:0.66250 (r=0.535,p=0.869),  time:65.410, tt:3466.747\n",
      "Ep:53, loss:0.00006, loss_test:0.12465, lr:9.41e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.436, tt:3533.522\n",
      "Ep:54, loss:0.00006, loss_test:0.12008, lr:9.32e-03, fs:0.65839 (r=0.535,p=0.855),  time:65.437, tt:3599.010\n",
      "Ep:55, loss:0.00006, loss_test:0.12921, lr:9.23e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.533, tt:3669.829\n",
      "Ep:56, loss:0.00005, loss_test:0.12882, lr:9.14e-03, fs:0.60927 (r=0.465,p=0.885),  time:65.538, tt:3735.687\n",
      "Ep:57, loss:0.00005, loss_test:0.12497, lr:9.04e-03, fs:0.65823 (r=0.525,p=0.881),  time:65.526, tt:3800.518\n",
      "Ep:58, loss:0.00005, loss_test:0.12750, lr:8.95e-03, fs:0.60927 (r=0.465,p=0.885),  time:65.508, tt:3864.973\n",
      "Ep:59, loss:0.00005, loss_test:0.12831, lr:8.86e-03, fs:0.60927 (r=0.465,p=0.885),  time:65.484, tt:3929.040\n",
      "Ep:60, loss:0.00005, loss_test:0.12649, lr:8.78e-03, fs:0.60526 (r=0.465,p=0.868),  time:65.452, tt:3992.575\n",
      "Ep:61, loss:0.00005, loss_test:0.12861, lr:8.69e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.421, tt:4056.111\n",
      "Ep:62, loss:0.00005, loss_test:0.12714, lr:8.60e-03, fs:0.60526 (r=0.465,p=0.868),  time:65.426, tt:4121.814\n",
      "Ep:63, loss:0.00005, loss_test:0.12737, lr:8.51e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.382, tt:4184.434\n",
      "Ep:64, loss:0.00004, loss_test:0.13069, lr:8.43e-03, fs:0.64516 (r=0.505,p=0.893),  time:65.368, tt:4248.926\n",
      "Ep:65, loss:0.00004, loss_test:0.13110, lr:8.35e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.336, tt:4312.170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:66, loss:0.00004, loss_test:0.13510, lr:8.26e-03, fs:0.61745 (r=0.465,p=0.920),  time:65.324, tt:4376.738\n",
      "Ep:67, loss:0.00004, loss_test:0.12996, lr:8.18e-03, fs:0.60927 (r=0.465,p=0.885),  time:65.389, tt:4446.422\n",
      "Ep:68, loss:0.00004, loss_test:0.12828, lr:8.10e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.378, tt:4511.067\n",
      "Ep:69, loss:0.00004, loss_test:0.13141, lr:8.02e-03, fs:0.60927 (r=0.465,p=0.885),  time:65.369, tt:4575.838\n",
      "Ep:70, loss:0.00004, loss_test:0.13526, lr:7.94e-03, fs:0.61745 (r=0.465,p=0.920),  time:65.357, tt:4640.342\n",
      "Ep:71, loss:0.00004, loss_test:0.13077, lr:7.86e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.387, tt:4707.857\n",
      "Ep:72, loss:0.00004, loss_test:0.13685, lr:7.78e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.376, tt:4772.462\n",
      "Ep:73, loss:0.00003, loss_test:0.13126, lr:7.70e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.395, tt:4839.194\n",
      "Ep:74, loss:0.00003, loss_test:0.13349, lr:7.62e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.384, tt:4903.777\n",
      "Ep:75, loss:0.00003, loss_test:0.13245, lr:7.55e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.411, tt:4971.272\n",
      "Ep:76, loss:0.00003, loss_test:0.13587, lr:7.47e-03, fs:0.61333 (r=0.465,p=0.902),  time:65.438, tt:5038.719\n",
      "Ep:77, loss:0.00003, loss_test:0.13477, lr:7.40e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.434, tt:5103.870\n",
      "Ep:78, loss:0.00003, loss_test:0.13471, lr:7.32e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.454, tt:5170.890\n",
      "Ep:79, loss:0.00003, loss_test:0.13924, lr:7.25e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.478, tt:5238.237\n",
      "Ep:80, loss:0.00003, loss_test:0.13665, lr:7.18e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.501, tt:5305.560\n",
      "Ep:81, loss:0.00003, loss_test:0.13455, lr:7.11e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.499, tt:5370.894\n",
      "Ep:82, loss:0.00003, loss_test:0.13850, lr:7.03e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.491, tt:5435.782\n",
      "Ep:83, loss:0.00003, loss_test:0.13683, lr:6.96e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.473, tt:5499.748\n",
      "Ep:84, loss:0.00003, loss_test:0.13645, lr:6.89e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.453, tt:5563.483\n",
      "Ep:85, loss:0.00003, loss_test:0.13633, lr:6.83e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.453, tt:5628.971\n",
      "Ep:86, loss:0.00002, loss_test:0.13807, lr:6.76e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.441, tt:5693.386\n",
      "Ep:87, loss:0.00002, loss_test:0.13853, lr:6.69e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.473, tt:5761.645\n",
      "Ep:88, loss:0.00002, loss_test:0.13723, lr:6.62e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.481, tt:5827.805\n",
      "Ep:89, loss:0.00002, loss_test:0.13813, lr:6.56e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.487, tt:5893.868\n",
      "Ep:90, loss:0.00002, loss_test:0.13741, lr:6.49e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.460, tt:5956.851\n",
      "Ep:91, loss:0.00002, loss_test:0.14175, lr:6.43e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.501, tt:6026.046\n",
      "Ep:92, loss:0.00002, loss_test:0.13889, lr:6.36e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.492, tt:6090.724\n",
      "Ep:93, loss:0.00002, loss_test:0.13720, lr:6.30e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.494, tt:6156.419\n",
      "Ep:94, loss:0.00002, loss_test:0.14271, lr:6.24e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.498, tt:6222.333\n",
      "Ep:95, loss:0.00002, loss_test:0.13594, lr:6.17e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.493, tt:6287.315\n",
      "Ep:96, loss:0.00002, loss_test:0.14141, lr:6.11e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.503, tt:6353.834\n",
      "Ep:97, loss:0.00002, loss_test:0.14043, lr:6.05e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.511, tt:6420.121\n",
      "Ep:98, loss:0.00002, loss_test:0.13832, lr:5.99e-03, fs:0.60000 (r=0.455,p=0.882),  time:65.514, tt:6485.914\n",
      "Ep:99, loss:0.00002, loss_test:0.13966, lr:5.93e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.524, tt:6552.374\n",
      "Ep:100, loss:0.00002, loss_test:0.13994, lr:5.87e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.526, tt:6618.141\n",
      "Ep:101, loss:0.00002, loss_test:0.14228, lr:5.81e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.521, tt:6683.100\n",
      "Ep:102, loss:0.00002, loss_test:0.14076, lr:5.75e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.478, tt:6744.205\n",
      "Ep:103, loss:0.00002, loss_test:0.13905, lr:5.70e-03, fs:0.60403 (r=0.455,p=0.900),  time:65.475, tt:6809.424\n",
      "Ep:104, loss:0.00002, loss_test:0.14037, lr:5.64e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.454, tt:6872.668\n",
      "Ep:105, loss:0.00002, loss_test:0.14204, lr:5.58e-03, fs:0.60811 (r=0.455,p=0.918),  time:65.366, tt:6928.823\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00056, loss_test:0.14544, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:76.347, tt:76.347\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00054, loss_test:0.13967, lr:1.00e-02, fs:0.63309 (r=0.889,p=0.492),  time:74.966, tt:149.931\n",
      "Ep:2, loss:0.00048, loss_test:0.13730, lr:1.00e-02, fs:0.54023 (r=0.475,p=0.627),  time:77.566, tt:232.699\n",
      "Ep:3, loss:0.00044, loss_test:0.12655, lr:1.00e-02, fs:0.63208 (r=0.677,p=0.593),  time:78.961, tt:315.846\n",
      "Ep:4, loss:0.00041, loss_test:0.12457, lr:1.00e-02, fs:0.59091 (r=0.525,p=0.675),  time:79.473, tt:397.363\n",
      "Ep:5, loss:0.00038, loss_test:0.11675, lr:1.00e-02, fs:0.66010 (r=0.677,p=0.644),  time:79.992, tt:479.950\n",
      "Ep:6, loss:0.00034, loss_test:0.11675, lr:1.00e-02, fs:0.62275 (r=0.525,p=0.765),  time:79.915, tt:559.402\n",
      "Ep:7, loss:0.00032, loss_test:0.10901, lr:1.00e-02, fs:0.66286 (r=0.586,p=0.763),  time:80.464, tt:643.712\n",
      "Ep:8, loss:0.00029, loss_test:0.10499, lr:1.00e-02, fs:0.72826 (r=0.677,p=0.788),  time:80.515, tt:724.636\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00027, loss_test:0.10266, lr:1.00e-02, fs:0.73514 (r=0.687,p=0.791),  time:80.686, tt:806.864\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00025, loss_test:0.10699, lr:1.00e-02, fs:0.65409 (r=0.525,p=0.867),  time:80.972, tt:890.688\n",
      "Ep:11, loss:0.00023, loss_test:0.10918, lr:1.00e-02, fs:0.62500 (r=0.505,p=0.820),  time:81.206, tt:974.472\n",
      "Ep:12, loss:0.00021, loss_test:0.10623, lr:1.00e-02, fs:0.65823 (r=0.525,p=0.881),  time:81.182, tt:1055.363\n",
      "Ep:13, loss:0.00019, loss_test:0.10648, lr:1.00e-02, fs:0.67073 (r=0.556,p=0.846),  time:81.573, tt:1142.015\n",
      "Ep:14, loss:0.00017, loss_test:0.11142, lr:1.00e-02, fs:0.60927 (r=0.465,p=0.885),  time:81.805, tt:1227.078\n",
      "Ep:15, loss:0.00016, loss_test:0.10974, lr:1.00e-02, fs:0.65823 (r=0.525,p=0.881),  time:81.829, tt:1309.261\n",
      "Ep:16, loss:0.00014, loss_test:0.11401, lr:1.00e-02, fs:0.59211 (r=0.455,p=0.849),  time:81.772, tt:1390.119\n",
      "Ep:17, loss:0.00013, loss_test:0.10797, lr:1.00e-02, fs:0.68293 (r=0.566,p=0.862),  time:81.925, tt:1474.655\n",
      "Ep:18, loss:0.00012, loss_test:0.11122, lr:1.00e-02, fs:0.64557 (r=0.515,p=0.864),  time:81.897, tt:1556.051\n",
      "Ep:19, loss:0.00011, loss_test:0.11418, lr:1.00e-02, fs:0.62338 (r=0.485,p=0.873),  time:81.951, tt:1639.022\n",
      "Ep:20, loss:0.00010, loss_test:0.12221, lr:1.00e-02, fs:0.58667 (r=0.444,p=0.863),  time:81.954, tt:1721.029\n",
      "Ep:21, loss:0.00009, loss_test:0.11943, lr:9.90e-03, fs:0.57718 (r=0.434,p=0.860),  time:81.988, tt:1803.728\n",
      "Ep:22, loss:0.00009, loss_test:0.11522, lr:9.80e-03, fs:0.61039 (r=0.475,p=0.855),  time:81.880, tt:1883.236\n",
      "Ep:23, loss:0.00008, loss_test:0.11616, lr:9.70e-03, fs:0.57718 (r=0.434,p=0.860),  time:82.048, tt:1969.161\n",
      "Ep:24, loss:0.00008, loss_test:0.12374, lr:9.61e-03, fs:0.62338 (r=0.485,p=0.873),  time:82.000, tt:2050.012\n",
      "Ep:25, loss:0.00007, loss_test:0.13223, lr:9.51e-03, fs:0.61745 (r=0.465,p=0.920),  time:81.992, tt:2131.788\n",
      "Ep:26, loss:0.00006, loss_test:0.12529, lr:9.41e-03, fs:0.56552 (r=0.414,p=0.891),  time:81.919, tt:2211.805\n",
      "Ep:27, loss:0.00006, loss_test:0.12747, lr:9.32e-03, fs:0.56164 (r=0.414,p=0.872),  time:81.837, tt:2291.436\n",
      "Ep:28, loss:0.00005, loss_test:0.12681, lr:9.23e-03, fs:0.63636 (r=0.495,p=0.891),  time:82.015, tt:2378.423\n",
      "Ep:29, loss:0.00005, loss_test:0.12694, lr:9.14e-03, fs:0.50000 (r=0.354,p=0.854),  time:82.085, tt:2462.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:30, loss:0.00005, loss_test:0.12669, lr:9.04e-03, fs:0.64516 (r=0.505,p=0.893),  time:82.116, tt:2545.609\n",
      "Ep:31, loss:0.00004, loss_test:0.12939, lr:8.95e-03, fs:0.53521 (r=0.384,p=0.884),  time:82.192, tt:2630.137\n",
      "Ep:32, loss:0.00004, loss_test:0.13841, lr:8.86e-03, fs:0.56738 (r=0.404,p=0.952),  time:82.149, tt:2710.904\n",
      "Ep:33, loss:0.00004, loss_test:0.13496, lr:8.78e-03, fs:0.63514 (r=0.475,p=0.959),  time:82.254, tt:2796.651\n",
      "Ep:34, loss:0.00003, loss_test:0.12281, lr:8.69e-03, fs:0.61745 (r=0.465,p=0.920),  time:82.290, tt:2880.142\n",
      "Ep:35, loss:0.00003, loss_test:0.13335, lr:8.60e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.328, tt:2963.825\n",
      "Ep:36, loss:0.00003, loss_test:0.13410, lr:8.51e-03, fs:0.63514 (r=0.475,p=0.959),  time:82.327, tt:3046.084\n",
      "Ep:37, loss:0.00003, loss_test:0.13606, lr:8.43e-03, fs:0.55714 (r=0.394,p=0.951),  time:82.345, tt:3129.127\n",
      "Ep:38, loss:0.00003, loss_test:0.13189, lr:8.35e-03, fs:0.59310 (r=0.434,p=0.935),  time:82.311, tt:3210.146\n",
      "Ep:39, loss:0.00002, loss_test:0.14299, lr:8.26e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.292, tt:3291.685\n",
      "Ep:40, loss:0.00002, loss_test:0.13979, lr:8.18e-03, fs:0.62585 (r=0.465,p=0.958),  time:82.342, tt:3376.009\n",
      "Ep:41, loss:0.00002, loss_test:0.13616, lr:8.10e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.376, tt:3459.812\n",
      "Ep:42, loss:0.00002, loss_test:0.14507, lr:8.02e-03, fs:0.63014 (r=0.465,p=0.979),  time:82.443, tt:3545.039\n",
      "Ep:43, loss:0.00002, loss_test:0.14217, lr:7.94e-03, fs:0.62585 (r=0.465,p=0.958),  time:82.458, tt:3628.161\n",
      "Ep:44, loss:0.00002, loss_test:0.14810, lr:7.86e-03, fs:0.57143 (r=0.404,p=0.976),  time:82.484, tt:3711.777\n",
      "Ep:45, loss:0.00002, loss_test:0.14507, lr:7.78e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.491, tt:3794.596\n",
      "Ep:46, loss:0.00001, loss_test:0.14772, lr:7.70e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.476, tt:3876.355\n",
      "Ep:47, loss:0.00001, loss_test:0.14952, lr:7.62e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.519, tt:3960.914\n",
      "Ep:48, loss:0.00001, loss_test:0.14827, lr:7.55e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.470, tt:4041.042\n",
      "Ep:49, loss:0.00001, loss_test:0.15536, lr:7.47e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.461, tt:4123.035\n",
      "Ep:50, loss:0.00001, loss_test:0.14594, lr:7.40e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.506, tt:4207.818\n",
      "Ep:51, loss:0.00001, loss_test:0.15757, lr:7.32e-03, fs:0.59155 (r=0.424,p=0.977),  time:82.568, tt:4293.533\n",
      "Ep:52, loss:0.00001, loss_test:0.14948, lr:7.25e-03, fs:0.60140 (r=0.434,p=0.977),  time:82.560, tt:4375.699\n",
      "Ep:53, loss:0.00001, loss_test:0.15212, lr:7.18e-03, fs:0.59155 (r=0.424,p=0.977),  time:82.611, tt:4461.007\n",
      "Ep:54, loss:0.00001, loss_test:0.15597, lr:7.11e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.620, tt:4544.102\n",
      "Ep:55, loss:0.00001, loss_test:0.15140, lr:7.03e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.584, tt:4624.697\n",
      "Ep:56, loss:0.00001, loss_test:0.15373, lr:6.96e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.541, tt:4704.848\n",
      "Ep:57, loss:0.00001, loss_test:0.15618, lr:6.89e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.523, tt:4786.339\n",
      "Ep:58, loss:0.00001, loss_test:0.15220, lr:6.83e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.504, tt:4867.707\n",
      "Ep:59, loss:0.00001, loss_test:0.15427, lr:6.76e-03, fs:0.57746 (r=0.414,p=0.953),  time:82.521, tt:4951.284\n",
      "Ep:60, loss:0.00001, loss_test:0.15302, lr:6.69e-03, fs:0.56115 (r=0.394,p=0.975),  time:82.462, tt:5030.159\n",
      "Ep:61, loss:0.00001, loss_test:0.15410, lr:6.62e-03, fs:0.51852 (r=0.354,p=0.972),  time:82.442, tt:5111.408\n",
      "Ep:62, loss:0.00001, loss_test:0.15342, lr:6.56e-03, fs:0.57746 (r=0.414,p=0.953),  time:82.443, tt:5193.907\n",
      "Ep:63, loss:0.00001, loss_test:0.15531, lr:6.49e-03, fs:0.60690 (r=0.444,p=0.957),  time:82.395, tt:5273.252\n",
      "Ep:64, loss:0.00001, loss_test:0.15539, lr:6.43e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.427, tt:5357.734\n",
      "Ep:65, loss:0.00001, loss_test:0.15847, lr:6.36e-03, fs:0.59722 (r=0.434,p=0.956),  time:82.417, tt:5439.501\n",
      "Ep:66, loss:0.00001, loss_test:0.15339, lr:6.30e-03, fs:0.58156 (r=0.414,p=0.976),  time:82.394, tt:5520.404\n",
      "Ep:67, loss:0.00000, loss_test:0.15859, lr:6.24e-03, fs:0.42857 (r=0.273,p=1.000),  time:82.375, tt:5601.484\n",
      "Ep:68, loss:0.00000, loss_test:0.15392, lr:6.17e-03, fs:0.45802 (r=0.303,p=0.938),  time:82.366, tt:5683.288\n",
      "Ep:69, loss:0.00000, loss_test:0.15538, lr:6.11e-03, fs:0.54412 (r=0.374,p=1.000),  time:82.384, tt:5766.878\n",
      "Ep:70, loss:0.00000, loss_test:0.15927, lr:6.05e-03, fs:0.45802 (r=0.303,p=0.938),  time:82.404, tt:5850.665\n",
      "Ep:71, loss:0.00000, loss_test:0.15963, lr:5.99e-03, fs:0.36066 (r=0.222,p=0.957),  time:82.355, tt:5929.550\n",
      "Ep:72, loss:0.00000, loss_test:0.15196, lr:5.93e-03, fs:0.61111 (r=0.444,p=0.978),  time:82.317, tt:6009.142\n",
      "Ep:73, loss:0.00000, loss_test:0.15917, lr:5.87e-03, fs:0.45313 (r=0.293,p=1.000),  time:82.304, tt:6090.530\n",
      "Ep:74, loss:0.00000, loss_test:0.15633, lr:5.81e-03, fs:0.50746 (r=0.343,p=0.971),  time:82.336, tt:6175.184\n",
      "Ep:75, loss:0.00000, loss_test:0.15444, lr:5.75e-03, fs:0.61111 (r=0.444,p=0.978),  time:82.346, tt:6258.275\n",
      "Ep:76, loss:0.00000, loss_test:0.15641, lr:5.70e-03, fs:0.48855 (r=0.323,p=1.000),  time:82.361, tt:6341.765\n",
      "Ep:77, loss:0.00000, loss_test:0.15595, lr:5.64e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.381, tt:6425.695\n",
      "Ep:78, loss:0.00000, loss_test:0.15550, lr:5.58e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.439, tt:6512.710\n",
      "Ep:79, loss:0.00000, loss_test:0.15459, lr:5.53e-03, fs:0.45802 (r=0.303,p=0.938),  time:82.451, tt:6596.080\n",
      "Ep:80, loss:0.00000, loss_test:0.15507, lr:5.47e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.440, tt:6677.643\n",
      "Ep:81, loss:0.00000, loss_test:0.15365, lr:5.42e-03, fs:0.58741 (r=0.424,p=0.955),  time:82.455, tt:6761.327\n",
      "Ep:82, loss:0.00000, loss_test:0.15780, lr:5.36e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.455, tt:6843.799\n",
      "Ep:83, loss:0.00000, loss_test:0.15696, lr:5.31e-03, fs:0.60690 (r=0.444,p=0.957),  time:82.477, tt:6928.043\n",
      "Ep:84, loss:0.00000, loss_test:0.15536, lr:5.26e-03, fs:0.48855 (r=0.323,p=1.000),  time:82.448, tt:7008.048\n",
      "Ep:85, loss:0.00000, loss_test:0.15657, lr:5.20e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.470, tt:7092.411\n",
      "Ep:86, loss:0.00000, loss_test:0.15609, lr:5.15e-03, fs:0.61644 (r=0.455,p=0.957),  time:82.431, tt:7171.539\n",
      "Ep:87, loss:0.00000, loss_test:0.15428, lr:5.10e-03, fs:0.55072 (r=0.384,p=0.974),  time:82.428, tt:7253.648\n",
      "Ep:88, loss:0.00000, loss_test:0.15537, lr:5.05e-03, fs:0.49254 (r=0.333,p=0.943),  time:82.448, tt:7337.916\n",
      "Ep:89, loss:0.00000, loss_test:0.15492, lr:5.00e-03, fs:0.54676 (r=0.384,p=0.950),  time:82.455, tt:7420.974\n",
      "Ep:90, loss:0.00000, loss_test:0.15469, lr:4.95e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.451, tt:7503.073\n",
      "Ep:91, loss:0.00000, loss_test:0.15467, lr:4.90e-03, fs:0.46970 (r=0.313,p=0.939),  time:82.479, tt:7588.064\n",
      "Ep:92, loss:0.00000, loss_test:0.15365, lr:4.85e-03, fs:0.49624 (r=0.333,p=0.971),  time:82.511, tt:7673.515\n",
      "Ep:93, loss:0.00000, loss_test:0.15631, lr:4.80e-03, fs:0.61111 (r=0.444,p=0.978),  time:82.501, tt:7755.094\n",
      "Ep:94, loss:0.00000, loss_test:0.15395, lr:4.75e-03, fs:0.57746 (r=0.414,p=0.953),  time:82.519, tt:7839.337\n",
      "Ep:95, loss:0.00000, loss_test:0.15673, lr:4.71e-03, fs:0.48485 (r=0.323,p=0.970),  time:82.521, tt:7922.009\n",
      "Ep:96, loss:0.00000, loss_test:0.15371, lr:4.66e-03, fs:0.51852 (r=0.354,p=0.972),  time:82.512, tt:8003.668\n",
      "Ep:97, loss:0.00000, loss_test:0.15650, lr:4.61e-03, fs:0.59155 (r=0.424,p=0.977),  time:82.505, tt:8085.519\n",
      "Ep:98, loss:0.00000, loss_test:0.15469, lr:4.57e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.496, tt:8167.135\n",
      "Ep:99, loss:0.00000, loss_test:0.15564, lr:4.52e-03, fs:0.62500 (r=0.455,p=1.000),  time:82.499, tt:8249.886\n",
      "Ep:100, loss:0.00000, loss_test:0.15657, lr:4.48e-03, fs:0.48120 (r=0.323,p=0.941),  time:82.525, tt:8335.049\n",
      "Ep:101, loss:0.00000, loss_test:0.15558, lr:4.43e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.491, tt:8414.083\n",
      "Ep:102, loss:0.00000, loss_test:0.15494, lr:4.39e-03, fs:0.52941 (r=0.364,p=0.973),  time:82.495, tt:8497.018\n",
      "Ep:103, loss:0.00000, loss_test:0.15386, lr:4.34e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.447, tt:8574.469\n",
      "Ep:104, loss:0.00000, loss_test:0.15596, lr:4.30e-03, fs:0.62069 (r=0.455,p=0.978),  time:82.396, tt:8651.628\n",
      "Ep:105, loss:0.00000, loss_test:0.15579, lr:4.26e-03, fs:0.46154 (r=0.303,p=0.968),  time:82.324, tt:8726.303\n",
      "Model and results saved\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 4\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 3552 Test samples: 198\n",
      "Train positive samples: 1776 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00054, loss_test:0.14346, lr:1.00e-02, fs:0.66202 (r=0.960,p=0.505),  time:68.040, tt:68.040\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00051, loss_test:0.13653, lr:1.00e-02, fs:0.65370 (r=0.848,p=0.532),  time:65.573, tt:131.147\n",
      "Ep:2, loss:0.00048, loss_test:0.13598, lr:1.00e-02, fs:0.59322 (r=0.707,p=0.511),  time:68.563, tt:205.690\n",
      "Ep:3, loss:0.00046, loss_test:0.13344, lr:1.00e-02, fs:0.56881 (r=0.626,p=0.521),  time:70.104, tt:280.415\n",
      "Ep:4, loss:0.00043, loss_test:0.12856, lr:1.00e-02, fs:0.58879 (r=0.636,p=0.548),  time:71.819, tt:359.095\n",
      "Ep:5, loss:0.00041, loss_test:0.12308, lr:1.00e-02, fs:0.61611 (r=0.657,p=0.580),  time:72.375, tt:434.250\n",
      "Ep:6, loss:0.00038, loss_test:0.11541, lr:1.00e-02, fs:0.67925 (r=0.727,p=0.637),  time:72.938, tt:510.565\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00036, loss_test:0.11190, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:73.129, tt:585.030\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00034, loss_test:0.10831, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:73.234, tt:659.103\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00032, loss_test:0.10536, lr:1.00e-02, fs:0.72464 (r=0.758,p=0.694),  time:73.553, tt:735.535\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00031, loss_test:0.10690, lr:1.00e-02, fs:0.71357 (r=0.717,p=0.710),  time:73.731, tt:811.037\n",
      "Ep:11, loss:0.00029, loss_test:0.10496, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:73.833, tt:885.996\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00027, loss_test:0.10322, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:73.870, tt:960.313\n",
      "Ep:13, loss:0.00025, loss_test:0.10748, lr:1.00e-02, fs:0.70899 (r=0.677,p=0.744),  time:74.029, tt:1036.399\n",
      "Ep:14, loss:0.00024, loss_test:0.10363, lr:1.00e-02, fs:0.72632 (r=0.697,p=0.758),  time:73.984, tt:1109.756\n",
      "Ep:15, loss:0.00022, loss_test:0.10377, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:74.134, tt:1186.150\n",
      "Ep:16, loss:0.00021, loss_test:0.10389, lr:1.00e-02, fs:0.71351 (r=0.667,p=0.767),  time:74.234, tt:1261.981\n",
      "Ep:17, loss:0.00019, loss_test:0.10424, lr:1.00e-02, fs:0.70652 (r=0.657,p=0.765),  time:74.249, tt:1336.481\n",
      "Ep:18, loss:0.00018, loss_test:0.10640, lr:1.00e-02, fs:0.68182 (r=0.606,p=0.779),  time:74.205, tt:1409.900\n",
      "Ep:19, loss:0.00017, loss_test:0.10890, lr:1.00e-02, fs:0.69318 (r=0.616,p=0.792),  time:74.306, tt:1486.115\n",
      "Ep:20, loss:0.00016, loss_test:0.10731, lr:1.00e-02, fs:0.68182 (r=0.606,p=0.779),  time:74.279, tt:1559.869\n",
      "Ep:21, loss:0.00014, loss_test:0.11489, lr:1.00e-02, fs:0.68966 (r=0.606,p=0.800),  time:74.264, tt:1633.798\n",
      "Ep:22, loss:0.00013, loss_test:0.11971, lr:1.00e-02, fs:0.67836 (r=0.586,p=0.806),  time:74.261, tt:1708.014\n",
      "Ep:23, loss:0.00013, loss_test:0.11550, lr:9.90e-03, fs:0.69006 (r=0.596,p=0.819),  time:74.211, tt:1781.067\n",
      "Ep:24, loss:0.00012, loss_test:0.11690, lr:9.80e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.252, tt:1856.294\n",
      "Ep:25, loss:0.00011, loss_test:0.11623, lr:9.70e-03, fs:0.68605 (r=0.596,p=0.808),  time:74.219, tt:1929.689\n",
      "Ep:26, loss:0.00011, loss_test:0.11958, lr:9.61e-03, fs:0.68639 (r=0.586,p=0.829),  time:74.195, tt:2003.269\n",
      "Ep:27, loss:0.00010, loss_test:0.11922, lr:9.51e-03, fs:0.68235 (r=0.586,p=0.817),  time:74.169, tt:2076.740\n",
      "Ep:28, loss:0.00010, loss_test:0.12519, lr:9.41e-03, fs:0.68639 (r=0.586,p=0.829),  time:74.206, tt:2151.987\n",
      "Ep:29, loss:0.00009, loss_test:0.12733, lr:9.32e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.220, tt:2226.610\n",
      "Ep:30, loss:0.00009, loss_test:0.12911, lr:9.23e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.231, tt:2301.158\n",
      "Ep:31, loss:0.00008, loss_test:0.12295, lr:9.14e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.252, tt:2376.057\n",
      "Ep:32, loss:0.00008, loss_test:0.12940, lr:9.04e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.260, tt:2450.585\n",
      "Ep:33, loss:0.00007, loss_test:0.12504, lr:8.95e-03, fs:0.69048 (r=0.586,p=0.841),  time:74.275, tt:2525.351\n",
      "Ep:34, loss:0.00007, loss_test:0.12532, lr:8.86e-03, fs:0.67456 (r=0.576,p=0.814),  time:74.299, tt:2600.474\n",
      "Ep:35, loss:0.00007, loss_test:0.12601, lr:8.78e-03, fs:0.68235 (r=0.586,p=0.817),  time:74.326, tt:2675.740\n",
      "Ep:36, loss:0.00007, loss_test:0.12726, lr:8.69e-03, fs:0.69880 (r=0.586,p=0.866),  time:74.392, tt:2752.501\n",
      "Ep:37, loss:0.00006, loss_test:0.13007, lr:8.60e-03, fs:0.70732 (r=0.586,p=0.892),  time:74.353, tt:2825.403\n",
      "Ep:38, loss:0.00006, loss_test:0.12985, lr:8.51e-03, fs:0.70732 (r=0.586,p=0.892),  time:74.302, tt:2897.789\n",
      "Ep:39, loss:0.00006, loss_test:0.13052, lr:8.43e-03, fs:0.70732 (r=0.586,p=0.892),  time:74.307, tt:2972.284\n",
      "Ep:40, loss:0.00006, loss_test:0.13213, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:74.316, tt:3046.966\n",
      "Ep:41, loss:0.00005, loss_test:0.12794, lr:8.26e-03, fs:0.70732 (r=0.586,p=0.892),  time:74.276, tt:3119.578\n",
      "Ep:42, loss:0.00005, loss_test:0.13221, lr:8.18e-03, fs:0.70732 (r=0.586,p=0.892),  time:74.254, tt:3192.942\n",
      "Ep:43, loss:0.00005, loss_test:0.12975, lr:8.10e-03, fs:0.69939 (r=0.576,p=0.891),  time:74.267, tt:3267.746\n",
      "Ep:44, loss:0.00005, loss_test:0.13219, lr:8.02e-03, fs:0.69939 (r=0.576,p=0.891),  time:74.255, tt:3341.462\n",
      "Ep:45, loss:0.00004, loss_test:0.13504, lr:7.94e-03, fs:0.57718 (r=0.434,p=0.860),  time:74.278, tt:3416.768\n",
      "Ep:46, loss:0.00004, loss_test:0.13513, lr:7.86e-03, fs:0.56757 (r=0.424,p=0.857),  time:74.299, tt:3492.042\n",
      "Ep:47, loss:0.00004, loss_test:0.13591, lr:7.78e-03, fs:0.67500 (r=0.545,p=0.885),  time:74.280, tt:3565.426\n",
      "Ep:48, loss:0.00004, loss_test:0.13489, lr:7.70e-03, fs:0.65409 (r=0.525,p=0.867),  time:74.313, tt:3641.317\n",
      "Ep:49, loss:0.00004, loss_test:0.13673, lr:7.62e-03, fs:0.65385 (r=0.515,p=0.895),  time:74.315, tt:3715.735\n",
      "Ep:50, loss:0.00004, loss_test:0.13788, lr:7.55e-03, fs:0.57718 (r=0.434,p=0.860),  time:74.323, tt:3790.457\n",
      "Ep:51, loss:0.00004, loss_test:0.13472, lr:7.47e-03, fs:0.58108 (r=0.434,p=0.878),  time:74.350, tt:3866.175\n",
      "Ep:52, loss:0.00004, loss_test:0.14120, lr:7.40e-03, fs:0.63158 (r=0.485,p=0.906),  time:74.415, tt:3943.975\n",
      "Ep:53, loss:0.00003, loss_test:0.13579, lr:7.32e-03, fs:0.67516 (r=0.535,p=0.914),  time:74.421, tt:4018.714\n",
      "Ep:54, loss:0.00003, loss_test:0.13849, lr:7.25e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.475, tt:4096.133\n",
      "Ep:55, loss:0.00003, loss_test:0.13649, lr:7.18e-03, fs:0.65806 (r=0.515,p=0.911),  time:74.466, tt:4170.116\n",
      "Ep:56, loss:0.00003, loss_test:0.13945, lr:7.11e-03, fs:0.63158 (r=0.485,p=0.906),  time:74.475, tt:4245.062\n",
      "Ep:57, loss:0.00003, loss_test:0.13761, lr:7.03e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.533, tt:4322.917\n",
      "Ep:58, loss:0.00003, loss_test:0.13710, lr:6.96e-03, fs:0.68750 (r=0.556,p=0.902),  time:74.463, tt:4393.288\n",
      "Ep:59, loss:0.00003, loss_test:0.13997, lr:6.89e-03, fs:0.65806 (r=0.515,p=0.911),  time:74.427, tt:4465.618\n",
      "Ep:60, loss:0.00003, loss_test:0.14136, lr:6.83e-03, fs:0.53521 (r=0.384,p=0.884),  time:74.438, tt:4540.714\n",
      "Ep:61, loss:0.00003, loss_test:0.14186, lr:6.76e-03, fs:0.64052 (r=0.495,p=0.907),  time:74.421, tt:4614.098\n",
      "Ep:62, loss:0.00003, loss_test:0.14199, lr:6.69e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.418, tt:4688.357\n",
      "Ep:63, loss:0.00003, loss_test:0.14016, lr:6.62e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.420, tt:4762.889\n",
      "Ep:64, loss:0.00003, loss_test:0.14273, lr:6.56e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.427, tt:4837.779\n",
      "Ep:65, loss:0.00002, loss_test:0.14297, lr:6.49e-03, fs:0.64052 (r=0.495,p=0.907),  time:74.447, tt:4913.498\n",
      "Ep:66, loss:0.00002, loss_test:0.14044, lr:6.43e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.456, tt:4988.561\n",
      "Ep:67, loss:0.00002, loss_test:0.14510, lr:6.36e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.457, tt:5063.077\n",
      "Ep:68, loss:0.00002, loss_test:0.14257, lr:6.30e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.501, tt:5140.547\n",
      "Ep:69, loss:0.00002, loss_test:0.14220, lr:6.24e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.534, tt:5217.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00002, loss_test:0.14390, lr:6.17e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.552, tt:5293.169\n",
      "Ep:71, loss:0.00002, loss_test:0.14356, lr:6.11e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.557, tt:5368.092\n",
      "Ep:72, loss:0.00002, loss_test:0.14436, lr:6.05e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.545, tt:5441.754\n",
      "Ep:73, loss:0.00002, loss_test:0.14455, lr:5.99e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.528, tt:5515.058\n",
      "Ep:74, loss:0.00002, loss_test:0.14444, lr:5.93e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.553, tt:5591.509\n",
      "Ep:75, loss:0.00002, loss_test:0.14420, lr:5.87e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.591, tt:5668.897\n",
      "Ep:76, loss:0.00002, loss_test:0.14414, lr:5.81e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.632, tt:5746.631\n",
      "Ep:77, loss:0.00002, loss_test:0.14479, lr:5.75e-03, fs:0.64474 (r=0.495,p=0.925),  time:74.616, tt:5820.054\n",
      "Ep:78, loss:0.00002, loss_test:0.14436, lr:5.70e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.662, tt:5898.268\n",
      "Ep:79, loss:0.00002, loss_test:0.14394, lr:5.64e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.672, tt:5973.762\n",
      "Ep:80, loss:0.00002, loss_test:0.14223, lr:5.58e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.670, tt:6048.306\n",
      "Ep:81, loss:0.00002, loss_test:0.14505, lr:5.53e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.689, tt:6124.501\n",
      "Ep:82, loss:0.00002, loss_test:0.14488, lr:5.47e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.655, tt:6196.353\n",
      "Ep:83, loss:0.00002, loss_test:0.14516, lr:5.42e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.645, tt:6270.197\n",
      "Ep:84, loss:0.00002, loss_test:0.14497, lr:5.36e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.665, tt:6346.500\n",
      "Ep:85, loss:0.00002, loss_test:0.14475, lr:5.31e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.685, tt:6422.868\n",
      "Ep:86, loss:0.00002, loss_test:0.14535, lr:5.26e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.690, tt:6498.032\n",
      "Ep:87, loss:0.00001, loss_test:0.14532, lr:5.20e-03, fs:0.50360 (r=0.354,p=0.875),  time:74.700, tt:6573.633\n",
      "Ep:88, loss:0.00002, loss_test:0.14742, lr:5.15e-03, fs:0.50360 (r=0.354,p=0.875),  time:74.716, tt:6649.701\n",
      "Ep:89, loss:0.00002, loss_test:0.14588, lr:5.10e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.770, tt:6729.275\n",
      "Ep:90, loss:0.00001, loss_test:0.14539, lr:5.05e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.784, tt:6805.386\n",
      "Ep:91, loss:0.00001, loss_test:0.14510, lr:5.00e-03, fs:0.57534 (r=0.424,p=0.894),  time:74.787, tt:6880.386\n",
      "Ep:92, loss:0.00001, loss_test:0.14464, lr:4.95e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.803, tt:6956.682\n",
      "Ep:93, loss:0.00001, loss_test:0.14385, lr:4.90e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.823, tt:7033.380\n",
      "Ep:94, loss:0.00001, loss_test:0.14465, lr:4.85e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.812, tt:7107.139\n",
      "Ep:95, loss:0.00001, loss_test:0.14612, lr:4.80e-03, fs:0.50725 (r=0.354,p=0.897),  time:74.801, tt:7180.886\n",
      "Ep:96, loss:0.00001, loss_test:0.14514, lr:4.75e-03, fs:0.62252 (r=0.475,p=0.904),  time:74.809, tt:7256.493\n",
      "Ep:97, loss:0.00001, loss_test:0.14405, lr:4.71e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.799, tt:7330.344\n",
      "Ep:98, loss:0.00001, loss_test:0.14324, lr:4.66e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.780, tt:7403.248\n",
      "Ep:99, loss:0.00001, loss_test:0.14364, lr:4.61e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.798, tt:7479.791\n",
      "Ep:100, loss:0.00001, loss_test:0.14393, lr:4.57e-03, fs:0.62252 (r=0.475,p=0.904),  time:74.772, tt:7552.005\n",
      "Ep:101, loss:0.00001, loss_test:0.14581, lr:4.52e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.760, tt:7625.523\n",
      "Ep:102, loss:0.00001, loss_test:0.14337, lr:4.48e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.751, tt:7699.313\n",
      "Ep:103, loss:0.00001, loss_test:0.14298, lr:4.43e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.661, tt:7764.729\n",
      "Ep:104, loss:0.00001, loss_test:0.14466, lr:4.39e-03, fs:0.65359 (r=0.505,p=0.926),  time:74.558, tt:7828.628\n",
      "Ep:105, loss:0.00001, loss_test:0.14436, lr:4.34e-03, fs:0.64935 (r=0.505,p=0.909),  time:74.247, tt:7870.192\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=4,st=\"isolation\",sp=True,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,True)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,106,cv_number,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_300_250_200_150 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00013, loss_test:0.02497, lr:6.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:22.706, tt:22.706\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02498, lr:6.00e-02, fs:0.66667 (r=0.970,p=0.508),  time:24.630, tt:49.260\n",
      "Ep:2, loss:0.00005, loss_test:0.02849, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:26.393, tt:79.178\n",
      "Ep:3, loss:0.00006, loss_test:0.02909, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:28.030, tt:112.122\n",
      "Ep:4, loss:0.00006, loss_test:0.02856, lr:6.00e-02, fs:0.65986 (r=0.980,p=0.497),  time:29.379, tt:146.896\n",
      "Ep:5, loss:0.00005, loss_test:0.02799, lr:6.00e-02, fs:0.65753 (r=0.970,p=0.497),  time:30.211, tt:181.268\n",
      "Ep:6, loss:0.00005, loss_test:0.02719, lr:6.00e-02, fs:0.65505 (r=0.949,p=0.500),  time:30.938, tt:216.568\n",
      "Ep:7, loss:0.00005, loss_test:0.02634, lr:6.00e-02, fs:0.65248 (r=0.929,p=0.503),  time:31.389, tt:251.114\n",
      "Ep:8, loss:0.00005, loss_test:0.02563, lr:6.00e-02, fs:0.65683 (r=0.899,p=0.517),  time:31.664, tt:284.974\n",
      "Ep:9, loss:0.00005, loss_test:0.02509, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:31.957, tt:319.574\n",
      "Ep:10, loss:0.00005, loss_test:0.02470, lr:6.00e-02, fs:0.65414 (r=0.879,p=0.521),  time:32.119, tt:353.309\n",
      "Ep:11, loss:0.00005, loss_test:0.02444, lr:6.00e-02, fs:0.66171 (r=0.899,p=0.524),  time:32.257, tt:387.081\n",
      "Ep:12, loss:0.00005, loss_test:0.02431, lr:5.94e-02, fs:0.65934 (r=0.909,p=0.517),  time:32.376, tt:420.885\n",
      "Ep:13, loss:0.00005, loss_test:0.02402, lr:5.88e-02, fs:0.65942 (r=0.919,p=0.514),  time:32.589, tt:456.244\n",
      "Ep:14, loss:0.00005, loss_test:0.02349, lr:5.82e-02, fs:0.66423 (r=0.919,p=0.520),  time:32.651, tt:489.769\n",
      "Ep:15, loss:0.00005, loss_test:0.02286, lr:5.76e-02, fs:0.67658 (r=0.919,p=0.535),  time:32.760, tt:524.158\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00005, loss_test:0.02222, lr:5.76e-02, fs:0.67669 (r=0.909,p=0.539),  time:32.815, tt:557.847\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00005, loss_test:0.02159, lr:5.76e-02, fs:0.68441 (r=0.909,p=0.549),  time:32.876, tt:591.770\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00004, loss_test:0.02101, lr:5.76e-02, fs:0.68182 (r=0.909,p=0.545),  time:32.927, tt:625.614\n",
      "Ep:19, loss:0.00004, loss_test:0.02046, lr:5.76e-02, fs:0.67681 (r=0.899,p=0.543),  time:33.006, tt:660.127\n",
      "Ep:20, loss:0.00004, loss_test:0.01996, lr:5.76e-02, fs:0.69697 (r=0.929,p=0.558),  time:33.080, tt:694.680\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00004, loss_test:0.01950, lr:5.76e-02, fs:0.69466 (r=0.919,p=0.558),  time:33.141, tt:729.112\n",
      "Ep:22, loss:0.00004, loss_test:0.01903, lr:5.76e-02, fs:0.69498 (r=0.909,p=0.562),  time:33.241, tt:764.553\n",
      "Ep:23, loss:0.00004, loss_test:0.01874, lr:5.76e-02, fs:0.69231 (r=0.909,p=0.559),  time:33.355, tt:800.518\n",
      "Ep:24, loss:0.00004, loss_test:0.01853, lr:5.76e-02, fs:0.70000 (r=0.919,p=0.565),  time:33.423, tt:835.570\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00004, loss_test:0.01833, lr:5.76e-02, fs:0.70039 (r=0.909,p=0.570),  time:33.471, tt:870.237\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00004, loss_test:0.01806, lr:5.76e-02, fs:0.70079 (r=0.899,p=0.574),  time:33.587, tt:906.840\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00004, loss_test:0.01780, lr:5.76e-02, fs:0.69355 (r=0.869,p=0.577),  time:33.584, tt:940.341\n",
      "Ep:28, loss:0.00003, loss_test:0.01749, lr:5.76e-02, fs:0.68800 (r=0.869,p=0.570),  time:33.627, tt:975.189\n",
      "Ep:29, loss:0.00003, loss_test:0.01728, lr:5.76e-02, fs:0.68826 (r=0.859,p=0.574),  time:33.640, tt:1009.212\n",
      "Ep:30, loss:0.00003, loss_test:0.01707, lr:5.76e-02, fs:0.69636 (r=0.869,p=0.581),  time:33.693, tt:1044.476\n",
      "Ep:31, loss:0.00003, loss_test:0.01682, lr:5.76e-02, fs:0.69919 (r=0.869,p=0.585),  time:33.710, tt:1078.710\n",
      "Ep:32, loss:0.00003, loss_test:0.01667, lr:5.76e-02, fs:0.70445 (r=0.879,p=0.588),  time:33.732, tt:1113.143\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00003, loss_test:0.01637, lr:5.76e-02, fs:0.71020 (r=0.879,p=0.596),  time:33.733, tt:1146.936\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00003, loss_test:0.01609, lr:5.76e-02, fs:0.70782 (r=0.869,p=0.597),  time:33.716, tt:1180.049\n",
      "Ep:35, loss:0.00003, loss_test:0.01584, lr:5.76e-02, fs:0.71074 (r=0.869,p=0.601),  time:33.759, tt:1215.325\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00003, loss_test:0.01569, lr:5.76e-02, fs:0.70492 (r=0.869,p=0.593),  time:33.792, tt:1250.289\n",
      "Ep:37, loss:0.00003, loss_test:0.01532, lr:5.76e-02, fs:0.71311 (r=0.879,p=0.600),  time:33.822, tt:1285.238\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00003, loss_test:0.01512, lr:5.76e-02, fs:0.73029 (r=0.889,p=0.620),  time:33.876, tt:1321.177\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00003, loss_test:0.01493, lr:5.76e-02, fs:0.74790 (r=0.899,p=0.640),  time:33.900, tt:1355.995\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00003, loss_test:0.01455, lr:5.76e-02, fs:0.75745 (r=0.899,p=0.654),  time:33.926, tt:1390.983\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00003, loss_test:0.01437, lr:5.76e-02, fs:0.76395 (r=0.899,p=0.664),  time:33.953, tt:1426.025\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00003, loss_test:0.01413, lr:5.76e-02, fs:0.76068 (r=0.899,p=0.659),  time:33.998, tt:1461.925\n",
      "Ep:43, loss:0.00002, loss_test:0.01382, lr:5.76e-02, fs:0.76271 (r=0.909,p=0.657),  time:34.031, tt:1497.384\n",
      "Ep:44, loss:0.00002, loss_test:0.01372, lr:5.76e-02, fs:0.76596 (r=0.909,p=0.662),  time:34.044, tt:1531.962\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00002, loss_test:0.01344, lr:5.76e-02, fs:0.77119 (r=0.919,p=0.664),  time:34.059, tt:1566.707\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00002, loss_test:0.01362, lr:5.76e-02, fs:0.77778 (r=0.919,p=0.674),  time:34.079, tt:1601.691\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01323, lr:5.76e-02, fs:0.78448 (r=0.919,p=0.684),  time:34.083, tt:1635.969\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01308, lr:5.76e-02, fs:0.78970 (r=0.929,p=0.687),  time:34.127, tt:1672.222\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00002, loss_test:0.01294, lr:5.76e-02, fs:0.80000 (r=0.929,p=0.702),  time:34.142, tt:1707.116\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00002, loss_test:0.01299, lr:5.76e-02, fs:0.79654 (r=0.929,p=0.697),  time:34.147, tt:1741.505\n",
      "Ep:51, loss:0.00002, loss_test:0.01268, lr:5.76e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.165, tt:1776.580\n",
      "##########Best model found so far##########\n",
      "Ep:52, loss:0.00002, loss_test:0.01268, lr:5.76e-02, fs:0.80349 (r=0.929,p=0.708),  time:34.207, tt:1812.965\n",
      "Ep:53, loss:0.00002, loss_test:0.01246, lr:5.76e-02, fs:0.80702 (r=0.929,p=0.713),  time:34.214, tt:1847.561\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00002, loss_test:0.01228, lr:5.76e-02, fs:0.80176 (r=0.919,p=0.711),  time:34.228, tt:1882.548\n",
      "Ep:55, loss:0.00002, loss_test:0.01279, lr:5.76e-02, fs:0.81223 (r=0.939,p=0.715),  time:34.249, tt:1917.960\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00002, loss_test:0.01194, lr:5.76e-02, fs:0.80702 (r=0.929,p=0.713),  time:34.255, tt:1952.534\n",
      "Ep:57, loss:0.00002, loss_test:0.01329, lr:5.76e-02, fs:0.80531 (r=0.919,p=0.717),  time:34.283, tt:1988.419\n",
      "Ep:58, loss:0.00002, loss_test:0.01161, lr:5.76e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.289, tt:2023.041\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:59, loss:0.00001, loss_test:0.01211, lr:5.76e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.318, tt:2059.056\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00001, loss_test:0.01180, lr:5.76e-02, fs:0.82667 (r=0.939,p=0.738),  time:34.347, tt:2095.171\n",
      "Ep:61, loss:0.00001, loss_test:0.01156, lr:5.76e-02, fs:0.82727 (r=0.919,p=0.752),  time:34.357, tt:2130.139\n",
      "Ep:62, loss:0.00001, loss_test:0.01324, lr:5.76e-02, fs:0.79821 (r=0.899,p=0.718),  time:34.346, tt:2163.782\n",
      "Ep:63, loss:0.00001, loss_test:0.01146, lr:5.76e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.346, tt:2198.122\n",
      "Ep:64, loss:0.00001, loss_test:0.01150, lr:5.76e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.351, tt:2232.808\n",
      "Ep:65, loss:0.00001, loss_test:0.01143, lr:5.76e-02, fs:0.83105 (r=0.919,p=0.758),  time:34.342, tt:2266.579\n",
      "Ep:66, loss:0.00001, loss_test:0.01121, lr:5.76e-02, fs:0.83784 (r=0.939,p=0.756),  time:34.368, tt:2302.655\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01284, lr:5.76e-02, fs:0.82629 (r=0.889,p=0.772),  time:34.380, tt:2337.849\n",
      "Ep:68, loss:0.00001, loss_test:0.01057, lr:5.76e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.384, tt:2372.489\n",
      "Ep:69, loss:0.00001, loss_test:0.01210, lr:5.76e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.400, tt:2407.966\n",
      "Ep:70, loss:0.00001, loss_test:0.01102, lr:5.76e-02, fs:0.84507 (r=0.909,p=0.789),  time:34.414, tt:2443.370\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01180, lr:5.76e-02, fs:0.83568 (r=0.899,p=0.781),  time:34.421, tt:2478.288\n",
      "Ep:72, loss:0.00001, loss_test:0.01209, lr:5.76e-02, fs:0.83654 (r=0.879,p=0.798),  time:34.459, tt:2515.524\n",
      "Ep:73, loss:0.00001, loss_test:0.01112, lr:5.76e-02, fs:0.84360 (r=0.899,p=0.795),  time:34.468, tt:2550.612\n",
      "Ep:74, loss:0.00001, loss_test:0.01161, lr:5.76e-02, fs:0.83412 (r=0.889,p=0.786),  time:34.464, tt:2584.834\n",
      "Ep:75, loss:0.00001, loss_test:0.01127, lr:5.76e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.464, tt:2619.242\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01060, lr:5.76e-02, fs:0.86385 (r=0.929,p=0.807),  time:34.472, tt:2654.361\n",
      "##########Best model found so far##########\n",
      "Ep:77, loss:0.00001, loss_test:0.01153, lr:5.76e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.471, tt:2688.773\n",
      "Ep:78, loss:0.00001, loss_test:0.01214, lr:5.76e-02, fs:0.84058 (r=0.879,p=0.806),  time:34.491, tt:2724.810\n",
      "Ep:79, loss:0.00001, loss_test:0.01079, lr:5.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:34.504, tt:2760.349\n",
      "Ep:80, loss:0.00001, loss_test:0.01129, lr:5.76e-02, fs:0.84466 (r=0.879,p=0.813),  time:34.497, tt:2794.249\n",
      "Ep:81, loss:0.00001, loss_test:0.01213, lr:5.76e-02, fs:0.83810 (r=0.889,p=0.793),  time:34.485, tt:2827.770\n",
      "Ep:82, loss:0.00001, loss_test:0.01072, lr:5.76e-02, fs:0.85308 (r=0.909,p=0.804),  time:34.475, tt:2861.394\n",
      "Ep:83, loss:0.00001, loss_test:0.00997, lr:5.76e-02, fs:0.86385 (r=0.929,p=0.807),  time:34.459, tt:2894.583\n",
      "Ep:84, loss:0.00001, loss_test:0.01185, lr:5.76e-02, fs:0.85167 (r=0.899,p=0.809),  time:34.454, tt:2928.550\n",
      "Ep:85, loss:0.00001, loss_test:0.01051, lr:5.76e-02, fs:0.85854 (r=0.889,p=0.830),  time:34.466, tt:2964.042\n",
      "Ep:86, loss:0.00001, loss_test:0.01141, lr:5.76e-02, fs:0.85581 (r=0.929,p=0.793),  time:34.463, tt:2998.312\n",
      "Ep:87, loss:0.00001, loss_test:0.01091, lr:5.76e-02, fs:0.85714 (r=0.879,p=0.837),  time:34.454, tt:3031.924\n",
      "Ep:88, loss:0.00001, loss_test:0.01203, lr:5.71e-02, fs:0.84615 (r=0.889,p=0.807),  time:34.439, tt:3065.096\n",
      "Ep:89, loss:0.00001, loss_test:0.01041, lr:5.65e-02, fs:0.87379 (r=0.909,p=0.841),  time:34.431, tt:3098.816\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01103, lr:5.65e-02, fs:0.86829 (r=0.899,p=0.840),  time:34.423, tt:3132.514\n",
      "Ep:91, loss:0.00001, loss_test:0.01059, lr:5.65e-02, fs:0.89216 (r=0.919,p=0.867),  time:34.416, tt:3166.281\n",
      "##########Best model found so far##########\n",
      "Ep:92, loss:0.00001, loss_test:0.01171, lr:5.65e-02, fs:0.88000 (r=0.889,p=0.871),  time:34.455, tt:3204.314\n",
      "Ep:93, loss:0.00001, loss_test:0.01112, lr:5.65e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.458, tt:3239.057\n",
      "Ep:94, loss:0.00001, loss_test:0.01100, lr:5.65e-02, fs:0.88670 (r=0.909,p=0.865),  time:34.449, tt:3272.700\n",
      "Ep:95, loss:0.00001, loss_test:0.01052, lr:5.65e-02, fs:0.89320 (r=0.929,p=0.860),  time:34.449, tt:3307.080\n",
      "##########Best model found so far##########\n",
      "Ep:96, loss:0.00001, loss_test:0.01051, lr:5.65e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.450, tt:3341.627\n",
      "Ep:97, loss:0.00001, loss_test:0.01329, lr:5.65e-02, fs:0.86010 (r=0.838,p=0.883),  time:34.441, tt:3375.209\n",
      "Ep:98, loss:0.00001, loss_test:0.01076, lr:5.65e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.440, tt:3409.587\n",
      "Ep:99, loss:0.00001, loss_test:0.01001, lr:5.65e-02, fs:0.88571 (r=0.939,p=0.838),  time:34.454, tt:3445.355\n",
      "Ep:100, loss:0.00001, loss_test:0.01143, lr:5.65e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.444, tt:3478.814\n",
      "Ep:101, loss:0.00001, loss_test:0.00979, lr:5.65e-02, fs:0.88152 (r=0.939,p=0.830),  time:34.462, tt:3515.168\n",
      "Ep:102, loss:0.00001, loss_test:0.00950, lr:5.65e-02, fs:0.88152 (r=0.939,p=0.830),  time:34.465, tt:3549.863\n",
      "Ep:103, loss:0.00001, loss_test:0.01122, lr:5.65e-02, fs:0.87619 (r=0.929,p=0.829),  time:34.484, tt:3586.292\n",
      "Ep:104, loss:0.00001, loss_test:0.00972, lr:5.65e-02, fs:0.88995 (r=0.939,p=0.845),  time:34.498, tt:3622.244\n",
      "Ep:105, loss:0.00001, loss_test:0.01161, lr:5.65e-02, fs:0.85024 (r=0.889,p=0.815),  time:34.510, tt:3658.073\n",
      "Ep:106, loss:0.00001, loss_test:0.00989, lr:5.65e-02, fs:0.89423 (r=0.939,p=0.853),  time:34.517, tt:3693.367\n",
      "##########Best model found so far##########\n",
      "Ep:107, loss:0.00001, loss_test:0.01127, lr:5.65e-02, fs:0.86869 (r=0.869,p=0.869),  time:34.513, tt:3727.378\n",
      "Ep:108, loss:0.00001, loss_test:0.01030, lr:5.65e-02, fs:0.87923 (r=0.919,p=0.843),  time:34.504, tt:3760.888\n",
      "Ep:109, loss:0.00001, loss_test:0.01076, lr:5.65e-02, fs:0.87685 (r=0.899,p=0.856),  time:34.494, tt:3794.324\n",
      "Ep:110, loss:0.00000, loss_test:0.01155, lr:5.65e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.503, tt:3829.822\n",
      "Ep:111, loss:0.00000, loss_test:0.01073, lr:5.65e-02, fs:0.88235 (r=0.909,p=0.857),  time:34.512, tt:3865.338\n",
      "Ep:112, loss:0.00000, loss_test:0.01182, lr:5.65e-02, fs:0.87047 (r=0.848,p=0.894),  time:34.511, tt:3899.795\n",
      "Ep:113, loss:0.00000, loss_test:0.01089, lr:5.65e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.519, tt:3935.112\n",
      "Ep:114, loss:0.00000, loss_test:0.01144, lr:5.65e-02, fs:0.88083 (r=0.859,p=0.904),  time:34.523, tt:3970.108\n",
      "Ep:115, loss:0.00000, loss_test:0.01149, lr:5.65e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.523, tt:4004.676\n",
      "Ep:116, loss:0.00000, loss_test:0.01197, lr:5.65e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.532, tt:4040.220\n",
      "Ep:117, loss:0.00000, loss_test:0.01222, lr:5.65e-02, fs:0.84656 (r=0.808,p=0.889),  time:34.534, tt:4075.012\n",
      "Ep:118, loss:0.00000, loss_test:0.01191, lr:5.59e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.536, tt:4109.768\n",
      "Ep:119, loss:0.00000, loss_test:0.01208, lr:5.54e-02, fs:0.85427 (r=0.859,p=0.850),  time:34.536, tt:4144.273\n",
      "Ep:120, loss:0.00000, loss_test:0.01207, lr:5.48e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.533, tt:4178.448\n",
      "Ep:121, loss:0.00000, loss_test:0.01148, lr:5.43e-02, fs:0.87179 (r=0.859,p=0.885),  time:34.534, tt:4213.161\n",
      "Ep:122, loss:0.00000, loss_test:0.01068, lr:5.37e-02, fs:0.89655 (r=0.919,p=0.875),  time:34.527, tt:4246.829\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01311, lr:5.37e-02, fs:0.87629 (r=0.859,p=0.895),  time:34.521, tt:4280.606\n",
      "Ep:124, loss:0.00000, loss_test:0.01116, lr:5.37e-02, fs:0.87437 (r=0.879,p=0.870),  time:34.511, tt:4313.918\n",
      "Ep:125, loss:0.00000, loss_test:0.01236, lr:5.37e-02, fs:0.85263 (r=0.818,p=0.890),  time:34.514, tt:4348.752\n",
      "Ep:126, loss:0.00000, loss_test:0.01147, lr:5.37e-02, fs:0.86458 (r=0.838,p=0.892),  time:34.507, tt:4382.363\n",
      "Ep:127, loss:0.00000, loss_test:0.01250, lr:5.37e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.500, tt:4416.035\n",
      "Ep:128, loss:0.00000, loss_test:0.01109, lr:5.37e-02, fs:0.90816 (r=0.899,p=0.918),  time:34.507, tt:4451.443\n",
      "##########Best model found so far##########\n",
      "Ep:129, loss:0.00000, loss_test:0.01283, lr:5.37e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.512, tt:4486.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:130, loss:0.00000, loss_test:0.01091, lr:5.37e-02, fs:0.91282 (r=0.899,p=0.927),  time:34.510, tt:4520.752\n",
      "##########Best model found so far##########\n",
      "Ep:131, loss:0.00000, loss_test:0.01333, lr:5.37e-02, fs:0.84043 (r=0.798,p=0.888),  time:34.531, tt:4558.114\n",
      "Ep:132, loss:0.00000, loss_test:0.01157, lr:5.37e-02, fs:0.87831 (r=0.838,p=0.922),  time:34.520, tt:4591.195\n",
      "Ep:133, loss:0.00000, loss_test:0.01355, lr:5.37e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.525, tt:4626.286\n",
      "Ep:134, loss:0.00000, loss_test:0.01161, lr:5.37e-02, fs:0.85561 (r=0.808,p=0.909),  time:34.530, tt:4661.567\n",
      "Ep:135, loss:0.00000, loss_test:0.01188, lr:5.37e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.536, tt:4696.955\n",
      "Ep:136, loss:0.00000, loss_test:0.01336, lr:5.37e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.540, tt:4731.961\n",
      "Ep:137, loss:0.00000, loss_test:0.01210, lr:5.37e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.543, tt:4767.001\n",
      "Ep:138, loss:0.00000, loss_test:0.01390, lr:5.37e-02, fs:0.81967 (r=0.758,p=0.893),  time:34.549, tt:4802.289\n",
      "Ep:139, loss:0.00000, loss_test:0.01256, lr:5.37e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.542, tt:4835.915\n",
      "Ep:140, loss:0.00000, loss_test:0.01339, lr:5.37e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.551, tt:4871.647\n",
      "Ep:141, loss:0.00000, loss_test:0.01322, lr:5.37e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.554, tt:4906.632\n",
      "Ep:142, loss:0.00000, loss_test:0.01277, lr:5.32e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.560, tt:4942.124\n",
      "Ep:143, loss:0.00000, loss_test:0.01402, lr:5.27e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.565, tt:4977.365\n",
      "Ep:144, loss:0.00000, loss_test:0.01323, lr:5.21e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.560, tt:5011.201\n",
      "Ep:145, loss:0.00000, loss_test:0.01317, lr:5.16e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.563, tt:5046.246\n",
      "Ep:146, loss:0.00000, loss_test:0.01452, lr:5.11e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.556, tt:5079.799\n",
      "Ep:147, loss:0.00000, loss_test:0.01260, lr:5.06e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.561, tt:5115.000\n",
      "Ep:148, loss:0.00000, loss_test:0.01516, lr:5.01e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.567, tt:5150.555\n",
      "Ep:149, loss:0.00000, loss_test:0.01249, lr:4.96e-02, fs:0.85405 (r=0.798,p=0.919),  time:34.578, tt:5186.674\n",
      "Ep:150, loss:0.00000, loss_test:0.01390, lr:4.91e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.579, tt:5221.432\n",
      "Ep:151, loss:0.00000, loss_test:0.01367, lr:4.86e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.584, tt:5256.816\n",
      "Ep:152, loss:0.00000, loss_test:0.01327, lr:4.81e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.580, tt:5290.730\n",
      "Ep:153, loss:0.00000, loss_test:0.01451, lr:4.76e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.580, tt:5325.317\n",
      "Ep:154, loss:0.00000, loss_test:0.01311, lr:4.71e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.583, tt:5360.293\n",
      "Ep:155, loss:0.00000, loss_test:0.01485, lr:4.67e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.585, tt:5395.205\n",
      "Ep:156, loss:0.00000, loss_test:0.01352, lr:4.62e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.588, tt:5430.243\n",
      "Ep:157, loss:0.00000, loss_test:0.01519, lr:4.57e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.588, tt:5464.963\n",
      "Ep:158, loss:0.00000, loss_test:0.01350, lr:4.53e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.588, tt:5499.567\n",
      "Ep:159, loss:0.00000, loss_test:0.01488, lr:4.48e-02, fs:0.82609 (r=0.768,p=0.894),  time:34.595, tt:5535.162\n",
      "Ep:160, loss:0.00000, loss_test:0.01411, lr:4.44e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.602, tt:5570.942\n",
      "Ep:161, loss:0.00000, loss_test:0.01444, lr:4.39e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.606, tt:5606.234\n",
      "Ep:162, loss:0.00000, loss_test:0.01476, lr:4.35e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.614, tt:5642.112\n",
      "Ep:163, loss:0.00000, loss_test:0.01391, lr:4.31e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.613, tt:5676.571\n",
      "Ep:164, loss:0.00000, loss_test:0.01527, lr:4.26e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.610, tt:5710.633\n",
      "Ep:165, loss:0.00000, loss_test:0.01392, lr:4.22e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.607, tt:5744.772\n",
      "Ep:166, loss:0.00000, loss_test:0.01531, lr:4.18e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.600, tt:5778.194\n",
      "Ep:167, loss:0.00000, loss_test:0.01442, lr:4.14e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.594, tt:5811.772\n",
      "Ep:168, loss:0.00000, loss_test:0.01527, lr:4.10e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.596, tt:5846.784\n",
      "Ep:169, loss:0.00000, loss_test:0.01457, lr:4.05e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.597, tt:5881.505\n",
      "Ep:170, loss:0.00000, loss_test:0.01533, lr:4.01e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.596, tt:5915.902\n",
      "Ep:171, loss:0.00000, loss_test:0.01469, lr:3.97e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.587, tt:5948.902\n",
      "Ep:172, loss:0.00000, loss_test:0.01555, lr:3.93e-02, fs:0.83243 (r=0.778,p=0.895),  time:34.579, tt:5982.252\n",
      "Ep:173, loss:0.00000, loss_test:0.01487, lr:3.89e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.582, tt:6017.271\n",
      "Ep:174, loss:0.00000, loss_test:0.01538, lr:3.86e-02, fs:0.83871 (r=0.788,p=0.897),  time:34.576, tt:6050.749\n",
      "Ep:175, loss:0.00000, loss_test:0.01495, lr:3.82e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.580, tt:6086.138\n",
      "Ep:176, loss:0.00000, loss_test:0.01512, lr:3.78e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.582, tt:6121.056\n",
      "Ep:177, loss:0.00000, loss_test:0.01534, lr:3.74e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.579, tt:6155.053\n",
      "Ep:178, loss:0.00000, loss_test:0.01512, lr:3.70e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.577, tt:6189.315\n",
      "Ep:179, loss:0.00000, loss_test:0.01568, lr:3.67e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.571, tt:6222.699\n",
      "Ep:180, loss:0.00000, loss_test:0.01505, lr:3.63e-02, fs:0.84492 (r=0.798,p=0.898),  time:34.565, tt:6256.253\n",
      "Ep:181, loss:0.00000, loss_test:0.01562, lr:3.59e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.564, tt:6290.650\n",
      "Ep:182, loss:0.00000, loss_test:0.01539, lr:3.56e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.560, tt:6324.558\n",
      "Ep:183, loss:0.00000, loss_test:0.01565, lr:3.52e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.556, tt:6358.214\n",
      "Ep:184, loss:0.00000, loss_test:0.01545, lr:3.49e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.556, tt:6392.896\n",
      "Ep:185, loss:0.00000, loss_test:0.01574, lr:3.45e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.556, tt:6427.488\n",
      "Ep:186, loss:0.00000, loss_test:0.01559, lr:3.42e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.550, tt:6460.816\n",
      "Ep:187, loss:0.00000, loss_test:0.01577, lr:3.38e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.541, tt:6493.619\n",
      "Ep:188, loss:0.00000, loss_test:0.01557, lr:3.35e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.537, tt:6527.545\n",
      "Ep:189, loss:0.00000, loss_test:0.01580, lr:3.32e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.531, tt:6560.936\n",
      "Ep:190, loss:0.00000, loss_test:0.01581, lr:3.28e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.530, tt:6595.150\n",
      "Ep:191, loss:0.00000, loss_test:0.01567, lr:3.25e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.527, tt:6629.184\n",
      "Ep:192, loss:0.00000, loss_test:0.01578, lr:3.22e-02, fs:0.83696 (r=0.778,p=0.906),  time:34.518, tt:6661.953\n",
      "Ep:193, loss:0.00000, loss_test:0.01596, lr:3.19e-02, fs:0.84946 (r=0.798,p=0.908),  time:34.490, tt:6691.125\n",
      "Ep:194, loss:0.00000, loss_test:0.01573, lr:3.15e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.479, tt:6723.336\n",
      "Ep:195, loss:0.00000, loss_test:0.01581, lr:3.12e-02, fs:0.84324 (r=0.788,p=0.907),  time:34.446, tt:6751.494\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.02049, lr:6.00e-02, fs:0.61832 (r=0.818,p=0.497),  time:27.644, tt:27.644\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02261, lr:6.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:26.629, tt:53.257\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00004, loss_test:0.02444, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.204, tt:81.611\n",
      "Ep:3, loss:0.00005, loss_test:0.02467, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.217, tt:108.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:4, loss:0.00005, loss_test:0.02424, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:27.818, tt:139.090\n",
      "Ep:5, loss:0.00005, loss_test:0.02331, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:28.022, tt:168.130\n",
      "Ep:6, loss:0.00004, loss_test:0.02203, lr:6.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:28.069, tt:196.485\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00004, loss_test:0.02078, lr:6.00e-02, fs:0.65493 (r=0.939,p=0.503),  time:28.195, tt:225.563\n",
      "Ep:8, loss:0.00004, loss_test:0.01979, lr:6.00e-02, fs:0.65455 (r=0.909,p=0.511),  time:28.421, tt:255.790\n",
      "Ep:9, loss:0.00004, loss_test:0.01913, lr:6.00e-02, fs:0.62642 (r=0.838,p=0.500),  time:28.556, tt:285.557\n",
      "Ep:10, loss:0.00004, loss_test:0.01863, lr:6.00e-02, fs:0.66135 (r=0.838,p=0.546),  time:28.672, tt:315.389\n",
      "Ep:11, loss:0.00004, loss_test:0.01820, lr:6.00e-02, fs:0.66932 (r=0.848,p=0.553),  time:28.683, tt:344.200\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00004, loss_test:0.01788, lr:6.00e-02, fs:0.67704 (r=0.879,p=0.551),  time:28.835, tt:374.849\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00003, loss_test:0.01764, lr:6.00e-02, fs:0.68199 (r=0.899,p=0.549),  time:28.950, tt:405.295\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00003, loss_test:0.01737, lr:6.00e-02, fs:0.68939 (r=0.919,p=0.552),  time:29.041, tt:435.621\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01710, lr:6.00e-02, fs:0.69732 (r=0.919,p=0.562),  time:29.176, tt:466.811\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00003, loss_test:0.01681, lr:6.00e-02, fs:0.70000 (r=0.919,p=0.565),  time:29.243, tt:497.129\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01651, lr:6.00e-02, fs:0.70769 (r=0.929,p=0.571),  time:29.323, tt:527.817\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01622, lr:6.00e-02, fs:0.70039 (r=0.909,p=0.570),  time:29.441, tt:559.375\n",
      "Ep:19, loss:0.00003, loss_test:0.01596, lr:6.00e-02, fs:0.70079 (r=0.899,p=0.574),  time:29.482, tt:589.630\n",
      "Ep:20, loss:0.00003, loss_test:0.01572, lr:6.00e-02, fs:0.70916 (r=0.899,p=0.586),  time:29.520, tt:619.929\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01552, lr:6.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:29.527, tt:649.600\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01533, lr:6.00e-02, fs:0.72581 (r=0.909,p=0.604),  time:29.613, tt:681.095\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01514, lr:6.00e-02, fs:0.73171 (r=0.909,p=0.612),  time:29.658, tt:711.788\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01495, lr:6.00e-02, fs:0.74897 (r=0.919,p=0.632),  time:29.727, tt:743.177\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00003, loss_test:0.01477, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:29.782, tt:774.334\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00003, loss_test:0.01460, lr:6.00e-02, fs:0.76543 (r=0.939,p=0.646),  time:29.794, tt:804.431\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00003, loss_test:0.01445, lr:6.00e-02, fs:0.77500 (r=0.939,p=0.660),  time:29.871, tt:836.388\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00003, loss_test:0.01430, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:29.907, tt:867.289\n",
      "Ep:29, loss:0.00002, loss_test:0.01416, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:29.909, tt:897.263\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01403, lr:6.00e-02, fs:0.77824 (r=0.939,p=0.664),  time:29.980, tt:929.383\n",
      "Ep:31, loss:0.00002, loss_test:0.01390, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:29.992, tt:959.750\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01379, lr:6.00e-02, fs:0.79149 (r=0.939,p=0.684),  time:30.042, tt:991.371\n",
      "Ep:33, loss:0.00002, loss_test:0.01367, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:30.081, tt:1022.739\n",
      "Ep:34, loss:0.00002, loss_test:0.01357, lr:6.00e-02, fs:0.78814 (r=0.939,p=0.679),  time:30.102, tt:1053.570\n",
      "Ep:35, loss:0.00002, loss_test:0.01346, lr:6.00e-02, fs:0.79661 (r=0.949,p=0.686),  time:30.117, tt:1084.217\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00002, loss_test:0.01335, lr:6.00e-02, fs:0.80000 (r=0.949,p=0.691),  time:30.128, tt:1114.750\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01323, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:30.203, tt:1147.714\n",
      "Ep:38, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:30.242, tt:1179.430\n",
      "Ep:39, loss:0.00002, loss_test:0.01301, lr:6.00e-02, fs:0.79828 (r=0.939,p=0.694),  time:30.272, tt:1210.889\n",
      "Ep:40, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.285, tt:1241.699\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01283, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:30.359, tt:1275.064\n",
      "Ep:42, loss:0.00002, loss_test:0.01275, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.337, tt:1304.512\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01267, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.351, tt:1335.462\n",
      "Ep:44, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.373, tt:1366.807\n",
      "Ep:45, loss:0.00002, loss_test:0.01253, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:30.392, tt:1398.009\n",
      "Ep:46, loss:0.00002, loss_test:0.01246, lr:6.00e-02, fs:0.82251 (r=0.960,p=0.720),  time:30.421, tt:1429.792\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00002, loss_test:0.01238, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.450, tt:1461.608\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00002, loss_test:0.01232, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.462, tt:1492.636\n",
      "Ep:49, loss:0.00002, loss_test:0.01226, lr:6.00e-02, fs:0.82609 (r=0.960,p=0.725),  time:30.458, tt:1522.875\n",
      "Ep:50, loss:0.00002, loss_test:0.01219, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.445, tt:1552.720\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00002, loss_test:0.01213, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.457, tt:1583.749\n",
      "Ep:52, loss:0.00002, loss_test:0.01207, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.447, tt:1613.688\n",
      "Ep:53, loss:0.00002, loss_test:0.01202, lr:6.00e-02, fs:0.82969 (r=0.960,p=0.731),  time:30.444, tt:1643.960\n",
      "Ep:54, loss:0.00002, loss_test:0.01199, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.452, tt:1674.874\n",
      "Ep:55, loss:0.00002, loss_test:0.01194, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.449, tt:1705.158\n",
      "Ep:56, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.442, tt:1735.168\n",
      "Ep:57, loss:0.00002, loss_test:0.01185, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.441, tt:1765.579\n",
      "Ep:58, loss:0.00002, loss_test:0.01179, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.444, tt:1796.175\n",
      "Ep:59, loss:0.00001, loss_test:0.01173, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.484, tt:1829.051\n",
      "Ep:60, loss:0.00001, loss_test:0.01168, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:30.502, tt:1860.627\n",
      "Ep:61, loss:0.00001, loss_test:0.01163, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.497, tt:1890.810\n",
      "Ep:62, loss:0.00001, loss_test:0.01159, lr:5.94e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.526, tt:1923.144\n",
      "Ep:63, loss:0.00001, loss_test:0.01155, lr:5.88e-02, fs:0.82819 (r=0.949,p=0.734),  time:30.518, tt:1953.147\n",
      "Ep:64, loss:0.00001, loss_test:0.01151, lr:5.82e-02, fs:0.81778 (r=0.929,p=0.730),  time:30.528, tt:1984.305\n",
      "Ep:65, loss:0.00001, loss_test:0.01147, lr:5.76e-02, fs:0.81778 (r=0.929,p=0.730),  time:30.519, tt:2014.228\n",
      "Ep:66, loss:0.00001, loss_test:0.01145, lr:5.71e-02, fs:0.81778 (r=0.929,p=0.730),  time:30.524, tt:2045.098\n",
      "Ep:67, loss:0.00001, loss_test:0.01142, lr:5.65e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.518, tt:2075.236\n",
      "Ep:68, loss:0.00001, loss_test:0.01137, lr:5.59e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.521, tt:2105.964\n",
      "Ep:69, loss:0.00001, loss_test:0.01133, lr:5.54e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.523, tt:2136.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:70, loss:0.00001, loss_test:0.01129, lr:5.48e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.536, tt:2168.055\n",
      "Ep:71, loss:0.00001, loss_test:0.01126, lr:5.43e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.538, tt:2198.726\n",
      "Ep:72, loss:0.00001, loss_test:0.01123, lr:5.37e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.528, tt:2228.573\n",
      "Ep:73, loss:0.00001, loss_test:0.01120, lr:5.32e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.529, tt:2259.177\n",
      "Ep:74, loss:0.00001, loss_test:0.01118, lr:5.27e-02, fs:0.82511 (r=0.929,p=0.742),  time:30.523, tt:2289.261\n",
      "Ep:75, loss:0.00001, loss_test:0.01114, lr:5.21e-02, fs:0.82143 (r=0.929,p=0.736),  time:30.508, tt:2318.608\n",
      "Ep:76, loss:0.00001, loss_test:0.01111, lr:5.16e-02, fs:0.82511 (r=0.929,p=0.742),  time:30.514, tt:2349.563\n",
      "Ep:77, loss:0.00001, loss_test:0.01109, lr:5.11e-02, fs:0.82511 (r=0.929,p=0.742),  time:30.490, tt:2378.223\n",
      "Ep:78, loss:0.00001, loss_test:0.01107, lr:5.06e-02, fs:0.82883 (r=0.929,p=0.748),  time:30.487, tt:2408.439\n",
      "Ep:79, loss:0.00001, loss_test:0.01104, lr:5.01e-02, fs:0.82883 (r=0.929,p=0.748),  time:30.484, tt:2438.733\n",
      "Ep:80, loss:0.00001, loss_test:0.01100, lr:4.96e-02, fs:0.82883 (r=0.929,p=0.748),  time:30.470, tt:2468.097\n",
      "Ep:81, loss:0.00001, loss_test:0.01099, lr:4.91e-02, fs:0.83258 (r=0.929,p=0.754),  time:30.472, tt:2498.720\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01098, lr:4.91e-02, fs:0.83258 (r=0.929,p=0.754),  time:30.455, tt:2527.783\n",
      "Ep:83, loss:0.00001, loss_test:0.01096, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.446, tt:2557.462\n",
      "##########Best model found so far##########\n",
      "Ep:84, loss:0.00001, loss_test:0.01093, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.450, tt:2588.244\n",
      "Ep:85, loss:0.00001, loss_test:0.01091, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.433, tt:2617.267\n",
      "Ep:86, loss:0.00001, loss_test:0.01090, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.427, tt:2647.185\n",
      "Ep:87, loss:0.00001, loss_test:0.01089, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.430, tt:2677.805\n",
      "Ep:88, loss:0.00001, loss_test:0.01085, lr:4.91e-02, fs:0.84018 (r=0.929,p=0.767),  time:30.420, tt:2707.357\n",
      "Ep:89, loss:0.00001, loss_test:0.01084, lr:4.91e-02, fs:0.84404 (r=0.929,p=0.773),  time:30.410, tt:2736.856\n",
      "##########Best model found so far##########\n",
      "Ep:90, loss:0.00001, loss_test:0.01081, lr:4.91e-02, fs:0.84404 (r=0.929,p=0.773),  time:30.410, tt:2767.303\n",
      "Ep:91, loss:0.00001, loss_test:0.01080, lr:4.91e-02, fs:0.84404 (r=0.929,p=0.773),  time:30.400, tt:2796.783\n",
      "Ep:92, loss:0.00001, loss_test:0.01078, lr:4.91e-02, fs:0.84404 (r=0.929,p=0.773),  time:30.387, tt:2825.997\n",
      "Ep:93, loss:0.00001, loss_test:0.01078, lr:4.91e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.380, tt:2855.747\n",
      "##########Best model found so far##########\n",
      "Ep:94, loss:0.00001, loss_test:0.01076, lr:4.91e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.376, tt:2885.677\n",
      "Ep:95, loss:0.00001, loss_test:0.01073, lr:4.91e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.360, tt:2914.544\n",
      "Ep:96, loss:0.00001, loss_test:0.01072, lr:4.91e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.371, tt:2945.971\n",
      "Ep:97, loss:0.00001, loss_test:0.01072, lr:4.91e-02, fs:0.84793 (r=0.929,p=0.780),  time:30.362, tt:2975.478\n",
      "Ep:98, loss:0.00001, loss_test:0.01069, lr:4.91e-02, fs:0.85321 (r=0.939,p=0.782),  time:30.352, tt:3004.817\n",
      "##########Best model found so far##########\n",
      "Ep:99, loss:0.00001, loss_test:0.01068, lr:4.91e-02, fs:0.85714 (r=0.939,p=0.788),  time:30.341, tt:3034.055\n",
      "##########Best model found so far##########\n",
      "Ep:100, loss:0.00001, loss_test:0.01068, lr:4.91e-02, fs:0.85185 (r=0.929,p=0.786),  time:30.323, tt:3062.605\n",
      "Ep:101, loss:0.00001, loss_test:0.01066, lr:4.91e-02, fs:0.85185 (r=0.929,p=0.786),  time:30.294, tt:3090.036\n",
      "Ep:102, loss:0.00001, loss_test:0.01064, lr:4.91e-02, fs:0.85185 (r=0.929,p=0.786),  time:30.284, tt:3119.281\n",
      "Ep:103, loss:0.00001, loss_test:0.01064, lr:4.91e-02, fs:0.85185 (r=0.929,p=0.786),  time:30.311, tt:3152.296\n",
      "Ep:104, loss:0.00001, loss_test:0.01062, lr:4.91e-02, fs:0.85185 (r=0.929,p=0.786),  time:30.298, tt:3181.281\n",
      "Ep:105, loss:0.00001, loss_test:0.01062, lr:4.91e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.271, tt:3208.755\n",
      "Ep:106, loss:0.00001, loss_test:0.01060, lr:4.91e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.262, tt:3238.062\n",
      "Ep:107, loss:0.00001, loss_test:0.01059, lr:4.91e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.256, tt:3267.642\n",
      "Ep:108, loss:0.00001, loss_test:0.01058, lr:4.91e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.272, tt:3299.606\n",
      "Ep:109, loss:0.00001, loss_test:0.01057, lr:4.91e-02, fs:0.85581 (r=0.929,p=0.793),  time:30.284, tt:3331.225\n",
      "Ep:110, loss:0.00001, loss_test:0.01056, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.286, tt:3361.795\n",
      "##########Best model found so far##########\n",
      "Ep:111, loss:0.00001, loss_test:0.01056, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.291, tt:3392.641\n",
      "Ep:112, loss:0.00001, loss_test:0.01054, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.282, tt:3421.904\n",
      "Ep:113, loss:0.00001, loss_test:0.01053, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.272, tt:3451.036\n",
      "Ep:114, loss:0.00001, loss_test:0.01052, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.266, tt:3480.638\n",
      "Ep:115, loss:0.00001, loss_test:0.01052, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.263, tt:3510.484\n",
      "Ep:116, loss:0.00001, loss_test:0.01052, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.262, tt:3540.648\n",
      "Ep:117, loss:0.00001, loss_test:0.01052, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.266, tt:3571.359\n",
      "Ep:118, loss:0.00001, loss_test:0.01050, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.260, tt:3600.889\n",
      "Ep:119, loss:0.00001, loss_test:0.01050, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.265, tt:3631.749\n",
      "Ep:120, loss:0.00001, loss_test:0.01050, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.277, tt:3663.479\n",
      "Ep:121, loss:0.00001, loss_test:0.01049, lr:4.91e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.281, tt:3694.297\n",
      "Ep:122, loss:0.00001, loss_test:0.01051, lr:4.86e-02, fs:0.86385 (r=0.929,p=0.807),  time:30.286, tt:3725.169\n",
      "Ep:123, loss:0.00001, loss_test:0.01049, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.290, tt:3755.904\n",
      "##########Best model found so far##########\n",
      "Ep:124, loss:0.00001, loss_test:0.01046, lr:4.81e-02, fs:0.86792 (r=0.929,p=0.814),  time:30.301, tt:3787.570\n",
      "Ep:125, loss:0.00001, loss_test:0.01048, lr:4.81e-02, fs:0.86792 (r=0.929,p=0.814),  time:30.304, tt:3818.341\n",
      "Ep:126, loss:0.00001, loss_test:0.01050, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.288, tt:3846.609\n",
      "Ep:127, loss:0.00001, loss_test:0.01048, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.283, tt:3876.242\n",
      "Ep:128, loss:0.00001, loss_test:0.01046, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.279, tt:3906.004\n",
      "Ep:129, loss:0.00001, loss_test:0.01047, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.280, tt:3936.424\n",
      "Ep:130, loss:0.00001, loss_test:0.01048, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.280, tt:3966.688\n",
      "Ep:131, loss:0.00001, loss_test:0.01047, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.288, tt:3998.071\n",
      "Ep:132, loss:0.00001, loss_test:0.01048, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.293, tt:4028.973\n",
      "Ep:133, loss:0.00001, loss_test:0.01046, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.292, tt:4059.156\n",
      "Ep:134, loss:0.00001, loss_test:0.01047, lr:4.81e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.290, tt:4089.092\n",
      "Ep:135, loss:0.00001, loss_test:0.01046, lr:4.76e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.294, tt:4119.936\n",
      "Ep:136, loss:0.00001, loss_test:0.01047, lr:4.71e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.294, tt:4150.291\n",
      "Ep:137, loss:0.00001, loss_test:0.01047, lr:4.67e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.293, tt:4180.382\n",
      "Ep:138, loss:0.00001, loss_test:0.01047, lr:4.62e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.293, tt:4210.701\n",
      "Ep:139, loss:0.00001, loss_test:0.01047, lr:4.57e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.296, tt:4241.496\n",
      "Ep:140, loss:0.00001, loss_test:0.01047, lr:4.53e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.300, tt:4272.338\n",
      "Ep:141, loss:0.00001, loss_test:0.01048, lr:4.48e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.297, tt:4302.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:142, loss:0.00001, loss_test:0.01048, lr:4.44e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.296, tt:4332.331\n",
      "Ep:143, loss:0.00001, loss_test:0.01048, lr:4.39e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.294, tt:4362.299\n",
      "Ep:144, loss:0.00001, loss_test:0.01048, lr:4.35e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.300, tt:4393.445\n",
      "Ep:145, loss:0.00001, loss_test:0.01047, lr:4.31e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.307, tt:4424.808\n",
      "Ep:146, loss:0.00001, loss_test:0.01048, lr:4.26e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.302, tt:4454.340\n",
      "Ep:147, loss:0.00001, loss_test:0.01049, lr:4.22e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.310, tt:4485.951\n",
      "Ep:148, loss:0.00001, loss_test:0.01049, lr:4.18e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.312, tt:4516.510\n",
      "Ep:149, loss:0.00001, loss_test:0.01049, lr:4.14e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.319, tt:4547.845\n",
      "Ep:150, loss:0.00001, loss_test:0.01049, lr:4.10e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.319, tt:4578.163\n",
      "Ep:151, loss:0.00001, loss_test:0.01050, lr:4.05e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.309, tt:4606.986\n",
      "Ep:152, loss:0.00001, loss_test:0.01049, lr:4.01e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.310, tt:4637.469\n",
      "Ep:153, loss:0.00001, loss_test:0.01050, lr:3.97e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.305, tt:4666.980\n",
      "Ep:154, loss:0.00001, loss_test:0.01051, lr:3.93e-02, fs:0.87204 (r=0.929,p=0.821),  time:30.301, tt:4696.706\n",
      "Ep:155, loss:0.00001, loss_test:0.01051, lr:3.89e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.304, tt:4727.409\n",
      "Ep:156, loss:0.00001, loss_test:0.01053, lr:3.86e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.299, tt:4756.989\n",
      "Ep:157, loss:0.00001, loss_test:0.01053, lr:3.82e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.295, tt:4786.556\n",
      "Ep:158, loss:0.00001, loss_test:0.01053, lr:3.78e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.295, tt:4816.898\n",
      "Ep:159, loss:0.00001, loss_test:0.01054, lr:3.74e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.299, tt:4847.804\n",
      "Ep:160, loss:0.00001, loss_test:0.01054, lr:3.70e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.297, tt:4877.789\n",
      "Ep:161, loss:0.00001, loss_test:0.01053, lr:3.67e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.299, tt:4908.400\n",
      "Ep:162, loss:0.00001, loss_test:0.01055, lr:3.63e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.294, tt:4937.879\n",
      "Ep:163, loss:0.00001, loss_test:0.01056, lr:3.59e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.294, tt:4968.162\n",
      "Ep:164, loss:0.00001, loss_test:0.01056, lr:3.56e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.299, tt:4999.268\n",
      "Ep:165, loss:0.00001, loss_test:0.01055, lr:3.52e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.302, tt:5030.195\n",
      "Ep:166, loss:0.00001, loss_test:0.01056, lr:3.49e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.307, tt:5061.202\n",
      "Ep:167, loss:0.00001, loss_test:0.01057, lr:3.45e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.302, tt:5090.788\n",
      "Ep:168, loss:0.00001, loss_test:0.01057, lr:3.42e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.298, tt:5120.438\n",
      "Ep:169, loss:0.00001, loss_test:0.01058, lr:3.38e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.300, tt:5150.959\n",
      "Ep:170, loss:0.00001, loss_test:0.01058, lr:3.35e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.307, tt:5182.437\n",
      "Ep:171, loss:0.00001, loss_test:0.01059, lr:3.32e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.301, tt:5211.836\n",
      "Ep:172, loss:0.00001, loss_test:0.01060, lr:3.28e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.301, tt:5242.074\n",
      "Ep:173, loss:0.00001, loss_test:0.01061, lr:3.25e-02, fs:0.86667 (r=0.919,p=0.820),  time:30.308, tt:5273.642\n",
      "Ep:174, loss:0.00001, loss_test:0.01062, lr:3.22e-02, fs:0.87081 (r=0.919,p=0.827),  time:30.303, tt:5302.949\n",
      "Ep:175, loss:0.00001, loss_test:0.01062, lr:3.19e-02, fs:0.87081 (r=0.919,p=0.827),  time:30.307, tt:5333.972\n",
      "Ep:176, loss:0.00001, loss_test:0.01063, lr:3.15e-02, fs:0.87081 (r=0.919,p=0.827),  time:30.304, tt:5363.820\n",
      "Ep:177, loss:0.00001, loss_test:0.01064, lr:3.12e-02, fs:0.87081 (r=0.919,p=0.827),  time:30.300, tt:5393.325\n",
      "Ep:178, loss:0.00001, loss_test:0.01063, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.296, tt:5422.929\n",
      "##########Best model found so far##########\n",
      "Ep:179, loss:0.00001, loss_test:0.01065, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.304, tt:5454.706\n",
      "Ep:180, loss:0.00001, loss_test:0.01065, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.299, tt:5484.190\n",
      "Ep:181, loss:0.00001, loss_test:0.01065, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.304, tt:5515.276\n",
      "Ep:182, loss:0.00001, loss_test:0.01066, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.306, tt:5545.923\n",
      "Ep:183, loss:0.00000, loss_test:0.01067, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.302, tt:5575.558\n",
      "Ep:184, loss:0.00000, loss_test:0.01068, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.297, tt:5605.025\n",
      "Ep:185, loss:0.00000, loss_test:0.01068, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.303, tt:5636.435\n",
      "Ep:186, loss:0.00000, loss_test:0.01069, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.303, tt:5666.754\n",
      "Ep:187, loss:0.00000, loss_test:0.01069, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.299, tt:5696.306\n",
      "Ep:188, loss:0.00000, loss_test:0.01069, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.292, tt:5725.202\n",
      "Ep:189, loss:0.00000, loss_test:0.01071, lr:3.09e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.282, tt:5753.489\n",
      "Ep:190, loss:0.00000, loss_test:0.01070, lr:3.06e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.282, tt:5783.936\n",
      "Ep:191, loss:0.00000, loss_test:0.01070, lr:3.03e-02, fs:0.87500 (r=0.919,p=0.835),  time:30.277, tt:5813.119\n",
      "Ep:192, loss:0.00000, loss_test:0.01071, lr:3.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:30.267, tt:5841.503\n",
      "##########Best model found so far##########\n",
      "Ep:193, loss:0.00000, loss_test:0.01072, lr:3.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:30.254, tt:5869.334\n",
      "Ep:194, loss:0.00000, loss_test:0.01073, lr:3.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:30.249, tt:5898.485\n",
      "Ep:195, loss:0.00000, loss_test:0.01074, lr:3.00e-02, fs:0.87923 (r=0.919,p=0.843),  time:30.207, tt:5920.601\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00007, loss_test:0.01999, lr:6.00e-02, fs:0.63704 (r=0.869,p=0.503),  time:32.888, tt:32.888\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00004, loss_test:0.02364, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.686, tt:71.373\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02533, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:35.760, tt:107.280\n",
      "Ep:3, loss:0.00005, loss_test:0.02534, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.298, tt:145.192\n",
      "Ep:4, loss:0.00005, loss_test:0.02431, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:36.769, tt:183.846\n",
      "Ep:5, loss:0.00005, loss_test:0.02266, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:36.579, tt:219.472\n",
      "Ep:6, loss:0.00004, loss_test:0.02071, lr:6.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:36.686, tt:256.800\n",
      "Ep:7, loss:0.00004, loss_test:0.01923, lr:6.00e-02, fs:0.67399 (r=0.929,p=0.529),  time:36.859, tt:294.875\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01836, lr:6.00e-02, fs:0.68750 (r=0.889,p=0.561),  time:37.030, tt:333.267\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00004, loss_test:0.01766, lr:6.00e-02, fs:0.69600 (r=0.879,p=0.576),  time:37.144, tt:371.435\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01727, lr:6.00e-02, fs:0.69531 (r=0.899,p=0.567),  time:37.188, tt:409.071\n",
      "Ep:11, loss:0.00004, loss_test:0.01715, lr:6.00e-02, fs:0.70270 (r=0.919,p=0.569),  time:37.116, tt:445.397\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00003, loss_test:0.01693, lr:6.00e-02, fs:0.70229 (r=0.929,p=0.564),  time:37.078, tt:482.012\n",
      "Ep:13, loss:0.00003, loss_test:0.01660, lr:6.00e-02, fs:0.71318 (r=0.929,p=0.579),  time:37.161, tt:520.259\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00003, loss_test:0.01623, lr:6.00e-02, fs:0.71654 (r=0.919,p=0.587),  time:37.168, tt:557.522\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01592, lr:6.00e-02, fs:0.71486 (r=0.899,p=0.593),  time:37.266, tt:596.262\n",
      "Ep:16, loss:0.00003, loss_test:0.01566, lr:6.00e-02, fs:0.72289 (r=0.909,p=0.600),  time:37.133, tt:631.256\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01541, lr:6.00e-02, fs:0.73684 (r=0.919,p=0.615),  time:37.256, tt:670.604\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01517, lr:6.00e-02, fs:0.74797 (r=0.929,p=0.626),  time:37.216, tt:707.104\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:37.250, tt:744.991\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01466, lr:6.00e-02, fs:0.75610 (r=0.939,p=0.633),  time:37.315, tt:783.618\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01440, lr:6.00e-02, fs:0.77178 (r=0.939,p=0.655),  time:37.196, tt:818.319\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00003, loss_test:0.01415, lr:6.00e-02, fs:0.78512 (r=0.960,p=0.664),  time:37.206, tt:855.747\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00003, loss_test:0.01394, lr:6.00e-02, fs:0.80335 (r=0.970,p=0.686),  time:37.171, tt:892.094\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01373, lr:6.00e-02, fs:0.80169 (r=0.960,p=0.688),  time:37.255, tt:931.382\n",
      "Ep:25, loss:0.00002, loss_test:0.01352, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:37.333, tt:970.660\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00002, loss_test:0.01332, lr:6.00e-02, fs:0.80851 (r=0.960,p=0.699),  time:37.375, tt:1009.124\n",
      "Ep:27, loss:0.00002, loss_test:0.01312, lr:6.00e-02, fs:0.81197 (r=0.960,p=0.704),  time:37.354, tt:1045.903\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00002, loss_test:0.01291, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.379, tt:1083.994\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01273, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.467, tt:1124.014\n",
      "Ep:30, loss:0.00002, loss_test:0.01259, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:37.398, tt:1159.325\n",
      "Ep:31, loss:0.00002, loss_test:0.01245, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.444, tt:1198.207\n",
      "Ep:32, loss:0.00002, loss_test:0.01230, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.451, tt:1235.894\n",
      "Ep:33, loss:0.00002, loss_test:0.01216, lr:6.00e-02, fs:0.81545 (r=0.960,p=0.709),  time:37.517, tt:1275.586\n",
      "Ep:34, loss:0.00002, loss_test:0.01206, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.567, tt:1314.862\n",
      "Ep:35, loss:0.00002, loss_test:0.01198, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.554, tt:1351.949\n",
      "Ep:36, loss:0.00002, loss_test:0.01188, lr:6.00e-02, fs:0.81897 (r=0.960,p=0.714),  time:37.539, tt:1388.939\n",
      "Ep:37, loss:0.00002, loss_test:0.01177, lr:6.00e-02, fs:0.82403 (r=0.970,p=0.716),  time:37.564, tt:1427.419\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00002, loss_test:0.01168, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:37.570, tt:1465.235\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00002, loss_test:0.01159, lr:6.00e-02, fs:0.83117 (r=0.970,p=0.727),  time:37.621, tt:1504.832\n",
      "Ep:40, loss:0.00002, loss_test:0.01152, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:37.586, tt:1541.006\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00002, loss_test:0.01144, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:37.631, tt:1580.513\n",
      "Ep:42, loss:0.00002, loss_test:0.01136, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:37.636, tt:1618.365\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00002, loss_test:0.01130, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:37.633, tt:1655.861\n",
      "Ep:44, loss:0.00002, loss_test:0.01125, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:37.619, tt:1692.861\n",
      "Ep:45, loss:0.00002, loss_test:0.01120, lr:6.00e-02, fs:0.83621 (r=0.980,p=0.729),  time:37.680, tt:1733.261\n",
      "Ep:46, loss:0.00001, loss_test:0.01112, lr:6.00e-02, fs:0.83983 (r=0.980,p=0.735),  time:37.684, tt:1771.152\n",
      "Ep:47, loss:0.00001, loss_test:0.01107, lr:6.00e-02, fs:0.84348 (r=0.980,p=0.740),  time:37.670, tt:1808.161\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00001, loss_test:0.01102, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:37.679, tt:1846.283\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00001, loss_test:0.01099, lr:6.00e-02, fs:0.84848 (r=0.990,p=0.742),  time:37.681, tt:1884.074\n",
      "Ep:50, loss:0.00001, loss_test:0.01093, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:37.672, tt:1921.257\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01086, lr:6.00e-02, fs:0.85217 (r=0.990,p=0.748),  time:37.671, tt:1958.915\n",
      "Ep:52, loss:0.00001, loss_test:0.01080, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:37.656, tt:1995.788\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00001, loss_test:0.01075, lr:6.00e-02, fs:0.85590 (r=0.990,p=0.754),  time:37.669, tt:2034.119\n",
      "Ep:54, loss:0.00001, loss_test:0.01069, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:37.705, tt:2073.787\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00001, loss_test:0.01064, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:37.690, tt:2110.633\n",
      "Ep:56, loss:0.00001, loss_test:0.01060, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:37.705, tt:2149.197\n",
      "Ep:57, loss:0.00001, loss_test:0.01055, lr:6.00e-02, fs:0.85965 (r=0.990,p=0.760),  time:37.673, tt:2185.025\n",
      "Ep:58, loss:0.00001, loss_test:0.01049, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:37.663, tt:2222.095\n",
      "##########Best model found so far##########\n",
      "Ep:59, loss:0.00001, loss_test:0.01045, lr:6.00e-02, fs:0.86726 (r=0.990,p=0.772),  time:37.674, tt:2260.462\n",
      "Ep:60, loss:0.00001, loss_test:0.01041, lr:6.00e-02, fs:0.87500 (r=0.990,p=0.784),  time:37.672, tt:2297.994\n",
      "##########Best model found so far##########\n",
      "Ep:61, loss:0.00001, loss_test:0.01036, lr:6.00e-02, fs:0.87892 (r=0.990,p=0.790),  time:37.665, tt:2335.205\n",
      "##########Best model found so far##########\n",
      "Ep:62, loss:0.00001, loss_test:0.01035, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:37.653, tt:2372.143\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00001, loss_test:0.01031, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:37.657, tt:2410.080\n",
      "Ep:64, loss:0.00001, loss_test:0.01025, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:37.653, tt:2447.439\n",
      "Ep:65, loss:0.00001, loss_test:0.01023, lr:6.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:37.661, tt:2485.655\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00001, loss_test:0.01022, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:37.649, tt:2522.498\n",
      "Ep:67, loss:0.00001, loss_test:0.01016, lr:6.00e-02, fs:0.88288 (r=0.990,p=0.797),  time:37.681, tt:2562.301\n",
      "Ep:68, loss:0.00001, loss_test:0.01012, lr:6.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:37.691, tt:2600.668\n",
      "Ep:69, loss:0.00001, loss_test:0.01009, lr:6.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:37.691, tt:2638.403\n",
      "Ep:70, loss:0.00001, loss_test:0.01001, lr:6.00e-02, fs:0.88688 (r=0.990,p=0.803),  time:37.684, tt:2675.545\n",
      "Ep:71, loss:0.00001, loss_test:0.01001, lr:6.00e-02, fs:0.89498 (r=0.990,p=0.817),  time:37.720, tt:2715.812\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.00999, lr:6.00e-02, fs:0.89908 (r=0.990,p=0.824),  time:37.756, tt:2756.208\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00001, loss_test:0.00997, lr:6.00e-02, fs:0.90323 (r=0.990,p=0.831),  time:37.826, tt:2799.118\n",
      "##########Best model found so far##########\n",
      "Ep:74, loss:0.00001, loss_test:0.00992, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:37.849, tt:2838.644\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.00993, lr:6.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:37.876, tt:2878.584\n",
      "Ep:76, loss:0.00001, loss_test:0.00989, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.886, tt:2917.228\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00001, loss_test:0.00988, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.893, tt:2955.618\n",
      "Ep:78, loss:0.00001, loss_test:0.00985, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.906, tt:2994.553\n",
      "Ep:79, loss:0.00001, loss_test:0.00982, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.913, tt:3033.072\n",
      "Ep:80, loss:0.00001, loss_test:0.00977, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.927, tt:3072.091\n",
      "Ep:81, loss:0.00001, loss_test:0.00978, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.941, tt:3111.193\n",
      "Ep:82, loss:0.00001, loss_test:0.00973, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.931, tt:3148.241\n",
      "Ep:83, loss:0.00001, loss_test:0.00971, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.934, tt:3186.459\n",
      "Ep:84, loss:0.00001, loss_test:0.00972, lr:6.00e-02, fs:0.91163 (r=0.990,p=0.845),  time:37.933, tt:3224.290\n",
      "Ep:85, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.940, tt:3262.816\n",
      "Ep:86, loss:0.00001, loss_test:0.00969, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.925, tt:3299.443\n",
      "Ep:87, loss:0.00001, loss_test:0.00970, lr:6.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.942, tt:3338.892\n",
      "Ep:88, loss:0.00001, loss_test:0.00968, lr:5.94e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.952, tt:3377.713\n",
      "Ep:89, loss:0.00001, loss_test:0.00965, lr:5.88e-02, fs:0.90141 (r=0.970,p=0.842),  time:37.974, tt:3417.643\n",
      "Ep:90, loss:0.00001, loss_test:0.00969, lr:5.82e-02, fs:0.90566 (r=0.970,p=0.850),  time:37.986, tt:3456.709\n",
      "Ep:91, loss:0.00001, loss_test:0.00969, lr:5.76e-02, fs:0.90566 (r=0.970,p=0.850),  time:37.999, tt:3495.919\n",
      "Ep:92, loss:0.00001, loss_test:0.00965, lr:5.71e-02, fs:0.90566 (r=0.970,p=0.850),  time:38.015, tt:3535.362\n",
      "Ep:93, loss:0.00001, loss_test:0.00971, lr:5.65e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.025, tt:3574.316\n",
      "Ep:94, loss:0.00001, loss_test:0.00967, lr:5.59e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.044, tt:3614.151\n",
      "Ep:95, loss:0.00001, loss_test:0.00964, lr:5.54e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.052, tt:3652.973\n",
      "Ep:96, loss:0.00001, loss_test:0.00966, lr:5.48e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.041, tt:3689.968\n",
      "Ep:97, loss:0.00001, loss_test:0.00967, lr:5.43e-02, fs:0.90995 (r=0.970,p=0.857),  time:38.052, tt:3729.116\n",
      "Ep:98, loss:0.00001, loss_test:0.00969, lr:5.37e-02, fs:0.89952 (r=0.949,p=0.855),  time:38.054, tt:3767.363\n",
      "Ep:99, loss:0.00001, loss_test:0.00970, lr:5.32e-02, fs:0.90385 (r=0.949,p=0.862),  time:38.070, tt:3807.046\n",
      "Ep:100, loss:0.00001, loss_test:0.00970, lr:5.27e-02, fs:0.90385 (r=0.949,p=0.862),  time:38.072, tt:3845.265\n",
      "Ep:101, loss:0.00001, loss_test:0.00971, lr:5.21e-02, fs:0.91262 (r=0.949,p=0.879),  time:38.075, tt:3883.688\n",
      "##########Best model found so far##########\n",
      "Ep:102, loss:0.00001, loss_test:0.00971, lr:5.21e-02, fs:0.90291 (r=0.939,p=0.869),  time:38.077, tt:3921.945\n",
      "Ep:103, loss:0.00001, loss_test:0.00974, lr:5.21e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.093, tt:3961.704\n",
      "Ep:104, loss:0.00000, loss_test:0.00973, lr:5.21e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.108, tt:4001.374\n",
      "Ep:105, loss:0.00000, loss_test:0.00974, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.102, tt:4038.817\n",
      "Ep:106, loss:0.00000, loss_test:0.00975, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.111, tt:4077.824\n",
      "Ep:107, loss:0.00000, loss_test:0.00975, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.105, tt:4115.319\n",
      "Ep:108, loss:0.00000, loss_test:0.00977, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.124, tt:4155.526\n",
      "Ep:109, loss:0.00000, loss_test:0.00979, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.134, tt:4194.754\n",
      "Ep:110, loss:0.00000, loss_test:0.00980, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.142, tt:4233.728\n",
      "Ep:111, loss:0.00000, loss_test:0.00983, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.146, tt:4272.301\n",
      "Ep:112, loss:0.00000, loss_test:0.00982, lr:5.21e-02, fs:0.90196 (r=0.929,p=0.876),  time:38.131, tt:4308.756\n",
      "Ep:113, loss:0.00000, loss_test:0.00983, lr:5.16e-02, fs:0.90732 (r=0.939,p=0.877),  time:38.118, tt:4345.398\n",
      "Ep:114, loss:0.00000, loss_test:0.00988, lr:5.11e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.115, tt:4383.273\n",
      "Ep:115, loss:0.00000, loss_test:0.00989, lr:5.06e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.127, tt:4422.765\n",
      "Ep:116, loss:0.00000, loss_test:0.00988, lr:5.01e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.155, tt:4464.132\n",
      "Ep:117, loss:0.00000, loss_test:0.00992, lr:4.96e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.165, tt:4503.492\n",
      "Ep:118, loss:0.00000, loss_test:0.00993, lr:4.91e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.175, tt:4542.784\n",
      "Ep:119, loss:0.00000, loss_test:0.00992, lr:4.86e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.186, tt:4582.303\n",
      "Ep:120, loss:0.00000, loss_test:0.00997, lr:4.81e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.186, tt:4620.451\n",
      "Ep:121, loss:0.00000, loss_test:0.00999, lr:4.76e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.183, tt:4658.346\n",
      "Ep:122, loss:0.00000, loss_test:0.01001, lr:4.71e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.185, tt:4696.729\n",
      "Ep:123, loss:0.00000, loss_test:0.01001, lr:4.67e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.196, tt:4736.303\n",
      "Ep:124, loss:0.00000, loss_test:0.01003, lr:4.62e-02, fs:0.91176 (r=0.939,p=0.886),  time:38.205, tt:4775.685\n",
      "Ep:125, loss:0.00000, loss_test:0.01001, lr:4.57e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.231, tt:4817.116\n",
      "Ep:126, loss:0.00000, loss_test:0.01005, lr:4.53e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.218, tt:4853.665\n",
      "Ep:127, loss:0.00000, loss_test:0.01008, lr:4.48e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.228, tt:4893.126\n",
      "Ep:128, loss:0.00000, loss_test:0.01007, lr:4.44e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.224, tt:4930.841\n",
      "Ep:129, loss:0.00000, loss_test:0.01013, lr:4.39e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.231, tt:4970.075\n",
      "Ep:130, loss:0.00000, loss_test:0.01011, lr:4.35e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.222, tt:5007.054\n",
      "Ep:131, loss:0.00000, loss_test:0.01013, lr:4.31e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.233, tt:5046.696\n",
      "Ep:132, loss:0.00000, loss_test:0.01018, lr:4.26e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.232, tt:5084.898\n",
      "Ep:133, loss:0.00000, loss_test:0.01016, lr:4.22e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.250, tt:5125.490\n",
      "Ep:134, loss:0.00000, loss_test:0.01019, lr:4.18e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.244, tt:5162.934\n",
      "Ep:135, loss:0.00000, loss_test:0.01021, lr:4.14e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.244, tt:5201.226\n",
      "Ep:136, loss:0.00000, loss_test:0.01022, lr:4.10e-02, fs:0.90640 (r=0.929,p=0.885),  time:38.249, tt:5240.157\n",
      "Ep:137, loss:0.00000, loss_test:0.01023, lr:4.05e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.250, tt:5278.463\n",
      "Ep:138, loss:0.00000, loss_test:0.01027, lr:4.01e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.262, tt:5318.378\n",
      "Ep:139, loss:0.00000, loss_test:0.01027, lr:3.97e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.267, tt:5357.404\n",
      "Ep:140, loss:0.00000, loss_test:0.01028, lr:3.93e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.272, tt:5396.315\n",
      "Ep:141, loss:0.00000, loss_test:0.01034, lr:3.89e-02, fs:0.90099 (r=0.919,p=0.883),  time:38.262, tt:5433.188\n",
      "Ep:142, loss:0.00000, loss_test:0.01035, lr:3.86e-02, fs:0.90547 (r=0.919,p=0.892),  time:38.257, tt:5470.819\n",
      "Ep:143, loss:0.00000, loss_test:0.01035, lr:3.82e-02, fs:0.89552 (r=0.909,p=0.882),  time:38.257, tt:5508.937\n",
      "Ep:144, loss:0.00000, loss_test:0.01036, lr:3.78e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.251, tt:5546.412\n",
      "Ep:145, loss:0.00000, loss_test:0.01039, lr:3.74e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.246, tt:5583.927\n",
      "Ep:146, loss:0.00000, loss_test:0.01039, lr:3.70e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.241, tt:5621.484\n",
      "Ep:147, loss:0.00000, loss_test:0.01041, lr:3.67e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.268, tt:5663.646\n",
      "Ep:148, loss:0.00000, loss_test:0.01043, lr:3.63e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.264, tt:5701.269\n",
      "Ep:149, loss:0.00000, loss_test:0.01047, lr:3.59e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.262, tt:5739.348\n",
      "Ep:150, loss:0.00000, loss_test:0.01045, lr:3.56e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.269, tt:5778.599\n",
      "Ep:151, loss:0.00000, loss_test:0.01047, lr:3.52e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.263, tt:5815.907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:152, loss:0.00000, loss_test:0.01051, lr:3.49e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.259, tt:5853.600\n",
      "Ep:153, loss:0.00000, loss_test:0.01054, lr:3.45e-02, fs:0.90000 (r=0.909,p=0.891),  time:38.267, tt:5893.043\n",
      "Ep:154, loss:0.00000, loss_test:0.01053, lr:3.42e-02, fs:0.90452 (r=0.909,p=0.900),  time:38.268, tt:5931.464\n",
      "Ep:155, loss:0.00000, loss_test:0.01056, lr:3.38e-02, fs:0.89899 (r=0.899,p=0.899),  time:38.274, tt:5970.708\n",
      "Ep:156, loss:0.00000, loss_test:0.01056, lr:3.35e-02, fs:0.89899 (r=0.899,p=0.899),  time:38.277, tt:6009.464\n",
      "Ep:157, loss:0.00000, loss_test:0.01058, lr:3.32e-02, fs:0.88776 (r=0.879,p=0.897),  time:38.272, tt:6046.910\n",
      "Ep:158, loss:0.00000, loss_test:0.01060, lr:3.28e-02, fs:0.88205 (r=0.869,p=0.896),  time:38.271, tt:6085.134\n",
      "Ep:159, loss:0.00000, loss_test:0.01062, lr:3.25e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.263, tt:6122.137\n",
      "Ep:160, loss:0.00000, loss_test:0.01065, lr:3.22e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.269, tt:6161.381\n",
      "Ep:161, loss:0.00000, loss_test:0.01063, lr:3.19e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.270, tt:6199.725\n",
      "Ep:162, loss:0.00000, loss_test:0.01066, lr:3.15e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.271, tt:6238.231\n",
      "Ep:163, loss:0.00000, loss_test:0.01068, lr:3.12e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.263, tt:6275.190\n",
      "Ep:164, loss:0.00000, loss_test:0.01069, lr:3.09e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.262, tt:6313.253\n",
      "Ep:165, loss:0.00000, loss_test:0.01070, lr:3.06e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.260, tt:6351.203\n",
      "Ep:166, loss:0.00000, loss_test:0.01072, lr:3.03e-02, fs:0.88660 (r=0.869,p=0.905),  time:38.256, tt:6388.683\n",
      "Ep:167, loss:0.00000, loss_test:0.01074, lr:3.00e-02, fs:0.88083 (r=0.859,p=0.904),  time:38.254, tt:6426.654\n",
      "Ep:168, loss:0.00000, loss_test:0.01075, lr:2.97e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.259, tt:6465.816\n",
      "Ep:169, loss:0.00000, loss_test:0.01077, lr:2.94e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.259, tt:6504.085\n",
      "Ep:170, loss:0.00000, loss_test:0.01078, lr:2.91e-02, fs:0.87500 (r=0.848,p=0.903),  time:38.258, tt:6542.168\n",
      "Ep:171, loss:0.00000, loss_test:0.01082, lr:2.88e-02, fs:0.86316 (r=0.828,p=0.901),  time:38.257, tt:6580.168\n",
      "Ep:172, loss:0.00000, loss_test:0.01082, lr:2.85e-02, fs:0.86911 (r=0.838,p=0.902),  time:38.252, tt:6617.651\n",
      "Ep:173, loss:0.00000, loss_test:0.01081, lr:2.82e-02, fs:0.86316 (r=0.828,p=0.901),  time:38.254, tt:6656.113\n",
      "Ep:174, loss:0.00000, loss_test:0.01084, lr:2.80e-02, fs:0.85714 (r=0.818,p=0.900),  time:38.255, tt:6694.565\n",
      "Ep:175, loss:0.00000, loss_test:0.01085, lr:2.77e-02, fs:0.85714 (r=0.818,p=0.900),  time:38.250, tt:6731.957\n",
      "Ep:176, loss:0.00000, loss_test:0.01088, lr:2.74e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.238, tt:6768.124\n",
      "Ep:177, loss:0.00000, loss_test:0.01087, lr:2.71e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.238, tt:6806.340\n",
      "Ep:178, loss:0.00000, loss_test:0.01089, lr:2.69e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.233, tt:6843.763\n",
      "Ep:179, loss:0.00000, loss_test:0.01092, lr:2.66e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.242, tt:6883.583\n",
      "Ep:180, loss:0.00000, loss_test:0.01091, lr:2.63e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.247, tt:6922.634\n",
      "Ep:181, loss:0.00000, loss_test:0.01092, lr:2.61e-02, fs:0.85106 (r=0.808,p=0.899),  time:38.251, tt:6961.689\n",
      "Ep:182, loss:0.00000, loss_test:0.01096, lr:2.58e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.252, tt:7000.058\n",
      "Ep:183, loss:0.00000, loss_test:0.01097, lr:2.55e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.246, tt:7037.188\n",
      "Ep:184, loss:0.00000, loss_test:0.01096, lr:2.53e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.244, tt:7075.175\n",
      "Ep:185, loss:0.00000, loss_test:0.01098, lr:2.50e-02, fs:0.84492 (r=0.798,p=0.898),  time:38.241, tt:7112.748\n",
      "Ep:186, loss:0.00000, loss_test:0.01099, lr:2.48e-02, fs:0.83871 (r=0.788,p=0.897),  time:38.243, tt:7151.531\n",
      "Ep:187, loss:0.00000, loss_test:0.01100, lr:2.45e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.250, tt:7190.992\n",
      "Ep:188, loss:0.00000, loss_test:0.01100, lr:2.43e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.252, tt:7229.711\n",
      "Ep:189, loss:0.00000, loss_test:0.01103, lr:2.40e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.250, tt:7267.491\n",
      "Ep:190, loss:0.00000, loss_test:0.01105, lr:2.38e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.253, tt:7306.234\n",
      "Ep:191, loss:0.00000, loss_test:0.01104, lr:2.36e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.250, tt:7343.988\n",
      "Ep:192, loss:0.00000, loss_test:0.01106, lr:2.33e-02, fs:0.81967 (r=0.758,p=0.893),  time:38.248, tt:7381.863\n",
      "Ep:193, loss:0.00000, loss_test:0.01107, lr:2.31e-02, fs:0.81319 (r=0.747,p=0.892),  time:38.249, tt:7420.293\n",
      "Ep:194, loss:0.00000, loss_test:0.01106, lr:2.29e-02, fs:0.81319 (r=0.747,p=0.892),  time:38.235, tt:7455.745\n",
      "Ep:195, loss:0.00000, loss_test:0.01108, lr:2.26e-02, fs:0.81319 (r=0.747,p=0.892),  time:38.227, tt:7492.560\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 5\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss ContrastiveLoss Split 1024: \n",
      "Ep:0, loss:0.00008, loss_test:0.02161, lr:6.00e-02, fs:0.64865 (r=0.848,p=0.525),  time:27.117, tt:27.117\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00005, loss_test:0.02426, lr:6.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:31.384, tt:62.768\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00005, loss_test:0.02650, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:32.244, tt:96.731\n",
      "Ep:3, loss:0.00005, loss_test:0.02666, lr:6.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:33.402, tt:133.610\n",
      "Ep:4, loss:0.00005, loss_test:0.02566, lr:6.00e-02, fs:0.66216 (r=0.990,p=0.497),  time:33.714, tt:168.572\n",
      "Ep:5, loss:0.00005, loss_test:0.02396, lr:6.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:34.002, tt:204.012\n",
      "Ep:6, loss:0.00005, loss_test:0.02190, lr:6.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:34.231, tt:239.616\n",
      "Ep:7, loss:0.00004, loss_test:0.02027, lr:6.00e-02, fs:0.67647 (r=0.929,p=0.532),  time:34.487, tt:275.894\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00004, loss_test:0.01931, lr:6.00e-02, fs:0.65613 (r=0.838,p=0.539),  time:34.520, tt:310.683\n",
      "Ep:9, loss:0.00004, loss_test:0.01865, lr:6.00e-02, fs:0.68254 (r=0.869,p=0.562),  time:34.478, tt:344.782\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00004, loss_test:0.01827, lr:6.00e-02, fs:0.69173 (r=0.929,p=0.551),  time:34.601, tt:380.607\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00004, loss_test:0.01808, lr:6.00e-02, fs:0.69145 (r=0.939,p=0.547),  time:34.706, tt:416.470\n",
      "Ep:12, loss:0.00004, loss_test:0.01774, lr:6.00e-02, fs:0.69925 (r=0.939,p=0.557),  time:34.758, tt:451.849\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00004, loss_test:0.01731, lr:6.00e-02, fs:0.70817 (r=0.919,p=0.576),  time:34.850, tt:487.898\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00004, loss_test:0.01692, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:34.728, tt:520.922\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00003, loss_test:0.01659, lr:6.00e-02, fs:0.71429 (r=0.909,p=0.588),  time:34.796, tt:556.743\n",
      "Ep:16, loss:0.00003, loss_test:0.01636, lr:6.00e-02, fs:0.72222 (r=0.919,p=0.595),  time:34.757, tt:590.866\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00003, loss_test:0.01621, lr:6.00e-02, fs:0.72510 (r=0.919,p=0.599),  time:34.713, tt:624.835\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00003, loss_test:0.01604, lr:6.00e-02, fs:0.73518 (r=0.939,p=0.604),  time:34.778, tt:660.788\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00003, loss_test:0.01577, lr:6.00e-02, fs:0.74603 (r=0.949,p=0.614),  time:34.714, tt:694.284\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00003, loss_test:0.01548, lr:6.00e-02, fs:0.75502 (r=0.949,p=0.627),  time:34.646, tt:727.561\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00003, loss_test:0.01520, lr:6.00e-02, fs:0.75000 (r=0.939,p=0.624),  time:34.664, tt:762.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:22, loss:0.00003, loss_test:0.01491, lr:6.00e-02, fs:0.74590 (r=0.919,p=0.628),  time:34.664, tt:797.271\n",
      "Ep:23, loss:0.00003, loss_test:0.01463, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.674, tt:832.170\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00003, loss_test:0.01439, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.634, tt:865.852\n",
      "Ep:25, loss:0.00003, loss_test:0.01415, lr:6.00e-02, fs:0.76349 (r=0.929,p=0.648),  time:34.602, tt:899.654\n",
      "Ep:26, loss:0.00003, loss_test:0.01394, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.615, tt:934.616\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00002, loss_test:0.01373, lr:6.00e-02, fs:0.76667 (r=0.929,p=0.652),  time:34.657, tt:970.393\n",
      "Ep:28, loss:0.00002, loss_test:0.01348, lr:6.00e-02, fs:0.76987 (r=0.929,p=0.657),  time:34.653, tt:1004.943\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00002, loss_test:0.01325, lr:6.00e-02, fs:0.77966 (r=0.929,p=0.672),  time:34.671, tt:1040.138\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00002, loss_test:0.01304, lr:6.00e-02, fs:0.78970 (r=0.929,p=0.687),  time:34.704, tt:1075.830\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00002, loss_test:0.01284, lr:6.00e-02, fs:0.81385 (r=0.949,p=0.712),  time:34.687, tt:1109.991\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00002, loss_test:0.01268, lr:6.00e-02, fs:0.81057 (r=0.929,p=0.719),  time:34.695, tt:1144.937\n",
      "Ep:33, loss:0.00002, loss_test:0.01248, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.660, tt:1178.438\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00002, loss_test:0.01231, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.636, tt:1212.270\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00002, loss_test:0.01217, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.655, tt:1247.574\n",
      "Ep:36, loss:0.00002, loss_test:0.01205, lr:6.00e-02, fs:0.82819 (r=0.949,p=0.734),  time:34.670, tt:1282.789\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00002, loss_test:0.01193, lr:6.00e-02, fs:0.82456 (r=0.949,p=0.729),  time:34.668, tt:1317.398\n",
      "Ep:38, loss:0.00002, loss_test:0.01184, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.675, tt:1352.309\n",
      "Ep:39, loss:0.00002, loss_test:0.01173, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.687, tt:1387.484\n",
      "Ep:40, loss:0.00002, loss_test:0.01161, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.712, tt:1423.200\n",
      "Ep:41, loss:0.00002, loss_test:0.01148, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.686, tt:1456.799\n",
      "Ep:42, loss:0.00002, loss_test:0.01135, lr:6.00e-02, fs:0.82096 (r=0.949,p=0.723),  time:34.696, tt:1491.907\n",
      "Ep:43, loss:0.00002, loss_test:0.01128, lr:6.00e-02, fs:0.81579 (r=0.939,p=0.721),  time:34.734, tt:1528.314\n",
      "Ep:44, loss:0.00002, loss_test:0.01121, lr:6.00e-02, fs:0.81416 (r=0.929,p=0.724),  time:34.745, tt:1563.526\n",
      "Ep:45, loss:0.00001, loss_test:0.01115, lr:6.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:34.780, tt:1599.873\n",
      "Ep:46, loss:0.00001, loss_test:0.01109, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.859, tt:1638.388\n",
      "Ep:47, loss:0.00001, loss_test:0.01101, lr:6.00e-02, fs:0.81778 (r=0.929,p=0.730),  time:34.864, tt:1673.483\n",
      "Ep:48, loss:0.00001, loss_test:0.01099, lr:5.94e-02, fs:0.82301 (r=0.939,p=0.732),  time:34.865, tt:1708.398\n",
      "Ep:49, loss:0.00001, loss_test:0.01093, lr:5.88e-02, fs:0.83036 (r=0.939,p=0.744),  time:34.885, tt:1744.228\n",
      "##########Best model found so far##########\n",
      "Ep:50, loss:0.00001, loss_test:0.01091, lr:5.88e-02, fs:0.83408 (r=0.939,p=0.750),  time:34.925, tt:1781.151\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00001, loss_test:0.01084, lr:5.88e-02, fs:0.83408 (r=0.939,p=0.750),  time:34.955, tt:1817.646\n",
      "Ep:52, loss:0.00001, loss_test:0.01080, lr:5.88e-02, fs:0.83258 (r=0.929,p=0.754),  time:34.998, tt:1854.920\n",
      "Ep:53, loss:0.00001, loss_test:0.01077, lr:5.88e-02, fs:0.83636 (r=0.929,p=0.760),  time:35.031, tt:1891.694\n",
      "##########Best model found so far##########\n",
      "Ep:54, loss:0.00001, loss_test:0.01071, lr:5.88e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.083, tt:1929.546\n",
      "Ep:55, loss:0.00001, loss_test:0.01072, lr:5.88e-02, fs:0.83636 (r=0.929,p=0.760),  time:35.070, tt:1963.918\n",
      "Ep:56, loss:0.00001, loss_test:0.01066, lr:5.88e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.066, tt:1998.749\n",
      "Ep:57, loss:0.00001, loss_test:0.01063, lr:5.88e-02, fs:0.83636 (r=0.929,p=0.760),  time:35.063, tt:2033.648\n",
      "Ep:58, loss:0.00001, loss_test:0.01061, lr:5.88e-02, fs:0.83636 (r=0.929,p=0.760),  time:35.067, tt:2068.959\n",
      "Ep:59, loss:0.00001, loss_test:0.01062, lr:5.88e-02, fs:0.83258 (r=0.929,p=0.754),  time:35.088, tt:2105.270\n",
      "Ep:60, loss:0.00001, loss_test:0.01067, lr:5.88e-02, fs:0.82791 (r=0.899,p=0.767),  time:35.148, tt:2144.008\n",
      "Ep:61, loss:0.00001, loss_test:0.01059, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:35.142, tt:2178.820\n",
      "Ep:62, loss:0.00001, loss_test:0.01055, lr:5.88e-02, fs:0.82407 (r=0.899,p=0.761),  time:35.189, tt:2216.903\n",
      "Ep:63, loss:0.00001, loss_test:0.01059, lr:5.88e-02, fs:0.82028 (r=0.899,p=0.754),  time:35.193, tt:2252.375\n",
      "Ep:64, loss:0.00001, loss_test:0.01060, lr:5.88e-02, fs:0.83178 (r=0.899,p=0.774),  time:35.206, tt:2288.362\n",
      "Ep:65, loss:0.00001, loss_test:0.01054, lr:5.82e-02, fs:0.83178 (r=0.899,p=0.774),  time:35.213, tt:2324.051\n",
      "Ep:66, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.83962 (r=0.899,p=0.788),  time:35.223, tt:2359.954\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00001, loss_test:0.01054, lr:5.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:35.232, tt:2395.769\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00001, loss_test:0.01056, lr:5.76e-02, fs:0.84762 (r=0.899,p=0.802),  time:35.235, tt:2431.208\n",
      "Ep:69, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.85167 (r=0.899,p=0.809),  time:35.233, tt:2466.294\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00001, loss_test:0.01044, lr:5.76e-02, fs:0.85577 (r=0.899,p=0.817),  time:35.217, tt:2500.386\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00001, loss_test:0.01046, lr:5.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:35.222, tt:2536.020\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00001, loss_test:0.01051, lr:5.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:35.221, tt:2571.163\n",
      "Ep:73, loss:0.00001, loss_test:0.01048, lr:5.76e-02, fs:0.85990 (r=0.899,p=0.824),  time:35.221, tt:2606.381\n",
      "Ep:74, loss:0.00001, loss_test:0.01048, lr:5.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:35.204, tt:2640.300\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.166, tt:2672.579\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.01053, lr:5.76e-02, fs:0.86408 (r=0.899,p=0.832),  time:35.161, tt:2707.406\n",
      "Ep:77, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.145, tt:2741.272\n",
      "Ep:78, loss:0.00001, loss_test:0.01050, lr:5.76e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.128, tt:2775.081\n",
      "Ep:79, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.86829 (r=0.899,p=0.840),  time:35.100, tt:2808.000\n",
      "Ep:80, loss:0.00001, loss_test:0.01057, lr:5.76e-02, fs:0.86700 (r=0.889,p=0.846),  time:35.087, tt:2842.034\n",
      "Ep:81, loss:0.00001, loss_test:0.01054, lr:5.76e-02, fs:0.87255 (r=0.899,p=0.848),  time:35.084, tt:2876.865\n",
      "##########Best model found so far##########\n",
      "Ep:82, loss:0.00001, loss_test:0.01054, lr:5.76e-02, fs:0.86700 (r=0.889,p=0.846),  time:35.076, tt:2911.311\n",
      "Ep:83, loss:0.00001, loss_test:0.01057, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.087, tt:2947.328\n",
      "Ep:84, loss:0.00001, loss_test:0.01056, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.105, tt:2983.900\n",
      "Ep:85, loss:0.00001, loss_test:0.01056, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.112, tt:3019.602\n",
      "Ep:86, loss:0.00001, loss_test:0.01052, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.111, tt:3054.674\n",
      "Ep:87, loss:0.00001, loss_test:0.01061, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.093, tt:3088.170\n",
      "Ep:88, loss:0.00001, loss_test:0.01060, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.076, tt:3121.738\n",
      "Ep:89, loss:0.00001, loss_test:0.01057, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.059, tt:3155.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:90, loss:0.00001, loss_test:0.01059, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.061, tt:3190.538\n",
      "Ep:91, loss:0.00001, loss_test:0.01068, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.055, tt:3225.092\n",
      "Ep:92, loss:0.00001, loss_test:0.01068, lr:5.76e-02, fs:0.87562 (r=0.889,p=0.863),  time:35.038, tt:3258.498\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00001, loss_test:0.01067, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.038, tt:3293.554\n",
      "Ep:94, loss:0.00001, loss_test:0.01076, lr:5.76e-02, fs:0.87129 (r=0.889,p=0.854),  time:35.015, tt:3326.449\n",
      "Ep:95, loss:0.00001, loss_test:0.01079, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.997, tt:3359.668\n",
      "Ep:96, loss:0.00001, loss_test:0.01074, lr:5.76e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.988, tt:3393.878\n",
      "Ep:97, loss:0.00000, loss_test:0.01079, lr:5.76e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.973, tt:3427.381\n",
      "Ep:98, loss:0.00000, loss_test:0.01085, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.957, tt:3460.760\n",
      "Ep:99, loss:0.00000, loss_test:0.01082, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.942, tt:3494.240\n",
      "Ep:100, loss:0.00000, loss_test:0.01079, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.928, tt:3527.752\n",
      "Ep:101, loss:0.00000, loss_test:0.01087, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.935, tt:3563.387\n",
      "Ep:102, loss:0.00000, loss_test:0.01097, lr:5.76e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.920, tt:3596.801\n",
      "Ep:103, loss:0.00000, loss_test:0.01092, lr:5.76e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.921, tt:3631.742\n",
      "Ep:104, loss:0.00000, loss_test:0.01099, lr:5.71e-02, fs:0.87129 (r=0.889,p=0.854),  time:34.919, tt:3666.462\n",
      "Ep:105, loss:0.00000, loss_test:0.01095, lr:5.65e-02, fs:0.85859 (r=0.859,p=0.859),  time:34.911, tt:3700.550\n",
      "Ep:106, loss:0.00000, loss_test:0.01101, lr:5.59e-02, fs:0.86567 (r=0.879,p=0.853),  time:34.921, tt:3736.524\n",
      "Ep:107, loss:0.00000, loss_test:0.01102, lr:5.54e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.913, tt:3770.624\n",
      "Ep:108, loss:0.00000, loss_test:0.01110, lr:5.48e-02, fs:0.87000 (r=0.879,p=0.861),  time:34.921, tt:3806.358\n",
      "Ep:109, loss:0.00000, loss_test:0.01115, lr:5.43e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.923, tt:3841.546\n",
      "Ep:110, loss:0.00000, loss_test:0.01116, lr:5.37e-02, fs:0.86432 (r=0.869,p=0.860),  time:34.942, tt:3878.600\n",
      "Ep:111, loss:0.00000, loss_test:0.01115, lr:5.32e-02, fs:0.87562 (r=0.889,p=0.863),  time:34.955, tt:3914.922\n",
      "Ep:112, loss:0.00000, loss_test:0.01119, lr:5.27e-02, fs:0.86294 (r=0.859,p=0.867),  time:34.962, tt:3950.738\n",
      "Ep:113, loss:0.00000, loss_test:0.01130, lr:5.21e-02, fs:0.87310 (r=0.869,p=0.878),  time:34.971, tt:3986.649\n",
      "Ep:114, loss:0.00000, loss_test:0.01130, lr:5.16e-02, fs:0.86735 (r=0.859,p=0.876),  time:34.999, tt:4024.887\n",
      "Ep:115, loss:0.00000, loss_test:0.01134, lr:5.11e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.001, tt:4060.167\n",
      "Ep:116, loss:0.00000, loss_test:0.01135, lr:5.06e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.010, tt:4096.150\n",
      "Ep:117, loss:0.00000, loss_test:0.01146, lr:5.01e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.041, tt:4134.806\n",
      "Ep:118, loss:0.00000, loss_test:0.01147, lr:4.96e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.048, tt:4170.676\n",
      "Ep:119, loss:0.00000, loss_test:0.01150, lr:4.91e-02, fs:0.86735 (r=0.859,p=0.876),  time:35.058, tt:4206.931\n",
      "Ep:120, loss:0.00000, loss_test:0.01154, lr:4.86e-02, fs:0.87179 (r=0.859,p=0.885),  time:35.076, tt:4244.194\n",
      "Ep:121, loss:0.00000, loss_test:0.01159, lr:4.81e-02, fs:0.86154 (r=0.848,p=0.875),  time:35.087, tt:4280.625\n",
      "Ep:122, loss:0.00000, loss_test:0.01165, lr:4.76e-02, fs:0.87629 (r=0.859,p=0.895),  time:35.077, tt:4314.455\n",
      "##########Best model found so far##########\n",
      "Ep:123, loss:0.00000, loss_test:0.01164, lr:4.76e-02, fs:0.86598 (r=0.848,p=0.884),  time:35.088, tt:4350.949\n",
      "Ep:124, loss:0.00000, loss_test:0.01169, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.094, tt:4386.728\n",
      "Ep:125, loss:0.00000, loss_test:0.01173, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.105, tt:4423.239\n",
      "Ep:126, loss:0.00000, loss_test:0.01181, lr:4.76e-02, fs:0.87047 (r=0.848,p=0.894),  time:35.105, tt:4458.386\n",
      "Ep:127, loss:0.00000, loss_test:0.01184, lr:4.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.107, tt:4493.746\n",
      "Ep:128, loss:0.00000, loss_test:0.01187, lr:4.76e-02, fs:0.86458 (r=0.838,p=0.892),  time:35.117, tt:4530.086\n",
      "Ep:129, loss:0.00000, loss_test:0.01190, lr:4.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.115, tt:4564.903\n",
      "Ep:130, loss:0.00000, loss_test:0.01196, lr:4.76e-02, fs:0.85864 (r=0.828,p=0.891),  time:35.114, tt:4599.899\n",
      "Ep:131, loss:0.00000, loss_test:0.01195, lr:4.76e-02, fs:0.86316 (r=0.828,p=0.901),  time:35.111, tt:4634.696\n",
      "Ep:132, loss:0.00000, loss_test:0.01199, lr:4.76e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.103, tt:4668.723\n",
      "Ep:133, loss:0.00000, loss_test:0.01206, lr:4.76e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.113, tt:4705.163\n",
      "Ep:134, loss:0.00000, loss_test:0.01218, lr:4.71e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.119, tt:4741.115\n",
      "Ep:135, loss:0.00000, loss_test:0.01214, lr:4.67e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.117, tt:4775.854\n",
      "Ep:136, loss:0.00000, loss_test:0.01222, lr:4.62e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.119, tt:4811.261\n",
      "Ep:137, loss:0.00000, loss_test:0.01216, lr:4.57e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.119, tt:4846.384\n",
      "Ep:138, loss:0.00000, loss_test:0.01224, lr:4.53e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.119, tt:4881.570\n",
      "Ep:139, loss:0.00000, loss_test:0.01228, lr:4.48e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.123, tt:4917.170\n",
      "Ep:140, loss:0.00000, loss_test:0.01235, lr:4.44e-02, fs:0.85263 (r=0.818,p=0.890),  time:35.130, tt:4953.280\n",
      "Ep:141, loss:0.00000, loss_test:0.01234, lr:4.39e-02, fs:0.85714 (r=0.818,p=0.900),  time:35.142, tt:4990.140\n",
      "Ep:142, loss:0.00000, loss_test:0.01238, lr:4.35e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.143, tt:5025.455\n",
      "Ep:143, loss:0.00000, loss_test:0.01241, lr:4.31e-02, fs:0.84492 (r=0.798,p=0.898),  time:35.142, tt:5060.394\n",
      "Ep:144, loss:0.00000, loss_test:0.01244, lr:4.26e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.137, tt:5094.913\n",
      "Ep:145, loss:0.00000, loss_test:0.01249, lr:4.22e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.137, tt:5130.016\n",
      "Ep:146, loss:0.00000, loss_test:0.01252, lr:4.18e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.137, tt:5165.146\n",
      "Ep:147, loss:0.00000, loss_test:0.01255, lr:4.14e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.143, tt:5201.236\n",
      "Ep:148, loss:0.00000, loss_test:0.01256, lr:4.10e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.135, tt:5235.143\n",
      "Ep:149, loss:0.00000, loss_test:0.01263, lr:4.05e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.143, tt:5271.483\n",
      "Ep:150, loss:0.00000, loss_test:0.01266, lr:4.01e-02, fs:0.85106 (r=0.808,p=0.899),  time:35.139, tt:5306.014\n",
      "Ep:151, loss:0.00000, loss_test:0.01264, lr:3.97e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.152, tt:5343.084\n",
      "Ep:152, loss:0.00000, loss_test:0.01269, lr:3.93e-02, fs:0.84656 (r=0.808,p=0.889),  time:35.156, tt:5378.822\n",
      "Ep:153, loss:0.00000, loss_test:0.01270, lr:3.89e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.161, tt:5414.804\n",
      "Ep:154, loss:0.00000, loss_test:0.01272, lr:3.86e-02, fs:0.84492 (r=0.798,p=0.898),  time:35.155, tt:5449.054\n",
      "Ep:155, loss:0.00000, loss_test:0.01275, lr:3.82e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.157, tt:5484.514\n",
      "Ep:156, loss:0.00000, loss_test:0.01280, lr:3.78e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.152, tt:5518.868\n",
      "Ep:157, loss:0.00000, loss_test:0.01283, lr:3.74e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.148, tt:5553.444\n",
      "Ep:158, loss:0.00000, loss_test:0.01282, lr:3.70e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.138, tt:5586.879\n",
      "Ep:159, loss:0.00000, loss_test:0.01283, lr:3.67e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.144, tt:5623.042\n",
      "Ep:160, loss:0.00000, loss_test:0.01288, lr:3.63e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.146, tt:5658.565\n",
      "Ep:161, loss:0.00000, loss_test:0.01295, lr:3.59e-02, fs:0.84043 (r=0.798,p=0.888),  time:35.140, tt:5692.724\n",
      "Ep:162, loss:0.00000, loss_test:0.01293, lr:3.56e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.139, tt:5727.731\n",
      "Ep:163, loss:0.00000, loss_test:0.01295, lr:3.52e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.142, tt:5763.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:164, loss:0.00000, loss_test:0.01297, lr:3.49e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.151, tt:5799.985\n",
      "Ep:165, loss:0.00000, loss_test:0.01301, lr:3.45e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.161, tt:5836.764\n",
      "Ep:166, loss:0.00000, loss_test:0.01302, lr:3.42e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.170, tt:5873.312\n",
      "Ep:167, loss:0.00000, loss_test:0.01305, lr:3.38e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.177, tt:5909.684\n",
      "Ep:168, loss:0.00000, loss_test:0.01306, lr:3.35e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.183, tt:5945.871\n",
      "Ep:169, loss:0.00000, loss_test:0.01309, lr:3.32e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.186, tt:5981.682\n",
      "Ep:170, loss:0.00000, loss_test:0.01310, lr:3.28e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.193, tt:6018.022\n",
      "Ep:171, loss:0.00000, loss_test:0.01315, lr:3.25e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.193, tt:6053.202\n",
      "Ep:172, loss:0.00000, loss_test:0.01314, lr:3.22e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.198, tt:6089.317\n",
      "Ep:173, loss:0.00000, loss_test:0.01316, lr:3.19e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.207, tt:6126.008\n",
      "Ep:174, loss:0.00000, loss_test:0.01322, lr:3.15e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.207, tt:6161.155\n",
      "Ep:175, loss:0.00000, loss_test:0.01322, lr:3.12e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.210, tt:6196.937\n",
      "Ep:176, loss:0.00000, loss_test:0.01324, lr:3.09e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.216, tt:6233.189\n",
      "Ep:177, loss:0.00000, loss_test:0.01321, lr:3.06e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.225, tt:6270.074\n",
      "Ep:178, loss:0.00000, loss_test:0.01328, lr:3.03e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.226, tt:6305.403\n",
      "Ep:179, loss:0.00000, loss_test:0.01328, lr:3.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.228, tt:6341.075\n",
      "Ep:180, loss:0.00000, loss_test:0.01330, lr:2.97e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.223, tt:6375.429\n",
      "Ep:181, loss:0.00000, loss_test:0.01331, lr:2.94e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.229, tt:6411.696\n",
      "Ep:182, loss:0.00000, loss_test:0.01331, lr:2.91e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.236, tt:6448.271\n",
      "Ep:183, loss:0.00000, loss_test:0.01336, lr:2.88e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.239, tt:6484.034\n",
      "Ep:184, loss:0.00000, loss_test:0.01338, lr:2.85e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.243, tt:6519.996\n",
      "Ep:185, loss:0.00000, loss_test:0.01341, lr:2.82e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.257, tt:6557.851\n",
      "Ep:186, loss:0.00000, loss_test:0.01343, lr:2.80e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.263, tt:6594.097\n",
      "Ep:187, loss:0.00000, loss_test:0.01339, lr:2.77e-02, fs:0.83871 (r=0.788,p=0.897),  time:35.262, tt:6629.302\n",
      "Ep:188, loss:0.00000, loss_test:0.01345, lr:2.74e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.266, tt:6665.328\n",
      "Ep:189, loss:0.00000, loss_test:0.01347, lr:2.71e-02, fs:0.82796 (r=0.778,p=0.885),  time:35.271, tt:6701.509\n",
      "Ep:190, loss:0.00000, loss_test:0.01348, lr:2.69e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.277, tt:6737.875\n",
      "Ep:191, loss:0.00000, loss_test:0.01350, lr:2.66e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.281, tt:6773.997\n",
      "Ep:192, loss:0.00000, loss_test:0.01348, lr:2.63e-02, fs:0.83422 (r=0.788,p=0.886),  time:35.289, tt:6810.824\n",
      "Ep:193, loss:0.00000, loss_test:0.01352, lr:2.61e-02, fs:0.81522 (r=0.758,p=0.882),  time:35.220, tt:6832.775\n",
      "Ep:194, loss:0.00000, loss_test:0.01356, lr:2.58e-02, fs:0.82162 (r=0.768,p=0.884),  time:35.117, tt:6847.790\n",
      "Ep:195, loss:0.00000, loss_test:0.01353, lr:2.55e-02, fs:0.80220 (r=0.737,p=0.880),  time:35.006, tt:6861.144\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"6-6\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_300_250_200_150\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)\n",
    "\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=6e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(0), #_of_option for loss \n",
    "            loss_parameters=\"0.3+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,196,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14283, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.854, tt:51.854\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14128, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.706, tt:101.412\n",
      "Ep:2, loss:0.00027, loss_test:0.13841, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:50.334, tt:151.003\n",
      "Ep:3, loss:0.00027, loss_test:0.13338, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:50.291, tt:201.166\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12423, lr:1.00e-02, fs:0.68310 (r=0.980,p=0.524),  time:50.492, tt:252.462\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11069, lr:1.00e-02, fs:0.72199 (r=0.879,p=0.613),  time:51.104, tt:306.625\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00022, loss_test:0.10515, lr:1.00e-02, fs:0.70936 (r=0.727,p=0.692),  time:51.161, tt:358.128\n",
      "Ep:7, loss:0.00021, loss_test:0.10251, lr:1.00e-02, fs:0.74208 (r=0.828,p=0.672),  time:51.596, tt:412.769\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10303, lr:1.00e-02, fs:0.74689 (r=0.909,p=0.634),  time:51.891, tt:467.021\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.09754, lr:1.00e-02, fs:0.76018 (r=0.848,p=0.689),  time:51.705, tt:517.054\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00019, loss_test:0.09486, lr:1.00e-02, fs:0.76279 (r=0.828,p=0.707),  time:51.469, tt:566.154\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09418, lr:1.00e-02, fs:0.77533 (r=0.889,p=0.688),  time:51.431, tt:617.176\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09290, lr:1.00e-02, fs:0.76786 (r=0.869,p=0.688),  time:51.555, tt:670.216\n",
      "Ep:13, loss:0.00018, loss_test:0.09027, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:51.547, tt:721.665\n",
      "Ep:14, loss:0.00017, loss_test:0.08812, lr:1.00e-02, fs:0.78095 (r=0.828,p=0.739),  time:51.676, tt:775.135\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08807, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:51.805, tt:828.879\n",
      "Ep:16, loss:0.00016, loss_test:0.08690, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:51.918, tt:882.614\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.08501, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:51.888, tt:933.982\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.08397, lr:1.00e-02, fs:0.79245 (r=0.848,p=0.743),  time:51.998, tt:987.967\n",
      "Ep:19, loss:0.00015, loss_test:0.08416, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:51.933, tt:1038.656\n",
      "Ep:20, loss:0.00015, loss_test:0.08272, lr:1.00e-02, fs:0.80383 (r=0.848,p=0.764),  time:51.982, tt:1091.615\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.08104, lr:1.00e-02, fs:0.81553 (r=0.848,p=0.785),  time:52.020, tt:1144.433\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.08110, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:51.992, tt:1195.817\n",
      "Ep:23, loss:0.00014, loss_test:0.07845, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:51.938, tt:1246.512\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.07958, lr:1.00e-02, fs:0.81951 (r=0.848,p=0.792),  time:51.973, tt:1299.319\n",
      "Ep:25, loss:0.00013, loss_test:0.07938, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:51.983, tt:1351.549\n",
      "Ep:26, loss:0.00013, loss_test:0.07854, lr:1.00e-02, fs:0.79612 (r=0.828,p=0.766),  time:51.965, tt:1403.067\n",
      "Ep:27, loss:0.00012, loss_test:0.07816, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:52.003, tt:1456.077\n",
      "Ep:28, loss:0.00012, loss_test:0.07737, lr:1.00e-02, fs:0.79798 (r=0.798,p=0.798),  time:52.075, tt:1510.164\n",
      "Ep:29, loss:0.00011, loss_test:0.07635, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:52.119, tt:1563.564\n",
      "Ep:30, loss:0.00011, loss_test:0.07523, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:52.155, tt:1616.798\n",
      "Ep:31, loss:0.00011, loss_test:0.07613, lr:1.00e-02, fs:0.78125 (r=0.758,p=0.806),  time:52.183, tt:1669.868\n",
      "Ep:32, loss:0.00010, loss_test:0.07548, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:52.201, tt:1722.647\n",
      "Ep:33, loss:0.00010, loss_test:0.07520, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:52.219, tt:1775.456\n",
      "Ep:34, loss:0.00010, loss_test:0.07555, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:52.225, tt:1827.890\n",
      "Ep:35, loss:0.00009, loss_test:0.07383, lr:9.90e-03, fs:0.79167 (r=0.768,p=0.817),  time:52.228, tt:1880.194\n",
      "Ep:36, loss:0.00009, loss_test:0.07465, lr:9.80e-03, fs:0.79570 (r=0.747,p=0.851),  time:52.263, tt:1933.722\n",
      "Ep:37, loss:0.00009, loss_test:0.07261, lr:9.70e-03, fs:0.81000 (r=0.818,p=0.802),  time:52.228, tt:1984.651\n",
      "Ep:38, loss:0.00009, loss_test:0.07367, lr:9.61e-03, fs:0.79121 (r=0.727,p=0.867),  time:52.217, tt:2036.475\n",
      "Ep:39, loss:0.00008, loss_test:0.07198, lr:9.51e-03, fs:0.80628 (r=0.778,p=0.837),  time:52.155, tt:2086.213\n",
      "Ep:40, loss:0.00008, loss_test:0.07130, lr:9.41e-03, fs:0.81481 (r=0.778,p=0.856),  time:52.163, tt:2138.700\n",
      "Ep:41, loss:0.00008, loss_test:0.07059, lr:9.32e-03, fs:0.81675 (r=0.788,p=0.848),  time:52.148, tt:2190.234\n",
      "Ep:42, loss:0.00008, loss_test:0.07110, lr:9.23e-03, fs:0.81081 (r=0.758,p=0.872),  time:52.152, tt:2242.557\n",
      "Ep:43, loss:0.00007, loss_test:0.06993, lr:9.14e-03, fs:0.80214 (r=0.758,p=0.852),  time:52.120, tt:2293.260\n",
      "Ep:44, loss:0.00007, loss_test:0.07031, lr:9.04e-03, fs:0.81522 (r=0.758,p=0.882),  time:52.119, tt:2345.368\n",
      "Ep:45, loss:0.00007, loss_test:0.07075, lr:8.95e-03, fs:0.80874 (r=0.747,p=0.881),  time:52.096, tt:2396.419\n",
      "Ep:46, loss:0.00007, loss_test:0.06875, lr:8.86e-03, fs:0.80000 (r=0.768,p=0.835),  time:52.102, tt:2448.771\n",
      "Ep:47, loss:0.00007, loss_test:0.07148, lr:8.78e-03, fs:0.77907 (r=0.677,p=0.918),  time:52.114, tt:2501.466\n",
      "Ep:48, loss:0.00006, loss_test:0.06878, lr:8.69e-03, fs:0.82902 (r=0.808,p=0.851),  time:52.079, tt:2551.883\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00007, loss_test:0.07131, lr:8.69e-03, fs:0.80460 (r=0.707,p=0.933),  time:52.075, tt:2603.753\n",
      "Ep:50, loss:0.00006, loss_test:0.06881, lr:8.69e-03, fs:0.78495 (r=0.737,p=0.839),  time:52.104, tt:2657.280\n",
      "Ep:51, loss:0.00006, loss_test:0.06853, lr:8.69e-03, fs:0.80447 (r=0.727,p=0.900),  time:52.110, tt:2709.697\n",
      "Ep:52, loss:0.00006, loss_test:0.06647, lr:8.69e-03, fs:0.79781 (r=0.737,p=0.869),  time:52.102, tt:2761.380\n",
      "Ep:53, loss:0.00006, loss_test:0.06893, lr:8.69e-03, fs:0.80226 (r=0.717,p=0.910),  time:52.105, tt:2813.688\n",
      "Ep:54, loss:0.00006, loss_test:0.06698, lr:8.69e-03, fs:0.79330 (r=0.717,p=0.887),  time:52.074, tt:2864.073\n",
      "Ep:55, loss:0.00005, loss_test:0.06850, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.084, tt:2916.707\n",
      "Ep:56, loss:0.00005, loss_test:0.06658, lr:8.69e-03, fs:0.79781 (r=0.737,p=0.869),  time:52.063, tt:2967.611\n",
      "Ep:57, loss:0.00005, loss_test:0.06916, lr:8.69e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.040, tt:3018.306\n",
      "Ep:58, loss:0.00005, loss_test:0.06770, lr:8.69e-03, fs:0.80460 (r=0.707,p=0.933),  time:52.067, tt:3071.973\n",
      "Ep:59, loss:0.00005, loss_test:0.06740, lr:8.69e-03, fs:0.82222 (r=0.747,p=0.914),  time:52.058, tt:3123.457\n",
      "Ep:60, loss:0.00005, loss_test:0.06596, lr:8.60e-03, fs:0.80000 (r=0.707,p=0.921),  time:52.065, tt:3175.967\n",
      "Ep:61, loss:0.00005, loss_test:0.06763, lr:8.51e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.032, tt:3225.959\n",
      "Ep:62, loss:0.00004, loss_test:0.06426, lr:8.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:51.997, tt:3275.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:63, loss:0.00004, loss_test:0.06474, lr:8.35e-03, fs:0.81768 (r=0.747,p=0.902),  time:51.997, tt:3327.821\n",
      "Ep:64, loss:0.00004, loss_test:0.06618, lr:8.26e-03, fs:0.80899 (r=0.727,p=0.911),  time:52.009, tt:3380.561\n",
      "Ep:65, loss:0.00004, loss_test:0.06775, lr:8.18e-03, fs:0.81609 (r=0.717,p=0.947),  time:52.038, tt:3434.519\n",
      "Ep:66, loss:0.00004, loss_test:0.06575, lr:8.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.058, tt:3487.914\n",
      "Ep:67, loss:0.00004, loss_test:0.06664, lr:8.02e-03, fs:0.81143 (r=0.717,p=0.934),  time:52.050, tt:3539.410\n",
      "Ep:68, loss:0.00003, loss_test:0.06591, lr:7.94e-03, fs:0.80682 (r=0.717,p=0.922),  time:52.036, tt:3590.507\n",
      "Ep:69, loss:0.00003, loss_test:0.06897, lr:7.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.052, tt:3643.654\n",
      "Ep:70, loss:0.00003, loss_test:0.06479, lr:7.78e-03, fs:0.82486 (r=0.737,p=0.936),  time:52.037, tt:3694.632\n",
      "Ep:71, loss:0.00003, loss_test:0.06859, lr:7.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.033, tt:3746.351\n",
      "Ep:72, loss:0.00003, loss_test:0.06510, lr:7.62e-03, fs:0.82486 (r=0.737,p=0.936),  time:52.029, tt:3798.112\n",
      "Ep:73, loss:0.00003, loss_test:0.07069, lr:7.55e-03, fs:0.80233 (r=0.697,p=0.945),  time:52.045, tt:3851.301\n",
      "Ep:74, loss:0.00003, loss_test:0.06560, lr:7.47e-03, fs:0.81564 (r=0.737,p=0.912),  time:52.076, tt:3905.727\n",
      "Ep:75, loss:0.00003, loss_test:0.06954, lr:7.40e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.074, tt:3957.641\n",
      "Ep:76, loss:0.00003, loss_test:0.06794, lr:7.32e-03, fs:0.82486 (r=0.737,p=0.936),  time:52.083, tt:4010.395\n",
      "Ep:77, loss:0.00003, loss_test:0.06916, lr:7.25e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.091, tt:4063.077\n",
      "Ep:78, loss:0.00002, loss_test:0.06655, lr:7.18e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.087, tt:4114.900\n",
      "Ep:79, loss:0.00002, loss_test:0.07067, lr:7.11e-03, fs:0.81609 (r=0.717,p=0.947),  time:52.084, tt:4166.733\n",
      "Ep:80, loss:0.00002, loss_test:0.06570, lr:7.03e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.089, tt:4219.195\n",
      "Ep:81, loss:0.00002, loss_test:0.06863, lr:6.96e-03, fs:0.81609 (r=0.717,p=0.947),  time:52.073, tt:4270.011\n",
      "Ep:82, loss:0.00002, loss_test:0.06985, lr:6.89e-03, fs:0.81818 (r=0.727,p=0.935),  time:52.052, tt:4320.311\n",
      "Ep:83, loss:0.00002, loss_test:0.06822, lr:6.83e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.056, tt:4372.686\n",
      "Ep:84, loss:0.00002, loss_test:0.06772, lr:6.76e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.063, tt:4425.338\n",
      "Ep:85, loss:0.00002, loss_test:0.06729, lr:6.69e-03, fs:0.82955 (r=0.737,p=0.948),  time:52.022, tt:4473.920\n",
      "##########Best model found so far##########\n",
      "Ep:86, loss:0.00002, loss_test:0.06802, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.010, tt:4524.830\n",
      "Ep:87, loss:0.00002, loss_test:0.06665, lr:6.69e-03, fs:0.82955 (r=0.737,p=0.948),  time:52.006, tt:4576.566\n",
      "Ep:88, loss:0.00002, loss_test:0.06863, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.007, tt:4628.582\n",
      "Ep:89, loss:0.00002, loss_test:0.06684, lr:6.69e-03, fs:0.82955 (r=0.737,p=0.948),  time:52.024, tt:4682.118\n",
      "Ep:90, loss:0.00002, loss_test:0.06928, lr:6.69e-03, fs:0.81609 (r=0.717,p=0.947),  time:52.012, tt:4733.098\n",
      "Ep:91, loss:0.00002, loss_test:0.06583, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.009, tt:4784.833\n",
      "Ep:92, loss:0.00002, loss_test:0.06978, lr:6.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.016, tt:4837.473\n",
      "Ep:93, loss:0.00002, loss_test:0.06764, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.008, tt:4888.784\n",
      "Ep:94, loss:0.00001, loss_test:0.06649, lr:6.69e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.007, tt:4940.644\n",
      "Ep:95, loss:0.00001, loss_test:0.06730, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.015, tt:4993.483\n",
      "Ep:96, loss:0.00001, loss_test:0.07015, lr:6.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.007, tt:5044.634\n",
      "Ep:97, loss:0.00001, loss_test:0.06862, lr:6.62e-03, fs:0.82955 (r=0.737,p=0.948),  time:51.991, tt:5095.146\n",
      "Ep:98, loss:0.00001, loss_test:0.06484, lr:6.56e-03, fs:0.82759 (r=0.727,p=0.960),  time:51.995, tt:5147.515\n",
      "Ep:99, loss:0.00001, loss_test:0.07111, lr:6.49e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.008, tt:5200.850\n",
      "Ep:100, loss:0.00001, loss_test:0.06491, lr:6.43e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.000, tt:5251.998\n",
      "Ep:101, loss:0.00001, loss_test:0.07172, lr:6.36e-03, fs:0.80925 (r=0.707,p=0.946),  time:52.023, tt:5306.358\n",
      "Ep:102, loss:0.00001, loss_test:0.06585, lr:6.30e-03, fs:0.81356 (r=0.727,p=0.923),  time:52.027, tt:5358.778\n",
      "Ep:103, loss:0.00001, loss_test:0.06997, lr:6.24e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.034, tt:5411.544\n",
      "Ep:104, loss:0.00001, loss_test:0.06587, lr:6.17e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.034, tt:5463.520\n",
      "Ep:105, loss:0.00001, loss_test:0.06870, lr:6.11e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.036, tt:5515.797\n",
      "Ep:106, loss:0.00001, loss_test:0.06390, lr:6.05e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.032, tt:5567.450\n",
      "Ep:107, loss:0.00001, loss_test:0.06944, lr:5.99e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.050, tt:5621.381\n",
      "Ep:108, loss:0.00001, loss_test:0.06683, lr:5.93e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.039, tt:5672.296\n",
      "Ep:109, loss:0.00001, loss_test:0.06776, lr:5.87e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.022, tt:5722.409\n",
      "Ep:110, loss:0.00001, loss_test:0.06609, lr:5.81e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.037, tt:5776.089\n",
      "Ep:111, loss:0.00001, loss_test:0.06736, lr:5.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.039, tt:5828.333\n",
      "Ep:112, loss:0.00001, loss_test:0.06680, lr:5.70e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.039, tt:5880.401\n",
      "Ep:113, loss:0.00001, loss_test:0.06800, lr:5.64e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.040, tt:5932.516\n",
      "Ep:114, loss:0.00001, loss_test:0.06691, lr:5.58e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.048, tt:5985.493\n",
      "Ep:115, loss:0.00001, loss_test:0.06846, lr:5.53e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.052, tt:6038.052\n",
      "Ep:116, loss:0.00001, loss_test:0.06655, lr:5.47e-03, fs:0.82286 (r=0.727,p=0.947),  time:52.052, tt:6090.037\n",
      "Ep:117, loss:0.00001, loss_test:0.06988, lr:5.42e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.057, tt:6142.680\n",
      "Ep:118, loss:0.00001, loss_test:0.06561, lr:5.36e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.071, tt:6196.421\n",
      "Ep:119, loss:0.00001, loss_test:0.06774, lr:5.31e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.069, tt:6248.289\n",
      "Ep:120, loss:0.00001, loss_test:0.06681, lr:5.26e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.081, tt:6301.853\n",
      "Ep:121, loss:0.00001, loss_test:0.06679, lr:5.20e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.090, tt:6354.924\n",
      "Ep:122, loss:0.00001, loss_test:0.06690, lr:5.15e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.098, tt:6408.085\n",
      "Ep:123, loss:0.00001, loss_test:0.06649, lr:5.10e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.076, tt:6457.427\n",
      "Ep:124, loss:0.00001, loss_test:0.06810, lr:5.05e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.054, tt:6506.813\n",
      "Ep:125, loss:0.00001, loss_test:0.06596, lr:5.00e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.038, tt:6556.745\n",
      "Ep:126, loss:0.00001, loss_test:0.06796, lr:4.95e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.046, tt:6609.856\n",
      "Ep:127, loss:0.00001, loss_test:0.06667, lr:4.90e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.069, tt:6664.875\n",
      "Ep:128, loss:0.00001, loss_test:0.06789, lr:4.85e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.080, tt:6718.283\n",
      "Ep:129, loss:0.00001, loss_test:0.06695, lr:4.80e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.107, tt:6773.876\n",
      "Ep:130, loss:0.00001, loss_test:0.06653, lr:4.75e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.137, tt:6829.995\n",
      "Ep:131, loss:0.00001, loss_test:0.06642, lr:4.71e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.162, tt:6885.379\n",
      "Ep:132, loss:0.00001, loss_test:0.06826, lr:4.66e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.177, tt:6939.587\n",
      "Ep:133, loss:0.00001, loss_test:0.06603, lr:4.61e-03, fs:0.82759 (r=0.727,p=0.960),  time:52.193, tt:6993.828\n",
      "Ep:134, loss:0.00001, loss_test:0.06791, lr:4.57e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.207, tt:7047.940\n",
      "Ep:135, loss:0.00001, loss_test:0.06695, lr:4.52e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.217, tt:7101.517\n",
      "Ep:136, loss:0.00001, loss_test:0.06659, lr:4.48e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.233, tt:7155.943\n",
      "Ep:137, loss:0.00001, loss_test:0.06679, lr:4.43e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.235, tt:7208.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:138, loss:0.00001, loss_test:0.06672, lr:4.39e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.251, tt:7262.869\n",
      "Ep:139, loss:0.00001, loss_test:0.06747, lr:4.34e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.254, tt:7315.573\n",
      "Ep:140, loss:0.00001, loss_test:0.06696, lr:4.30e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.258, tt:7368.388\n",
      "Ep:141, loss:0.00001, loss_test:0.06768, lr:4.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.290, tt:7425.230\n",
      "Ep:142, loss:0.00001, loss_test:0.06705, lr:4.21e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.307, tt:7479.894\n",
      "Ep:143, loss:0.00001, loss_test:0.06646, lr:4.17e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.328, tt:7535.268\n",
      "Ep:144, loss:0.00001, loss_test:0.06763, lr:4.13e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.333, tt:7588.352\n",
      "Ep:145, loss:0.00001, loss_test:0.06660, lr:4.09e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.344, tt:7642.212\n",
      "Ep:146, loss:0.00000, loss_test:0.06770, lr:4.05e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.356, tt:7696.293\n",
      "Ep:147, loss:0.00000, loss_test:0.06717, lr:4.01e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.364, tt:7749.853\n",
      "Ep:148, loss:0.00000, loss_test:0.06705, lr:3.97e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.371, tt:7803.236\n",
      "Ep:149, loss:0.00000, loss_test:0.06780, lr:3.93e-03, fs:0.80000 (r=0.687,p=0.958),  time:52.376, tt:7856.423\n",
      "Ep:150, loss:0.00000, loss_test:0.06738, lr:3.89e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.392, tt:7911.187\n",
      "Ep:151, loss:0.00000, loss_test:0.06645, lr:3.85e-03, fs:0.82081 (r=0.717,p=0.959),  time:52.398, tt:7964.540\n",
      "Ep:152, loss:0.00000, loss_test:0.06822, lr:3.81e-03, fs:0.79290 (r=0.677,p=0.957),  time:52.405, tt:8017.908\n",
      "Ep:153, loss:0.00000, loss_test:0.06690, lr:3.77e-03, fs:0.81395 (r=0.707,p=0.959),  time:52.355, tt:8062.719\n",
      "Ep:154, loss:0.00000, loss_test:0.06773, lr:3.73e-03, fs:0.80702 (r=0.697,p=0.958),  time:52.357, tt:8115.371\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14675, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:52.746, tt:52.746\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14586, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.713, tt:103.426\n",
      "Ep:2, loss:0.00027, loss_test:0.14421, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:51.598, tt:154.793\n",
      "Ep:3, loss:0.00027, loss_test:0.14095, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:52.253, tt:209.013\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00025, loss_test:0.13484, lr:1.00e-02, fs:0.66434 (r=0.960,p=0.508),  time:52.604, tt:263.022\n",
      "Ep:5, loss:0.00023, loss_test:0.12433, lr:1.00e-02, fs:0.65198 (r=0.747,p=0.578),  time:52.830, tt:316.977\n",
      "Ep:6, loss:0.00022, loss_test:0.12516, lr:1.00e-02, fs:0.60914 (r=0.606,p=0.612),  time:53.020, tt:371.140\n",
      "Ep:7, loss:0.00021, loss_test:0.12187, lr:1.00e-02, fs:0.61321 (r=0.657,p=0.575),  time:53.089, tt:424.712\n",
      "Ep:8, loss:0.00020, loss_test:0.11892, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:53.187, tt:478.682\n",
      "Ep:9, loss:0.00019, loss_test:0.11718, lr:1.00e-02, fs:0.66667 (r=0.697,p=0.639),  time:53.412, tt:534.116\n",
      "Ep:10, loss:0.00019, loss_test:0.11861, lr:1.00e-02, fs:0.66995 (r=0.687,p=0.654),  time:53.356, tt:586.911\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00018, loss_test:0.11667, lr:1.00e-02, fs:0.68246 (r=0.727,p=0.643),  time:53.305, tt:639.656\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00017, loss_test:0.11441, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:53.310, tt:693.026\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.11337, lr:1.00e-02, fs:0.68627 (r=0.707,p=0.667),  time:53.282, tt:745.949\n",
      "Ep:14, loss:0.00016, loss_test:0.11419, lr:1.00e-02, fs:0.68932 (r=0.717,p=0.664),  time:53.383, tt:800.739\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.11284, lr:1.00e-02, fs:0.68900 (r=0.727,p=0.655),  time:53.468, tt:855.493\n",
      "Ep:16, loss:0.00015, loss_test:0.11129, lr:1.00e-02, fs:0.72081 (r=0.717,p=0.724),  time:53.443, tt:908.524\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.11180, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:53.296, tt:959.321\n",
      "Ep:18, loss:0.00014, loss_test:0.11054, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:53.205, tt:1010.903\n",
      "Ep:19, loss:0.00014, loss_test:0.11051, lr:1.00e-02, fs:0.71066 (r=0.707,p=0.714),  time:53.031, tt:1060.625\n",
      "Ep:20, loss:0.00013, loss_test:0.11168, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:52.991, tt:1112.812\n",
      "Ep:21, loss:0.00013, loss_test:0.10926, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:52.867, tt:1163.064\n",
      "Ep:22, loss:0.00013, loss_test:0.11052, lr:1.00e-02, fs:0.70707 (r=0.707,p=0.707),  time:52.806, tt:1214.544\n",
      "Ep:23, loss:0.00012, loss_test:0.10784, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:52.744, tt:1265.858\n",
      "Ep:24, loss:0.00012, loss_test:0.10919, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:52.783, tt:1319.563\n",
      "Ep:25, loss:0.00011, loss_test:0.10707, lr:1.00e-02, fs:0.70588 (r=0.727,p=0.686),  time:52.813, tt:1373.137\n",
      "Ep:26, loss:0.00011, loss_test:0.10879, lr:1.00e-02, fs:0.72165 (r=0.707,p=0.737),  time:52.743, tt:1424.065\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.10554, lr:1.00e-02, fs:0.71220 (r=0.737,p=0.689),  time:52.744, tt:1476.843\n",
      "Ep:28, loss:0.00010, loss_test:0.10747, lr:1.00e-02, fs:0.73016 (r=0.697,p=0.767),  time:52.743, tt:1529.554\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.10469, lr:1.00e-02, fs:0.71287 (r=0.727,p=0.699),  time:52.690, tt:1580.690\n",
      "Ep:30, loss:0.00010, loss_test:0.10815, lr:1.00e-02, fs:0.71958 (r=0.687,p=0.756),  time:52.688, tt:1633.315\n",
      "Ep:31, loss:0.00009, loss_test:0.10324, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:52.845, tt:1691.031\n",
      "Ep:32, loss:0.00009, loss_test:0.11047, lr:1.00e-02, fs:0.69945 (r=0.646,p=0.762),  time:52.986, tt:1748.527\n",
      "Ep:33, loss:0.00009, loss_test:0.10201, lr:1.00e-02, fs:0.73797 (r=0.697,p=0.784),  time:53.028, tt:1802.952\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.10344, lr:1.00e-02, fs:0.73913 (r=0.687,p=0.800),  time:53.023, tt:1855.798\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.10550, lr:1.00e-02, fs:0.74033 (r=0.677,p=0.817),  time:52.952, tt:1906.269\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.10127, lr:1.00e-02, fs:0.74074 (r=0.707,p=0.778),  time:52.954, tt:1959.311\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.10156, lr:1.00e-02, fs:0.75138 (r=0.687,p=0.829),  time:52.934, tt:2011.476\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.10721, lr:1.00e-02, fs:0.70718 (r=0.646,p=0.780),  time:52.983, tt:2066.345\n",
      "Ep:39, loss:0.00007, loss_test:0.09835, lr:1.00e-02, fs:0.76243 (r=0.697,p=0.841),  time:53.023, tt:2120.925\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00007, loss_test:0.10513, lr:1.00e-02, fs:0.71823 (r=0.657,p=0.793),  time:53.071, tt:2175.895\n",
      "Ep:41, loss:0.00006, loss_test:0.10431, lr:1.00e-02, fs:0.72000 (r=0.636,p=0.829),  time:53.072, tt:2229.012\n",
      "Ep:42, loss:0.00006, loss_test:0.10029, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:53.065, tt:2281.807\n",
      "Ep:43, loss:0.00006, loss_test:0.10438, lr:1.00e-02, fs:0.69006 (r=0.596,p=0.819),  time:53.041, tt:2333.797\n",
      "Ep:44, loss:0.00006, loss_test:0.10366, lr:1.00e-02, fs:0.75978 (r=0.687,p=0.850),  time:53.039, tt:2386.742\n",
      "Ep:45, loss:0.00005, loss_test:0.10990, lr:1.00e-02, fs:0.67429 (r=0.596,p=0.776),  time:53.041, tt:2439.881\n",
      "Ep:46, loss:0.00005, loss_test:0.10084, lr:1.00e-02, fs:0.77966 (r=0.697,p=0.885),  time:53.035, tt:2492.634\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00005, loss_test:0.10792, lr:1.00e-02, fs:0.67836 (r=0.586,p=0.806),  time:53.024, tt:2545.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:48, loss:0.00005, loss_test:0.10804, lr:1.00e-02, fs:0.71345 (r=0.616,p=0.847),  time:53.039, tt:2598.911\n",
      "Ep:49, loss:0.00005, loss_test:0.10938, lr:1.00e-02, fs:0.69091 (r=0.576,p=0.864),  time:53.050, tt:2652.493\n",
      "Ep:50, loss:0.00005, loss_test:0.10958, lr:1.00e-02, fs:0.68235 (r=0.586,p=0.817),  time:53.042, tt:2705.117\n",
      "Ep:51, loss:0.00004, loss_test:0.10746, lr:1.00e-02, fs:0.70238 (r=0.596,p=0.855),  time:53.026, tt:2757.369\n",
      "Ep:52, loss:0.00004, loss_test:0.11635, lr:1.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:53.024, tt:2810.269\n",
      "Ep:53, loss:0.00004, loss_test:0.11158, lr:1.00e-02, fs:0.72515 (r=0.626,p=0.861),  time:53.041, tt:2864.201\n",
      "Ep:54, loss:0.00004, loss_test:0.10965, lr:1.00e-02, fs:0.68235 (r=0.586,p=0.817),  time:53.046, tt:2917.528\n",
      "Ep:55, loss:0.00004, loss_test:0.11481, lr:1.00e-02, fs:0.69461 (r=0.586,p=0.853),  time:53.035, tt:2969.959\n",
      "Ep:56, loss:0.00004, loss_test:0.11334, lr:1.00e-02, fs:0.68639 (r=0.586,p=0.829),  time:53.015, tt:3021.829\n",
      "Ep:57, loss:0.00004, loss_test:0.11800, lr:1.00e-02, fs:0.69880 (r=0.586,p=0.866),  time:53.000, tt:3074.012\n",
      "Ep:58, loss:0.00003, loss_test:0.10831, lr:9.90e-03, fs:0.77966 (r=0.697,p=0.885),  time:52.987, tt:3126.231\n",
      "Ep:59, loss:0.00004, loss_test:0.11830, lr:9.80e-03, fs:0.67836 (r=0.586,p=0.806),  time:53.004, tt:3180.258\n",
      "Ep:60, loss:0.00004, loss_test:0.12659, lr:9.70e-03, fs:0.69091 (r=0.576,p=0.864),  time:52.981, tt:3231.858\n",
      "Ep:61, loss:0.00003, loss_test:0.10858, lr:9.61e-03, fs:0.69767 (r=0.606,p=0.822),  time:52.960, tt:3283.543\n",
      "Ep:62, loss:0.00004, loss_test:0.13428, lr:9.51e-03, fs:0.65432 (r=0.535,p=0.841),  time:52.941, tt:3335.311\n",
      "Ep:63, loss:0.00003, loss_test:0.11659, lr:9.41e-03, fs:0.68639 (r=0.586,p=0.829),  time:52.928, tt:3387.362\n",
      "Ep:64, loss:0.00003, loss_test:0.11573, lr:9.32e-03, fs:0.74854 (r=0.646,p=0.889),  time:52.930, tt:3440.454\n",
      "Ep:65, loss:0.00003, loss_test:0.12065, lr:9.23e-03, fs:0.70303 (r=0.586,p=0.879),  time:52.929, tt:3493.341\n",
      "Ep:66, loss:0.00003, loss_test:0.10980, lr:9.14e-03, fs:0.76836 (r=0.687,p=0.872),  time:52.948, tt:3547.533\n",
      "Ep:67, loss:0.00003, loss_test:0.12057, lr:9.04e-03, fs:0.69048 (r=0.586,p=0.841),  time:52.910, tt:3597.852\n",
      "Ep:68, loss:0.00003, loss_test:0.11881, lr:8.95e-03, fs:0.70732 (r=0.586,p=0.892),  time:52.926, tt:3651.871\n",
      "Ep:69, loss:0.00003, loss_test:0.11496, lr:8.86e-03, fs:0.69048 (r=0.586,p=0.841),  time:52.939, tt:3705.711\n",
      "Ep:70, loss:0.00002, loss_test:0.12561, lr:8.78e-03, fs:0.70440 (r=0.566,p=0.933),  time:52.953, tt:3759.658\n",
      "Ep:71, loss:0.00002, loss_test:0.11386, lr:8.69e-03, fs:0.70303 (r=0.586,p=0.879),  time:52.945, tt:3812.010\n",
      "Ep:72, loss:0.00002, loss_test:0.12956, lr:8.60e-03, fs:0.70807 (r=0.576,p=0.919),  time:52.952, tt:3865.474\n",
      "Ep:73, loss:0.00002, loss_test:0.12084, lr:8.51e-03, fs:0.69880 (r=0.586,p=0.866),  time:52.940, tt:3917.534\n",
      "Ep:74, loss:0.00002, loss_test:0.11962, lr:8.43e-03, fs:0.72727 (r=0.606,p=0.909),  time:52.963, tt:3972.252\n",
      "Ep:75, loss:0.00002, loss_test:0.12148, lr:8.35e-03, fs:0.69939 (r=0.576,p=0.891),  time:52.974, tt:4026.056\n",
      "Ep:76, loss:0.00002, loss_test:0.13007, lr:8.26e-03, fs:0.70807 (r=0.576,p=0.919),  time:52.968, tt:4078.510\n",
      "Ep:77, loss:0.00002, loss_test:0.11675, lr:8.18e-03, fs:0.70303 (r=0.586,p=0.879),  time:52.947, tt:4129.883\n",
      "Ep:78, loss:0.00002, loss_test:0.12700, lr:8.10e-03, fs:0.68387 (r=0.535,p=0.946),  time:52.960, tt:4183.869\n",
      "Ep:79, loss:0.00002, loss_test:0.12529, lr:8.02e-03, fs:0.70807 (r=0.576,p=0.919),  time:52.953, tt:4236.214\n",
      "Ep:80, loss:0.00002, loss_test:0.12259, lr:7.94e-03, fs:0.69939 (r=0.576,p=0.891),  time:52.888, tt:4283.917\n",
      "Ep:81, loss:0.00002, loss_test:0.13092, lr:7.86e-03, fs:0.70064 (r=0.556,p=0.948),  time:52.824, tt:4331.571\n",
      "Ep:82, loss:0.00002, loss_test:0.12197, lr:7.78e-03, fs:0.70807 (r=0.576,p=0.919),  time:52.755, tt:4378.651\n",
      "Ep:83, loss:0.00002, loss_test:0.12387, lr:7.70e-03, fs:0.69182 (r=0.556,p=0.917),  time:52.681, tt:4425.214\n",
      "Ep:84, loss:0.00002, loss_test:0.12521, lr:7.62e-03, fs:0.71250 (r=0.576,p=0.934),  time:52.698, tt:4479.333\n",
      "Ep:85, loss:0.00002, loss_test:0.12493, lr:7.55e-03, fs:0.69620 (r=0.556,p=0.932),  time:52.695, tt:4531.793\n",
      "Ep:86, loss:0.00001, loss_test:0.12351, lr:7.47e-03, fs:0.71698 (r=0.576,p=0.950),  time:52.692, tt:4584.209\n",
      "Ep:87, loss:0.00001, loss_test:0.13029, lr:7.40e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.687, tt:4636.468\n",
      "Ep:88, loss:0.00001, loss_test:0.12185, lr:7.32e-03, fs:0.71250 (r=0.576,p=0.934),  time:52.678, tt:4688.352\n",
      "Ep:89, loss:0.00001, loss_test:0.13090, lr:7.25e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.677, tt:4740.908\n",
      "Ep:90, loss:0.00001, loss_test:0.12333, lr:7.18e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.656, tt:4791.739\n",
      "Ep:91, loss:0.00001, loss_test:0.13138, lr:7.11e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.652, tt:4843.939\n",
      "Ep:92, loss:0.00001, loss_test:0.12437, lr:7.03e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.647, tt:4896.137\n",
      "Ep:93, loss:0.00001, loss_test:0.12627, lr:6.96e-03, fs:0.70064 (r=0.556,p=0.948),  time:52.649, tt:4948.982\n",
      "Ep:94, loss:0.00001, loss_test:0.12791, lr:6.89e-03, fs:0.72152 (r=0.576,p=0.966),  time:52.621, tt:4999.033\n",
      "Ep:95, loss:0.00001, loss_test:0.12871, lr:6.83e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.624, tt:5051.877\n",
      "Ep:96, loss:0.00001, loss_test:0.12530, lr:6.76e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.622, tt:5104.300\n",
      "Ep:97, loss:0.00001, loss_test:0.13199, lr:6.69e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.625, tt:5157.231\n",
      "Ep:98, loss:0.00001, loss_test:0.12778, lr:6.62e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.601, tt:5207.483\n",
      "Ep:99, loss:0.00001, loss_test:0.12928, lr:6.56e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.606, tt:5260.587\n",
      "Ep:100, loss:0.00001, loss_test:0.13236, lr:6.49e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.602, tt:5312.836\n",
      "Ep:101, loss:0.00001, loss_test:0.12910, lr:6.43e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.601, tt:5365.278\n",
      "Ep:102, loss:0.00001, loss_test:0.13001, lr:6.36e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.606, tt:5418.402\n",
      "Ep:103, loss:0.00001, loss_test:0.13158, lr:6.30e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.597, tt:5470.038\n",
      "Ep:104, loss:0.00001, loss_test:0.12714, lr:6.24e-03, fs:0.70513 (r=0.556,p=0.965),  time:52.577, tt:5520.578\n",
      "Ep:105, loss:0.00001, loss_test:0.14295, lr:6.17e-03, fs:0.70130 (r=0.545,p=0.982),  time:52.563, tt:5571.655\n",
      "Ep:106, loss:0.00001, loss_test:0.13015, lr:6.11e-03, fs:0.70968 (r=0.556,p=0.982),  time:52.554, tt:5623.320\n",
      "Ep:107, loss:0.00001, loss_test:0.13796, lr:6.05e-03, fs:0.68831 (r=0.535,p=0.964),  time:52.549, tt:5675.256\n",
      "Ep:108, loss:0.00001, loss_test:0.13494, lr:5.99e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.549, tt:5727.791\n",
      "Ep:109, loss:0.00001, loss_test:0.13188, lr:5.93e-03, fs:0.68831 (r=0.535,p=0.964),  time:52.553, tt:5780.839\n",
      "Ep:110, loss:0.00001, loss_test:0.13356, lr:5.87e-03, fs:0.70130 (r=0.545,p=0.982),  time:52.548, tt:5832.834\n",
      "Ep:111, loss:0.00001, loss_test:0.13440, lr:5.81e-03, fs:0.68831 (r=0.535,p=0.964),  time:52.550, tt:5885.545\n",
      "Ep:112, loss:0.00001, loss_test:0.13154, lr:5.75e-03, fs:0.70130 (r=0.545,p=0.982),  time:52.536, tt:5936.621\n",
      "Ep:113, loss:0.00001, loss_test:0.13513, lr:5.70e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.525, tt:5987.826\n",
      "Ep:114, loss:0.00001, loss_test:0.13654, lr:5.64e-03, fs:0.67550 (r=0.515,p=0.981),  time:52.524, tt:6040.281\n",
      "Ep:115, loss:0.00001, loss_test:0.13468, lr:5.58e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.512, tt:6091.374\n",
      "Ep:116, loss:0.00001, loss_test:0.13547, lr:5.53e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.491, tt:6141.418\n",
      "Ep:117, loss:0.00001, loss_test:0.13604, lr:5.47e-03, fs:0.68421 (r=0.525,p=0.981),  time:52.488, tt:6193.589\n",
      "Ep:118, loss:0.00001, loss_test:0.13516, lr:5.42e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.490, tt:6246.256\n",
      "Ep:119, loss:0.00001, loss_test:0.13816, lr:5.36e-03, fs:0.68000 (r=0.515,p=1.000),  time:52.498, tt:6299.712\n",
      "Ep:120, loss:0.00001, loss_test:0.13874, lr:5.31e-03, fs:0.65772 (r=0.495,p=0.980),  time:52.498, tt:6352.212\n",
      "Ep:121, loss:0.00001, loss_test:0.13656, lr:5.26e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.499, tt:6404.827\n",
      "Ep:122, loss:0.00001, loss_test:0.13882, lr:5.20e-03, fs:0.68874 (r=0.525,p=1.000),  time:52.473, tt:6454.220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:123, loss:0.00001, loss_test:0.13898, lr:5.15e-03, fs:0.66667 (r=0.505,p=0.980),  time:52.459, tt:6504.904\n",
      "Ep:124, loss:0.00001, loss_test:0.13652, lr:5.10e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.452, tt:6556.540\n",
      "Ep:125, loss:0.00001, loss_test:0.13875, lr:5.05e-03, fs:0.66667 (r=0.505,p=0.980),  time:52.433, tt:6606.541\n",
      "Ep:126, loss:0.00001, loss_test:0.13986, lr:5.00e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.438, tt:6659.620\n",
      "Ep:127, loss:0.00001, loss_test:0.13643, lr:4.95e-03, fs:0.69281 (r=0.535,p=0.981),  time:52.442, tt:6712.556\n",
      "Ep:128, loss:0.00001, loss_test:0.13966, lr:4.90e-03, fs:0.66667 (r=0.505,p=0.980),  time:52.445, tt:6765.408\n",
      "Ep:129, loss:0.00001, loss_test:0.14056, lr:4.85e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.424, tt:6815.178\n",
      "Ep:130, loss:0.00001, loss_test:0.13759, lr:4.80e-03, fs:0.69737 (r=0.535,p=1.000),  time:52.420, tt:6867.070\n",
      "Ep:131, loss:0.00001, loss_test:0.13770, lr:4.75e-03, fs:0.69737 (r=0.535,p=1.000),  time:52.423, tt:6919.789\n",
      "Ep:132, loss:0.00001, loss_test:0.14105, lr:4.71e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.401, tt:6969.293\n",
      "Ep:133, loss:0.00001, loss_test:0.13810, lr:4.66e-03, fs:0.68874 (r=0.525,p=1.000),  time:52.412, tt:7023.191\n",
      "Ep:134, loss:0.00001, loss_test:0.14001, lr:4.61e-03, fs:0.67114 (r=0.505,p=1.000),  time:52.418, tt:7076.433\n",
      "Ep:135, loss:0.00001, loss_test:0.14134, lr:4.57e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.395, tt:7125.698\n",
      "Ep:136, loss:0.00001, loss_test:0.13851, lr:4.52e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.397, tt:7178.333\n",
      "Ep:137, loss:0.00001, loss_test:0.14065, lr:4.48e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.390, tt:7229.754\n",
      "Ep:138, loss:0.00001, loss_test:0.13887, lr:4.43e-03, fs:0.67114 (r=0.505,p=1.000),  time:52.414, tt:7285.517\n",
      "Ep:139, loss:0.00001, loss_test:0.14106, lr:4.39e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.428, tt:7339.941\n",
      "Ep:140, loss:0.00000, loss_test:0.14044, lr:4.34e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.441, tt:7394.138\n",
      "Ep:141, loss:0.00000, loss_test:0.14095, lr:4.30e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.443, tt:7446.840\n",
      "Ep:142, loss:0.00000, loss_test:0.14152, lr:4.26e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.433, tt:7497.986\n",
      "Ep:143, loss:0.00000, loss_test:0.14319, lr:4.21e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.435, tt:7550.709\n",
      "Ep:144, loss:0.00000, loss_test:0.14138, lr:4.17e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.426, tt:7601.757\n",
      "Ep:145, loss:0.00000, loss_test:0.14307, lr:4.13e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.442, tt:7656.537\n",
      "Ep:146, loss:0.00000, loss_test:0.14207, lr:4.09e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.435, tt:7707.928\n",
      "Ep:147, loss:0.00000, loss_test:0.14298, lr:4.05e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.434, tt:7760.211\n",
      "Ep:148, loss:0.00000, loss_test:0.14146, lr:4.01e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.422, tt:7810.879\n",
      "Ep:149, loss:0.00000, loss_test:0.14248, lr:3.97e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.417, tt:7862.600\n",
      "Ep:150, loss:0.00000, loss_test:0.14375, lr:3.93e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.416, tt:7914.782\n",
      "Ep:151, loss:0.00000, loss_test:0.14318, lr:3.89e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.415, tt:7967.109\n",
      "Ep:152, loss:0.00000, loss_test:0.14250, lr:3.85e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.406, tt:8018.053\n",
      "Ep:153, loss:0.00000, loss_test:0.14580, lr:3.81e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.396, tt:8069.008\n",
      "Ep:154, loss:0.00000, loss_test:0.14349, lr:3.77e-03, fs:0.66216 (r=0.495,p=1.000),  time:52.377, tt:8118.391\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14011, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:20.128, tt:20.128\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13867, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:19.915, tt:39.831\n",
      "Ep:2, loss:0.00028, loss_test:0.13619, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:20.256, tt:60.767\n",
      "Ep:3, loss:0.00027, loss_test:0.13200, lr:1.00e-02, fs:0.66899 (r=0.970,p=0.511),  time:20.433, tt:81.732\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12535, lr:1.00e-02, fs:0.66667 (r=0.929,p=0.520),  time:20.388, tt:101.941\n",
      "Ep:5, loss:0.00025, loss_test:0.11662, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:20.589, tt:123.536\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.10833, lr:1.00e-02, fs:0.69444 (r=0.758,p=0.641),  time:20.889, tt:146.221\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00023, loss_test:0.10327, lr:1.00e-02, fs:0.69388 (r=0.687,p=0.701),  time:20.751, tt:166.011\n",
      "Ep:8, loss:0.00022, loss_test:0.10133, lr:1.00e-02, fs:0.71362 (r=0.768,p=0.667),  time:20.874, tt:187.870\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10052, lr:1.00e-02, fs:0.73820 (r=0.869,p=0.642),  time:20.909, tt:209.095\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00021, loss_test:0.09501, lr:1.00e-02, fs:0.74074 (r=0.808,p=0.684),  time:20.846, tt:229.306\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09162, lr:1.00e-02, fs:0.74257 (r=0.758,p=0.728),  time:20.853, tt:250.238\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.09135, lr:1.00e-02, fs:0.75829 (r=0.808,p=0.714),  time:20.951, tt:272.369\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.09186, lr:1.00e-02, fs:0.77273 (r=0.859,p=0.702),  time:20.992, tt:293.882\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.08839, lr:1.00e-02, fs:0.77570 (r=0.838,p=0.722),  time:20.987, tt:314.805\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.08560, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:20.963, tt:335.403\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08520, lr:1.00e-02, fs:0.78182 (r=0.869,p=0.711),  time:20.979, tt:356.643\n",
      "Ep:17, loss:0.00016, loss_test:0.08156, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:20.961, tt:377.291\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07940, lr:1.00e-02, fs:0.80597 (r=0.818,p=0.794),  time:20.990, tt:398.803\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.07921, lr:1.00e-02, fs:0.81690 (r=0.879,p=0.763),  time:20.968, tt:419.358\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07586, lr:1.00e-02, fs:0.80203 (r=0.798,p=0.806),  time:20.912, tt:439.143\n",
      "Ep:21, loss:0.00014, loss_test:0.07582, lr:1.00e-02, fs:0.83412 (r=0.889,p=0.786),  time:20.911, tt:460.049\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00013, loss_test:0.07280, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:20.923, tt:481.218\n",
      "Ep:23, loss:0.00013, loss_test:0.07229, lr:1.00e-02, fs:0.83333 (r=0.859,p=0.810),  time:20.955, tt:502.909\n",
      "Ep:24, loss:0.00012, loss_test:0.07065, lr:1.00e-02, fs:0.84878 (r=0.879,p=0.821),  time:20.940, tt:523.492\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.06917, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:20.834, tt:541.694\n",
      "Ep:26, loss:0.00012, loss_test:0.06871, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:20.801, tt:561.629\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.06682, lr:1.00e-02, fs:0.85000 (r=0.859,p=0.842),  time:20.814, tt:582.778\n",
      "Ep:28, loss:0.00011, loss_test:0.06557, lr:1.00e-02, fs:0.88571 (r=0.939,p=0.838),  time:20.821, tt:603.802\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:29, loss:0.00010, loss_test:0.06352, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:20.792, tt:623.771\n",
      "Ep:30, loss:0.00010, loss_test:0.06262, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:20.753, tt:643.347\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00010, loss_test:0.06009, lr:1.00e-02, fs:0.88205 (r=0.869,p=0.896),  time:20.749, tt:663.976\n",
      "Ep:32, loss:0.00009, loss_test:0.05892, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:20.768, tt:685.336\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.05735, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:20.802, tt:707.269\n",
      "Ep:34, loss:0.00008, loss_test:0.05628, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:20.786, tt:727.521\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.05536, lr:1.00e-02, fs:0.91542 (r=0.929,p=0.902),  time:20.799, tt:748.777\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.05529, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:20.814, tt:770.112\n",
      "Ep:37, loss:0.00008, loss_test:0.05551, lr:1.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:20.789, tt:790.000\n",
      "Ep:38, loss:0.00007, loss_test:0.05622, lr:1.00e-02, fs:0.86813 (r=0.798,p=0.952),  time:20.798, tt:811.124\n",
      "Ep:39, loss:0.00007, loss_test:0.05344, lr:1.00e-02, fs:0.90741 (r=0.990,p=0.838),  time:20.798, tt:831.912\n",
      "Ep:40, loss:0.00007, loss_test:0.05305, lr:1.00e-02, fs:0.88649 (r=0.828,p=0.953),  time:20.816, tt:853.454\n",
      "Ep:41, loss:0.00007, loss_test:0.05044, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:20.855, tt:875.913\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00006, loss_test:0.05009, lr:1.00e-02, fs:0.91099 (r=0.879,p=0.946),  time:20.892, tt:898.372\n",
      "Ep:43, loss:0.00006, loss_test:0.04902, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:20.982, tt:923.199\n",
      "Ep:44, loss:0.00006, loss_test:0.04868, lr:1.00e-02, fs:0.90526 (r=0.869,p=0.945),  time:21.053, tt:947.395\n",
      "Ep:45, loss:0.00006, loss_test:0.04799, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:21.112, tt:971.166\n",
      "Ep:46, loss:0.00005, loss_test:0.04736, lr:1.00e-02, fs:0.93401 (r=0.929,p=0.939),  time:21.077, tt:990.609\n",
      "Ep:47, loss:0.00005, loss_test:0.04728, lr:1.00e-02, fs:0.90909 (r=0.859,p=0.966),  time:21.067, tt:1011.237\n",
      "Ep:48, loss:0.00005, loss_test:0.04630, lr:1.00e-02, fs:0.95000 (r=0.960,p=0.941),  time:21.105, tt:1034.138\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.04716, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:21.084, tt:1054.219\n",
      "Ep:50, loss:0.00004, loss_test:0.04521, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:21.096, tt:1075.914\n",
      "Ep:51, loss:0.00004, loss_test:0.04525, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:21.065, tt:1095.375\n",
      "Ep:52, loss:0.00004, loss_test:0.04459, lr:1.00e-02, fs:0.94949 (r=0.949,p=0.949),  time:21.038, tt:1114.997\n",
      "Ep:53, loss:0.00004, loss_test:0.04444, lr:1.00e-02, fs:0.91398 (r=0.859,p=0.977),  time:21.016, tt:1134.877\n",
      "Ep:54, loss:0.00004, loss_test:0.04349, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:20.985, tt:1154.169\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00003, loss_test:0.04420, lr:1.00e-02, fs:0.90811 (r=0.848,p=0.977),  time:20.968, tt:1174.196\n",
      "Ep:56, loss:0.00003, loss_test:0.04185, lr:1.00e-02, fs:0.96447 (r=0.960,p=0.969),  time:20.949, tt:1194.092\n",
      "##########Best model found so far##########\n",
      "Ep:57, loss:0.00003, loss_test:0.04357, lr:1.00e-02, fs:0.93194 (r=0.899,p=0.967),  time:20.931, tt:1213.991\n",
      "Ep:58, loss:0.00003, loss_test:0.04191, lr:1.00e-02, fs:0.94845 (r=0.929,p=0.968),  time:20.903, tt:1233.298\n",
      "Ep:59, loss:0.00003, loss_test:0.04153, lr:1.00e-02, fs:0.95385 (r=0.939,p=0.969),  time:20.909, tt:1254.562\n",
      "Ep:60, loss:0.00003, loss_test:0.04090, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:20.911, tt:1275.545\n",
      "Ep:61, loss:0.00003, loss_test:0.04043, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:20.925, tt:1297.338\n",
      "Ep:62, loss:0.00002, loss_test:0.03988, lr:1.00e-02, fs:0.96939 (r=0.960,p=0.979),  time:20.930, tt:1318.573\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00002, loss_test:0.04022, lr:1.00e-02, fs:0.95876 (r=0.939,p=0.979),  time:20.928, tt:1339.416\n",
      "Ep:64, loss:0.00002, loss_test:0.03992, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:20.927, tt:1360.284\n",
      "Ep:65, loss:0.00002, loss_test:0.03921, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:20.968, tt:1383.915\n",
      "Ep:66, loss:0.00002, loss_test:0.04066, lr:1.00e-02, fs:0.95918 (r=0.949,p=0.969),  time:20.963, tt:1404.540\n",
      "Ep:67, loss:0.00002, loss_test:0.04059, lr:1.00e-02, fs:0.94792 (r=0.919,p=0.978),  time:20.981, tt:1426.698\n",
      "Ep:68, loss:0.00002, loss_test:0.03933, lr:1.00e-02, fs:0.95833 (r=0.929,p=0.989),  time:20.984, tt:1447.902\n",
      "Ep:69, loss:0.00002, loss_test:0.03959, lr:1.00e-02, fs:0.95918 (r=0.949,p=0.969),  time:21.002, tt:1470.121\n",
      "Ep:70, loss:0.00002, loss_test:0.03911, lr:1.00e-02, fs:0.95833 (r=0.929,p=0.989),  time:20.994, tt:1490.610\n",
      "Ep:71, loss:0.00002, loss_test:0.03942, lr:1.00e-02, fs:0.95918 (r=0.949,p=0.969),  time:21.036, tt:1514.560\n",
      "Ep:72, loss:0.00002, loss_test:0.03992, lr:1.00e-02, fs:0.94180 (r=0.899,p=0.989),  time:21.034, tt:1535.455\n",
      "Ep:73, loss:0.00002, loss_test:0.03803, lr:1.00e-02, fs:0.96410 (r=0.949,p=0.979),  time:21.039, tt:1556.898\n",
      "Ep:74, loss:0.00001, loss_test:0.03846, lr:9.90e-03, fs:0.96907 (r=0.949,p=0.989),  time:21.014, tt:1576.033\n",
      "Ep:75, loss:0.00001, loss_test:0.03823, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:21.005, tt:1596.381\n",
      "##########Best model found so far##########\n",
      "Ep:76, loss:0.00001, loss_test:0.03868, lr:9.80e-03, fs:0.96939 (r=0.960,p=0.979),  time:20.980, tt:1615.486\n",
      "Ep:77, loss:0.00001, loss_test:0.03793, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.966, tt:1635.378\n",
      "Ep:78, loss:0.00001, loss_test:0.03811, lr:9.80e-03, fs:0.96939 (r=0.960,p=0.979),  time:20.947, tt:1654.840\n",
      "Ep:79, loss:0.00001, loss_test:0.03880, lr:9.80e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.937, tt:1674.968\n",
      "Ep:80, loss:0.00001, loss_test:0.03745, lr:9.80e-03, fs:0.96939 (r=0.960,p=0.979),  time:20.929, tt:1695.266\n",
      "Ep:81, loss:0.00001, loss_test:0.03946, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.914, tt:1714.910\n",
      "Ep:82, loss:0.00001, loss_test:0.03797, lr:9.80e-03, fs:0.96939 (r=0.960,p=0.979),  time:20.908, tt:1735.340\n",
      "Ep:83, loss:0.00001, loss_test:0.03761, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.893, tt:1754.992\n",
      "Ep:84, loss:0.00001, loss_test:0.04119, lr:9.80e-03, fs:0.95876 (r=0.939,p=0.979),  time:20.909, tt:1777.285\n",
      "Ep:85, loss:0.00001, loss_test:0.03801, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.893, tt:1796.771\n",
      "Ep:86, loss:0.00001, loss_test:0.03931, lr:9.80e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.911, tt:1819.290\n",
      "Ep:87, loss:0.00001, loss_test:0.03862, lr:9.70e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.918, tt:1840.758\n",
      "Ep:88, loss:0.00001, loss_test:0.03754, lr:9.61e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.917, tt:1861.615\n",
      "Ep:89, loss:0.00001, loss_test:0.04059, lr:9.51e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.901, tt:1881.062\n",
      "Ep:90, loss:0.00001, loss_test:0.03851, lr:9.41e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.900, tt:1901.855\n",
      "Ep:91, loss:0.00001, loss_test:0.03833, lr:9.32e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.889, tt:1921.822\n",
      "Ep:92, loss:0.00001, loss_test:0.03945, lr:9.23e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.886, tt:1942.418\n",
      "Ep:93, loss:0.00001, loss_test:0.03822, lr:9.14e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.884, tt:1963.064\n",
      "Ep:94, loss:0.00001, loss_test:0.03914, lr:9.04e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.876, tt:1983.204\n",
      "Ep:95, loss:0.00001, loss_test:0.03937, lr:8.95e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.874, tt:2003.891\n",
      "Ep:96, loss:0.00001, loss_test:0.03861, lr:8.86e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.875, tt:2024.855\n",
      "Ep:97, loss:0.00001, loss_test:0.04016, lr:8.78e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.873, tt:2045.534\n",
      "Ep:98, loss:0.00001, loss_test:0.03879, lr:8.69e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.869, tt:2065.987\n",
      "Ep:99, loss:0.00001, loss_test:0.03840, lr:8.60e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.865, tt:2086.463\n",
      "Ep:100, loss:0.00001, loss_test:0.04087, lr:8.51e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.853, tt:2106.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:101, loss:0.00001, loss_test:0.04036, lr:8.43e-03, fs:0.91892 (r=0.859,p=0.988),  time:20.869, tt:2128.600\n",
      "Ep:102, loss:0.00001, loss_test:0.03877, lr:8.35e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.897, tt:2152.366\n",
      "Ep:103, loss:0.00001, loss_test:0.04020, lr:8.26e-03, fs:0.94180 (r=0.899,p=0.989),  time:20.910, tt:2174.637\n",
      "Ep:104, loss:0.00001, loss_test:0.04025, lr:8.18e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.915, tt:2196.025\n",
      "Ep:105, loss:0.00000, loss_test:0.03874, lr:8.10e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.920, tt:2217.470\n",
      "Ep:106, loss:0.00000, loss_test:0.04045, lr:8.02e-03, fs:0.91892 (r=0.859,p=0.988),  time:20.929, tt:2239.364\n",
      "Ep:107, loss:0.00000, loss_test:0.04071, lr:7.94e-03, fs:0.94737 (r=0.909,p=0.989),  time:20.922, tt:2259.582\n",
      "Ep:108, loss:0.00000, loss_test:0.03920, lr:7.86e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.906, tt:2278.726\n",
      "Ep:109, loss:0.00000, loss_test:0.03992, lr:7.78e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.904, tt:2299.446\n",
      "Ep:110, loss:0.00000, loss_test:0.04085, lr:7.70e-03, fs:0.91892 (r=0.859,p=0.988),  time:20.893, tt:2319.089\n",
      "Ep:111, loss:0.00000, loss_test:0.03950, lr:7.62e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.898, tt:2340.588\n",
      "Ep:112, loss:0.00000, loss_test:0.03994, lr:7.55e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.901, tt:2361.777\n",
      "Ep:113, loss:0.00000, loss_test:0.04146, lr:7.47e-03, fs:0.90710 (r=0.838,p=0.988),  time:20.889, tt:2381.305\n",
      "Ep:114, loss:0.00000, loss_test:0.04044, lr:7.40e-03, fs:0.92473 (r=0.869,p=0.989),  time:20.871, tt:2400.172\n",
      "Ep:115, loss:0.00000, loss_test:0.03948, lr:7.32e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.863, tt:2420.136\n",
      "Ep:116, loss:0.00000, loss_test:0.03998, lr:7.25e-03, fs:0.94737 (r=0.909,p=0.989),  time:20.854, tt:2439.866\n",
      "Ep:117, loss:0.00000, loss_test:0.04040, lr:7.18e-03, fs:0.95833 (r=0.929,p=0.989),  time:20.856, tt:2461.026\n",
      "Ep:118, loss:0.00000, loss_test:0.04024, lr:7.11e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.855, tt:2481.801\n",
      "Ep:119, loss:0.00000, loss_test:0.03981, lr:7.03e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.845, tt:2501.390\n",
      "Ep:120, loss:0.00000, loss_test:0.04024, lr:6.96e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.858, tt:2523.796\n",
      "Ep:121, loss:0.00000, loss_test:0.04038, lr:6.89e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.867, tt:2545.795\n",
      "Ep:122, loss:0.00000, loss_test:0.04042, lr:6.83e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.870, tt:2566.994\n",
      "Ep:123, loss:0.00000, loss_test:0.04021, lr:6.76e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.874, tt:2588.363\n",
      "Ep:124, loss:0.00000, loss_test:0.04008, lr:6.69e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.883, tt:2610.403\n",
      "Ep:125, loss:0.00000, loss_test:0.04027, lr:6.62e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.873, tt:2630.047\n",
      "Ep:126, loss:0.00000, loss_test:0.04049, lr:6.56e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.871, tt:2650.643\n",
      "Ep:127, loss:0.00000, loss_test:0.04047, lr:6.49e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.869, tt:2671.236\n",
      "Ep:128, loss:0.00000, loss_test:0.04042, lr:6.43e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.889, tt:2694.732\n",
      "Ep:129, loss:0.00000, loss_test:0.04055, lr:6.36e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.883, tt:2714.795\n",
      "Ep:130, loss:0.00000, loss_test:0.04053, lr:6.30e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.900, tt:2737.838\n",
      "Ep:131, loss:0.00000, loss_test:0.04011, lr:6.24e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.903, tt:2759.160\n",
      "Ep:132, loss:0.00000, loss_test:0.04087, lr:6.17e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.907, tt:2780.572\n",
      "Ep:133, loss:0.00000, loss_test:0.04083, lr:6.11e-03, fs:0.94180 (r=0.899,p=0.989),  time:20.888, tt:2798.975\n",
      "Ep:134, loss:0.00000, loss_test:0.04076, lr:6.05e-03, fs:0.94737 (r=0.909,p=0.989),  time:20.884, tt:2819.364\n",
      "Ep:135, loss:0.00000, loss_test:0.04051, lr:5.99e-03, fs:0.94737 (r=0.909,p=0.989),  time:20.876, tt:2839.119\n",
      "Ep:136, loss:0.00000, loss_test:0.04064, lr:5.93e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.878, tt:2860.355\n",
      "Ep:137, loss:0.00000, loss_test:0.04062, lr:5.87e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.874, tt:2880.656\n",
      "Ep:138, loss:0.00000, loss_test:0.04054, lr:5.81e-03, fs:0.95833 (r=0.929,p=0.989),  time:20.856, tt:2899.020\n",
      "Ep:139, loss:0.00000, loss_test:0.04068, lr:5.75e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.856, tt:2919.855\n",
      "Ep:140, loss:0.00000, loss_test:0.04072, lr:5.70e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.858, tt:2940.966\n",
      "Ep:141, loss:0.00000, loss_test:0.04048, lr:5.64e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.865, tt:2962.881\n",
      "Ep:142, loss:0.00000, loss_test:0.04073, lr:5.58e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.884, tt:2986.391\n",
      "Ep:143, loss:0.00000, loss_test:0.04110, lr:5.53e-03, fs:0.93048 (r=0.879,p=0.989),  time:20.880, tt:3006.754\n",
      "Ep:144, loss:0.00000, loss_test:0.04080, lr:5.47e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.883, tt:3028.018\n",
      "Ep:145, loss:0.00000, loss_test:0.04074, lr:5.42e-03, fs:0.95833 (r=0.929,p=0.989),  time:20.883, tt:3048.960\n",
      "Ep:146, loss:0.00000, loss_test:0.04080, lr:5.36e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.880, tt:3069.321\n",
      "Ep:147, loss:0.00000, loss_test:0.04062, lr:5.31e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.880, tt:3090.294\n",
      "Ep:148, loss:0.00000, loss_test:0.04090, lr:5.26e-03, fs:0.94737 (r=0.909,p=0.989),  time:20.896, tt:3113.517\n",
      "Ep:149, loss:0.00000, loss_test:0.04091, lr:5.20e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.912, tt:3136.834\n",
      "Ep:150, loss:0.00000, loss_test:0.04089, lr:5.15e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.932, tt:3160.660\n",
      "Ep:151, loss:0.00000, loss_test:0.04057, lr:5.10e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.941, tt:3183.050\n",
      "Ep:152, loss:0.00000, loss_test:0.04046, lr:5.05e-03, fs:0.97436 (r=0.960,p=0.990),  time:20.944, tt:3204.463\n",
      "Ep:153, loss:0.00000, loss_test:0.04115, lr:5.00e-03, fs:0.95288 (r=0.919,p=0.989),  time:20.918, tt:3221.395\n",
      "Ep:154, loss:0.00000, loss_test:0.04088, lr:4.95e-03, fs:0.96907 (r=0.949,p=0.989),  time:20.921, tt:3242.759\n",
      "Ep:155, loss:0.00000, loss_test:0.04089, lr:4.90e-03, fs:0.96373 (r=0.939,p=0.989),  time:20.920, tt:3263.448\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14446, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:19.666, tt:19.666\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14348, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:20.187, tt:40.375\n",
      "Ep:2, loss:0.00028, loss_test:0.14171, lr:1.00e-02, fs:0.67119 (r=1.000,p=0.505),  time:20.310, tt:60.930\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13864, lr:1.00e-02, fs:0.66667 (r=0.980,p=0.505),  time:20.861, tt:83.442\n",
      "Ep:4, loss:0.00026, loss_test:0.13382, lr:1.00e-02, fs:0.64769 (r=0.919,p=0.500),  time:21.034, tt:105.171\n",
      "Ep:5, loss:0.00025, loss_test:0.12689, lr:1.00e-02, fs:0.63745 (r=0.808,p=0.526),  time:21.260, tt:127.562\n",
      "Ep:6, loss:0.00023, loss_test:0.11965, lr:1.00e-02, fs:0.65403 (r=0.697,p=0.616),  time:21.068, tt:147.474\n",
      "Ep:7, loss:0.00023, loss_test:0.11569, lr:1.00e-02, fs:0.67327 (r=0.687,p=0.660),  time:21.042, tt:168.333\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.11577, lr:1.00e-02, fs:0.63208 (r=0.677,p=0.593),  time:21.059, tt:189.527\n",
      "Ep:9, loss:0.00021, loss_test:0.11661, lr:1.00e-02, fs:0.68103 (r=0.798,p=0.594),  time:21.107, tt:211.075\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.11186, lr:1.00e-02, fs:0.64734 (r=0.677,p=0.620),  time:20.995, tt:230.950\n",
      "Ep:11, loss:0.00019, loss_test:0.10842, lr:1.00e-02, fs:0.65263 (r=0.626,p=0.681),  time:21.003, tt:252.037\n",
      "Ep:12, loss:0.00019, loss_test:0.10617, lr:1.00e-02, fs:0.70244 (r=0.727,p=0.679),  time:21.050, tt:273.653\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.10497, lr:1.00e-02, fs:0.70813 (r=0.747,p=0.673),  time:21.087, tt:295.211\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:14, loss:0.00017, loss_test:0.10133, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:20.986, tt:314.791\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.09882, lr:1.00e-02, fs:0.73469 (r=0.727,p=0.742),  time:20.896, tt:334.330\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.09763, lr:1.00e-02, fs:0.73632 (r=0.747,p=0.725),  time:20.993, tt:356.876\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.09667, lr:1.00e-02, fs:0.74227 (r=0.727,p=0.758),  time:21.085, tt:379.531\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09670, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:21.092, tt:400.752\n",
      "Ep:19, loss:0.00014, loss_test:0.09627, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:21.083, tt:421.659\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.09399, lr:1.00e-02, fs:0.74737 (r=0.717,p=0.780),  time:21.017, tt:441.353\n",
      "Ep:21, loss:0.00014, loss_test:0.09219, lr:1.00e-02, fs:0.77083 (r=0.747,p=0.796),  time:21.063, tt:463.397\n",
      "Ep:22, loss:0.00013, loss_test:0.09091, lr:1.00e-02, fs:0.78756 (r=0.768,p=0.809),  time:21.045, tt:484.042\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.08919, lr:1.00e-02, fs:0.77895 (r=0.747,p=0.813),  time:20.986, tt:503.654\n",
      "Ep:24, loss:0.00012, loss_test:0.08752, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:20.993, tt:524.826\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.08631, lr:1.00e-02, fs:0.78534 (r=0.758,p=0.815),  time:21.017, tt:546.447\n",
      "Ep:26, loss:0.00011, loss_test:0.08488, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:21.004, tt:567.114\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.08517, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:20.980, tt:587.445\n",
      "Ep:28, loss:0.00010, loss_test:0.08373, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:21.043, tt:610.256\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.08150, lr:1.00e-02, fs:0.82051 (r=0.808,p=0.833),  time:21.016, tt:630.483\n",
      "Ep:30, loss:0.00010, loss_test:0.08469, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:21.019, tt:651.582\n",
      "Ep:31, loss:0.00009, loss_test:0.08070, lr:1.00e-02, fs:0.83417 (r=0.838,p=0.830),  time:21.076, tt:674.425\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.08155, lr:1.00e-02, fs:0.84043 (r=0.798,p=0.888),  time:21.055, tt:694.831\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00009, loss_test:0.07853, lr:1.00e-02, fs:0.84264 (r=0.838,p=0.847),  time:21.070, tt:716.375\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.08327, lr:1.00e-02, fs:0.85106 (r=0.808,p=0.899),  time:21.109, tt:738.798\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.07648, lr:1.00e-02, fs:0.83838 (r=0.838,p=0.838),  time:21.104, tt:759.761\n",
      "Ep:36, loss:0.00008, loss_test:0.08242, lr:1.00e-02, fs:0.84492 (r=0.798,p=0.898),  time:21.122, tt:781.519\n",
      "Ep:37, loss:0.00007, loss_test:0.07521, lr:1.00e-02, fs:0.85128 (r=0.838,p=0.865),  time:21.115, tt:802.366\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00007, loss_test:0.08048, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:21.107, tt:823.187\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.07477, lr:1.00e-02, fs:0.84536 (r=0.828,p=0.863),  time:21.151, tt:846.027\n",
      "Ep:40, loss:0.00006, loss_test:0.07680, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:21.151, tt:867.188\n",
      "##########Best model found so far##########\n",
      "Ep:41, loss:0.00006, loss_test:0.07207, lr:1.00e-02, fs:0.85714 (r=0.848,p=0.866),  time:21.150, tt:888.299\n",
      "Ep:42, loss:0.00006, loss_test:0.07902, lr:1.00e-02, fs:0.86957 (r=0.808,p=0.941),  time:21.233, tt:913.016\n",
      "Ep:43, loss:0.00006, loss_test:0.07174, lr:1.00e-02, fs:0.86598 (r=0.848,p=0.884),  time:21.269, tt:935.832\n",
      "Ep:44, loss:0.00005, loss_test:0.07788, lr:1.00e-02, fs:0.86339 (r=0.798,p=0.940),  time:21.248, tt:956.139\n",
      "Ep:45, loss:0.00005, loss_test:0.07182, lr:1.00e-02, fs:0.87047 (r=0.848,p=0.894),  time:21.246, tt:977.298\n",
      "Ep:46, loss:0.00005, loss_test:0.07589, lr:1.00e-02, fs:0.87568 (r=0.818,p=0.942),  time:21.278, tt:1000.050\n",
      "Ep:47, loss:0.00005, loss_test:0.07181, lr:1.00e-02, fs:0.87831 (r=0.838,p=0.922),  time:21.263, tt:1020.638\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.07651, lr:1.00e-02, fs:0.89011 (r=0.818,p=0.976),  time:21.260, tt:1041.730\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00004, loss_test:0.07301, lr:1.00e-02, fs:0.87701 (r=0.828,p=0.932),  time:21.258, tt:1062.923\n",
      "Ep:50, loss:0.00004, loss_test:0.07341, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:21.243, tt:1083.413\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00004, loss_test:0.07343, lr:1.00e-02, fs:0.88298 (r=0.838,p=0.933),  time:21.227, tt:1103.807\n",
      "Ep:52, loss:0.00004, loss_test:0.07140, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:21.257, tt:1126.595\n",
      "Ep:53, loss:0.00004, loss_test:0.07179, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.261, tt:1148.091\n",
      "Ep:54, loss:0.00004, loss_test:0.07398, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:21.274, tt:1170.051\n",
      "Ep:55, loss:0.00003, loss_test:0.07128, lr:1.00e-02, fs:0.88770 (r=0.838,p=0.943),  time:21.297, tt:1192.631\n",
      "Ep:56, loss:0.00003, loss_test:0.07432, lr:1.00e-02, fs:0.90217 (r=0.838,p=0.976),  time:21.305, tt:1214.410\n",
      "Ep:57, loss:0.00003, loss_test:0.07070, lr:1.00e-02, fs:0.89247 (r=0.838,p=0.954),  time:21.282, tt:1234.361\n",
      "Ep:58, loss:0.00003, loss_test:0.07335, lr:1.00e-02, fs:0.89617 (r=0.828,p=0.976),  time:21.267, tt:1254.782\n",
      "Ep:59, loss:0.00003, loss_test:0.07303, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.304, tt:1278.261\n",
      "Ep:60, loss:0.00003, loss_test:0.07131, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.317, tt:1300.337\n",
      "Ep:61, loss:0.00003, loss_test:0.07400, lr:1.00e-02, fs:0.89730 (r=0.838,p=0.965),  time:21.307, tt:1321.024\n",
      "Ep:62, loss:0.00003, loss_test:0.07184, lr:9.90e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.300, tt:1341.920\n",
      "Ep:63, loss:0.00002, loss_test:0.07074, lr:9.80e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.313, tt:1364.053\n",
      "Ep:64, loss:0.00002, loss_test:0.07375, lr:9.70e-03, fs:0.89130 (r=0.828,p=0.965),  time:21.326, tt:1386.217\n",
      "Ep:65, loss:0.00002, loss_test:0.07137, lr:9.61e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.334, tt:1408.029\n",
      "Ep:66, loss:0.00002, loss_test:0.07445, lr:9.51e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.341, tt:1429.840\n",
      "Ep:67, loss:0.00002, loss_test:0.07144, lr:9.41e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.330, tt:1450.446\n",
      "Ep:68, loss:0.00002, loss_test:0.07425, lr:9.32e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.320, tt:1471.086\n",
      "Ep:69, loss:0.00002, loss_test:0.07217, lr:9.23e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.321, tt:1492.491\n",
      "Ep:70, loss:0.00002, loss_test:0.07605, lr:9.14e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.341, tt:1515.243\n",
      "Ep:71, loss:0.00002, loss_test:0.07208, lr:9.04e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.343, tt:1536.708\n",
      "Ep:72, loss:0.00002, loss_test:0.07622, lr:8.95e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.353, tt:1558.778\n",
      "Ep:73, loss:0.00002, loss_test:0.07438, lr:8.86e-03, fs:0.87912 (r=0.808,p=0.964),  time:21.334, tt:1578.752\n",
      "Ep:74, loss:0.00002, loss_test:0.07598, lr:8.78e-03, fs:0.86034 (r=0.778,p=0.963),  time:21.329, tt:1599.681\n",
      "Ep:75, loss:0.00002, loss_test:0.07318, lr:8.69e-03, fs:0.87912 (r=0.808,p=0.964),  time:21.315, tt:1619.910\n",
      "Ep:76, loss:0.00001, loss_test:0.07621, lr:8.60e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.316, tt:1641.368\n",
      "Ep:77, loss:0.00001, loss_test:0.07476, lr:8.51e-03, fs:0.84746 (r=0.758,p=0.962),  time:21.324, tt:1663.238\n",
      "Ep:78, loss:0.00001, loss_test:0.07687, lr:8.43e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.328, tt:1684.891\n",
      "Ep:79, loss:0.00001, loss_test:0.07435, lr:8.35e-03, fs:0.86667 (r=0.788,p=0.963),  time:21.335, tt:1706.806\n",
      "Ep:80, loss:0.00001, loss_test:0.07687, lr:8.26e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.318, tt:1726.760\n",
      "Ep:81, loss:0.00001, loss_test:0.07467, lr:8.18e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.340, tt:1749.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:82, loss:0.00001, loss_test:0.07751, lr:8.10e-03, fs:0.86364 (r=0.768,p=0.987),  time:21.346, tt:1771.717\n",
      "Ep:83, loss:0.00001, loss_test:0.07618, lr:8.02e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.342, tt:1792.692\n",
      "Ep:84, loss:0.00001, loss_test:0.07836, lr:7.94e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.335, tt:1813.451\n",
      "Ep:85, loss:0.00001, loss_test:0.07561, lr:7.86e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.333, tt:1834.631\n",
      "Ep:86, loss:0.00001, loss_test:0.07737, lr:7.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.342, tt:1856.782\n",
      "Ep:87, loss:0.00001, loss_test:0.07770, lr:7.70e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.330, tt:1877.069\n",
      "Ep:88, loss:0.00001, loss_test:0.07746, lr:7.62e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.339, tt:1899.198\n",
      "Ep:89, loss:0.00001, loss_test:0.07804, lr:7.55e-03, fs:0.83908 (r=0.737,p=0.973),  time:21.338, tt:1920.393\n",
      "Ep:90, loss:0.00001, loss_test:0.07761, lr:7.47e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.332, tt:1941.202\n",
      "Ep:91, loss:0.00001, loss_test:0.07877, lr:7.40e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.349, tt:1964.062\n",
      "Ep:92, loss:0.00001, loss_test:0.07802, lr:7.32e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.340, tt:1984.615\n",
      "Ep:93, loss:0.00001, loss_test:0.07924, lr:7.25e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.337, tt:2005.698\n",
      "Ep:94, loss:0.00001, loss_test:0.07962, lr:7.18e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.335, tt:2026.852\n",
      "Ep:95, loss:0.00001, loss_test:0.07856, lr:7.11e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.319, tt:2046.606\n",
      "Ep:96, loss:0.00001, loss_test:0.07800, lr:7.03e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.347, tt:2070.666\n",
      "Ep:97, loss:0.00001, loss_test:0.07977, lr:6.96e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.338, tt:2091.150\n",
      "Ep:98, loss:0.00001, loss_test:0.08037, lr:6.89e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.343, tt:2112.958\n",
      "Ep:99, loss:0.00001, loss_test:0.07893, lr:6.83e-03, fs:0.82558 (r=0.717,p=0.973),  time:21.335, tt:2133.486\n",
      "Ep:100, loss:0.00001, loss_test:0.08094, lr:6.76e-03, fs:0.85227 (r=0.758,p=0.974),  time:21.344, tt:2155.745\n",
      "Ep:101, loss:0.00001, loss_test:0.07903, lr:6.69e-03, fs:0.85393 (r=0.768,p=0.962),  time:21.362, tt:2178.939\n",
      "Ep:102, loss:0.00001, loss_test:0.08013, lr:6.62e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.355, tt:2199.560\n",
      "Ep:103, loss:0.00001, loss_test:0.08269, lr:6.56e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.361, tt:2221.508\n",
      "Ep:104, loss:0.00001, loss_test:0.07863, lr:6.49e-03, fs:0.80702 (r=0.697,p=0.958),  time:21.330, tt:2239.675\n",
      "Ep:105, loss:0.00001, loss_test:0.08174, lr:6.43e-03, fs:0.85876 (r=0.768,p=0.974),  time:21.310, tt:2258.851\n",
      "Ep:106, loss:0.00001, loss_test:0.08081, lr:6.36e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.298, tt:2278.847\n",
      "Ep:107, loss:0.00001, loss_test:0.08145, lr:6.30e-03, fs:0.86364 (r=0.768,p=0.987),  time:21.291, tt:2299.419\n",
      "Ep:108, loss:0.00001, loss_test:0.08196, lr:6.24e-03, fs:0.81657 (r=0.697,p=0.986),  time:21.288, tt:2320.363\n",
      "Ep:109, loss:0.00001, loss_test:0.08056, lr:6.17e-03, fs:0.83429 (r=0.737,p=0.961),  time:21.273, tt:2339.999\n",
      "Ep:110, loss:0.00001, loss_test:0.08236, lr:6.11e-03, fs:0.83908 (r=0.737,p=0.973),  time:21.247, tt:2358.396\n",
      "Ep:111, loss:0.00001, loss_test:0.08146, lr:6.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.223, tt:2376.960\n",
      "Ep:112, loss:0.00001, loss_test:0.08237, lr:5.99e-03, fs:0.84571 (r=0.747,p=0.974),  time:21.222, tt:2398.131\n",
      "Ep:113, loss:0.00001, loss_test:0.08247, lr:5.93e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.218, tt:2418.871\n",
      "Ep:114, loss:0.00001, loss_test:0.08070, lr:5.87e-03, fs:0.84091 (r=0.747,p=0.961),  time:21.221, tt:2440.409\n",
      "Ep:115, loss:0.00001, loss_test:0.08327, lr:5.81e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.226, tt:2462.197\n",
      "Ep:116, loss:0.00001, loss_test:0.08302, lr:5.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.220, tt:2482.784\n",
      "Ep:117, loss:0.00001, loss_test:0.08164, lr:5.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:21.223, tt:2504.260\n",
      "Ep:118, loss:0.00001, loss_test:0.08354, lr:5.64e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.214, tt:2524.461\n",
      "Ep:119, loss:0.00001, loss_test:0.08248, lr:5.58e-03, fs:0.80000 (r=0.687,p=0.958),  time:21.213, tt:2545.540\n",
      "Ep:120, loss:0.00001, loss_test:0.08258, lr:5.53e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.200, tt:2565.175\n",
      "Ep:121, loss:0.00000, loss_test:0.08399, lr:5.47e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.195, tt:2585.761\n",
      "Ep:122, loss:0.00000, loss_test:0.08129, lr:5.42e-03, fs:0.79290 (r=0.677,p=0.957),  time:21.196, tt:2607.064\n",
      "Ep:123, loss:0.00000, loss_test:0.08401, lr:5.36e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.204, tt:2629.279\n",
      "Ep:124, loss:0.00000, loss_test:0.08460, lr:5.31e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.218, tt:2652.222\n",
      "Ep:125, loss:0.00000, loss_test:0.08211, lr:5.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:21.228, tt:2674.783\n",
      "Ep:126, loss:0.00000, loss_test:0.08282, lr:5.20e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.225, tt:2695.584\n",
      "Ep:127, loss:0.00000, loss_test:0.08455, lr:5.15e-03, fs:0.82353 (r=0.707,p=0.986),  time:21.218, tt:2715.858\n",
      "Ep:128, loss:0.00000, loss_test:0.08294, lr:5.10e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.235, tt:2739.296\n",
      "Ep:129, loss:0.00000, loss_test:0.08379, lr:5.05e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.245, tt:2761.911\n",
      "Ep:130, loss:0.00000, loss_test:0.08317, lr:5.00e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.243, tt:2782.804\n",
      "Ep:131, loss:0.00000, loss_test:0.08329, lr:4.95e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.244, tt:2804.174\n",
      "Ep:132, loss:0.00000, loss_test:0.08336, lr:4.90e-03, fs:0.79290 (r=0.677,p=0.957),  time:21.239, tt:2824.850\n",
      "Ep:133, loss:0.00000, loss_test:0.08393, lr:4.85e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.249, tt:2847.412\n",
      "Ep:134, loss:0.00000, loss_test:0.08375, lr:4.80e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.256, tt:2869.619\n",
      "Ep:135, loss:0.00000, loss_test:0.08345, lr:4.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.260, tt:2891.364\n",
      "Ep:136, loss:0.00000, loss_test:0.08309, lr:4.71e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.262, tt:2912.833\n",
      "Ep:137, loss:0.00000, loss_test:0.08422, lr:4.66e-03, fs:0.80473 (r=0.687,p=0.971),  time:21.248, tt:2932.261\n",
      "Ep:138, loss:0.00000, loss_test:0.08338, lr:4.61e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.248, tt:2953.411\n",
      "Ep:139, loss:0.00000, loss_test:0.08425, lr:4.57e-03, fs:0.79762 (r=0.677,p=0.971),  time:21.248, tt:2974.723\n",
      "Ep:140, loss:0.00000, loss_test:0.08377, lr:4.52e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.236, tt:2994.227\n",
      "Ep:141, loss:0.00000, loss_test:0.08413, lr:4.48e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.228, tt:3014.342\n",
      "Ep:142, loss:0.00000, loss_test:0.08427, lr:4.43e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.228, tt:3035.619\n",
      "Ep:143, loss:0.00000, loss_test:0.08420, lr:4.39e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.239, tt:3058.359\n",
      "Ep:144, loss:0.00000, loss_test:0.08378, lr:4.34e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.242, tt:3080.037\n",
      "Ep:145, loss:0.00000, loss_test:0.08440, lr:4.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.252, tt:3102.841\n",
      "Ep:146, loss:0.00000, loss_test:0.08366, lr:4.26e-03, fs:0.79042 (r=0.667,p=0.971),  time:21.249, tt:3123.653\n",
      "Ep:147, loss:0.00000, loss_test:0.08440, lr:4.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.254, tt:3145.635\n",
      "Ep:148, loss:0.00000, loss_test:0.08466, lr:4.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.256, tt:3167.166\n",
      "Ep:149, loss:0.00000, loss_test:0.08437, lr:4.13e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.252, tt:3187.735\n",
      "Ep:150, loss:0.00000, loss_test:0.08453, lr:4.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.251, tt:3208.876\n",
      "Ep:151, loss:0.00000, loss_test:0.08432, lr:4.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.273, tt:3233.535\n",
      "Ep:152, loss:0.00000, loss_test:0.08509, lr:4.01e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.263, tt:3253.312\n",
      "Ep:153, loss:0.00000, loss_test:0.08509, lr:3.97e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.227, tt:3268.939\n",
      "Ep:154, loss:0.00000, loss_test:0.08392, lr:3.93e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.194, tt:3285.055\n",
      "Ep:155, loss:0.00000, loss_test:0.08502, lr:3.89e-03, fs:0.78313 (r=0.657,p=0.970),  time:21.169, tt:3302.333\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14066, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.296, tt:25.296\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13901, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:24.835, tt:49.669\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00028, loss_test:0.13627, lr:1.00e-02, fs:0.66667 (r=0.990,p=0.503),  time:24.491, tt:73.472\n",
      "Ep:3, loss:0.00027, loss_test:0.13189, lr:1.00e-02, fs:0.66197 (r=0.949,p=0.508),  time:24.601, tt:98.403\n",
      "Ep:4, loss:0.00027, loss_test:0.12568, lr:1.00e-02, fs:0.66165 (r=0.889,p=0.527),  time:24.689, tt:123.446\n",
      "Ep:5, loss:0.00026, loss_test:0.12129, lr:1.00e-02, fs:0.66122 (r=0.818,p=0.555),  time:24.576, tt:147.453\n",
      "Ep:6, loss:0.00025, loss_test:0.11898, lr:1.00e-02, fs:0.66087 (r=0.768,p=0.580),  time:24.559, tt:171.910\n",
      "Ep:7, loss:0.00025, loss_test:0.11570, lr:1.00e-02, fs:0.66667 (r=0.768,p=0.589),  time:24.562, tt:196.496\n",
      "Ep:8, loss:0.00024, loss_test:0.11229, lr:1.00e-02, fs:0.65801 (r=0.768,p=0.576),  time:24.677, tt:222.092\n",
      "Ep:9, loss:0.00023, loss_test:0.10898, lr:1.00e-02, fs:0.67241 (r=0.788,p=0.586),  time:24.581, tt:245.807\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10396, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:24.466, tt:269.123\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.09891, lr:1.00e-02, fs:0.72115 (r=0.758,p=0.688),  time:24.572, tt:294.861\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.09531, lr:1.00e-02, fs:0.73529 (r=0.758,p=0.714),  time:24.557, tt:319.245\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09244, lr:1.00e-02, fs:0.75000 (r=0.818,p=0.692),  time:24.619, tt:344.664\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.08926, lr:1.00e-02, fs:0.77512 (r=0.818,p=0.736),  time:24.703, tt:370.548\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00018, loss_test:0.08639, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:24.769, tt:396.305\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.08517, lr:1.00e-02, fs:0.79227 (r=0.828,p=0.759),  time:24.730, tt:420.418\n",
      "Ep:17, loss:0.00017, loss_test:0.08376, lr:1.00e-02, fs:0.78818 (r=0.808,p=0.769),  time:24.693, tt:444.474\n",
      "Ep:18, loss:0.00016, loss_test:0.08188, lr:1.00e-02, fs:0.79803 (r=0.818,p=0.779),  time:24.707, tt:469.428\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00015, loss_test:0.08013, lr:1.00e-02, fs:0.82126 (r=0.859,p=0.787),  time:24.748, tt:494.957\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.07765, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:24.694, tt:518.578\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00014, loss_test:0.07678, lr:1.00e-02, fs:0.84360 (r=0.899,p=0.795),  time:24.703, tt:543.468\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00014, loss_test:0.07421, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:24.707, tt:568.263\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00013, loss_test:0.07391, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:24.698, tt:592.750\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00013, loss_test:0.07105, lr:1.00e-02, fs:0.86124 (r=0.909,p=0.818),  time:24.715, tt:617.875\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00012, loss_test:0.07085, lr:1.00e-02, fs:0.87037 (r=0.949,p=0.803),  time:24.736, tt:643.137\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00012, loss_test:0.06825, lr:1.00e-02, fs:0.87736 (r=0.939,p=0.823),  time:24.723, tt:667.533\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.06696, lr:1.00e-02, fs:0.87204 (r=0.929,p=0.821),  time:24.682, tt:691.087\n",
      "Ep:28, loss:0.00011, loss_test:0.06581, lr:1.00e-02, fs:0.89100 (r=0.949,p=0.839),  time:24.686, tt:715.891\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00011, loss_test:0.06373, lr:1.00e-02, fs:0.89320 (r=0.929,p=0.860),  time:24.702, tt:741.070\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.06397, lr:1.00e-02, fs:0.87442 (r=0.949,p=0.810),  time:24.726, tt:766.492\n",
      "Ep:31, loss:0.00010, loss_test:0.06125, lr:1.00e-02, fs:0.90547 (r=0.919,p=0.892),  time:24.718, tt:790.984\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.06179, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:24.728, tt:816.038\n",
      "Ep:33, loss:0.00009, loss_test:0.05844, lr:1.00e-02, fs:0.90452 (r=0.909,p=0.900),  time:24.790, tt:842.850\n",
      "Ep:34, loss:0.00009, loss_test:0.05955, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:24.770, tt:866.967\n",
      "Ep:35, loss:0.00009, loss_test:0.05577, lr:1.00e-02, fs:0.92857 (r=0.919,p=0.938),  time:24.763, tt:891.463\n",
      "##########Best model found so far##########\n",
      "Ep:36, loss:0.00008, loss_test:0.05604, lr:1.00e-02, fs:0.91262 (r=0.949,p=0.879),  time:24.749, tt:915.719\n",
      "Ep:37, loss:0.00008, loss_test:0.05412, lr:1.00e-02, fs:0.92929 (r=0.929,p=0.929),  time:24.787, tt:941.898\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.05254, lr:1.00e-02, fs:0.93939 (r=0.939,p=0.939),  time:24.791, tt:966.829\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.05525, lr:1.00e-02, fs:0.90476 (r=0.960,p=0.856),  time:24.778, tt:991.113\n",
      "Ep:40, loss:0.00007, loss_test:0.05122, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:24.834, tt:1018.182\n",
      "Ep:41, loss:0.00007, loss_test:0.05216, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:24.885, tt:1045.164\n",
      "Ep:42, loss:0.00007, loss_test:0.04907, lr:1.00e-02, fs:0.94359 (r=0.929,p=0.958),  time:24.932, tt:1072.061\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00006, loss_test:0.04872, lr:1.00e-02, fs:0.94059 (r=0.960,p=0.922),  time:24.921, tt:1096.505\n",
      "Ep:44, loss:0.00006, loss_test:0.04964, lr:1.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:24.918, tt:1121.305\n",
      "Ep:45, loss:0.00006, loss_test:0.04686, lr:1.00e-02, fs:0.95431 (r=0.949,p=0.959),  time:24.920, tt:1146.301\n",
      "##########Best model found so far##########\n",
      "Ep:46, loss:0.00006, loss_test:0.04826, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:24.991, tt:1174.575\n",
      "Ep:47, loss:0.00006, loss_test:0.04566, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:24.965, tt:1198.335\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00005, loss_test:0.04492, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:24.955, tt:1222.797\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00005, loss_test:0.04474, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:24.996, tt:1249.807\n",
      "Ep:50, loss:0.00005, loss_test:0.04365, lr:1.00e-02, fs:0.94416 (r=0.939,p=0.949),  time:25.033, tt:1276.679\n",
      "Ep:51, loss:0.00005, loss_test:0.04286, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:25.014, tt:1300.707\n",
      "Ep:52, loss:0.00004, loss_test:0.04245, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:25.027, tt:1326.458\n",
      "Ep:53, loss:0.00004, loss_test:0.04173, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:25.039, tt:1352.088\n",
      "Ep:54, loss:0.00004, loss_test:0.04210, lr:1.00e-02, fs:0.93401 (r=0.929,p=0.939),  time:25.022, tt:1376.200\n",
      "Ep:55, loss:0.00004, loss_test:0.04151, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:25.027, tt:1401.527\n",
      "Ep:56, loss:0.00004, loss_test:0.04126, lr:1.00e-02, fs:0.93467 (r=0.939,p=0.930),  time:25.047, tt:1427.671\n",
      "Ep:57, loss:0.00004, loss_test:0.04044, lr:1.00e-02, fs:0.95477 (r=0.960,p=0.950),  time:25.034, tt:1451.955\n",
      "Ep:58, loss:0.00003, loss_test:0.04074, lr:1.00e-02, fs:0.93333 (r=0.919,p=0.948),  time:25.034, tt:1477.007\n",
      "Ep:59, loss:0.00003, loss_test:0.04020, lr:1.00e-02, fs:0.93878 (r=0.929,p=0.948),  time:25.035, tt:1502.093\n",
      "Ep:60, loss:0.00003, loss_test:0.03981, lr:9.90e-03, fs:0.94949 (r=0.949,p=0.949),  time:25.024, tt:1526.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:61, loss:0.00003, loss_test:0.03942, lr:9.80e-03, fs:0.94949 (r=0.949,p=0.949),  time:25.014, tt:1550.895\n",
      "Ep:62, loss:0.00003, loss_test:0.03896, lr:9.70e-03, fs:0.94949 (r=0.949,p=0.949),  time:25.004, tt:1575.239\n",
      "Ep:63, loss:0.00003, loss_test:0.03922, lr:9.61e-03, fs:0.92308 (r=0.909,p=0.938),  time:25.002, tt:1600.110\n",
      "Ep:64, loss:0.00003, loss_test:0.03880, lr:9.51e-03, fs:0.95000 (r=0.960,p=0.941),  time:25.021, tt:1626.333\n",
      "Ep:65, loss:0.00003, loss_test:0.03920, lr:9.41e-03, fs:0.91667 (r=0.889,p=0.946),  time:24.994, tt:1649.606\n",
      "Ep:66, loss:0.00003, loss_test:0.03828, lr:9.32e-03, fs:0.95477 (r=0.960,p=0.950),  time:24.994, tt:1674.622\n",
      "Ep:67, loss:0.00002, loss_test:0.03921, lr:9.23e-03, fs:0.87432 (r=0.808,p=0.952),  time:24.998, tt:1699.865\n",
      "Ep:68, loss:0.00002, loss_test:0.03824, lr:9.14e-03, fs:0.93878 (r=0.929,p=0.948),  time:24.997, tt:1724.809\n",
      "Ep:69, loss:0.00002, loss_test:0.03842, lr:9.04e-03, fs:0.88172 (r=0.828,p=0.943),  time:25.012, tt:1750.861\n",
      "Ep:70, loss:0.00002, loss_test:0.03951, lr:8.95e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.016, tt:1776.128\n",
      "Ep:71, loss:0.00002, loss_test:0.03764, lr:8.86e-03, fs:0.91099 (r=0.879,p=0.946),  time:25.060, tt:1804.285\n",
      "Ep:72, loss:0.00002, loss_test:0.03932, lr:8.78e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.109, tt:1832.931\n",
      "Ep:73, loss:0.00002, loss_test:0.03832, lr:8.69e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.089, tt:1856.603\n",
      "Ep:74, loss:0.00002, loss_test:0.03817, lr:8.60e-03, fs:0.88043 (r=0.818,p=0.953),  time:25.084, tt:1881.264\n",
      "Ep:75, loss:0.00002, loss_test:0.03937, lr:8.51e-03, fs:0.87293 (r=0.798,p=0.963),  time:25.105, tt:1907.989\n",
      "Ep:76, loss:0.00002, loss_test:0.03788, lr:8.43e-03, fs:0.88043 (r=0.818,p=0.953),  time:25.117, tt:1934.046\n",
      "Ep:77, loss:0.00002, loss_test:0.03881, lr:8.35e-03, fs:0.88398 (r=0.808,p=0.976),  time:25.120, tt:1959.352\n",
      "Ep:78, loss:0.00002, loss_test:0.03851, lr:8.26e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.124, tt:1984.797\n",
      "Ep:79, loss:0.00002, loss_test:0.03796, lr:8.18e-03, fs:0.87912 (r=0.808,p=0.964),  time:25.111, tt:2008.855\n",
      "Ep:80, loss:0.00002, loss_test:0.03876, lr:8.10e-03, fs:0.87778 (r=0.798,p=0.975),  time:25.117, tt:2034.487\n",
      "Ep:81, loss:0.00002, loss_test:0.03784, lr:8.02e-03, fs:0.88398 (r=0.808,p=0.976),  time:25.126, tt:2060.335\n",
      "Ep:82, loss:0.00001, loss_test:0.03904, lr:7.94e-03, fs:0.87778 (r=0.798,p=0.975),  time:25.126, tt:2085.484\n",
      "Ep:83, loss:0.00001, loss_test:0.03810, lr:7.86e-03, fs:0.88398 (r=0.808,p=0.976),  time:25.117, tt:2109.795\n",
      "Ep:84, loss:0.00001, loss_test:0.03936, lr:7.78e-03, fs:0.87151 (r=0.788,p=0.975),  time:25.081, tt:2131.922\n",
      "Ep:85, loss:0.00001, loss_test:0.03820, lr:7.70e-03, fs:0.87778 (r=0.798,p=0.975),  time:25.036, tt:2153.122\n",
      "Ep:86, loss:0.00001, loss_test:0.03937, lr:7.62e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.991, tt:2174.202\n",
      "Ep:87, loss:0.00001, loss_test:0.03863, lr:7.55e-03, fs:0.87778 (r=0.798,p=0.975),  time:24.951, tt:2195.714\n",
      "Ep:88, loss:0.00001, loss_test:0.03873, lr:7.47e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.899, tt:2216.022\n",
      "Ep:89, loss:0.00001, loss_test:0.03939, lr:7.40e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.886, tt:2239.760\n",
      "Ep:90, loss:0.00001, loss_test:0.03895, lr:7.32e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.861, tt:2262.372\n",
      "Ep:91, loss:0.00001, loss_test:0.03904, lr:7.25e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.834, tt:2284.688\n",
      "Ep:92, loss:0.00001, loss_test:0.03935, lr:7.18e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.817, tt:2308.025\n",
      "Ep:93, loss:0.00001, loss_test:0.03925, lr:7.11e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.834, tt:2334.385\n",
      "Ep:94, loss:0.00001, loss_test:0.03897, lr:7.03e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.842, tt:2359.944\n",
      "Ep:95, loss:0.00001, loss_test:0.03971, lr:6.96e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.839, tt:2384.531\n",
      "Ep:96, loss:0.00001, loss_test:0.03908, lr:6.89e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.854, tt:2410.797\n",
      "Ep:97, loss:0.00001, loss_test:0.03921, lr:6.83e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.846, tt:2434.942\n",
      "Ep:98, loss:0.00001, loss_test:0.03936, lr:6.76e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.877, tt:2462.807\n",
      "Ep:99, loss:0.00001, loss_test:0.03925, lr:6.69e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.867, tt:2486.730\n",
      "Ep:100, loss:0.00001, loss_test:0.03933, lr:6.62e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.890, tt:2513.898\n",
      "Ep:101, loss:0.00001, loss_test:0.03961, lr:6.56e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.881, tt:2537.894\n",
      "Ep:102, loss:0.00001, loss_test:0.04011, lr:6.49e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.872, tt:2561.828\n",
      "Ep:103, loss:0.00001, loss_test:0.03932, lr:6.43e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.863, tt:2585.728\n",
      "Ep:104, loss:0.00001, loss_test:0.03970, lr:6.36e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.860, tt:2610.306\n",
      "Ep:105, loss:0.00001, loss_test:0.04002, lr:6.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.866, tt:2635.838\n",
      "Ep:106, loss:0.00001, loss_test:0.03917, lr:6.24e-03, fs:0.87151 (r=0.788,p=0.975),  time:24.894, tt:2663.708\n",
      "Ep:107, loss:0.00001, loss_test:0.03990, lr:6.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.892, tt:2688.308\n",
      "Ep:108, loss:0.00001, loss_test:0.03967, lr:6.11e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.888, tt:2712.825\n",
      "Ep:109, loss:0.00001, loss_test:0.03987, lr:6.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.883, tt:2737.134\n",
      "Ep:110, loss:0.00001, loss_test:0.03965, lr:5.99e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.882, tt:2761.917\n",
      "Ep:111, loss:0.00001, loss_test:0.03980, lr:5.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.898, tt:2788.596\n",
      "Ep:112, loss:0.00001, loss_test:0.03963, lr:5.87e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.896, tt:2813.293\n",
      "Ep:113, loss:0.00001, loss_test:0.04023, lr:5.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.896, tt:2838.158\n",
      "Ep:114, loss:0.00001, loss_test:0.04025, lr:5.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.891, tt:2862.470\n",
      "Ep:115, loss:0.00001, loss_test:0.03981, lr:5.70e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.905, tt:2889.009\n",
      "Ep:116, loss:0.00001, loss_test:0.03995, lr:5.64e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.897, tt:2912.905\n",
      "Ep:117, loss:0.00001, loss_test:0.04007, lr:5.58e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.899, tt:2938.100\n",
      "Ep:118, loss:0.00001, loss_test:0.04032, lr:5.53e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.887, tt:2961.600\n",
      "Ep:119, loss:0.00001, loss_test:0.03976, lr:5.47e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.883, tt:2986.004\n",
      "Ep:120, loss:0.00001, loss_test:0.04069, lr:5.42e-03, fs:0.88136 (r=0.788,p=1.000),  time:24.885, tt:3011.026\n",
      "Ep:121, loss:0.00001, loss_test:0.04041, lr:5.36e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.877, tt:3035.050\n",
      "Ep:122, loss:0.00001, loss_test:0.04021, lr:5.31e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.873, tt:3059.345\n",
      "Ep:123, loss:0.00001, loss_test:0.04086, lr:5.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.861, tt:3082.768\n",
      "Ep:124, loss:0.00001, loss_test:0.04013, lr:5.20e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.882, tt:3110.192\n",
      "Ep:125, loss:0.00001, loss_test:0.04055, lr:5.15e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.865, tt:3132.977\n",
      "Ep:126, loss:0.00001, loss_test:0.04037, lr:5.10e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.870, tt:3158.485\n",
      "Ep:127, loss:0.00001, loss_test:0.04043, lr:5.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.875, tt:3184.020\n",
      "Ep:128, loss:0.00001, loss_test:0.04026, lr:5.00e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.877, tt:3209.099\n",
      "Ep:129, loss:0.00001, loss_test:0.03992, lr:4.95e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.870, tt:3233.114\n",
      "Ep:130, loss:0.00001, loss_test:0.04030, lr:4.90e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.875, tt:3258.609\n",
      "Ep:131, loss:0.00000, loss_test:0.04033, lr:4.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.871, tt:3283.013\n",
      "Ep:132, loss:0.00000, loss_test:0.03993, lr:4.80e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.863, tt:3306.732\n",
      "Ep:133, loss:0.00000, loss_test:0.04032, lr:4.75e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.872, tt:3332.908\n",
      "Ep:134, loss:0.00000, loss_test:0.04046, lr:4.71e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.864, tt:3356.603\n",
      "Ep:135, loss:0.00000, loss_test:0.04014, lr:4.66e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.857, tt:3380.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:136, loss:0.00000, loss_test:0.04040, lr:4.61e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.847, tt:3404.037\n",
      "Ep:137, loss:0.00000, loss_test:0.04008, lr:4.57e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.851, tt:3429.472\n",
      "Ep:138, loss:0.00000, loss_test:0.04047, lr:4.52e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.838, tt:3452.476\n",
      "Ep:139, loss:0.00000, loss_test:0.04027, lr:4.48e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.877, tt:3482.805\n",
      "Ep:140, loss:0.00000, loss_test:0.04045, lr:4.43e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.866, tt:3506.070\n",
      "Ep:141, loss:0.00000, loss_test:0.04032, lr:4.39e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.864, tt:3530.734\n",
      "Ep:142, loss:0.00000, loss_test:0.04023, lr:4.34e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.855, tt:3554.275\n",
      "Ep:143, loss:0.00000, loss_test:0.04049, lr:4.30e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.845, tt:3577.749\n",
      "Ep:144, loss:0.00000, loss_test:0.04034, lr:4.26e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.847, tt:3602.808\n",
      "Ep:145, loss:0.00000, loss_test:0.04040, lr:4.21e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.838, tt:3626.389\n",
      "Ep:146, loss:0.00000, loss_test:0.04041, lr:4.17e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.831, tt:3650.132\n",
      "Ep:147, loss:0.00000, loss_test:0.04070, lr:4.13e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.825, tt:3674.036\n",
      "Ep:148, loss:0.00000, loss_test:0.04031, lr:4.09e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.820, tt:3698.191\n",
      "Ep:149, loss:0.00000, loss_test:0.04038, lr:4.05e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.819, tt:3722.862\n",
      "Ep:150, loss:0.00000, loss_test:0.04063, lr:4.01e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.838, tt:3750.584\n",
      "Ep:151, loss:0.00000, loss_test:0.04056, lr:3.97e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.831, tt:3774.344\n",
      "Ep:152, loss:0.00000, loss_test:0.04060, lr:3.93e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.828, tt:3798.749\n",
      "Ep:153, loss:0.00000, loss_test:0.04049, lr:3.89e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.822, tt:3822.563\n",
      "Ep:154, loss:0.00000, loss_test:0.04070, lr:3.85e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.806, tt:3844.932\n",
      "Ep:155, loss:0.00000, loss_test:0.04097, lr:3.81e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.802, tt:3869.182\n",
      "Ep:156, loss:0.00000, loss_test:0.04050, lr:3.77e-03, fs:0.87640 (r=0.788,p=0.987),  time:24.795, tt:3892.789\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_728_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14448, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:24.458, tt:24.458\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14324, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:25.112, tt:50.223\n",
      "Ep:2, loss:0.00028, loss_test:0.14100, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:25.442, tt:76.327\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13730, lr:1.00e-02, fs:0.66436 (r=0.970,p=0.505),  time:25.289, tt:101.157\n",
      "Ep:4, loss:0.00027, loss_test:0.13147, lr:1.00e-02, fs:0.65201 (r=0.899,p=0.511),  time:24.951, tt:124.753\n",
      "Ep:5, loss:0.00026, loss_test:0.12479, lr:1.00e-02, fs:0.68000 (r=0.859,p=0.563),  time:25.199, tt:151.195\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.12168, lr:1.00e-02, fs:0.68333 (r=0.828,p=0.582),  time:25.268, tt:176.878\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.12042, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:25.383, tt:203.064\n",
      "Ep:8, loss:0.00023, loss_test:0.11826, lr:1.00e-02, fs:0.67249 (r=0.778,p=0.592),  time:25.459, tt:229.127\n",
      "Ep:9, loss:0.00022, loss_test:0.11708, lr:1.00e-02, fs:0.68122 (r=0.788,p=0.600),  time:25.277, tt:252.775\n",
      "Ep:10, loss:0.00021, loss_test:0.11595, lr:1.00e-02, fs:0.68778 (r=0.768,p=0.623),  time:25.149, tt:276.634\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.11437, lr:1.00e-02, fs:0.68020 (r=0.677,p=0.684),  time:25.081, tt:300.978\n",
      "Ep:12, loss:0.00019, loss_test:0.11270, lr:1.00e-02, fs:0.68342 (r=0.687,p=0.680),  time:25.157, tt:327.047\n",
      "Ep:13, loss:0.00018, loss_test:0.11044, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:25.298, tt:354.175\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10805, lr:1.00e-02, fs:0.73298 (r=0.707,p=0.761),  time:25.342, tt:380.132\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10537, lr:1.00e-02, fs:0.74346 (r=0.717,p=0.772),  time:25.367, tt:405.875\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.10294, lr:1.00e-02, fs:0.76000 (r=0.768,p=0.752),  time:25.317, tt:430.392\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00016, loss_test:0.10077, lr:1.00e-02, fs:0.76596 (r=0.727,p=0.809),  time:25.346, tt:456.221\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.09833, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:25.415, tt:482.884\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.09678, lr:1.00e-02, fs:0.79793 (r=0.778,p=0.819),  time:25.420, tt:508.406\n",
      "Ep:20, loss:0.00014, loss_test:0.09562, lr:1.00e-02, fs:0.80000 (r=0.768,p=0.835),  time:25.409, tt:533.588\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.09432, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:25.425, tt:559.348\n",
      "Ep:22, loss:0.00013, loss_test:0.09341, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:25.438, tt:585.064\n",
      "Ep:23, loss:0.00012, loss_test:0.09110, lr:1.00e-02, fs:0.78723 (r=0.747,p=0.831),  time:25.423, tt:610.152\n",
      "Ep:24, loss:0.00012, loss_test:0.08999, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:25.374, tt:634.351\n",
      "Ep:25, loss:0.00011, loss_test:0.08932, lr:1.00e-02, fs:0.78495 (r=0.737,p=0.839),  time:25.422, tt:660.959\n",
      "Ep:26, loss:0.00011, loss_test:0.08723, lr:1.00e-02, fs:0.77419 (r=0.727,p=0.828),  time:25.447, tt:687.078\n",
      "Ep:27, loss:0.00010, loss_test:0.08685, lr:1.00e-02, fs:0.78022 (r=0.717,p=0.855),  time:25.387, tt:710.822\n",
      "Ep:28, loss:0.00010, loss_test:0.08543, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:25.320, tt:734.270\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.08625, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:25.301, tt:759.027\n",
      "Ep:30, loss:0.00009, loss_test:0.08409, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:25.247, tt:782.668\n",
      "Ep:31, loss:0.00008, loss_test:0.08382, lr:1.00e-02, fs:0.78919 (r=0.737,p=0.849),  time:25.248, tt:807.927\n",
      "Ep:32, loss:0.00008, loss_test:0.08297, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:25.199, tt:831.565\n",
      "Ep:33, loss:0.00008, loss_test:0.08303, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:25.256, tt:858.713\n",
      "Ep:34, loss:0.00007, loss_test:0.08170, lr:1.00e-02, fs:0.80214 (r=0.758,p=0.852),  time:25.236, tt:883.268\n",
      "Ep:35, loss:0.00007, loss_test:0.08284, lr:1.00e-02, fs:0.80663 (r=0.737,p=0.890),  time:25.229, tt:908.244\n",
      "Ep:36, loss:0.00007, loss_test:0.08340, lr:1.00e-02, fs:0.77528 (r=0.697,p=0.873),  time:25.210, tt:932.773\n",
      "Ep:37, loss:0.00007, loss_test:0.08203, lr:1.00e-02, fs:0.78689 (r=0.727,p=0.857),  time:25.220, tt:958.377\n",
      "Ep:38, loss:0.00006, loss_test:0.08171, lr:1.00e-02, fs:0.79558 (r=0.727,p=0.878),  time:25.195, tt:982.607\n",
      "Ep:39, loss:0.00006, loss_test:0.08067, lr:1.00e-02, fs:0.79781 (r=0.737,p=0.869),  time:25.162, tt:1006.493\n",
      "Ep:40, loss:0.00006, loss_test:0.08203, lr:9.90e-03, fs:0.77273 (r=0.687,p=0.883),  time:25.109, tt:1029.476\n",
      "Ep:41, loss:0.00006, loss_test:0.08303, lr:9.80e-03, fs:0.78889 (r=0.717,p=0.877),  time:25.069, tt:1052.912\n",
      "Ep:42, loss:0.00005, loss_test:0.08317, lr:9.70e-03, fs:0.77273 (r=0.687,p=0.883),  time:25.075, tt:1078.223\n",
      "Ep:43, loss:0.00005, loss_test:0.08426, lr:9.61e-03, fs:0.76301 (r=0.667,p=0.892),  time:25.048, tt:1102.118\n",
      "Ep:44, loss:0.00005, loss_test:0.08474, lr:9.51e-03, fs:0.75429 (r=0.667,p=0.868),  time:25.095, tt:1129.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:45, loss:0.00005, loss_test:0.08470, lr:9.41e-03, fs:0.75862 (r=0.667,p=0.880),  time:25.054, tt:1152.473\n",
      "Ep:46, loss:0.00005, loss_test:0.08483, lr:9.32e-03, fs:0.76301 (r=0.667,p=0.892),  time:25.083, tt:1178.905\n",
      "Ep:47, loss:0.00004, loss_test:0.08458, lr:9.23e-03, fs:0.75862 (r=0.667,p=0.880),  time:25.037, tt:1201.754\n",
      "Ep:48, loss:0.00004, loss_test:0.08503, lr:9.14e-03, fs:0.75862 (r=0.667,p=0.880),  time:25.047, tt:1227.301\n",
      "Ep:49, loss:0.00004, loss_test:0.08580, lr:9.04e-03, fs:0.76301 (r=0.667,p=0.892),  time:25.042, tt:1252.119\n",
      "Ep:50, loss:0.00004, loss_test:0.08370, lr:8.95e-03, fs:0.75862 (r=0.667,p=0.880),  time:25.027, tt:1276.363\n",
      "Ep:51, loss:0.00004, loss_test:0.08589, lr:8.86e-03, fs:0.76023 (r=0.657,p=0.903),  time:25.012, tt:1300.628\n",
      "Ep:52, loss:0.00004, loss_test:0.08572, lr:8.78e-03, fs:0.76471 (r=0.657,p=0.915),  time:25.004, tt:1325.198\n",
      "Ep:53, loss:0.00004, loss_test:0.08392, lr:8.69e-03, fs:0.77714 (r=0.687,p=0.895),  time:25.020, tt:1351.097\n",
      "Ep:54, loss:0.00004, loss_test:0.08707, lr:8.60e-03, fs:0.76923 (r=0.657,p=0.929),  time:25.003, tt:1375.192\n",
      "Ep:55, loss:0.00004, loss_test:0.08489, lr:8.51e-03, fs:0.76471 (r=0.657,p=0.915),  time:25.018, tt:1401.031\n",
      "Ep:56, loss:0.00004, loss_test:0.08537, lr:8.43e-03, fs:0.76471 (r=0.657,p=0.915),  time:25.000, tt:1425.027\n",
      "Ep:57, loss:0.00003, loss_test:0.08861, lr:8.35e-03, fs:0.76923 (r=0.657,p=0.929),  time:25.013, tt:1450.758\n",
      "Ep:58, loss:0.00003, loss_test:0.08457, lr:8.26e-03, fs:0.76471 (r=0.657,p=0.915),  time:24.980, tt:1473.833\n",
      "Ep:59, loss:0.00003, loss_test:0.08679, lr:8.18e-03, fs:0.76471 (r=0.657,p=0.915),  time:24.960, tt:1497.625\n",
      "Ep:60, loss:0.00003, loss_test:0.08745, lr:8.10e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.940, tt:1521.325\n",
      "Ep:61, loss:0.00003, loss_test:0.08688, lr:8.02e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.962, tt:1547.646\n",
      "Ep:62, loss:0.00003, loss_test:0.08508, lr:7.94e-03, fs:0.77193 (r=0.667,p=0.917),  time:24.952, tt:1571.949\n",
      "Ep:63, loss:0.00003, loss_test:0.09015, lr:7.86e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.968, tt:1597.925\n",
      "Ep:64, loss:0.00003, loss_test:0.08735, lr:7.78e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.955, tt:1622.061\n",
      "Ep:65, loss:0.00003, loss_test:0.08612, lr:7.70e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.972, tt:1648.133\n",
      "Ep:66, loss:0.00003, loss_test:0.08852, lr:7.62e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.970, tt:1672.999\n",
      "Ep:67, loss:0.00003, loss_test:0.08918, lr:7.55e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.965, tt:1697.598\n",
      "Ep:68, loss:0.00003, loss_test:0.08483, lr:7.47e-03, fs:0.77647 (r=0.667,p=0.930),  time:24.953, tt:1721.749\n",
      "Ep:69, loss:0.00003, loss_test:0.09071, lr:7.40e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.935, tt:1745.421\n",
      "Ep:70, loss:0.00003, loss_test:0.08540, lr:7.32e-03, fs:0.77647 (r=0.667,p=0.930),  time:24.918, tt:1769.180\n",
      "Ep:71, loss:0.00002, loss_test:0.09047, lr:7.25e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.920, tt:1794.226\n",
      "Ep:72, loss:0.00002, loss_test:0.08783, lr:7.18e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.913, tt:1818.681\n",
      "Ep:73, loss:0.00002, loss_test:0.08788, lr:7.11e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.913, tt:1843.577\n",
      "Ep:74, loss:0.00002, loss_test:0.08641, lr:7.03e-03, fs:0.78363 (r=0.677,p=0.931),  time:24.921, tt:1869.101\n",
      "Ep:75, loss:0.00002, loss_test:0.09008, lr:6.96e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.902, tt:1892.541\n",
      "Ep:76, loss:0.00002, loss_test:0.08612, lr:6.89e-03, fs:0.77647 (r=0.667,p=0.930),  time:24.899, tt:1917.245\n",
      "Ep:77, loss:0.00002, loss_test:0.08943, lr:6.83e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.873, tt:1940.080\n",
      "Ep:78, loss:0.00002, loss_test:0.08791, lr:6.76e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.877, tt:1965.275\n",
      "Ep:79, loss:0.00002, loss_test:0.08873, lr:6.69e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.851, tt:1988.116\n",
      "Ep:80, loss:0.00002, loss_test:0.08689, lr:6.62e-03, fs:0.78824 (r=0.677,p=0.944),  time:24.848, tt:2012.681\n",
      "Ep:81, loss:0.00002, loss_test:0.09033, lr:6.56e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.846, tt:2037.378\n",
      "Ep:82, loss:0.00002, loss_test:0.08583, lr:6.49e-03, fs:0.78363 (r=0.677,p=0.931),  time:24.826, tt:2060.554\n",
      "Ep:83, loss:0.00002, loss_test:0.08957, lr:6.43e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.824, tt:2085.175\n",
      "Ep:84, loss:0.00002, loss_test:0.08825, lr:6.36e-03, fs:0.76923 (r=0.657,p=0.929),  time:24.823, tt:2109.967\n",
      "Ep:85, loss:0.00002, loss_test:0.08831, lr:6.30e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.805, tt:2133.263\n",
      "Ep:86, loss:0.00002, loss_test:0.08952, lr:6.24e-03, fs:0.77844 (r=0.657,p=0.956),  time:24.783, tt:2156.115\n",
      "Ep:87, loss:0.00002, loss_test:0.08824, lr:6.17e-03, fs:0.77381 (r=0.657,p=0.942),  time:24.790, tt:2181.557\n",
      "Ep:88, loss:0.00002, loss_test:0.08914, lr:6.11e-03, fs:0.77844 (r=0.657,p=0.956),  time:24.773, tt:2204.840\n",
      "Ep:89, loss:0.00002, loss_test:0.08890, lr:6.05e-03, fs:0.77844 (r=0.657,p=0.956),  time:24.757, tt:2228.145\n",
      "Ep:90, loss:0.00002, loss_test:0.08951, lr:5.99e-03, fs:0.77844 (r=0.657,p=0.956),  time:24.748, tt:2252.084\n",
      "Ep:91, loss:0.00002, loss_test:0.09017, lr:5.93e-03, fs:0.77844 (r=0.657,p=0.956),  time:24.737, tt:2275.831\n",
      "Ep:92, loss:0.00002, loss_test:0.08956, lr:5.87e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.715, tt:2298.531\n",
      "Ep:93, loss:0.00002, loss_test:0.09002, lr:5.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.692, tt:2321.086\n",
      "Ep:94, loss:0.00001, loss_test:0.08950, lr:5.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.704, tt:2346.866\n",
      "Ep:95, loss:0.00001, loss_test:0.09127, lr:5.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.689, tt:2370.101\n",
      "Ep:96, loss:0.00001, loss_test:0.08962, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.690, tt:2394.961\n",
      "Ep:97, loss:0.00001, loss_test:0.09259, lr:5.58e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.692, tt:2419.852\n",
      "Ep:98, loss:0.00001, loss_test:0.08941, lr:5.53e-03, fs:0.79762 (r=0.677,p=0.971),  time:24.690, tt:2444.345\n",
      "Ep:99, loss:0.00001, loss_test:0.09347, lr:5.47e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.681, tt:2468.119\n",
      "Ep:100, loss:0.00001, loss_test:0.09167, lr:5.42e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.672, tt:2491.851\n",
      "Ep:101, loss:0.00001, loss_test:0.09345, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.660, tt:2515.284\n",
      "Ep:102, loss:0.00001, loss_test:0.09240, lr:5.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.647, tt:2538.679\n",
      "Ep:103, loss:0.00001, loss_test:0.09318, lr:5.26e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.653, tt:2563.930\n",
      "Ep:104, loss:0.00001, loss_test:0.09169, lr:5.20e-03, fs:0.79042 (r=0.667,p=0.971),  time:24.662, tt:2589.459\n",
      "Ep:105, loss:0.00001, loss_test:0.09454, lr:5.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.659, tt:2613.876\n",
      "Ep:106, loss:0.00001, loss_test:0.09139, lr:5.10e-03, fs:0.79762 (r=0.677,p=0.971),  time:24.663, tt:2638.972\n",
      "Ep:107, loss:0.00001, loss_test:0.09481, lr:5.05e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.657, tt:2662.976\n",
      "Ep:108, loss:0.00001, loss_test:0.09187, lr:5.00e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.655, tt:2687.410\n",
      "Ep:109, loss:0.00001, loss_test:0.09450, lr:4.95e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.645, tt:2711.003\n",
      "Ep:110, loss:0.00001, loss_test:0.09178, lr:4.90e-03, fs:0.79042 (r=0.667,p=0.971),  time:24.647, tt:2735.786\n",
      "Ep:111, loss:0.00001, loss_test:0.09514, lr:4.85e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.640, tt:2759.703\n",
      "Ep:112, loss:0.00001, loss_test:0.09226, lr:4.80e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.634, tt:2783.595\n",
      "Ep:113, loss:0.00001, loss_test:0.09366, lr:4.75e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.623, tt:2807.064\n",
      "Ep:114, loss:0.00001, loss_test:0.09400, lr:4.71e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.619, tt:2831.156\n",
      "Ep:115, loss:0.00001, loss_test:0.09289, lr:4.66e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.610, tt:2854.812\n",
      "Ep:116, loss:0.00001, loss_test:0.09360, lr:4.61e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.611, tt:2879.499\n",
      "Ep:117, loss:0.00001, loss_test:0.09507, lr:4.57e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.603, tt:2903.128\n",
      "Ep:118, loss:0.00001, loss_test:0.09325, lr:4.52e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.602, tt:2927.601\n",
      "Ep:119, loss:0.00001, loss_test:0.09366, lr:4.48e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.596, tt:2951.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:120, loss:0.00001, loss_test:0.09367, lr:4.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.586, tt:2974.856\n",
      "Ep:121, loss:0.00001, loss_test:0.09537, lr:4.39e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.593, tt:3000.318\n",
      "Ep:122, loss:0.00001, loss_test:0.09329, lr:4.34e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.595, tt:3025.157\n",
      "Ep:123, loss:0.00001, loss_test:0.09421, lr:4.30e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.603, tt:3050.822\n",
      "Ep:124, loss:0.00001, loss_test:0.09606, lr:4.26e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.605, tt:3075.670\n",
      "Ep:125, loss:0.00001, loss_test:0.09401, lr:4.21e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.609, tt:3100.703\n",
      "Ep:126, loss:0.00001, loss_test:0.09439, lr:4.17e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.618, tt:3126.547\n",
      "Ep:127, loss:0.00001, loss_test:0.09513, lr:4.13e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.614, tt:3150.579\n",
      "Ep:128, loss:0.00001, loss_test:0.09445, lr:4.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.602, tt:3173.691\n",
      "Ep:129, loss:0.00001, loss_test:0.09449, lr:4.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.614, tt:3199.814\n",
      "Ep:130, loss:0.00001, loss_test:0.09710, lr:4.01e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.613, tt:3224.309\n",
      "Ep:131, loss:0.00001, loss_test:0.09406, lr:3.97e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.613, tt:3248.948\n",
      "Ep:132, loss:0.00001, loss_test:0.09635, lr:3.93e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.614, tt:3273.652\n",
      "Ep:133, loss:0.00001, loss_test:0.09615, lr:3.89e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.608, tt:3297.507\n",
      "Ep:134, loss:0.00001, loss_test:0.09609, lr:3.85e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.608, tt:3322.133\n",
      "Ep:135, loss:0.00001, loss_test:0.09512, lr:3.81e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.613, tt:3347.305\n",
      "Ep:136, loss:0.00001, loss_test:0.09664, lr:3.77e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.621, tt:3373.096\n",
      "Ep:137, loss:0.00001, loss_test:0.09625, lr:3.73e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.626, tt:3398.436\n",
      "Ep:138, loss:0.00001, loss_test:0.09460, lr:3.70e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.629, tt:3423.372\n",
      "Ep:139, loss:0.00001, loss_test:0.09803, lr:3.66e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.618, tt:3446.526\n",
      "Ep:140, loss:0.00001, loss_test:0.09621, lr:3.62e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.619, tt:3471.245\n",
      "Ep:141, loss:0.00001, loss_test:0.09636, lr:3.59e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.609, tt:3494.496\n",
      "Ep:142, loss:0.00001, loss_test:0.09781, lr:3.55e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.622, tt:3521.014\n",
      "Ep:143, loss:0.00001, loss_test:0.09730, lr:3.52e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.620, tt:3545.305\n",
      "Ep:144, loss:0.00001, loss_test:0.09686, lr:3.48e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.617, tt:3569.535\n",
      "Ep:145, loss:0.00001, loss_test:0.09747, lr:3.45e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.616, tt:3593.902\n",
      "Ep:146, loss:0.00001, loss_test:0.09775, lr:3.41e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.612, tt:3618.019\n",
      "Ep:147, loss:0.00001, loss_test:0.09673, lr:3.38e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.613, tt:3642.682\n",
      "Ep:148, loss:0.00001, loss_test:0.09790, lr:3.34e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.618, tt:3668.055\n",
      "Ep:149, loss:0.00001, loss_test:0.09636, lr:3.31e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.637, tt:3695.566\n",
      "Ep:150, loss:0.00001, loss_test:0.09811, lr:3.28e-03, fs:0.78049 (r=0.646,p=0.985),  time:24.637, tt:3720.213\n",
      "Ep:151, loss:0.00001, loss_test:0.09765, lr:3.24e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.645, tt:3746.073\n",
      "Ep:152, loss:0.00001, loss_test:0.09737, lr:3.21e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.667, tt:3774.116\n",
      "Ep:153, loss:0.00001, loss_test:0.09744, lr:3.18e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.649, tt:3796.010\n",
      "Ep:154, loss:0.00001, loss_test:0.09778, lr:3.15e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.616, tt:3815.478\n",
      "Ep:155, loss:0.00001, loss_test:0.09790, lr:3.12e-03, fs:0.77576 (r=0.646,p=0.970),  time:24.584, tt:3835.136\n",
      "Ep:156, loss:0.00001, loss_test:0.09722, lr:3.09e-03, fs:0.78313 (r=0.657,p=0.970),  time:24.546, tt:3853.794\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14199, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:42.304, tt:42.304\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14013, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:43.249, tt:86.497\n",
      "Ep:2, loss:0.00027, loss_test:0.13661, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:42.960, tt:128.881\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00027, loss_test:0.13087, lr:1.00e-02, fs:0.67138 (r=0.960,p=0.516),  time:42.992, tt:171.967\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.12303, lr:1.00e-02, fs:0.67910 (r=0.919,p=0.538),  time:42.856, tt:214.278\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00024, loss_test:0.11407, lr:1.00e-02, fs:0.69919 (r=0.869,p=0.585),  time:42.560, tt:255.358\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.10788, lr:1.00e-02, fs:0.69643 (r=0.788,p=0.624),  time:42.643, tt:298.500\n",
      "Ep:7, loss:0.00022, loss_test:0.10538, lr:1.00e-02, fs:0.70852 (r=0.798,p=0.637),  time:42.949, tt:343.592\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00021, loss_test:0.10310, lr:1.00e-02, fs:0.72103 (r=0.848,p=0.627),  time:42.905, tt:386.142\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.10018, lr:1.00e-02, fs:0.73362 (r=0.848,p=0.646),  time:42.596, tt:425.956\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09790, lr:1.00e-02, fs:0.75336 (r=0.848,p=0.677),  time:42.408, tt:466.492\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00020, loss_test:0.09614, lr:1.00e-02, fs:0.75221 (r=0.859,p=0.669),  time:42.593, tt:511.118\n",
      "Ep:12, loss:0.00019, loss_test:0.09404, lr:1.00e-02, fs:0.77130 (r=0.869,p=0.694),  time:42.683, tt:554.885\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00019, loss_test:0.09217, lr:1.00e-02, fs:0.79452 (r=0.879,p=0.725),  time:42.827, tt:599.575\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.09076, lr:1.00e-02, fs:0.77333 (r=0.879,p=0.690),  time:43.038, tt:645.572\n",
      "Ep:15, loss:0.00018, loss_test:0.08908, lr:1.00e-02, fs:0.78027 (r=0.879,p=0.702),  time:42.995, tt:687.913\n",
      "Ep:16, loss:0.00017, loss_test:0.08733, lr:1.00e-02, fs:0.80184 (r=0.879,p=0.737),  time:42.850, tt:728.457\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00017, loss_test:0.08616, lr:1.00e-02, fs:0.80717 (r=0.909,p=0.726),  time:42.808, tt:770.547\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08482, lr:1.00e-02, fs:0.81279 (r=0.899,p=0.742),  time:42.737, tt:811.995\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00016, loss_test:0.08425, lr:1.00e-02, fs:0.81982 (r=0.919,p=0.740),  time:42.736, tt:854.712\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00016, loss_test:0.08234, lr:1.00e-02, fs:0.82143 (r=0.929,p=0.736),  time:42.674, tt:896.147\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00016, loss_test:0.08111, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.632, tt:937.896\n",
      "##########Best model found so far##########\n",
      "Ep:22, loss:0.00015, loss_test:0.08009, lr:1.00e-02, fs:0.82301 (r=0.939,p=0.732),  time:42.682, tt:981.690\n",
      "Ep:23, loss:0.00015, loss_test:0.07914, lr:1.00e-02, fs:0.82511 (r=0.929,p=0.742),  time:42.770, tt:1026.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:24, loss:0.00015, loss_test:0.07858, lr:1.00e-02, fs:0.82192 (r=0.909,p=0.750),  time:42.792, tt:1069.812\n",
      "Ep:25, loss:0.00015, loss_test:0.07700, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.701, tt:1110.223\n",
      "Ep:26, loss:0.00014, loss_test:0.07661, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.688, tt:1152.573\n",
      "Ep:27, loss:0.00014, loss_test:0.07558, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.715, tt:1196.016\n",
      "Ep:28, loss:0.00014, loss_test:0.07436, lr:1.00e-02, fs:0.83486 (r=0.919,p=0.765),  time:42.640, tt:1236.556\n",
      "Ep:29, loss:0.00014, loss_test:0.07448, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:42.657, tt:1279.700\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00013, loss_test:0.07321, lr:1.00e-02, fs:0.84404 (r=0.929,p=0.773),  time:42.660, tt:1322.473\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00013, loss_test:0.07298, lr:1.00e-02, fs:0.83721 (r=0.909,p=0.776),  time:42.673, tt:1365.535\n",
      "Ep:32, loss:0.00013, loss_test:0.07169, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:42.594, tt:1405.604\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00013, loss_test:0.07114, lr:1.00e-02, fs:0.83871 (r=0.919,p=0.771),  time:42.610, tt:1448.742\n",
      "Ep:34, loss:0.00012, loss_test:0.07070, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:42.512, tt:1487.914\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00012, loss_test:0.06985, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:42.502, tt:1530.088\n",
      "Ep:36, loss:0.00012, loss_test:0.06938, lr:1.00e-02, fs:0.85446 (r=0.919,p=0.798),  time:42.531, tt:1573.652\n",
      "Ep:37, loss:0.00012, loss_test:0.06868, lr:1.00e-02, fs:0.86512 (r=0.939,p=0.802),  time:42.552, tt:1616.971\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00012, loss_test:0.06838, lr:1.00e-02, fs:0.85047 (r=0.919,p=0.791),  time:42.639, tt:1662.923\n",
      "Ep:39, loss:0.00011, loss_test:0.06796, lr:1.00e-02, fs:0.86111 (r=0.939,p=0.795),  time:42.682, tt:1707.285\n",
      "Ep:40, loss:0.00011, loss_test:0.06747, lr:1.00e-02, fs:0.85849 (r=0.919,p=0.805),  time:42.615, tt:1747.212\n",
      "Ep:41, loss:0.00011, loss_test:0.06728, lr:1.00e-02, fs:0.87379 (r=0.909,p=0.841),  time:42.545, tt:1786.875\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00011, loss_test:0.06660, lr:1.00e-02, fs:0.87850 (r=0.949,p=0.817),  time:42.515, tt:1828.130\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00010, loss_test:0.06572, lr:1.00e-02, fs:0.88038 (r=0.929,p=0.836),  time:42.505, tt:1870.206\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00010, loss_test:0.06569, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:42.501, tt:1912.566\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00010, loss_test:0.06535, lr:1.00e-02, fs:0.89202 (r=0.960,p=0.833),  time:42.543, tt:1956.971\n",
      "Ep:46, loss:0.00010, loss_test:0.06516, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:42.545, tt:1999.630\n",
      "Ep:47, loss:0.00010, loss_test:0.06441, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:42.549, tt:2042.330\n",
      "##########Best model found so far##########\n",
      "Ep:48, loss:0.00009, loss_test:0.06445, lr:1.00e-02, fs:0.90909 (r=0.960,p=0.864),  time:42.539, tt:2084.419\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00009, loss_test:0.06374, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:42.574, tt:2128.708\n",
      "Ep:50, loss:0.00009, loss_test:0.06365, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:42.528, tt:2168.909\n",
      "Ep:51, loss:0.00009, loss_test:0.06450, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:42.505, tt:2210.249\n",
      "Ep:52, loss:0.00009, loss_test:0.06325, lr:1.00e-02, fs:0.90141 (r=0.970,p=0.842),  time:42.504, tt:2252.688\n",
      "Ep:53, loss:0.00009, loss_test:0.06429, lr:1.00e-02, fs:0.90640 (r=0.929,p=0.885),  time:42.507, tt:2295.384\n",
      "Ep:54, loss:0.00008, loss_test:0.06293, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:42.490, tt:2336.940\n",
      "Ep:55, loss:0.00008, loss_test:0.06239, lr:1.00e-02, fs:0.91429 (r=0.970,p=0.865),  time:42.488, tt:2379.329\n",
      "##########Best model found so far##########\n",
      "Ep:56, loss:0.00008, loss_test:0.06397, lr:1.00e-02, fs:0.88557 (r=0.899,p=0.873),  time:42.503, tt:2422.667\n",
      "Ep:57, loss:0.00008, loss_test:0.06293, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:42.501, tt:2465.074\n",
      "Ep:58, loss:0.00008, loss_test:0.06176, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:42.532, tt:2509.397\n",
      "Ep:59, loss:0.00008, loss_test:0.06518, lr:1.00e-02, fs:0.86772 (r=0.828,p=0.911),  time:42.573, tt:2554.363\n",
      "Ep:60, loss:0.00008, loss_test:0.06340, lr:1.00e-02, fs:0.88889 (r=0.970,p=0.821),  time:42.569, tt:2596.732\n",
      "Ep:61, loss:0.00008, loss_test:0.06477, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:42.592, tt:2640.712\n",
      "Ep:62, loss:0.00008, loss_test:0.06117, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:42.554, tt:2680.923\n",
      "##########Best model found so far##########\n",
      "Ep:63, loss:0.00007, loss_test:0.06108, lr:1.00e-02, fs:0.92233 (r=0.960,p=0.888),  time:42.564, tt:2724.087\n",
      "Ep:64, loss:0.00007, loss_test:0.06262, lr:1.00e-02, fs:0.87958 (r=0.848,p=0.913),  time:42.550, tt:2765.776\n",
      "Ep:65, loss:0.00007, loss_test:0.05939, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:42.538, tt:2807.488\n",
      "Ep:66, loss:0.00007, loss_test:0.06117, lr:1.00e-02, fs:0.93000 (r=0.939,p=0.921),  time:42.527, tt:2849.299\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00007, loss_test:0.05887, lr:1.00e-02, fs:0.93204 (r=0.970,p=0.897),  time:42.581, tt:2895.499\n",
      "##########Best model found so far##########\n",
      "Ep:68, loss:0.00006, loss_test:0.05980, lr:1.00e-02, fs:0.92537 (r=0.939,p=0.912),  time:42.575, tt:2937.701\n",
      "Ep:69, loss:0.00006, loss_test:0.05915, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:42.559, tt:2979.144\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00006, loss_test:0.05875, lr:1.00e-02, fs:0.93069 (r=0.949,p=0.913),  time:42.589, tt:3023.839\n",
      "Ep:71, loss:0.00006, loss_test:0.05871, lr:1.00e-02, fs:0.91919 (r=0.919,p=0.919),  time:42.600, tt:3067.182\n",
      "Ep:72, loss:0.00006, loss_test:0.05761, lr:1.00e-02, fs:0.94581 (r=0.970,p=0.923),  time:42.598, tt:3109.661\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00006, loss_test:0.05899, lr:1.00e-02, fs:0.91371 (r=0.909,p=0.918),  time:42.605, tt:3152.734\n",
      "Ep:74, loss:0.00006, loss_test:0.06047, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:42.645, tt:3198.406\n",
      "Ep:75, loss:0.00006, loss_test:0.05843, lr:1.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:42.647, tt:3241.200\n",
      "Ep:76, loss:0.00006, loss_test:0.06043, lr:1.00e-02, fs:0.89119 (r=0.869,p=0.915),  time:42.643, tt:3283.509\n",
      "Ep:77, loss:0.00006, loss_test:0.05790, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:42.647, tt:3326.480\n",
      "Ep:78, loss:0.00006, loss_test:0.06136, lr:1.00e-02, fs:0.86316 (r=0.828,p=0.901),  time:42.658, tt:3369.998\n",
      "Ep:79, loss:0.00006, loss_test:0.06050, lr:1.00e-02, fs:0.89796 (r=0.889,p=0.907),  time:42.655, tt:3412.392\n",
      "Ep:80, loss:0.00005, loss_test:0.05744, lr:1.00e-02, fs:0.94118 (r=0.970,p=0.914),  time:42.652, tt:3454.836\n",
      "Ep:81, loss:0.00005, loss_test:0.05892, lr:1.00e-02, fs:0.88776 (r=0.879,p=0.897),  time:42.650, tt:3497.328\n",
      "Ep:82, loss:0.00005, loss_test:0.05762, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:42.679, tt:3542.324\n",
      "Ep:83, loss:0.00005, loss_test:0.06130, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:42.674, tt:3584.657\n",
      "Ep:84, loss:0.00005, loss_test:0.05633, lr:9.90e-03, fs:0.93596 (r=0.960,p=0.913),  time:42.674, tt:3627.300\n",
      "Ep:85, loss:0.00005, loss_test:0.05861, lr:9.80e-03, fs:0.90816 (r=0.899,p=0.918),  time:42.682, tt:3670.680\n",
      "Ep:86, loss:0.00005, loss_test:0.05611, lr:9.70e-03, fs:0.93532 (r=0.949,p=0.922),  time:42.683, tt:3713.439\n",
      "Ep:87, loss:0.00005, loss_test:0.05845, lr:9.61e-03, fs:0.87629 (r=0.859,p=0.895),  time:42.692, tt:3756.924\n",
      "Ep:88, loss:0.00005, loss_test:0.05737, lr:9.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.701, tt:3800.389\n",
      "Ep:89, loss:0.00004, loss_test:0.05758, lr:9.41e-03, fs:0.93532 (r=0.949,p=0.922),  time:42.707, tt:3843.592\n",
      "Ep:90, loss:0.00004, loss_test:0.05925, lr:9.32e-03, fs:0.86631 (r=0.818,p=0.920),  time:42.685, tt:3884.376\n",
      "Ep:91, loss:0.00004, loss_test:0.05580, lr:9.23e-03, fs:0.89691 (r=0.879,p=0.916),  time:42.690, tt:3927.449\n",
      "Ep:92, loss:0.00004, loss_test:0.05654, lr:9.14e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.682, tt:3969.464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:93, loss:0.00004, loss_test:0.05566, lr:9.04e-03, fs:0.87500 (r=0.848,p=0.903),  time:42.679, tt:4011.785\n",
      "Ep:94, loss:0.00004, loss_test:0.05900, lr:8.95e-03, fs:0.86631 (r=0.818,p=0.920),  time:42.665, tt:4053.181\n",
      "Ep:95, loss:0.00004, loss_test:0.05510, lr:8.86e-03, fs:0.94527 (r=0.960,p=0.931),  time:42.665, tt:4095.832\n",
      "Ep:96, loss:0.00004, loss_test:0.05923, lr:8.78e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.654, tt:4137.403\n",
      "Ep:97, loss:0.00004, loss_test:0.05666, lr:8.69e-03, fs:0.91919 (r=0.919,p=0.919),  time:42.674, tt:4182.067\n",
      "Ep:98, loss:0.00004, loss_test:0.05953, lr:8.60e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.668, tt:4224.091\n",
      "Ep:99, loss:0.00004, loss_test:0.05636, lr:8.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.657, tt:4265.683\n",
      "Ep:100, loss:0.00004, loss_test:0.05686, lr:8.43e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.667, tt:4309.349\n",
      "Ep:101, loss:0.00003, loss_test:0.05751, lr:8.35e-03, fs:0.85106 (r=0.808,p=0.899),  time:42.656, tt:4350.903\n",
      "Ep:102, loss:0.00003, loss_test:0.05831, lr:8.26e-03, fs:0.89119 (r=0.869,p=0.915),  time:42.657, tt:4393.630\n",
      "Ep:103, loss:0.00003, loss_test:0.05909, lr:8.18e-03, fs:0.83871 (r=0.788,p=0.897),  time:42.652, tt:4435.849\n",
      "Ep:104, loss:0.00003, loss_test:0.05604, lr:8.10e-03, fs:0.87831 (r=0.838,p=0.922),  time:42.667, tt:4480.036\n",
      "Ep:105, loss:0.00003, loss_test:0.05901, lr:8.02e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.669, tt:4522.863\n",
      "Ep:106, loss:0.00003, loss_test:0.05683, lr:7.94e-03, fs:0.87234 (r=0.828,p=0.921),  time:42.657, tt:4564.316\n",
      "Ep:107, loss:0.00003, loss_test:0.05672, lr:7.86e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.652, tt:4606.386\n",
      "Ep:108, loss:0.00003, loss_test:0.05680, lr:7.78e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.674, tt:4651.464\n",
      "Ep:109, loss:0.00003, loss_test:0.05675, lr:7.70e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.686, tt:4695.475\n",
      "Ep:110, loss:0.00003, loss_test:0.05753, lr:7.62e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.691, tt:4738.688\n",
      "Ep:111, loss:0.00003, loss_test:0.05787, lr:7.55e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.696, tt:4781.916\n",
      "Ep:112, loss:0.00003, loss_test:0.05785, lr:7.47e-03, fs:0.83243 (r=0.778,p=0.895),  time:42.704, tt:4825.576\n",
      "Ep:113, loss:0.00003, loss_test:0.05666, lr:7.40e-03, fs:0.89583 (r=0.869,p=0.925),  time:42.697, tt:4867.489\n",
      "Ep:114, loss:0.00003, loss_test:0.05900, lr:7.32e-03, fs:0.83243 (r=0.778,p=0.895),  time:42.684, tt:4908.701\n",
      "Ep:115, loss:0.00003, loss_test:0.05757, lr:7.25e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.684, tt:4951.381\n",
      "Ep:116, loss:0.00003, loss_test:0.05882, lr:7.18e-03, fs:0.83060 (r=0.768,p=0.905),  time:42.697, tt:4995.500\n",
      "Ep:117, loss:0.00003, loss_test:0.05718, lr:7.11e-03, fs:0.87234 (r=0.828,p=0.921),  time:42.706, tt:5039.283\n",
      "Ep:118, loss:0.00003, loss_test:0.06027, lr:7.03e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.708, tt:5082.251\n",
      "Ep:119, loss:0.00003, loss_test:0.05608, lr:6.96e-03, fs:0.86316 (r=0.828,p=0.901),  time:42.691, tt:5122.959\n",
      "Ep:120, loss:0.00003, loss_test:0.06087, lr:6.89e-03, fs:0.81564 (r=0.737,p=0.912),  time:42.693, tt:5165.838\n",
      "Ep:121, loss:0.00003, loss_test:0.05766, lr:6.83e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.680, tt:5207.006\n",
      "Ep:122, loss:0.00003, loss_test:0.05923, lr:6.76e-03, fs:0.83516 (r=0.768,p=0.916),  time:42.701, tt:5252.165\n",
      "Ep:123, loss:0.00003, loss_test:0.05876, lr:6.69e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.715, tt:5296.678\n",
      "Ep:124, loss:0.00002, loss_test:0.05836, lr:6.62e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.715, tt:5339.378\n",
      "Ep:125, loss:0.00002, loss_test:0.05781, lr:6.56e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.727, tt:5383.590\n",
      "Ep:126, loss:0.00002, loss_test:0.05771, lr:6.49e-03, fs:0.86022 (r=0.808,p=0.920),  time:42.724, tt:5425.927\n",
      "Ep:127, loss:0.00002, loss_test:0.05896, lr:6.43e-03, fs:0.82418 (r=0.758,p=0.904),  time:42.733, tt:5469.774\n",
      "Ep:128, loss:0.00002, loss_test:0.05826, lr:6.36e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.728, tt:5511.972\n",
      "Ep:129, loss:0.00002, loss_test:0.05990, lr:6.30e-03, fs:0.82796 (r=0.778,p=0.885),  time:42.721, tt:5553.779\n",
      "Ep:130, loss:0.00002, loss_test:0.05855, lr:6.24e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.728, tt:5597.367\n",
      "Ep:131, loss:0.00002, loss_test:0.06075, lr:6.17e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.732, tt:5640.614\n",
      "Ep:132, loss:0.00002, loss_test:0.05840, lr:6.11e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.733, tt:5683.500\n",
      "Ep:133, loss:0.00002, loss_test:0.05793, lr:6.05e-03, fs:0.83516 (r=0.768,p=0.916),  time:42.718, tt:5724.272\n",
      "Ep:134, loss:0.00002, loss_test:0.05959, lr:5.99e-03, fs:0.81768 (r=0.747,p=0.902),  time:42.693, tt:5763.587\n",
      "Ep:135, loss:0.00002, loss_test:0.05805, lr:5.93e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.650, tt:5800.357\n",
      "Ep:136, loss:0.00002, loss_test:0.06050, lr:5.87e-03, fs:0.82162 (r=0.768,p=0.884),  time:42.654, tt:5843.601\n",
      "Ep:137, loss:0.00002, loss_test:0.05824, lr:5.81e-03, fs:0.85405 (r=0.798,p=0.919),  time:42.641, tt:5884.474\n",
      "Ep:138, loss:0.00002, loss_test:0.06078, lr:5.75e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.676, tt:5931.986\n",
      "Ep:139, loss:0.00002, loss_test:0.05884, lr:5.70e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.678, tt:5974.887\n",
      "Ep:140, loss:0.00002, loss_test:0.05929, lr:5.64e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.664, tt:6015.610\n",
      "Ep:141, loss:0.00002, loss_test:0.05890, lr:5.58e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.660, tt:6057.680\n",
      "Ep:142, loss:0.00002, loss_test:0.05822, lr:5.53e-03, fs:0.84153 (r=0.778,p=0.917),  time:42.658, tt:6100.037\n",
      "Ep:143, loss:0.00002, loss_test:0.05990, lr:5.47e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.664, tt:6143.553\n",
      "Ep:144, loss:0.00002, loss_test:0.05995, lr:5.42e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.655, tt:6185.031\n",
      "Ep:145, loss:0.00002, loss_test:0.05878, lr:5.36e-03, fs:0.83978 (r=0.768,p=0.927),  time:42.666, tt:6229.217\n",
      "Ep:146, loss:0.00002, loss_test:0.06158, lr:5.31e-03, fs:0.81564 (r=0.737,p=0.912),  time:42.662, tt:6271.281\n",
      "Ep:147, loss:0.00002, loss_test:0.05777, lr:5.26e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.666, tt:6314.633\n",
      "Ep:148, loss:0.00002, loss_test:0.06189, lr:5.20e-03, fs:0.80447 (r=0.727,p=0.900),  time:42.670, tt:6357.897\n",
      "Ep:149, loss:0.00002, loss_test:0.05781, lr:5.15e-03, fs:0.84783 (r=0.788,p=0.918),  time:42.661, tt:6399.197\n",
      "Ep:150, loss:0.00002, loss_test:0.06278, lr:5.10e-03, fs:0.81111 (r=0.737,p=0.901),  time:42.663, tt:6442.165\n",
      "Ep:151, loss:0.00002, loss_test:0.05992, lr:5.05e-03, fs:0.82222 (r=0.747,p=0.914),  time:42.669, tt:6485.651\n",
      "Ep:152, loss:0.00002, loss_test:0.05924, lr:5.00e-03, fs:0.85870 (r=0.798,p=0.929),  time:42.667, tt:6528.010\n",
      "Ep:153, loss:0.00002, loss_test:0.06201, lr:4.95e-03, fs:0.80899 (r=0.727,p=0.911),  time:42.645, tt:6567.342\n",
      "Ep:154, loss:0.00002, loss_test:0.05942, lr:4.90e-03, fs:0.82873 (r=0.758,p=0.915),  time:42.601, tt:6603.162\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_NEW\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14562, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:42.747, tt:42.747\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.14425, lr:1.00e-02, fs:0.66667 (r=1.000,p=0.500),  time:43.814, tt:87.628\n",
      "Ep:2, loss:0.00027, loss_test:0.14134, lr:1.00e-02, fs:0.66441 (r=0.990,p=0.500),  time:43.602, tt:130.807\n",
      "Ep:3, loss:0.00026, loss_test:0.13640, lr:1.00e-02, fs:0.66212 (r=0.980,p=0.500),  time:43.529, tt:174.117\n",
      "Ep:4, loss:0.00025, loss_test:0.12922, lr:1.00e-02, fs:0.65957 (r=0.939,p=0.508),  time:43.265, tt:216.324\n",
      "Ep:5, loss:0.00024, loss_test:0.11791, lr:1.00e-02, fs:0.69421 (r=0.848,p=0.587),  time:43.264, tt:259.586\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11386, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:43.048, tt:301.335\n",
      "Ep:7, loss:0.00022, loss_test:0.11357, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:42.972, tt:343.774\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:8, loss:0.00021, loss_test:0.11304, lr:1.00e-02, fs:0.69565 (r=0.808,p=0.611),  time:42.852, tt:385.668\n",
      "Ep:9, loss:0.00021, loss_test:0.11158, lr:1.00e-02, fs:0.68444 (r=0.778,p=0.611),  time:42.889, tt:428.888\n",
      "Ep:10, loss:0.00020, loss_test:0.10894, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:42.769, tt:470.458\n",
      "Ep:11, loss:0.00019, loss_test:0.10696, lr:1.00e-02, fs:0.70093 (r=0.758,p=0.652),  time:42.757, tt:513.090\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.10687, lr:1.00e-02, fs:0.68837 (r=0.747,p=0.638),  time:42.910, tt:557.831\n",
      "Ep:13, loss:0.00018, loss_test:0.10662, lr:1.00e-02, fs:0.70370 (r=0.768,p=0.650),  time:42.816, tt:599.428\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00018, loss_test:0.10637, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:42.672, tt:640.079\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00017, loss_test:0.10483, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:42.656, tt:682.490\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00017, loss_test:0.10480, lr:1.00e-02, fs:0.70423 (r=0.758,p=0.658),  time:42.576, tt:723.796\n",
      "Ep:17, loss:0.00016, loss_test:0.10405, lr:1.00e-02, fs:0.70755 (r=0.758,p=0.664),  time:42.596, tt:766.720\n",
      "Ep:18, loss:0.00016, loss_test:0.10372, lr:1.00e-02, fs:0.70142 (r=0.747,p=0.661),  time:42.633, tt:810.028\n",
      "Ep:19, loss:0.00016, loss_test:0.10297, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:42.652, tt:853.035\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00015, loss_test:0.10137, lr:1.00e-02, fs:0.71498 (r=0.747,p=0.685),  time:42.642, tt:895.488\n",
      "Ep:21, loss:0.00015, loss_test:0.10240, lr:1.00e-02, fs:0.70352 (r=0.707,p=0.700),  time:42.617, tt:937.580\n",
      "Ep:22, loss:0.00015, loss_test:0.09937, lr:1.00e-02, fs:0.72000 (r=0.727,p=0.713),  time:42.672, tt:981.463\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00014, loss_test:0.10087, lr:1.00e-02, fs:0.72727 (r=0.727,p=0.727),  time:42.807, tt:1027.359\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.10094, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:42.906, tt:1072.658\n",
      "Ep:25, loss:0.00014, loss_test:0.10000, lr:1.00e-02, fs:0.72277 (r=0.737,p=0.709),  time:42.893, tt:1115.213\n",
      "Ep:26, loss:0.00013, loss_test:0.10109, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:42.805, tt:1155.733\n",
      "Ep:27, loss:0.00013, loss_test:0.09966, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:42.787, tt:1198.031\n",
      "Ep:28, loss:0.00013, loss_test:0.10079, lr:1.00e-02, fs:0.73267 (r=0.747,p=0.718),  time:42.788, tt:1240.847\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00013, loss_test:0.09945, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:42.831, tt:1284.940\n",
      "Ep:30, loss:0.00012, loss_test:0.10144, lr:1.00e-02, fs:0.72906 (r=0.747,p=0.712),  time:42.844, tt:1328.161\n",
      "Ep:31, loss:0.00012, loss_test:0.09757, lr:1.00e-02, fs:0.71642 (r=0.727,p=0.706),  time:42.866, tt:1371.698\n",
      "Ep:32, loss:0.00012, loss_test:0.10124, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:42.920, tt:1416.358\n",
      "Ep:33, loss:0.00012, loss_test:0.09795, lr:1.00e-02, fs:0.71000 (r=0.717,p=0.703),  time:42.923, tt:1459.377\n",
      "Ep:34, loss:0.00011, loss_test:0.10114, lr:1.00e-02, fs:0.73196 (r=0.717,p=0.747),  time:42.954, tt:1503.397\n",
      "Ep:35, loss:0.00011, loss_test:0.09920, lr:1.00e-02, fs:0.71717 (r=0.717,p=0.717),  time:42.987, tt:1547.520\n",
      "Ep:36, loss:0.00011, loss_test:0.09894, lr:1.00e-02, fs:0.72449 (r=0.717,p=0.732),  time:42.988, tt:1590.560\n",
      "Ep:37, loss:0.00011, loss_test:0.09898, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:43.021, tt:1634.813\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00011, loss_test:0.09941, lr:1.00e-02, fs:0.72362 (r=0.727,p=0.720),  time:43.039, tt:1678.519\n",
      "Ep:39, loss:0.00010, loss_test:0.09672, lr:1.00e-02, fs:0.74112 (r=0.737,p=0.745),  time:43.058, tt:1722.339\n",
      "##########Best model found so far##########\n",
      "Ep:40, loss:0.00010, loss_test:0.09980, lr:1.00e-02, fs:0.73846 (r=0.727,p=0.750),  time:43.056, tt:1765.293\n",
      "Ep:41, loss:0.00010, loss_test:0.09725, lr:1.00e-02, fs:0.73367 (r=0.737,p=0.730),  time:43.045, tt:1807.882\n",
      "Ep:42, loss:0.00010, loss_test:0.09985, lr:1.00e-02, fs:0.72821 (r=0.717,p=0.740),  time:43.048, tt:1851.061\n",
      "Ep:43, loss:0.00010, loss_test:0.09610, lr:1.00e-02, fs:0.75127 (r=0.747,p=0.755),  time:43.062, tt:1894.721\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00009, loss_test:0.09826, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:43.076, tt:1938.434\n",
      "Ep:45, loss:0.00009, loss_test:0.09705, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:43.103, tt:1982.733\n",
      "Ep:46, loss:0.00009, loss_test:0.09761, lr:1.00e-02, fs:0.73575 (r=0.717,p=0.755),  time:43.144, tt:2027.775\n",
      "Ep:47, loss:0.00009, loss_test:0.09695, lr:1.00e-02, fs:0.73958 (r=0.717,p=0.763),  time:43.115, tt:2069.498\n",
      "Ep:48, loss:0.00009, loss_test:0.09603, lr:1.00e-02, fs:0.76042 (r=0.737,p=0.785),  time:43.074, tt:2110.645\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00008, loss_test:0.10051, lr:1.00e-02, fs:0.72917 (r=0.707,p=0.753),  time:43.076, tt:2153.786\n",
      "Ep:50, loss:0.00008, loss_test:0.09773, lr:1.00e-02, fs:0.75000 (r=0.727,p=0.774),  time:43.087, tt:2197.438\n",
      "Ep:51, loss:0.00008, loss_test:0.09908, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:43.045, tt:2238.330\n",
      "Ep:52, loss:0.00008, loss_test:0.09696, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:43.020, tt:2280.042\n",
      "Ep:53, loss:0.00008, loss_test:0.09971, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:43.009, tt:2322.486\n",
      "Ep:54, loss:0.00008, loss_test:0.09818, lr:1.00e-02, fs:0.75132 (r=0.717,p=0.789),  time:42.996, tt:2364.787\n",
      "Ep:55, loss:0.00007, loss_test:0.10295, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:42.977, tt:2406.718\n",
      "Ep:56, loss:0.00007, loss_test:0.09642, lr:1.00e-02, fs:0.75393 (r=0.727,p=0.783),  time:42.973, tt:2449.475\n",
      "Ep:57, loss:0.00007, loss_test:0.09928, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:42.985, tt:2493.103\n",
      "##########Best model found so far##########\n",
      "Ep:58, loss:0.00007, loss_test:0.10093, lr:1.00e-02, fs:0.73404 (r=0.697,p=0.775),  time:42.999, tt:2536.922\n",
      "Ep:59, loss:0.00007, loss_test:0.09763, lr:1.00e-02, fs:0.75269 (r=0.707,p=0.805),  time:42.986, tt:2579.177\n",
      "Ep:60, loss:0.00007, loss_test:0.09939, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:42.984, tt:2622.016\n",
      "Ep:61, loss:0.00007, loss_test:0.09888, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:42.983, tt:2664.969\n",
      "Ep:62, loss:0.00007, loss_test:0.09751, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:42.975, tt:2707.417\n",
      "Ep:63, loss:0.00007, loss_test:0.09812, lr:1.00e-02, fs:0.74468 (r=0.707,p=0.787),  time:42.969, tt:2750.013\n",
      "Ep:64, loss:0.00007, loss_test:0.10337, lr:1.00e-02, fs:0.74866 (r=0.707,p=0.795),  time:42.995, tt:2794.690\n",
      "Ep:65, loss:0.00006, loss_test:0.09513, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.989, tt:2837.267\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00006, loss_test:0.10158, lr:1.00e-02, fs:0.76087 (r=0.707,p=0.824),  time:42.929, tt:2876.276\n",
      "Ep:67, loss:0.00006, loss_test:0.09879, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.837, tt:2912.904\n",
      "Ep:68, loss:0.00006, loss_test:0.10242, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.724, tt:2947.972\n",
      "Ep:69, loss:0.00006, loss_test:0.10118, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.676, tt:2987.332\n",
      "Ep:70, loss:0.00006, loss_test:0.10139, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:42.694, tt:3031.304\n",
      "Ep:71, loss:0.00005, loss_test:0.09874, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:42.710, tt:3075.137\n",
      "##########Best model found so far##########\n",
      "Ep:72, loss:0.00005, loss_test:0.09698, lr:1.00e-02, fs:0.77348 (r=0.707,p=0.854),  time:42.708, tt:3117.683\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00005, loss_test:0.10732, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:42.707, tt:3160.282\n",
      "Ep:74, loss:0.00005, loss_test:0.09252, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:42.710, tt:3203.281\n",
      "Ep:75, loss:0.00006, loss_test:0.10075, lr:1.00e-02, fs:0.76923 (r=0.707,p=0.843),  time:42.720, tt:3246.724\n",
      "Ep:76, loss:0.00005, loss_test:0.10469, lr:1.00e-02, fs:0.74317 (r=0.687,p=0.810),  time:42.724, tt:3289.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:77, loss:0.00005, loss_test:0.09385, lr:1.00e-02, fs:0.76667 (r=0.697,p=0.852),  time:42.717, tt:3331.919\n",
      "Ep:78, loss:0.00006, loss_test:0.11432, lr:1.00e-02, fs:0.74595 (r=0.697,p=0.802),  time:42.745, tt:3376.839\n",
      "Ep:79, loss:0.00006, loss_test:0.10423, lr:1.00e-02, fs:0.72432 (r=0.677,p=0.779),  time:42.755, tt:3420.367\n",
      "Ep:80, loss:0.00005, loss_test:0.10404, lr:1.00e-02, fs:0.75410 (r=0.697,p=0.821),  time:42.781, tt:3465.236\n",
      "Ep:81, loss:0.00005, loss_test:0.10455, lr:1.00e-02, fs:0.75676 (r=0.707,p=0.814),  time:42.769, tt:3507.063\n",
      "Ep:82, loss:0.00005, loss_test:0.11079, lr:1.00e-02, fs:0.75824 (r=0.697,p=0.831),  time:42.770, tt:3549.885\n",
      "Ep:83, loss:0.00005, loss_test:0.10003, lr:1.00e-02, fs:0.76503 (r=0.707,p=0.833),  time:42.778, tt:3593.383\n",
      "Ep:84, loss:0.00005, loss_test:0.11233, lr:9.90e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.777, tt:3636.045\n",
      "Ep:85, loss:0.00004, loss_test:0.09554, lr:9.80e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.793, tt:3680.232\n",
      "Ep:86, loss:0.00004, loss_test:0.11118, lr:9.70e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.790, tt:3722.708\n",
      "Ep:87, loss:0.00004, loss_test:0.09437, lr:9.61e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.800, tt:3766.431\n",
      "##########Best model found so far##########\n",
      "Ep:88, loss:0.00004, loss_test:0.10807, lr:9.61e-03, fs:0.75138 (r=0.687,p=0.829),  time:42.797, tt:3808.964\n",
      "Ep:89, loss:0.00004, loss_test:0.10620, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.810, tt:3852.909\n",
      "Ep:90, loss:0.00004, loss_test:0.10493, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.797, tt:3894.494\n",
      "Ep:91, loss:0.00004, loss_test:0.10630, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.794, tt:3937.021\n",
      "Ep:92, loss:0.00004, loss_test:0.10124, lr:9.61e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.778, tt:3978.372\n",
      "Ep:93, loss:0.00004, loss_test:0.11235, lr:9.61e-03, fs:0.73034 (r=0.657,p=0.823),  time:42.784, tt:4021.682\n",
      "Ep:94, loss:0.00004, loss_test:0.09659, lr:9.61e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.788, tt:4064.880\n",
      "##########Best model found so far##########\n",
      "Ep:95, loss:0.00004, loss_test:0.11483, lr:9.61e-03, fs:0.75824 (r=0.697,p=0.831),  time:42.777, tt:4106.621\n",
      "Ep:96, loss:0.00004, loss_test:0.10228, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.788, tt:4150.417\n",
      "Ep:97, loss:0.00004, loss_test:0.11342, lr:9.61e-03, fs:0.75824 (r=0.697,p=0.831),  time:42.782, tt:4192.616\n",
      "Ep:98, loss:0.00004, loss_test:0.10266, lr:9.61e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.782, tt:4235.424\n",
      "Ep:99, loss:0.00003, loss_test:0.11266, lr:9.61e-03, fs:0.75556 (r=0.687,p=0.840),  time:42.783, tt:4278.336\n",
      "Ep:100, loss:0.00003, loss_test:0.10285, lr:9.61e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.797, tt:4322.504\n",
      "Ep:101, loss:0.00003, loss_test:0.11270, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.795, tt:4365.043\n",
      "Ep:102, loss:0.00003, loss_test:0.10450, lr:9.61e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.790, tt:4407.389\n",
      "Ep:103, loss:0.00003, loss_test:0.11626, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.801, tt:4451.301\n",
      "Ep:104, loss:0.00003, loss_test:0.10574, lr:9.61e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.796, tt:4493.529\n",
      "Ep:105, loss:0.00003, loss_test:0.10927, lr:9.61e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.801, tt:4536.921\n",
      "Ep:106, loss:0.00003, loss_test:0.10398, lr:9.51e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.807, tt:4580.315\n",
      "Ep:107, loss:0.00003, loss_test:0.11373, lr:9.41e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.796, tt:4621.997\n",
      "Ep:108, loss:0.00003, loss_test:0.09989, lr:9.32e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.797, tt:4664.827\n",
      "Ep:109, loss:0.00003, loss_test:0.11598, lr:9.23e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.839, tt:4712.314\n",
      "Ep:110, loss:0.00003, loss_test:0.10579, lr:9.14e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.828, tt:4753.946\n",
      "Ep:111, loss:0.00003, loss_test:0.11544, lr:9.04e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.844, tt:4798.581\n",
      "Ep:112, loss:0.00003, loss_test:0.10862, lr:8.95e-03, fs:0.76243 (r=0.697,p=0.841),  time:42.846, tt:4841.545\n",
      "Ep:113, loss:0.00003, loss_test:0.10961, lr:8.86e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.836, tt:4883.309\n",
      "Ep:114, loss:0.00003, loss_test:0.10929, lr:8.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.822, tt:4924.553\n",
      "Ep:115, loss:0.00003, loss_test:0.11290, lr:8.69e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.823, tt:4967.463\n",
      "Ep:116, loss:0.00003, loss_test:0.10434, lr:8.60e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.827, tt:5010.772\n",
      "Ep:117, loss:0.00003, loss_test:0.11854, lr:8.51e-03, fs:0.75429 (r=0.667,p=0.868),  time:42.811, tt:5051.743\n",
      "Ep:118, loss:0.00003, loss_test:0.10333, lr:8.43e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.812, tt:5094.622\n",
      "##########Best model found so far##########\n",
      "Ep:119, loss:0.00003, loss_test:0.11757, lr:8.43e-03, fs:0.69822 (r=0.596,p=0.843),  time:42.813, tt:5137.538\n",
      "Ep:120, loss:0.00002, loss_test:0.10903, lr:8.43e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.816, tt:5180.776\n",
      "Ep:121, loss:0.00002, loss_test:0.11664, lr:8.43e-03, fs:0.73563 (r=0.646,p=0.853),  time:42.832, tt:5225.499\n",
      "Ep:122, loss:0.00002, loss_test:0.10797, lr:8.43e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.822, tt:5267.095\n",
      "Ep:123, loss:0.00002, loss_test:0.11420, lr:8.43e-03, fs:0.77095 (r=0.697,p=0.863),  time:42.812, tt:5308.626\n",
      "Ep:124, loss:0.00002, loss_test:0.10949, lr:8.43e-03, fs:0.79769 (r=0.697,p=0.932),  time:42.793, tt:5349.090\n",
      "##########Best model found so far##########\n",
      "Ep:125, loss:0.00002, loss_test:0.11689, lr:8.43e-03, fs:0.75978 (r=0.687,p=0.850),  time:42.811, tt:5394.236\n",
      "Ep:126, loss:0.00002, loss_test:0.10991, lr:8.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.796, tt:5435.038\n",
      "Ep:127, loss:0.00002, loss_test:0.11514, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.788, tt:5476.916\n",
      "Ep:128, loss:0.00002, loss_test:0.10996, lr:8.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.799, tt:5521.069\n",
      "Ep:129, loss:0.00002, loss_test:0.11452, lr:8.43e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.816, tt:5566.109\n",
      "Ep:130, loss:0.00002, loss_test:0.11073, lr:8.43e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.822, tt:5609.727\n",
      "Ep:131, loss:0.00002, loss_test:0.11504, lr:8.43e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.804, tt:5650.123\n",
      "Ep:132, loss:0.00002, loss_test:0.11142, lr:8.43e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.782, tt:5689.954\n",
      "Ep:133, loss:0.00002, loss_test:0.11739, lr:8.43e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.791, tt:5734.028\n",
      "Ep:134, loss:0.00002, loss_test:0.11138, lr:8.43e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.795, tt:5777.340\n",
      "Ep:135, loss:0.00002, loss_test:0.12019, lr:8.43e-03, fs:0.76404 (r=0.687,p=0.861),  time:42.813, tt:5822.632\n",
      "Ep:136, loss:0.00002, loss_test:0.11012, lr:8.35e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.821, tt:5866.467\n",
      "Ep:137, loss:0.00002, loss_test:0.11537, lr:8.26e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.838, tt:5911.651\n",
      "Ep:138, loss:0.00002, loss_test:0.11382, lr:8.18e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.840, tt:5954.731\n",
      "Ep:139, loss:0.00002, loss_test:0.11446, lr:8.10e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.847, tt:5998.517\n",
      "Ep:140, loss:0.00002, loss_test:0.11646, lr:8.02e-03, fs:0.79310 (r=0.697,p=0.920),  time:42.849, tt:6041.678\n",
      "Ep:141, loss:0.00002, loss_test:0.11499, lr:7.94e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.860, tt:6086.150\n",
      "Ep:142, loss:0.00002, loss_test:0.11544, lr:7.86e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.857, tt:6128.611\n",
      "Ep:143, loss:0.00002, loss_test:0.11611, lr:7.78e-03, fs:0.77966 (r=0.697,p=0.885),  time:42.855, tt:6171.135\n",
      "Ep:144, loss:0.00002, loss_test:0.11323, lr:7.70e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.859, tt:6214.522\n",
      "Ep:145, loss:0.00002, loss_test:0.11946, lr:7.62e-03, fs:0.77528 (r=0.697,p=0.873),  time:42.873, tt:6259.434\n",
      "Ep:146, loss:0.00002, loss_test:0.11514, lr:7.55e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.882, tt:6303.602\n",
      "Ep:147, loss:0.00002, loss_test:0.11718, lr:7.47e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.893, tt:6348.142\n",
      "Ep:148, loss:0.00002, loss_test:0.11573, lr:7.40e-03, fs:0.77714 (r=0.687,p=0.895),  time:42.902, tt:6392.410\n",
      "Ep:149, loss:0.00002, loss_test:0.12065, lr:7.32e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.900, tt:6434.990\n",
      "Ep:150, loss:0.00002, loss_test:0.11538, lr:7.25e-03, fs:0.78409 (r=0.697,p=0.896),  time:42.902, tt:6478.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:151, loss:0.00002, loss_test:0.11947, lr:7.18e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.922, tt:6524.137\n",
      "Ep:152, loss:0.00002, loss_test:0.11552, lr:7.11e-03, fs:0.78857 (r=0.697,p=0.908),  time:42.918, tt:6566.429\n",
      "Ep:153, loss:0.00002, loss_test:0.11936, lr:7.03e-03, fs:0.76667 (r=0.697,p=0.852),  time:42.888, tt:6604.757\n",
      "Ep:154, loss:0.00002, loss_test:0.11684, lr:6.96e-03, fs:0.79310 (r=0.697,p=0.920),  time:42.879, tt:6646.313\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.13682, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:15.991, tt:15.991\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13402, lr:1.00e-02, fs:0.67123 (r=0.990,p=0.508),  time:17.142, tt:34.284\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.12913, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:16.722, tt:50.167\n",
      "Ep:3, loss:0.00027, loss_test:0.12283, lr:1.00e-02, fs:0.67424 (r=0.899,p=0.539),  time:17.069, tt:68.277\n",
      "##########Best model found so far##########\n",
      "Ep:4, loss:0.00026, loss_test:0.11793, lr:1.00e-02, fs:0.67729 (r=0.859,p=0.559),  time:17.402, tt:87.009\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11457, lr:1.00e-02, fs:0.68354 (r=0.818,p=0.587),  time:17.094, tt:102.562\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00024, loss_test:0.11125, lr:1.00e-02, fs:0.69298 (r=0.798,p=0.612),  time:17.227, tt:120.592\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.10904, lr:1.00e-02, fs:0.70386 (r=0.828,p=0.612),  time:17.134, tt:137.074\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.10691, lr:1.00e-02, fs:0.70940 (r=0.838,p=0.615),  time:17.178, tt:154.598\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00023, loss_test:0.10415, lr:1.00e-02, fs:0.71053 (r=0.818,p=0.628),  time:17.266, tt:172.656\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00022, loss_test:0.10160, lr:1.00e-02, fs:0.70222 (r=0.798,p=0.627),  time:17.180, tt:188.978\n",
      "Ep:11, loss:0.00021, loss_test:0.09850, lr:1.00e-02, fs:0.71429 (r=0.808,p=0.640),  time:17.332, tt:207.978\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00021, loss_test:0.09476, lr:1.00e-02, fs:0.72000 (r=0.818,p=0.643),  time:17.295, tt:224.835\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00020, loss_test:0.09257, lr:1.00e-02, fs:0.73214 (r=0.828,p=0.656),  time:17.502, tt:245.022\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00019, loss_test:0.08996, lr:1.00e-02, fs:0.75926 (r=0.828,p=0.701),  time:17.541, tt:263.113\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.08855, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:17.531, tt:280.494\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.08676, lr:1.00e-02, fs:0.76995 (r=0.828,p=0.719),  time:17.458, tt:296.786\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.08510, lr:1.00e-02, fs:0.79048 (r=0.838,p=0.748),  time:17.503, tt:315.047\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.08357, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:17.602, tt:334.437\n",
      "Ep:19, loss:0.00017, loss_test:0.08202, lr:1.00e-02, fs:0.78261 (r=0.818,p=0.750),  time:17.684, tt:353.680\n",
      "Ep:20, loss:0.00016, loss_test:0.08051, lr:1.00e-02, fs:0.78469 (r=0.828,p=0.745),  time:17.623, tt:370.081\n",
      "Ep:21, loss:0.00016, loss_test:0.07896, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:17.561, tt:386.341\n",
      "Ep:22, loss:0.00015, loss_test:0.07898, lr:1.00e-02, fs:0.79621 (r=0.848,p=0.750),  time:17.580, tt:404.337\n",
      "##########Best model found so far##########\n",
      "Ep:23, loss:0.00015, loss_test:0.07659, lr:1.00e-02, fs:0.80583 (r=0.838,p=0.776),  time:17.654, tt:423.686\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.07476, lr:1.00e-02, fs:0.81159 (r=0.848,p=0.778),  time:17.682, tt:442.043\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00014, loss_test:0.07391, lr:1.00e-02, fs:0.82524 (r=0.859,p=0.794),  time:17.733, tt:461.052\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.07224, lr:1.00e-02, fs:0.82759 (r=0.848,p=0.808),  time:17.877, tt:482.687\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00013, loss_test:0.07250, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:17.920, tt:501.757\n",
      "Ep:28, loss:0.00013, loss_test:0.06860, lr:1.00e-02, fs:0.85149 (r=0.869,p=0.835),  time:18.028, tt:522.825\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00012, loss_test:0.07156, lr:1.00e-02, fs:0.82569 (r=0.909,p=0.756),  time:18.016, tt:540.471\n",
      "Ep:30, loss:0.00012, loss_test:0.06591, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:18.034, tt:559.066\n",
      "##########Best model found so far##########\n",
      "Ep:31, loss:0.00012, loss_test:0.06947, lr:1.00e-02, fs:0.82353 (r=0.919,p=0.746),  time:18.137, tt:580.397\n",
      "Ep:32, loss:0.00011, loss_test:0.06456, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:18.098, tt:597.232\n",
      "##########Best model found so far##########\n",
      "Ep:33, loss:0.00011, loss_test:0.06860, lr:1.00e-02, fs:0.83036 (r=0.939,p=0.744),  time:18.108, tt:615.657\n",
      "Ep:34, loss:0.00011, loss_test:0.06250, lr:1.00e-02, fs:0.86139 (r=0.879,p=0.845),  time:18.125, tt:634.372\n",
      "Ep:35, loss:0.00011, loss_test:0.06566, lr:1.00e-02, fs:0.85321 (r=0.939,p=0.782),  time:18.048, tt:649.720\n",
      "Ep:36, loss:0.00010, loss_test:0.06108, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:18.042, tt:667.568\n",
      "Ep:37, loss:0.00010, loss_test:0.06302, lr:1.00e-02, fs:0.84932 (r=0.939,p=0.775),  time:18.009, tt:684.352\n",
      "Ep:38, loss:0.00010, loss_test:0.05938, lr:1.00e-02, fs:0.84848 (r=0.848,p=0.848),  time:18.015, tt:702.595\n",
      "Ep:39, loss:0.00009, loss_test:0.06036, lr:1.00e-02, fs:0.86667 (r=0.919,p=0.820),  time:18.004, tt:720.155\n",
      "Ep:40, loss:0.00009, loss_test:0.05739, lr:1.00e-02, fs:0.86567 (r=0.879,p=0.853),  time:18.009, tt:738.390\n",
      "Ep:41, loss:0.00009, loss_test:0.05883, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:18.023, tt:756.965\n",
      "Ep:42, loss:0.00009, loss_test:0.05643, lr:1.00e-02, fs:0.88780 (r=0.919,p=0.858),  time:18.010, tt:774.413\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00008, loss_test:0.05835, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:18.067, tt:794.964\n",
      "Ep:44, loss:0.00008, loss_test:0.05476, lr:1.00e-02, fs:0.88119 (r=0.899,p=0.864),  time:18.079, tt:813.552\n",
      "Ep:45, loss:0.00008, loss_test:0.05646, lr:1.00e-02, fs:0.86432 (r=0.869,p=0.860),  time:18.034, tt:829.557\n",
      "Ep:46, loss:0.00007, loss_test:0.05332, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:18.049, tt:848.313\n",
      "Ep:47, loss:0.00007, loss_test:0.05311, lr:1.00e-02, fs:0.85859 (r=0.859,p=0.859),  time:18.027, tt:865.276\n",
      "Ep:48, loss:0.00007, loss_test:0.05230, lr:1.00e-02, fs:0.86010 (r=0.838,p=0.883),  time:18.050, tt:884.427\n",
      "Ep:49, loss:0.00007, loss_test:0.05176, lr:1.00e-02, fs:0.85427 (r=0.859,p=0.850),  time:18.052, tt:902.618\n",
      "Ep:50, loss:0.00006, loss_test:0.05205, lr:1.00e-02, fs:0.85864 (r=0.828,p=0.891),  time:18.013, tt:918.642\n",
      "Ep:51, loss:0.00006, loss_test:0.05104, lr:1.00e-02, fs:0.85279 (r=0.848,p=0.857),  time:18.067, tt:939.501\n",
      "Ep:52, loss:0.00006, loss_test:0.05221, lr:1.00e-02, fs:0.85567 (r=0.838,p=0.874),  time:18.077, tt:958.093\n",
      "Ep:53, loss:0.00006, loss_test:0.04995, lr:1.00e-02, fs:0.86458 (r=0.838,p=0.892),  time:18.098, tt:977.268\n",
      "Ep:54, loss:0.00006, loss_test:0.05022, lr:9.90e-03, fs:0.85714 (r=0.848,p=0.866),  time:18.103, tt:995.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:55, loss:0.00006, loss_test:0.05125, lr:9.80e-03, fs:0.86598 (r=0.848,p=0.884),  time:18.101, tt:1013.643\n",
      "Ep:56, loss:0.00005, loss_test:0.04884, lr:9.70e-03, fs:0.87500 (r=0.848,p=0.903),  time:18.090, tt:1031.151\n",
      "Ep:57, loss:0.00005, loss_test:0.04957, lr:9.61e-03, fs:0.87500 (r=0.848,p=0.903),  time:18.061, tt:1047.522\n",
      "Ep:58, loss:0.00005, loss_test:0.04898, lr:9.51e-03, fs:0.86911 (r=0.838,p=0.902),  time:18.073, tt:1066.325\n",
      "Ep:59, loss:0.00005, loss_test:0.04876, lr:9.41e-03, fs:0.87368 (r=0.838,p=0.912),  time:18.062, tt:1083.744\n",
      "Ep:60, loss:0.00005, loss_test:0.04871, lr:9.32e-03, fs:0.87831 (r=0.838,p=0.922),  time:18.038, tt:1100.324\n",
      "Ep:61, loss:0.00004, loss_test:0.04830, lr:9.23e-03, fs:0.87368 (r=0.838,p=0.912),  time:18.031, tt:1117.940\n",
      "Ep:62, loss:0.00004, loss_test:0.05003, lr:9.14e-03, fs:0.86598 (r=0.848,p=0.884),  time:18.007, tt:1134.462\n",
      "Ep:63, loss:0.00004, loss_test:0.05014, lr:9.04e-03, fs:0.87831 (r=0.838,p=0.922),  time:18.003, tt:1152.167\n",
      "Ep:64, loss:0.00004, loss_test:0.04780, lr:8.95e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.980, tt:1168.706\n",
      "Ep:65, loss:0.00004, loss_test:0.04977, lr:8.86e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.944, tt:1184.272\n",
      "Ep:66, loss:0.00004, loss_test:0.04816, lr:8.78e-03, fs:0.86458 (r=0.838,p=0.892),  time:17.956, tt:1203.023\n",
      "Ep:67, loss:0.00004, loss_test:0.04803, lr:8.69e-03, fs:0.88770 (r=0.838,p=0.943),  time:17.938, tt:1219.767\n",
      "Ep:68, loss:0.00004, loss_test:0.04960, lr:8.60e-03, fs:0.86911 (r=0.838,p=0.902),  time:17.911, tt:1235.846\n",
      "Ep:69, loss:0.00004, loss_test:0.04770, lr:8.51e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.892, tt:1252.472\n",
      "Ep:70, loss:0.00004, loss_test:0.04736, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.868, tt:1268.658\n",
      "##########Best model found so far##########\n",
      "Ep:71, loss:0.00003, loss_test:0.04875, lr:8.43e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.902, tt:1288.940\n",
      "Ep:72, loss:0.00003, loss_test:0.04803, lr:8.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:17.906, tt:1307.168\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.04839, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.901, tt:1324.649\n",
      "Ep:74, loss:0.00003, loss_test:0.04805, lr:8.43e-03, fs:0.88298 (r=0.838,p=0.933),  time:17.925, tt:1344.402\n",
      "Ep:75, loss:0.00003, loss_test:0.04709, lr:8.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:17.889, tt:1359.538\n",
      "Ep:76, loss:0.00003, loss_test:0.04901, lr:8.43e-03, fs:0.89730 (r=0.838,p=0.965),  time:17.895, tt:1377.946\n",
      "Ep:77, loss:0.00003, loss_test:0.04950, lr:8.43e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.910, tt:1396.962\n",
      "Ep:78, loss:0.00003, loss_test:0.04871, lr:8.43e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.887, tt:1413.097\n",
      "##########Best model found so far##########\n",
      "Ep:79, loss:0.00003, loss_test:0.04999, lr:8.43e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.886, tt:1430.901\n",
      "Ep:80, loss:0.00003, loss_test:0.05056, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.877, tt:1448.014\n",
      "Ep:81, loss:0.00003, loss_test:0.04802, lr:8.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.858, tt:1464.351\n",
      "Ep:82, loss:0.00003, loss_test:0.05051, lr:8.43e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.848, tt:1481.357\n",
      "Ep:83, loss:0.00003, loss_test:0.04769, lr:8.43e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.829, tt:1497.647\n",
      "Ep:84, loss:0.00003, loss_test:0.04830, lr:8.43e-03, fs:0.87831 (r=0.838,p=0.922),  time:17.856, tt:1517.748\n",
      "Ep:85, loss:0.00003, loss_test:0.05287, lr:8.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.846, tt:1534.720\n",
      "Ep:86, loss:0.00003, loss_test:0.04835, lr:8.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.843, tt:1552.384\n",
      "Ep:87, loss:0.00003, loss_test:0.05032, lr:8.43e-03, fs:0.87368 (r=0.838,p=0.912),  time:17.837, tt:1569.680\n",
      "Ep:88, loss:0.00003, loss_test:0.04895, lr:8.43e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.817, tt:1585.676\n",
      "Ep:89, loss:0.00003, loss_test:0.05006, lr:8.43e-03, fs:0.89247 (r=0.838,p=0.954),  time:17.819, tt:1603.731\n",
      "Ep:90, loss:0.00002, loss_test:0.04941, lr:8.35e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.817, tt:1621.363\n",
      "Ep:91, loss:0.00002, loss_test:0.05097, lr:8.26e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.795, tt:1637.163\n",
      "Ep:92, loss:0.00002, loss_test:0.04659, lr:8.18e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.788, tt:1654.255\n",
      "Ep:93, loss:0.00002, loss_test:0.05094, lr:8.10e-03, fs:0.89730 (r=0.838,p=0.965),  time:17.786, tt:1671.849\n",
      "Ep:94, loss:0.00002, loss_test:0.04907, lr:8.02e-03, fs:0.89730 (r=0.838,p=0.965),  time:17.790, tt:1690.012\n",
      "Ep:95, loss:0.00002, loss_test:0.04899, lr:7.94e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.784, tt:1707.304\n",
      "Ep:96, loss:0.00002, loss_test:0.04894, lr:7.86e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.767, tt:1723.363\n",
      "Ep:97, loss:0.00002, loss_test:0.04925, lr:7.78e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.767, tt:1741.149\n",
      "Ep:98, loss:0.00002, loss_test:0.04925, lr:7.70e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.769, tt:1759.087\n",
      "Ep:99, loss:0.00002, loss_test:0.04905, lr:7.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.793, tt:1779.293\n",
      "Ep:100, loss:0.00002, loss_test:0.04912, lr:7.55e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.825, tt:1800.290\n",
      "Ep:101, loss:0.00002, loss_test:0.04939, lr:7.47e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.809, tt:1816.569\n",
      "Ep:102, loss:0.00002, loss_test:0.04911, lr:7.40e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.826, tt:1836.104\n",
      "Ep:103, loss:0.00002, loss_test:0.05051, lr:7.32e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.832, tt:1854.491\n",
      "Ep:104, loss:0.00002, loss_test:0.05149, lr:7.25e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.845, tt:1873.678\n",
      "Ep:105, loss:0.00002, loss_test:0.04989, lr:7.18e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.871, tt:1894.318\n",
      "Ep:106, loss:0.00002, loss_test:0.05081, lr:7.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.900, tt:1915.314\n",
      "Ep:107, loss:0.00002, loss_test:0.05042, lr:7.03e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.971, tt:1940.822\n",
      "Ep:108, loss:0.00002, loss_test:0.05149, lr:6.96e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.953, tt:1956.874\n",
      "Ep:109, loss:0.00001, loss_test:0.05037, lr:6.89e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.956, tt:1975.141\n",
      "Ep:110, loss:0.00001, loss_test:0.05169, lr:6.83e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.939, tt:1991.185\n",
      "Ep:111, loss:0.00001, loss_test:0.05041, lr:6.76e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.941, tt:2009.356\n",
      "Ep:112, loss:0.00001, loss_test:0.05145, lr:6.69e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.941, tt:2027.361\n",
      "Ep:113, loss:0.00001, loss_test:0.05026, lr:6.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.937, tt:2044.783\n",
      "Ep:114, loss:0.00001, loss_test:0.05113, lr:6.56e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.940, tt:2063.094\n",
      "Ep:115, loss:0.00001, loss_test:0.05146, lr:6.49e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.934, tt:2080.345\n",
      "Ep:116, loss:0.00001, loss_test:0.05186, lr:6.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.925, tt:2097.180\n",
      "Ep:117, loss:0.00001, loss_test:0.05102, lr:6.36e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.923, tt:2114.863\n",
      "Ep:118, loss:0.00001, loss_test:0.05064, lr:6.30e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.906, tt:2130.854\n",
      "Ep:119, loss:0.00001, loss_test:0.05419, lr:6.24e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.900, tt:2148.026\n",
      "Ep:120, loss:0.00001, loss_test:0.05075, lr:6.17e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.905, tt:2166.543\n",
      "Ep:121, loss:0.00001, loss_test:0.05196, lr:6.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.897, tt:2183.470\n",
      "Ep:122, loss:0.00001, loss_test:0.05175, lr:6.05e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.888, tt:2200.256\n",
      "Ep:123, loss:0.00001, loss_test:0.05174, lr:5.99e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.868, tt:2215.636\n",
      "Ep:124, loss:0.00001, loss_test:0.05180, lr:5.93e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.870, tt:2233.770\n",
      "Ep:125, loss:0.00001, loss_test:0.05133, lr:5.87e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.874, tt:2252.073\n",
      "Ep:126, loss:0.00001, loss_test:0.05208, lr:5.81e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.863, tt:2268.625\n",
      "Ep:127, loss:0.00001, loss_test:0.05206, lr:5.75e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.854, tt:2285.312\n",
      "Ep:128, loss:0.00001, loss_test:0.05164, lr:5.70e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.848, tt:2302.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:129, loss:0.00001, loss_test:0.05221, lr:5.64e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.850, tt:2320.451\n",
      "Ep:130, loss:0.00001, loss_test:0.05199, lr:5.58e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.840, tt:2336.994\n",
      "Ep:131, loss:0.00001, loss_test:0.05410, lr:5.53e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.817, tt:2351.891\n",
      "Ep:132, loss:0.00001, loss_test:0.05071, lr:5.47e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.818, tt:2369.851\n",
      "Ep:133, loss:0.00001, loss_test:0.05302, lr:5.42e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.815, tt:2387.271\n",
      "Ep:134, loss:0.00001, loss_test:0.05168, lr:5.36e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.818, tt:2405.400\n",
      "Ep:135, loss:0.00001, loss_test:0.05125, lr:5.31e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.813, tt:2422.598\n",
      "Ep:136, loss:0.00001, loss_test:0.05199, lr:5.26e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.795, tt:2437.914\n",
      "Ep:137, loss:0.00001, loss_test:0.05239, lr:5.20e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.793, tt:2455.398\n",
      "Ep:138, loss:0.00001, loss_test:0.05299, lr:5.15e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.793, tt:2473.246\n",
      "Ep:139, loss:0.00001, loss_test:0.05088, lr:5.10e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.782, tt:2489.489\n",
      "Ep:140, loss:0.00001, loss_test:0.05386, lr:5.05e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.789, tt:2508.189\n",
      "Ep:141, loss:0.00001, loss_test:0.05227, lr:5.00e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.771, tt:2523.500\n",
      "Ep:142, loss:0.00001, loss_test:0.05177, lr:4.95e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.778, tt:2542.317\n",
      "Ep:143, loss:0.00001, loss_test:0.05278, lr:4.90e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.773, tt:2559.249\n",
      "Ep:144, loss:0.00001, loss_test:0.05295, lr:4.85e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.776, tt:2577.586\n",
      "Ep:145, loss:0.00001, loss_test:0.05195, lr:4.80e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.772, tt:2594.678\n",
      "Ep:146, loss:0.00001, loss_test:0.05344, lr:4.75e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.762, tt:2611.070\n",
      "Ep:147, loss:0.00001, loss_test:0.05281, lr:4.71e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.770, tt:2629.921\n",
      "Ep:148, loss:0.00001, loss_test:0.05294, lr:4.66e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.774, tt:2648.303\n",
      "Ep:149, loss:0.00001, loss_test:0.05276, lr:4.61e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.765, tt:2664.725\n",
      "Ep:150, loss:0.00001, loss_test:0.05392, lr:4.57e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.768, tt:2683.029\n",
      "Ep:151, loss:0.00001, loss_test:0.05203, lr:4.52e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.751, tt:2698.221\n",
      "Ep:152, loss:0.00001, loss_test:0.05317, lr:4.48e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.743, tt:2714.740\n",
      "Ep:153, loss:0.00001, loss_test:0.05310, lr:4.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.746, tt:2732.886\n",
      "Ep:154, loss:0.00001, loss_test:0.05244, lr:4.39e-03, fs:0.90217 (r=0.838,p=0.976),  time:17.726, tt:2747.513\n",
      "Ep:155, loss:0.00001, loss_test:0.05283, lr:4.34e-03, fs:0.90710 (r=0.838,p=0.988),  time:17.744, tt:2768.097\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_CLEAN\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00028, loss_test:0.14212, lr:1.00e-02, fs:0.66892 (r=1.000,p=0.503),  time:18.491, tt:18.491\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00028, loss_test:0.13999, lr:1.00e-02, fs:0.66894 (r=0.990,p=0.505),  time:18.528, tt:37.056\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00027, loss_test:0.13606, lr:1.00e-02, fs:0.65972 (r=0.960,p=0.503),  time:17.977, tt:53.930\n",
      "Ep:3, loss:0.00027, loss_test:0.13070, lr:1.00e-02, fs:0.65950 (r=0.929,p=0.511),  time:18.294, tt:73.177\n",
      "Ep:4, loss:0.00026, loss_test:0.12402, lr:1.00e-02, fs:0.68182 (r=0.909,p=0.545),  time:18.167, tt:90.837\n",
      "##########Best model found so far##########\n",
      "Ep:5, loss:0.00025, loss_test:0.11810, lr:1.00e-02, fs:0.69323 (r=0.879,p=0.572),  time:18.192, tt:109.152\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00025, loss_test:0.11421, lr:1.00e-02, fs:0.69748 (r=0.838,p=0.597),  time:18.044, tt:126.310\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00024, loss_test:0.11163, lr:1.00e-02, fs:0.71795 (r=0.848,p=0.622),  time:18.175, tt:145.401\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00023, loss_test:0.11066, lr:1.00e-02, fs:0.70886 (r=0.848,p=0.609),  time:18.378, tt:165.402\n",
      "Ep:9, loss:0.00023, loss_test:0.10965, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:18.181, tt:181.810\n",
      "Ep:10, loss:0.00022, loss_test:0.10635, lr:1.00e-02, fs:0.73973 (r=0.818,p=0.675),  time:18.180, tt:199.982\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00021, loss_test:0.10386, lr:1.00e-02, fs:0.74528 (r=0.798,p=0.699),  time:18.059, tt:216.712\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00020, loss_test:0.10230, lr:1.00e-02, fs:0.72222 (r=0.788,p=0.667),  time:17.866, tt:232.255\n",
      "Ep:13, loss:0.00020, loss_test:0.09850, lr:1.00e-02, fs:0.74178 (r=0.798,p=0.693),  time:17.693, tt:247.707\n",
      "Ep:14, loss:0.00019, loss_test:0.09507, lr:1.00e-02, fs:0.76329 (r=0.798,p=0.731),  time:17.474, tt:262.112\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00019, loss_test:0.09471, lr:1.00e-02, fs:0.76636 (r=0.828,p=0.713),  time:17.405, tt:278.473\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00018, loss_test:0.09379, lr:1.00e-02, fs:0.76777 (r=0.818,p=0.723),  time:17.271, tt:293.602\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00018, loss_test:0.09241, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:17.322, tt:311.800\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00017, loss_test:0.09192, lr:1.00e-02, fs:0.77670 (r=0.808,p=0.748),  time:17.420, tt:330.983\n",
      "Ep:19, loss:0.00017, loss_test:0.09121, lr:1.00e-02, fs:0.77295 (r=0.808,p=0.741),  time:17.546, tt:350.914\n",
      "Ep:20, loss:0.00016, loss_test:0.08970, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:17.644, tt:370.526\n",
      "Ep:21, loss:0.00015, loss_test:0.08914, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:17.650, tt:388.306\n",
      "Ep:22, loss:0.00015, loss_test:0.08901, lr:1.00e-02, fs:0.77073 (r=0.798,p=0.745),  time:17.676, tt:406.546\n",
      "Ep:23, loss:0.00014, loss_test:0.08668, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:17.698, tt:424.746\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00014, loss_test:0.08583, lr:1.00e-02, fs:0.76847 (r=0.788,p=0.750),  time:17.768, tt:444.191\n",
      "Ep:25, loss:0.00013, loss_test:0.08588, lr:1.00e-02, fs:0.80000 (r=0.788,p=0.812),  time:17.942, tt:466.498\n",
      "##########Best model found so far##########\n",
      "Ep:26, loss:0.00013, loss_test:0.08525, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:18.155, tt:490.190\n",
      "Ep:27, loss:0.00012, loss_test:0.08409, lr:1.00e-02, fs:0.79188 (r=0.788,p=0.796),  time:18.222, tt:510.227\n",
      "Ep:28, loss:0.00012, loss_test:0.08356, lr:1.00e-02, fs:0.78571 (r=0.778,p=0.794),  time:18.331, tt:531.587\n",
      "Ep:29, loss:0.00012, loss_test:0.08297, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.400, tt:551.986\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00011, loss_test:0.08255, lr:1.00e-02, fs:0.80612 (r=0.798,p=0.814),  time:18.423, tt:571.120\n",
      "Ep:31, loss:0.00011, loss_test:0.08183, lr:1.00e-02, fs:0.81818 (r=0.818,p=0.818),  time:18.365, tt:587.667\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00010, loss_test:0.08161, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:18.454, tt:608.984\n",
      "Ep:33, loss:0.00010, loss_test:0.08174, lr:1.00e-02, fs:0.78947 (r=0.758,p=0.824),  time:18.490, tt:628.658\n",
      "Ep:34, loss:0.00010, loss_test:0.08064, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:18.521, tt:648.241\n",
      "Ep:35, loss:0.00009, loss_test:0.08078, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:18.580, tt:668.865\n",
      "Ep:36, loss:0.00009, loss_test:0.08007, lr:1.00e-02, fs:0.79787 (r=0.758,p=0.843),  time:18.531, tt:685.636\n",
      "Ep:37, loss:0.00009, loss_test:0.08013, lr:1.00e-02, fs:0.79592 (r=0.788,p=0.804),  time:18.517, tt:703.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:38, loss:0.00009, loss_test:0.07902, lr:1.00e-02, fs:0.81053 (r=0.778,p=0.846),  time:18.528, tt:722.573\n",
      "Ep:39, loss:0.00008, loss_test:0.07728, lr:1.00e-02, fs:0.80829 (r=0.788,p=0.830),  time:18.501, tt:740.057\n",
      "Ep:40, loss:0.00008, loss_test:0.07701, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:18.509, tt:758.866\n",
      "Ep:41, loss:0.00008, loss_test:0.07624, lr:1.00e-02, fs:0.82000 (r=0.828,p=0.812),  time:18.538, tt:778.592\n",
      "##########Best model found so far##########\n",
      "Ep:42, loss:0.00007, loss_test:0.07831, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:18.587, tt:799.233\n",
      "Ep:43, loss:0.00007, loss_test:0.07465, lr:1.00e-02, fs:0.82234 (r=0.818,p=0.827),  time:18.646, tt:820.431\n",
      "##########Best model found so far##########\n",
      "Ep:44, loss:0.00007, loss_test:0.07629, lr:1.00e-02, fs:0.80874 (r=0.747,p=0.881),  time:18.670, tt:840.135\n",
      "Ep:45, loss:0.00007, loss_test:0.07422, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:18.723, tt:861.259\n",
      "Ep:46, loss:0.00007, loss_test:0.07443, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:18.769, tt:882.128\n",
      "Ep:47, loss:0.00006, loss_test:0.07485, lr:1.00e-02, fs:0.81522 (r=0.758,p=0.882),  time:18.845, tt:904.557\n",
      "Ep:48, loss:0.00006, loss_test:0.07432, lr:1.00e-02, fs:0.84211 (r=0.808,p=0.879),  time:18.928, tt:927.476\n",
      "##########Best model found so far##########\n",
      "Ep:49, loss:0.00006, loss_test:0.07291, lr:1.00e-02, fs:0.80851 (r=0.768,p=0.854),  time:18.988, tt:949.381\n",
      "Ep:50, loss:0.00006, loss_test:0.07473, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:19.018, tt:969.934\n",
      "Ep:51, loss:0.00006, loss_test:0.07342, lr:1.00e-02, fs:0.81283 (r=0.768,p=0.864),  time:19.053, tt:990.774\n",
      "Ep:52, loss:0.00006, loss_test:0.07329, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:19.042, tt:1009.201\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00006, loss_test:0.07397, lr:1.00e-02, fs:0.83598 (r=0.798,p=0.878),  time:19.033, tt:1027.765\n",
      "Ep:54, loss:0.00006, loss_test:0.07291, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:19.078, tt:1049.302\n",
      "Ep:55, loss:0.00005, loss_test:0.07583, lr:1.00e-02, fs:0.82353 (r=0.778,p=0.875),  time:19.106, tt:1069.940\n",
      "Ep:56, loss:0.00005, loss_test:0.07750, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:19.122, tt:1089.935\n",
      "Ep:57, loss:0.00006, loss_test:0.07583, lr:1.00e-02, fs:0.78889 (r=0.717,p=0.877),  time:19.151, tt:1110.768\n",
      "Ep:58, loss:0.00005, loss_test:0.07182, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:19.165, tt:1130.753\n",
      "Ep:59, loss:0.00005, loss_test:0.07191, lr:1.00e-02, fs:0.84974 (r=0.828,p=0.872),  time:19.218, tt:1153.102\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00005, loss_test:0.07253, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:19.259, tt:1174.803\n",
      "Ep:61, loss:0.00005, loss_test:0.07628, lr:1.00e-02, fs:0.76136 (r=0.677,p=0.870),  time:19.251, tt:1193.544\n",
      "Ep:62, loss:0.00005, loss_test:0.07178, lr:1.00e-02, fs:0.83422 (r=0.788,p=0.886),  time:19.263, tt:1213.553\n",
      "Ep:63, loss:0.00005, loss_test:0.07076, lr:1.00e-02, fs:0.82162 (r=0.768,p=0.884),  time:19.284, tt:1234.163\n",
      "Ep:64, loss:0.00004, loss_test:0.06956, lr:1.00e-02, fs:0.84656 (r=0.808,p=0.889),  time:19.252, tt:1251.405\n",
      "Ep:65, loss:0.00004, loss_test:0.07261, lr:1.00e-02, fs:0.81111 (r=0.737,p=0.901),  time:19.248, tt:1270.353\n",
      "Ep:66, loss:0.00004, loss_test:0.06806, lr:1.00e-02, fs:0.85263 (r=0.818,p=0.890),  time:19.215, tt:1287.374\n",
      "##########Best model found so far##########\n",
      "Ep:67, loss:0.00004, loss_test:0.06910, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:19.178, tt:1304.100\n",
      "Ep:68, loss:0.00004, loss_test:0.06866, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:19.157, tt:1321.842\n",
      "Ep:69, loss:0.00004, loss_test:0.06916, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:19.180, tt:1342.606\n",
      "Ep:70, loss:0.00004, loss_test:0.06777, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:19.149, tt:1359.565\n",
      "Ep:71, loss:0.00004, loss_test:0.06684, lr:1.00e-02, fs:0.83696 (r=0.778,p=0.906),  time:19.160, tt:1379.488\n",
      "Ep:72, loss:0.00004, loss_test:0.06929, lr:1.00e-02, fs:0.82418 (r=0.758,p=0.904),  time:19.137, tt:1397.023\n",
      "Ep:73, loss:0.00003, loss_test:0.06708, lr:1.00e-02, fs:0.82609 (r=0.768,p=0.894),  time:19.149, tt:1417.020\n",
      "Ep:74, loss:0.00003, loss_test:0.06814, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:19.145, tt:1435.904\n",
      "Ep:75, loss:0.00003, loss_test:0.06650, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:19.128, tt:1453.747\n",
      "Ep:76, loss:0.00003, loss_test:0.06716, lr:1.00e-02, fs:0.82873 (r=0.758,p=0.915),  time:19.109, tt:1471.416\n",
      "Ep:77, loss:0.00003, loss_test:0.06869, lr:1.00e-02, fs:0.83060 (r=0.768,p=0.905),  time:19.083, tt:1488.511\n",
      "Ep:78, loss:0.00003, loss_test:0.06790, lr:9.90e-03, fs:0.83060 (r=0.768,p=0.905),  time:19.060, tt:1505.745\n",
      "Ep:79, loss:0.00003, loss_test:0.06859, lr:9.80e-03, fs:0.83696 (r=0.778,p=0.906),  time:19.053, tt:1524.240\n",
      "Ep:80, loss:0.00003, loss_test:0.06757, lr:9.70e-03, fs:0.83516 (r=0.768,p=0.916),  time:19.088, tt:1546.124\n",
      "Ep:81, loss:0.00003, loss_test:0.06656, lr:9.61e-03, fs:0.84153 (r=0.778,p=0.917),  time:19.117, tt:1567.599\n",
      "Ep:82, loss:0.00003, loss_test:0.07022, lr:9.51e-03, fs:0.79096 (r=0.707,p=0.897),  time:19.115, tt:1586.520\n",
      "Ep:83, loss:0.00003, loss_test:0.06870, lr:9.41e-03, fs:0.84153 (r=0.778,p=0.917),  time:19.153, tt:1608.885\n",
      "Ep:84, loss:0.00003, loss_test:0.07115, lr:9.32e-03, fs:0.77011 (r=0.677,p=0.893),  time:19.153, tt:1627.988\n",
      "Ep:85, loss:0.00003, loss_test:0.06862, lr:9.23e-03, fs:0.84916 (r=0.768,p=0.950),  time:19.131, tt:1645.268\n",
      "Ep:86, loss:0.00003, loss_test:0.06981, lr:9.14e-03, fs:0.76744 (r=0.667,p=0.904),  time:19.146, tt:1665.699\n",
      "Ep:87, loss:0.00003, loss_test:0.06896, lr:9.04e-03, fs:0.82286 (r=0.727,p=0.947),  time:19.174, tt:1687.335\n",
      "Ep:88, loss:0.00003, loss_test:0.06823, lr:8.95e-03, fs:0.83799 (r=0.758,p=0.938),  time:19.189, tt:1707.806\n",
      "Ep:89, loss:0.00003, loss_test:0.07005, lr:8.86e-03, fs:0.81609 (r=0.717,p=0.947),  time:19.194, tt:1727.473\n",
      "Ep:90, loss:0.00002, loss_test:0.06701, lr:8.78e-03, fs:0.86813 (r=0.798,p=0.952),  time:19.212, tt:1748.282\n",
      "##########Best model found so far##########\n",
      "Ep:91, loss:0.00002, loss_test:0.06927, lr:8.78e-03, fs:0.84270 (r=0.758,p=0.949),  time:19.223, tt:1768.557\n",
      "Ep:92, loss:0.00002, loss_test:0.06712, lr:8.78e-03, fs:0.88649 (r=0.828,p=0.953),  time:19.215, tt:1786.990\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.07161, lr:8.78e-03, fs:0.80899 (r=0.727,p=0.911),  time:19.210, tt:1805.758\n",
      "Ep:94, loss:0.00002, loss_test:0.06893, lr:8.78e-03, fs:0.86034 (r=0.778,p=0.963),  time:19.202, tt:1824.176\n",
      "Ep:95, loss:0.00002, loss_test:0.06930, lr:8.78e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.205, tt:1843.636\n",
      "Ep:96, loss:0.00002, loss_test:0.06837, lr:8.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:19.202, tt:1862.599\n",
      "Ep:97, loss:0.00002, loss_test:0.06963, lr:8.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:19.236, tt:1885.168\n",
      "Ep:98, loss:0.00002, loss_test:0.07032, lr:8.78e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.258, tt:1906.503\n",
      "Ep:99, loss:0.00002, loss_test:0.06817, lr:8.78e-03, fs:0.84091 (r=0.747,p=0.961),  time:19.276, tt:1927.580\n",
      "Ep:100, loss:0.00002, loss_test:0.06973, lr:8.78e-03, fs:0.84091 (r=0.747,p=0.961),  time:19.268, tt:1946.084\n",
      "Ep:101, loss:0.00002, loss_test:0.06939, lr:8.78e-03, fs:0.82759 (r=0.727,p=0.960),  time:19.268, tt:1965.369\n",
      "Ep:102, loss:0.00002, loss_test:0.06913, lr:8.78e-03, fs:0.85393 (r=0.768,p=0.962),  time:19.260, tt:1983.829\n",
      "Ep:103, loss:0.00002, loss_test:0.07018, lr:8.78e-03, fs:0.82081 (r=0.717,p=0.959),  time:19.287, tt:2005.807\n",
      "Ep:104, loss:0.00002, loss_test:0.07141, lr:8.69e-03, fs:0.82759 (r=0.727,p=0.960),  time:19.271, tt:2023.404\n",
      "Ep:105, loss:0.00002, loss_test:0.06994, lr:8.60e-03, fs:0.82759 (r=0.727,p=0.960),  time:19.255, tt:2041.027\n",
      "Ep:106, loss:0.00002, loss_test:0.07023, lr:8.51e-03, fs:0.82759 (r=0.727,p=0.960),  time:19.255, tt:2060.268\n",
      "Ep:107, loss:0.00002, loss_test:0.06861, lr:8.43e-03, fs:0.84746 (r=0.758,p=0.962),  time:19.255, tt:2079.577\n",
      "Ep:108, loss:0.00002, loss_test:0.06980, lr:8.35e-03, fs:0.84091 (r=0.747,p=0.961),  time:19.245, tt:2097.714\n",
      "Ep:109, loss:0.00001, loss_test:0.07048, lr:8.26e-03, fs:0.81395 (r=0.707,p=0.959),  time:19.269, tt:2119.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:110, loss:0.00001, loss_test:0.07040, lr:8.18e-03, fs:0.81395 (r=0.707,p=0.959),  time:19.272, tt:2139.215\n",
      "Ep:111, loss:0.00001, loss_test:0.06919, lr:8.10e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.263, tt:2157.403\n",
      "Ep:112, loss:0.00001, loss_test:0.06940, lr:8.02e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.261, tt:2176.479\n",
      "Ep:113, loss:0.00001, loss_test:0.07024, lr:7.94e-03, fs:0.82081 (r=0.717,p=0.959),  time:19.267, tt:2196.424\n",
      "Ep:114, loss:0.00001, loss_test:0.07004, lr:7.86e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.265, tt:2215.496\n",
      "Ep:115, loss:0.00001, loss_test:0.06973, lr:7.78e-03, fs:0.82081 (r=0.717,p=0.959),  time:19.255, tt:2233.526\n",
      "Ep:116, loss:0.00001, loss_test:0.07003, lr:7.70e-03, fs:0.82081 (r=0.717,p=0.959),  time:19.259, tt:2253.337\n",
      "Ep:117, loss:0.00001, loss_test:0.06973, lr:7.62e-03, fs:0.82759 (r=0.727,p=0.960),  time:19.274, tt:2274.307\n",
      "Ep:118, loss:0.00001, loss_test:0.06961, lr:7.55e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.260, tt:2291.968\n",
      "Ep:119, loss:0.00001, loss_test:0.06909, lr:7.47e-03, fs:0.83429 (r=0.737,p=0.961),  time:19.264, tt:2311.689\n",
      "Ep:120, loss:0.00001, loss_test:0.07091, lr:7.40e-03, fs:0.83908 (r=0.737,p=0.973),  time:19.245, tt:2328.630\n",
      "Ep:121, loss:0.00001, loss_test:0.07206, lr:7.32e-03, fs:0.79042 (r=0.667,p=0.971),  time:19.270, tt:2350.953\n",
      "Ep:122, loss:0.00001, loss_test:0.07066, lr:7.25e-03, fs:0.85393 (r=0.768,p=0.962),  time:19.263, tt:2369.314\n",
      "Ep:123, loss:0.00001, loss_test:0.07333, lr:7.18e-03, fs:0.72152 (r=0.576,p=0.966),  time:19.247, tt:2386.641\n",
      "Ep:124, loss:0.00001, loss_test:0.07036, lr:7.11e-03, fs:0.83237 (r=0.727,p=0.973),  time:19.239, tt:2404.865\n",
      "Ep:125, loss:0.00001, loss_test:0.07075, lr:7.03e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.264, tt:2427.277\n",
      "Ep:126, loss:0.00001, loss_test:0.07026, lr:6.96e-03, fs:0.81176 (r=0.697,p=0.972),  time:19.276, tt:2448.037\n",
      "Ep:127, loss:0.00001, loss_test:0.07095, lr:6.89e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.282, tt:2468.076\n",
      "Ep:128, loss:0.00001, loss_test:0.06938, lr:6.83e-03, fs:0.83908 (r=0.737,p=0.973),  time:19.263, tt:2484.949\n",
      "Ep:129, loss:0.00001, loss_test:0.07155, lr:6.76e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.256, tt:2503.249\n",
      "Ep:130, loss:0.00001, loss_test:0.07036, lr:6.69e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.242, tt:2520.736\n",
      "Ep:131, loss:0.00001, loss_test:0.07078, lr:6.62e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.223, tt:2537.403\n",
      "Ep:132, loss:0.00001, loss_test:0.07089, lr:6.56e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.223, tt:2556.666\n",
      "Ep:133, loss:0.00001, loss_test:0.07056, lr:6.49e-03, fs:0.83908 (r=0.737,p=0.973),  time:19.217, tt:2575.028\n",
      "Ep:134, loss:0.00001, loss_test:0.07260, lr:6.43e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.210, tt:2593.349\n",
      "Ep:135, loss:0.00001, loss_test:0.06994, lr:6.36e-03, fs:0.85227 (r=0.758,p=0.974),  time:19.201, tt:2611.292\n",
      "Ep:136, loss:0.00001, loss_test:0.07215, lr:6.30e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.187, tt:2628.646\n",
      "Ep:137, loss:0.00001, loss_test:0.07081, lr:6.24e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.199, tt:2649.512\n",
      "Ep:138, loss:0.00001, loss_test:0.07102, lr:6.17e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.187, tt:2666.964\n",
      "Ep:139, loss:0.00001, loss_test:0.07174, lr:6.11e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.172, tt:2684.091\n",
      "Ep:140, loss:0.00001, loss_test:0.07115, lr:6.05e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.160, tt:2701.545\n",
      "Ep:141, loss:0.00001, loss_test:0.07125, lr:5.99e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.158, tt:2720.420\n",
      "Ep:142, loss:0.00001, loss_test:0.07079, lr:5.93e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.146, tt:2737.884\n",
      "Ep:143, loss:0.00001, loss_test:0.07132, lr:5.87e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.124, tt:2753.887\n",
      "Ep:144, loss:0.00001, loss_test:0.07080, lr:5.81e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.117, tt:2771.904\n",
      "Ep:145, loss:0.00001, loss_test:0.07065, lr:5.75e-03, fs:0.79762 (r=0.677,p=0.971),  time:19.112, tt:2790.308\n",
      "Ep:146, loss:0.00001, loss_test:0.07057, lr:5.70e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.103, tt:2808.159\n",
      "Ep:147, loss:0.00001, loss_test:0.07272, lr:5.64e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.109, tt:2828.137\n",
      "Ep:148, loss:0.00001, loss_test:0.07093, lr:5.58e-03, fs:0.82558 (r=0.717,p=0.973),  time:19.098, tt:2845.674\n",
      "Ep:149, loss:0.00001, loss_test:0.07125, lr:5.53e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.097, tt:2864.605\n",
      "Ep:150, loss:0.00001, loss_test:0.07080, lr:5.47e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.090, tt:2882.553\n",
      "Ep:151, loss:0.00001, loss_test:0.07128, lr:5.42e-03, fs:0.80473 (r=0.687,p=0.971),  time:19.081, tt:2900.304\n",
      "Ep:152, loss:0.00001, loss_test:0.07091, lr:5.36e-03, fs:0.78313 (r=0.657,p=0.970),  time:19.052, tt:2915.006\n",
      "Ep:153, loss:0.00001, loss_test:0.07044, lr:5.31e-03, fs:0.82558 (r=0.717,p=0.973),  time:19.042, tt:2932.484\n",
      "Ep:154, loss:0.00001, loss_test:0.07258, lr:5.26e-03, fs:0.76829 (r=0.636,p=0.969),  time:19.040, tt:2951.132\n",
      "Ep:155, loss:0.00001, loss_test:0.07060, lr:5.20e-03, fs:0.81871 (r=0.707,p=0.972),  time:19.022, tt:2967.471\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= -1\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 8\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n",
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.12991, lr:1.00e-02, fs:0.66182 (r=0.919,p=0.517),  time:22.103, tt:22.103\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12367, lr:1.00e-02, fs:0.66406 (r=0.859,p=0.541),  time:22.393, tt:44.785\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12109, lr:1.00e-02, fs:0.63519 (r=0.747,p=0.552),  time:23.208, tt:69.623\n",
      "Ep:3, loss:0.00025, loss_test:0.11949, lr:1.00e-02, fs:0.64035 (r=0.737,p=0.566),  time:22.950, tt:91.799\n",
      "Ep:4, loss:0.00025, loss_test:0.11680, lr:1.00e-02, fs:0.64935 (r=0.758,p=0.568),  time:22.563, tt:112.815\n",
      "Ep:5, loss:0.00024, loss_test:0.11441, lr:1.00e-02, fs:0.66667 (r=0.788,p=0.578),  time:21.958, tt:131.747\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11100, lr:1.00e-02, fs:0.66667 (r=0.778,p=0.583),  time:21.771, tt:152.395\n",
      "Ep:7, loss:0.00022, loss_test:0.10698, lr:1.00e-02, fs:0.69124 (r=0.758,p=0.636),  time:21.544, tt:172.355\n",
      "##########Best model found so far##########\n",
      "Ep:8, loss:0.00022, loss_test:0.10269, lr:1.00e-02, fs:0.70476 (r=0.747,p=0.667),  time:21.362, tt:192.257\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00021, loss_test:0.09830, lr:1.00e-02, fs:0.71090 (r=0.758,p=0.670),  time:21.066, tt:210.658\n",
      "##########Best model found so far##########\n",
      "Ep:10, loss:0.00020, loss_test:0.09515, lr:1.00e-02, fs:0.73239 (r=0.788,p=0.684),  time:20.772, tt:228.489\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.09166, lr:1.00e-02, fs:0.75000 (r=0.788,p=0.716),  time:20.384, tt:244.608\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00019, loss_test:0.08735, lr:1.00e-02, fs:0.76617 (r=0.778,p=0.755),  time:20.262, tt:263.405\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00018, loss_test:0.08520, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:20.085, tt:281.185\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.08369, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:20.121, tt:301.820\n",
      "Ep:15, loss:0.00017, loss_test:0.08112, lr:1.00e-02, fs:0.79208 (r=0.808,p=0.777),  time:20.263, tt:324.211\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00016, loss_test:0.07947, lr:1.00e-02, fs:0.80000 (r=0.848,p=0.757),  time:20.290, tt:344.925\n",
      "##########Best model found so far##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:17, loss:0.00015, loss_test:0.07702, lr:1.00e-02, fs:0.82353 (r=0.848,p=0.800),  time:20.253, tt:364.546\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00015, loss_test:0.07611, lr:1.00e-02, fs:0.83168 (r=0.848,p=0.816),  time:20.288, tt:385.478\n",
      "##########Best model found so far##########\n",
      "Ep:19, loss:0.00014, loss_test:0.07423, lr:1.00e-02, fs:0.83654 (r=0.879,p=0.798),  time:20.287, tt:405.750\n",
      "##########Best model found so far##########\n",
      "Ep:20, loss:0.00014, loss_test:0.07187, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:20.318, tt:426.669\n",
      "##########Best model found so far##########\n",
      "Ep:21, loss:0.00013, loss_test:0.07065, lr:1.00e-02, fs:0.84211 (r=0.889,p=0.800),  time:20.270, tt:445.932\n",
      "Ep:22, loss:0.00013, loss_test:0.06783, lr:1.00e-02, fs:0.84466 (r=0.879,p=0.813),  time:20.344, tt:467.915\n",
      "Ep:23, loss:0.00012, loss_test:0.06772, lr:1.00e-02, fs:0.85714 (r=0.909,p=0.811),  time:20.432, tt:490.367\n",
      "##########Best model found so far##########\n",
      "Ep:24, loss:0.00012, loss_test:0.06518, lr:1.00e-02, fs:0.86700 (r=0.889,p=0.846),  time:20.518, tt:512.960\n",
      "##########Best model found so far##########\n",
      "Ep:25, loss:0.00011, loss_test:0.06553, lr:1.00e-02, fs:0.86408 (r=0.899,p=0.832),  time:20.526, tt:533.678\n",
      "Ep:26, loss:0.00011, loss_test:0.06256, lr:1.00e-02, fs:0.87255 (r=0.899,p=0.848),  time:20.656, tt:557.720\n",
      "##########Best model found so far##########\n",
      "Ep:27, loss:0.00011, loss_test:0.06252, lr:1.00e-02, fs:0.86829 (r=0.899,p=0.840),  time:20.765, tt:581.412\n",
      "Ep:28, loss:0.00010, loss_test:0.06039, lr:1.00e-02, fs:0.88670 (r=0.909,p=0.865),  time:20.796, tt:603.092\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00010, loss_test:0.05914, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:20.751, tt:622.518\n",
      "##########Best model found so far##########\n",
      "Ep:30, loss:0.00010, loss_test:0.05783, lr:1.00e-02, fs:0.89109 (r=0.909,p=0.874),  time:20.805, tt:644.952\n",
      "Ep:31, loss:0.00009, loss_test:0.05650, lr:1.00e-02, fs:0.90099 (r=0.919,p=0.883),  time:20.810, tt:665.916\n",
      "##########Best model found so far##########\n",
      "Ep:32, loss:0.00009, loss_test:0.05533, lr:1.00e-02, fs:0.89756 (r=0.929,p=0.868),  time:20.804, tt:686.535\n",
      "Ep:33, loss:0.00009, loss_test:0.05442, lr:1.00e-02, fs:0.90196 (r=0.929,p=0.876),  time:20.865, tt:709.422\n",
      "##########Best model found so far##########\n",
      "Ep:34, loss:0.00008, loss_test:0.05376, lr:1.00e-02, fs:0.90821 (r=0.949,p=0.870),  time:20.832, tt:729.106\n",
      "##########Best model found so far##########\n",
      "Ep:35, loss:0.00008, loss_test:0.05292, lr:1.00e-02, fs:0.90291 (r=0.939,p=0.869),  time:20.803, tt:748.910\n",
      "Ep:36, loss:0.00008, loss_test:0.05269, lr:1.00e-02, fs:0.90385 (r=0.949,p=0.862),  time:20.793, tt:769.330\n",
      "Ep:37, loss:0.00008, loss_test:0.05111, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:20.835, tt:791.716\n",
      "##########Best model found so far##########\n",
      "Ep:38, loss:0.00008, loss_test:0.04966, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:20.844, tt:812.904\n",
      "##########Best model found so far##########\n",
      "Ep:39, loss:0.00007, loss_test:0.05017, lr:1.00e-02, fs:0.91787 (r=0.960,p=0.880),  time:20.834, tt:833.365\n",
      "Ep:40, loss:0.00007, loss_test:0.05091, lr:1.00e-02, fs:0.89952 (r=0.949,p=0.855),  time:20.854, tt:855.004\n",
      "Ep:41, loss:0.00007, loss_test:0.04857, lr:1.00e-02, fs:0.91346 (r=0.960,p=0.872),  time:20.847, tt:875.559\n",
      "Ep:42, loss:0.00007, loss_test:0.04776, lr:1.00e-02, fs:0.92079 (r=0.939,p=0.903),  time:20.856, tt:896.793\n",
      "##########Best model found so far##########\n",
      "Ep:43, loss:0.00007, loss_test:0.04812, lr:1.00e-02, fs:0.90995 (r=0.970,p=0.857),  time:20.865, tt:918.060\n",
      "Ep:44, loss:0.00006, loss_test:0.04624, lr:1.00e-02, fs:0.92683 (r=0.960,p=0.896),  time:20.893, tt:940.177\n",
      "##########Best model found so far##########\n",
      "Ep:45, loss:0.00006, loss_test:0.04679, lr:1.00e-02, fs:0.91707 (r=0.949,p=0.887),  time:20.991, tt:965.597\n",
      "Ep:46, loss:0.00006, loss_test:0.04559, lr:1.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:21.008, tt:987.360\n",
      "##########Best model found so far##########\n",
      "Ep:47, loss:0.00006, loss_test:0.04575, lr:1.00e-02, fs:0.93137 (r=0.960,p=0.905),  time:21.009, tt:1008.432\n",
      "Ep:48, loss:0.00006, loss_test:0.04582, lr:1.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:20.989, tt:1028.468\n",
      "Ep:49, loss:0.00006, loss_test:0.04520, lr:1.00e-02, fs:0.93204 (r=0.970,p=0.897),  time:21.020, tt:1050.979\n",
      "Ep:50, loss:0.00006, loss_test:0.04437, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:21.023, tt:1072.158\n",
      "##########Best model found so far##########\n",
      "Ep:51, loss:0.00005, loss_test:0.04479, lr:1.00e-02, fs:0.92823 (r=0.980,p=0.882),  time:21.006, tt:1092.303\n",
      "Ep:52, loss:0.00005, loss_test:0.04383, lr:1.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:20.988, tt:1112.370\n",
      "##########Best model found so far##########\n",
      "Ep:53, loss:0.00005, loss_test:0.04477, lr:1.00e-02, fs:0.92754 (r=0.970,p=0.889),  time:20.970, tt:1132.375\n",
      "Ep:54, loss:0.00005, loss_test:0.04259, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:20.965, tt:1153.068\n",
      "##########Best model found so far##########\n",
      "Ep:55, loss:0.00005, loss_test:0.04313, lr:1.00e-02, fs:0.93269 (r=0.980,p=0.890),  time:20.955, tt:1173.473\n",
      "Ep:56, loss:0.00005, loss_test:0.04188, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:20.992, tt:1196.545\n",
      "Ep:57, loss:0.00005, loss_test:0.04156, lr:1.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:20.996, tt:1217.779\n",
      "Ep:58, loss:0.00004, loss_test:0.04161, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:21.001, tt:1239.071\n",
      "Ep:59, loss:0.00004, loss_test:0.04118, lr:1.00e-02, fs:0.95146 (r=0.990,p=0.916),  time:21.027, tt:1261.598\n",
      "##########Best model found so far##########\n",
      "Ep:60, loss:0.00004, loss_test:0.04213, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:21.018, tt:1282.100\n",
      "Ep:61, loss:0.00004, loss_test:0.04281, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:21.023, tt:1303.404\n",
      "Ep:62, loss:0.00004, loss_test:0.04449, lr:1.00e-02, fs:0.91866 (r=0.970,p=0.873),  time:21.017, tt:1324.042\n",
      "Ep:63, loss:0.00004, loss_test:0.04063, lr:1.00e-02, fs:0.95146 (r=0.990,p=0.916),  time:21.031, tt:1345.992\n",
      "Ep:64, loss:0.00004, loss_test:0.04118, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:21.046, tt:1367.992\n",
      "Ep:65, loss:0.00004, loss_test:0.03925, lr:1.00e-02, fs:0.95192 (r=1.000,p=0.908),  time:21.080, tt:1391.252\n",
      "##########Best model found so far##########\n",
      "Ep:66, loss:0.00004, loss_test:0.04096, lr:1.00e-02, fs:0.93659 (r=0.970,p=0.906),  time:21.062, tt:1411.155\n",
      "Ep:67, loss:0.00004, loss_test:0.03783, lr:1.00e-02, fs:0.94231 (r=0.990,p=0.899),  time:21.072, tt:1432.869\n",
      "Ep:68, loss:0.00003, loss_test:0.03850, lr:1.00e-02, fs:0.94175 (r=0.980,p=0.907),  time:21.066, tt:1453.551\n",
      "Ep:69, loss:0.00003, loss_test:0.03852, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:21.060, tt:1474.174\n",
      "##########Best model found so far##########\n",
      "Ep:70, loss:0.00003, loss_test:0.03877, lr:1.00e-02, fs:0.94686 (r=0.990,p=0.907),  time:21.051, tt:1494.595\n",
      "Ep:71, loss:0.00003, loss_test:0.03802, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:21.067, tt:1516.805\n",
      "Ep:72, loss:0.00003, loss_test:0.03759, lr:1.00e-02, fs:0.96078 (r=0.990,p=0.933),  time:21.077, tt:1538.602\n",
      "##########Best model found so far##########\n",
      "Ep:73, loss:0.00003, loss_test:0.03727, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:21.118, tt:1562.729\n",
      "Ep:74, loss:0.00003, loss_test:0.03747, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.116, tt:1583.680\n",
      "##########Best model found so far##########\n",
      "Ep:75, loss:0.00003, loss_test:0.03768, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:21.119, tt:1605.043\n",
      "Ep:76, loss:0.00003, loss_test:0.03780, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.120, tt:1626.269\n",
      "Ep:77, loss:0.00003, loss_test:0.03808, lr:1.00e-02, fs:0.94634 (r=0.980,p=0.915),  time:21.154, tt:1650.007\n",
      "Ep:78, loss:0.00003, loss_test:0.03688, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.188, tt:1673.826\n",
      "Ep:79, loss:0.00003, loss_test:0.03855, lr:1.00e-02, fs:0.94527 (r=0.960,p=0.931),  time:21.182, tt:1694.582\n",
      "Ep:80, loss:0.00003, loss_test:0.03686, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.185, tt:1716.022\n",
      "Ep:81, loss:0.00003, loss_test:0.03729, lr:1.00e-02, fs:0.95050 (r=0.970,p=0.932),  time:21.190, tt:1737.616\n",
      "Ep:82, loss:0.00003, loss_test:0.03665, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.220, tt:1761.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:83, loss:0.00002, loss_test:0.03705, lr:1.00e-02, fs:0.95522 (r=0.970,p=0.941),  time:21.230, tt:1783.313\n",
      "Ep:84, loss:0.00002, loss_test:0.03684, lr:1.00e-02, fs:0.96552 (r=0.990,p=0.942),  time:21.236, tt:1805.061\n",
      "Ep:85, loss:0.00002, loss_test:0.03640, lr:1.00e-02, fs:0.95610 (r=0.990,p=0.925),  time:21.233, tt:1826.072\n",
      "Ep:86, loss:0.00002, loss_test:0.03623, lr:9.90e-03, fs:0.96552 (r=0.990,p=0.942),  time:21.228, tt:1846.803\n",
      "Ep:87, loss:0.00002, loss_test:0.03758, lr:9.80e-03, fs:0.96000 (r=0.970,p=0.950),  time:21.214, tt:1866.846\n",
      "Ep:88, loss:0.00002, loss_test:0.03602, lr:9.70e-03, fs:0.96078 (r=0.990,p=0.933),  time:21.200, tt:1886.761\n",
      "Ep:89, loss:0.00002, loss_test:0.03686, lr:9.61e-03, fs:0.96000 (r=0.970,p=0.950),  time:21.190, tt:1907.129\n",
      "Ep:90, loss:0.00002, loss_test:0.03588, lr:9.51e-03, fs:0.96552 (r=0.990,p=0.942),  time:21.212, tt:1930.314\n",
      "Ep:91, loss:0.00002, loss_test:0.03696, lr:9.41e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.202, tt:1950.629\n",
      "Ep:92, loss:0.00002, loss_test:0.03596, lr:9.32e-03, fs:0.97512 (r=0.990,p=0.961),  time:21.187, tt:1970.385\n",
      "##########Best model found so far##########\n",
      "Ep:93, loss:0.00002, loss_test:0.03619, lr:9.32e-03, fs:0.95522 (r=0.970,p=0.941),  time:21.174, tt:1990.385\n",
      "Ep:94, loss:0.00002, loss_test:0.03670, lr:9.32e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.165, tt:2010.690\n",
      "Ep:95, loss:0.00002, loss_test:0.03560, lr:9.32e-03, fs:0.95610 (r=0.990,p=0.925),  time:21.156, tt:2030.953\n",
      "Ep:96, loss:0.00002, loss_test:0.03697, lr:9.32e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.140, tt:2050.581\n",
      "Ep:97, loss:0.00002, loss_test:0.03551, lr:9.32e-03, fs:0.97512 (r=0.990,p=0.961),  time:21.123, tt:2070.102\n",
      "Ep:98, loss:0.00002, loss_test:0.03610, lr:9.32e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.110, tt:2089.922\n",
      "Ep:99, loss:0.00002, loss_test:0.03621, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.115, tt:2111.488\n",
      "Ep:100, loss:0.00002, loss_test:0.03557, lr:9.32e-03, fs:0.96078 (r=0.990,p=0.933),  time:21.150, tt:2136.179\n",
      "Ep:101, loss:0.00002, loss_test:0.03693, lr:9.32e-03, fs:0.95385 (r=0.939,p=0.969),  time:21.178, tt:2160.108\n",
      "Ep:102, loss:0.00002, loss_test:0.03622, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.167, tt:2180.204\n",
      "Ep:103, loss:0.00002, loss_test:0.03536, lr:9.32e-03, fs:0.98020 (r=1.000,p=0.961),  time:21.176, tt:2202.308\n",
      "##########Best model found so far##########\n",
      "Ep:104, loss:0.00002, loss_test:0.03746, lr:9.32e-03, fs:0.96447 (r=0.960,p=0.969),  time:21.196, tt:2225.611\n",
      "Ep:105, loss:0.00002, loss_test:0.03581, lr:9.32e-03, fs:0.98000 (r=0.990,p=0.970),  time:21.207, tt:2247.903\n",
      "Ep:106, loss:0.00002, loss_test:0.03593, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.197, tt:2268.132\n",
      "Ep:107, loss:0.00002, loss_test:0.03684, lr:9.32e-03, fs:0.93750 (r=0.909,p=0.968),  time:21.193, tt:2288.802\n",
      "Ep:108, loss:0.00002, loss_test:0.03586, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.182, tt:2308.855\n",
      "Ep:109, loss:0.00002, loss_test:0.03586, lr:9.32e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.168, tt:2328.519\n",
      "Ep:110, loss:0.00002, loss_test:0.03585, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.173, tt:2350.234\n",
      "Ep:111, loss:0.00002, loss_test:0.03525, lr:9.32e-03, fs:0.96970 (r=0.970,p=0.970),  time:21.194, tt:2373.766\n",
      "Ep:112, loss:0.00001, loss_test:0.03583, lr:9.32e-03, fs:0.97000 (r=0.980,p=0.960),  time:21.190, tt:2394.431\n",
      "Ep:113, loss:0.00001, loss_test:0.03678, lr:9.32e-03, fs:0.92063 (r=0.879,p=0.967),  time:21.180, tt:2414.515\n",
      "Ep:114, loss:0.00001, loss_test:0.03622, lr:9.32e-03, fs:0.91489 (r=0.869,p=0.966),  time:21.177, tt:2435.377\n",
      "Ep:115, loss:0.00001, loss_test:0.03528, lr:9.23e-03, fs:0.97512 (r=0.990,p=0.961),  time:21.197, tt:2458.817\n",
      "Ep:116, loss:0.00001, loss_test:0.03631, lr:9.14e-03, fs:0.93750 (r=0.909,p=0.968),  time:21.178, tt:2477.852\n",
      "Ep:117, loss:0.00001, loss_test:0.03628, lr:9.04e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.168, tt:2497.792\n",
      "Ep:118, loss:0.00001, loss_test:0.03597, lr:8.95e-03, fs:0.96482 (r=0.970,p=0.960),  time:21.167, tt:2518.887\n",
      "Ep:119, loss:0.00001, loss_test:0.03664, lr:8.86e-03, fs:0.90323 (r=0.848,p=0.966),  time:21.154, tt:2538.498\n",
      "Ep:120, loss:0.00001, loss_test:0.03676, lr:8.78e-03, fs:0.92632 (r=0.889,p=0.967),  time:21.154, tt:2559.629\n",
      "Ep:121, loss:0.00001, loss_test:0.03577, lr:8.69e-03, fs:0.94301 (r=0.919,p=0.968),  time:21.152, tt:2580.568\n",
      "Ep:122, loss:0.00001, loss_test:0.03648, lr:8.60e-03, fs:0.93194 (r=0.899,p=0.967),  time:21.140, tt:2600.168\n",
      "Ep:123, loss:0.00001, loss_test:0.03593, lr:8.51e-03, fs:0.92632 (r=0.889,p=0.967),  time:21.136, tt:2620.851\n",
      "Ep:124, loss:0.00001, loss_test:0.03615, lr:8.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.143, tt:2642.918\n",
      "Ep:125, loss:0.00001, loss_test:0.03790, lr:8.35e-03, fs:0.90426 (r=0.859,p=0.955),  time:21.138, tt:2663.326\n",
      "Ep:126, loss:0.00001, loss_test:0.03600, lr:8.26e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.125, tt:2682.858\n",
      "Ep:127, loss:0.00001, loss_test:0.03719, lr:8.18e-03, fs:0.92708 (r=0.899,p=0.957),  time:21.119, tt:2703.177\n",
      "Ep:128, loss:0.00001, loss_test:0.03743, lr:8.10e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.132, tt:2726.082\n",
      "Ep:129, loss:0.00001, loss_test:0.03647, lr:8.02e-03, fs:0.90110 (r=0.828,p=0.988),  time:21.132, tt:2747.186\n",
      "Ep:130, loss:0.00001, loss_test:0.03704, lr:7.94e-03, fs:0.90909 (r=0.859,p=0.966),  time:21.135, tt:2768.634\n",
      "Ep:131, loss:0.00001, loss_test:0.03648, lr:7.86e-03, fs:0.90110 (r=0.828,p=0.988),  time:21.139, tt:2790.401\n",
      "Ep:132, loss:0.00001, loss_test:0.03699, lr:7.78e-03, fs:0.91398 (r=0.859,p=0.977),  time:21.128, tt:2809.988\n",
      "Ep:133, loss:0.00001, loss_test:0.03689, lr:7.70e-03, fs:0.90323 (r=0.848,p=0.966),  time:21.140, tt:2832.826\n",
      "Ep:134, loss:0.00001, loss_test:0.03694, lr:7.62e-03, fs:0.90110 (r=0.828,p=0.988),  time:21.155, tt:2855.893\n",
      "Ep:135, loss:0.00001, loss_test:0.03583, lr:7.55e-03, fs:0.93122 (r=0.889,p=0.978),  time:21.149, tt:2876.300\n",
      "Ep:136, loss:0.00001, loss_test:0.03664, lr:7.47e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.141, tt:2896.271\n",
      "Ep:137, loss:0.00001, loss_test:0.03763, lr:7.40e-03, fs:0.89730 (r=0.838,p=0.965),  time:21.156, tt:2919.542\n",
      "Ep:138, loss:0.00001, loss_test:0.03565, lr:7.32e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.158, tt:2940.974\n",
      "Ep:139, loss:0.00001, loss_test:0.03824, lr:7.25e-03, fs:0.90710 (r=0.838,p=0.988),  time:21.166, tt:2963.225\n",
      "Ep:140, loss:0.00001, loss_test:0.03594, lr:7.18e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.161, tt:2983.720\n",
      "Ep:141, loss:0.00001, loss_test:0.03722, lr:7.11e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.165, tt:3005.425\n",
      "Ep:142, loss:0.00001, loss_test:0.03602, lr:7.03e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.172, tt:3027.612\n",
      "Ep:143, loss:0.00001, loss_test:0.03747, lr:6.96e-03, fs:0.90710 (r=0.838,p=0.988),  time:21.179, tt:3049.844\n",
      "Ep:144, loss:0.00001, loss_test:0.03583, lr:6.89e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.179, tt:3070.968\n",
      "Ep:145, loss:0.00001, loss_test:0.03765, lr:6.83e-03, fs:0.90710 (r=0.838,p=0.988),  time:21.174, tt:3091.361\n",
      "Ep:146, loss:0.00001, loss_test:0.03593, lr:6.76e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.179, tt:3113.272\n",
      "Ep:147, loss:0.00001, loss_test:0.03680, lr:6.69e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.197, tt:3137.094\n",
      "Ep:148, loss:0.00001, loss_test:0.03551, lr:6.62e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.207, tt:3159.786\n",
      "Ep:149, loss:0.00001, loss_test:0.03780, lr:6.56e-03, fs:0.91304 (r=0.848,p=0.988),  time:21.204, tt:3180.602\n",
      "Ep:150, loss:0.00001, loss_test:0.03628, lr:6.49e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.218, tt:3203.985\n",
      "Ep:151, loss:0.00001, loss_test:0.03745, lr:6.43e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.234, tt:3227.533\n",
      "Ep:152, loss:0.00001, loss_test:0.03699, lr:6.36e-03, fs:0.90710 (r=0.838,p=0.988),  time:21.212, tt:3245.432\n",
      "Ep:153, loss:0.00001, loss_test:0.03686, lr:6.30e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.193, tt:3263.701\n",
      "Ep:154, loss:0.00001, loss_test:0.03655, lr:6.24e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.192, tt:3284.811\n",
      "Ep:155, loss:0.00001, loss_test:0.03656, lr:6.17e-03, fs:0.90217 (r=0.838,p=0.976),  time:21.205, tt:3308.054\n",
      "Ep:156, loss:0.00001, loss_test:0.03702, lr:6.11e-03, fs:0.90811 (r=0.848,p=0.977),  time:21.199, tt:3328.254\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n",
      "Values to load\n",
      "dataset_name=openml_203ds_datasets_matching\n",
      "neg_sample= 2\n",
      "strategy= isolation\n",
      "create_new_split= False\n",
      "word_embedding_encoding= FASTTEXT2_SHORT\n",
      "cross_v= 9\n",
      "Dataset splits loaded\n",
      "Train samples: 1776 Test samples: 198\n",
      "Train positive samples: 888 Test positive samples: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-feature graph from datasets loaded\n",
      "Start of training...NN Fasttext2_364_364_364 Loss CosineEmbeddingLoss Split 1024: \n",
      "Ep:0, loss:0.00027, loss_test:0.13442, lr:1.00e-02, fs:0.65734 (r=0.949,p=0.503),  time:21.117, tt:21.117\n",
      "##########Best model found so far##########\n",
      "Ep:1, loss:0.00027, loss_test:0.12880, lr:1.00e-02, fs:0.66418 (r=0.899,p=0.527),  time:21.709, tt:43.418\n",
      "##########Best model found so far##########\n",
      "Ep:2, loss:0.00026, loss_test:0.12341, lr:1.00e-02, fs:0.69076 (r=0.869,p=0.573),  time:21.756, tt:65.267\n",
      "##########Best model found so far##########\n",
      "Ep:3, loss:0.00025, loss_test:0.12097, lr:1.00e-02, fs:0.67500 (r=0.818,p=0.574),  time:21.859, tt:87.436\n",
      "Ep:4, loss:0.00025, loss_test:0.11872, lr:1.00e-02, fs:0.68880 (r=0.838,p=0.585),  time:21.969, tt:109.843\n",
      "Ep:5, loss:0.00024, loss_test:0.11817, lr:1.00e-02, fs:0.69672 (r=0.859,p=0.586),  time:21.974, tt:131.846\n",
      "##########Best model found so far##########\n",
      "Ep:6, loss:0.00023, loss_test:0.11421, lr:1.00e-02, fs:0.70638 (r=0.838,p=0.610),  time:22.083, tt:154.583\n",
      "##########Best model found so far##########\n",
      "Ep:7, loss:0.00022, loss_test:0.10877, lr:1.00e-02, fs:0.69725 (r=0.768,p=0.639),  time:21.996, tt:175.969\n",
      "Ep:8, loss:0.00021, loss_test:0.10630, lr:1.00e-02, fs:0.71028 (r=0.768,p=0.661),  time:21.781, tt:196.032\n",
      "##########Best model found so far##########\n",
      "Ep:9, loss:0.00020, loss_test:0.10611, lr:1.00e-02, fs:0.70968 (r=0.778,p=0.653),  time:21.937, tt:219.373\n",
      "Ep:10, loss:0.00019, loss_test:0.10478, lr:1.00e-02, fs:0.71233 (r=0.788,p=0.650),  time:21.869, tt:240.561\n",
      "##########Best model found so far##########\n",
      "Ep:11, loss:0.00019, loss_test:0.10141, lr:1.00e-02, fs:0.72986 (r=0.778,p=0.688),  time:21.602, tt:259.221\n",
      "##########Best model found so far##########\n",
      "Ep:12, loss:0.00018, loss_test:0.09826, lr:1.00e-02, fs:0.75122 (r=0.778,p=0.726),  time:21.299, tt:276.881\n",
      "##########Best model found so far##########\n",
      "Ep:13, loss:0.00017, loss_test:0.09659, lr:1.00e-02, fs:0.76098 (r=0.788,p=0.736),  time:20.834, tt:291.683\n",
      "##########Best model found so far##########\n",
      "Ep:14, loss:0.00017, loss_test:0.09580, lr:1.00e-02, fs:0.77228 (r=0.788,p=0.757),  time:20.410, tt:306.156\n",
      "##########Best model found so far##########\n",
      "Ep:15, loss:0.00016, loss_test:0.09515, lr:1.00e-02, fs:0.77451 (r=0.798,p=0.752),  time:20.083, tt:321.325\n",
      "##########Best model found so far##########\n",
      "Ep:16, loss:0.00015, loss_test:0.09298, lr:1.00e-02, fs:0.78641 (r=0.818,p=0.757),  time:19.767, tt:336.042\n",
      "##########Best model found so far##########\n",
      "Ep:17, loss:0.00015, loss_test:0.09057, lr:1.00e-02, fs:0.80198 (r=0.818,p=0.786),  time:19.487, tt:350.762\n",
      "##########Best model found so far##########\n",
      "Ep:18, loss:0.00014, loss_test:0.09012, lr:1.00e-02, fs:0.79412 (r=0.818,p=0.771),  time:19.203, tt:364.853\n",
      "Ep:19, loss:0.00014, loss_test:0.08740, lr:1.00e-02, fs:0.79024 (r=0.818,p=0.764),  time:18.998, tt:379.964\n",
      "Ep:20, loss:0.00013, loss_test:0.08664, lr:1.00e-02, fs:0.78788 (r=0.788,p=0.788),  time:18.790, tt:394.598\n",
      "Ep:21, loss:0.00013, loss_test:0.08522, lr:1.00e-02, fs:0.79000 (r=0.798,p=0.782),  time:18.597, tt:409.143\n",
      "Ep:22, loss:0.00012, loss_test:0.08417, lr:1.00e-02, fs:0.78173 (r=0.778,p=0.786),  time:18.415, tt:423.534\n",
      "Ep:23, loss:0.00012, loss_test:0.08360, lr:1.00e-02, fs:0.79602 (r=0.808,p=0.784),  time:18.241, tt:437.794\n",
      "Ep:24, loss:0.00011, loss_test:0.08274, lr:1.00e-02, fs:0.79167 (r=0.768,p=0.817),  time:18.107, tt:452.666\n",
      "Ep:25, loss:0.00011, loss_test:0.08123, lr:1.00e-02, fs:0.80000 (r=0.808,p=0.792),  time:17.980, tt:467.488\n",
      "Ep:26, loss:0.00010, loss_test:0.07979, lr:1.00e-02, fs:0.79381 (r=0.778,p=0.811),  time:17.836, tt:481.571\n",
      "Ep:27, loss:0.00010, loss_test:0.08042, lr:1.00e-02, fs:0.80808 (r=0.808,p=0.808),  time:17.722, tt:496.221\n",
      "##########Best model found so far##########\n",
      "Ep:28, loss:0.00009, loss_test:0.07856, lr:1.00e-02, fs:0.81865 (r=0.798,p=0.840),  time:17.661, tt:512.159\n",
      "##########Best model found so far##########\n",
      "Ep:29, loss:0.00009, loss_test:0.07842, lr:1.00e-02, fs:0.79581 (r=0.768,p=0.826),  time:17.550, tt:526.499\n",
      "Ep:30, loss:0.00009, loss_test:0.07460, lr:1.00e-02, fs:0.81250 (r=0.788,p=0.839),  time:17.440, tt:540.646\n",
      "Ep:31, loss:0.00008, loss_test:0.07519, lr:1.00e-02, fs:0.80628 (r=0.778,p=0.837),  time:17.346, tt:555.071\n",
      "Ep:32, loss:0.00008, loss_test:0.07333, lr:1.00e-02, fs:0.81675 (r=0.788,p=0.848),  time:17.269, tt:569.888\n",
      "Ep:33, loss:0.00008, loss_test:0.07394, lr:1.00e-02, fs:0.81026 (r=0.798,p=0.823),  time:17.194, tt:584.588\n",
      "Ep:34, loss:0.00008, loss_test:0.07208, lr:1.00e-02, fs:0.81768 (r=0.747,p=0.902),  time:17.122, tt:599.279\n",
      "Ep:35, loss:0.00007, loss_test:0.07298, lr:1.00e-02, fs:0.80412 (r=0.788,p=0.821),  time:17.058, tt:614.076\n",
      "Ep:36, loss:0.00007, loss_test:0.06960, lr:1.00e-02, fs:0.84783 (r=0.788,p=0.918),  time:16.995, tt:628.801\n",
      "##########Best model found so far##########\n",
      "Ep:37, loss:0.00007, loss_test:0.07245, lr:1.00e-02, fs:0.81915 (r=0.778,p=0.865),  time:16.931, tt:643.371\n",
      "Ep:38, loss:0.00007, loss_test:0.06871, lr:1.00e-02, fs:0.83243 (r=0.778,p=0.895),  time:16.876, tt:658.155\n",
      "Ep:39, loss:0.00006, loss_test:0.06941, lr:1.00e-02, fs:0.84324 (r=0.788,p=0.907),  time:16.811, tt:672.437\n",
      "Ep:40, loss:0.00006, loss_test:0.06892, lr:1.00e-02, fs:0.81720 (r=0.768,p=0.874),  time:16.748, tt:686.651\n",
      "Ep:41, loss:0.00006, loss_test:0.06856, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:16.699, tt:701.368\n",
      "Ep:42, loss:0.00006, loss_test:0.06573, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:16.661, tt:716.434\n",
      "Ep:43, loss:0.00006, loss_test:0.07115, lr:1.00e-02, fs:0.82796 (r=0.778,p=0.885),  time:16.646, tt:732.411\n",
      "Ep:44, loss:0.00005, loss_test:0.06556, lr:1.00e-02, fs:0.82682 (r=0.747,p=0.925),  time:16.599, tt:746.975\n",
      "Ep:45, loss:0.00005, loss_test:0.06731, lr:1.00e-02, fs:0.83871 (r=0.788,p=0.897),  time:16.570, tt:762.214\n",
      "Ep:46, loss:0.00005, loss_test:0.06653, lr:1.00e-02, fs:0.83333 (r=0.758,p=0.926),  time:16.539, tt:777.334\n",
      "Ep:47, loss:0.00005, loss_test:0.06541, lr:1.00e-02, fs:0.84153 (r=0.778,p=0.917),  time:16.499, tt:791.930\n",
      "Ep:48, loss:0.00005, loss_test:0.06592, lr:9.90e-03, fs:0.83516 (r=0.768,p=0.916),  time:16.485, tt:807.754\n",
      "Ep:49, loss:0.00005, loss_test:0.06545, lr:9.80e-03, fs:0.83516 (r=0.768,p=0.916),  time:16.443, tt:822.170\n",
      "Ep:50, loss:0.00004, loss_test:0.06469, lr:9.70e-03, fs:0.84153 (r=0.778,p=0.917),  time:16.418, tt:837.322\n",
      "Ep:51, loss:0.00004, loss_test:0.06450, lr:9.61e-03, fs:0.83243 (r=0.778,p=0.895),  time:16.404, tt:853.020\n",
      "Ep:52, loss:0.00004, loss_test:0.06553, lr:9.51e-03, fs:0.80000 (r=0.707,p=0.921),  time:16.403, tt:869.375\n",
      "Ep:53, loss:0.00004, loss_test:0.06623, lr:9.41e-03, fs:0.81522 (r=0.758,p=0.882),  time:16.407, tt:885.995\n",
      "Ep:54, loss:0.00004, loss_test:0.06485, lr:9.32e-03, fs:0.82222 (r=0.747,p=0.914),  time:16.384, tt:901.095\n",
      "Ep:55, loss:0.00004, loss_test:0.06442, lr:9.23e-03, fs:0.82873 (r=0.758,p=0.915),  time:16.364, tt:916.403\n",
      "Ep:56, loss:0.00004, loss_test:0.06459, lr:9.14e-03, fs:0.83978 (r=0.768,p=0.927),  time:16.332, tt:930.921\n",
      "Ep:57, loss:0.00004, loss_test:0.06433, lr:9.04e-03, fs:0.81818 (r=0.727,p=0.935),  time:16.322, tt:946.674\n",
      "Ep:58, loss:0.00004, loss_test:0.06758, lr:8.95e-03, fs:0.82162 (r=0.768,p=0.884),  time:16.326, tt:963.244\n",
      "Ep:59, loss:0.00004, loss_test:0.06396, lr:8.86e-03, fs:0.80460 (r=0.707,p=0.933),  time:16.326, tt:979.532\n",
      "Ep:60, loss:0.00004, loss_test:0.06569, lr:8.78e-03, fs:0.80874 (r=0.747,p=0.881),  time:16.310, tt:994.886\n",
      "Ep:61, loss:0.00004, loss_test:0.06446, lr:8.69e-03, fs:0.80460 (r=0.707,p=0.933),  time:16.290, tt:1009.976\n",
      "Ep:62, loss:0.00004, loss_test:0.06649, lr:8.60e-03, fs:0.79775 (r=0.717,p=0.899),  time:16.261, tt:1024.443\n",
      "Ep:63, loss:0.00003, loss_test:0.06410, lr:8.51e-03, fs:0.82486 (r=0.737,p=0.936),  time:16.244, tt:1039.633\n",
      "Ep:64, loss:0.00003, loss_test:0.06632, lr:8.43e-03, fs:0.83978 (r=0.768,p=0.927),  time:16.223, tt:1054.526\n",
      "Ep:65, loss:0.00003, loss_test:0.06492, lr:8.35e-03, fs:0.82022 (r=0.737,p=0.924),  time:16.205, tt:1069.525\n",
      "Ep:66, loss:0.00003, loss_test:0.06366, lr:8.26e-03, fs:0.82486 (r=0.737,p=0.936),  time:16.185, tt:1084.421\n",
      "Ep:67, loss:0.00003, loss_test:0.06302, lr:8.18e-03, fs:0.80899 (r=0.727,p=0.911),  time:16.182, tt:1100.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:68, loss:0.00003, loss_test:0.06439, lr:8.10e-03, fs:0.81143 (r=0.717,p=0.934),  time:16.156, tt:1114.770\n",
      "Ep:69, loss:0.00003, loss_test:0.06390, lr:8.02e-03, fs:0.80925 (r=0.707,p=0.946),  time:16.142, tt:1129.925\n",
      "Ep:70, loss:0.00003, loss_test:0.06400, lr:7.94e-03, fs:0.80226 (r=0.717,p=0.910),  time:16.128, tt:1145.079\n",
      "Ep:71, loss:0.00003, loss_test:0.06381, lr:7.86e-03, fs:0.80925 (r=0.707,p=0.946),  time:16.102, tt:1159.379\n",
      "Ep:72, loss:0.00003, loss_test:0.06420, lr:7.78e-03, fs:0.80925 (r=0.707,p=0.946),  time:16.084, tt:1174.143\n",
      "Ep:73, loss:0.00003, loss_test:0.06360, lr:7.70e-03, fs:0.81143 (r=0.717,p=0.934),  time:16.066, tt:1188.867\n",
      "Ep:74, loss:0.00003, loss_test:0.06447, lr:7.62e-03, fs:0.80925 (r=0.707,p=0.946),  time:16.052, tt:1203.873\n",
      "Ep:75, loss:0.00003, loss_test:0.06435, lr:7.55e-03, fs:0.80460 (r=0.707,p=0.933),  time:16.042, tt:1219.203\n",
      "Ep:76, loss:0.00003, loss_test:0.06391, lr:7.47e-03, fs:0.81143 (r=0.717,p=0.934),  time:16.027, tt:1234.051\n",
      "Ep:77, loss:0.00003, loss_test:0.06395, lr:7.40e-03, fs:0.80925 (r=0.707,p=0.946),  time:16.013, tt:1249.021\n",
      "Ep:78, loss:0.00003, loss_test:0.06388, lr:7.32e-03, fs:0.80682 (r=0.717,p=0.922),  time:15.999, tt:1263.921\n",
      "Ep:79, loss:0.00003, loss_test:0.06386, lr:7.25e-03, fs:0.80925 (r=0.707,p=0.946),  time:15.979, tt:1278.317\n",
      "Ep:80, loss:0.00003, loss_test:0.06329, lr:7.18e-03, fs:0.81143 (r=0.717,p=0.934),  time:15.969, tt:1293.480\n",
      "Ep:81, loss:0.00003, loss_test:0.06475, lr:7.11e-03, fs:0.80925 (r=0.707,p=0.946),  time:15.952, tt:1308.036\n",
      "Ep:82, loss:0.00003, loss_test:0.06511, lr:7.03e-03, fs:0.80460 (r=0.707,p=0.933),  time:15.938, tt:1322.813\n",
      "Ep:83, loss:0.00003, loss_test:0.06529, lr:6.96e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.922, tt:1337.409\n",
      "Ep:84, loss:0.00002, loss_test:0.06377, lr:6.89e-03, fs:0.80925 (r=0.707,p=0.946),  time:15.912, tt:1352.500\n",
      "Ep:85, loss:0.00002, loss_test:0.06450, lr:6.83e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.901, tt:1367.499\n",
      "Ep:86, loss:0.00002, loss_test:0.06443, lr:6.76e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.887, tt:1382.146\n",
      "Ep:87, loss:0.00002, loss_test:0.06418, lr:6.69e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.888, tt:1398.118\n",
      "Ep:88, loss:0.00002, loss_test:0.06538, lr:6.62e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.874, tt:1412.754\n",
      "Ep:89, loss:0.00002, loss_test:0.06471, lr:6.56e-03, fs:0.81143 (r=0.717,p=0.934),  time:15.872, tt:1428.493\n",
      "Ep:90, loss:0.00002, loss_test:0.06475, lr:6.49e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.860, tt:1443.269\n",
      "Ep:91, loss:0.00002, loss_test:0.06366, lr:6.43e-03, fs:0.81609 (r=0.717,p=0.947),  time:15.858, tt:1458.922\n",
      "Ep:92, loss:0.00002, loss_test:0.06607, lr:6.36e-03, fs:0.80925 (r=0.707,p=0.946),  time:15.859, tt:1474.901\n",
      "Ep:93, loss:0.00002, loss_test:0.06414, lr:6.30e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.844, tt:1489.361\n",
      "Ep:94, loss:0.00002, loss_test:0.06542, lr:6.24e-03, fs:0.80460 (r=0.707,p=0.933),  time:15.843, tt:1505.064\n",
      "Ep:95, loss:0.00002, loss_test:0.06456, lr:6.17e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.835, tt:1520.135\n",
      "Ep:96, loss:0.00002, loss_test:0.06633, lr:6.11e-03, fs:0.80233 (r=0.697,p=0.945),  time:15.832, tt:1535.708\n",
      "Ep:97, loss:0.00002, loss_test:0.06419, lr:6.05e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.838, tt:1552.170\n",
      "Ep:98, loss:0.00002, loss_test:0.06636, lr:5.99e-03, fs:0.80233 (r=0.697,p=0.945),  time:15.825, tt:1566.661\n",
      "Ep:99, loss:0.00002, loss_test:0.06437, lr:5.93e-03, fs:0.80925 (r=0.707,p=0.946),  time:15.814, tt:1581.440\n",
      "Ep:100, loss:0.00002, loss_test:0.06540, lr:5.87e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.807, tt:1596.502\n",
      "Ep:101, loss:0.00002, loss_test:0.06380, lr:5.81e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.791, tt:1610.654\n",
      "Ep:102, loss:0.00002, loss_test:0.06461, lr:5.75e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.778, tt:1625.185\n",
      "Ep:103, loss:0.00002, loss_test:0.06517, lr:5.70e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.769, tt:1640.001\n",
      "Ep:104, loss:0.00002, loss_test:0.06485, lr:5.64e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.768, tt:1655.624\n",
      "Ep:105, loss:0.00002, loss_test:0.06473, lr:5.58e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.762, tt:1670.722\n",
      "Ep:106, loss:0.00002, loss_test:0.06505, lr:5.53e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.750, tt:1685.276\n",
      "Ep:107, loss:0.00002, loss_test:0.06468, lr:5.47e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.743, tt:1700.223\n",
      "Ep:108, loss:0.00002, loss_test:0.06484, lr:5.42e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.733, tt:1714.859\n",
      "Ep:109, loss:0.00002, loss_test:0.06492, lr:5.36e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.724, tt:1729.622\n",
      "Ep:110, loss:0.00002, loss_test:0.06479, lr:5.31e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.716, tt:1744.479\n",
      "Ep:111, loss:0.00002, loss_test:0.06655, lr:5.26e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.705, tt:1758.910\n",
      "Ep:112, loss:0.00002, loss_test:0.06517, lr:5.20e-03, fs:0.81395 (r=0.707,p=0.959),  time:15.693, tt:1773.345\n",
      "Ep:113, loss:0.00002, loss_test:0.06712, lr:5.15e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.678, tt:1787.322\n",
      "Ep:114, loss:0.00002, loss_test:0.06503, lr:5.10e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.675, tt:1802.637\n",
      "Ep:115, loss:0.00002, loss_test:0.06659, lr:5.05e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.663, tt:1816.881\n",
      "Ep:116, loss:0.00002, loss_test:0.06495, lr:5.00e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.653, tt:1831.369\n",
      "Ep:117, loss:0.00002, loss_test:0.06646, lr:4.95e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.643, tt:1845.849\n",
      "Ep:118, loss:0.00002, loss_test:0.06506, lr:4.90e-03, fs:0.80233 (r=0.697,p=0.945),  time:15.634, tt:1860.424\n",
      "Ep:119, loss:0.00002, loss_test:0.06690, lr:4.85e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.625, tt:1874.951\n",
      "Ep:120, loss:0.00002, loss_test:0.06591, lr:4.80e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.618, tt:1889.770\n",
      "Ep:121, loss:0.00002, loss_test:0.06699, lr:4.75e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.610, tt:1904.415\n",
      "Ep:122, loss:0.00002, loss_test:0.06603, lr:4.71e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.604, tt:1919.303\n",
      "Ep:123, loss:0.00002, loss_test:0.06673, lr:4.66e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.599, tt:1934.280\n",
      "Ep:124, loss:0.00001, loss_test:0.06632, lr:4.61e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.594, tt:1949.207\n",
      "Ep:125, loss:0.00001, loss_test:0.06615, lr:4.57e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.585, tt:1963.662\n",
      "Ep:126, loss:0.00001, loss_test:0.06701, lr:4.52e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.575, tt:1978.040\n",
      "Ep:127, loss:0.00001, loss_test:0.06574, lr:4.48e-03, fs:0.80702 (r=0.697,p=0.958),  time:15.568, tt:1992.766\n",
      "Ep:128, loss:0.00001, loss_test:0.06784, lr:4.43e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.569, tt:2008.453\n",
      "Ep:129, loss:0.00001, loss_test:0.06646, lr:4.39e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.559, tt:2022.657\n",
      "Ep:130, loss:0.00001, loss_test:0.06709, lr:4.34e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.553, tt:2037.433\n",
      "Ep:131, loss:0.00001, loss_test:0.06819, lr:4.30e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.556, tt:2053.359\n",
      "Ep:132, loss:0.00001, loss_test:0.06661, lr:4.26e-03, fs:0.81657 (r=0.697,p=0.986),  time:15.548, tt:2067.848\n",
      "Ep:133, loss:0.00001, loss_test:0.06669, lr:4.21e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.542, tt:2082.684\n",
      "Ep:134, loss:0.00001, loss_test:0.06757, lr:4.17e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.540, tt:2097.842\n",
      "Ep:135, loss:0.00001, loss_test:0.06593, lr:4.13e-03, fs:0.81176 (r=0.697,p=0.972),  time:15.533, tt:2112.477\n",
      "Ep:136, loss:0.00001, loss_test:0.06806, lr:4.09e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.525, tt:2126.858\n",
      "Ep:137, loss:0.00001, loss_test:0.06717, lr:4.05e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.523, tt:2142.153\n",
      "Ep:138, loss:0.00001, loss_test:0.06700, lr:4.01e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.514, tt:2156.503\n",
      "Ep:139, loss:0.00001, loss_test:0.06731, lr:3.97e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.513, tt:2171.758\n",
      "Ep:140, loss:0.00001, loss_test:0.06715, lr:3.93e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.508, tt:2186.682\n",
      "Ep:141, loss:0.00001, loss_test:0.06726, lr:3.89e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.503, tt:2201.391\n",
      "Ep:142, loss:0.00001, loss_test:0.06686, lr:3.85e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.499, tt:2216.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:143, loss:0.00001, loss_test:0.06759, lr:3.81e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.494, tt:2231.195\n",
      "Ep:144, loss:0.00001, loss_test:0.06671, lr:3.77e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.488, tt:2245.712\n",
      "Ep:145, loss:0.00001, loss_test:0.06646, lr:3.73e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.486, tt:2260.950\n",
      "Ep:146, loss:0.00001, loss_test:0.06735, lr:3.70e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.483, tt:2275.972\n",
      "Ep:147, loss:0.00001, loss_test:0.06687, lr:3.66e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.479, tt:2290.836\n",
      "Ep:148, loss:0.00001, loss_test:0.06699, lr:3.62e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.476, tt:2305.921\n",
      "Ep:149, loss:0.00001, loss_test:0.06720, lr:3.59e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.472, tt:2320.777\n",
      "Ep:150, loss:0.00001, loss_test:0.06648, lr:3.55e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.466, tt:2335.367\n",
      "Ep:151, loss:0.00001, loss_test:0.06729, lr:3.52e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.462, tt:2350.225\n",
      "Ep:152, loss:0.00001, loss_test:0.06726, lr:3.48e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.457, tt:2364.952\n",
      "Ep:153, loss:0.00001, loss_test:0.06655, lr:3.45e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.434, tt:2376.836\n",
      "Ep:154, loss:0.00001, loss_test:0.06696, lr:3.41e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.412, tt:2388.833\n",
      "Ep:155, loss:0.00001, loss_test:0.06687, lr:3.38e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.389, tt:2400.692\n",
      "Ep:156, loss:0.00001, loss_test:0.06720, lr:3.34e-03, fs:0.82143 (r=0.697,p=1.000),  time:15.356, tt:2410.944\n",
      "Model and results saved\n",
      "Saving best model...\n",
      "Model and results saved\n"
     ]
    }
   ],
   "source": [
    "cv_number=\"9-10\"\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_728_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)\n",
    "\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_NEW\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,155,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_CLEAN\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,156,cv_number,2,False)\n",
    "\n",
    "step3_gcnsm.load_env(ds_name=dataset_name,ns=2,st=\"isolation\",sp=False,we=\"FASTTEXT2_SHORT\")\n",
    "training_object = gcn_training.Training()\n",
    "training_object.set_training(\n",
    "            net_name= \"Fasttext2_364_364_364\",  #_of_option for NN architecture\n",
    "            batch_splits=1024 ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "            lr=1e-2 , #learning rate for training (e.g. 1e-3 )\n",
    "            loss_name=gcn_loss.get_option_name(1), #_of_option for loss \n",
    "            loss_parameters=\"0.7+mean\" ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "            optimizer_name=\"sgd\" ) #adam or sgd, default adam\n",
    "cross_validation(training_object,157,cv_number,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train new model and specify parameters\n",
    "# training_object = gcn_training.Training()\n",
    "# training_object.set_training(\n",
    "#             net_name= gcn_nn.get_option_name(),  #_of_option for NN architecture\n",
    "#             batch_splits= ,#_of_sets(this will (give dataset / batch_splits) size of batch\n",
    "#             lr= , #learning rate for training (e.g. 1e-3 )\n",
    "#             loss_name=gcn_loss.get_option_name(), #_of_option for loss \n",
    "#             loss_parameters= ,#loss function parameters separated by '+' e.g. for cosine and contrastive \"0.0+mean\"\n",
    "#             optimizer_name= ) #adam or sgd, default adam\n",
    "\n",
    "##cross_validation(training_object,num_of_training_iterations_per_fold,nsample[opt],create_split[opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results <br>\n",
    "\n",
    "<p>This will plot charts of loss/accuracy for all the results that match the parameters options under the /results folder</p>\n",
    "\n",
    "#### Parameters options\n",
    "\n",
    "<p> Choose one of each and pass it to the corresponding plot function in the following order:\n",
    "\n",
    "<b>1) neg_sample</b> = [1,2,3,4...etc] <br>\n",
    "<b>2) db_name</b> = [\"openml_203ds_datasets_matching\"] <br>\n",
    "<b>3) strategy</b> = [\"isolation\",\"random\"] <br>\n",
    "<b>4) archi</b> = [\"Fasttext_150\",\"Fasttext_300\",\"Bert_300\",\"Bert_768\"] <br>\n",
    "<b>5) optimizer</b> = [\"adam\",\"sgd\"] <br>\n",
    "<b>6) loss_functions</b> = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"] <br>\n",
    "\n",
    "#### Type of chart\n",
    "<b>plot_by_loss_parameters:</b> groups in one chart the different results for loss functions parameters (margin) <br>\n",
    "<b>plot_by_split </b>: groups in one chart the different results for size of batch splits <br>\n",
    "<b>plot_cv </b>: plot the result of cross validation runs that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"random\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [2]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [4]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [8]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [16]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = [\"adam\",\"sgd\"]\n",
    "samp = [24]\n",
    "arch = [\"Fasttext_150\",\"Fasttext_300\",\"Fasttext2_150\",\"Fasttext2_364\",\"FasttextSum_150\",\"FasttextSum_364\",\"Bert_300\",\"Bert_768\",\"Bert2_300\",\"Bert2_768\"]\n",
    "loss = [\"ContrastiveLoss\",\"CosineEmbeddingLoss\"]\n",
    "for a in arch:\n",
    "    for o in opti:\n",
    "        for s in samp:\n",
    "            for l in loss:\n",
    "                plot.plot_by_loss_parameters(s,\"openml_203ds_datasets_matching\",\"isolation\",a,o,l)\n",
    "        #         plot.plot_by_split(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")\n",
    "        #         plot.plot_cv(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"random\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(2,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(4,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"adam\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(8,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"FasttextSum_150\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cv_3(16,\"openml_203ds_datasets_matching\",\"isolation\",\"Fasttext2_364\",\"sgd\",\"ContrastiveLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
