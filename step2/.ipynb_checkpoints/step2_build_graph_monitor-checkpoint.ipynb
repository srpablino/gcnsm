{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset and plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "\n",
    "def read_dataset(path,drop_columns=None,keep_columns=None):\n",
    "    #get rid of useless columns\n",
    "    csv_data = pd.read_csv(path,sep=\"~\")\n",
    "    \n",
    "    if keep_columns != None:\n",
    "        #keep only these columns\n",
    "        return csv_data.filter(items=keep_columns)\n",
    "    \n",
    "    if drop_columns!= None:\n",
    "        #drop these and keep the rest\n",
    "        return csv_data.drop(drop_columns, axis=1)\n",
    "    \n",
    "    #finally, didn't drop or filter any column\n",
    "    return csv_data     \n",
    "\n",
    "def plot_graph(g,ds_nodes=[],attribute_nodes=[],feat_nodes=[],lit_nodes=[]):\n",
    "    pos=nx.spring_layout(g)    \n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=ds_nodes,node_color=\"blue\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=attribute_nodes,node_color=\"green\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=feat_nodes,node_color=\"grey\",node_size=900)\n",
    "    nx.draw_networkx_nodes(g,pos,nodelist=lit_nodes,node_color=\"red\",node_size=900)\n",
    "\n",
    "    nx.draw_networkx_edges(g,pos,width=3)\n",
    "    nx.draw_networkx_labels(g,pos,font_size=8)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph  construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_ds_id(data):\n",
    "    return \"DS_\"+data\n",
    "def code_attr_id(data,parent):\n",
    "    return data+\"|\"+parent\n",
    "def code_feat_id(data,parent):\n",
    "    return data+\"|\"+parent\n",
    "def code_literal_id(data,parent):\n",
    "    return \"literal_\"+data+\"|\"+parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_dataset_short(datasets,g=None,wem=\"fasttext\",instances=0):\n",
    "    if g == None:\n",
    "        g = nx.Graph()\n",
    "    \n",
    "    #create nodes and edges at datasetLevel\n",
    "    features = datasets.columns[2:]\n",
    "    \n",
    "    if instances==0:\n",
    "        number_instances = len(datasets)\n",
    "    else:\n",
    "        number_instances = instances\n",
    "    \n",
    "    for r in range(number_instances): \n",
    "        #node id is the openML id which is in the first column\n",
    "#         dataset_id = code_ds_id(str(datasets.iloc[r][0]))\n",
    "        dataset_id = datasets.iloc[r][0]\n",
    "        g.add_node(dataset_id,vector=word_embedding(\"dataset|\"+datasets.iloc[r][1] ,wem),tipo=\"attribute\")\n",
    "        row = datasets.iloc[r][2:]\n",
    "        \n",
    "        if instances == 0:\n",
    "            number_features = len(features)\n",
    "        else:\n",
    "            number_features = min(instances,len(features))\n",
    "            \n",
    "        for i in range (number_features):\n",
    "            feature_dataset_id = code_feat_id(features[i],dataset_id)\n",
    "#             literal_dataset_id = code_literal_id(str(i),dataset_id)\n",
    "            g.add_node(feature_dataset_id,vector=word_embedding(features[i]+\"|\"+str(row[i]) ,wem),tipo=\"feature dataset\")\n",
    "#             g.add_node(literal_dataset_id,vector=word_embedding(row[i],wem),tipo=\"literal dataset\")\n",
    "            g.add_edge(dataset_id,feature_dataset_id)\n",
    "#             g.add_edge(feature_dataset_id,literal_dataset_id)\n",
    "            \n",
    "    return g\n",
    "\n",
    "\n",
    "def graph_attribute_short(datasets,g=None,wem=\"fasttext\",instances=0):\n",
    "    if g == None:\n",
    "        g = nx.Graph()\n",
    "        \n",
    "    #create nodes and edges at datasetLevel\n",
    "    features = datasets.columns[2:]\n",
    "    \n",
    "    if instances==0:\n",
    "        number_instances = len(datasets)\n",
    "    else:\n",
    "        number_instances = min (instances,len(datasets))\n",
    "    \n",
    "    for r in range(number_instances): \n",
    "        #node id is the openML id which is in the first column\n",
    "        #attr name is the 2nd column\n",
    "#         dataset_id = code_ds_id(str(datasets.iloc[r][0]))\n",
    "        dataset_id = datasets.iloc[r][0]\n",
    "        attribute_id = code_ds_id(dataset_id+\"//\"+datasets.iloc[r][1])\n",
    "        row = datasets.iloc[r][2:]\n",
    "        \n",
    "        g.add_node(attribute_id,vector=word_embedding(\"attribute|\"+datasets.iloc[r][1],wem),tipo=\"dataset\")\n",
    "        \n",
    "        #relation of dataset and an attribute\n",
    "        g.add_edge(dataset_id,attribute_id)\n",
    "        \n",
    "        if instances == 0:\n",
    "            number_features = len(features)\n",
    "        else:\n",
    "            number_features = min (instances,len(features))\n",
    "            \n",
    "        for i in range (number_features):\n",
    "            feature_attribute_id = code_feat_id(features[i],attribute_id)\n",
    "#             literal_dataset_id = code_literal_id(str(i),attribute_id)\n",
    "            g.add_node(feature_attribute_id,vector=word_embedding(features[i]+\"|\"+str(row[i]),wem),tipo=\"feature attribute\")\n",
    "#             g.add_node(literal_dataset_id,vector=word_embedding(row[i],wem),tipo=\"literal attribute\")\n",
    "            g.add_edge(attribute_id,feature_attribute_id)\n",
    "#             g.add_edge(feature_attribute_id,literal_dataset_id)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if input is number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    #Returns True is string is a number.\n",
    "    try:\n",
    "        float(s)\n",
    "        if float(s) == float(\"INF\") or float(s) == float(\"NAN\") or s == \"NAN\" or s == \"nan\":\n",
    "            return False\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From numbers to bin tensor vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import bitstring\n",
    "import torch\n",
    "#clean\n",
    "def num2vec(num):\n",
    "    rep_sc = str('{:.11E}'.format(num))\n",
    "    print(rep_sc)\n",
    "    dec_part = int(rep_sc.split(\"E\")[0].replace(\".\",\"\"))\n",
    "    c = 1\n",
    "    if dec_part <0:\n",
    "        c = -1\n",
    "    dec_part = abs(dec_part)\n",
    "    \n",
    "    exp_part = int(rep_sc.split(\"E\")[1])\n",
    "    if exp_part <0:\n",
    "        exp_pos = 0\n",
    "        exp_neg = exp_part\n",
    "    else:\n",
    "        exp_pos = exp_part\n",
    "        exp_neg = 0\n",
    "\n",
    "    exp_pos = abs(exp_pos)    \n",
    "    exp_neg = abs(exp_neg)\n",
    "    \n",
    "    rep_str = str(\"{:03}{:03}{:012}\".format(exp_pos,exp_neg,dec_part))\n",
    "    print(rep_str)\n",
    "    \n",
    "    print(dec_part)\n",
    "    rep_int = int(rep_str) * c\n",
    "    rep_bin = bitstring.Bits(int=rep_int, length=64).bin\n",
    "    print(rep_bin)\n",
    "\n",
    "    bin_tensor = torch.tensor(np.array([float(x) for x in rep_bin]))\n",
    "    return bin_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.00000000000E+00\n",
      "000000200000000000\n",
      "200000000000\n",
      "0000000000000000000000000010111010010000111011011101000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2vec(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import fasttext\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('./resources/fasttext.bin')\n",
    "print(ft.get_dimension())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttex_simple(value):\n",
    "    if is_number(value):\n",
    "        value = str(value)\n",
    "    \n",
    "    values = value.split(\"|\")\n",
    "    out_tensor = torch.zeros(300)\n",
    "    for v in values:\n",
    "        out_tensor = out_tensor + torch.tensor(ft.get_sentence_vector(value))\n",
    "    out_tensor = out_tensor / len(values)\n",
    "    return out_tensor\n",
    "    \n",
    "def fasttex_(value):\n",
    "    value = str(value)\n",
    "    values = value.split(\"|\")\n",
    "    out_tensor = torch.zeros(364)\n",
    "    for v in values:\n",
    "        if is_number(v):\n",
    "            value_f = float(v)\n",
    "            bin_tensor = num2vec(value_f)\n",
    "            out_tensor = out_tensor + torch.cat((torch.zeros(300),bin_tensor.float()))\n",
    "        else:\n",
    "            str_tensor = torch.tensor(ft.get_sentence_vector(value))\n",
    "            out_tensor = out_tensor + torch.cat((str_tensor.float(),torch.zeros(64)))\n",
    "    out_tensor = out_tensor / len(values)\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(data, model):\n",
    "    if model==\"fasttext\":\n",
    "        return fasttex_(data)\n",
    "    if model==\"bert\":\n",
    "        return bert(data)\n",
    "    if model==\"fasttext_simple\":\n",
    "        return fasttex_simple(data)\n",
    "    if model==\"bert_simple\":\n",
    "        return bert_simple(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_monitorfasttext_short2.gpickle\n"
     ]
    }
   ],
   "source": [
    "#build graph\n",
    "word_emb = \"fasttext\"\n",
    "df_dataset = read_dataset(\"./resources/monitor_clean/ds2.csv\");\n",
    "g = g = nx.Graph()\n",
    "g = graph_dataset_short(df_dataset,g,word_emb)\n",
    "df_attributes = read_dataset(\"./resources/monitor_clean/attr_cat2.csv\");\n",
    "g = graph_attribute_short(df_attributes,g,word_emb)\n",
    "df_attributes_numeric = read_dataset(\"./resources/monitor_clean/attr_num2.csv\");\n",
    "g = graph_attribute_short(df_attributes_numeric,g,word_emb)\n",
    "#write graph to file\n",
    "nx.write_gpickle(g, \"../word_embeddings/clean_monitor_\"+word_emb+\"_short2.gpickle\")\n",
    "print(\"clean_monitor\"+word_emb+\"_short2.gpickle\")\n",
    "##clean with older notation\n",
    "##clean 2 with higher numbers that didnt work\n",
    "##clean 3 with exp+,exp-,fraction\n",
    "##clean 4 with +exp+,+exp-,-exp+,-exp-,fraction with sign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read previously created graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read\n",
    "g = nx.read_gpickle(\"../word_embeddings/clean_monitor_fasttext_short.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = g.subgraph(\"www.best-deal-items.com//display resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(H.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = nx.number_of_nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48911\n"
     ]
    }
   ],
   "source": [
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesg = nx.nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.0223e-03,  6.1975e-03, -8.1225e-03,  6.9885e-02, -4.3083e-02,\n",
       "        -1.8552e-02, -4.3418e-03, -2.6688e-02, -1.4315e-02,  1.9211e-02,\n",
       "        -3.9717e-03, -1.8107e-02,  3.9169e-02,  3.3390e-02,  3.2606e-04,\n",
       "        -1.4275e-01,  2.1018e-02, -2.6587e-02,  2.2666e-02, -1.0658e-01,\n",
       "        -9.2528e-04, -9.0795e-03, -2.1855e-02,  2.5881e-02, -4.2198e-02,\n",
       "         1.1728e-02,  2.2016e-03,  5.4410e-02,  5.2185e-02,  3.6289e-02,\n",
       "         2.4765e-02,  2.1216e-02,  2.8413e-02, -4.8492e-02,  1.8319e-02,\n",
       "         2.0977e-02, -4.5620e-02, -7.1136e-02,  1.7818e-02,  1.2355e-02,\n",
       "        -1.2732e-02, -1.9463e-03, -2.3491e-02,  9.3629e-03, -8.6660e-02,\n",
       "        -1.1051e-02,  6.0026e-03, -8.4843e-02, -1.6608e-02,  2.4070e-02,\n",
       "        -6.8959e-03,  5.4117e-03, -3.5538e-03, -1.4239e-02, -1.4355e-02,\n",
       "         3.3411e-02,  3.4816e-02,  3.3450e-02, -8.9429e-02, -4.6620e-03,\n",
       "        -3.6198e-02, -4.1949e-03, -1.6564e-02, -6.4998e-02,  3.0676e-02,\n",
       "        -7.7396e-02, -2.5179e-02,  2.7802e-02, -2.4632e-02, -3.5316e-02,\n",
       "        -4.4881e-02,  5.8351e-02,  3.7504e-02,  9.3142e-03, -8.9990e-03,\n",
       "        -2.0148e-02,  3.5004e-03,  1.8468e-03,  8.3814e-02, -2.4890e-03,\n",
       "        -3.7417e-02,  1.5579e-02, -1.3141e-02,  6.6198e-02, -1.7328e-02,\n",
       "        -3.0446e-02, -3.5593e-02, -5.3245e-02,  1.5311e-02,  4.4911e-02,\n",
       "        -6.4017e-02,  1.3984e-02,  8.0344e-03, -1.8012e-02,  5.9700e-02,\n",
       "         5.8437e-02,  5.2268e-02, -2.8307e-02, -2.4538e-02, -3.9039e-02,\n",
       "         1.2600e-02, -2.0898e-02, -4.0802e-03, -5.7787e-04,  3.8983e-02,\n",
       "         5.2255e-02,  2.2421e-03, -3.5864e-02,  1.1214e-02, -5.5353e-03,\n",
       "        -6.0705e-03, -9.6975e-03,  2.8305e-02,  1.5474e-02, -1.9059e-02,\n",
       "        -3.1151e-02,  3.9861e-02,  6.3216e-03, -2.0702e-02, -5.2284e-02,\n",
       "         2.6461e-02,  1.5926e-02,  5.2822e-02,  4.4370e-02,  2.5177e-02,\n",
       "        -1.8226e-02, -2.2144e-03,  2.6832e-02, -1.1650e-02, -4.6141e-03,\n",
       "        -2.1922e-02,  2.2065e-03,  7.2876e-03,  4.3272e-02,  1.1567e-02,\n",
       "         2.9750e-03,  1.8126e-02,  2.1038e-02, -6.7944e-03, -1.4507e-03,\n",
       "         4.7377e-02,  1.6369e-02,  1.2757e-02, -4.1474e-03, -2.2468e-02,\n",
       "        -1.2322e-02, -1.2236e-01,  3.4048e-02,  3.4908e-02, -6.0343e-03,\n",
       "        -9.0887e-05,  2.3433e-02, -6.4637e-02,  7.9437e-03,  1.1445e-02,\n",
       "         1.2153e-02,  3.3150e-02, -3.8668e-02,  1.5239e-02, -2.8595e-02,\n",
       "        -3.4320e-02, -2.2047e-02, -1.5915e-02,  3.8743e-03,  3.3198e-02,\n",
       "        -5.4923e-02, -1.7569e-03,  2.8335e-02, -2.7278e-02,  9.0660e-03,\n",
       "        -2.0371e-02,  3.7805e-02,  3.1789e-02,  3.5152e-03, -2.4988e-02,\n",
       "         1.1354e-03,  1.8083e-03, -9.5454e-03,  1.4470e-02, -2.2350e-02,\n",
       "        -3.8525e-02, -3.8233e-02, -6.6268e-02, -2.6951e-02,  3.0255e-02,\n",
       "        -6.9827e-03, -3.3250e-02, -1.1741e-03, -2.3160e-02,  8.8067e-03,\n",
       "        -2.2282e-02, -4.8159e-02,  1.3607e-02,  6.1418e-02,  1.8869e-02,\n",
       "        -5.2079e-03, -4.7250e-02,  6.3168e-03, -9.1193e-03, -2.7059e-02,\n",
       "        -2.7057e-02,  8.3624e-02,  2.5816e-02,  4.4613e-02, -4.8659e-02,\n",
       "         9.0444e-03, -3.1829e-02,  3.1114e-02, -2.5998e-02,  3.7485e-02,\n",
       "         9.9064e-02, -1.7141e-02,  1.1138e-02, -4.1451e-02,  2.5761e-03,\n",
       "         4.0957e-02,  1.8257e-02,  4.4891e-02, -2.2530e-03, -2.7876e-02,\n",
       "        -1.0825e-02, -4.1755e-02, -3.5807e-03,  4.0029e-02, -4.3301e-02,\n",
       "         2.5232e-02,  1.5342e-02,  3.4365e-03,  2.7283e-02,  4.0496e-02,\n",
       "         2.0138e-02,  1.3832e-03,  2.5213e-02,  5.5080e-02,  2.1390e-02,\n",
       "         4.5289e-02,  5.9057e-03, -4.1020e-02,  7.0203e-03,  2.3875e-02,\n",
       "        -1.6660e-02, -9.6001e-03, -7.1890e-02, -6.0807e-02,  1.1547e-01,\n",
       "        -1.2434e-03,  2.7718e-02,  7.9543e-03,  3.7538e-02,  4.5532e-02,\n",
       "         3.4013e-02, -4.9550e-02,  5.3593e-02, -1.2184e-02,  3.6978e-02,\n",
       "         8.7817e-02, -7.7984e-03, -4.7176e-02, -2.7414e-02, -1.2665e-02,\n",
       "        -4.2313e-02, -4.4672e-03, -9.1989e-02,  3.2958e-03, -4.8708e-02,\n",
       "         6.8277e-03, -2.1059e-02, -3.9994e-02,  2.8382e-02, -1.3393e-03,\n",
       "        -1.1161e-02,  9.3443e-03,  2.9910e-02, -8.0906e-02,  2.0227e-02,\n",
       "         1.9965e-02,  3.1429e-02,  8.6169e-02, -5.8954e-02,  3.9058e-02,\n",
       "        -2.8768e-03, -1.1881e-01, -9.0308e-02, -1.9342e-02,  1.2775e-02,\n",
       "        -5.3448e-03,  1.7409e-04,  7.3272e-03, -1.4908e-02, -4.3664e-02,\n",
       "         9.6121e-02, -1.0749e-03, -5.1555e-02,  3.2784e-02, -1.7551e-02,\n",
       "        -4.7627e-02,  2.8187e-02,  9.0237e-02, -2.6445e-02,  1.9734e-02,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodesg[\"number distinct values|DS_ca.pcpartpicker.com//builtin speakers\"][\"vector\"]*2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
